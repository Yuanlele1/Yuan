Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=38, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_180_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_180_336_FITS_ETTm2_ftM_sl180_ll48_pl336_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34045
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=38, out_features=108, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3677184.0
params:  4212.0
Trainable parameters:  4212
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3826575
	speed: 0.0180s/iter; left time: 475.0326s
	iters: 200, epoch: 1 | loss: 0.4257440
	speed: 0.0119s/iter; left time: 313.3147s
Epoch: 1 cost time: 4.863301038742065
Epoch: 1, Steps: 265 | Train Loss: 0.4987539 Vali Loss: 0.2261763 Test Loss: 0.3099577
Validation loss decreased (inf --> 0.226176).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5527768
	speed: 0.0689s/iter; left time: 1801.5632s
	iters: 200, epoch: 2 | loss: 0.3944102
	speed: 0.0107s/iter; left time: 279.7175s
Epoch: 2 cost time: 3.799686908721924
Epoch: 2, Steps: 265 | Train Loss: 0.4412757 Vali Loss: 0.2157285 Test Loss: 0.2978432
Validation loss decreased (0.226176 --> 0.215728).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3407569
	speed: 0.0521s/iter; left time: 1347.6423s
	iters: 200, epoch: 3 | loss: 0.6395475
	speed: 0.0114s/iter; left time: 294.4051s
Epoch: 3 cost time: 3.5127859115600586
Epoch: 3, Steps: 265 | Train Loss: 0.4318463 Vali Loss: 0.2126378 Test Loss: 0.2935858
Validation loss decreased (0.215728 --> 0.212638).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3656343
	speed: 0.0674s/iter; left time: 1726.3672s
	iters: 200, epoch: 4 | loss: 0.4445809
	speed: 0.0129s/iter; left time: 330.2169s
Epoch: 4 cost time: 3.9870948791503906
Epoch: 4, Steps: 265 | Train Loss: 0.4272833 Vali Loss: 0.2109376 Test Loss: 0.2913350
Validation loss decreased (0.212638 --> 0.210938).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4173141
	speed: 0.0964s/iter; left time: 2443.4644s
	iters: 200, epoch: 5 | loss: 0.2807252
	speed: 0.0119s/iter; left time: 300.9920s
Epoch: 5 cost time: 5.3612236976623535
Epoch: 5, Steps: 265 | Train Loss: 0.4252791 Vali Loss: 0.2098629 Test Loss: 0.2899165
Validation loss decreased (0.210938 --> 0.209863).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4863365
	speed: 0.0663s/iter; left time: 1663.5753s
	iters: 200, epoch: 6 | loss: 0.4968978
	speed: 0.0167s/iter; left time: 416.5233s
Epoch: 6 cost time: 4.965860366821289
Epoch: 6, Steps: 265 | Train Loss: 0.4233308 Vali Loss: 0.2092770 Test Loss: 0.2889644
Validation loss decreased (0.209863 --> 0.209277).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3992904
	speed: 0.0558s/iter; left time: 1384.7221s
	iters: 200, epoch: 7 | loss: 0.6104768
	speed: 0.0102s/iter; left time: 252.1641s
Epoch: 7 cost time: 3.3375234603881836
Epoch: 7, Steps: 265 | Train Loss: 0.4221256 Vali Loss: 0.2087673 Test Loss: 0.2881105
Validation loss decreased (0.209277 --> 0.208767).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4929101
	speed: 0.0555s/iter; left time: 1363.3207s
	iters: 200, epoch: 8 | loss: 0.6141440
	speed: 0.0108s/iter; left time: 264.3191s
Epoch: 8 cost time: 3.5034446716308594
Epoch: 8, Steps: 265 | Train Loss: 0.4211297 Vali Loss: 0.2083594 Test Loss: 0.2874196
Validation loss decreased (0.208767 --> 0.208359).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3006667
	speed: 0.0548s/iter; left time: 1329.9350s
	iters: 200, epoch: 9 | loss: 0.4210507
	speed: 0.0111s/iter; left time: 269.3656s
Epoch: 9 cost time: 3.5376436710357666
Epoch: 9, Steps: 265 | Train Loss: 0.4197406 Vali Loss: 0.2080470 Test Loss: 0.2871029
Validation loss decreased (0.208359 --> 0.208047).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3344926
	speed: 0.0578s/iter; left time: 1388.2465s
	iters: 200, epoch: 10 | loss: 0.4630725
	speed: 0.0135s/iter; left time: 323.7824s
Epoch: 10 cost time: 4.170498847961426
Epoch: 10, Steps: 265 | Train Loss: 0.4194870 Vali Loss: 0.2080951 Test Loss: 0.2867326
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4867069
	speed: 0.0614s/iter; left time: 1457.6565s
	iters: 200, epoch: 11 | loss: 0.2622063
	speed: 0.0115s/iter; left time: 270.9135s
Epoch: 11 cost time: 3.697108030319214
Epoch: 11, Steps: 265 | Train Loss: 0.4191033 Vali Loss: 0.2077556 Test Loss: 0.2864389
Validation loss decreased (0.208047 --> 0.207756).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.6949784
	speed: 0.0643s/iter; left time: 1509.9776s
	iters: 200, epoch: 12 | loss: 0.4668934
	speed: 0.0216s/iter; left time: 506.1579s
Epoch: 12 cost time: 4.562146425247192
Epoch: 12, Steps: 265 | Train Loss: 0.4176791 Vali Loss: 0.2076292 Test Loss: 0.2861479
Validation loss decreased (0.207756 --> 0.207629).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3729443
	speed: 0.0704s/iter; left time: 1635.6184s
	iters: 200, epoch: 13 | loss: 0.6369016
	speed: 0.0122s/iter; left time: 283.2023s
Epoch: 13 cost time: 3.916619300842285
Epoch: 13, Steps: 265 | Train Loss: 0.4183790 Vali Loss: 0.2075101 Test Loss: 0.2860245
Validation loss decreased (0.207629 --> 0.207510).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3636798
	speed: 0.0661s/iter; left time: 1517.5435s
	iters: 200, epoch: 14 | loss: 0.5364745
	speed: 0.0137s/iter; left time: 312.5012s
Epoch: 14 cost time: 4.175634860992432
Epoch: 14, Steps: 265 | Train Loss: 0.4175856 Vali Loss: 0.2073693 Test Loss: 0.2858196
Validation loss decreased (0.207510 --> 0.207369).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4683308
	speed: 0.0569s/iter; left time: 1290.0738s
	iters: 200, epoch: 15 | loss: 0.3092021
	speed: 0.0114s/iter; left time: 257.9661s
Epoch: 15 cost time: 3.7408416271209717
Epoch: 15, Steps: 265 | Train Loss: 0.4175746 Vali Loss: 0.2072797 Test Loss: 0.2857089
Validation loss decreased (0.207369 --> 0.207280).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3959249
	speed: 0.0559s/iter; left time: 1252.7397s
	iters: 200, epoch: 16 | loss: 0.4100663
	speed: 0.0100s/iter; left time: 224.3536s
Epoch: 16 cost time: 3.310257911682129
Epoch: 16, Steps: 265 | Train Loss: 0.4175286 Vali Loss: 0.2072963 Test Loss: 0.2855970
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2963074
	speed: 0.0520s/iter; left time: 1153.0916s
	iters: 200, epoch: 17 | loss: 0.3464159
	speed: 0.0103s/iter; left time: 226.5091s
Epoch: 17 cost time: 3.2920174598693848
Epoch: 17, Steps: 265 | Train Loss: 0.4175682 Vali Loss: 0.2073862 Test Loss: 0.2854919
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3470249
	speed: 0.0545s/iter; left time: 1192.6000s
	iters: 200, epoch: 18 | loss: 0.3082080
	speed: 0.0110s/iter; left time: 238.8863s
Epoch: 18 cost time: 3.4456675052642822
Epoch: 18, Steps: 265 | Train Loss: 0.4172033 Vali Loss: 0.2073010 Test Loss: 0.2853658
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2944179
	speed: 0.0719s/iter; left time: 1555.6989s
	iters: 200, epoch: 19 | loss: 0.3829189
	speed: 0.0437s/iter; left time: 940.1118s
Epoch: 19 cost time: 10.813763618469238
Epoch: 19, Steps: 265 | Train Loss: 0.4169955 Vali Loss: 0.2071719 Test Loss: 0.2853015
Validation loss decreased (0.207280 --> 0.207172).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.5213552
	speed: 0.0771s/iter; left time: 1646.7828s
	iters: 200, epoch: 20 | loss: 0.3626299
	speed: 0.0106s/iter; left time: 224.3674s
Epoch: 20 cost time: 3.2090675830841064
Epoch: 20, Steps: 265 | Train Loss: 0.4166293 Vali Loss: 0.2071049 Test Loss: 0.2852476
Validation loss decreased (0.207172 --> 0.207105).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.5275252
	speed: 0.0551s/iter; left time: 1163.6851s
	iters: 200, epoch: 21 | loss: 0.4924444
	speed: 0.0107s/iter; left time: 225.0842s
Epoch: 21 cost time: 3.4220778942108154
Epoch: 21, Steps: 265 | Train Loss: 0.4164469 Vali Loss: 0.2071818 Test Loss: 0.2851615
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2658967
	speed: 0.0706s/iter; left time: 1470.5440s
	iters: 200, epoch: 22 | loss: 0.4205965
	speed: 0.0172s/iter; left time: 357.5931s
Epoch: 22 cost time: 4.3949830532073975
Epoch: 22, Steps: 265 | Train Loss: 0.4165848 Vali Loss: 0.2072563 Test Loss: 0.2851448
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4031482
	speed: 0.0636s/iter; left time: 1307.5254s
	iters: 200, epoch: 23 | loss: 0.4538102
	speed: 0.0129s/iter; left time: 263.1207s
Epoch: 23 cost time: 4.802340269088745
Epoch: 23, Steps: 265 | Train Loss: 0.4172822 Vali Loss: 0.2071658 Test Loss: 0.2850829
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3879289
	speed: 0.0581s/iter; left time: 1180.2819s
	iters: 200, epoch: 24 | loss: 0.4938625
	speed: 0.0103s/iter; left time: 208.5941s
Epoch: 24 cost time: 3.3883249759674072
Epoch: 24, Steps: 265 | Train Loss: 0.4172312 Vali Loss: 0.2071763 Test Loss: 0.2850610
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3694689
	speed: 0.0534s/iter; left time: 1070.5290s
	iters: 200, epoch: 25 | loss: 0.3920109
	speed: 0.0105s/iter; left time: 208.9508s
Epoch: 25 cost time: 3.3361730575561523
Epoch: 25, Steps: 265 | Train Loss: 0.4167687 Vali Loss: 0.2071463 Test Loss: 0.2850177
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3805466
	speed: 0.0558s/iter; left time: 1103.6737s
	iters: 200, epoch: 26 | loss: 0.3389588
	speed: 0.0116s/iter; left time: 228.9491s
Epoch: 26 cost time: 3.653653860092163
Epoch: 26, Steps: 265 | Train Loss: 0.4164848 Vali Loss: 0.2070700 Test Loss: 0.2849957
Validation loss decreased (0.207105 --> 0.207070).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4199589
	speed: 0.0524s/iter; left time: 1022.3349s
	iters: 200, epoch: 27 | loss: 0.2520000
	speed: 0.0106s/iter; left time: 206.3042s
Epoch: 27 cost time: 3.320929765701294
Epoch: 27, Steps: 265 | Train Loss: 0.4170035 Vali Loss: 0.2069732 Test Loss: 0.2849759
Validation loss decreased (0.207070 --> 0.206973).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4582162
	speed: 0.0506s/iter; left time: 973.2250s
	iters: 200, epoch: 28 | loss: 0.4859463
	speed: 0.0106s/iter; left time: 202.1859s
Epoch: 28 cost time: 3.2847163677215576
Epoch: 28, Steps: 265 | Train Loss: 0.4167113 Vali Loss: 0.2069964 Test Loss: 0.2849441
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3235821
	speed: 0.0509s/iter; left time: 965.2115s
	iters: 200, epoch: 29 | loss: 0.6294379
	speed: 0.0103s/iter; left time: 195.3673s
Epoch: 29 cost time: 3.1648178100585938
Epoch: 29, Steps: 265 | Train Loss: 0.4167191 Vali Loss: 0.2071872 Test Loss: 0.2849192
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3823130
	speed: 0.0522s/iter; left time: 977.2653s
	iters: 200, epoch: 30 | loss: 0.5858738
	speed: 0.0105s/iter; left time: 196.3527s
Epoch: 30 cost time: 3.2688302993774414
Epoch: 30, Steps: 265 | Train Loss: 0.4164519 Vali Loss: 0.2069988 Test Loss: 0.2849133
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.5149272
	speed: 0.0517s/iter; left time: 954.1481s
	iters: 200, epoch: 31 | loss: 0.3811576
	speed: 0.0103s/iter; left time: 189.6118s
Epoch: 31 cost time: 3.263023614883423
Epoch: 31, Steps: 265 | Train Loss: 0.4161835 Vali Loss: 0.2071207 Test Loss: 0.2848911
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4578155
	speed: 0.0523s/iter; left time: 951.5302s
	iters: 200, epoch: 32 | loss: 0.2900862
	speed: 0.0105s/iter; left time: 189.4284s
Epoch: 32 cost time: 3.3147623538970947
Epoch: 32, Steps: 265 | Train Loss: 0.4167654 Vali Loss: 0.2070654 Test Loss: 0.2848679
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.5733004
	speed: 0.0521s/iter; left time: 933.2779s
	iters: 200, epoch: 33 | loss: 0.4431400
	speed: 0.0103s/iter; left time: 184.2460s
Epoch: 33 cost time: 3.3677735328674316
Epoch: 33, Steps: 265 | Train Loss: 0.4166348 Vali Loss: 0.2072655 Test Loss: 0.2848513
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3970788
	speed: 0.0581s/iter; left time: 1025.8183s
	iters: 200, epoch: 34 | loss: 0.5530249
	speed: 0.0114s/iter; left time: 200.9998s
Epoch: 34 cost time: 3.615976095199585
Epoch: 34, Steps: 265 | Train Loss: 0.4163030 Vali Loss: 0.2070750 Test Loss: 0.2848442
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4348470
	speed: 0.0584s/iter; left time: 1015.0006s
	iters: 200, epoch: 35 | loss: 0.3009909
	speed: 0.0108s/iter; left time: 186.9583s
Epoch: 35 cost time: 3.526461124420166
Epoch: 35, Steps: 265 | Train Loss: 0.4153267 Vali Loss: 0.2070042 Test Loss: 0.2848102
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3562841
	speed: 0.0593s/iter; left time: 1016.0194s
	iters: 200, epoch: 36 | loss: 0.4631868
	speed: 0.0125s/iter; left time: 213.1221s
Epoch: 36 cost time: 3.7441818714141846
Epoch: 36, Steps: 265 | Train Loss: 0.4159738 Vali Loss: 0.2071235 Test Loss: 0.2847913
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.5781994
	speed: 0.0554s/iter; left time: 934.6946s
	iters: 200, epoch: 37 | loss: 0.3433292
	speed: 0.0112s/iter; left time: 188.4130s
Epoch: 37 cost time: 3.6404778957366943
Epoch: 37, Steps: 265 | Train Loss: 0.4165950 Vali Loss: 0.2070866 Test Loss: 0.2848036
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3039752
	speed: 0.0548s/iter; left time: 910.2610s
	iters: 200, epoch: 38 | loss: 0.4649259
	speed: 0.0118s/iter; left time: 194.4820s
Epoch: 38 cost time: 3.6100387573242188
Epoch: 38, Steps: 265 | Train Loss: 0.4159426 Vali Loss: 0.2071609 Test Loss: 0.2847741
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4178764
	speed: 0.0541s/iter; left time: 884.1643s
	iters: 200, epoch: 39 | loss: 0.4267643
	speed: 0.0100s/iter; left time: 162.6098s
Epoch: 39 cost time: 3.343925714492798
Epoch: 39, Steps: 265 | Train Loss: 0.4162332 Vali Loss: 0.2070986 Test Loss: 0.2847691
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.3391727
	speed: 0.0655s/iter; left time: 1052.6410s
	iters: 200, epoch: 40 | loss: 0.3950001
	speed: 0.0112s/iter; left time: 178.5124s
Epoch: 40 cost time: 4.134615421295166
Epoch: 40, Steps: 265 | Train Loss: 0.4157536 Vali Loss: 0.2069861 Test Loss: 0.2847630
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.5332490
	speed: 0.0565s/iter; left time: 892.6606s
	iters: 200, epoch: 41 | loss: 0.5063668
	speed: 0.0106s/iter; left time: 166.4823s
Epoch: 41 cost time: 3.4719016551971436
Epoch: 41, Steps: 265 | Train Loss: 0.4166111 Vali Loss: 0.2071600 Test Loss: 0.2847590
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3318914
	speed: 0.0542s/iter; left time: 842.3218s
	iters: 200, epoch: 42 | loss: 0.4564876
	speed: 0.0115s/iter; left time: 176.8987s
Epoch: 42 cost time: 3.6237149238586426
Epoch: 42, Steps: 265 | Train Loss: 0.4154787 Vali Loss: 0.2070564 Test Loss: 0.2847525
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3789278
	speed: 0.0558s/iter; left time: 852.8085s
	iters: 200, epoch: 43 | loss: 0.5145543
	speed: 0.0113s/iter; left time: 171.1715s
Epoch: 43 cost time: 3.5498504638671875
Epoch: 43, Steps: 265 | Train Loss: 0.4165574 Vali Loss: 0.2071655 Test Loss: 0.2847401
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.4318829
	speed: 0.0567s/iter; left time: 850.1685s
	iters: 200, epoch: 44 | loss: 0.3164669
	speed: 0.0107s/iter; left time: 160.1801s
Epoch: 44 cost time: 3.4676239490509033
Epoch: 44, Steps: 265 | Train Loss: 0.4158800 Vali Loss: 0.2071875 Test Loss: 0.2847354
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.4203452
	speed: 0.0535s/iter; left time: 789.0735s
	iters: 200, epoch: 45 | loss: 0.3759771
	speed: 0.0101s/iter; left time: 148.2808s
Epoch: 45 cost time: 3.3718020915985107
Epoch: 45, Steps: 265 | Train Loss: 0.4159705 Vali Loss: 0.2071808 Test Loss: 0.2847331
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.3558383
	speed: 0.0544s/iter; left time: 787.8629s
	iters: 200, epoch: 46 | loss: 0.2540675
	speed: 0.0122s/iter; left time: 176.0920s
Epoch: 46 cost time: 3.600507974624634
Epoch: 46, Steps: 265 | Train Loss: 0.4158976 Vali Loss: 0.2071763 Test Loss: 0.2847314
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.3733784
	speed: 0.0520s/iter; left time: 739.4475s
	iters: 200, epoch: 47 | loss: 0.3651211
	speed: 0.0106s/iter; left time: 149.5728s
Epoch: 47 cost time: 3.3198795318603516
Epoch: 47, Steps: 265 | Train Loss: 0.4163652 Vali Loss: 0.2070672 Test Loss: 0.2847205
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_180_336_FITS_ETTm2_ftM_sl180_ll48_pl336_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.28623151779174805, mae:0.33157604932785034, rse:0.4321349263191223, corr:[0.56100076 0.5607271  0.5545973  0.554589   0.555684   0.55360967
 0.55111563 0.55090636 0.55156213 0.5507668  0.5490292  0.54839164
 0.54895777 0.549037   0.54788136 0.5466225  0.54640085 0.5466306
 0.54614073 0.5449187  0.5439591  0.5436967  0.5434891  0.5427772
 0.54188603 0.54152566 0.5416345  0.5413731  0.54041666 0.53939956
 0.5389957  0.53894615 0.5385132  0.53760016 0.53679276 0.53651583
 0.5363311  0.5357335  0.53471047 0.5337934  0.5333312  0.5331096
 0.53277653 0.5322993  0.53188664 0.5315769  0.53105414 0.5301612
 0.5291228  0.52829427 0.52772087 0.5272214  0.5265967  0.52592534
 0.5254342  0.5251001  0.5246316  0.5240712  0.5235816  0.5232858
 0.5230304  0.52276456 0.52253133 0.52233815 0.52223927 0.5221473
 0.521921   0.52164686 0.5214707  0.5214424  0.5213621  0.52116334
 0.5209316  0.5207006  0.52051884 0.5202598  0.51992184 0.519536
 0.5191785  0.5188255  0.51840454 0.5179276  0.51748395 0.5170724
 0.516676   0.51626205 0.51581764 0.5153908  0.5149613  0.51454103
 0.5142014  0.5139142  0.5134833  0.51271874 0.5115648  0.51005363
 0.50831044 0.5065432  0.50479525 0.50315464 0.5017304  0.50052255
 0.4993717  0.49812794 0.49675143 0.49536753 0.49410784 0.49300084
 0.4919627  0.49087188 0.48989353 0.4890357  0.48825508 0.48739025
 0.48628607 0.485072   0.48389918 0.48286968 0.4820013  0.48112765
 0.48021364 0.47925466 0.4782852  0.4773409  0.47646403 0.4756533
 0.47485054 0.47397396 0.4729877  0.47195852 0.47104326 0.4702503
 0.4695068  0.4686544  0.4678598  0.4672872  0.46686804 0.46647525
 0.46592867 0.46528342 0.4647224  0.46429485 0.4638108  0.46303505
 0.4620202  0.46101442 0.46015254 0.45938292 0.45861349 0.45781836
 0.4572351  0.45698902 0.45667246 0.4561321  0.4555343  0.455075
 0.45473823 0.4543421  0.45375955 0.4532748  0.45313022 0.4531451
 0.4530254  0.45258582 0.45224983 0.4522263  0.45236242 0.45239916
 0.45224667 0.4521628  0.452317   0.45257118 0.45268166 0.45251948
 0.4523449  0.45230028 0.45231396 0.45217243 0.45190457 0.4517398
 0.45169333 0.45157614 0.45129314 0.4508721  0.45054892 0.45037517
 0.45023954 0.44997507 0.44950733 0.44884327 0.44788212 0.4464703
 0.4446925  0.44298816 0.4416195  0.44051272 0.439398   0.4380346
 0.4366312  0.43552482 0.43469667 0.43395346 0.43306804 0.43224308
 0.43165213 0.43115643 0.43042034 0.4294815  0.4286424  0.428016
 0.4274957  0.42691928 0.42624182 0.4255822  0.42496648 0.4242279
 0.4233579  0.42240912 0.4216797  0.42099616 0.4200997  0.41905987
 0.41803715 0.41723946 0.41668972 0.4160763  0.4154178  0.41476387
 0.4140045  0.41306964 0.41202047 0.41115025 0.4105725  0.4102593
 0.4098991  0.40949607 0.4092151  0.408934   0.40865302 0.4082428
 0.40774813 0.4072655  0.40682045 0.40644976 0.40607524 0.4057836
 0.4057711  0.40595546 0.40615317 0.40619224 0.40622854 0.40638435
 0.40656698 0.40677166 0.4068941  0.40700403 0.4071717  0.40728304
 0.4071487  0.40682638 0.40664253 0.40685588 0.40713072 0.40707293
 0.40682033 0.40677783 0.40707433 0.40734416 0.40734598 0.4071774
 0.40703684 0.40701783 0.4067954  0.40637752 0.4060833  0.40624592
 0.4066646  0.4068679  0.4067324  0.40647587 0.4063183  0.40639195
 0.4064554  0.4062854  0.4060461  0.405851   0.4054416  0.40448782
 0.403082   0.4019336  0.40113735 0.4005115  0.3996909  0.39873648
 0.39809734 0.39769518 0.39725152 0.39654723 0.39583212 0.39530903
 0.39497954 0.39445046 0.3937272  0.39301434 0.39234588 0.39160827
 0.3908311  0.3900719  0.3894053  0.3887421  0.38794127 0.38711235
 0.3863613  0.3857977  0.38503867 0.38411322 0.3831534  0.38237858
 0.3815027  0.38026115 0.37897342 0.37828928 0.3781859  0.37769908
 0.37640136 0.37498528 0.37453714 0.37456584 0.37368953 0.3721364
 0.37169516 0.37274346 0.37283814 0.37098762 0.370459   0.37598345]
