Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=20, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_90_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_90_336_FITS_ETTm2_ftM_sl90_ll48_pl336_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=20, out_features=94, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1684480.0
params:  1974.0
Trainable parameters:  1974
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4689154
	speed: 0.0191s/iter; left time: 505.5282s
	iters: 200, epoch: 1 | loss: 0.6378524
	speed: 0.0125s/iter; left time: 329.6341s
Epoch: 1 cost time: 3.9524714946746826
Epoch: 1, Steps: 266 | Train Loss: 0.4630533 Vali Loss: 0.2525803 Test Loss: 0.3495093
Validation loss decreased (inf --> 0.252580).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5264201
	speed: 0.0716s/iter; left time: 1878.4878s
	iters: 200, epoch: 2 | loss: 0.5707192
	speed: 0.0118s/iter; left time: 307.7824s
Epoch: 2 cost time: 3.7334988117218018
Epoch: 2, Steps: 266 | Train Loss: 0.3772763 Vali Loss: 0.2270354 Test Loss: 0.3188103
Validation loss decreased (0.252580 --> 0.227035).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2908350
	speed: 0.0638s/iter; left time: 1655.8484s
	iters: 200, epoch: 3 | loss: 0.3612140
	speed: 0.0128s/iter; left time: 331.2589s
Epoch: 3 cost time: 3.9845051765441895
Epoch: 3, Steps: 266 | Train Loss: 0.3593376 Vali Loss: 0.2209842 Test Loss: 0.3115899
Validation loss decreased (0.227035 --> 0.220984).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4125467
	speed: 0.0663s/iter; left time: 1704.5657s
	iters: 200, epoch: 4 | loss: 0.4148314
	speed: 0.0132s/iter; left time: 337.0516s
Epoch: 4 cost time: 4.011583566665649
Epoch: 4, Steps: 266 | Train Loss: 0.3549190 Vali Loss: 0.2191114 Test Loss: 0.3094788
Validation loss decreased (0.220984 --> 0.219111).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3660804
	speed: 0.0653s/iter; left time: 1661.5009s
	iters: 200, epoch: 5 | loss: 0.2364251
	speed: 0.0130s/iter; left time: 330.2874s
Epoch: 5 cost time: 3.918489933013916
Epoch: 5, Steps: 266 | Train Loss: 0.3533893 Vali Loss: 0.2184447 Test Loss: 0.3083939
Validation loss decreased (0.219111 --> 0.218445).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4403737
	speed: 0.0678s/iter; left time: 1705.7326s
	iters: 200, epoch: 6 | loss: 0.3347159
	speed: 0.0134s/iter; left time: 336.1376s
Epoch: 6 cost time: 4.067799806594849
Epoch: 6, Steps: 266 | Train Loss: 0.3527256 Vali Loss: 0.2183654 Test Loss: 0.3080648
Validation loss decreased (0.218445 --> 0.218365).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2760693
	speed: 0.0667s/iter; left time: 1661.9454s
	iters: 200, epoch: 7 | loss: 0.3358760
	speed: 0.0131s/iter; left time: 323.9671s
Epoch: 7 cost time: 4.098221778869629
Epoch: 7, Steps: 266 | Train Loss: 0.3519329 Vali Loss: 0.2184304 Test Loss: 0.3079337
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2969828
	speed: 0.0658s/iter; left time: 1621.2413s
	iters: 200, epoch: 8 | loss: 0.4347573
	speed: 0.0127s/iter; left time: 312.4626s
Epoch: 8 cost time: 3.9066309928894043
Epoch: 8, Steps: 266 | Train Loss: 0.3514451 Vali Loss: 0.2182429 Test Loss: 0.3078358
Validation loss decreased (0.218365 --> 0.218243).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2352867
	speed: 0.0667s/iter; left time: 1625.5901s
	iters: 200, epoch: 9 | loss: 0.4383255
	speed: 0.0132s/iter; left time: 319.2612s
Epoch: 9 cost time: 4.064488172531128
Epoch: 9, Steps: 266 | Train Loss: 0.3512701 Vali Loss: 0.2182030 Test Loss: 0.3077322
Validation loss decreased (0.218243 --> 0.218203).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3903064
	speed: 0.0656s/iter; left time: 1582.4021s
	iters: 200, epoch: 10 | loss: 0.4076951
	speed: 0.0154s/iter; left time: 370.0936s
Epoch: 10 cost time: 5.575603246688843
Epoch: 10, Steps: 266 | Train Loss: 0.3509315 Vali Loss: 0.2184767 Test Loss: 0.3077427
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2842569
	speed: 0.0770s/iter; left time: 1836.0665s
	iters: 200, epoch: 11 | loss: 0.3892418
	speed: 0.0138s/iter; left time: 327.6235s
Epoch: 11 cost time: 4.129554986953735
Epoch: 11, Steps: 266 | Train Loss: 0.3509615 Vali Loss: 0.2184591 Test Loss: 0.3077111
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.5647706
	speed: 0.0636s/iter; left time: 1499.5933s
	iters: 200, epoch: 12 | loss: 0.3377750
	speed: 0.0129s/iter; left time: 302.6034s
Epoch: 12 cost time: 3.925593614578247
Epoch: 12, Steps: 266 | Train Loss: 0.3505589 Vali Loss: 0.2184205 Test Loss: 0.3077091
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4683008
	speed: 0.0638s/iter; left time: 1486.5993s
	iters: 200, epoch: 13 | loss: 0.3963057
	speed: 0.0117s/iter; left time: 271.8997s
Epoch: 13 cost time: 3.6418850421905518
Epoch: 13, Steps: 266 | Train Loss: 0.3508161 Vali Loss: 0.2185017 Test Loss: 0.3078079
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4452773
	speed: 0.0624s/iter; left time: 1437.1213s
	iters: 200, epoch: 14 | loss: 0.2553356
	speed: 0.0119s/iter; left time: 272.0494s
Epoch: 14 cost time: 3.7436718940734863
Epoch: 14, Steps: 266 | Train Loss: 0.3508176 Vali Loss: 0.2186885 Test Loss: 0.3077498
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4663417
	speed: 0.0657s/iter; left time: 1496.9597s
	iters: 200, epoch: 15 | loss: 0.2335237
	speed: 0.0123s/iter; left time: 278.1622s
Epoch: 15 cost time: 3.8534557819366455
Epoch: 15, Steps: 266 | Train Loss: 0.3507510 Vali Loss: 0.2185255 Test Loss: 0.3078254
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3820837
	speed: 0.0657s/iter; left time: 1477.9297s
	iters: 200, epoch: 16 | loss: 0.3065124
	speed: 0.0123s/iter; left time: 276.5149s
Epoch: 16 cost time: 3.9300365447998047
Epoch: 16, Steps: 266 | Train Loss: 0.3508445 Vali Loss: 0.2187871 Test Loss: 0.3078965
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4134059
	speed: 0.0653s/iter; left time: 1453.5644s
	iters: 200, epoch: 17 | loss: 0.2505171
	speed: 0.0131s/iter; left time: 289.1520s
Epoch: 17 cost time: 3.9684839248657227
Epoch: 17, Steps: 266 | Train Loss: 0.3505931 Vali Loss: 0.2186878 Test Loss: 0.3078946
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2883196
	speed: 0.0655s/iter; left time: 1439.9499s
	iters: 200, epoch: 18 | loss: 0.4249974
	speed: 0.0134s/iter; left time: 294.1517s
Epoch: 18 cost time: 4.090335130691528
Epoch: 18, Steps: 266 | Train Loss: 0.3502235 Vali Loss: 0.2188419 Test Loss: 0.3079385
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3217309
	speed: 0.0666s/iter; left time: 1445.5250s
	iters: 200, epoch: 19 | loss: 0.2967426
	speed: 0.0134s/iter; left time: 288.7637s
Epoch: 19 cost time: 4.097371578216553
Epoch: 19, Steps: 266 | Train Loss: 0.3503440 Vali Loss: 0.2190281 Test Loss: 0.3079611
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2927842
	speed: 0.0645s/iter; left time: 1382.5465s
	iters: 200, epoch: 20 | loss: 0.4375851
	speed: 0.0119s/iter; left time: 253.1877s
Epoch: 20 cost time: 3.791088342666626
Epoch: 20, Steps: 266 | Train Loss: 0.3502052 Vali Loss: 0.2190678 Test Loss: 0.3079545
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2679271
	speed: 0.0653s/iter; left time: 1383.7030s
	iters: 200, epoch: 21 | loss: 0.5462732
	speed: 0.0133s/iter; left time: 280.1617s
Epoch: 21 cost time: 4.1616692543029785
Epoch: 21, Steps: 266 | Train Loss: 0.3500325 Vali Loss: 0.2191005 Test Loss: 0.3079688
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4219030
	speed: 0.0657s/iter; left time: 1374.9953s
	iters: 200, epoch: 22 | loss: 0.2795320
	speed: 0.0127s/iter; left time: 264.0692s
Epoch: 22 cost time: 3.909203052520752
Epoch: 22, Steps: 266 | Train Loss: 0.3499478 Vali Loss: 0.2189862 Test Loss: 0.3079724
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4134986
	speed: 0.0644s/iter; left time: 1329.0990s
	iters: 200, epoch: 23 | loss: 0.3632311
	speed: 0.0130s/iter; left time: 266.1140s
Epoch: 23 cost time: 3.995664358139038
Epoch: 23, Steps: 266 | Train Loss: 0.3501067 Vali Loss: 0.2190947 Test Loss: 0.3080139
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3826144
	speed: 0.1080s/iter; left time: 2201.6148s
	iters: 200, epoch: 24 | loss: 0.3814213
	speed: 0.0127s/iter; left time: 257.6962s
Epoch: 24 cost time: 4.0245137214660645
Epoch: 24, Steps: 266 | Train Loss: 0.3502363 Vali Loss: 0.2191896 Test Loss: 0.3080117
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3259136
	speed: 0.0651s/iter; left time: 1308.9233s
	iters: 200, epoch: 25 | loss: 0.2980776
	speed: 0.0127s/iter; left time: 253.2882s
Epoch: 25 cost time: 3.9770278930664062
Epoch: 25, Steps: 266 | Train Loss: 0.3501254 Vali Loss: 0.2189895 Test Loss: 0.3080169
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.5104758
	speed: 0.0668s/iter; left time: 1326.4587s
	iters: 200, epoch: 26 | loss: 0.2588564
	speed: 0.0137s/iter; left time: 271.2217s
Epoch: 26 cost time: 4.10631251335144
Epoch: 26, Steps: 266 | Train Loss: 0.3502677 Vali Loss: 0.2190554 Test Loss: 0.3080150
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2138665
	speed: 0.0649s/iter; left time: 1270.9502s
	iters: 200, epoch: 27 | loss: 0.2623899
	speed: 0.0123s/iter; left time: 239.5969s
Epoch: 27 cost time: 3.8210527896881104
Epoch: 27, Steps: 266 | Train Loss: 0.3501961 Vali Loss: 0.2192247 Test Loss: 0.3080404
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3162901
	speed: 0.0663s/iter; left time: 1280.2816s
	iters: 200, epoch: 28 | loss: 0.2768436
	speed: 0.0131s/iter; left time: 252.4496s
Epoch: 28 cost time: 4.04931378364563
Epoch: 28, Steps: 266 | Train Loss: 0.3504309 Vali Loss: 0.2191425 Test Loss: 0.3080400
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3478352
	speed: 0.0679s/iter; left time: 1293.4385s
	iters: 200, epoch: 29 | loss: 0.4158264
	speed: 0.0132s/iter; left time: 250.0547s
Epoch: 29 cost time: 4.130803108215332
Epoch: 29, Steps: 266 | Train Loss: 0.3505693 Vali Loss: 0.2192764 Test Loss: 0.3080393
EarlyStopping counter: 20 out of 20
Early stopping
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=20, out_features=94, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1684480.0
params:  1974.0
Trainable parameters:  1974
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3443891
	speed: 0.0188s/iter; left time: 498.8636s
	iters: 200, epoch: 1 | loss: 0.4928387
	speed: 0.0124s/iter; left time: 326.3257s
Epoch: 1 cost time: 3.8954734802246094
Epoch: 1, Steps: 266 | Train Loss: 0.4421771 Vali Loss: 0.2180035 Test Loss: 0.3073300
Validation loss decreased (inf --> 0.218003).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3907450
	speed: 0.0657s/iter; left time: 1722.3922s
	iters: 200, epoch: 2 | loss: 0.6041857
	speed: 0.0123s/iter; left time: 321.5857s
Epoch: 2 cost time: 3.885498046875
Epoch: 2, Steps: 266 | Train Loss: 0.4419096 Vali Loss: 0.2180854 Test Loss: 0.3073115
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4777871
	speed: 0.0649s/iter; left time: 1685.3631s
	iters: 200, epoch: 3 | loss: 0.5596033
	speed: 0.0125s/iter; left time: 322.7330s
Epoch: 3 cost time: 3.9069786071777344
Epoch: 3, Steps: 266 | Train Loss: 0.4417044 Vali Loss: 0.2185168 Test Loss: 0.3074012
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3136325
	speed: 0.0656s/iter; left time: 1685.2460s
	iters: 200, epoch: 4 | loss: 0.4160235
	speed: 0.0130s/iter; left time: 331.6711s
Epoch: 4 cost time: 4.2446582317352295
Epoch: 4, Steps: 266 | Train Loss: 0.4409834 Vali Loss: 0.2181652 Test Loss: 0.3072717
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3815378
	speed: 0.0666s/iter; left time: 1695.1731s
	iters: 200, epoch: 5 | loss: 0.5485865
	speed: 0.0121s/iter; left time: 307.7945s
Epoch: 5 cost time: 3.7418620586395264
Epoch: 5, Steps: 266 | Train Loss: 0.4411830 Vali Loss: 0.2185490 Test Loss: 0.3073487
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3821593
	speed: 0.0649s/iter; left time: 1633.6338s
	iters: 200, epoch: 6 | loss: 0.3920104
	speed: 0.0118s/iter; left time: 295.8085s
Epoch: 6 cost time: 3.988927125930786
Epoch: 6, Steps: 266 | Train Loss: 0.4408720 Vali Loss: 0.2184927 Test Loss: 0.3074404
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.6224074
	speed: 0.0673s/iter; left time: 1676.4902s
	iters: 200, epoch: 7 | loss: 0.3839087
	speed: 0.0123s/iter; left time: 304.0163s
Epoch: 7 cost time: 3.9230213165283203
Epoch: 7, Steps: 266 | Train Loss: 0.4411142 Vali Loss: 0.2184806 Test Loss: 0.3074223
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.5558074
	speed: 0.0672s/iter; left time: 1654.9312s
	iters: 200, epoch: 8 | loss: 0.4000507
	speed: 0.0133s/iter; left time: 326.7890s
Epoch: 8 cost time: 4.07293963432312
Epoch: 8, Steps: 266 | Train Loss: 0.4406682 Vali Loss: 0.2186161 Test Loss: 0.3074000
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4758859
	speed: 0.0653s/iter; left time: 1592.6426s
	iters: 200, epoch: 9 | loss: 0.3594234
	speed: 0.0130s/iter; left time: 314.3804s
Epoch: 9 cost time: 3.9851956367492676
Epoch: 9, Steps: 266 | Train Loss: 0.4410856 Vali Loss: 0.2185877 Test Loss: 0.3074440
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.5100884
	speed: 0.0664s/iter; left time: 1600.0116s
	iters: 200, epoch: 10 | loss: 0.5472146
	speed: 0.0129s/iter; left time: 308.7876s
Epoch: 10 cost time: 4.0315141677856445
Epoch: 10, Steps: 266 | Train Loss: 0.4404268 Vali Loss: 0.2185979 Test Loss: 0.3074040
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.5030848
	speed: 0.0696s/iter; left time: 1659.2067s
	iters: 200, epoch: 11 | loss: 0.6125835
	speed: 0.0131s/iter; left time: 310.2484s
Epoch: 11 cost time: 4.131971597671509
Epoch: 11, Steps: 266 | Train Loss: 0.4398983 Vali Loss: 0.2188056 Test Loss: 0.3075238
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3605163
	speed: 0.0659s/iter; left time: 1554.0836s
	iters: 200, epoch: 12 | loss: 0.3995199
	speed: 0.0128s/iter; left time: 299.9758s
Epoch: 12 cost time: 3.8713080883026123
Epoch: 12, Steps: 266 | Train Loss: 0.4406287 Vali Loss: 0.2185293 Test Loss: 0.3073988
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4400038
	speed: 0.0629s/iter; left time: 1466.5550s
	iters: 200, epoch: 13 | loss: 0.3950079
	speed: 0.0127s/iter; left time: 294.1480s
Epoch: 13 cost time: 3.8548452854156494
Epoch: 13, Steps: 266 | Train Loss: 0.4404725 Vali Loss: 0.2188519 Test Loss: 0.3075156
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3069362
	speed: 0.0647s/iter; left time: 1491.2800s
	iters: 200, epoch: 14 | loss: 0.5550873
	speed: 0.0123s/iter; left time: 283.2967s
Epoch: 14 cost time: 3.84409761428833
Epoch: 14, Steps: 266 | Train Loss: 0.4410603 Vali Loss: 0.2186075 Test Loss: 0.3074336
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.5220854
	speed: 0.0672s/iter; left time: 1530.9830s
	iters: 200, epoch: 15 | loss: 0.4154553
	speed: 0.0132s/iter; left time: 299.7394s
Epoch: 15 cost time: 4.147449016571045
Epoch: 15, Steps: 266 | Train Loss: 0.4402585 Vali Loss: 0.2189166 Test Loss: 0.3075158
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.5761611
	speed: 0.0676s/iter; left time: 1521.4876s
	iters: 200, epoch: 16 | loss: 0.6123173
	speed: 0.0133s/iter; left time: 298.3016s
Epoch: 16 cost time: 4.082175254821777
Epoch: 16, Steps: 266 | Train Loss: 0.4403065 Vali Loss: 0.2188891 Test Loss: 0.3075137
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4005913
	speed: 0.0663s/iter; left time: 1474.7726s
	iters: 200, epoch: 17 | loss: 0.3957319
	speed: 0.0147s/iter; left time: 325.7225s
Epoch: 17 cost time: 4.183873653411865
Epoch: 17, Steps: 266 | Train Loss: 0.4407612 Vali Loss: 0.2188526 Test Loss: 0.3074925
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4281912
	speed: 0.0668s/iter; left time: 1468.0071s
	iters: 200, epoch: 18 | loss: 0.7859100
	speed: 0.0139s/iter; left time: 304.5696s
Epoch: 18 cost time: 4.143672704696655
Epoch: 18, Steps: 266 | Train Loss: 0.4403447 Vali Loss: 0.2189694 Test Loss: 0.3075141
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4823602
	speed: 0.0635s/iter; left time: 1379.7540s
	iters: 200, epoch: 19 | loss: 0.4276637
	speed: 0.0126s/iter; left time: 272.2830s
Epoch: 19 cost time: 3.8708009719848633
Epoch: 19, Steps: 266 | Train Loss: 0.4405499 Vali Loss: 0.2188833 Test Loss: 0.3075187
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4310651
	speed: 0.1010s/iter; left time: 2166.0375s
	iters: 200, epoch: 20 | loss: 0.3720916
	speed: 0.0121s/iter; left time: 257.8952s
Epoch: 20 cost time: 3.8252363204956055
Epoch: 20, Steps: 266 | Train Loss: 0.4407679 Vali Loss: 0.2187170 Test Loss: 0.3075504
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.6699950
	speed: 0.0643s/iter; left time: 1361.8776s
	iters: 200, epoch: 21 | loss: 0.3925485
	speed: 0.0113s/iter; left time: 237.8945s
Epoch: 21 cost time: 3.660400867462158
Epoch: 21, Steps: 266 | Train Loss: 0.4406636 Vali Loss: 0.2190268 Test Loss: 0.3075488
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_90_336_FITS_ETTm2_ftM_sl90_ll48_pl336_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.30871254205703735, mae:0.3435461223125458, rse:0.4487844407558441, corr:[0.5602647  0.5604972  0.5553083  0.5519455  0.55168813 0.5513205
 0.54939616 0.54768914 0.5474746  0.54752535 0.54663044 0.54526097
 0.544654   0.544767   0.54430455 0.5428845  0.541373   0.54051805
 0.53988427 0.5388228  0.5375817  0.53684145 0.5365368  0.5360409
 0.5350656  0.53409845 0.53373474 0.53365207 0.5332366  0.532456
 0.53159344 0.5308488  0.53012735 0.5294644  0.52899075 0.528705
 0.52822286 0.5273849  0.5263534  0.52540016 0.52466965 0.52418983
 0.5239149  0.52382505 0.5237764  0.5234278  0.522756   0.5218482
 0.5209249  0.52013254 0.5193702  0.5186198  0.5178892  0.51718324
 0.51654965 0.51588106 0.515207   0.51477116 0.51461303 0.5145981
 0.5144635  0.51419914 0.51405615 0.51412445 0.5142022  0.51415676
 0.5140238  0.5139141  0.5139364  0.5140241  0.5140493  0.5140482
 0.5140349  0.51403904 0.5139593  0.51378834 0.5136025  0.51342636
 0.5133022  0.5131683  0.5129544  0.5126799  0.5124449  0.512237
 0.5119759  0.51160806 0.51121503 0.510941   0.51079446 0.5106262
 0.5102825  0.5097193  0.5090577  0.50830054 0.5072445  0.50562763
 0.50347173 0.5012268  0.49921027 0.49740902 0.4957032  0.49410185
 0.4926548  0.49139637 0.490274   0.48908895 0.4877811  0.48643225
 0.4851062  0.48378637 0.4824459  0.48112324 0.47990882 0.47869372
 0.47733745 0.47589937 0.47450414 0.47329038 0.47228324 0.471267
 0.4702767  0.46933204 0.46835306 0.46730617 0.46624574 0.46527487
 0.46440908 0.4635042  0.462376   0.4611706  0.46012804 0.4592694
 0.45846286 0.45764136 0.45687425 0.45643768 0.45607242 0.45564586
 0.45514515 0.4547336  0.4544629  0.45412406 0.45356423 0.4528478
 0.4521646  0.45156705 0.45076507 0.44974804 0.448656   0.44776285
 0.44718906 0.4468967  0.44647068 0.44578707 0.4452056  0.4448999
 0.44467497 0.44447875 0.44426358 0.44420406 0.44413364 0.44389552
 0.44369873 0.44359943 0.44380486 0.44403628 0.44407716 0.4440416
 0.44414008 0.44436675 0.44444525 0.44430777 0.4442569  0.44453225
 0.44493997 0.4450849  0.44486743 0.44465277 0.44476196 0.44508624
 0.44521567 0.4449945  0.44473088 0.444602   0.44457647 0.44445872
 0.44417632 0.44381613 0.44330677 0.44246867 0.4411551  0.4393531
 0.4372455  0.43514156 0.43315032 0.43138367 0.429968   0.42879492
 0.42766985 0.4265091  0.42538756 0.42426267 0.42301577 0.42165092
 0.42034516 0.41923133 0.41806602 0.41665092 0.41508362 0.41369534
 0.41254428 0.41147205 0.41023785 0.4088684  0.4076226  0.40661138
 0.40568304 0.40456438 0.40333194 0.40210533 0.40102884 0.40009066
 0.39913157 0.39793435 0.39678252 0.3956641  0.39472735 0.39387077
 0.3929945  0.39209956 0.391135   0.39024332 0.38947773 0.3889724
 0.38872802 0.38857332 0.38826355 0.3877201  0.3872596  0.38712314
 0.3871821  0.3869801  0.3862033  0.3854548  0.38515216 0.385232
 0.38547412 0.38546294 0.3852086  0.38491789 0.3848647  0.38500825
 0.38514426 0.38541523 0.3859953  0.38671637 0.38721344 0.38728413
 0.3871583  0.38717964 0.38745022 0.38793606 0.38853064 0.3891982
 0.38989115 0.39030933 0.39045477 0.39043388 0.39054242 0.3907718
 0.39080742 0.39062357 0.39058176 0.39115638 0.3921983  0.39303443
 0.393446   0.39363486 0.39383826 0.3940441  0.39396885 0.3937099
 0.39365664 0.3939636  0.39422792 0.3939544  0.39310923 0.39202654
 0.3909629  0.38993526 0.38899544 0.38846812 0.3884624  0.38870594
 0.38878578 0.388534   0.38825297 0.38812461 0.3879021  0.38742107
 0.38681242 0.38625214 0.38567558 0.38485846 0.38374043 0.3825956
 0.3816857  0.38082469 0.37973225 0.3784867  0.3775116  0.37714598
 0.37690857 0.37616873 0.37484393 0.373644   0.37316185 0.3728699
 0.37188235 0.3703482  0.36918518 0.36873573 0.3681646  0.36678797
 0.36521983 0.36460024 0.3645864  0.36358663 0.36161387 0.3604494
 0.36091    0.36085063 0.3586298  0.35681173 0.358664   0.3594045 ]
