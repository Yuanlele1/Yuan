Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=30, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_180_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_180_720_FITS_ETTm2_ftM_sl180_ll48_pl720_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33661
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=30, out_features=150, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4032000.0
params:  4650.0
Trainable parameters:  4650
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.8168908
	speed: 0.0233s/iter; left time: 606.9405s
	iters: 200, epoch: 1 | loss: 0.6380616
	speed: 0.0171s/iter; left time: 443.3924s
Epoch: 1 cost time: 5.056464433670044
Epoch: 1, Steps: 262 | Train Loss: 0.5977569 Vali Loss: 0.3155088 Test Loss: 0.4360962
Validation loss decreased (inf --> 0.315509).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5135304
	speed: 0.0746s/iter; left time: 1926.3008s
	iters: 200, epoch: 2 | loss: 0.4872370
	speed: 0.0148s/iter; left time: 381.3635s
Epoch: 2 cost time: 4.3867504596710205
Epoch: 2, Steps: 262 | Train Loss: 0.4831509 Vali Loss: 0.2907361 Test Loss: 0.4049981
Validation loss decreased (0.315509 --> 0.290736).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4092048
	speed: 0.0719s/iter; left time: 1838.5610s
	iters: 200, epoch: 3 | loss: 0.5317838
	speed: 0.0152s/iter; left time: 388.3236s
Epoch: 3 cost time: 4.474767208099365
Epoch: 3, Steps: 262 | Train Loss: 0.4634689 Vali Loss: 0.2842728 Test Loss: 0.3972059
Validation loss decreased (0.290736 --> 0.284273).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3913598
	speed: 0.0742s/iter; left time: 1878.4515s
	iters: 200, epoch: 4 | loss: 0.3845098
	speed: 0.0150s/iter; left time: 377.5560s
Epoch: 4 cost time: 4.557634115219116
Epoch: 4, Steps: 262 | Train Loss: 0.4576810 Vali Loss: 0.2814857 Test Loss: 0.3938897
Validation loss decreased (0.284273 --> 0.281486).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4266474
	speed: 0.0725s/iter; left time: 1816.8651s
	iters: 200, epoch: 5 | loss: 0.6064161
	speed: 0.0150s/iter; left time: 374.5897s
Epoch: 5 cost time: 4.457417249679565
Epoch: 5, Steps: 262 | Train Loss: 0.4535152 Vali Loss: 0.2801934 Test Loss: 0.3920443
Validation loss decreased (0.281486 --> 0.280193).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.5634100
	speed: 0.0731s/iter; left time: 1811.4989s
	iters: 200, epoch: 6 | loss: 0.5708232
	speed: 0.0149s/iter; left time: 368.9116s
Epoch: 6 cost time: 4.516568183898926
Epoch: 6, Steps: 262 | Train Loss: 0.4517826 Vali Loss: 0.2791613 Test Loss: 0.3908579
Validation loss decreased (0.280193 --> 0.279161).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3822441
	speed: 0.0823s/iter; left time: 2019.0972s
	iters: 200, epoch: 7 | loss: 0.4092785
	speed: 0.0167s/iter; left time: 408.4357s
Epoch: 7 cost time: 5.0273919105529785
Epoch: 7, Steps: 262 | Train Loss: 0.4509980 Vali Loss: 0.2787142 Test Loss: 0.3901473
Validation loss decreased (0.279161 --> 0.278714).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3000059
	speed: 0.0910s/iter; left time: 2208.8537s
	iters: 200, epoch: 8 | loss: 0.4540533
	speed: 0.0388s/iter; left time: 938.6475s
Epoch: 8 cost time: 7.200612306594849
Epoch: 8, Steps: 262 | Train Loss: 0.4497161 Vali Loss: 0.2783055 Test Loss: 0.3895801
Validation loss decreased (0.278714 --> 0.278305).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4744417
	speed: 0.0767s/iter; left time: 1841.1880s
	iters: 200, epoch: 9 | loss: 0.4297234
	speed: 0.0152s/iter; left time: 363.6553s
Epoch: 9 cost time: 4.640363931655884
Epoch: 9, Steps: 262 | Train Loss: 0.4493449 Vali Loss: 0.2779421 Test Loss: 0.3891650
Validation loss decreased (0.278305 --> 0.277942).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4077644
	speed: 0.0731s/iter; left time: 1735.6153s
	iters: 200, epoch: 10 | loss: 0.4667205
	speed: 0.0148s/iter; left time: 350.1044s
Epoch: 10 cost time: 4.500072002410889
Epoch: 10, Steps: 262 | Train Loss: 0.4489261 Vali Loss: 0.2777354 Test Loss: 0.3888000
Validation loss decreased (0.277942 --> 0.277735).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3964152
	speed: 0.0717s/iter; left time: 1683.0749s
	iters: 200, epoch: 11 | loss: 0.3911940
	speed: 0.0150s/iter; left time: 351.5445s
Epoch: 11 cost time: 4.428448677062988
Epoch: 11, Steps: 262 | Train Loss: 0.4484857 Vali Loss: 0.2772696 Test Loss: 0.3885254
Validation loss decreased (0.277735 --> 0.277270).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.6450869
	speed: 0.0717s/iter; left time: 1665.7875s
	iters: 200, epoch: 12 | loss: 0.4602575
	speed: 0.0152s/iter; left time: 350.6038s
Epoch: 12 cost time: 4.568475008010864
Epoch: 12, Steps: 262 | Train Loss: 0.4477580 Vali Loss: 0.2775526 Test Loss: 0.3883308
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.6328972
	speed: 0.0724s/iter; left time: 1661.5651s
	iters: 200, epoch: 13 | loss: 0.4725652
	speed: 0.0149s/iter; left time: 340.1493s
Epoch: 13 cost time: 4.454629421234131
Epoch: 13, Steps: 262 | Train Loss: 0.4477352 Vali Loss: 0.2771352 Test Loss: 0.3881317
Validation loss decreased (0.277270 --> 0.277135).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3785237
	speed: 0.0716s/iter; left time: 1625.7651s
	iters: 200, epoch: 14 | loss: 0.3986813
	speed: 0.0154s/iter; left time: 347.5373s
Epoch: 14 cost time: 4.619754314422607
Epoch: 14, Steps: 262 | Train Loss: 0.4478065 Vali Loss: 0.2770917 Test Loss: 0.3879867
Validation loss decreased (0.277135 --> 0.277092).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.5975195
	speed: 0.0720s/iter; left time: 1614.0840s
	iters: 200, epoch: 15 | loss: 0.4910215
	speed: 0.0150s/iter; left time: 335.0380s
Epoch: 15 cost time: 4.549822092056274
Epoch: 15, Steps: 262 | Train Loss: 0.4470813 Vali Loss: 0.2770822 Test Loss: 0.3878554
Validation loss decreased (0.277092 --> 0.277082).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4847122
	speed: 0.0736s/iter; left time: 1631.2227s
	iters: 200, epoch: 16 | loss: 0.5139440
	speed: 0.0152s/iter; left time: 335.4066s
Epoch: 16 cost time: 4.520359516143799
Epoch: 16, Steps: 262 | Train Loss: 0.4470502 Vali Loss: 0.2772847 Test Loss: 0.3877960
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4292432
	speed: 0.0724s/iter; left time: 1585.7294s
	iters: 200, epoch: 17 | loss: 0.5516693
	speed: 0.0154s/iter; left time: 335.9643s
Epoch: 17 cost time: 4.64219069480896
Epoch: 17, Steps: 262 | Train Loss: 0.4470776 Vali Loss: 0.2771344 Test Loss: 0.3876894
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4800094
	speed: 0.0774s/iter; left time: 1675.4926s
	iters: 200, epoch: 18 | loss: 0.4818214
	speed: 0.0157s/iter; left time: 338.3410s
Epoch: 18 cost time: 4.541527032852173
Epoch: 18, Steps: 262 | Train Loss: 0.4468909 Vali Loss: 0.2772877 Test Loss: 0.3875501
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4394930
	speed: 0.0732s/iter; left time: 1565.8744s
	iters: 200, epoch: 19 | loss: 0.4600234
	speed: 0.0152s/iter; left time: 324.1182s
Epoch: 19 cost time: 4.620453834533691
Epoch: 19, Steps: 262 | Train Loss: 0.4469412 Vali Loss: 0.2769188 Test Loss: 0.3875042
Validation loss decreased (0.277082 --> 0.276919).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4379637
	speed: 0.0732s/iter; left time: 1545.3387s
	iters: 200, epoch: 20 | loss: 0.4266308
	speed: 0.0152s/iter; left time: 318.6963s
Epoch: 20 cost time: 4.521591901779175
Epoch: 20, Steps: 262 | Train Loss: 0.4474947 Vali Loss: 0.2768617 Test Loss: 0.3874214
Validation loss decreased (0.276919 --> 0.276862).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4458393
	speed: 0.0736s/iter; left time: 1534.8066s
	iters: 200, epoch: 21 | loss: 0.4330033
	speed: 0.0157s/iter; left time: 326.4040s
Epoch: 21 cost time: 4.654742002487183
Epoch: 21, Steps: 262 | Train Loss: 0.4469913 Vali Loss: 0.2769054 Test Loss: 0.3873631
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.5080650
	speed: 0.0719s/iter; left time: 1481.2862s
	iters: 200, epoch: 22 | loss: 0.5311192
	speed: 0.0155s/iter; left time: 318.3542s
Epoch: 22 cost time: 4.6353936195373535
Epoch: 22, Steps: 262 | Train Loss: 0.4468416 Vali Loss: 0.2769049 Test Loss: 0.3872896
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3384129
	speed: 0.0746s/iter; left time: 1518.1405s
	iters: 200, epoch: 23 | loss: 0.5646735
	speed: 0.0155s/iter; left time: 313.0566s
Epoch: 23 cost time: 4.618321418762207
Epoch: 23, Steps: 262 | Train Loss: 0.4462743 Vali Loss: 0.2765556 Test Loss: 0.3872738
Validation loss decreased (0.276862 --> 0.276556).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2810937
	speed: 0.0744s/iter; left time: 1493.4174s
	iters: 200, epoch: 24 | loss: 0.5320140
	speed: 0.0154s/iter; left time: 307.2835s
Epoch: 24 cost time: 4.65020227432251
Epoch: 24, Steps: 262 | Train Loss: 0.4465322 Vali Loss: 0.2769049 Test Loss: 0.3872294
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4522587
	speed: 0.0769s/iter; left time: 1523.7089s
	iters: 200, epoch: 25 | loss: 0.4051892
	speed: 0.0164s/iter; left time: 323.0429s
Epoch: 25 cost time: 4.919498443603516
Epoch: 25, Steps: 262 | Train Loss: 0.4465793 Vali Loss: 0.2767872 Test Loss: 0.3872019
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.5537151
	speed: 0.0876s/iter; left time: 1713.0352s
	iters: 200, epoch: 26 | loss: 0.4270972
	speed: 0.0151s/iter; left time: 293.5690s
Epoch: 26 cost time: 4.550748348236084
Epoch: 26, Steps: 262 | Train Loss: 0.4465625 Vali Loss: 0.2766718 Test Loss: 0.3871738
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.5206872
	speed: 0.0911s/iter; left time: 1758.1734s
	iters: 200, epoch: 27 | loss: 0.5483115
	speed: 0.0326s/iter; left time: 625.9614s
Epoch: 27 cost time: 7.627492427825928
Epoch: 27, Steps: 262 | Train Loss: 0.4463406 Vali Loss: 0.2767617 Test Loss: 0.3871589
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3199471
	speed: 0.0738s/iter; left time: 1404.4536s
	iters: 200, epoch: 28 | loss: 0.5460092
	speed: 0.0148s/iter; left time: 279.6063s
Epoch: 28 cost time: 4.454164743423462
Epoch: 28, Steps: 262 | Train Loss: 0.4466130 Vali Loss: 0.2766282 Test Loss: 0.3871392
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3518621
	speed: 0.0729s/iter; left time: 1368.8716s
	iters: 200, epoch: 29 | loss: 0.4924272
	speed: 0.0148s/iter; left time: 276.3242s
Epoch: 29 cost time: 4.4538867473602295
Epoch: 29, Steps: 262 | Train Loss: 0.4464113 Vali Loss: 0.2767963 Test Loss: 0.3870968
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3971888
	speed: 0.0707s/iter; left time: 1308.5047s
	iters: 200, epoch: 30 | loss: 0.4533121
	speed: 0.0151s/iter; left time: 278.1562s
Epoch: 30 cost time: 4.495476007461548
Epoch: 30, Steps: 262 | Train Loss: 0.4464815 Vali Loss: 0.2767543 Test Loss: 0.3870796
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4175664
	speed: 0.0720s/iter; left time: 1313.7900s
	iters: 200, epoch: 31 | loss: 0.3880861
	speed: 0.0150s/iter; left time: 272.6848s
Epoch: 31 cost time: 4.486909627914429
Epoch: 31, Steps: 262 | Train Loss: 0.4464962 Vali Loss: 0.2767364 Test Loss: 0.3870838
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.5416676
	speed: 0.0730s/iter; left time: 1312.2505s
	iters: 200, epoch: 32 | loss: 0.4610208
	speed: 0.0147s/iter; left time: 262.8850s
Epoch: 32 cost time: 4.396780490875244
Epoch: 32, Steps: 262 | Train Loss: 0.4462313 Vali Loss: 0.2767184 Test Loss: 0.3870613
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3299412
	speed: 0.0710s/iter; left time: 1258.2046s
	iters: 200, epoch: 33 | loss: 0.5101104
	speed: 0.0150s/iter; left time: 263.9097s
Epoch: 33 cost time: 4.397972106933594
Epoch: 33, Steps: 262 | Train Loss: 0.4466441 Vali Loss: 0.2768635 Test Loss: 0.3870504
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4831565
	speed: 0.0717s/iter; left time: 1252.0045s
	iters: 200, epoch: 34 | loss: 0.5060604
	speed: 0.0152s/iter; left time: 263.0942s
Epoch: 34 cost time: 4.409458875656128
Epoch: 34, Steps: 262 | Train Loss: 0.4465581 Vali Loss: 0.2765451 Test Loss: 0.3870296
Validation loss decreased (0.276556 --> 0.276545).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3089104
	speed: 0.0722s/iter; left time: 1241.7292s
	iters: 200, epoch: 35 | loss: 0.4442782
	speed: 0.0164s/iter; left time: 279.6988s
Epoch: 35 cost time: 4.745208740234375
Epoch: 35, Steps: 262 | Train Loss: 0.4464077 Vali Loss: 0.2766722 Test Loss: 0.3870136
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.5628015
	speed: 0.0755s/iter; left time: 1278.8380s
	iters: 200, epoch: 36 | loss: 0.3497670
	speed: 0.0148s/iter; left time: 248.6714s
Epoch: 36 cost time: 4.491423606872559
Epoch: 36, Steps: 262 | Train Loss: 0.4458354 Vali Loss: 0.2768027 Test Loss: 0.3870088
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3720777
	speed: 0.0735s/iter; left time: 1225.6234s
	iters: 200, epoch: 37 | loss: 0.5401031
	speed: 0.0150s/iter; left time: 248.5314s
Epoch: 37 cost time: 4.49934458732605
Epoch: 37, Steps: 262 | Train Loss: 0.4460760 Vali Loss: 0.2767876 Test Loss: 0.3869893
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.5150872
	speed: 0.0730s/iter; left time: 1198.0848s
	iters: 200, epoch: 38 | loss: 0.3332897
	speed: 0.0148s/iter; left time: 241.1844s
Epoch: 38 cost time: 4.458837985992432
Epoch: 38, Steps: 262 | Train Loss: 0.4461023 Vali Loss: 0.2765894 Test Loss: 0.3869852
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3304743
	speed: 0.0766s/iter; left time: 1236.6736s
	iters: 200, epoch: 39 | loss: 0.4281836
	speed: 0.0163s/iter; left time: 262.2703s
Epoch: 39 cost time: 4.826223850250244
Epoch: 39, Steps: 262 | Train Loss: 0.4456281 Vali Loss: 0.2766645 Test Loss: 0.3869696
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.5133151
	speed: 0.0775s/iter; left time: 1231.6666s
	iters: 200, epoch: 40 | loss: 0.4909729
	speed: 0.0161s/iter; left time: 254.4066s
Epoch: 40 cost time: 4.826032638549805
Epoch: 40, Steps: 262 | Train Loss: 0.4454903 Vali Loss: 0.2764625 Test Loss: 0.3869615
Validation loss decreased (0.276545 --> 0.276462).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.4826787
	speed: 0.0788s/iter; left time: 1231.6879s
	iters: 200, epoch: 41 | loss: 0.5061381
	speed: 0.0180s/iter; left time: 279.8055s
Epoch: 41 cost time: 5.085846900939941
Epoch: 41, Steps: 262 | Train Loss: 0.4462926 Vali Loss: 0.2767951 Test Loss: 0.3869760
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.4096359
	speed: 0.0786s/iter; left time: 1207.8787s
	iters: 200, epoch: 42 | loss: 0.5352446
	speed: 0.0165s/iter; left time: 251.7935s
Epoch: 42 cost time: 4.917846918106079
Epoch: 42, Steps: 262 | Train Loss: 0.4461717 Vali Loss: 0.2763413 Test Loss: 0.3869654
Validation loss decreased (0.276462 --> 0.276341).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2921940
	speed: 0.0738s/iter; left time: 1113.7065s
	iters: 200, epoch: 43 | loss: 0.4237734
	speed: 0.0149s/iter; left time: 223.2977s
Epoch: 43 cost time: 4.4286699295043945
Epoch: 43, Steps: 262 | Train Loss: 0.4460451 Vali Loss: 0.2765585 Test Loss: 0.3869498
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.4651596
	speed: 0.0911s/iter; left time: 1351.6933s
	iters: 200, epoch: 44 | loss: 0.4087002
	speed: 0.0153s/iter; left time: 225.0875s
Epoch: 44 cost time: 4.745539903640747
Epoch: 44, Steps: 262 | Train Loss: 0.4465682 Vali Loss: 0.2767564 Test Loss: 0.3869585
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.5024853
	speed: 0.0876s/iter; left time: 1275.8685s
	iters: 200, epoch: 45 | loss: 0.4391976
	speed: 0.0162s/iter; left time: 234.9190s
Epoch: 45 cost time: 6.129183053970337
Epoch: 45, Steps: 262 | Train Loss: 0.4456288 Vali Loss: 0.2765799 Test Loss: 0.3869464
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.4235882
	speed: 0.0732s/iter; left time: 1047.4872s
	iters: 200, epoch: 46 | loss: 0.3461162
	speed: 0.0153s/iter; left time: 217.3613s
Epoch: 46 cost time: 4.532590627670288
Epoch: 46, Steps: 262 | Train Loss: 0.4465576 Vali Loss: 0.2765736 Test Loss: 0.3869476
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.3813624
	speed: 0.0736s/iter; left time: 1034.0297s
	iters: 200, epoch: 47 | loss: 0.3224504
	speed: 0.0155s/iter; left time: 216.6974s
Epoch: 47 cost time: 4.6123716831207275
Epoch: 47, Steps: 262 | Train Loss: 0.4461321 Vali Loss: 0.2765211 Test Loss: 0.3869483
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.4713929
	speed: 0.0733s/iter; left time: 1010.0607s
	iters: 200, epoch: 48 | loss: 0.4993878
	speed: 0.0148s/iter; left time: 202.3840s
Epoch: 48 cost time: 4.457183361053467
Epoch: 48, Steps: 262 | Train Loss: 0.4461206 Vali Loss: 0.2767397 Test Loss: 0.3869353
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.3021816
	speed: 0.0701s/iter; left time: 947.9472s
	iters: 200, epoch: 49 | loss: 0.5878922
	speed: 0.0149s/iter; left time: 200.0241s
Epoch: 49 cost time: 4.357136964797974
Epoch: 49, Steps: 262 | Train Loss: 0.4459014 Vali Loss: 0.2765614 Test Loss: 0.3869343
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.3919829
	speed: 0.0709s/iter; left time: 939.7178s
	iters: 200, epoch: 50 | loss: 0.4535326
	speed: 0.0151s/iter; left time: 198.8892s
Epoch: 50 cost time: 4.415536642074585
Epoch: 50, Steps: 262 | Train Loss: 0.4462501 Vali Loss: 0.2767144 Test Loss: 0.3869348
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.3392459
	speed: 0.0701s/iter; left time: 911.2292s
	iters: 200, epoch: 51 | loss: 0.4741478
	speed: 0.0150s/iter; left time: 192.8920s
Epoch: 51 cost time: 4.416886568069458
Epoch: 51, Steps: 262 | Train Loss: 0.4462564 Vali Loss: 0.2763085 Test Loss: 0.3869335
Validation loss decreased (0.276341 --> 0.276309).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.3045540
	speed: 0.0723s/iter; left time: 920.8139s
	iters: 200, epoch: 52 | loss: 0.4960971
	speed: 0.0157s/iter; left time: 198.3107s
Epoch: 52 cost time: 4.704901456832886
Epoch: 52, Steps: 262 | Train Loss: 0.4462578 Vali Loss: 0.2769212 Test Loss: 0.3869230
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.3129765
	speed: 0.0761s/iter; left time: 950.1228s
	iters: 200, epoch: 53 | loss: 0.5996742
	speed: 0.0153s/iter; left time: 188.8349s
Epoch: 53 cost time: 4.528100490570068
Epoch: 53, Steps: 262 | Train Loss: 0.4468788 Vali Loss: 0.2767779 Test Loss: 0.3869258
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.5638032
	speed: 0.0891s/iter; left time: 1088.2218s
	iters: 200, epoch: 54 | loss: 0.5343126
	speed: 0.0152s/iter; left time: 183.8755s
Epoch: 54 cost time: 4.617550611495972
Epoch: 54, Steps: 262 | Train Loss: 0.4463752 Vali Loss: 0.2766795 Test Loss: 0.3869218
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.5665458
	speed: 0.0775s/iter; left time: 925.8220s
	iters: 200, epoch: 55 | loss: 0.4253356
	speed: 0.0165s/iter; left time: 195.3776s
Epoch: 55 cost time: 4.861323595046997
Epoch: 55, Steps: 262 | Train Loss: 0.4466952 Vali Loss: 0.2763064 Test Loss: 0.3869216
Validation loss decreased (0.276309 --> 0.276306).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.4480281
	speed: 0.0785s/iter; left time: 917.2204s
	iters: 200, epoch: 56 | loss: 0.5388680
	speed: 0.0165s/iter; left time: 191.6300s
Epoch: 56 cost time: 4.866364002227783
Epoch: 56, Steps: 262 | Train Loss: 0.4454922 Vali Loss: 0.2766678 Test Loss: 0.3869232
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.4578657
	speed: 0.0756s/iter; left time: 864.4171s
	iters: 200, epoch: 57 | loss: 0.4766240
	speed: 0.0151s/iter; left time: 171.2361s
Epoch: 57 cost time: 4.579067945480347
Epoch: 57, Steps: 262 | Train Loss: 0.4463878 Vali Loss: 0.2767259 Test Loss: 0.3869182
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.3142237
	speed: 0.0726s/iter; left time: 810.7759s
	iters: 200, epoch: 58 | loss: 0.5052555
	speed: 0.0166s/iter; left time: 183.4208s
Epoch: 58 cost time: 4.735230922698975
Epoch: 58, Steps: 262 | Train Loss: 0.4459174 Vali Loss: 0.2767929 Test Loss: 0.3869122
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.4515515
	speed: 0.0746s/iter; left time: 813.7388s
	iters: 200, epoch: 59 | loss: 0.4688411
	speed: 0.0154s/iter; left time: 166.0712s
Epoch: 59 cost time: 4.634978294372559
Epoch: 59, Steps: 262 | Train Loss: 0.4460774 Vali Loss: 0.2765658 Test Loss: 0.3869123
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.4753975
	speed: 0.0714s/iter; left time: 759.9671s
	iters: 200, epoch: 60 | loss: 0.4942696
	speed: 0.0149s/iter; left time: 157.6042s
Epoch: 60 cost time: 4.48189902305603
Epoch: 60, Steps: 262 | Train Loss: 0.4456501 Vali Loss: 0.2767312 Test Loss: 0.3869087
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.5327451
	speed: 0.0728s/iter; left time: 756.0052s
	iters: 200, epoch: 61 | loss: 0.5127745
	speed: 0.0154s/iter; left time: 157.9486s
Epoch: 61 cost time: 4.542543172836304
Epoch: 61, Steps: 262 | Train Loss: 0.4464574 Vali Loss: 0.2766729 Test Loss: 0.3869051
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.5102790
	speed: 0.0727s/iter; left time: 735.6132s
	iters: 200, epoch: 62 | loss: 0.6124006
	speed: 0.0152s/iter; left time: 152.0473s
Epoch: 62 cost time: 4.5118396282196045
Epoch: 62, Steps: 262 | Train Loss: 0.4459815 Vali Loss: 0.2766411 Test Loss: 0.3869074
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.5791696
	speed: 0.0718s/iter; left time: 707.2775s
	iters: 200, epoch: 63 | loss: 0.4471257
	speed: 0.0155s/iter; left time: 150.9234s
Epoch: 63 cost time: 4.523403644561768
Epoch: 63, Steps: 262 | Train Loss: 0.4461597 Vali Loss: 0.2767563 Test Loss: 0.3869057
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.4165504
	speed: 0.0764s/iter; left time: 732.6131s
	iters: 200, epoch: 64 | loss: 0.3903080
	speed: 0.0151s/iter; left time: 143.6423s
Epoch: 64 cost time: 4.511606931686401
Epoch: 64, Steps: 262 | Train Loss: 0.4458805 Vali Loss: 0.2765999 Test Loss: 0.3869036
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.3279780
	speed: 0.0734s/iter; left time: 684.7584s
	iters: 200, epoch: 65 | loss: 0.4668511
	speed: 0.0148s/iter; left time: 136.3000s
Epoch: 65 cost time: 4.522339105606079
Epoch: 65, Steps: 262 | Train Loss: 0.4460479 Vali Loss: 0.2765482 Test Loss: 0.3869033
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.5994495
	speed: 0.0712s/iter; left time: 645.9078s
	iters: 200, epoch: 66 | loss: 0.4959536
	speed: 0.0151s/iter; left time: 135.0425s
Epoch: 66 cost time: 4.43759822845459
Epoch: 66, Steps: 262 | Train Loss: 0.4463941 Vali Loss: 0.2765565 Test Loss: 0.3869024
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.4867564
	speed: 0.0714s/iter; left time: 629.2332s
	iters: 200, epoch: 67 | loss: 0.4718956
	speed: 0.0159s/iter; left time: 138.5993s
Epoch: 67 cost time: 4.634758234024048
Epoch: 67, Steps: 262 | Train Loss: 0.4461486 Vali Loss: 0.2766603 Test Loss: 0.3869022
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.3815270
	speed: 0.0778s/iter; left time: 665.3601s
	iters: 200, epoch: 68 | loss: 0.4446367
	speed: 0.0173s/iter; left time: 145.8156s
Epoch: 68 cost time: 4.960422515869141
Epoch: 68, Steps: 262 | Train Loss: 0.4457788 Vali Loss: 0.2761349 Test Loss: 0.3869005
Validation loss decreased (0.276306 --> 0.276135).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.4524758
	speed: 0.0814s/iter; left time: 674.5326s
	iters: 200, epoch: 69 | loss: 0.5342737
	speed: 0.0164s/iter; left time: 133.8730s
Epoch: 69 cost time: 4.71042799949646
Epoch: 69, Steps: 262 | Train Loss: 0.4468740 Vali Loss: 0.2766996 Test Loss: 0.3869014
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.3831540
	speed: 0.0700s/iter; left time: 561.7047s
	iters: 200, epoch: 70 | loss: 0.4019476
	speed: 0.0151s/iter; left time: 119.9959s
Epoch: 70 cost time: 4.363031625747681
Epoch: 70, Steps: 262 | Train Loss: 0.4462064 Vali Loss: 0.2767173 Test Loss: 0.3868993
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.2914532
	speed: 0.0707s/iter; left time: 548.5313s
	iters: 200, epoch: 71 | loss: 0.4405411
	speed: 0.0150s/iter; left time: 115.1247s
Epoch: 71 cost time: 4.434873580932617
Epoch: 71, Steps: 262 | Train Loss: 0.4465346 Vali Loss: 0.2765042 Test Loss: 0.3868975
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.5453224
	speed: 0.0720s/iter; left time: 539.6092s
	iters: 200, epoch: 72 | loss: 0.4864998
	speed: 0.0156s/iter; left time: 115.4015s
Epoch: 72 cost time: 4.506779670715332
Epoch: 72, Steps: 262 | Train Loss: 0.4462585 Vali Loss: 0.2763372 Test Loss: 0.3868989
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.4015879
	speed: 0.0778s/iter; left time: 563.2996s
	iters: 200, epoch: 73 | loss: 0.3659667
	speed: 0.0150s/iter; left time: 106.9714s
Epoch: 73 cost time: 4.581737995147705
Epoch: 73, Steps: 262 | Train Loss: 0.4461309 Vali Loss: 0.2764866 Test Loss: 0.3868970
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.3625306
	speed: 0.0709s/iter; left time: 494.3919s
	iters: 200, epoch: 74 | loss: 0.2684330
	speed: 0.0151s/iter; left time: 104.0022s
Epoch: 74 cost time: 4.3731911182403564
Epoch: 74, Steps: 262 | Train Loss: 0.4464822 Vali Loss: 0.2766871 Test Loss: 0.3868987
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.4089724
	speed: 0.0733s/iter; left time: 492.1410s
	iters: 200, epoch: 75 | loss: 0.4635631
	speed: 0.0153s/iter; left time: 101.0658s
Epoch: 75 cost time: 4.63598895072937
Epoch: 75, Steps: 262 | Train Loss: 0.4466386 Vali Loss: 0.2765313 Test Loss: 0.3868973
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.5061814
	speed: 0.0719s/iter; left time: 463.7043s
	iters: 200, epoch: 76 | loss: 0.5283045
	speed: 0.0149s/iter; left time: 94.7696s
Epoch: 76 cost time: 4.443012714385986
Epoch: 76, Steps: 262 | Train Loss: 0.4461853 Vali Loss: 0.2765225 Test Loss: 0.3868964
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.3960776
	speed: 0.0713s/iter; left time: 441.5584s
	iters: 200, epoch: 77 | loss: 0.5517070
	speed: 0.0191s/iter; left time: 116.3815s
Epoch: 77 cost time: 4.964061498641968
Epoch: 77, Steps: 262 | Train Loss: 0.4456279 Vali Loss: 0.2765667 Test Loss: 0.3868969
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.4162309
	speed: 0.0726s/iter; left time: 430.1786s
	iters: 200, epoch: 78 | loss: 0.3395517
	speed: 0.0158s/iter; left time: 91.9910s
Epoch: 78 cost time: 4.542711973190308
Epoch: 78, Steps: 262 | Train Loss: 0.4458644 Vali Loss: 0.2766711 Test Loss: 0.3868950
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.3812583
	speed: 0.0736s/iter; left time: 417.0224s
	iters: 200, epoch: 79 | loss: 0.2956835
	speed: 0.0149s/iter; left time: 82.9876s
Epoch: 79 cost time: 4.4350786209106445
Epoch: 79, Steps: 262 | Train Loss: 0.4456968 Vali Loss: 0.2765027 Test Loss: 0.3868944
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.3855604
	speed: 0.0736s/iter; left time: 397.6675s
	iters: 200, epoch: 80 | loss: 0.3794034
	speed: 0.0151s/iter; left time: 80.2223s
Epoch: 80 cost time: 4.515496015548706
Epoch: 80, Steps: 262 | Train Loss: 0.4460248 Vali Loss: 0.2768103 Test Loss: 0.3868928
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.3671380
	speed: 0.0711s/iter; left time: 365.6905s
	iters: 200, epoch: 81 | loss: 0.3479991
	speed: 0.0151s/iter; left time: 75.8804s
Epoch: 81 cost time: 4.473605394363403
Epoch: 81, Steps: 262 | Train Loss: 0.4458896 Vali Loss: 0.2763985 Test Loss: 0.3868922
EarlyStopping counter: 13 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.3683484
	speed: 0.0745s/iter; left time: 363.5842s
	iters: 200, epoch: 82 | loss: 0.5390896
	speed: 0.0156s/iter; left time: 74.5620s
Epoch: 82 cost time: 4.662200689315796
Epoch: 82, Steps: 262 | Train Loss: 0.4457707 Vali Loss: 0.2766883 Test Loss: 0.3868921
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.5056425
	speed: 0.0776s/iter; left time: 358.2196s
	iters: 200, epoch: 83 | loss: 0.3617468
	speed: 0.0151s/iter; left time: 68.0227s
Epoch: 83 cost time: 4.696847915649414
Epoch: 83, Steps: 262 | Train Loss: 0.4464884 Vali Loss: 0.2767150 Test Loss: 0.3868920
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.3781224
	speed: 0.0732s/iter; left time: 318.8781s
	iters: 200, epoch: 84 | loss: 0.3958445
	speed: 0.0148s/iter; left time: 63.0821s
Epoch: 84 cost time: 4.482311487197876
Epoch: 84, Steps: 262 | Train Loss: 0.4460263 Vali Loss: 0.2766870 Test Loss: 0.3868917
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.3994726
	speed: 0.0704s/iter; left time: 288.0940s
	iters: 200, epoch: 85 | loss: 0.4097360
	speed: 0.0152s/iter; left time: 60.5146s
Epoch: 85 cost time: 4.41088080406189
Epoch: 85, Steps: 262 | Train Loss: 0.4463489 Vali Loss: 0.2768689 Test Loss: 0.3868924
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.4011243
	speed: 0.0711s/iter; left time: 272.4588s
	iters: 200, epoch: 86 | loss: 0.4970365
	speed: 0.0149s/iter; left time: 55.6813s
Epoch: 86 cost time: 4.384328842163086
Epoch: 86, Steps: 262 | Train Loss: 0.4459310 Vali Loss: 0.2766541 Test Loss: 0.3868909
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.6118547
	speed: 0.0708s/iter; left time: 252.7653s
	iters: 200, epoch: 87 | loss: 0.4258861
	speed: 0.0152s/iter; left time: 52.8718s
Epoch: 87 cost time: 4.381326198577881
Epoch: 87, Steps: 262 | Train Loss: 0.4456037 Vali Loss: 0.2767203 Test Loss: 0.3868896
EarlyStopping counter: 19 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.3517710
	speed: 0.0739s/iter; left time: 244.3621s
	iters: 200, epoch: 88 | loss: 0.4431829
	speed: 0.0154s/iter; left time: 49.5304s
Epoch: 88 cost time: 4.544007778167725
Epoch: 88, Steps: 262 | Train Loss: 0.4462600 Vali Loss: 0.2767661 Test Loss: 0.3868903
EarlyStopping counter: 20 out of 20
Early stopping
train 33661
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=30, out_features=150, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4032000.0
params:  4650.0
Trainable parameters:  4650
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6959749
	speed: 0.0217s/iter; left time: 566.3762s
	iters: 200, epoch: 1 | loss: 0.5249872
	speed: 0.0150s/iter; left time: 389.9838s
Epoch: 1 cost time: 4.610533237457275
Epoch: 1, Steps: 262 | Train Loss: 0.5542504 Vali Loss: 0.2764246 Test Loss: 0.3866498
Validation loss decreased (inf --> 0.276425).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4919725
	speed: 0.0734s/iter; left time: 1896.3608s
	iters: 200, epoch: 2 | loss: 0.6089741
	speed: 0.0152s/iter; left time: 390.3588s
Epoch: 2 cost time: 4.506162881851196
Epoch: 2, Steps: 262 | Train Loss: 0.5548497 Vali Loss: 0.2762362 Test Loss: 0.3864620
Validation loss decreased (0.276425 --> 0.276236).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4502648
	speed: 0.0732s/iter; left time: 1872.1198s
	iters: 200, epoch: 3 | loss: 0.5295817
	speed: 0.0148s/iter; left time: 376.2779s
Epoch: 3 cost time: 4.4454052448272705
Epoch: 3, Steps: 262 | Train Loss: 0.5543748 Vali Loss: 0.2765968 Test Loss: 0.3864420
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.5967488
	speed: 0.0716s/iter; left time: 1812.8830s
	iters: 200, epoch: 4 | loss: 0.5224504
	speed: 0.0148s/iter; left time: 373.6322s
Epoch: 4 cost time: 4.375182390213013
Epoch: 4, Steps: 262 | Train Loss: 0.5542232 Vali Loss: 0.2765046 Test Loss: 0.3865172
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4600657
	speed: 0.0709s/iter; left time: 1776.0171s
	iters: 200, epoch: 5 | loss: 0.4141644
	speed: 0.0149s/iter; left time: 372.1111s
Epoch: 5 cost time: 4.407191276550293
Epoch: 5, Steps: 262 | Train Loss: 0.5541767 Vali Loss: 0.2765856 Test Loss: 0.3864230
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.6051949
	speed: 0.0726s/iter; left time: 1799.2205s
	iters: 200, epoch: 6 | loss: 0.4273473
	speed: 0.0149s/iter; left time: 367.6582s
Epoch: 6 cost time: 4.437910318374634
Epoch: 6, Steps: 262 | Train Loss: 0.5543072 Vali Loss: 0.2764987 Test Loss: 0.3863716
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.6556075
	speed: 0.0735s/iter; left time: 1803.4138s
	iters: 200, epoch: 7 | loss: 0.5347710
	speed: 0.0152s/iter; left time: 372.4032s
Epoch: 7 cost time: 4.497535705566406
Epoch: 7, Steps: 262 | Train Loss: 0.5539961 Vali Loss: 0.2763901 Test Loss: 0.3864226
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.5012007
	speed: 0.0796s/iter; left time: 1931.4484s
	iters: 200, epoch: 8 | loss: 0.7362581
	speed: 0.0168s/iter; left time: 405.9057s
Epoch: 8 cost time: 5.026432037353516
Epoch: 8, Steps: 262 | Train Loss: 0.5537786 Vali Loss: 0.2765457 Test Loss: 0.3863564
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.5470299
	speed: 0.0732s/iter; left time: 1758.3185s
	iters: 200, epoch: 9 | loss: 0.6346277
	speed: 0.0150s/iter; left time: 359.5936s
Epoch: 9 cost time: 4.493718862533569
Epoch: 9, Steps: 262 | Train Loss: 0.5540056 Vali Loss: 0.2763262 Test Loss: 0.3863656
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4311345
	speed: 0.0756s/iter; left time: 1794.0932s
	iters: 200, epoch: 10 | loss: 0.6091326
	speed: 0.0167s/iter; left time: 394.8774s
Epoch: 10 cost time: 4.913175344467163
Epoch: 10, Steps: 262 | Train Loss: 0.5530868 Vali Loss: 0.2765535 Test Loss: 0.3863369
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.7359189
	speed: 0.0792s/iter; left time: 1859.1775s
	iters: 200, epoch: 11 | loss: 0.4099412
	speed: 0.0165s/iter; left time: 385.2521s
Epoch: 11 cost time: 4.833982706069946
Epoch: 11, Steps: 262 | Train Loss: 0.5534168 Vali Loss: 0.2762737 Test Loss: 0.3863770
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.6300431
	speed: 0.0784s/iter; left time: 1819.5957s
	iters: 200, epoch: 12 | loss: 0.4644679
	speed: 0.0164s/iter; left time: 379.1446s
Epoch: 12 cost time: 4.868360757827759
Epoch: 12, Steps: 262 | Train Loss: 0.5533544 Vali Loss: 0.2765752 Test Loss: 0.3864143
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.6372835
	speed: 0.0749s/iter; left time: 1719.1927s
	iters: 200, epoch: 13 | loss: 0.4928322
	speed: 0.0153s/iter; left time: 350.6595s
Epoch: 13 cost time: 4.5738794803619385
Epoch: 13, Steps: 262 | Train Loss: 0.5530585 Vali Loss: 0.2762937 Test Loss: 0.3863464
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4833444
	speed: 0.0700s/iter; left time: 1588.6714s
	iters: 200, epoch: 14 | loss: 0.3795353
	speed: 0.0150s/iter; left time: 338.0243s
Epoch: 14 cost time: 4.408090591430664
Epoch: 14, Steps: 262 | Train Loss: 0.5531281 Vali Loss: 0.2765822 Test Loss: 0.3862980
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4988316
	speed: 0.0715s/iter; left time: 1603.7500s
	iters: 200, epoch: 15 | loss: 0.7059720
	speed: 0.0151s/iter; left time: 336.7688s
Epoch: 15 cost time: 4.454571723937988
Epoch: 15, Steps: 262 | Train Loss: 0.5529777 Vali Loss: 0.2764292 Test Loss: 0.3863851
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4887660
	speed: 0.0735s/iter; left time: 1629.5561s
	iters: 200, epoch: 16 | loss: 0.6230995
	speed: 0.0153s/iter; left time: 337.2774s
Epoch: 16 cost time: 4.530924558639526
Epoch: 16, Steps: 262 | Train Loss: 0.5537957 Vali Loss: 0.2767404 Test Loss: 0.3863538
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.5723174
	speed: 0.0731s/iter; left time: 1601.9140s
	iters: 200, epoch: 17 | loss: 0.5209013
	speed: 0.0151s/iter; left time: 329.3377s
Epoch: 17 cost time: 4.541775465011597
Epoch: 17, Steps: 262 | Train Loss: 0.5538104 Vali Loss: 0.2763340 Test Loss: 0.3863329
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.5714567
	speed: 0.0763s/iter; left time: 1651.7352s
	iters: 200, epoch: 18 | loss: 0.6103268
	speed: 0.0150s/iter; left time: 323.6924s
Epoch: 18 cost time: 4.471927881240845
Epoch: 18, Steps: 262 | Train Loss: 0.5534275 Vali Loss: 0.2764368 Test Loss: 0.3863640
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.7194114
	speed: 0.0730s/iter; left time: 1561.4110s
	iters: 200, epoch: 19 | loss: 0.4534215
	speed: 0.0149s/iter; left time: 317.4183s
Epoch: 19 cost time: 4.433329820632935
Epoch: 19, Steps: 262 | Train Loss: 0.5537070 Vali Loss: 0.2764400 Test Loss: 0.3863680
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.5028184
	speed: 0.0738s/iter; left time: 1559.1868s
	iters: 200, epoch: 20 | loss: 0.5255491
	speed: 0.0153s/iter; left time: 322.6427s
Epoch: 20 cost time: 4.73966383934021
Epoch: 20, Steps: 262 | Train Loss: 0.5539475 Vali Loss: 0.2763935 Test Loss: 0.3863725
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.5420684
	speed: 0.0782s/iter; left time: 1630.6004s
	iters: 200, epoch: 21 | loss: 0.5558031
	speed: 0.0166s/iter; left time: 344.4041s
Epoch: 21 cost time: 4.947362184524536
Epoch: 21, Steps: 262 | Train Loss: 0.5531343 Vali Loss: 0.2764591 Test Loss: 0.3863599
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.5288882
	speed: 0.0758s/iter; left time: 1562.2072s
	iters: 200, epoch: 22 | loss: 0.4333885
	speed: 0.0148s/iter; left time: 302.7206s
Epoch: 22 cost time: 4.470316648483276
Epoch: 22, Steps: 262 | Train Loss: 0.5536298 Vali Loss: 0.2764875 Test Loss: 0.3863252
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_180_720_FITS_ETTm2_ftM_sl180_ll48_pl720_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.38382670283317566, mae:0.3875749707221985, rse:0.4979800879955292, corr:[0.5456124  0.54867077 0.5458637  0.5419497  0.53986305 0.5396663
 0.5396868  0.53867185 0.5368102  0.5350949  0.5342343  0.534066
 0.5338654  0.533215   0.5323347  0.5316369  0.53126025 0.5309351
 0.5303295  0.52936494 0.5283262  0.5275519  0.5271831  0.52709097
 0.5269613  0.52660763 0.52606237 0.5254081  0.52467155 0.5238703
 0.5231033  0.52247566 0.5219979  0.5216312  0.5212518  0.52074087
 0.52001613 0.5192359  0.5184984  0.51788515 0.51740724 0.51696897
 0.5164706  0.51586556 0.5152148  0.51459235 0.5139291  0.51313525
 0.51220906 0.51128125 0.5105089  0.5099918  0.5095754  0.5090587
 0.50842637 0.50777835 0.5071637  0.50673383 0.5064382  0.5061792
 0.5058231  0.5054388  0.50515014 0.5049371  0.5048133  0.50471777
 0.5044893  0.5041703  0.50383973 0.503621   0.50351423 0.50349045
 0.50350034 0.5033999  0.503198   0.5028492  0.50241613 0.5019204
 0.5014498  0.5010146  0.5005849  0.5001377  0.49970588 0.49928427
 0.4988766  0.49848017 0.49806282 0.49765605 0.4972213  0.4967608
 0.4963242  0.49589306 0.4953701  0.49459654 0.49343    0.49182037
 0.48990744 0.4880407  0.48630986 0.48467568 0.4831417  0.48175654
 0.48050487 0.47931597 0.47805485 0.4766851  0.4752696  0.47393188
 0.4727062  0.4714617  0.47036526 0.4693668  0.468433   0.46746826
 0.4663563  0.4651806  0.4639963  0.4628068  0.46166113 0.46054474
 0.4595501  0.45872554 0.45801327 0.45728192 0.4564377  0.45544556
 0.45436046 0.45325446 0.45222038 0.4512738  0.4504302  0.44960657
 0.4487421  0.44774187 0.4468     0.4460501  0.4455222  0.4452392
 0.4450069  0.44462818 0.44399866 0.44321176 0.44243512 0.4416958
 0.44093975 0.44008216 0.43906954 0.43804964 0.43721426 0.4365505
 0.43600833 0.43557972 0.43507448 0.43449554 0.4339254  0.43336424
 0.432833   0.43231454 0.43171617 0.43113506 0.43074772 0.43062037
 0.4307155  0.43072447 0.43067923 0.4304657  0.4300803  0.42973247
 0.42955512 0.42957327 0.4296186  0.4295976  0.42954767 0.42945442
 0.4294153  0.4294025  0.4294157  0.42939654 0.4293694  0.42935005
 0.42924407 0.42896494 0.428578   0.4281174  0.42772648 0.42742708
 0.42724982 0.42707065 0.4267035  0.42594546 0.42469928 0.42302683
 0.42117178 0.41947898 0.41793388 0.41646808 0.4151414  0.41390097
 0.412698   0.411507   0.41030616 0.40923277 0.40822804 0.4073739
 0.40662596 0.4059301  0.40522915 0.40452948 0.40387523 0.40328014
 0.40269434 0.40204048 0.4012278  0.40023765 0.39920902 0.39824504
 0.39744484 0.39668694 0.39602152 0.3952431  0.39416218 0.39286876
 0.3914786  0.3902697  0.38946453 0.38884765 0.38826963 0.38756168
 0.38659084 0.3854312  0.384281   0.38336185 0.3826934  0.38226196
 0.38187775 0.381495   0.38118294 0.38082436 0.38054043 0.3802431
 0.3798669  0.37931094 0.37862125 0.37807247 0.3777244  0.37760052
 0.3776292  0.37766865 0.37773457 0.37783393 0.3780439  0.37833422
 0.37856236 0.37875924 0.37882045 0.37866324 0.3783298  0.3780514
 0.37794802 0.37794444 0.37798956 0.37810495 0.3782025  0.3781654
 0.37810084 0.37811676 0.37816778 0.37813658 0.37802088 0.37786
 0.3776057  0.37731043 0.376973   0.3767171  0.37658608 0.376603
 0.3766639  0.37665647 0.37656215 0.37640402 0.3761453  0.37602153
 0.37605843 0.37609416 0.3759737  0.37555    0.37471688 0.37344918
 0.37189114 0.37052375 0.36939013 0.36854315 0.3678928  0.36736366
 0.36699706 0.3666157  0.36612332 0.36552396 0.3649832  0.3645576
 0.36421138 0.36365867 0.3629676  0.3622159  0.36146393 0.36067283
 0.35985228 0.35898653 0.35800633 0.35698754 0.3560657  0.35535756
 0.35476905 0.35427475 0.35377422 0.35326347 0.35259    0.35177368
 0.35085863 0.34989464 0.3489962  0.3482781  0.3477703  0.3473238
 0.34675685 0.34594467 0.34500328 0.34418786 0.34371054 0.3436368
 0.3437691  0.34368038 0.3431793  0.34228125 0.341312   0.34067672
 0.34034598 0.34007448 0.3396243  0.3391352  0.33870006 0.3384953
 0.3385468  0.3387104  0.33873218 0.33856335 0.3381594  0.3376894
 0.3372106  0.3368215  0.33663294 0.33679178 0.3373515  0.3381078
 0.33861575 0.33852902 0.3377518  0.33667073 0.33582783 0.33566782
 0.3362067  0.3369714  0.3374175  0.33741337 0.33721247 0.33729833
 0.3377472  0.3383209  0.33864826 0.33857203 0.3384438  0.33849117
 0.33885872 0.33936962 0.3396522  0.33950785 0.33907092 0.3387128
 0.33873293 0.3389759  0.3390298  0.3385207  0.33743125 0.33599353
 0.33460698 0.33355793 0.33283377 0.3322272  0.3314937  0.3306756
 0.32976687 0.32872254 0.32756793 0.32644817 0.32551455 0.32496357
 0.3247542  0.32456288 0.32414362 0.32345602 0.3225978  0.32169232
 0.32084754 0.31990138 0.31879288 0.31757963 0.3164212  0.3155394
 0.31505954 0.31478035 0.3144052  0.3137798  0.31300017 0.31229433
 0.31176174 0.31125906 0.31056777 0.30970174 0.30879608 0.3082195
 0.30805296 0.30803052 0.3078588  0.30750456 0.3070297  0.30675948
 0.30688307 0.3071681  0.3071577  0.30670828 0.30599892 0.30553538
 0.3054896  0.30571136 0.3056135  0.30495974 0.3038557  0.30275938
 0.30222818 0.30228657 0.30249527 0.302301   0.3016034  0.3009202
 0.3007193  0.30110353 0.30167383 0.3018138  0.3013621  0.30070433
 0.3003997  0.30061895 0.30116305 0.30160502 0.30153725 0.3011411
 0.30076185 0.3007118  0.30091164 0.3011247  0.3012291  0.30127066
 0.30141237 0.3017501  0.30208635 0.30211565 0.30163652 0.30089948
 0.3003155  0.30002928 0.29988703 0.2994976  0.29877973 0.29798943
 0.29748523 0.29749128 0.29776505 0.29771727 0.29688913 0.29523998
 0.29315922 0.2912932  0.28990826 0.28895983 0.288198   0.28744724
 0.28671712 0.28602538 0.28540647 0.28489378 0.28453046 0.28432524
 0.28426683 0.28425542 0.28417635 0.2838796  0.28325287 0.2822617
 0.2810959  0.279948   0.27894658 0.27817154 0.27753988 0.27695706
 0.27629483 0.27556923 0.2748509  0.27417505 0.2736246  0.27319676
 0.27277383 0.27222276 0.27145067 0.27049178 0.26952654 0.26876238
 0.26823595 0.2677959  0.26723397 0.2664313  0.26555738 0.26489305
 0.26460874 0.2646996  0.26484933 0.26469693 0.26426136 0.26361844
 0.2630315  0.26253575 0.2619682  0.2611755  0.26023102 0.25930196
 0.25874946 0.25874802 0.25913054 0.25943616 0.25945416 0.25912735
 0.25883225 0.2588238  0.25896165 0.2589468  0.2585063  0.25770378
 0.25689045 0.25655904 0.25684872 0.2574746  0.25790778 0.25792027
 0.25755262 0.2571135  0.25687426 0.2568589  0.25698704 0.25719902
 0.25736493 0.25754866 0.25767857 0.25765955 0.25745243 0.25709772
 0.25667557 0.25633088 0.25606373 0.25578234 0.25549608 0.25524902
 0.2551776  0.2552001  0.255113   0.2545961  0.25347713 0.25174722
 0.24977522 0.24806814 0.2466397  0.24535656 0.24413522 0.24308698
 0.24229915 0.24183445 0.24145643 0.24087712 0.24005464 0.23919468
 0.23846692 0.23791738 0.2376282  0.23746903 0.23716018 0.23651424
 0.23553371 0.23443484 0.23348336 0.23274928 0.23227432 0.23192552
 0.23159851 0.23126112 0.23079579 0.23013732 0.22945707 0.2287636
 0.22796033 0.22712415 0.2263032  0.22554033 0.2250449  0.22478525
 0.22469473 0.22448167 0.22402032 0.223387   0.22281194 0.22256362
 0.22261555 0.22289585 0.22297561 0.22283404 0.22248828 0.22201997
 0.2216461  0.22142251 0.2213075  0.22114205 0.22079958 0.22031458
 0.2199432  0.2199332  0.22015812 0.220497   0.22096704 0.22135568
 0.2216904  0.22182305 0.22164518 0.22126447 0.22091119 0.22074689
 0.22089465 0.22127329 0.22165298 0.22172642 0.22149508 0.22117004
 0.22093175 0.22095296 0.22103435 0.22117513 0.22137827 0.22172289
 0.22235796 0.22303745 0.22339816 0.2233023  0.22286288 0.22249328
 0.2228101  0.22389743 0.22532643 0.22638018 0.22658171 0.22603092
 0.2252948  0.22495523 0.22504579 0.22510116 0.22452083 0.22303812
 0.22098756 0.21909374 0.21778655 0.21700029 0.21643083 0.21589786
 0.21538565 0.21497953 0.21465589 0.21423928 0.2136658  0.2131171
 0.21287741 0.21289943 0.21313486 0.21327281 0.21301049 0.21215977
 0.21090412 0.2096234  0.20862181 0.20791844 0.2072897  0.20642985
 0.20534804 0.20418753 0.20316514 0.20237558 0.20154928 0.20040628
 0.19876912 0.19694798 0.19540691 0.19457446 0.19420964 0.19367982
 0.19237883 0.19044115 0.18860227 0.18779267 0.18805513 0.18871756
 0.18848933 0.18709233 0.18597399 0.18732622 0.19131108 0.19453426]
