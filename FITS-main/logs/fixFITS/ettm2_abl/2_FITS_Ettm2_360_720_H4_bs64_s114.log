Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_360_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_360_720_FITS_ETTm2_ftM_sl360_ll48_pl720_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33481
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=26, out_features=78, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1817088.0
params:  2106.0
Trainable parameters:  2106
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4216559
	speed: 0.1200s/iter; left time: 3121.4171s
	iters: 200, epoch: 1 | loss: 0.4111045
	speed: 0.1353s/iter; left time: 3503.7920s
Epoch: 1 cost time: 33.889999866485596
Epoch: 1, Steps: 261 | Train Loss: 0.5031894 Vali Loss: 0.3059796 Test Loss: 0.4177706
Validation loss decreased (inf --> 0.305980).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3896475
	speed: 0.4955s/iter; left time: 12755.1931s
	iters: 200, epoch: 2 | loss: 0.3407595
	speed: 0.1227s/iter; left time: 3145.6530s
Epoch: 2 cost time: 32.862236976623535
Epoch: 2, Steps: 261 | Train Loss: 0.3974038 Vali Loss: 0.2844352 Test Loss: 0.3893212
Validation loss decreased (0.305980 --> 0.284435).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2679297
	speed: 0.5006s/iter; left time: 12753.5383s
	iters: 200, epoch: 3 | loss: 0.3890829
	speed: 0.0999s/iter; left time: 2534.7083s
Epoch: 3 cost time: 27.999149560928345
Epoch: 3, Steps: 261 | Train Loss: 0.3753778 Vali Loss: 0.2773910 Test Loss: 0.3808502
Validation loss decreased (0.284435 --> 0.277391).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3683738
	speed: 0.5176s/iter; left time: 13054.0181s
	iters: 200, epoch: 4 | loss: 0.5017333
	speed: 0.1363s/iter; left time: 3424.3300s
Epoch: 4 cost time: 35.804725646972656
Epoch: 4, Steps: 261 | Train Loss: 0.3680217 Vali Loss: 0.2738428 Test Loss: 0.3769710
Validation loss decreased (0.277391 --> 0.273843).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2780916
	speed: 0.5493s/iter; left time: 13708.2574s
	iters: 200, epoch: 5 | loss: 0.2718540
	speed: 0.1362s/iter; left time: 3385.9048s
Epoch: 5 cost time: 37.25392985343933
Epoch: 5, Steps: 261 | Train Loss: 0.3641439 Vali Loss: 0.2722982 Test Loss: 0.3748088
Validation loss decreased (0.273843 --> 0.272298).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3408117
	speed: 0.4974s/iter; left time: 12284.4301s
	iters: 200, epoch: 6 | loss: 0.5652413
	speed: 0.1317s/iter; left time: 3239.0369s
Epoch: 6 cost time: 35.03586030006409
Epoch: 6, Steps: 261 | Train Loss: 0.3621108 Vali Loss: 0.2708762 Test Loss: 0.3733941
Validation loss decreased (0.272298 --> 0.270876).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4104252
	speed: 0.5039s/iter; left time: 12312.0220s
	iters: 200, epoch: 7 | loss: 0.2732741
	speed: 0.1277s/iter; left time: 3108.4916s
Epoch: 7 cost time: 33.120243310928345
Epoch: 7, Steps: 261 | Train Loss: 0.3601671 Vali Loss: 0.2698579 Test Loss: 0.3725222
Validation loss decreased (0.270876 --> 0.269858).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4185408
	speed: 0.4638s/iter; left time: 11210.8222s
	iters: 200, epoch: 8 | loss: 0.5303386
	speed: 0.1295s/iter; left time: 3117.2629s
Epoch: 8 cost time: 33.792266607284546
Epoch: 8, Steps: 261 | Train Loss: 0.3593994 Vali Loss: 0.2687061 Test Loss: 0.3719904
Validation loss decreased (0.269858 --> 0.268706).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4251691
	speed: 0.5622s/iter; left time: 13444.9634s
	iters: 200, epoch: 9 | loss: 0.3305401
	speed: 0.1226s/iter; left time: 2920.1385s
Epoch: 9 cost time: 34.146506786346436
Epoch: 9, Steps: 261 | Train Loss: 0.3584646 Vali Loss: 0.2685838 Test Loss: 0.3715523
Validation loss decreased (0.268706 --> 0.268584).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2858572
	speed: 0.5000s/iter; left time: 11827.1016s
	iters: 200, epoch: 10 | loss: 0.4362626
	speed: 0.1279s/iter; left time: 3012.2077s
Epoch: 10 cost time: 33.47422003746033
Epoch: 10, Steps: 261 | Train Loss: 0.3578244 Vali Loss: 0.2679597 Test Loss: 0.3713011
Validation loss decreased (0.268584 --> 0.267960).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2597935
	speed: 0.4764s/iter; left time: 11144.4517s
	iters: 200, epoch: 11 | loss: 0.2751059
	speed: 0.1191s/iter; left time: 2773.8096s
Epoch: 11 cost time: 30.869542837142944
Epoch: 11, Steps: 261 | Train Loss: 0.3572940 Vali Loss: 0.2676416 Test Loss: 0.3711278
Validation loss decreased (0.267960 --> 0.267642).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4496735
	speed: 0.4324s/iter; left time: 10002.4212s
	iters: 200, epoch: 12 | loss: 0.4637054
	speed: 0.1152s/iter; left time: 2653.1516s
Epoch: 12 cost time: 27.77281951904297
Epoch: 12, Steps: 261 | Train Loss: 0.3572935 Vali Loss: 0.2674806 Test Loss: 0.3709951
Validation loss decreased (0.267642 --> 0.267481).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3582698
	speed: 0.4316s/iter; left time: 9869.6228s
	iters: 200, epoch: 13 | loss: 0.4142542
	speed: 0.0911s/iter; left time: 2074.4550s
Epoch: 13 cost time: 24.592880249023438
Epoch: 13, Steps: 261 | Train Loss: 0.3569239 Vali Loss: 0.2671786 Test Loss: 0.3708657
Validation loss decreased (0.267481 --> 0.267179).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3864498
	speed: 0.4202s/iter; left time: 9498.8506s
	iters: 200, epoch: 14 | loss: 0.3500841
	speed: 0.1096s/iter; left time: 2466.2683s
Epoch: 14 cost time: 29.205877780914307
Epoch: 14, Steps: 261 | Train Loss: 0.3569368 Vali Loss: 0.2668162 Test Loss: 0.3708045
Validation loss decreased (0.267179 --> 0.266816).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2846403
	speed: 0.4486s/iter; left time: 10025.0542s
	iters: 200, epoch: 15 | loss: 0.4177400
	speed: 0.1102s/iter; left time: 2452.0155s
Epoch: 15 cost time: 29.897477388381958
Epoch: 15, Steps: 261 | Train Loss: 0.3568160 Vali Loss: 0.2666614 Test Loss: 0.3707552
Validation loss decreased (0.266816 --> 0.266661).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3383482
	speed: 0.4293s/iter; left time: 9481.5946s
	iters: 200, epoch: 16 | loss: 0.2766292
	speed: 0.1040s/iter; left time: 2287.6180s
Epoch: 16 cost time: 28.692917585372925
Epoch: 16, Steps: 261 | Train Loss: 0.3566527 Vali Loss: 0.2669172 Test Loss: 0.3707381
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2894036
	speed: 0.4170s/iter; left time: 9100.5986s
	iters: 200, epoch: 17 | loss: 0.2845121
	speed: 0.1204s/iter; left time: 2616.0374s
Epoch: 17 cost time: 28.600056886672974
Epoch: 17, Steps: 261 | Train Loss: 0.3564083 Vali Loss: 0.2669611 Test Loss: 0.3706999
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3316012
	speed: 0.4400s/iter; left time: 9489.1860s
	iters: 200, epoch: 18 | loss: 0.3537950
	speed: 0.1162s/iter; left time: 2495.0140s
Epoch: 18 cost time: 28.09109854698181
Epoch: 18, Steps: 261 | Train Loss: 0.3567071 Vali Loss: 0.2668468 Test Loss: 0.3707326
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3065391
	speed: 0.4455s/iter; left time: 9489.5692s
	iters: 200, epoch: 19 | loss: 0.4035013
	speed: 0.1146s/iter; left time: 2430.3668s
Epoch: 19 cost time: 30.425862073898315
Epoch: 19, Steps: 261 | Train Loss: 0.3565017 Vali Loss: 0.2665021 Test Loss: 0.3706920
Validation loss decreased (0.266661 --> 0.266502).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3413543
	speed: 0.4383s/iter; left time: 9223.6013s
	iters: 200, epoch: 20 | loss: 0.4253834
	speed: 0.0933s/iter; left time: 1953.1429s
Epoch: 20 cost time: 25.15298891067505
Epoch: 20, Steps: 261 | Train Loss: 0.3563655 Vali Loss: 0.2664687 Test Loss: 0.3706395
Validation loss decreased (0.266502 --> 0.266469).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2839701
	speed: 0.4375s/iter; left time: 9092.4687s
	iters: 200, epoch: 21 | loss: 0.3460617
	speed: 0.1110s/iter; left time: 2294.7772s
Epoch: 21 cost time: 29.278120756149292
Epoch: 21, Steps: 261 | Train Loss: 0.3561485 Vali Loss: 0.2666208 Test Loss: 0.3706747
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2816568
	speed: 0.4717s/iter; left time: 9678.9156s
	iters: 200, epoch: 22 | loss: 0.2523660
	speed: 0.1229s/iter; left time: 2510.2934s
Epoch: 22 cost time: 30.69990611076355
Epoch: 22, Steps: 261 | Train Loss: 0.3564881 Vali Loss: 0.2665334 Test Loss: 0.3706712
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3741113
	speed: 0.4295s/iter; left time: 8700.4878s
	iters: 200, epoch: 23 | loss: 0.2961313
	speed: 0.0971s/iter; left time: 1957.5297s
Epoch: 23 cost time: 28.065382719039917
Epoch: 23, Steps: 261 | Train Loss: 0.3560614 Vali Loss: 0.2665399 Test Loss: 0.3706554
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3868373
	speed: 0.4437s/iter; left time: 8873.8276s
	iters: 200, epoch: 24 | loss: 0.4103220
	speed: 0.1152s/iter; left time: 2291.4518s
Epoch: 24 cost time: 29.760860681533813
Epoch: 24, Steps: 261 | Train Loss: 0.3564144 Vali Loss: 0.2664332 Test Loss: 0.3705997
Validation loss decreased (0.266469 --> 0.266433).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3828244
	speed: 0.4399s/iter; left time: 8682.1937s
	iters: 200, epoch: 25 | loss: 0.3331908
	speed: 0.1187s/iter; left time: 2331.7112s
Epoch: 25 cost time: 28.859413146972656
Epoch: 25, Steps: 261 | Train Loss: 0.3563950 Vali Loss: 0.2662472 Test Loss: 0.3706116
Validation loss decreased (0.266433 --> 0.266247).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4829383
	speed: 0.3844s/iter; left time: 7487.2214s
	iters: 200, epoch: 26 | loss: 0.4978040
	speed: 0.0996s/iter; left time: 1929.5584s
Epoch: 26 cost time: 27.010109901428223
Epoch: 26, Steps: 261 | Train Loss: 0.3563544 Vali Loss: 0.2662994 Test Loss: 0.3706099
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3773370
	speed: 0.5043s/iter; left time: 9689.2277s
	iters: 200, epoch: 27 | loss: 0.3270476
	speed: 0.1159s/iter; left time: 2214.4924s
Epoch: 27 cost time: 29.56723380088806
Epoch: 27, Steps: 261 | Train Loss: 0.3559302 Vali Loss: 0.2668284 Test Loss: 0.3705925
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3461953
	speed: 0.4056s/iter; left time: 7687.1985s
	iters: 200, epoch: 28 | loss: 0.4771575
	speed: 0.1053s/iter; left time: 1985.2699s
Epoch: 28 cost time: 27.483957529067993
Epoch: 28, Steps: 261 | Train Loss: 0.3563078 Vali Loss: 0.2666165 Test Loss: 0.3705942
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4626049
	speed: 0.4015s/iter; left time: 7504.3467s
	iters: 200, epoch: 29 | loss: 0.4217145
	speed: 0.1232s/iter; left time: 2291.5822s
Epoch: 29 cost time: 30.069841384887695
Epoch: 29, Steps: 261 | Train Loss: 0.3562533 Vali Loss: 0.2663101 Test Loss: 0.3706211
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3945373
	speed: 0.4838s/iter; left time: 8918.2389s
	iters: 200, epoch: 30 | loss: 0.3485833
	speed: 0.1088s/iter; left time: 1994.1238s
Epoch: 30 cost time: 29.004156351089478
Epoch: 30, Steps: 261 | Train Loss: 0.3562918 Vali Loss: 0.2665492 Test Loss: 0.3706079
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3394505
	speed: 0.4217s/iter; left time: 7661.9332s
	iters: 200, epoch: 31 | loss: 0.4390832
	speed: 0.1063s/iter; left time: 1921.3585s
Epoch: 31 cost time: 28.70390558242798
Epoch: 31, Steps: 261 | Train Loss: 0.3560848 Vali Loss: 0.2664598 Test Loss: 0.3706059
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3213404
	speed: 0.4552s/iter; left time: 8152.8953s
	iters: 200, epoch: 32 | loss: 0.2863593
	speed: 0.1030s/iter; left time: 1833.9660s
Epoch: 32 cost time: 28.167413473129272
Epoch: 32, Steps: 261 | Train Loss: 0.3563999 Vali Loss: 0.2660491 Test Loss: 0.3706062
Validation loss decreased (0.266247 --> 0.266049).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2514400
	speed: 0.4389s/iter; left time: 7746.6488s
	iters: 200, epoch: 33 | loss: 0.2749736
	speed: 0.1089s/iter; left time: 1910.3557s
Epoch: 33 cost time: 26.787206411361694
Epoch: 33, Steps: 261 | Train Loss: 0.3561252 Vali Loss: 0.2663650 Test Loss: 0.3706124
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2820361
	speed: 0.4243s/iter; left time: 7378.5350s
	iters: 200, epoch: 34 | loss: 0.4171616
	speed: 0.1267s/iter; left time: 2189.9021s
Epoch: 34 cost time: 30.348005294799805
Epoch: 34, Steps: 261 | Train Loss: 0.3561761 Vali Loss: 0.2665277 Test Loss: 0.3706138
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3543749
	speed: 0.4063s/iter; left time: 6959.4323s
	iters: 200, epoch: 35 | loss: 0.3810637
	speed: 0.0958s/iter; left time: 1631.2125s
Epoch: 35 cost time: 24.97068738937378
Epoch: 35, Steps: 261 | Train Loss: 0.3560501 Vali Loss: 0.2662718 Test Loss: 0.3706011
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2763507
	speed: 0.4258s/iter; left time: 7181.1761s
	iters: 200, epoch: 36 | loss: 0.4047626
	speed: 0.0910s/iter; left time: 1525.5386s
Epoch: 36 cost time: 24.75844144821167
Epoch: 36, Steps: 261 | Train Loss: 0.3563281 Vali Loss: 0.2665427 Test Loss: 0.3705889
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4674758
	speed: 0.3836s/iter; left time: 6370.2979s
	iters: 200, epoch: 37 | loss: 0.3298731
	speed: 0.1023s/iter; left time: 1687.7862s
Epoch: 37 cost time: 26.310631036758423
Epoch: 37, Steps: 261 | Train Loss: 0.3561824 Vali Loss: 0.2663718 Test Loss: 0.3705983
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2678335
	speed: 0.4289s/iter; left time: 7009.3653s
	iters: 200, epoch: 38 | loss: 0.3138592
	speed: 0.1078s/iter; left time: 1750.8998s
Epoch: 38 cost time: 27.059455633163452
Epoch: 38, Steps: 261 | Train Loss: 0.3559869 Vali Loss: 0.2666358 Test Loss: 0.3705887
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4450499
	speed: 0.4441s/iter; left time: 7143.1619s
	iters: 200, epoch: 39 | loss: 0.3554954
	speed: 0.0874s/iter; left time: 1396.3685s
Epoch: 39 cost time: 24.316127061843872
Epoch: 39, Steps: 261 | Train Loss: 0.3560183 Vali Loss: 0.2662489 Test Loss: 0.3705947
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2840554
	speed: 0.4572s/iter; left time: 7234.4413s
	iters: 200, epoch: 40 | loss: 0.3428468
	speed: 0.0857s/iter; left time: 1347.9227s
Epoch: 40 cost time: 26.224822998046875
Epoch: 40, Steps: 261 | Train Loss: 0.3563106 Vali Loss: 0.2662972 Test Loss: 0.3705829
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2858021
	speed: 0.4258s/iter; left time: 6626.5785s
	iters: 200, epoch: 41 | loss: 0.2793484
	speed: 0.1177s/iter; left time: 1819.3951s
Epoch: 41 cost time: 30.97258687019348
Epoch: 41, Steps: 261 | Train Loss: 0.3556115 Vali Loss: 0.2663162 Test Loss: 0.3705834
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3572729
	speed: 0.4312s/iter; left time: 6598.0340s
	iters: 200, epoch: 42 | loss: 0.2264441
	speed: 0.1007s/iter; left time: 1530.2049s
Epoch: 42 cost time: 26.188259840011597
Epoch: 42, Steps: 261 | Train Loss: 0.3562145 Vali Loss: 0.2665892 Test Loss: 0.3705830
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3702142
	speed: 0.4069s/iter; left time: 6118.6553s
	iters: 200, epoch: 43 | loss: 0.3313599
	speed: 0.1001s/iter; left time: 1494.8724s
Epoch: 43 cost time: 28.29539656639099
Epoch: 43, Steps: 261 | Train Loss: 0.3560572 Vali Loss: 0.2662455 Test Loss: 0.3705764
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.4165016
	speed: 0.4460s/iter; left time: 6591.0484s
	iters: 200, epoch: 44 | loss: 0.3563375
	speed: 0.1034s/iter; left time: 1517.8419s
Epoch: 44 cost time: 26.65965700149536
Epoch: 44, Steps: 261 | Train Loss: 0.3559925 Vali Loss: 0.2662675 Test Loss: 0.3705752
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.3448676
	speed: 0.4316s/iter; left time: 6265.8806s
	iters: 200, epoch: 45 | loss: 0.3099355
	speed: 0.0835s/iter; left time: 1204.3744s
Epoch: 45 cost time: 24.57692241668701
Epoch: 45, Steps: 261 | Train Loss: 0.3561335 Vali Loss: 0.2662911 Test Loss: 0.3705748
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.3132308
	speed: 0.4124s/iter; left time: 5878.5252s
	iters: 200, epoch: 46 | loss: 0.2895599
	speed: 0.1009s/iter; left time: 1428.4510s
Epoch: 46 cost time: 27.65855383872986
Epoch: 46, Steps: 261 | Train Loss: 0.3560008 Vali Loss: 0.2664880 Test Loss: 0.3705730
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2166634
	speed: 0.4292s/iter; left time: 6006.2473s
	iters: 200, epoch: 47 | loss: 0.2992309
	speed: 0.1106s/iter; left time: 1536.6924s
Epoch: 47 cost time: 27.714224576950073
Epoch: 47, Steps: 261 | Train Loss: 0.3558398 Vali Loss: 0.2664780 Test Loss: 0.3705733
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.4455200
	speed: 0.3894s/iter; left time: 5347.3633s
	iters: 200, epoch: 48 | loss: 0.3259808
	speed: 0.0769s/iter; left time: 1048.7522s
Epoch: 48 cost time: 23.119590282440186
Epoch: 48, Steps: 261 | Train Loss: 0.3560299 Vali Loss: 0.2663062 Test Loss: 0.3705786
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.3027193
	speed: 0.3873s/iter; left time: 5218.4140s
	iters: 200, epoch: 49 | loss: 0.3799194
	speed: 0.0901s/iter; left time: 1205.1603s
Epoch: 49 cost time: 24.394328117370605
Epoch: 49, Steps: 261 | Train Loss: 0.3561673 Vali Loss: 0.2663052 Test Loss: 0.3705662
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.3985287
	speed: 0.3800s/iter; left time: 5021.0517s
	iters: 200, epoch: 50 | loss: 0.3554384
	speed: 0.0989s/iter; left time: 1297.0692s
Epoch: 50 cost time: 24.783621072769165
Epoch: 50, Steps: 261 | Train Loss: 0.3560398 Vali Loss: 0.2664072 Test Loss: 0.3705662
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.3798366
	speed: 0.3712s/iter; left time: 4807.7821s
	iters: 200, epoch: 51 | loss: 0.3315670
	speed: 0.1089s/iter; left time: 1399.1838s
Epoch: 51 cost time: 26.936973094940186
Epoch: 51, Steps: 261 | Train Loss: 0.3560746 Vali Loss: 0.2662924 Test Loss: 0.3705724
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.3913634
	speed: 0.4314s/iter; left time: 5474.0488s
	iters: 200, epoch: 52 | loss: 0.3915129
	speed: 0.0888s/iter; left time: 1117.3915s
Epoch: 52 cost time: 24.807067394256592
Epoch: 52, Steps: 261 | Train Loss: 0.3559656 Vali Loss: 0.2661650 Test Loss: 0.3705652
EarlyStopping counter: 20 out of 20
Early stopping
train 33481
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=26, out_features=78, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1817088.0
params:  2106.0
Trainable parameters:  2106
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6436046
	speed: 0.1008s/iter; left time: 2620.5494s
	iters: 200, epoch: 1 | loss: 0.3548499
	speed: 0.0961s/iter; left time: 2488.3719s
Epoch: 1 cost time: 25.161662101745605
Epoch: 1, Steps: 261 | Train Loss: 0.5211931 Vali Loss: 0.2660370 Test Loss: 0.3701381
Validation loss decreased (inf --> 0.266037).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5806876
	speed: 0.3931s/iter; left time: 10117.5085s
	iters: 200, epoch: 2 | loss: 0.5436765
	speed: 0.1060s/iter; left time: 2716.5979s
Epoch: 2 cost time: 25.637638330459595
Epoch: 2, Steps: 261 | Train Loss: 0.5205378 Vali Loss: 0.2657553 Test Loss: 0.3699594
Validation loss decreased (0.266037 --> 0.265755).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5898671
	speed: 0.3893s/iter; left time: 9918.9499s
	iters: 200, epoch: 3 | loss: 0.4210585
	speed: 0.1002s/iter; left time: 2543.2889s
Epoch: 3 cost time: 27.090903759002686
Epoch: 3, Steps: 261 | Train Loss: 0.5201815 Vali Loss: 0.2656945 Test Loss: 0.3698183
Validation loss decreased (0.265755 --> 0.265694).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4887435
	speed: 0.4106s/iter; left time: 10354.3631s
	iters: 200, epoch: 4 | loss: 0.4191845
	speed: 0.0844s/iter; left time: 2118.9530s
Epoch: 4 cost time: 24.879109621047974
Epoch: 4, Steps: 261 | Train Loss: 0.5203574 Vali Loss: 0.2655314 Test Loss: 0.3698764
Validation loss decreased (0.265694 --> 0.265531).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3604208
	speed: 0.3895s/iter; left time: 9721.0139s
	iters: 200, epoch: 5 | loss: 0.6715333
	speed: 0.0963s/iter; left time: 2393.1159s
Epoch: 5 cost time: 25.792226314544678
Epoch: 5, Steps: 261 | Train Loss: 0.5202733 Vali Loss: 0.2657046 Test Loss: 0.3698995
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4916094
	speed: 0.4341s/iter; left time: 10721.4508s
	iters: 200, epoch: 6 | loss: 0.5798487
	speed: 0.1192s/iter; left time: 2932.3881s
Epoch: 6 cost time: 29.45467472076416
Epoch: 6, Steps: 261 | Train Loss: 0.5197937 Vali Loss: 0.2651165 Test Loss: 0.3697292
Validation loss decreased (0.265531 --> 0.265116).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.5043576
	speed: 0.4514s/iter; left time: 11029.6616s
	iters: 200, epoch: 7 | loss: 0.5871206
	speed: 0.1155s/iter; left time: 2811.1057s
Epoch: 7 cost time: 30.573941469192505
Epoch: 7, Steps: 261 | Train Loss: 0.5194344 Vali Loss: 0.2652798 Test Loss: 0.3698070
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.5982685
	speed: 0.4057s/iter; left time: 9806.3170s
	iters: 200, epoch: 8 | loss: 0.4128100
	speed: 0.1097s/iter; left time: 2640.2802s
Epoch: 8 cost time: 27.748568773269653
Epoch: 8, Steps: 261 | Train Loss: 0.5198746 Vali Loss: 0.2651316 Test Loss: 0.3696840
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4548290
	speed: 0.4359s/iter; left time: 10423.1031s
	iters: 200, epoch: 9 | loss: 0.6020319
	speed: 0.1112s/iter; left time: 2648.2916s
Epoch: 9 cost time: 28.827956438064575
Epoch: 9, Steps: 261 | Train Loss: 0.5194121 Vali Loss: 0.2652989 Test Loss: 0.3697466
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.7050761
	speed: 0.4530s/iter; left time: 10714.4405s
	iters: 200, epoch: 10 | loss: 0.5432705
	speed: 0.1135s/iter; left time: 2674.1831s
Epoch: 10 cost time: 29.138585567474365
Epoch: 10, Steps: 261 | Train Loss: 0.5197320 Vali Loss: 0.2654385 Test Loss: 0.3697492
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3445352
	speed: 0.4672s/iter; left time: 10928.4710s
	iters: 200, epoch: 11 | loss: 0.5741035
	speed: 0.1056s/iter; left time: 2459.6340s
Epoch: 11 cost time: 28.57920241355896
Epoch: 11, Steps: 261 | Train Loss: 0.5195516 Vali Loss: 0.2654481 Test Loss: 0.3697301
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.6619381
	speed: 0.4462s/iter; left time: 10320.2131s
	iters: 200, epoch: 12 | loss: 0.3704975
	speed: 0.0886s/iter; left time: 2040.8104s
Epoch: 12 cost time: 24.980007886886597
Epoch: 12, Steps: 261 | Train Loss: 0.5189717 Vali Loss: 0.2653630 Test Loss: 0.3696622
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.5612918
	speed: 0.4170s/iter; left time: 9535.5518s
	iters: 200, epoch: 13 | loss: 0.5381823
	speed: 0.0980s/iter; left time: 2231.2565s
Epoch: 13 cost time: 27.149088621139526
Epoch: 13, Steps: 261 | Train Loss: 0.5198489 Vali Loss: 0.2652762 Test Loss: 0.3697014
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4282225
	speed: 0.4318s/iter; left time: 9761.0715s
	iters: 200, epoch: 14 | loss: 0.3702034
	speed: 0.0864s/iter; left time: 1943.5855s
Epoch: 14 cost time: 24.346032857894897
Epoch: 14, Steps: 261 | Train Loss: 0.5194599 Vali Loss: 0.2651081 Test Loss: 0.3697458
Validation loss decreased (0.265116 --> 0.265108).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.5956008
	speed: 0.3903s/iter; left time: 8721.7313s
	iters: 200, epoch: 15 | loss: 0.4721656
	speed: 0.0968s/iter; left time: 2153.0409s
Epoch: 15 cost time: 27.086713075637817
Epoch: 15, Steps: 261 | Train Loss: 0.5192600 Vali Loss: 0.2654248 Test Loss: 0.3697268
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.5899193
	speed: 0.4440s/iter; left time: 9805.6477s
	iters: 200, epoch: 16 | loss: 0.4857295
	speed: 0.0934s/iter; left time: 2054.1776s
Epoch: 16 cost time: 26.03155517578125
Epoch: 16, Steps: 261 | Train Loss: 0.5194391 Vali Loss: 0.2652021 Test Loss: 0.3696900
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.5625866
	speed: 0.3987s/iter; left time: 8701.7758s
	iters: 200, epoch: 17 | loss: 0.5813101
	speed: 0.1157s/iter; left time: 2513.8226s
Epoch: 17 cost time: 27.116479635238647
Epoch: 17, Steps: 261 | Train Loss: 0.5191056 Vali Loss: 0.2654001 Test Loss: 0.3697181
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.5283982
	speed: 0.4524s/iter; left time: 9755.2846s
	iters: 200, epoch: 18 | loss: 0.6458829
	speed: 0.1029s/iter; left time: 2208.6438s
Epoch: 18 cost time: 27.978418111801147
Epoch: 18, Steps: 261 | Train Loss: 0.5193312 Vali Loss: 0.2652985 Test Loss: 0.3697292
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4838864
	speed: 0.4338s/iter; left time: 9241.0572s
	iters: 200, epoch: 19 | loss: 0.5367637
	speed: 0.0975s/iter; left time: 2066.9248s
Epoch: 19 cost time: 25.162461519241333
Epoch: 19, Steps: 261 | Train Loss: 0.5190950 Vali Loss: 0.2655649 Test Loss: 0.3697345
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4316371
	speed: 0.4116s/iter; left time: 8660.4300s
	iters: 200, epoch: 20 | loss: 0.5734050
	speed: 0.1090s/iter; left time: 2282.8145s
Epoch: 20 cost time: 28.696479320526123
Epoch: 20, Steps: 261 | Train Loss: 0.5193010 Vali Loss: 0.2652841 Test Loss: 0.3697342
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3438284
	speed: 0.4323s/iter; left time: 8983.8755s
	iters: 200, epoch: 21 | loss: 0.6507609
	speed: 0.0952s/iter; left time: 1968.7461s
Epoch: 21 cost time: 25.61822485923767
Epoch: 21, Steps: 261 | Train Loss: 0.5194442 Vali Loss: 0.2651500 Test Loss: 0.3696852
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.5354311
	speed: 0.4477s/iter; left time: 9186.5358s
	iters: 200, epoch: 22 | loss: 0.6497037
	speed: 0.1066s/iter; left time: 2176.3882s
Epoch: 22 cost time: 28.741758346557617
Epoch: 22, Steps: 261 | Train Loss: 0.5190152 Vali Loss: 0.2652564 Test Loss: 0.3697383
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.5259215
	speed: 0.4220s/iter; left time: 8548.9798s
	iters: 200, epoch: 23 | loss: 0.4527067
	speed: 0.0935s/iter; left time: 1884.4874s
Epoch: 23 cost time: 25.194225311279297
Epoch: 23, Steps: 261 | Train Loss: 0.5192593 Vali Loss: 0.2650757 Test Loss: 0.3697567
Validation loss decreased (0.265108 --> 0.265076).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4403092
	speed: 0.4070s/iter; left time: 8139.2357s
	iters: 200, epoch: 24 | loss: 0.3931691
	speed: 0.1065s/iter; left time: 2119.6341s
Epoch: 24 cost time: 27.314966678619385
Epoch: 24, Steps: 261 | Train Loss: 0.5192652 Vali Loss: 0.2652877 Test Loss: 0.3697312
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.6667966
	speed: 0.4385s/iter; left time: 8655.6088s
	iters: 200, epoch: 25 | loss: 0.4418911
	speed: 0.1033s/iter; left time: 2027.8196s
Epoch: 25 cost time: 27.05800771713257
Epoch: 25, Steps: 261 | Train Loss: 0.5189278 Vali Loss: 0.2649058 Test Loss: 0.3697082
Validation loss decreased (0.265076 --> 0.264906).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.5163439
	speed: 0.4030s/iter; left time: 7848.4589s
	iters: 200, epoch: 26 | loss: 0.5954750
	speed: 0.0965s/iter; left time: 1869.2294s
Epoch: 26 cost time: 26.027575969696045
Epoch: 26, Steps: 261 | Train Loss: 0.5193697 Vali Loss: 0.2652956 Test Loss: 0.3697096
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.5326413
	speed: 0.3909s/iter; left time: 7511.9980s
	iters: 200, epoch: 27 | loss: 0.4695112
	speed: 0.0883s/iter; left time: 1688.4788s
Epoch: 27 cost time: 25.250640153884888
Epoch: 27, Steps: 261 | Train Loss: 0.5196187 Vali Loss: 0.2648962 Test Loss: 0.3697241
Validation loss decreased (0.264906 --> 0.264896).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4254362
	speed: 0.3974s/iter; left time: 7532.9156s
	iters: 200, epoch: 28 | loss: 0.7704750
	speed: 0.0939s/iter; left time: 1771.0712s
Epoch: 28 cost time: 25.51450800895691
Epoch: 28, Steps: 261 | Train Loss: 0.5192502 Vali Loss: 0.2650298 Test Loss: 0.3697173
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4369757
	speed: 0.4306s/iter; left time: 8050.0209s
	iters: 200, epoch: 29 | loss: 0.5308298
	speed: 0.1117s/iter; left time: 2075.9579s
Epoch: 29 cost time: 30.72298789024353
Epoch: 29, Steps: 261 | Train Loss: 0.5190379 Vali Loss: 0.2651119 Test Loss: 0.3697345
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4633965
	speed: 0.4099s/iter; left time: 7555.1929s
	iters: 200, epoch: 30 | loss: 0.4922549
	speed: 0.1107s/iter; left time: 2028.7000s
Epoch: 30 cost time: 25.60743522644043
Epoch: 30, Steps: 261 | Train Loss: 0.5191147 Vali Loss: 0.2650657 Test Loss: 0.3697160
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.6275726
	speed: 0.4172s/iter; left time: 7580.2964s
	iters: 200, epoch: 31 | loss: 0.5360313
	speed: 0.0903s/iter; left time: 1631.2929s
Epoch: 31 cost time: 24.49947500228882
Epoch: 31, Steps: 261 | Train Loss: 0.5189598 Vali Loss: 0.2653070 Test Loss: 0.3697206
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.5534372
	speed: 0.3955s/iter; left time: 7082.5107s
	iters: 200, epoch: 32 | loss: 0.5631853
	speed: 0.1106s/iter; left time: 1970.5854s
Epoch: 32 cost time: 27.496818780899048
Epoch: 32, Steps: 261 | Train Loss: 0.5186852 Vali Loss: 0.2652877 Test Loss: 0.3697211
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.5056989
	speed: 0.4272s/iter; left time: 7538.9918s
	iters: 200, epoch: 33 | loss: 0.5201442
	speed: 0.1092s/iter; left time: 1916.6205s
Epoch: 33 cost time: 27.808412790298462
Epoch: 33, Steps: 261 | Train Loss: 0.5194958 Vali Loss: 0.2652158 Test Loss: 0.3697252
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.5524826
	speed: 0.4142s/iter; left time: 7201.7195s
	iters: 200, epoch: 34 | loss: 0.6375256
	speed: 0.1017s/iter; left time: 1758.3955s
Epoch: 34 cost time: 27.717288732528687
Epoch: 34, Steps: 261 | Train Loss: 0.5192919 Vali Loss: 0.2654313 Test Loss: 0.3697211
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.7167535
	speed: 0.4085s/iter; left time: 6995.5975s
	iters: 200, epoch: 35 | loss: 0.5729342
	speed: 0.0884s/iter; left time: 1506.0147s
Epoch: 35 cost time: 24.841883182525635
Epoch: 35, Steps: 261 | Train Loss: 0.5189853 Vali Loss: 0.2652474 Test Loss: 0.3697164
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4315873
	speed: 0.4068s/iter; left time: 6861.5765s
	iters: 200, epoch: 36 | loss: 0.5059797
	speed: 0.0904s/iter; left time: 1514.8086s
Epoch: 36 cost time: 25.046849012374878
Epoch: 36, Steps: 261 | Train Loss: 0.5186799 Vali Loss: 0.2651641 Test Loss: 0.3697193
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.6082266
	speed: 0.4065s/iter; left time: 6750.2156s
	iters: 200, epoch: 37 | loss: 0.6457211
	speed: 0.1058s/iter; left time: 1746.5742s
Epoch: 37 cost time: 26.70766019821167
Epoch: 37, Steps: 261 | Train Loss: 0.5189190 Vali Loss: 0.2654009 Test Loss: 0.3697035
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4205862
	speed: 0.4230s/iter; left time: 6913.5463s
	iters: 200, epoch: 38 | loss: 0.4258829
	speed: 0.0869s/iter; left time: 1411.9762s
Epoch: 38 cost time: 23.418493270874023
Epoch: 38, Steps: 261 | Train Loss: 0.5191732 Vali Loss: 0.2653975 Test Loss: 0.3697168
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4008608
	speed: 0.3815s/iter; left time: 6136.3191s
	iters: 200, epoch: 39 | loss: 0.4979248
	speed: 0.1114s/iter; left time: 1779.7800s
Epoch: 39 cost time: 28.460267543792725
Epoch: 39, Steps: 261 | Train Loss: 0.5191988 Vali Loss: 0.2650059 Test Loss: 0.3697248
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.5328046
	speed: 0.4418s/iter; left time: 6990.2770s
	iters: 200, epoch: 40 | loss: 0.4468274
	speed: 0.1004s/iter; left time: 1578.6269s
Epoch: 40 cost time: 27.962930917739868
Epoch: 40, Steps: 261 | Train Loss: 0.5187163 Vali Loss: 0.2651742 Test Loss: 0.3697270
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.6538826
	speed: 0.4471s/iter; left time: 6956.6838s
	iters: 200, epoch: 41 | loss: 0.3494510
	speed: 0.1229s/iter; left time: 1900.5391s
Epoch: 41 cost time: 31.127760887145996
Epoch: 41, Steps: 261 | Train Loss: 0.5188017 Vali Loss: 0.2652535 Test Loss: 0.3697263
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.4864849
	speed: 0.4164s/iter; left time: 6371.3710s
	iters: 200, epoch: 42 | loss: 0.5074320
	speed: 0.0881s/iter; left time: 1339.6202s
Epoch: 42 cost time: 23.965208292007446
Epoch: 42, Steps: 261 | Train Loss: 0.5191325 Vali Loss: 0.2653076 Test Loss: 0.3697270
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.5742587
	speed: 0.3811s/iter; left time: 5731.8307s
	iters: 200, epoch: 43 | loss: 0.5106661
	speed: 0.0864s/iter; left time: 1290.8482s
Epoch: 43 cost time: 23.48474359512329
Epoch: 43, Steps: 261 | Train Loss: 0.5188821 Vali Loss: 0.2652272 Test Loss: 0.3697295
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.5542046
	speed: 0.3875s/iter; left time: 5726.5678s
	iters: 200, epoch: 44 | loss: 0.4355541
	speed: 0.0988s/iter; left time: 1450.4388s
Epoch: 44 cost time: 27.429992198944092
Epoch: 44, Steps: 261 | Train Loss: 0.5188308 Vali Loss: 0.2652450 Test Loss: 0.3697256
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.4979841
	speed: 0.4771s/iter; left time: 6926.1321s
	iters: 200, epoch: 45 | loss: 0.4656799
	speed: 0.1027s/iter; left time: 1481.0572s
Epoch: 45 cost time: 27.96266007423401
Epoch: 45, Steps: 261 | Train Loss: 0.5188269 Vali Loss: 0.2652170 Test Loss: 0.3697182
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.3428469
	speed: 0.4235s/iter; left time: 6037.6646s
	iters: 200, epoch: 46 | loss: 0.4385341
	speed: 0.1140s/iter; left time: 1613.9505s
Epoch: 46 cost time: 30.08634114265442
Epoch: 46, Steps: 261 | Train Loss: 0.5181841 Vali Loss: 0.2652328 Test Loss: 0.3697167
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.5273196
	speed: 0.4533s/iter; left time: 6343.6286s
	iters: 200, epoch: 47 | loss: 0.4723679
	speed: 0.1260s/iter; left time: 1751.1562s
Epoch: 47 cost time: 32.095744609832764
Epoch: 47, Steps: 261 | Train Loss: 0.5191867 Vali Loss: 0.2653345 Test Loss: 0.3697179
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_360_720_FITS_ETTm2_ftM_sl360_ll48_pl720_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.3669736385345459, mae:0.383157342672348, rse:0.4869247376918793, corr:[0.5396062  0.5414115  0.5422584  0.54202235 0.5410352  0.5396537
 0.5383324  0.5372768  0.5365823  0.53627837 0.5362341  0.5363542
 0.5364864  0.536453   0.53616923 0.5355619  0.534721   0.53375995
 0.53280133 0.5319353  0.53127646 0.53089976 0.53072727 0.5307306
 0.53076756 0.53067803 0.5304047  0.52995515 0.52940124 0.52877617
 0.52814764 0.52760446 0.5271424  0.52673036 0.526321   0.52588356
 0.52539635 0.52487385 0.5243505  0.52384216 0.52333134 0.5228234
 0.522275   0.52164054 0.5209084  0.5200456  0.51913583 0.5182489
 0.51740056 0.51661295 0.51585114 0.5151612  0.51448756 0.5137812
 0.5130518  0.51234394 0.51168644 0.5111277  0.5107119  0.51042694
 0.5102619  0.5101632  0.510096   0.5099909  0.5098089  0.50957596
 0.50929046 0.5089977  0.5087377  0.50854313 0.50839216 0.50825447
 0.50809985 0.5079165  0.5076734  0.5073239  0.50689626 0.50639445
 0.5058664  0.5053104  0.50477946 0.50423604 0.503688   0.5030997
 0.50251776 0.5019842  0.5014882  0.501063   0.500675   0.5002801
 0.49982134 0.4992348  0.49840206 0.49729243 0.49594146 0.49440145
 0.49274692 0.49114382 0.48966208 0.4882803  0.48695835 0.4857099
 0.48451975 0.48332858 0.48209482 0.48088604 0.4797744  0.47882327
 0.4780298  0.47731462 0.47664487 0.4759315  0.47515327 0.4742905
 0.4733697  0.47246224 0.47162995 0.47089672 0.47031042 0.46978724
 0.46923727 0.46855468 0.46778038 0.4669131  0.46596354 0.46496192
 0.4639927  0.46307558 0.46220216 0.46138224 0.46063465 0.459942
 0.4592826  0.45865318 0.45805386 0.45750254 0.45691875 0.45632532
 0.45566142 0.45490515 0.45404533 0.45307562 0.4520475  0.45097125
 0.44992083 0.44895756 0.44816282 0.44753987 0.44702783 0.44652864
 0.44600654 0.4454537  0.4448135  0.44410345 0.4433928  0.44275734
 0.4422156  0.44176063 0.4413222  0.44094098 0.44055292 0.44013372
 0.4397256  0.4393465  0.43907538 0.4389267  0.4387984  0.43869585
 0.43852714 0.43826786 0.4379037  0.43744108 0.4368878  0.43632072
 0.43579853 0.4353808  0.43506247 0.4348002  0.43455443 0.4343017
 0.4340006  0.43363273 0.43325537 0.43286654 0.43246827 0.4320451
 0.43153968 0.43086872 0.42996937 0.42878756 0.42741698 0.42584968
 0.4241857  0.4226441  0.4212058  0.41979757 0.41842365 0.4170162
 0.41557476 0.4140627  0.41248432 0.4109139  0.40944207 0.408151
 0.40705806 0.40615588 0.40532923 0.40450794 0.40363196 0.40273708
 0.4017852  0.40076518 0.39974675 0.39883807 0.39802638 0.3972939
 0.39656818 0.39559534 0.39442036 0.39309725 0.3916802  0.39024168
 0.38892168 0.38773978 0.38674948 0.38580963 0.3848432  0.38377476
 0.38264316 0.3815446  0.3805379  0.37966636 0.3789416  0.37836722
 0.3778314  0.377247   0.37660095 0.37584674 0.37502128 0.37423313
 0.3735465  0.37302127 0.37267718 0.37261862 0.37266323 0.3727246
 0.37276873 0.3727198  0.37253693 0.37224963 0.371934   0.37170184
 0.3715101  0.3714367  0.37138358 0.37130186 0.37113747 0.37086785
 0.37058574 0.3703483  0.37023386 0.37023413 0.37024242 0.37023944
 0.37020335 0.37010974 0.36992428 0.36959067 0.36918154 0.36879402
 0.3684625  0.36819497 0.36800224 0.36793062 0.3678881  0.36783716
 0.3676794  0.36739746 0.36703265 0.3666599  0.3663065  0.36602607
 0.3657508  0.36541465 0.364952   0.36429697 0.36338323 0.36227486
 0.36109692 0.3600661  0.35920763 0.358479   0.35785502 0.35729185
 0.3566973  0.3560312  0.35531837 0.35452327 0.35374844 0.35310248
 0.35261065 0.3521815  0.35181323 0.35146093 0.351059   0.35058218
 0.35016632 0.34981003 0.3495365  0.34944668 0.3495181  0.34968913
 0.34978747 0.34971744 0.34938225 0.34880573 0.34806168 0.3472386
 0.3464741  0.34582648 0.3452927  0.34488776 0.34459993 0.344395
 0.34421667 0.34410095 0.3440424  0.34398636 0.34386778 0.34371504
 0.34350693 0.34320325 0.34279788 0.34224373 0.34155184 0.34087548
 0.3402616  0.33978572 0.33950076 0.33944115 0.33953193 0.33967814
 0.33976477 0.33978838 0.3397157  0.3395214  0.33927357 0.33901557
 0.3388094  0.338653   0.33848682 0.33830097 0.3381158  0.33790743
 0.3376878  0.3375537  0.33749914 0.33752346 0.33759624 0.33762142
 0.33757058 0.33743927 0.33715922 0.3367588  0.33626056 0.33580664
 0.33544025 0.33525515 0.3352517  0.33537877 0.33560747 0.33579996
 0.33590484 0.33592966 0.33590084 0.33580798 0.33566275 0.33550042
 0.33530855 0.3350553  0.3346759  0.3340566  0.3332829  0.3323655
 0.33137125 0.33043388 0.3296153  0.32890812 0.32822382 0.32756722
 0.3268624  0.3260569  0.32521087 0.32433903 0.32349518 0.3227384
 0.32214114 0.32174128 0.3213589  0.32092556 0.32039818 0.31973138
 0.31902117 0.31831646 0.31774744 0.31739318 0.3172386  0.31725156
 0.31731537 0.31728315 0.31710494 0.316803   0.31639597 0.31597775
 0.31561947 0.31536868 0.31518927 0.3150214  0.31480733 0.3145444
 0.31425118 0.31400695 0.31382564 0.31371966 0.3137011  0.31374013
 0.31376266 0.3137459  0.3136456  0.3134021  0.3130463  0.31261218
 0.3121373  0.31169564 0.31130743 0.31104487 0.3108763  0.31076452
 0.31061572 0.3104446  0.31015676 0.3098364  0.30949208 0.30919388
 0.3089464  0.3087688  0.3086484  0.3084917  0.3082597  0.30793232
 0.30762437 0.3073811  0.3071999  0.3070821  0.30699128 0.30688706
 0.30674362 0.3065385  0.30621213 0.30579406 0.30536228 0.30490884
 0.3045108  0.30420533 0.3040308  0.30393022 0.3037775  0.30356953
 0.30324635 0.3028083  0.30223662 0.30157942 0.30091372 0.30024916
 0.29955482 0.2987637  0.29786634 0.29683793 0.29567093 0.29437044
 0.29304945 0.29181626 0.29070708 0.28974497 0.28886622 0.2880086
 0.28713328 0.2862373  0.2853428  0.28452313 0.28377518 0.28307554
 0.28245005 0.28190476 0.28140545 0.2808855  0.28032893 0.27969903
 0.27903664 0.27837163 0.27773908 0.27720004 0.27677915 0.27647397
 0.2762046  0.27581665 0.27531907 0.2747186  0.27412745 0.2735537
 0.27305323 0.27265027 0.27231824 0.27200562 0.27168593 0.27130634
 0.27090594 0.27048612 0.27008703 0.2697558  0.269491   0.26930624
 0.2691241  0.2689277  0.26863888 0.26823473 0.2677525  0.2672089
 0.2666498  0.26617312 0.26579267 0.26553497 0.26540384 0.26538736
 0.2654132  0.26542073 0.2654376  0.26541758 0.2653615  0.26531145
 0.26522103 0.26511407 0.26496068 0.2647667  0.26449883 0.2641937
 0.26388475 0.26365775 0.2635409  0.26353174 0.26353598 0.2635473
 0.26348627 0.26330885 0.26302227 0.26260427 0.2621183  0.26163328
 0.26121518 0.260932   0.2608101  0.26081467 0.26084363 0.26084155
 0.26076147 0.26056087 0.26025483 0.2598032  0.259284   0.2587131
 0.25807717 0.25732538 0.25638157 0.25522843 0.25393233 0.2525035
 0.25102252 0.24966462 0.24847955 0.24745992 0.24653453 0.245658
 0.24467115 0.24360357 0.24244417 0.2412367  0.24008638 0.23909153
 0.23821442 0.23742242 0.23673405 0.23613162 0.23551305 0.23483594
 0.23414367 0.2334782  0.23290017 0.23242067 0.23207834 0.23181963
 0.23156814 0.23123278 0.23076984 0.23019974 0.22958258 0.22899432
 0.22848988 0.22809277 0.2277715  0.2274512  0.22710888 0.22668849
 0.22623849 0.22573835 0.22523801 0.22481777 0.22450504 0.22434384
 0.22423731 0.22414224 0.2239628  0.22369139 0.2233711  0.22304426
 0.22274978 0.2224808  0.22228046 0.22220254 0.2222174  0.22220974
 0.22216688 0.22211787 0.22206643 0.22195785 0.22185715 0.22175847
 0.22179744 0.22190599 0.22199947 0.22207189 0.22205244 0.22197072
 0.22179702 0.22165425 0.2215835  0.2215628  0.2216888  0.22178343
 0.2218253  0.22177774 0.22160037 0.22134198 0.22104837 0.22074005
 0.22056805 0.22059    0.22076082 0.22109728 0.22151406 0.22187662
 0.22218241 0.22244446 0.22267175 0.22284253 0.22300768 0.22313459
 0.2231604  0.22302099 0.22267638 0.22200334 0.22098951 0.21976359
 0.21844643 0.21721193 0.21613254 0.21520379 0.21441011 0.21377079
 0.21314636 0.2125127  0.21192819 0.2113834  0.21085618 0.2103982
 0.21006784 0.20977902 0.20949319 0.2091333  0.20872736 0.20816034
 0.20752972 0.20687482 0.20626873 0.20590162 0.2057806  0.2058347
 0.20597765 0.20599453 0.20581633 0.20543604 0.20493612 0.20434919
 0.20382257 0.20332295 0.20287286 0.2024916  0.20209341 0.20171297
 0.20126444 0.20082223 0.20044225 0.20014499 0.1998805  0.19962712
 0.19931263 0.1988501  0.19815432 0.19736959 0.19649746 0.19569302]
