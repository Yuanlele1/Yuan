Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=14, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_90_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_90_96_FITS_ETTm2_ftM_sl90_ll48_pl96_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34375
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=14, out_features=28, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  351232.0
params:  420.0
Trainable parameters:  420
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2354867
	speed: 0.0751s/iter; left time: 2006.4279s
	iters: 200, epoch: 1 | loss: 0.2458117
	speed: 0.0697s/iter; left time: 1853.1703s
Epoch: 1 cost time: 19.29701566696167
Epoch: 1, Steps: 268 | Train Loss: 0.2987759 Vali Loss: 0.1396252 Test Loss: 0.2001763
Validation loss decreased (inf --> 0.139625).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4065653
	speed: 0.3194s/iter; left time: 8442.0257s
	iters: 200, epoch: 2 | loss: 0.2097943
	speed: 0.0690s/iter; left time: 1816.7064s
Epoch: 2 cost time: 19.072595357894897
Epoch: 2, Steps: 268 | Train Loss: 0.2577895 Vali Loss: 0.1321469 Test Loss: 0.1899913
Validation loss decreased (0.139625 --> 0.132147).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2203013
	speed: 0.3119s/iter; left time: 8161.3974s
	iters: 200, epoch: 3 | loss: 0.1666944
	speed: 0.0668s/iter; left time: 1741.5860s
Epoch: 3 cost time: 18.686048984527588
Epoch: 3, Steps: 268 | Train Loss: 0.2501643 Vali Loss: 0.1307151 Test Loss: 0.1875655
Validation loss decreased (0.132147 --> 0.130715).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3181521
	speed: 0.3123s/iter; left time: 8087.3877s
	iters: 200, epoch: 4 | loss: 0.3198554
	speed: 0.0685s/iter; left time: 1766.4430s
Epoch: 4 cost time: 18.938097715377808
Epoch: 4, Steps: 268 | Train Loss: 0.2472400 Vali Loss: 0.1305147 Test Loss: 0.1867005
Validation loss decreased (0.130715 --> 0.130515).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2236749
	speed: 0.3104s/iter; left time: 7956.2187s
	iters: 200, epoch: 5 | loss: 0.2518157
	speed: 0.0682s/iter; left time: 1741.0804s
Epoch: 5 cost time: 18.73062491416931
Epoch: 5, Steps: 268 | Train Loss: 0.2452932 Vali Loss: 0.1304990 Test Loss: 0.1863386
Validation loss decreased (0.130515 --> 0.130499).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2214883
	speed: 0.2987s/iter; left time: 7574.1009s
	iters: 200, epoch: 6 | loss: 0.2358658
	speed: 0.0691s/iter; left time: 1745.2348s
Epoch: 6 cost time: 18.868974447250366
Epoch: 6, Steps: 268 | Train Loss: 0.2447486 Vali Loss: 0.1301475 Test Loss: 0.1859354
Validation loss decreased (0.130499 --> 0.130148).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3115977
	speed: 0.3007s/iter; left time: 7545.3122s
	iters: 200, epoch: 7 | loss: 0.2809153
	speed: 0.0697s/iter; left time: 1742.6579s
Epoch: 7 cost time: 18.96849775314331
Epoch: 7, Steps: 268 | Train Loss: 0.2440323 Vali Loss: 0.1303463 Test Loss: 0.1858249
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2501521
	speed: 0.3125s/iter; left time: 7758.3624s
	iters: 200, epoch: 8 | loss: 0.1949914
	speed: 0.0684s/iter; left time: 1690.7330s
Epoch: 8 cost time: 18.878530025482178
Epoch: 8, Steps: 268 | Train Loss: 0.2436134 Vali Loss: 0.1304058 Test Loss: 0.1857105
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4471562
	speed: 0.3260s/iter; left time: 8004.9523s
	iters: 200, epoch: 9 | loss: 0.1893584
	speed: 0.0700s/iter; left time: 1711.8296s
Epoch: 9 cost time: 19.672157764434814
Epoch: 9, Steps: 268 | Train Loss: 0.2431457 Vali Loss: 0.1303690 Test Loss: 0.1856143
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3087709
	speed: 0.3046s/iter; left time: 7397.7817s
	iters: 200, epoch: 10 | loss: 0.2451464
	speed: 0.0674s/iter; left time: 1629.5886s
Epoch: 10 cost time: 18.66048574447632
Epoch: 10, Steps: 268 | Train Loss: 0.2430120 Vali Loss: 0.1306983 Test Loss: 0.1857166
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3476142
	speed: 0.3054s/iter; left time: 7336.6161s
	iters: 200, epoch: 11 | loss: 0.2478431
	speed: 0.0676s/iter; left time: 1618.0518s
Epoch: 11 cost time: 19.147798538208008
Epoch: 11, Steps: 268 | Train Loss: 0.2429360 Vali Loss: 0.1306468 Test Loss: 0.1856329
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1705380
	speed: 0.2919s/iter; left time: 6933.8978s
	iters: 200, epoch: 12 | loss: 0.2090829
	speed: 0.0670s/iter; left time: 1584.3528s
Epoch: 12 cost time: 18.874269485473633
Epoch: 12, Steps: 268 | Train Loss: 0.2424201 Vali Loss: 0.1305743 Test Loss: 0.1854984
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2255015
	speed: 0.3165s/iter; left time: 7432.4751s
	iters: 200, epoch: 13 | loss: 0.2186965
	speed: 0.0662s/iter; left time: 1547.2263s
Epoch: 13 cost time: 19.075106620788574
Epoch: 13, Steps: 268 | Train Loss: 0.2426823 Vali Loss: 0.1306231 Test Loss: 0.1855702
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2662619
	speed: 0.2962s/iter; left time: 6876.6506s
	iters: 200, epoch: 14 | loss: 0.2433499
	speed: 0.0645s/iter; left time: 1491.6345s
Epoch: 14 cost time: 15.13849949836731
Epoch: 14, Steps: 268 | Train Loss: 0.2423472 Vali Loss: 0.1304407 Test Loss: 0.1853559
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1985966
	speed: 0.2416s/iter; left time: 5545.3365s
	iters: 200, epoch: 15 | loss: 0.2623764
	speed: 0.0606s/iter; left time: 1383.7839s
Epoch: 15 cost time: 16.001673698425293
Epoch: 15, Steps: 268 | Train Loss: 0.2421855 Vali Loss: 0.1305044 Test Loss: 0.1853555
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1617997
	speed: 0.1943s/iter; left time: 4406.4894s
	iters: 200, epoch: 16 | loss: 0.3300913
	speed: 0.0656s/iter; left time: 1481.5440s
Epoch: 16 cost time: 16.93328285217285
Epoch: 16, Steps: 268 | Train Loss: 0.2422968 Vali Loss: 0.1305313 Test Loss: 0.1853823
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2378386
	speed: 0.2927s/iter; left time: 6559.5822s
	iters: 200, epoch: 17 | loss: 0.1526051
	speed: 0.0685s/iter; left time: 1527.8158s
Epoch: 17 cost time: 18.87966251373291
Epoch: 17, Steps: 268 | Train Loss: 0.2421333 Vali Loss: 0.1305515 Test Loss: 0.1853991
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2612238
	speed: 0.2958s/iter; left time: 6549.4681s
	iters: 200, epoch: 18 | loss: 0.2786594
	speed: 0.0565s/iter; left time: 1244.8888s
Epoch: 18 cost time: 17.096490621566772
Epoch: 18, Steps: 268 | Train Loss: 0.2421796 Vali Loss: 0.1306510 Test Loss: 0.1854040
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2247723
	speed: 0.2562s/iter; left time: 5604.7409s
	iters: 200, epoch: 19 | loss: 0.3002068
	speed: 0.0604s/iter; left time: 1315.6769s
Epoch: 19 cost time: 16.851497888565063
Epoch: 19, Steps: 268 | Train Loss: 0.2420652 Vali Loss: 0.1305268 Test Loss: 0.1852956
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2494990
	speed: 0.2646s/iter; left time: 5718.6385s
	iters: 200, epoch: 20 | loss: 0.3191286
	speed: 0.0636s/iter; left time: 1367.8761s
Epoch: 20 cost time: 17.059126377105713
Epoch: 20, Steps: 268 | Train Loss: 0.2419649 Vali Loss: 0.1306940 Test Loss: 0.1853734
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2781012
	speed: 0.2731s/iter; left time: 5828.9598s
	iters: 200, epoch: 21 | loss: 0.1816862
	speed: 0.0621s/iter; left time: 1318.3480s
Epoch: 21 cost time: 16.757371425628662
Epoch: 21, Steps: 268 | Train Loss: 0.2421605 Vali Loss: 0.1306106 Test Loss: 0.1853627
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1912067
	speed: 0.2440s/iter; left time: 5142.8292s
	iters: 200, epoch: 22 | loss: 0.3526926
	speed: 0.0498s/iter; left time: 1043.9218s
Epoch: 22 cost time: 12.377197027206421
Epoch: 22, Steps: 268 | Train Loss: 0.2418680 Vali Loss: 0.1306987 Test Loss: 0.1853618
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3001605
	speed: 0.1642s/iter; left time: 3415.9115s
	iters: 200, epoch: 23 | loss: 0.2790619
	speed: 0.0508s/iter; left time: 1052.4148s
Epoch: 23 cost time: 12.057644128799438
Epoch: 23, Steps: 268 | Train Loss: 0.2418767 Vali Loss: 0.1307226 Test Loss: 0.1853427
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2164356
	speed: 0.1801s/iter; left time: 3699.6089s
	iters: 200, epoch: 24 | loss: 0.2734669
	speed: 0.0327s/iter; left time: 667.7964s
Epoch: 24 cost time: 11.467557668685913
Epoch: 24, Steps: 268 | Train Loss: 0.2417467 Vali Loss: 0.1306669 Test Loss: 0.1853275
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2202441
	speed: 0.2095s/iter; left time: 4245.7402s
	iters: 200, epoch: 25 | loss: 0.1576095
	speed: 0.0586s/iter; left time: 1181.3518s
Epoch: 25 cost time: 16.729360818862915
Epoch: 25, Steps: 268 | Train Loss: 0.2417466 Vali Loss: 0.1305498 Test Loss: 0.1852870
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1570041
	speed: 0.2648s/iter; left time: 5295.8982s
	iters: 200, epoch: 26 | loss: 0.2526900
	speed: 0.0595s/iter; left time: 1183.7741s
Epoch: 26 cost time: 15.3387451171875
Epoch: 26, Steps: 268 | Train Loss: 0.2415955 Vali Loss: 0.1306307 Test Loss: 0.1852964
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_90_96_FITS_ETTm2_ftM_sl90_ll48_pl96_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.1867985725402832, mae:0.2703264653682709, rse:0.3504152297973633, corr:[0.5619563  0.5682958  0.56637776 0.561403   0.5577008  0.55703676
 0.5581412  0.5587238  0.5578218  0.55603623 0.5544804  0.55396646
 0.55439717 0.55486447 0.5544965  0.5531628  0.55141395 0.5500085
 0.54940164 0.54929143 0.54904294 0.5483078  0.5471954  0.5461698
 0.54564035 0.5455601  0.5455438  0.54514855 0.5442254  0.5430725
 0.54208887 0.5415951  0.5414644  0.5413433  0.5409442  0.5402512
 0.53934705 0.5384433  0.5377304  0.5371991  0.5367547  0.53636014
 0.5359371  0.53549385 0.5351141  0.5347345  0.53428805 0.53363353
 0.5327656  0.53175944 0.53078306 0.53004086 0.5295079  0.52900803
 0.5285061  0.5279307  0.5272298  0.5265644  0.5260568  0.52581644
 0.5257505  0.5257082  0.52557886 0.52539724 0.52520627 0.52506375
 0.525006   0.524999   0.525038   0.5250233  0.5249645  0.52493143
 0.52493614 0.52504647 0.5251801  0.5252463  0.52518976 0.5249792
 0.5247125  0.5245049  0.52443534 0.524439   0.5243768  0.52415496
 0.5237891  0.5234151  0.52319866 0.5232295  0.5233217  0.5232727
 0.5230105  0.5226703  0.52252287 0.5226288  0.52243435 0.52075976]
