Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_720_720_FITS_ETTm2_ftM_sl720_ll48_pl720_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=90, out_features=180, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  14515200.0
params:  16380.0
Trainable parameters:  16380
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5168626
	speed: 0.0315s/iter; left time: 808.7015s
	iters: 200, epoch: 1 | loss: 0.6278936
	speed: 0.0255s/iter; left time: 652.3635s
Epoch: 1 cost time: 7.280834197998047
Epoch: 1, Steps: 258 | Train Loss: 0.5805778 Vali Loss: 0.2803797 Test Loss: 0.3748262
Validation loss decreased (inf --> 0.280380).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5651718
	speed: 0.1141s/iter; left time: 2903.7925s
	iters: 200, epoch: 2 | loss: 0.7278928
	speed: 0.0231s/iter; left time: 584.4311s
Epoch: 2 cost time: 7.299187421798706
Epoch: 2, Steps: 258 | Train Loss: 0.5185585 Vali Loss: 0.2699361 Test Loss: 0.3644669
Validation loss decreased (0.280380 --> 0.269936).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.6949957
	speed: 0.1110s/iter; left time: 2795.5520s
	iters: 200, epoch: 3 | loss: 0.4218248
	speed: 0.0257s/iter; left time: 645.2211s
Epoch: 3 cost time: 6.883420944213867
Epoch: 3, Steps: 258 | Train Loss: 0.5088136 Vali Loss: 0.2666877 Test Loss: 0.3605225
Validation loss decreased (0.269936 --> 0.266688).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.6174852
	speed: 0.1122s/iter; left time: 2796.0731s
	iters: 200, epoch: 4 | loss: 0.3530059
	speed: 0.0222s/iter; left time: 550.5889s
Epoch: 4 cost time: 7.416850805282593
Epoch: 4, Steps: 258 | Train Loss: 0.5048054 Vali Loss: 0.2654897 Test Loss: 0.3583662
Validation loss decreased (0.266688 --> 0.265490).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.5036401
	speed: 0.1061s/iter; left time: 2618.5581s
	iters: 200, epoch: 5 | loss: 0.5482855
	speed: 0.0210s/iter; left time: 516.1200s
Epoch: 5 cost time: 7.078587532043457
Epoch: 5, Steps: 258 | Train Loss: 0.5014524 Vali Loss: 0.2644366 Test Loss: 0.3568571
Validation loss decreased (0.265490 --> 0.264437).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4506030
	speed: 0.1043s/iter; left time: 2545.4211s
	iters: 200, epoch: 6 | loss: 0.3311033
	speed: 0.0243s/iter; left time: 590.5816s
Epoch: 6 cost time: 6.668091297149658
Epoch: 6, Steps: 258 | Train Loss: 0.5001056 Vali Loss: 0.2633841 Test Loss: 0.3560343
Validation loss decreased (0.264437 --> 0.263384).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.5697007
	speed: 0.1080s/iter; left time: 2608.8750s
	iters: 200, epoch: 7 | loss: 0.4195233
	speed: 0.0226s/iter; left time: 543.3093s
Epoch: 7 cost time: 6.9393630027771
Epoch: 7, Steps: 258 | Train Loss: 0.4993179 Vali Loss: 0.2628843 Test Loss: 0.3552372
Validation loss decreased (0.263384 --> 0.262884).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4401585
	speed: 0.1100s/iter; left time: 2629.0129s
	iters: 200, epoch: 8 | loss: 0.5172739
	speed: 0.0219s/iter; left time: 520.8121s
Epoch: 8 cost time: 7.321669578552246
Epoch: 8, Steps: 258 | Train Loss: 0.4982117 Vali Loss: 0.2628721 Test Loss: 0.3547669
Validation loss decreased (0.262884 --> 0.262872).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.5587465
	speed: 0.1100s/iter; left time: 2598.9631s
	iters: 200, epoch: 9 | loss: 0.4417576
	speed: 0.0244s/iter; left time: 575.1388s
Epoch: 9 cost time: 6.848505258560181
Epoch: 9, Steps: 258 | Train Loss: 0.4976066 Vali Loss: 0.2624674 Test Loss: 0.3541912
Validation loss decreased (0.262872 --> 0.262467).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.6075826
	speed: 0.1116s/iter; left time: 2609.5072s
	iters: 200, epoch: 10 | loss: 0.4145564
	speed: 0.0211s/iter; left time: 490.6360s
Epoch: 10 cost time: 7.005685329437256
Epoch: 10, Steps: 258 | Train Loss: 0.4976082 Vali Loss: 0.2623997 Test Loss: 0.3539131
Validation loss decreased (0.262467 --> 0.262400).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4909028
	speed: 0.1012s/iter; left time: 2338.8483s
	iters: 200, epoch: 11 | loss: 0.6676282
	speed: 0.0215s/iter; left time: 494.9659s
Epoch: 11 cost time: 6.95261025428772
Epoch: 11, Steps: 258 | Train Loss: 0.4971417 Vali Loss: 0.2617125 Test Loss: 0.3539708
Validation loss decreased (0.262400 --> 0.261713).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.5488831
	speed: 0.1028s/iter; left time: 2351.1019s
	iters: 200, epoch: 12 | loss: 0.5252265
	speed: 0.0221s/iter; left time: 501.9281s
Epoch: 12 cost time: 7.213115453720093
Epoch: 12, Steps: 258 | Train Loss: 0.4963422 Vali Loss: 0.2615878 Test Loss: 0.3535342
Validation loss decreased (0.261713 --> 0.261588).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4193499
	speed: 0.1086s/iter; left time: 2454.5609s
	iters: 200, epoch: 13 | loss: 0.4457580
	speed: 0.0292s/iter; left time: 656.6236s
Epoch: 13 cost time: 7.139274597167969
Epoch: 13, Steps: 258 | Train Loss: 0.4968191 Vali Loss: 0.2613761 Test Loss: 0.3535480
Validation loss decreased (0.261588 --> 0.261376).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.6931291
	speed: 0.1059s/iter; left time: 2367.0533s
	iters: 200, epoch: 14 | loss: 0.3756372
	speed: 0.0249s/iter; left time: 554.1581s
Epoch: 14 cost time: 6.983880281448364
Epoch: 14, Steps: 258 | Train Loss: 0.4961187 Vali Loss: 0.2618047 Test Loss: 0.3533706
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3448982
	speed: 0.1110s/iter; left time: 2451.3397s
	iters: 200, epoch: 15 | loss: 0.5076945
	speed: 0.0224s/iter; left time: 492.2066s
Epoch: 15 cost time: 7.706767320632935
Epoch: 15, Steps: 258 | Train Loss: 0.4954036 Vali Loss: 0.2612707 Test Loss: 0.3533026
Validation loss decreased (0.261376 --> 0.261271).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.5593000
	speed: 0.1034s/iter; left time: 2256.7954s
	iters: 200, epoch: 16 | loss: 0.4606126
	speed: 0.0217s/iter; left time: 471.5966s
Epoch: 16 cost time: 6.953020811080933
Epoch: 16, Steps: 258 | Train Loss: 0.4952594 Vali Loss: 0.2615788 Test Loss: 0.3529984
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.6162699
	speed: 0.1077s/iter; left time: 2322.9725s
	iters: 200, epoch: 17 | loss: 0.6046748
	speed: 0.0292s/iter; left time: 627.8128s
Epoch: 17 cost time: 7.376601219177246
Epoch: 17, Steps: 258 | Train Loss: 0.4956662 Vali Loss: 0.2613642 Test Loss: 0.3532148
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4966239
	speed: 0.1016s/iter; left time: 2165.3267s
	iters: 200, epoch: 18 | loss: 0.5236257
	speed: 0.0287s/iter; left time: 608.1854s
Epoch: 18 cost time: 7.8011651039123535
Epoch: 18, Steps: 258 | Train Loss: 0.4953931 Vali Loss: 0.2614258 Test Loss: 0.3531328
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.5353417
	speed: 0.1140s/iter; left time: 2400.7796s
	iters: 200, epoch: 19 | loss: 0.4884450
	speed: 0.0213s/iter; left time: 446.3917s
Epoch: 19 cost time: 6.841520547866821
Epoch: 19, Steps: 258 | Train Loss: 0.4955480 Vali Loss: 0.2614273 Test Loss: 0.3529697
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.6719236
	speed: 0.1093s/iter; left time: 2273.9833s
	iters: 200, epoch: 20 | loss: 0.4634104
	speed: 0.0263s/iter; left time: 543.4001s
Epoch: 20 cost time: 7.451529264450073
Epoch: 20, Steps: 258 | Train Loss: 0.4951214 Vali Loss: 0.2613326 Test Loss: 0.3529643
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.6294397
	speed: 0.1104s/iter; left time: 2268.7106s
	iters: 200, epoch: 21 | loss: 0.4654400
	speed: 0.0247s/iter; left time: 504.8357s
Epoch: 21 cost time: 7.096877098083496
Epoch: 21, Steps: 258 | Train Loss: 0.4946028 Vali Loss: 0.2610733 Test Loss: 0.3528663
Validation loss decreased (0.261271 --> 0.261073).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2917246
	speed: 0.1137s/iter; left time: 2305.4217s
	iters: 200, epoch: 22 | loss: 0.4435153
	speed: 0.0217s/iter; left time: 437.4199s
Epoch: 22 cost time: 7.0023252964019775
Epoch: 22, Steps: 258 | Train Loss: 0.4953999 Vali Loss: 0.2612064 Test Loss: 0.3528541
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3304224
	speed: 0.1075s/iter; left time: 2153.3423s
	iters: 200, epoch: 23 | loss: 0.4407874
	speed: 0.0271s/iter; left time: 540.8973s
Epoch: 23 cost time: 7.681938648223877
Epoch: 23, Steps: 258 | Train Loss: 0.4951327 Vali Loss: 0.2608563 Test Loss: 0.3526737
Validation loss decreased (0.261073 --> 0.260856).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4657570
	speed: 0.1039s/iter; left time: 2054.1890s
	iters: 200, epoch: 24 | loss: 0.4219998
	speed: 0.0247s/iter; left time: 486.1034s
Epoch: 24 cost time: 7.266482353210449
Epoch: 24, Steps: 258 | Train Loss: 0.4945681 Vali Loss: 0.2611577 Test Loss: 0.3526130
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3906975
	speed: 0.1077s/iter; left time: 2100.4405s
	iters: 200, epoch: 25 | loss: 0.5076593
	speed: 0.0225s/iter; left time: 436.2503s
Epoch: 25 cost time: 6.9144463539123535
Epoch: 25, Steps: 258 | Train Loss: 0.4945605 Vali Loss: 0.2609328 Test Loss: 0.3527388
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.5006889
	speed: 0.1041s/iter; left time: 2004.2814s
	iters: 200, epoch: 26 | loss: 0.3901271
	speed: 0.0311s/iter; left time: 595.2143s
Epoch: 26 cost time: 7.880183935165405
Epoch: 26, Steps: 258 | Train Loss: 0.4945029 Vali Loss: 0.2608322 Test Loss: 0.3526277
Validation loss decreased (0.260856 --> 0.260832).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.5198498
	speed: 0.1005s/iter; left time: 1907.8783s
	iters: 200, epoch: 27 | loss: 0.4574671
	speed: 0.0253s/iter; left time: 477.4667s
Epoch: 27 cost time: 7.202239036560059
Epoch: 27, Steps: 258 | Train Loss: 0.4946698 Vali Loss: 0.2609021 Test Loss: 0.3526165
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4257675
	speed: 0.1094s/iter; left time: 2049.2620s
	iters: 200, epoch: 28 | loss: 0.4970519
	speed: 0.0260s/iter; left time: 484.5663s
Epoch: 28 cost time: 7.406898736953735
Epoch: 28, Steps: 258 | Train Loss: 0.4948515 Vali Loss: 0.2607768 Test Loss: 0.3526587
Validation loss decreased (0.260832 --> 0.260777).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4672236
	speed: 0.1161s/iter; left time: 2145.0559s
	iters: 200, epoch: 29 | loss: 0.4340764
	speed: 0.0253s/iter; left time: 464.0276s
Epoch: 29 cost time: 7.04388427734375
Epoch: 29, Steps: 258 | Train Loss: 0.4940316 Vali Loss: 0.2611422 Test Loss: 0.3526028
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3736784
	speed: 0.1037s/iter; left time: 1889.7741s
	iters: 200, epoch: 30 | loss: 0.4813470
	speed: 0.0217s/iter; left time: 392.5264s
Epoch: 30 cost time: 6.695538520812988
Epoch: 30, Steps: 258 | Train Loss: 0.4948766 Vali Loss: 0.2607896 Test Loss: 0.3525874
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.5000443
	speed: 0.1021s/iter; left time: 1833.1865s
	iters: 200, epoch: 31 | loss: 0.6082186
	speed: 0.0225s/iter; left time: 401.1700s
Epoch: 31 cost time: 7.483689308166504
Epoch: 31, Steps: 258 | Train Loss: 0.4944976 Vali Loss: 0.2607600 Test Loss: 0.3525739
Validation loss decreased (0.260777 --> 0.260760).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4388745
	speed: 0.1130s/iter; left time: 2001.0021s
	iters: 200, epoch: 32 | loss: 0.6727666
	speed: 0.0291s/iter; left time: 512.2777s
Epoch: 32 cost time: 7.135474443435669
Epoch: 32, Steps: 258 | Train Loss: 0.4947154 Vali Loss: 0.2608302 Test Loss: 0.3526471
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.5017901
	speed: 0.1099s/iter; left time: 1916.6356s
	iters: 200, epoch: 33 | loss: 0.6171860
	speed: 0.0225s/iter; left time: 389.7421s
Epoch: 33 cost time: 7.222244024276733
Epoch: 33, Steps: 258 | Train Loss: 0.4943013 Vali Loss: 0.2608228 Test Loss: 0.3525291
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4898135
	speed: 0.1082s/iter; left time: 1859.3653s
	iters: 200, epoch: 34 | loss: 0.4007560
	speed: 0.0309s/iter; left time: 527.5019s
Epoch: 34 cost time: 7.131036758422852
Epoch: 34, Steps: 258 | Train Loss: 0.4938347 Vali Loss: 0.2610138 Test Loss: 0.3525186
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.5300093
	speed: 0.1098s/iter; left time: 1858.3135s
	iters: 200, epoch: 35 | loss: 0.3992911
	speed: 0.0212s/iter; left time: 356.8296s
Epoch: 35 cost time: 6.92002010345459
Epoch: 35, Steps: 258 | Train Loss: 0.4947540 Vali Loss: 0.2611250 Test Loss: 0.3524792
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4279588
	speed: 0.1060s/iter; left time: 1767.1175s
	iters: 200, epoch: 36 | loss: 0.6425181
	speed: 0.0277s/iter; left time: 458.8577s
Epoch: 36 cost time: 6.69997763633728
Epoch: 36, Steps: 258 | Train Loss: 0.4940196 Vali Loss: 0.2608097 Test Loss: 0.3525257
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4977253
	speed: 0.1040s/iter; left time: 1707.4753s
	iters: 200, epoch: 37 | loss: 0.4424168
	speed: 0.0259s/iter; left time: 422.7325s
Epoch: 37 cost time: 7.205413341522217
Epoch: 37, Steps: 258 | Train Loss: 0.4944452 Vali Loss: 0.2608617 Test Loss: 0.3525433
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4766418
	speed: 0.1126s/iter; left time: 1819.4511s
	iters: 200, epoch: 38 | loss: 0.5340002
	speed: 0.0215s/iter; left time: 344.7396s
Epoch: 38 cost time: 7.5105743408203125
Epoch: 38, Steps: 258 | Train Loss: 0.4945207 Vali Loss: 0.2610123 Test Loss: 0.3525211
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4207759
	speed: 0.1113s/iter; left time: 1768.7834s
	iters: 200, epoch: 39 | loss: 0.5095543
	speed: 0.0253s/iter; left time: 398.8809s
Epoch: 39 cost time: 7.012484073638916
Epoch: 39, Steps: 258 | Train Loss: 0.4942714 Vali Loss: 0.2608930 Test Loss: 0.3524966
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.5777391
	speed: 0.1055s/iter; left time: 1650.5790s
	iters: 200, epoch: 40 | loss: 0.4260519
	speed: 0.0261s/iter; left time: 406.0995s
Epoch: 40 cost time: 6.8519885540008545
Epoch: 40, Steps: 258 | Train Loss: 0.4940048 Vali Loss: 0.2608003 Test Loss: 0.3524613
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.4627765
	speed: 0.1059s/iter; left time: 1629.2974s
	iters: 200, epoch: 41 | loss: 0.4122078
	speed: 0.0311s/iter; left time: 475.6566s
Epoch: 41 cost time: 7.463960409164429
Epoch: 41, Steps: 258 | Train Loss: 0.4939365 Vali Loss: 0.2610166 Test Loss: 0.3524290
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3822668
	speed: 0.1022s/iter; left time: 1545.8487s
	iters: 200, epoch: 42 | loss: 0.4155933
	speed: 0.0282s/iter; left time: 423.4136s
Epoch: 42 cost time: 6.831255674362183
Epoch: 42, Steps: 258 | Train Loss: 0.4945234 Vali Loss: 0.2609213 Test Loss: 0.3524321
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3333025
	speed: 0.1005s/iter; left time: 1493.7781s
	iters: 200, epoch: 43 | loss: 0.3555346
	speed: 0.0313s/iter; left time: 462.2176s
Epoch: 43 cost time: 7.082425832748413
Epoch: 43, Steps: 258 | Train Loss: 0.4942829 Vali Loss: 0.2608982 Test Loss: 0.3524400
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.4144351
	speed: 0.1004s/iter; left time: 1466.7552s
	iters: 200, epoch: 44 | loss: 0.5050436
	speed: 0.0249s/iter; left time: 361.1426s
Epoch: 44 cost time: 6.852019309997559
Epoch: 44, Steps: 258 | Train Loss: 0.4942499 Vali Loss: 0.2609456 Test Loss: 0.3524545
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.5750870
	speed: 0.1086s/iter; left time: 1558.4705s
	iters: 200, epoch: 45 | loss: 0.4094426
	speed: 0.0217s/iter; left time: 308.7010s
Epoch: 45 cost time: 6.901543855667114
Epoch: 45, Steps: 258 | Train Loss: 0.4941426 Vali Loss: 0.2607747 Test Loss: 0.3524718
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.4941520
	speed: 0.1063s/iter; left time: 1497.5755s
	iters: 200, epoch: 46 | loss: 0.4003370
	speed: 0.0226s/iter; left time: 315.7019s
Epoch: 46 cost time: 7.785332918167114
Epoch: 46, Steps: 258 | Train Loss: 0.4942415 Vali Loss: 0.2606620 Test Loss: 0.3524486
Validation loss decreased (0.260760 --> 0.260662).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.5411026
	speed: 0.1077s/iter; left time: 1489.3270s
	iters: 200, epoch: 47 | loss: 0.6682222
	speed: 0.0288s/iter; left time: 395.8253s
Epoch: 47 cost time: 7.139468431472778
Epoch: 47, Steps: 258 | Train Loss: 0.4940967 Vali Loss: 0.2608035 Test Loss: 0.3524238
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.4753652
	speed: 0.1096s/iter; left time: 1487.4898s
	iters: 200, epoch: 48 | loss: 0.5599388
	speed: 0.0229s/iter; left time: 308.3505s
Epoch: 48 cost time: 7.520129680633545
Epoch: 48, Steps: 258 | Train Loss: 0.4937708 Vali Loss: 0.2607788 Test Loss: 0.3524194
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.4964946
	speed: 0.1087s/iter; left time: 1447.5307s
	iters: 200, epoch: 49 | loss: 0.3913329
	speed: 0.0345s/iter; left time: 455.6254s
Epoch: 49 cost time: 8.368969440460205
Epoch: 49, Steps: 258 | Train Loss: 0.4944388 Vali Loss: 0.2608550 Test Loss: 0.3523943
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.5368127
	speed: 0.1032s/iter; left time: 1347.9742s
	iters: 200, epoch: 50 | loss: 0.5688229
	speed: 0.0243s/iter; left time: 314.9738s
Epoch: 50 cost time: 6.8087568283081055
Epoch: 50, Steps: 258 | Train Loss: 0.4932061 Vali Loss: 0.2610856 Test Loss: 0.3524086
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.4960665
	speed: 0.1044s/iter; left time: 1335.9265s
	iters: 200, epoch: 51 | loss: 0.6468470
	speed: 0.0221s/iter; left time: 280.4010s
Epoch: 51 cost time: 7.280598878860474
Epoch: 51, Steps: 258 | Train Loss: 0.4935832 Vali Loss: 0.2605597 Test Loss: 0.3524141
Validation loss decreased (0.260662 --> 0.260560).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.4526975
	speed: 0.1009s/iter; left time: 1265.0564s
	iters: 200, epoch: 52 | loss: 0.5536595
	speed: 0.0250s/iter; left time: 311.1714s
Epoch: 52 cost time: 6.712291479110718
Epoch: 52, Steps: 258 | Train Loss: 0.4943112 Vali Loss: 0.2606657 Test Loss: 0.3524163
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.3649133
	speed: 0.1035s/iter; left time: 1271.6987s
	iters: 200, epoch: 53 | loss: 0.4899097
	speed: 0.0318s/iter; left time: 388.0546s
Epoch: 53 cost time: 7.27114200592041
Epoch: 53, Steps: 258 | Train Loss: 0.4935250 Vali Loss: 0.2607276 Test Loss: 0.3524016
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.3492402
	speed: 0.1100s/iter; left time: 1322.6901s
	iters: 200, epoch: 54 | loss: 0.5466735
	speed: 0.0310s/iter; left time: 369.8212s
Epoch: 54 cost time: 7.99333381652832
Epoch: 54, Steps: 258 | Train Loss: 0.4940540 Vali Loss: 0.2604748 Test Loss: 0.3524033
Validation loss decreased (0.260560 --> 0.260475).  Saving model ...
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.4745468
	speed: 0.1084s/iter; left time: 1276.0677s
	iters: 200, epoch: 55 | loss: 0.4147445
	speed: 0.0218s/iter; left time: 254.0956s
Epoch: 55 cost time: 7.527933359146118
Epoch: 55, Steps: 258 | Train Loss: 0.4942939 Vali Loss: 0.2604349 Test Loss: 0.3524133
Validation loss decreased (0.260475 --> 0.260435).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.5458192
	speed: 0.1092s/iter; left time: 1256.4611s
	iters: 200, epoch: 56 | loss: 0.4175955
	speed: 0.0265s/iter; left time: 301.8870s
Epoch: 56 cost time: 6.773423194885254
Epoch: 56, Steps: 258 | Train Loss: 0.4941025 Vali Loss: 0.2605469 Test Loss: 0.3524072
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.3407418
	speed: 0.1056s/iter; left time: 1188.5026s
	iters: 200, epoch: 57 | loss: 0.3843200
	speed: 0.0245s/iter; left time: 273.3039s
Epoch: 57 cost time: 6.715738773345947
Epoch: 57, Steps: 258 | Train Loss: 0.4939647 Vali Loss: 0.2607266 Test Loss: 0.3523975
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.6698850
	speed: 0.1021s/iter; left time: 1122.4937s
	iters: 200, epoch: 58 | loss: 0.4403253
	speed: 0.0215s/iter; left time: 234.5401s
Epoch: 58 cost time: 7.008744478225708
Epoch: 58, Steps: 258 | Train Loss: 0.4943003 Vali Loss: 0.2606495 Test Loss: 0.3524044
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.4514301
	speed: 0.1006s/iter; left time: 1080.1445s
	iters: 200, epoch: 59 | loss: 0.4324146
	speed: 0.0239s/iter; left time: 254.4667s
Epoch: 59 cost time: 6.821316480636597
Epoch: 59, Steps: 258 | Train Loss: 0.4935066 Vali Loss: 0.2604037 Test Loss: 0.3524013
Validation loss decreased (0.260435 --> 0.260404).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.5350421
	speed: 0.1178s/iter; left time: 1234.5004s
	iters: 200, epoch: 60 | loss: 0.4925521
	speed: 0.0252s/iter; left time: 262.0182s
Epoch: 60 cost time: 7.776429176330566
Epoch: 60, Steps: 258 | Train Loss: 0.4945256 Vali Loss: 0.2606010 Test Loss: 0.3523969
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.5073828
	speed: 0.1066s/iter; left time: 1089.7105s
	iters: 200, epoch: 61 | loss: 0.5177951
	speed: 0.0249s/iter; left time: 252.2840s
Epoch: 61 cost time: 6.823474168777466
Epoch: 61, Steps: 258 | Train Loss: 0.4938811 Vali Loss: 0.2607314 Test Loss: 0.3524014
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.5146739
	speed: 0.1093s/iter; left time: 1089.0666s
	iters: 200, epoch: 62 | loss: 0.5692071
	speed: 0.0273s/iter; left time: 269.1821s
Epoch: 62 cost time: 6.985076904296875
Epoch: 62, Steps: 258 | Train Loss: 0.4942127 Vali Loss: 0.2608133 Test Loss: 0.3523907
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.4906591
	speed: 0.1063s/iter; left time: 1031.6070s
	iters: 200, epoch: 63 | loss: 0.4143656
	speed: 0.0292s/iter; left time: 280.2327s
Epoch: 63 cost time: 7.6569085121154785
Epoch: 63, Steps: 258 | Train Loss: 0.4944212 Vali Loss: 0.2608081 Test Loss: 0.3523987
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.4663658
	speed: 0.1136s/iter; left time: 1073.1635s
	iters: 200, epoch: 64 | loss: 0.5034159
	speed: 0.0226s/iter; left time: 210.8537s
Epoch: 64 cost time: 7.2088775634765625
Epoch: 64, Steps: 258 | Train Loss: 0.4935466 Vali Loss: 0.2604516 Test Loss: 0.3523906
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.5843913
	speed: 0.1041s/iter; left time: 956.8262s
	iters: 200, epoch: 65 | loss: 0.5005217
	speed: 0.0249s/iter; left time: 226.2862s
Epoch: 65 cost time: 7.072706699371338
Epoch: 65, Steps: 258 | Train Loss: 0.4938692 Vali Loss: 0.2607629 Test Loss: 0.3523913
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.3798573
	speed: 0.1090s/iter; left time: 973.1196s
	iters: 200, epoch: 66 | loss: 0.4366406
	speed: 0.0244s/iter; left time: 215.4711s
Epoch: 66 cost time: 7.128385305404663
Epoch: 66, Steps: 258 | Train Loss: 0.4937280 Vali Loss: 0.2605236 Test Loss: 0.3523830
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.4260380
	speed: 0.0998s/iter; left time: 865.8016s
	iters: 200, epoch: 67 | loss: 0.5836101
	speed: 0.0286s/iter; left time: 245.4803s
Epoch: 67 cost time: 7.8346381187438965
Epoch: 67, Steps: 258 | Train Loss: 0.4939841 Vali Loss: 0.2609228 Test Loss: 0.3523912
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.4029827
	speed: 0.1134s/iter; left time: 954.4732s
	iters: 200, epoch: 68 | loss: 0.3640021
	speed: 0.0216s/iter; left time: 179.5469s
Epoch: 68 cost time: 6.976070165634155
Epoch: 68, Steps: 258 | Train Loss: 0.4939477 Vali Loss: 0.2608096 Test Loss: 0.3523921
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.4964985
	speed: 0.1180s/iter; left time: 962.5901s
	iters: 200, epoch: 69 | loss: 0.5545350
	speed: 0.0221s/iter; left time: 178.3753s
Epoch: 69 cost time: 8.084195375442505
Epoch: 69, Steps: 258 | Train Loss: 0.4942733 Vali Loss: 0.2606638 Test Loss: 0.3523875
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.5136408
	speed: 0.1067s/iter; left time: 843.0191s
	iters: 200, epoch: 70 | loss: 0.5381065
	speed: 0.0244s/iter; left time: 190.5815s
Epoch: 70 cost time: 6.99010157585144
Epoch: 70, Steps: 258 | Train Loss: 0.4939077 Vali Loss: 0.2607051 Test Loss: 0.3523825
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.5005596
	speed: 0.0999s/iter; left time: 763.0744s
	iters: 200, epoch: 71 | loss: 0.4666075
	speed: 0.0238s/iter; left time: 179.2651s
Epoch: 71 cost time: 7.1230127811431885
Epoch: 71, Steps: 258 | Train Loss: 0.4936314 Vali Loss: 0.2607026 Test Loss: 0.3523863
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.4258095
	speed: 0.1081s/iter; left time: 798.3729s
	iters: 200, epoch: 72 | loss: 0.4208250
	speed: 0.0284s/iter; left time: 206.8591s
Epoch: 72 cost time: 6.949933290481567
Epoch: 72, Steps: 258 | Train Loss: 0.4943688 Vali Loss: 0.2609010 Test Loss: 0.3523906
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.7313240
	speed: 0.1014s/iter; left time: 722.2497s
	iters: 200, epoch: 73 | loss: 0.4166629
	speed: 0.0277s/iter; left time: 194.7742s
Epoch: 73 cost time: 6.864290475845337
Epoch: 73, Steps: 258 | Train Loss: 0.4938160 Vali Loss: 0.2603377 Test Loss: 0.3523851
Validation loss decreased (0.260404 --> 0.260338).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.3665015
	speed: 0.1030s/iter; left time: 707.3320s
	iters: 200, epoch: 74 | loss: 0.3851506
	speed: 0.0244s/iter; left time: 165.2770s
Epoch: 74 cost time: 6.791340112686157
Epoch: 74, Steps: 258 | Train Loss: 0.4931047 Vali Loss: 0.2607328 Test Loss: 0.3523842
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.3876884
	speed: 0.0972s/iter; left time: 642.3581s
	iters: 200, epoch: 75 | loss: 0.5470589
	speed: 0.0240s/iter; left time: 156.3012s
Epoch: 75 cost time: 6.953952312469482
Epoch: 75, Steps: 258 | Train Loss: 0.4938233 Vali Loss: 0.2606853 Test Loss: 0.3523805
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.4005060
	speed: 0.0983s/iter; left time: 624.5509s
	iters: 200, epoch: 76 | loss: 0.4373214
	speed: 0.0287s/iter; left time: 179.1925s
Epoch: 76 cost time: 6.764966249465942
Epoch: 76, Steps: 258 | Train Loss: 0.4939250 Vali Loss: 0.2607816 Test Loss: 0.3523817
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.6101544
	speed: 0.0933s/iter; left time: 568.3398s
	iters: 200, epoch: 77 | loss: 0.3850803
	speed: 0.0260s/iter; left time: 155.8722s
Epoch: 77 cost time: 6.5034339427948
Epoch: 77, Steps: 258 | Train Loss: 0.4941227 Vali Loss: 0.2605999 Test Loss: 0.3523823
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.4093643
	speed: 0.1014s/iter; left time: 591.6577s
	iters: 200, epoch: 78 | loss: 0.6110837
	speed: 0.0247s/iter; left time: 141.8517s
Epoch: 78 cost time: 7.186096906661987
Epoch: 78, Steps: 258 | Train Loss: 0.4935768 Vali Loss: 0.2608255 Test Loss: 0.3523807
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.4789424
	speed: 0.1015s/iter; left time: 565.8949s
	iters: 200, epoch: 79 | loss: 0.5215421
	speed: 0.0284s/iter; left time: 155.4666s
Epoch: 79 cost time: 6.872651100158691
Epoch: 79, Steps: 258 | Train Loss: 0.4937646 Vali Loss: 0.2606746 Test Loss: 0.3523800
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.5188420
	speed: 0.1085s/iter; left time: 576.9609s
	iters: 200, epoch: 80 | loss: 0.4617039
	speed: 0.0218s/iter; left time: 113.5159s
Epoch: 80 cost time: 6.927488565444946
Epoch: 80, Steps: 258 | Train Loss: 0.4938029 Vali Loss: 0.2607259 Test Loss: 0.3523831
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.4240589
	speed: 0.1052s/iter; left time: 532.1978s
	iters: 200, epoch: 81 | loss: 0.5184023
	speed: 0.0245s/iter; left time: 121.3424s
Epoch: 81 cost time: 7.122778654098511
Epoch: 81, Steps: 258 | Train Loss: 0.4936604 Vali Loss: 0.2607965 Test Loss: 0.3523859
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.5371455
	speed: 0.1138s/iter; left time: 546.7440s
	iters: 200, epoch: 82 | loss: 0.3940372
	speed: 0.0242s/iter; left time: 113.7353s
Epoch: 82 cost time: 7.140474557876587
Epoch: 82, Steps: 258 | Train Loss: 0.4939816 Vali Loss: 0.2608379 Test Loss: 0.3523798
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.5261488
	speed: 0.0973s/iter; left time: 442.2271s
	iters: 200, epoch: 83 | loss: 0.3337230
	speed: 0.0242s/iter; left time: 107.6565s
Epoch: 83 cost time: 6.9501261711120605
Epoch: 83, Steps: 258 | Train Loss: 0.4937978 Vali Loss: 0.2607946 Test Loss: 0.3523821
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.6656204
	speed: 0.1021s/iter; left time: 437.5357s
	iters: 200, epoch: 84 | loss: 0.5363353
	speed: 0.0210s/iter; left time: 87.8930s
Epoch: 84 cost time: 7.343387126922607
Epoch: 84, Steps: 258 | Train Loss: 0.4941830 Vali Loss: 0.2608306 Test Loss: 0.3523803
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.5746036
	speed: 0.1087s/iter; left time: 437.8079s
	iters: 200, epoch: 85 | loss: 0.6900634
	speed: 0.0285s/iter; left time: 112.1465s
Epoch: 85 cost time: 6.990055799484253
Epoch: 85, Steps: 258 | Train Loss: 0.4939311 Vali Loss: 0.2606386 Test Loss: 0.3523822
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.5098359
	speed: 0.1133s/iter; left time: 427.3768s
	iters: 200, epoch: 86 | loss: 0.4714145
	speed: 0.0327s/iter; left time: 120.2000s
Epoch: 86 cost time: 8.475100994110107
Epoch: 86, Steps: 258 | Train Loss: 0.4935931 Vali Loss: 0.2606879 Test Loss: 0.3523794
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.5600575
	speed: 0.1032s/iter; left time: 362.4990s
	iters: 200, epoch: 87 | loss: 0.4172423
	speed: 0.0221s/iter; left time: 75.2600s
Epoch: 87 cost time: 7.14112114906311
Epoch: 87, Steps: 258 | Train Loss: 0.4939945 Vali Loss: 0.2608491 Test Loss: 0.3523811
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.5591356
	speed: 0.0976s/iter; left time: 317.6881s
	iters: 200, epoch: 88 | loss: 0.5233735
	speed: 0.0218s/iter; left time: 68.6645s
Epoch: 88 cost time: 6.677228689193726
Epoch: 88, Steps: 258 | Train Loss: 0.4941852 Vali Loss: 0.2606072 Test Loss: 0.3523793
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.6377169
	speed: 0.0963s/iter; left time: 288.5835s
	iters: 200, epoch: 89 | loss: 0.7073679
	speed: 0.0215s/iter; left time: 62.1494s
Epoch: 89 cost time: 6.331527471542358
Epoch: 89, Steps: 258 | Train Loss: 0.4935770 Vali Loss: 0.2608768 Test Loss: 0.3523777
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.5617525
	speed: 0.0923s/iter; left time: 252.7965s
	iters: 200, epoch: 90 | loss: 0.5269639
	speed: 0.0211s/iter; left time: 55.6989s
Epoch: 90 cost time: 6.326570987701416
Epoch: 90, Steps: 258 | Train Loss: 0.4934906 Vali Loss: 0.2605487 Test Loss: 0.3523766
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.204402478767869e-06
	iters: 100, epoch: 91 | loss: 0.4030805
	speed: 0.0965s/iter; left time: 239.4145s
	iters: 200, epoch: 91 | loss: 0.6108324
	speed: 0.0214s/iter; left time: 51.0541s
Epoch: 91 cost time: 6.516912937164307
Epoch: 91, Steps: 258 | Train Loss: 0.4935387 Vali Loss: 0.2606214 Test Loss: 0.3523771
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.944182354829475e-06
	iters: 100, epoch: 92 | loss: 0.3690249
	speed: 0.0981s/iter; left time: 218.1479s
	iters: 200, epoch: 92 | loss: 0.5000734
	speed: 0.0231s/iter; left time: 48.9382s
Epoch: 92 cost time: 6.466240644454956
Epoch: 92, Steps: 258 | Train Loss: 0.4940457 Vali Loss: 0.2607401 Test Loss: 0.3523783
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.696973237088e-06
	iters: 100, epoch: 93 | loss: 0.4303664
	speed: 0.1018s/iter; left time: 200.0629s
	iters: 200, epoch: 93 | loss: 0.4495652
	speed: 0.0210s/iter; left time: 39.1452s
Epoch: 93 cost time: 6.586500406265259
Epoch: 93, Steps: 258 | Train Loss: 0.4941130 Vali Loss: 0.2608419 Test Loss: 0.3523772
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_720_720_FITS_ETTm2_ftM_sl720_ll48_pl720_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.34901854395866394, mae:0.3779962360858917, rse:0.47486335039138794, corr:[0.54075086 0.5434673  0.5399359  0.5367768  0.53576756 0.5364884
 0.5374975  0.5376106  0.5368141  0.53582615 0.5352719  0.53534126
 0.53584534 0.53626996 0.53624874 0.5356403  0.53475136 0.5339416
 0.5333776  0.53304225 0.53280544 0.5324276  0.5318564  0.531216
 0.530622   0.53019536 0.5299396  0.5297622  0.52948934 0.5290324
 0.52840286 0.5278001  0.52730805 0.52687806 0.52649224 0.52611226
 0.525621   0.52500206 0.52426976 0.5235338  0.52289397 0.5223698
 0.52197784 0.52163416 0.5212371  0.5206675  0.5199332  0.51911974
 0.5182566  0.51738065 0.51658    0.51592445 0.5153445  0.51476264
 0.5141449  0.5135178  0.51292145 0.51241624 0.51206875 0.511849
 0.51171184 0.511599   0.5114513  0.5112134  0.5108976  0.5106116
 0.5103226  0.51009524 0.509896   0.50966287 0.50934535 0.5089501
 0.50853354 0.50814676 0.5077681  0.50736696 0.50689816 0.50632334
 0.50568527 0.5050253  0.50433964 0.5037046  0.50315034 0.50263846
 0.50212526 0.5015854  0.50097257 0.50038296 0.49985698 0.4994424
 0.49913645 0.4988195  0.49831036 0.4974951  0.49632585 0.49485987
 0.4932724  0.49180612 0.49051073 0.48935363 0.48826724 0.48717377
 0.486039   0.48487133 0.4837077  0.48261166 0.48163033 0.48077068
 0.47992218 0.47901857 0.47805044 0.47704673 0.476135   0.47531927
 0.47454485 0.47377142 0.47296724 0.4720767  0.4711523  0.4702122
 0.46938902 0.4686953  0.4681321  0.4675728  0.46688923 0.46600056
 0.46496928 0.46388522 0.4628577  0.46195146 0.46118218 0.46046638
 0.45975092 0.4589817  0.45818573 0.4574058  0.45668742 0.45610145
 0.4556261  0.45518366 0.45465904 0.45399585 0.45322022 0.4523389
 0.45144916 0.45059198 0.4499029  0.44932732 0.4487891  0.44816732
 0.4474644  0.44674036 0.44599983 0.44529125 0.4446598  0.44411555
 0.44361177 0.44309118 0.44250205 0.44193938 0.44141716 0.44098872
 0.4406277  0.44032195 0.44001612 0.43967274 0.43924746 0.43878138
 0.43835422 0.43802696 0.43771172 0.43736473 0.4368975  0.43630803
 0.4356329  0.4349662  0.43437782 0.43388262 0.43340963 0.43292797
 0.43234625 0.43165705 0.43096527 0.43035376 0.42986763 0.42948797
 0.42916736 0.4287438  0.42809325 0.4271146  0.42583635 0.4243506
 0.42283934 0.4215618  0.42040926 0.41925472 0.41805887 0.416774
 0.4154629  0.4141834  0.41298464 0.4118664  0.41077507 0.40965366
 0.40846974 0.40722904 0.4059769  0.40478998 0.40381232 0.40310916
 0.40247405 0.40172    0.40076268 0.39963558 0.3984961  0.3974108
 0.39641714 0.3954419  0.39447355 0.39341974 0.3922227  0.39093375
 0.38967302 0.38858745 0.38778704 0.38710502 0.3863811  0.38553777
 0.38448265 0.3833237  0.38220862 0.3813012  0.38065714 0.38025585
 0.37993252 0.37957552 0.3790869  0.37846076 0.37781554 0.37724522
 0.37683123 0.3765136  0.376216   0.37597194 0.37564245 0.3752646
 0.37490112 0.37464347 0.37450594 0.3744404  0.3744425  0.37440407
 0.37424654 0.3740143  0.373702   0.37340552 0.37316    0.3730063
 0.3728664  0.3726402  0.3722391  0.37170523 0.37111935 0.37067538
 0.37045035 0.3703679  0.37033233 0.370198   0.36983362 0.36921576
 0.3685404  0.36798948 0.367634   0.36749804 0.36744627 0.3673017
 0.36701816 0.36651462 0.365861   0.3653068  0.3649479  0.36484584
 0.3648672  0.36483935 0.3645926  0.36401293 0.36313006 0.36199054
 0.36081976 0.35986874 0.35912108 0.35844883 0.35775733 0.3569628
 0.3561899  0.35549548 0.35489616 0.35437685 0.3539187  0.35339102
 0.35280576 0.3520974  0.35140267 0.35072    0.35016882 0.34975263
 0.34947476 0.34917757 0.3487952  0.34833962 0.34787506 0.34758696
 0.34742236 0.34738505 0.3473204  0.34708816 0.3466805  0.3461883
 0.3456818  0.34530917 0.3451571  0.34517097 0.3452181  0.3452081
 0.34507853 0.34490246 0.34476832 0.34466976 0.3446894  0.34476528
 0.3448925  0.34494135 0.34486607 0.34471914 0.3445033  0.344365
 0.344318   0.34425852 0.34417915 0.344088   0.3439387  0.34368625
 0.34340605 0.34318885 0.34308586 0.34307057 0.34308308 0.34308454
 0.34300625 0.34286553 0.3426849  0.34250462 0.34237757 0.34228492
 0.34217548 0.3420148  0.3417094  0.34136173 0.3409421  0.34058958
 0.34037605 0.34031084 0.34032044 0.3402986  0.34013057 0.3398598
 0.33949047 0.33918223 0.33900076 0.33898684 0.3391152  0.33924258
 0.33928272 0.3392408  0.33914948 0.33906734 0.33904225 0.33914053
 0.33935064 0.3395541  0.33958304 0.3392797  0.33873668 0.3379808
 0.3372127  0.33653834 0.3359773  0.33542377 0.33475238 0.33401987
 0.33323574 0.33248723 0.33183888 0.33131236 0.33087415 0.33042258
 0.32990474 0.32935518 0.3287317  0.32809195 0.3275666  0.32709357
 0.32662195 0.32607937 0.32548907 0.3249419  0.32443237 0.3240564
 0.3238036  0.32369563 0.32364768 0.3235327  0.32333457 0.32302704
 0.3227308  0.32254708 0.3224595  0.32244015 0.32239345 0.32229114
 0.32217276 0.3220797  0.32202604 0.32206425 0.32221597 0.32244942
 0.32271567 0.32290286 0.3229922  0.32297787 0.3229252  0.32290187
 0.3229302  0.32292002 0.32284915 0.32270634 0.32251397 0.32225558
 0.3218898  0.32156253 0.3212644  0.3209396  0.32058322 0.32024482
 0.31984988 0.31947184 0.3191344  0.3188339  0.3186093  0.31840447
 0.31819868 0.31793687 0.3176225  0.31721517 0.31679773 0.31648964
 0.31631792 0.31624985 0.31617388 0.31598586 0.3157082  0.31528208
 0.3148144  0.31441122 0.31414127 0.31399423 0.31387275 0.31367618
 0.3133572  0.312912   0.31238115 0.31184047 0.31142062 0.31109497
 0.31080857 0.31039593 0.30981374 0.30898857 0.30799007 0.3068938
 0.30577257 0.30475375 0.30377585 0.30279446 0.30179656 0.30078357
 0.29976505 0.29885203 0.29806975 0.2974872  0.2969992  0.29646677
 0.2957993  0.29505715 0.29429138 0.2934989  0.29274723 0.29205206
 0.29141343 0.29071513 0.28991574 0.28911898 0.28835985 0.28778172
 0.28731918 0.2869108  0.2865242  0.2860937  0.28565973 0.2852007
 0.2847493  0.28433254 0.2839401  0.28356707 0.28321987 0.28287628
 0.28249654 0.2820451  0.28169963 0.28145134 0.2812686  0.2811247
 0.28095865 0.28075695 0.28048083 0.28016904 0.27991575 0.2797442
 0.27961364 0.27951035 0.27936757 0.27915928 0.27891538 0.27864566
 0.27835074 0.2780791  0.27795032 0.27791995 0.2779219  0.27788162
 0.27774498 0.27753413 0.27726057 0.27702183 0.27682498 0.27662632
 0.27638713 0.27612382 0.2758327  0.2755374  0.27523115 0.27500594
 0.27485096 0.27477768 0.27473047 0.27465838 0.27438694 0.27400798
 0.2736104  0.27337033 0.27329037 0.27330562 0.2733328  0.2732793
 0.27309716 0.27278265 0.27243313 0.27213347 0.27195072 0.27189207
 0.27187055 0.2717435  0.2713252  0.27056417 0.26950526 0.26817086
 0.26669222 0.26538715 0.2643481  0.2635495  0.26283842 0.26211405
 0.26133513 0.26050374 0.25965512 0.258802   0.25793853 0.25711536
 0.2563283  0.25555754 0.25489658 0.25432956 0.25382233 0.25336647
 0.2529048  0.25236797 0.25184438 0.251334   0.25096196 0.2507756
 0.25071168 0.25071886 0.2506192  0.25030264 0.2498633  0.24941878
 0.24900725 0.24872127 0.2486391  0.24861948 0.24860957 0.24853894
 0.24846318 0.24827087 0.2480794  0.248045   0.24816915 0.24835934
 0.24852462 0.24866855 0.24876052 0.24888335 0.24914183 0.2495979
 0.2501474  0.25059932 0.2507969  0.2507655  0.25056362 0.25030717
 0.2500816  0.25001118 0.2501602  0.25026873 0.250381   0.25035626
 0.25018078 0.24994932 0.24969922 0.24964468 0.2496503  0.2496699
 0.24954717 0.24933359 0.24896826 0.24843863 0.24805525 0.24777538
 0.24770914 0.24774855 0.24777578 0.24766286 0.24746418 0.24709241
 0.2468138  0.24668796 0.24667631 0.24684177 0.24707606 0.24718143
 0.24705364 0.24691314 0.2468078  0.24687454 0.24724512 0.24778488
 0.24824408 0.2484793  0.24835221 0.24774773 0.24675274 0.24561782
 0.24453847 0.24360456 0.24276552 0.24189344 0.24101062 0.24010251
 0.23922448 0.23844913 0.238048   0.23784092 0.23769292 0.23737435
 0.23680995 0.23608203 0.23535351 0.23475267 0.234435   0.2341982
 0.23388742 0.23333266 0.23245297 0.23159634 0.2309029  0.23046605
 0.23028049 0.23011883 0.22984287 0.22921108 0.22831644 0.2273706
 0.2267656  0.22640194 0.22620456 0.22597872 0.22551788 0.22482164
 0.22400345 0.2234306  0.22321942 0.22332546 0.22311601 0.2223241
 0.22102481 0.21993257 0.21995698 0.22114618 0.2217412  0.21811731]
