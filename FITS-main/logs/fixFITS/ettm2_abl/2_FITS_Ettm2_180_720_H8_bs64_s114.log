Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_180_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_180_720_FITS_ETTm2_ftM_sl180_ll48_pl720_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33661
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=26, out_features=130, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3028480.0
params:  3510.0
Trainable parameters:  3510
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5621834
	speed: 0.0247s/iter; left time: 643.9044s
	iters: 200, epoch: 1 | loss: 0.4370217
	speed: 0.0166s/iter; left time: 432.5612s
Epoch: 1 cost time: 5.199344158172607
Epoch: 1, Steps: 262 | Train Loss: 0.5951152 Vali Loss: 0.3174344 Test Loss: 0.4380159
Validation loss decreased (inf --> 0.317434).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5580322
	speed: 0.0917s/iter; left time: 2369.6471s
	iters: 200, epoch: 2 | loss: 0.4335985
	speed: 0.0232s/iter; left time: 596.1784s
Epoch: 2 cost time: 6.553562641143799
Epoch: 2, Steps: 262 | Train Loss: 0.4835236 Vali Loss: 0.2911687 Test Loss: 0.4052185
Validation loss decreased (0.317434 --> 0.291169).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5173635
	speed: 0.0872s/iter; left time: 2230.2360s
	iters: 200, epoch: 3 | loss: 0.3295763
	speed: 0.0174s/iter; left time: 444.3042s
Epoch: 3 cost time: 5.251941442489624
Epoch: 3, Steps: 262 | Train Loss: 0.4627196 Vali Loss: 0.2844313 Test Loss: 0.3971836
Validation loss decreased (0.291169 --> 0.284431).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4443738
	speed: 0.0824s/iter; left time: 2086.6221s
	iters: 200, epoch: 4 | loss: 0.4557311
	speed: 0.0200s/iter; left time: 505.0611s
Epoch: 4 cost time: 5.523715972900391
Epoch: 4, Steps: 262 | Train Loss: 0.4571712 Vali Loss: 0.2817075 Test Loss: 0.3939762
Validation loss decreased (0.284431 --> 0.281708).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.5985874
	speed: 0.0876s/iter; left time: 2194.4056s
	iters: 200, epoch: 5 | loss: 0.5686234
	speed: 0.0179s/iter; left time: 446.9661s
Epoch: 5 cost time: 5.373588562011719
Epoch: 5, Steps: 262 | Train Loss: 0.4545893 Vali Loss: 0.2800341 Test Loss: 0.3921950
Validation loss decreased (0.281708 --> 0.280034).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3760409
	speed: 0.0806s/iter; left time: 1998.7777s
	iters: 200, epoch: 6 | loss: 0.3937152
	speed: 0.0170s/iter; left time: 420.4115s
Epoch: 6 cost time: 5.209927558898926
Epoch: 6, Steps: 262 | Train Loss: 0.4519586 Vali Loss: 0.2793859 Test Loss: 0.3910397
Validation loss decreased (0.280034 --> 0.279386).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4106145
	speed: 0.0839s/iter; left time: 2056.8101s
	iters: 200, epoch: 7 | loss: 0.4554726
	speed: 0.0188s/iter; left time: 460.4016s
Epoch: 7 cost time: 5.351887464523315
Epoch: 7, Steps: 262 | Train Loss: 0.4513046 Vali Loss: 0.2786948 Test Loss: 0.3901854
Validation loss decreased (0.279386 --> 0.278695).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.5246244
	speed: 0.0846s/iter; left time: 2053.7376s
	iters: 200, epoch: 8 | loss: 0.4641181
	speed: 0.0206s/iter; left time: 497.7053s
Epoch: 8 cost time: 6.130095720291138
Epoch: 8, Steps: 262 | Train Loss: 0.4498281 Vali Loss: 0.2783802 Test Loss: 0.3896466
Validation loss decreased (0.278695 --> 0.278380).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4167036
	speed: 0.1023s/iter; left time: 2455.6615s
	iters: 200, epoch: 9 | loss: 0.4832953
	speed: 0.0216s/iter; left time: 516.6821s
Epoch: 9 cost time: 5.7524330615997314
Epoch: 9, Steps: 262 | Train Loss: 0.4502044 Vali Loss: 0.2780686 Test Loss: 0.3892256
Validation loss decreased (0.278380 --> 0.278069).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3648177
	speed: 0.0922s/iter; left time: 2189.2817s
	iters: 200, epoch: 10 | loss: 0.4667928
	speed: 0.0180s/iter; left time: 425.5244s
Epoch: 10 cost time: 6.170730352401733
Epoch: 10, Steps: 262 | Train Loss: 0.4494912 Vali Loss: 0.2777749 Test Loss: 0.3888752
Validation loss decreased (0.278069 --> 0.277775).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3391845
	speed: 0.0912s/iter; left time: 2141.0135s
	iters: 200, epoch: 11 | loss: 0.4559584
	speed: 0.0199s/iter; left time: 466.4312s
Epoch: 11 cost time: 5.7256340980529785
Epoch: 11, Steps: 262 | Train Loss: 0.4492145 Vali Loss: 0.2778284 Test Loss: 0.3886698
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3874809
	speed: 0.0922s/iter; left time: 2139.9080s
	iters: 200, epoch: 12 | loss: 0.4067352
	speed: 0.0179s/iter; left time: 413.6843s
Epoch: 12 cost time: 5.610175609588623
Epoch: 12, Steps: 262 | Train Loss: 0.4483873 Vali Loss: 0.2775941 Test Loss: 0.3884183
Validation loss decreased (0.277775 --> 0.277594).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3294358
	speed: 0.0818s/iter; left time: 1878.8211s
	iters: 200, epoch: 13 | loss: 0.5056071
	speed: 0.0178s/iter; left time: 406.8434s
Epoch: 13 cost time: 5.53423285484314
Epoch: 13, Steps: 262 | Train Loss: 0.4482072 Vali Loss: 0.2774317 Test Loss: 0.3882828
Validation loss decreased (0.277594 --> 0.277432).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.5364813
	speed: 0.0922s/iter; left time: 2093.5650s
	iters: 200, epoch: 14 | loss: 0.4812177
	speed: 0.0192s/iter; left time: 433.0780s
Epoch: 14 cost time: 5.8259596824646
Epoch: 14, Steps: 262 | Train Loss: 0.4476296 Vali Loss: 0.2773731 Test Loss: 0.3880422
Validation loss decreased (0.277432 --> 0.277373).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4878457
	speed: 0.0928s/iter; left time: 2081.1011s
	iters: 200, epoch: 15 | loss: 0.4274954
	speed: 0.0177s/iter; left time: 394.3854s
Epoch: 15 cost time: 5.530930757522583
Epoch: 15, Steps: 262 | Train Loss: 0.4480097 Vali Loss: 0.2773162 Test Loss: 0.3879012
Validation loss decreased (0.277373 --> 0.277316).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.6752788
	speed: 0.0886s/iter; left time: 1963.3323s
	iters: 200, epoch: 16 | loss: 0.4915872
	speed: 0.0182s/iter; left time: 402.2237s
Epoch: 16 cost time: 5.206014156341553
Epoch: 16, Steps: 262 | Train Loss: 0.4478866 Vali Loss: 0.2773246 Test Loss: 0.3878270
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4387268
	speed: 0.0793s/iter; left time: 1737.5045s
	iters: 200, epoch: 17 | loss: 0.4426201
	speed: 0.0173s/iter; left time: 378.3596s
Epoch: 17 cost time: 5.028726816177368
Epoch: 17, Steps: 262 | Train Loss: 0.4473623 Vali Loss: 0.2770802 Test Loss: 0.3877086
Validation loss decreased (0.277316 --> 0.277080).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4398627
	speed: 0.0828s/iter; left time: 1792.0110s
	iters: 200, epoch: 18 | loss: 0.3477396
	speed: 0.0204s/iter; left time: 439.5654s
Epoch: 18 cost time: 5.740590333938599
Epoch: 18, Steps: 262 | Train Loss: 0.4477721 Vali Loss: 0.2770964 Test Loss: 0.3876621
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3550828
	speed: 0.0843s/iter; left time: 1803.7815s
	iters: 200, epoch: 19 | loss: 0.5262930
	speed: 0.0265s/iter; left time: 563.1199s
Epoch: 19 cost time: 6.651750326156616
Epoch: 19, Steps: 262 | Train Loss: 0.4470199 Vali Loss: 0.2770346 Test Loss: 0.3875954
Validation loss decreased (0.277080 --> 0.277035).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3439615
	speed: 0.1015s/iter; left time: 2144.0231s
	iters: 200, epoch: 20 | loss: 0.4530743
	speed: 0.0199s/iter; left time: 418.8461s
Epoch: 20 cost time: 5.3753132820129395
Epoch: 20, Steps: 262 | Train Loss: 0.4470701 Vali Loss: 0.2771236 Test Loss: 0.3875285
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.6064333
	speed: 0.0936s/iter; left time: 1953.0990s
	iters: 200, epoch: 21 | loss: 0.4182825
	speed: 0.0181s/iter; left time: 375.8736s
Epoch: 21 cost time: 5.518542766571045
Epoch: 21, Steps: 262 | Train Loss: 0.4474489 Vali Loss: 0.2767787 Test Loss: 0.3874453
Validation loss decreased (0.277035 --> 0.276779).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.5769582
	speed: 0.0975s/iter; left time: 2009.1462s
	iters: 200, epoch: 22 | loss: 0.4415122
	speed: 0.0168s/iter; left time: 343.3802s
Epoch: 22 cost time: 5.215198755264282
Epoch: 22, Steps: 262 | Train Loss: 0.4476735 Vali Loss: 0.2767086 Test Loss: 0.3874165
Validation loss decreased (0.276779 --> 0.276709).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3419910
	speed: 0.0855s/iter; left time: 1739.6976s
	iters: 200, epoch: 23 | loss: 0.3647464
	speed: 0.0215s/iter; left time: 434.8403s
Epoch: 23 cost time: 5.427743911743164
Epoch: 23, Steps: 262 | Train Loss: 0.4473667 Vali Loss: 0.2770806 Test Loss: 0.3873639
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3224137
	speed: 0.0873s/iter; left time: 1752.9390s
	iters: 200, epoch: 24 | loss: 0.2835810
	speed: 0.0173s/iter; left time: 344.7462s
Epoch: 24 cost time: 5.0737693309783936
Epoch: 24, Steps: 262 | Train Loss: 0.4473860 Vali Loss: 0.2767672 Test Loss: 0.3873143
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4277071
	speed: 0.0917s/iter; left time: 1816.4210s
	iters: 200, epoch: 25 | loss: 0.4145865
	speed: 0.0196s/iter; left time: 385.9000s
Epoch: 25 cost time: 6.111445188522339
Epoch: 25, Steps: 262 | Train Loss: 0.4470680 Vali Loss: 0.2771455 Test Loss: 0.3872977
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.5433875
	speed: 0.0872s/iter; left time: 1704.4980s
	iters: 200, epoch: 26 | loss: 0.4104725
	speed: 0.0173s/iter; left time: 336.7515s
Epoch: 26 cost time: 5.961456060409546
Epoch: 26, Steps: 262 | Train Loss: 0.4471027 Vali Loss: 0.2770055 Test Loss: 0.3872702
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3278957
	speed: 0.0885s/iter; left time: 1706.7174s
	iters: 200, epoch: 27 | loss: 0.4295103
	speed: 0.0180s/iter; left time: 344.7914s
Epoch: 27 cost time: 5.460718870162964
Epoch: 27, Steps: 262 | Train Loss: 0.4472459 Vali Loss: 0.2768728 Test Loss: 0.3872395
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3651008
	speed: 0.0926s/iter; left time: 1761.2017s
	iters: 200, epoch: 28 | loss: 0.4040559
	speed: 0.0189s/iter; left time: 358.2556s
Epoch: 28 cost time: 5.580252170562744
Epoch: 28, Steps: 262 | Train Loss: 0.4467633 Vali Loss: 0.2768763 Test Loss: 0.3872193
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2790565
	speed: 0.0800s/iter; left time: 1501.1934s
	iters: 200, epoch: 29 | loss: 0.3527060
	speed: 0.0163s/iter; left time: 303.7791s
Epoch: 29 cost time: 4.993803262710571
Epoch: 29, Steps: 262 | Train Loss: 0.4465004 Vali Loss: 0.2769836 Test Loss: 0.3871661
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4636545
	speed: 0.0835s/iter; left time: 1544.7155s
	iters: 200, epoch: 30 | loss: 0.6516209
	speed: 0.0196s/iter; left time: 361.3832s
Epoch: 30 cost time: 5.4178102016448975
Epoch: 30, Steps: 262 | Train Loss: 0.4468859 Vali Loss: 0.2769280 Test Loss: 0.3871613
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3495950
	speed: 0.0941s/iter; left time: 1715.9211s
	iters: 200, epoch: 31 | loss: 0.2924369
	speed: 0.0174s/iter; left time: 315.5470s
Epoch: 31 cost time: 5.810260057449341
Epoch: 31, Steps: 262 | Train Loss: 0.4465167 Vali Loss: 0.2767331 Test Loss: 0.3871525
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.6817333
	speed: 0.0997s/iter; left time: 1792.6397s
	iters: 200, epoch: 32 | loss: 0.4536382
	speed: 0.0194s/iter; left time: 346.1788s
Epoch: 32 cost time: 5.973328113555908
Epoch: 32, Steps: 262 | Train Loss: 0.4471060 Vali Loss: 0.2766956 Test Loss: 0.3871374
Validation loss decreased (0.276709 --> 0.276696).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3716315
	speed: 0.0859s/iter; left time: 1521.8160s
	iters: 200, epoch: 33 | loss: 0.6045921
	speed: 0.0203s/iter; left time: 357.4083s
Epoch: 33 cost time: 5.539345026016235
Epoch: 33, Steps: 262 | Train Loss: 0.4467506 Vali Loss: 0.2767725 Test Loss: 0.3871214
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4456881
	speed: 0.0844s/iter; left time: 1473.0061s
	iters: 200, epoch: 34 | loss: 0.5023441
	speed: 0.0171s/iter; left time: 297.2534s
Epoch: 34 cost time: 5.19723105430603
Epoch: 34, Steps: 262 | Train Loss: 0.4472699 Vali Loss: 0.2765507 Test Loss: 0.3871156
Validation loss decreased (0.276696 --> 0.276551).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.5890957
	speed: 0.0899s/iter; left time: 1545.0511s
	iters: 200, epoch: 35 | loss: 0.4882333
	speed: 0.0179s/iter; left time: 305.5951s
Epoch: 35 cost time: 6.1800620555877686
Epoch: 35, Steps: 262 | Train Loss: 0.4463638 Vali Loss: 0.2768180 Test Loss: 0.3870928
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4298335
	speed: 0.0914s/iter; left time: 1548.0586s
	iters: 200, epoch: 36 | loss: 0.4038292
	speed: 0.0214s/iter; left time: 360.5334s
Epoch: 36 cost time: 5.749473571777344
Epoch: 36, Steps: 262 | Train Loss: 0.4469510 Vali Loss: 0.2767526 Test Loss: 0.3870937
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4921899
	speed: 0.0851s/iter; left time: 1417.9521s
	iters: 200, epoch: 37 | loss: 0.3531490
	speed: 0.0212s/iter; left time: 350.4474s
Epoch: 37 cost time: 5.699891090393066
Epoch: 37, Steps: 262 | Train Loss: 0.4457110 Vali Loss: 0.2767279 Test Loss: 0.3870842
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.7147222
	speed: 0.0911s/iter; left time: 1494.6687s
	iters: 200, epoch: 38 | loss: 0.4108288
	speed: 0.0168s/iter; left time: 273.9776s
Epoch: 38 cost time: 5.212273120880127
Epoch: 38, Steps: 262 | Train Loss: 0.4466927 Vali Loss: 0.2768122 Test Loss: 0.3870794
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.5623360
	speed: 0.0887s/iter; left time: 1432.5264s
	iters: 200, epoch: 39 | loss: 0.4974772
	speed: 0.0185s/iter; left time: 296.1392s
Epoch: 39 cost time: 6.064330339431763
Epoch: 39, Steps: 262 | Train Loss: 0.4463349 Vali Loss: 0.2765005 Test Loss: 0.3870717
Validation loss decreased (0.276551 --> 0.276500).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.4985695
	speed: 0.0946s/iter; left time: 1502.6959s
	iters: 200, epoch: 40 | loss: 0.3858780
	speed: 0.0177s/iter; left time: 278.8542s
Epoch: 40 cost time: 6.236785888671875
Epoch: 40, Steps: 262 | Train Loss: 0.4462809 Vali Loss: 0.2765721 Test Loss: 0.3870701
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.5847035
	speed: 0.0935s/iter; left time: 1460.4279s
	iters: 200, epoch: 41 | loss: 0.3825497
	speed: 0.0169s/iter; left time: 261.6596s
Epoch: 41 cost time: 5.2194743156433105
Epoch: 41, Steps: 262 | Train Loss: 0.4468381 Vali Loss: 0.2770864 Test Loss: 0.3870482
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2974199
	speed: 0.0897s/iter; left time: 1377.0577s
	iters: 200, epoch: 42 | loss: 0.5097134
	speed: 0.0207s/iter; left time: 315.6317s
Epoch: 42 cost time: 6.140956163406372
Epoch: 42, Steps: 262 | Train Loss: 0.4467762 Vali Loss: 0.2766342 Test Loss: 0.3870467
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.5659291
	speed: 0.0926s/iter; left time: 1397.5032s
	iters: 200, epoch: 43 | loss: 0.3795400
	speed: 0.0171s/iter; left time: 256.5655s
Epoch: 43 cost time: 5.373228549957275
Epoch: 43, Steps: 262 | Train Loss: 0.4466072 Vali Loss: 0.2765830 Test Loss: 0.3870376
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.5357075
	speed: 0.0890s/iter; left time: 1320.5437s
	iters: 200, epoch: 44 | loss: 0.3295536
	speed: 0.0189s/iter; left time: 278.3671s
Epoch: 44 cost time: 6.190590143203735
Epoch: 44, Steps: 262 | Train Loss: 0.4460416 Vali Loss: 0.2766896 Test Loss: 0.3870333
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.4339190
	speed: 0.0965s/iter; left time: 1406.6719s
	iters: 200, epoch: 45 | loss: 0.3656268
	speed: 0.0190s/iter; left time: 275.3818s
Epoch: 45 cost time: 5.497792959213257
Epoch: 45, Steps: 262 | Train Loss: 0.4470981 Vali Loss: 0.2765563 Test Loss: 0.3870328
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.4793602
	speed: 0.0853s/iter; left time: 1221.0623s
	iters: 200, epoch: 46 | loss: 0.3430979
	speed: 0.0163s/iter; left time: 231.3092s
Epoch: 46 cost time: 4.937678098678589
Epoch: 46, Steps: 262 | Train Loss: 0.4462890 Vali Loss: 0.2766958 Test Loss: 0.3870240
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.5059654
	speed: 0.0839s/iter; left time: 1179.4080s
	iters: 200, epoch: 47 | loss: 0.2864540
	speed: 0.0187s/iter; left time: 261.2324s
Epoch: 47 cost time: 5.409129858016968
Epoch: 47, Steps: 262 | Train Loss: 0.4469006 Vali Loss: 0.2768012 Test Loss: 0.3870253
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.4924432
	speed: 0.0926s/iter; left time: 1276.6507s
	iters: 200, epoch: 48 | loss: 0.5614134
	speed: 0.0198s/iter; left time: 271.0211s
Epoch: 48 cost time: 5.526268482208252
Epoch: 48, Steps: 262 | Train Loss: 0.4463759 Vali Loss: 0.2768979 Test Loss: 0.3870287
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.5627235
	speed: 0.0899s/iter; left time: 1215.4610s
	iters: 200, epoch: 49 | loss: 0.4768803
	speed: 0.0185s/iter; left time: 247.7327s
Epoch: 49 cost time: 5.3864991664886475
Epoch: 49, Steps: 262 | Train Loss: 0.4469294 Vali Loss: 0.2766593 Test Loss: 0.3870221
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.3520659
	speed: 0.0955s/iter; left time: 1266.4032s
	iters: 200, epoch: 50 | loss: 0.6431605
	speed: 0.0185s/iter; left time: 242.9091s
Epoch: 50 cost time: 5.42376446723938
Epoch: 50, Steps: 262 | Train Loss: 0.4468540 Vali Loss: 0.2766852 Test Loss: 0.3870205
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.4284006
	speed: 0.0869s/iter; left time: 1129.1799s
	iters: 200, epoch: 51 | loss: 0.3330936
	speed: 0.0167s/iter; left time: 215.5054s
Epoch: 51 cost time: 5.374214172363281
Epoch: 51, Steps: 262 | Train Loss: 0.4460998 Vali Loss: 0.2765397 Test Loss: 0.3870154
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.3770279
	speed: 0.0935s/iter; left time: 1191.6339s
	iters: 200, epoch: 52 | loss: 0.5926219
	speed: 0.0271s/iter; left time: 343.0460s
Epoch: 52 cost time: 6.16944146156311
Epoch: 52, Steps: 262 | Train Loss: 0.4469149 Vali Loss: 0.2766706 Test Loss: 0.3870112
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.4841719
	speed: 0.0881s/iter; left time: 1098.8793s
	iters: 200, epoch: 53 | loss: 0.6350604
	speed: 0.0174s/iter; left time: 215.9738s
Epoch: 53 cost time: 5.3077592849731445
Epoch: 53, Steps: 262 | Train Loss: 0.4468468 Vali Loss: 0.2767992 Test Loss: 0.3870085
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.6780695
	speed: 0.0891s/iter; left time: 1088.7555s
	iters: 200, epoch: 54 | loss: 0.3024270
	speed: 0.0178s/iter; left time: 215.4737s
Epoch: 54 cost time: 5.726405382156372
Epoch: 54, Steps: 262 | Train Loss: 0.4467372 Vali Loss: 0.2770280 Test Loss: 0.3870073
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.4196689
	speed: 0.0891s/iter; left time: 1065.4981s
	iters: 200, epoch: 55 | loss: 0.4730496
	speed: 0.0179s/iter; left time: 211.6352s
Epoch: 55 cost time: 5.749480724334717
Epoch: 55, Steps: 262 | Train Loss: 0.4468610 Vali Loss: 0.2767248 Test Loss: 0.3870013
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.3767702
	speed: 0.0985s/iter; left time: 1151.3057s
	iters: 200, epoch: 56 | loss: 0.5239894
	speed: 0.0168s/iter; left time: 194.1502s
Epoch: 56 cost time: 5.968364477157593
Epoch: 56, Steps: 262 | Train Loss: 0.4466657 Vali Loss: 0.2768182 Test Loss: 0.3869992
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.5017528
	speed: 0.0901s/iter; left time: 1029.9349s
	iters: 200, epoch: 57 | loss: 0.5528042
	speed: 0.0172s/iter; left time: 194.3112s
Epoch: 57 cost time: 5.277685165405273
Epoch: 57, Steps: 262 | Train Loss: 0.4463964 Vali Loss: 0.2769150 Test Loss: 0.3869963
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.4784822
	speed: 0.0870s/iter; left time: 971.0115s
	iters: 200, epoch: 58 | loss: 0.6701834
	speed: 0.0184s/iter; left time: 203.3683s
Epoch: 58 cost time: 5.260033369064331
Epoch: 58, Steps: 262 | Train Loss: 0.4463726 Vali Loss: 0.2769793 Test Loss: 0.3869956
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.3777401
	speed: 0.0882s/iter; left time: 961.8364s
	iters: 200, epoch: 59 | loss: 0.6269739
	speed: 0.0185s/iter; left time: 200.1813s
Epoch: 59 cost time: 5.220383405685425
Epoch: 59, Steps: 262 | Train Loss: 0.4467673 Vali Loss: 0.2764912 Test Loss: 0.3869947
Validation loss decreased (0.276500 --> 0.276491).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.6430483
	speed: 0.0840s/iter; left time: 893.9550s
	iters: 200, epoch: 60 | loss: 0.4442089
	speed: 0.0267s/iter; left time: 281.4737s
Epoch: 60 cost time: 6.4053955078125
Epoch: 60, Steps: 262 | Train Loss: 0.4461253 Vali Loss: 0.2766759 Test Loss: 0.3869941
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.6414809
	speed: 0.0997s/iter; left time: 1034.5035s
	iters: 200, epoch: 61 | loss: 0.3744525
	speed: 0.0219s/iter; left time: 225.4100s
Epoch: 61 cost time: 6.0067384243011475
Epoch: 61, Steps: 262 | Train Loss: 0.4466831 Vali Loss: 0.2764565 Test Loss: 0.3869887
Validation loss decreased (0.276491 --> 0.276457).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.5179290
	speed: 0.0832s/iter; left time: 842.0749s
	iters: 200, epoch: 62 | loss: 0.3572873
	speed: 0.0181s/iter; left time: 181.4995s
Epoch: 62 cost time: 5.133614540100098
Epoch: 62, Steps: 262 | Train Loss: 0.4458093 Vali Loss: 0.2766177 Test Loss: 0.3869870
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.3551312
	speed: 0.0879s/iter; left time: 866.2108s
	iters: 200, epoch: 63 | loss: 0.5177891
	speed: 0.0191s/iter; left time: 186.6437s
Epoch: 63 cost time: 5.668956995010376
Epoch: 63, Steps: 262 | Train Loss: 0.4471127 Vali Loss: 0.2766787 Test Loss: 0.3869886
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.4440600
	speed: 0.0936s/iter; left time: 898.2143s
	iters: 200, epoch: 64 | loss: 0.4375197
	speed: 0.0187s/iter; left time: 177.9754s
Epoch: 64 cost time: 6.06771445274353
Epoch: 64, Steps: 262 | Train Loss: 0.4464089 Vali Loss: 0.2768098 Test Loss: 0.3869866
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.4765009
	speed: 0.0879s/iter; left time: 820.6018s
	iters: 200, epoch: 65 | loss: 0.4499083
	speed: 0.0288s/iter; left time: 265.9376s
Epoch: 65 cost time: 6.359988451004028
Epoch: 65, Steps: 262 | Train Loss: 0.4468127 Vali Loss: 0.2767664 Test Loss: 0.3869870
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.4709494
	speed: 0.0928s/iter; left time: 841.6462s
	iters: 200, epoch: 66 | loss: 0.5006768
	speed: 0.0237s/iter; left time: 212.2032s
Epoch: 66 cost time: 6.156466245651245
Epoch: 66, Steps: 262 | Train Loss: 0.4464883 Vali Loss: 0.2770064 Test Loss: 0.3869857
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.4754637
	speed: 0.0875s/iter; left time: 771.1642s
	iters: 200, epoch: 67 | loss: 0.5263792
	speed: 0.0171s/iter; left time: 148.5932s
Epoch: 67 cost time: 5.910638809204102
Epoch: 67, Steps: 262 | Train Loss: 0.4466196 Vali Loss: 0.2766297 Test Loss: 0.3869833
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.3374912
	speed: 0.0820s/iter; left time: 700.8318s
	iters: 200, epoch: 68 | loss: 0.3877319
	speed: 0.0185s/iter; left time: 156.4108s
Epoch: 68 cost time: 5.159264087677002
Epoch: 68, Steps: 262 | Train Loss: 0.4464984 Vali Loss: 0.2766932 Test Loss: 0.3869824
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.4048027
	speed: 0.0839s/iter; left time: 695.3177s
	iters: 200, epoch: 69 | loss: 0.4781833
	speed: 0.0173s/iter; left time: 141.2685s
Epoch: 69 cost time: 5.117545127868652
Epoch: 69, Steps: 262 | Train Loss: 0.4469827 Vali Loss: 0.2766534 Test Loss: 0.3869831
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.3183348
	speed: 0.0845s/iter; left time: 677.8360s
	iters: 200, epoch: 70 | loss: 0.8561089
	speed: 0.0190s/iter; left time: 150.6372s
Epoch: 70 cost time: 5.241854190826416
Epoch: 70, Steps: 262 | Train Loss: 0.4466955 Vali Loss: 0.2767452 Test Loss: 0.3869808
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.3501937
	speed: 0.0849s/iter; left time: 659.2419s
	iters: 200, epoch: 71 | loss: 0.6455233
	speed: 0.0194s/iter; left time: 148.4985s
Epoch: 71 cost time: 5.497518301010132
Epoch: 71, Steps: 262 | Train Loss: 0.4467202 Vali Loss: 0.2765242 Test Loss: 0.3869809
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.5197694
	speed: 0.0830s/iter; left time: 622.4486s
	iters: 200, epoch: 72 | loss: 0.3202756
	speed: 0.0167s/iter; left time: 123.8067s
Epoch: 72 cost time: 5.21273398399353
Epoch: 72, Steps: 262 | Train Loss: 0.4464957 Vali Loss: 0.2765722 Test Loss: 0.3869777
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.3142290
	speed: 0.0857s/iter; left time: 620.0544s
	iters: 200, epoch: 73 | loss: 0.6512437
	speed: 0.0179s/iter; left time: 127.7559s
Epoch: 73 cost time: 5.256148099899292
Epoch: 73, Steps: 262 | Train Loss: 0.4461524 Vali Loss: 0.2768407 Test Loss: 0.3869804
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.5481709
	speed: 0.0862s/iter; left time: 601.1260s
	iters: 200, epoch: 74 | loss: 0.5147802
	speed: 0.0169s/iter; left time: 116.2529s
Epoch: 74 cost time: 5.24347448348999
Epoch: 74, Steps: 262 | Train Loss: 0.4462211 Vali Loss: 0.2766274 Test Loss: 0.3869771
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.3782269
	speed: 0.0856s/iter; left time: 574.6045s
	iters: 200, epoch: 75 | loss: 0.4091284
	speed: 0.0197s/iter; left time: 130.4502s
Epoch: 75 cost time: 5.612358570098877
Epoch: 75, Steps: 262 | Train Loss: 0.4469296 Vali Loss: 0.2766716 Test Loss: 0.3869752
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.6772188
	speed: 0.0892s/iter; left time: 575.1073s
	iters: 200, epoch: 76 | loss: 0.4679014
	speed: 0.0202s/iter; left time: 128.3656s
Epoch: 76 cost time: 6.169440031051636
Epoch: 76, Steps: 262 | Train Loss: 0.4467857 Vali Loss: 0.2767161 Test Loss: 0.3869770
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.5443622
	speed: 0.0915s/iter; left time: 566.5901s
	iters: 200, epoch: 77 | loss: 0.4113861
	speed: 0.0172s/iter; left time: 105.0225s
Epoch: 77 cost time: 5.781721591949463
Epoch: 77, Steps: 262 | Train Loss: 0.4468034 Vali Loss: 0.2768529 Test Loss: 0.3869752
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.3960320
	speed: 0.1117s/iter; left time: 662.1277s
	iters: 200, epoch: 78 | loss: 0.4557627
	speed: 0.0279s/iter; left time: 162.6954s
Epoch: 78 cost time: 13.795922994613647
Epoch: 78, Steps: 262 | Train Loss: 0.4464935 Vali Loss: 0.2769475 Test Loss: 0.3869762
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.3895259
	speed: 0.1350s/iter; left time: 765.0438s
	iters: 200, epoch: 79 | loss: 0.4677144
	speed: 0.0185s/iter; left time: 102.9294s
Epoch: 79 cost time: 5.587808132171631
Epoch: 79, Steps: 262 | Train Loss: 0.4462242 Vali Loss: 0.2768453 Test Loss: 0.3869744
EarlyStopping counter: 18 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.5602112
	speed: 0.0829s/iter; left time: 448.0238s
	iters: 200, epoch: 80 | loss: 0.3873391
	speed: 0.0185s/iter; left time: 98.1797s
Epoch: 80 cost time: 5.401407241821289
Epoch: 80, Steps: 262 | Train Loss: 0.4467057 Vali Loss: 0.2770202 Test Loss: 0.3869749
EarlyStopping counter: 19 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.3804579
	speed: 0.0951s/iter; left time: 488.7539s
	iters: 200, epoch: 81 | loss: 0.4947551
	speed: 0.0177s/iter; left time: 89.1496s
Epoch: 81 cost time: 5.949450492858887
Epoch: 81, Steps: 262 | Train Loss: 0.4469015 Vali Loss: 0.2766602 Test Loss: 0.3869735
EarlyStopping counter: 20 out of 20
Early stopping
train 33661
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=26, out_features=130, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3028480.0
params:  3510.0
Trainable parameters:  3510
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6849384
	speed: 0.0242s/iter; left time: 630.7041s
	iters: 200, epoch: 1 | loss: 0.5982294
	speed: 0.0185s/iter; left time: 479.8207s
Epoch: 1 cost time: 5.342958927154541
Epoch: 1, Steps: 262 | Train Loss: 0.5549862 Vali Loss: 0.2767813 Test Loss: 0.3866951
Validation loss decreased (inf --> 0.276781).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5258543
	speed: 0.0869s/iter; left time: 2245.1436s
	iters: 200, epoch: 2 | loss: 0.4552959
	speed: 0.0187s/iter; left time: 481.6814s
Epoch: 2 cost time: 5.22042441368103
Epoch: 2, Steps: 262 | Train Loss: 0.5542591 Vali Loss: 0.2765222 Test Loss: 0.3865392
Validation loss decreased (0.276781 --> 0.276522).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3749024
	speed: 0.0855s/iter; left time: 2186.5481s
	iters: 200, epoch: 3 | loss: 0.5813813
	speed: 0.0185s/iter; left time: 471.2166s
Epoch: 3 cost time: 5.359290361404419
Epoch: 3, Steps: 262 | Train Loss: 0.5553415 Vali Loss: 0.2765651 Test Loss: 0.3865759
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.5568193
	speed: 0.0876s/iter; left time: 2217.8857s
	iters: 200, epoch: 4 | loss: 0.4756646
	speed: 0.0172s/iter; left time: 434.2201s
Epoch: 4 cost time: 4.9666454792022705
Epoch: 4, Steps: 262 | Train Loss: 0.5545355 Vali Loss: 0.2762752 Test Loss: 0.3865312
Validation loss decreased (0.276522 --> 0.276275).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.5905386
	speed: 0.0819s/iter; left time: 2051.8153s
	iters: 200, epoch: 5 | loss: 0.6460588
	speed: 0.0168s/iter; left time: 418.3356s
Epoch: 5 cost time: 4.903250694274902
Epoch: 5, Steps: 262 | Train Loss: 0.5531451 Vali Loss: 0.2767539 Test Loss: 0.3865375
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.5354379
	speed: 0.0961s/iter; left time: 2382.9097s
	iters: 200, epoch: 6 | loss: 0.6414803
	speed: 0.0169s/iter; left time: 417.8436s
Epoch: 6 cost time: 5.602387189865112
Epoch: 6, Steps: 262 | Train Loss: 0.5534387 Vali Loss: 0.2764427 Test Loss: 0.3864835
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4992189
	speed: 0.0851s/iter; left time: 2086.6237s
	iters: 200, epoch: 7 | loss: 0.7230477
	speed: 0.0188s/iter; left time: 458.1258s
Epoch: 7 cost time: 5.269743204116821
Epoch: 7, Steps: 262 | Train Loss: 0.5546063 Vali Loss: 0.2766446 Test Loss: 0.3864158
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3983177
	speed: 0.0895s/iter; left time: 2172.4823s
	iters: 200, epoch: 8 | loss: 0.4913575
	speed: 0.0205s/iter; left time: 495.5820s
Epoch: 8 cost time: 5.454120397567749
Epoch: 8, Steps: 262 | Train Loss: 0.5542218 Vali Loss: 0.2763902 Test Loss: 0.3864341
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.5010124
	speed: 0.0899s/iter; left time: 2158.8468s
	iters: 200, epoch: 9 | loss: 0.4640506
	speed: 0.0201s/iter; left time: 480.1115s
Epoch: 9 cost time: 6.467985391616821
Epoch: 9, Steps: 262 | Train Loss: 0.5546463 Vali Loss: 0.2764742 Test Loss: 0.3865065
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.5469065
	speed: 0.0926s/iter; left time: 2198.6492s
	iters: 200, epoch: 10 | loss: 0.6362084
	speed: 0.0159s/iter; left time: 376.3530s
Epoch: 10 cost time: 5.08051872253418
Epoch: 10, Steps: 262 | Train Loss: 0.5544383 Vali Loss: 0.2763532 Test Loss: 0.3864170
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.6082222
	speed: 0.0836s/iter; left time: 1964.1554s
	iters: 200, epoch: 11 | loss: 0.7230147
	speed: 0.0187s/iter; left time: 436.4651s
Epoch: 11 cost time: 5.357674837112427
Epoch: 11, Steps: 262 | Train Loss: 0.5539035 Vali Loss: 0.2765728 Test Loss: 0.3864461
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4679887
	speed: 0.0920s/iter; left time: 2135.9732s
	iters: 200, epoch: 12 | loss: 0.5126151
	speed: 0.0209s/iter; left time: 484.1306s
Epoch: 12 cost time: 6.0045859813690186
Epoch: 12, Steps: 262 | Train Loss: 0.5532329 Vali Loss: 0.2764241 Test Loss: 0.3863696
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.7713753
	speed: 0.0829s/iter; left time: 1903.2731s
	iters: 200, epoch: 13 | loss: 0.4320287
	speed: 0.0216s/iter; left time: 493.9207s
Epoch: 13 cost time: 5.559177875518799
Epoch: 13, Steps: 262 | Train Loss: 0.5534756 Vali Loss: 0.2764797 Test Loss: 0.3864475
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.6140416
	speed: 0.0885s/iter; left time: 2008.8925s
	iters: 200, epoch: 14 | loss: 0.4790887
	speed: 0.0187s/iter; left time: 423.4643s
Epoch: 14 cost time: 5.304103374481201
Epoch: 14, Steps: 262 | Train Loss: 0.5537223 Vali Loss: 0.2767966 Test Loss: 0.3864905
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.6026913
	speed: 0.1011s/iter; left time: 2267.9208s
	iters: 200, epoch: 15 | loss: 0.6628000
	speed: 0.0208s/iter; left time: 464.3040s
Epoch: 15 cost time: 6.82357931137085
Epoch: 15, Steps: 262 | Train Loss: 0.5542141 Vali Loss: 0.2765754 Test Loss: 0.3864067
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.5627778
	speed: 0.0830s/iter; left time: 1840.7610s
	iters: 200, epoch: 16 | loss: 0.4686333
	speed: 0.0196s/iter; left time: 431.7043s
Epoch: 16 cost time: 5.531488656997681
Epoch: 16, Steps: 262 | Train Loss: 0.5539813 Vali Loss: 0.2763894 Test Loss: 0.3864577
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4086942
	speed: 0.0884s/iter; left time: 1935.7791s
	iters: 200, epoch: 17 | loss: 0.3967019
	speed: 0.0177s/iter; left time: 386.0951s
Epoch: 17 cost time: 5.583331108093262
Epoch: 17, Steps: 262 | Train Loss: 0.5537439 Vali Loss: 0.2766181 Test Loss: 0.3864350
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4912191
	speed: 0.0878s/iter; left time: 1900.0464s
	iters: 200, epoch: 18 | loss: 0.4590976
	speed: 0.0188s/iter; left time: 404.4068s
Epoch: 18 cost time: 5.607205629348755
Epoch: 18, Steps: 262 | Train Loss: 0.5532640 Vali Loss: 0.2764699 Test Loss: 0.3864315
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.7361388
	speed: 0.0887s/iter; left time: 1897.8766s
	iters: 200, epoch: 19 | loss: 0.7169400
	speed: 0.0180s/iter; left time: 382.6421s
Epoch: 19 cost time: 5.065185546875
Epoch: 19, Steps: 262 | Train Loss: 0.5545156 Vali Loss: 0.2764482 Test Loss: 0.3864393
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4210542
	speed: 0.0885s/iter; left time: 1870.2510s
	iters: 200, epoch: 20 | loss: 0.6912078
	speed: 0.0246s/iter; left time: 516.3757s
Epoch: 20 cost time: 6.138471364974976
Epoch: 20, Steps: 262 | Train Loss: 0.5540141 Vali Loss: 0.2765873 Test Loss: 0.3864510
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4206046
	speed: 0.0963s/iter; left time: 2009.7380s
	iters: 200, epoch: 21 | loss: 0.6219109
	speed: 0.0182s/iter; left time: 378.6665s
Epoch: 21 cost time: 6.784624099731445
Epoch: 21, Steps: 262 | Train Loss: 0.5535927 Vali Loss: 0.2764533 Test Loss: 0.3864425
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4979659
	speed: 0.0992s/iter; left time: 2043.5966s
	iters: 200, epoch: 22 | loss: 0.8453596
	speed: 0.0197s/iter; left time: 403.2733s
Epoch: 22 cost time: 5.706400632858276
Epoch: 22, Steps: 262 | Train Loss: 0.5533555 Vali Loss: 0.2763824 Test Loss: 0.3864607
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.5283408
	speed: 0.0892s/iter; left time: 1813.7556s
	iters: 200, epoch: 23 | loss: 0.5699642
	speed: 0.0189s/iter; left time: 383.0768s
Epoch: 23 cost time: 5.567376613616943
Epoch: 23, Steps: 262 | Train Loss: 0.5535641 Vali Loss: 0.2764933 Test Loss: 0.3864431
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.5614273
	speed: 0.0882s/iter; left time: 1771.0055s
	iters: 200, epoch: 24 | loss: 0.5319054
	speed: 0.0180s/iter; left time: 358.7975s
Epoch: 24 cost time: 5.140156030654907
Epoch: 24, Steps: 262 | Train Loss: 0.5535967 Vali Loss: 0.2765632 Test Loss: 0.3864332
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_180_720_FITS_ETTm2_ftM_sl180_ll48_pl720_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.38389864563941956, mae:0.38771721720695496, rse:0.4980267584323883, corr:[0.54485285 0.54756176 0.5453622  0.5417395  0.5392656  0.53847384
 0.5384726  0.5380896  0.53690743 0.5353519  0.53413445 0.53366596
 0.53369546 0.53362703 0.53310704 0.532103   0.53093296 0.5299974
 0.52945554 0.5291297  0.52871263 0.52798504 0.5269821  0.5259842
 0.52524006 0.5248287  0.5245985  0.5242797  0.52369684 0.52289486
 0.5221241  0.52158475 0.52125055 0.52095985 0.5205164  0.5198668
 0.5190375  0.5182385  0.5175374  0.51696503 0.5165005  0.51605874
 0.5155882  0.5150761  0.5145416  0.5140268  0.51348394 0.5128628
 0.51209855 0.5111957  0.51024127 0.50941205 0.50872445 0.5081135
 0.5075718  0.5070936  0.50660574 0.5061986  0.50588524 0.5056745
 0.5054758  0.5052804  0.5050612  0.5047169  0.50434124 0.50405294
 0.5038388  0.50373477 0.5036793  0.50360936 0.5034374  0.50319415
 0.502986   0.50278467 0.50262815 0.50244534 0.5022153  0.50186193
 0.501426   0.50093144 0.5004035  0.4998904  0.49947998 0.49915087
 0.4988351  0.49846393 0.49799037 0.4974876  0.4969887  0.49653903
 0.49618834 0.49587378 0.4954514  0.49474376 0.4935779  0.49187633
 0.48978508 0.48772013 0.48585755 0.48423004 0.48281527 0.48155096
 0.4803418  0.47911888 0.4778072  0.47645324 0.47515556 0.47398382
 0.4728844  0.47164527 0.47040057 0.46916363 0.4680074  0.4669022
 0.4657605  0.46464688 0.4635725  0.46250072 0.46144193 0.46035153
 0.45933378 0.45847347 0.45774406 0.4570249  0.4561805  0.45511928
 0.45388567 0.45260647 0.45144314 0.4504527  0.44965434 0.4489267
 0.44818416 0.44732767 0.44653735 0.44592774 0.44549048 0.44519186
 0.444874   0.44440573 0.44371858 0.44288567 0.4420734  0.44133654
 0.44066948 0.4400147  0.43924457 0.43837056 0.43749568 0.43664497
 0.43592596 0.43547034 0.43512455 0.43476397 0.43430397 0.43366778
 0.43295753 0.43234405 0.43187827 0.43160778 0.43147075 0.4313251
 0.4311303  0.4307625  0.43044856 0.43024364 0.43017328 0.43026897
 0.4304446  0.43063158 0.43071237 0.4306676  0.43057364 0.43043253
 0.43034843 0.43032154 0.43037197 0.4304126  0.43038136 0.430207
 0.42978793 0.42913905 0.42847514 0.42793286 0.427642   0.4275107
 0.42743632 0.4272529  0.42681453 0.4260001  0.4247704  0.42320764
 0.4215213  0.4200182  0.4186312  0.41724575 0.4158665  0.4144202
 0.41291782 0.41145977 0.41013893 0.40915093 0.40838468 0.40780193
 0.40723246 0.40655312 0.40572757 0.40483394 0.40397868 0.4031808
 0.40238592 0.40156588 0.40072912 0.39990687 0.39915583 0.39843547
 0.3977434  0.39691433 0.3960398  0.39506263 0.39393562 0.3927856
 0.39164326 0.3906298  0.3898603  0.38913268 0.38838068 0.38755104
 0.3865775  0.38549465 0.38441524 0.3834906  0.3827659  0.38229147
 0.38194078 0.38164073 0.38136727 0.38094446 0.3804621  0.37988988
 0.37927386 0.37866232 0.3781564  0.37791198 0.3777917  0.37770686
 0.37763262 0.37757194 0.37758023 0.37763515 0.3777796  0.37798193
 0.3781184  0.37826365 0.37838146 0.37842387 0.37838542 0.37836382
 0.37837273 0.37833378 0.37822935 0.37810588 0.3779173  0.37762102
 0.3773104  0.37709174 0.37702063 0.37708154 0.37724334 0.3774218
 0.37744057 0.37727606 0.37693816 0.37661952 0.37641177 0.37634957
 0.37633923 0.37628964 0.37620905 0.37615177 0.37608254 0.37615138
 0.37630272 0.37637073 0.3762093  0.37569895 0.37478882 0.37352446
 0.37208685 0.37089255 0.36993492 0.3692139  0.36858335 0.3679142
 0.36725688 0.36653587 0.36580294 0.3651434  0.36468467 0.36438632
 0.36415252 0.36368963 0.36303845 0.3622705  0.36149532 0.36076164
 0.36009616 0.3594231  0.3586211  0.35771763 0.35680637 0.35602978
 0.35537025 0.35481143 0.3541817  0.35343456 0.3524535  0.35134867
 0.35027975 0.34935084 0.34858721 0.34791744 0.3472669  0.3465456
 0.3457879  0.34505093 0.34443104 0.34393635 0.34350425 0.34312826
 0.34284487 0.342597   0.34240824 0.3421931  0.34189868 0.34155968
 0.34108946 0.34048834 0.33981267 0.3392887  0.33888087 0.33855602
 0.33827344 0.3380426  0.33785105 0.33778784 0.33780834 0.3379492
 0.33808234 0.33812106 0.33801138 0.3377793  0.3375089  0.3373075
 0.3372074  0.33722058 0.33722827 0.33720225 0.33708626 0.33688402
 0.3366665  0.33647555 0.33632863 0.33627594 0.3363411  0.3366321
 0.33706868 0.3375683  0.33798447 0.33817393 0.33823293 0.3381246
 0.33799198 0.33802965 0.33832312 0.33882037 0.33933285 0.3396525
 0.3396784  0.33935422 0.33874542 0.33793184 0.3370825  0.33621877
 0.3353348  0.33439872 0.33338252 0.33229873 0.33114085 0.330089
 0.329172   0.3283252  0.3274933  0.3266607  0.32578793 0.32494357
 0.3241549  0.32335696 0.32257926 0.3219101  0.32132694 0.3206956
 0.31997722 0.31908947 0.31814963 0.31730548 0.31661624 0.31608286
 0.31568804 0.31529555 0.31475607 0.3139957  0.31309056 0.3122327
 0.31158707 0.3111943  0.31095362 0.31073445 0.31030405 0.30966532
 0.308877   0.30803236 0.3072996  0.30683085 0.30650452 0.30628648
 0.30619782 0.30622405 0.30628505 0.30636337 0.3063272  0.30613902
 0.30568665 0.30510867 0.3044986  0.3040869  0.30387318 0.30371085
 0.30352938 0.30324635 0.3028777  0.30243513 0.301983   0.30169353
 0.3015465  0.30147135 0.3013858  0.30116183 0.3008375  0.30057478
 0.3005087  0.300612   0.30087417 0.30122554 0.3014454  0.30152047
 0.30140603 0.30117184 0.3008563  0.30054888 0.30034503 0.3002434
 0.30024076 0.30037007 0.30059126 0.3007893  0.30076447 0.300493
 0.3000581  0.29957247 0.29924488 0.2991459  0.29930347 0.29955608
 0.29959345 0.29923132 0.29842058 0.297187   0.29568318 0.29412782
 0.29267278 0.29145962 0.2904126  0.28948456 0.2886101  0.28773615
 0.28686044 0.28595042 0.2850638  0.28431317 0.28377575 0.2834196
 0.28315693 0.28286284 0.28250045 0.2820654  0.28158146 0.28099993
 0.28032747 0.27951664 0.27857003 0.27761796 0.27674958 0.27605063
 0.27548033 0.27501565 0.27459094 0.274076   0.27343425 0.27268368
 0.27186    0.27103493 0.2702399  0.26946375 0.26869625 0.26796773
 0.2673104  0.26676968 0.26639017 0.26614153 0.266006   0.2659032
 0.26574117 0.26554537 0.2653062  0.26497877 0.26463795 0.26415142
 0.26349553 0.26261637 0.26155594 0.26048386 0.25965646 0.25916603
 0.2590818  0.259362   0.25989386 0.26040798 0.2607671  0.26077405
 0.26054654 0.26020014 0.2597688  0.2593594  0.25902817 0.25882542
 0.25869295 0.2585933  0.25842515 0.25810856 0.25758013 0.2570068
 0.25656894 0.2564443  0.25665176 0.25698435 0.25720322 0.25718012
 0.25683346 0.25642163 0.25617313 0.256252   0.25665408 0.2571862
 0.2575685  0.2576806  0.25752366 0.257209   0.2569306  0.25673667
 0.25660622 0.2563424  0.25578535 0.25478837 0.25336534 0.25156796
 0.24967545 0.24806361 0.24674104 0.24564771 0.24469377 0.24381578
 0.24289986 0.2419771  0.2410275  0.24006112 0.23918575 0.23850846
 0.23795645 0.2373727  0.23680204 0.2362654  0.23571384 0.23512268
 0.2344526  0.23370965 0.23294458 0.23212722 0.23134454 0.23062436
 0.23006052 0.22973858 0.22951654 0.22915258 0.22861771 0.2278564
 0.226892   0.22602063 0.22545107 0.2251929  0.22521886 0.22522356
 0.22503823 0.22449706 0.22373983 0.22303557 0.22260995 0.22254716
 0.22261018 0.22263166 0.22229299 0.2217819  0.22127502 0.22085935
 0.22062312 0.22048937 0.22037685 0.22020656 0.21996194 0.21972367
 0.21967992 0.21996707 0.22039792 0.22077097 0.22104806 0.22106111
 0.22097081 0.22081445 0.22060376 0.22036617 0.22011188 0.21982364
 0.21966247 0.21980205 0.22028051 0.22083583 0.22119817 0.22117001
 0.22068821 0.22006404 0.21955398 0.21954656 0.22001873 0.22063577
 0.22112691 0.22122957 0.22102626 0.22094375 0.22126558 0.22198194
 0.22296444 0.22387746 0.22452793 0.22487608 0.22502847 0.2251277
 0.22521128 0.22518991 0.22483794 0.2239831  0.22262722 0.22104122
 0.2196584  0.21878031 0.21831146 0.21794385 0.21740337 0.21660155
 0.215593   0.21458094 0.21374832 0.21312708 0.21268404 0.2123803
 0.21218342 0.21189591 0.21159363 0.21130045 0.21105257 0.21072753
 0.21025157 0.20959066 0.20876586 0.20783766 0.20688994 0.20591249
 0.2049885  0.20409554 0.20317279 0.20218089 0.20101419 0.1997174
 0.1983196  0.19699098 0.19576852 0.19469848 0.19361332 0.19237894
 0.19097382 0.18969373 0.18876569 0.18831785 0.188028   0.18763413
 0.18672854 0.18551789 0.18490107 0.18600214 0.1889685  0.19230478]
