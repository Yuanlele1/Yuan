Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=42, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_360_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_360_192_FITS_ETTm2_ftM_sl360_ll48_pl192_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34009
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=42, out_features=64, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2408448.0
params:  2752.0
Trainable parameters:  2752
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2804908
	speed: 0.0200s/iter; left time: 527.7825s
	iters: 200, epoch: 1 | loss: 0.4142947
	speed: 0.0144s/iter; left time: 378.3649s
Epoch: 1 cost time: 4.393236875534058
Epoch: 1, Steps: 265 | Train Loss: 0.3935725 Vali Loss: 0.1762582 Test Loss: 0.2420490
Validation loss decreased (inf --> 0.176258).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2645739
	speed: 0.0665s/iter; left time: 1737.6030s
	iters: 200, epoch: 2 | loss: 0.2386171
	speed: 0.0128s/iter; left time: 334.1974s
Epoch: 2 cost time: 3.9386074542999268
Epoch: 2, Steps: 265 | Train Loss: 0.3309272 Vali Loss: 0.1660414 Test Loss: 0.2310593
Validation loss decreased (0.176258 --> 0.166041).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3824989
	speed: 0.0655s/iter; left time: 1693.8776s
	iters: 200, epoch: 3 | loss: 0.1792773
	speed: 0.0127s/iter; left time: 326.4086s
Epoch: 3 cost time: 3.9537241458892822
Epoch: 3, Steps: 265 | Train Loss: 0.3193059 Vali Loss: 0.1624788 Test Loss: 0.2269343
Validation loss decreased (0.166041 --> 0.162479).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2613239
	speed: 0.0672s/iter; left time: 1721.5012s
	iters: 200, epoch: 4 | loss: 0.3143000
	speed: 0.0128s/iter; left time: 325.5542s
Epoch: 4 cost time: 4.0226850509643555
Epoch: 4, Steps: 265 | Train Loss: 0.3127863 Vali Loss: 0.1606485 Test Loss: 0.2247785
Validation loss decreased (0.162479 --> 0.160649).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2059229
	speed: 0.0662s/iter; left time: 1677.2250s
	iters: 200, epoch: 5 | loss: 0.3003637
	speed: 0.0129s/iter; left time: 324.8845s
Epoch: 5 cost time: 3.9951553344726562
Epoch: 5, Steps: 265 | Train Loss: 0.3096553 Vali Loss: 0.1596656 Test Loss: 0.2233944
Validation loss decreased (0.160649 --> 0.159666).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2825010
	speed: 0.0672s/iter; left time: 1685.2112s
	iters: 200, epoch: 6 | loss: 0.3864383
	speed: 0.0132s/iter; left time: 328.6982s
Epoch: 6 cost time: 3.927905797958374
Epoch: 6, Steps: 265 | Train Loss: 0.3075254 Vali Loss: 0.1587617 Test Loss: 0.2230313
Validation loss decreased (0.159666 --> 0.158762).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3062034
	speed: 0.0666s/iter; left time: 1651.6855s
	iters: 200, epoch: 7 | loss: 0.4842887
	speed: 0.0128s/iter; left time: 315.8933s
Epoch: 7 cost time: 3.8961613178253174
Epoch: 7, Steps: 265 | Train Loss: 0.3059529 Vali Loss: 0.1583031 Test Loss: 0.2222098
Validation loss decreased (0.158762 --> 0.158303).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2410869
	speed: 0.0648s/iter; left time: 1589.5926s
	iters: 200, epoch: 8 | loss: 0.2347767
	speed: 0.0130s/iter; left time: 317.0070s
Epoch: 8 cost time: 3.9108731746673584
Epoch: 8, Steps: 265 | Train Loss: 0.3045711 Vali Loss: 0.1579634 Test Loss: 0.2216911
Validation loss decreased (0.158303 --> 0.157963).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2649203
	speed: 0.0708s/iter; left time: 1719.0680s
	iters: 200, epoch: 9 | loss: 0.2326444
	speed: 0.0154s/iter; left time: 372.9292s
Epoch: 9 cost time: 4.5370495319366455
Epoch: 9, Steps: 265 | Train Loss: 0.3037836 Vali Loss: 0.1574391 Test Loss: 0.2214637
Validation loss decreased (0.157963 --> 0.157439).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3096923
	speed: 0.0685s/iter; left time: 1645.8384s
	iters: 200, epoch: 10 | loss: 0.3039250
	speed: 0.0136s/iter; left time: 325.1077s
Epoch: 10 cost time: 3.992642879486084
Epoch: 10, Steps: 265 | Train Loss: 0.3031875 Vali Loss: 0.1574186 Test Loss: 0.2210992
Validation loss decreased (0.157439 --> 0.157419).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2865260
	speed: 0.0715s/iter; left time: 1698.2939s
	iters: 200, epoch: 11 | loss: 0.3164380
	speed: 0.0150s/iter; left time: 354.5326s
Epoch: 11 cost time: 4.347188234329224
Epoch: 11, Steps: 265 | Train Loss: 0.3024808 Vali Loss: 0.1572446 Test Loss: 0.2208693
Validation loss decreased (0.157419 --> 0.157245).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2814099
	speed: 0.0675s/iter; left time: 1585.6864s
	iters: 200, epoch: 12 | loss: 0.2704134
	speed: 0.0127s/iter; left time: 297.5772s
Epoch: 12 cost time: 3.990001916885376
Epoch: 12, Steps: 265 | Train Loss: 0.3023236 Vali Loss: 0.1570572 Test Loss: 0.2209191
Validation loss decreased (0.157245 --> 0.157057).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2189550
	speed: 0.0674s/iter; left time: 1564.9206s
	iters: 200, epoch: 13 | loss: 0.2134548
	speed: 0.0126s/iter; left time: 292.1934s
Epoch: 13 cost time: 3.9261839389801025
Epoch: 13, Steps: 265 | Train Loss: 0.3012840 Vali Loss: 0.1571717 Test Loss: 0.2206243
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4422614
	speed: 0.0662s/iter; left time: 1520.1014s
	iters: 200, epoch: 14 | loss: 0.2647175
	speed: 0.0129s/iter; left time: 294.9552s
Epoch: 14 cost time: 3.882124900817871
Epoch: 14, Steps: 265 | Train Loss: 0.3011921 Vali Loss: 0.1570222 Test Loss: 0.2205991
Validation loss decreased (0.157057 --> 0.157022).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2363064
	speed: 0.0664s/iter; left time: 1506.9323s
	iters: 200, epoch: 15 | loss: 0.3392811
	speed: 0.0130s/iter; left time: 294.1966s
Epoch: 15 cost time: 4.028900861740112
Epoch: 15, Steps: 265 | Train Loss: 0.3010502 Vali Loss: 0.1568414 Test Loss: 0.2205306
Validation loss decreased (0.157022 --> 0.156841).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2173243
	speed: 0.0683s/iter; left time: 1532.6477s
	iters: 200, epoch: 16 | loss: 0.2595936
	speed: 0.0144s/iter; left time: 321.2917s
Epoch: 16 cost time: 4.469043016433716
Epoch: 16, Steps: 265 | Train Loss: 0.3004616 Vali Loss: 0.1566426 Test Loss: 0.2204718
Validation loss decreased (0.156841 --> 0.156643).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3426696
	speed: 0.0675s/iter; left time: 1496.1501s
	iters: 200, epoch: 17 | loss: 0.3150706
	speed: 0.0129s/iter; left time: 283.9854s
Epoch: 17 cost time: 4.041406869888306
Epoch: 17, Steps: 265 | Train Loss: 0.3004930 Vali Loss: 0.1568013 Test Loss: 0.2203007
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2562422
	speed: 0.0658s/iter; left time: 1440.8373s
	iters: 200, epoch: 18 | loss: 0.1961429
	speed: 0.0130s/iter; left time: 284.3673s
Epoch: 18 cost time: 3.8877828121185303
Epoch: 18, Steps: 265 | Train Loss: 0.3009070 Vali Loss: 0.1565865 Test Loss: 0.2202909
Validation loss decreased (0.156643 --> 0.156587).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2368438
	speed: 0.0685s/iter; left time: 1482.1690s
	iters: 200, epoch: 19 | loss: 0.3136726
	speed: 0.0130s/iter; left time: 279.8435s
Epoch: 19 cost time: 3.9673290252685547
Epoch: 19, Steps: 265 | Train Loss: 0.3004138 Vali Loss: 0.1568922 Test Loss: 0.2201773
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2319971
	speed: 0.0662s/iter; left time: 1413.6923s
	iters: 200, epoch: 20 | loss: 0.2656330
	speed: 0.0128s/iter; left time: 271.5857s
Epoch: 20 cost time: 3.948755979537964
Epoch: 20, Steps: 265 | Train Loss: 0.3000523 Vali Loss: 0.1566350 Test Loss: 0.2201269
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2585573
	speed: 0.0666s/iter; left time: 1404.7758s
	iters: 200, epoch: 21 | loss: 0.2181857
	speed: 0.0132s/iter; left time: 276.8988s
Epoch: 21 cost time: 3.9182708263397217
Epoch: 21, Steps: 265 | Train Loss: 0.3001891 Vali Loss: 0.1566403 Test Loss: 0.2201706
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2867312
	speed: 0.0673s/iter; left time: 1401.8670s
	iters: 200, epoch: 22 | loss: 0.2830268
	speed: 0.0125s/iter; left time: 259.6001s
Epoch: 22 cost time: 3.8928656578063965
Epoch: 22, Steps: 265 | Train Loss: 0.3002639 Vali Loss: 0.1564247 Test Loss: 0.2201566
Validation loss decreased (0.156587 --> 0.156425).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4249347
	speed: 0.0658s/iter; left time: 1353.0651s
	iters: 200, epoch: 23 | loss: 0.3158941
	speed: 0.0127s/iter; left time: 260.2252s
Epoch: 23 cost time: 3.7963032722473145
Epoch: 23, Steps: 265 | Train Loss: 0.2998123 Vali Loss: 0.1566285 Test Loss: 0.2200925
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3706312
	speed: 0.0658s/iter; left time: 1337.0242s
	iters: 200, epoch: 24 | loss: 0.3077834
	speed: 0.0127s/iter; left time: 257.1158s
Epoch: 24 cost time: 3.9139254093170166
Epoch: 24, Steps: 265 | Train Loss: 0.3000500 Vali Loss: 0.1566287 Test Loss: 0.2199993
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3304003
	speed: 0.0670s/iter; left time: 1342.2322s
	iters: 200, epoch: 25 | loss: 0.3302454
	speed: 0.0136s/iter; left time: 271.2011s
Epoch: 25 cost time: 4.077983856201172
Epoch: 25, Steps: 265 | Train Loss: 0.2998861 Vali Loss: 0.1565432 Test Loss: 0.2199586
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2461342
	speed: 0.0688s/iter; left time: 1359.7044s
	iters: 200, epoch: 26 | loss: 0.2801018
	speed: 0.0131s/iter; left time: 257.4060s
Epoch: 26 cost time: 4.04643702507019
Epoch: 26, Steps: 265 | Train Loss: 0.2997095 Vali Loss: 0.1565214 Test Loss: 0.2200026
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2907312
	speed: 0.0682s/iter; left time: 1331.0537s
	iters: 200, epoch: 27 | loss: 0.3122669
	speed: 0.0128s/iter; left time: 247.5246s
Epoch: 27 cost time: 3.952240467071533
Epoch: 27, Steps: 265 | Train Loss: 0.2999369 Vali Loss: 0.1565183 Test Loss: 0.2200128
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2923083
	speed: 0.0732s/iter; left time: 1408.7767s
	iters: 200, epoch: 28 | loss: 0.2422091
	speed: 0.0152s/iter; left time: 290.2484s
Epoch: 28 cost time: 4.538997650146484
Epoch: 28, Steps: 265 | Train Loss: 0.2995183 Vali Loss: 0.1564204 Test Loss: 0.2200106
Validation loss decreased (0.156425 --> 0.156420).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2264998
	speed: 0.0717s/iter; left time: 1361.4590s
	iters: 200, epoch: 29 | loss: 0.2866229
	speed: 0.0132s/iter; left time: 249.4094s
Epoch: 29 cost time: 4.0130109786987305
Epoch: 29, Steps: 265 | Train Loss: 0.2996947 Vali Loss: 0.1564751 Test Loss: 0.2199806
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2537587
	speed: 0.0724s/iter; left time: 1354.4425s
	iters: 200, epoch: 30 | loss: 0.2585412
	speed: 0.0152s/iter; left time: 282.1507s
Epoch: 30 cost time: 4.596142053604126
Epoch: 30, Steps: 265 | Train Loss: 0.2999157 Vali Loss: 0.1564287 Test Loss: 0.2199769
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2172507
	speed: 0.0743s/iter; left time: 1370.0723s
	iters: 200, epoch: 31 | loss: 0.4724155
	speed: 0.0152s/iter; left time: 279.3459s
Epoch: 31 cost time: 4.574565172195435
Epoch: 31, Steps: 265 | Train Loss: 0.2998322 Vali Loss: 0.1562753 Test Loss: 0.2199295
Validation loss decreased (0.156420 --> 0.156275).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3165689
	speed: 0.0716s/iter; left time: 1301.5485s
	iters: 200, epoch: 32 | loss: 0.2612839
	speed: 0.0229s/iter; left time: 414.2506s
Epoch: 32 cost time: 6.124886989593506
Epoch: 32, Steps: 265 | Train Loss: 0.2996007 Vali Loss: 0.1564056 Test Loss: 0.2198851
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3181228
	speed: 0.0827s/iter; left time: 1481.3176s
	iters: 200, epoch: 33 | loss: 0.2075337
	speed: 0.0152s/iter; left time: 271.1111s
Epoch: 33 cost time: 4.522061347961426
Epoch: 33, Steps: 265 | Train Loss: 0.2997590 Vali Loss: 0.1562791 Test Loss: 0.2198574
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3371426
	speed: 0.0694s/iter; left time: 1225.5285s
	iters: 200, epoch: 34 | loss: 0.2240370
	speed: 0.0146s/iter; left time: 255.7952s
Epoch: 34 cost time: 4.441495895385742
Epoch: 34, Steps: 265 | Train Loss: 0.2991380 Vali Loss: 0.1562600 Test Loss: 0.2198501
Validation loss decreased (0.156275 --> 0.156260).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3136113
	speed: 0.0662s/iter; left time: 1151.9578s
	iters: 200, epoch: 35 | loss: 0.3223343
	speed: 0.0126s/iter; left time: 217.8298s
Epoch: 35 cost time: 3.7135303020477295
Epoch: 35, Steps: 265 | Train Loss: 0.2995429 Vali Loss: 0.1564313 Test Loss: 0.2198870
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3772191
	speed: 0.0652s/iter; left time: 1116.3262s
	iters: 200, epoch: 36 | loss: 0.2939726
	speed: 0.0126s/iter; left time: 214.8767s
Epoch: 36 cost time: 3.7684826850891113
Epoch: 36, Steps: 265 | Train Loss: 0.2996086 Vali Loss: 0.1563216 Test Loss: 0.2198796
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2840663
	speed: 0.0675s/iter; left time: 1138.3059s
	iters: 200, epoch: 37 | loss: 0.2267857
	speed: 0.0124s/iter; left time: 207.7789s
Epoch: 37 cost time: 3.848151206970215
Epoch: 37, Steps: 265 | Train Loss: 0.2992670 Vali Loss: 0.1563340 Test Loss: 0.2198620
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4797181
	speed: 0.0663s/iter; left time: 1100.5901s
	iters: 200, epoch: 38 | loss: 0.2712461
	speed: 0.0129s/iter; left time: 212.0323s
Epoch: 38 cost time: 3.845583438873291
Epoch: 38, Steps: 265 | Train Loss: 0.2995361 Vali Loss: 0.1564461 Test Loss: 0.2198481
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2701163
	speed: 0.0659s/iter; left time: 1076.6530s
	iters: 200, epoch: 39 | loss: 0.2635473
	speed: 0.0132s/iter; left time: 214.6727s
Epoch: 39 cost time: 4.033296346664429
Epoch: 39, Steps: 265 | Train Loss: 0.2990728 Vali Loss: 0.1564375 Test Loss: 0.2198162
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2664509
	speed: 0.0678s/iter; left time: 1089.3021s
	iters: 200, epoch: 40 | loss: 0.2380943
	speed: 0.0129s/iter; left time: 206.3625s
Epoch: 40 cost time: 3.995802879333496
Epoch: 40, Steps: 265 | Train Loss: 0.2993779 Vali Loss: 0.1563350 Test Loss: 0.2198154
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2647380
	speed: 0.0690s/iter; left time: 1089.8654s
	iters: 200, epoch: 41 | loss: 0.3372553
	speed: 0.0131s/iter; left time: 205.1944s
Epoch: 41 cost time: 4.0824339389801025
Epoch: 41, Steps: 265 | Train Loss: 0.2993746 Vali Loss: 0.1563322 Test Loss: 0.2198036
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2301582
	speed: 0.0680s/iter; left time: 1055.8659s
	iters: 200, epoch: 42 | loss: 0.4859200
	speed: 0.0130s/iter; left time: 200.4572s
Epoch: 42 cost time: 3.858264207839966
Epoch: 42, Steps: 265 | Train Loss: 0.2992687 Vali Loss: 0.1564071 Test Loss: 0.2197956
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2946010
	speed: 0.0676s/iter; left time: 1031.8345s
	iters: 200, epoch: 43 | loss: 0.3938969
	speed: 0.0130s/iter; left time: 197.7085s
Epoch: 43 cost time: 3.9597160816192627
Epoch: 43, Steps: 265 | Train Loss: 0.2994061 Vali Loss: 0.1562893 Test Loss: 0.2197979
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.3540127
	speed: 0.0676s/iter; left time: 1015.0545s
	iters: 200, epoch: 44 | loss: 0.2003530
	speed: 0.0130s/iter; left time: 193.1413s
Epoch: 44 cost time: 3.945786237716675
Epoch: 44, Steps: 265 | Train Loss: 0.2994568 Vali Loss: 0.1563705 Test Loss: 0.2197764
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.4176293
	speed: 0.0671s/iter; left time: 989.8353s
	iters: 200, epoch: 45 | loss: 0.2826495
	speed: 0.0127s/iter; left time: 185.8044s
Epoch: 45 cost time: 3.9268312454223633
Epoch: 45, Steps: 265 | Train Loss: 0.2991506 Vali Loss: 0.1564549 Test Loss: 0.2197816
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2572264
	speed: 0.0666s/iter; left time: 964.1920s
	iters: 200, epoch: 46 | loss: 0.2797381
	speed: 0.0127s/iter; left time: 182.7657s
Epoch: 46 cost time: 3.9946107864379883
Epoch: 46, Steps: 265 | Train Loss: 0.2989291 Vali Loss: 0.1564015 Test Loss: 0.2197743
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2872711
	speed: 0.0671s/iter; left time: 953.3883s
	iters: 200, epoch: 47 | loss: 0.2941309
	speed: 0.0130s/iter; left time: 183.9463s
Epoch: 47 cost time: 3.9257912635803223
Epoch: 47, Steps: 265 | Train Loss: 0.2991576 Vali Loss: 0.1565260 Test Loss: 0.2197684
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.4259256
	speed: 0.0667s/iter; left time: 930.4451s
	iters: 200, epoch: 48 | loss: 0.3402033
	speed: 0.0133s/iter; left time: 183.7557s
Epoch: 48 cost time: 3.9693357944488525
Epoch: 48, Steps: 265 | Train Loss: 0.2988922 Vali Loss: 0.1564149 Test Loss: 0.2197498
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.4057881
	speed: 0.0651s/iter; left time: 890.5774s
	iters: 200, epoch: 49 | loss: 0.3764422
	speed: 0.0131s/iter; left time: 177.7027s
Epoch: 49 cost time: 3.8680241107940674
Epoch: 49, Steps: 265 | Train Loss: 0.2992919 Vali Loss: 0.1563686 Test Loss: 0.2197398
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.3164285
	speed: 0.0664s/iter; left time: 890.5023s
	iters: 200, epoch: 50 | loss: 0.3648184
	speed: 0.0134s/iter; left time: 179.0519s
Epoch: 50 cost time: 3.965440034866333
Epoch: 50, Steps: 265 | Train Loss: 0.2986671 Vali Loss: 0.1563653 Test Loss: 0.2197310
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2779899
	speed: 0.0686s/iter; left time: 902.6740s
	iters: 200, epoch: 51 | loss: 0.3683880
	speed: 0.0130s/iter; left time: 169.9501s
Epoch: 51 cost time: 4.064834117889404
Epoch: 51, Steps: 265 | Train Loss: 0.2990440 Vali Loss: 0.1565086 Test Loss: 0.2197351
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.3417657
	speed: 0.0689s/iter; left time: 888.3118s
	iters: 200, epoch: 52 | loss: 0.2730817
	speed: 0.0126s/iter; left time: 161.2788s
Epoch: 52 cost time: 3.9320948123931885
Epoch: 52, Steps: 265 | Train Loss: 0.2990816 Vali Loss: 0.1563105 Test Loss: 0.2197489
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2518566
	speed: 0.0660s/iter; left time: 832.5233s
	iters: 200, epoch: 53 | loss: 0.3613038
	speed: 0.0127s/iter; left time: 158.6669s
Epoch: 53 cost time: 3.894742012023926
Epoch: 53, Steps: 265 | Train Loss: 0.2991185 Vali Loss: 0.1563543 Test Loss: 0.2197436
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2259903
	speed: 0.0682s/iter; left time: 843.2457s
	iters: 200, epoch: 54 | loss: 0.2405079
	speed: 0.0152s/iter; left time: 185.9819s
Epoch: 54 cost time: 4.3150954246521
Epoch: 54, Steps: 265 | Train Loss: 0.2993399 Vali Loss: 0.1564231 Test Loss: 0.2197441
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_360_192_FITS_ETTm2_ftM_sl360_ll48_pl192_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.22059646248817444, mae:0.29197970032691956, rse:0.38018447160720825, corr:[0.5575158  0.56373686 0.5637008  0.56109303 0.55911654 0.5586315
 0.559336   0.5602176  0.560414   0.55975807 0.5586416  0.5577422
 0.5574591  0.55775666 0.5583386  0.5587109  0.55855995 0.55778474
 0.5566594  0.5555633  0.5548377  0.5546003  0.5546646  0.5547904
 0.5546892  0.5541986  0.55342716 0.5526115  0.5519814  0.55159944
 0.55142987 0.55136126 0.5511884  0.5507823  0.5501291  0.54935044
 0.54859614 0.5479681  0.547535   0.54723257 0.5469492  0.546594
 0.5460654  0.54535306 0.544545   0.543713   0.54298127 0.5423742
 0.5418069  0.5412211  0.54051524 0.5397445  0.53889835 0.53800786
 0.53715444 0.5364531  0.53591025 0.5355092  0.5352154  0.5349573
 0.53466654 0.5343484  0.534032   0.53374743 0.5335009  0.53332764
 0.53318715 0.5330369  0.5328893  0.53275704 0.53260225 0.53242016
 0.53220356 0.53197604 0.5317138  0.5313526  0.5309095  0.5303785
 0.5298133  0.5292498  0.52876294 0.52830297 0.5278597  0.52736044
 0.5268134  0.5262897  0.5257484  0.5252785  0.5248962  0.524571
 0.5242522  0.5238767  0.523281   0.52241117 0.5212728  0.5198846
 0.5183291  0.516815   0.5154483  0.51418984 0.5129776  0.5118044
 0.5106823  0.50954926 0.5083306  0.50711125 0.505995   0.50508624
 0.50436634 0.5037274  0.50311947 0.50245816 0.50173813 0.5009293
 0.5000922  0.49931464 0.49864927 0.49807653 0.4976228  0.49716344
 0.4966099  0.49585766 0.4950323  0.49420506 0.49344096 0.4927843
 0.49220893 0.4916031  0.49085855 0.48993987 0.48893988 0.48795754
 0.48713169 0.4865652  0.4862054  0.48595348 0.48554605 0.48500934
 0.48425975 0.48339465 0.48255283 0.48183772 0.48130023 0.48079196
 0.48015535 0.47928476 0.47822988 0.4770978  0.47603974 0.47515666
 0.47460264 0.4743338  0.4740957  0.4736773  0.47298393 0.47214285
 0.47127277 0.4705822  0.47013697 0.47004795 0.47002742 0.46984923
 0.46941888 0.46873146 0.4680357  0.46758276 0.46739054 0.46757305
 0.46786326 0.4680385  0.4678881  0.46732485 0.46644554 0.46555758
 0.46502528 0.46497893 0.4651902  0.4652652  0.46491155 0.4640578
 0.46275154 0.4613345  0.4605313  0.4605121  0.46081927 0.4608561
 0.46023834 0.4590096  0.45751342 0.45699543 0.45899904 0.4607356 ]
