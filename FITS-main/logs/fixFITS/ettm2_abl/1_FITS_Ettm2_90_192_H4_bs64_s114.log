Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=14, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_90_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_90_192_FITS_ETTm2_ftM_sl90_ll48_pl192_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34279
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=14, out_features=43, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  539392.0
params:  645.0
Trainable parameters:  645
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4060525
	speed: 0.0640s/iter; left time: 1702.4347s
	iters: 200, epoch: 1 | loss: 0.4067957
	speed: 0.0510s/iter; left time: 1352.4118s
Epoch: 1 cost time: 15.264337539672852
Epoch: 1, Steps: 267 | Train Loss: 0.4159040 Vali Loss: 0.1911889 Test Loss: 0.2710984
Validation loss decreased (inf --> 0.191189).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4029224
	speed: 0.2128s/iter; left time: 5603.3646s
	iters: 200, epoch: 2 | loss: 0.4053329
	speed: 0.0417s/iter; left time: 1093.1163s
Epoch: 2 cost time: 12.760226011276245
Epoch: 2, Steps: 267 | Train Loss: 0.3573414 Vali Loss: 0.1771517 Test Loss: 0.2544079
Validation loss decreased (0.191189 --> 0.177152).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3533984
	speed: 0.2772s/iter; left time: 7226.1859s
	iters: 200, epoch: 3 | loss: 0.3219186
	speed: 0.0598s/iter; left time: 1553.0512s
Epoch: 3 cost time: 16.88277006149292
Epoch: 3, Steps: 267 | Train Loss: 0.3468699 Vali Loss: 0.1745228 Test Loss: 0.2513740
Validation loss decreased (0.177152 --> 0.174523).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2766940
	speed: 0.2601s/iter; left time: 6709.8114s
	iters: 200, epoch: 4 | loss: 0.4578842
	speed: 0.0511s/iter; left time: 1314.0978s
Epoch: 4 cost time: 14.388759851455688
Epoch: 4, Steps: 267 | Train Loss: 0.3439493 Vali Loss: 0.1740442 Test Loss: 0.2502046
Validation loss decreased (0.174523 --> 0.174044).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2819712
	speed: 0.1911s/iter; left time: 4880.3587s
	iters: 200, epoch: 5 | loss: 0.4693466
	speed: 0.0424s/iter; left time: 1078.0238s
Epoch: 5 cost time: 11.68425703048706
Epoch: 5, Steps: 267 | Train Loss: 0.3420989 Vali Loss: 0.1735854 Test Loss: 0.2496482
Validation loss decreased (0.174044 --> 0.173585).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3615298
	speed: 0.2444s/iter; left time: 6173.8822s
	iters: 200, epoch: 6 | loss: 0.3275707
	speed: 0.0482s/iter; left time: 1213.4300s
Epoch: 6 cost time: 12.955344200134277
Epoch: 6, Steps: 267 | Train Loss: 0.3401121 Vali Loss: 0.1733878 Test Loss: 0.2491589
Validation loss decreased (0.173585 --> 0.173388).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4442629
	speed: 0.2571s/iter; left time: 6426.0553s
	iters: 200, epoch: 7 | loss: 0.3059437
	speed: 0.0619s/iter; left time: 1542.3788s
Epoch: 7 cost time: 17.42559051513672
Epoch: 7, Steps: 267 | Train Loss: 0.3401387 Vali Loss: 0.1733668 Test Loss: 0.2489448
Validation loss decreased (0.173388 --> 0.173367).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3904038
	speed: 0.2676s/iter; left time: 6617.3449s
	iters: 200, epoch: 8 | loss: 0.3859407
	speed: 0.0583s/iter; left time: 1436.0722s
Epoch: 8 cost time: 16.06940531730652
Epoch: 8, Steps: 267 | Train Loss: 0.3392656 Vali Loss: 0.1733811 Test Loss: 0.2488562
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3114320
	speed: 0.2235s/iter; left time: 5468.6394s
	iters: 200, epoch: 9 | loss: 0.3074690
	speed: 0.0548s/iter; left time: 1334.3625s
Epoch: 9 cost time: 13.952228784561157
Epoch: 9, Steps: 267 | Train Loss: 0.3390968 Vali Loss: 0.1735344 Test Loss: 0.2487077
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3139223
	speed: 0.2258s/iter; left time: 5463.9091s
	iters: 200, epoch: 10 | loss: 0.4322695
	speed: 0.0563s/iter; left time: 1356.6470s
Epoch: 10 cost time: 14.855159282684326
Epoch: 10, Steps: 267 | Train Loss: 0.3388861 Vali Loss: 0.1733618 Test Loss: 0.2486414
Validation loss decreased (0.173367 --> 0.173362).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3820960
	speed: 0.2290s/iter; left time: 5479.1246s
	iters: 200, epoch: 11 | loss: 0.2825725
	speed: 0.0530s/iter; left time: 1261.8649s
Epoch: 11 cost time: 15.793479442596436
Epoch: 11, Steps: 267 | Train Loss: 0.3384970 Vali Loss: 0.1733294 Test Loss: 0.2485687
Validation loss decreased (0.173362 --> 0.173329).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4336551
	speed: 0.2779s/iter; left time: 6575.3851s
	iters: 200, epoch: 12 | loss: 0.2997522
	speed: 0.0623s/iter; left time: 1467.8893s
Epoch: 12 cost time: 17.36787462234497
Epoch: 12, Steps: 267 | Train Loss: 0.3379608 Vali Loss: 0.1734546 Test Loss: 0.2486535
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4061306
	speed: 0.2297s/iter; left time: 5374.1276s
	iters: 200, epoch: 13 | loss: 0.3265869
	speed: 0.0362s/iter; left time: 844.1099s
Epoch: 13 cost time: 12.528967142105103
Epoch: 13, Steps: 267 | Train Loss: 0.3376070 Vali Loss: 0.1735416 Test Loss: 0.2486542
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2230277
	speed: 0.1905s/iter; left time: 4406.9013s
	iters: 200, epoch: 14 | loss: 0.2424271
	speed: 0.0580s/iter; left time: 1335.7717s
Epoch: 14 cost time: 14.9958176612854
Epoch: 14, Steps: 267 | Train Loss: 0.3380571 Vali Loss: 0.1736799 Test Loss: 0.2485810
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2490300
	speed: 0.1678s/iter; left time: 3836.3225s
	iters: 200, epoch: 15 | loss: 0.4584754
	speed: 0.0529s/iter; left time: 1204.7514s
Epoch: 15 cost time: 14.349023818969727
Epoch: 15, Steps: 267 | Train Loss: 0.3377785 Vali Loss: 0.1733458 Test Loss: 0.2485544
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3117303
	speed: 0.2621s/iter; left time: 5923.0964s
	iters: 200, epoch: 16 | loss: 0.3661887
	speed: 0.0587s/iter; left time: 1319.6697s
Epoch: 16 cost time: 16.917447090148926
Epoch: 16, Steps: 267 | Train Loss: 0.3377597 Vali Loss: 0.1738203 Test Loss: 0.2486157
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2570945
	speed: 0.2424s/iter; left time: 5413.5618s
	iters: 200, epoch: 17 | loss: 0.4510167
	speed: 0.0583s/iter; left time: 1295.7796s
Epoch: 17 cost time: 15.947200059890747
Epoch: 17, Steps: 267 | Train Loss: 0.3380468 Vali Loss: 0.1738153 Test Loss: 0.2486199
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3622883
	speed: 0.2181s/iter; left time: 4810.6228s
	iters: 200, epoch: 18 | loss: 0.3753806
	speed: 0.0610s/iter; left time: 1338.6761s
Epoch: 18 cost time: 16.232649087905884
Epoch: 18, Steps: 267 | Train Loss: 0.3380870 Vali Loss: 0.1738431 Test Loss: 0.2486152
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2764753
	speed: 0.3250s/iter; left time: 7083.1009s
	iters: 200, epoch: 19 | loss: 0.3805524
	speed: 0.0712s/iter; left time: 1544.3131s
Epoch: 19 cost time: 19.572691679000854
Epoch: 19, Steps: 267 | Train Loss: 0.3378326 Vali Loss: 0.1738840 Test Loss: 0.2486560
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2897654
	speed: 0.3212s/iter; left time: 6915.2215s
	iters: 200, epoch: 20 | loss: 0.2957067
	speed: 0.0717s/iter; left time: 1535.8640s
Epoch: 20 cost time: 19.90580129623413
Epoch: 20, Steps: 267 | Train Loss: 0.3376094 Vali Loss: 0.1737990 Test Loss: 0.2486015
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2863526
	speed: 0.3242s/iter; left time: 6893.2821s
	iters: 200, epoch: 21 | loss: 0.2824804
	speed: 0.0712s/iter; left time: 1505.8082s
Epoch: 21 cost time: 19.696224689483643
Epoch: 21, Steps: 267 | Train Loss: 0.3377335 Vali Loss: 0.1739346 Test Loss: 0.2486243
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3635992
	speed: 0.3233s/iter; left time: 6786.5621s
	iters: 200, epoch: 22 | loss: 0.2583058
	speed: 0.0715s/iter; left time: 1493.5861s
Epoch: 22 cost time: 19.782910585403442
Epoch: 22, Steps: 267 | Train Loss: 0.3367112 Vali Loss: 0.1739188 Test Loss: 0.2485792
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3575653
	speed: 0.3239s/iter; left time: 6712.7888s
	iters: 200, epoch: 23 | loss: 0.3126969
	speed: 0.0675s/iter; left time: 1391.5476s
Epoch: 23 cost time: 19.03579831123352
Epoch: 23, Steps: 267 | Train Loss: 0.3378457 Vali Loss: 0.1735860 Test Loss: 0.2485958
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4193034
	speed: 0.3194s/iter; left time: 6534.5733s
	iters: 200, epoch: 24 | loss: 0.4565877
	speed: 0.0707s/iter; left time: 1440.3975s
Epoch: 24 cost time: 19.591962814331055
Epoch: 24, Steps: 267 | Train Loss: 0.3378319 Vali Loss: 0.1736521 Test Loss: 0.2485922
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4209351
	speed: 0.3189s/iter; left time: 6439.2049s
	iters: 200, epoch: 25 | loss: 0.4085436
	speed: 0.0724s/iter; left time: 1454.8924s
Epoch: 25 cost time: 19.656726837158203
Epoch: 25, Steps: 267 | Train Loss: 0.3374744 Vali Loss: 0.1736593 Test Loss: 0.2486025
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.5368496
	speed: 0.3165s/iter; left time: 6307.3294s
	iters: 200, epoch: 26 | loss: 0.2412395
	speed: 0.0709s/iter; left time: 1406.6380s
Epoch: 26 cost time: 19.454757690429688
Epoch: 26, Steps: 267 | Train Loss: 0.3373955 Vali Loss: 0.1737683 Test Loss: 0.2486029
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4306442
	speed: 0.3214s/iter; left time: 6318.6613s
	iters: 200, epoch: 27 | loss: 0.3099390
	speed: 0.0711s/iter; left time: 1389.9558s
Epoch: 27 cost time: 19.951266050338745
Epoch: 27, Steps: 267 | Train Loss: 0.3374774 Vali Loss: 0.1738917 Test Loss: 0.2486468
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3008530
	speed: 0.3191s/iter; left time: 6188.9522s
	iters: 200, epoch: 28 | loss: 0.2614785
	speed: 0.0713s/iter; left time: 1376.1975s
Epoch: 28 cost time: 19.668362855911255
Epoch: 28, Steps: 267 | Train Loss: 0.3372016 Vali Loss: 0.1739687 Test Loss: 0.2486133
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2882778
	speed: 0.3188s/iter; left time: 6096.9674s
	iters: 200, epoch: 29 | loss: 0.4497746
	speed: 0.0708s/iter; left time: 1346.8217s
Epoch: 29 cost time: 19.596954584121704
Epoch: 29, Steps: 267 | Train Loss: 0.3373410 Vali Loss: 0.1739536 Test Loss: 0.2486300
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3502585
	speed: 0.3269s/iter; left time: 6164.2114s
	iters: 200, epoch: 30 | loss: 0.3114116
	speed: 0.0692s/iter; left time: 1298.2607s
Epoch: 30 cost time: 19.555509090423584
Epoch: 30, Steps: 267 | Train Loss: 0.3376802 Vali Loss: 0.1737399 Test Loss: 0.2485931
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2973064
	speed: 0.3173s/iter; left time: 5899.0493s
	iters: 200, epoch: 31 | loss: 0.2025113
	speed: 0.0714s/iter; left time: 1319.4153s
Epoch: 31 cost time: 19.730982303619385
Epoch: 31, Steps: 267 | Train Loss: 0.3375813 Vali Loss: 0.1739183 Test Loss: 0.2486308
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_90_192_FITS_ETTm2_ftM_sl90_ll48_pl192_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.2494044154882431, mae:0.3074658215045929, rse:0.40424734354019165, corr:[0.5622536  0.5672599  0.5636696  0.55814946 0.5551319  0.55518585
 0.5560969  0.55575013 0.5540014  0.5519826  0.5508012  0.55068547
 0.55094934 0.55071557 0.5496447  0.54806036 0.5466456  0.5458219
 0.5454613  0.54503196 0.5441859  0.54298806 0.5418194  0.54111636
 0.54093665 0.5409064  0.54065645 0.53999996 0.539046   0.53814846
 0.5375343  0.537181   0.53684396 0.5363596  0.5356659  0.5348975
 0.5341407  0.5334201  0.53272957 0.53205067 0.5314344  0.5309992
 0.53075796 0.5306026  0.53036815 0.52988553 0.5291466  0.52816963
 0.5271354  0.5262541  0.52559835 0.52511907 0.5246416  0.5240252
 0.5233393  0.5226898  0.52214754 0.52177393 0.52153134 0.52139103
 0.52124816 0.5210777  0.5209274  0.52090174 0.5209186  0.5209053
 0.5208215  0.5206674  0.52055085 0.5205288  0.52060807 0.5207601
 0.5208917  0.5209681  0.5209169  0.52077085 0.52061456 0.5204401
 0.5202644  0.5200823  0.51989776 0.51968896 0.51946646 0.5192039
 0.5188884  0.5185636  0.5182513  0.51802945 0.51788    0.5177034
 0.51738954 0.51684684 0.51605093 0.5150886  0.51396304 0.5125633
 0.5107745  0.50868505 0.5065455  0.5045786  0.5029183  0.50157285
 0.50039905 0.4991067  0.49761882 0.49609974 0.49469942 0.49345148
 0.49229613 0.49118647 0.49005684 0.48876575 0.48735115 0.48588428
 0.48447207 0.48322496 0.4821599  0.48117915 0.4801828  0.47902334
 0.47781426 0.4766958  0.47575834 0.47494346 0.47412708 0.47321174
 0.47219175 0.4711505  0.4700973  0.4690803  0.46816126 0.46728054
 0.46637905 0.4654392  0.46449077 0.4637968  0.4633303  0.46315455
 0.46307096 0.46288112 0.46249107 0.4619103  0.46124998 0.4605863
 0.45988715 0.45912746 0.45822656 0.45728934 0.45639643 0.45561698
 0.45499766 0.4546603  0.45436063 0.45379615 0.45301396 0.45227665
 0.45179728 0.45177385 0.4519363  0.45209074 0.45195228 0.45145884
 0.45091853 0.4504624  0.4504678  0.45078576 0.45111057 0.45124042
 0.45120692 0.45121711 0.45143017 0.45183158 0.45222583 0.45235926
 0.45215982 0.4518031  0.45160997 0.45187843 0.45254302 0.45330667
 0.453788   0.45371798 0.45335853 0.4529942  0.45298302 0.45335352
 0.45386264 0.454318   0.4545197  0.45455348 0.4543888  0.45340544]
