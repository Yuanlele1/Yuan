Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=50, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_360_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_360_720_FITS_ETTm2_ftM_sl360_ll48_pl720_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33481
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=50, out_features=150, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6720000.0
params:  7650.0
Trainable parameters:  7650
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4730231
	speed: 0.0219s/iter; left time: 569.9790s
	iters: 200, epoch: 1 | loss: 0.3930831
	speed: 0.0245s/iter; left time: 635.0381s
Epoch: 1 cost time: 5.872171878814697
Epoch: 1, Steps: 261 | Train Loss: 0.5002225 Vali Loss: 0.3002162 Test Loss: 0.4089941
Validation loss decreased (inf --> 0.300216).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4145159
	speed: 0.0784s/iter; left time: 2019.2704s
	iters: 200, epoch: 2 | loss: 0.3582788
	speed: 0.0159s/iter; left time: 408.5549s
Epoch: 2 cost time: 4.619859218597412
Epoch: 2, Steps: 261 | Train Loss: 0.3943265 Vali Loss: 0.2821938 Test Loss: 0.3867411
Validation loss decreased (0.300216 --> 0.282194).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3663144
	speed: 0.0765s/iter; left time: 1948.8813s
	iters: 200, epoch: 3 | loss: 0.4094813
	speed: 0.0157s/iter; left time: 398.6116s
Epoch: 3 cost time: 4.600382566452026
Epoch: 3, Steps: 261 | Train Loss: 0.3730426 Vali Loss: 0.2754825 Test Loss: 0.3792814
Validation loss decreased (0.282194 --> 0.275482).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3272285
	speed: 0.0753s/iter; left time: 1899.2366s
	iters: 200, epoch: 4 | loss: 0.3844917
	speed: 0.0157s/iter; left time: 395.4669s
Epoch: 4 cost time: 4.5681304931640625
Epoch: 4, Steps: 261 | Train Loss: 0.3641484 Vali Loss: 0.2721715 Test Loss: 0.3752246
Validation loss decreased (0.275482 --> 0.272172).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3254957
	speed: 0.0755s/iter; left time: 1884.2659s
	iters: 200, epoch: 5 | loss: 0.3878813
	speed: 0.0159s/iter; left time: 395.3594s
Epoch: 5 cost time: 4.651047945022583
Epoch: 5, Steps: 261 | Train Loss: 0.3596695 Vali Loss: 0.2699429 Test Loss: 0.3731191
Validation loss decreased (0.272172 --> 0.269943).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3642883
	speed: 0.0760s/iter; left time: 1876.3492s
	iters: 200, epoch: 6 | loss: 0.3897413
	speed: 0.0160s/iter; left time: 393.7704s
Epoch: 6 cost time: 4.606021404266357
Epoch: 6, Steps: 261 | Train Loss: 0.3566331 Vali Loss: 0.2687802 Test Loss: 0.3718308
Validation loss decreased (0.269943 --> 0.268780).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2398784
	speed: 0.0758s/iter; left time: 1852.2995s
	iters: 200, epoch: 7 | loss: 0.2904111
	speed: 0.0157s/iter; left time: 382.6784s
Epoch: 7 cost time: 4.579248905181885
Epoch: 7, Steps: 261 | Train Loss: 0.3549248 Vali Loss: 0.2678195 Test Loss: 0.3710123
Validation loss decreased (0.268780 --> 0.267819).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2859097
	speed: 0.0770s/iter; left time: 1862.2312s
	iters: 200, epoch: 8 | loss: 0.2880350
	speed: 0.0162s/iter; left time: 390.3223s
Epoch: 8 cost time: 4.727024078369141
Epoch: 8, Steps: 261 | Train Loss: 0.3537120 Vali Loss: 0.2672895 Test Loss: 0.3706160
Validation loss decreased (0.267819 --> 0.267289).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3247723
	speed: 0.0869s/iter; left time: 2077.2020s
	iters: 200, epoch: 9 | loss: 0.3676430
	speed: 0.0164s/iter; left time: 389.5712s
Epoch: 9 cost time: 5.659002065658569
Epoch: 9, Steps: 261 | Train Loss: 0.3532371 Vali Loss: 0.2666792 Test Loss: 0.3703166
Validation loss decreased (0.267289 --> 0.266679).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3214599
	speed: 0.0757s/iter; left time: 1789.4898s
	iters: 200, epoch: 10 | loss: 0.4638582
	speed: 0.0155s/iter; left time: 364.6120s
Epoch: 10 cost time: 4.535719394683838
Epoch: 10, Steps: 261 | Train Loss: 0.3527085 Vali Loss: 0.2661583 Test Loss: 0.3701002
Validation loss decreased (0.266679 --> 0.266158).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4106272
	speed: 0.0781s/iter; left time: 1826.6066s
	iters: 200, epoch: 11 | loss: 0.2953221
	speed: 0.0165s/iter; left time: 384.7971s
Epoch: 11 cost time: 4.983137369155884
Epoch: 11, Steps: 261 | Train Loss: 0.3520833 Vali Loss: 0.2658131 Test Loss: 0.3699284
Validation loss decreased (0.266158 --> 0.265813).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3360486
	speed: 0.0806s/iter; left time: 1864.9432s
	iters: 200, epoch: 12 | loss: 0.3905582
	speed: 0.0167s/iter; left time: 383.7476s
Epoch: 12 cost time: 4.858070135116577
Epoch: 12, Steps: 261 | Train Loss: 0.3519789 Vali Loss: 0.2655974 Test Loss: 0.3698191
Validation loss decreased (0.265813 --> 0.265597).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4122096
	speed: 0.0842s/iter; left time: 1925.0022s
	iters: 200, epoch: 13 | loss: 0.3499926
	speed: 0.0168s/iter; left time: 382.9532s
Epoch: 13 cost time: 5.034154176712036
Epoch: 13, Steps: 261 | Train Loss: 0.3517535 Vali Loss: 0.2656730 Test Loss: 0.3697847
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2741942
	speed: 0.0812s/iter; left time: 1836.3677s
	iters: 200, epoch: 14 | loss: 0.4461589
	speed: 0.0159s/iter; left time: 357.6510s
Epoch: 14 cost time: 4.866879940032959
Epoch: 14, Steps: 261 | Train Loss: 0.3514773 Vali Loss: 0.2653591 Test Loss: 0.3696577
Validation loss decreased (0.265597 --> 0.265359).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2884571
	speed: 0.0884s/iter; left time: 1974.7837s
	iters: 200, epoch: 15 | loss: 0.3808312
	speed: 0.0170s/iter; left time: 379.2856s
Epoch: 15 cost time: 5.827529191970825
Epoch: 15, Steps: 261 | Train Loss: 0.3511963 Vali Loss: 0.2652106 Test Loss: 0.3697158
Validation loss decreased (0.265359 --> 0.265211).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3829425
	speed: 0.0754s/iter; left time: 1665.3997s
	iters: 200, epoch: 16 | loss: 0.3149110
	speed: 0.0155s/iter; left time: 340.6339s
Epoch: 16 cost time: 4.5918684005737305
Epoch: 16, Steps: 261 | Train Loss: 0.3509974 Vali Loss: 0.2651992 Test Loss: 0.3695921
Validation loss decreased (0.265211 --> 0.265199).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3071353
	speed: 0.0762s/iter; left time: 1664.0465s
	iters: 200, epoch: 17 | loss: 0.2959130
	speed: 0.0159s/iter; left time: 344.8090s
Epoch: 17 cost time: 4.753537654876709
Epoch: 17, Steps: 261 | Train Loss: 0.3511548 Vali Loss: 0.2649626 Test Loss: 0.3696112
Validation loss decreased (0.265199 --> 0.264963).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3663093
	speed: 0.0766s/iter; left time: 1651.9949s
	iters: 200, epoch: 18 | loss: 0.3199225
	speed: 0.0157s/iter; left time: 336.7466s
Epoch: 18 cost time: 4.601323127746582
Epoch: 18, Steps: 261 | Train Loss: 0.3511430 Vali Loss: 0.2651531 Test Loss: 0.3695489
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3209455
	speed: 0.0761s/iter; left time: 1621.0524s
	iters: 200, epoch: 19 | loss: 0.2784865
	speed: 0.0157s/iter; left time: 333.8438s
Epoch: 19 cost time: 4.667220115661621
Epoch: 19, Steps: 261 | Train Loss: 0.3508447 Vali Loss: 0.2648525 Test Loss: 0.3695347
Validation loss decreased (0.264963 --> 0.264852).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2949760
	speed: 0.0749s/iter; left time: 1576.6375s
	iters: 200, epoch: 20 | loss: 0.4167678
	speed: 0.0158s/iter; left time: 331.0230s
Epoch: 20 cost time: 4.600883722305298
Epoch: 20, Steps: 261 | Train Loss: 0.3507445 Vali Loss: 0.2646312 Test Loss: 0.3695668
Validation loss decreased (0.264852 --> 0.264631).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3248919
	speed: 0.0757s/iter; left time: 1573.5080s
	iters: 200, epoch: 21 | loss: 0.3128929
	speed: 0.0160s/iter; left time: 330.0121s
Epoch: 21 cost time: 4.669739723205566
Epoch: 21, Steps: 261 | Train Loss: 0.3507752 Vali Loss: 0.2646267 Test Loss: 0.3695303
Validation loss decreased (0.264631 --> 0.264627).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2664819
	speed: 0.0759s/iter; left time: 1557.5609s
	iters: 200, epoch: 22 | loss: 0.2507195
	speed: 0.0157s/iter; left time: 320.2893s
Epoch: 22 cost time: 4.649486064910889
Epoch: 22, Steps: 261 | Train Loss: 0.3508747 Vali Loss: 0.2647262 Test Loss: 0.3695078
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3539836
	speed: 0.0770s/iter; left time: 1559.0818s
	iters: 200, epoch: 23 | loss: 0.3132071
	speed: 0.0155s/iter; left time: 312.3814s
Epoch: 23 cost time: 4.659477472305298
Epoch: 23, Steps: 261 | Train Loss: 0.3509199 Vali Loss: 0.2647039 Test Loss: 0.3695551
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2588001
	speed: 0.0770s/iter; left time: 1539.3196s
	iters: 200, epoch: 24 | loss: 0.3663010
	speed: 0.0180s/iter; left time: 357.3047s
Epoch: 24 cost time: 4.86970329284668
Epoch: 24, Steps: 261 | Train Loss: 0.3509769 Vali Loss: 0.2645707 Test Loss: 0.3695062
Validation loss decreased (0.264627 --> 0.264571).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3116816
	speed: 0.0816s/iter; left time: 1609.7905s
	iters: 200, epoch: 25 | loss: 0.3047941
	speed: 0.0164s/iter; left time: 323.0018s
Epoch: 25 cost time: 4.890322685241699
Epoch: 25, Steps: 261 | Train Loss: 0.3507903 Vali Loss: 0.2646638 Test Loss: 0.3694559
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3551407
	speed: 0.0779s/iter; left time: 1516.6732s
	iters: 200, epoch: 26 | loss: 0.4502142
	speed: 0.0157s/iter; left time: 304.2565s
Epoch: 26 cost time: 4.814057111740112
Epoch: 26, Steps: 261 | Train Loss: 0.3508196 Vali Loss: 0.2648945 Test Loss: 0.3694713
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3145049
	speed: 0.0804s/iter; left time: 1545.0587s
	iters: 200, epoch: 27 | loss: 0.3470617
	speed: 0.0162s/iter; left time: 310.2604s
Epoch: 27 cost time: 4.96756386756897
Epoch: 27, Steps: 261 | Train Loss: 0.3506054 Vali Loss: 0.2645102 Test Loss: 0.3694785
Validation loss decreased (0.264571 --> 0.264510).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3252697
	speed: 0.0762s/iter; left time: 1445.0299s
	iters: 200, epoch: 28 | loss: 0.2923576
	speed: 0.0153s/iter; left time: 288.9177s
Epoch: 28 cost time: 4.614595174789429
Epoch: 28, Steps: 261 | Train Loss: 0.3507214 Vali Loss: 0.2645712 Test Loss: 0.3694680
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4211076
	speed: 0.0759s/iter; left time: 1419.0804s
	iters: 200, epoch: 29 | loss: 0.3293533
	speed: 0.0153s/iter; left time: 284.4950s
Epoch: 29 cost time: 4.536241054534912
Epoch: 29, Steps: 261 | Train Loss: 0.3509299 Vali Loss: 0.2645324 Test Loss: 0.3694738
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2938640
	speed: 0.0817s/iter; left time: 1505.2620s
	iters: 200, epoch: 30 | loss: 0.2931321
	speed: 0.0202s/iter; left time: 369.9883s
Epoch: 30 cost time: 5.3655619621276855
Epoch: 30, Steps: 261 | Train Loss: 0.3507342 Vali Loss: 0.2646653 Test Loss: 0.3694792
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3504218
	speed: 0.0766s/iter; left time: 1391.7637s
	iters: 200, epoch: 31 | loss: 0.3572930
	speed: 0.0154s/iter; left time: 279.0999s
Epoch: 31 cost time: 4.632242202758789
Epoch: 31, Steps: 261 | Train Loss: 0.3504788 Vali Loss: 0.2644951 Test Loss: 0.3694628
Validation loss decreased (0.264510 --> 0.264495).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3857470
	speed: 0.0803s/iter; left time: 1437.6878s
	iters: 200, epoch: 32 | loss: 0.3444158
	speed: 0.0178s/iter; left time: 317.7416s
Epoch: 32 cost time: 4.9067957401275635
Epoch: 32, Steps: 261 | Train Loss: 0.3506511 Vali Loss: 0.2646845 Test Loss: 0.3694493
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3666454
	speed: 0.0735s/iter; left time: 1297.0345s
	iters: 200, epoch: 33 | loss: 0.2847601
	speed: 0.0164s/iter; left time: 287.3266s
Epoch: 33 cost time: 4.734542369842529
Epoch: 33, Steps: 261 | Train Loss: 0.3503827 Vali Loss: 0.2645454 Test Loss: 0.3694566
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2848398
	speed: 0.0793s/iter; left time: 1378.8537s
	iters: 200, epoch: 34 | loss: 0.4161393
	speed: 0.0154s/iter; left time: 266.8191s
Epoch: 34 cost time: 4.74219012260437
Epoch: 34, Steps: 261 | Train Loss: 0.3503747 Vali Loss: 0.2645353 Test Loss: 0.3694473
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3730288
	speed: 0.0763s/iter; left time: 1307.1595s
	iters: 200, epoch: 35 | loss: 0.2564946
	speed: 0.0160s/iter; left time: 271.9082s
Epoch: 35 cost time: 4.725918292999268
Epoch: 35, Steps: 261 | Train Loss: 0.3505127 Vali Loss: 0.2646725 Test Loss: 0.3694363
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2647933
	speed: 0.0739s/iter; left time: 1247.1548s
	iters: 200, epoch: 36 | loss: 0.2427353
	speed: 0.0151s/iter; left time: 253.2704s
Epoch: 36 cost time: 4.492504596710205
Epoch: 36, Steps: 261 | Train Loss: 0.3505256 Vali Loss: 0.2643177 Test Loss: 0.3694449
Validation loss decreased (0.264495 --> 0.264318).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3146204
	speed: 0.0755s/iter; left time: 1252.8848s
	iters: 200, epoch: 37 | loss: 0.3422014
	speed: 0.0157s/iter; left time: 258.9358s
Epoch: 37 cost time: 4.661010503768921
Epoch: 37, Steps: 261 | Train Loss: 0.3509307 Vali Loss: 0.2643784 Test Loss: 0.3694451
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4521650
	speed: 0.0759s/iter; left time: 1240.1620s
	iters: 200, epoch: 38 | loss: 0.3260486
	speed: 0.0154s/iter; left time: 249.9509s
Epoch: 38 cost time: 4.5602052211761475
Epoch: 38, Steps: 261 | Train Loss: 0.3504140 Vali Loss: 0.2647607 Test Loss: 0.3694460
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.5325729
	speed: 0.0768s/iter; left time: 1235.4636s
	iters: 200, epoch: 39 | loss: 0.4449634
	speed: 0.0156s/iter; left time: 249.8179s
Epoch: 39 cost time: 4.6845338344573975
Epoch: 39, Steps: 261 | Train Loss: 0.3504571 Vali Loss: 0.2645969 Test Loss: 0.3694255
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2511811
	speed: 0.0749s/iter; left time: 1184.8127s
	iters: 200, epoch: 40 | loss: 0.3555935
	speed: 0.0155s/iter; left time: 243.9984s
Epoch: 40 cost time: 4.59099006652832
Epoch: 40, Steps: 261 | Train Loss: 0.3506480 Vali Loss: 0.2644287 Test Loss: 0.3694317
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3668714
	speed: 0.0764s/iter; left time: 1188.1399s
	iters: 200, epoch: 41 | loss: 0.3102112
	speed: 0.0157s/iter; left time: 242.7027s
Epoch: 41 cost time: 4.710723876953125
Epoch: 41, Steps: 261 | Train Loss: 0.3500502 Vali Loss: 0.2648186 Test Loss: 0.3694229
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3560505
	speed: 0.0770s/iter; left time: 1177.3499s
	iters: 200, epoch: 42 | loss: 0.2791753
	speed: 0.0156s/iter; left time: 236.8824s
Epoch: 42 cost time: 4.572643280029297
Epoch: 42, Steps: 261 | Train Loss: 0.3505813 Vali Loss: 0.2645315 Test Loss: 0.3694277
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3138899
	speed: 0.0768s/iter; left time: 1155.4444s
	iters: 200, epoch: 43 | loss: 0.3639833
	speed: 0.0152s/iter; left time: 227.1170s
Epoch: 43 cost time: 4.637026786804199
Epoch: 43, Steps: 261 | Train Loss: 0.3505165 Vali Loss: 0.2645266 Test Loss: 0.3694225
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.3334053
	speed: 0.0763s/iter; left time: 1128.1544s
	iters: 200, epoch: 44 | loss: 0.3389816
	speed: 0.0162s/iter; left time: 237.2279s
Epoch: 44 cost time: 4.686072587966919
Epoch: 44, Steps: 261 | Train Loss: 0.3506843 Vali Loss: 0.2646349 Test Loss: 0.3694267
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.4427637
	speed: 0.0789s/iter; left time: 1145.3636s
	iters: 200, epoch: 45 | loss: 0.3432128
	speed: 0.0159s/iter; left time: 229.6349s
Epoch: 45 cost time: 4.804115533828735
Epoch: 45, Steps: 261 | Train Loss: 0.3508207 Vali Loss: 0.2644118 Test Loss: 0.3694275
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.4624773
	speed: 0.0761s/iter; left time: 1084.3677s
	iters: 200, epoch: 46 | loss: 0.2589259
	speed: 0.0159s/iter; left time: 224.6464s
Epoch: 46 cost time: 4.690113067626953
Epoch: 46, Steps: 261 | Train Loss: 0.3504772 Vali Loss: 0.2646631 Test Loss: 0.3694170
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.3901150
	speed: 0.0939s/iter; left time: 1314.2673s
	iters: 200, epoch: 47 | loss: 0.2319081
	speed: 0.0168s/iter; left time: 233.6343s
Epoch: 47 cost time: 6.4950902462005615
Epoch: 47, Steps: 261 | Train Loss: 0.3505169 Vali Loss: 0.2645107 Test Loss: 0.3694238
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.3877301
	speed: 0.0808s/iter; left time: 1109.1518s
	iters: 200, epoch: 48 | loss: 0.3815368
	speed: 0.0165s/iter; left time: 225.2443s
Epoch: 48 cost time: 4.867210865020752
Epoch: 48, Steps: 261 | Train Loss: 0.3504468 Vali Loss: 0.2645703 Test Loss: 0.3694227
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.3286132
	speed: 0.0813s/iter; left time: 1095.6731s
	iters: 200, epoch: 49 | loss: 0.3482901
	speed: 0.0164s/iter; left time: 219.4529s
Epoch: 49 cost time: 4.962521076202393
Epoch: 49, Steps: 261 | Train Loss: 0.3503686 Vali Loss: 0.2645590 Test Loss: 0.3694144
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.5591845
	speed: 0.0793s/iter; left time: 1047.2898s
	iters: 200, epoch: 50 | loss: 0.3876618
	speed: 0.0169s/iter; left time: 221.7004s
Epoch: 50 cost time: 4.98915433883667
Epoch: 50, Steps: 261 | Train Loss: 0.3507066 Vali Loss: 0.2645629 Test Loss: 0.3694158
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2757545
	speed: 0.0978s/iter; left time: 1266.9426s
	iters: 200, epoch: 51 | loss: 0.3172733
	speed: 0.0153s/iter; left time: 196.8525s
Epoch: 51 cost time: 4.566512107849121
Epoch: 51, Steps: 261 | Train Loss: 0.3503906 Vali Loss: 0.2646122 Test Loss: 0.3694139
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.3683879
	speed: 0.0745s/iter; left time: 945.0932s
	iters: 200, epoch: 52 | loss: 0.3301904
	speed: 0.0152s/iter; left time: 191.5330s
Epoch: 52 cost time: 4.5913307666778564
Epoch: 52, Steps: 261 | Train Loss: 0.3505170 Vali Loss: 0.2646329 Test Loss: 0.3694214
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.4037001
	speed: 0.0765s/iter; left time: 951.1886s
	iters: 200, epoch: 53 | loss: 0.2233093
	speed: 0.0157s/iter; left time: 193.6762s
Epoch: 53 cost time: 4.67763614654541
Epoch: 53, Steps: 261 | Train Loss: 0.3505722 Vali Loss: 0.2644107 Test Loss: 0.3694140
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.3453550
	speed: 0.0774s/iter; left time: 941.2647s
	iters: 200, epoch: 54 | loss: 0.3528796
	speed: 0.0158s/iter; left time: 190.9170s
Epoch: 54 cost time: 4.7706217765808105
Epoch: 54, Steps: 261 | Train Loss: 0.3505538 Vali Loss: 0.2646069 Test Loss: 0.3694170
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.3241068
	speed: 0.0781s/iter; left time: 930.1591s
	iters: 200, epoch: 55 | loss: 0.3708784
	speed: 0.0157s/iter; left time: 184.7995s
Epoch: 55 cost time: 4.682315826416016
Epoch: 55, Steps: 261 | Train Loss: 0.3505574 Vali Loss: 0.2646935 Test Loss: 0.3694180
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2907050
	speed: 0.0768s/iter; left time: 894.0123s
	iters: 200, epoch: 56 | loss: 0.3398500
	speed: 0.0162s/iter; left time: 187.6000s
Epoch: 56 cost time: 4.832679033279419
Epoch: 56, Steps: 261 | Train Loss: 0.3506951 Vali Loss: 0.2643804 Test Loss: 0.3694155
EarlyStopping counter: 20 out of 20
Early stopping
train 33481
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=50, out_features=150, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6720000.0
params:  7650.0
Trainable parameters:  7650
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5460013
	speed: 0.0216s/iter; left time: 562.6130s
	iters: 200, epoch: 1 | loss: 0.3358939
	speed: 0.0158s/iter; left time: 408.6593s
Epoch: 1 cost time: 4.684134483337402
Epoch: 1, Steps: 261 | Train Loss: 0.5186259 Vali Loss: 0.2645618 Test Loss: 0.3690798
Validation loss decreased (inf --> 0.264562).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4182636
	speed: 0.0768s/iter; left time: 1977.4491s
	iters: 200, epoch: 2 | loss: 0.4996450
	speed: 0.0159s/iter; left time: 407.7388s
Epoch: 2 cost time: 4.7924644947052
Epoch: 2, Steps: 261 | Train Loss: 0.5176852 Vali Loss: 0.2641644 Test Loss: 0.3689498
Validation loss decreased (0.264562 --> 0.264164).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3954942
	speed: 0.0771s/iter; left time: 1964.7769s
	iters: 200, epoch: 3 | loss: 0.5191102
	speed: 0.0168s/iter; left time: 427.4823s
Epoch: 3 cost time: 4.701294898986816
Epoch: 3, Steps: 261 | Train Loss: 0.5175340 Vali Loss: 0.2640132 Test Loss: 0.3688978
Validation loss decreased (0.264164 --> 0.264013).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.5189519
	speed: 0.0757s/iter; left time: 1909.2249s
	iters: 200, epoch: 4 | loss: 0.4966196
	speed: 0.0153s/iter; left time: 385.1430s
Epoch: 4 cost time: 4.682769775390625
Epoch: 4, Steps: 261 | Train Loss: 0.5177175 Vali Loss: 0.2638065 Test Loss: 0.3687749
Validation loss decreased (0.264013 --> 0.263806).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.5358138
	speed: 0.0764s/iter; left time: 1907.3166s
	iters: 200, epoch: 5 | loss: 0.5231637
	speed: 0.0162s/iter; left time: 403.2490s
Epoch: 5 cost time: 5.63107442855835
Epoch: 5, Steps: 261 | Train Loss: 0.5172522 Vali Loss: 0.2635450 Test Loss: 0.3686523
Validation loss decreased (0.263806 --> 0.263545).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.5703446
	speed: 0.0873s/iter; left time: 2157.0026s
	iters: 200, epoch: 6 | loss: 0.4780680
	speed: 0.0166s/iter; left time: 407.4309s
Epoch: 6 cost time: 4.9394371509552
Epoch: 6, Steps: 261 | Train Loss: 0.5174453 Vali Loss: 0.2636952 Test Loss: 0.3687844
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.5261707
	speed: 0.0788s/iter; left time: 1925.0321s
	iters: 200, epoch: 7 | loss: 0.4102755
	speed: 0.0166s/iter; left time: 404.0862s
Epoch: 7 cost time: 4.892849922180176
Epoch: 7, Steps: 261 | Train Loss: 0.5168169 Vali Loss: 0.2635533 Test Loss: 0.3687313
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.5349982
	speed: 0.0815s/iter; left time: 1969.9830s
	iters: 200, epoch: 8 | loss: 0.5277464
	speed: 0.0169s/iter; left time: 406.0785s
Epoch: 8 cost time: 4.92864990234375
Epoch: 8, Steps: 261 | Train Loss: 0.5166626 Vali Loss: 0.2635343 Test Loss: 0.3686535
Validation loss decreased (0.263545 --> 0.263534).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4802847
	speed: 0.0808s/iter; left time: 1933.1070s
	iters: 200, epoch: 9 | loss: 0.5110967
	speed: 0.0167s/iter; left time: 397.7818s
Epoch: 9 cost time: 4.9294233322143555
Epoch: 9, Steps: 261 | Train Loss: 0.5164476 Vali Loss: 0.2636595 Test Loss: 0.3686819
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.5261081
	speed: 0.0769s/iter; left time: 1818.0119s
	iters: 200, epoch: 10 | loss: 0.6249261
	speed: 0.0157s/iter; left time: 368.7573s
Epoch: 10 cost time: 4.606082439422607
Epoch: 10, Steps: 261 | Train Loss: 0.5166721 Vali Loss: 0.2632262 Test Loss: 0.3686401
Validation loss decreased (0.263534 --> 0.263226).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4487353
	speed: 0.0761s/iter; left time: 1780.4071s
	iters: 200, epoch: 11 | loss: 0.4132282
	speed: 0.0152s/iter; left time: 354.7975s
Epoch: 11 cost time: 4.628299951553345
Epoch: 11, Steps: 261 | Train Loss: 0.5164874 Vali Loss: 0.2636539 Test Loss: 0.3686334
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4947130
	speed: 0.0735s/iter; left time: 1700.6314s
	iters: 200, epoch: 12 | loss: 0.5964599
	speed: 0.0155s/iter; left time: 358.0931s
Epoch: 12 cost time: 4.5332231521606445
Epoch: 12, Steps: 261 | Train Loss: 0.5167411 Vali Loss: 0.2634726 Test Loss: 0.3686690
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.5783005
	speed: 0.0754s/iter; left time: 1724.3856s
	iters: 200, epoch: 13 | loss: 0.4059022
	speed: 0.0151s/iter; left time: 344.6334s
Epoch: 13 cost time: 4.551068305969238
Epoch: 13, Steps: 261 | Train Loss: 0.5165560 Vali Loss: 0.2633141 Test Loss: 0.3686339
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.5285607
	speed: 0.0769s/iter; left time: 1739.3924s
	iters: 200, epoch: 14 | loss: 0.4487457
	speed: 0.0163s/iter; left time: 366.5952s
Epoch: 14 cost time: 4.872666597366333
Epoch: 14, Steps: 261 | Train Loss: 0.5166274 Vali Loss: 0.2634540 Test Loss: 0.3687013
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.6556685
	speed: 0.0806s/iter; left time: 1800.5825s
	iters: 200, epoch: 15 | loss: 0.5030336
	speed: 0.0185s/iter; left time: 411.1039s
Epoch: 15 cost time: 5.154700517654419
Epoch: 15, Steps: 261 | Train Loss: 0.5164329 Vali Loss: 0.2633667 Test Loss: 0.3686647
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.5202371
	speed: 0.0758s/iter; left time: 1674.1802s
	iters: 200, epoch: 16 | loss: 0.4122446
	speed: 0.0154s/iter; left time: 338.9458s
Epoch: 16 cost time: 4.637225389480591
Epoch: 16, Steps: 261 | Train Loss: 0.5163941 Vali Loss: 0.2636718 Test Loss: 0.3686618
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.5230629
	speed: 0.0772s/iter; left time: 1684.7860s
	iters: 200, epoch: 17 | loss: 0.5630633
	speed: 0.0159s/iter; left time: 345.6317s
Epoch: 17 cost time: 4.746483325958252
Epoch: 17, Steps: 261 | Train Loss: 0.5160735 Vali Loss: 0.2635244 Test Loss: 0.3686098
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4814260
	speed: 0.0961s/iter; left time: 2071.4036s
	iters: 200, epoch: 18 | loss: 0.4685960
	speed: 0.0432s/iter; left time: 927.4045s
Epoch: 18 cost time: 11.155731678009033
Epoch: 18, Steps: 261 | Train Loss: 0.5160695 Vali Loss: 0.2634466 Test Loss: 0.3686199
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4862074
	speed: 0.0934s/iter; left time: 1988.6371s
	iters: 200, epoch: 19 | loss: 0.5302316
	speed: 0.0157s/iter; left time: 332.3318s
Epoch: 19 cost time: 4.625305891036987
Epoch: 19, Steps: 261 | Train Loss: 0.5166548 Vali Loss: 0.2633880 Test Loss: 0.3685833
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.5138182
	speed: 0.0780s/iter; left time: 1641.0746s
	iters: 200, epoch: 20 | loss: 0.4364796
	speed: 0.0169s/iter; left time: 352.9950s
Epoch: 20 cost time: 4.938676834106445
Epoch: 20, Steps: 261 | Train Loss: 0.5162417 Vali Loss: 0.2635759 Test Loss: 0.3686026
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4638783
	speed: 0.0807s/iter; left time: 1676.8172s
	iters: 200, epoch: 21 | loss: 0.4049046
	speed: 0.0161s/iter; left time: 333.4030s
Epoch: 21 cost time: 4.782543182373047
Epoch: 21, Steps: 261 | Train Loss: 0.5162753 Vali Loss: 0.2633523 Test Loss: 0.3686128
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4363511
	speed: 0.0851s/iter; left time: 1745.4410s
	iters: 200, epoch: 22 | loss: 0.7456300
	speed: 0.0165s/iter; left time: 336.8137s
Epoch: 22 cost time: 4.871004104614258
Epoch: 22, Steps: 261 | Train Loss: 0.5160919 Vali Loss: 0.2635556 Test Loss: 0.3685893
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4931716
	speed: 0.0783s/iter; left time: 1585.3045s
	iters: 200, epoch: 23 | loss: 0.5811251
	speed: 0.0160s/iter; left time: 322.8552s
Epoch: 23 cost time: 4.72470235824585
Epoch: 23, Steps: 261 | Train Loss: 0.5167228 Vali Loss: 0.2636648 Test Loss: 0.3686047
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3950318
	speed: 0.0764s/iter; left time: 1528.6683s
	iters: 200, epoch: 24 | loss: 0.6289350
	speed: 0.0157s/iter; left time: 311.6681s
Epoch: 24 cost time: 4.687347888946533
Epoch: 24, Steps: 261 | Train Loss: 0.5162694 Vali Loss: 0.2635151 Test Loss: 0.3685875
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.6759817
	speed: 0.0738s/iter; left time: 1455.7186s
	iters: 200, epoch: 25 | loss: 0.6760326
	speed: 0.0161s/iter; left time: 316.5877s
Epoch: 25 cost time: 4.6193342208862305
Epoch: 25, Steps: 261 | Train Loss: 0.5163580 Vali Loss: 0.2633111 Test Loss: 0.3686227
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3637323
	speed: 0.0764s/iter; left time: 1488.1845s
	iters: 200, epoch: 26 | loss: 0.5568927
	speed: 0.0160s/iter; left time: 309.9159s
Epoch: 26 cost time: 4.80964732170105
Epoch: 26, Steps: 261 | Train Loss: 0.5165020 Vali Loss: 0.2634661 Test Loss: 0.3685780
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4724465
	speed: 0.0763s/iter; left time: 1465.7073s
	iters: 200, epoch: 27 | loss: 0.3893994
	speed: 0.0157s/iter; left time: 300.2126s
Epoch: 27 cost time: 4.701020002365112
Epoch: 27, Steps: 261 | Train Loss: 0.5157816 Vali Loss: 0.2635003 Test Loss: 0.3685793
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3654312
	speed: 0.0769s/iter; left time: 1457.7374s
	iters: 200, epoch: 28 | loss: 0.5259666
	speed: 0.0158s/iter; left time: 297.0080s
Epoch: 28 cost time: 4.827556133270264
Epoch: 28, Steps: 261 | Train Loss: 0.5160463 Vali Loss: 0.2635309 Test Loss: 0.3685915
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.5057694
	speed: 0.0787s/iter; left time: 1470.6300s
	iters: 200, epoch: 29 | loss: 0.6642630
	speed: 0.0157s/iter; left time: 292.0998s
Epoch: 29 cost time: 4.704189300537109
Epoch: 29, Steps: 261 | Train Loss: 0.5161839 Vali Loss: 0.2634810 Test Loss: 0.3685985
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4005034
	speed: 0.0758s/iter; left time: 1397.2903s
	iters: 200, epoch: 30 | loss: 0.5562064
	speed: 0.0158s/iter; left time: 289.3923s
Epoch: 30 cost time: 4.709011793136597
Epoch: 30, Steps: 261 | Train Loss: 0.5162413 Vali Loss: 0.2635120 Test Loss: 0.3685942
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_360_720_FITS_ETTm2_ftM_sl360_ll48_pl720_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.3659352660179138, mae:0.38216593861579895, rse:0.4862353205680847, corr:[0.5433299  0.54724634 0.54545903 0.5422623  0.54051715 0.5403857
 0.54086894 0.5407491  0.53971046 0.53838193 0.53747594 0.5373022
 0.5375713  0.5376926  0.53726333 0.5362766  0.5351505  0.5342685
 0.53378093 0.53354305 0.5333291  0.53296316 0.53240746 0.5318892
 0.53152955 0.5312952  0.53106594 0.5306716  0.53004616 0.5292804
 0.52862453 0.528274   0.52818644 0.5281406  0.5278726  0.5272449
 0.52630746 0.5252933  0.52445364 0.52391154 0.52362007 0.5234349
 0.5231451  0.52261424 0.52185637 0.520949   0.5200504  0.51922524
 0.5184345  0.5176429  0.51681226 0.51603174 0.51529217 0.51458263
 0.5139313  0.5133466  0.5127979  0.51229405 0.5118612  0.5114913
 0.5112039  0.5109863  0.5108224  0.5106345  0.51040006 0.51016575
 0.50990933 0.5096653  0.5094554  0.5092814  0.5090918  0.5088682
 0.50862354 0.5083909  0.5081455  0.5078387  0.5074932  0.5070821
 0.50662965 0.5061219  0.50560665 0.5050509  0.50447387 0.5038412
 0.50320596 0.5026079  0.5020437  0.5015914  0.5012381  0.50092715
 0.50059843 0.50017387 0.49954173 0.49864388 0.49745977 0.49599206
 0.4943163  0.4926467  0.49110624 0.48968846 0.48834953 0.48708835
 0.4858652  0.48460308 0.4832715  0.48199853 0.48088747 0.4799654
 0.47915098 0.4783276  0.47748527 0.4766076  0.47575232 0.474938
 0.47417536 0.4734695  0.47280565 0.47214663 0.4715338  0.4709087
 0.47024924 0.4695179  0.4687909  0.4680443  0.4672517  0.46641862
 0.46560428 0.46481067 0.4640256  0.463257   0.46253455 0.4618336
 0.4611337  0.46046406 0.45984232 0.4592896  0.45869404 0.4580697
 0.45738196 0.4566633  0.45595285 0.45526785 0.45462433 0.45393407
 0.45314783 0.45225    0.4513079  0.45035928 0.44941738 0.44848427
 0.44763556 0.44692126 0.4462725  0.44567862 0.44516814 0.44475985
 0.4443948  0.44401008 0.44351268 0.44298097 0.44238526 0.44176963
 0.44123453 0.4408211  0.44058803 0.44045836 0.44024882 0.44001067
 0.43972805 0.4394846  0.4393121  0.43918365 0.43899974 0.43869066
 0.43822208 0.43764094 0.43700585 0.43640143 0.43591228 0.4355664
 0.43528903 0.43499377 0.434699   0.4343844  0.4340678  0.4337447
 0.43336263 0.43283108 0.43208063 0.43105212 0.42982024 0.42835957
 0.42677096 0.42528164 0.42380133 0.4222139  0.4205602  0.41884124
 0.4171329  0.41545978 0.41384798 0.41235134 0.4110262  0.40989357
 0.4089143  0.40805626 0.4072043  0.40632963 0.40540752 0.40449974
 0.40355644 0.4025709  0.40163225 0.40083712 0.40011513 0.399416
 0.39862618 0.39748377 0.3962082  0.394982   0.39390323 0.39296857
 0.39216372 0.39134365 0.39048535 0.38939697 0.3881069  0.38670465
 0.38542396 0.38441744 0.38363665 0.3829554  0.38227576 0.38159385
 0.3808803  0.3801853  0.37963474 0.37918675 0.37877864 0.37831798
 0.37764612 0.3767332  0.37569118 0.37490287 0.37438545 0.37426215
 0.3745728  0.37509453 0.37553984 0.37571648 0.3756077  0.3753901
 0.37512684 0.37505585 0.37508044 0.37508297 0.37486693 0.37433115
 0.3736436  0.37301612 0.37271562 0.37281787 0.3731311  0.37348875
 0.3737038  0.37364626 0.373334   0.3728271  0.37237793 0.37214205
 0.3720169  0.3718003  0.37134755 0.37075496 0.37008598 0.36958522
 0.3693295  0.36930424 0.36936015 0.3692871  0.36890084 0.3682667
 0.36750388 0.3668622  0.36650607 0.36636937 0.36611864 0.36547446
 0.36432928 0.36294246 0.36149684 0.3601926  0.3592205  0.35860378
 0.35815188 0.35766947 0.35707763 0.3563132  0.3555756  0.35504645
 0.35471687 0.35438243 0.35396338 0.35339013 0.35267815 0.35197964
 0.3515719  0.3514466  0.3515159  0.35172766 0.35191432 0.3519292
 0.35161346 0.35101286 0.3502396  0.34951428 0.34897304 0.34862506
 0.34843776 0.3482786  0.3479996  0.34756795 0.34701148 0.34639606
 0.34580052 0.34540915 0.34528422 0.34532186 0.34535834 0.3453431
 0.3452063  0.34491065 0.34451264 0.34402397 0.34348828 0.3430536
 0.34263235 0.3421785  0.34169236 0.34128776 0.34101188 0.34092674
 0.34099966 0.34123263 0.34145108 0.34147868 0.34131187 0.34100354
 0.34071803 0.34055573 0.34050694 0.34057415 0.340763   0.3409905
 0.34121335 0.34147716 0.34168297 0.3417423  0.3415682  0.34107417
 0.3403652  0.33963722 0.33898982 0.33855465 0.3382744  0.33810022
 0.33781108 0.33738503 0.33689234 0.3364854  0.33642146 0.3366703
 0.3371494  0.33765623 0.3379874  0.3380066  0.33777782 0.337527
 0.33741316 0.33745128 0.3374551  0.3370889  0.33624765 0.33489984
 0.33327097 0.33179164 0.33071128 0.3300072  0.32944095 0.32887524
 0.32817176 0.32731926 0.32649156 0.32575715 0.32514438 0.32460642
 0.32410842 0.3236602  0.32315344 0.3226704  0.3222595  0.321843
 0.32139742 0.32081807 0.32017687 0.31962055 0.31929657 0.31929177
 0.31944978 0.31948802 0.3192499  0.31874117 0.3180605  0.31743214
 0.3170514  0.31700546 0.31716043 0.31727403 0.3171479  0.31675774
 0.31622675 0.31579846 0.31559587 0.3156383  0.3158384  0.31602186
 0.3160245  0.31585672 0.3155811  0.3152608  0.31500733 0.31481442
 0.31459406 0.3142836  0.31380862 0.3132931  0.3127919  0.3123911
 0.3120693  0.3118755  0.31162745 0.31136972 0.31106815 0.31081575
 0.3106744  0.31071422 0.3109125  0.3110782  0.3110707  0.3108
 0.31039104 0.30992717 0.30943903 0.30899975 0.30861878 0.30829775
 0.3080636  0.30791357 0.30777043 0.3076648  0.30763096 0.30754206
 0.30736288 0.30705503 0.30664644 0.3061263  0.30545932 0.30478954
 0.30416352 0.30362412 0.3031081  0.30259165 0.30209166 0.3015776
 0.3010024  0.3003236  0.2995448  0.29862618 0.2975073  0.2961481
 0.29468155 0.29329094 0.2920734  0.29108742 0.29026657 0.28953353
 0.2888158  0.28807113 0.28727505 0.2864757  0.28566682 0.28487766
 0.28421333 0.28373954 0.2834408  0.28322083 0.28300107 0.28267077
 0.2822208  0.28165326 0.2810075  0.28037122 0.27980497 0.2793496
 0.27895674 0.27850154 0.27805662 0.27767774 0.27745968 0.27731076
 0.27716807 0.27696186 0.27664095 0.2762013  0.27568272 0.27507898
 0.27445942 0.27380252 0.2731338  0.27250043 0.2719095  0.27140665
 0.27093554 0.27052388 0.27013308 0.26978943 0.26955998 0.26942292
 0.26935032 0.26930353 0.26915562 0.26885888 0.26844102 0.2680164
 0.26766858 0.26746884 0.26747832 0.2675572  0.2675682  0.2674793
 0.26723638 0.26697844 0.26680884 0.2667905  0.26682508 0.26679704
 0.26661727 0.26632917 0.26601267 0.26578853 0.26565585 0.26567984
 0.265744   0.2657317  0.2655923  0.26531398 0.2650374  0.2648771
 0.26484972 0.2649098  0.26492855 0.26475576 0.26427528 0.26357076
 0.26288357 0.26237965 0.2621895  0.26222956 0.26244605 0.26263776
 0.2626001  0.26217955 0.26129472 0.2599699  0.25833797 0.25649816
 0.25465837 0.2531221  0.25194004 0.25098854 0.25007144 0.24906036
 0.24776946 0.24631521 0.24482806 0.24349277 0.2424803  0.2418379
 0.24135447 0.24084118 0.2402303  0.23952052 0.23869108 0.23784864
 0.23715536 0.23668051 0.2363981  0.23619215 0.23600149 0.23571818
 0.23528986 0.23471269 0.23404534 0.23339695 0.23285963 0.23248047
 0.23226134 0.2321879  0.2321768  0.23210935 0.23193784 0.23159045
 0.23114656 0.23061197 0.23009029 0.22968729 0.22938542 0.2291758
 0.22888692 0.22850937 0.22803842 0.22762117 0.22737183 0.22727443
 0.22721007 0.2270002  0.22665869 0.2263128  0.22604918 0.22586124
 0.22584338 0.22602145 0.22624683 0.22630416 0.22621366 0.22601551
 0.22597551 0.22603768 0.22610818 0.22615616 0.2261062  0.22601332
 0.22589359 0.22590439 0.2260397  0.22615594 0.22628035 0.2261288
 0.22577758 0.22535223 0.22498363 0.22480068 0.22475149 0.22465979
 0.22456081 0.22449933 0.22452188 0.22482082 0.22538052 0.22598277
 0.22650057 0.2268158  0.22688526 0.22672515 0.22660166 0.22662695
 0.22676034 0.22686177 0.22675262 0.22616434 0.2249847  0.22338928
 0.22161105 0.21993864 0.2184398  0.21705656 0.21578632 0.21476658
 0.21395414 0.21341822 0.2132005  0.21312585 0.21297356 0.21268742
 0.21233301 0.21189897 0.21149458 0.21114208 0.2109424  0.21071155
 0.2105263  0.21035461 0.21021612 0.21029317 0.21048863 0.21061791
 0.21053636 0.21005008 0.2093081  0.20857549 0.20808978 0.20779666
 0.2076483  0.20732282 0.20670772 0.20589828 0.20500074 0.2043564
 0.20395115 0.20385967 0.20393603 0.2038923  0.20347728 0.20274957
 0.20180541 0.20078611 0.19992082 0.19966955 0.19981916 0.20020062]
