Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=34, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_180_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_180_720_FITS_ETTm2_ftM_sl180_ll48_pl720_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33661
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=34, out_features=170, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  5178880.0
params:  5950.0
Trainable parameters:  5950
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6338678
	speed: 0.0275s/iter; left time: 717.0759s
	iters: 200, epoch: 1 | loss: 0.4965191
	speed: 0.0231s/iter; left time: 600.3629s
Epoch: 1 cost time: 6.824267864227295
Epoch: 1, Steps: 262 | Train Loss: 0.5837182 Vali Loss: 0.3110618 Test Loss: 0.4293645
Validation loss decreased (inf --> 0.311062).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6153011
	speed: 0.1280s/iter; left time: 3306.1755s
	iters: 200, epoch: 2 | loss: 0.3575290
	speed: 0.0244s/iter; left time: 627.5903s
Epoch: 2 cost time: 7.383123397827148
Epoch: 2, Steps: 262 | Train Loss: 0.4783136 Vali Loss: 0.2901771 Test Loss: 0.4034832
Validation loss decreased (0.311062 --> 0.290177).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4537696
	speed: 0.1214s/iter; left time: 3106.0881s
	iters: 200, epoch: 3 | loss: 0.3639023
	speed: 0.0257s/iter; left time: 655.9102s
Epoch: 3 cost time: 8.433414459228516
Epoch: 3, Steps: 262 | Train Loss: 0.4616003 Vali Loss: 0.2844405 Test Loss: 0.3969286
Validation loss decreased (0.290177 --> 0.284441).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4843295
	speed: 0.1445s/iter; left time: 3659.1842s
	iters: 200, epoch: 4 | loss: 0.3423946
	speed: 0.0204s/iter; left time: 514.9571s
Epoch: 4 cost time: 6.181113958358765
Epoch: 4, Steps: 262 | Train Loss: 0.4564366 Vali Loss: 0.2817802 Test Loss: 0.3938602
Validation loss decreased (0.284441 --> 0.281780).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.6316920
	speed: 0.1233s/iter; left time: 3088.2255s
	iters: 200, epoch: 5 | loss: 0.4968179
	speed: 0.0260s/iter; left time: 648.2927s
Epoch: 5 cost time: 7.242398738861084
Epoch: 5, Steps: 262 | Train Loss: 0.4532774 Vali Loss: 0.2801946 Test Loss: 0.3920211
Validation loss decreased (0.281780 --> 0.280195).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3348383
	speed: 0.1215s/iter; left time: 3013.2351s
	iters: 200, epoch: 6 | loss: 0.4474009
	speed: 0.0255s/iter; left time: 628.8374s
Epoch: 6 cost time: 7.821041822433472
Epoch: 6, Steps: 262 | Train Loss: 0.4521805 Vali Loss: 0.2791879 Test Loss: 0.3909155
Validation loss decreased (0.280195 --> 0.279188).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4904299
	speed: 0.1211s/iter; left time: 2970.3500s
	iters: 200, epoch: 7 | loss: 0.5200128
	speed: 0.0212s/iter; left time: 518.9217s
Epoch: 7 cost time: 7.079212188720703
Epoch: 7, Steps: 262 | Train Loss: 0.4507945 Vali Loss: 0.2786906 Test Loss: 0.3901160
Validation loss decreased (0.279188 --> 0.278691).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3628887
	speed: 0.1128s/iter; left time: 2737.6535s
	iters: 200, epoch: 8 | loss: 0.5923780
	speed: 0.0224s/iter; left time: 541.6602s
Epoch: 8 cost time: 6.489215135574341
Epoch: 8, Steps: 262 | Train Loss: 0.4492441 Vali Loss: 0.2784126 Test Loss: 0.3895863
Validation loss decreased (0.278691 --> 0.278413).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3461459
	speed: 0.1112s/iter; left time: 2668.8099s
	iters: 200, epoch: 9 | loss: 0.3481336
	speed: 0.0206s/iter; left time: 491.6467s
Epoch: 9 cost time: 6.558810710906982
Epoch: 9, Steps: 262 | Train Loss: 0.4489724 Vali Loss: 0.2777257 Test Loss: 0.3890450
Validation loss decreased (0.278413 --> 0.277726).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3947601
	speed: 0.1047s/iter; left time: 2486.3551s
	iters: 200, epoch: 10 | loss: 0.4292360
	speed: 0.0204s/iter; left time: 481.7696s
Epoch: 10 cost time: 6.276915550231934
Epoch: 10, Steps: 262 | Train Loss: 0.4487500 Vali Loss: 0.2777893 Test Loss: 0.3887645
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.5031140
	speed: 0.1481s/iter; left time: 3477.1055s
	iters: 200, epoch: 11 | loss: 0.6045141
	speed: 0.0419s/iter; left time: 979.7380s
Epoch: 11 cost time: 8.327649354934692
Epoch: 11, Steps: 262 | Train Loss: 0.4486221 Vali Loss: 0.2774330 Test Loss: 0.3884841
Validation loss decreased (0.277726 --> 0.277433).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3896846
	speed: 0.1177s/iter; left time: 2732.8971s
	iters: 200, epoch: 12 | loss: 0.3728182
	speed: 0.0236s/iter; left time: 545.5386s
Epoch: 12 cost time: 7.268574953079224
Epoch: 12, Steps: 262 | Train Loss: 0.4479678 Vali Loss: 0.2774125 Test Loss: 0.3882440
Validation loss decreased (0.277433 --> 0.277412).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.5147755
	speed: 0.1235s/iter; left time: 2834.3056s
	iters: 200, epoch: 13 | loss: 0.2429408
	speed: 0.0423s/iter; left time: 966.3036s
Epoch: 13 cost time: 9.068651914596558
Epoch: 13, Steps: 262 | Train Loss: 0.4478524 Vali Loss: 0.2774688 Test Loss: 0.3880982
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.5521821
	speed: 0.1107s/iter; left time: 2511.3042s
	iters: 200, epoch: 14 | loss: 0.6234833
	speed: 0.0212s/iter; left time: 477.9105s
Epoch: 14 cost time: 6.127896070480347
Epoch: 14, Steps: 262 | Train Loss: 0.4475769 Vali Loss: 0.2773809 Test Loss: 0.3879001
Validation loss decreased (0.277412 --> 0.277381).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3760585
	speed: 0.1035s/iter; left time: 2321.1007s
	iters: 200, epoch: 15 | loss: 0.4336890
	speed: 0.0259s/iter; left time: 577.6336s
Epoch: 15 cost time: 6.533617734909058
Epoch: 15, Steps: 262 | Train Loss: 0.4472399 Vali Loss: 0.2772794 Test Loss: 0.3877974
Validation loss decreased (0.277381 --> 0.277279).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4422502
	speed: 0.1129s/iter; left time: 2503.8977s
	iters: 200, epoch: 16 | loss: 0.3848347
	speed: 0.0234s/iter; left time: 516.5733s
Epoch: 16 cost time: 7.883558750152588
Epoch: 16, Steps: 262 | Train Loss: 0.4468497 Vali Loss: 0.2769632 Test Loss: 0.3877171
Validation loss decreased (0.277279 --> 0.276963).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4287750
	speed: 0.1086s/iter; left time: 2378.2365s
	iters: 200, epoch: 17 | loss: 0.3568443
	speed: 0.0202s/iter; left time: 440.4548s
Epoch: 17 cost time: 6.912576913833618
Epoch: 17, Steps: 262 | Train Loss: 0.4469791 Vali Loss: 0.2769002 Test Loss: 0.3875950
Validation loss decreased (0.276963 --> 0.276900).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3050086
	speed: 0.1438s/iter; left time: 3112.1774s
	iters: 200, epoch: 18 | loss: 0.4521983
	speed: 0.0292s/iter; left time: 629.3825s
Epoch: 18 cost time: 9.124042749404907
Epoch: 18, Steps: 262 | Train Loss: 0.4471522 Vali Loss: 0.2769224 Test Loss: 0.3875470
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.5173607
	speed: 0.1271s/iter; left time: 2718.9766s
	iters: 200, epoch: 19 | loss: 0.5136672
	speed: 0.0335s/iter; left time: 713.9634s
Epoch: 19 cost time: 9.202623128890991
Epoch: 19, Steps: 262 | Train Loss: 0.4468574 Vali Loss: 0.2769486 Test Loss: 0.3874543
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4157798
	speed: 0.1295s/iter; left time: 2735.8349s
	iters: 200, epoch: 20 | loss: 0.3844233
	speed: 0.0205s/iter; left time: 430.7509s
Epoch: 20 cost time: 6.0482823848724365
Epoch: 20, Steps: 262 | Train Loss: 0.4469146 Vali Loss: 0.2769528 Test Loss: 0.3873476
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3035671
	speed: 0.1237s/iter; left time: 2580.3871s
	iters: 200, epoch: 21 | loss: 0.4056230
	speed: 0.0308s/iter; left time: 638.5442s
Epoch: 21 cost time: 8.879563808441162
Epoch: 21, Steps: 262 | Train Loss: 0.4465426 Vali Loss: 0.2769039 Test Loss: 0.3873423
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3846204
	speed: 0.1351s/iter; left time: 2783.2847s
	iters: 200, epoch: 22 | loss: 0.4855037
	speed: 0.0238s/iter; left time: 488.2070s
Epoch: 22 cost time: 7.7591493129730225
Epoch: 22, Steps: 262 | Train Loss: 0.4469870 Vali Loss: 0.2770417 Test Loss: 0.3872918
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4421955
	speed: 0.1414s/iter; left time: 2875.1694s
	iters: 200, epoch: 23 | loss: 0.4993975
	speed: 0.0336s/iter; left time: 680.9004s
Epoch: 23 cost time: 8.775904417037964
Epoch: 23, Steps: 262 | Train Loss: 0.4461802 Vali Loss: 0.2766858 Test Loss: 0.3872304
Validation loss decreased (0.276900 --> 0.276686).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4975104
	speed: 0.1181s/iter; left time: 2371.4287s
	iters: 200, epoch: 24 | loss: 0.3258528
	speed: 0.0263s/iter; left time: 525.9853s
Epoch: 24 cost time: 7.219804763793945
Epoch: 24, Steps: 262 | Train Loss: 0.4465848 Vali Loss: 0.2768902 Test Loss: 0.3871598
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4283962
	speed: 0.1190s/iter; left time: 2358.5591s
	iters: 200, epoch: 25 | loss: 0.3302341
	speed: 0.0324s/iter; left time: 637.8970s
Epoch: 25 cost time: 8.107816457748413
Epoch: 25, Steps: 262 | Train Loss: 0.4463797 Vali Loss: 0.2766655 Test Loss: 0.3871498
Validation loss decreased (0.276686 --> 0.276665).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3309018
	speed: 0.1152s/iter; left time: 2253.0837s
	iters: 200, epoch: 26 | loss: 0.4787442
	speed: 0.0357s/iter; left time: 695.0680s
Epoch: 26 cost time: 8.474719524383545
Epoch: 26, Steps: 262 | Train Loss: 0.4460782 Vali Loss: 0.2766050 Test Loss: 0.3871215
Validation loss decreased (0.276665 --> 0.276605).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.5328974
	speed: 0.1266s/iter; left time: 2441.7952s
	iters: 200, epoch: 27 | loss: 0.4137554
	speed: 0.0288s/iter; left time: 552.2246s
Epoch: 27 cost time: 8.082347631454468
Epoch: 27, Steps: 262 | Train Loss: 0.4459406 Vali Loss: 0.2767805 Test Loss: 0.3871258
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4162084
	speed: 0.1375s/iter; left time: 2615.7053s
	iters: 200, epoch: 28 | loss: 0.2887797
	speed: 0.0341s/iter; left time: 645.2668s
Epoch: 28 cost time: 8.951144456863403
Epoch: 28, Steps: 262 | Train Loss: 0.4456468 Vali Loss: 0.2771251 Test Loss: 0.3870821
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.5298293
	speed: 0.1316s/iter; left time: 2470.1469s
	iters: 200, epoch: 29 | loss: 0.7106627
	speed: 0.0203s/iter; left time: 378.4918s
Epoch: 29 cost time: 7.393551826477051
Epoch: 29, Steps: 262 | Train Loss: 0.4464590 Vali Loss: 0.2765066 Test Loss: 0.3870960
Validation loss decreased (0.276605 --> 0.276507).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.5433191
	speed: 0.1233s/iter; left time: 2280.6831s
	iters: 200, epoch: 30 | loss: 0.3532461
	speed: 0.0221s/iter; left time: 406.6403s
Epoch: 30 cost time: 7.470019102096558
Epoch: 30, Steps: 262 | Train Loss: 0.4462030 Vali Loss: 0.2767687 Test Loss: 0.3870493
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4092009
	speed: 0.1142s/iter; left time: 2082.2231s
	iters: 200, epoch: 31 | loss: 0.5040344
	speed: 0.0233s/iter; left time: 423.5734s
Epoch: 31 cost time: 6.761902093887329
Epoch: 31, Steps: 262 | Train Loss: 0.4460214 Vali Loss: 0.2768109 Test Loss: 0.3870428
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2697581
	speed: 0.1141s/iter; left time: 2051.4179s
	iters: 200, epoch: 32 | loss: 0.4386874
	speed: 0.0242s/iter; left time: 433.0421s
Epoch: 32 cost time: 7.553269863128662
Epoch: 32, Steps: 262 | Train Loss: 0.4460960 Vali Loss: 0.2766039 Test Loss: 0.3870373
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3087173
	speed: 0.1180s/iter; left time: 2091.1803s
	iters: 200, epoch: 33 | loss: 0.3166122
	speed: 0.0263s/iter; left time: 463.9600s
Epoch: 33 cost time: 6.621134281158447
Epoch: 33, Steps: 262 | Train Loss: 0.4464214 Vali Loss: 0.2766181 Test Loss: 0.3870335
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3593549
	speed: 0.1133s/iter; left time: 1977.8232s
	iters: 200, epoch: 34 | loss: 0.3539776
	speed: 0.0265s/iter; left time: 459.2073s
Epoch: 34 cost time: 7.842368841171265
Epoch: 34, Steps: 262 | Train Loss: 0.4463495 Vali Loss: 0.2766814 Test Loss: 0.3870074
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4796936
	speed: 0.1147s/iter; left time: 1971.2541s
	iters: 200, epoch: 35 | loss: 0.3821104
	speed: 0.0228s/iter; left time: 389.0811s
Epoch: 35 cost time: 7.276933908462524
Epoch: 35, Steps: 262 | Train Loss: 0.4456751 Vali Loss: 0.2767089 Test Loss: 0.3869701
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4366977
	speed: 0.1155s/iter; left time: 1955.4221s
	iters: 200, epoch: 36 | loss: 0.5534588
	speed: 0.0212s/iter; left time: 356.2379s
Epoch: 36 cost time: 6.498993396759033
Epoch: 36, Steps: 262 | Train Loss: 0.4459806 Vali Loss: 0.2764435 Test Loss: 0.3869752
Validation loss decreased (0.276507 --> 0.276444).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.6235821
	speed: 0.1331s/iter; left time: 2218.7265s
	iters: 200, epoch: 37 | loss: 0.5311872
	speed: 0.0219s/iter; left time: 362.2537s
Epoch: 37 cost time: 7.326020240783691
Epoch: 37, Steps: 262 | Train Loss: 0.4459828 Vali Loss: 0.2764487 Test Loss: 0.3869611
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4559035
	speed: 0.1469s/iter; left time: 2410.6366s
	iters: 200, epoch: 38 | loss: 0.5367318
	speed: 0.0302s/iter; left time: 492.7549s
Epoch: 38 cost time: 7.14225435256958
Epoch: 38, Steps: 262 | Train Loss: 0.4458991 Vali Loss: 0.2767352 Test Loss: 0.3869570
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3906697
	speed: 0.1131s/iter; left time: 1826.2285s
	iters: 200, epoch: 39 | loss: 0.5727575
	speed: 0.0198s/iter; left time: 317.8509s
Epoch: 39 cost time: 5.8870697021484375
Epoch: 39, Steps: 262 | Train Loss: 0.4458812 Vali Loss: 0.2765444 Test Loss: 0.3869370
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.4218936
	speed: 0.1179s/iter; left time: 1872.7290s
	iters: 200, epoch: 40 | loss: 0.4531249
	speed: 0.0325s/iter; left time: 512.8766s
Epoch: 40 cost time: 7.988329887390137
Epoch: 40, Steps: 262 | Train Loss: 0.4461570 Vali Loss: 0.2768125 Test Loss: 0.3869408
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3160675
	speed: 0.1316s/iter; left time: 2056.3162s
	iters: 200, epoch: 41 | loss: 0.3896344
	speed: 0.0206s/iter; left time: 319.7857s
Epoch: 41 cost time: 6.475850582122803
Epoch: 41, Steps: 262 | Train Loss: 0.4460302 Vali Loss: 0.2768207 Test Loss: 0.3869333
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.5176176
	speed: 0.1235s/iter; left time: 1896.2681s
	iters: 200, epoch: 42 | loss: 0.4516881
	speed: 0.0305s/iter; left time: 464.7657s
Epoch: 42 cost time: 8.678184747695923
Epoch: 42, Steps: 262 | Train Loss: 0.4460507 Vali Loss: 0.2769614 Test Loss: 0.3869404
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.4024160
	speed: 0.1363s/iter; left time: 2058.2394s
	iters: 200, epoch: 43 | loss: 0.3782439
	speed: 0.0216s/iter; left time: 323.4475s
Epoch: 43 cost time: 6.201673746109009
Epoch: 43, Steps: 262 | Train Loss: 0.4456237 Vali Loss: 0.2768756 Test Loss: 0.3869271
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.4776257
	speed: 0.1078s/iter; left time: 1599.4589s
	iters: 200, epoch: 44 | loss: 0.5454782
	speed: 0.0212s/iter; left time: 312.3109s
Epoch: 44 cost time: 6.389449119567871
Epoch: 44, Steps: 262 | Train Loss: 0.4456156 Vali Loss: 0.2765106 Test Loss: 0.3869247
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.3923844
	speed: 0.1178s/iter; left time: 1716.5687s
	iters: 200, epoch: 45 | loss: 0.4351917
	speed: 0.0234s/iter; left time: 338.8466s
Epoch: 45 cost time: 7.058519124984741
Epoch: 45, Steps: 262 | Train Loss: 0.4460470 Vali Loss: 0.2763065 Test Loss: 0.3869162
Validation loss decreased (0.276444 --> 0.276306).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2777598
	speed: 0.1395s/iter; left time: 1996.5143s
	iters: 200, epoch: 46 | loss: 0.2962208
	speed: 0.0335s/iter; left time: 476.7710s
Epoch: 46 cost time: 9.720894813537598
Epoch: 46, Steps: 262 | Train Loss: 0.4461834 Vali Loss: 0.2768015 Test Loss: 0.3869087
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.3981289
	speed: 0.1438s/iter; left time: 2019.9220s
	iters: 200, epoch: 47 | loss: 0.3401208
	speed: 0.0228s/iter; left time: 317.9015s
Epoch: 47 cost time: 7.127629995346069
Epoch: 47, Steps: 262 | Train Loss: 0.4462831 Vali Loss: 0.2765585 Test Loss: 0.3868961
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.3723585
	speed: 0.1386s/iter; left time: 1910.8308s
	iters: 200, epoch: 48 | loss: 0.4671683
	speed: 0.0252s/iter; left time: 345.4284s
Epoch: 48 cost time: 7.349597454071045
Epoch: 48, Steps: 262 | Train Loss: 0.4457365 Vali Loss: 0.2765217 Test Loss: 0.3868865
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.6585429
	speed: 0.1142s/iter; left time: 1544.9533s
	iters: 200, epoch: 49 | loss: 0.3226645
	speed: 0.0202s/iter; left time: 270.8343s
Epoch: 49 cost time: 6.119745969772339
Epoch: 49, Steps: 262 | Train Loss: 0.4461936 Vali Loss: 0.2763796 Test Loss: 0.3868932
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.4442519
	speed: 0.1187s/iter; left time: 1574.2324s
	iters: 200, epoch: 50 | loss: 0.5040820
	speed: 0.0281s/iter; left time: 369.8688s
Epoch: 50 cost time: 7.900204658508301
Epoch: 50, Steps: 262 | Train Loss: 0.4460506 Vali Loss: 0.2765758 Test Loss: 0.3868957
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.4048654
	speed: 0.1217s/iter; left time: 1581.6095s
	iters: 200, epoch: 51 | loss: 0.4957513
	speed: 0.0247s/iter; left time: 318.6759s
Epoch: 51 cost time: 7.57352089881897
Epoch: 51, Steps: 262 | Train Loss: 0.4460106 Vali Loss: 0.2766512 Test Loss: 0.3868814
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.5144278
	speed: 0.1141s/iter; left time: 1453.5045s
	iters: 200, epoch: 52 | loss: 0.4044394
	speed: 0.0233s/iter; left time: 294.2423s
Epoch: 52 cost time: 6.98867654800415
Epoch: 52, Steps: 262 | Train Loss: 0.4462957 Vali Loss: 0.2767006 Test Loss: 0.3868797
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.3864259
	speed: 0.1101s/iter; left time: 1374.3066s
	iters: 200, epoch: 53 | loss: 0.5896360
	speed: 0.0211s/iter; left time: 260.8414s
Epoch: 53 cost time: 6.117849349975586
Epoch: 53, Steps: 262 | Train Loss: 0.4455963 Vali Loss: 0.2763421 Test Loss: 0.3868813
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.3524339
	speed: 0.1078s/iter; left time: 1316.8083s
	iters: 200, epoch: 54 | loss: 0.3534513
	speed: 0.0210s/iter; left time: 254.0205s
Epoch: 54 cost time: 6.041679859161377
Epoch: 54, Steps: 262 | Train Loss: 0.4452984 Vali Loss: 0.2765551 Test Loss: 0.3868780
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.4957035
	speed: 0.1288s/iter; left time: 1539.7141s
	iters: 200, epoch: 55 | loss: 0.4558084
	speed: 0.0231s/iter; left time: 273.6586s
Epoch: 55 cost time: 6.514835596084595
Epoch: 55, Steps: 262 | Train Loss: 0.4454517 Vali Loss: 0.2765293 Test Loss: 0.3868717
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.3483412
	speed: 0.1285s/iter; left time: 1502.5797s
	iters: 200, epoch: 56 | loss: 0.4324188
	speed: 0.0297s/iter; left time: 343.7208s
Epoch: 56 cost time: 8.332734107971191
Epoch: 56, Steps: 262 | Train Loss: 0.4460950 Vali Loss: 0.2766496 Test Loss: 0.3868733
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.4812052
	speed: 0.1327s/iter; left time: 1516.9392s
	iters: 200, epoch: 57 | loss: 0.3805681
	speed: 0.0220s/iter; left time: 249.7400s
Epoch: 57 cost time: 6.688725233078003
Epoch: 57, Steps: 262 | Train Loss: 0.4455156 Vali Loss: 0.2767603 Test Loss: 0.3868712
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.4437432
	speed: 0.1141s/iter; left time: 1274.6390s
	iters: 200, epoch: 58 | loss: 0.3185965
	speed: 0.0283s/iter; left time: 313.4555s
Epoch: 58 cost time: 7.932567834854126
Epoch: 58, Steps: 262 | Train Loss: 0.4453993 Vali Loss: 0.2766533 Test Loss: 0.3868680
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.4387053
	speed: 0.1174s/iter; left time: 1280.5690s
	iters: 200, epoch: 59 | loss: 0.4400488
	speed: 0.0290s/iter; left time: 313.0175s
Epoch: 59 cost time: 7.218323707580566
Epoch: 59, Steps: 262 | Train Loss: 0.4455468 Vali Loss: 0.2765756 Test Loss: 0.3868646
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.4535992
	speed: 0.1317s/iter; left time: 1401.3871s
	iters: 200, epoch: 60 | loss: 0.5582396
	speed: 0.0355s/iter; left time: 374.6877s
Epoch: 60 cost time: 8.371824502944946
Epoch: 60, Steps: 262 | Train Loss: 0.4456332 Vali Loss: 0.2764956 Test Loss: 0.3868623
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.4025684
	speed: 0.1470s/iter; left time: 1526.0996s
	iters: 200, epoch: 61 | loss: 0.4012458
	speed: 0.0356s/iter; left time: 365.9333s
Epoch: 61 cost time: 10.089372158050537
Epoch: 61, Steps: 262 | Train Loss: 0.4462597 Vali Loss: 0.2763693 Test Loss: 0.3868614
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.4258546
	speed: 0.1447s/iter; left time: 1463.9022s
	iters: 200, epoch: 62 | loss: 0.4642617
	speed: 0.0288s/iter; left time: 288.5311s
Epoch: 62 cost time: 8.221585512161255
Epoch: 62, Steps: 262 | Train Loss: 0.4450770 Vali Loss: 0.2765512 Test Loss: 0.3868567
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.3704194
	speed: 0.1038s/iter; left time: 1023.6359s
	iters: 200, epoch: 63 | loss: 0.6304806
	speed: 0.0222s/iter; left time: 217.0654s
Epoch: 63 cost time: 6.232023239135742
Epoch: 63, Steps: 262 | Train Loss: 0.4454506 Vali Loss: 0.2768183 Test Loss: 0.3868549
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.5959321
	speed: 0.1126s/iter; left time: 1080.4548s
	iters: 200, epoch: 64 | loss: 0.4427473
	speed: 0.0285s/iter; left time: 270.4100s
Epoch: 64 cost time: 7.252539396286011
Epoch: 64, Steps: 262 | Train Loss: 0.4455510 Vali Loss: 0.2764679 Test Loss: 0.3868541
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.5474365
	speed: 0.1349s/iter; left time: 1259.2148s
	iters: 200, epoch: 65 | loss: 0.5141895
	speed: 0.0213s/iter; left time: 196.9879s
Epoch: 65 cost time: 6.71370005607605
Epoch: 65, Steps: 262 | Train Loss: 0.4460476 Vali Loss: 0.2766315 Test Loss: 0.3868567
EarlyStopping counter: 20 out of 20
Early stopping
train 33661
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=34, out_features=170, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  5178880.0
params:  5950.0
Trainable parameters:  5950
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4703410
	speed: 0.0261s/iter; left time: 680.7891s
	iters: 200, epoch: 1 | loss: 0.4688877
	speed: 0.0253s/iter; left time: 657.4142s
Epoch: 1 cost time: 7.208725214004517
Epoch: 1, Steps: 262 | Train Loss: 0.5548586 Vali Loss: 0.2765873 Test Loss: 0.3865791
Validation loss decreased (inf --> 0.276587).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4386802
	speed: 0.1271s/iter; left time: 3284.7932s
	iters: 200, epoch: 2 | loss: 0.4886807
	speed: 0.0228s/iter; left time: 587.2864s
Epoch: 2 cost time: 6.775696754455566
Epoch: 2, Steps: 262 | Train Loss: 0.5541474 Vali Loss: 0.2765411 Test Loss: 0.3865228
Validation loss decreased (0.276587 --> 0.276541).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.6481087
	speed: 0.1064s/iter; left time: 2721.6986s
	iters: 200, epoch: 3 | loss: 0.3675606
	speed: 0.0265s/iter; left time: 675.6530s
Epoch: 3 cost time: 7.790334463119507
Epoch: 3, Steps: 262 | Train Loss: 0.5533037 Vali Loss: 0.2762491 Test Loss: 0.3863819
Validation loss decreased (0.276541 --> 0.276249).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.5856550
	speed: 0.1285s/iter; left time: 3253.3738s
	iters: 200, epoch: 4 | loss: 0.3127348
	speed: 0.0234s/iter; left time: 589.8812s
Epoch: 4 cost time: 6.55129337310791
Epoch: 4, Steps: 262 | Train Loss: 0.5543547 Vali Loss: 0.2763278 Test Loss: 0.3864218
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.5047910
	speed: 0.1209s/iter; left time: 3029.4823s
	iters: 200, epoch: 5 | loss: 0.5185732
	speed: 0.0214s/iter; left time: 534.8094s
Epoch: 5 cost time: 7.410778999328613
Epoch: 5, Steps: 262 | Train Loss: 0.5542651 Vali Loss: 0.2763709 Test Loss: 0.3863458
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4615477
	speed: 0.1323s/iter; left time: 3279.2883s
	iters: 200, epoch: 6 | loss: 0.5939955
	speed: 0.0240s/iter; left time: 592.8139s
Epoch: 6 cost time: 8.072852373123169
Epoch: 6, Steps: 262 | Train Loss: 0.5546308 Vali Loss: 0.2767009 Test Loss: 0.3864301
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.6028139
	speed: 0.1260s/iter; left time: 3090.2513s
	iters: 200, epoch: 7 | loss: 0.5408293
	speed: 0.0214s/iter; left time: 523.7663s
Epoch: 7 cost time: 6.2689080238342285
Epoch: 7, Steps: 262 | Train Loss: 0.5536737 Vali Loss: 0.2761734 Test Loss: 0.3863479
Validation loss decreased (0.276249 --> 0.276173).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.5636685
	speed: 0.1047s/iter; left time: 2540.9446s
	iters: 200, epoch: 8 | loss: 0.7288287
	speed: 0.0237s/iter; left time: 573.5641s
Epoch: 8 cost time: 6.6433656215667725
Epoch: 8, Steps: 262 | Train Loss: 0.5532835 Vali Loss: 0.2764277 Test Loss: 0.3863213
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4791544
	speed: 0.1305s/iter; left time: 3131.6986s
	iters: 200, epoch: 9 | loss: 0.4886279
	speed: 0.0210s/iter; left time: 501.1899s
Epoch: 9 cost time: 6.805514097213745
Epoch: 9, Steps: 262 | Train Loss: 0.5533949 Vali Loss: 0.2760965 Test Loss: 0.3862853
Validation loss decreased (0.276173 --> 0.276097).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.6100813
	speed: 0.1062s/iter; left time: 2521.1795s
	iters: 200, epoch: 10 | loss: 0.4293320
	speed: 0.0230s/iter; left time: 544.0190s
Epoch: 10 cost time: 6.5682313442230225
Epoch: 10, Steps: 262 | Train Loss: 0.5538556 Vali Loss: 0.2765116 Test Loss: 0.3863302
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.5992005
	speed: 0.1151s/iter; left time: 2702.4779s
	iters: 200, epoch: 11 | loss: 0.5385458
	speed: 0.0222s/iter; left time: 517.9451s
Epoch: 11 cost time: 6.9274373054504395
Epoch: 11, Steps: 262 | Train Loss: 0.5531981 Vali Loss: 0.2761844 Test Loss: 0.3863237
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.6138152
	speed: 0.1165s/iter; left time: 2705.7200s
	iters: 200, epoch: 12 | loss: 0.4495385
	speed: 0.0290s/iter; left time: 670.4038s
Epoch: 12 cost time: 7.215717792510986
Epoch: 12, Steps: 262 | Train Loss: 0.5537379 Vali Loss: 0.2764917 Test Loss: 0.3863146
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.5759766
	speed: 0.1120s/iter; left time: 2571.6099s
	iters: 200, epoch: 13 | loss: 0.5199230
	speed: 0.0244s/iter; left time: 556.8985s
Epoch: 13 cost time: 9.32359790802002
Epoch: 13, Steps: 262 | Train Loss: 0.5535059 Vali Loss: 0.2764322 Test Loss: 0.3863087
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.5052319
	speed: 0.1538s/iter; left time: 3490.9153s
	iters: 200, epoch: 14 | loss: 0.4883813
	speed: 0.0329s/iter; left time: 742.8364s
Epoch: 14 cost time: 8.427697658538818
Epoch: 14, Steps: 262 | Train Loss: 0.5540244 Vali Loss: 0.2761374 Test Loss: 0.3863437
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.5738031
	speed: 0.1058s/iter; left time: 2372.4425s
	iters: 200, epoch: 15 | loss: 0.5025034
	speed: 0.0280s/iter; left time: 624.3123s
Epoch: 15 cost time: 6.993786811828613
Epoch: 15, Steps: 262 | Train Loss: 0.5542140 Vali Loss: 0.2762464 Test Loss: 0.3862827
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.6593687
	speed: 0.1175s/iter; left time: 2605.4175s
	iters: 200, epoch: 16 | loss: 0.5504429
	speed: 0.0219s/iter; left time: 484.3776s
Epoch: 16 cost time: 6.35587739944458
Epoch: 16, Steps: 262 | Train Loss: 0.5534200 Vali Loss: 0.2765083 Test Loss: 0.3863261
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.5161561
	speed: 0.1303s/iter; left time: 2855.2764s
	iters: 200, epoch: 17 | loss: 0.5861965
	speed: 0.0317s/iter; left time: 692.3029s
Epoch: 17 cost time: 8.283850193023682
Epoch: 17, Steps: 262 | Train Loss: 0.5529913 Vali Loss: 0.2763177 Test Loss: 0.3862849
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.5954367
	speed: 0.1262s/iter; left time: 2731.8082s
	iters: 200, epoch: 18 | loss: 0.6618034
	speed: 0.0216s/iter; left time: 464.8261s
Epoch: 18 cost time: 7.587643384933472
Epoch: 18, Steps: 262 | Train Loss: 0.5530497 Vali Loss: 0.2763625 Test Loss: 0.3863305
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4683101
	speed: 0.1426s/iter; left time: 3048.4962s
	iters: 200, epoch: 19 | loss: 0.5869825
	speed: 0.0335s/iter; left time: 713.2199s
Epoch: 19 cost time: 9.385538101196289
Epoch: 19, Steps: 262 | Train Loss: 0.5535678 Vali Loss: 0.2766300 Test Loss: 0.3863645
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.7162669
	speed: 0.1241s/iter; left time: 2620.9247s
	iters: 200, epoch: 20 | loss: 0.3802001
	speed: 0.0263s/iter; left time: 552.0030s
Epoch: 20 cost time: 6.847700357437134
Epoch: 20, Steps: 262 | Train Loss: 0.5534636 Vali Loss: 0.2762142 Test Loss: 0.3863106
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.5134302
	speed: 0.1219s/iter; left time: 2543.4774s
	iters: 200, epoch: 21 | loss: 0.4808804
	speed: 0.0244s/iter; left time: 506.7547s
Epoch: 21 cost time: 7.112710952758789
Epoch: 21, Steps: 262 | Train Loss: 0.5531174 Vali Loss: 0.2761717 Test Loss: 0.3863033
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.5483807
	speed: 0.1172s/iter; left time: 2414.5052s
	iters: 200, epoch: 22 | loss: 0.4802803
	speed: 0.0266s/iter; left time: 545.5129s
Epoch: 22 cost time: 8.736411571502686
Epoch: 22, Steps: 262 | Train Loss: 0.5532749 Vali Loss: 0.2764177 Test Loss: 0.3863015
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4353247
	speed: 0.1454s/iter; left time: 2956.3291s
	iters: 200, epoch: 23 | loss: 0.5756887
	speed: 0.0298s/iter; left time: 603.4044s
Epoch: 23 cost time: 9.297531127929688
Epoch: 23, Steps: 262 | Train Loss: 0.5539999 Vali Loss: 0.2765217 Test Loss: 0.3863162
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3690219
	speed: 0.1621s/iter; left time: 3253.1790s
	iters: 200, epoch: 24 | loss: 0.4075279
	speed: 0.0236s/iter; left time: 470.5373s
Epoch: 24 cost time: 7.5221216678619385
Epoch: 24, Steps: 262 | Train Loss: 0.5533308 Vali Loss: 0.2763044 Test Loss: 0.3862864
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3868453
	speed: 0.1123s/iter; left time: 2224.4613s
	iters: 200, epoch: 25 | loss: 0.6446558
	speed: 0.0278s/iter; left time: 548.8527s
Epoch: 25 cost time: 7.918565034866333
Epoch: 25, Steps: 262 | Train Loss: 0.5527632 Vali Loss: 0.2764556 Test Loss: 0.3862917
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3735423
	speed: 0.1313s/iter; left time: 2566.1312s
	iters: 200, epoch: 26 | loss: 0.5864966
	speed: 0.0223s/iter; left time: 434.5883s
Epoch: 26 cost time: 6.185755014419556
Epoch: 26, Steps: 262 | Train Loss: 0.5526712 Vali Loss: 0.2765270 Test Loss: 0.3863147
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4881159
	speed: 0.1164s/iter; left time: 2245.1881s
	iters: 200, epoch: 27 | loss: 0.8349400
	speed: 0.0214s/iter; left time: 409.8584s
Epoch: 27 cost time: 7.697333574295044
Epoch: 27, Steps: 262 | Train Loss: 0.5537226 Vali Loss: 0.2765578 Test Loss: 0.3862944
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4649998
	speed: 0.1575s/iter; left time: 2996.7367s
	iters: 200, epoch: 28 | loss: 0.3761050
	speed: 0.0246s/iter; left time: 465.2109s
Epoch: 28 cost time: 9.53932499885559
Epoch: 28, Steps: 262 | Train Loss: 0.5529173 Vali Loss: 0.2763224 Test Loss: 0.3862898
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4789881
	speed: 0.1110s/iter; left time: 2082.9235s
	iters: 200, epoch: 29 | loss: 0.5357051
	speed: 0.0213s/iter; left time: 396.8305s
Epoch: 29 cost time: 6.633407831192017
Epoch: 29, Steps: 262 | Train Loss: 0.5534865 Vali Loss: 0.2766882 Test Loss: 0.3862992
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_180_720_FITS_ETTm2_ftM_sl180_ll48_pl720_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.38366445899009705, mae:0.38749590516090393, rse:0.49787482619285583, corr:[0.5490939  0.5488971  0.54388577 0.541077   0.54078454 0.5402624
 0.53854823 0.5367295  0.53593963 0.53580976 0.5352899  0.5342012
 0.5332165  0.5328726  0.5327857  0.5321411  0.5308041  0.5294354
 0.5286462  0.52828825 0.5277342  0.5266702  0.52551156 0.5248832
 0.52481055 0.52479744 0.52448696 0.5239399  0.5234565  0.5231284
 0.52282494 0.5224057  0.52180576 0.5212008  0.52073985 0.5203699
 0.51980776 0.5190293  0.5180877  0.51717794 0.5164549  0.51591986
 0.51552093 0.51519716 0.5148774  0.51448816 0.51391774 0.51315045
 0.51226985 0.51141965 0.5106512  0.5099602  0.50919026 0.5083133
 0.5075328  0.50700706 0.5065847  0.50621617 0.50581074 0.5054069
 0.50500536 0.5047008  0.5045002  0.50424564 0.5040178  0.5039028
 0.50380135 0.5036887  0.50353277 0.5034054  0.5033095  0.5032479
 0.5032019  0.5030438  0.5028239  0.5025182  0.5021894  0.5018095
 0.5014177  0.500996   0.5005209  0.50001097 0.4995447  0.49911803
 0.49871665 0.4983298  0.4979127  0.49751803 0.49712512 0.49675113
 0.4964539  0.4961863  0.49578822 0.4951066  0.49402335 0.4924633
 0.49048704 0.4884192  0.48642385 0.4846432  0.4831681  0.48192462
 0.4807174  0.4794063  0.4779542  0.47654247 0.4753294  0.47429308
 0.47324425 0.47199664 0.47085026 0.46986425 0.46898898 0.468003
 0.46671668 0.46535236 0.46414462 0.46316326 0.46232137 0.46132952
 0.46014038 0.45889118 0.45776603 0.45683622 0.4560568  0.45529762
 0.4544651  0.45350924 0.4524704  0.4513729  0.45031983 0.449335
 0.44846103 0.4476129  0.44691166 0.44634238 0.44574726 0.44513187
 0.44453883 0.4440331  0.44355345 0.44301638 0.44238546 0.44159755
 0.44069004 0.43975136 0.43879265 0.43788776 0.4371062  0.43640453
 0.43584162 0.43551594 0.4351422  0.43459734 0.4339622  0.4333556
 0.43290427 0.43254334 0.43202898 0.43136325 0.4307157  0.4302304
 0.42998585 0.42970893 0.4295031  0.4293114  0.42916647 0.42918876
 0.42931393 0.42947334 0.42958185 0.4297178  0.4299686  0.43016624
 0.43021202 0.42997414 0.42956242 0.4291215  0.428832   0.42870444
 0.4285493  0.42827487 0.42802852 0.4278911  0.4279276  0.4280003
 0.4280145  0.42788455 0.4275403  0.42685503 0.42569345 0.4240182
 0.42203456 0.4202204  0.41867796 0.4173403  0.41616    0.41494226
 0.41360596 0.41222322 0.41089085 0.40978372 0.40880886 0.40804225
 0.40743166 0.4069025  0.40633598 0.40566283 0.40488887 0.4040235
 0.40308735 0.40216163 0.40131733 0.4005645  0.3998899  0.3991715
 0.39837402 0.39735743 0.39634165 0.39532527 0.3942847  0.39330378
 0.39226022 0.3911906  0.3902431  0.38932833 0.38852245 0.38779417
 0.38699278 0.38605887 0.3850413  0.3841195  0.38337162 0.3828498
 0.38237652 0.38190696 0.3815037  0.38105032 0.38071898 0.3804247
 0.38012332 0.37969118 0.37907368 0.37848666 0.3779754  0.37763408
 0.37751824 0.3775864  0.37780115 0.37803403 0.37829888 0.3785438
 0.3786527  0.3787466  0.37875396 0.37862206 0.37843066 0.37838256
 0.3784534  0.37845904 0.3783544  0.37827873 0.37828398 0.3783135
 0.37835804 0.37836304 0.3782947  0.3781771  0.37814128 0.37819698
 0.37812263 0.3778295  0.37729284 0.37679857 0.37657177 0.37665343
 0.37680015 0.37678948 0.37662143 0.3763875  0.37610438 0.37600684
 0.37607014 0.37611064 0.37601352 0.37568745 0.37503958 0.3740082
 0.37266544 0.3714377  0.37033054 0.36939737 0.36855984 0.36779675
 0.36723545 0.36671725 0.36611792 0.36540365 0.36475143 0.36426097
 0.36395922 0.36356926 0.36306944 0.36239678 0.36159587 0.36078194
 0.36008534 0.3594333  0.3586498  0.3577532  0.35687312 0.3561494
 0.3554973  0.35483348 0.35397837 0.35303798 0.35208088 0.35126334
 0.35057318 0.34988806 0.34914955 0.34840396 0.34777537 0.34725338
 0.34674433 0.34610543 0.3453782  0.34470657 0.34419766 0.34386027
 0.34357792 0.3431098  0.34249905 0.34188646 0.34147915 0.34134713
 0.34112334 0.34050086 0.33946338 0.3384969  0.33787358 0.3377505
 0.33799547 0.3383016  0.3383424  0.33815137 0.3378442  0.33773205
 0.3378216  0.33798343 0.3379966  0.33777523 0.33745548 0.33727145
 0.3373103  0.33749956 0.33751956 0.33727598 0.33684292 0.33648598
 0.33646554 0.3367597  0.33710063 0.3372815  0.33725226 0.33726162
 0.33736584 0.33752733 0.3375603  0.3373135  0.3370525  0.33689445
 0.33708397 0.33766425 0.33836117 0.3388145  0.3388506  0.3386124
 0.33847496 0.338613   0.33893573 0.3390675  0.3386802  0.3375626
 0.3358773  0.33404058 0.3324295  0.3312141  0.33031273 0.3297256
 0.32925963 0.3286497  0.32773352 0.3265615  0.32533428 0.3244166
 0.3239376  0.32368168 0.32343715 0.3230671  0.32245708 0.32158938
 0.32066637 0.319764   0.31898293 0.31828234 0.31752673 0.3166573
 0.31580058 0.3150734  0.3145351  0.3141358  0.3137757  0.313362
 0.31283417 0.3121907  0.31150028 0.31087267 0.3102607  0.30979234
 0.30948085 0.3092601  0.309078   0.30888677 0.30842468 0.30775157
 0.30712134 0.30673176 0.30656478 0.30654293 0.30641985 0.3061646
 0.30572262 0.3053124  0.30496702 0.3047894  0.3046418  0.30441543
 0.30426952 0.30428177 0.30440062 0.30434185 0.30390662 0.30329588
 0.30275926 0.30256268 0.30274302 0.30295852 0.30293182 0.3026232
 0.30220953 0.30188438 0.30187374 0.30217463 0.3024236  0.30251628
 0.3024052  0.30226353 0.30220902 0.3023142  0.30253035 0.30262518
 0.3024131  0.30194747 0.30139893 0.30098805 0.30079335 0.30088302
 0.3011418  0.30126616 0.3011226  0.30071002 0.30033413 0.3002458
 0.3003468  0.30038464 0.30003664 0.29904884 0.29743916 0.29544947
 0.29340354 0.29168606 0.2903761  0.2894611  0.28881088 0.28829122
 0.28779763 0.28718793 0.28646314 0.28578892 0.28535205 0.2851774
 0.28510854 0.2849394  0.28462473 0.28419676 0.28365862 0.2829509
 0.28208447 0.28109053 0.2801234  0.27940324 0.27888718 0.27837503
 0.27758035 0.27649048 0.27532643 0.27434665 0.2737154  0.27333266
 0.2729136  0.27230322 0.27154467 0.27080077 0.2702019  0.2697256
 0.26920977 0.26856095 0.2678566  0.26722124 0.2667689  0.26641625
 0.26597437 0.26544464 0.26488695 0.26436108 0.2640267  0.2636755
 0.26320273 0.2625262  0.2617709  0.2611849  0.26092044 0.26074564
 0.26045743 0.26003966 0.2597113  0.25960538 0.25979108 0.25994432
 0.25995386 0.25979823 0.2595279  0.2593437  0.2592793  0.25916836
 0.25877872 0.2581863  0.25765133 0.25746903 0.25764814 0.25804675
 0.25830483 0.258208   0.2577395  0.25703216 0.25637633 0.25605568
 0.25605756 0.25641188 0.256917   0.25735646 0.25760636 0.2576442
 0.25752494 0.25742868 0.25741175 0.25742868 0.257476   0.2574892
 0.2574237  0.2570516  0.2561907  0.25474453 0.2528944  0.25089353
 0.24911508 0.2478248  0.2467843  0.24576822 0.24474049 0.24381559
 0.24296273 0.24214919 0.24125375 0.2403154  0.23958349 0.23921259
 0.23895611 0.2384619  0.23775548 0.23699757 0.23630601 0.23572347
 0.23515208 0.23449335 0.2337114  0.23279561 0.23192339 0.2311288
 0.23042646 0.22985427 0.2292819  0.22860454 0.22796436 0.22732975
 0.22661543 0.22597906 0.22549106 0.22509882 0.2248544  0.22461446
 0.22443026 0.22425519 0.2241371  0.2240352  0.22383124 0.22348629
 0.22298783 0.22264597 0.22243913 0.22248138 0.22254682 0.22237714
 0.22205117 0.22168368 0.22137268 0.22102025 0.22054525 0.22010206
 0.22011264 0.22083108 0.22173549 0.22216704 0.22192033 0.22111906
 0.2205407  0.22060163 0.22115132 0.22172338 0.22192827 0.22167312
 0.22129634 0.22109103 0.22109236 0.22100873 0.22074093 0.22040802
 0.22010905 0.21998078 0.219845   0.2198593  0.22012782 0.22063507
 0.22133769 0.22193378 0.22230493 0.22267215 0.22314829 0.22359039
 0.22390948 0.22402392 0.22420406 0.22478747 0.22578973 0.22677249
 0.22715443 0.22675073 0.2258487  0.22491714 0.22407016 0.22298951
 0.221407   0.21955898 0.21797848 0.2170368  0.2166231  0.21629886
 0.21565765 0.21474117 0.21392694 0.21347791 0.21334055 0.213233
 0.21294448 0.21241552 0.21202241 0.21183787 0.21154687 0.21069346
 0.20932172 0.20792897 0.20699026 0.20650966 0.20604883 0.20512699
 0.20386548 0.20269845 0.20193815 0.20138162 0.2003963  0.19877426
 0.1968651  0.19542812 0.19465175 0.19415025 0.19321884 0.19179168
 0.19042298 0.18971628 0.18935654 0.18869008 0.1874477  0.1865371
 0.18635559 0.18622051 0.1851717  0.18429504 0.1871881  0.19654362]
