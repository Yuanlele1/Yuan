Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=38, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_180_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_180_192_FITS_ETTm2_ftM_sl180_ll48_pl192_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34189
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=38, out_features=78, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2655744.0
params:  3042.0
Trainable parameters:  3042
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4186773
	speed: 0.0145s/iter; left time: 386.8596s
	iters: 200, epoch: 1 | loss: 0.4459011
	speed: 0.0090s/iter; left time: 237.3925s
Epoch: 1 cost time: 2.969900369644165
Epoch: 1, Steps: 267 | Train Loss: 0.4030285 Vali Loss: 0.1858338 Test Loss: 0.2621942
Validation loss decreased (inf --> 0.185834).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3721108
	speed: 0.0458s/iter; left time: 1206.1138s
	iters: 200, epoch: 2 | loss: 0.2885068
	speed: 0.0083s/iter; left time: 218.9142s
Epoch: 2 cost time: 2.7193636894226074
Epoch: 2, Steps: 267 | Train Loss: 0.3495245 Vali Loss: 0.1743183 Test Loss: 0.2484524
Validation loss decreased (0.185834 --> 0.174318).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2628151
	speed: 0.0440s/iter; left time: 1146.6244s
	iters: 200, epoch: 3 | loss: 0.4270550
	speed: 0.0084s/iter; left time: 218.9771s
Epoch: 3 cost time: 2.7815113067626953
Epoch: 3, Steps: 267 | Train Loss: 0.3375647 Vali Loss: 0.1698362 Test Loss: 0.2425876
Validation loss decreased (0.174318 --> 0.169836).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2696294
	speed: 0.0470s/iter; left time: 1213.7877s
	iters: 200, epoch: 4 | loss: 0.4423211
	speed: 0.0096s/iter; left time: 246.1706s
Epoch: 4 cost time: 3.2700438499450684
Epoch: 4, Steps: 267 | Train Loss: 0.3317524 Vali Loss: 0.1678133 Test Loss: 0.2393759
Validation loss decreased (0.169836 --> 0.167813).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4288915
	speed: 0.0573s/iter; left time: 1463.4888s
	iters: 200, epoch: 5 | loss: 0.2477022
	speed: 0.0097s/iter; left time: 247.2807s
Epoch: 5 cost time: 3.1023662090301514
Epoch: 5, Steps: 267 | Train Loss: 0.3289057 Vali Loss: 0.1662847 Test Loss: 0.2372532
Validation loss decreased (0.167813 --> 0.166285).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3676683
	speed: 0.0455s/iter; left time: 1148.3704s
	iters: 200, epoch: 6 | loss: 0.2095826
	speed: 0.0078s/iter; left time: 197.3173s
Epoch: 6 cost time: 2.6359200477600098
Epoch: 6, Steps: 267 | Train Loss: 0.3269311 Vali Loss: 0.1655986 Test Loss: 0.2360446
Validation loss decreased (0.166285 --> 0.165599).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3245396
	speed: 0.0428s/iter; left time: 1070.1085s
	iters: 200, epoch: 7 | loss: 0.3397956
	speed: 0.0077s/iter; left time: 192.6941s
Epoch: 7 cost time: 2.647541046142578
Epoch: 7, Steps: 267 | Train Loss: 0.3255130 Vali Loss: 0.1651252 Test Loss: 0.2351168
Validation loss decreased (0.165599 --> 0.165125).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3349365
	speed: 0.0456s/iter; left time: 1128.2714s
	iters: 200, epoch: 8 | loss: 0.2345422
	speed: 0.0199s/iter; left time: 489.5183s
Epoch: 8 cost time: 4.534284830093384
Epoch: 8, Steps: 267 | Train Loss: 0.3245116 Vali Loss: 0.1648353 Test Loss: 0.2345232
Validation loss decreased (0.165125 --> 0.164835).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3220026
	speed: 0.0513s/iter; left time: 1256.1888s
	iters: 200, epoch: 9 | loss: 0.3946711
	speed: 0.0078s/iter; left time: 189.4559s
Epoch: 9 cost time: 2.6712889671325684
Epoch: 9, Steps: 267 | Train Loss: 0.3237425 Vali Loss: 0.1646153 Test Loss: 0.2342055
Validation loss decreased (0.164835 --> 0.164615).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3468191
	speed: 0.0434s/iter; left time: 1051.2960s
	iters: 200, epoch: 10 | loss: 0.2502826
	speed: 0.0087s/iter; left time: 209.1070s
Epoch: 10 cost time: 2.702174663543701
Epoch: 10, Steps: 267 | Train Loss: 0.3230710 Vali Loss: 0.1643162 Test Loss: 0.2337983
Validation loss decreased (0.164615 --> 0.164316).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3505525
	speed: 0.0436s/iter; left time: 1042.6638s
	iters: 200, epoch: 11 | loss: 0.4135751
	speed: 0.0077s/iter; left time: 184.6716s
Epoch: 11 cost time: 2.762984275817871
Epoch: 11, Steps: 267 | Train Loss: 0.3226493 Vali Loss: 0.1643390 Test Loss: 0.2335445
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3552576
	speed: 0.0433s/iter; left time: 1024.6757s
	iters: 200, epoch: 12 | loss: 0.3605941
	speed: 0.0079s/iter; left time: 185.7735s
Epoch: 12 cost time: 2.61137318611145
Epoch: 12, Steps: 267 | Train Loss: 0.3222337 Vali Loss: 0.1639198 Test Loss: 0.2332572
Validation loss decreased (0.164316 --> 0.163920).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2855582
	speed: 0.0454s/iter; left time: 1062.2235s
	iters: 200, epoch: 13 | loss: 0.2735917
	speed: 0.0080s/iter; left time: 187.2223s
Epoch: 13 cost time: 2.987910509109497
Epoch: 13, Steps: 267 | Train Loss: 0.3219766 Vali Loss: 0.1639637 Test Loss: 0.2331793
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2677468
	speed: 0.0435s/iter; left time: 1007.1929s
	iters: 200, epoch: 14 | loss: 0.1988875
	speed: 0.0078s/iter; left time: 179.1012s
Epoch: 14 cost time: 2.7345666885375977
Epoch: 14, Steps: 267 | Train Loss: 0.3216749 Vali Loss: 0.1638166 Test Loss: 0.2330744
Validation loss decreased (0.163920 --> 0.163817).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3508576
	speed: 0.0471s/iter; left time: 1076.4128s
	iters: 200, epoch: 15 | loss: 0.4309560
	speed: 0.0110s/iter; left time: 250.0402s
Epoch: 15 cost time: 3.31168532371521
Epoch: 15, Steps: 267 | Train Loss: 0.3215479 Vali Loss: 0.1639426 Test Loss: 0.2329434
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3358225
	speed: 0.0501s/iter; left time: 1132.0648s
	iters: 200, epoch: 16 | loss: 0.4223597
	speed: 0.0098s/iter; left time: 221.2420s
Epoch: 16 cost time: 3.2024614810943604
Epoch: 16, Steps: 267 | Train Loss: 0.3213745 Vali Loss: 0.1637763 Test Loss: 0.2328678
Validation loss decreased (0.163817 --> 0.163776).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2815859
	speed: 0.0462s/iter; left time: 1030.5199s
	iters: 200, epoch: 17 | loss: 0.3525382
	speed: 0.0077s/iter; left time: 171.0877s
Epoch: 17 cost time: 2.6862668991088867
Epoch: 17, Steps: 267 | Train Loss: 0.3211174 Vali Loss: 0.1637275 Test Loss: 0.2327433
Validation loss decreased (0.163776 --> 0.163727).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2561187
	speed: 0.0453s/iter; left time: 999.6759s
	iters: 200, epoch: 18 | loss: 0.5150142
	speed: 0.0078s/iter; left time: 171.6346s
Epoch: 18 cost time: 2.691141366958618
Epoch: 18, Steps: 267 | Train Loss: 0.3210028 Vali Loss: 0.1637205 Test Loss: 0.2326482
Validation loss decreased (0.163727 --> 0.163720).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3237576
	speed: 0.0437s/iter; left time: 952.9685s
	iters: 200, epoch: 19 | loss: 0.2556613
	speed: 0.0078s/iter; left time: 168.1564s
Epoch: 19 cost time: 2.6343462467193604
Epoch: 19, Steps: 267 | Train Loss: 0.3209274 Vali Loss: 0.1637264 Test Loss: 0.2326370
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4375514
	speed: 0.0436s/iter; left time: 938.3908s
	iters: 200, epoch: 20 | loss: 0.2441903
	speed: 0.0081s/iter; left time: 172.5367s
Epoch: 20 cost time: 2.745530128479004
Epoch: 20, Steps: 267 | Train Loss: 0.3207094 Vali Loss: 0.1638133 Test Loss: 0.2325897
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3623662
	speed: 0.0486s/iter; left time: 1033.1675s
	iters: 200, epoch: 21 | loss: 0.4566309
	speed: 0.0110s/iter; left time: 232.3169s
Epoch: 21 cost time: 3.5246870517730713
Epoch: 21, Steps: 267 | Train Loss: 0.3207157 Vali Loss: 0.1637168 Test Loss: 0.2325171
Validation loss decreased (0.163720 --> 0.163717).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3546653
	speed: 0.0496s/iter; left time: 1040.6975s
	iters: 200, epoch: 22 | loss: 0.3456247
	speed: 0.0078s/iter; left time: 163.5663s
Epoch: 22 cost time: 3.505270481109619
Epoch: 22, Steps: 267 | Train Loss: 0.3205833 Vali Loss: 0.1636791 Test Loss: 0.2324741
Validation loss decreased (0.163717 --> 0.163679).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3545006
	speed: 0.0532s/iter; left time: 1102.1415s
	iters: 200, epoch: 23 | loss: 0.4045290
	speed: 0.0082s/iter; left time: 168.5911s
Epoch: 23 cost time: 2.8132193088531494
Epoch: 23, Steps: 267 | Train Loss: 0.3205993 Vali Loss: 0.1636728 Test Loss: 0.2325197
Validation loss decreased (0.163679 --> 0.163673).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2834120
	speed: 0.0484s/iter; left time: 989.7183s
	iters: 200, epoch: 24 | loss: 0.3337114
	speed: 0.0086s/iter; left time: 175.1140s
Epoch: 24 cost time: 2.9219119548797607
Epoch: 24, Steps: 267 | Train Loss: 0.3204572 Vali Loss: 0.1637687 Test Loss: 0.2324891
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3943875
	speed: 0.0464s/iter; left time: 937.5835s
	iters: 200, epoch: 25 | loss: 0.2985387
	speed: 0.0080s/iter; left time: 161.5353s
Epoch: 25 cost time: 2.7679080963134766
Epoch: 25, Steps: 267 | Train Loss: 0.3202594 Vali Loss: 0.1637118 Test Loss: 0.2324391
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3611627
	speed: 0.0439s/iter; left time: 874.3920s
	iters: 200, epoch: 26 | loss: 0.4157629
	speed: 0.0078s/iter; left time: 155.3056s
Epoch: 26 cost time: 2.7430593967437744
Epoch: 26, Steps: 267 | Train Loss: 0.3204430 Vali Loss: 0.1634348 Test Loss: 0.2323832
Validation loss decreased (0.163673 --> 0.163435).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3393001
	speed: 0.0429s/iter; left time: 842.6663s
	iters: 200, epoch: 27 | loss: 0.2778521
	speed: 0.0078s/iter; left time: 153.1799s
Epoch: 27 cost time: 2.6755473613739014
Epoch: 27, Steps: 267 | Train Loss: 0.3203899 Vali Loss: 0.1635432 Test Loss: 0.2323885
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2757145
	speed: 0.0454s/iter; left time: 880.4861s
	iters: 200, epoch: 28 | loss: 0.2529816
	speed: 0.0079s/iter; left time: 151.7425s
Epoch: 28 cost time: 2.6931848526000977
Epoch: 28, Steps: 267 | Train Loss: 0.3201019 Vali Loss: 0.1635234 Test Loss: 0.2323436
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4154293
	speed: 0.0451s/iter; left time: 863.0413s
	iters: 200, epoch: 29 | loss: 0.2446775
	speed: 0.0079s/iter; left time: 149.5250s
Epoch: 29 cost time: 2.721959352493286
Epoch: 29, Steps: 267 | Train Loss: 0.3201383 Vali Loss: 0.1635728 Test Loss: 0.2323631
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3199438
	speed: 0.0434s/iter; left time: 818.7368s
	iters: 200, epoch: 30 | loss: 0.2378094
	speed: 0.0079s/iter; left time: 147.4180s
Epoch: 30 cost time: 2.705151319503784
Epoch: 30, Steps: 267 | Train Loss: 0.3203074 Vali Loss: 0.1635870 Test Loss: 0.2323213
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3866805
	speed: 0.0443s/iter; left time: 822.7816s
	iters: 200, epoch: 31 | loss: 0.2693196
	speed: 0.0080s/iter; left time: 147.2231s
Epoch: 31 cost time: 2.6047558784484863
Epoch: 31, Steps: 267 | Train Loss: 0.3199091 Vali Loss: 0.1636394 Test Loss: 0.2323394
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3747139
	speed: 0.0477s/iter; left time: 873.7499s
	iters: 200, epoch: 32 | loss: 0.2458549
	speed: 0.0092s/iter; left time: 167.7626s
Epoch: 32 cost time: 3.20011043548584
Epoch: 32, Steps: 267 | Train Loss: 0.3200533 Vali Loss: 0.1636679 Test Loss: 0.2323076
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3161815
	speed: 0.0451s/iter; left time: 814.6461s
	iters: 200, epoch: 33 | loss: 0.4422930
	speed: 0.0085s/iter; left time: 152.6970s
Epoch: 33 cost time: 2.803598642349243
Epoch: 33, Steps: 267 | Train Loss: 0.3201658 Vali Loss: 0.1635873 Test Loss: 0.2323055
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4652101
	speed: 0.0440s/iter; left time: 782.1274s
	iters: 200, epoch: 34 | loss: 0.3296100
	speed: 0.0086s/iter; left time: 152.5842s
Epoch: 34 cost time: 2.82387113571167
Epoch: 34, Steps: 267 | Train Loss: 0.3201685 Vali Loss: 0.1636899 Test Loss: 0.2323363
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3602160
	speed: 0.0453s/iter; left time: 794.1768s
	iters: 200, epoch: 35 | loss: 0.3095746
	speed: 0.0081s/iter; left time: 140.9342s
Epoch: 35 cost time: 2.7501380443573
Epoch: 35, Steps: 267 | Train Loss: 0.3199425 Vali Loss: 0.1637259 Test Loss: 0.2322811
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3266043
	speed: 0.0443s/iter; left time: 764.3071s
	iters: 200, epoch: 36 | loss: 0.3140635
	speed: 0.0077s/iter; left time: 131.4681s
Epoch: 36 cost time: 2.652210235595703
Epoch: 36, Steps: 267 | Train Loss: 0.3198272 Vali Loss: 0.1635691 Test Loss: 0.2322722
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4124120
	speed: 0.0629s/iter; left time: 1068.9833s
	iters: 200, epoch: 37 | loss: 0.5213197
	speed: 0.0091s/iter; left time: 154.3591s
Epoch: 37 cost time: 4.448539972305298
Epoch: 37, Steps: 267 | Train Loss: 0.3201051 Vali Loss: 0.1637631 Test Loss: 0.2322683
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2599019
	speed: 0.0519s/iter; left time: 868.4574s
	iters: 200, epoch: 38 | loss: 0.4717735
	speed: 0.0105s/iter; left time: 174.2528s
Epoch: 38 cost time: 3.436506748199463
Epoch: 38, Steps: 267 | Train Loss: 0.3200580 Vali Loss: 0.1634859 Test Loss: 0.2322728
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3834712
	speed: 0.0491s/iter; left time: 808.4513s
	iters: 200, epoch: 39 | loss: 0.4070530
	speed: 0.0081s/iter; left time: 132.3452s
Epoch: 39 cost time: 2.7444772720336914
Epoch: 39, Steps: 267 | Train Loss: 0.3200656 Vali Loss: 0.1637425 Test Loss: 0.2322661
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2994536
	speed: 0.0446s/iter; left time: 721.9464s
	iters: 200, epoch: 40 | loss: 0.3269974
	speed: 0.0081s/iter; left time: 131.0099s
Epoch: 40 cost time: 2.7172255516052246
Epoch: 40, Steps: 267 | Train Loss: 0.3200759 Vali Loss: 0.1634824 Test Loss: 0.2322474
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2584186
	speed: 0.0465s/iter; left time: 740.8713s
	iters: 200, epoch: 41 | loss: 0.3057261
	speed: 0.0079s/iter; left time: 125.5767s
Epoch: 41 cost time: 2.833906888961792
Epoch: 41, Steps: 267 | Train Loss: 0.3200389 Vali Loss: 0.1636717 Test Loss: 0.2322345
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.4388688
	speed: 0.0474s/iter; left time: 742.0703s
	iters: 200, epoch: 42 | loss: 0.3280081
	speed: 0.0185s/iter; left time: 287.1762s
Epoch: 42 cost time: 4.50426721572876
Epoch: 42, Steps: 267 | Train Loss: 0.3200422 Vali Loss: 0.1636162 Test Loss: 0.2322478
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.4254639
	speed: 0.0533s/iter; left time: 820.7914s
	iters: 200, epoch: 43 | loss: 0.2903362
	speed: 0.0091s/iter; left time: 138.9683s
Epoch: 43 cost time: 3.2964518070220947
Epoch: 43, Steps: 267 | Train Loss: 0.3199865 Vali Loss: 0.1637227 Test Loss: 0.2322160
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2364937
	speed: 0.0638s/iter; left time: 964.5676s
	iters: 200, epoch: 44 | loss: 0.3000370
	speed: 0.0079s/iter; left time: 118.0987s
Epoch: 44 cost time: 2.7571964263916016
Epoch: 44, Steps: 267 | Train Loss: 0.3198901 Vali Loss: 0.1636227 Test Loss: 0.2322268
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2832574
	speed: 0.0466s/iter; left time: 691.7826s
	iters: 200, epoch: 45 | loss: 0.2861958
	speed: 0.0083s/iter; left time: 122.2961s
Epoch: 45 cost time: 2.723931074142456
Epoch: 45, Steps: 267 | Train Loss: 0.3200186 Vali Loss: 0.1636007 Test Loss: 0.2322388
EarlyStopping counter: 19 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2974552
	speed: 0.0470s/iter; left time: 685.6490s
	iters: 200, epoch: 46 | loss: 0.2809287
	speed: 0.0093s/iter; left time: 134.0205s
Epoch: 46 cost time: 3.0163891315460205
Epoch: 46, Steps: 267 | Train Loss: 0.3199564 Vali Loss: 0.1636850 Test Loss: 0.2322305
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_180_192_FITS_ETTm2_ftM_sl180_ll48_pl192_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.23316243290901184, mae:0.29675257205963135, rse:0.3908628523349762, corr:[0.5668169  0.567449   0.5612077  0.56086236 0.561997   0.5603425
 0.5581011  0.55772835 0.5579653  0.5569245  0.55527574 0.55485386
 0.555423   0.5553609  0.5542319  0.5531829  0.55307984 0.55313474
 0.55241674 0.55120885 0.55048317 0.5503515  0.55002445 0.54912114
 0.548207   0.5479799  0.5481939  0.54796815 0.54706144 0.5460913
 0.5456323  0.54545563 0.54501015 0.5443156  0.5437881  0.543525
 0.5430705  0.5422062  0.541192   0.5404815  0.5401232  0.5398095
 0.5393372  0.53885263 0.538534   0.53824604 0.537662   0.53673774
 0.53577554 0.5350357  0.5344656  0.53391045 0.53324836 0.53259915
 0.53210855 0.53171116 0.53112215 0.53048307 0.5300201  0.52978885
 0.52953786 0.5292368  0.5289981  0.52887154 0.52884644 0.52879614
 0.5285293  0.5282078  0.528033   0.52804166 0.52799004 0.52776945
 0.5275148  0.5272885  0.5271723  0.5269809  0.5266496  0.5262271
 0.5258598  0.5255417  0.525175   0.5247104  0.52425325 0.52385527
 0.52348745 0.5231066  0.522636   0.52219033 0.5217879  0.5214166
 0.5210883  0.5207796  0.52035546 0.5197269  0.51877743 0.5174248
 0.515719   0.5139609  0.5123005  0.510744   0.509267   0.5078942
 0.50666535 0.50553167 0.50431436 0.5030078  0.50171244 0.5006384
 0.49976656 0.49881274 0.49780193 0.4967254  0.495787   0.49493042
 0.4939179  0.492752   0.4915405  0.49047184 0.4896068  0.4887429
 0.48782054 0.48690394 0.48609942 0.48533413 0.48450878 0.4835708
 0.4825832  0.48159525 0.48058155 0.47953606 0.4786369  0.4779203
 0.47727415 0.47643554 0.47562355 0.47506648 0.47468248 0.47431728
 0.4737805  0.4731643  0.47267663 0.47229636 0.4717837  0.4709521
 0.46997315 0.46911186 0.46825927 0.46732602 0.4664815  0.46585998
 0.46554756 0.4652912  0.46468925 0.4638961  0.46336687 0.4631934
 0.46288967 0.46225268 0.46140283 0.46098003 0.46095306 0.46077633
 0.46033    0.4598523  0.45994994 0.46021247 0.46011674 0.45974723
 0.45960632 0.45998985 0.46034828 0.4602825  0.46008658 0.46013728
 0.46046    0.4603531  0.45972607 0.45921573 0.4594028  0.45980325
 0.45948854 0.45848703 0.45812145 0.4585709  0.4589114  0.45849645
 0.45812157 0.4587215  0.45912296 0.45841438 0.45737824 0.4577179 ]
