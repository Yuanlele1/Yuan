Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=30, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_180_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_180_720_FITS_ETTm2_ftM_sl180_ll48_pl720_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33661
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=30, out_features=150, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4032000.0
params:  4650.0
Trainable parameters:  4650
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.9321041
	speed: 0.0216s/iter; left time: 563.8857s
	iters: 200, epoch: 1 | loss: 0.7516888
	speed: 0.0151s/iter; left time: 392.9859s
Epoch: 1 cost time: 4.642174243927002
Epoch: 1, Steps: 262 | Train Loss: 0.6790792 Vali Loss: 0.3048707 Test Loss: 0.4233452
Validation loss decreased (inf --> 0.304871).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6113453
	speed: 0.0747s/iter; left time: 1929.5156s
	iters: 200, epoch: 2 | loss: 0.5944386
	speed: 0.0161s/iter; left time: 415.5293s
Epoch: 2 cost time: 4.685235261917114
Epoch: 2, Steps: 262 | Train Loss: 0.5825815 Vali Loss: 0.2862880 Test Loss: 0.4005493
Validation loss decreased (0.304871 --> 0.286288).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5009104
	speed: 0.0736s/iter; left time: 1881.8573s
	iters: 200, epoch: 3 | loss: 0.6569190
	speed: 0.0154s/iter; left time: 391.4183s
Epoch: 3 cost time: 4.555548906326294
Epoch: 3, Steps: 262 | Train Loss: 0.5697469 Vali Loss: 0.2819504 Test Loss: 0.3952365
Validation loss decreased (0.286288 --> 0.281950).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4841296
	speed: 0.0711s/iter; left time: 1800.8779s
	iters: 200, epoch: 4 | loss: 0.4751561
	speed: 0.0151s/iter; left time: 380.7642s
Epoch: 4 cost time: 4.45871376991272
Epoch: 4, Steps: 262 | Train Loss: 0.5660818 Vali Loss: 0.2801307 Test Loss: 0.3928680
Validation loss decreased (0.281950 --> 0.280131).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.5288173
	speed: 0.0845s/iter; left time: 2116.3354s
	iters: 200, epoch: 5 | loss: 0.7528012
	speed: 0.0174s/iter; left time: 433.5225s
Epoch: 5 cost time: 6.2402262687683105
Epoch: 5, Steps: 262 | Train Loss: 0.5623020 Vali Loss: 0.2793165 Test Loss: 0.3913996
Validation loss decreased (0.280131 --> 0.279316).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.6997070
	speed: 0.0791s/iter; left time: 1961.4718s
	iters: 200, epoch: 6 | loss: 0.7089509
	speed: 0.0172s/iter; left time: 424.9527s
Epoch: 6 cost time: 4.932612895965576
Epoch: 6, Steps: 262 | Train Loss: 0.5607653 Vali Loss: 0.2785487 Test Loss: 0.3903782
Validation loss decreased (0.279316 --> 0.278549).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4743205
	speed: 0.0794s/iter; left time: 1946.4842s
	iters: 200, epoch: 7 | loss: 0.5086319
	speed: 0.0164s/iter; left time: 400.7476s
Epoch: 7 cost time: 4.828686237335205
Epoch: 7, Steps: 262 | Train Loss: 0.5600558 Vali Loss: 0.2782451 Test Loss: 0.3897119
Validation loss decreased (0.278549 --> 0.278245).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3722745
	speed: 0.0809s/iter; left time: 1962.1289s
	iters: 200, epoch: 8 | loss: 0.5640282
	speed: 0.0168s/iter; left time: 405.6297s
Epoch: 8 cost time: 4.92623233795166
Epoch: 8, Steps: 262 | Train Loss: 0.5585706 Vali Loss: 0.2779188 Test Loss: 0.3891792
Validation loss decreased (0.278245 --> 0.277919).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.5886186
	speed: 0.0761s/iter; left time: 1827.7292s
	iters: 200, epoch: 9 | loss: 0.5332059
	speed: 0.0150s/iter; left time: 358.4863s
Epoch: 9 cost time: 4.450108051300049
Epoch: 9, Steps: 262 | Train Loss: 0.5581573 Vali Loss: 0.2775824 Test Loss: 0.3887399
Validation loss decreased (0.277919 --> 0.277582).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.5066850
	speed: 0.0721s/iter; left time: 1711.9857s
	iters: 200, epoch: 10 | loss: 0.5794573
	speed: 0.0148s/iter; left time: 348.8864s
Epoch: 10 cost time: 4.547884464263916
Epoch: 10, Steps: 262 | Train Loss: 0.5576660 Vali Loss: 0.2774030 Test Loss: 0.3883888
Validation loss decreased (0.277582 --> 0.277403).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4925545
	speed: 0.0724s/iter; left time: 1700.5661s
	iters: 200, epoch: 11 | loss: 0.4844242
	speed: 0.0153s/iter; left time: 357.0905s
Epoch: 11 cost time: 4.51706075668335
Epoch: 11, Steps: 262 | Train Loss: 0.5571316 Vali Loss: 0.2769659 Test Loss: 0.3881283
Validation loss decreased (0.277403 --> 0.276966).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.8014742
	speed: 0.0727s/iter; left time: 1687.1983s
	iters: 200, epoch: 12 | loss: 0.5717033
	speed: 0.0150s/iter; left time: 346.5440s
Epoch: 12 cost time: 4.566674470901489
Epoch: 12, Steps: 262 | Train Loss: 0.5562363 Vali Loss: 0.2772567 Test Loss: 0.3879364
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.7881552
	speed: 0.0734s/iter; left time: 1684.3622s
	iters: 200, epoch: 13 | loss: 0.5868229
	speed: 0.0150s/iter; left time: 343.6459s
Epoch: 13 cost time: 4.600533962249756
Epoch: 13, Steps: 262 | Train Loss: 0.5562160 Vali Loss: 0.2768458 Test Loss: 0.3877525
Validation loss decreased (0.276966 --> 0.276846).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4706355
	speed: 0.0779s/iter; left time: 1768.1284s
	iters: 200, epoch: 14 | loss: 0.4949301
	speed: 0.0157s/iter; left time: 355.0790s
Epoch: 14 cost time: 4.87190580368042
Epoch: 14, Steps: 262 | Train Loss: 0.5563044 Vali Loss: 0.2768041 Test Loss: 0.3876087
Validation loss decreased (0.276846 --> 0.276804).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.7434459
	speed: 0.0739s/iter; left time: 1658.5683s
	iters: 200, epoch: 15 | loss: 0.6106251
	speed: 0.0217s/iter; left time: 485.4780s
Epoch: 15 cost time: 5.2673094272613525
Epoch: 15, Steps: 262 | Train Loss: 0.5554065 Vali Loss: 0.2768058 Test Loss: 0.3874910
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.6022967
	speed: 0.0731s/iter; left time: 1620.2350s
	iters: 200, epoch: 16 | loss: 0.6385505
	speed: 0.0146s/iter; left time: 323.2319s
Epoch: 16 cost time: 4.522336006164551
Epoch: 16, Steps: 262 | Train Loss: 0.5553599 Vali Loss: 0.2770170 Test Loss: 0.3874311
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.5340930
	speed: 0.0726s/iter; left time: 1590.3701s
	iters: 200, epoch: 17 | loss: 0.6861554
	speed: 0.0148s/iter; left time: 323.5155s
Epoch: 17 cost time: 4.497545957565308
Epoch: 17, Steps: 262 | Train Loss: 0.5553955 Vali Loss: 0.2768667 Test Loss: 0.3873152
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.5966135
	speed: 0.0732s/iter; left time: 1584.8957s
	iters: 200, epoch: 18 | loss: 0.5986653
	speed: 0.0166s/iter; left time: 358.2798s
Epoch: 18 cost time: 4.759325981140137
Epoch: 18, Steps: 262 | Train Loss: 0.5551596 Vali Loss: 0.2770264 Test Loss: 0.3871898
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.5460404
	speed: 0.0740s/iter; left time: 1581.4413s
	iters: 200, epoch: 19 | loss: 0.5717173
	speed: 0.0147s/iter; left time: 312.0889s
Epoch: 19 cost time: 4.344943523406982
Epoch: 19, Steps: 262 | Train Loss: 0.5552123 Vali Loss: 0.2766511 Test Loss: 0.3871338
Validation loss decreased (0.276804 --> 0.276651).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.5449295
	speed: 0.0771s/iter; left time: 1629.1300s
	iters: 200, epoch: 20 | loss: 0.5300892
	speed: 0.0405s/iter; left time: 850.6411s
Epoch: 20 cost time: 7.619399785995483
Epoch: 20, Steps: 262 | Train Loss: 0.5558979 Vali Loss: 0.2765963 Test Loss: 0.3870516
Validation loss decreased (0.276651 --> 0.276596).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.5538039
	speed: 0.0781s/iter; left time: 1629.1347s
	iters: 200, epoch: 21 | loss: 0.5386872
	speed: 0.0436s/iter; left time: 904.5275s
Epoch: 21 cost time: 7.860528230667114
Epoch: 21, Steps: 262 | Train Loss: 0.5552654 Vali Loss: 0.2766460 Test Loss: 0.3869958
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.6314409
	speed: 0.0865s/iter; left time: 1780.9596s
	iters: 200, epoch: 22 | loss: 0.6600674
	speed: 0.0151s/iter; left time: 309.2670s
Epoch: 22 cost time: 4.500032186508179
Epoch: 22, Steps: 262 | Train Loss: 0.5550747 Vali Loss: 0.2766505 Test Loss: 0.3869243
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4196491
	speed: 0.0706s/iter; left time: 1436.5764s
	iters: 200, epoch: 23 | loss: 0.7003863
	speed: 0.0155s/iter; left time: 314.0033s
Epoch: 23 cost time: 4.494609117507935
Epoch: 23, Steps: 262 | Train Loss: 0.5543584 Vali Loss: 0.2762989 Test Loss: 0.3869057
Validation loss decreased (0.276596 --> 0.276299).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3479788
	speed: 0.0725s/iter; left time: 1454.7605s
	iters: 200, epoch: 24 | loss: 0.6611049
	speed: 0.0151s/iter; left time: 301.3367s
Epoch: 24 cost time: 4.48465633392334
Epoch: 24, Steps: 262 | Train Loss: 0.5546702 Vali Loss: 0.2766524 Test Loss: 0.3868704
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.5623227
	speed: 0.0726s/iter; left time: 1438.1838s
	iters: 200, epoch: 25 | loss: 0.5029665
	speed: 0.0150s/iter; left time: 295.2859s
Epoch: 25 cost time: 4.467264175415039
Epoch: 25, Steps: 262 | Train Loss: 0.5547188 Vali Loss: 0.2765357 Test Loss: 0.3868426
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.6896816
	speed: 0.0717s/iter; left time: 1402.4953s
	iters: 200, epoch: 26 | loss: 0.5306759
	speed: 0.0154s/iter; left time: 299.0980s
Epoch: 26 cost time: 4.471191883087158
Epoch: 26, Steps: 262 | Train Loss: 0.5546963 Vali Loss: 0.2764199 Test Loss: 0.3868093
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.6474624
	speed: 0.0724s/iter; left time: 1397.3477s
	iters: 200, epoch: 27 | loss: 0.6815206
	speed: 0.0151s/iter; left time: 289.5367s
Epoch: 27 cost time: 6.021097183227539
Epoch: 27, Steps: 262 | Train Loss: 0.5544117 Vali Loss: 0.2765138 Test Loss: 0.3867957
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3959975
	speed: 0.0887s/iter; left time: 1687.1117s
	iters: 200, epoch: 28 | loss: 0.6788039
	speed: 0.0155s/iter; left time: 292.8703s
Epoch: 28 cost time: 4.604639291763306
Epoch: 28, Steps: 262 | Train Loss: 0.5547457 Vali Loss: 0.2763771 Test Loss: 0.3867690
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4368971
	speed: 0.0733s/iter; left time: 1375.4238s
	iters: 200, epoch: 29 | loss: 0.6120552
	speed: 0.0151s/iter; left time: 281.6340s
Epoch: 29 cost time: 4.553549528121948
Epoch: 29, Steps: 262 | Train Loss: 0.5544868 Vali Loss: 0.2765499 Test Loss: 0.3867343
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4922182
	speed: 0.0716s/iter; left time: 1324.3961s
	iters: 200, epoch: 30 | loss: 0.5632707
	speed: 0.0149s/iter; left time: 274.1330s
Epoch: 30 cost time: 4.451728105545044
Epoch: 30, Steps: 262 | Train Loss: 0.5545716 Vali Loss: 0.2765082 Test Loss: 0.3867140
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.5173002
	speed: 0.0726s/iter; left time: 1324.9887s
	iters: 200, epoch: 31 | loss: 0.4821102
	speed: 0.0152s/iter; left time: 274.9649s
Epoch: 31 cost time: 4.510677337646484
Epoch: 31, Steps: 262 | Train Loss: 0.5545839 Vali Loss: 0.2764931 Test Loss: 0.3867189
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.6740430
	speed: 0.0718s/iter; left time: 1290.5181s
	iters: 200, epoch: 32 | loss: 0.5726253
	speed: 0.0152s/iter; left time: 271.0189s
Epoch: 32 cost time: 4.428179979324341
Epoch: 32, Steps: 262 | Train Loss: 0.5542468 Vali Loss: 0.2764749 Test Loss: 0.3866958
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4090576
	speed: 0.0730s/iter; left time: 1293.5680s
	iters: 200, epoch: 33 | loss: 0.6346620
	speed: 0.0153s/iter; left time: 270.0917s
Epoch: 33 cost time: 4.496264457702637
Epoch: 33, Steps: 262 | Train Loss: 0.5547543 Vali Loss: 0.2766199 Test Loss: 0.3866821
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.5998807
	speed: 0.0728s/iter; left time: 1270.6190s
	iters: 200, epoch: 34 | loss: 0.6291433
	speed: 0.0153s/iter; left time: 266.1823s
Epoch: 34 cost time: 4.522413730621338
Epoch: 34, Steps: 262 | Train Loss: 0.5546464 Vali Loss: 0.2763053 Test Loss: 0.3866689
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3825750
	speed: 0.0735s/iter; left time: 1263.6397s
	iters: 200, epoch: 35 | loss: 0.5516776
	speed: 0.0153s/iter; left time: 261.0324s
Epoch: 35 cost time: 4.505577087402344
Epoch: 35, Steps: 262 | Train Loss: 0.5544528 Vali Loss: 0.2764311 Test Loss: 0.3866461
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.6979415
	speed: 0.0718s/iter; left time: 1215.5917s
	iters: 200, epoch: 36 | loss: 0.4334866
	speed: 0.0157s/iter; left time: 264.2342s
Epoch: 36 cost time: 4.50397253036499
Epoch: 36, Steps: 262 | Train Loss: 0.5537310 Vali Loss: 0.2765602 Test Loss: 0.3866401
EarlyStopping counter: 13 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4614961
	speed: 0.0765s/iter; left time: 1275.1373s
	iters: 200, epoch: 37 | loss: 0.6697476
	speed: 0.0164s/iter; left time: 271.6289s
Epoch: 37 cost time: 4.8979246616363525
Epoch: 37, Steps: 262 | Train Loss: 0.5540258 Vali Loss: 0.2765489 Test Loss: 0.3866237
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.6392415
	speed: 0.0801s/iter; left time: 1313.9654s
	iters: 200, epoch: 38 | loss: 0.4133988
	speed: 0.0315s/iter; left time: 514.0300s
Epoch: 38 cost time: 8.173592805862427
Epoch: 38, Steps: 262 | Train Loss: 0.5540594 Vali Loss: 0.2763539 Test Loss: 0.3866229
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4098078
	speed: 0.0890s/iter; left time: 1437.5149s
	iters: 200, epoch: 39 | loss: 0.5313968
	speed: 0.0153s/iter; left time: 244.7825s
Epoch: 39 cost time: 4.364055871963501
Epoch: 39, Steps: 262 | Train Loss: 0.5534607 Vali Loss: 0.2764273 Test Loss: 0.3866038
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.6380408
	speed: 0.0737s/iter; left time: 1170.1205s
	iters: 200, epoch: 40 | loss: 0.6098726
	speed: 0.0151s/iter; left time: 238.4978s
Epoch: 40 cost time: 4.424742937088013
Epoch: 40, Steps: 262 | Train Loss: 0.5532887 Vali Loss: 0.2762249 Test Loss: 0.3865981
Validation loss decreased (0.276299 --> 0.276225).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.5994689
	speed: 0.0736s/iter; left time: 1149.4572s
	iters: 200, epoch: 41 | loss: 0.6280344
	speed: 0.0151s/iter; left time: 234.4254s
Epoch: 41 cost time: 4.548232793807983
Epoch: 41, Steps: 262 | Train Loss: 0.5542869 Vali Loss: 0.2765517 Test Loss: 0.3866025
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.5089318
	speed: 0.0830s/iter; left time: 1274.5006s
	iters: 200, epoch: 42 | loss: 0.6644603
	speed: 0.0164s/iter; left time: 250.2482s
Epoch: 42 cost time: 4.90749454498291
Epoch: 42, Steps: 262 | Train Loss: 0.5541365 Vali Loss: 0.2761037 Test Loss: 0.3865942
Validation loss decreased (0.276225 --> 0.276104).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3619625
	speed: 0.0707s/iter; left time: 1067.2546s
	iters: 200, epoch: 43 | loss: 0.5250952
	speed: 0.0149s/iter; left time: 222.7738s
Epoch: 43 cost time: 4.361414909362793
Epoch: 43, Steps: 262 | Train Loss: 0.5539775 Vali Loss: 0.2763226 Test Loss: 0.3865826
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.5774832
	speed: 0.0732s/iter; left time: 1086.0029s
	iters: 200, epoch: 44 | loss: 0.5066230
	speed: 0.0150s/iter; left time: 221.1593s
Epoch: 44 cost time: 4.468207836151123
Epoch: 44, Steps: 262 | Train Loss: 0.5546242 Vali Loss: 0.2765200 Test Loss: 0.3865867
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.6232783
	speed: 0.0767s/iter; left time: 1117.2725s
	iters: 200, epoch: 45 | loss: 0.5459100
	speed: 0.0158s/iter; left time: 228.7960s
Epoch: 45 cost time: 4.672729253768921
Epoch: 45, Steps: 262 | Train Loss: 0.5534469 Vali Loss: 0.2763419 Test Loss: 0.3865729
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.5258723
	speed: 0.0918s/iter; left time: 1313.5395s
	iters: 200, epoch: 46 | loss: 0.4295703
	speed: 0.0172s/iter; left time: 244.6632s
Epoch: 46 cost time: 5.177316665649414
Epoch: 46, Steps: 262 | Train Loss: 0.5546116 Vali Loss: 0.2763396 Test Loss: 0.3865788
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.4724384
	speed: 0.0740s/iter; left time: 1039.3117s
	iters: 200, epoch: 47 | loss: 0.3994267
	speed: 0.0154s/iter; left time: 215.2530s
Epoch: 47 cost time: 4.4502692222595215
Epoch: 47, Steps: 262 | Train Loss: 0.5540800 Vali Loss: 0.2762821 Test Loss: 0.3865736
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.5847991
	speed: 0.0744s/iter; left time: 1025.2427s
	iters: 200, epoch: 48 | loss: 0.6216164
	speed: 0.0166s/iter; left time: 226.7662s
Epoch: 48 cost time: 4.8925416469573975
Epoch: 48, Steps: 262 | Train Loss: 0.5540583 Vali Loss: 0.2765018 Test Loss: 0.3865637
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.3741893
	speed: 0.0793s/iter; left time: 1072.5996s
	iters: 200, epoch: 49 | loss: 0.7303998
	speed: 0.0166s/iter; left time: 222.7047s
Epoch: 49 cost time: 4.930206537246704
Epoch: 49, Steps: 262 | Train Loss: 0.5537813 Vali Loss: 0.2763209 Test Loss: 0.3865584
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.4868462
	speed: 0.0770s/iter; left time: 1021.4405s
	iters: 200, epoch: 50 | loss: 0.5627155
	speed: 0.0163s/iter; left time: 214.7594s
Epoch: 50 cost time: 4.88114857673645
Epoch: 50, Steps: 262 | Train Loss: 0.5542143 Vali Loss: 0.2764751 Test Loss: 0.3865578
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.4207723
	speed: 0.0784s/iter; left time: 1018.7361s
	iters: 200, epoch: 51 | loss: 0.5889338
	speed: 0.0167s/iter; left time: 215.0110s
Epoch: 51 cost time: 4.866835832595825
Epoch: 51, Steps: 262 | Train Loss: 0.5542184 Vali Loss: 0.2760706 Test Loss: 0.3865606
Validation loss decreased (0.276104 --> 0.276071).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.3768391
	speed: 0.0997s/iter; left time: 1269.4576s
	iters: 200, epoch: 52 | loss: 0.6157225
	speed: 0.0149s/iter; left time: 188.0305s
Epoch: 52 cost time: 4.485017538070679
Epoch: 52, Steps: 262 | Train Loss: 0.5542222 Vali Loss: 0.2766829 Test Loss: 0.3865479
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.3873234
	speed: 0.0719s/iter; left time: 897.3442s
	iters: 200, epoch: 53 | loss: 0.7451658
	speed: 0.0149s/iter; left time: 184.0932s
Epoch: 53 cost time: 4.437946081161499
Epoch: 53, Steps: 262 | Train Loss: 0.5549950 Vali Loss: 0.2765406 Test Loss: 0.3865510
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.7015812
	speed: 0.0755s/iter; left time: 921.8341s
	iters: 200, epoch: 54 | loss: 0.6629603
	speed: 0.0162s/iter; left time: 196.4709s
Epoch: 54 cost time: 4.822843074798584
Epoch: 54, Steps: 262 | Train Loss: 0.5543643 Vali Loss: 0.2764435 Test Loss: 0.3865467
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.7048346
	speed: 0.0759s/iter; left time: 907.6353s
	iters: 200, epoch: 55 | loss: 0.5267716
	speed: 0.0154s/iter; left time: 182.7002s
Epoch: 55 cost time: 4.630366802215576
Epoch: 55, Steps: 262 | Train Loss: 0.5547635 Vali Loss: 0.2760683 Test Loss: 0.3865460
Validation loss decreased (0.276071 --> 0.276068).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.5557520
	speed: 0.0727s/iter; left time: 849.8175s
	iters: 200, epoch: 56 | loss: 0.6706701
	speed: 0.0151s/iter; left time: 175.4319s
Epoch: 56 cost time: 4.491262674331665
Epoch: 56, Steps: 262 | Train Loss: 0.5532675 Vali Loss: 0.2764292 Test Loss: 0.3865452
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.5678068
	speed: 0.0714s/iter; left time: 815.4756s
	iters: 200, epoch: 57 | loss: 0.5923125
	speed: 0.0155s/iter; left time: 175.6782s
Epoch: 57 cost time: 4.602870464324951
Epoch: 57, Steps: 262 | Train Loss: 0.5543793 Vali Loss: 0.2764885 Test Loss: 0.3865427
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.3895353
	speed: 0.0796s/iter; left time: 889.0079s
	iters: 200, epoch: 58 | loss: 0.6286792
	speed: 0.0148s/iter; left time: 163.9381s
Epoch: 58 cost time: 4.510205268859863
Epoch: 58, Steps: 262 | Train Loss: 0.5537881 Vali Loss: 0.2765573 Test Loss: 0.3865373
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.5619420
	speed: 0.0731s/iter; left time: 796.9092s
	iters: 200, epoch: 59 | loss: 0.5835046
	speed: 0.0147s/iter; left time: 159.0756s
Epoch: 59 cost time: 4.47430682182312
Epoch: 59, Steps: 262 | Train Loss: 0.5539914 Vali Loss: 0.2763305 Test Loss: 0.3865356
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.5907456
	speed: 0.0707s/iter; left time: 752.0055s
	iters: 200, epoch: 60 | loss: 0.6148961
	speed: 0.0153s/iter; left time: 160.9360s
Epoch: 60 cost time: 4.4696595668792725
Epoch: 60, Steps: 262 | Train Loss: 0.5534531 Vali Loss: 0.2764933 Test Loss: 0.3865321
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.6614705
	speed: 0.0730s/iter; left time: 757.5209s
	iters: 200, epoch: 61 | loss: 0.6376261
	speed: 0.0150s/iter; left time: 154.6556s
Epoch: 61 cost time: 4.420553922653198
Epoch: 61, Steps: 262 | Train Loss: 0.5544639 Vali Loss: 0.2764351 Test Loss: 0.3865293
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.6332496
	speed: 0.0727s/iter; left time: 736.0591s
	iters: 200, epoch: 62 | loss: 0.7615907
	speed: 0.0151s/iter; left time: 150.8130s
Epoch: 62 cost time: 4.586220979690552
Epoch: 62, Steps: 262 | Train Loss: 0.5538653 Vali Loss: 0.2764052 Test Loss: 0.3865300
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.7184968
	speed: 0.0728s/iter; left time: 717.9005s
	iters: 200, epoch: 63 | loss: 0.5545508
	speed: 0.0393s/iter; left time: 383.4168s
Epoch: 63 cost time: 7.0817461013793945
Epoch: 63, Steps: 262 | Train Loss: 0.5540862 Vali Loss: 0.2765182 Test Loss: 0.3865290
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.5185463
	speed: 0.0810s/iter; left time: 777.3097s
	iters: 200, epoch: 64 | loss: 0.4850675
	speed: 0.0170s/iter; left time: 161.4862s
Epoch: 64 cost time: 5.236169338226318
Epoch: 64, Steps: 262 | Train Loss: 0.5537401 Vali Loss: 0.2763628 Test Loss: 0.3865277
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.4056224
	speed: 0.0787s/iter; left time: 734.2535s
	iters: 200, epoch: 65 | loss: 0.5803784
	speed: 0.0167s/iter; left time: 154.3560s
Epoch: 65 cost time: 4.8515520095825195
Epoch: 65, Steps: 262 | Train Loss: 0.5539432 Vali Loss: 0.2763115 Test Loss: 0.3865255
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.7467262
	speed: 0.0802s/iter; left time: 727.1879s
	iters: 200, epoch: 66 | loss: 0.6153175
	speed: 0.0157s/iter; left time: 140.9062s
Epoch: 66 cost time: 4.78398585319519
Epoch: 66, Steps: 262 | Train Loss: 0.5543780 Vali Loss: 0.2763188 Test Loss: 0.3865244
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.6043701
	speed: 0.0725s/iter; left time: 639.0778s
	iters: 200, epoch: 67 | loss: 0.5864963
	speed: 0.0166s/iter; left time: 144.9914s
Epoch: 67 cost time: 4.649271011352539
Epoch: 67, Steps: 262 | Train Loss: 0.5540681 Vali Loss: 0.2764222 Test Loss: 0.3865234
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.4734750
	speed: 0.0730s/iter; left time: 624.2685s
	iters: 200, epoch: 68 | loss: 0.5511144
	speed: 0.0167s/iter; left time: 140.8292s
Epoch: 68 cost time: 4.702648639678955
Epoch: 68, Steps: 262 | Train Loss: 0.5536090 Vali Loss: 0.2759002 Test Loss: 0.3865233
Validation loss decreased (0.276068 --> 0.275900).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.5622596
	speed: 0.0730s/iter; left time: 605.0067s
	iters: 200, epoch: 69 | loss: 0.6654282
	speed: 0.0150s/iter; left time: 122.4098s
Epoch: 69 cost time: 4.396479845046997
Epoch: 69, Steps: 262 | Train Loss: 0.5549802 Vali Loss: 0.2764630 Test Loss: 0.3865232
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.4754567
	speed: 0.0724s/iter; left time: 581.0103s
	iters: 200, epoch: 70 | loss: 0.4991543
	speed: 0.0151s/iter; left time: 119.7727s
Epoch: 70 cost time: 4.5305986404418945
Epoch: 70, Steps: 262 | Train Loss: 0.5541414 Vali Loss: 0.2764826 Test Loss: 0.3865207
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.3611821
	speed: 0.0702s/iter; left time: 544.9596s
	iters: 200, epoch: 71 | loss: 0.5476847
	speed: 0.0147s/iter; left time: 112.9743s
Epoch: 71 cost time: 4.409775018692017
Epoch: 71, Steps: 262 | Train Loss: 0.5545526 Vali Loss: 0.2762686 Test Loss: 0.3865195
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.6777797
	speed: 0.0714s/iter; left time: 535.1711s
	iters: 200, epoch: 72 | loss: 0.6039444
	speed: 0.0152s/iter; left time: 112.6759s
Epoch: 72 cost time: 4.462541818618774
Epoch: 72, Steps: 262 | Train Loss: 0.5542075 Vali Loss: 0.2761002 Test Loss: 0.3865196
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.4984122
	speed: 0.0727s/iter; left time: 526.3298s
	iters: 200, epoch: 73 | loss: 0.4552654
	speed: 0.0150s/iter; left time: 106.7857s
Epoch: 73 cost time: 4.504234790802002
Epoch: 73, Steps: 262 | Train Loss: 0.5540455 Vali Loss: 0.2762530 Test Loss: 0.3865181
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.4497674
	speed: 0.0721s/iter; left time: 502.9523s
	iters: 200, epoch: 74 | loss: 0.3321420
	speed: 0.0147s/iter; left time: 101.3982s
Epoch: 74 cost time: 4.341602563858032
Epoch: 74, Steps: 262 | Train Loss: 0.5544821 Vali Loss: 0.2764495 Test Loss: 0.3865195
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.5068087
	speed: 0.0745s/iter; left time: 499.9066s
	iters: 200, epoch: 75 | loss: 0.5764715
	speed: 0.0171s/iter; left time: 112.9092s
Epoch: 75 cost time: 4.852524280548096
Epoch: 75, Steps: 262 | Train Loss: 0.5546780 Vali Loss: 0.2762969 Test Loss: 0.3865186
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.6294402
	speed: 0.0727s/iter; left time: 469.1772s
	iters: 200, epoch: 76 | loss: 0.6566312
	speed: 0.0152s/iter; left time: 96.2227s
Epoch: 76 cost time: 4.487693548202515
Epoch: 76, Steps: 262 | Train Loss: 0.5541115 Vali Loss: 0.2762863 Test Loss: 0.3865173
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.4913551
	speed: 0.0733s/iter; left time: 453.9289s
	iters: 200, epoch: 77 | loss: 0.6863981
	speed: 0.0151s/iter; left time: 91.7169s
Epoch: 77 cost time: 4.460444688796997
Epoch: 77, Steps: 262 | Train Loss: 0.5534163 Vali Loss: 0.2763308 Test Loss: 0.3865175
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.5173562
	speed: 0.0746s/iter; left time: 441.8884s
	iters: 200, epoch: 78 | loss: 0.4211376
	speed: 0.0146s/iter; left time: 85.0218s
Epoch: 78 cost time: 4.534886837005615
Epoch: 78, Steps: 262 | Train Loss: 0.5537098 Vali Loss: 0.2764328 Test Loss: 0.3865159
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.4732731
	speed: 0.0721s/iter; left time: 408.4363s
	iters: 200, epoch: 79 | loss: 0.3656099
	speed: 0.0167s/iter; left time: 92.8582s
Epoch: 79 cost time: 4.800447225570679
Epoch: 79, Steps: 262 | Train Loss: 0.5535030 Vali Loss: 0.2762657 Test Loss: 0.3865156
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.4779559
	speed: 0.0787s/iter; left time: 425.2610s
	iters: 200, epoch: 80 | loss: 0.4703487
	speed: 0.0166s/iter; left time: 87.8553s
Epoch: 80 cost time: 4.784571886062622
Epoch: 80, Steps: 262 | Train Loss: 0.5539079 Vali Loss: 0.2765769 Test Loss: 0.3865137
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.4560598
	speed: 0.0785s/iter; left time: 403.4270s
	iters: 200, epoch: 81 | loss: 0.4318720
	speed: 0.0163s/iter; left time: 82.3170s
Epoch: 81 cost time: 4.7915873527526855
Epoch: 81, Steps: 262 | Train Loss: 0.5537435 Vali Loss: 0.2761624 Test Loss: 0.3865129
EarlyStopping counter: 13 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.4566773
	speed: 0.0881s/iter; left time: 430.0128s
	iters: 200, epoch: 82 | loss: 0.6693897
	speed: 0.0160s/iter; left time: 76.4038s
Epoch: 82 cost time: 5.236249685287476
Epoch: 82, Steps: 262 | Train Loss: 0.5535919 Vali Loss: 0.2764530 Test Loss: 0.3865131
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.6276781
	speed: 0.0795s/iter; left time: 367.1838s
	iters: 200, epoch: 83 | loss: 0.4495651
	speed: 0.0273s/iter; left time: 123.1606s
Epoch: 83 cost time: 6.3062663078308105
Epoch: 83, Steps: 262 | Train Loss: 0.5544884 Vali Loss: 0.2764801 Test Loss: 0.3865122
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.4693577
	speed: 0.0777s/iter; left time: 338.5013s
	iters: 200, epoch: 84 | loss: 0.4910435
	speed: 0.0163s/iter; left time: 69.2747s
Epoch: 84 cost time: 4.896987676620483
Epoch: 84, Steps: 262 | Train Loss: 0.5539116 Vali Loss: 0.2764524 Test Loss: 0.3865122
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.4955295
	speed: 0.0728s/iter; left time: 297.8313s
	iters: 200, epoch: 85 | loss: 0.5091696
	speed: 0.0226s/iter; left time: 90.2787s
Epoch: 85 cost time: 5.5068018436431885
Epoch: 85, Steps: 262 | Train Loss: 0.5543117 Vali Loss: 0.2766346 Test Loss: 0.3865125
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.4974166
	speed: 0.0733s/iter; left time: 280.6892s
	iters: 200, epoch: 86 | loss: 0.6183485
	speed: 0.0147s/iter; left time: 54.9897s
Epoch: 86 cost time: 4.350062370300293
Epoch: 86, Steps: 262 | Train Loss: 0.5537872 Vali Loss: 0.2764170 Test Loss: 0.3865109
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.7604893
	speed: 0.0725s/iter; left time: 258.7738s
	iters: 200, epoch: 87 | loss: 0.5279590
	speed: 0.0148s/iter; left time: 51.3700s
Epoch: 87 cost time: 4.493456125259399
Epoch: 87, Steps: 262 | Train Loss: 0.5533853 Vali Loss: 0.2764825 Test Loss: 0.3865099
EarlyStopping counter: 19 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.4365487
	speed: 0.0709s/iter; left time: 234.5932s
	iters: 200, epoch: 88 | loss: 0.5501505
	speed: 0.0148s/iter; left time: 47.5592s
Epoch: 88 cost time: 4.400891065597534
Epoch: 88, Steps: 262 | Train Loss: 0.5542073 Vali Loss: 0.2765280 Test Loss: 0.3865101
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_180_720_FITS_ETTm2_ftM_sl180_ll48_pl720_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.3838862180709839, mae:0.3874606788158417, rse:0.49801871180534363, corr:[0.54842323 0.5468628  0.54187316 0.5396146  0.5396513  0.5393476
 0.5378132  0.5359347  0.5349039  0.5347288  0.5345595  0.5338794
 0.5328451  0.53202856 0.5317662  0.5316076  0.5310023  0.52987826
 0.5286592  0.52782166 0.5274225  0.5270633  0.5264255  0.52562386
 0.5249853  0.5246914  0.52460134 0.5243183  0.52358896 0.52256495
 0.5217047  0.52127534 0.5210779  0.52078754 0.5202071  0.5194528
 0.5186999  0.51812506 0.5175845  0.51694524 0.5162352  0.51560146
 0.5152169  0.5150288  0.5147826  0.5142938  0.51349103 0.51250374
 0.5115345  0.5107134  0.51001424 0.50937885 0.5086528  0.507828
 0.507117   0.50666994 0.5063361  0.5060184  0.5055986  0.50514424
 0.5047504  0.50455254 0.50451845 0.5044074  0.50417536 0.5039072
 0.5036532  0.5035335  0.5035026  0.5034793  0.50334036 0.5031107
 0.50291294 0.50274223 0.5026208  0.5024196  0.5021112  0.5016953
 0.5012871  0.50091153 0.5005312  0.50010866 0.4996688  0.49921596
 0.49877864 0.49837345 0.49796256 0.49757499 0.4971725  0.4967695
 0.496409   0.49605003 0.49556118 0.49479738 0.4936448  0.49206018
 0.49013498 0.48817688 0.486314   0.48460132 0.4830674  0.48170477
 0.48043782 0.479177   0.47782794 0.4764405  0.47513118 0.47397906
 0.47292015 0.47176597 0.47065452 0.46958426 0.46855852 0.4674945
 0.46630833 0.46510375 0.46395415 0.46287298 0.46186122 0.4608419
 0.45984834 0.45891008 0.4580155  0.45711553 0.45616975 0.45516643
 0.4541459  0.4531318  0.45216328 0.45121744 0.45031008 0.44941494
 0.44856265 0.447709   0.44699252 0.4464194  0.44587862 0.44534853
 0.44479552 0.44423717 0.44364536 0.443003   0.44229674 0.44146293
 0.44051415 0.43952933 0.43855193 0.43767297 0.43693575 0.4362432
 0.43561697 0.43518737 0.43482482 0.43443692 0.4339547  0.4333326
 0.43269446 0.43219268 0.43180603 0.43150583 0.43122104 0.4308849
 0.43058026 0.43027544 0.43018878 0.43024212 0.430289   0.43029058
 0.43023562 0.4302138  0.43024334 0.43032163 0.4304084  0.4303558
 0.43019316 0.42996448 0.4297867  0.42965823 0.42955992 0.42943388
 0.4291839  0.42882723 0.4285133  0.42828348 0.42815346 0.42799288
 0.42775285 0.42738685 0.42686453 0.4261001  0.42497838 0.42343098
 0.42156887 0.41973352 0.4180573  0.41660547 0.4154104  0.41427216
 0.41302043 0.41163704 0.41023472 0.4090964  0.40821856 0.40757608
 0.4069604  0.40623644 0.40542042 0.404635   0.4039396  0.40325716
 0.4024709  0.40157565 0.40066585 0.39983398 0.39910105 0.39834416
 0.3975037  0.39648807 0.39550707 0.39457256 0.39361122 0.3926294
 0.3915479  0.39047548 0.38960254 0.38882568 0.3881126  0.38736683
 0.38645044 0.38537833 0.3842907  0.38338625 0.3827143  0.3822707
 0.38187778 0.38148233 0.38113883 0.38072437 0.38033047 0.3798739
 0.37933582 0.37868586 0.37800628 0.37754223 0.3772895  0.37721607
 0.37727714 0.37739748 0.37757105 0.37773204 0.37791237 0.37808666
 0.37818274 0.37832546 0.37847972 0.37855572 0.37850425 0.3784051
 0.37829724 0.37817478 0.37808767 0.37810326 0.37814564 0.37808543
 0.3779656  0.3778654  0.3778312  0.3778346  0.37785068 0.37783405
 0.3776853  0.3774474  0.37714556 0.3769192  0.3767988  0.3767818
 0.3767625  0.37666237 0.3765149  0.37638187 0.37620968 0.37614036
 0.37613788 0.3760635  0.37583396 0.3753611  0.37457022 0.37341702
 0.37200522 0.37073383 0.36966276 0.36884975 0.36818904 0.36756346
 0.3669928  0.36635438 0.36565745 0.3649711  0.3644332  0.36403647
 0.36369336 0.36316246 0.36254352 0.36190632 0.3612667  0.36058277
 0.3598743  0.35913065 0.3583167  0.35749346 0.35670525 0.35598925
 0.35528675 0.3546221  0.3539223  0.3532093  0.35237446 0.3514518
 0.3505203  0.3496589  0.34893098 0.3483161  0.34775275 0.3471438
 0.34648868 0.34581378 0.3451977  0.3446668  0.34418094 0.3437706
 0.34348997 0.34325522 0.34302932 0.3426714  0.34212992 0.34151143
 0.34083813 0.34017956 0.3395762  0.33914846 0.33877406 0.33843842
 0.33822116 0.33821678 0.33835727 0.33855185 0.33858496 0.33848202
 0.33828747 0.3381566  0.3381417  0.33817086 0.33810902 0.33791727
 0.33768073 0.33759198 0.33766365 0.3378311  0.33788368 0.3377344
 0.33751377 0.33743864 0.33760646 0.33793086 0.33814994 0.33817473
 0.33798912 0.33782005 0.33784932 0.3380479  0.33835888 0.33849537
 0.33844662 0.33840495 0.33853343 0.33882117 0.33908    0.33913246
 0.33898073 0.3387063  0.33842364 0.3380698  0.3374723  0.3364155
 0.3349487  0.33340657 0.33214045 0.33125153 0.33050257 0.3297219
 0.32875004 0.32761797 0.3265282  0.32564873 0.32493916 0.32432586
 0.32369906 0.32299343 0.32233748 0.32186356 0.32147282 0.32091412
 0.32009166 0.31902122 0.3179618  0.31711563 0.31646022 0.31586713
 0.3152694  0.3146445  0.31403214 0.31345406 0.31288335 0.31226164
 0.31156325 0.31084993 0.3102353  0.30981088 0.30942866 0.30902144
 0.308512   0.3079266  0.30744547 0.30724803 0.30716512 0.30707896
 0.30695897 0.30681863 0.30667397 0.30658522 0.30642593 0.30610773
 0.3054828  0.30471802 0.30397108 0.30351144 0.30328512 0.30309469
 0.30289915 0.3027036  0.30257854 0.3024735  0.30229902 0.30210495
 0.30188555 0.3017259  0.30169702 0.30167934 0.30158347 0.30140206
 0.301205   0.30105278 0.30108154 0.30131024 0.30146652 0.30147052
 0.30128634 0.3010991  0.30104834 0.30117327 0.3013621  0.3013863
 0.30116236 0.3008683  0.30072218 0.30080602 0.3009276  0.30093628
 0.3007756  0.30047694 0.30020052 0.29998302 0.2998306  0.29964456
 0.2992737  0.2987304  0.2980706  0.2972316  0.29608703 0.29455343
 0.29272363 0.29095963 0.28951672 0.28851357 0.28779098 0.28707823
 0.28622115 0.2852148  0.28425953 0.28358483 0.28326228 0.28315017
 0.2830493  0.28282818 0.282533   0.2822525  0.28194523 0.28144395
 0.28068084 0.27968013 0.2786025  0.27768278 0.27696303 0.2763567
 0.27567858 0.274897   0.27409467 0.27334797 0.27273282 0.2722095
 0.2716595  0.2710388  0.2703778  0.26974627 0.26918837 0.2686984
 0.2681978  0.26764712 0.26709247 0.2665861  0.26620135 0.26592213
 0.2656569  0.2653956  0.26508263 0.26464522 0.26418537 0.2636175
 0.26299176 0.26231387 0.26162824 0.26101458 0.26056293 0.26019764
 0.25992993 0.2597994  0.2598353  0.25989982 0.25992283 0.25973925
 0.25950465 0.25937214 0.25933596 0.2593423  0.25922862 0.25892535
 0.25848576 0.25815752 0.25808856 0.25822505 0.25828776 0.25815922
 0.25784528 0.25756505 0.25751445 0.25764292 0.25776693 0.25773898
 0.2574548  0.25716072 0.2570389  0.25713256 0.25731    0.25736892
 0.2572028  0.2569631  0.256812   0.2567731  0.25677583 0.2566472
 0.25636888 0.25593632 0.25539246 0.2546088  0.2534022  0.2515971
 0.24943437 0.24748638 0.2460045  0.24500011 0.24425511 0.24351488
 0.2425607  0.24147715 0.24036926 0.2393381  0.23850568 0.23793732
 0.23750034 0.23702015 0.23658583 0.23622394 0.23577785 0.23509486
 0.2341368  0.23307066 0.2321507  0.2314416  0.2309595  0.23051937
 0.23001938 0.22950286 0.22896181 0.2283777  0.22787857 0.22738323
 0.22675243 0.22609773 0.2255115  0.22500867 0.22467817 0.2243778
 0.2240682  0.22363591 0.22317165 0.22280048 0.2225707  0.222482
 0.22237283 0.22228567 0.22206023 0.22189242 0.22174726 0.22146921
 0.22108977 0.22069088 0.22044523 0.22038229 0.22037035 0.22026703
 0.22015764 0.22027294 0.22053114 0.22081934 0.22110198 0.22112426
 0.22101954 0.22087725 0.2208115  0.2208901  0.22101937 0.22096874
 0.22077285 0.22062159 0.22070922 0.22092207 0.22108157 0.22104856
 0.22081125 0.22070095 0.22080112 0.22118542 0.2215758  0.2216756
 0.22159715 0.22152174 0.22169113 0.222205   0.22276089 0.22300488
 0.22305728 0.22317736 0.2236482  0.22440386 0.22509733 0.22542654
 0.22536789 0.22518533 0.22502089 0.2247125  0.2238677  0.22228801
 0.22028536 0.21852984 0.21738891 0.21671918 0.21613352 0.21539572
 0.21451807 0.21378314 0.21339433 0.21323436 0.21307401 0.21277311
 0.21235693 0.21182095 0.21150166 0.21141559 0.21134469 0.21087927
 0.20992859 0.20872572 0.20759693 0.206702   0.2059929  0.20517543
 0.20418325 0.2030521  0.20193014 0.20095028 0.19999592 0.19896331
 0.19769329 0.19635102 0.19503583 0.19400631 0.19324838 0.1926329
 0.19197814 0.19130008 0.1904511  0.18958089 0.18881665 0.18866812
 0.18902652 0.18924114 0.18880962 0.18826404 0.18906492 0.19346252]
