Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=50, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_360_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_360_336_FITS_ETTm2_ftM_sl360_ll48_pl336_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33865
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=50, out_features=96, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4300800.0
params:  4896.0
Trainable parameters:  4896
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5079725
	speed: 0.0280s/iter; left time: 735.4279s
	iters: 200, epoch: 1 | loss: 0.4268003
	speed: 0.0137s/iter; left time: 358.3350s
Epoch: 1 cost time: 5.0736095905303955
Epoch: 1, Steps: 264 | Train Loss: 0.4877513 Vali Loss: 0.2219545 Test Loss: 0.2948390
Validation loss decreased (inf --> 0.221955).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3232801
	speed: 0.0699s/iter; left time: 1820.2511s
	iters: 200, epoch: 2 | loss: 0.5404126
	speed: 0.0132s/iter; left time: 343.1576s
Epoch: 2 cost time: 4.065794467926025
Epoch: 2, Steps: 264 | Train Loss: 0.4239889 Vali Loss: 0.2107651 Test Loss: 0.2833081
Validation loss decreased (0.221955 --> 0.210765).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3087208
	speed: 0.0673s/iter; left time: 1733.2614s
	iters: 200, epoch: 3 | loss: 0.5166541
	speed: 0.0131s/iter; left time: 335.6765s
Epoch: 3 cost time: 4.0960588455200195
Epoch: 3, Steps: 264 | Train Loss: 0.4107112 Vali Loss: 0.2063268 Test Loss: 0.2789986
Validation loss decreased (0.210765 --> 0.206327).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3289446
	speed: 0.0667s/iter; left time: 1701.1884s
	iters: 200, epoch: 4 | loss: 0.5611915
	speed: 0.0130s/iter; left time: 330.5217s
Epoch: 4 cost time: 3.9651849269866943
Epoch: 4, Steps: 264 | Train Loss: 0.4048323 Vali Loss: 0.2039802 Test Loss: 0.2765012
Validation loss decreased (0.206327 --> 0.203980).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3505709
	speed: 0.0669s/iter; left time: 1689.3656s
	iters: 200, epoch: 5 | loss: 0.4028807
	speed: 0.0129s/iter; left time: 324.5701s
Epoch: 5 cost time: 3.911592721939087
Epoch: 5, Steps: 264 | Train Loss: 0.4010343 Vali Loss: 0.2024414 Test Loss: 0.2750449
Validation loss decreased (0.203980 --> 0.202441).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3854515
	speed: 0.0689s/iter; left time: 1722.1121s
	iters: 200, epoch: 6 | loss: 0.4444091
	speed: 0.0129s/iter; left time: 320.1528s
Epoch: 6 cost time: 4.0463645458221436
Epoch: 6, Steps: 264 | Train Loss: 0.3986661 Vali Loss: 0.2015441 Test Loss: 0.2742437
Validation loss decreased (0.202441 --> 0.201544).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3924072
	speed: 0.0677s/iter; left time: 1673.1884s
	iters: 200, epoch: 7 | loss: 0.3642645
	speed: 0.0132s/iter; left time: 325.6982s
Epoch: 7 cost time: 4.198420286178589
Epoch: 7, Steps: 264 | Train Loss: 0.3964606 Vali Loss: 0.2006273 Test Loss: 0.2734701
Validation loss decreased (0.201544 --> 0.200627).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3812329
	speed: 0.0746s/iter; left time: 1824.9166s
	iters: 200, epoch: 8 | loss: 0.4422586
	speed: 0.0131s/iter; left time: 317.9040s
Epoch: 8 cost time: 4.197015047073364
Epoch: 8, Steps: 264 | Train Loss: 0.3953029 Vali Loss: 0.2000873 Test Loss: 0.2731937
Validation loss decreased (0.200627 --> 0.200087).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2766098
	speed: 0.0666s/iter; left time: 1610.5455s
	iters: 200, epoch: 9 | loss: 0.2900935
	speed: 0.0128s/iter; left time: 309.0651s
Epoch: 9 cost time: 3.883402109146118
Epoch: 9, Steps: 264 | Train Loss: 0.3943492 Vali Loss: 0.1997811 Test Loss: 0.2728218
Validation loss decreased (0.200087 --> 0.199781).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4482324
	speed: 0.0664s/iter; left time: 1589.4598s
	iters: 200, epoch: 10 | loss: 0.2598111
	speed: 0.0129s/iter; left time: 306.1777s
Epoch: 10 cost time: 3.9730165004730225
Epoch: 10, Steps: 264 | Train Loss: 0.3935806 Vali Loss: 0.1994146 Test Loss: 0.2727568
Validation loss decreased (0.199781 --> 0.199415).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3616371
	speed: 0.0694s/iter; left time: 1641.4903s
	iters: 200, epoch: 11 | loss: 0.3090070
	speed: 0.0136s/iter; left time: 319.4119s
Epoch: 11 cost time: 4.0251970291137695
Epoch: 11, Steps: 264 | Train Loss: 0.3931629 Vali Loss: 0.1991843 Test Loss: 0.2725492
Validation loss decreased (0.199415 --> 0.199184).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3216959
	speed: 0.0708s/iter; left time: 1657.3680s
	iters: 200, epoch: 12 | loss: 0.2626127
	speed: 0.0139s/iter; left time: 324.7055s
Epoch: 12 cost time: 4.382630109786987
Epoch: 12, Steps: 264 | Train Loss: 0.3928494 Vali Loss: 0.1990484 Test Loss: 0.2724313
Validation loss decreased (0.199184 --> 0.199048).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2771719
	speed: 0.0722s/iter; left time: 1669.8564s
	iters: 200, epoch: 13 | loss: 0.5165572
	speed: 0.0161s/iter; left time: 370.0637s
Epoch: 13 cost time: 4.8272528648376465
Epoch: 13, Steps: 264 | Train Loss: 0.3925349 Vali Loss: 0.1989285 Test Loss: 0.2723158
Validation loss decreased (0.199048 --> 0.198928).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3664211
	speed: 0.0901s/iter; left time: 2059.6517s
	iters: 200, epoch: 14 | loss: 0.4157695
	speed: 0.0166s/iter; left time: 377.3968s
Epoch: 14 cost time: 6.120192527770996
Epoch: 14, Steps: 264 | Train Loss: 0.3921419 Vali Loss: 0.1986704 Test Loss: 0.2721544
Validation loss decreased (0.198928 --> 0.198670).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.5590216
	speed: 0.0683s/iter; left time: 1544.6640s
	iters: 200, epoch: 15 | loss: 0.4142651
	speed: 0.0136s/iter; left time: 305.1531s
Epoch: 15 cost time: 4.105398893356323
Epoch: 15, Steps: 264 | Train Loss: 0.3918282 Vali Loss: 0.1987526 Test Loss: 0.2722421
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3254532
	speed: 0.0671s/iter; left time: 1499.0600s
	iters: 200, epoch: 16 | loss: 0.4530067
	speed: 0.0132s/iter; left time: 293.5766s
Epoch: 16 cost time: 3.9962472915649414
Epoch: 16, Steps: 264 | Train Loss: 0.3917401 Vali Loss: 0.1987894 Test Loss: 0.2721792
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3745361
	speed: 0.0674s/iter; left time: 1488.1580s
	iters: 200, epoch: 17 | loss: 0.5312583
	speed: 0.0131s/iter; left time: 288.7914s
Epoch: 17 cost time: 4.028532981872559
Epoch: 17, Steps: 264 | Train Loss: 0.3911182 Vali Loss: 0.1986002 Test Loss: 0.2721407
Validation loss decreased (0.198670 --> 0.198600).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2835913
	speed: 0.0690s/iter; left time: 1504.0503s
	iters: 200, epoch: 18 | loss: 0.3131454
	speed: 0.0138s/iter; left time: 299.7578s
Epoch: 18 cost time: 4.204766273498535
Epoch: 18, Steps: 264 | Train Loss: 0.3911184 Vali Loss: 0.1986209 Test Loss: 0.2720881
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3617384
	speed: 0.0696s/iter; left time: 1498.9606s
	iters: 200, epoch: 19 | loss: 0.4841837
	speed: 0.0152s/iter; left time: 326.0318s
Epoch: 19 cost time: 4.336735248565674
Epoch: 19, Steps: 264 | Train Loss: 0.3907069 Vali Loss: 0.1984044 Test Loss: 0.2719642
Validation loss decreased (0.198600 --> 0.198404).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2926632
	speed: 0.0694s/iter; left time: 1476.2802s
	iters: 200, epoch: 20 | loss: 0.5572822
	speed: 0.0130s/iter; left time: 274.9446s
Epoch: 20 cost time: 4.026817321777344
Epoch: 20, Steps: 264 | Train Loss: 0.3902082 Vali Loss: 0.1982919 Test Loss: 0.2719822
Validation loss decreased (0.198404 --> 0.198292).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3607424
	speed: 0.0657s/iter; left time: 1381.9715s
	iters: 200, epoch: 21 | loss: 0.2896318
	speed: 0.0131s/iter; left time: 274.0198s
Epoch: 21 cost time: 3.9975991249084473
Epoch: 21, Steps: 264 | Train Loss: 0.3904713 Vali Loss: 0.1985405 Test Loss: 0.2719674
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.5180629
	speed: 0.0684s/iter; left time: 1419.9564s
	iters: 200, epoch: 22 | loss: 0.4693222
	speed: 0.0127s/iter; left time: 263.3538s
Epoch: 22 cost time: 3.929328680038452
Epoch: 22, Steps: 264 | Train Loss: 0.3906163 Vali Loss: 0.1981936 Test Loss: 0.2719249
Validation loss decreased (0.198292 --> 0.198194).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3745666
	speed: 0.0660s/iter; left time: 1352.3016s
	iters: 200, epoch: 23 | loss: 0.3146456
	speed: 0.0160s/iter; left time: 325.6924s
Epoch: 23 cost time: 4.968832492828369
Epoch: 23, Steps: 264 | Train Loss: 0.3904988 Vali Loss: 0.1983228 Test Loss: 0.2718841
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.5517732
	speed: 0.0754s/iter; left time: 1525.1890s
	iters: 200, epoch: 24 | loss: 0.4673443
	speed: 0.0127s/iter; left time: 255.1658s
Epoch: 24 cost time: 4.046126127243042
Epoch: 24, Steps: 264 | Train Loss: 0.3903330 Vali Loss: 0.1981168 Test Loss: 0.2718813
Validation loss decreased (0.198194 --> 0.198117).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3903140
	speed: 0.0670s/iter; left time: 1336.7885s
	iters: 200, epoch: 25 | loss: 0.4645967
	speed: 0.0129s/iter; left time: 257.0893s
Epoch: 25 cost time: 3.92549991607666
Epoch: 25, Steps: 264 | Train Loss: 0.3900304 Vali Loss: 0.1981591 Test Loss: 0.2718693
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2985716
	speed: 0.0672s/iter; left time: 1323.5903s
	iters: 200, epoch: 26 | loss: 0.3616181
	speed: 0.0131s/iter; left time: 257.2844s
Epoch: 26 cost time: 3.9743807315826416
Epoch: 26, Steps: 264 | Train Loss: 0.3901482 Vali Loss: 0.1983375 Test Loss: 0.2718799
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4622995
	speed: 0.0719s/iter; left time: 1397.3625s
	iters: 200, epoch: 27 | loss: 0.4769389
	speed: 0.0166s/iter; left time: 320.4194s
Epoch: 27 cost time: 4.726036071777344
Epoch: 27, Steps: 264 | Train Loss: 0.3900087 Vali Loss: 0.1982684 Test Loss: 0.2718477
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2644114
	speed: 0.0736s/iter; left time: 1410.6190s
	iters: 200, epoch: 28 | loss: 0.3240031
	speed: 0.0136s/iter; left time: 260.0491s
Epoch: 28 cost time: 4.357740640640259
Epoch: 28, Steps: 264 | Train Loss: 0.3898293 Vali Loss: 0.1983315 Test Loss: 0.2717920
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3189604
	speed: 0.0728s/iter; left time: 1376.9698s
	iters: 200, epoch: 29 | loss: 0.3790975
	speed: 0.0139s/iter; left time: 260.7958s
Epoch: 29 cost time: 4.363154411315918
Epoch: 29, Steps: 264 | Train Loss: 0.3902089 Vali Loss: 0.1979452 Test Loss: 0.2717780
Validation loss decreased (0.198117 --> 0.197945).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2776498
	speed: 0.0680s/iter; left time: 1268.7921s
	iters: 200, epoch: 30 | loss: 0.4101589
	speed: 0.0150s/iter; left time: 278.2331s
Epoch: 30 cost time: 4.392959356307983
Epoch: 30, Steps: 264 | Train Loss: 0.3900340 Vali Loss: 0.1980779 Test Loss: 0.2718062
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3976499
	speed: 0.0764s/iter; left time: 1404.4801s
	iters: 200, epoch: 31 | loss: 0.3661179
	speed: 0.0158s/iter; left time: 288.6887s
Epoch: 31 cost time: 4.709360122680664
Epoch: 31, Steps: 264 | Train Loss: 0.3902588 Vali Loss: 0.1982380 Test Loss: 0.2717810
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.5177226
	speed: 0.0706s/iter; left time: 1278.9125s
	iters: 200, epoch: 32 | loss: 0.4662154
	speed: 0.0141s/iter; left time: 253.1523s
Epoch: 32 cost time: 4.177280426025391
Epoch: 32, Steps: 264 | Train Loss: 0.3898015 Vali Loss: 0.1981531 Test Loss: 0.2717562
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.5345749
	speed: 0.0664s/iter; left time: 1184.9682s
	iters: 200, epoch: 33 | loss: 0.4337874
	speed: 0.0141s/iter; left time: 250.2375s
Epoch: 33 cost time: 4.184698104858398
Epoch: 33, Steps: 264 | Train Loss: 0.3900263 Vali Loss: 0.1980373 Test Loss: 0.2717543
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2939301
	speed: 0.0724s/iter; left time: 1272.6220s
	iters: 200, epoch: 34 | loss: 0.4120239
	speed: 0.0164s/iter; left time: 287.2408s
Epoch: 34 cost time: 4.639180898666382
Epoch: 34, Steps: 264 | Train Loss: 0.3890733 Vali Loss: 0.1980057 Test Loss: 0.2717313
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2853558
	speed: 0.0894s/iter; left time: 1548.8118s
	iters: 200, epoch: 35 | loss: 0.3573048
	speed: 0.0163s/iter; left time: 280.4863s
Epoch: 35 cost time: 4.744509935379028
Epoch: 35, Steps: 264 | Train Loss: 0.3896781 Vali Loss: 0.1982635 Test Loss: 0.2717248
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3098502
	speed: 0.0707s/iter; left time: 1205.4647s
	iters: 200, epoch: 36 | loss: 0.4830793
	speed: 0.0129s/iter; left time: 218.6612s
Epoch: 36 cost time: 4.153578996658325
Epoch: 36, Steps: 264 | Train Loss: 0.3898624 Vali Loss: 0.1978771 Test Loss: 0.2717400
Validation loss decreased (0.197945 --> 0.197877).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.5451421
	speed: 0.0677s/iter; left time: 1136.3872s
	iters: 200, epoch: 37 | loss: 0.3378130
	speed: 0.0129s/iter; left time: 215.5929s
Epoch: 37 cost time: 3.9928736686706543
Epoch: 37, Steps: 264 | Train Loss: 0.3896173 Vali Loss: 0.1979757 Test Loss: 0.2717056
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4935889
	speed: 0.1057s/iter; left time: 1747.9139s
	iters: 200, epoch: 38 | loss: 0.3036645
	speed: 0.0135s/iter; left time: 222.5741s
Epoch: 38 cost time: 4.07649827003479
Epoch: 38, Steps: 264 | Train Loss: 0.3896278 Vali Loss: 0.1981119 Test Loss: 0.2717023
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.5411075
	speed: 0.0726s/iter; left time: 1180.9677s
	iters: 200, epoch: 39 | loss: 0.3557138
	speed: 0.0163s/iter; left time: 263.8570s
Epoch: 39 cost time: 4.95444130897522
Epoch: 39, Steps: 264 | Train Loss: 0.3892396 Vali Loss: 0.1981908 Test Loss: 0.2717075
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.3568632
	speed: 0.0813s/iter; left time: 1301.3426s
	iters: 200, epoch: 40 | loss: 0.3611001
	speed: 0.0202s/iter; left time: 320.6291s
Epoch: 40 cost time: 5.54910945892334
Epoch: 40, Steps: 264 | Train Loss: 0.3891432 Vali Loss: 0.1980017 Test Loss: 0.2717120
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3157711
	speed: 0.0699s/iter; left time: 1100.9674s
	iters: 200, epoch: 41 | loss: 0.3382979
	speed: 0.0134s/iter; left time: 209.5009s
Epoch: 41 cost time: 4.174273252487183
Epoch: 41, Steps: 264 | Train Loss: 0.3898189 Vali Loss: 0.1979357 Test Loss: 0.2716825
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3733726
	speed: 0.0692s/iter; left time: 1070.4600s
	iters: 200, epoch: 42 | loss: 0.3619128
	speed: 0.0148s/iter; left time: 228.1391s
Epoch: 42 cost time: 4.186940670013428
Epoch: 42, Steps: 264 | Train Loss: 0.3897315 Vali Loss: 0.1982639 Test Loss: 0.2716902
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.4667417
	speed: 0.0683s/iter; left time: 1039.5711s
	iters: 200, epoch: 43 | loss: 0.3424361
	speed: 0.0128s/iter; left time: 193.4204s
Epoch: 43 cost time: 3.92879319190979
Epoch: 43, Steps: 264 | Train Loss: 0.3897281 Vali Loss: 0.1981162 Test Loss: 0.2716829
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2634954
	speed: 0.0676s/iter; left time: 1010.6758s
	iters: 200, epoch: 44 | loss: 0.3553886
	speed: 0.0133s/iter; left time: 197.6187s
Epoch: 44 cost time: 3.9863734245300293
Epoch: 44, Steps: 264 | Train Loss: 0.3896778 Vali Loss: 0.1981218 Test Loss: 0.2716801
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.3863559
	speed: 0.0678s/iter; left time: 995.9513s
	iters: 200, epoch: 45 | loss: 0.3379697
	speed: 0.0128s/iter; left time: 186.1010s
Epoch: 45 cost time: 4.132331132888794
Epoch: 45, Steps: 264 | Train Loss: 0.3897305 Vali Loss: 0.1980453 Test Loss: 0.2716679
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.4230730
	speed: 0.0877s/iter; left time: 1265.0874s
	iters: 200, epoch: 46 | loss: 0.3754473
	speed: 0.0439s/iter; left time: 628.2835s
Epoch: 46 cost time: 10.489018201828003
Epoch: 46, Steps: 264 | Train Loss: 0.3895358 Vali Loss: 0.1979777 Test Loss: 0.2716718
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.3123893
	speed: 0.0869s/iter; left time: 1230.9157s
	iters: 200, epoch: 47 | loss: 0.4583958
	speed: 0.0154s/iter; left time: 216.6498s
Epoch: 47 cost time: 4.305246114730835
Epoch: 47, Steps: 264 | Train Loss: 0.3895287 Vali Loss: 0.1979527 Test Loss: 0.2716739
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.4298669
	speed: 0.0733s/iter; left time: 1018.1503s
	iters: 200, epoch: 48 | loss: 0.4534018
	speed: 0.0132s/iter; left time: 182.2029s
Epoch: 48 cost time: 4.087999105453491
Epoch: 48, Steps: 264 | Train Loss: 0.3893721 Vali Loss: 0.1979285 Test Loss: 0.2716621
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2838598
	speed: 0.0677s/iter; left time: 922.4215s
	iters: 200, epoch: 49 | loss: 0.2621756
	speed: 0.0284s/iter; left time: 384.1919s
Epoch: 49 cost time: 5.5593342781066895
Epoch: 49, Steps: 264 | Train Loss: 0.3889337 Vali Loss: 0.1980496 Test Loss: 0.2716599
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.3569249
	speed: 0.0853s/iter; left time: 1140.4145s
	iters: 200, epoch: 50 | loss: 0.4132238
	speed: 0.0433s/iter; left time: 574.0539s
Epoch: 50 cost time: 9.676681280136108
Epoch: 50, Steps: 264 | Train Loss: 0.3896740 Vali Loss: 0.1981803 Test Loss: 0.2716584
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.5615945
	speed: 0.0811s/iter; left time: 1062.2823s
	iters: 200, epoch: 51 | loss: 0.4699703
	speed: 0.0129s/iter; left time: 167.4872s
Epoch: 51 cost time: 4.0334789752960205
Epoch: 51, Steps: 264 | Train Loss: 0.3896168 Vali Loss: 0.1982314 Test Loss: 0.2716617
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.3453433
	speed: 0.0707s/iter; left time: 908.0492s
	iters: 200, epoch: 52 | loss: 0.3745330
	speed: 0.0159s/iter; left time: 202.9985s
Epoch: 52 cost time: 4.797725200653076
Epoch: 52, Steps: 264 | Train Loss: 0.3895508 Vali Loss: 0.1981119 Test Loss: 0.2716632
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.4180201
	speed: 0.0727s/iter; left time: 913.6358s
	iters: 200, epoch: 53 | loss: 0.2980568
	speed: 0.0133s/iter; left time: 165.2761s
Epoch: 53 cost time: 4.070211172103882
Epoch: 53, Steps: 264 | Train Loss: 0.3893461 Vali Loss: 0.1980529 Test Loss: 0.2716490
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2573352
	speed: 0.0752s/iter; left time: 925.9747s
	iters: 200, epoch: 54 | loss: 0.4401107
	speed: 0.0161s/iter; left time: 196.1904s
Epoch: 54 cost time: 4.838713645935059
Epoch: 54, Steps: 264 | Train Loss: 0.3892602 Vali Loss: 0.1980507 Test Loss: 0.2716529
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.3615656
	speed: 0.0774s/iter; left time: 932.5005s
	iters: 200, epoch: 55 | loss: 0.3879548
	speed: 0.0263s/iter; left time: 313.6282s
Epoch: 55 cost time: 5.780014276504517
Epoch: 55, Steps: 264 | Train Loss: 0.3894025 Vali Loss: 0.1980017 Test Loss: 0.2716476
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.3034286
	speed: 0.0669s/iter; left time: 787.8437s
	iters: 200, epoch: 56 | loss: 0.3208215
	speed: 0.0131s/iter; left time: 152.5122s
Epoch: 56 cost time: 3.944716691970825
Epoch: 56, Steps: 264 | Train Loss: 0.3894955 Vali Loss: 0.1979275 Test Loss: 0.2716570
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_360_336_FITS_ETTm2_ftM_sl360_ll48_pl336_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.27303773164749146, mae:0.32603946328163147, rse:0.4220578372478485, corr:[0.55280846 0.5587675  0.5561614  0.5527719  0.55185235 0.55286723
 0.55417794 0.5542496  0.5530859  0.5517702  0.55114156 0.55142033
 0.5521236  0.5524883  0.5521305  0.5512199  0.55030805 0.5497676
 0.54962957 0.5496296  0.5494563  0.54899514 0.5483158  0.54773223
 0.5474011  0.54726595 0.5471661  0.5468887  0.54635704 0.545654
 0.54499745 0.54457384 0.54436636 0.54422414 0.54392934 0.54337865
 0.5426089  0.54177964 0.54107416 0.5405496  0.5401581  0.5398144
 0.5393717  0.53877014 0.5380529  0.537293   0.53660786 0.5359968
 0.5353697  0.53467447 0.53386056 0.533038   0.5322354  0.5314779
 0.53080326 0.53024024 0.5297296  0.52925056 0.5288174  0.52843773
 0.52811366 0.5278696  0.52769285 0.5275064  0.5272724  0.52701426
 0.52675366 0.5265091  0.52631307 0.5261679  0.5260153  0.5258278
 0.5255917  0.5253402  0.52506953 0.5247484  0.52437645 0.5239175
 0.5233837  0.5228023  0.5222622  0.5217612  0.5213115  0.5208541
 0.5203976  0.5199243  0.5194004  0.51888293 0.51840585 0.517971
 0.517551   0.51708394 0.5164571  0.5156048  0.51450217 0.5131555
 0.51164573 0.5101595  0.5087876  0.50750446 0.5062656  0.5050792
 0.5039324  0.5027663  0.5015987  0.50048923 0.4995041  0.4986276
 0.4978261  0.4969921  0.49614176 0.49528754 0.49448833 0.49375248
 0.49306884 0.49241725 0.4917673  0.49107656 0.49040905 0.48975885
 0.48913628 0.48850107 0.48790106 0.48728785 0.4865989  0.485848
 0.48509398 0.4843472  0.48360088 0.48286682 0.48216894 0.4814741
 0.48074755 0.4800168  0.4792902  0.4786195  0.4779465  0.47731414
 0.47668177 0.47607884 0.47548953 0.47488603 0.47425392 0.4735169
 0.47267237 0.47174528 0.47085026 0.47005135 0.46934363 0.46866968
 0.4680276  0.46740958 0.46674478 0.4660688  0.46545345 0.46500194
 0.4646548  0.46433613 0.4639481  0.46352503 0.4630547  0.46257842
 0.4622117  0.46196875 0.46187133 0.46182883 0.46164095 0.46133745
 0.46094272 0.46059105 0.46032932 0.4601353  0.45993835 0.45966884
 0.4593073  0.45891613 0.45855376 0.4582799  0.4580685  0.45784882
 0.45746    0.45680767 0.45601967 0.45525536 0.4547037  0.4544693
 0.4544744  0.45451912 0.45431736 0.45364657 0.452504   0.45093167
 0.44917482 0.44757923 0.44618326 0.44485223 0.44351143 0.44206363
 0.44053215 0.4389756  0.43750566 0.43619332 0.43507597 0.43407091
 0.43307686 0.43206394 0.43098512 0.42996097 0.42903998 0.42827666
 0.42753765 0.4267115  0.4258388  0.42503178 0.42430264 0.4236764
 0.4230622  0.422179   0.42113703 0.42004374 0.41897613 0.41800407
 0.41723192 0.41656289 0.415955   0.41515437 0.41410708 0.41283923
 0.411554   0.41049898 0.40967262 0.40905333 0.4085338  0.408062
 0.4075288  0.40691656 0.4062736  0.40561247 0.40494072 0.40429816
 0.4036562  0.40302393 0.4025027  0.40225074 0.40204594 0.40180895
 0.40158683 0.40136027 0.40109622 0.40087366 0.40079212 0.4009345
 0.40110412 0.40131342 0.40136194 0.4012086  0.4008993  0.40047938
 0.40017822 0.4000011  0.39997444 0.39998633 0.3998781  0.39969677
 0.39953062 0.39944133 0.3994254  0.3993129  0.3990905  0.3988513
 0.3985449  0.39826533 0.39805323 0.39797717 0.39786524 0.39763436
 0.39717886 0.39655915 0.39598805 0.39563167 0.3955178  0.39560482
 0.39565897 0.39554286 0.39522165 0.39472714 0.39402416 0.39315403
 0.39210528 0.39103857 0.38986418 0.38858652 0.3874197  0.38660038
 0.3861477  0.385885   0.38557857 0.38491848 0.38405028 0.38324282
 0.38273844 0.3825458  0.38253444 0.38238215 0.38179404 0.3808469
 0.3799842  0.3794632  0.37945598 0.3799554  0.38050452 0.38070646
 0.38028282 0.3794393  0.37854284 0.37801197 0.37787238 0.37775797
 0.3773346  0.37651327 0.3755495  0.3750067  0.37517577 0.375751
 0.37598163 0.37540013 0.37412784 0.3728361  0.37251532 0.37364554
 0.37530178 0.37585258 0.3745273  0.37238932 0.37345377 0.38131583]
