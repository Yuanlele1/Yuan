Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_360_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_360_336_FITS_ETTm2_ftM_sl360_ll48_pl336_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33865
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=26, out_features=50, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1164800.0
params:  1350.0
Trainable parameters:  1350
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4433624
	speed: 0.0936s/iter; left time: 2462.8432s
	iters: 200, epoch: 1 | loss: 0.3281912
	speed: 0.0810s/iter; left time: 2123.3214s
Epoch: 1 cost time: 23.848941802978516
Epoch: 1, Steps: 264 | Train Loss: 0.4929900 Vali Loss: 0.2263157 Test Loss: 0.2991855
Validation loss decreased (inf --> 0.226316).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3644137
	speed: 0.4468s/iter; left time: 11633.9760s
	iters: 200, epoch: 2 | loss: 0.5418584
	speed: 0.0886s/iter; left time: 2297.6940s
Epoch: 2 cost time: 26.53400707244873
Epoch: 2, Steps: 264 | Train Loss: 0.4280842 Vali Loss: 0.2131157 Test Loss: 0.2851941
Validation loss decreased (0.226316 --> 0.213116).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3408401
	speed: 0.3948s/iter; left time: 10175.2476s
	iters: 200, epoch: 3 | loss: 0.3740883
	speed: 0.0877s/iter; left time: 2250.6442s
Epoch: 3 cost time: 26.073485136032104
Epoch: 3, Steps: 264 | Train Loss: 0.4154722 Vali Loss: 0.2085103 Test Loss: 0.2803249
Validation loss decreased (0.213116 --> 0.208510).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4004701
	speed: 0.3907s/iter; left time: 9965.9276s
	iters: 200, epoch: 4 | loss: 0.4020151
	speed: 0.0874s/iter; left time: 2221.3033s
Epoch: 4 cost time: 23.18416738510132
Epoch: 4, Steps: 264 | Train Loss: 0.4087393 Vali Loss: 0.2061977 Test Loss: 0.2779336
Validation loss decreased (0.208510 --> 0.206198).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4219889
	speed: 0.4377s/iter; left time: 11048.9282s
	iters: 200, epoch: 5 | loss: 0.4677273
	speed: 0.0814s/iter; left time: 2045.8269s
Epoch: 5 cost time: 22.574469804763794
Epoch: 5, Steps: 264 | Train Loss: 0.4044235 Vali Loss: 0.2044473 Test Loss: 0.2766159
Validation loss decreased (0.206198 --> 0.204447).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2627682
	speed: 0.4059s/iter; left time: 10139.8741s
	iters: 200, epoch: 6 | loss: 0.5748546
	speed: 0.1143s/iter; left time: 2843.0213s
Epoch: 6 cost time: 27.01562190055847
Epoch: 6, Steps: 264 | Train Loss: 0.4021603 Vali Loss: 0.2034720 Test Loss: 0.2756494
Validation loss decreased (0.204447 --> 0.203472).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3682764
	speed: 0.4081s/iter; left time: 10087.1496s
	iters: 200, epoch: 7 | loss: 0.3857388
	speed: 0.1015s/iter; left time: 2497.6062s
Epoch: 7 cost time: 27.489481449127197
Epoch: 7, Steps: 264 | Train Loss: 0.4002156 Vali Loss: 0.2027186 Test Loss: 0.2750912
Validation loss decreased (0.203472 --> 0.202719).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4698281
	speed: 0.4010s/iter; left time: 9806.2700s
	iters: 200, epoch: 8 | loss: 0.4587789
	speed: 0.0796s/iter; left time: 1937.2907s
Epoch: 8 cost time: 24.61612367630005
Epoch: 8, Steps: 264 | Train Loss: 0.3988832 Vali Loss: 0.2022194 Test Loss: 0.2747193
Validation loss decreased (0.202719 --> 0.202219).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4828214
	speed: 0.4307s/iter; left time: 10419.2081s
	iters: 200, epoch: 9 | loss: 0.5040366
	speed: 0.0819s/iter; left time: 1972.1873s
Epoch: 9 cost time: 23.42419409751892
Epoch: 9, Steps: 264 | Train Loss: 0.3976057 Vali Loss: 0.2016777 Test Loss: 0.2743702
Validation loss decreased (0.202219 --> 0.201678).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4738436
	speed: 0.4319s/iter; left time: 10332.1271s
	iters: 200, epoch: 10 | loss: 0.3315822
	speed: 0.0877s/iter; left time: 2089.8692s
Epoch: 10 cost time: 23.70919179916382
Epoch: 10, Steps: 264 | Train Loss: 0.3974486 Vali Loss: 0.2013356 Test Loss: 0.2742342
Validation loss decreased (0.201678 --> 0.201336).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3972919
	speed: 0.4081s/iter; left time: 9655.2544s
	iters: 200, epoch: 11 | loss: 0.4033720
	speed: 0.0835s/iter; left time: 1966.7979s
Epoch: 11 cost time: 23.10024404525757
Epoch: 11, Steps: 264 | Train Loss: 0.3965815 Vali Loss: 0.2013365 Test Loss: 0.2740183
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4120480
	speed: 0.3783s/iter; left time: 8851.8308s
	iters: 200, epoch: 12 | loss: 0.3796152
	speed: 0.0808s/iter; left time: 1883.0467s
Epoch: 12 cost time: 23.92351222038269
Epoch: 12, Steps: 264 | Train Loss: 0.3963666 Vali Loss: 0.2012563 Test Loss: 0.2738923
Validation loss decreased (0.201336 --> 0.201256).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3415390
	speed: 0.3853s/iter; left time: 8912.8125s
	iters: 200, epoch: 13 | loss: 0.4696904
	speed: 0.1066s/iter; left time: 2454.2472s
Epoch: 13 cost time: 25.72382926940918
Epoch: 13, Steps: 264 | Train Loss: 0.3958415 Vali Loss: 0.2010066 Test Loss: 0.2737694
Validation loss decreased (0.201256 --> 0.201007).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2643836
	speed: 0.3595s/iter; left time: 8221.4487s
	iters: 200, epoch: 14 | loss: 0.3114390
	speed: 0.0850s/iter; left time: 1935.8050s
Epoch: 14 cost time: 25.081238746643066
Epoch: 14, Steps: 264 | Train Loss: 0.3953294 Vali Loss: 0.2008918 Test Loss: 0.2736928
Validation loss decreased (0.201007 --> 0.200892).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.5870258
	speed: 0.4007s/iter; left time: 9058.4066s
	iters: 200, epoch: 15 | loss: 0.4242354
	speed: 0.1173s/iter; left time: 2638.9308s
Epoch: 15 cost time: 28.09291172027588
Epoch: 15, Steps: 264 | Train Loss: 0.3946951 Vali Loss: 0.2007054 Test Loss: 0.2735755
Validation loss decreased (0.200892 --> 0.200705).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2972762
	speed: 0.4954s/iter; left time: 11067.9300s
	iters: 200, epoch: 16 | loss: 0.3411159
	speed: 0.1116s/iter; left time: 2481.4785s
Epoch: 16 cost time: 35.32895874977112
Epoch: 16, Steps: 264 | Train Loss: 0.3950405 Vali Loss: 0.2006030 Test Loss: 0.2736202
Validation loss decreased (0.200705 --> 0.200603).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2418070
	speed: 0.5642s/iter; left time: 12455.3469s
	iters: 200, epoch: 17 | loss: 0.4585004
	speed: 0.1317s/iter; left time: 2894.8856s
Epoch: 17 cost time: 34.719072341918945
Epoch: 17, Steps: 264 | Train Loss: 0.3947198 Vali Loss: 0.2003368 Test Loss: 0.2734525
Validation loss decreased (0.200603 --> 0.200337).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2899325
	speed: 0.5508s/iter; left time: 12015.5385s
	iters: 200, epoch: 18 | loss: 0.4473037
	speed: 0.1383s/iter; left time: 3002.6660s
Epoch: 18 cost time: 32.89099860191345
Epoch: 18, Steps: 264 | Train Loss: 0.3944563 Vali Loss: 0.2004249 Test Loss: 0.2733646
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4436415
	speed: 0.5255s/iter; left time: 11325.0717s
	iters: 200, epoch: 19 | loss: 0.3453183
	speed: 0.1353s/iter; left time: 2901.7425s
Epoch: 19 cost time: 32.86852216720581
Epoch: 19, Steps: 264 | Train Loss: 0.3944331 Vali Loss: 0.2004078 Test Loss: 0.2734175
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3769298
	speed: 0.5397s/iter; left time: 11487.8765s
	iters: 200, epoch: 20 | loss: 0.4639372
	speed: 0.1183s/iter; left time: 2505.5822s
Epoch: 20 cost time: 32.45598530769348
Epoch: 20, Steps: 264 | Train Loss: 0.3939924 Vali Loss: 0.2004903 Test Loss: 0.2733214
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2879677
	speed: 0.5265s/iter; left time: 11067.9838s
	iters: 200, epoch: 21 | loss: 0.2741946
	speed: 0.1232s/iter; left time: 2577.1181s
Epoch: 21 cost time: 35.142542362213135
Epoch: 21, Steps: 264 | Train Loss: 0.3938635 Vali Loss: 0.2001381 Test Loss: 0.2733341
Validation loss decreased (0.200337 --> 0.200138).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3088405
	speed: 0.5239s/iter; left time: 10875.0333s
	iters: 200, epoch: 22 | loss: 0.3443728
	speed: 0.1269s/iter; left time: 2622.2277s
Epoch: 22 cost time: 33.025583028793335
Epoch: 22, Steps: 264 | Train Loss: 0.3938000 Vali Loss: 0.2003054 Test Loss: 0.2732376
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3851489
	speed: 0.5741s/iter; left time: 11764.6144s
	iters: 200, epoch: 23 | loss: 0.4447813
	speed: 0.1206s/iter; left time: 2459.0830s
Epoch: 23 cost time: 33.25569200515747
Epoch: 23, Steps: 264 | Train Loss: 0.3937316 Vali Loss: 0.2002855 Test Loss: 0.2732354
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3108163
	speed: 0.5194s/iter; left time: 10506.7933s
	iters: 200, epoch: 24 | loss: 0.3587596
	speed: 0.1355s/iter; left time: 2728.0740s
Epoch: 24 cost time: 36.09242105484009
Epoch: 24, Steps: 264 | Train Loss: 0.3938706 Vali Loss: 0.2000953 Test Loss: 0.2732390
Validation loss decreased (0.200138 --> 0.200095).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4137716
	speed: 0.5562s/iter; left time: 11105.1218s
	iters: 200, epoch: 25 | loss: 0.4235914
	speed: 0.1568s/iter; left time: 3114.6453s
Epoch: 25 cost time: 38.90505862236023
Epoch: 25, Steps: 264 | Train Loss: 0.3936181 Vali Loss: 0.2002156 Test Loss: 0.2732379
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4078027
	speed: 0.5182s/iter; left time: 10208.8179s
	iters: 200, epoch: 26 | loss: 0.3752410
	speed: 0.1227s/iter; left time: 2404.4243s
Epoch: 26 cost time: 32.0308952331543
Epoch: 26, Steps: 264 | Train Loss: 0.3937303 Vali Loss: 0.2002650 Test Loss: 0.2732284
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4827967
	speed: 0.5695s/iter; left time: 11069.8151s
	iters: 200, epoch: 27 | loss: 0.3939378
	speed: 0.1293s/iter; left time: 2500.6259s
Epoch: 27 cost time: 34.52937698364258
Epoch: 27, Steps: 264 | Train Loss: 0.3936000 Vali Loss: 0.1999094 Test Loss: 0.2731938
Validation loss decreased (0.200095 --> 0.199909).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4011999
	speed: 0.5597s/iter; left time: 10731.3307s
	iters: 200, epoch: 28 | loss: 0.2949666
	speed: 0.1284s/iter; left time: 2448.6350s
Epoch: 28 cost time: 32.3125433921814
Epoch: 28, Steps: 264 | Train Loss: 0.3936205 Vali Loss: 0.2000065 Test Loss: 0.2731915
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2824906
	speed: 0.4294s/iter; left time: 8119.8006s
	iters: 200, epoch: 29 | loss: 0.4307643
	speed: 0.0820s/iter; left time: 1542.0368s
Epoch: 29 cost time: 22.760088205337524
Epoch: 29, Steps: 264 | Train Loss: 0.3935329 Vali Loss: 0.2001206 Test Loss: 0.2732047
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3781654
	speed: 0.4133s/iter; left time: 7705.0661s
	iters: 200, epoch: 30 | loss: 0.3939371
	speed: 0.0875s/iter; left time: 1622.7052s
Epoch: 30 cost time: 24.07886552810669
Epoch: 30, Steps: 264 | Train Loss: 0.3931110 Vali Loss: 0.2002256 Test Loss: 0.2731875
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3420212
	speed: 0.5320s/iter; left time: 9778.9202s
	iters: 200, epoch: 31 | loss: 0.4470595
	speed: 0.1050s/iter; left time: 1919.3269s
Epoch: 31 cost time: 29.84822416305542
Epoch: 31, Steps: 264 | Train Loss: 0.3934107 Vali Loss: 0.2002068 Test Loss: 0.2731375
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4573905
	speed: 0.4734s/iter; left time: 8576.2102s
	iters: 200, epoch: 32 | loss: 0.2955501
	speed: 0.0938s/iter; left time: 1690.4846s
Epoch: 32 cost time: 27.632259845733643
Epoch: 32, Steps: 264 | Train Loss: 0.3934233 Vali Loss: 0.2000133 Test Loss: 0.2731616
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.6291515
	speed: 0.4365s/iter; left time: 7793.5313s
	iters: 200, epoch: 33 | loss: 0.2617953
	speed: 0.1075s/iter; left time: 1908.4402s
Epoch: 33 cost time: 27.520487785339355
Epoch: 33, Steps: 264 | Train Loss: 0.3933426 Vali Loss: 0.1999900 Test Loss: 0.2731347
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3122057
	speed: 0.3873s/iter; left time: 6811.9456s
	iters: 200, epoch: 34 | loss: 0.3986384
	speed: 0.0792s/iter; left time: 1384.2903s
Epoch: 34 cost time: 21.543945789337158
Epoch: 34, Steps: 264 | Train Loss: 0.3928479 Vali Loss: 0.2002153 Test Loss: 0.2731059
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2875321
	speed: 0.3898s/iter; left time: 6753.0997s
	iters: 200, epoch: 35 | loss: 0.3916821
	speed: 0.0793s/iter; left time: 1365.5794s
Epoch: 35 cost time: 21.536932945251465
Epoch: 35, Steps: 264 | Train Loss: 0.3931610 Vali Loss: 0.2002643 Test Loss: 0.2731105
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3436942
	speed: 0.3762s/iter; left time: 6418.8396s
	iters: 200, epoch: 36 | loss: 0.4690901
	speed: 0.1028s/iter; left time: 1743.9818s
Epoch: 36 cost time: 26.080068111419678
Epoch: 36, Steps: 264 | Train Loss: 0.3932987 Vali Loss: 0.2001345 Test Loss: 0.2731185
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2868386
	speed: 0.4231s/iter; left time: 7106.8233s
	iters: 200, epoch: 37 | loss: 0.4307083
	speed: 0.0962s/iter; left time: 1605.9017s
Epoch: 37 cost time: 26.519296407699585
Epoch: 37, Steps: 264 | Train Loss: 0.3930472 Vali Loss: 0.1998001 Test Loss: 0.2731021
Validation loss decreased (0.199909 --> 0.199800).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4672056
	speed: 0.4138s/iter; left time: 6840.6587s
	iters: 200, epoch: 38 | loss: 0.3059468
	speed: 0.1354s/iter; left time: 2225.3245s
Epoch: 38 cost time: 31.189300298690796
Epoch: 38, Steps: 264 | Train Loss: 0.3930628 Vali Loss: 0.2001942 Test Loss: 0.2731022
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4435371
	speed: 0.4377s/iter; left time: 7120.7624s
	iters: 200, epoch: 39 | loss: 0.4398723
	speed: 0.0880s/iter; left time: 1423.0876s
Epoch: 39 cost time: 25.120249271392822
Epoch: 39, Steps: 264 | Train Loss: 0.3930752 Vali Loss: 0.1999643 Test Loss: 0.2731029
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.5265229
	speed: 0.3814s/iter; left time: 6104.3844s
	iters: 200, epoch: 40 | loss: 0.3503256
	speed: 0.1030s/iter; left time: 1637.5014s
Epoch: 40 cost time: 25.854392766952515
Epoch: 40, Steps: 264 | Train Loss: 0.3927553 Vali Loss: 0.2002206 Test Loss: 0.2730943
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2538893
	speed: 0.4110s/iter; left time: 6469.9553s
	iters: 200, epoch: 41 | loss: 0.4124557
	speed: 0.0786s/iter; left time: 1228.6058s
Epoch: 41 cost time: 21.76577877998352
Epoch: 41, Steps: 264 | Train Loss: 0.3928135 Vali Loss: 0.1999697 Test Loss: 0.2731032
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.4994716
	speed: 0.3983s/iter; left time: 6164.6822s
	iters: 200, epoch: 42 | loss: 0.4037295
	speed: 0.0821s/iter; left time: 1262.7998s
Epoch: 42 cost time: 23.527470588684082
Epoch: 42, Steps: 264 | Train Loss: 0.3929695 Vali Loss: 0.2000620 Test Loss: 0.2730862
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3021874
	speed: 0.3492s/iter; left time: 5311.8473s
	iters: 200, epoch: 43 | loss: 0.3805610
	speed: 0.0726s/iter; left time: 1096.5468s
Epoch: 43 cost time: 20.312952280044556
Epoch: 43, Steps: 264 | Train Loss: 0.3931135 Vali Loss: 0.1999652 Test Loss: 0.2730894
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.4792596
	speed: 0.3679s/iter; left time: 5499.8704s
	iters: 200, epoch: 44 | loss: 0.2487374
	speed: 0.1030s/iter; left time: 1529.2106s
Epoch: 44 cost time: 26.985207319259644
Epoch: 44, Steps: 264 | Train Loss: 0.3928600 Vali Loss: 0.2000954 Test Loss: 0.2730749
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.3589386
	speed: 0.4019s/iter; left time: 5901.3531s
	iters: 200, epoch: 45 | loss: 0.4598017
	speed: 0.0815s/iter; left time: 1189.2719s
Epoch: 45 cost time: 21.850240230560303
Epoch: 45, Steps: 264 | Train Loss: 0.3931472 Vali Loss: 0.1998439 Test Loss: 0.2730802
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2772978
	speed: 0.3778s/iter; left time: 5448.6588s
	iters: 200, epoch: 46 | loss: 0.2559423
	speed: 0.0874s/iter; left time: 1251.5253s
Epoch: 46 cost time: 24.488518238067627
Epoch: 46, Steps: 264 | Train Loss: 0.3931047 Vali Loss: 0.1999475 Test Loss: 0.2730812
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.4729199
	speed: 0.3600s/iter; left time: 5096.5431s
	iters: 200, epoch: 47 | loss: 0.3991497
	speed: 0.0924s/iter; left time: 1298.4922s
Epoch: 47 cost time: 24.74970579147339
Epoch: 47, Steps: 264 | Train Loss: 0.3929323 Vali Loss: 0.2000553 Test Loss: 0.2730683
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.4597502
	speed: 0.4147s/iter; left time: 5762.0095s
	iters: 200, epoch: 48 | loss: 0.3015475
	speed: 0.1019s/iter; left time: 1404.9647s
Epoch: 48 cost time: 25.116681814193726
Epoch: 48, Steps: 264 | Train Loss: 0.3929915 Vali Loss: 0.1999994 Test Loss: 0.2730727
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.3456199
	speed: 0.3667s/iter; left time: 4997.6489s
	iters: 200, epoch: 49 | loss: 0.3289667
	speed: 0.0952s/iter; left time: 1288.4867s
Epoch: 49 cost time: 23.098527193069458
Epoch: 49, Steps: 264 | Train Loss: 0.3929199 Vali Loss: 0.1999917 Test Loss: 0.2730764
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.3445940
	speed: 0.3619s/iter; left time: 4836.6676s
	iters: 200, epoch: 50 | loss: 0.3604858
	speed: 0.0902s/iter; left time: 1197.0425s
Epoch: 50 cost time: 25.43820595741272
Epoch: 50, Steps: 264 | Train Loss: 0.3929342 Vali Loss: 0.2000606 Test Loss: 0.2730740
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.3644797
	speed: 0.4062s/iter; left time: 5321.3846s
	iters: 200, epoch: 51 | loss: 0.4601905
	speed: 0.0896s/iter; left time: 1164.3136s
Epoch: 51 cost time: 23.819536924362183
Epoch: 51, Steps: 264 | Train Loss: 0.3924962 Vali Loss: 0.1999617 Test Loss: 0.2730694
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2977998
	speed: 0.3961s/iter; left time: 5084.3824s
	iters: 200, epoch: 52 | loss: 0.4809436
	speed: 0.1102s/iter; left time: 1403.8490s
Epoch: 52 cost time: 27.626549005508423
Epoch: 52, Steps: 264 | Train Loss: 0.3927118 Vali Loss: 0.1999820 Test Loss: 0.2730604
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2762928
	speed: 0.3800s/iter; left time: 4777.6916s
	iters: 200, epoch: 53 | loss: 0.3054803
	speed: 0.0877s/iter; left time: 1093.7093s
Epoch: 53 cost time: 23.676762104034424
Epoch: 53, Steps: 264 | Train Loss: 0.3928183 Vali Loss: 0.1999726 Test Loss: 0.2730662
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.4237299
	speed: 0.4102s/iter; left time: 5049.6503s
	iters: 200, epoch: 54 | loss: 0.3109579
	speed: 0.1096s/iter; left time: 1338.1656s
Epoch: 54 cost time: 26.242377042770386
Epoch: 54, Steps: 264 | Train Loss: 0.3930308 Vali Loss: 0.2001127 Test Loss: 0.2730705
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.4391141
	speed: 0.3885s/iter; left time: 4679.0929s
	iters: 200, epoch: 55 | loss: 0.6262423
	speed: 0.0850s/iter; left time: 1015.1043s
Epoch: 55 cost time: 24.864293813705444
Epoch: 55, Steps: 264 | Train Loss: 0.3931355 Vali Loss: 0.2000569 Test Loss: 0.2730654
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.3137685
	speed: 0.3864s/iter; left time: 4551.9931s
	iters: 200, epoch: 56 | loss: 0.3474473
	speed: 0.0995s/iter; left time: 1161.7562s
Epoch: 56 cost time: 26.55974531173706
Epoch: 56, Steps: 264 | Train Loss: 0.3929984 Vali Loss: 0.1999852 Test Loss: 0.2730652
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.3607678
	speed: 0.3697s/iter; left time: 4257.8996s
	iters: 200, epoch: 57 | loss: 0.3265423
	speed: 0.0957s/iter; left time: 1092.9335s
Epoch: 57 cost time: 24.574495792388916
Epoch: 57, Steps: 264 | Train Loss: 0.3926518 Vali Loss: 0.1998409 Test Loss: 0.2730629
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_360_336_FITS_ETTm2_ftM_sl360_ll48_pl336_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.2743907868862152, mae:0.3272337317466736, rse:0.42310231924057007, corr:[0.54718715 0.5516437  0.5543686  0.5551615  0.5546011  0.5533591
 0.55212045 0.55117214 0.5506573  0.55059576 0.5508333  0.5512455
 0.5516608  0.55186975 0.5517784  0.551341   0.55065006 0.549828
 0.54899925 0.54825526 0.5476834  0.5473536  0.54719025 0.5471589
 0.54713917 0.54699033 0.54667807 0.54620355 0.54563725 0.54501414
 0.5443921  0.5438464  0.5433712  0.5429526  0.5425367  0.54210794
 0.5416502  0.5411691  0.5406964  0.54022706 0.5397477  0.53926545
 0.5387374  0.5381228  0.537412   0.53658515 0.5357198  0.5348686
 0.5340469  0.53327775 0.5325396  0.53187156 0.53123057 0.5305851
 0.5299302  0.5293201  0.5287616  0.52828294 0.5279113  0.52763987
 0.5274342  0.5272726  0.52713263 0.5269641  0.52674246 0.52648824
 0.52622753 0.5259731  0.5257587  0.52559686 0.5254532  0.5252991
 0.52509385 0.5248352  0.5245045  0.524082   0.5235977  0.5230616
 0.52250403 0.5219424  0.5214202  0.5209084  0.5204041  0.5198769
 0.5193611  0.5188761  0.5184075  0.5179679  0.51753694 0.51707596
 0.5165449  0.51590437 0.5150704  0.51402557 0.51280284 0.51144356
 0.50999457 0.50858307 0.5072599  0.5060053  0.5047828  0.5036045
 0.5024683  0.5013205  0.5001725  0.4990551  0.49803588 0.49714884
 0.49641237 0.4957428  0.49510318 0.494425   0.49368933 0.49287832
 0.49201438 0.49115238 0.49035212 0.48962817 0.48902744 0.48848814
 0.48794547 0.48731455 0.4866276  0.48587444 0.48503947 0.48414966
 0.48326075 0.48238373 0.4815161  0.48068914 0.4799386  0.47926876
 0.4786629  0.4781267  0.47764674 0.4772168  0.47676393 0.47628623
 0.4757186  0.47505787 0.4742803  0.47337636 0.47239214 0.47135046
 0.47033963 0.46941638 0.46865442 0.46806315 0.46759355 0.4671532
 0.4667068  0.46623787 0.46568462 0.46506685 0.4644245  0.46384987
 0.4633352  0.46287775 0.46244478 0.46207327 0.461733   0.46138793
 0.4610833  0.460815   0.46063104 0.46054226 0.4604448  0.46032858
 0.4601317  0.45987138 0.45952758 0.45909855 0.4586137  0.45813414
 0.45770866 0.457375   0.4571123  0.45688543 0.45664367 0.45637992
 0.45605326 0.45564166 0.4552122  0.4547778  0.45434517 0.45391008
 0.45341882 0.45283487 0.45207873 0.4510851  0.44990954 0.44853687
 0.4470418  0.44557774 0.44414988 0.44269937 0.44124317 0.4397567
 0.4382688  0.43677038 0.43529445 0.43389654 0.4326545  0.4315993
 0.43072122 0.42999476 0.42928836 0.42857373 0.4277898  0.4269742
 0.4261005  0.4251711  0.42426056 0.42347085 0.42277798 0.42216676
 0.42156622 0.42075023 0.41973856 0.4185718  0.4172806  0.4159193
 0.41463342 0.4134436  0.41242144 0.41147003 0.41054806 0.40960497
 0.4086602  0.40783867 0.40711528 0.40652615 0.40603706 0.40562496
 0.4051789  0.40462863 0.40394923 0.4031595  0.40230632 0.40150574
 0.40083915 0.40034884 0.4000954  0.40012994 0.40026882 0.4003908
 0.40047345 0.40045264 0.40025225 0.39991608 0.39953312 0.39923778
 0.3989989  0.39891794 0.39891765 0.39893743 0.398951   0.39886546
 0.39877677 0.3986657  0.39859334 0.39854547 0.39844042 0.39827648
 0.39805362 0.39780283 0.39755458 0.39726657 0.39699167 0.39683166
 0.39671987 0.39666712 0.39663795 0.3966336  0.39655688 0.3963746
 0.396023   0.39551643 0.39496753 0.3944836  0.39413333 0.39400715
 0.39402404 0.39406738 0.39400473 0.39369944 0.3930115  0.39195922
 0.39063624 0.38929743 0.38801137 0.38681537 0.38578066 0.38496768
 0.38434845 0.38389313 0.38360193 0.38334668 0.38315624 0.382999
 0.38281006 0.38247615 0.38197163 0.38128975 0.38042167 0.37947512
 0.37870148 0.3781632  0.37794262 0.3781585  0.37869173 0.3793883
 0.3799414  0.3801559  0.3798465  0.37900296 0.3777244  0.37618834
 0.37470135 0.3735089  0.37274662 0.372522   0.37278372 0.37337047
 0.37400565 0.37450653 0.37471962 0.37447226 0.373697   0.37256652
 0.3713812  0.3705586  0.37065428 0.3720479  0.37471062 0.3780282 ]
