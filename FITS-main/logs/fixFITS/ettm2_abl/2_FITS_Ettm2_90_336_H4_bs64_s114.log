Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=14, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_90_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_90_336_FITS_ETTm2_ftM_sl90_ll48_pl336_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=14, out_features=66, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  827904.0
params:  990.0
Trainable parameters:  990
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6033900
	speed: 0.0701s/iter; left time: 1858.5012s
	iters: 200, epoch: 1 | loss: 0.5252892
	speed: 0.0614s/iter; left time: 1619.7553s
Epoch: 1 cost time: 17.309890747070312
Epoch: 1, Steps: 266 | Train Loss: 0.4763557 Vali Loss: 0.2605924 Test Loss: 0.3592855
Validation loss decreased (inf --> 0.260592).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3778380
	speed: 0.2704s/iter; left time: 7093.4153s
	iters: 200, epoch: 2 | loss: 0.4273717
	speed: 0.0602s/iter; left time: 1572.6575s
Epoch: 2 cost time: 16.762141942977905
Epoch: 2, Steps: 266 | Train Loss: 0.3873163 Vali Loss: 0.2302344 Test Loss: 0.3221575
Validation loss decreased (0.260592 --> 0.230234).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4784199
	speed: 0.2548s/iter; left time: 6617.6854s
	iters: 200, epoch: 3 | loss: 0.2508540
	speed: 0.0583s/iter; left time: 1507.8210s
Epoch: 3 cost time: 16.470947980880737
Epoch: 3, Steps: 266 | Train Loss: 0.3633750 Vali Loss: 0.2219509 Test Loss: 0.3124608
Validation loss decreased (0.230234 --> 0.221951).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3838010
	speed: 0.2704s/iter; left time: 6948.8999s
	iters: 200, epoch: 4 | loss: 0.4598958
	speed: 0.0623s/iter; left time: 1595.1706s
Epoch: 4 cost time: 16.530895471572876
Epoch: 4, Steps: 266 | Train Loss: 0.3568018 Vali Loss: 0.2198037 Test Loss: 0.3097211
Validation loss decreased (0.221951 --> 0.219804).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3406814
	speed: 0.2873s/iter; left time: 7308.2442s
	iters: 200, epoch: 5 | loss: 0.1952320
	speed: 0.0683s/iter; left time: 1730.8737s
Epoch: 5 cost time: 19.045052766799927
Epoch: 5, Steps: 266 | Train Loss: 0.3552216 Vali Loss: 0.2189412 Test Loss: 0.3087486
Validation loss decreased (0.219804 --> 0.218941).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2233418
	speed: 0.3121s/iter; left time: 7856.8443s
	iters: 200, epoch: 6 | loss: 0.4778977
	speed: 0.0705s/iter; left time: 1766.3981s
Epoch: 6 cost time: 19.276707649230957
Epoch: 6, Steps: 266 | Train Loss: 0.3534192 Vali Loss: 0.2185728 Test Loss: 0.3083385
Validation loss decreased (0.218941 --> 0.218573).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4216228
	speed: 0.3215s/iter; left time: 8006.2035s
	iters: 200, epoch: 7 | loss: 0.2494947
	speed: 0.0684s/iter; left time: 1696.8019s
Epoch: 7 cost time: 19.34011459350586
Epoch: 7, Steps: 266 | Train Loss: 0.3533597 Vali Loss: 0.2187820 Test Loss: 0.3082514
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4681235
	speed: 0.3021s/iter; left time: 7444.2414s
	iters: 200, epoch: 8 | loss: 0.3568419
	speed: 0.0714s/iter; left time: 1753.0843s
Epoch: 8 cost time: 19.565280437469482
Epoch: 8, Steps: 266 | Train Loss: 0.3525221 Vali Loss: 0.2187715 Test Loss: 0.3081282
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2453577
	speed: 0.3234s/iter; left time: 7881.8510s
	iters: 200, epoch: 9 | loss: 0.3063683
	speed: 0.0707s/iter; left time: 1716.0664s
Epoch: 9 cost time: 19.753483533859253
Epoch: 9, Steps: 266 | Train Loss: 0.3530147 Vali Loss: 0.2187129 Test Loss: 0.3082030
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4161260
	speed: 0.3199s/iter; left time: 7712.5185s
	iters: 200, epoch: 10 | loss: 0.2963732
	speed: 0.0725s/iter; left time: 1739.4749s
Epoch: 10 cost time: 20.013750791549683
Epoch: 10, Steps: 266 | Train Loss: 0.3527997 Vali Loss: 0.2189458 Test Loss: 0.3081334
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2486090
	speed: 0.3233s/iter; left time: 7707.1157s
	iters: 200, epoch: 11 | loss: 0.3411481
	speed: 0.0754s/iter; left time: 1790.6284s
Epoch: 11 cost time: 20.427249908447266
Epoch: 11, Steps: 266 | Train Loss: 0.3523183 Vali Loss: 0.2190126 Test Loss: 0.3082215
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3803421
	speed: 0.3246s/iter; left time: 7652.9811s
	iters: 200, epoch: 12 | loss: 0.4326335
	speed: 0.0722s/iter; left time: 1695.6288s
Epoch: 12 cost time: 19.876514434814453
Epoch: 12, Steps: 266 | Train Loss: 0.3524507 Vali Loss: 0.2188535 Test Loss: 0.3082609
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2657178
	speed: 0.3257s/iter; left time: 7591.8145s
	iters: 200, epoch: 13 | loss: 0.2639782
	speed: 0.0706s/iter; left time: 1638.7764s
Epoch: 13 cost time: 19.820919036865234
Epoch: 13, Steps: 266 | Train Loss: 0.3517278 Vali Loss: 0.2189987 Test Loss: 0.3082182
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4385142
	speed: 0.3217s/iter; left time: 7413.2628s
	iters: 200, epoch: 14 | loss: 0.3804910
	speed: 0.0724s/iter; left time: 1660.4617s
Epoch: 14 cost time: 20.073472023010254
Epoch: 14, Steps: 266 | Train Loss: 0.3521981 Vali Loss: 0.2190214 Test Loss: 0.3082893
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3601637
	speed: 0.3274s/iter; left time: 7457.4798s
	iters: 200, epoch: 15 | loss: 0.3530332
	speed: 0.0730s/iter; left time: 1655.7205s
Epoch: 15 cost time: 20.01264238357544
Epoch: 15, Steps: 266 | Train Loss: 0.3523064 Vali Loss: 0.2190410 Test Loss: 0.3083239
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3810804
	speed: 0.3279s/iter; left time: 7380.7852s
	iters: 200, epoch: 16 | loss: 0.5974453
	speed: 0.0714s/iter; left time: 1601.0730s
Epoch: 16 cost time: 19.881989002227783
Epoch: 16, Steps: 266 | Train Loss: 0.3518953 Vali Loss: 0.2191120 Test Loss: 0.3082737
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3102432
	speed: 0.3251s/iter; left time: 7232.9285s
	iters: 200, epoch: 17 | loss: 0.3964512
	speed: 0.0713s/iter; left time: 1578.3060s
Epoch: 17 cost time: 19.964378833770752
Epoch: 17, Steps: 266 | Train Loss: 0.3515205 Vali Loss: 0.2193184 Test Loss: 0.3083282
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3091761
	speed: 0.3190s/iter; left time: 7010.7343s
	iters: 200, epoch: 18 | loss: 0.4382249
	speed: 0.0720s/iter; left time: 1574.8844s
Epoch: 18 cost time: 19.855794429779053
Epoch: 18, Steps: 266 | Train Loss: 0.3519522 Vali Loss: 0.2194105 Test Loss: 0.3083951
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2430353
	speed: 0.3180s/iter; left time: 6904.9433s
	iters: 200, epoch: 19 | loss: 0.3578471
	speed: 0.0731s/iter; left time: 1580.2757s
Epoch: 19 cost time: 19.823775053024292
Epoch: 19, Steps: 266 | Train Loss: 0.3514417 Vali Loss: 0.2193436 Test Loss: 0.3083303
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3179956
	speed: 0.3298s/iter; left time: 7072.3985s
	iters: 200, epoch: 20 | loss: 0.2732364
	speed: 0.0706s/iter; left time: 1506.4751s
Epoch: 20 cost time: 20.205406665802002
Epoch: 20, Steps: 266 | Train Loss: 0.3516481 Vali Loss: 0.2193970 Test Loss: 0.3083753
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2820297
	speed: 0.3252s/iter; left time: 6888.4112s
	iters: 200, epoch: 21 | loss: 0.3086420
	speed: 0.0724s/iter; left time: 1525.3429s
Epoch: 21 cost time: 19.97235918045044
Epoch: 21, Steps: 266 | Train Loss: 0.3518060 Vali Loss: 0.2194625 Test Loss: 0.3083981
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3430430
	speed: 0.3212s/iter; left time: 6717.8568s
	iters: 200, epoch: 22 | loss: 0.4270588
	speed: 0.0723s/iter; left time: 1505.0512s
Epoch: 22 cost time: 19.941452264785767
Epoch: 22, Steps: 266 | Train Loss: 0.3512691 Vali Loss: 0.2194976 Test Loss: 0.3084363
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3695960
	speed: 0.3230s/iter; left time: 6669.5050s
	iters: 200, epoch: 23 | loss: 0.6378961
	speed: 0.0718s/iter; left time: 1475.3110s
Epoch: 23 cost time: 19.891945362091064
Epoch: 23, Steps: 266 | Train Loss: 0.3518454 Vali Loss: 0.2194433 Test Loss: 0.3084363
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4032099
	speed: 0.3288s/iter; left time: 6701.7387s
	iters: 200, epoch: 24 | loss: 0.3397526
	speed: 0.0734s/iter; left time: 1489.7707s
Epoch: 24 cost time: 20.226061820983887
Epoch: 24, Steps: 266 | Train Loss: 0.3513685 Vali Loss: 0.2196956 Test Loss: 0.3084695
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3597633
	speed: 0.3304s/iter; left time: 6647.0183s
	iters: 200, epoch: 25 | loss: 0.2740280
	speed: 0.0720s/iter; left time: 1440.8721s
Epoch: 25 cost time: 20.051371812820435
Epoch: 25, Steps: 266 | Train Loss: 0.3517829 Vali Loss: 0.2193157 Test Loss: 0.3084747
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2629604
	speed: 0.3222s/iter; left time: 6395.9940s
	iters: 200, epoch: 26 | loss: 0.4513715
	speed: 0.0724s/iter; left time: 1430.1118s
Epoch: 26 cost time: 19.74455165863037
Epoch: 26, Steps: 266 | Train Loss: 0.3518930 Vali Loss: 0.2195399 Test Loss: 0.3084283
EarlyStopping counter: 20 out of 20
Early stopping
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=14, out_features=66, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  827904.0
params:  990.0
Trainable parameters:  990
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6679660
	speed: 0.0798s/iter; left time: 2113.8672s
	iters: 200, epoch: 1 | loss: 0.4633387
	speed: 0.0717s/iter; left time: 1894.2410s
Epoch: 1 cost time: 19.84282374382019
Epoch: 1, Steps: 266 | Train Loss: 0.4439932 Vali Loss: 0.2185576 Test Loss: 0.3078146
Validation loss decreased (inf --> 0.218558).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4405474
	speed: 0.3312s/iter; left time: 8688.2267s
	iters: 200, epoch: 2 | loss: 0.3785872
	speed: 0.0712s/iter; left time: 1861.0267s
Epoch: 2 cost time: 19.94391131401062
Epoch: 2, Steps: 266 | Train Loss: 0.4432122 Vali Loss: 0.2184497 Test Loss: 0.3077002
Validation loss decreased (0.218558 --> 0.218450).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4261950
	speed: 0.3206s/iter; left time: 8325.2557s
	iters: 200, epoch: 3 | loss: 0.5355039
	speed: 0.0737s/iter; left time: 1905.8774s
Epoch: 3 cost time: 19.693746328353882
Epoch: 3, Steps: 266 | Train Loss: 0.4425794 Vali Loss: 0.2184892 Test Loss: 0.3075633
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.5175530
	speed: 0.3224s/iter; left time: 8286.5854s
	iters: 200, epoch: 4 | loss: 0.4638386
	speed: 0.0705s/iter; left time: 1805.4962s
Epoch: 4 cost time: 19.653231382369995
Epoch: 4, Steps: 266 | Train Loss: 0.4424444 Vali Loss: 0.2188310 Test Loss: 0.3077652
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4321168
	speed: 0.3192s/iter; left time: 8119.8075s
	iters: 200, epoch: 5 | loss: 0.3713289
	speed: 0.0746s/iter; left time: 1889.5413s
Epoch: 5 cost time: 20.170578479766846
Epoch: 5, Steps: 266 | Train Loss: 0.4418862 Vali Loss: 0.2187096 Test Loss: 0.3076682
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4314662
	speed: 0.3227s/iter; left time: 8122.4028s
	iters: 200, epoch: 6 | loss: 0.5621110
	speed: 0.0710s/iter; left time: 1779.6290s
Epoch: 6 cost time: 19.7908034324646
Epoch: 6, Steps: 266 | Train Loss: 0.4420979 Vali Loss: 0.2187051 Test Loss: 0.3077894
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4216197
	speed: 0.3212s/iter; left time: 7999.1869s
	iters: 200, epoch: 7 | loss: 0.5386535
	speed: 0.0708s/iter; left time: 1756.3210s
Epoch: 7 cost time: 19.95632266998291
Epoch: 7, Steps: 266 | Train Loss: 0.4418990 Vali Loss: 0.2188185 Test Loss: 0.3077456
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3820290
	speed: 0.3252s/iter; left time: 8013.5248s
	iters: 200, epoch: 8 | loss: 0.4092377
	speed: 0.0699s/iter; left time: 1714.7237s
Epoch: 8 cost time: 19.570844888687134
Epoch: 8, Steps: 266 | Train Loss: 0.4419883 Vali Loss: 0.2188524 Test Loss: 0.3077938
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3244162
	speed: 0.3217s/iter; left time: 7841.6170s
	iters: 200, epoch: 9 | loss: 0.4187483
	speed: 0.0694s/iter; left time: 1685.7031s
Epoch: 9 cost time: 19.45229458808899
Epoch: 9, Steps: 266 | Train Loss: 0.4413825 Vali Loss: 0.2189850 Test Loss: 0.3078642
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4121078
	speed: 0.3210s/iter; left time: 7737.4674s
	iters: 200, epoch: 10 | loss: 0.4336431
	speed: 0.0711s/iter; left time: 1706.8126s
Epoch: 10 cost time: 19.752715587615967
Epoch: 10, Steps: 266 | Train Loss: 0.4416215 Vali Loss: 0.2191339 Test Loss: 0.3078480
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4826984
	speed: 0.3178s/iter; left time: 7577.8524s
	iters: 200, epoch: 11 | loss: 0.4914004
	speed: 0.0713s/iter; left time: 1693.0919s
Epoch: 11 cost time: 19.61590814590454
Epoch: 11, Steps: 266 | Train Loss: 0.4416956 Vali Loss: 0.2192292 Test Loss: 0.3078136
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4949974
	speed: 0.3220s/iter; left time: 7592.2457s
	iters: 200, epoch: 12 | loss: 0.4782285
	speed: 0.0710s/iter; left time: 1667.4432s
Epoch: 12 cost time: 19.910231828689575
Epoch: 12, Steps: 266 | Train Loss: 0.4418692 Vali Loss: 0.2189738 Test Loss: 0.3078308
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3900496
	speed: 0.3178s/iter; left time: 7407.2773s
	iters: 200, epoch: 13 | loss: 0.3257212
	speed: 0.0715s/iter; left time: 1659.8273s
Epoch: 13 cost time: 19.9127676486969
Epoch: 13, Steps: 266 | Train Loss: 0.4417126 Vali Loss: 0.2191088 Test Loss: 0.3078354
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.5198388
	speed: 0.3206s/iter; left time: 7386.4694s
	iters: 200, epoch: 14 | loss: 0.3717826
	speed: 0.0714s/iter; left time: 1638.5840s
Epoch: 14 cost time: 19.74836230278015
Epoch: 14, Steps: 266 | Train Loss: 0.4408257 Vali Loss: 0.2191596 Test Loss: 0.3078029
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4366120
	speed: 0.3221s/iter; left time: 7336.7634s
	iters: 200, epoch: 15 | loss: 0.3918684
	speed: 0.0716s/iter; left time: 1624.4111s
Epoch: 15 cost time: 19.90709686279297
Epoch: 15, Steps: 266 | Train Loss: 0.4417983 Vali Loss: 0.2191878 Test Loss: 0.3078274
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4463246
	speed: 0.3248s/iter; left time: 7312.3516s
	iters: 200, epoch: 16 | loss: 0.4252889
	speed: 0.0728s/iter; left time: 1632.4780s
Epoch: 16 cost time: 19.99164342880249
Epoch: 16, Steps: 266 | Train Loss: 0.4416326 Vali Loss: 0.2190355 Test Loss: 0.3078544
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3808466
	speed: 0.3197s/iter; left time: 7112.4016s
	iters: 200, epoch: 17 | loss: 0.3962021
	speed: 0.0721s/iter; left time: 1597.3675s
Epoch: 17 cost time: 20.04279613494873
Epoch: 17, Steps: 266 | Train Loss: 0.4414405 Vali Loss: 0.2191465 Test Loss: 0.3078876
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.5450060
	speed: 0.3202s/iter; left time: 7037.1580s
	iters: 200, epoch: 18 | loss: 0.5634208
	speed: 0.0714s/iter; left time: 1563.0269s
Epoch: 18 cost time: 19.77008318901062
Epoch: 18, Steps: 266 | Train Loss: 0.4412849 Vali Loss: 0.2192204 Test Loss: 0.3079200
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3348764
	speed: 0.3203s/iter; left time: 6954.7217s
	iters: 200, epoch: 19 | loss: 0.3567100
	speed: 0.0704s/iter; left time: 1521.3459s
Epoch: 19 cost time: 19.54766035079956
Epoch: 19, Steps: 266 | Train Loss: 0.4417056 Vali Loss: 0.2191571 Test Loss: 0.3079341
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.5981359
	speed: 0.3181s/iter; left time: 6822.3639s
	iters: 200, epoch: 20 | loss: 0.2966540
	speed: 0.0723s/iter; left time: 1543.2564s
Epoch: 20 cost time: 19.979676961898804
Epoch: 20, Steps: 266 | Train Loss: 0.4416765 Vali Loss: 0.2191423 Test Loss: 0.3079152
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4686864
	speed: 0.3226s/iter; left time: 6832.7614s
	iters: 200, epoch: 21 | loss: 0.4516052
	speed: 0.0716s/iter; left time: 1509.6225s
Epoch: 21 cost time: 20.005897045135498
Epoch: 21, Steps: 266 | Train Loss: 0.4406103 Vali Loss: 0.2192847 Test Loss: 0.3079179
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4346346
	speed: 0.3225s/iter; left time: 6744.2275s
	iters: 200, epoch: 22 | loss: 0.5508194
	speed: 0.0724s/iter; left time: 1506.8636s
Epoch: 22 cost time: 19.961758852005005
Epoch: 22, Steps: 266 | Train Loss: 0.4408109 Vali Loss: 0.2193179 Test Loss: 0.3079683
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_90_336_FITS_ETTm2_ftM_sl90_ll48_pl336_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.30908626317977905, mae:0.34380224347114563, rse:0.4490559995174408, corr:[0.55806273 0.5600909  0.55711263 0.55285776 0.5500454  0.5493946
 0.54968756 0.5493811  0.5481216  0.54652786 0.5453352  0.5448122
 0.54463977 0.54425603 0.5433322  0.5419979  0.54066426 0.53966135
 0.5389587  0.53823143 0.53726906 0.53615934 0.53518885 0.5346612
 0.5345297  0.53441244 0.53399694 0.5331802  0.53211075 0.531173
 0.53056496 0.5302379  0.5299296  0.5294595  0.5287533  0.5279481
 0.5271278  0.5263754  0.52567744 0.5250059  0.52441436 0.52402264
 0.5238333  0.5237281  0.52354485 0.5231136  0.52243817 0.52156216
 0.5206264  0.5197852  0.51907015 0.51849276 0.5179382  0.5173149
 0.5167145  0.516201   0.5157874  0.51547754 0.5152118  0.5149756
 0.51473916 0.51452    0.51440465 0.5144237  0.5144734  0.514468
 0.5143735  0.51419705 0.5140494  0.5139917  0.51402825 0.5141277
 0.51419026 0.514192   0.5140633  0.5138495  0.51363534 0.5134339
 0.51324975 0.5130604  0.5128434  0.51257825 0.51228386 0.5119752
 0.5116799  0.5114039  0.5111519  0.5109277  0.5106857  0.5103778
 0.5099573  0.50933844 0.50850177 0.50741124 0.50599027 0.5041678
 0.5020184  0.4998278  0.49785164 0.4961796  0.4947224  0.49334055
 0.49187773 0.49027473 0.4887351  0.48743248 0.48636803 0.48538947
 0.48434082 0.48313698 0.48179966 0.48036644 0.47895545 0.4776181
 0.47635037 0.47515994 0.47402945 0.47293052 0.47187072 0.47080234
 0.46980157 0.46887738 0.46797597 0.4670171  0.46596515 0.46485534
 0.46378618 0.46282706 0.4619144  0.4610221  0.4601266  0.45919275
 0.45821723 0.45728812 0.45644385 0.45584098 0.4553753  0.45502493
 0.45470682 0.45436332 0.45399818 0.453597   0.4531399  0.45257488
 0.45185053 0.45100436 0.45008647 0.44926724 0.4485888  0.44804418
 0.44757357 0.44723114 0.44687143 0.4463358  0.44569057 0.44504794
 0.44450822 0.4442178  0.4441138  0.44422057 0.44440427 0.4445086
 0.44453907 0.4443773  0.44420978 0.44409874 0.44407976 0.44420123
 0.44446635 0.44480568 0.4450696  0.44513896 0.44500938 0.44476295
 0.44454792 0.4444744  0.4445388  0.44464862 0.4446699  0.44456652
 0.4443677  0.44414636 0.4440579  0.4440583  0.44406816 0.44394064
 0.44357312 0.44293848 0.44200724 0.4407688  0.43923834 0.4374233
 0.43543375 0.43349853 0.431712   0.43012023 0.42875358 0.4275183
 0.42629412 0.42494476 0.42356342 0.42230737 0.42127895 0.42038226
 0.41942805 0.4183188  0.41697273 0.4154482  0.4139007  0.4125515
 0.41138995 0.41032928 0.40923595 0.4080428  0.40679467 0.40557346
 0.40449068 0.40354392 0.40273586 0.4018676  0.40078124 0.39949805
 0.39819705 0.39698437 0.3961054  0.3954031  0.39474943 0.3939237
 0.39282715 0.3915583  0.39027923 0.389325   0.38881782 0.38870123
 0.3887098  0.38857654 0.38820538 0.3876404  0.38708118 0.386653
 0.38641322 0.38632175 0.386228   0.38624808 0.38629398 0.3862598
 0.38623688 0.38622227 0.38616017 0.38595384 0.38570774 0.38555452
 0.38556945 0.3858207  0.38626093 0.38673604 0.38715705 0.38746005
 0.38763568 0.3877268  0.38778257 0.3879452  0.3882632  0.38869047
 0.38920382 0.38967976 0.39011806 0.39042622 0.3906167  0.3907246
 0.39074746 0.39080563 0.39096394 0.3912925  0.39177403 0.39228362
 0.3927412  0.39309078 0.39331535 0.39347503 0.39354944 0.39357597
 0.39351794 0.39333746 0.3930129  0.39254344 0.39191142 0.391087
 0.39009953 0.389088   0.38816568 0.3874795  0.38703877 0.3868053
 0.38669553 0.38654932 0.38638145 0.3862671  0.3862283  0.38616678
 0.3859542  0.3854655  0.38462928 0.38352415 0.3823452  0.38130957
 0.38053104 0.37989753 0.3792319  0.37841102 0.37740046 0.3763663
 0.37546197 0.37483105 0.3743506  0.37371174 0.3727079  0.37135157
 0.36991942 0.36882538 0.3682544  0.36803275 0.36769792 0.36687747
 0.3655187  0.3640772  0.3631527  0.3627584  0.36243373 0.3614828
 0.35979334 0.35823712 0.35834765 0.36075535 0.3637603  0.36320743]
