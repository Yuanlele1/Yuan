Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=18, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_90_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_90_336_FITS_ETTm2_ftM_sl90_ll48_pl336_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=18, out_features=85, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1370880.0
params:  1615.0
Trainable parameters:  1615
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4533670
	speed: 0.0462s/iter; left time: 1223.2956s
	iters: 200, epoch: 1 | loss: 0.4061865
	speed: 0.0239s/iter; left time: 631.0721s
Epoch: 1 cost time: 9.304959535598755
Epoch: 1, Steps: 266 | Train Loss: 0.4690250 Vali Loss: 0.2564786 Test Loss: 0.3536041
Validation loss decreased (inf --> 0.256479).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3074473
	speed: 0.1600s/iter; left time: 4196.4133s
	iters: 200, epoch: 2 | loss: 0.3724465
	speed: 0.0270s/iter; left time: 706.5234s
Epoch: 2 cost time: 9.401795625686646
Epoch: 2, Steps: 266 | Train Loss: 0.3785409 Vali Loss: 0.2277348 Test Loss: 0.3192582
Validation loss decreased (0.256479 --> 0.227735).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5440427
	speed: 0.1204s/iter; left time: 3127.9331s
	iters: 200, epoch: 3 | loss: 0.2144628
	speed: 0.0311s/iter; left time: 804.2940s
Epoch: 3 cost time: 7.661228895187378
Epoch: 3, Steps: 266 | Train Loss: 0.3602841 Vali Loss: 0.2209419 Test Loss: 0.3113060
Validation loss decreased (0.227735 --> 0.220942).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3133405
	speed: 0.1274s/iter; left time: 3275.2757s
	iters: 200, epoch: 4 | loss: 0.4413803
	speed: 0.0204s/iter; left time: 521.8395s
Epoch: 4 cost time: 7.18905782699585
Epoch: 4, Steps: 266 | Train Loss: 0.3553823 Vali Loss: 0.2190034 Test Loss: 0.3090414
Validation loss decreased (0.220942 --> 0.219003).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4384773
	speed: 0.0891s/iter; left time: 2266.1495s
	iters: 200, epoch: 5 | loss: 0.3473412
	speed: 0.0177s/iter; left time: 448.8375s
Epoch: 5 cost time: 6.580397129058838
Epoch: 5, Steps: 266 | Train Loss: 0.3540026 Vali Loss: 0.2185508 Test Loss: 0.3083240
Validation loss decreased (0.219003 --> 0.218551).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3988310
	speed: 0.1115s/iter; left time: 2806.0085s
	iters: 200, epoch: 6 | loss: 0.4214862
	speed: 0.0310s/iter; left time: 778.0522s
Epoch: 6 cost time: 8.352709770202637
Epoch: 6, Steps: 266 | Train Loss: 0.3529676 Vali Loss: 0.2182966 Test Loss: 0.3080571
Validation loss decreased (0.218551 --> 0.218297).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2895188
	speed: 0.1322s/iter; left time: 3292.9642s
	iters: 200, epoch: 7 | loss: 0.2572780
	speed: 0.0206s/iter; left time: 511.8620s
Epoch: 7 cost time: 7.935542821884155
Epoch: 7, Steps: 266 | Train Loss: 0.3521623 Vali Loss: 0.2183332 Test Loss: 0.3078716
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4681999
	speed: 0.1220s/iter; left time: 3005.0847s
	iters: 200, epoch: 8 | loss: 0.2398313
	speed: 0.0334s/iter; left time: 818.9905s
Epoch: 8 cost time: 8.103891849517822
Epoch: 8, Steps: 266 | Train Loss: 0.3519632 Vali Loss: 0.2184558 Test Loss: 0.3077914
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3727072
	speed: 0.1399s/iter; left time: 3410.9707s
	iters: 200, epoch: 9 | loss: 0.2412454
	speed: 0.0280s/iter; left time: 679.3510s
Epoch: 9 cost time: 8.62393856048584
Epoch: 9, Steps: 266 | Train Loss: 0.3518736 Vali Loss: 0.2183787 Test Loss: 0.3077338
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3193285
	speed: 0.1127s/iter; left time: 2717.0073s
	iters: 200, epoch: 10 | loss: 0.3255030
	speed: 0.0174s/iter; left time: 416.8167s
Epoch: 10 cost time: 7.215343475341797
Epoch: 10, Steps: 266 | Train Loss: 0.3516568 Vali Loss: 0.2185181 Test Loss: 0.3077957
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1873883
	speed: 0.1196s/iter; left time: 2851.5425s
	iters: 200, epoch: 11 | loss: 0.4318980
	speed: 0.0435s/iter; left time: 1032.6406s
Epoch: 11 cost time: 10.031920433044434
Epoch: 11, Steps: 266 | Train Loss: 0.3513794 Vali Loss: 0.2187826 Test Loss: 0.3078386
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.5410870
	speed: 0.1605s/iter; left time: 3783.3507s
	iters: 200, epoch: 12 | loss: 0.4531160
	speed: 0.0281s/iter; left time: 658.6127s
Epoch: 12 cost time: 9.16845703125
Epoch: 12, Steps: 266 | Train Loss: 0.3510009 Vali Loss: 0.2186038 Test Loss: 0.3079503
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4450167
	speed: 0.1216s/iter; left time: 2834.4354s
	iters: 200, epoch: 13 | loss: 0.4150413
	speed: 0.0267s/iter; left time: 618.8474s
Epoch: 13 cost time: 7.957641839981079
Epoch: 13, Steps: 266 | Train Loss: 0.3510583 Vali Loss: 0.2186780 Test Loss: 0.3079227
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3669425
	speed: 0.1495s/iter; left time: 3444.7096s
	iters: 200, epoch: 14 | loss: 0.3081030
	speed: 0.0410s/iter; left time: 940.1364s
Epoch: 14 cost time: 12.231966018676758
Epoch: 14, Steps: 266 | Train Loss: 0.3511168 Vali Loss: 0.2186715 Test Loss: 0.3079599
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4798757
	speed: 0.1241s/iter; left time: 2825.5517s
	iters: 200, epoch: 15 | loss: 0.3067687
	speed: 0.0152s/iter; left time: 344.6431s
Epoch: 15 cost time: 5.769826173782349
Epoch: 15, Steps: 266 | Train Loss: 0.3510517 Vali Loss: 0.2186505 Test Loss: 0.3079000
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3352831
	speed: 0.1139s/iter; left time: 2564.2920s
	iters: 200, epoch: 16 | loss: 0.5340474
	speed: 0.0164s/iter; left time: 367.4486s
Epoch: 16 cost time: 6.188432931900024
Epoch: 16, Steps: 266 | Train Loss: 0.3506466 Vali Loss: 0.2188664 Test Loss: 0.3079349
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2530076
	speed: 0.1501s/iter; left time: 3338.3922s
	iters: 200, epoch: 17 | loss: 0.2814406
	speed: 0.0344s/iter; left time: 761.1453s
Epoch: 17 cost time: 10.827997922897339
Epoch: 17, Steps: 266 | Train Loss: 0.3503270 Vali Loss: 0.2189025 Test Loss: 0.3079661
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4331166
	speed: 0.1700s/iter; left time: 3735.7517s
	iters: 200, epoch: 18 | loss: 0.3403648
	speed: 0.0261s/iter; left time: 570.1866s
Epoch: 18 cost time: 9.082931756973267
Epoch: 18, Steps: 266 | Train Loss: 0.3508033 Vali Loss: 0.2189882 Test Loss: 0.3080950
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4405987
	speed: 0.1007s/iter; left time: 2186.7616s
	iters: 200, epoch: 19 | loss: 0.3329539
	speed: 0.0301s/iter; left time: 651.4722s
Epoch: 19 cost time: 7.713639259338379
Epoch: 19, Steps: 266 | Train Loss: 0.3500557 Vali Loss: 0.2190679 Test Loss: 0.3080064
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3779535
	speed: 0.1335s/iter; left time: 2863.6786s
	iters: 200, epoch: 20 | loss: 0.3484667
	speed: 0.0188s/iter; left time: 401.8353s
Epoch: 20 cost time: 6.266706228256226
Epoch: 20, Steps: 266 | Train Loss: 0.3508590 Vali Loss: 0.2189449 Test Loss: 0.3081205
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2403589
	speed: 0.0946s/iter; left time: 2003.5762s
	iters: 200, epoch: 21 | loss: 0.3838902
	speed: 0.0458s/iter; left time: 965.4951s
Epoch: 21 cost time: 8.244204044342041
Epoch: 21, Steps: 266 | Train Loss: 0.3509562 Vali Loss: 0.2190888 Test Loss: 0.3081149
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4419370
	speed: 0.1011s/iter; left time: 2114.3871s
	iters: 200, epoch: 22 | loss: 0.2912408
	speed: 0.0346s/iter; left time: 720.3931s
Epoch: 22 cost time: 9.138949394226074
Epoch: 22, Steps: 266 | Train Loss: 0.3508110 Vali Loss: 0.2190716 Test Loss: 0.3080773
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4592938
	speed: 0.1398s/iter; left time: 2887.3333s
	iters: 200, epoch: 23 | loss: 0.4003435
	speed: 0.0244s/iter; left time: 500.9320s
Epoch: 23 cost time: 8.58908486366272
Epoch: 23, Steps: 266 | Train Loss: 0.3506112 Vali Loss: 0.2191927 Test Loss: 0.3080567
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3581319
	speed: 0.1751s/iter; left time: 3569.4776s
	iters: 200, epoch: 24 | loss: 0.3632351
	speed: 0.0298s/iter; left time: 603.7896s
Epoch: 24 cost time: 10.080970287322998
Epoch: 24, Steps: 266 | Train Loss: 0.3502029 Vali Loss: 0.2190739 Test Loss: 0.3081082
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4866763
	speed: 0.1381s/iter; left time: 2778.6671s
	iters: 200, epoch: 25 | loss: 0.4178670
	speed: 0.0325s/iter; left time: 649.8696s
Epoch: 25 cost time: 9.62720775604248
Epoch: 25, Steps: 266 | Train Loss: 0.3506426 Vali Loss: 0.2191443 Test Loss: 0.3080634
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2803304
	speed: 0.1328s/iter; left time: 2636.4864s
	iters: 200, epoch: 26 | loss: 0.2121453
	speed: 0.0173s/iter; left time: 342.6690s
Epoch: 26 cost time: 6.907891273498535
Epoch: 26, Steps: 266 | Train Loss: 0.3503600 Vali Loss: 0.2191745 Test Loss: 0.3080935
EarlyStopping counter: 20 out of 20
Early stopping
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=18, out_features=85, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1370880.0
params:  1615.0
Trainable parameters:  1615
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5385509
	speed: 0.0243s/iter; left time: 643.6226s
	iters: 200, epoch: 1 | loss: 0.6357814
	speed: 0.0252s/iter; left time: 664.2564s
Epoch: 1 cost time: 6.304958820343018
Epoch: 1, Steps: 266 | Train Loss: 0.4425595 Vali Loss: 0.2181095 Test Loss: 0.3074450
Validation loss decreased (inf --> 0.218109).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3799748
	speed: 0.1288s/iter; left time: 3379.9013s
	iters: 200, epoch: 2 | loss: 0.4035167
	speed: 0.0194s/iter; left time: 507.1491s
Epoch: 2 cost time: 6.116417407989502
Epoch: 2, Steps: 266 | Train Loss: 0.4425315 Vali Loss: 0.2181195 Test Loss: 0.3073994
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3014354
	speed: 0.1209s/iter; left time: 3139.3314s
	iters: 200, epoch: 3 | loss: 0.5399371
	speed: 0.0215s/iter; left time: 555.8041s
Epoch: 3 cost time: 6.951133728027344
Epoch: 3, Steps: 266 | Train Loss: 0.4417121 Vali Loss: 0.2179373 Test Loss: 0.3071921
Validation loss decreased (0.218109 --> 0.217937).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.6275880
	speed: 0.1130s/iter; left time: 2904.9685s
	iters: 200, epoch: 4 | loss: 0.4976154
	speed: 0.0312s/iter; left time: 798.3982s
Epoch: 4 cost time: 7.240990161895752
Epoch: 4, Steps: 266 | Train Loss: 0.4419508 Vali Loss: 0.2182072 Test Loss: 0.3073315
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.5483988
	speed: 0.1072s/iter; left time: 2728.1047s
	iters: 200, epoch: 5 | loss: 0.3482755
	speed: 0.0239s/iter; left time: 604.6690s
Epoch: 5 cost time: 8.274723291397095
Epoch: 5, Steps: 266 | Train Loss: 0.4416214 Vali Loss: 0.2183130 Test Loss: 0.3072625
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3311483
	speed: 0.1630s/iter; left time: 4101.8540s
	iters: 200, epoch: 6 | loss: 0.2885315
	speed: 0.0258s/iter; left time: 645.6720s
Epoch: 6 cost time: 10.1384756565094
Epoch: 6, Steps: 266 | Train Loss: 0.4414601 Vali Loss: 0.2183063 Test Loss: 0.3073091
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3020511
	speed: 0.1574s/iter; left time: 3919.7093s
	iters: 200, epoch: 7 | loss: 0.5242048
	speed: 0.0273s/iter; left time: 676.8246s
Epoch: 7 cost time: 9.436566591262817
Epoch: 7, Steps: 266 | Train Loss: 0.4416859 Vali Loss: 0.2183536 Test Loss: 0.3073608
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3315443
	speed: 0.1593s/iter; left time: 3926.1005s
	iters: 200, epoch: 8 | loss: 0.4141598
	speed: 0.0299s/iter; left time: 734.8332s
Epoch: 8 cost time: 8.387112855911255
Epoch: 8, Steps: 266 | Train Loss: 0.4413605 Vali Loss: 0.2186460 Test Loss: 0.3074459
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.6025088
	speed: 0.1121s/iter; left time: 2732.2001s
	iters: 200, epoch: 9 | loss: 0.4406281
	speed: 0.0228s/iter; left time: 554.2558s
Epoch: 9 cost time: 6.26465368270874
Epoch: 9, Steps: 266 | Train Loss: 0.4411974 Vali Loss: 0.2185410 Test Loss: 0.3074080
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4324434
	speed: 0.0944s/iter; left time: 2275.5339s
	iters: 200, epoch: 10 | loss: 0.6620425
	speed: 0.0245s/iter; left time: 588.7108s
Epoch: 10 cost time: 7.8376781940460205
Epoch: 10, Steps: 266 | Train Loss: 0.4409928 Vali Loss: 0.2187130 Test Loss: 0.3074543
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3740397
	speed: 0.1389s/iter; left time: 3311.9889s
	iters: 200, epoch: 11 | loss: 0.4057690
	speed: 0.0345s/iter; left time: 818.7116s
Epoch: 11 cost time: 11.494494199752808
Epoch: 11, Steps: 266 | Train Loss: 0.4412518 Vali Loss: 0.2188613 Test Loss: 0.3076102
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.5425568
	speed: 0.1765s/iter; left time: 4160.8378s
	iters: 200, epoch: 12 | loss: 0.4006657
	speed: 0.0279s/iter; left time: 655.4135s
Epoch: 12 cost time: 10.230719327926636
Epoch: 12, Steps: 266 | Train Loss: 0.4407663 Vali Loss: 0.2187481 Test Loss: 0.3074431
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3256129
	speed: 0.1542s/iter; left time: 3595.2188s
	iters: 200, epoch: 13 | loss: 0.3669219
	speed: 0.0184s/iter; left time: 426.3675s
Epoch: 13 cost time: 8.640588521957397
Epoch: 13, Steps: 266 | Train Loss: 0.4405975 Vali Loss: 0.2188713 Test Loss: 0.3074891
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4693457
	speed: 0.1108s/iter; left time: 2553.5644s
	iters: 200, epoch: 14 | loss: 0.3203291
	speed: 0.0188s/iter; left time: 432.2025s
Epoch: 14 cost time: 6.285157918930054
Epoch: 14, Steps: 266 | Train Loss: 0.4411707 Vali Loss: 0.2186896 Test Loss: 0.3075297
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3188260
	speed: 0.1074s/iter; left time: 2446.4253s
	iters: 200, epoch: 15 | loss: 0.4284410
	speed: 0.0189s/iter; left time: 429.5704s
Epoch: 15 cost time: 6.444031000137329
Epoch: 15, Steps: 266 | Train Loss: 0.4413386 Vali Loss: 0.2187870 Test Loss: 0.3075690
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3397951
	speed: 0.0956s/iter; left time: 2151.8133s
	iters: 200, epoch: 16 | loss: 0.4357586
	speed: 0.0368s/iter; left time: 825.5403s
Epoch: 16 cost time: 7.613714218139648
Epoch: 16, Steps: 266 | Train Loss: 0.4406956 Vali Loss: 0.2187562 Test Loss: 0.3075483
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3555420
	speed: 0.1465s/iter; left time: 3258.6878s
	iters: 200, epoch: 17 | loss: 0.4933977
	speed: 0.0270s/iter; left time: 597.5310s
Epoch: 17 cost time: 9.746910333633423
Epoch: 17, Steps: 266 | Train Loss: 0.4398890 Vali Loss: 0.2187009 Test Loss: 0.3075868
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.5275050
	speed: 0.1396s/iter; left time: 3067.5901s
	iters: 200, epoch: 18 | loss: 0.4223503
	speed: 0.0336s/iter; left time: 734.3691s
Epoch: 18 cost time: 8.688819169998169
Epoch: 18, Steps: 266 | Train Loss: 0.4406075 Vali Loss: 0.2190352 Test Loss: 0.3075786
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.5459042
	speed: 0.1598s/iter; left time: 3470.2892s
	iters: 200, epoch: 19 | loss: 0.3560615
	speed: 0.0361s/iter; left time: 780.7629s
Epoch: 19 cost time: 9.225805044174194
Epoch: 19, Steps: 266 | Train Loss: 0.4407826 Vali Loss: 0.2189290 Test Loss: 0.3075655
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3561656
	speed: 0.1029s/iter; left time: 2207.6868s
	iters: 200, epoch: 20 | loss: 0.5179806
	speed: 0.0247s/iter; left time: 526.8756s
Epoch: 20 cost time: 6.666242837905884
Epoch: 20, Steps: 266 | Train Loss: 0.4411066 Vali Loss: 0.2189296 Test Loss: 0.3075877
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.5184886
	speed: 0.1345s/iter; left time: 2848.5892s
	iters: 200, epoch: 21 | loss: 0.3290405
	speed: 0.0226s/iter; left time: 477.1356s
Epoch: 21 cost time: 8.397047281265259
Epoch: 21, Steps: 266 | Train Loss: 0.4409069 Vali Loss: 0.2189197 Test Loss: 0.3075923
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3339756
	speed: 0.1109s/iter; left time: 2319.5178s
	iters: 200, epoch: 22 | loss: 0.3664411
	speed: 0.0215s/iter; left time: 448.2806s
Epoch: 22 cost time: 6.5795371532440186
Epoch: 22, Steps: 266 | Train Loss: 0.4408031 Vali Loss: 0.2188864 Test Loss: 0.3076209
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4225566
	speed: 0.1240s/iter; left time: 2559.6666s
	iters: 200, epoch: 23 | loss: 0.6156139
	speed: 0.0505s/iter; left time: 1037.8242s
Epoch: 23 cost time: 12.144965648651123
Epoch: 23, Steps: 266 | Train Loss: 0.4403364 Vali Loss: 0.2185918 Test Loss: 0.3075751
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_90_336_FITS_ETTm2_ftM_sl90_ll48_pl336_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.3085767328739166, mae:0.3433641791343689, rse:0.4486857056617737, corr:[0.5612576  0.5628764  0.5568256  0.5522942  0.5519994  0.55257535
 0.5511865  0.5487275  0.54739505 0.54745096 0.5474244  0.54635555
 0.5447727  0.543768   0.5434149  0.54283017 0.54159343 0.5402723
 0.539523   0.53912485 0.5383774  0.5370968  0.5358035  0.53515065
 0.53500813 0.5347073  0.53401816 0.5331866  0.53255534 0.53209645
 0.5314154  0.5304541  0.5295125  0.5289957  0.52879274 0.5284736
 0.5276829  0.5265979  0.5256497  0.52501094 0.52454674 0.5241337
 0.5237037  0.523328   0.5230325  0.5226282  0.52204496 0.52125674
 0.52040136 0.5196158  0.5188783  0.51823044 0.51763666 0.5170551
 0.5165586  0.51606256 0.5154881  0.5149653  0.5146131  0.5144748
 0.5143743  0.5141764  0.5139757  0.51392204 0.51398844 0.5140692
 0.51404476 0.5139028  0.5138029  0.51384574 0.51399434 0.5141589
 0.51420534 0.51417786 0.5140716  0.5139425  0.5138563  0.51372963
 0.51353043 0.5132721  0.5130276  0.5128323  0.51264954 0.5124033
 0.5120956  0.5117654  0.51148605 0.5112826  0.51108277 0.510813
 0.5104539  0.50999796 0.5094311  0.50867224 0.5074997  0.5057245
 0.50350815 0.5012954  0.49932918 0.49758673 0.49596462 0.49444914
 0.49301654 0.49163246 0.490332   0.4890711  0.48783296 0.48660976
 0.48537955 0.48412168 0.48282474 0.48146152 0.48010585 0.47877315
 0.47743747 0.47614542 0.4749485  0.4738507  0.47280735 0.47169074
 0.47057638 0.46951517 0.46849436 0.46747866 0.46646154 0.46546942
 0.46453235 0.46361327 0.46259102 0.46152586 0.46054313 0.45966265
 0.45882097 0.45795405 0.45703638 0.45634177 0.45584297 0.45556873
 0.45536304 0.4550817  0.45470756 0.4542585  0.45378903 0.45325047
 0.45251215 0.45154345 0.45038104 0.44930774 0.44842508 0.4477264
 0.44711345 0.44663268 0.44610718 0.44542694 0.44482693 0.4445046
 0.44444957 0.44459102 0.44462872 0.44459316 0.4444718  0.44427684
 0.44413936 0.44393393 0.44385087 0.44389945 0.44404215 0.44425195
 0.44448724 0.44469807 0.44483343 0.44490597 0.4449747  0.44503206
 0.4450432  0.44499567 0.44489655 0.44483227 0.4448025  0.44480535
 0.4447822  0.4446557  0.44450146 0.44428256 0.4440626  0.44387725
 0.44372642 0.4435189  0.44300127 0.441997   0.4404902  0.4385781
 0.4364791  0.43445686 0.4325759  0.4308913  0.42952952 0.42842978
 0.4273715  0.42613956 0.42485785 0.42368376 0.42263702 0.42157185
 0.42035365 0.41903135 0.4176519  0.41631836 0.41506037 0.41384825
 0.41254982 0.41124547 0.41003084 0.40890178 0.40781218 0.40667662
 0.40550435 0.40437227 0.40342376 0.4024874  0.40138793 0.40013063
 0.39887267 0.39765835 0.3967229  0.3958742  0.39510098 0.39430568
 0.3934241  0.3924201  0.39124578 0.39015114 0.38930655 0.3888406
 0.38862583 0.38846314 0.38823494 0.38791808 0.38761097 0.3872952
 0.38697672 0.38669026 0.38639832 0.3863305  0.3862934  0.3860501
 0.38577977 0.38568977 0.38588062 0.3861005  0.3861281  0.38589355
 0.38558197 0.3856094  0.38613802 0.38684484 0.38732356 0.38740715
 0.38727295 0.3872641  0.38748565 0.3878711  0.38821194 0.38839507
 0.3886143  0.38894114 0.38941738 0.3898104  0.39008638 0.39034262
 0.39061958 0.39096972 0.3913016  0.3916091  0.39194456 0.39231604
 0.3927174  0.39302242 0.39318657 0.39332765 0.3935416  0.39389545
 0.39429495 0.394529   0.3943866  0.39381748 0.39291525 0.39177364
 0.39052248 0.38938746 0.38850504 0.38804576 0.38800323 0.38820288
 0.38838318 0.38837215 0.388279   0.38817903 0.3879652  0.3874834
 0.38674313 0.38590717 0.38514477 0.38449413 0.3838102  0.38293314
 0.38190186 0.38089684 0.3800948  0.37942353 0.37862495 0.37767902
 0.37671962 0.3760138  0.37547794 0.37476692 0.37369743 0.3724664
 0.37145656 0.3708555  0.37034062 0.36952433 0.36846766 0.36761653
 0.36708033 0.36643183 0.36519092 0.36352912 0.36253273 0.36273578
 0.36315525 0.36235064 0.36085895 0.36103678 0.3642182  0.36508277]
