Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=38, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_180_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_180_720_FITS_ETTm2_ftM_sl180_ll48_pl720_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33661
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=38, out_features=190, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6469120.0
params:  7410.0
Trainable parameters:  7410
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.9521006
	speed: 0.0489s/iter; left time: 1277.3099s
	iters: 200, epoch: 1 | loss: 0.7556356
	speed: 0.0422s/iter; left time: 1096.6770s
Epoch: 1 cost time: 11.130473136901855
Epoch: 1, Steps: 262 | Train Loss: 0.5843314 Vali Loss: 0.3103884 Test Loss: 0.4298740
Validation loss decreased (inf --> 0.310388).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5274456
	speed: 0.1480s/iter; left time: 3823.7520s
	iters: 200, epoch: 2 | loss: 0.4191555
	speed: 0.0630s/iter; left time: 1622.6264s
Epoch: 2 cost time: 14.033092498779297
Epoch: 2, Steps: 262 | Train Loss: 0.4768721 Vali Loss: 0.2896817 Test Loss: 0.4039589
Validation loss decreased (0.310388 --> 0.289682).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3295974
	speed: 0.2035s/iter; left time: 5205.8187s
	iters: 200, epoch: 3 | loss: 0.3601354
	speed: 0.0362s/iter; left time: 922.7585s
Epoch: 3 cost time: 11.284808158874512
Epoch: 3, Steps: 262 | Train Loss: 0.4608601 Vali Loss: 0.2843781 Test Loss: 0.3972677
Validation loss decreased (0.289682 --> 0.284378).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3899367
	speed: 0.2087s/iter; left time: 5282.2214s
	iters: 200, epoch: 4 | loss: 0.4075012
	speed: 0.0546s/iter; left time: 1377.5363s
Epoch: 4 cost time: 14.058456659317017
Epoch: 4, Steps: 262 | Train Loss: 0.4550532 Vali Loss: 0.2819327 Test Loss: 0.3939857
Validation loss decreased (0.284378 --> 0.281933).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3530452
	speed: 0.2039s/iter; left time: 5109.0957s
	iters: 200, epoch: 5 | loss: 0.3744332
	speed: 0.0464s/iter; left time: 1157.4272s
Epoch: 5 cost time: 13.197351455688477
Epoch: 5, Steps: 262 | Train Loss: 0.4531647 Vali Loss: 0.2804551 Test Loss: 0.3920858
Validation loss decreased (0.281933 --> 0.280455).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3867530
	speed: 0.2089s/iter; left time: 5178.3479s
	iters: 200, epoch: 6 | loss: 0.4903915
	speed: 0.0555s/iter; left time: 1370.6608s
Epoch: 6 cost time: 13.614155292510986
Epoch: 6, Steps: 262 | Train Loss: 0.4511863 Vali Loss: 0.2792617 Test Loss: 0.3908931
Validation loss decreased (0.280455 --> 0.279262).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4539255
	speed: 0.2693s/iter; left time: 6606.1380s
	iters: 200, epoch: 7 | loss: 0.4528311
	speed: 0.0452s/iter; left time: 1103.6267s
Epoch: 7 cost time: 14.542728185653687
Epoch: 7, Steps: 262 | Train Loss: 0.4500716 Vali Loss: 0.2784013 Test Loss: 0.3900303
Validation loss decreased (0.279262 --> 0.278401).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4686003
	speed: 0.1202s/iter; left time: 2917.2050s
	iters: 200, epoch: 8 | loss: 0.3877923
	speed: 0.0245s/iter; left time: 592.5438s
Epoch: 8 cost time: 8.023624658584595
Epoch: 8, Steps: 262 | Train Loss: 0.4491075 Vali Loss: 0.2781895 Test Loss: 0.3894277
Validation loss decreased (0.278401 --> 0.278190).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4113186
	speed: 0.1429s/iter; left time: 3430.5015s
	iters: 200, epoch: 9 | loss: 0.3992732
	speed: 0.0470s/iter; left time: 1123.5506s
Epoch: 9 cost time: 14.06549596786499
Epoch: 9, Steps: 262 | Train Loss: 0.4484007 Vali Loss: 0.2780671 Test Loss: 0.3890369
Validation loss decreased (0.278190 --> 0.278067).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4003834
	speed: 0.2233s/iter; left time: 5301.8194s
	iters: 200, epoch: 10 | loss: 0.4036496
	speed: 0.0500s/iter; left time: 1181.6546s
Epoch: 10 cost time: 13.522306680679321
Epoch: 10, Steps: 262 | Train Loss: 0.4484740 Vali Loss: 0.2778722 Test Loss: 0.3886996
Validation loss decreased (0.278067 --> 0.277872).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4016835
	speed: 0.1572s/iter; left time: 3691.5233s
	iters: 200, epoch: 11 | loss: 0.4302496
	speed: 0.0392s/iter; left time: 917.0282s
Epoch: 11 cost time: 8.687116146087646
Epoch: 11, Steps: 262 | Train Loss: 0.4474625 Vali Loss: 0.2774174 Test Loss: 0.3884080
Validation loss decreased (0.277872 --> 0.277417).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3795368
	speed: 0.1373s/iter; left time: 3187.7953s
	iters: 200, epoch: 12 | loss: 0.3822736
	speed: 0.0308s/iter; left time: 712.2583s
Epoch: 12 cost time: 8.910766363143921
Epoch: 12, Steps: 262 | Train Loss: 0.4473041 Vali Loss: 0.2771568 Test Loss: 0.3881763
Validation loss decreased (0.277417 --> 0.277157).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4698105
	speed: 0.1557s/iter; left time: 3574.6603s
	iters: 200, epoch: 13 | loss: 0.5503399
	speed: 0.0263s/iter; left time: 601.8158s
Epoch: 13 cost time: 9.483862161636353
Epoch: 13, Steps: 262 | Train Loss: 0.4474385 Vali Loss: 0.2773870 Test Loss: 0.3880495
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.6941007
	speed: 0.2216s/iter; left time: 5029.7577s
	iters: 200, epoch: 14 | loss: 0.5157376
	speed: 0.0351s/iter; left time: 792.2204s
Epoch: 14 cost time: 12.598028898239136
Epoch: 14, Steps: 262 | Train Loss: 0.4470136 Vali Loss: 0.2771698 Test Loss: 0.3878714
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3680547
	speed: 0.2057s/iter; left time: 4614.9714s
	iters: 200, epoch: 15 | loss: 0.3770467
	speed: 0.0510s/iter; left time: 1139.4710s
Epoch: 15 cost time: 12.384991884231567
Epoch: 15, Steps: 262 | Train Loss: 0.4464546 Vali Loss: 0.2767261 Test Loss: 0.3877044
Validation loss decreased (0.277157 --> 0.276726).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4931751
	speed: 0.1410s/iter; left time: 3125.8584s
	iters: 200, epoch: 16 | loss: 0.4297234
	speed: 0.0448s/iter; left time: 988.2956s
Epoch: 16 cost time: 12.039271831512451
Epoch: 16, Steps: 262 | Train Loss: 0.4470292 Vali Loss: 0.2771971 Test Loss: 0.3876371
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3959637
	speed: 0.2162s/iter; left time: 4736.6355s
	iters: 200, epoch: 17 | loss: 0.4920576
	speed: 0.0573s/iter; left time: 1249.6027s
Epoch: 17 cost time: 14.36623740196228
Epoch: 17, Steps: 262 | Train Loss: 0.4466324 Vali Loss: 0.2771088 Test Loss: 0.3875080
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.5955181
	speed: 0.1928s/iter; left time: 4173.3650s
	iters: 200, epoch: 18 | loss: 0.4467037
	speed: 0.0607s/iter; left time: 1308.9616s
Epoch: 18 cost time: 17.442484378814697
Epoch: 18, Steps: 262 | Train Loss: 0.4460917 Vali Loss: 0.2769560 Test Loss: 0.3874321
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4568684
	speed: 0.2422s/iter; left time: 5178.5075s
	iters: 200, epoch: 19 | loss: 0.3407513
	speed: 0.0286s/iter; left time: 608.2587s
Epoch: 19 cost time: 10.598660707473755
Epoch: 19, Steps: 262 | Train Loss: 0.4446730 Vali Loss: 0.2768046 Test Loss: 0.3873906
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4133995
	speed: 0.1502s/iter; left time: 3172.0361s
	iters: 200, epoch: 20 | loss: 0.5064336
	speed: 0.0362s/iter; left time: 761.0233s
Epoch: 20 cost time: 9.438400030136108
Epoch: 20, Steps: 262 | Train Loss: 0.4461387 Vali Loss: 0.2770047 Test Loss: 0.3873179
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3787443
	speed: 0.2072s/iter; left time: 4322.8524s
	iters: 200, epoch: 21 | loss: 0.5335100
	speed: 0.0366s/iter; left time: 759.5388s
Epoch: 21 cost time: 12.595800161361694
Epoch: 21, Steps: 262 | Train Loss: 0.4463764 Vali Loss: 0.2770733 Test Loss: 0.3872696
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4722885
	speed: 0.2045s/iter; left time: 4213.0696s
	iters: 200, epoch: 22 | loss: 0.7239109
	speed: 0.0309s/iter; left time: 633.5069s
Epoch: 22 cost time: 10.070090532302856
Epoch: 22, Steps: 262 | Train Loss: 0.4454243 Vali Loss: 0.2767971 Test Loss: 0.3872207
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4922472
	speed: 0.1434s/iter; left time: 2916.8690s
	iters: 200, epoch: 23 | loss: 0.4609412
	speed: 0.0384s/iter; left time: 777.7712s
Epoch: 23 cost time: 10.294245481491089
Epoch: 23, Steps: 262 | Train Loss: 0.4464217 Vali Loss: 0.2768893 Test Loss: 0.3871894
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4939252
	speed: 0.1699s/iter; left time: 3411.1762s
	iters: 200, epoch: 24 | loss: 0.4878649
	speed: 0.0632s/iter; left time: 1262.3653s
Epoch: 24 cost time: 17.35987901687622
Epoch: 24, Steps: 262 | Train Loss: 0.4459857 Vali Loss: 0.2767281 Test Loss: 0.3871346
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3860275
	speed: 0.2073s/iter; left time: 4106.7498s
	iters: 200, epoch: 25 | loss: 0.5261981
	speed: 0.0370s/iter; left time: 728.5296s
Epoch: 25 cost time: 11.886273860931396
Epoch: 25, Steps: 262 | Train Loss: 0.4453390 Vali Loss: 0.2766906 Test Loss: 0.3871188
Validation loss decreased (0.276726 --> 0.276691).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2745034
	speed: 0.1970s/iter; left time: 3852.4926s
	iters: 200, epoch: 26 | loss: 0.6048851
	speed: 0.0249s/iter; left time: 483.4922s
Epoch: 26 cost time: 11.511500358581543
Epoch: 26, Steps: 262 | Train Loss: 0.4459639 Vali Loss: 0.2767385 Test Loss: 0.3870886
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4624166
	speed: 0.1386s/iter; left time: 2674.2129s
	iters: 200, epoch: 27 | loss: 0.4231060
	speed: 0.0383s/iter; left time: 735.8582s
Epoch: 27 cost time: 11.12455701828003
Epoch: 27, Steps: 262 | Train Loss: 0.4453445 Vali Loss: 0.2767515 Test Loss: 0.3870770
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2807746
	speed: 0.1860s/iter; left time: 3538.4740s
	iters: 200, epoch: 28 | loss: 0.3618542
	speed: 0.0298s/iter; left time: 564.5316s
Epoch: 28 cost time: 8.11846399307251
Epoch: 28, Steps: 262 | Train Loss: 0.4456374 Vali Loss: 0.2765958 Test Loss: 0.3870515
Validation loss decreased (0.276691 --> 0.276596).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3944222
	speed: 0.1698s/iter; left time: 3186.6415s
	iters: 200, epoch: 29 | loss: 0.3084342
	speed: 0.0318s/iter; left time: 593.4910s
Epoch: 29 cost time: 8.955672979354858
Epoch: 29, Steps: 262 | Train Loss: 0.4455387 Vali Loss: 0.2765469 Test Loss: 0.3870192
Validation loss decreased (0.276596 --> 0.276547).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.5284451
	speed: 0.2018s/iter; left time: 3734.1630s
	iters: 200, epoch: 30 | loss: 0.4497080
	speed: 0.0741s/iter; left time: 1364.1886s
Epoch: 30 cost time: 18.237401247024536
Epoch: 30, Steps: 262 | Train Loss: 0.4458935 Vali Loss: 0.2767468 Test Loss: 0.3869739
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4012114
	speed: 0.2279s/iter; left time: 4157.3787s
	iters: 200, epoch: 31 | loss: 0.3617913
	speed: 0.0374s/iter; left time: 678.7217s
Epoch: 31 cost time: 11.433979272842407
Epoch: 31, Steps: 262 | Train Loss: 0.4457457 Vali Loss: 0.2764733 Test Loss: 0.3869767
Validation loss decreased (0.276547 --> 0.276473).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3506399
	speed: 0.1527s/iter; left time: 2745.6930s
	iters: 200, epoch: 32 | loss: 0.4538519
	speed: 0.0280s/iter; left time: 500.9009s
Epoch: 32 cost time: 8.235499382019043
Epoch: 32, Steps: 262 | Train Loss: 0.4456149 Vali Loss: 0.2768520 Test Loss: 0.3869733
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4758763
	speed: 0.1386s/iter; left time: 2454.7887s
	iters: 200, epoch: 33 | loss: 0.3153253
	speed: 0.0344s/iter; left time: 606.4700s
Epoch: 33 cost time: 10.386340141296387
Epoch: 33, Steps: 262 | Train Loss: 0.4458647 Vali Loss: 0.2766111 Test Loss: 0.3869465
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4533634
	speed: 0.2095s/iter; left time: 3657.0213s
	iters: 200, epoch: 34 | loss: 0.6164586
	speed: 0.0309s/iter; left time: 536.4294s
Epoch: 34 cost time: 13.693554878234863
Epoch: 34, Steps: 262 | Train Loss: 0.4455750 Vali Loss: 0.2767932 Test Loss: 0.3869216
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4724600
	speed: 0.1868s/iter; left time: 3211.9280s
	iters: 200, epoch: 35 | loss: 0.2539665
	speed: 0.0445s/iter; left time: 760.3362s
Epoch: 35 cost time: 12.368587017059326
Epoch: 35, Steps: 262 | Train Loss: 0.4453207 Vali Loss: 0.2767216 Test Loss: 0.3869258
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3360510
	speed: 0.2037s/iter; left time: 3448.7782s
	iters: 200, epoch: 36 | loss: 0.4975461
	speed: 0.0348s/iter; left time: 585.6914s
Epoch: 36 cost time: 11.131039381027222
Epoch: 36, Steps: 262 | Train Loss: 0.4461171 Vali Loss: 0.2764115 Test Loss: 0.3869038
Validation loss decreased (0.276473 --> 0.276412).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.5744326
	speed: 0.1545s/iter; left time: 2576.0741s
	iters: 200, epoch: 37 | loss: 0.4644750
	speed: 0.0342s/iter; left time: 567.0244s
Epoch: 37 cost time: 10.447839260101318
Epoch: 37, Steps: 262 | Train Loss: 0.4456871 Vali Loss: 0.2768222 Test Loss: 0.3869099
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4324382
	speed: 0.1991s/iter; left time: 3266.7526s
	iters: 200, epoch: 38 | loss: 0.4245612
	speed: 0.0488s/iter; left time: 795.8471s
Epoch: 38 cost time: 13.294189929962158
Epoch: 38, Steps: 262 | Train Loss: 0.4458413 Vali Loss: 0.2768519 Test Loss: 0.3869063
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4381734
	speed: 0.2478s/iter; left time: 3999.9487s
	iters: 200, epoch: 39 | loss: 0.4595166
	speed: 0.0411s/iter; left time: 659.8025s
Epoch: 39 cost time: 12.549436330795288
Epoch: 39, Steps: 262 | Train Loss: 0.4457508 Vali Loss: 0.2767780 Test Loss: 0.3868883
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.4309183
	speed: 0.1877s/iter; left time: 2981.7023s
	iters: 200, epoch: 40 | loss: 0.4180026
	speed: 0.0286s/iter; left time: 451.2822s
Epoch: 40 cost time: 8.121308088302612
Epoch: 40, Steps: 262 | Train Loss: 0.4461615 Vali Loss: 0.2764371 Test Loss: 0.3868892
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.4822211
	speed: 0.2103s/iter; left time: 3284.8097s
	iters: 200, epoch: 41 | loss: 0.3422724
	speed: 0.0635s/iter; left time: 984.8441s
Epoch: 41 cost time: 16.03434705734253
Epoch: 41, Steps: 262 | Train Loss: 0.4461050 Vali Loss: 0.2766946 Test Loss: 0.3868723
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2921018
	speed: 0.2372s/iter; left time: 3643.8895s
	iters: 200, epoch: 42 | loss: 0.3597306
	speed: 0.0446s/iter; left time: 680.6492s
Epoch: 42 cost time: 12.495301008224487
Epoch: 42, Steps: 262 | Train Loss: 0.4455685 Vali Loss: 0.2766618 Test Loss: 0.3868719
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3142373
	speed: 0.1973s/iter; left time: 2979.3904s
	iters: 200, epoch: 43 | loss: 0.4366992
	speed: 0.0353s/iter; left time: 529.6677s
Epoch: 43 cost time: 10.180813074111938
Epoch: 43, Steps: 262 | Train Loss: 0.4455121 Vali Loss: 0.2766122 Test Loss: 0.3868602
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.4436924
	speed: 0.1793s/iter; left time: 2659.7109s
	iters: 200, epoch: 44 | loss: 0.4730398
	speed: 0.0429s/iter; left time: 631.6803s
Epoch: 44 cost time: 11.565478801727295
Epoch: 44, Steps: 262 | Train Loss: 0.4458710 Vali Loss: 0.2766108 Test Loss: 0.3868657
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.4806857
	speed: 0.2049s/iter; left time: 2985.2798s
	iters: 200, epoch: 45 | loss: 0.4178586
	speed: 0.0414s/iter; left time: 599.6958s
Epoch: 45 cost time: 13.156457424163818
Epoch: 45, Steps: 262 | Train Loss: 0.4455585 Vali Loss: 0.2766329 Test Loss: 0.3868600
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.3725054
	speed: 0.2411s/iter; left time: 3450.9658s
	iters: 200, epoch: 46 | loss: 0.5683140
	speed: 0.0664s/iter; left time: 943.0990s
Epoch: 46 cost time: 17.085875034332275
Epoch: 46, Steps: 262 | Train Loss: 0.4457233 Vali Loss: 0.2764336 Test Loss: 0.3868559
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.4346213
	speed: 0.1625s/iter; left time: 2282.8324s
	iters: 200, epoch: 47 | loss: 0.3904717
	speed: 0.0231s/iter; left time: 321.9442s
Epoch: 47 cost time: 7.054986476898193
Epoch: 47, Steps: 262 | Train Loss: 0.4451598 Vali Loss: 0.2765573 Test Loss: 0.3868481
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.4098236
	speed: 0.1122s/iter; left time: 1547.1692s
	iters: 200, epoch: 48 | loss: 0.5909082
	speed: 0.0435s/iter; left time: 594.7630s
Epoch: 48 cost time: 9.682834386825562
Epoch: 48, Steps: 262 | Train Loss: 0.4456483 Vali Loss: 0.2767254 Test Loss: 0.3868368
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.3479202
	speed: 0.1623s/iter; left time: 2194.9931s
	iters: 200, epoch: 49 | loss: 0.2478254
	speed: 0.0448s/iter; left time: 601.9010s
Epoch: 49 cost time: 14.15391492843628
Epoch: 49, Steps: 262 | Train Loss: 0.4449614 Vali Loss: 0.2765144 Test Loss: 0.3868394
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.3140797
	speed: 0.2468s/iter; left time: 3272.9288s
	iters: 200, epoch: 50 | loss: 0.4390147
	speed: 0.0460s/iter; left time: 605.3852s
Epoch: 50 cost time: 15.019754409790039
Epoch: 50, Steps: 262 | Train Loss: 0.4458187 Vali Loss: 0.2767197 Test Loss: 0.3868357
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.3048199
	speed: 0.2158s/iter; left time: 2805.5905s
	iters: 200, epoch: 51 | loss: 0.4660060
	speed: 0.0395s/iter; left time: 509.5222s
Epoch: 51 cost time: 11.618669033050537
Epoch: 51, Steps: 262 | Train Loss: 0.4458609 Vali Loss: 0.2766598 Test Loss: 0.3868328
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.4069298
	speed: 0.1870s/iter; left time: 2382.3096s
	iters: 200, epoch: 52 | loss: 0.4344544
	speed: 0.0567s/iter; left time: 717.0008s
Epoch: 52 cost time: 14.586713314056396
Epoch: 52, Steps: 262 | Train Loss: 0.4453769 Vali Loss: 0.2765277 Test Loss: 0.3868325
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.3473922
	speed: 0.1920s/iter; left time: 2395.1196s
	iters: 200, epoch: 53 | loss: 0.4661503
	speed: 0.0413s/iter; left time: 511.1692s
Epoch: 53 cost time: 12.081820726394653
Epoch: 53, Steps: 262 | Train Loss: 0.4456720 Vali Loss: 0.2764226 Test Loss: 0.3868284
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.4502926
	speed: 0.1575s/iter; left time: 1923.5959s
	iters: 200, epoch: 54 | loss: 0.4174937
	speed: 0.0350s/iter; left time: 424.2073s
Epoch: 54 cost time: 9.784590005874634
Epoch: 54, Steps: 262 | Train Loss: 0.4452809 Vali Loss: 0.2766627 Test Loss: 0.3868260
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.4003409
	speed: 0.2034s/iter; left time: 2430.7006s
	iters: 200, epoch: 55 | loss: 0.5740983
	speed: 0.0349s/iter; left time: 413.4914s
Epoch: 55 cost time: 12.861288070678711
Epoch: 55, Steps: 262 | Train Loss: 0.4454445 Vali Loss: 0.2768536 Test Loss: 0.3868221
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.4151723
	speed: 0.1666s/iter; left time: 1947.7948s
	iters: 200, epoch: 56 | loss: 0.3216107
	speed: 0.0291s/iter; left time: 336.9485s
Epoch: 56 cost time: 11.356054782867432
Epoch: 56, Steps: 262 | Train Loss: 0.4458212 Vali Loss: 0.2764780 Test Loss: 0.3868240
EarlyStopping counter: 20 out of 20
Early stopping
train 33661
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=38, out_features=190, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6469120.0
params:  7410.0
Trainable parameters:  7410
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4434227
	speed: 0.0526s/iter; left time: 1372.3184s
	iters: 200, epoch: 1 | loss: 0.4583427
	speed: 0.0421s/iter; left time: 1095.3877s
Epoch: 1 cost time: 12.621114253997803
Epoch: 1, Steps: 262 | Train Loss: 0.5538114 Vali Loss: 0.2764295 Test Loss: 0.3865198
Validation loss decreased (inf --> 0.276430).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.7879310
	speed: 0.2380s/iter; left time: 6149.9695s
	iters: 200, epoch: 2 | loss: 0.5169340
	speed: 0.0547s/iter; left time: 1407.8229s
Epoch: 2 cost time: 14.033241748809814
Epoch: 2, Steps: 262 | Train Loss: 0.5540551 Vali Loss: 0.2764801 Test Loss: 0.3865373
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5333111
	speed: 0.2067s/iter; left time: 5286.9428s
	iters: 200, epoch: 3 | loss: 0.3731191
	speed: 0.0408s/iter; left time: 1039.8486s
Epoch: 3 cost time: 11.806605815887451
Epoch: 3, Steps: 262 | Train Loss: 0.5540140 Vali Loss: 0.2765364 Test Loss: 0.3864650
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.6622207
	speed: 0.2169s/iter; left time: 5490.1746s
	iters: 200, epoch: 4 | loss: 0.5323815
	speed: 0.0344s/iter; left time: 866.8049s
Epoch: 4 cost time: 11.702425479888916
Epoch: 4, Steps: 262 | Train Loss: 0.5540639 Vali Loss: 0.2762231 Test Loss: 0.3863175
Validation loss decreased (0.276430 --> 0.276223).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4974325
	speed: 0.1991s/iter; left time: 4989.1853s
	iters: 200, epoch: 5 | loss: 0.6110725
	speed: 0.0467s/iter; left time: 1165.6524s
Epoch: 5 cost time: 13.745138168334961
Epoch: 5, Steps: 262 | Train Loss: 0.5535307 Vali Loss: 0.2762110 Test Loss: 0.3863313
Validation loss decreased (0.276223 --> 0.276211).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4269883
	speed: 0.2322s/iter; left time: 5756.0863s
	iters: 200, epoch: 6 | loss: 0.4506567
	speed: 0.0237s/iter; left time: 584.5720s
Epoch: 6 cost time: 10.323768854141235
Epoch: 6, Steps: 262 | Train Loss: 0.5537240 Vali Loss: 0.2764784 Test Loss: 0.3863353
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4866235
	speed: 0.2342s/iter; left time: 5744.1869s
	iters: 200, epoch: 7 | loss: 0.4839014
	speed: 0.0237s/iter; left time: 579.2924s
Epoch: 7 cost time: 8.902682542800903
Epoch: 7, Steps: 262 | Train Loss: 0.5539192 Vali Loss: 0.2764167 Test Loss: 0.3862790
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.6359898
	speed: 0.1597s/iter; left time: 3876.1759s
	iters: 200, epoch: 8 | loss: 0.8189232
	speed: 0.0310s/iter; left time: 749.4141s
Epoch: 8 cost time: 8.179799556732178
Epoch: 8, Steps: 262 | Train Loss: 0.5541303 Vali Loss: 0.2762631 Test Loss: 0.3863577
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.5726335
	speed: 0.2045s/iter; left time: 4908.3270s
	iters: 200, epoch: 9 | loss: 0.4680426
	speed: 0.0592s/iter; left time: 1416.1544s
Epoch: 9 cost time: 14.768514633178711
Epoch: 9, Steps: 262 | Train Loss: 0.5525176 Vali Loss: 0.2767417 Test Loss: 0.3863211
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.7771256
	speed: 0.2391s/iter; left time: 5676.6242s
	iters: 200, epoch: 10 | loss: 0.6702100
	speed: 0.0524s/iter; left time: 1237.8603s
Epoch: 10 cost time: 14.300015926361084
Epoch: 10, Steps: 262 | Train Loss: 0.5534001 Vali Loss: 0.2764283 Test Loss: 0.3863058
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.6425170
	speed: 0.2355s/iter; left time: 5530.1735s
	iters: 200, epoch: 11 | loss: 0.7860032
	speed: 0.0318s/iter; left time: 742.6451s
Epoch: 11 cost time: 10.0110502243042
Epoch: 11, Steps: 262 | Train Loss: 0.5537199 Vali Loss: 0.2762993 Test Loss: 0.3862860
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.5205499
	speed: 0.1401s/iter; left time: 3252.5976s
	iters: 200, epoch: 12 | loss: 0.6018770
	speed: 0.0468s/iter; left time: 1082.2685s
Epoch: 12 cost time: 10.424124240875244
Epoch: 12, Steps: 262 | Train Loss: 0.5534764 Vali Loss: 0.2764152 Test Loss: 0.3863145
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.7027146
	speed: 0.1451s/iter; left time: 3332.1143s
	iters: 200, epoch: 13 | loss: 0.5951886
	speed: 0.0343s/iter; left time: 784.3021s
Epoch: 13 cost time: 11.245129108428955
Epoch: 13, Steps: 262 | Train Loss: 0.5536561 Vali Loss: 0.2762334 Test Loss: 0.3862386
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.5252609
	speed: 0.2049s/iter; left time: 4651.0127s
	iters: 200, epoch: 14 | loss: 0.5834901
	speed: 0.0452s/iter; left time: 1021.6173s
Epoch: 14 cost time: 12.029689311981201
Epoch: 14, Steps: 262 | Train Loss: 0.5537575 Vali Loss: 0.2764837 Test Loss: 0.3862929
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.5075040
	speed: 0.1987s/iter; left time: 4458.1253s
	iters: 200, epoch: 15 | loss: 0.8978384
	speed: 0.0508s/iter; left time: 1135.2599s
Epoch: 15 cost time: 10.397706747055054
Epoch: 15, Steps: 262 | Train Loss: 0.5533503 Vali Loss: 0.2762218 Test Loss: 0.3862170
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4958385
	speed: 0.1424s/iter; left time: 3156.5577s
	iters: 200, epoch: 16 | loss: 0.6267464
	speed: 0.0275s/iter; left time: 607.0612s
Epoch: 16 cost time: 7.207874536514282
Epoch: 16, Steps: 262 | Train Loss: 0.5535086 Vali Loss: 0.2764785 Test Loss: 0.3862442
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.6686726
	speed: 0.1638s/iter; left time: 3588.0984s
	iters: 200, epoch: 17 | loss: 0.5943689
	speed: 0.0422s/iter; left time: 921.0946s
Epoch: 17 cost time: 11.345887422561646
Epoch: 17, Steps: 262 | Train Loss: 0.5536355 Vali Loss: 0.2763828 Test Loss: 0.3862330
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4802453
	speed: 0.2060s/iter; left time: 4458.6278s
	iters: 200, epoch: 18 | loss: 0.3571450
	speed: 0.0652s/iter; left time: 1404.5578s
Epoch: 18 cost time: 16.805068731307983
Epoch: 18, Steps: 262 | Train Loss: 0.5531743 Vali Loss: 0.2763808 Test Loss: 0.3862474
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4840281
	speed: 0.2057s/iter; left time: 4398.1637s
	iters: 200, epoch: 19 | loss: 0.4392003
	speed: 0.0448s/iter; left time: 953.1294s
Epoch: 19 cost time: 12.968472480773926
Epoch: 19, Steps: 262 | Train Loss: 0.5538177 Vali Loss: 0.2764334 Test Loss: 0.3862849
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4052488
	speed: 0.1668s/iter; left time: 3523.6905s
	iters: 200, epoch: 20 | loss: 0.6432120
	speed: 0.0268s/iter; left time: 562.4485s
Epoch: 20 cost time: 8.659043073654175
Epoch: 20, Steps: 262 | Train Loss: 0.5536036 Vali Loss: 0.2765499 Test Loss: 0.3862974
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.6272261
	speed: 0.1461s/iter; left time: 3048.4374s
	iters: 200, epoch: 21 | loss: 0.6274118
	speed: 0.0471s/iter; left time: 978.8143s
Epoch: 21 cost time: 11.561458349227905
Epoch: 21, Steps: 262 | Train Loss: 0.5533941 Vali Loss: 0.2763209 Test Loss: 0.3863042
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.5029560
	speed: 0.1520s/iter; left time: 3130.0509s
	iters: 200, epoch: 22 | loss: 0.5351503
	speed: 0.0265s/iter; left time: 543.0286s
Epoch: 22 cost time: 8.223485946655273
Epoch: 22, Steps: 262 | Train Loss: 0.5536695 Vali Loss: 0.2765253 Test Loss: 0.3862807
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.6505885
	speed: 0.1975s/iter; left time: 4016.6477s
	iters: 200, epoch: 23 | loss: 0.3847256
	speed: 0.0545s/iter; left time: 1102.1547s
Epoch: 23 cost time: 15.632079601287842
Epoch: 23, Steps: 262 | Train Loss: 0.5525891 Vali Loss: 0.2765542 Test Loss: 0.3862462
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.5143395
	speed: 0.2398s/iter; left time: 4814.5179s
	iters: 200, epoch: 24 | loss: 0.4925272
	speed: 0.0277s/iter; left time: 554.2324s
Epoch: 24 cost time: 10.971797704696655
Epoch: 24, Steps: 262 | Train Loss: 0.5531744 Vali Loss: 0.2761491 Test Loss: 0.3862379
Validation loss decreased (0.276211 --> 0.276149).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.5700121
	speed: 0.2127s/iter; left time: 4213.6330s
	iters: 200, epoch: 25 | loss: 0.6738299
	speed: 0.0325s/iter; left time: 640.9681s
Epoch: 25 cost time: 10.195189714431763
Epoch: 25, Steps: 262 | Train Loss: 0.5533644 Vali Loss: 0.2762571 Test Loss: 0.3862628
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.6306973
	speed: 0.2133s/iter; left time: 4170.4354s
	iters: 200, epoch: 26 | loss: 0.5185691
	speed: 0.0478s/iter; left time: 929.2809s
Epoch: 26 cost time: 14.467962980270386
Epoch: 26, Steps: 262 | Train Loss: 0.5536639 Vali Loss: 0.2763006 Test Loss: 0.3863000
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.7500795
	speed: 0.1847s/iter; left time: 3563.3504s
	iters: 200, epoch: 27 | loss: 0.6186346
	speed: 0.0401s/iter; left time: 769.9332s
Epoch: 27 cost time: 10.637431383132935
Epoch: 27, Steps: 262 | Train Loss: 0.5532500 Vali Loss: 0.2766022 Test Loss: 0.3862722
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.5749131
	speed: 0.2220s/iter; left time: 4223.7404s
	iters: 200, epoch: 28 | loss: 0.5628895
	speed: 0.0298s/iter; left time: 564.3572s
Epoch: 28 cost time: 11.491145133972168
Epoch: 28, Steps: 262 | Train Loss: 0.5524077 Vali Loss: 0.2762508 Test Loss: 0.3862870
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.5158463
	speed: 0.2167s/iter; left time: 4066.2503s
	iters: 200, epoch: 29 | loss: 0.4776325
	speed: 0.0739s/iter; left time: 1379.8917s
Epoch: 29 cost time: 16.933906078338623
Epoch: 29, Steps: 262 | Train Loss: 0.5534162 Vali Loss: 0.2764382 Test Loss: 0.3862728
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4277812
	speed: 0.2279s/iter; left time: 4216.6135s
	iters: 200, epoch: 30 | loss: 0.3809460
	speed: 0.0623s/iter; left time: 1145.6939s
Epoch: 30 cost time: 15.037101030349731
Epoch: 30, Steps: 262 | Train Loss: 0.5522837 Vali Loss: 0.2765796 Test Loss: 0.3862598
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.6161325
	speed: 0.1851s/iter; left time: 3377.2787s
	iters: 200, epoch: 31 | loss: 0.5576997
	speed: 0.0349s/iter; left time: 633.5480s
Epoch: 31 cost time: 9.336321353912354
Epoch: 31, Steps: 262 | Train Loss: 0.5532072 Vali Loss: 0.2765409 Test Loss: 0.3862625
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.6495481
	speed: 0.1683s/iter; left time: 3025.0465s
	iters: 200, epoch: 32 | loss: 0.4201554
	speed: 0.0253s/iter; left time: 451.8402s
Epoch: 32 cost time: 10.299522876739502
Epoch: 32, Steps: 262 | Train Loss: 0.5537487 Vali Loss: 0.2764617 Test Loss: 0.3862512
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.5094349
	speed: 0.2106s/iter; left time: 3731.2794s
	iters: 200, epoch: 33 | loss: 0.4148074
	speed: 0.0489s/iter; left time: 861.2900s
Epoch: 33 cost time: 14.022176742553711
Epoch: 33, Steps: 262 | Train Loss: 0.5537206 Vali Loss: 0.2764930 Test Loss: 0.3862522
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.6976008
	speed: 0.2351s/iter; left time: 4104.5242s
	iters: 200, epoch: 34 | loss: 0.4952102
	speed: 0.0465s/iter; left time: 806.8770s
Epoch: 34 cost time: 13.792117357254028
Epoch: 34, Steps: 262 | Train Loss: 0.5535003 Vali Loss: 0.2763554 Test Loss: 0.3862548
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.5540562
	speed: 0.1678s/iter; left time: 2885.3865s
	iters: 200, epoch: 35 | loss: 0.7291932
	speed: 0.0332s/iter; left time: 567.0941s
Epoch: 35 cost time: 10.103683948516846
Epoch: 35, Steps: 262 | Train Loss: 0.5530898 Vali Loss: 0.2764310 Test Loss: 0.3862724
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4539782
	speed: 0.1944s/iter; left time: 3291.8993s
	iters: 200, epoch: 36 | loss: 0.7437661
	speed: 0.0720s/iter; left time: 1211.5821s
Epoch: 36 cost time: 15.898119926452637
Epoch: 36, Steps: 262 | Train Loss: 0.5528234 Vali Loss: 0.2762986 Test Loss: 0.3862582
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.5321050
	speed: 0.2187s/iter; left time: 3645.6398s
	iters: 200, epoch: 37 | loss: 0.4726786
	speed: 0.0338s/iter; left time: 560.5567s
Epoch: 37 cost time: 12.297760486602783
Epoch: 37, Steps: 262 | Train Loss: 0.5535440 Vali Loss: 0.2765558 Test Loss: 0.3862748
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.5084429
	speed: 0.2283s/iter; left time: 3746.3274s
	iters: 200, epoch: 38 | loss: 0.7005432
	speed: 0.0327s/iter; left time: 532.7166s
Epoch: 38 cost time: 11.977503776550293
Epoch: 38, Steps: 262 | Train Loss: 0.5536732 Vali Loss: 0.2764894 Test Loss: 0.3862674
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.5140108
	speed: 0.1656s/iter; left time: 2673.4782s
	iters: 200, epoch: 39 | loss: 0.7814236
	speed: 0.0232s/iter; left time: 372.4777s
Epoch: 39 cost time: 9.131716966629028
Epoch: 39, Steps: 262 | Train Loss: 0.5532841 Vali Loss: 0.2765310 Test Loss: 0.3862643
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.4230146
	speed: 0.2278s/iter; left time: 3618.7774s
	iters: 200, epoch: 40 | loss: 0.5607377
	speed: 0.0475s/iter; left time: 749.6608s
Epoch: 40 cost time: 13.43506145477295
Epoch: 40, Steps: 262 | Train Loss: 0.5534579 Vali Loss: 0.2763765 Test Loss: 0.3862651
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3572340
	speed: 0.2394s/iter; left time: 3739.7730s
	iters: 200, epoch: 41 | loss: 0.6621954
	speed: 0.0422s/iter; left time: 654.8860s
Epoch: 41 cost time: 13.696282863616943
Epoch: 41, Steps: 262 | Train Loss: 0.5533658 Vali Loss: 0.2763941 Test Loss: 0.3862703
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.7477731
	speed: 0.1678s/iter; left time: 2577.4353s
	iters: 200, epoch: 42 | loss: 0.6005681
	speed: 0.0340s/iter; left time: 519.2071s
Epoch: 42 cost time: 9.767812490463257
Epoch: 42, Steps: 262 | Train Loss: 0.5535744 Vali Loss: 0.2762958 Test Loss: 0.3862540
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.6089628
	speed: 0.1570s/iter; left time: 2369.7812s
	iters: 200, epoch: 43 | loss: 0.8289358
	speed: 0.0226s/iter; left time: 339.3525s
Epoch: 43 cost time: 7.021136045455933
Epoch: 43, Steps: 262 | Train Loss: 0.5529002 Vali Loss: 0.2764230 Test Loss: 0.3862572
EarlyStopping counter: 19 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.4212117
	speed: 0.1242s/iter; left time: 1842.5132s
	iters: 200, epoch: 44 | loss: 0.6280540
	speed: 0.0320s/iter; left time: 471.8691s
Epoch: 44 cost time: 7.630957365036011
Epoch: 44, Steps: 262 | Train Loss: 0.5527645 Vali Loss: 0.2764287 Test Loss: 0.3862564
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_180_720_FITS_ETTm2_ftM_sl180_ll48_pl720_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.38362032175064087, mae:0.38752081990242004, rse:0.49784621596336365, corr:[0.55140233 0.54783285 0.5430284  0.5418521  0.5415692  0.539804
 0.5380133  0.53734124 0.53705144 0.5360874  0.53473455 0.5340374
 0.5339349  0.53353304 0.5326442  0.53178334 0.5312891  0.53075975
 0.5297374  0.5285242  0.527719   0.52728105 0.52673703 0.52595824
 0.52526796 0.52495843 0.524837   0.52440697 0.5235977  0.5227516
 0.522125   0.5215657  0.52080536 0.52005136 0.51964664 0.5195346
 0.5191898  0.5184867  0.51758045 0.5167904  0.5162167  0.51574504
 0.51534945 0.51507664 0.5148392  0.51445746 0.51377404 0.5129067
 0.5120307  0.5111934  0.5102955  0.5093881  0.50857717 0.5079516
 0.5074598  0.50691855 0.50616753 0.5055791  0.5053191  0.50525934
 0.50502545 0.50463474 0.5043574  0.5041943  0.50409263 0.50393194
 0.5036278  0.5034076  0.5033437  0.5033497  0.50322384 0.50301397
 0.50289446 0.50280786 0.5027041  0.50242025 0.5020549  0.5017017
 0.50141823 0.50108635 0.5006038  0.50004405 0.4995666  0.4991691
 0.49879146 0.49839243 0.49795294 0.49756992 0.49719238 0.49679023
 0.4964227  0.49610555 0.49575096 0.49518573 0.49421465 0.492724
 0.49081698 0.48887485 0.48700413 0.48521385 0.48358482 0.48219076
 0.48099917 0.47984478 0.47850913 0.4770539  0.47572532 0.47467
 0.47369915 0.47246557 0.471215   0.47007075 0.4690692  0.46804523
 0.46678248 0.46541643 0.4641294  0.46304217 0.46216065 0.46122217
 0.46017647 0.459086   0.45804065 0.45711628 0.45628345 0.45542705
 0.4544889  0.4534482  0.45238718 0.45134532 0.4504091  0.449541
 0.44874236 0.44790012 0.44717246 0.4465861  0.4460178  0.44550738
 0.4450531  0.44463325 0.44412303 0.44345996 0.44273135 0.4419541
 0.44110128 0.4401292  0.43900013 0.43794498 0.43718803 0.4365903
 0.43600565 0.43547475 0.43486077 0.43427044 0.4337969  0.43331867
 0.43280604 0.43231845 0.4318326  0.431433   0.43111396 0.43078578
 0.4305056  0.43015116 0.42999518 0.42994273 0.42990592 0.42997986
 0.43015116 0.43037164 0.4304802  0.43047082 0.43049    0.43049052
 0.4305041  0.4304191  0.43026507 0.43003857 0.4298059  0.42956728
 0.4292523  0.42893144 0.42881405 0.42879802 0.42870298 0.42836148
 0.427945   0.427687   0.42753235 0.42710957 0.42607626 0.42441154
 0.4224917  0.4208327  0.4193503  0.41789877 0.4166054  0.41546088
 0.4143706  0.4131794  0.41181487 0.41055992 0.40952605 0.40887654
 0.40840784 0.4078526  0.40708086 0.40616983 0.40525225 0.40436977
 0.40351105 0.4026661  0.40180698 0.4009097  0.40003967 0.3991855
 0.39837027 0.39743945 0.3965851  0.39570636 0.3947137  0.39368773
 0.39252907 0.3913712  0.39045623 0.3896353  0.38886264 0.38801596
 0.3869858  0.3858725  0.38484424 0.38402563 0.38331667 0.3827398
 0.3822092  0.3817911  0.38153338 0.38111866 0.38067585 0.38021797
 0.37977043 0.37922204 0.3785379  0.37800804 0.37768206 0.37757295
 0.37761772 0.3777369  0.37795436 0.3781565  0.37835684 0.37850192
 0.3785296  0.3786555  0.37882602 0.37890917 0.37884957 0.3787972
 0.37880364 0.37879065 0.37873966 0.37869993 0.3785944  0.37837097
 0.37819606 0.37813476 0.37811786 0.3780724  0.37809116 0.3782128
 0.37824485 0.37809435 0.3776845  0.37727565 0.37702343 0.37696788
 0.37696078 0.3768716  0.3767465  0.37660483 0.37633765 0.37617424
 0.376184   0.3762511  0.37624753 0.37602538 0.37545687 0.37445456
 0.37308437 0.37177727 0.3705654  0.36964306 0.36901984 0.3685627
 0.3681781  0.36759833 0.36682457 0.36601096 0.3653734  0.36488262
 0.3644837  0.363952   0.363403   0.3628008  0.36205685 0.36113814
 0.36021304 0.3594095  0.35867774 0.35795763 0.35714784 0.35627407
 0.35537174 0.35463393 0.3539887  0.35336494 0.3525129  0.35152143
 0.35056788 0.3497631  0.34909678 0.3484677  0.34781134 0.34706673
 0.3462641  0.34541297 0.34464857 0.3440894  0.34375843 0.34363136
 0.3435865  0.34332606 0.34282023 0.3420966  0.34133673 0.34080213
 0.34042683 0.340089   0.33962935 0.33916193 0.33861384 0.33814278
 0.3379308  0.3380073  0.33812502 0.33818796 0.33806407 0.33792216
 0.3377437  0.33753303 0.33731043 0.33716032 0.33715168 0.337251
 0.33732417 0.33736378 0.33730364 0.33720744 0.33702025 0.33677763
 0.3366505  0.33673832 0.33692572 0.3370597  0.33705592 0.337163
 0.3374118  0.3376965  0.33775795 0.3374938  0.33734396 0.33746517
 0.33789787 0.33840287 0.33865288 0.33857808 0.33836907 0.3382659
 0.33840492 0.33864948 0.3388227  0.33871135 0.3381824  0.33714652
 0.33580756 0.33455113 0.33357716 0.33276796 0.33183166 0.3308539
 0.32993075 0.3290632  0.32814455 0.32712543 0.32610506 0.32540402
 0.32503945 0.32464585 0.32404575 0.32334298 0.32262668 0.32181588
 0.32090107 0.3198379  0.31888574 0.3182208  0.31767315 0.31694824
 0.316055   0.31520554 0.31457102 0.31404448 0.31340975 0.3126526
 0.31194913 0.31144932 0.311084   0.31066924 0.31001464 0.30938447
 0.30893874 0.30859482 0.3082571  0.3080179  0.30784053 0.3078634
 0.30803433 0.3080247  0.30758187 0.3069707  0.3065326  0.30650666
 0.30647874 0.3060707  0.30508673 0.30407175 0.30349588 0.3034188
 0.30357233 0.30347094 0.3030074  0.30238193 0.30191323 0.30182642
 0.30186003 0.30182302 0.30179524 0.30183703 0.30195692 0.3020134
 0.30188122 0.30157548 0.30139297 0.30152252 0.30167612 0.30177432
 0.30170622 0.30153286 0.30128425 0.3011276  0.30127528 0.301646
 0.30193144 0.30191836 0.30161557 0.30129617 0.3011114  0.3010771
 0.3010219  0.30082452 0.3006886  0.3006314  0.30048844 0.30001995
 0.29924047 0.29863417 0.2984609  0.29826826 0.29738846 0.29567212
 0.2937026  0.29228458 0.29142004 0.29063693 0.28961787 0.28856215
 0.2878238  0.28728688 0.28662392 0.28579417 0.2851597  0.28501877
 0.28523082 0.28531894 0.28501657 0.2844276  0.2837718  0.2830715
 0.28224885 0.28119433 0.27998403 0.27886724 0.27791783 0.2771342
 0.2764452  0.27590144 0.27543476 0.27481565 0.27396774 0.27300596
 0.2721159  0.27144724 0.270932   0.27038586 0.269735   0.26905593
 0.26840898 0.26782405 0.26733014 0.26691946 0.26664174 0.26643553
 0.26616028 0.2658676  0.26558137 0.26528218 0.2650508  0.2645869
 0.26383123 0.26284075 0.26186678 0.26114613 0.26069832 0.26019052
 0.259566   0.2590823  0.2590378  0.25928664 0.2595328  0.259407
 0.25918156 0.2592019  0.25939834 0.25945878 0.25909165 0.25842085
 0.2578291  0.25762644 0.25765648 0.25760895 0.25736773 0.2572496
 0.25734603 0.25744694 0.25726864 0.2568308  0.25653586 0.2566514
 0.25684634 0.2569164  0.25684783 0.25688684 0.2571058  0.25721484
 0.25695848 0.25662333 0.2566205  0.25693294 0.2571339  0.2568514
 0.25633025 0.2560115  0.25602263 0.2558172  0.25482714 0.25294003
 0.25079107 0.24912092 0.24785227 0.24669753 0.24561742 0.24479035
 0.244145   0.24347961 0.24252231 0.24131547 0.24022213 0.23950979
 0.23904784 0.23862778 0.23830836 0.2380289  0.2375252  0.23662572
 0.23541704 0.2342594  0.23344532 0.23287034 0.232342   0.23162262
 0.2308384  0.23032959 0.2300517  0.22965582 0.22897156 0.227953
 0.22688892 0.22634904 0.22633512 0.22629862 0.22592694 0.22517551
 0.22452997 0.22415553 0.22393219 0.22358687 0.2230837  0.22273594
 0.22266805 0.22292876 0.2230331  0.22297548 0.22268732 0.2221231
 0.22148463 0.22094563 0.22069608 0.22066335 0.22056654 0.22025079
 0.22003986 0.2204018  0.221105   0.22164887 0.22177957 0.22143804
 0.22124608 0.22142856 0.2216898  0.22167875 0.22138555 0.22100107
 0.2208377  0.22087148 0.22091915 0.22077666 0.22058946 0.220531
 0.22052781 0.2206287  0.2207223  0.22102772 0.22146532 0.22177938
 0.22200607 0.22218235 0.222412   0.2227673  0.2230722  0.22323622
 0.22358319 0.22419849 0.22493246 0.22550511 0.22585149 0.22614044
 0.22642078 0.22652301 0.22618936 0.22542138 0.22436306 0.22304124
 0.22140546 0.2196016  0.21801594 0.21709697 0.2168631  0.21678911
 0.21627893 0.21536306 0.21452627 0.21405299 0.21378718 0.21348293
 0.21318476 0.21290933 0.21270679 0.212305   0.21153988 0.21054366
 0.20975004 0.20922671 0.20852645 0.20729208 0.20580877 0.20466247
 0.20416671 0.20380895 0.20296237 0.20163281 0.20026967 0.19920416
 0.19802213 0.19639795 0.19464521 0.19371662 0.19367263 0.19358255
 0.19253431 0.19105102 0.19021206 0.19022378 0.18986648 0.18884332
 0.18820508 0.18904354 0.19004032 0.18924083 0.18887782 0.19581987]
