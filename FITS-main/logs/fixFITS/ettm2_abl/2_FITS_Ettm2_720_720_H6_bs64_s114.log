Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=58, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_720_720_FITS_ETTm2_ftM_sl720_ll48_pl720_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=58, out_features=116, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6028288.0
params:  6844.0
Trainable parameters:  6844
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4612929
	speed: 0.0279s/iter; left time: 717.1981s
	iters: 200, epoch: 1 | loss: 0.3006701
	speed: 0.0224s/iter; left time: 574.6427s
Epoch: 1 cost time: 6.244541168212891
Epoch: 1, Steps: 258 | Train Loss: 0.4523825 Vali Loss: 0.3016296 Test Loss: 0.4008217
Validation loss decreased (inf --> 0.301630).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3380256
	speed: 0.0897s/iter; left time: 2283.1179s
	iters: 200, epoch: 2 | loss: 0.3863722
	speed: 0.0220s/iter; left time: 556.5814s
Epoch: 2 cost time: 6.158598184585571
Epoch: 2, Steps: 258 | Train Loss: 0.3299793 Vali Loss: 0.2835619 Test Loss: 0.3784410
Validation loss decreased (0.301630 --> 0.283562).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2646056
	speed: 0.0909s/iter; left time: 2289.3403s
	iters: 200, epoch: 3 | loss: 0.2463864
	speed: 0.0215s/iter; left time: 539.7704s
Epoch: 3 cost time: 6.1844260692596436
Epoch: 3, Steps: 258 | Train Loss: 0.2969379 Vali Loss: 0.2772181 Test Loss: 0.3700478
Validation loss decreased (0.283562 --> 0.277218).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2534938
	speed: 0.0908s/iter; left time: 2262.9814s
	iters: 200, epoch: 4 | loss: 0.2635144
	speed: 0.0210s/iter; left time: 520.1451s
Epoch: 4 cost time: 6.175931930541992
Epoch: 4, Steps: 258 | Train Loss: 0.2812827 Vali Loss: 0.2730573 Test Loss: 0.3649787
Validation loss decreased (0.277218 --> 0.273057).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2407985
	speed: 0.0916s/iter; left time: 2259.9813s
	iters: 200, epoch: 5 | loss: 0.2335362
	speed: 0.0219s/iter; left time: 537.0785s
Epoch: 5 cost time: 6.233543157577515
Epoch: 5, Steps: 258 | Train Loss: 0.2729873 Vali Loss: 0.2699237 Test Loss: 0.3619837
Validation loss decreased (0.273057 --> 0.269924).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2925375
	speed: 0.0893s/iter; left time: 2180.5589s
	iters: 200, epoch: 6 | loss: 0.2588676
	speed: 0.0217s/iter; left time: 526.4184s
Epoch: 6 cost time: 6.110351800918579
Epoch: 6, Steps: 258 | Train Loss: 0.2685016 Vali Loss: 0.2686343 Test Loss: 0.3594228
Validation loss decreased (0.269924 --> 0.268634).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2102533
	speed: 0.0920s/iter; left time: 2221.5237s
	iters: 200, epoch: 7 | loss: 0.2864002
	speed: 0.0217s/iter; left time: 521.8803s
Epoch: 7 cost time: 6.166955471038818
Epoch: 7, Steps: 258 | Train Loss: 0.2657976 Vali Loss: 0.2671157 Test Loss: 0.3582327
Validation loss decreased (0.268634 --> 0.267116).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2795492
	speed: 0.0900s/iter; left time: 2151.6994s
	iters: 200, epoch: 8 | loss: 0.3305283
	speed: 0.0213s/iter; left time: 505.7920s
Epoch: 8 cost time: 6.13680100440979
Epoch: 8, Steps: 258 | Train Loss: 0.2644511 Vali Loss: 0.2664986 Test Loss: 0.3573493
Validation loss decreased (0.267116 --> 0.266499).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2394210
	speed: 0.0907s/iter; left time: 2142.7532s
	iters: 200, epoch: 9 | loss: 0.2598177
	speed: 0.0222s/iter; left time: 522.0607s
Epoch: 9 cost time: 6.27126145362854
Epoch: 9, Steps: 258 | Train Loss: 0.2634691 Vali Loss: 0.2659499 Test Loss: 0.3567143
Validation loss decreased (0.266499 --> 0.265950).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2301496
	speed: 0.0926s/iter; left time: 2163.9291s
	iters: 200, epoch: 10 | loss: 0.1826696
	speed: 0.0221s/iter; left time: 514.2380s
Epoch: 10 cost time: 6.322900056838989
Epoch: 10, Steps: 258 | Train Loss: 0.2630956 Vali Loss: 0.2655930 Test Loss: 0.3562289
Validation loss decreased (0.265950 --> 0.265593).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2716322
	speed: 0.0931s/iter; left time: 2152.6344s
	iters: 200, epoch: 11 | loss: 0.2226534
	speed: 0.0215s/iter; left time: 494.6342s
Epoch: 11 cost time: 6.2465996742248535
Epoch: 11, Steps: 258 | Train Loss: 0.2630886 Vali Loss: 0.2657074 Test Loss: 0.3559604
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2224482
	speed: 0.0927s/iter; left time: 2120.4387s
	iters: 200, epoch: 12 | loss: 0.2483998
	speed: 0.0216s/iter; left time: 492.0507s
Epoch: 12 cost time: 6.176556348800659
Epoch: 12, Steps: 258 | Train Loss: 0.2624471 Vali Loss: 0.2655140 Test Loss: 0.3558789
Validation loss decreased (0.265593 --> 0.265514).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2609599
	speed: 0.0931s/iter; left time: 2103.4169s
	iters: 200, epoch: 13 | loss: 0.2275119
	speed: 0.0221s/iter; left time: 496.6883s
Epoch: 13 cost time: 6.274758815765381
Epoch: 13, Steps: 258 | Train Loss: 0.2625639 Vali Loss: 0.2654759 Test Loss: 0.3556168
Validation loss decreased (0.265514 --> 0.265476).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3160820
	speed: 0.0910s/iter; left time: 2033.6299s
	iters: 200, epoch: 14 | loss: 0.2942273
	speed: 0.0214s/iter; left time: 477.1504s
Epoch: 14 cost time: 5.995477676391602
Epoch: 14, Steps: 258 | Train Loss: 0.2622321 Vali Loss: 0.2652044 Test Loss: 0.3556218
Validation loss decreased (0.265476 --> 0.265204).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2466436
	speed: 0.0890s/iter; left time: 1965.6786s
	iters: 200, epoch: 15 | loss: 0.2421392
	speed: 0.0215s/iter; left time: 473.1815s
Epoch: 15 cost time: 6.127614736557007
Epoch: 15, Steps: 258 | Train Loss: 0.2620826 Vali Loss: 0.2649097 Test Loss: 0.3556109
Validation loss decreased (0.265204 --> 0.264910).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2194650
	speed: 0.0929s/iter; left time: 2028.7426s
	iters: 200, epoch: 16 | loss: 0.2586221
	speed: 0.0212s/iter; left time: 461.3529s
Epoch: 16 cost time: 6.517057418823242
Epoch: 16, Steps: 258 | Train Loss: 0.2623477 Vali Loss: 0.2652892 Test Loss: 0.3552409
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3015334
	speed: 0.0965s/iter; left time: 2081.9560s
	iters: 200, epoch: 17 | loss: 0.1909721
	speed: 0.0214s/iter; left time: 460.2551s
Epoch: 17 cost time: 6.246716260910034
Epoch: 17, Steps: 258 | Train Loss: 0.2621297 Vali Loss: 0.2650152 Test Loss: 0.3554187
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3153991
	speed: 0.0961s/iter; left time: 2048.1027s
	iters: 200, epoch: 18 | loss: 0.2408956
	speed: 0.0217s/iter; left time: 459.8727s
Epoch: 18 cost time: 6.240240097045898
Epoch: 18, Steps: 258 | Train Loss: 0.2619040 Vali Loss: 0.2646700 Test Loss: 0.3553838
Validation loss decreased (0.264910 --> 0.264670).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2453579
	speed: 0.0930s/iter; left time: 1957.8409s
	iters: 200, epoch: 19 | loss: 0.2216045
	speed: 0.0228s/iter; left time: 478.8283s
Epoch: 19 cost time: 6.305023908615112
Epoch: 19, Steps: 258 | Train Loss: 0.2619220 Vali Loss: 0.2648943 Test Loss: 0.3552567
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1911321
	speed: 0.0905s/iter; left time: 1881.5137s
	iters: 200, epoch: 20 | loss: 0.1827685
	speed: 0.0220s/iter; left time: 455.1227s
Epoch: 20 cost time: 6.255244255065918
Epoch: 20, Steps: 258 | Train Loss: 0.2622728 Vali Loss: 0.2650884 Test Loss: 0.3551471
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2955697
	speed: 0.0916s/iter; left time: 1882.1297s
	iters: 200, epoch: 21 | loss: 0.3083211
	speed: 0.0216s/iter; left time: 440.5694s
Epoch: 21 cost time: 6.439126014709473
Epoch: 21, Steps: 258 | Train Loss: 0.2623918 Vali Loss: 0.2649166 Test Loss: 0.3551911
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2785211
	speed: 0.0947s/iter; left time: 1921.0460s
	iters: 200, epoch: 22 | loss: 0.2638469
	speed: 0.0215s/iter; left time: 433.1103s
Epoch: 22 cost time: 6.104522943496704
Epoch: 22, Steps: 258 | Train Loss: 0.2622231 Vali Loss: 0.2652219 Test Loss: 0.3550775
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2268557
	speed: 0.0924s/iter; left time: 1849.4696s
	iters: 200, epoch: 23 | loss: 0.3057908
	speed: 0.0218s/iter; left time: 434.7261s
Epoch: 23 cost time: 6.229816198348999
Epoch: 23, Steps: 258 | Train Loss: 0.2619108 Vali Loss: 0.2647626 Test Loss: 0.3552070
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2080630
	speed: 0.0924s/iter; left time: 1826.4751s
	iters: 200, epoch: 24 | loss: 0.1772411
	speed: 0.0223s/iter; left time: 438.6737s
Epoch: 24 cost time: 6.20634651184082
Epoch: 24, Steps: 258 | Train Loss: 0.2620594 Vali Loss: 0.2649646 Test Loss: 0.3551480
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2505133
	speed: 0.0916s/iter; left time: 1786.2201s
	iters: 200, epoch: 25 | loss: 0.2165588
	speed: 0.0219s/iter; left time: 425.7942s
Epoch: 25 cost time: 6.140290021896362
Epoch: 25, Steps: 258 | Train Loss: 0.2622368 Vali Loss: 0.2651385 Test Loss: 0.3551330
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2863948
	speed: 0.0937s/iter; left time: 1803.3228s
	iters: 200, epoch: 26 | loss: 0.2915842
	speed: 0.0213s/iter; left time: 407.0671s
Epoch: 26 cost time: 6.203181743621826
Epoch: 26, Steps: 258 | Train Loss: 0.2618630 Vali Loss: 0.2648337 Test Loss: 0.3551456
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3070782
	speed: 0.0905s/iter; left time: 1719.1978s
	iters: 200, epoch: 27 | loss: 0.3350720
	speed: 0.0214s/iter; left time: 404.4645s
Epoch: 27 cost time: 6.1370298862457275
Epoch: 27, Steps: 258 | Train Loss: 0.2621375 Vali Loss: 0.2645020 Test Loss: 0.3551771
Validation loss decreased (0.264670 --> 0.264502).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3118290
	speed: 0.0926s/iter; left time: 1735.4781s
	iters: 200, epoch: 28 | loss: 0.2678499
	speed: 0.0220s/iter; left time: 409.3001s
Epoch: 28 cost time: 6.264371395111084
Epoch: 28, Steps: 258 | Train Loss: 0.2621569 Vali Loss: 0.2650354 Test Loss: 0.3551198
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4228013
	speed: 0.0945s/iter; left time: 1745.2049s
	iters: 200, epoch: 29 | loss: 0.3078174
	speed: 0.0218s/iter; left time: 401.2339s
Epoch: 29 cost time: 6.374871730804443
Epoch: 29, Steps: 258 | Train Loss: 0.2617568 Vali Loss: 0.2650042 Test Loss: 0.3550766
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2854892
	speed: 0.0953s/iter; left time: 1735.4420s
	iters: 200, epoch: 30 | loss: 0.2240400
	speed: 0.0214s/iter; left time: 388.5131s
Epoch: 30 cost time: 6.223275423049927
Epoch: 30, Steps: 258 | Train Loss: 0.2620546 Vali Loss: 0.2649596 Test Loss: 0.3550623
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2119743
	speed: 0.0938s/iter; left time: 1684.5582s
	iters: 200, epoch: 31 | loss: 0.2398221
	speed: 0.0215s/iter; left time: 384.0765s
Epoch: 31 cost time: 6.239396572113037
Epoch: 31, Steps: 258 | Train Loss: 0.2618215 Vali Loss: 0.2648453 Test Loss: 0.3550446
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2632951
	speed: 0.0926s/iter; left time: 1639.5576s
	iters: 200, epoch: 32 | loss: 0.2038415
	speed: 0.0213s/iter; left time: 375.6660s
Epoch: 32 cost time: 6.177511930465698
Epoch: 32, Steps: 258 | Train Loss: 0.2617291 Vali Loss: 0.2649557 Test Loss: 0.3550341
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2346868
	speed: 0.0929s/iter; left time: 1620.1329s
	iters: 200, epoch: 33 | loss: 0.3498424
	speed: 0.0214s/iter; left time: 371.4534s
Epoch: 33 cost time: 6.223551988601685
Epoch: 33, Steps: 258 | Train Loss: 0.2621046 Vali Loss: 0.2649643 Test Loss: 0.3550560
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2298009
	speed: 0.0893s/iter; left time: 1534.8551s
	iters: 200, epoch: 34 | loss: 0.2981219
	speed: 0.0216s/iter; left time: 368.4398s
Epoch: 34 cost time: 6.046570539474487
Epoch: 34, Steps: 258 | Train Loss: 0.2622584 Vali Loss: 0.2650524 Test Loss: 0.3550246
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2368434
	speed: 0.0892s/iter; left time: 1510.7534s
	iters: 200, epoch: 35 | loss: 0.2185082
	speed: 0.0212s/iter; left time: 356.6647s
Epoch: 35 cost time: 6.1443092823028564
Epoch: 35, Steps: 258 | Train Loss: 0.2617894 Vali Loss: 0.2648593 Test Loss: 0.3550400
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2456943
	speed: 0.0901s/iter; left time: 1501.3383s
	iters: 200, epoch: 36 | loss: 0.2013735
	speed: 0.0222s/iter; left time: 368.4783s
Epoch: 36 cost time: 6.208847999572754
Epoch: 36, Steps: 258 | Train Loss: 0.2619783 Vali Loss: 0.2649420 Test Loss: 0.3550238
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2663235
	speed: 0.0904s/iter; left time: 1483.7689s
	iters: 200, epoch: 37 | loss: 0.2385885
	speed: 0.0216s/iter; left time: 351.9108s
Epoch: 37 cost time: 6.244903564453125
Epoch: 37, Steps: 258 | Train Loss: 0.2620148 Vali Loss: 0.2650775 Test Loss: 0.3550362
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2290847
	speed: 0.0923s/iter; left time: 1491.8744s
	iters: 200, epoch: 38 | loss: 0.3077069
	speed: 0.0221s/iter; left time: 354.9334s
Epoch: 38 cost time: 6.218320369720459
Epoch: 38, Steps: 258 | Train Loss: 0.2616908 Vali Loss: 0.2649760 Test Loss: 0.3550059
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2216116
	speed: 0.0889s/iter; left time: 1412.5960s
	iters: 200, epoch: 39 | loss: 0.2108055
	speed: 0.0216s/iter; left time: 341.9155s
Epoch: 39 cost time: 6.043859958648682
Epoch: 39, Steps: 258 | Train Loss: 0.2620113 Vali Loss: 0.2650196 Test Loss: 0.3550352
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2273034
	speed: 0.0910s/iter; left time: 1422.4111s
	iters: 200, epoch: 40 | loss: 0.2285608
	speed: 0.0215s/iter; left time: 334.0822s
Epoch: 40 cost time: 6.170466899871826
Epoch: 40, Steps: 258 | Train Loss: 0.2619473 Vali Loss: 0.2647228 Test Loss: 0.3550160
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2608813
	speed: 0.0925s/iter; left time: 1423.0522s
	iters: 200, epoch: 41 | loss: 0.2531068
	speed: 0.0214s/iter; left time: 326.5281s
Epoch: 41 cost time: 6.169398546218872
Epoch: 41, Steps: 258 | Train Loss: 0.2622307 Vali Loss: 0.2649550 Test Loss: 0.3550268
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2431829
	speed: 0.0903s/iter; left time: 1365.4051s
	iters: 200, epoch: 42 | loss: 0.2945052
	speed: 0.0242s/iter; left time: 363.4659s
Epoch: 42 cost time: 6.460850477218628
Epoch: 42, Steps: 258 | Train Loss: 0.2619933 Vali Loss: 0.2649643 Test Loss: 0.3549939
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2473290
	speed: 0.0915s/iter; left time: 1359.7560s
	iters: 200, epoch: 43 | loss: 0.2643034
	speed: 0.0210s/iter; left time: 310.7738s
Epoch: 43 cost time: 6.143168210983276
Epoch: 43, Steps: 258 | Train Loss: 0.2620103 Vali Loss: 0.2649749 Test Loss: 0.3549875
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2147137
	speed: 0.0916s/iter; left time: 1337.5355s
	iters: 200, epoch: 44 | loss: 0.1740647
	speed: 0.0215s/iter; left time: 312.3503s
Epoch: 44 cost time: 6.215899467468262
Epoch: 44, Steps: 258 | Train Loss: 0.2619542 Vali Loss: 0.2647821 Test Loss: 0.3549835
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.3222410
	speed: 0.0907s/iter; left time: 1301.5877s
	iters: 200, epoch: 45 | loss: 0.2099767
	speed: 0.0217s/iter; left time: 308.8855s
Epoch: 45 cost time: 6.098839044570923
Epoch: 45, Steps: 258 | Train Loss: 0.2618343 Vali Loss: 0.2649232 Test Loss: 0.3549657
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2095802
	speed: 0.0902s/iter; left time: 1270.9715s
	iters: 200, epoch: 46 | loss: 0.2495121
	speed: 0.0223s/iter; left time: 311.4191s
Epoch: 46 cost time: 6.33371639251709
Epoch: 46, Steps: 258 | Train Loss: 0.2617440 Vali Loss: 0.2649298 Test Loss: 0.3549928
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2445342
	speed: 0.0911s/iter; left time: 1260.4163s
	iters: 200, epoch: 47 | loss: 0.2301961
	speed: 0.0215s/iter; left time: 294.6007s
Epoch: 47 cost time: 6.287982225418091
Epoch: 47, Steps: 258 | Train Loss: 0.2617585 Vali Loss: 0.2651419 Test Loss: 0.3549666
EarlyStopping counter: 20 out of 20
Early stopping
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=58, out_features=116, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6028288.0
params:  6844.0
Trainable parameters:  6844
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4983306
	speed: 0.0279s/iter; left time: 718.1587s
	iters: 200, epoch: 1 | loss: 0.5646217
	speed: 0.0207s/iter; left time: 528.9217s
Epoch: 1 cost time: 6.045835018157959
Epoch: 1, Steps: 258 | Train Loss: 0.4993642 Vali Loss: 0.2638733 Test Loss: 0.3540997
Validation loss decreased (inf --> 0.263873).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5361447
	speed: 0.0885s/iter; left time: 2251.6337s
	iters: 200, epoch: 2 | loss: 0.5919084
	speed: 0.0208s/iter; left time: 526.6981s
Epoch: 2 cost time: 5.96314549446106
Epoch: 2, Steps: 258 | Train Loss: 0.4990332 Vali Loss: 0.2637112 Test Loss: 0.3541161
Validation loss decreased (0.263873 --> 0.263711).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4870531
	speed: 0.0917s/iter; left time: 2309.9742s
	iters: 200, epoch: 3 | loss: 0.4438731
	speed: 0.0214s/iter; left time: 536.8089s
Epoch: 3 cost time: 6.136122465133667
Epoch: 3, Steps: 258 | Train Loss: 0.4980262 Vali Loss: 0.2628202 Test Loss: 0.3537467
Validation loss decreased (0.263711 --> 0.262820).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.5187141
	speed: 0.0905s/iter; left time: 2257.0531s
	iters: 200, epoch: 4 | loss: 0.4072974
	speed: 0.0219s/iter; left time: 543.3368s
Epoch: 4 cost time: 6.211669206619263
Epoch: 4, Steps: 258 | Train Loss: 0.4977379 Vali Loss: 0.2623793 Test Loss: 0.3537195
Validation loss decreased (0.262820 --> 0.262379).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4998995
	speed: 0.0877s/iter; left time: 2164.4407s
	iters: 200, epoch: 5 | loss: 0.3821964
	speed: 0.0218s/iter; left time: 536.2723s
Epoch: 5 cost time: 6.2605884075164795
Epoch: 5, Steps: 258 | Train Loss: 0.4976409 Vali Loss: 0.2626760 Test Loss: 0.3533317
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.6075369
	speed: 0.0923s/iter; left time: 2253.3985s
	iters: 200, epoch: 6 | loss: 0.4330788
	speed: 0.0219s/iter; left time: 533.5782s
Epoch: 6 cost time: 6.362907648086548
Epoch: 6, Steps: 258 | Train Loss: 0.4971410 Vali Loss: 0.2625058 Test Loss: 0.3532640
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4954992
	speed: 0.0905s/iter; left time: 2186.3183s
	iters: 200, epoch: 7 | loss: 0.6638759
	speed: 0.0218s/iter; left time: 525.0499s
Epoch: 7 cost time: 6.248405456542969
Epoch: 7, Steps: 258 | Train Loss: 0.4976898 Vali Loss: 0.2621260 Test Loss: 0.3533832
Validation loss decreased (0.262379 --> 0.262126).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4113680
	speed: 0.0918s/iter; left time: 2193.6544s
	iters: 200, epoch: 8 | loss: 0.4312281
	speed: 0.0215s/iter; left time: 511.7966s
Epoch: 8 cost time: 6.1919519901275635
Epoch: 8, Steps: 258 | Train Loss: 0.4970417 Vali Loss: 0.2622409 Test Loss: 0.3532336
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.5340814
	speed: 0.0892s/iter; left time: 2107.4083s
	iters: 200, epoch: 9 | loss: 0.4375440
	speed: 0.0218s/iter; left time: 511.9331s
Epoch: 9 cost time: 6.090463638305664
Epoch: 9, Steps: 258 | Train Loss: 0.4965249 Vali Loss: 0.2623523 Test Loss: 0.3530005
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4045680
	speed: 0.0919s/iter; left time: 2147.8829s
	iters: 200, epoch: 10 | loss: 0.5977181
	speed: 0.0219s/iter; left time: 509.0307s
Epoch: 10 cost time: 6.319429159164429
Epoch: 10, Steps: 258 | Train Loss: 0.4974461 Vali Loss: 0.2623367 Test Loss: 0.3532505
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3538156
	speed: 0.0908s/iter; left time: 2099.2691s
	iters: 200, epoch: 11 | loss: 0.5634055
	speed: 0.0211s/iter; left time: 485.1159s
Epoch: 11 cost time: 6.142645359039307
Epoch: 11, Steps: 258 | Train Loss: 0.4967772 Vali Loss: 0.2622008 Test Loss: 0.3532201
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4803496
	speed: 0.0967s/iter; left time: 2211.9437s
	iters: 200, epoch: 12 | loss: 0.5299343
	speed: 0.0214s/iter; left time: 488.0140s
Epoch: 12 cost time: 6.655723333358765
Epoch: 12, Steps: 258 | Train Loss: 0.4970920 Vali Loss: 0.2619161 Test Loss: 0.3532759
Validation loss decreased (0.262126 --> 0.261916).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.5846178
	speed: 0.0899s/iter; left time: 2032.7268s
	iters: 200, epoch: 13 | loss: 0.4107421
	speed: 0.0211s/iter; left time: 473.8242s
Epoch: 13 cost time: 6.045710802078247
Epoch: 13, Steps: 258 | Train Loss: 0.4964339 Vali Loss: 0.2622471 Test Loss: 0.3531812
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.5761255
	speed: 0.0902s/iter; left time: 2016.1902s
	iters: 200, epoch: 14 | loss: 0.5664744
	speed: 0.0211s/iter; left time: 469.5303s
Epoch: 14 cost time: 6.058488607406616
Epoch: 14, Steps: 258 | Train Loss: 0.4963009 Vali Loss: 0.2622658 Test Loss: 0.3530857
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.5447881
	speed: 0.0924s/iter; left time: 2041.0588s
	iters: 200, epoch: 15 | loss: 0.3940594
	speed: 0.0216s/iter; left time: 474.0179s
Epoch: 15 cost time: 6.290242910385132
Epoch: 15, Steps: 258 | Train Loss: 0.4969905 Vali Loss: 0.2622562 Test Loss: 0.3530689
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3546649
	speed: 0.0890s/iter; left time: 1942.8515s
	iters: 200, epoch: 16 | loss: 0.3888721
	speed: 0.0214s/iter; left time: 464.7827s
Epoch: 16 cost time: 6.176303386688232
Epoch: 16, Steps: 258 | Train Loss: 0.4967875 Vali Loss: 0.2619398 Test Loss: 0.3532451
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4050237
	speed: 0.0912s/iter; left time: 1966.9968s
	iters: 200, epoch: 17 | loss: 0.5401205
	speed: 0.0217s/iter; left time: 466.4676s
Epoch: 17 cost time: 6.216608047485352
Epoch: 17, Steps: 258 | Train Loss: 0.4965231 Vali Loss: 0.2620562 Test Loss: 0.3531459
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.5163090
	speed: 0.0905s/iter; left time: 1929.4856s
	iters: 200, epoch: 18 | loss: 0.4967789
	speed: 0.0217s/iter; left time: 460.0865s
Epoch: 18 cost time: 6.260286092758179
Epoch: 18, Steps: 258 | Train Loss: 0.4961368 Vali Loss: 0.2621124 Test Loss: 0.3532278
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.6001951
	speed: 0.0915s/iter; left time: 1926.8574s
	iters: 200, epoch: 19 | loss: 0.4520901
	speed: 0.0220s/iter; left time: 460.5122s
Epoch: 19 cost time: 6.439965009689331
Epoch: 19, Steps: 258 | Train Loss: 0.4971399 Vali Loss: 0.2621774 Test Loss: 0.3530791
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4466462
	speed: 0.0947s/iter; left time: 1970.5681s
	iters: 200, epoch: 20 | loss: 0.5319249
	speed: 0.0229s/iter; left time: 473.5763s
Epoch: 20 cost time: 6.4843785762786865
Epoch: 20, Steps: 258 | Train Loss: 0.4965668 Vali Loss: 0.2620483 Test Loss: 0.3532032
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.5972911
	speed: 0.0912s/iter; left time: 1872.4130s
	iters: 200, epoch: 21 | loss: 0.3591818
	speed: 0.0210s/iter; left time: 429.4251s
Epoch: 21 cost time: 6.075585126876831
Epoch: 21, Steps: 258 | Train Loss: 0.4959616 Vali Loss: 0.2619031 Test Loss: 0.3530474
Validation loss decreased (0.261916 --> 0.261903).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4785269
	speed: 0.0930s/iter; left time: 1886.3922s
	iters: 200, epoch: 22 | loss: 0.6062223
	speed: 0.0221s/iter; left time: 446.1748s
Epoch: 22 cost time: 6.307519435882568
Epoch: 22, Steps: 258 | Train Loss: 0.4957814 Vali Loss: 0.2621325 Test Loss: 0.3531244
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.5435348
	speed: 0.0913s/iter; left time: 1827.3556s
	iters: 200, epoch: 23 | loss: 0.3878974
	speed: 0.0211s/iter; left time: 419.6997s
Epoch: 23 cost time: 6.090475559234619
Epoch: 23, Steps: 258 | Train Loss: 0.4963888 Vali Loss: 0.2622352 Test Loss: 0.3530390
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4921609
	speed: 0.0913s/iter; left time: 1804.0381s
	iters: 200, epoch: 24 | loss: 0.3790954
	speed: 0.0409s/iter; left time: 804.6558s
Epoch: 24 cost time: 8.124572038650513
Epoch: 24, Steps: 258 | Train Loss: 0.4962463 Vali Loss: 0.2618832 Test Loss: 0.3531809
Validation loss decreased (0.261903 --> 0.261883).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.5901666
	speed: 0.0909s/iter; left time: 1774.2866s
	iters: 200, epoch: 25 | loss: 0.5491619
	speed: 0.0211s/iter; left time: 408.7114s
Epoch: 25 cost time: 6.127831697463989
Epoch: 25, Steps: 258 | Train Loss: 0.4963595 Vali Loss: 0.2620568 Test Loss: 0.3531877
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.5148959
	speed: 0.0938s/iter; left time: 1806.3216s
	iters: 200, epoch: 26 | loss: 0.5017397
	speed: 0.0213s/iter; left time: 408.0146s
Epoch: 26 cost time: 6.2042741775512695
Epoch: 26, Steps: 258 | Train Loss: 0.4962790 Vali Loss: 0.2618938 Test Loss: 0.3531875
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4298261
	speed: 0.0934s/iter; left time: 1773.6403s
	iters: 200, epoch: 27 | loss: 0.5175910
	speed: 0.0217s/iter; left time: 410.8244s
Epoch: 27 cost time: 6.338761568069458
Epoch: 27, Steps: 258 | Train Loss: 0.4957437 Vali Loss: 0.2622887 Test Loss: 0.3530867
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4561853
	speed: 0.0939s/iter; left time: 1758.7376s
	iters: 200, epoch: 28 | loss: 0.5184240
	speed: 0.0215s/iter; left time: 400.5944s
Epoch: 28 cost time: 6.220301151275635
Epoch: 28, Steps: 258 | Train Loss: 0.4964240 Vali Loss: 0.2618757 Test Loss: 0.3530747
Validation loss decreased (0.261883 --> 0.261876).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.5967581
	speed: 0.0947s/iter; left time: 1750.0957s
	iters: 200, epoch: 29 | loss: 0.4530641
	speed: 0.0221s/iter; left time: 406.2835s
Epoch: 29 cost time: 6.419497966766357
Epoch: 29, Steps: 258 | Train Loss: 0.4957221 Vali Loss: 0.2622888 Test Loss: 0.3530046
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.5924075
	speed: 0.0940s/iter; left time: 1711.6809s
	iters: 200, epoch: 30 | loss: 0.5614840
	speed: 0.0219s/iter; left time: 396.6883s
Epoch: 30 cost time: 6.208062648773193
Epoch: 30, Steps: 258 | Train Loss: 0.4962821 Vali Loss: 0.2619206 Test Loss: 0.3530711
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4555404
	speed: 0.0948s/iter; left time: 1702.9624s
	iters: 200, epoch: 31 | loss: 0.4358431
	speed: 0.0217s/iter; left time: 386.9154s
Epoch: 31 cost time: 6.306024551391602
Epoch: 31, Steps: 258 | Train Loss: 0.4963512 Vali Loss: 0.2619852 Test Loss: 0.3530786
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.5273345
	speed: 0.0931s/iter; left time: 1648.1563s
	iters: 200, epoch: 32 | loss: 0.4961029
	speed: 0.0210s/iter; left time: 370.3789s
Epoch: 32 cost time: 6.2447144985198975
Epoch: 32, Steps: 258 | Train Loss: 0.4963108 Vali Loss: 0.2619465 Test Loss: 0.3530472
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3822340
	speed: 0.0956s/iter; left time: 1667.9202s
	iters: 200, epoch: 33 | loss: 0.3661413
	speed: 0.0211s/iter; left time: 366.4318s
Epoch: 33 cost time: 6.308490753173828
Epoch: 33, Steps: 258 | Train Loss: 0.4964751 Vali Loss: 0.2620759 Test Loss: 0.3530079
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.5619262
	speed: 0.0951s/iter; left time: 1634.1323s
	iters: 200, epoch: 34 | loss: 0.4362339
	speed: 0.0224s/iter; left time: 382.9488s
Epoch: 34 cost time: 6.236872434616089
Epoch: 34, Steps: 258 | Train Loss: 0.4965934 Vali Loss: 0.2617653 Test Loss: 0.3530770
Validation loss decreased (0.261876 --> 0.261765).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.6472966
	speed: 0.0939s/iter; left time: 1590.4677s
	iters: 200, epoch: 35 | loss: 0.5375131
	speed: 0.0218s/iter; left time: 367.6524s
Epoch: 35 cost time: 6.283912420272827
Epoch: 35, Steps: 258 | Train Loss: 0.4964490 Vali Loss: 0.2619856 Test Loss: 0.3530744
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.6172076
	speed: 0.0945s/iter; left time: 1574.9174s
	iters: 200, epoch: 36 | loss: 0.4423264
	speed: 0.0210s/iter; left time: 348.3790s
Epoch: 36 cost time: 6.099547624588013
Epoch: 36, Steps: 258 | Train Loss: 0.4960703 Vali Loss: 0.2620603 Test Loss: 0.3531097
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3869921
	speed: 0.0926s/iter; left time: 1520.6575s
	iters: 200, epoch: 37 | loss: 0.6764596
	speed: 0.0219s/iter; left time: 356.4603s
Epoch: 37 cost time: 6.181342124938965
Epoch: 37, Steps: 258 | Train Loss: 0.4962145 Vali Loss: 0.2618923 Test Loss: 0.3530900
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.6331608
	speed: 0.0911s/iter; left time: 1471.8742s
	iters: 200, epoch: 38 | loss: 0.5790772
	speed: 0.0219s/iter; left time: 351.4846s
Epoch: 38 cost time: 6.21035361289978
Epoch: 38, Steps: 258 | Train Loss: 0.4959241 Vali Loss: 0.2616138 Test Loss: 0.3530316
Validation loss decreased (0.261765 --> 0.261614).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4620529
	speed: 0.0905s/iter; left time: 1438.7031s
	iters: 200, epoch: 39 | loss: 0.5541196
	speed: 0.0222s/iter; left time: 349.9423s
Epoch: 39 cost time: 6.273252010345459
Epoch: 39, Steps: 258 | Train Loss: 0.4957017 Vali Loss: 0.2619785 Test Loss: 0.3530778
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.4475787
	speed: 0.0911s/iter; left time: 1424.5699s
	iters: 200, epoch: 40 | loss: 0.5711708
	speed: 0.0212s/iter; left time: 329.8523s
Epoch: 40 cost time: 6.139924049377441
Epoch: 40, Steps: 258 | Train Loss: 0.4956563 Vali Loss: 0.2620180 Test Loss: 0.3530920
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.4784421
	speed: 0.0905s/iter; left time: 1392.1326s
	iters: 200, epoch: 41 | loss: 0.4992636
	speed: 0.0215s/iter; left time: 328.5953s
Epoch: 41 cost time: 6.23651385307312
Epoch: 41, Steps: 258 | Train Loss: 0.4959434 Vali Loss: 0.2620762 Test Loss: 0.3531106
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.5395680
	speed: 0.0919s/iter; left time: 1389.5886s
	iters: 200, epoch: 42 | loss: 0.4876057
	speed: 0.0214s/iter; left time: 321.7139s
Epoch: 42 cost time: 6.04537034034729
Epoch: 42, Steps: 258 | Train Loss: 0.4961866 Vali Loss: 0.2620047 Test Loss: 0.3531094
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3569473
	speed: 0.0921s/iter; left time: 1369.1792s
	iters: 200, epoch: 43 | loss: 0.4367175
	speed: 0.0214s/iter; left time: 316.3845s
Epoch: 43 cost time: 6.132982969284058
Epoch: 43, Steps: 258 | Train Loss: 0.4956452 Vali Loss: 0.2617475 Test Loss: 0.3530723
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.4377135
	speed: 0.0912s/iter; left time: 1331.7878s
	iters: 200, epoch: 44 | loss: 0.4888828
	speed: 0.0213s/iter; left time: 309.3925s
Epoch: 44 cost time: 6.0527660846710205
Epoch: 44, Steps: 258 | Train Loss: 0.4960844 Vali Loss: 0.2618427 Test Loss: 0.3530910
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.5609525
	speed: 0.0917s/iter; left time: 1315.1713s
	iters: 200, epoch: 45 | loss: 0.4546728
	speed: 0.0217s/iter; left time: 308.9875s
Epoch: 45 cost time: 6.2935144901275635
Epoch: 45, Steps: 258 | Train Loss: 0.4954943 Vali Loss: 0.2619057 Test Loss: 0.3530539
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.5184213
	speed: 0.0906s/iter; left time: 1277.2516s
	iters: 200, epoch: 46 | loss: 0.5637272
	speed: 0.0206s/iter; left time: 287.5661s
Epoch: 46 cost time: 6.06407356262207
Epoch: 46, Steps: 258 | Train Loss: 0.4960604 Vali Loss: 0.2619601 Test Loss: 0.3530802
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.4365686
	speed: 0.0934s/iter; left time: 1291.9400s
	iters: 200, epoch: 47 | loss: 0.4191613
	speed: 0.0211s/iter; left time: 290.4411s
Epoch: 47 cost time: 6.115419387817383
Epoch: 47, Steps: 258 | Train Loss: 0.4963429 Vali Loss: 0.2617102 Test Loss: 0.3531082
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.5199277
	speed: 0.0878s/iter; left time: 1191.9874s
	iters: 200, epoch: 48 | loss: 0.5297109
	speed: 0.0217s/iter; left time: 292.7711s
Epoch: 48 cost time: 6.159419775009155
Epoch: 48, Steps: 258 | Train Loss: 0.4958173 Vali Loss: 0.2620198 Test Loss: 0.3530876
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.4317356
	speed: 0.0907s/iter; left time: 1207.7912s
	iters: 200, epoch: 49 | loss: 0.5014182
	speed: 0.0214s/iter; left time: 283.4499s
Epoch: 49 cost time: 6.136559963226318
Epoch: 49, Steps: 258 | Train Loss: 0.4962112 Vali Loss: 0.2617523 Test Loss: 0.3531087
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.4191878
	speed: 0.0915s/iter; left time: 1194.8844s
	iters: 200, epoch: 50 | loss: 0.4541253
	speed: 0.0217s/iter; left time: 280.7313s
Epoch: 50 cost time: 6.295244932174683
Epoch: 50, Steps: 258 | Train Loss: 0.4955553 Vali Loss: 0.2621016 Test Loss: 0.3530836
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.5390797
	speed: 0.0907s/iter; left time: 1160.9613s
	iters: 200, epoch: 51 | loss: 0.4287698
	speed: 0.0219s/iter; left time: 278.6707s
Epoch: 51 cost time: 6.251636743545532
Epoch: 51, Steps: 258 | Train Loss: 0.4958557 Vali Loss: 0.2618462 Test Loss: 0.3530906
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.4949428
	speed: 0.0896s/iter; left time: 1124.2124s
	iters: 200, epoch: 52 | loss: 0.4734944
	speed: 0.0215s/iter; left time: 267.4672s
Epoch: 52 cost time: 6.008327960968018
Epoch: 52, Steps: 258 | Train Loss: 0.4961042 Vali Loss: 0.2619434 Test Loss: 0.3530745
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.5157247
	speed: 0.0933s/iter; left time: 1146.6474s
	iters: 200, epoch: 53 | loss: 0.4323122
	speed: 0.0214s/iter; left time: 260.7579s
Epoch: 53 cost time: 6.191879510879517
Epoch: 53, Steps: 258 | Train Loss: 0.4959216 Vali Loss: 0.2619582 Test Loss: 0.3530749
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.3898497
	speed: 0.0905s/iter; left time: 1088.8811s
	iters: 200, epoch: 54 | loss: 0.5961342
	speed: 0.0213s/iter; left time: 253.9212s
Epoch: 54 cost time: 6.2191431522369385
Epoch: 54, Steps: 258 | Train Loss: 0.4952670 Vali Loss: 0.2619180 Test Loss: 0.3530873
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.3617977
	speed: 0.0899s/iter; left time: 1057.5649s
	iters: 200, epoch: 55 | loss: 0.4014232
	speed: 0.0220s/iter; left time: 256.8495s
Epoch: 55 cost time: 6.168189287185669
Epoch: 55, Steps: 258 | Train Loss: 0.4959159 Vali Loss: 0.2615956 Test Loss: 0.3530876
Validation loss decreased (0.261614 --> 0.261596).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.4548710
	speed: 0.0920s/iter; left time: 1058.8711s
	iters: 200, epoch: 56 | loss: 0.4134614
	speed: 0.0218s/iter; left time: 249.2978s
Epoch: 56 cost time: 6.158564329147339
Epoch: 56, Steps: 258 | Train Loss: 0.4962510 Vali Loss: 0.2619455 Test Loss: 0.3530720
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.5624719
	speed: 0.0915s/iter; left time: 1029.7620s
	iters: 200, epoch: 57 | loss: 0.4676479
	speed: 0.0213s/iter; left time: 237.5357s
Epoch: 57 cost time: 6.249790906906128
Epoch: 57, Steps: 258 | Train Loss: 0.4956997 Vali Loss: 0.2616213 Test Loss: 0.3530775
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.4439740
	speed: 0.0919s/iter; left time: 1010.2191s
	iters: 200, epoch: 58 | loss: 0.5514490
	speed: 0.0215s/iter; left time: 233.8418s
Epoch: 58 cost time: 6.1719651222229
Epoch: 58, Steps: 258 | Train Loss: 0.4955861 Vali Loss: 0.2618731 Test Loss: 0.3530819
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.5293217
	speed: 0.0915s/iter; left time: 982.8839s
	iters: 200, epoch: 59 | loss: 0.5332458
	speed: 0.0214s/iter; left time: 227.8738s
Epoch: 59 cost time: 6.149631500244141
Epoch: 59, Steps: 258 | Train Loss: 0.4959832 Vali Loss: 0.2617734 Test Loss: 0.3530854
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.5469280
	speed: 0.0879s/iter; left time: 921.5483s
	iters: 200, epoch: 60 | loss: 0.5182945
	speed: 0.0255s/iter; left time: 264.7345s
Epoch: 60 cost time: 6.531615257263184
Epoch: 60, Steps: 258 | Train Loss: 0.4963086 Vali Loss: 0.2617615 Test Loss: 0.3530855
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.4426482
	speed: 0.0922s/iter; left time: 942.1012s
	iters: 200, epoch: 61 | loss: 0.5584770
	speed: 0.0224s/iter; left time: 226.6886s
Epoch: 61 cost time: 6.384585618972778
Epoch: 61, Steps: 258 | Train Loss: 0.4961153 Vali Loss: 0.2621034 Test Loss: 0.3530792
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.4607275
	speed: 0.0939s/iter; left time: 935.0329s
	iters: 200, epoch: 62 | loss: 0.4145353
	speed: 0.0215s/iter; left time: 212.0622s
Epoch: 62 cost time: 6.306201219558716
Epoch: 62, Steps: 258 | Train Loss: 0.4962205 Vali Loss: 0.2620908 Test Loss: 0.3530768
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.4402501
	speed: 0.0903s/iter; left time: 876.7124s
	iters: 200, epoch: 63 | loss: 0.4595557
	speed: 0.0214s/iter; left time: 205.2303s
Epoch: 63 cost time: 6.119191884994507
Epoch: 63, Steps: 258 | Train Loss: 0.4963655 Vali Loss: 0.2619207 Test Loss: 0.3530782
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.6117042
	speed: 0.0939s/iter; left time: 886.7121s
	iters: 200, epoch: 64 | loss: 0.4764093
	speed: 0.0220s/iter; left time: 205.1788s
Epoch: 64 cost time: 6.209472179412842
Epoch: 64, Steps: 258 | Train Loss: 0.4954314 Vali Loss: 0.2617534 Test Loss: 0.3530750
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.4534328
	speed: 0.0923s/iter; left time: 848.5077s
	iters: 200, epoch: 65 | loss: 0.5501117
	speed: 0.0216s/iter; left time: 196.4841s
Epoch: 65 cost time: 6.2075841426849365
Epoch: 65, Steps: 258 | Train Loss: 0.4956256 Vali Loss: 0.2619421 Test Loss: 0.3530731
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.4753829
	speed: 0.0920s/iter; left time: 821.4481s
	iters: 200, epoch: 66 | loss: 0.5010454
	speed: 0.0220s/iter; left time: 193.8506s
Epoch: 66 cost time: 6.214521646499634
Epoch: 66, Steps: 258 | Train Loss: 0.4952799 Vali Loss: 0.2618975 Test Loss: 0.3530761
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.4331808
	speed: 0.0928s/iter; left time: 804.7544s
	iters: 200, epoch: 67 | loss: 0.5384972
	speed: 0.0216s/iter; left time: 185.2166s
Epoch: 67 cost time: 6.240607500076294
Epoch: 67, Steps: 258 | Train Loss: 0.4965499 Vali Loss: 0.2619921 Test Loss: 0.3530822
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.6840248
	speed: 0.0921s/iter; left time: 775.3943s
	iters: 200, epoch: 68 | loss: 0.6241280
	speed: 0.0214s/iter; left time: 177.7815s
Epoch: 68 cost time: 6.1707611083984375
Epoch: 68, Steps: 258 | Train Loss: 0.4959367 Vali Loss: 0.2620026 Test Loss: 0.3530785
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.4757719
	speed: 0.0920s/iter; left time: 750.1393s
	iters: 200, epoch: 69 | loss: 0.5412341
	speed: 0.0212s/iter; left time: 171.1301s
Epoch: 69 cost time: 6.1673970222473145
Epoch: 69, Steps: 258 | Train Loss: 0.4959933 Vali Loss: 0.2618522 Test Loss: 0.3530797
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.6073776
	speed: 0.0912s/iter; left time: 720.5074s
	iters: 200, epoch: 70 | loss: 0.4540654
	speed: 0.0218s/iter; left time: 169.6534s
Epoch: 70 cost time: 6.1353983879089355
Epoch: 70, Steps: 258 | Train Loss: 0.4959533 Vali Loss: 0.2620124 Test Loss: 0.3530775
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.5090862
	speed: 0.0928s/iter; left time: 709.3835s
	iters: 200, epoch: 71 | loss: 0.4030454
	speed: 0.0224s/iter; left time: 168.6164s
Epoch: 71 cost time: 6.418129205703735
Epoch: 71, Steps: 258 | Train Loss: 0.4955964 Vali Loss: 0.2621456 Test Loss: 0.3530847
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.4634953
	speed: 0.0920s/iter; left time: 678.9877s
	iters: 200, epoch: 72 | loss: 0.4737899
	speed: 0.0210s/iter; left time: 152.5984s
Epoch: 72 cost time: 6.110075235366821
Epoch: 72, Steps: 258 | Train Loss: 0.4958838 Vali Loss: 0.2620609 Test Loss: 0.3530762
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.4155441
	speed: 0.0936s/iter; left time: 666.5999s
	iters: 200, epoch: 73 | loss: 0.4800948
	speed: 0.0215s/iter; left time: 151.3679s
Epoch: 73 cost time: 6.134757041931152
Epoch: 73, Steps: 258 | Train Loss: 0.4956184 Vali Loss: 0.2620007 Test Loss: 0.3530761
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.4701985
	speed: 0.0973s/iter; left time: 667.8298s
	iters: 200, epoch: 74 | loss: 0.6141125
	speed: 0.0216s/iter; left time: 146.2206s
Epoch: 74 cost time: 6.461106777191162
Epoch: 74, Steps: 258 | Train Loss: 0.4954656 Vali Loss: 0.2618268 Test Loss: 0.3530765
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.4689888
	speed: 0.0933s/iter; left time: 616.7693s
	iters: 200, epoch: 75 | loss: 0.5905846
	speed: 0.0213s/iter; left time: 138.8441s
Epoch: 75 cost time: 6.179691791534424
Epoch: 75, Steps: 258 | Train Loss: 0.4962476 Vali Loss: 0.2619394 Test Loss: 0.3530784
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_720_720_FITS_ETTm2_ftM_sl720_ll48_pl720_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.3497697114944458, mae:0.37891024351119995, rse:0.4753740727901459, corr:[0.54120576 0.5422573  0.54204684 0.54080874 0.53922004 0.5378484
 0.5369529  0.5365628  0.5365855  0.5368579  0.5371469  0.53722954
 0.5370129  0.53648376 0.5357785  0.5349461  0.53412503 0.53342426
 0.5328556  0.53238386 0.5319978  0.5316122  0.53120106 0.5307685
 0.5302653  0.52970874 0.5291223  0.528557   0.5280361  0.5275818
 0.5271696  0.52685773 0.5265926  0.5262409  0.52576804 0.5251984
 0.52453446 0.5238497  0.52315867 0.5225048  0.5219122  0.5213512
 0.5208309  0.5203232  0.51982075 0.51926273 0.5186519  0.51801366
 0.5173003  0.5164569  0.5155055  0.51454496 0.5136093  0.5127497
 0.51201624 0.51145744 0.51105994 0.5107846  0.5106021  0.5104418
 0.5102791  0.5101131  0.50993955 0.5097269  0.5094574  0.5091917
 0.50886786 0.50856787 0.5083153  0.50810087 0.50788474 0.50763494
 0.5073412  0.5069893  0.5065484  0.50602657 0.50544834 0.50482076
 0.5041907  0.5035784  0.5029254  0.5022652  0.50163174 0.5010437
 0.5005288  0.5001005  0.49969387 0.49932152 0.49892405 0.49847576
 0.49797747 0.49741945 0.49671152 0.49582058 0.49471843 0.49340883
 0.49196154 0.49053314 0.48914018 0.48778996 0.4865091  0.48530203
 0.4841654  0.48308063 0.48201784 0.48097748 0.47997808 0.47906592
 0.47819033 0.47732416 0.47644833 0.47552806 0.47463596 0.47376254
 0.4728829  0.47203174 0.47125942 0.47054136 0.46990183 0.4692566
 0.4686222  0.46794027 0.46722987 0.4664585  0.4655883  0.46459815
 0.46355876 0.46251985 0.46154022 0.46064052 0.45984888 0.45912647
 0.45847136 0.4578608  0.4572933  0.45672798 0.4561062  0.45544544
 0.4547474  0.4540474  0.45335528 0.4527102  0.452146   0.45158142
 0.45097065 0.45020542 0.449376   0.44849437 0.4476195  0.44675228
 0.44595614 0.4452847  0.44467917 0.4440786  0.44347358 0.44289201
 0.4423447  0.44182643 0.44127834 0.44076595 0.44024345 0.43972743
 0.43921039 0.43874204 0.43835345 0.4380691  0.43783936 0.4376203
 0.43738276 0.43712765 0.4367637  0.43630198 0.43571433 0.43504694
 0.43433768 0.4336401  0.43297842 0.432351   0.43172938 0.43117052
 0.43063954 0.43012783 0.42966992 0.4292529  0.42883414 0.42836627
 0.42784014 0.42720598 0.42645407 0.4255389  0.42445064 0.42317477
 0.4217755  0.42047808 0.41921481 0.4179234  0.41662273 0.41527918
 0.41393486 0.41259846 0.41129297 0.41002738 0.40880424 0.40763488
 0.40653276 0.40548623 0.40445745 0.40340328 0.40240318 0.4015679
 0.40079838 0.40001503 0.3991727  0.3982722  0.39736938 0.396417
 0.39540094 0.39426443 0.39308307 0.39188036 0.39066568 0.3894678
 0.3883069  0.38722026 0.3862824  0.38537383 0.3844411  0.3835166
 0.38255835 0.38163486 0.38077354 0.38000682 0.37930012 0.37864658
 0.37798712 0.37734392 0.3767286  0.37616274 0.37570617 0.37534916
 0.37507987 0.37478855 0.3744154  0.37405974 0.3736416  0.37322092
 0.37283638 0.3725269  0.37227592 0.37205252 0.37192312 0.37187022
 0.37185967 0.3719025  0.37189242 0.37179354 0.37154156 0.37117434
 0.37071872 0.3702257  0.3697179  0.3692627  0.36886686 0.36860657
 0.36847168 0.36838695 0.3683141  0.36820278 0.36797583 0.3675727
 0.3670587  0.3664795  0.3658537  0.36527517 0.3647735  0.36436668
 0.36412787 0.36398607 0.36387816 0.36383024 0.3637619  0.36365852
 0.3634433  0.36308864 0.36257422 0.36187324 0.36101484 0.35995394
 0.3588156  0.35780764 0.3569699  0.3562693  0.35568118 0.3551041
 0.35458    0.35406822 0.3535131  0.35289395 0.35225242 0.35155424
 0.3508838  0.35020137 0.34959826 0.3490097  0.34849766 0.34807757
 0.3478132  0.34760112 0.3473969  0.3471604  0.34686652 0.3466093
 0.3463218  0.34606704 0.34580696 0.34551597 0.34521908 0.34495565
 0.34468222 0.3444333  0.34423885 0.3440786  0.34391552 0.34377074
 0.34364566 0.3436063  0.34366792 0.3437354  0.34382084 0.3438493
 0.34387964 0.3438541  0.34378222 0.34371704 0.34361228 0.34353536
 0.3434609  0.34327704 0.34302753 0.34281144 0.34265524 0.34252128
 0.34243006 0.34237635 0.3423294  0.34223807 0.3420841  0.34191692
 0.34174258 0.34160602 0.3415018  0.34139463 0.3412688  0.341081
 0.3408193  0.34053314 0.3401885  0.33990023 0.3395844  0.33928835
 0.33901697 0.33877647 0.33856258 0.33838326 0.33821526 0.33811685
 0.33803356 0.33799702 0.337969   0.33794838 0.33795184 0.3379354
 0.33790046 0.33789393 0.33792776 0.33798113 0.33802003 0.33806926
 0.33816522 0.3382907  0.3383546  0.33820865 0.33790132 0.33735868
 0.3366924  0.33598468 0.33531132 0.3346663  0.33398736 0.33334744
 0.33270139 0.3320534  0.33140707 0.33078006 0.3301916  0.32960242
 0.3290156  0.32847145 0.32788715 0.32725424 0.32667518 0.3261204
 0.32559708 0.32508823 0.3246369  0.324291   0.32396537 0.32366443
 0.32333323 0.32302302 0.32273176 0.322432   0.32217187 0.32193026
 0.32177803 0.32174262 0.32175562 0.32177442 0.32172891 0.32163027
 0.32154506 0.32151294 0.3215082  0.32153872 0.32160133 0.3216843
 0.32179877 0.3219096  0.32204646 0.32219607 0.3223688  0.32254726
 0.32269293 0.32268965 0.3225304  0.32224873 0.32192728 0.32158744
 0.32118705 0.32085267 0.32054865 0.3202072  0.31982234 0.3194621
 0.31906405 0.3186864  0.3183283  0.3179628  0.31763247 0.31731606
 0.31705606 0.3168489  0.31670618 0.31653947 0.3163317  0.31609678
 0.31581643 0.3154953  0.31512186 0.31469697 0.31432006 0.3139387
 0.31359142 0.3132869  0.31302437 0.3127846  0.31252253 0.3122348
 0.31193632 0.31162962 0.31129804 0.3109203  0.31055206 0.31016487
 0.30975574 0.30923146 0.30861872 0.307848   0.30693892 0.305888
 0.30471554 0.30354837 0.30238014 0.3012362  0.3001579  0.29915103
 0.2981844  0.29730433 0.29649204 0.2958218  0.29523447 0.29464477
 0.2939808  0.29328954 0.29258072 0.29180515 0.29101148 0.29024097
 0.28954408 0.2888573  0.2881523  0.287496   0.2868695  0.2863558
 0.28587848 0.28539303 0.2849091  0.28440738 0.2839487  0.28350973
 0.28309867 0.2827087  0.2823083  0.28189227 0.28149027 0.28110623
 0.28071025 0.2802536  0.27986306 0.27951908 0.27920145 0.27892315
 0.27867386 0.27848628 0.2783287  0.27820128 0.2781291  0.27806628
 0.27792785 0.27771455 0.277406   0.27704453 0.27672654 0.2764925
 0.27631235 0.27616853 0.2761191  0.27610767 0.2760943  0.2760455
 0.27593043 0.2757574  0.27548432 0.27515438 0.274765   0.27431118
 0.2738231  0.27339816 0.2730815  0.27288777 0.27275285 0.27267745
 0.27257508 0.27243513 0.27226853 0.27210736 0.2718374  0.2715273
 0.27120218 0.2709445  0.2707373  0.27055204 0.27039456 0.2702711
 0.27017495 0.27009332 0.27003062 0.26995543 0.26984242 0.26968846
 0.269464   0.26912576 0.26857182 0.26779315 0.26683035 0.26566097
 0.26435047 0.26314536 0.26213232 0.26132986 0.26062134 0.25991744
 0.25915614 0.2583244  0.2574533  0.25657755 0.25572154 0.25493184
 0.25419447 0.25345486 0.2527577  0.25207642 0.25141743 0.25083637
 0.25034404 0.24989907 0.24954663 0.24921677 0.24893421 0.24869
 0.2484386  0.24819753 0.24790159 0.24751331 0.24711214 0.24674621
 0.24638519 0.24605739 0.24582715 0.2456196  0.24545288 0.24532093
 0.24528371 0.24520281 0.24510828 0.24506344 0.245067   0.24508588
 0.24512118 0.24524227 0.24544567 0.24575529 0.24618708 0.24672544
 0.24725424 0.24764177 0.24779572 0.24778818 0.24768136 0.24753992
 0.24736449 0.24720956 0.24713837 0.24700469 0.24693204 0.24687457
 0.24682933 0.24680446 0.2467161  0.24665345 0.24646708 0.24619083
 0.2457988  0.24546239 0.24518453 0.24491808 0.2448114  0.24472879
 0.24469888 0.24466155 0.24459295 0.2444747  0.24438767 0.24421346
 0.2440732  0.243928   0.24371797 0.24356978 0.2435329  0.24356887
 0.243635   0.24381052 0.24399546 0.24416271 0.24433358 0.2444407
 0.24441187 0.24427374 0.24398868 0.24345109 0.24265069 0.24167193
 0.24061687 0.23959316 0.2386678  0.23784274 0.23717001 0.23658375
 0.23601    0.23538052 0.23484376 0.23431796 0.23381849 0.23329711
 0.23274404 0.23217171 0.23158559 0.23096937 0.23039883 0.22979112
 0.22916096 0.22849962 0.22778976 0.22719997 0.22670932 0.22627956
 0.22588038 0.22541179 0.22487976 0.22419176 0.22341566 0.22260687
 0.22194937 0.22139797 0.22100255 0.22075588 0.22057569 0.22037837
 0.22002175 0.21950853 0.2188452  0.21820751 0.21759136 0.21716587
 0.21700989 0.21715146 0.21750157 0.21778406 0.21743442 0.21575578]
