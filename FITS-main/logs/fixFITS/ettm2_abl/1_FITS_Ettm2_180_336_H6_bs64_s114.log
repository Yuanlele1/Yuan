Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=22, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_180_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_180_336_FITS_ETTm2_ftM_sl180_ll48_pl336_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34045
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=22, out_features=63, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1241856.0
params:  1449.0
Trainable parameters:  1449
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6362691
	speed: 0.0197s/iter; left time: 519.5736s
	iters: 200, epoch: 1 | loss: 0.3115960
	speed: 0.0132s/iter; left time: 346.7129s
Epoch: 1 cost time: 4.1511993408203125
Epoch: 1, Steps: 265 | Train Loss: 0.5086332 Vali Loss: 0.2277454 Test Loss: 0.3110478
Validation loss decreased (inf --> 0.227745).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3648209
	speed: 0.0707s/iter; left time: 1847.2299s
	iters: 200, epoch: 2 | loss: 0.3984746
	speed: 0.0137s/iter; left time: 356.6506s
Epoch: 2 cost time: 4.21349573135376
Epoch: 2, Steps: 265 | Train Loss: 0.4442717 Vali Loss: 0.2159756 Test Loss: 0.2972979
Validation loss decreased (0.227745 --> 0.215976).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4242200
	speed: 0.0706s/iter; left time: 1825.8806s
	iters: 200, epoch: 3 | loss: 0.4251936
	speed: 0.0148s/iter; left time: 380.3172s
Epoch: 3 cost time: 4.340829372406006
Epoch: 3, Steps: 265 | Train Loss: 0.4333066 Vali Loss: 0.2129827 Test Loss: 0.2937348
Validation loss decreased (0.215976 --> 0.212983).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4606920
	speed: 0.0721s/iter; left time: 1846.9798s
	iters: 200, epoch: 4 | loss: 0.4865364
	speed: 0.0139s/iter; left time: 353.8073s
Epoch: 4 cost time: 4.251511812210083
Epoch: 4, Steps: 265 | Train Loss: 0.4283993 Vali Loss: 0.2114764 Test Loss: 0.2917807
Validation loss decreased (0.212983 --> 0.211476).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.6845294
	speed: 0.0681s/iter; left time: 1725.2491s
	iters: 200, epoch: 5 | loss: 0.6314352
	speed: 0.0136s/iter; left time: 342.8743s
Epoch: 5 cost time: 4.058343410491943
Epoch: 5, Steps: 265 | Train Loss: 0.4258618 Vali Loss: 0.2104325 Test Loss: 0.2904252
Validation loss decreased (0.211476 --> 0.210432).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.5322182
	speed: 0.0692s/iter; left time: 1736.0397s
	iters: 200, epoch: 6 | loss: 0.3639609
	speed: 0.0132s/iter; left time: 328.6260s
Epoch: 6 cost time: 4.072253465652466
Epoch: 6, Steps: 265 | Train Loss: 0.4249099 Vali Loss: 0.2100868 Test Loss: 0.2894202
Validation loss decreased (0.210432 --> 0.210087).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3900272
	speed: 0.0716s/iter; left time: 1777.4408s
	iters: 200, epoch: 7 | loss: 0.4076967
	speed: 0.0136s/iter; left time: 336.6739s
Epoch: 7 cost time: 4.163324356079102
Epoch: 7, Steps: 265 | Train Loss: 0.4230573 Vali Loss: 0.2092370 Test Loss: 0.2885822
Validation loss decreased (0.210087 --> 0.209237).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3117619
	speed: 0.0706s/iter; left time: 1733.4338s
	iters: 200, epoch: 8 | loss: 0.4427024
	speed: 0.0134s/iter; left time: 327.8567s
Epoch: 8 cost time: 4.079982042312622
Epoch: 8, Steps: 265 | Train Loss: 0.4228301 Vali Loss: 0.2090930 Test Loss: 0.2880280
Validation loss decreased (0.209237 --> 0.209093).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3125642
	speed: 0.0700s/iter; left time: 1699.5139s
	iters: 200, epoch: 9 | loss: 0.2863212
	speed: 0.0138s/iter; left time: 333.3655s
Epoch: 9 cost time: 4.145467042922974
Epoch: 9, Steps: 265 | Train Loss: 0.4219369 Vali Loss: 0.2087409 Test Loss: 0.2875658
Validation loss decreased (0.209093 --> 0.208741).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.6768433
	speed: 0.0703s/iter; left time: 1689.4617s
	iters: 200, epoch: 10 | loss: 0.2820986
	speed: 0.0139s/iter; left time: 331.4443s
Epoch: 10 cost time: 4.153966426849365
Epoch: 10, Steps: 265 | Train Loss: 0.4206605 Vali Loss: 0.2088270 Test Loss: 0.2872265
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2593948
	speed: 0.0690s/iter; left time: 1639.6441s
	iters: 200, epoch: 11 | loss: 0.4196031
	speed: 0.0136s/iter; left time: 321.1501s
Epoch: 11 cost time: 4.151163578033447
Epoch: 11, Steps: 265 | Train Loss: 0.4203460 Vali Loss: 0.2085584 Test Loss: 0.2868689
Validation loss decreased (0.208741 --> 0.208558).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2972851
	speed: 0.0710s/iter; left time: 1667.6792s
	iters: 200, epoch: 12 | loss: 0.5968587
	speed: 0.0140s/iter; left time: 327.6080s
Epoch: 12 cost time: 4.2169883251190186
Epoch: 12, Steps: 265 | Train Loss: 0.4198701 Vali Loss: 0.2084875 Test Loss: 0.2867388
Validation loss decreased (0.208558 --> 0.208487).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.5104280
	speed: 0.0714s/iter; left time: 1658.5737s
	iters: 200, epoch: 13 | loss: 0.2865199
	speed: 0.0139s/iter; left time: 321.8396s
Epoch: 13 cost time: 4.2541184425354
Epoch: 13, Steps: 265 | Train Loss: 0.4193388 Vali Loss: 0.2081401 Test Loss: 0.2864805
Validation loss decreased (0.208487 --> 0.208140).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2752416
	speed: 0.0680s/iter; left time: 1560.3562s
	iters: 200, epoch: 14 | loss: 0.4063167
	speed: 0.0134s/iter; left time: 306.0546s
Epoch: 14 cost time: 3.9861271381378174
Epoch: 14, Steps: 265 | Train Loss: 0.4190672 Vali Loss: 0.2082214 Test Loss: 0.2862754
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.5113358
	speed: 0.0684s/iter; left time: 1552.3288s
	iters: 200, epoch: 15 | loss: 0.3523709
	speed: 0.0136s/iter; left time: 306.2663s
Epoch: 15 cost time: 4.0381410121917725
Epoch: 15, Steps: 265 | Train Loss: 0.4192865 Vali Loss: 0.2080848 Test Loss: 0.2861708
Validation loss decreased (0.208140 --> 0.208085).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4340802
	speed: 0.0741s/iter; left time: 1660.8023s
	iters: 200, epoch: 16 | loss: 0.4554175
	speed: 0.0135s/iter; left time: 300.7104s
Epoch: 16 cost time: 3.9999866485595703
Epoch: 16, Steps: 265 | Train Loss: 0.4190146 Vali Loss: 0.2080113 Test Loss: 0.2861260
Validation loss decreased (0.208085 --> 0.208011).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3357449
	speed: 0.0700s/iter; left time: 1551.8615s
	iters: 200, epoch: 17 | loss: 0.3332146
	speed: 0.0136s/iter; left time: 300.6067s
Epoch: 17 cost time: 4.281748294830322
Epoch: 17, Steps: 265 | Train Loss: 0.4193049 Vali Loss: 0.2079636 Test Loss: 0.2859305
Validation loss decreased (0.208011 --> 0.207964).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3280411
	speed: 0.0711s/iter; left time: 1556.8422s
	iters: 200, epoch: 18 | loss: 0.3641058
	speed: 0.0140s/iter; left time: 305.5423s
Epoch: 18 cost time: 4.098934650421143
Epoch: 18, Steps: 265 | Train Loss: 0.4191153 Vali Loss: 0.2079935 Test Loss: 0.2858468
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3071505
	speed: 0.0734s/iter; left time: 1587.0314s
	iters: 200, epoch: 19 | loss: 0.3176360
	speed: 0.0144s/iter; left time: 308.9736s
Epoch: 19 cost time: 4.250096559524536
Epoch: 19, Steps: 265 | Train Loss: 0.4180541 Vali Loss: 0.2079408 Test Loss: 0.2857699
Validation loss decreased (0.207964 --> 0.207941).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4672517
	speed: 0.0690s/iter; left time: 1474.7035s
	iters: 200, epoch: 20 | loss: 0.4826107
	speed: 0.0133s/iter; left time: 283.6768s
Epoch: 20 cost time: 4.010558366775513
Epoch: 20, Steps: 265 | Train Loss: 0.4181755 Vali Loss: 0.2079266 Test Loss: 0.2857412
Validation loss decreased (0.207941 --> 0.207927).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4791736
	speed: 0.0703s/iter; left time: 1483.4779s
	iters: 200, epoch: 21 | loss: 0.4303663
	speed: 0.0138s/iter; left time: 290.2475s
Epoch: 21 cost time: 4.19508957862854
Epoch: 21, Steps: 265 | Train Loss: 0.4177804 Vali Loss: 0.2079678 Test Loss: 0.2857050
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3527883
	speed: 0.0703s/iter; left time: 1464.2637s
	iters: 200, epoch: 22 | loss: 0.4697637
	speed: 0.0138s/iter; left time: 286.9173s
Epoch: 22 cost time: 4.0910725593566895
Epoch: 22, Steps: 265 | Train Loss: 0.4180105 Vali Loss: 0.2078836 Test Loss: 0.2856375
Validation loss decreased (0.207927 --> 0.207884).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3556187
	speed: 0.0698s/iter; left time: 1436.5449s
	iters: 200, epoch: 23 | loss: 0.4126822
	speed: 0.0131s/iter; left time: 267.9701s
Epoch: 23 cost time: 4.085632085800171
Epoch: 23, Steps: 265 | Train Loss: 0.4180038 Vali Loss: 0.2078215 Test Loss: 0.2855689
Validation loss decreased (0.207884 --> 0.207821).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3698893
	speed: 0.0702s/iter; left time: 1425.2335s
	iters: 200, epoch: 24 | loss: 0.3885171
	speed: 0.0135s/iter; left time: 272.3628s
Epoch: 24 cost time: 4.132804870605469
Epoch: 24, Steps: 265 | Train Loss: 0.4179009 Vali Loss: 0.2077095 Test Loss: 0.2855282
Validation loss decreased (0.207821 --> 0.207710).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4063819
	speed: 0.0714s/iter; left time: 1431.0528s
	iters: 200, epoch: 25 | loss: 0.3757182
	speed: 0.0200s/iter; left time: 398.9985s
Epoch: 25 cost time: 4.728951454162598
Epoch: 25, Steps: 265 | Train Loss: 0.4181916 Vali Loss: 0.2076516 Test Loss: 0.2854948
Validation loss decreased (0.207710 --> 0.207652).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.6582875
	speed: 0.0702s/iter; left time: 1388.6349s
	iters: 200, epoch: 26 | loss: 0.3692615
	speed: 0.0137s/iter; left time: 269.4793s
Epoch: 26 cost time: 4.110706329345703
Epoch: 26, Steps: 265 | Train Loss: 0.4172276 Vali Loss: 0.2077922 Test Loss: 0.2854548
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3245653
	speed: 0.0697s/iter; left time: 1359.9091s
	iters: 200, epoch: 27 | loss: 0.7312145
	speed: 0.0137s/iter; left time: 266.3736s
Epoch: 27 cost time: 4.132803440093994
Epoch: 27, Steps: 265 | Train Loss: 0.4178119 Vali Loss: 0.2079659 Test Loss: 0.2854114
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2816965
	speed: 0.0717s/iter; left time: 1380.2067s
	iters: 200, epoch: 28 | loss: 0.3573629
	speed: 0.0139s/iter; left time: 265.4560s
Epoch: 28 cost time: 4.290690183639526
Epoch: 28, Steps: 265 | Train Loss: 0.4181490 Vali Loss: 0.2079597 Test Loss: 0.2854156
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3609575
	speed: 0.0691s/iter; left time: 1312.5051s
	iters: 200, epoch: 29 | loss: 0.3060044
	speed: 0.0136s/iter; left time: 256.1430s
Epoch: 29 cost time: 4.3189380168914795
Epoch: 29, Steps: 265 | Train Loss: 0.4167384 Vali Loss: 0.2077866 Test Loss: 0.2853764
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4012893
	speed: 0.0711s/iter; left time: 1330.7041s
	iters: 200, epoch: 30 | loss: 0.3435045
	speed: 0.0149s/iter; left time: 277.9821s
Epoch: 30 cost time: 4.317263126373291
Epoch: 30, Steps: 265 | Train Loss: 0.4178321 Vali Loss: 0.2076598 Test Loss: 0.2853346
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4133175
	speed: 0.0698s/iter; left time: 1288.3756s
	iters: 200, epoch: 31 | loss: 0.2519407
	speed: 0.0144s/iter; left time: 265.0217s
Epoch: 31 cost time: 4.316228151321411
Epoch: 31, Steps: 265 | Train Loss: 0.4169695 Vali Loss: 0.2076707 Test Loss: 0.2853057
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.6003331
	speed: 0.0712s/iter; left time: 1295.0035s
	iters: 200, epoch: 32 | loss: 0.2383927
	speed: 0.0144s/iter; left time: 260.1760s
Epoch: 32 cost time: 4.272752285003662
Epoch: 32, Steps: 265 | Train Loss: 0.4177953 Vali Loss: 0.2077807 Test Loss: 0.2853179
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4094125
	speed: 0.0709s/iter; left time: 1271.4920s
	iters: 200, epoch: 33 | loss: 0.3272344
	speed: 0.0144s/iter; left time: 257.1083s
Epoch: 33 cost time: 4.305355072021484
Epoch: 33, Steps: 265 | Train Loss: 0.4169008 Vali Loss: 0.2078282 Test Loss: 0.2852852
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4122523
	speed: 0.0713s/iter; left time: 1258.7558s
	iters: 200, epoch: 34 | loss: 0.3000001
	speed: 0.0139s/iter; left time: 243.5093s
Epoch: 34 cost time: 4.177271127700806
Epoch: 34, Steps: 265 | Train Loss: 0.4162431 Vali Loss: 0.2078841 Test Loss: 0.2852553
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.7737190
	speed: 0.0695s/iter; left time: 1209.4055s
	iters: 200, epoch: 35 | loss: 0.3045961
	speed: 0.0135s/iter; left time: 233.2365s
Epoch: 35 cost time: 4.172343969345093
Epoch: 35, Steps: 265 | Train Loss: 0.4172890 Vali Loss: 0.2075753 Test Loss: 0.2852687
Validation loss decreased (0.207652 --> 0.207575).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3838149
	speed: 0.0712s/iter; left time: 1218.9424s
	iters: 200, epoch: 36 | loss: 0.5724115
	speed: 0.0151s/iter; left time: 257.0548s
Epoch: 36 cost time: 4.435989141464233
Epoch: 36, Steps: 265 | Train Loss: 0.4166031 Vali Loss: 0.2078571 Test Loss: 0.2852514
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2766594
	speed: 0.0727s/iter; left time: 1225.2930s
	iters: 200, epoch: 37 | loss: 0.3217552
	speed: 0.0142s/iter; left time: 238.4119s
Epoch: 37 cost time: 4.497351884841919
Epoch: 37, Steps: 265 | Train Loss: 0.4177459 Vali Loss: 0.2075840 Test Loss: 0.2852342
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4336417
	speed: 0.0688s/iter; left time: 1141.0105s
	iters: 200, epoch: 38 | loss: 0.4853019
	speed: 0.0141s/iter; left time: 233.3937s
Epoch: 38 cost time: 4.147973299026489
Epoch: 38, Steps: 265 | Train Loss: 0.4177870 Vali Loss: 0.2076124 Test Loss: 0.2852313
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4630880
	speed: 0.0703s/iter; left time: 1148.1421s
	iters: 200, epoch: 39 | loss: 0.5042907
	speed: 0.0130s/iter; left time: 211.2118s
Epoch: 39 cost time: 4.188850402832031
Epoch: 39, Steps: 265 | Train Loss: 0.4175337 Vali Loss: 0.2076390 Test Loss: 0.2852156
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.3038214
	speed: 0.0701s/iter; left time: 1125.7109s
	iters: 200, epoch: 40 | loss: 0.3496686
	speed: 0.0136s/iter; left time: 217.6072s
Epoch: 40 cost time: 4.053260326385498
Epoch: 40, Steps: 265 | Train Loss: 0.4168339 Vali Loss: 0.2076800 Test Loss: 0.2852063
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3936706
	speed: 0.0686s/iter; left time: 1083.6183s
	iters: 200, epoch: 41 | loss: 0.4696658
	speed: 0.0140s/iter; left time: 219.5287s
Epoch: 41 cost time: 4.151196479797363
Epoch: 41, Steps: 265 | Train Loss: 0.4175861 Vali Loss: 0.2078064 Test Loss: 0.2852006
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.5696085
	speed: 0.0699s/iter; left time: 1086.2810s
	iters: 200, epoch: 42 | loss: 0.3995450
	speed: 0.0129s/iter; left time: 199.3570s
Epoch: 42 cost time: 4.024203538894653
Epoch: 42, Steps: 265 | Train Loss: 0.4172013 Vali Loss: 0.2077023 Test Loss: 0.2851961
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2890658
	speed: 0.0685s/iter; left time: 1045.9760s
	iters: 200, epoch: 43 | loss: 0.3590541
	speed: 0.0132s/iter; left time: 199.7968s
Epoch: 43 cost time: 4.027490854263306
Epoch: 43, Steps: 265 | Train Loss: 0.4171033 Vali Loss: 0.2077759 Test Loss: 0.2851904
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.3114978
	speed: 0.0681s/iter; left time: 1021.6094s
	iters: 200, epoch: 44 | loss: 0.4724482
	speed: 0.0131s/iter; left time: 195.0263s
Epoch: 44 cost time: 4.023029804229736
Epoch: 44, Steps: 265 | Train Loss: 0.4171377 Vali Loss: 0.2077161 Test Loss: 0.2851906
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2509973
	speed: 0.0700s/iter; left time: 1032.3455s
	iters: 200, epoch: 45 | loss: 0.3029985
	speed: 0.0134s/iter; left time: 196.0061s
Epoch: 45 cost time: 4.109745979309082
Epoch: 45, Steps: 265 | Train Loss: 0.4158419 Vali Loss: 0.2077889 Test Loss: 0.2851693
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.3329275
	speed: 0.0808s/iter; left time: 1169.6936s
	iters: 200, epoch: 46 | loss: 0.5475733
	speed: 0.0137s/iter; left time: 197.0226s
Epoch: 46 cost time: 4.229128122329712
Epoch: 46, Steps: 265 | Train Loss: 0.4173684 Vali Loss: 0.2077748 Test Loss: 0.2851647
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.3176035
	speed: 0.0716s/iter; left time: 1016.9493s
	iters: 200, epoch: 47 | loss: 0.4460540
	speed: 0.0139s/iter; left time: 196.0322s
Epoch: 47 cost time: 4.283085823059082
Epoch: 47, Steps: 265 | Train Loss: 0.4177701 Vali Loss: 0.2079374 Test Loss: 0.2851680
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2539541
	speed: 0.0703s/iter; left time: 980.8563s
	iters: 200, epoch: 48 | loss: 0.2784248
	speed: 0.0138s/iter; left time: 190.9984s
Epoch: 48 cost time: 4.142542123794556
Epoch: 48, Steps: 265 | Train Loss: 0.4165853 Vali Loss: 0.2077305 Test Loss: 0.2851602
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.4093941
	speed: 0.0693s/iter; left time: 947.9685s
	iters: 200, epoch: 49 | loss: 0.3727229
	speed: 0.0129s/iter; left time: 175.7013s
Epoch: 49 cost time: 4.044847726821899
Epoch: 49, Steps: 265 | Train Loss: 0.4176328 Vali Loss: 0.2077366 Test Loss: 0.2851493
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.3157495
	speed: 0.0693s/iter; left time: 929.0902s
	iters: 200, epoch: 50 | loss: 0.4541948
	speed: 0.0134s/iter; left time: 178.4300s
Epoch: 50 cost time: 4.003783941268921
Epoch: 50, Steps: 265 | Train Loss: 0.4172758 Vali Loss: 0.2076834 Test Loss: 0.2851401
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2743171
	speed: 0.0720s/iter; left time: 947.3881s
	iters: 200, epoch: 51 | loss: 0.3324268
	speed: 0.0136s/iter; left time: 177.4773s
Epoch: 51 cost time: 4.152418851852417
Epoch: 51, Steps: 265 | Train Loss: 0.4167334 Vali Loss: 0.2076832 Test Loss: 0.2851491
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.5003669
	speed: 0.0690s/iter; left time: 888.5285s
	iters: 200, epoch: 52 | loss: 0.4002202
	speed: 0.0136s/iter; left time: 173.9908s
Epoch: 52 cost time: 4.003490447998047
Epoch: 52, Steps: 265 | Train Loss: 0.4169016 Vali Loss: 0.2078072 Test Loss: 0.2851401
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.3582419
	speed: 0.0692s/iter; left time: 873.9747s
	iters: 200, epoch: 53 | loss: 0.5407135
	speed: 0.0143s/iter; left time: 179.4435s
Epoch: 53 cost time: 4.777153253555298
Epoch: 53, Steps: 265 | Train Loss: 0.4176004 Vali Loss: 0.2077922 Test Loss: 0.2851319
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.4093556
	speed: 0.0774s/iter; left time: 956.6300s
	iters: 200, epoch: 54 | loss: 0.4869626
	speed: 0.0133s/iter; left time: 163.0891s
Epoch: 54 cost time: 4.105871915817261
Epoch: 54, Steps: 265 | Train Loss: 0.4174341 Vali Loss: 0.2075739 Test Loss: 0.2851278
Validation loss decreased (0.207575 --> 0.207574).  Saving model ...
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2870141
	speed: 0.0683s/iter; left time: 825.4486s
	iters: 200, epoch: 55 | loss: 0.6513539
	speed: 0.0135s/iter; left time: 161.5539s
Epoch: 55 cost time: 4.009801864624023
Epoch: 55, Steps: 265 | Train Loss: 0.4172034 Vali Loss: 0.2078602 Test Loss: 0.2851261
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.3382883
	speed: 0.0688s/iter; left time: 813.2740s
	iters: 200, epoch: 56 | loss: 0.4402311
	speed: 0.0137s/iter; left time: 160.1056s
Epoch: 56 cost time: 4.071782350540161
Epoch: 56, Steps: 265 | Train Loss: 0.4170224 Vali Loss: 0.2076597 Test Loss: 0.2851272
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2707521
	speed: 0.0696s/iter; left time: 804.4972s
	iters: 200, epoch: 57 | loss: 0.3176232
	speed: 0.0136s/iter; left time: 156.1259s
Epoch: 57 cost time: 4.15967583656311
Epoch: 57, Steps: 265 | Train Loss: 0.4169525 Vali Loss: 0.2076560 Test Loss: 0.2851266
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.4882439
	speed: 0.0704s/iter; left time: 795.3629s
	iters: 200, epoch: 58 | loss: 0.3828857
	speed: 0.0140s/iter; left time: 156.5013s
Epoch: 58 cost time: 4.266026735305786
Epoch: 58, Steps: 265 | Train Loss: 0.4174075 Vali Loss: 0.2077443 Test Loss: 0.2851219
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.5373653
	speed: 0.0698s/iter; left time: 770.2755s
	iters: 200, epoch: 59 | loss: 0.4446757
	speed: 0.0141s/iter; left time: 154.0133s
Epoch: 59 cost time: 4.1891984939575195
Epoch: 59, Steps: 265 | Train Loss: 0.4171982 Vali Loss: 0.2077530 Test Loss: 0.2851190
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.5107557
	speed: 0.0691s/iter; left time: 744.3808s
	iters: 200, epoch: 60 | loss: 0.4588408
	speed: 0.0141s/iter; left time: 149.9223s
Epoch: 60 cost time: 4.234732389450073
Epoch: 60, Steps: 265 | Train Loss: 0.4174879 Vali Loss: 0.2076677 Test Loss: 0.2851203
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.4547355
	speed: 0.0702s/iter; left time: 737.3067s
	iters: 200, epoch: 61 | loss: 0.2453077
	speed: 0.0132s/iter; left time: 137.0166s
Epoch: 61 cost time: 4.173455715179443
Epoch: 61, Steps: 265 | Train Loss: 0.4173028 Vali Loss: 0.2076528 Test Loss: 0.2851168
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.5485998
	speed: 0.0701s/iter; left time: 717.1173s
	iters: 200, epoch: 62 | loss: 0.3993728
	speed: 0.0151s/iter; left time: 152.8076s
Epoch: 62 cost time: 4.369925022125244
Epoch: 62, Steps: 265 | Train Loss: 0.4174563 Vali Loss: 0.2078163 Test Loss: 0.2851148
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.5255636
	speed: 0.0747s/iter; left time: 744.9299s
	iters: 200, epoch: 63 | loss: 0.6921645
	speed: 0.0153s/iter; left time: 151.5005s
Epoch: 63 cost time: 4.668689727783203
Epoch: 63, Steps: 265 | Train Loss: 0.4171734 Vali Loss: 0.2075771 Test Loss: 0.2851132
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.3855845
	speed: 0.0716s/iter; left time: 694.6122s
	iters: 200, epoch: 64 | loss: 0.4177861
	speed: 0.0135s/iter; left time: 129.4020s
Epoch: 64 cost time: 4.070680141448975
Epoch: 64, Steps: 265 | Train Loss: 0.4175050 Vali Loss: 0.2078670 Test Loss: 0.2851109
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.3325433
	speed: 0.0672s/iter; left time: 633.9879s
	iters: 200, epoch: 65 | loss: 0.3562913
	speed: 0.0130s/iter; left time: 121.0087s
Epoch: 65 cost time: 3.9257051944732666
Epoch: 65, Steps: 265 | Train Loss: 0.4173503 Vali Loss: 0.2076923 Test Loss: 0.2851113
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.4252559
	speed: 0.0684s/iter; left time: 627.2639s
	iters: 200, epoch: 66 | loss: 0.5402896
	speed: 0.0134s/iter; left time: 121.8299s
Epoch: 66 cost time: 4.096758842468262
Epoch: 66, Steps: 265 | Train Loss: 0.4174384 Vali Loss: 0.2076913 Test Loss: 0.2851083
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.2265292
	speed: 0.0685s/iter; left time: 610.6221s
	iters: 200, epoch: 67 | loss: 0.3934815
	speed: 0.0141s/iter; left time: 124.2789s
Epoch: 67 cost time: 4.126718759536743
Epoch: 67, Steps: 265 | Train Loss: 0.4164329 Vali Loss: 0.2078269 Test Loss: 0.2851073
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.3166108
	speed: 0.0692s/iter; left time: 598.5569s
	iters: 200, epoch: 68 | loss: 0.4812287
	speed: 0.0145s/iter; left time: 123.9233s
Epoch: 68 cost time: 4.301128149032593
Epoch: 68, Steps: 265 | Train Loss: 0.4174255 Vali Loss: 0.2075892 Test Loss: 0.2851057
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.3770572
	speed: 0.0852s/iter; left time: 713.9129s
	iters: 200, epoch: 69 | loss: 0.4464821
	speed: 0.0133s/iter; left time: 110.4383s
Epoch: 69 cost time: 5.499515056610107
Epoch: 69, Steps: 265 | Train Loss: 0.4176791 Vali Loss: 0.2077374 Test Loss: 0.2851030
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.3902275
	speed: 0.0727s/iter; left time: 590.1006s
	iters: 200, epoch: 70 | loss: 0.3219848
	speed: 0.0170s/iter; left time: 135.9145s
Epoch: 70 cost time: 4.708448886871338
Epoch: 70, Steps: 265 | Train Loss: 0.4172561 Vali Loss: 0.2076939 Test Loss: 0.2851021
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.2434650
	speed: 0.0709s/iter; left time: 556.3841s
	iters: 200, epoch: 71 | loss: 0.2623002
	speed: 0.0131s/iter; left time: 101.2094s
Epoch: 71 cost time: 4.001354932785034
Epoch: 71, Steps: 265 | Train Loss: 0.4169088 Vali Loss: 0.2077521 Test Loss: 0.2851020
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.3168675
	speed: 0.0671s/iter; left time: 508.7374s
	iters: 200, epoch: 72 | loss: 0.5139743
	speed: 0.0134s/iter; left time: 100.4639s
Epoch: 72 cost time: 4.004820108413696
Epoch: 72, Steps: 265 | Train Loss: 0.4168006 Vali Loss: 0.2077254 Test Loss: 0.2850977
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.3271281
	speed: 0.0703s/iter; left time: 514.3816s
	iters: 200, epoch: 73 | loss: 0.3495788
	speed: 0.0198s/iter; left time: 143.0696s
Epoch: 73 cost time: 5.368400573730469
Epoch: 73, Steps: 265 | Train Loss: 0.4175120 Vali Loss: 0.2077638 Test Loss: 0.2850979
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.3780299
	speed: 0.0729s/iter; left time: 514.5896s
	iters: 200, epoch: 74 | loss: 0.3203630
	speed: 0.0132s/iter; left time: 91.6175s
Epoch: 74 cost time: 3.9432952404022217
Epoch: 74, Steps: 265 | Train Loss: 0.4173656 Vali Loss: 0.2076271 Test Loss: 0.2850991
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_180_336_FITS_ETTm2_ftM_sl180_ll48_pl336_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.28638699650764465, mae:0.331924706697464, rse:0.43225228786468506, corr:[0.55755174 0.56053597 0.55874056 0.5553286  0.55281883 0.5517988
 0.5518282  0.5519488  0.5515758  0.55067414 0.54954374 0.54864407
 0.5481629  0.5479529  0.5478244  0.5474819  0.546774   0.545786
 0.5447307  0.5438366  0.54323846 0.5429002  0.5426638  0.5423931
 0.5419798  0.54139566 0.5407559  0.54013914 0.53958136 0.5390623
 0.5385766  0.53813004 0.5376638  0.53716224 0.53659886 0.536025
 0.5354059  0.5347946  0.53417516 0.5335653  0.53302026 0.5325681
 0.5321905  0.53183186 0.53140587 0.530896   0.5302652  0.5295229
 0.52868706 0.5278091  0.5269555  0.52623796 0.52563584 0.5250854
 0.52457386 0.5241332  0.5237001  0.5233199  0.52298695 0.52271754
 0.52245414 0.5222484  0.52210027 0.52191734 0.52171034 0.5215201
 0.52134615 0.5212087  0.52110857 0.5210555  0.5209774  0.52085733
 0.5207108  0.520498   0.5202748  0.5200144  0.51973027 0.51938176
 0.5189935  0.5185853  0.51816076 0.5177299  0.51733    0.5169382
 0.5165487  0.5161327  0.51567745 0.5152624  0.5149027  0.51458645
 0.514289   0.513925   0.51336205 0.51248354 0.5112331  0.50961494
 0.50775445 0.5059662  0.50435424 0.5029034  0.50155175 0.5002506
 0.49895862 0.49766406 0.49637228 0.4951336  0.49401012 0.4930032
 0.49202675 0.49087954 0.48967293 0.4884354  0.4872848  0.48627082
 0.4853309  0.4844625  0.4836035  0.4826654  0.4816388  0.48049837
 0.47935572 0.47833648 0.47749695 0.47678295 0.4760871  0.47529837
 0.47435415 0.47328773 0.4721935  0.47116625 0.47029102 0.46953967
 0.46888438 0.46821642 0.4675783  0.4669846  0.46640804 0.465892
 0.4654024  0.4649055  0.4643592  0.46373686 0.46304533 0.4622503
 0.4613644  0.4604364  0.45950317 0.4586764  0.45803142 0.45748866
 0.45702595 0.4566802  0.45631278 0.45588896 0.45540583 0.45488033
 0.45435813 0.45389807 0.45345694 0.45307806 0.45278993 0.452566
 0.45242938 0.45227242 0.45219645 0.4521701  0.45215505 0.45217776
 0.4522298  0.45234263 0.452476   0.45258135 0.4526639  0.45262575
 0.4525186  0.45235378 0.45219633 0.45204946 0.45190403 0.45176426
 0.4515496  0.45123568 0.45093364 0.45067465 0.45050701 0.45035654
 0.45017296 0.44989523 0.44941044 0.4486327  0.4475091  0.446091
 0.44453233 0.44306365 0.44169474 0.44039974 0.43921787 0.43807167
 0.43690753 0.4357288  0.43456888 0.43358162 0.43276304 0.43212286
 0.43154588 0.4309284  0.4301952  0.42939568 0.4286265  0.42793247
 0.42729145 0.42667663 0.42605266 0.42540064 0.42473048 0.4240025
 0.42324114 0.4223579  0.4214784  0.4206012  0.41968334 0.4187879
 0.41790426 0.41707957 0.41639915 0.41568947 0.41494069 0.41414455
 0.41326147 0.4123666  0.41150093 0.4107932  0.41022974 0.40982145
 0.4094642  0.40912738 0.4088346  0.40848577 0.40812862 0.40771928
 0.40725192 0.40672168 0.40618622 0.40580097 0.40558448 0.40548623
 0.40548503 0.40554705 0.40568504 0.40585497 0.40608191 0.40634573
 0.4065529  0.40676886 0.40692878 0.40697744 0.40693927 0.4069156
 0.40693727 0.4069552  0.40694183 0.40694606 0.4069387  0.4068825
 0.4068421  0.4068694  0.40698424 0.40711486 0.40721548 0.4072364
 0.40707332 0.4068192  0.4065317  0.4063745  0.40637445 0.4064889
 0.40659645 0.4065699  0.406442   0.40627867 0.4060905  0.40604022
 0.40611407 0.4061566  0.4060272  0.40561774 0.40487292 0.40382525
 0.40259784 0.40154216 0.40062782 0.39990947 0.3992765  0.3986478
 0.3980799  0.3974772  0.39687046 0.39629617 0.39588878 0.39554754
 0.39518046 0.39455906 0.39376974 0.3929029  0.3920233  0.39122322
 0.39056548 0.38995257 0.38924384 0.38840568 0.38746744 0.3865747
 0.38574654 0.38505593 0.38438845 0.38369778 0.38283008 0.38181984
 0.38073295 0.37970236 0.37881404 0.3780572  0.37732908 0.37652582
 0.37563902 0.37472087 0.3739871  0.3735395  0.37329212 0.37308407
 0.3728262  0.3723958  0.3719645  0.37190685 0.3727203  0.3740227 ]
