Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=20, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_90_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_90_192_FITS_ETTm2_ftM_sl90_ll48_pl192_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34279
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=20, out_features=62, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1111040.0
params:  1302.0
Trainable parameters:  1302
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5988896
	speed: 0.0168s/iter; left time: 446.8952s
	iters: 200, epoch: 1 | loss: 0.2644235
	speed: 0.0106s/iter; left time: 280.6576s
Epoch: 1 cost time: 3.4703965187072754
Epoch: 1, Steps: 267 | Train Loss: 0.4065104 Vali Loss: 0.1865605 Test Loss: 0.2662577
Validation loss decreased (inf --> 0.186561).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4072249
	speed: 0.0611s/iter; left time: 1609.9793s
	iters: 200, epoch: 2 | loss: 0.3740465
	speed: 0.0164s/iter; left time: 431.2919s
Epoch: 2 cost time: 4.207134485244751
Epoch: 2, Steps: 267 | Train Loss: 0.3528975 Vali Loss: 0.1756474 Test Loss: 0.2527381
Validation loss decreased (0.186561 --> 0.175647).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3354687
	speed: 0.0594s/iter; left time: 1548.1773s
	iters: 200, epoch: 3 | loss: 0.3736865
	speed: 0.0100s/iter; left time: 259.5774s
Epoch: 3 cost time: 3.171842336654663
Epoch: 3, Steps: 267 | Train Loss: 0.3449657 Vali Loss: 0.1736727 Test Loss: 0.2501649
Validation loss decreased (0.175647 --> 0.173673).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3879522
	speed: 0.0605s/iter; left time: 1561.4700s
	iters: 200, epoch: 4 | loss: 0.4809452
	speed: 0.0100s/iter; left time: 256.3058s
Epoch: 4 cost time: 3.473271131515503
Epoch: 4, Steps: 267 | Train Loss: 0.3419661 Vali Loss: 0.1729315 Test Loss: 0.2490450
Validation loss decreased (0.173673 --> 0.172932).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3680484
	speed: 0.0584s/iter; left time: 1491.9193s
	iters: 200, epoch: 5 | loss: 0.2798090
	speed: 0.0104s/iter; left time: 264.0117s
Epoch: 5 cost time: 3.329000234603882
Epoch: 5, Steps: 267 | Train Loss: 0.3404302 Vali Loss: 0.1729386 Test Loss: 0.2485578
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2843679
	speed: 0.0599s/iter; left time: 1514.0283s
	iters: 200, epoch: 6 | loss: 0.4331819
	speed: 0.0100s/iter; left time: 252.9119s
Epoch: 6 cost time: 3.3242087364196777
Epoch: 6, Steps: 267 | Train Loss: 0.3391709 Vali Loss: 0.1727166 Test Loss: 0.2482745
Validation loss decreased (0.172932 --> 0.172717).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2992713
	speed: 0.0590s/iter; left time: 1474.1494s
	iters: 200, epoch: 7 | loss: 0.3508941
	speed: 0.0100s/iter; left time: 248.1467s
Epoch: 7 cost time: 3.2351250648498535
Epoch: 7, Steps: 267 | Train Loss: 0.3386042 Vali Loss: 0.1727134 Test Loss: 0.2480811
Validation loss decreased (0.172717 --> 0.172713).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4003661
	speed: 0.0592s/iter; left time: 1463.0936s
	iters: 200, epoch: 8 | loss: 0.3156175
	speed: 0.0098s/iter; left time: 242.2471s
Epoch: 8 cost time: 3.170927047729492
Epoch: 8, Steps: 267 | Train Loss: 0.3384331 Vali Loss: 0.1729192 Test Loss: 0.2481666
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4082754
	speed: 0.0576s/iter; left time: 1409.0293s
	iters: 200, epoch: 9 | loss: 0.3454804
	speed: 0.0101s/iter; left time: 245.9894s
Epoch: 9 cost time: 3.2157042026519775
Epoch: 9, Steps: 267 | Train Loss: 0.3374034 Vali Loss: 0.1727128 Test Loss: 0.2480884
Validation loss decreased (0.172713 --> 0.172713).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3114761
	speed: 0.0590s/iter; left time: 1426.5656s
	iters: 200, epoch: 10 | loss: 0.2365856
	speed: 0.0100s/iter; left time: 240.6958s
Epoch: 10 cost time: 3.311440944671631
Epoch: 10, Steps: 267 | Train Loss: 0.3377620 Vali Loss: 0.1729351 Test Loss: 0.2479507
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3416119
	speed: 0.0588s/iter; left time: 1406.3612s
	iters: 200, epoch: 11 | loss: 0.4780016
	speed: 0.0100s/iter; left time: 239.1940s
Epoch: 11 cost time: 3.2332961559295654
Epoch: 11, Steps: 267 | Train Loss: 0.3375439 Vali Loss: 0.1729379 Test Loss: 0.2480368
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3801255
	speed: 0.0621s/iter; left time: 1468.5343s
	iters: 200, epoch: 12 | loss: 0.3581398
	speed: 0.0101s/iter; left time: 237.4103s
Epoch: 12 cost time: 3.4359021186828613
Epoch: 12, Steps: 267 | Train Loss: 0.3372944 Vali Loss: 0.1728233 Test Loss: 0.2479354
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3295220
	speed: 0.0610s/iter; left time: 1426.4475s
	iters: 200, epoch: 13 | loss: 0.4162988
	speed: 0.0102s/iter; left time: 238.2137s
Epoch: 13 cost time: 3.2685279846191406
Epoch: 13, Steps: 267 | Train Loss: 0.3374432 Vali Loss: 0.1729822 Test Loss: 0.2479638
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2890982
	speed: 0.0582s/iter; left time: 1345.9517s
	iters: 200, epoch: 14 | loss: 0.2201812
	speed: 0.0100s/iter; left time: 230.4330s
Epoch: 14 cost time: 3.191873788833618
Epoch: 14, Steps: 267 | Train Loss: 0.3368478 Vali Loss: 0.1729357 Test Loss: 0.2479498
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4116844
	speed: 0.0565s/iter; left time: 1291.9222s
	iters: 200, epoch: 15 | loss: 0.2991077
	speed: 0.0099s/iter; left time: 224.2436s
Epoch: 15 cost time: 3.2170250415802
Epoch: 15, Steps: 267 | Train Loss: 0.3370817 Vali Loss: 0.1729196 Test Loss: 0.2478770
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4102953
	speed: 0.0586s/iter; left time: 1324.7850s
	iters: 200, epoch: 16 | loss: 0.2504827
	speed: 0.0103s/iter; left time: 232.5793s
Epoch: 16 cost time: 3.3335931301116943
Epoch: 16, Steps: 267 | Train Loss: 0.3368941 Vali Loss: 0.1730079 Test Loss: 0.2479525
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3274123
	speed: 0.0580s/iter; left time: 1295.0640s
	iters: 200, epoch: 17 | loss: 0.2327041
	speed: 0.0101s/iter; left time: 223.9571s
Epoch: 17 cost time: 3.2115345001220703
Epoch: 17, Steps: 267 | Train Loss: 0.3369081 Vali Loss: 0.1732681 Test Loss: 0.2479279
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4436126
	speed: 0.0594s/iter; left time: 1310.2992s
	iters: 200, epoch: 18 | loss: 0.3156137
	speed: 0.0106s/iter; left time: 231.9198s
Epoch: 18 cost time: 3.306018352508545
Epoch: 18, Steps: 267 | Train Loss: 0.3370378 Vali Loss: 0.1731697 Test Loss: 0.2479616
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3888284
	speed: 0.0590s/iter; left time: 1286.6288s
	iters: 200, epoch: 19 | loss: 0.2847685
	speed: 0.0100s/iter; left time: 217.3710s
Epoch: 19 cost time: 3.285285234451294
Epoch: 19, Steps: 267 | Train Loss: 0.3359329 Vali Loss: 0.1730242 Test Loss: 0.2479691
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4040762
	speed: 0.0621s/iter; left time: 1336.5154s
	iters: 200, epoch: 20 | loss: 0.4876298
	speed: 0.0102s/iter; left time: 217.7286s
Epoch: 20 cost time: 3.4010257720947266
Epoch: 20, Steps: 267 | Train Loss: 0.3366475 Vali Loss: 0.1731445 Test Loss: 0.2479820
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2417094
	speed: 0.0607s/iter; left time: 1291.5262s
	iters: 200, epoch: 21 | loss: 0.2826840
	speed: 0.0098s/iter; left time: 208.4284s
Epoch: 21 cost time: 3.283156394958496
Epoch: 21, Steps: 267 | Train Loss: 0.3369196 Vali Loss: 0.1732410 Test Loss: 0.2479746
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4577930
	speed: 0.0582s/iter; left time: 1222.5601s
	iters: 200, epoch: 22 | loss: 0.3200419
	speed: 0.0099s/iter; left time: 206.2907s
Epoch: 22 cost time: 3.282083749771118
Epoch: 22, Steps: 267 | Train Loss: 0.3364135 Vali Loss: 0.1731652 Test Loss: 0.2480049
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3803388
	speed: 0.0575s/iter; left time: 1190.8897s
	iters: 200, epoch: 23 | loss: 0.3197426
	speed: 0.0101s/iter; left time: 208.5970s
Epoch: 23 cost time: 3.230092763900757
Epoch: 23, Steps: 267 | Train Loss: 0.3369658 Vali Loss: 0.1731369 Test Loss: 0.2479609
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4086617
	speed: 0.0595s/iter; left time: 1216.8399s
	iters: 200, epoch: 24 | loss: 0.4421978
	speed: 0.0101s/iter; left time: 205.1436s
Epoch: 24 cost time: 3.335543394088745
Epoch: 24, Steps: 267 | Train Loss: 0.3366303 Vali Loss: 0.1731119 Test Loss: 0.2479524
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3030314
	speed: 0.0582s/iter; left time: 1175.4183s
	iters: 200, epoch: 25 | loss: 0.3371296
	speed: 0.0102s/iter; left time: 205.5336s
Epoch: 25 cost time: 3.3021440505981445
Epoch: 25, Steps: 267 | Train Loss: 0.3363579 Vali Loss: 0.1731174 Test Loss: 0.2479761
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2334569
	speed: 0.0589s/iter; left time: 1172.9944s
	iters: 200, epoch: 26 | loss: 0.2127666
	speed: 0.0100s/iter; left time: 198.0923s
Epoch: 26 cost time: 3.1613211631774902
Epoch: 26, Steps: 267 | Train Loss: 0.3362205 Vali Loss: 0.1733466 Test Loss: 0.2480025
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3583318
	speed: 0.0595s/iter; left time: 1170.6030s
	iters: 200, epoch: 27 | loss: 0.3179262
	speed: 0.0100s/iter; left time: 195.0901s
Epoch: 27 cost time: 3.3357784748077393
Epoch: 27, Steps: 267 | Train Loss: 0.3367841 Vali Loss: 0.1731059 Test Loss: 0.2479754
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2786732
	speed: 0.0574s/iter; left time: 1113.3803s
	iters: 200, epoch: 28 | loss: 0.2650107
	speed: 0.0100s/iter; left time: 192.0802s
Epoch: 28 cost time: 3.1915829181671143
Epoch: 28, Steps: 267 | Train Loss: 0.3366880 Vali Loss: 0.1733177 Test Loss: 0.2479813
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3308218
	speed: 0.0580s/iter; left time: 1109.1049s
	iters: 200, epoch: 29 | loss: 0.3560821
	speed: 0.0099s/iter; left time: 188.1992s
Epoch: 29 cost time: 3.203651189804077
Epoch: 29, Steps: 267 | Train Loss: 0.3361188 Vali Loss: 0.1732952 Test Loss: 0.2479669
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_90_192_FITS_ETTm2_ftM_sl90_ll48_pl192_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.24891886115074158, mae:0.30690017342567444, rse:0.4038536548614502, corr:[0.5663623  0.56914765 0.5608892  0.55764824 0.55906105 0.55803037
 0.5544009  0.55260986 0.55345803 0.5534291  0.5513913  0.54957354
 0.5498284  0.5504079  0.5492511  0.5472127  0.54648995 0.54687566
 0.54634666 0.54439443 0.5426137  0.54234135 0.5425082  0.5417953
 0.540533   0.54002327 0.5403705  0.5402724  0.5392148  0.5380842
 0.5376945  0.53753465 0.53684247 0.5358135  0.5352379  0.5352103
 0.5348197  0.5337879  0.53269845 0.53212607 0.53183365 0.5313948
 0.53078896 0.53041834 0.53037953 0.5301215  0.52939296 0.5284123
 0.5276327  0.52701014 0.52619076 0.5252362  0.5244929  0.5240522
 0.5236944  0.5230951  0.52231747 0.5218451  0.52174324 0.5217192
 0.5214139  0.52103156 0.52097607 0.5212094  0.5213537  0.52118564
 0.5209146  0.5207705  0.520775   0.5207949  0.5207485  0.5207481
 0.52078205 0.52086383 0.5208613  0.5207104  0.52051556 0.5203424
 0.5202402  0.5201147  0.5198638  0.51946867 0.5191375  0.5189461
 0.5187954  0.51853216 0.5180921  0.51771533 0.5175098  0.51736885
 0.51707417 0.51655614 0.515942   0.5152605  0.51417696 0.51242924
 0.51029897 0.5082806  0.50645447 0.50458914 0.50279665 0.5014229
 0.5004705  0.4994327  0.49798697 0.4963976  0.49499688 0.49390867
 0.49288082 0.49166125 0.49032328 0.4890247  0.4879056  0.48676717
 0.48548645 0.4841374  0.48288128 0.48178658 0.48076597 0.47965685
 0.47861204 0.47772655 0.47691277 0.47602618 0.4749541  0.47381872
 0.47281748 0.47194427 0.47099337 0.46991995 0.4689344  0.46806207
 0.46724677 0.4663682  0.46546018 0.4648954  0.4644852  0.46419948
 0.46384907 0.46353662 0.46335632 0.46309337 0.46255794 0.46180353
 0.46104944 0.4603444  0.45936182 0.45816883 0.45715687 0.45655447
 0.45615673 0.45562094 0.4547282  0.45386374 0.45353076 0.45345974
 0.45291695 0.45215118 0.4517257  0.4520002  0.45218107 0.45163622
 0.450985   0.4508155  0.45123446 0.45123434 0.45059362 0.45022187
 0.45081976 0.45164934 0.45153338 0.4507026  0.45054647 0.45144644
 0.4521062  0.45168474 0.45097208 0.45132023 0.45232219 0.45261806
 0.45199546 0.45172718 0.4526479  0.45330933 0.45270014 0.4518719
 0.4524572  0.45380405 0.4541412  0.45383507 0.45489252 0.45406702]
