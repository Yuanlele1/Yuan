Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=122, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=1919, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_720_720_FITS_ETTm2_ftM_sl720_ll48_pl720_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=122, out_features=244, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  26672128.0
params:  30012.0
Trainable parameters:  30012
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3727796
	speed: 0.0233s/iter; left time: 600.0853s
	iters: 200, epoch: 1 | loss: 0.3158963
	speed: 0.0167s/iter; left time: 427.2233s
Epoch: 1 cost time: 4.964679956436157
Epoch: 1, Steps: 258 | Train Loss: 0.4271971 Vali Loss: 0.2947395 Test Loss: 0.3915899
Validation loss decreased (inf --> 0.294739).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3273691
	speed: 0.0695s/iter; left time: 1768.6217s
	iters: 200, epoch: 2 | loss: 0.2786762
	speed: 0.0162s/iter; left time: 410.9830s
Epoch: 2 cost time: 4.62931227684021
Epoch: 2, Steps: 258 | Train Loss: 0.3179566 Vali Loss: 0.2797893 Test Loss: 0.3752337
Validation loss decreased (0.294739 --> 0.279789).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3694464
	speed: 0.0683s/iter; left time: 1719.2338s
	iters: 200, epoch: 3 | loss: 0.3094995
	speed: 0.0166s/iter; left time: 415.8535s
Epoch: 3 cost time: 4.680223703384399
Epoch: 3, Steps: 258 | Train Loss: 0.2878478 Vali Loss: 0.2738865 Test Loss: 0.3676356
Validation loss decreased (0.279789 --> 0.273886).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2729681
	speed: 0.0706s/iter; left time: 1760.2979s
	iters: 200, epoch: 4 | loss: 0.2551459
	speed: 0.0163s/iter; left time: 403.5136s
Epoch: 4 cost time: 4.67436408996582
Epoch: 4, Steps: 258 | Train Loss: 0.2730001 Vali Loss: 0.2700441 Test Loss: 0.3628904
Validation loss decreased (0.273886 --> 0.270044).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2488830
	speed: 0.0694s/iter; left time: 1712.1709s
	iters: 200, epoch: 5 | loss: 0.2580757
	speed: 0.0164s/iter; left time: 403.7142s
Epoch: 5 cost time: 4.687124013900757
Epoch: 5, Steps: 258 | Train Loss: 0.2654136 Vali Loss: 0.2676337 Test Loss: 0.3601014
Validation loss decreased (0.270044 --> 0.267634).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2321544
	speed: 0.0705s/iter; left time: 1720.3076s
	iters: 200, epoch: 6 | loss: 0.2476634
	speed: 0.0167s/iter; left time: 405.6033s
Epoch: 6 cost time: 4.781829357147217
Epoch: 6, Steps: 258 | Train Loss: 0.2609328 Vali Loss: 0.2657641 Test Loss: 0.3580922
Validation loss decreased (0.267634 --> 0.265764).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2360263
	speed: 0.0712s/iter; left time: 1718.7424s
	iters: 200, epoch: 7 | loss: 0.3233252
	speed: 0.0167s/iter; left time: 402.1759s
Epoch: 7 cost time: 4.75285530090332
Epoch: 7, Steps: 258 | Train Loss: 0.2586433 Vali Loss: 0.2649604 Test Loss: 0.3567712
Validation loss decreased (0.265764 --> 0.264960).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1951307
	speed: 0.0690s/iter; left time: 1647.8610s
	iters: 200, epoch: 8 | loss: 0.2508192
	speed: 0.0163s/iter; left time: 388.2672s
Epoch: 8 cost time: 4.76239800453186
Epoch: 8, Steps: 258 | Train Loss: 0.2573702 Vali Loss: 0.2640014 Test Loss: 0.3559829
Validation loss decreased (0.264960 --> 0.264001).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1826480
	speed: 0.0702s/iter; left time: 1659.3016s
	iters: 200, epoch: 9 | loss: 0.2656715
	speed: 0.0166s/iter; left time: 391.4730s
Epoch: 9 cost time: 4.68182110786438
Epoch: 9, Steps: 258 | Train Loss: 0.2562192 Vali Loss: 0.2640646 Test Loss: 0.3553293
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3579478
	speed: 0.0706s/iter; left time: 1651.3321s
	iters: 200, epoch: 10 | loss: 0.2834881
	speed: 0.0163s/iter; left time: 379.8195s
Epoch: 10 cost time: 4.796372890472412
Epoch: 10, Steps: 258 | Train Loss: 0.2556777 Vali Loss: 0.2632411 Test Loss: 0.3552436
Validation loss decreased (0.264001 --> 0.263241).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2025357
	speed: 0.0691s/iter; left time: 1598.5159s
	iters: 200, epoch: 11 | loss: 0.3184380
	speed: 0.0167s/iter; left time: 384.9260s
Epoch: 11 cost time: 4.738587141036987
Epoch: 11, Steps: 258 | Train Loss: 0.2558357 Vali Loss: 0.2635919 Test Loss: 0.3546650
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2756139
	speed: 0.0692s/iter; left time: 1583.0327s
	iters: 200, epoch: 12 | loss: 0.2626539
	speed: 0.0165s/iter; left time: 374.7641s
Epoch: 12 cost time: 4.680755376815796
Epoch: 12, Steps: 258 | Train Loss: 0.2555656 Vali Loss: 0.2632092 Test Loss: 0.3547073
Validation loss decreased (0.263241 --> 0.263209).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2395593
	speed: 0.0700s/iter; left time: 1581.7022s
	iters: 200, epoch: 13 | loss: 0.2759568
	speed: 0.0163s/iter; left time: 366.6503s
Epoch: 13 cost time: 4.773267984390259
Epoch: 13, Steps: 258 | Train Loss: 0.2555268 Vali Loss: 0.2633292 Test Loss: 0.3545736
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2292449
	speed: 0.0693s/iter; left time: 1549.5160s
	iters: 200, epoch: 14 | loss: 0.2612771
	speed: 0.0162s/iter; left time: 359.8687s
Epoch: 14 cost time: 4.685002088546753
Epoch: 14, Steps: 258 | Train Loss: 0.2554071 Vali Loss: 0.2628881 Test Loss: 0.3545183
Validation loss decreased (0.263209 --> 0.262888).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1633188
	speed: 0.0701s/iter; left time: 1548.0920s
	iters: 200, epoch: 15 | loss: 0.2025729
	speed: 0.0164s/iter; left time: 360.8371s
Epoch: 15 cost time: 4.731252908706665
Epoch: 15, Steps: 258 | Train Loss: 0.2553595 Vali Loss: 0.2629798 Test Loss: 0.3544859
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2659692
	speed: 0.0689s/iter; left time: 1503.6757s
	iters: 200, epoch: 16 | loss: 0.2771981
	speed: 0.0161s/iter; left time: 350.2295s
Epoch: 16 cost time: 4.666842699050903
Epoch: 16, Steps: 258 | Train Loss: 0.2550502 Vali Loss: 0.2629958 Test Loss: 0.3543507
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2817633
	speed: 0.0702s/iter; left time: 1514.1427s
	iters: 200, epoch: 17 | loss: 0.2112739
	speed: 0.0165s/iter; left time: 354.7954s
Epoch: 17 cost time: 4.762965440750122
Epoch: 17, Steps: 258 | Train Loss: 0.2551399 Vali Loss: 0.2629583 Test Loss: 0.3542298
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2306626
	speed: 0.0702s/iter; left time: 1497.1154s
	iters: 200, epoch: 18 | loss: 0.2598229
	speed: 0.0167s/iter; left time: 353.7059s
Epoch: 18 cost time: 4.691163539886475
Epoch: 18, Steps: 258 | Train Loss: 0.2548506 Vali Loss: 0.2628675 Test Loss: 0.3542491
Validation loss decreased (0.262888 --> 0.262868).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2565945
	speed: 0.0704s/iter; left time: 1481.7065s
	iters: 200, epoch: 19 | loss: 0.2009090
	speed: 0.0167s/iter; left time: 349.5201s
Epoch: 19 cost time: 4.799102544784546
Epoch: 19, Steps: 258 | Train Loss: 0.2547674 Vali Loss: 0.2625197 Test Loss: 0.3542804
Validation loss decreased (0.262868 --> 0.262520).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1911507
	speed: 0.0696s/iter; left time: 1447.6319s
	iters: 200, epoch: 20 | loss: 0.2565311
	speed: 0.0166s/iter; left time: 342.7407s
Epoch: 20 cost time: 4.753065586090088
Epoch: 20, Steps: 258 | Train Loss: 0.2549481 Vali Loss: 0.2626922 Test Loss: 0.3540229
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2387300
	speed: 0.0703s/iter; left time: 1444.5664s
	iters: 200, epoch: 21 | loss: 0.2983750
	speed: 0.0165s/iter; left time: 337.6335s
Epoch: 21 cost time: 4.7179975509643555
Epoch: 21, Steps: 258 | Train Loss: 0.2550991 Vali Loss: 0.2627611 Test Loss: 0.3541921
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2332383
	speed: 0.0699s/iter; left time: 1417.2468s
	iters: 200, epoch: 22 | loss: 0.2742877
	speed: 0.0166s/iter; left time: 334.6497s
Epoch: 22 cost time: 4.769088983535767
Epoch: 22, Steps: 258 | Train Loss: 0.2552334 Vali Loss: 0.2625685 Test Loss: 0.3541372
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2674645
	speed: 0.0690s/iter; left time: 1382.0339s
	iters: 200, epoch: 23 | loss: 0.2400891
	speed: 0.0165s/iter; left time: 328.6458s
Epoch: 23 cost time: 4.7100207805633545
Epoch: 23, Steps: 258 | Train Loss: 0.2549862 Vali Loss: 0.2627333 Test Loss: 0.3541574
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2325260
	speed: 0.0701s/iter; left time: 1385.1996s
	iters: 200, epoch: 24 | loss: 0.3184818
	speed: 0.0168s/iter; left time: 331.1364s
Epoch: 24 cost time: 4.809563875198364
Epoch: 24, Steps: 258 | Train Loss: 0.2547024 Vali Loss: 0.2628272 Test Loss: 0.3540324
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2357078
	speed: 0.0696s/iter; left time: 1356.8873s
	iters: 200, epoch: 25 | loss: 0.2766536
	speed: 0.0168s/iter; left time: 325.9553s
Epoch: 25 cost time: 4.8887856006622314
Epoch: 25, Steps: 258 | Train Loss: 0.2547751 Vali Loss: 0.2629240 Test Loss: 0.3540527
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2447419
	speed: 0.0713s/iter; left time: 1373.5373s
	iters: 200, epoch: 26 | loss: 0.2847992
	speed: 0.0165s/iter; left time: 316.6343s
Epoch: 26 cost time: 4.764757394790649
Epoch: 26, Steps: 258 | Train Loss: 0.2550743 Vali Loss: 0.2627073 Test Loss: 0.3540426
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3352478
	speed: 0.0712s/iter; left time: 1353.1733s
	iters: 200, epoch: 27 | loss: 0.2128185
	speed: 0.0167s/iter; left time: 315.5543s
Epoch: 27 cost time: 4.857806921005249
Epoch: 27, Steps: 258 | Train Loss: 0.2550551 Vali Loss: 0.2626208 Test Loss: 0.3540457
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2042258
	speed: 0.0704s/iter; left time: 1318.5036s
	iters: 200, epoch: 28 | loss: 0.3041656
	speed: 0.0168s/iter; left time: 313.0535s
Epoch: 28 cost time: 4.809037208557129
Epoch: 28, Steps: 258 | Train Loss: 0.2548930 Vali Loss: 0.2626123 Test Loss: 0.3541091
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2964247
	speed: 0.0712s/iter; left time: 1315.0078s
	iters: 200, epoch: 29 | loss: 0.3372581
	speed: 0.0168s/iter; left time: 309.1665s
Epoch: 29 cost time: 4.849678993225098
Epoch: 29, Steps: 258 | Train Loss: 0.2545733 Vali Loss: 0.2624801 Test Loss: 0.3539676
Validation loss decreased (0.262520 --> 0.262480).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2722355
	speed: 0.0699s/iter; left time: 1273.8790s
	iters: 200, epoch: 30 | loss: 0.2163345
	speed: 0.0168s/iter; left time: 305.3023s
Epoch: 30 cost time: 4.748621702194214
Epoch: 30, Steps: 258 | Train Loss: 0.2549067 Vali Loss: 0.2629725 Test Loss: 0.3539190
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2727636
	speed: 0.0707s/iter; left time: 1269.1307s
	iters: 200, epoch: 31 | loss: 0.2939814
	speed: 0.0166s/iter; left time: 296.2171s
Epoch: 31 cost time: 4.848492383956909
Epoch: 31, Steps: 258 | Train Loss: 0.2548790 Vali Loss: 0.2626536 Test Loss: 0.3539514
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1988382
	speed: 0.0685s/iter; left time: 1212.7375s
	iters: 200, epoch: 32 | loss: 0.3042994
	speed: 0.0168s/iter; left time: 295.8812s
Epoch: 32 cost time: 4.750441074371338
Epoch: 32, Steps: 258 | Train Loss: 0.2550006 Vali Loss: 0.2626402 Test Loss: 0.3540020
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2832679
	speed: 0.0706s/iter; left time: 1231.6219s
	iters: 200, epoch: 33 | loss: 0.2778680
	speed: 0.0168s/iter; left time: 292.0721s
Epoch: 33 cost time: 4.770509958267212
Epoch: 33, Steps: 258 | Train Loss: 0.2547834 Vali Loss: 0.2624937 Test Loss: 0.3540318
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1961901
	speed: 0.0713s/iter; left time: 1224.5984s
	iters: 200, epoch: 34 | loss: 0.2771158
	speed: 0.0165s/iter; left time: 282.1763s
Epoch: 34 cost time: 4.8072545528411865
Epoch: 34, Steps: 258 | Train Loss: 0.2544058 Vali Loss: 0.2624716 Test Loss: 0.3539509
Validation loss decreased (0.262480 --> 0.262472).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2192373
	speed: 0.0712s/iter; left time: 1205.1832s
	iters: 200, epoch: 35 | loss: 0.2441393
	speed: 0.0165s/iter; left time: 278.1318s
Epoch: 35 cost time: 4.7618865966796875
Epoch: 35, Steps: 258 | Train Loss: 0.2547022 Vali Loss: 0.2628028 Test Loss: 0.3539469
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2491134
	speed: 0.0695s/iter; left time: 1158.9481s
	iters: 200, epoch: 36 | loss: 0.2229019
	speed: 0.0165s/iter; left time: 272.9100s
Epoch: 36 cost time: 4.715777397155762
Epoch: 36, Steps: 258 | Train Loss: 0.2544671 Vali Loss: 0.2629157 Test Loss: 0.3539363
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2113773
	speed: 0.0687s/iter; left time: 1127.2806s
	iters: 200, epoch: 37 | loss: 0.2333872
	speed: 0.0165s/iter; left time: 268.6534s
Epoch: 37 cost time: 4.718449831008911
Epoch: 37, Steps: 258 | Train Loss: 0.2548622 Vali Loss: 0.2623508 Test Loss: 0.3539537
Validation loss decreased (0.262472 --> 0.262351).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2746269
	speed: 0.0702s/iter; left time: 1134.8523s
	iters: 200, epoch: 38 | loss: 0.1560311
	speed: 0.0168s/iter; left time: 269.0690s
Epoch: 38 cost time: 4.772248029708862
Epoch: 38, Steps: 258 | Train Loss: 0.2548863 Vali Loss: 0.2627946 Test Loss: 0.3539398
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2199309
	speed: 0.0691s/iter; left time: 1098.0004s
	iters: 200, epoch: 39 | loss: 0.2527484
	speed: 0.0168s/iter; left time: 265.0952s
Epoch: 39 cost time: 4.716804265975952
Epoch: 39, Steps: 258 | Train Loss: 0.2550031 Vali Loss: 0.2624559 Test Loss: 0.3539400
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2207678
	speed: 0.0685s/iter; left time: 1071.0334s
	iters: 200, epoch: 40 | loss: 0.2493316
	speed: 0.0168s/iter; left time: 261.5174s
Epoch: 40 cost time: 4.6629478931427
Epoch: 40, Steps: 258 | Train Loss: 0.2548652 Vali Loss: 0.2627486 Test Loss: 0.3539275
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2345775
	speed: 0.0692s/iter; left time: 1064.2734s
	iters: 200, epoch: 41 | loss: 0.1845222
	speed: 0.0163s/iter; left time: 248.3696s
Epoch: 41 cost time: 4.735980033874512
Epoch: 41, Steps: 258 | Train Loss: 0.2545856 Vali Loss: 0.2627311 Test Loss: 0.3539353
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2398711
	speed: 0.0702s/iter; left time: 1060.9511s
	iters: 200, epoch: 42 | loss: 0.2260563
	speed: 0.0168s/iter; left time: 252.6516s
Epoch: 42 cost time: 4.8017189502716064
Epoch: 42, Steps: 258 | Train Loss: 0.2547682 Vali Loss: 0.2625128 Test Loss: 0.3539287
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2608182
	speed: 0.0707s/iter; left time: 1051.5494s
	iters: 200, epoch: 43 | loss: 0.2624105
	speed: 0.0163s/iter; left time: 240.9783s
Epoch: 43 cost time: 4.715816020965576
Epoch: 43, Steps: 258 | Train Loss: 0.2549203 Vali Loss: 0.2626173 Test Loss: 0.3539028
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2538123
	speed: 0.0703s/iter; left time: 1027.5821s
	iters: 200, epoch: 44 | loss: 0.2573565
	speed: 0.0167s/iter; left time: 242.6340s
Epoch: 44 cost time: 4.7680370807647705
Epoch: 44, Steps: 258 | Train Loss: 0.2546608 Vali Loss: 0.2623114 Test Loss: 0.3539037
Validation loss decreased (0.262351 --> 0.262311).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1990853
	speed: 0.0700s/iter; left time: 1004.5955s
	iters: 200, epoch: 45 | loss: 0.2139480
	speed: 0.0165s/iter; left time: 235.7484s
Epoch: 45 cost time: 4.770751714706421
Epoch: 45, Steps: 258 | Train Loss: 0.2547977 Vali Loss: 0.2625689 Test Loss: 0.3539143
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.3324558
	speed: 0.0708s/iter; left time: 997.2525s
	iters: 200, epoch: 46 | loss: 0.2946805
	speed: 0.0166s/iter; left time: 231.6810s
Epoch: 46 cost time: 4.775559663772583
Epoch: 46, Steps: 258 | Train Loss: 0.2547890 Vali Loss: 0.2623534 Test Loss: 0.3539277
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.3244933
	speed: 0.0716s/iter; left time: 990.2628s
	iters: 200, epoch: 47 | loss: 0.2093054
	speed: 0.0170s/iter; left time: 233.5496s
Epoch: 47 cost time: 4.85403847694397
Epoch: 47, Steps: 258 | Train Loss: 0.2549063 Vali Loss: 0.2625766 Test Loss: 0.3539083
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1746935
	speed: 0.0703s/iter; left time: 953.8919s
	iters: 200, epoch: 48 | loss: 0.1990269
	speed: 0.0170s/iter; left time: 229.3484s
Epoch: 48 cost time: 4.852743148803711
Epoch: 48, Steps: 258 | Train Loss: 0.2547096 Vali Loss: 0.2625739 Test Loss: 0.3538981
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2114120
	speed: 0.0712s/iter; left time: 948.8173s
	iters: 200, epoch: 49 | loss: 0.2036650
	speed: 0.0168s/iter; left time: 222.1021s
Epoch: 49 cost time: 4.755834579467773
Epoch: 49, Steps: 258 | Train Loss: 0.2544908 Vali Loss: 0.2625564 Test Loss: 0.3539044
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2460420
	speed: 0.0705s/iter; left time: 920.4423s
	iters: 200, epoch: 50 | loss: 0.1857488
	speed: 0.0166s/iter; left time: 215.3870s
Epoch: 50 cost time: 4.736559867858887
Epoch: 50, Steps: 258 | Train Loss: 0.2546952 Vali Loss: 0.2624231 Test Loss: 0.3539104
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2651115
	speed: 0.0704s/iter; left time: 901.6986s
	iters: 200, epoch: 51 | loss: 0.2520285
	speed: 0.0169s/iter; left time: 214.3114s
Epoch: 51 cost time: 4.797654628753662
Epoch: 51, Steps: 258 | Train Loss: 0.2547520 Vali Loss: 0.2622736 Test Loss: 0.3539044
Validation loss decreased (0.262311 --> 0.262274).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2203928
	speed: 0.0696s/iter; left time: 873.4801s
	iters: 200, epoch: 52 | loss: 0.2394586
	speed: 0.0165s/iter; left time: 205.6370s
Epoch: 52 cost time: 4.698086500167847
Epoch: 52, Steps: 258 | Train Loss: 0.2544672 Vali Loss: 0.2625253 Test Loss: 0.3538896
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2564950
	speed: 0.0704s/iter; left time: 864.8709s
	iters: 200, epoch: 53 | loss: 0.2625259
	speed: 0.0167s/iter; left time: 204.0411s
Epoch: 53 cost time: 4.815730810165405
Epoch: 53, Steps: 258 | Train Loss: 0.2546355 Vali Loss: 0.2626508 Test Loss: 0.3538907
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2391424
	speed: 0.0708s/iter; left time: 851.4195s
	iters: 200, epoch: 54 | loss: 0.2639825
	speed: 0.0169s/iter; left time: 201.6035s
Epoch: 54 cost time: 4.79095983505249
Epoch: 54, Steps: 258 | Train Loss: 0.2550395 Vali Loss: 0.2624230 Test Loss: 0.3538952
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2568609
	speed: 0.0707s/iter; left time: 832.0941s
	iters: 200, epoch: 55 | loss: 0.2284292
	speed: 0.0168s/iter; left time: 196.3185s
Epoch: 55 cost time: 4.785701274871826
Epoch: 55, Steps: 258 | Train Loss: 0.2545268 Vali Loss: 0.2624969 Test Loss: 0.3538955
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2194174
	speed: 0.0709s/iter; left time: 816.5631s
	iters: 200, epoch: 56 | loss: 0.2345564
	speed: 0.0168s/iter; left time: 191.2512s
Epoch: 56 cost time: 4.854028940200806
Epoch: 56, Steps: 258 | Train Loss: 0.2546375 Vali Loss: 0.2625688 Test Loss: 0.3538911
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2207909
	speed: 0.0713s/iter; left time: 802.7171s
	iters: 200, epoch: 57 | loss: 0.2812700
	speed: 0.0169s/iter; left time: 188.9745s
Epoch: 57 cost time: 4.928640365600586
Epoch: 57, Steps: 258 | Train Loss: 0.2546411 Vali Loss: 0.2623351 Test Loss: 0.3538879
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2495406
	speed: 0.0709s/iter; left time: 779.9675s
	iters: 200, epoch: 58 | loss: 0.2766439
	speed: 0.0166s/iter; left time: 180.3365s
Epoch: 58 cost time: 4.782384634017944
Epoch: 58, Steps: 258 | Train Loss: 0.2545775 Vali Loss: 0.2622300 Test Loss: 0.3538759
Validation loss decreased (0.262274 --> 0.262230).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2068470
	speed: 0.0707s/iter; left time: 758.5967s
	iters: 200, epoch: 59 | loss: 0.2577139
	speed: 0.0165s/iter; left time: 175.6244s
Epoch: 59 cost time: 4.748985767364502
Epoch: 59, Steps: 258 | Train Loss: 0.2544454 Vali Loss: 0.2624114 Test Loss: 0.3538965
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.2292604
	speed: 0.0698s/iter; left time: 731.8818s
	iters: 200, epoch: 60 | loss: 0.2974591
	speed: 0.0166s/iter; left time: 172.1768s
Epoch: 60 cost time: 4.731226921081543
Epoch: 60, Steps: 258 | Train Loss: 0.2546457 Vali Loss: 0.2624048 Test Loss: 0.3538900
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1943900
	speed: 0.0714s/iter; left time: 729.9103s
	iters: 200, epoch: 61 | loss: 0.2241412
	speed: 0.0165s/iter; left time: 166.9877s
Epoch: 61 cost time: 4.759814023971558
Epoch: 61, Steps: 258 | Train Loss: 0.2547647 Vali Loss: 0.2625183 Test Loss: 0.3538966
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.2776976
	speed: 0.0699s/iter; left time: 696.1080s
	iters: 200, epoch: 62 | loss: 0.2869252
	speed: 0.0167s/iter; left time: 164.4615s
Epoch: 62 cost time: 4.724427938461304
Epoch: 62, Steps: 258 | Train Loss: 0.2548247 Vali Loss: 0.2621905 Test Loss: 0.3538781
Validation loss decreased (0.262230 --> 0.262190).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.2822116
	speed: 0.0713s/iter; left time: 691.7954s
	iters: 200, epoch: 63 | loss: 0.2343499
	speed: 0.0166s/iter; left time: 159.6565s
Epoch: 63 cost time: 4.756350994110107
Epoch: 63, Steps: 258 | Train Loss: 0.2547549 Vali Loss: 0.2624985 Test Loss: 0.3538900
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.2516449
	speed: 0.0701s/iter; left time: 662.4616s
	iters: 200, epoch: 64 | loss: 0.2675920
	speed: 0.0169s/iter; left time: 158.1509s
Epoch: 64 cost time: 4.802572011947632
Epoch: 64, Steps: 258 | Train Loss: 0.2546083 Vali Loss: 0.2627186 Test Loss: 0.3538807
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.3286381
	speed: 0.0698s/iter; left time: 641.0477s
	iters: 200, epoch: 65 | loss: 0.2691156
	speed: 0.0166s/iter; left time: 150.7299s
Epoch: 65 cost time: 4.69222617149353
Epoch: 65, Steps: 258 | Train Loss: 0.2548771 Vali Loss: 0.2625908 Test Loss: 0.3538788
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.2197762
	speed: 0.0693s/iter; left time: 618.6768s
	iters: 200, epoch: 66 | loss: 0.2339658
	speed: 0.0167s/iter; left time: 147.4568s
Epoch: 66 cost time: 4.757175445556641
Epoch: 66, Steps: 258 | Train Loss: 0.2547109 Vali Loss: 0.2621931 Test Loss: 0.3538792
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.2218015
	speed: 0.0712s/iter; left time: 617.3300s
	iters: 200, epoch: 67 | loss: 0.3081940
	speed: 0.0166s/iter; left time: 142.1255s
Epoch: 67 cost time: 4.813052654266357
Epoch: 67, Steps: 258 | Train Loss: 0.2550129 Vali Loss: 0.2623899 Test Loss: 0.3538865
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.3159637
	speed: 0.0706s/iter; left time: 594.4028s
	iters: 200, epoch: 68 | loss: 0.2914290
	speed: 0.0165s/iter; left time: 137.3483s
Epoch: 68 cost time: 4.799659013748169
Epoch: 68, Steps: 258 | Train Loss: 0.2548468 Vali Loss: 0.2624431 Test Loss: 0.3538795
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.2455102
	speed: 0.0706s/iter; left time: 575.6648s
	iters: 200, epoch: 69 | loss: 0.2626730
	speed: 0.0165s/iter; left time: 132.7733s
Epoch: 69 cost time: 4.751289129257202
Epoch: 69, Steps: 258 | Train Loss: 0.2545909 Vali Loss: 0.2624969 Test Loss: 0.3538831
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.3024951
	speed: 0.0690s/iter; left time: 545.3532s
	iters: 200, epoch: 70 | loss: 0.2780088
	speed: 0.0168s/iter; left time: 131.2987s
Epoch: 70 cost time: 4.760613918304443
Epoch: 70, Steps: 258 | Train Loss: 0.2548456 Vali Loss: 0.2626760 Test Loss: 0.3538757
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.2100613
	speed: 0.0707s/iter; left time: 540.2835s
	iters: 200, epoch: 71 | loss: 0.3384272
	speed: 0.0169s/iter; left time: 127.0667s
Epoch: 71 cost time: 4.754090309143066
Epoch: 71, Steps: 258 | Train Loss: 0.2548886 Vali Loss: 0.2624292 Test Loss: 0.3538752
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.2861606
	speed: 0.0722s/iter; left time: 533.0669s
	iters: 200, epoch: 72 | loss: 0.2859046
	speed: 0.0166s/iter; left time: 121.0381s
Epoch: 72 cost time: 4.84734582901001
Epoch: 72, Steps: 258 | Train Loss: 0.2546471 Vali Loss: 0.2622616 Test Loss: 0.3538736
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.2987536
	speed: 0.0717s/iter; left time: 511.1383s
	iters: 200, epoch: 73 | loss: 0.2629316
	speed: 0.0167s/iter; left time: 117.5393s
Epoch: 73 cost time: 4.852154731750488
Epoch: 73, Steps: 258 | Train Loss: 0.2543132 Vali Loss: 0.2624527 Test Loss: 0.3538734
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.2931108
	speed: 0.0713s/iter; left time: 489.9020s
	iters: 200, epoch: 74 | loss: 0.2455768
	speed: 0.0170s/iter; left time: 114.8581s
Epoch: 74 cost time: 4.760520935058594
Epoch: 74, Steps: 258 | Train Loss: 0.2548958 Vali Loss: 0.2626698 Test Loss: 0.3538738
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.2020888
	speed: 0.0696s/iter; left time: 460.1558s
	iters: 200, epoch: 75 | loss: 0.2458515
	speed: 0.0173s/iter; left time: 112.5420s
Epoch: 75 cost time: 4.863830804824829
Epoch: 75, Steps: 258 | Train Loss: 0.2547430 Vali Loss: 0.2624335 Test Loss: 0.3538771
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.3329680
	speed: 0.0702s/iter; left time: 445.6735s
	iters: 200, epoch: 76 | loss: 0.2638127
	speed: 0.0170s/iter; left time: 106.1316s
Epoch: 76 cost time: 4.744565963745117
Epoch: 76, Steps: 258 | Train Loss: 0.2546497 Vali Loss: 0.2626548 Test Loss: 0.3538723
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.2779433
	speed: 0.0699s/iter; left time: 425.6139s
	iters: 200, epoch: 77 | loss: 0.2594541
	speed: 0.0167s/iter; left time: 99.9681s
Epoch: 77 cost time: 4.7734901905059814
Epoch: 77, Steps: 258 | Train Loss: 0.2545699 Vali Loss: 0.2628016 Test Loss: 0.3538730
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.2767945
	speed: 0.0713s/iter; left time: 416.1974s
	iters: 200, epoch: 78 | loss: 0.2499062
	speed: 0.0169s/iter; left time: 96.8372s
Epoch: 78 cost time: 4.914018154144287
Epoch: 78, Steps: 258 | Train Loss: 0.2548540 Vali Loss: 0.2624815 Test Loss: 0.3538754
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.2651963
	speed: 0.0718s/iter; left time: 400.2921s
	iters: 200, epoch: 79 | loss: 0.3294832
	speed: 0.0168s/iter; left time: 92.0512s
Epoch: 79 cost time: 4.801249265670776
Epoch: 79, Steps: 258 | Train Loss: 0.2546318 Vali Loss: 0.2624141 Test Loss: 0.3538707
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.2359934
	speed: 0.0708s/iter; left time: 376.3898s
	iters: 200, epoch: 80 | loss: 0.2659014
	speed: 0.0172s/iter; left time: 89.6258s
Epoch: 80 cost time: 4.927142858505249
Epoch: 80, Steps: 258 | Train Loss: 0.2544856 Vali Loss: 0.2626939 Test Loss: 0.3538662
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.1687682
	speed: 0.0725s/iter; left time: 367.1358s
	iters: 200, epoch: 81 | loss: 0.2555548
	speed: 0.0170s/iter; left time: 84.3061s
Epoch: 81 cost time: 4.886132717132568
Epoch: 81, Steps: 258 | Train Loss: 0.2546735 Vali Loss: 0.2624568 Test Loss: 0.3538688
EarlyStopping counter: 19 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.1791208
	speed: 0.0714s/iter; left time: 343.1517s
	iters: 200, epoch: 82 | loss: 0.3147405
	speed: 0.0164s/iter; left time: 77.1734s
Epoch: 82 cost time: 4.7575297355651855
Epoch: 82, Steps: 258 | Train Loss: 0.2548317 Vali Loss: 0.2624739 Test Loss: 0.3538675
EarlyStopping counter: 20 out of 20
Early stopping
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=122, out_features=244, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  26672128.0
params:  30012.0
Trainable parameters:  30012
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4281746
	speed: 0.0222s/iter; left time: 571.7462s
	iters: 200, epoch: 1 | loss: 0.5656847
	speed: 0.0166s/iter; left time: 426.1039s
Epoch: 1 cost time: 4.827432155609131
Epoch: 1, Steps: 258 | Train Loss: 0.4966191 Vali Loss: 0.2616347 Test Loss: 0.3534790
Validation loss decreased (inf --> 0.261635).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3797931
	speed: 0.0697s/iter; left time: 1774.5789s
	iters: 200, epoch: 2 | loss: 0.5321340
	speed: 0.0166s/iter; left time: 419.6819s
Epoch: 2 cost time: 4.7387800216674805
Epoch: 2, Steps: 258 | Train Loss: 0.4956857 Vali Loss: 0.2608790 Test Loss: 0.3530508
Validation loss decreased (0.261635 --> 0.260879).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5209590
	speed: 0.0704s/iter; left time: 1773.4146s
	iters: 200, epoch: 3 | loss: 0.5674715
	speed: 0.0165s/iter; left time: 414.0047s
Epoch: 3 cost time: 4.778547286987305
Epoch: 3, Steps: 258 | Train Loss: 0.4953629 Vali Loss: 0.2603760 Test Loss: 0.3529205
Validation loss decreased (0.260879 --> 0.260376).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.6115423
	speed: 0.0692s/iter; left time: 1723.8110s
	iters: 200, epoch: 4 | loss: 0.5649007
	speed: 0.0168s/iter; left time: 417.7517s
Epoch: 4 cost time: 4.69429612159729
Epoch: 4, Steps: 258 | Train Loss: 0.4944890 Vali Loss: 0.2604053 Test Loss: 0.3526254
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4259579
	speed: 0.0687s/iter; left time: 1694.5877s
	iters: 200, epoch: 5 | loss: 0.7278510
	speed: 0.0162s/iter; left time: 397.5020s
Epoch: 5 cost time: 4.62839674949646
Epoch: 5, Steps: 258 | Train Loss: 0.4944437 Vali Loss: 0.2607008 Test Loss: 0.3524107
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.5186820
	speed: 0.0702s/iter; left time: 1712.8088s
	iters: 200, epoch: 6 | loss: 0.4176326
	speed: 0.0165s/iter; left time: 401.5409s
Epoch: 6 cost time: 4.695860147476196
Epoch: 6, Steps: 258 | Train Loss: 0.4940172 Vali Loss: 0.2603616 Test Loss: 0.3526836
Validation loss decreased (0.260376 --> 0.260362).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3549683
	speed: 0.0690s/iter; left time: 1666.6855s
	iters: 200, epoch: 7 | loss: 0.4894507
	speed: 0.0168s/iter; left time: 404.3201s
Epoch: 7 cost time: 4.74772834777832
Epoch: 7, Steps: 258 | Train Loss: 0.4939170 Vali Loss: 0.2604126 Test Loss: 0.3523984
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4492302
	speed: 0.0705s/iter; left time: 1683.8004s
	iters: 200, epoch: 8 | loss: 0.6103016
	speed: 0.0166s/iter; left time: 396.0972s
Epoch: 8 cost time: 4.769770383834839
Epoch: 8, Steps: 258 | Train Loss: 0.4940466 Vali Loss: 0.2597796 Test Loss: 0.3522990
Validation loss decreased (0.260362 --> 0.259780).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4481999
	speed: 0.0695s/iter; left time: 1642.2170s
	iters: 200, epoch: 9 | loss: 0.5789190
	speed: 0.0163s/iter; left time: 384.7428s
Epoch: 9 cost time: 4.737097263336182
Epoch: 9, Steps: 258 | Train Loss: 0.4941761 Vali Loss: 0.2601863 Test Loss: 0.3522306
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4545238
	speed: 0.0706s/iter; left time: 1651.1318s
	iters: 200, epoch: 10 | loss: 0.3474701
	speed: 0.0163s/iter; left time: 379.9306s
Epoch: 10 cost time: 4.726332664489746
Epoch: 10, Steps: 258 | Train Loss: 0.4934481 Vali Loss: 0.2603170 Test Loss: 0.3520386
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3670442
	speed: 0.0697s/iter; left time: 1611.4118s
	iters: 200, epoch: 11 | loss: 0.5147804
	speed: 0.0164s/iter; left time: 378.1317s
Epoch: 11 cost time: 4.73904013633728
Epoch: 11, Steps: 258 | Train Loss: 0.4941286 Vali Loss: 0.2597723 Test Loss: 0.3523489
Validation loss decreased (0.259780 --> 0.259772).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4182496
	speed: 0.0708s/iter; left time: 1618.4847s
	iters: 200, epoch: 12 | loss: 0.4791017
	speed: 0.0164s/iter; left time: 373.2709s
Epoch: 12 cost time: 4.79994010925293
Epoch: 12, Steps: 258 | Train Loss: 0.4933500 Vali Loss: 0.2601214 Test Loss: 0.3521639
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4027837
	speed: 0.0697s/iter; left time: 1576.2000s
	iters: 200, epoch: 13 | loss: 0.4977639
	speed: 0.0167s/iter; left time: 375.2666s
Epoch: 13 cost time: 4.771879434585571
Epoch: 13, Steps: 258 | Train Loss: 0.4932574 Vali Loss: 0.2601731 Test Loss: 0.3520554
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4510250
	speed: 0.0702s/iter; left time: 1567.8547s
	iters: 200, epoch: 14 | loss: 0.6735191
	speed: 0.0170s/iter; left time: 377.4368s
Epoch: 14 cost time: 4.783812046051025
Epoch: 14, Steps: 258 | Train Loss: 0.4935739 Vali Loss: 0.2599334 Test Loss: 0.3521672
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4103420
	speed: 0.0700s/iter; left time: 1545.3456s
	iters: 200, epoch: 15 | loss: 0.3625064
	speed: 0.0168s/iter; left time: 369.5839s
Epoch: 15 cost time: 4.703369855880737
Epoch: 15, Steps: 258 | Train Loss: 0.4938988 Vali Loss: 0.2600265 Test Loss: 0.3521188
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4849365
	speed: 0.0703s/iter; left time: 1534.0262s
	iters: 200, epoch: 16 | loss: 0.5376718
	speed: 0.0166s/iter; left time: 360.5088s
Epoch: 16 cost time: 4.688442230224609
Epoch: 16, Steps: 258 | Train Loss: 0.4938270 Vali Loss: 0.2603285 Test Loss: 0.3520005
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.5113738
	speed: 0.0693s/iter; left time: 1495.8296s
	iters: 200, epoch: 17 | loss: 0.4854315
	speed: 0.0165s/iter; left time: 355.0778s
Epoch: 17 cost time: 4.7349183559417725
Epoch: 17, Steps: 258 | Train Loss: 0.4931000 Vali Loss: 0.2598318 Test Loss: 0.3520091
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4186658
	speed: 0.0691s/iter; left time: 1471.9491s
	iters: 200, epoch: 18 | loss: 0.6385265
	speed: 0.0168s/iter; left time: 356.3421s
Epoch: 18 cost time: 4.757140159606934
Epoch: 18, Steps: 258 | Train Loss: 0.4936484 Vali Loss: 0.2598082 Test Loss: 0.3519981
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.5248877
	speed: 0.0699s/iter; left time: 1471.6460s
	iters: 200, epoch: 19 | loss: 0.3715652
	speed: 0.0164s/iter; left time: 344.4235s
Epoch: 19 cost time: 4.76767635345459
Epoch: 19, Steps: 258 | Train Loss: 0.4936372 Vali Loss: 0.2599220 Test Loss: 0.3520631
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.5268217
	speed: 0.0694s/iter; left time: 1443.3498s
	iters: 200, epoch: 20 | loss: 0.5283459
	speed: 0.0165s/iter; left time: 342.1524s
Epoch: 20 cost time: 4.724445104598999
Epoch: 20, Steps: 258 | Train Loss: 0.4930251 Vali Loss: 0.2598194 Test Loss: 0.3521248
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.6174079
	speed: 0.0714s/iter; left time: 1466.6202s
	iters: 200, epoch: 21 | loss: 0.5398980
	speed: 0.0169s/iter; left time: 345.7676s
Epoch: 21 cost time: 4.818955898284912
Epoch: 21, Steps: 258 | Train Loss: 0.4935195 Vali Loss: 0.2599539 Test Loss: 0.3519478
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.6351078
	speed: 0.0704s/iter; left time: 1427.8943s
	iters: 200, epoch: 22 | loss: 0.5194035
	speed: 0.0167s/iter; left time: 337.6014s
Epoch: 22 cost time: 4.782506704330444
Epoch: 22, Steps: 258 | Train Loss: 0.4935109 Vali Loss: 0.2598084 Test Loss: 0.3519743
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.6952066
	speed: 0.0698s/iter; left time: 1398.5199s
	iters: 200, epoch: 23 | loss: 0.4219087
	speed: 0.0167s/iter; left time: 333.0596s
Epoch: 23 cost time: 4.865186452865601
Epoch: 23, Steps: 258 | Train Loss: 0.4930602 Vali Loss: 0.2597967 Test Loss: 0.3520031
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3758708
	speed: 0.0704s/iter; left time: 1391.7476s
	iters: 200, epoch: 24 | loss: 0.5752812
	speed: 0.0164s/iter; left time: 323.2248s
Epoch: 24 cost time: 4.836680173873901
Epoch: 24, Steps: 258 | Train Loss: 0.4934198 Vali Loss: 0.2598698 Test Loss: 0.3519912
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4258445
	speed: 0.0690s/iter; left time: 1345.2343s
	iters: 200, epoch: 25 | loss: 0.4787202
	speed: 0.0165s/iter; left time: 320.9663s
Epoch: 25 cost time: 4.65265417098999
Epoch: 25, Steps: 258 | Train Loss: 0.4936237 Vali Loss: 0.2599106 Test Loss: 0.3520728
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.7098941
	speed: 0.0699s/iter; left time: 1344.9805s
	iters: 200, epoch: 26 | loss: 0.5448877
	speed: 0.0168s/iter; left time: 320.9338s
Epoch: 26 cost time: 4.82095193862915
Epoch: 26, Steps: 258 | Train Loss: 0.4929743 Vali Loss: 0.2597385 Test Loss: 0.3520409
Validation loss decreased (0.259772 --> 0.259738).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.5445127
	speed: 0.0699s/iter; left time: 1327.1225s
	iters: 200, epoch: 27 | loss: 0.5329002
	speed: 0.0170s/iter; left time: 321.2897s
Epoch: 27 cost time: 4.850492715835571
Epoch: 27, Steps: 258 | Train Loss: 0.4934558 Vali Loss: 0.2595545 Test Loss: 0.3519145
Validation loss decreased (0.259738 --> 0.259555).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4413485
	speed: 0.0690s/iter; left time: 1292.0382s
	iters: 200, epoch: 28 | loss: 0.5899943
	speed: 0.0167s/iter; left time: 312.0433s
Epoch: 28 cost time: 4.78003454208374
Epoch: 28, Steps: 258 | Train Loss: 0.4934485 Vali Loss: 0.2599213 Test Loss: 0.3519377
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.5217081
	speed: 0.0701s/iter; left time: 1295.3618s
	iters: 200, epoch: 29 | loss: 0.4512641
	speed: 0.0165s/iter; left time: 303.2996s
Epoch: 29 cost time: 4.80303692817688
Epoch: 29, Steps: 258 | Train Loss: 0.4932873 Vali Loss: 0.2598555 Test Loss: 0.3519855
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.5969015
	speed: 0.0695s/iter; left time: 1265.8331s
	iters: 200, epoch: 30 | loss: 0.5572824
	speed: 0.0164s/iter; left time: 297.0821s
Epoch: 30 cost time: 4.7153236865997314
Epoch: 30, Steps: 258 | Train Loss: 0.4927073 Vali Loss: 0.2600170 Test Loss: 0.3519796
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3537097
	speed: 0.0695s/iter; left time: 1247.6035s
	iters: 200, epoch: 31 | loss: 0.5643422
	speed: 0.0171s/iter; left time: 305.8997s
Epoch: 31 cost time: 4.790550708770752
Epoch: 31, Steps: 258 | Train Loss: 0.4928832 Vali Loss: 0.2596965 Test Loss: 0.3519653
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4296857
	speed: 0.0701s/iter; left time: 1240.4609s
	iters: 200, epoch: 32 | loss: 0.4191715
	speed: 0.0167s/iter; left time: 294.7461s
Epoch: 32 cost time: 4.8272082805633545
Epoch: 32, Steps: 258 | Train Loss: 0.4929311 Vali Loss: 0.2598811 Test Loss: 0.3519825
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4801458
	speed: 0.0698s/iter; left time: 1218.4060s
	iters: 200, epoch: 33 | loss: 0.3911951
	speed: 0.0167s/iter; left time: 289.6777s
Epoch: 33 cost time: 4.78607439994812
Epoch: 33, Steps: 258 | Train Loss: 0.4929678 Vali Loss: 0.2599126 Test Loss: 0.3519220
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3835496
	speed: 0.0692s/iter; left time: 1189.6139s
	iters: 200, epoch: 34 | loss: 0.4027667
	speed: 0.0165s/iter; left time: 281.6258s
Epoch: 34 cost time: 4.730362415313721
Epoch: 34, Steps: 258 | Train Loss: 0.4930102 Vali Loss: 0.2598926 Test Loss: 0.3519222
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.5617173
	speed: 0.0702s/iter; left time: 1188.9736s
	iters: 200, epoch: 35 | loss: 0.5278224
	speed: 0.0168s/iter; left time: 283.0657s
Epoch: 35 cost time: 4.7694923877716064
Epoch: 35, Steps: 258 | Train Loss: 0.4931665 Vali Loss: 0.2597403 Test Loss: 0.3519378
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3212752
	speed: 0.0702s/iter; left time: 1170.7775s
	iters: 200, epoch: 36 | loss: 0.4768440
	speed: 0.0170s/iter; left time: 280.9282s
Epoch: 36 cost time: 4.798827171325684
Epoch: 36, Steps: 258 | Train Loss: 0.4931721 Vali Loss: 0.2600209 Test Loss: 0.3519349
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3648935
	speed: 0.0709s/iter; left time: 1163.3309s
	iters: 200, epoch: 37 | loss: 0.4751193
	speed: 0.0164s/iter; left time: 267.9535s
Epoch: 37 cost time: 4.728327512741089
Epoch: 37, Steps: 258 | Train Loss: 0.4931777 Vali Loss: 0.2599259 Test Loss: 0.3519290
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4246547
	speed: 0.0705s/iter; left time: 1139.5650s
	iters: 200, epoch: 38 | loss: 0.3418908
	speed: 0.0162s/iter; left time: 260.0573s
Epoch: 38 cost time: 4.786109209060669
Epoch: 38, Steps: 258 | Train Loss: 0.4928586 Vali Loss: 0.2596616 Test Loss: 0.3519050
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.6579387
	speed: 0.0690s/iter; left time: 1097.5949s
	iters: 200, epoch: 39 | loss: 0.5413237
	speed: 0.0168s/iter; left time: 265.0541s
Epoch: 39 cost time: 4.674211502075195
Epoch: 39, Steps: 258 | Train Loss: 0.4931108 Vali Loss: 0.2597466 Test Loss: 0.3519585
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.5006863
	speed: 0.0709s/iter; left time: 1108.1349s
	iters: 200, epoch: 40 | loss: 0.5055579
	speed: 0.0169s/iter; left time: 262.8042s
Epoch: 40 cost time: 4.873500108718872
Epoch: 40, Steps: 258 | Train Loss: 0.4922408 Vali Loss: 0.2599636 Test Loss: 0.3519484
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.4897612
	speed: 0.0696s/iter; left time: 1071.2745s
	iters: 200, epoch: 41 | loss: 0.5219697
	speed: 0.0168s/iter; left time: 256.0847s
Epoch: 41 cost time: 4.8180317878723145
Epoch: 41, Steps: 258 | Train Loss: 0.4930454 Vali Loss: 0.2598160 Test Loss: 0.3520132
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.5224059
	speed: 0.0702s/iter; left time: 1061.1356s
	iters: 200, epoch: 42 | loss: 0.4579093
	speed: 0.0165s/iter; left time: 247.8603s
Epoch: 42 cost time: 4.663620471954346
Epoch: 42, Steps: 258 | Train Loss: 0.4930888 Vali Loss: 0.2599402 Test Loss: 0.3519496
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.4326620
	speed: 0.0710s/iter; left time: 1056.0067s
	iters: 200, epoch: 43 | loss: 0.5255373
	speed: 0.0166s/iter; left time: 244.6030s
Epoch: 43 cost time: 4.80379056930542
Epoch: 43, Steps: 258 | Train Loss: 0.4930702 Vali Loss: 0.2597003 Test Loss: 0.3519531
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.5352868
	speed: 0.0696s/iter; left time: 1017.3235s
	iters: 200, epoch: 44 | loss: 0.5045559
	speed: 0.0167s/iter; left time: 242.0414s
Epoch: 44 cost time: 4.757814168930054
Epoch: 44, Steps: 258 | Train Loss: 0.4930145 Vali Loss: 0.2599134 Test Loss: 0.3519495
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.3700522
	speed: 0.0697s/iter; left time: 999.7859s
	iters: 200, epoch: 45 | loss: 0.7869648
	speed: 0.0166s/iter; left time: 236.7339s
Epoch: 45 cost time: 4.682403326034546
Epoch: 45, Steps: 258 | Train Loss: 0.4931028 Vali Loss: 0.2598887 Test Loss: 0.3519673
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.5340803
	speed: 0.0704s/iter; left time: 992.2522s
	iters: 200, epoch: 46 | loss: 0.4749342
	speed: 0.0166s/iter; left time: 232.3851s
Epoch: 46 cost time: 4.78023624420166
Epoch: 46, Steps: 258 | Train Loss: 0.4929627 Vali Loss: 0.2599854 Test Loss: 0.3519704
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.5395374
	speed: 0.0695s/iter; left time: 961.1954s
	iters: 200, epoch: 47 | loss: 0.4346911
	speed: 0.0165s/iter; left time: 226.9712s
Epoch: 47 cost time: 4.7447898387908936
Epoch: 47, Steps: 258 | Train Loss: 0.4924853 Vali Loss: 0.2598788 Test Loss: 0.3519642
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_720_720_FITS_ETTm2_ftM_sl720_ll48_pl720_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.34857144951820374, mae:0.3778585195541382, rse:0.47455912828445435, corr:[0.5482003  0.545786   0.5413916  0.53987175 0.54034907 0.54045826
 0.539373   0.5381495  0.5377608  0.5381266  0.53838396 0.5379494
 0.53719026 0.5367063  0.53670186 0.5366923  0.53621095 0.53529465
 0.5343307  0.5336712  0.53333485 0.53296834 0.5323614  0.5316497
 0.53108174 0.53080356 0.53064144 0.5302968  0.529651   0.5289078
 0.52832377 0.5280438  0.5278295  0.5273587  0.5266371  0.52588934
 0.52526665 0.5247916  0.524246   0.52353114 0.52275443 0.5220975
 0.5217223  0.52152807 0.5212354  0.5205785  0.5196224  0.5186356
 0.5178027  0.51714784 0.5165487  0.5158676  0.5150144  0.51411957
 0.5134286  0.5130463  0.5127878  0.5124285  0.5119377  0.5114191
 0.51107085 0.510978   0.5109698  0.5108103  0.51047224 0.51016015
 0.5099596  0.50993043 0.5098819  0.5096317  0.50917643 0.5086709
 0.50827855 0.5080453  0.5077973  0.50739324 0.5068187  0.5061639
 0.50556386 0.50504285 0.50445026 0.50375396 0.5029904  0.5022689
 0.5017053  0.50130457 0.5009231  0.5005222  0.5000657  0.49960384
 0.4992119  0.49884647 0.49835455 0.4976599  0.496701   0.4954648
 0.49400935 0.4924825  0.49093592 0.48948398 0.48822233 0.48712492
 0.4860958  0.48500675 0.48380777 0.48257697 0.48143804 0.48043525
 0.47942385 0.4783555  0.47730052 0.47637358 0.47571445 0.47517505
 0.4745215  0.47367194 0.47270238 0.4717285  0.47091797 0.4702108
 0.46956027 0.46882045 0.4680529  0.4673447  0.46678558 0.46633258
 0.46585363 0.46513575 0.4640985  0.4628528  0.46164247 0.4606039
 0.45975405 0.45900393 0.4583275  0.45776847 0.45733377 0.45696655
 0.45646304 0.45568475 0.45466125 0.4536602  0.45295218 0.4524945
 0.45209464 0.4514877  0.4507772  0.45006782 0.44947106 0.44888633
 0.44821647 0.4474276  0.44652167 0.4456753  0.44506282 0.44466364
 0.44429076 0.44381306 0.44324848 0.4428322  0.4425278  0.44219494
 0.44162482 0.4408676  0.44019568 0.43992332 0.44002745 0.44019145
 0.4400589  0.43952417 0.4387051  0.43801042 0.4376359  0.43743438
 0.43706217 0.4363473  0.43542644 0.43462256 0.43411145 0.4338263
 0.43339118 0.43262896 0.43175727 0.43107373 0.43070316 0.43049213
 0.4301852  0.4296121  0.42885008 0.42806467 0.4273044  0.42634922
 0.42497188 0.42329693 0.42146328 0.41986606 0.41881043 0.4180736
 0.4172324  0.41591865 0.41416204 0.41231284 0.41079256 0.40978298
 0.40912142 0.40847072 0.40759045 0.4064397  0.4052158  0.4041119
 0.40307269 0.40213266 0.40136263 0.40073025 0.40010214 0.399215
 0.3980322  0.39671746 0.3956572  0.39486945 0.39407325 0.39297417
 0.39150327 0.38996574 0.38881958 0.38807964 0.3875352  0.38686115
 0.385747   0.38432273 0.38292223 0.38185626 0.3811492  0.38065705
 0.3801598  0.37966186 0.37922457 0.3788684  0.37855828 0.37812495
 0.37752512 0.37679866 0.37616062 0.37586054 0.3756796  0.37551
 0.37531272 0.3752128  0.37526    0.3753424  0.37536597 0.37513855
 0.3746707  0.37428766 0.37413937 0.3742398  0.37427345 0.37403724
 0.37349865 0.37292215 0.37257892 0.3725584  0.37257373 0.3723692
 0.37181675 0.37102836 0.37038797 0.37007666 0.36997446 0.36981985
 0.36959282 0.3693695  0.36918452 0.36908022 0.36890227 0.3685197
 0.36803126 0.36744085 0.36683875 0.3663869  0.36602482 0.36579594
 0.36565608 0.36559296 0.36549395 0.3651498  0.3644186  0.3632207
 0.3618435  0.3606948  0.3597317  0.35877368 0.35780296 0.35692745
 0.35647053 0.35633862 0.35610166 0.35539857 0.354285   0.3530981
 0.35247862 0.3525365  0.35296106 0.35296673 0.352281   0.35112354
 0.35013232 0.34968477 0.3497579  0.3498818  0.34964016 0.3491608
 0.34865823 0.34852976 0.348698   0.34879127 0.34855032 0.34805474
 0.34754592 0.34735164 0.34747082 0.34753737 0.34722468 0.34660617
 0.34603113 0.345906   0.34623936 0.34657615 0.3466265  0.34622613
 0.34571663 0.34540492 0.34551337 0.3459779  0.34642267 0.3467225
 0.3467651  0.34648174 0.34605092 0.3456348  0.34518847 0.34463426
 0.3440913  0.34368888 0.3434563  0.34336707 0.34340373 0.34360695
 0.3439025  0.34418467 0.34426096 0.3440179  0.3435899  0.3432149
 0.3430803  0.34318298 0.3431917  0.34298986 0.342447   0.34189552
 0.34161362 0.34163544 0.3416879  0.34146023 0.34083414 0.34015477
 0.33971912 0.33976164 0.34005302 0.34022498 0.34009594 0.3397122
 0.33942485 0.3395478  0.3400481  0.34061593 0.34094086 0.34100837
 0.34097958 0.3409594  0.34085903 0.3404947  0.3399634  0.33929694
 0.33872712 0.33828044 0.33779976 0.33703548 0.33592933 0.3348214
 0.3339904  0.3335754  0.33344144 0.33334017 0.33307347 0.33256996
 0.33193073 0.33130333 0.33062583 0.32992706 0.32933155 0.32876748
 0.3281916  0.32755667 0.32693157 0.32647744 0.32625273 0.32633242
 0.3264982  0.32654142 0.32623583 0.32559532 0.32501525 0.3247903
 0.32502228 0.32542488 0.3255505  0.32521778 0.32457083 0.32401744
 0.3238581  0.32399753 0.32409802 0.32399777 0.32381338 0.32382545
 0.32422665 0.32486075 0.32547626 0.32582396 0.32589266 0.32581928
 0.32571223 0.3254606  0.32505354 0.3245966  0.32429564 0.32422352
 0.3242429  0.32431826 0.32417077 0.323673   0.3230526  0.32264656
 0.32243705 0.3223376  0.32208747 0.32153445 0.32087427 0.32034323
 0.32011554 0.32009262 0.32008728 0.319873   0.3195029  0.31915352
 0.3188937  0.31866705 0.31833568 0.3178924  0.31758127 0.3173923
 0.31732246 0.31722432 0.3169212  0.3163922  0.31577826 0.31530145
 0.31504077 0.31483722 0.31445903 0.313833   0.31317928 0.31266955
 0.31240195 0.31220573 0.31192687 0.311347   0.31047785 0.309418
 0.3082657  0.3071878  0.30610886 0.30502748 0.30400625 0.30306357
 0.30213413 0.30123916 0.30032787 0.29948545 0.2986746  0.2978619
 0.2970578  0.29637572 0.29582787 0.29527906 0.29468548 0.29398236
 0.29315293 0.29218262 0.29119852 0.29044613 0.28992093 0.28962344
 0.28929198 0.28883803 0.28834963 0.28789136 0.2875418  0.28717232
 0.28664747 0.28598192 0.28532866 0.28490794 0.28479242 0.2847676
 0.28449738 0.28380153 0.28303644 0.28244323 0.28215215 0.2820905
 0.28199452 0.28174356 0.28134015 0.28102812 0.2810474  0.28130767
 0.28151187 0.28143317 0.2810075  0.2804156  0.27989817 0.27952132
 0.2791905  0.27887473 0.2787135  0.27874124 0.2788896  0.27900684
 0.2789144  0.27862665 0.2782884  0.2781745  0.27832425 0.27851492
 0.27853003 0.27828664 0.27781716 0.27728182 0.27676532 0.2763802
 0.2760652  0.27582997 0.27565834 0.27553955 0.2752949  0.275014
 0.2747079  0.27452868 0.27443293 0.2743647  0.27431136 0.27428436
 0.27433693 0.2744607  0.27461773 0.2746369  0.2743781  0.27386454
 0.27323067 0.2727034  0.27233654 0.27205274 0.27159044 0.27058074
 0.26897907 0.26729077 0.26588696 0.2649027  0.26417312 0.26349884
 0.26274303 0.26184887 0.2608765  0.2598947  0.25892597 0.25807375
 0.25734064 0.2567012  0.25619844 0.25572863 0.2552052  0.25466272
 0.2541057  0.25352877 0.25305942 0.2526553  0.25239533 0.25229457
 0.25229552 0.25239894 0.2523936  0.2521166  0.25162968 0.25105113
 0.25044215 0.24999002 0.24981183 0.24970208 0.24955678 0.24930942
 0.2491125  0.24894132 0.2489706  0.24926265 0.24959241 0.2496824
 0.24946353 0.24917245 0.24900346 0.2491713  0.24967223 0.2503679
 0.25100046 0.25142094 0.2516331  0.2517438  0.2517114  0.25148472
 0.25109202 0.2508113  0.25088397 0.25106674 0.251341   0.25141066
 0.25120646 0.25090587 0.25062254 0.2505658  0.250437   0.25011653
 0.24961813 0.24930799 0.24927743 0.24937527 0.24957742 0.24947016
 0.24913211 0.24872205 0.24851474 0.24856365 0.2488304  0.24892892
 0.24889667 0.24870752 0.24837725 0.24810787 0.24790983 0.24769653
 0.24748273 0.24753992 0.24774699 0.24798234 0.24822448 0.2484058
 0.24853574 0.2487557  0.24898244 0.24885996 0.24813557 0.24688326
 0.24542016 0.24412185 0.24313572 0.24231    0.24149877 0.24053065
 0.23945409 0.23847158 0.23802195 0.23789907 0.2378544  0.23755075
 0.23690923 0.23609048 0.23531225 0.2346791  0.23429833 0.23393014
 0.23351495 0.23303014 0.23246585 0.23208104 0.23178141 0.23143557
 0.23097885 0.23032771 0.22960755 0.22880915 0.2281033  0.22753814
 0.22718213 0.22670211 0.22609417 0.22555175 0.22528528 0.22532177
 0.22526975 0.22480112 0.223863   0.2231575  0.2231297  0.22376089
 0.22399415 0.222843   0.2208421  0.2202551  0.22247942 0.22379999]
