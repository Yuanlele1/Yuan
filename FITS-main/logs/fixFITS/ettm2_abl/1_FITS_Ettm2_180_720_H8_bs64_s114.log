Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_180_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_180_720_FITS_ETTm2_ftM_sl180_ll48_pl720_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33661
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=26, out_features=130, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3028480.0
params:  3510.0
Trainable parameters:  3510
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6444809
	speed: 0.0213s/iter; left time: 555.7758s
	iters: 200, epoch: 1 | loss: 0.5024361
	speed: 0.0151s/iter; left time: 393.5225s
Epoch: 1 cost time: 4.579103231430054
Epoch: 1, Steps: 262 | Train Loss: 0.6828795 Vali Loss: 0.3068235 Test Loss: 0.4253416
Validation loss decreased (inf --> 0.306824).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6775780
	speed: 0.0763s/iter; left time: 1971.2524s
	iters: 200, epoch: 2 | loss: 0.5224893
	speed: 0.0150s/iter; left time: 385.3349s
Epoch: 2 cost time: 4.648255109786987
Epoch: 2, Steps: 262 | Train Loss: 0.5837097 Vali Loss: 0.2868074 Test Loss: 0.4008423
Validation loss decreased (0.306824 --> 0.286807).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.6379444
	speed: 0.0754s/iter; left time: 1927.9846s
	iters: 200, epoch: 3 | loss: 0.4025280
	speed: 0.0150s/iter; left time: 381.5650s
Epoch: 3 cost time: 4.4952757358551025
Epoch: 3, Steps: 262 | Train Loss: 0.5684772 Vali Loss: 0.2820587 Test Loss: 0.3950197
Validation loss decreased (0.286807 --> 0.282059).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.5488146
	speed: 0.0777s/iter; left time: 1966.1717s
	iters: 200, epoch: 4 | loss: 0.5612105
	speed: 0.0149s/iter; left time: 375.4481s
Epoch: 4 cost time: 4.525898694992065
Epoch: 4, Steps: 262 | Train Loss: 0.5644789 Vali Loss: 0.2801460 Test Loss: 0.3925700
Validation loss decreased (0.282059 --> 0.280146).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.7427388
	speed: 0.0738s/iter; left time: 1848.8141s
	iters: 200, epoch: 5 | loss: 0.7044481
	speed: 0.0167s/iter; left time: 417.3512s
Epoch: 5 cost time: 4.816620826721191
Epoch: 5, Steps: 262 | Train Loss: 0.5625241 Vali Loss: 0.2789273 Test Loss: 0.3911581
Validation loss decreased (0.280146 --> 0.278927).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4657392
	speed: 0.0774s/iter; left time: 1919.8895s
	iters: 200, epoch: 6 | loss: 0.4879727
	speed: 0.0151s/iter; left time: 373.4712s
Epoch: 6 cost time: 4.461223125457764
Epoch: 6, Steps: 262 | Train Loss: 0.5599290 Vali Loss: 0.2785653 Test Loss: 0.3902323
Validation loss decreased (0.278927 --> 0.278565).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.5083587
	speed: 0.0723s/iter; left time: 1773.4832s
	iters: 200, epoch: 7 | loss: 0.5652701
	speed: 0.0147s/iter; left time: 359.6735s
Epoch: 7 cost time: 4.366193532943726
Epoch: 7, Steps: 262 | Train Loss: 0.5595271 Vali Loss: 0.2780611 Test Loss: 0.3895272
Validation loss decreased (0.278565 --> 0.278061).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.6484404
	speed: 0.0708s/iter; left time: 1717.8411s
	iters: 200, epoch: 8 | loss: 0.5767916
	speed: 0.0151s/iter; left time: 364.9937s
Epoch: 8 cost time: 4.3942248821258545
Epoch: 8, Steps: 262 | Train Loss: 0.5579219 Vali Loss: 0.2778658 Test Loss: 0.3890938
Validation loss decreased (0.278061 --> 0.277866).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.5161104
	speed: 0.0746s/iter; left time: 1791.7251s
	iters: 200, epoch: 9 | loss: 0.6012621
	speed: 0.0165s/iter; left time: 395.0212s
Epoch: 9 cost time: 5.00334095954895
Epoch: 9, Steps: 262 | Train Loss: 0.5585529 Vali Loss: 0.2776199 Test Loss: 0.3887132
Validation loss decreased (0.277866 --> 0.277620).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4507935
	speed: 0.0781s/iter; left time: 1853.6901s
	iters: 200, epoch: 10 | loss: 0.5788599
	speed: 0.0169s/iter; left time: 400.0575s
Epoch: 10 cost time: 4.915825843811035
Epoch: 10, Steps: 262 | Train Loss: 0.5577654 Vali Loss: 0.2773757 Test Loss: 0.3884009
Validation loss decreased (0.277620 --> 0.277376).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4210954
	speed: 0.0818s/iter; left time: 1920.1189s
	iters: 200, epoch: 11 | loss: 0.5663349
	speed: 0.0149s/iter; left time: 348.5300s
Epoch: 11 cost time: 4.699084281921387
Epoch: 11, Steps: 262 | Train Loss: 0.5574961 Vali Loss: 0.2774390 Test Loss: 0.3881996
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4797075
	speed: 0.0726s/iter; left time: 1684.5763s
	iters: 200, epoch: 12 | loss: 0.5046417
	speed: 0.0152s/iter; left time: 351.8898s
Epoch: 12 cost time: 4.474026203155518
Epoch: 12, Steps: 262 | Train Loss: 0.5565136 Vali Loss: 0.2772379 Test Loss: 0.3879798
Validation loss decreased (0.277376 --> 0.277238).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4086343
	speed: 0.0730s/iter; left time: 1676.9517s
	iters: 200, epoch: 13 | loss: 0.6285057
	speed: 0.0150s/iter; left time: 343.0199s
Epoch: 13 cost time: 4.473220586776733
Epoch: 13, Steps: 262 | Train Loss: 0.5563396 Vali Loss: 0.2770844 Test Loss: 0.3878618
Validation loss decreased (0.277238 --> 0.277084).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.6665990
	speed: 0.0718s/iter; left time: 1629.0840s
	iters: 200, epoch: 14 | loss: 0.5956599
	speed: 0.0148s/iter; left time: 333.6144s
Epoch: 14 cost time: 4.394540548324585
Epoch: 14, Steps: 262 | Train Loss: 0.5556388 Vali Loss: 0.2770484 Test Loss: 0.3876382
Validation loss decreased (0.277084 --> 0.277048).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.6070336
	speed: 0.0723s/iter; left time: 1621.9196s
	iters: 200, epoch: 15 | loss: 0.5312731
	speed: 0.0150s/iter; left time: 334.7970s
Epoch: 15 cost time: 4.424326419830322
Epoch: 15, Steps: 262 | Train Loss: 0.5561360 Vali Loss: 0.2769992 Test Loss: 0.3875104
Validation loss decreased (0.277048 --> 0.276999).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.8391151
	speed: 0.0743s/iter; left time: 1646.4859s
	iters: 200, epoch: 16 | loss: 0.6100535
	speed: 0.0146s/iter; left time: 323.0891s
Epoch: 16 cost time: 4.460232496261597
Epoch: 16, Steps: 262 | Train Loss: 0.5559986 Vali Loss: 0.2770180 Test Loss: 0.3874396
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.5459465
	speed: 0.0777s/iter; left time: 1701.5584s
	iters: 200, epoch: 17 | loss: 0.5497050
	speed: 0.0151s/iter; left time: 330.2221s
Epoch: 17 cost time: 4.542126417160034
Epoch: 17, Steps: 262 | Train Loss: 0.5553517 Vali Loss: 0.2767770 Test Loss: 0.3873274
Validation loss decreased (0.276999 --> 0.276777).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.5467587
	speed: 0.0732s/iter; left time: 1584.4301s
	iters: 200, epoch: 18 | loss: 0.4308334
	speed: 0.0148s/iter; left time: 319.8496s
Epoch: 18 cost time: 4.407339572906494
Epoch: 18, Steps: 262 | Train Loss: 0.5558666 Vali Loss: 0.2767995 Test Loss: 0.3872840
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4391773
	speed: 0.0722s/iter; left time: 1544.4340s
	iters: 200, epoch: 19 | loss: 0.6548688
	speed: 0.0147s/iter; left time: 313.7967s
Epoch: 19 cost time: 4.450815439224243
Epoch: 19, Steps: 262 | Train Loss: 0.5549296 Vali Loss: 0.2767480 Test Loss: 0.3872274
Validation loss decreased (0.276777 --> 0.276748).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4258232
	speed: 0.0736s/iter; left time: 1553.7614s
	iters: 200, epoch: 20 | loss: 0.5620893
	speed: 0.0153s/iter; left time: 321.3941s
Epoch: 20 cost time: 4.453723669052124
Epoch: 20, Steps: 262 | Train Loss: 0.5549948 Vali Loss: 0.2768441 Test Loss: 0.3871677
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.7556159
	speed: 0.0729s/iter; left time: 1520.0941s
	iters: 200, epoch: 21 | loss: 0.5184860
	speed: 0.0149s/iter; left time: 309.3888s
Epoch: 21 cost time: 4.4861040115356445
Epoch: 21, Steps: 262 | Train Loss: 0.5554682 Vali Loss: 0.2764997 Test Loss: 0.3870846
Validation loss decreased (0.276748 --> 0.276500).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.7168041
	speed: 0.0725s/iter; left time: 1493.9199s
	iters: 200, epoch: 22 | loss: 0.5485224
	speed: 0.0152s/iter; left time: 311.1790s
Epoch: 22 cost time: 4.531808376312256
Epoch: 22, Steps: 262 | Train Loss: 0.5557444 Vali Loss: 0.2764390 Test Loss: 0.3870664
Validation loss decreased (0.276500 --> 0.276439).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4235166
	speed: 0.0734s/iter; left time: 1492.6175s
	iters: 200, epoch: 23 | loss: 0.4527193
	speed: 0.0152s/iter; left time: 307.7754s
Epoch: 23 cost time: 4.543919086456299
Epoch: 23, Steps: 262 | Train Loss: 0.5553547 Vali Loss: 0.2768120 Test Loss: 0.3870104
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3996941
	speed: 0.0733s/iter; left time: 1471.8943s
	iters: 200, epoch: 24 | loss: 0.3509556
	speed: 0.0152s/iter; left time: 302.7046s
Epoch: 24 cost time: 4.542815923690796
Epoch: 24, Steps: 262 | Train Loss: 0.5553765 Vali Loss: 0.2764978 Test Loss: 0.3869585
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.5308200
	speed: 0.0761s/iter; left time: 1508.4501s
	iters: 200, epoch: 25 | loss: 0.5144669
	speed: 0.0152s/iter; left time: 299.2395s
Epoch: 25 cost time: 4.396609783172607
Epoch: 25, Steps: 262 | Train Loss: 0.5549723 Vali Loss: 0.2768748 Test Loss: 0.3869404
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.6759399
	speed: 0.0732s/iter; left time: 1430.4016s
	iters: 200, epoch: 26 | loss: 0.5104361
	speed: 0.0148s/iter; left time: 288.6448s
Epoch: 26 cost time: 4.530629873275757
Epoch: 26, Steps: 262 | Train Loss: 0.5550081 Vali Loss: 0.2767472 Test Loss: 0.3869205
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4060648
	speed: 0.0721s/iter; left time: 1391.0204s
	iters: 200, epoch: 27 | loss: 0.5328495
	speed: 0.0210s/iter; left time: 403.0191s
Epoch: 27 cost time: 6.749039649963379
Epoch: 27, Steps: 262 | Train Loss: 0.5551808 Vali Loss: 0.2766060 Test Loss: 0.3868824
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4536684
	speed: 0.0987s/iter; left time: 1877.8065s
	iters: 200, epoch: 28 | loss: 0.5014833
	speed: 0.0168s/iter; left time: 318.4784s
Epoch: 28 cost time: 4.999190092086792
Epoch: 28, Steps: 262 | Train Loss: 0.5545740 Vali Loss: 0.2766136 Test Loss: 0.3868620
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3450368
	speed: 0.0810s/iter; left time: 1520.9022s
	iters: 200, epoch: 29 | loss: 0.4374852
	speed: 0.0370s/iter; left time: 691.2946s
Epoch: 29 cost time: 6.9889161586761475
Epoch: 29, Steps: 262 | Train Loss: 0.5542452 Vali Loss: 0.2767280 Test Loss: 0.3868190
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.5766304
	speed: 0.0743s/iter; left time: 1374.3505s
	iters: 200, epoch: 30 | loss: 0.8105266
	speed: 0.0154s/iter; left time: 282.7861s
Epoch: 30 cost time: 4.52314567565918
Epoch: 30, Steps: 262 | Train Loss: 0.5547162 Vali Loss: 0.2766644 Test Loss: 0.3868008
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4324940
	speed: 0.0727s/iter; left time: 1326.7691s
	iters: 200, epoch: 31 | loss: 0.3626446
	speed: 0.0151s/iter; left time: 273.0552s
Epoch: 31 cost time: 4.526447534561157
Epoch: 31, Steps: 262 | Train Loss: 0.5542542 Vali Loss: 0.2764749 Test Loss: 0.3867927
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.8484452
	speed: 0.0715s/iter; left time: 1285.6792s
	iters: 200, epoch: 32 | loss: 0.5626436
	speed: 0.0149s/iter; left time: 267.0015s
Epoch: 32 cost time: 4.437084197998047
Epoch: 32, Steps: 262 | Train Loss: 0.5549849 Vali Loss: 0.2764414 Test Loss: 0.3867848
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4610939
	speed: 0.0764s/iter; left time: 1353.7500s
	iters: 200, epoch: 33 | loss: 0.7506154
	speed: 0.0150s/iter; left time: 264.6724s
Epoch: 33 cost time: 4.59984278678894
Epoch: 33, Steps: 262 | Train Loss: 0.5545361 Vali Loss: 0.2765265 Test Loss: 0.3867745
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.5535123
	speed: 0.0756s/iter; left time: 1320.0965s
	iters: 200, epoch: 34 | loss: 0.6222639
	speed: 0.0146s/iter; left time: 253.8939s
Epoch: 34 cost time: 4.514127254486084
Epoch: 34, Steps: 262 | Train Loss: 0.5551818 Vali Loss: 0.2762995 Test Loss: 0.3867650
Validation loss decreased (0.276439 --> 0.276300).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.7314806
	speed: 0.0732s/iter; left time: 1258.3933s
	iters: 200, epoch: 35 | loss: 0.6057584
	speed: 0.0150s/iter; left time: 255.5437s
Epoch: 35 cost time: 4.3909525871276855
Epoch: 35, Steps: 262 | Train Loss: 0.5540436 Vali Loss: 0.2765658 Test Loss: 0.3867359
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.5329226
	speed: 0.0848s/iter; left time: 1435.0164s
	iters: 200, epoch: 36 | loss: 0.5001131
	speed: 0.0152s/iter; left time: 255.5470s
Epoch: 36 cost time: 5.758647918701172
Epoch: 36, Steps: 262 | Train Loss: 0.5547733 Vali Loss: 0.2764972 Test Loss: 0.3867331
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.6115740
	speed: 0.0725s/iter; left time: 1209.0685s
	iters: 200, epoch: 37 | loss: 0.4367899
	speed: 0.0148s/iter; left time: 244.5730s
Epoch: 37 cost time: 4.400842666625977
Epoch: 37, Steps: 262 | Train Loss: 0.5532257 Vali Loss: 0.2764778 Test Loss: 0.3867284
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.8898207
	speed: 0.0722s/iter; left time: 1184.3724s
	iters: 200, epoch: 38 | loss: 0.5100182
	speed: 0.0150s/iter; left time: 244.4396s
Epoch: 38 cost time: 4.542981147766113
Epoch: 38, Steps: 262 | Train Loss: 0.5544431 Vali Loss: 0.2765580 Test Loss: 0.3867166
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.6987320
	speed: 0.0745s/iter; left time: 1202.1505s
	iters: 200, epoch: 39 | loss: 0.6186805
	speed: 0.0151s/iter; left time: 242.6308s
Epoch: 39 cost time: 4.4576256275177
Epoch: 39, Steps: 262 | Train Loss: 0.5539923 Vali Loss: 0.2762514 Test Loss: 0.3867135
Validation loss decreased (0.276300 --> 0.276251).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.6195083
	speed: 0.0742s/iter; left time: 1178.1757s
	iters: 200, epoch: 40 | loss: 0.4784260
	speed: 0.0151s/iter; left time: 237.5989s
Epoch: 40 cost time: 4.49860954284668
Epoch: 40, Steps: 262 | Train Loss: 0.5539238 Vali Loss: 0.2763185 Test Loss: 0.3867064
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.7272549
	speed: 0.0739s/iter; left time: 1154.6743s
	iters: 200, epoch: 41 | loss: 0.4745089
	speed: 0.0150s/iter; left time: 232.6608s
Epoch: 41 cost time: 4.56569242477417
Epoch: 41, Steps: 262 | Train Loss: 0.5546224 Vali Loss: 0.2768401 Test Loss: 0.3866913
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3690802
	speed: 0.0733s/iter; left time: 1125.4570s
	iters: 200, epoch: 42 | loss: 0.6329126
	speed: 0.0152s/iter; left time: 232.3919s
Epoch: 42 cost time: 4.528386831283569
Epoch: 42, Steps: 262 | Train Loss: 0.5545354 Vali Loss: 0.2763856 Test Loss: 0.3866852
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.7033512
	speed: 0.0715s/iter; left time: 1079.2024s
	iters: 200, epoch: 43 | loss: 0.4701928
	speed: 0.0149s/iter; left time: 222.8455s
Epoch: 43 cost time: 4.467510938644409
Epoch: 43, Steps: 262 | Train Loss: 0.5543244 Vali Loss: 0.2763350 Test Loss: 0.3866791
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.6653459
	speed: 0.0710s/iter; left time: 1053.4821s
	iters: 200, epoch: 44 | loss: 0.4079043
	speed: 0.0150s/iter; left time: 220.6729s
Epoch: 44 cost time: 4.421846628189087
Epoch: 44, Steps: 262 | Train Loss: 0.5536101 Vali Loss: 0.2764418 Test Loss: 0.3866709
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.5401587
	speed: 0.0866s/iter; left time: 1262.2353s
	iters: 200, epoch: 45 | loss: 0.4536304
	speed: 0.0149s/iter; left time: 216.1101s
Epoch: 45 cost time: 5.7307069301605225
Epoch: 45, Steps: 262 | Train Loss: 0.5549309 Vali Loss: 0.2763097 Test Loss: 0.3866691
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.5958402
	speed: 0.0725s/iter; left time: 1037.4009s
	iters: 200, epoch: 46 | loss: 0.4253330
	speed: 0.0166s/iter; left time: 236.4676s
Epoch: 46 cost time: 4.728485584259033
Epoch: 46, Steps: 262 | Train Loss: 0.5539241 Vali Loss: 0.2764468 Test Loss: 0.3866605
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.6277887
	speed: 0.0746s/iter; left time: 1048.6649s
	iters: 200, epoch: 47 | loss: 0.3548670
	speed: 0.0151s/iter; left time: 210.2144s
Epoch: 47 cost time: 4.466295480728149
Epoch: 47, Steps: 262 | Train Loss: 0.5546765 Vali Loss: 0.2765546 Test Loss: 0.3866622
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.6110500
	speed: 0.0742s/iter; left time: 1023.2043s
	iters: 200, epoch: 48 | loss: 0.6963850
	speed: 0.0151s/iter; left time: 207.0783s
Epoch: 48 cost time: 4.61517596244812
Epoch: 48, Steps: 262 | Train Loss: 0.5540231 Vali Loss: 0.2766467 Test Loss: 0.3866605
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.6985474
	speed: 0.0742s/iter; left time: 1003.2386s
	iters: 200, epoch: 49 | loss: 0.5926378
	speed: 0.0153s/iter; left time: 205.1783s
Epoch: 49 cost time: 4.740687131881714
Epoch: 49, Steps: 262 | Train Loss: 0.5547115 Vali Loss: 0.2764105 Test Loss: 0.3866553
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.4362231
	speed: 0.0754s/iter; left time: 1000.3447s
	iters: 200, epoch: 50 | loss: 0.8001170
	speed: 0.0167s/iter; left time: 219.6206s
Epoch: 50 cost time: 4.846203327178955
Epoch: 50, Steps: 262 | Train Loss: 0.5546159 Vali Loss: 0.2764365 Test Loss: 0.3866545
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.5324580
	speed: 0.0795s/iter; left time: 1033.1198s
	iters: 200, epoch: 51 | loss: 0.4119777
	speed: 0.0160s/iter; left time: 206.4720s
Epoch: 51 cost time: 4.684477090835571
Epoch: 51, Steps: 262 | Train Loss: 0.5536727 Vali Loss: 0.2762950 Test Loss: 0.3866498
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.4669667
	speed: 0.0775s/iter; left time: 986.8490s
	iters: 200, epoch: 52 | loss: 0.7369366
	speed: 0.0151s/iter; left time: 190.2848s
Epoch: 52 cost time: 4.699764251708984
Epoch: 52, Steps: 262 | Train Loss: 0.5546877 Vali Loss: 0.2764243 Test Loss: 0.3866444
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.6015029
	speed: 0.0775s/iter; left time: 966.3966s
	iters: 200, epoch: 53 | loss: 0.7886968
	speed: 0.0154s/iter; left time: 190.5426s
Epoch: 53 cost time: 4.761894941329956
Epoch: 53, Steps: 262 | Train Loss: 0.5545995 Vali Loss: 0.2765504 Test Loss: 0.3866400
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.8429236
	speed: 0.0728s/iter; left time: 889.6271s
	iters: 200, epoch: 54 | loss: 0.3748502
	speed: 0.0153s/iter; left time: 184.8415s
Epoch: 54 cost time: 4.664454936981201
Epoch: 54, Steps: 262 | Train Loss: 0.5544633 Vali Loss: 0.2767835 Test Loss: 0.3866400
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.5208218
	speed: 0.0746s/iter; left time: 891.8116s
	iters: 200, epoch: 55 | loss: 0.5861604
	speed: 0.0151s/iter; left time: 179.1360s
Epoch: 55 cost time: 4.545296669006348
Epoch: 55, Steps: 262 | Train Loss: 0.5546165 Vali Loss: 0.2764775 Test Loss: 0.3866332
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.4670715
	speed: 0.0807s/iter; left time: 943.7969s
	iters: 200, epoch: 56 | loss: 0.6505948
	speed: 0.0156s/iter; left time: 180.6069s
Epoch: 56 cost time: 4.702035665512085
Epoch: 56, Steps: 262 | Train Loss: 0.5543720 Vali Loss: 0.2765721 Test Loss: 0.3866314
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.6224083
	speed: 0.0743s/iter; left time: 848.6943s
	iters: 200, epoch: 57 | loss: 0.6864520
	speed: 0.0153s/iter; left time: 173.3487s
Epoch: 57 cost time: 4.599115371704102
Epoch: 57, Steps: 262 | Train Loss: 0.5540388 Vali Loss: 0.2766678 Test Loss: 0.3866276
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.5939187
	speed: 0.0755s/iter; left time: 842.6256s
	iters: 200, epoch: 58 | loss: 0.8330861
	speed: 0.0152s/iter; left time: 168.4801s
Epoch: 58 cost time: 4.571894884109497
Epoch: 58, Steps: 262 | Train Loss: 0.5540017 Vali Loss: 0.2767327 Test Loss: 0.3866271
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.4687418
	speed: 0.0730s/iter; left time: 796.5855s
	iters: 200, epoch: 59 | loss: 0.7812303
	speed: 0.0151s/iter; left time: 162.9386s
Epoch: 59 cost time: 4.461138725280762
Epoch: 59, Steps: 262 | Train Loss: 0.5544996 Vali Loss: 0.2762444 Test Loss: 0.3866258
Validation loss decreased (0.276251 --> 0.276244).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.7990771
	speed: 0.0749s/iter; left time: 796.6558s
	iters: 200, epoch: 60 | loss: 0.5518965
	speed: 0.0150s/iter; left time: 158.0269s
Epoch: 60 cost time: 4.534265995025635
Epoch: 60, Steps: 262 | Train Loss: 0.5536919 Vali Loss: 0.2764291 Test Loss: 0.3866258
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.7980740
	speed: 0.0750s/iter; left time: 779.0530s
	iters: 200, epoch: 61 | loss: 0.4642614
	speed: 0.0165s/iter; left time: 169.7148s
Epoch: 61 cost time: 4.845965147018433
Epoch: 61, Steps: 262 | Train Loss: 0.5543854 Vali Loss: 0.2762105 Test Loss: 0.3866196
Validation loss decreased (0.276244 --> 0.276211).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.6440343
	speed: 0.0821s/iter; left time: 831.1469s
	iters: 200, epoch: 62 | loss: 0.4424451
	speed: 0.0153s/iter; left time: 152.7986s
Epoch: 62 cost time: 4.7545740604400635
Epoch: 62, Steps: 262 | Train Loss: 0.5533003 Vali Loss: 0.2763723 Test Loss: 0.3866170
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.4389780
	speed: 0.0737s/iter; left time: 726.4615s
	iters: 200, epoch: 63 | loss: 0.6430480
	speed: 0.0152s/iter; left time: 148.3381s
Epoch: 63 cost time: 4.630383491516113
Epoch: 63, Steps: 262 | Train Loss: 0.5549234 Vali Loss: 0.2764302 Test Loss: 0.3866179
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.5515056
	speed: 0.0780s/iter; left time: 748.8681s
	iters: 200, epoch: 64 | loss: 0.5418248
	speed: 0.0165s/iter; left time: 156.3422s
Epoch: 64 cost time: 5.00186824798584
Epoch: 64, Steps: 262 | Train Loss: 0.5540424 Vali Loss: 0.2765631 Test Loss: 0.3866152
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.5931829
	speed: 0.0837s/iter; left time: 780.7224s
	iters: 200, epoch: 65 | loss: 0.5582682
	speed: 0.0166s/iter; left time: 152.8067s
Epoch: 65 cost time: 5.034955024719238
Epoch: 65, Steps: 262 | Train Loss: 0.5545439 Vali Loss: 0.2765217 Test Loss: 0.3866161
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.5845258
	speed: 0.0802s/iter; left time: 727.3753s
	iters: 200, epoch: 66 | loss: 0.6213546
	speed: 0.0166s/iter; left time: 148.4761s
Epoch: 66 cost time: 4.934227228164673
Epoch: 66, Steps: 262 | Train Loss: 0.5541443 Vali Loss: 0.2767608 Test Loss: 0.3866144
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.5910417
	speed: 0.0779s/iter; left time: 686.4476s
	iters: 200, epoch: 67 | loss: 0.6529965
	speed: 0.0155s/iter; left time: 134.7670s
Epoch: 67 cost time: 4.56926417350769
Epoch: 67, Steps: 262 | Train Loss: 0.5543076 Vali Loss: 0.2763826 Test Loss: 0.3866130
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.4184323
	speed: 0.0782s/iter; left time: 668.7236s
	iters: 200, epoch: 68 | loss: 0.4794798
	speed: 0.0151s/iter; left time: 127.5172s
Epoch: 68 cost time: 4.837526559829712
Epoch: 68, Steps: 262 | Train Loss: 0.5541495 Vali Loss: 0.2764453 Test Loss: 0.3866107
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.5008085
	speed: 0.0738s/iter; left time: 611.2395s
	iters: 200, epoch: 69 | loss: 0.5921166
	speed: 0.0156s/iter; left time: 127.8574s
Epoch: 69 cost time: 4.6006810665130615
Epoch: 69, Steps: 262 | Train Loss: 0.5547572 Vali Loss: 0.2764066 Test Loss: 0.3866112
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.3941707
	speed: 0.0739s/iter; left time: 593.0653s
	iters: 200, epoch: 70 | loss: 1.0670580
	speed: 0.0150s/iter; left time: 118.8904s
Epoch: 70 cost time: 4.465386152267456
Epoch: 70, Steps: 262 | Train Loss: 0.5543937 Vali Loss: 0.2764982 Test Loss: 0.3866100
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.4340204
	speed: 0.0752s/iter; left time: 583.6621s
	iters: 200, epoch: 71 | loss: 0.8038355
	speed: 0.0162s/iter; left time: 124.4898s
Epoch: 71 cost time: 4.785995006561279
Epoch: 71, Steps: 262 | Train Loss: 0.5544299 Vali Loss: 0.2762783 Test Loss: 0.3866091
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.6461784
	speed: 0.0769s/iter; left time: 576.7877s
	iters: 200, epoch: 72 | loss: 0.3961660
	speed: 0.0150s/iter; left time: 111.0202s
Epoch: 72 cost time: 4.570040225982666
Epoch: 72, Steps: 262 | Train Loss: 0.5541497 Vali Loss: 0.2763298 Test Loss: 0.3866068
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.3894947
	speed: 0.0726s/iter; left time: 525.6966s
	iters: 200, epoch: 73 | loss: 0.8111567
	speed: 0.0152s/iter; left time: 108.5942s
Epoch: 73 cost time: 4.452319383621216
Epoch: 73, Steps: 262 | Train Loss: 0.5537128 Vali Loss: 0.2765934 Test Loss: 0.3866078
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.6821545
	speed: 0.0739s/iter; left time: 515.1412s
	iters: 200, epoch: 74 | loss: 0.6379310
	speed: 0.0161s/iter; left time: 110.8861s
Epoch: 74 cost time: 4.638535261154175
Epoch: 74, Steps: 262 | Train Loss: 0.5538004 Vali Loss: 0.2763821 Test Loss: 0.3866048
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.4694759
	speed: 0.0751s/iter; left time: 503.8701s
	iters: 200, epoch: 75 | loss: 0.5069919
	speed: 0.0149s/iter; left time: 98.7982s
Epoch: 75 cost time: 4.586159706115723
Epoch: 75, Steps: 262 | Train Loss: 0.5546851 Vali Loss: 0.2764252 Test Loss: 0.3866029
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.8423745
	speed: 0.0755s/iter; left time: 487.1321s
	iters: 200, epoch: 76 | loss: 0.5814328
	speed: 0.0155s/iter; left time: 98.5422s
Epoch: 76 cost time: 4.673463344573975
Epoch: 76, Steps: 262 | Train Loss: 0.5545041 Vali Loss: 0.2764698 Test Loss: 0.3866040
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.6765301
	speed: 0.0746s/iter; left time: 461.9062s
	iters: 200, epoch: 77 | loss: 0.5112194
	speed: 0.0154s/iter; left time: 93.7608s
Epoch: 77 cost time: 4.631310939788818
Epoch: 77, Steps: 262 | Train Loss: 0.5545286 Vali Loss: 0.2766067 Test Loss: 0.3866023
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.4915631
	speed: 0.0727s/iter; left time: 430.7519s
	iters: 200, epoch: 78 | loss: 0.5669005
	speed: 0.0146s/iter; left time: 85.3079s
Epoch: 78 cost time: 4.4209699630737305
Epoch: 78, Steps: 262 | Train Loss: 0.5541402 Vali Loss: 0.2767008 Test Loss: 0.3866032
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.4830950
	speed: 0.0709s/iter; left time: 401.5196s
	iters: 200, epoch: 79 | loss: 0.5808628
	speed: 0.0152s/iter; left time: 84.7684s
Epoch: 79 cost time: 4.456223487854004
Epoch: 79, Steps: 262 | Train Loss: 0.5538057 Vali Loss: 0.2766006 Test Loss: 0.3866013
EarlyStopping counter: 18 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.6963830
	speed: 0.0717s/iter; left time: 387.1768s
	iters: 200, epoch: 80 | loss: 0.4807616
	speed: 0.0154s/iter; left time: 81.6908s
Epoch: 80 cost time: 4.466233730316162
Epoch: 80, Steps: 262 | Train Loss: 0.5544023 Vali Loss: 0.2767740 Test Loss: 0.3866018
EarlyStopping counter: 19 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.4713541
	speed: 0.0827s/iter; left time: 425.1108s
	iters: 200, epoch: 81 | loss: 0.6147201
	speed: 0.0150s/iter; left time: 75.6249s
Epoch: 81 cost time: 5.498364210128784
Epoch: 81, Steps: 262 | Train Loss: 0.5546486 Vali Loss: 0.2764141 Test Loss: 0.3866003
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_180_720_FITS_ETTm2_ftM_sl180_ll48_pl720_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.38397955894470215, mae:0.3875352740287781, rse:0.49807924032211304, corr:[0.54639804 0.54625666 0.5421201  0.53923887 0.53851396 0.5384943
 0.5379583  0.5365607  0.5350345  0.53411585 0.53383046 0.53377044
 0.5333911  0.5324978  0.5315012  0.5307236  0.53020036 0.52973264
 0.5290493  0.52808017 0.52704823 0.52622944 0.5257609  0.5255688
 0.5253858  0.5249779  0.5243249  0.5235583  0.5228508  0.5222646
 0.5217965  0.5213692  0.52086395 0.520265   0.51964015 0.5191031
 0.5185898  0.5180683  0.51741177 0.51664305 0.5159112  0.51535755
 0.51504844 0.51485574 0.5145611  0.5140341  0.51323354 0.5122622
 0.5112687  0.51038    0.5096395  0.50905704 0.50847435 0.50777626
 0.50703853 0.5064219  0.5059564  0.50568795 0.5055008  0.5052964
 0.5049857  0.5046531  0.5044013  0.5041911  0.504047   0.5039546
 0.5037991  0.5036044  0.50339866 0.5032572  0.5031655  0.5030961
 0.50303483 0.50287354 0.50263894 0.50231373 0.5019701  0.50160545
 0.50125426 0.5008801  0.5004429  0.4999601  0.49950865 0.49910158
 0.49871507 0.49831706 0.49786803 0.49743256 0.49702322 0.4966574
 0.49634156 0.4959898  0.4954566  0.49460712 0.4933484  0.4916739
 0.48972198 0.48780853 0.48603114 0.48439342 0.4828821  0.48149464
 0.4801932  0.47893342 0.4776279  0.47628486 0.474976   0.47378194
 0.47269264 0.4715468  0.4704398  0.46933216 0.46825206 0.4671665
 0.4660155  0.4648742  0.46378314 0.46273196 0.46171415 0.46066007
 0.45962226 0.45866394 0.45778725 0.45694324 0.45606804 0.45510554
 0.4540798  0.45303535 0.4520289  0.4510614  0.45016292 0.4493064
 0.448493   0.44767028 0.44695678 0.4463677  0.44582835 0.4453251
 0.44480586 0.4442574  0.44365668 0.44300005 0.4422898  0.44145304
 0.4404788  0.439442   0.43841526 0.43754223 0.43690178 0.43637276
 0.43586677 0.43541923 0.4349317  0.4344276  0.4339498  0.43347698
 0.43303728 0.43262815 0.4321631  0.43166995 0.43122524 0.43087918
 0.4307027  0.4305581  0.4305191  0.43048808 0.4304073  0.43033782
 0.43031394 0.43038452 0.43048805 0.43056786 0.4305948  0.43048427
 0.4302998  0.43008825 0.4299347  0.4298165  0.42971042 0.42956066
 0.42927852 0.42886522 0.42847592 0.42818293 0.42804992 0.42795375
 0.4278027  0.42746398 0.42684874 0.4258957  0.42460045 0.42301205
 0.42128026 0.41965258 0.41809785 0.41658258 0.41518024 0.41386583
 0.4126163  0.411424   0.41025135 0.40920115 0.4082119  0.40735477
 0.40660313 0.40592033 0.40524706 0.40456107 0.40386283 0.40312105
 0.40230522 0.4014401  0.40057337 0.3997412  0.39896244 0.39817297
 0.39736912 0.3964394  0.39550066 0.39453778 0.3935133  0.39250022
 0.39147815 0.39052925 0.3897479  0.38897148 0.388166   0.38730747
 0.38635558 0.3853474  0.38436738 0.3835148  0.3828082  0.3822832
 0.38184315 0.38146305 0.38116673 0.380809   0.38043573 0.37996367
 0.3793872  0.37871054 0.37803125 0.37758297 0.37736073 0.3773281
 0.37740198 0.3774991  0.37761924 0.37772983 0.3778812  0.37808067
 0.37825477 0.37846553 0.37863308 0.3786631  0.3785384  0.37838122
 0.37826782 0.37818718 0.37814596 0.37817144 0.37817922 0.37807798
 0.377924   0.37781772 0.37780383 0.37784746 0.37789986 0.37789243
 0.37771705 0.37741    0.37703818 0.37678874 0.37670904 0.37675318
 0.37678063 0.3766823  0.3764807  0.37628242 0.37609228 0.37605342
 0.37608984 0.37603095 0.37575233 0.375166   0.37425634 0.37306702
 0.37172973 0.37057373 0.36958212 0.36876842 0.36804202 0.36733887
 0.36672705 0.3661201  0.36549965 0.36488008 0.3643486  0.3638926
 0.36347988 0.36292008 0.36229616 0.36165074 0.3610121  0.3603625
 0.3597223  0.35905376 0.35827643 0.3574271  0.35657495 0.35582587
 0.35516635 0.35459444 0.3539847  0.35329497 0.35242045 0.35143363
 0.35046715 0.34962577 0.34895128 0.3483843  0.34783193 0.34718707
 0.3464629  0.3457274  0.3451067  0.34465626 0.34431976 0.34404033
 0.34377554 0.34342602 0.3430173  0.34254214 0.3420335  0.34156698
 0.34103632 0.34038025 0.33962372 0.33901626 0.33862084 0.33848584
 0.3385562  0.3387134  0.33878687 0.33874965 0.33858332 0.33844668
 0.33838087 0.3384078  0.33844796 0.33841282 0.3382639  0.33806148
 0.3378965  0.33787757 0.33795112 0.33805826 0.33806637 0.33792827
 0.3377301  0.33760142 0.33763003 0.33782694 0.3380658  0.33826315
 0.33827814 0.33814448 0.33798742 0.3379351  0.3381709  0.33852607
 0.33884147 0.3390108  0.33900124 0.33889645 0.33882022 0.3388602
 0.3389944  0.33903858 0.33880895 0.33816844 0.33717126 0.33591875
 0.33459648 0.33335924 0.3322558  0.33124888 0.3302288  0.32927844
 0.32839447 0.3275396  0.3266934  0.32584465 0.32495564 0.3240949
 0.32332724 0.3226406  0.32206416 0.32162005 0.3212203  0.3206962
 0.3199911  0.31906003 0.31805325 0.31713575 0.3163569  0.31570223
 0.31516537 0.31467074 0.31413603 0.31351176 0.312809   0.31209725
 0.31143674 0.31083933 0.31029296 0.30980533 0.30927014 0.30874225
 0.30823222 0.30775008 0.30737564 0.30720934 0.3071324  0.30709133
 0.30706328 0.30698726 0.30678898 0.30651507 0.30615962 0.30578092
 0.30528414 0.30471507 0.30405563 0.3034762  0.30303517 0.3027373
 0.30262858 0.3026298  0.30262798 0.30246887 0.30210865 0.30173373
 0.30146432 0.30139574 0.3015086  0.30159816 0.30152863 0.30131477
 0.3010706  0.30088213 0.3008851  0.30108732 0.30125916 0.30130854
 0.3011519  0.30090427 0.30071026 0.3007171  0.30093378 0.3011679
 0.30121756 0.30104703 0.30076486 0.30054778 0.30046627 0.30054885
 0.3006774  0.3006358  0.3003497  0.2998446  0.2993533  0.29903805
 0.29883322 0.2985761  0.2980546  0.29706746 0.29559946 0.2938391
 0.29205987 0.290562   0.2893588  0.28838113 0.28748822 0.286582
 0.2856792  0.28481114 0.28406754 0.28352895 0.2831933  0.28295466
 0.2827152  0.28241378 0.28209564 0.28181046 0.2815399  0.2811494
 0.28056014 0.27970487 0.27864408 0.2775896  0.27669087 0.27601787
 0.27546158 0.2749148  0.27429312 0.27353707 0.27273175 0.27198893
 0.27136612 0.2708647  0.2704067  0.26989317 0.26928157 0.2686168
 0.26796284 0.26738042 0.26690537 0.2665012  0.2661605  0.2658501
 0.2655255  0.26521417 0.2648823  0.264451   0.26399866 0.2634503
 0.26285517 0.2622096  0.26152393 0.26086208 0.260337   0.25993726
 0.25969452 0.25960484 0.2596522  0.25967997 0.25964722 0.2594295
 0.25917843 0.2590111  0.2589099  0.2588605  0.25876567 0.2585732
 0.25826815 0.2579975  0.25786978 0.2579054  0.2579538  0.2579312
 0.2577424  0.2574441  0.25718653 0.25707775 0.25716984 0.25741404
 0.25756094 0.25754818 0.25733685 0.2570428  0.2568528  0.25685576
 0.25696364 0.25705355 0.25699672 0.25675806 0.2564804  0.2562724
 0.25620762 0.25611448 0.25574574 0.25482088 0.25327244 0.2511927
 0.24901322 0.24726565 0.24601978 0.24513671 0.24436992 0.24353328
 0.24248843 0.24135618 0.24024183 0.23923646 0.23845153 0.2379289
 0.23751566 0.2370004  0.23643951 0.23591097 0.23539977 0.23485531
 0.23419265 0.23339918 0.2325528  0.23168737 0.23094065 0.23032252
 0.22984852 0.22951582 0.22915834 0.22860055 0.2279362  0.2272115
 0.22644894 0.2258269  0.22538678 0.22502926 0.22474691 0.22438873
 0.22396983 0.22343463 0.22289443 0.2224849  0.22228011 0.22229274
 0.22232406 0.2223183  0.22203869 0.2216673  0.22131118 0.2209819
 0.22075425 0.2205831  0.22043918 0.22025648 0.2199946  0.21969661
 0.21955779 0.21976976 0.22015934 0.22051656 0.2207764  0.2207406
 0.22057956 0.22039697 0.22030014 0.22036783 0.22052892 0.22055103
 0.22037902 0.22011243 0.21996889 0.22003347 0.22034271 0.22076488
 0.22101827 0.2210408  0.22076568 0.22053234 0.22056347 0.2208798
 0.22143422 0.2219029  0.22209851 0.2221564  0.22223946 0.22246562
 0.2229891  0.22366926 0.22433864 0.22483271 0.2251069  0.22526401
 0.22542165 0.22560163 0.22558501 0.22507602 0.22387014 0.22209817
 0.22021806 0.21872549 0.21773912 0.21707156 0.21645096 0.21572736
 0.21487051 0.21406047 0.21348947 0.21317607 0.21303405 0.21293733
 0.21275735 0.21223642 0.21159121 0.2110389  0.2107326  0.21047123
 0.21003255 0.20923854 0.20807037 0.20671329 0.20545793 0.20441268
 0.20366406 0.20303218 0.2022593  0.20121932 0.19984984 0.1983476
 0.19686443 0.19565684 0.19472726 0.1940632  0.19341879 0.19262125
 0.19156554 0.19049624 0.1896379  0.18920247 0.1890591  0.18925443
 0.1893141  0.1889893  0.18853475 0.18861505 0.19023085 0.19413668]
