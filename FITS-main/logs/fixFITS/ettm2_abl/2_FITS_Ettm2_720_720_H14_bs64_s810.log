Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=122, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=810, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_720_720_FITS_ETTm2_ftM_sl720_ll48_pl720_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=122, out_features=244, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  26672128.0
params:  30012.0
Trainable parameters:  30012
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4251310
	speed: 0.0230s/iter; left time: 590.3989s
	iters: 200, epoch: 1 | loss: 0.4286642
	speed: 0.0168s/iter; left time: 429.2319s
Epoch: 1 cost time: 4.8588707447052
Epoch: 1, Steps: 258 | Train Loss: 0.4287654 Vali Loss: 0.2959727 Test Loss: 0.3950923
Validation loss decreased (inf --> 0.295973).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4100413
	speed: 0.0661s/iter; left time: 1680.8175s
	iters: 200, epoch: 2 | loss: 0.2766672
	speed: 0.0154s/iter; left time: 389.0761s
Epoch: 2 cost time: 4.474629878997803
Epoch: 2, Steps: 258 | Train Loss: 0.3158073 Vali Loss: 0.2803015 Test Loss: 0.3771632
Validation loss decreased (0.295973 --> 0.280301).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2309958
	speed: 0.0673s/iter; left time: 1693.7343s
	iters: 200, epoch: 3 | loss: 0.2198671
	speed: 0.0153s/iter; left time: 384.3380s
Epoch: 3 cost time: 4.453612565994263
Epoch: 3, Steps: 258 | Train Loss: 0.2862567 Vali Loss: 0.2742006 Test Loss: 0.3691939
Validation loss decreased (0.280301 --> 0.274201).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3570657
	speed: 0.0669s/iter; left time: 1667.8572s
	iters: 200, epoch: 4 | loss: 0.2189629
	speed: 0.0155s/iter; left time: 384.2510s
Epoch: 4 cost time: 4.453114032745361
Epoch: 4, Steps: 258 | Train Loss: 0.2720269 Vali Loss: 0.2704872 Test Loss: 0.3641663
Validation loss decreased (0.274201 --> 0.270487).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2934185
	speed: 0.0666s/iter; left time: 1642.9041s
	iters: 200, epoch: 5 | loss: 0.3269805
	speed: 0.0155s/iter; left time: 380.0020s
Epoch: 5 cost time: 4.496904134750366
Epoch: 5, Steps: 258 | Train Loss: 0.2647914 Vali Loss: 0.2677953 Test Loss: 0.3609851
Validation loss decreased (0.270487 --> 0.267795).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3027537
	speed: 0.0666s/iter; left time: 1626.3313s
	iters: 200, epoch: 6 | loss: 0.2927232
	speed: 0.0157s/iter; left time: 381.2461s
Epoch: 6 cost time: 4.510690212249756
Epoch: 6, Steps: 258 | Train Loss: 0.2605888 Vali Loss: 0.2661701 Test Loss: 0.3588115
Validation loss decreased (0.267795 --> 0.266170).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1846086
	speed: 0.0662s/iter; left time: 1598.0957s
	iters: 200, epoch: 7 | loss: 0.2798323
	speed: 0.0154s/iter; left time: 371.2033s
Epoch: 7 cost time: 4.428940534591675
Epoch: 7, Steps: 258 | Train Loss: 0.2586633 Vali Loss: 0.2651136 Test Loss: 0.3574384
Validation loss decreased (0.266170 --> 0.265114).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2195126
	speed: 0.0656s/iter; left time: 1566.7901s
	iters: 200, epoch: 8 | loss: 0.2025152
	speed: 0.0154s/iter; left time: 365.5361s
Epoch: 8 cost time: 4.41487979888916
Epoch: 8, Steps: 258 | Train Loss: 0.2572419 Vali Loss: 0.2645249 Test Loss: 0.3565241
Validation loss decreased (0.265114 --> 0.264525).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3151509
	speed: 0.0675s/iter; left time: 1595.7166s
	iters: 200, epoch: 9 | loss: 0.2545446
	speed: 0.0154s/iter; left time: 363.2688s
Epoch: 9 cost time: 4.542936086654663
Epoch: 9, Steps: 258 | Train Loss: 0.2565667 Vali Loss: 0.2638244 Test Loss: 0.3558656
Validation loss decreased (0.264525 --> 0.263824).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2423864
	speed: 0.0672s/iter; left time: 1571.8098s
	iters: 200, epoch: 10 | loss: 0.2043261
	speed: 0.0154s/iter; left time: 358.6414s
Epoch: 10 cost time: 4.46248984336853
Epoch: 10, Steps: 258 | Train Loss: 0.2561195 Vali Loss: 0.2634919 Test Loss: 0.3555866
Validation loss decreased (0.263824 --> 0.263492).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1789267
	speed: 0.0671s/iter; left time: 1552.0903s
	iters: 200, epoch: 11 | loss: 0.3047906
	speed: 0.0157s/iter; left time: 360.9628s
Epoch: 11 cost time: 4.433211088180542
Epoch: 11, Steps: 258 | Train Loss: 0.2559132 Vali Loss: 0.2636878 Test Loss: 0.3549568
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2711151
	speed: 0.0650s/iter; left time: 1486.6692s
	iters: 200, epoch: 12 | loss: 0.2782124
	speed: 0.0151s/iter; left time: 344.6261s
Epoch: 12 cost time: 4.383381128311157
Epoch: 12, Steps: 258 | Train Loss: 0.2556540 Vali Loss: 0.2632779 Test Loss: 0.3547784
Validation loss decreased (0.263492 --> 0.263278).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2358571
	speed: 0.0670s/iter; left time: 1514.9925s
	iters: 200, epoch: 13 | loss: 0.2015651
	speed: 0.0155s/iter; left time: 348.7211s
Epoch: 13 cost time: 4.469162464141846
Epoch: 13, Steps: 258 | Train Loss: 0.2551429 Vali Loss: 0.2627248 Test Loss: 0.3547636
Validation loss decreased (0.263278 --> 0.262725).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2488865
	speed: 0.0684s/iter; left time: 1528.9215s
	iters: 200, epoch: 14 | loss: 0.2830655
	speed: 0.0154s/iter; left time: 342.9262s
Epoch: 14 cost time: 4.502061128616333
Epoch: 14, Steps: 258 | Train Loss: 0.2552498 Vali Loss: 0.2629609 Test Loss: 0.3545730
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2556428
	speed: 0.1116s/iter; left time: 2464.6461s
	iters: 200, epoch: 15 | loss: 0.3086768
	speed: 0.0294s/iter; left time: 645.9025s
Epoch: 15 cost time: 8.16318416595459
Epoch: 15, Steps: 258 | Train Loss: 0.2547759 Vali Loss: 0.2625784 Test Loss: 0.3544826
Validation loss decreased (0.262725 --> 0.262578).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3082837
	speed: 0.1107s/iter; left time: 2417.3534s
	iters: 200, epoch: 16 | loss: 0.3024810
	speed: 0.0295s/iter; left time: 640.3344s
Epoch: 16 cost time: 7.685483455657959
Epoch: 16, Steps: 258 | Train Loss: 0.2552451 Vali Loss: 0.2628565 Test Loss: 0.3542100
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2247173
	speed: 0.1146s/iter; left time: 2471.2721s
	iters: 200, epoch: 17 | loss: 0.2576788
	speed: 0.0300s/iter; left time: 644.9589s
Epoch: 17 cost time: 8.532855033874512
Epoch: 17, Steps: 258 | Train Loss: 0.2552111 Vali Loss: 0.2627998 Test Loss: 0.3542592
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2327506
	speed: 0.1057s/iter; left time: 2253.4354s
	iters: 200, epoch: 18 | loss: 0.2566889
	speed: 0.0317s/iter; left time: 671.6178s
Epoch: 18 cost time: 8.199949979782104
Epoch: 18, Steps: 258 | Train Loss: 0.2549421 Vali Loss: 0.2623308 Test Loss: 0.3543448
Validation loss decreased (0.262578 --> 0.262331).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2349166
	speed: 0.1179s/iter; left time: 2483.2263s
	iters: 200, epoch: 19 | loss: 0.2735162
	speed: 0.0333s/iter; left time: 697.4637s
Epoch: 19 cost time: 8.542561769485474
Epoch: 19, Steps: 258 | Train Loss: 0.2547918 Vali Loss: 0.2627299 Test Loss: 0.3541713
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2461706
	speed: 0.1143s/iter; left time: 2377.7248s
	iters: 200, epoch: 20 | loss: 0.1433262
	speed: 0.0328s/iter; left time: 679.5020s
Epoch: 20 cost time: 9.138315200805664
Epoch: 20, Steps: 258 | Train Loss: 0.2549495 Vali Loss: 0.2625009 Test Loss: 0.3541682
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2010489
	speed: 0.1238s/iter; left time: 2542.5807s
	iters: 200, epoch: 21 | loss: 0.2886474
	speed: 0.0361s/iter; left time: 738.7671s
Epoch: 21 cost time: 9.153606653213501
Epoch: 21, Steps: 258 | Train Loss: 0.2548414 Vali Loss: 0.2627544 Test Loss: 0.3542323
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2562326
	speed: 0.1168s/iter; left time: 2368.5517s
	iters: 200, epoch: 22 | loss: 0.2337253
	speed: 0.0311s/iter; left time: 627.9322s
Epoch: 22 cost time: 8.324066400527954
Epoch: 22, Steps: 258 | Train Loss: 0.2546340 Vali Loss: 0.2627885 Test Loss: 0.3540520
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2306495
	speed: 0.1220s/iter; left time: 2442.2531s
	iters: 200, epoch: 23 | loss: 0.2301736
	speed: 0.0373s/iter; left time: 742.6263s
Epoch: 23 cost time: 9.394808292388916
Epoch: 23, Steps: 258 | Train Loss: 0.2547393 Vali Loss: 0.2627698 Test Loss: 0.3541319
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2363286
	speed: 0.1048s/iter; left time: 2070.9738s
	iters: 200, epoch: 24 | loss: 0.3398786
	speed: 0.0234s/iter; left time: 460.0158s
Epoch: 24 cost time: 6.470117568969727
Epoch: 24, Steps: 258 | Train Loss: 0.2549001 Vali Loss: 0.2625181 Test Loss: 0.3540892
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2792966
	speed: 0.1083s/iter; left time: 2113.1582s
	iters: 200, epoch: 25 | loss: 0.2333737
	speed: 0.0255s/iter; left time: 494.4656s
Epoch: 25 cost time: 6.989187002182007
Epoch: 25, Steps: 258 | Train Loss: 0.2549233 Vali Loss: 0.2625735 Test Loss: 0.3541005
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3896822
	speed: 0.0933s/iter; left time: 1795.2958s
	iters: 200, epoch: 26 | loss: 0.1792014
	speed: 0.0250s/iter; left time: 479.2634s
Epoch: 26 cost time: 7.128950357437134
Epoch: 26, Steps: 258 | Train Loss: 0.2547527 Vali Loss: 0.2626550 Test Loss: 0.3540511
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2508394
	speed: 0.1103s/iter; left time: 2094.5431s
	iters: 200, epoch: 27 | loss: 0.2241630
	speed: 0.0276s/iter; left time: 521.7724s
Epoch: 27 cost time: 7.907962322235107
Epoch: 27, Steps: 258 | Train Loss: 0.2549144 Vali Loss: 0.2624382 Test Loss: 0.3540455
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2668209
	speed: 0.1049s/iter; left time: 1965.4259s
	iters: 200, epoch: 28 | loss: 0.2166346
	speed: 0.0251s/iter; left time: 468.1477s
Epoch: 28 cost time: 7.123577117919922
Epoch: 28, Steps: 258 | Train Loss: 0.2550506 Vali Loss: 0.2629295 Test Loss: 0.3539826
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2616967
	speed: 0.0971s/iter; left time: 1794.5690s
	iters: 200, epoch: 29 | loss: 0.2447165
	speed: 0.0271s/iter; left time: 497.8014s
Epoch: 29 cost time: 7.5441038608551025
Epoch: 29, Steps: 258 | Train Loss: 0.2549544 Vali Loss: 0.2624441 Test Loss: 0.3540514
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2208227
	speed: 0.1108s/iter; left time: 2018.6616s
	iters: 200, epoch: 30 | loss: 0.1935523
	speed: 0.0307s/iter; left time: 556.9514s
Epoch: 30 cost time: 8.881269216537476
Epoch: 30, Steps: 258 | Train Loss: 0.2549686 Vali Loss: 0.2626123 Test Loss: 0.3539849
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2508442
	speed: 0.1142s/iter; left time: 2050.7249s
	iters: 200, epoch: 31 | loss: 0.2442967
	speed: 0.0287s/iter; left time: 512.2952s
Epoch: 31 cost time: 7.574120759963989
Epoch: 31, Steps: 258 | Train Loss: 0.2547503 Vali Loss: 0.2624272 Test Loss: 0.3539700
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2496716
	speed: 0.0978s/iter; left time: 1731.6152s
	iters: 200, epoch: 32 | loss: 0.2414302
	speed: 0.0266s/iter; left time: 467.8458s
Epoch: 32 cost time: 7.256191730499268
Epoch: 32, Steps: 258 | Train Loss: 0.2547346 Vali Loss: 0.2623810 Test Loss: 0.3540046
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3029594
	speed: 0.1024s/iter; left time: 1786.7495s
	iters: 200, epoch: 33 | loss: 0.1763620
	speed: 0.0355s/iter; left time: 615.3277s
Epoch: 33 cost time: 8.493383407592773
Epoch: 33, Steps: 258 | Train Loss: 0.2549761 Vali Loss: 0.2628580 Test Loss: 0.3539519
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1857962
	speed: 0.1160s/iter; left time: 1993.0119s
	iters: 200, epoch: 34 | loss: 0.2508741
	speed: 0.0274s/iter; left time: 467.9848s
Epoch: 34 cost time: 7.598762273788452
Epoch: 34, Steps: 258 | Train Loss: 0.2546933 Vali Loss: 0.2625208 Test Loss: 0.3539599
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3269058
	speed: 0.1068s/iter; left time: 1808.3511s
	iters: 200, epoch: 35 | loss: 0.2357075
	speed: 0.0281s/iter; left time: 472.2405s
Epoch: 35 cost time: 7.628455400466919
Epoch: 35, Steps: 258 | Train Loss: 0.2546719 Vali Loss: 0.2628438 Test Loss: 0.3539136
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2533554
	speed: 0.1067s/iter; left time: 1778.0437s
	iters: 200, epoch: 36 | loss: 0.2310497
	speed: 0.0271s/iter; left time: 448.3549s
Epoch: 36 cost time: 7.638510465621948
Epoch: 36, Steps: 258 | Train Loss: 0.2546836 Vali Loss: 0.2626395 Test Loss: 0.3539052
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2369583
	speed: 0.1258s/iter; left time: 2064.8403s
	iters: 200, epoch: 37 | loss: 0.2259255
	speed: 0.0300s/iter; left time: 489.1864s
Epoch: 37 cost time: 8.824790716171265
Epoch: 37, Steps: 258 | Train Loss: 0.2543059 Vali Loss: 0.2624182 Test Loss: 0.3539323
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1683633
	speed: 0.1064s/iter; left time: 1719.0741s
	iters: 200, epoch: 38 | loss: 0.2385633
	speed: 0.0304s/iter; left time: 487.3287s
Epoch: 38 cost time: 7.464778900146484
Epoch: 38, Steps: 258 | Train Loss: 0.2548327 Vali Loss: 0.2624513 Test Loss: 0.3540008
EarlyStopping counter: 20 out of 20
Early stopping
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=122, out_features=244, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  26672128.0
params:  30012.0
Trainable parameters:  30012
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4727293
	speed: 0.0331s/iter; left time: 851.3686s
	iters: 200, epoch: 1 | loss: 0.4371919
	speed: 0.0288s/iter; left time: 738.1226s
Epoch: 1 cost time: 7.58700704574585
Epoch: 1, Steps: 258 | Train Loss: 0.4965445 Vali Loss: 0.2613885 Test Loss: 0.3536028
Validation loss decreased (inf --> 0.261388).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5168557
	speed: 0.1228s/iter; left time: 3124.4499s
	iters: 200, epoch: 2 | loss: 0.4652781
	speed: 0.0501s/iter; left time: 1268.7567s
Epoch: 2 cost time: 12.539021968841553
Epoch: 2, Steps: 258 | Train Loss: 0.4955956 Vali Loss: 0.2608734 Test Loss: 0.3532515
Validation loss decreased (0.261388 --> 0.260873).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3181955
	speed: 0.1481s/iter; left time: 3730.1271s
	iters: 200, epoch: 3 | loss: 0.5901725
	speed: 0.0277s/iter; left time: 695.0161s
Epoch: 3 cost time: 7.834785223007202
Epoch: 3, Steps: 258 | Train Loss: 0.4953355 Vali Loss: 0.2607002 Test Loss: 0.3528089
Validation loss decreased (0.260873 --> 0.260700).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3703309
	speed: 0.1087s/iter; left time: 2708.3688s
	iters: 200, epoch: 4 | loss: 0.4256088
	speed: 0.0265s/iter; left time: 657.9947s
Epoch: 4 cost time: 7.990795135498047
Epoch: 4, Steps: 258 | Train Loss: 0.4951322 Vali Loss: 0.2608072 Test Loss: 0.3526633
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.6052621
	speed: 0.1140s/iter; left time: 2812.2621s
	iters: 200, epoch: 5 | loss: 0.5128736
	speed: 0.0312s/iter; left time: 767.5247s
Epoch: 5 cost time: 7.9111549854278564
Epoch: 5, Steps: 258 | Train Loss: 0.4945534 Vali Loss: 0.2603974 Test Loss: 0.3524643
Validation loss decreased (0.260700 --> 0.260397).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4788660
	speed: 0.1046s/iter; left time: 2552.6722s
	iters: 200, epoch: 6 | loss: 0.4451041
	speed: 0.0267s/iter; left time: 647.9988s
Epoch: 6 cost time: 7.6725616455078125
Epoch: 6, Steps: 258 | Train Loss: 0.4951038 Vali Loss: 0.2603749 Test Loss: 0.3520165
Validation loss decreased (0.260397 --> 0.260375).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3216943
	speed: 0.1057s/iter; left time: 2553.6032s
	iters: 200, epoch: 7 | loss: 0.5501634
	speed: 0.0274s/iter; left time: 659.4738s
Epoch: 7 cost time: 7.30615496635437
Epoch: 7, Steps: 258 | Train Loss: 0.4945935 Vali Loss: 0.2605459 Test Loss: 0.3521655
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.5516568
	speed: 0.1201s/iter; left time: 2870.5223s
	iters: 200, epoch: 8 | loss: 0.5831546
	speed: 0.0350s/iter; left time: 831.7959s
Epoch: 8 cost time: 8.793205261230469
Epoch: 8, Steps: 258 | Train Loss: 0.4943068 Vali Loss: 0.2606520 Test Loss: 0.3521548
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.5189151
	speed: 0.1087s/iter; left time: 2568.8094s
	iters: 200, epoch: 9 | loss: 0.5784726
	speed: 0.0285s/iter; left time: 671.3259s
Epoch: 9 cost time: 7.664813041687012
Epoch: 9, Steps: 258 | Train Loss: 0.4937488 Vali Loss: 0.2598999 Test Loss: 0.3523663
Validation loss decreased (0.260375 --> 0.259900).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.6175523
	speed: 0.1068s/iter; left time: 2496.6409s
	iters: 200, epoch: 10 | loss: 0.4928937
	speed: 0.0265s/iter; left time: 616.1067s
Epoch: 10 cost time: 7.469485521316528
Epoch: 10, Steps: 258 | Train Loss: 0.4943821 Vali Loss: 0.2602004 Test Loss: 0.3521352
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3596506
	speed: 0.1174s/iter; left time: 2713.8713s
	iters: 200, epoch: 11 | loss: 0.6259280
	speed: 0.0303s/iter; left time: 697.9804s
Epoch: 11 cost time: 8.722222805023193
Epoch: 11, Steps: 258 | Train Loss: 0.4939302 Vali Loss: 0.2603387 Test Loss: 0.3523438
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3573862
	speed: 0.1053s/iter; left time: 2406.6715s
	iters: 200, epoch: 12 | loss: 0.5164691
	speed: 0.0263s/iter; left time: 599.4485s
Epoch: 12 cost time: 7.205398082733154
Epoch: 12, Steps: 258 | Train Loss: 0.4935917 Vali Loss: 0.2599468 Test Loss: 0.3522934
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4863259
	speed: 0.1034s/iter; left time: 2337.0051s
	iters: 200, epoch: 13 | loss: 0.3994705
	speed: 0.0262s/iter; left time: 589.5761s
Epoch: 13 cost time: 7.568318843841553
Epoch: 13, Steps: 258 | Train Loss: 0.4939121 Vali Loss: 0.2600788 Test Loss: 0.3521461
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4782637
	speed: 0.0989s/iter; left time: 2209.5010s
	iters: 200, epoch: 14 | loss: 0.4504386
	speed: 0.0223s/iter; left time: 495.7667s
Epoch: 14 cost time: 5.649166107177734
Epoch: 14, Steps: 258 | Train Loss: 0.4936665 Vali Loss: 0.2599376 Test Loss: 0.3521348
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.5393087
	speed: 0.1004s/iter; left time: 2217.7964s
	iters: 200, epoch: 15 | loss: 0.4444241
	speed: 0.0323s/iter; left time: 709.5663s
Epoch: 15 cost time: 8.217534065246582
Epoch: 15, Steps: 258 | Train Loss: 0.4938188 Vali Loss: 0.2598762 Test Loss: 0.3523012
Validation loss decreased (0.259900 --> 0.259876).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.6486093
	speed: 0.1452s/iter; left time: 3170.2921s
	iters: 200, epoch: 16 | loss: 0.6022811
	speed: 0.0282s/iter; left time: 612.8102s
Epoch: 16 cost time: 8.791126489639282
Epoch: 16, Steps: 258 | Train Loss: 0.4936152 Vali Loss: 0.2598661 Test Loss: 0.3522223
Validation loss decreased (0.259876 --> 0.259866).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4498636
	speed: 0.1034s/iter; left time: 2230.7485s
	iters: 200, epoch: 17 | loss: 0.5757799
	speed: 0.0318s/iter; left time: 682.1756s
Epoch: 17 cost time: 7.854693651199341
Epoch: 17, Steps: 258 | Train Loss: 0.4932164 Vali Loss: 0.2601657 Test Loss: 0.3520469
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4426053
	speed: 0.1148s/iter; left time: 2446.4772s
	iters: 200, epoch: 18 | loss: 0.5473378
	speed: 0.0316s/iter; left time: 670.1570s
Epoch: 18 cost time: 8.473212003707886
Epoch: 18, Steps: 258 | Train Loss: 0.4934967 Vali Loss: 0.2600707 Test Loss: 0.3520152
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4054407
	speed: 0.1108s/iter; left time: 2332.9409s
	iters: 200, epoch: 19 | loss: 0.4815074
	speed: 0.0267s/iter; left time: 559.8771s
Epoch: 19 cost time: 7.303628921508789
Epoch: 19, Steps: 258 | Train Loss: 0.4934154 Vali Loss: 0.2601946 Test Loss: 0.3520148
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4188818
	speed: 0.1050s/iter; left time: 2183.1150s
	iters: 200, epoch: 20 | loss: 0.4706385
	speed: 0.0257s/iter; left time: 532.6670s
Epoch: 20 cost time: 7.519515514373779
Epoch: 20, Steps: 258 | Train Loss: 0.4936697 Vali Loss: 0.2598848 Test Loss: 0.3519936
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4225104
	speed: 0.1113s/iter; left time: 2285.5520s
	iters: 200, epoch: 21 | loss: 0.4626517
	speed: 0.0311s/iter; left time: 635.3433s
Epoch: 21 cost time: 8.158620357513428
Epoch: 21, Steps: 258 | Train Loss: 0.4935462 Vali Loss: 0.2600442 Test Loss: 0.3521029
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4182041
	speed: 0.1099s/iter; left time: 2229.6396s
	iters: 200, epoch: 22 | loss: 0.5516770
	speed: 0.0298s/iter; left time: 600.5648s
Epoch: 22 cost time: 7.364562749862671
Epoch: 22, Steps: 258 | Train Loss: 0.4932478 Vali Loss: 0.2599950 Test Loss: 0.3520676
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4871588
	speed: 0.0980s/iter; left time: 1963.1242s
	iters: 200, epoch: 23 | loss: 0.4220121
	speed: 0.0287s/iter; left time: 571.6580s
Epoch: 23 cost time: 7.777687311172485
Epoch: 23, Steps: 258 | Train Loss: 0.4932176 Vali Loss: 0.2599601 Test Loss: 0.3521150
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4071981
	speed: 0.1096s/iter; left time: 2166.0761s
	iters: 200, epoch: 24 | loss: 0.5450836
	speed: 0.0271s/iter; left time: 532.2491s
Epoch: 24 cost time: 7.7286622524261475
Epoch: 24, Steps: 258 | Train Loss: 0.4935126 Vali Loss: 0.2599466 Test Loss: 0.3519950
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4092302
	speed: 0.1147s/iter; left time: 2236.7888s
	iters: 200, epoch: 25 | loss: 0.4710872
	speed: 0.0302s/iter; left time: 586.5434s
Epoch: 25 cost time: 7.966488838195801
Epoch: 25, Steps: 258 | Train Loss: 0.4935135 Vali Loss: 0.2598059 Test Loss: 0.3520643
Validation loss decreased (0.259866 --> 0.259806).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4759068
	speed: 0.1040s/iter; left time: 2001.5589s
	iters: 200, epoch: 26 | loss: 0.4239964
	speed: 0.0268s/iter; left time: 513.5893s
Epoch: 26 cost time: 7.717296361923218
Epoch: 26, Steps: 258 | Train Loss: 0.4929357 Vali Loss: 0.2597388 Test Loss: 0.3520171
Validation loss decreased (0.259806 --> 0.259739).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.6114739
	speed: 0.1060s/iter; left time: 2012.3973s
	iters: 200, epoch: 27 | loss: 0.4933339
	speed: 0.0250s/iter; left time: 471.6180s
Epoch: 27 cost time: 7.610485792160034
Epoch: 27, Steps: 258 | Train Loss: 0.4935221 Vali Loss: 0.2596894 Test Loss: 0.3520675
Validation loss decreased (0.259739 --> 0.259689).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.5418459
	speed: 0.1113s/iter; left time: 2085.6963s
	iters: 200, epoch: 28 | loss: 0.3388271
	speed: 0.0268s/iter; left time: 498.8692s
Epoch: 28 cost time: 7.157336950302124
Epoch: 28, Steps: 258 | Train Loss: 0.4930385 Vali Loss: 0.2596982 Test Loss: 0.3519726
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3861264
	speed: 0.1000s/iter; left time: 1848.3316s
	iters: 200, epoch: 29 | loss: 0.3492959
	speed: 0.0269s/iter; left time: 495.1463s
Epoch: 29 cost time: 7.480670213699341
Epoch: 29, Steps: 258 | Train Loss: 0.4930331 Vali Loss: 0.2598902 Test Loss: 0.3520177
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.5135168
	speed: 0.0998s/iter; left time: 1818.9774s
	iters: 200, epoch: 30 | loss: 0.4334147
	speed: 0.0247s/iter; left time: 447.3513s
Epoch: 30 cost time: 7.083509206771851
Epoch: 30, Steps: 258 | Train Loss: 0.4932673 Vali Loss: 0.2598460 Test Loss: 0.3519624
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4831639
	speed: 0.1007s/iter; left time: 1808.6106s
	iters: 200, epoch: 31 | loss: 0.4584501
	speed: 0.0325s/iter; left time: 579.8604s
Epoch: 31 cost time: 8.401170015335083
Epoch: 31, Steps: 258 | Train Loss: 0.4927309 Vali Loss: 0.2600616 Test Loss: 0.3519214
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4474471
	speed: 0.1135s/iter; left time: 2009.8845s
	iters: 200, epoch: 32 | loss: 0.6553278
	speed: 0.0259s/iter; left time: 455.8377s
Epoch: 32 cost time: 7.440619945526123
Epoch: 32, Steps: 258 | Train Loss: 0.4928451 Vali Loss: 0.2596906 Test Loss: 0.3519989
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4740749
	speed: 0.1022s/iter; left time: 1782.0318s
	iters: 200, epoch: 33 | loss: 0.4613805
	speed: 0.0278s/iter; left time: 481.5396s
Epoch: 33 cost time: 7.905809164047241
Epoch: 33, Steps: 258 | Train Loss: 0.4930011 Vali Loss: 0.2597559 Test Loss: 0.3519386
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3678186
	speed: 0.1014s/iter; left time: 1743.4422s
	iters: 200, epoch: 34 | loss: 0.4506029
	speed: 0.0307s/iter; left time: 523.8968s
Epoch: 34 cost time: 7.888676643371582
Epoch: 34, Steps: 258 | Train Loss: 0.4931716 Vali Loss: 0.2597571 Test Loss: 0.3520215
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4013487
	speed: 0.1221s/iter; left time: 2066.5697s
	iters: 200, epoch: 35 | loss: 0.5405796
	speed: 0.0297s/iter; left time: 499.6032s
Epoch: 35 cost time: 8.154312133789062
Epoch: 35, Steps: 258 | Train Loss: 0.4933673 Vali Loss: 0.2597130 Test Loss: 0.3519743
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.5369860
	speed: 0.0890s/iter; left time: 1483.4231s
	iters: 200, epoch: 36 | loss: 0.4960521
	speed: 0.0276s/iter; left time: 456.9849s
Epoch: 36 cost time: 6.496158599853516
Epoch: 36, Steps: 258 | Train Loss: 0.4930227 Vali Loss: 0.2597813 Test Loss: 0.3520096
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4336656
	speed: 0.1052s/iter; left time: 1726.9442s
	iters: 200, epoch: 37 | loss: 0.3902325
	speed: 0.0262s/iter; left time: 427.7598s
Epoch: 37 cost time: 7.406968355178833
Epoch: 37, Steps: 258 | Train Loss: 0.4927640 Vali Loss: 0.2596504 Test Loss: 0.3520139
Validation loss decreased (0.259689 --> 0.259650).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4332115
	speed: 0.1085s/iter; left time: 1752.8528s
	iters: 200, epoch: 38 | loss: 0.5176840
	speed: 0.0320s/iter; left time: 514.5430s
Epoch: 38 cost time: 9.164527654647827
Epoch: 38, Steps: 258 | Train Loss: 0.4927938 Vali Loss: 0.2597892 Test Loss: 0.3519414
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3943799
	speed: 0.1174s/iter; left time: 1866.7906s
	iters: 200, epoch: 39 | loss: 0.4467433
	speed: 0.0264s/iter; left time: 416.9377s
Epoch: 39 cost time: 7.415725946426392
Epoch: 39, Steps: 258 | Train Loss: 0.4924124 Vali Loss: 0.2595924 Test Loss: 0.3519573
Validation loss decreased (0.259650 --> 0.259592).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.5994792
	speed: 0.1021s/iter; left time: 1596.0249s
	iters: 200, epoch: 40 | loss: 0.5240824
	speed: 0.0280s/iter; left time: 434.7332s
Epoch: 40 cost time: 7.3880393505096436
Epoch: 40, Steps: 258 | Train Loss: 0.4930593 Vali Loss: 0.2599236 Test Loss: 0.3519543
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.4708290
	speed: 0.1096s/iter; left time: 1685.4536s
	iters: 200, epoch: 41 | loss: 0.5295346
	speed: 0.0295s/iter; left time: 450.4903s
Epoch: 41 cost time: 8.969541788101196
Epoch: 41, Steps: 258 | Train Loss: 0.4931419 Vali Loss: 0.2596561 Test Loss: 0.3520018
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3889787
	speed: 0.1151s/iter; left time: 1740.8855s
	iters: 200, epoch: 42 | loss: 0.5164877
	speed: 0.0260s/iter; left time: 391.0727s
Epoch: 42 cost time: 7.7147979736328125
Epoch: 42, Steps: 258 | Train Loss: 0.4934160 Vali Loss: 0.2595926 Test Loss: 0.3519788
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.5098907
	speed: 0.1008s/iter; left time: 1498.7381s
	iters: 200, epoch: 43 | loss: 0.4567702
	speed: 0.0281s/iter; left time: 415.2450s
Epoch: 43 cost time: 7.347340822219849
Epoch: 43, Steps: 258 | Train Loss: 0.4933233 Vali Loss: 0.2597187 Test Loss: 0.3519691
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.4869398
	speed: 0.0985s/iter; left time: 1438.4689s
	iters: 200, epoch: 44 | loss: 0.5382305
	speed: 0.0295s/iter; left time: 428.5459s
Epoch: 44 cost time: 7.912040948867798
Epoch: 44, Steps: 258 | Train Loss: 0.4922004 Vali Loss: 0.2596564 Test Loss: 0.3519543
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.4880893
	speed: 0.1128s/iter; left time: 1619.1949s
	iters: 200, epoch: 45 | loss: 0.5640295
	speed: 0.0303s/iter; left time: 432.2118s
Epoch: 45 cost time: 8.231993913650513
Epoch: 45, Steps: 258 | Train Loss: 0.4932802 Vali Loss: 0.2597586 Test Loss: 0.3519571
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.5866668
	speed: 0.1488s/iter; left time: 2097.4380s
	iters: 200, epoch: 46 | loss: 0.3556702
	speed: 0.0410s/iter; left time: 573.4441s
Epoch: 46 cost time: 10.997626543045044
Epoch: 46, Steps: 258 | Train Loss: 0.4927870 Vali Loss: 0.2595010 Test Loss: 0.3519623
Validation loss decreased (0.259592 --> 0.259501).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.4269166
	speed: 0.1517s/iter; left time: 2098.6651s
	iters: 200, epoch: 47 | loss: 0.4851298
	speed: 0.0350s/iter; left time: 480.7158s
Epoch: 47 cost time: 9.787410020828247
Epoch: 47, Steps: 258 | Train Loss: 0.4934361 Vali Loss: 0.2597506 Test Loss: 0.3519381
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.5229476
	speed: 0.1077s/iter; left time: 1462.4368s
	iters: 200, epoch: 48 | loss: 0.5784433
	speed: 0.0277s/iter; left time: 373.5238s
Epoch: 48 cost time: 7.479111433029175
Epoch: 48, Steps: 258 | Train Loss: 0.4931662 Vali Loss: 0.2598130 Test Loss: 0.3519660
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.4664493
	speed: 0.1055s/iter; left time: 1404.6365s
	iters: 200, epoch: 49 | loss: 0.4422447
	speed: 0.0293s/iter; left time: 387.0057s
Epoch: 49 cost time: 8.090144634246826
Epoch: 49, Steps: 258 | Train Loss: 0.4926366 Vali Loss: 0.2598820 Test Loss: 0.3519621
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.4398966
	speed: 0.1093s/iter; left time: 1427.9516s
	iters: 200, epoch: 50 | loss: 0.4047331
	speed: 0.0314s/iter; left time: 406.7676s
Epoch: 50 cost time: 8.786747455596924
Epoch: 50, Steps: 258 | Train Loss: 0.4930166 Vali Loss: 0.2598460 Test Loss: 0.3519470
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.4642735
	speed: 0.1216s/iter; left time: 1556.0419s
	iters: 200, epoch: 51 | loss: 0.5383222
	speed: 0.0268s/iter; left time: 340.6626s
Epoch: 51 cost time: 7.754368782043457
Epoch: 51, Steps: 258 | Train Loss: 0.4926917 Vali Loss: 0.2595130 Test Loss: 0.3519506
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.5338523
	speed: 0.0993s/iter; left time: 1245.2607s
	iters: 200, epoch: 52 | loss: 0.4050245
	speed: 0.0293s/iter; left time: 364.8565s
Epoch: 52 cost time: 7.545344352722168
Epoch: 52, Steps: 258 | Train Loss: 0.4925486 Vali Loss: 0.2596864 Test Loss: 0.3519608
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.3533046
	speed: 0.1004s/iter; left time: 1233.5040s
	iters: 200, epoch: 53 | loss: 0.4358874
	speed: 0.0274s/iter; left time: 333.8595s
Epoch: 53 cost time: 7.635478496551514
Epoch: 53, Steps: 258 | Train Loss: 0.4927927 Vali Loss: 0.2596749 Test Loss: 0.3519538
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.5597922
	speed: 0.1249s/iter; left time: 1502.3403s
	iters: 200, epoch: 54 | loss: 0.5514258
	speed: 0.0325s/iter; left time: 387.7658s
Epoch: 54 cost time: 8.403626441955566
Epoch: 54, Steps: 258 | Train Loss: 0.4928068 Vali Loss: 0.2599089 Test Loss: 0.3519477
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.4981277
	speed: 0.1065s/iter; left time: 1253.4157s
	iters: 200, epoch: 55 | loss: 0.4628805
	speed: 0.0297s/iter; left time: 346.2519s
Epoch: 55 cost time: 7.8587965965271
Epoch: 55, Steps: 258 | Train Loss: 0.4929316 Vali Loss: 0.2597739 Test Loss: 0.3519394
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.4816080
	speed: 0.1038s/iter; left time: 1194.8922s
	iters: 200, epoch: 56 | loss: 0.4595202
	speed: 0.0283s/iter; left time: 323.0046s
Epoch: 56 cost time: 7.579580068588257
Epoch: 56, Steps: 258 | Train Loss: 0.4926627 Vali Loss: 0.2597322 Test Loss: 0.3519520
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.6524304
	speed: 0.1109s/iter; left time: 1248.3330s
	iters: 200, epoch: 57 | loss: 0.3440369
	speed: 0.0333s/iter; left time: 370.8971s
Epoch: 57 cost time: 8.34160566329956
Epoch: 57, Steps: 258 | Train Loss: 0.4929739 Vali Loss: 0.2597720 Test Loss: 0.3519358
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.4290752
	speed: 0.1155s/iter; left time: 1269.6349s
	iters: 200, epoch: 58 | loss: 0.5101402
	speed: 0.0275s/iter; left time: 299.4100s
Epoch: 58 cost time: 8.041123151779175
Epoch: 58, Steps: 258 | Train Loss: 0.4922285 Vali Loss: 0.2599835 Test Loss: 0.3519449
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.5429155
	speed: 0.1138s/iter; left time: 1222.0145s
	iters: 200, epoch: 59 | loss: 0.4758405
	speed: 0.0297s/iter; left time: 316.0688s
Epoch: 59 cost time: 8.32133674621582
Epoch: 59, Steps: 258 | Train Loss: 0.4925561 Vali Loss: 0.2599162 Test Loss: 0.3519285
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.4339871
	speed: 0.1181s/iter; left time: 1237.4848s
	iters: 200, epoch: 60 | loss: 0.3492125
	speed: 0.0342s/iter; left time: 354.8124s
Epoch: 60 cost time: 9.161815643310547
Epoch: 60, Steps: 258 | Train Loss: 0.4929568 Vali Loss: 0.2597105 Test Loss: 0.3519404
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.3789382
	speed: 0.1087s/iter; left time: 1110.7777s
	iters: 200, epoch: 61 | loss: 0.5182042
	speed: 0.0291s/iter; left time: 294.9512s
Epoch: 61 cost time: 7.583709001541138
Epoch: 61, Steps: 258 | Train Loss: 0.4930570 Vali Loss: 0.2596961 Test Loss: 0.3519300
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.3785397
	speed: 0.1035s/iter; left time: 1031.3976s
	iters: 200, epoch: 62 | loss: 0.5580581
	speed: 0.0281s/iter; left time: 276.8366s
Epoch: 62 cost time: 7.748208045959473
Epoch: 62, Steps: 258 | Train Loss: 0.4929882 Vali Loss: 0.2597596 Test Loss: 0.3519286
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.4070230
	speed: 0.1094s/iter; left time: 1061.7100s
	iters: 200, epoch: 63 | loss: 0.4748712
	speed: 0.0327s/iter; left time: 314.1216s
Epoch: 63 cost time: 8.507146120071411
Epoch: 63, Steps: 258 | Train Loss: 0.4927807 Vali Loss: 0.2596150 Test Loss: 0.3519377
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.5444612
	speed: 0.1134s/iter; left time: 1071.2226s
	iters: 200, epoch: 64 | loss: 0.4773139
	speed: 0.0307s/iter; left time: 286.6008s
Epoch: 64 cost time: 8.193266153335571
Epoch: 64, Steps: 258 | Train Loss: 0.4922798 Vali Loss: 0.2597103 Test Loss: 0.3519428
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.3269538
	speed: 0.0870s/iter; left time: 799.5054s
	iters: 200, epoch: 65 | loss: 0.4450096
	speed: 0.0159s/iter; left time: 144.2678s
Epoch: 65 cost time: 4.80395770072937
Epoch: 65, Steps: 258 | Train Loss: 0.4928733 Vali Loss: 0.2598341 Test Loss: 0.3519381
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.4661645
	speed: 0.0863s/iter; left time: 770.5241s
	iters: 200, epoch: 66 | loss: 0.5348619
	speed: 0.0269s/iter; left time: 237.8185s
Epoch: 66 cost time: 7.66036581993103
Epoch: 66, Steps: 258 | Train Loss: 0.4926057 Vali Loss: 0.2599095 Test Loss: 0.3519383
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_720_720_FITS_ETTm2_ftM_sl720_ll48_pl720_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.348625123500824, mae:0.3778134882450104, rse:0.4745956063270569, corr:[0.54946667 0.5457412  0.54140174 0.54020476 0.54068935 0.5404346
 0.53912425 0.53798735 0.5377566  0.5380586  0.5379992  0.5372925
 0.53654003 0.53628063 0.5365155  0.53655577 0.5359467  0.53490543
 0.5339436  0.533391   0.53315276 0.5327736  0.5320706  0.53127664
 0.5307006  0.53047395 0.5303656  0.5300354  0.5293807  0.5286368
 0.5280682  0.5278168  0.5276172  0.52713513 0.5264063  0.525683
 0.52509886 0.5246559  0.5241391  0.5234565  0.52270997 0.52206284
 0.52166384 0.52140886 0.5210557  0.5203977  0.51951844 0.5186366
 0.5178504  0.51715153 0.51645875 0.5157281  0.5149231  0.5141445
 0.5135231  0.5130742  0.5126432  0.5121295  0.51159763 0.51116717
 0.5109661  0.5109853  0.5110104  0.5108389  0.51048577 0.510157
 0.5098962  0.5097632  0.5096352  0.50938755 0.5090127  0.50861377
 0.5082737  0.5079855  0.50762326 0.5071607  0.50664234 0.5061267
 0.5056599  0.5051894  0.5045575  0.5038036  0.50302744 0.50234246
 0.5018116  0.50138867 0.5009203  0.50042236 0.4999163  0.4994601
 0.4990792  0.4986777  0.4980965  0.49731335 0.49633053 0.49515024
 0.49378872 0.49233645 0.490808   0.48935106 0.48814481 0.48720327
 0.48637202 0.48539546 0.48414153 0.48272246 0.48140246 0.48038727
 0.47957334 0.4787995  0.47795877 0.47704005 0.47619262 0.47539672
 0.47453997 0.4735853  0.4725811  0.47160846 0.4708495  0.4702817
 0.46984386 0.4692977  0.46857932 0.46769786 0.4667807  0.46594152
 0.46522522 0.46450168 0.4636468  0.46265283 0.46164617 0.46071002
 0.45987743 0.45908725 0.45833015 0.45765373 0.4570944  0.45666817
 0.4562386  0.4556949  0.4550234  0.45437324 0.45388207 0.45342472
 0.45282045 0.45188117 0.4508215  0.44986656 0.44921154 0.44874015
 0.44824627 0.44756404 0.4466245  0.44563082 0.44488177 0.4444443
 0.44409302 0.44358575 0.44285685 0.44220364 0.44179848 0.44167578
 0.4415876  0.44133794 0.440871   0.44030848 0.4397732  0.4393487
 0.43898678 0.43861446 0.4381245  0.43764177 0.43724844 0.43693745
 0.4365637  0.43601146 0.43528435 0.4345094  0.43381044 0.43329588
 0.4327975  0.43219203 0.43156096 0.4310172  0.4306482  0.43043032
 0.43024787 0.42990148 0.42928168 0.4283536  0.42717338 0.42578888
 0.4243023  0.42294803 0.42163268 0.42033663 0.41913667 0.41797382
 0.4168123  0.41559812 0.4143865  0.41323084 0.41214025 0.41107
 0.40993303 0.40867546 0.40736106 0.40612113 0.40512797 0.40437958
 0.40356296 0.40254268 0.4014142  0.4003657  0.39952868 0.39875358
 0.39787686 0.39678505 0.39565134 0.39453253 0.39342582 0.39232257
 0.39120647 0.39014995 0.38927516 0.38844195 0.38757297 0.38664094
 0.38554293 0.3843894  0.38330287 0.3823764  0.3815794  0.38086978
 0.38016045 0.37952495 0.37901953 0.37865734 0.3784225  0.37815896
 0.3777895  0.37726083 0.3767037  0.376374   0.3761423  0.37597302
 0.37579823 0.37561762 0.37540165 0.37511623 0.374862   0.37459564
 0.3743169  0.3741675  0.37409014 0.37407437 0.37399065 0.3738376
 0.37358937 0.37328368 0.37292683 0.37256685 0.37217075 0.37182194
 0.37153816 0.3712341  0.37090972 0.37051275 0.37002155 0.3695001
 0.36918557 0.36911246 0.36903816 0.36878043 0.3682441  0.36760193
 0.36724117 0.3671847  0.36721924 0.36710703 0.3665822  0.36579466
 0.36504394 0.3646647  0.36466923 0.3647031  0.36436495 0.36338758
 0.36203972 0.36086863 0.3600154  0.35934407 0.35869536 0.35794657
 0.35728145 0.356731   0.35617903 0.35551357 0.35476533 0.35395995
 0.35333496 0.35286656 0.35253394 0.3520219  0.35134396 0.3506579
 0.35022306 0.34999514 0.3498548  0.34961188 0.34919903 0.34887257
 0.34870124 0.34879375 0.34891447 0.3487834  0.348339   0.34776285
 0.3472352  0.34696692 0.34693247 0.34689018 0.3466463  0.34625372
 0.345875   0.3457309  0.34585074 0.34600788 0.34613553 0.34612373
 0.34611115 0.3460571  0.34596953 0.34590262 0.3458125  0.3458517
 0.3459721  0.3459631  0.345782   0.34546366 0.34502947 0.34456795
 0.34429526 0.34429705 0.344441   0.34453708 0.34447715 0.34433258
 0.3441645  0.34406027 0.34398746 0.3438654  0.3437067  0.34352848
 0.343351   0.34318554 0.3428953  0.34257862 0.34215614 0.34180605
 0.34158713 0.34146342 0.34133366 0.34117794 0.3410265  0.34104365
 0.341121   0.34117958 0.3410363  0.34069237 0.3403616  0.34020332
 0.34030735 0.34057868 0.3407815  0.3407563  0.3405468  0.3404131
 0.34051383 0.34073442 0.34078452 0.34045926 0.33996665 0.33944204
 0.3390736  0.33875751 0.33827567 0.33747733 0.33647797 0.33567938
 0.33519995 0.33490384 0.3344929  0.33382076 0.33300012 0.3322568
 0.33177328 0.33152232 0.33117026 0.33057627 0.32989758 0.3292158
 0.32861087 0.32801136 0.32735568 0.32670298 0.32614768 0.3259188
 0.32596716 0.32613176 0.3260736  0.32559988 0.32494098 0.32440585
 0.32428017 0.32449144 0.32468435 0.3246064  0.32423618 0.32384768
 0.3237293  0.32388556 0.3240839  0.32417148 0.32415888 0.3241934
 0.32440817 0.32469904 0.32492915 0.32496646 0.32487056 0.32479453
 0.3248278  0.32482433 0.32470423 0.32447073 0.32423088 0.32402912
 0.32379612 0.3236309  0.32338688 0.32296893 0.3224996  0.32218176
 0.32194373 0.3217518  0.32145137 0.32096583 0.32045168 0.32001892
 0.31975955 0.31959096 0.31938764 0.3189776  0.31844357 0.31799173
 0.31773028 0.3176597  0.3176495  0.3175777  0.3174679  0.31716093
 0.31669495 0.31617197 0.31571695 0.3154398  0.31531897 0.31525746
 0.31511047 0.31476077 0.3142113  0.31360868 0.3131847  0.31292054
 0.31269985 0.3123063  0.31172448 0.31093597 0.3100428  0.30906782
 0.30795974 0.30680323 0.30559078 0.30445766 0.30354226 0.3028101
 0.30207253 0.30126017 0.30034176 0.29950652 0.29881272 0.29822358
 0.29764205 0.2970375  0.29634684 0.2954912  0.29457346 0.29367355
 0.29284254 0.29202268 0.2912279  0.2905849  0.29005295 0.28968596
 0.2893041  0.28885666 0.28841168 0.28800213 0.28769246 0.28735682
 0.28686565 0.28619793 0.28545502 0.28484648 0.28452605 0.2844052
 0.28423598 0.28380373 0.28330442 0.2828268  0.28248456 0.2823356
 0.28226823 0.28218508 0.28195098 0.28160718 0.28131375 0.281122
 0.28100082 0.28092778 0.28084275 0.28073084 0.28058773 0.2803497
 0.27995926 0.27949297 0.27917108 0.27903506 0.27900866 0.27896833
 0.27880967 0.27858418 0.27836883 0.2782852  0.27825734 0.2780758
 0.2776844  0.27721697 0.27683073 0.27663767 0.2765554  0.27652815
 0.27639848 0.2761911  0.27598286 0.27584305 0.275618   0.2753844
 0.275142   0.2750298  0.27501747 0.27504846 0.27505213 0.2749388
 0.27468866 0.27430284 0.27388686 0.27349806 0.2731933  0.27302974
 0.2729827  0.27297422 0.2727914  0.27229857 0.27141583 0.27006128
 0.26840046 0.26693252 0.2658331  0.26503575 0.26433885 0.2636587
 0.26299298 0.26230708 0.26153645 0.2605928  0.25946125 0.25835288
 0.25744498 0.25679627 0.25638252 0.25595084 0.25531158 0.25451604
 0.25370064 0.25299507 0.25254557 0.252217   0.25197667 0.25178835
 0.25162008 0.25154728 0.25143602 0.25116262 0.25079387 0.2504191
 0.2500461  0.24978773 0.24970105 0.24957661 0.24936263 0.24905273
 0.24881949 0.24859218 0.24847256 0.24851254 0.24858293 0.24856609
 0.2485045  0.24860342 0.24888687 0.24936856 0.2499396  0.25049773
 0.25090387 0.25111845 0.2512047  0.25130162 0.25137588 0.25134474
 0.25114474 0.25092867 0.25086215 0.25075766 0.2507533  0.25070208
 0.2505685  0.25043663 0.25028935 0.25028268 0.25017476 0.24992508
 0.2495477  0.24931766 0.24921526 0.24906544 0.24894199 0.24858907
 0.24817593 0.24782681 0.2476875  0.24771543 0.24786189 0.24783261
 0.24778533 0.24775484 0.24771051 0.24775957 0.24781992 0.24774759
 0.24755432 0.24755085 0.24767324 0.24782255 0.24795364 0.24797389
 0.24789722 0.2479324  0.24808435 0.24804355 0.24749851 0.24639355
 0.24493635 0.24351162 0.24240753 0.24164815 0.24115893 0.2406728
 0.24002934 0.23923466 0.23865539 0.23818378 0.2377716  0.2372494
 0.23658228 0.23584335 0.23512106 0.2344569  0.23399906 0.23360594
 0.23324728 0.23279096 0.23206094 0.23125018 0.230388   0.22961733
 0.2291188  0.2288286  0.22865112 0.22826283 0.22765428 0.22693887
 0.22639883 0.22584738 0.22523472 0.22457865 0.22398074 0.22358537
 0.22325924 0.22285639 0.22225448 0.2218487  0.2217889  0.22209355
 0.22203824 0.22094129 0.21936841 0.21928394 0.22174191 0.22328617]
