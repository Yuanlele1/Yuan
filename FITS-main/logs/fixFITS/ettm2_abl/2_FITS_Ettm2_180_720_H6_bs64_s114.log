Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=22, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_180_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_180_720_FITS_ETTm2_ftM_sl180_ll48_pl720_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33661
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=22, out_features=110, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2168320.0
params:  2530.0
Trainable parameters:  2530
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6543719
	speed: 0.0238s/iter; left time: 621.0724s
	iters: 200, epoch: 1 | loss: 0.3750780
	speed: 0.0173s/iter; left time: 450.2633s
Epoch: 1 cost time: 5.171430826187134
Epoch: 1, Steps: 262 | Train Loss: 0.6105231 Vali Loss: 0.3218167 Test Loss: 0.4451242
Validation loss decreased (inf --> 0.321817).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4707637
	speed: 0.0932s/iter; left time: 2407.1121s
	iters: 200, epoch: 2 | loss: 0.3539994
	speed: 0.0183s/iter; left time: 470.2792s
Epoch: 2 cost time: 6.0601646900177
Epoch: 2, Steps: 262 | Train Loss: 0.4914736 Vali Loss: 0.2935528 Test Loss: 0.4080307
Validation loss decreased (0.321817 --> 0.293553).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4178753
	speed: 0.0853s/iter; left time: 2181.0503s
	iters: 200, epoch: 3 | loss: 0.4539156
	speed: 0.0176s/iter; left time: 447.7074s
Epoch: 3 cost time: 5.2510857582092285
Epoch: 3, Steps: 262 | Train Loss: 0.4660396 Vali Loss: 0.2856378 Test Loss: 0.3982719
Validation loss decreased (0.293553 --> 0.285638).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4156758
	speed: 0.0872s/iter; left time: 2207.6164s
	iters: 200, epoch: 4 | loss: 0.6042459
	speed: 0.0169s/iter; left time: 425.9768s
Epoch: 4 cost time: 5.404191493988037
Epoch: 4, Steps: 262 | Train Loss: 0.4583797 Vali Loss: 0.2825597 Test Loss: 0.3944119
Validation loss decreased (0.285638 --> 0.282560).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.7509819
	speed: 0.0818s/iter; left time: 2049.7894s
	iters: 200, epoch: 5 | loss: 0.5340719
	speed: 0.0177s/iter; left time: 441.7673s
Epoch: 5 cost time: 4.958614110946655
Epoch: 5, Steps: 262 | Train Loss: 0.4550902 Vali Loss: 0.2808813 Test Loss: 0.3923857
Validation loss decreased (0.282560 --> 0.280881).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.5337915
	speed: 0.1095s/iter; left time: 2715.7635s
	iters: 200, epoch: 6 | loss: 0.5114841
	speed: 0.0180s/iter; left time: 444.6018s
Epoch: 6 cost time: 7.863164663314819
Epoch: 6, Steps: 262 | Train Loss: 0.4534284 Vali Loss: 0.2798045 Test Loss: 0.3912114
Validation loss decreased (0.280881 --> 0.279804).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4572210
	speed: 0.0835s/iter; left time: 2047.2634s
	iters: 200, epoch: 7 | loss: 0.5843301
	speed: 0.0233s/iter; left time: 569.7020s
Epoch: 7 cost time: 5.993841648101807
Epoch: 7, Steps: 262 | Train Loss: 0.4524074 Vali Loss: 0.2790920 Test Loss: 0.3903227
Validation loss decreased (0.279804 --> 0.279092).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3466747
	speed: 0.0912s/iter; left time: 2213.5906s
	iters: 200, epoch: 8 | loss: 0.5124923
	speed: 0.0172s/iter; left time: 416.7480s
Epoch: 8 cost time: 5.169945001602173
Epoch: 8, Steps: 262 | Train Loss: 0.4510384 Vali Loss: 0.2789192 Test Loss: 0.3897661
Validation loss decreased (0.279092 --> 0.278919).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3668910
	speed: 0.0794s/iter; left time: 1906.1872s
	iters: 200, epoch: 9 | loss: 0.4319111
	speed: 0.0163s/iter; left time: 389.9256s
Epoch: 9 cost time: 5.09308648109436
Epoch: 9, Steps: 262 | Train Loss: 0.4506879 Vali Loss: 0.2785907 Test Loss: 0.3893305
Validation loss decreased (0.278919 --> 0.278591).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3829412
	speed: 0.0870s/iter; left time: 2065.9175s
	iters: 200, epoch: 10 | loss: 0.3877524
	speed: 0.0170s/iter; left time: 401.6311s
Epoch: 10 cost time: 5.107162237167358
Epoch: 10, Steps: 262 | Train Loss: 0.4502895 Vali Loss: 0.2783583 Test Loss: 0.3889503
Validation loss decreased (0.278591 --> 0.278358).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.5183296
	speed: 0.0799s/iter; left time: 1876.9155s
	iters: 200, epoch: 11 | loss: 0.5298148
	speed: 0.0182s/iter; left time: 425.2090s
Epoch: 11 cost time: 5.2967846393585205
Epoch: 11, Steps: 262 | Train Loss: 0.4494699 Vali Loss: 0.2782181 Test Loss: 0.3887548
Validation loss decreased (0.278358 --> 0.278218).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.6028266
	speed: 0.0805s/iter; left time: 1869.7537s
	iters: 200, epoch: 12 | loss: 0.5442652
	speed: 0.0219s/iter; left time: 507.1284s
Epoch: 12 cost time: 5.502973556518555
Epoch: 12, Steps: 262 | Train Loss: 0.4498138 Vali Loss: 0.2778520 Test Loss: 0.3885327
Validation loss decreased (0.278218 --> 0.277852).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3988139
	speed: 0.0817s/iter; left time: 1876.5541s
	iters: 200, epoch: 13 | loss: 0.4429695
	speed: 0.0187s/iter; left time: 427.5010s
Epoch: 13 cost time: 5.284438371658325
Epoch: 13, Steps: 262 | Train Loss: 0.4491148 Vali Loss: 0.2777815 Test Loss: 0.3883315
Validation loss decreased (0.277852 --> 0.277782).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4194102
	speed: 0.0859s/iter; left time: 1949.9709s
	iters: 200, epoch: 14 | loss: 0.4655476
	speed: 0.0185s/iter; left time: 418.9619s
Epoch: 14 cost time: 5.394442558288574
Epoch: 14, Steps: 262 | Train Loss: 0.4491572 Vali Loss: 0.2778223 Test Loss: 0.3882127
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4492078
	speed: 0.0857s/iter; left time: 1922.0705s
	iters: 200, epoch: 15 | loss: 0.4515175
	speed: 0.0168s/iter; left time: 375.2714s
Epoch: 15 cost time: 5.123314142227173
Epoch: 15, Steps: 262 | Train Loss: 0.4486738 Vali Loss: 0.2774985 Test Loss: 0.3880093
Validation loss decreased (0.277782 --> 0.277498).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4121725
	speed: 0.0959s/iter; left time: 2127.2442s
	iters: 200, epoch: 16 | loss: 0.4181893
	speed: 0.0172s/iter; left time: 379.8956s
Epoch: 16 cost time: 6.283264636993408
Epoch: 16, Steps: 262 | Train Loss: 0.4483315 Vali Loss: 0.2776228 Test Loss: 0.3879255
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3704818
	speed: 0.0797s/iter; left time: 1745.0633s
	iters: 200, epoch: 17 | loss: 0.3546372
	speed: 0.0244s/iter; left time: 532.4502s
Epoch: 17 cost time: 5.872705936431885
Epoch: 17, Steps: 262 | Train Loss: 0.4486604 Vali Loss: 0.2773029 Test Loss: 0.3878514
Validation loss decreased (0.277498 --> 0.277303).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.6507180
	speed: 0.0951s/iter; left time: 2058.7766s
	iters: 200, epoch: 18 | loss: 0.3240767
	speed: 0.0250s/iter; left time: 539.6237s
Epoch: 18 cost time: 8.002306699752808
Epoch: 18, Steps: 262 | Train Loss: 0.4483304 Vali Loss: 0.2774841 Test Loss: 0.3877653
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3955212
	speed: 0.0941s/iter; left time: 2012.9903s
	iters: 200, epoch: 19 | loss: 0.3375931
	speed: 0.0173s/iter; left time: 367.5460s
Epoch: 19 cost time: 5.206430196762085
Epoch: 19, Steps: 262 | Train Loss: 0.4474544 Vali Loss: 0.2775763 Test Loss: 0.3876744
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3704515
	speed: 0.0820s/iter; left time: 1732.3700s
	iters: 200, epoch: 20 | loss: 0.4071105
	speed: 0.0183s/iter; left time: 385.4147s
Epoch: 20 cost time: 5.388823509216309
Epoch: 20, Steps: 262 | Train Loss: 0.4481287 Vali Loss: 0.2774920 Test Loss: 0.3876107
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4816836
	speed: 0.0898s/iter; left time: 1873.8528s
	iters: 200, epoch: 21 | loss: 0.3364888
	speed: 0.0182s/iter; left time: 377.4263s
Epoch: 21 cost time: 5.22593879699707
Epoch: 21, Steps: 262 | Train Loss: 0.4476794 Vali Loss: 0.2774639 Test Loss: 0.3875869
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.5383457
	speed: 0.0874s/iter; left time: 1800.1276s
	iters: 200, epoch: 22 | loss: 0.5035940
	speed: 0.0170s/iter; left time: 347.5620s
Epoch: 22 cost time: 5.028660535812378
Epoch: 22, Steps: 262 | Train Loss: 0.4483291 Vali Loss: 0.2773929 Test Loss: 0.3875247
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.5325048
	speed: 0.0828s/iter; left time: 1684.0035s
	iters: 200, epoch: 23 | loss: 0.4295215
	speed: 0.0168s/iter; left time: 340.6690s
Epoch: 23 cost time: 4.984656572341919
Epoch: 23, Steps: 262 | Train Loss: 0.4475380 Vali Loss: 0.2773629 Test Loss: 0.3874977
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4018483
	speed: 0.0820s/iter; left time: 1646.1471s
	iters: 200, epoch: 24 | loss: 0.3980383
	speed: 0.0165s/iter; left time: 329.9562s
Epoch: 24 cost time: 5.085773706436157
Epoch: 24, Steps: 262 | Train Loss: 0.4476764 Vali Loss: 0.2770435 Test Loss: 0.3874583
Validation loss decreased (0.277303 --> 0.277043).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4084589
	speed: 0.0781s/iter; left time: 1547.2387s
	iters: 200, epoch: 25 | loss: 0.4442474
	speed: 0.0171s/iter; left time: 338.0287s
Epoch: 25 cost time: 5.154825210571289
Epoch: 25, Steps: 262 | Train Loss: 0.4478884 Vali Loss: 0.2772964 Test Loss: 0.3873973
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.7252464
	speed: 0.0867s/iter; left time: 1695.6707s
	iters: 200, epoch: 26 | loss: 0.6658570
	speed: 0.0180s/iter; left time: 349.6179s
Epoch: 26 cost time: 5.1433258056640625
Epoch: 26, Steps: 262 | Train Loss: 0.4480788 Vali Loss: 0.2771501 Test Loss: 0.3874091
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.5869080
	speed: 0.0805s/iter; left time: 1552.4807s
	iters: 200, epoch: 27 | loss: 0.4156034
	speed: 0.0171s/iter; left time: 328.3990s
Epoch: 27 cost time: 5.208112955093384
Epoch: 27, Steps: 262 | Train Loss: 0.4478585 Vali Loss: 0.2774666 Test Loss: 0.3873782
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4327955
	speed: 0.0823s/iter; left time: 1564.9847s
	iters: 200, epoch: 28 | loss: 0.4649752
	speed: 0.0169s/iter; left time: 319.1861s
Epoch: 28 cost time: 5.024701118469238
Epoch: 28, Steps: 262 | Train Loss: 0.4474546 Vali Loss: 0.2774421 Test Loss: 0.3873534
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.5134789
	speed: 0.0830s/iter; left time: 1557.0991s
	iters: 200, epoch: 29 | loss: 0.4660605
	speed: 0.0172s/iter; left time: 321.5340s
Epoch: 29 cost time: 5.044477224349976
Epoch: 29, Steps: 262 | Train Loss: 0.4472155 Vali Loss: 0.2771133 Test Loss: 0.3873229
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3730212
	speed: 0.0896s/iter; left time: 1658.4759s
	iters: 200, epoch: 30 | loss: 0.4033143
	speed: 0.0170s/iter; left time: 313.1452s
Epoch: 30 cost time: 5.078911066055298
Epoch: 30, Steps: 262 | Train Loss: 0.4476791 Vali Loss: 0.2771365 Test Loss: 0.3873196
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4475799
	speed: 0.0871s/iter; left time: 1588.5302s
	iters: 200, epoch: 31 | loss: 0.6408557
	speed: 0.0170s/iter; left time: 307.7876s
Epoch: 31 cost time: 5.957766056060791
Epoch: 31, Steps: 262 | Train Loss: 0.4476528 Vali Loss: 0.2774194 Test Loss: 0.3872994
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4466183
	speed: 0.0777s/iter; left time: 1397.8175s
	iters: 200, epoch: 32 | loss: 0.3624670
	speed: 0.0165s/iter; left time: 294.8961s
Epoch: 32 cost time: 5.05315899848938
Epoch: 32, Steps: 262 | Train Loss: 0.4477308 Vali Loss: 0.2773374 Test Loss: 0.3872861
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4356610
	speed: 0.0832s/iter; left time: 1473.8558s
	iters: 200, epoch: 33 | loss: 0.4001028
	speed: 0.0170s/iter; left time: 299.6720s
Epoch: 33 cost time: 4.940445184707642
Epoch: 33, Steps: 262 | Train Loss: 0.4482384 Vali Loss: 0.2773473 Test Loss: 0.3872668
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3966322
	speed: 0.0817s/iter; left time: 1426.4479s
	iters: 200, epoch: 34 | loss: 0.5268384
	speed: 0.0158s/iter; left time: 273.6185s
Epoch: 34 cost time: 4.811581373214722
Epoch: 34, Steps: 262 | Train Loss: 0.4477596 Vali Loss: 0.2770953 Test Loss: 0.3872465
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4987918
	speed: 0.0785s/iter; left time: 1349.4784s
	iters: 200, epoch: 35 | loss: 0.4353415
	speed: 0.0154s/iter; left time: 263.3810s
Epoch: 35 cost time: 4.7227699756622314
Epoch: 35, Steps: 262 | Train Loss: 0.4476331 Vali Loss: 0.2771634 Test Loss: 0.3872419
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.5390370
	speed: 0.0836s/iter; left time: 1415.4341s
	iters: 200, epoch: 36 | loss: 0.5424106
	speed: 0.0216s/iter; left time: 363.7809s
Epoch: 36 cost time: 5.656784534454346
Epoch: 36, Steps: 262 | Train Loss: 0.4481437 Vali Loss: 0.2770274 Test Loss: 0.3872346
Validation loss decreased (0.277043 --> 0.277027).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4252816
	speed: 0.0832s/iter; left time: 1387.3202s
	iters: 200, epoch: 37 | loss: 0.4931008
	speed: 0.0167s/iter; left time: 276.5031s
Epoch: 37 cost time: 5.103821754455566
Epoch: 37, Steps: 262 | Train Loss: 0.4481808 Vali Loss: 0.2770561 Test Loss: 0.3872307
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4236653
	speed: 0.0815s/iter; left time: 1337.6613s
	iters: 200, epoch: 38 | loss: 0.3522817
	speed: 0.0170s/iter; left time: 277.3448s
Epoch: 38 cost time: 4.934249401092529
Epoch: 38, Steps: 262 | Train Loss: 0.4473985 Vali Loss: 0.2772008 Test Loss: 0.3872205
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4274690
	speed: 0.0785s/iter; left time: 1266.7503s
	iters: 200, epoch: 39 | loss: 0.4551528
	speed: 0.0213s/iter; left time: 341.2308s
Epoch: 39 cost time: 5.5115861892700195
Epoch: 39, Steps: 262 | Train Loss: 0.4480755 Vali Loss: 0.2774148 Test Loss: 0.3872198
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.4199620
	speed: 0.0819s/iter; left time: 1301.1439s
	iters: 200, epoch: 40 | loss: 0.4215992
	speed: 0.0183s/iter; left time: 289.4172s
Epoch: 40 cost time: 6.14696741104126
Epoch: 40, Steps: 262 | Train Loss: 0.4474768 Vali Loss: 0.2772549 Test Loss: 0.3872118
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.5205280
	speed: 0.0879s/iter; left time: 1373.8563s
	iters: 200, epoch: 41 | loss: 0.4499438
	speed: 0.0162s/iter; left time: 251.7326s
Epoch: 41 cost time: 4.762237071990967
Epoch: 41, Steps: 262 | Train Loss: 0.4474049 Vali Loss: 0.2771126 Test Loss: 0.3872114
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3889829
	speed: 0.0820s/iter; left time: 1259.8027s
	iters: 200, epoch: 42 | loss: 0.3307652
	speed: 0.0168s/iter; left time: 256.2958s
Epoch: 42 cost time: 5.047302484512329
Epoch: 42, Steps: 262 | Train Loss: 0.4477059 Vali Loss: 0.2773196 Test Loss: 0.3872078
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.4406779
	speed: 0.0771s/iter; left time: 1163.9188s
	iters: 200, epoch: 43 | loss: 0.2679757
	speed: 0.0167s/iter; left time: 250.3015s
Epoch: 43 cost time: 4.753770351409912
Epoch: 43, Steps: 262 | Train Loss: 0.4477521 Vali Loss: 0.2771856 Test Loss: 0.3872010
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.5774678
	speed: 0.0785s/iter; left time: 1164.8476s
	iters: 200, epoch: 44 | loss: 0.4988537
	speed: 0.0199s/iter; left time: 293.1541s
Epoch: 44 cost time: 5.261428356170654
Epoch: 44, Steps: 262 | Train Loss: 0.4480729 Vali Loss: 0.2770411 Test Loss: 0.3871891
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.4351908
	speed: 0.0782s/iter; left time: 1140.3130s
	iters: 200, epoch: 45 | loss: 0.4711060
	speed: 0.0182s/iter; left time: 263.2232s
Epoch: 45 cost time: 5.224149227142334
Epoch: 45, Steps: 262 | Train Loss: 0.4476970 Vali Loss: 0.2772264 Test Loss: 0.3871862
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.4854895
	speed: 0.0901s/iter; left time: 1289.2014s
	iters: 200, epoch: 46 | loss: 0.6512989
	speed: 0.0173s/iter; left time: 245.7924s
Epoch: 46 cost time: 5.95196270942688
Epoch: 46, Steps: 262 | Train Loss: 0.4471742 Vali Loss: 0.2772576 Test Loss: 0.3871773
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.4003833
	speed: 0.0791s/iter; left time: 1111.7351s
	iters: 200, epoch: 47 | loss: 0.5025169
	speed: 0.0158s/iter; left time: 220.6367s
Epoch: 47 cost time: 4.897526979446411
Epoch: 47, Steps: 262 | Train Loss: 0.4480092 Vali Loss: 0.2770851 Test Loss: 0.3871825
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.5211798
	speed: 0.0824s/iter; left time: 1136.2919s
	iters: 200, epoch: 48 | loss: 0.6590244
	speed: 0.0171s/iter; left time: 234.0563s
Epoch: 48 cost time: 5.182903051376343
Epoch: 48, Steps: 262 | Train Loss: 0.4473698 Vali Loss: 0.2767169 Test Loss: 0.3871726
Validation loss decreased (0.277027 --> 0.276717).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.3520479
	speed: 0.0849s/iter; left time: 1148.4554s
	iters: 200, epoch: 49 | loss: 0.3211244
	speed: 0.0185s/iter; left time: 248.5917s
Epoch: 49 cost time: 5.115723609924316
Epoch: 49, Steps: 262 | Train Loss: 0.4473479 Vali Loss: 0.2768480 Test Loss: 0.3871648
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.4852808
	speed: 0.0823s/iter; left time: 1091.6533s
	iters: 200, epoch: 50 | loss: 0.5833276
	speed: 0.0177s/iter; left time: 232.8318s
Epoch: 50 cost time: 5.23097038269043
Epoch: 50, Steps: 262 | Train Loss: 0.4475137 Vali Loss: 0.2770590 Test Loss: 0.3871647
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.3491616
	speed: 0.0841s/iter; left time: 1093.0149s
	iters: 200, epoch: 51 | loss: 0.4648033
	speed: 0.0162s/iter; left time: 209.1205s
Epoch: 51 cost time: 5.767039775848389
Epoch: 51, Steps: 262 | Train Loss: 0.4477654 Vali Loss: 0.2772056 Test Loss: 0.3871637
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.4831216
	speed: 0.0918s/iter; left time: 1169.0786s
	iters: 200, epoch: 52 | loss: 0.4082388
	speed: 0.0172s/iter; left time: 217.9547s
Epoch: 52 cost time: 5.188695669174194
Epoch: 52, Steps: 262 | Train Loss: 0.4479192 Vali Loss: 0.2769994 Test Loss: 0.3871625
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.4955462
	speed: 0.0803s/iter; left time: 1001.9857s
	iters: 200, epoch: 53 | loss: 0.6377933
	speed: 0.0175s/iter; left time: 216.3726s
Epoch: 53 cost time: 5.158454179763794
Epoch: 53, Steps: 262 | Train Loss: 0.4472358 Vali Loss: 0.2770793 Test Loss: 0.3871571
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.4637037
	speed: 0.0923s/iter; left time: 1127.5788s
	iters: 200, epoch: 54 | loss: 0.3187559
	speed: 0.0192s/iter; left time: 232.7728s
Epoch: 54 cost time: 5.704300403594971
Epoch: 54, Steps: 262 | Train Loss: 0.4475846 Vali Loss: 0.2772192 Test Loss: 0.3871568
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.5114111
	speed: 0.0817s/iter; left time: 976.2669s
	iters: 200, epoch: 55 | loss: 0.7735624
	speed: 0.0215s/iter; left time: 254.4808s
Epoch: 55 cost time: 5.694765090942383
Epoch: 55, Steps: 262 | Train Loss: 0.4478485 Vali Loss: 0.2768634 Test Loss: 0.3871530
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.3777905
	speed: 0.0922s/iter; left time: 1077.4460s
	iters: 200, epoch: 56 | loss: 0.5839085
	speed: 0.0179s/iter; left time: 207.2705s
Epoch: 56 cost time: 5.693341493606567
Epoch: 56, Steps: 262 | Train Loss: 0.4471860 Vali Loss: 0.2771373 Test Loss: 0.3871506
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.4448337
	speed: 0.0953s/iter; left time: 1088.9362s
	iters: 200, epoch: 57 | loss: 0.5638162
	speed: 0.0156s/iter; left time: 176.6293s
Epoch: 57 cost time: 4.67145848274231
Epoch: 57, Steps: 262 | Train Loss: 0.4476653 Vali Loss: 0.2769628 Test Loss: 0.3871469
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.4723569
	speed: 0.0859s/iter; left time: 958.8231s
	iters: 200, epoch: 58 | loss: 0.5164626
	speed: 0.0201s/iter; left time: 222.4515s
Epoch: 58 cost time: 5.327426910400391
Epoch: 58, Steps: 262 | Train Loss: 0.4477432 Vali Loss: 0.2772160 Test Loss: 0.3871489
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.4272123
	speed: 0.0774s/iter; left time: 843.9550s
	iters: 200, epoch: 59 | loss: 0.4148680
	speed: 0.0159s/iter; left time: 172.1217s
Epoch: 59 cost time: 4.868897438049316
Epoch: 59, Steps: 262 | Train Loss: 0.4474868 Vali Loss: 0.2770367 Test Loss: 0.3871485
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.4798276
	speed: 0.0876s/iter; left time: 931.9496s
	iters: 200, epoch: 60 | loss: 0.3620935
	speed: 0.0175s/iter; left time: 184.2620s
Epoch: 60 cost time: 5.186810255050659
Epoch: 60, Steps: 262 | Train Loss: 0.4469182 Vali Loss: 0.2767974 Test Loss: 0.3871461
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.4189493
	speed: 0.0824s/iter; left time: 855.3393s
	iters: 200, epoch: 61 | loss: 0.5628874
	speed: 0.0164s/iter; left time: 168.1176s
Epoch: 61 cost time: 5.080670356750488
Epoch: 61, Steps: 262 | Train Loss: 0.4475280 Vali Loss: 0.2771924 Test Loss: 0.3871429
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.5031888
	speed: 0.0896s/iter; left time: 906.7920s
	iters: 200, epoch: 62 | loss: 0.5288970
	speed: 0.0179s/iter; left time: 179.8260s
Epoch: 62 cost time: 5.656574487686157
Epoch: 62, Steps: 262 | Train Loss: 0.4469541 Vali Loss: 0.2768877 Test Loss: 0.3871434
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.3981996
	speed: 0.1021s/iter; left time: 1006.1625s
	iters: 200, epoch: 63 | loss: 0.4850349
	speed: 0.0180s/iter; left time: 175.8233s
Epoch: 63 cost time: 6.0651774406433105
Epoch: 63, Steps: 262 | Train Loss: 0.4476462 Vali Loss: 0.2773013 Test Loss: 0.3871410
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.5296229
	speed: 0.1099s/iter; left time: 1054.1349s
	iters: 200, epoch: 64 | loss: 0.3920903
	speed: 0.0236s/iter; left time: 224.1870s
Epoch: 64 cost time: 5.8035736083984375
Epoch: 64, Steps: 262 | Train Loss: 0.4473473 Vali Loss: 0.2768785 Test Loss: 0.3871410
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.5738182
	speed: 0.0812s/iter; left time: 757.6568s
	iters: 200, epoch: 65 | loss: 0.4058489
	speed: 0.0196s/iter; left time: 180.7082s
Epoch: 65 cost time: 5.202278137207031
Epoch: 65, Steps: 262 | Train Loss: 0.4470542 Vali Loss: 0.2771385 Test Loss: 0.3871409
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.3717577
	speed: 0.0785s/iter; left time: 712.3164s
	iters: 200, epoch: 66 | loss: 0.4894204
	speed: 0.0178s/iter; left time: 159.4678s
Epoch: 66 cost time: 5.124206304550171
Epoch: 66, Steps: 262 | Train Loss: 0.4476845 Vali Loss: 0.2770356 Test Loss: 0.3871384
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.2856741
	speed: 0.0832s/iter; left time: 732.5872s
	iters: 200, epoch: 67 | loss: 0.3523089
	speed: 0.0203s/iter; left time: 176.6740s
Epoch: 67 cost time: 5.390124320983887
Epoch: 67, Steps: 262 | Train Loss: 0.4469774 Vali Loss: 0.2770356 Test Loss: 0.3871359
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.3501685
	speed: 0.0851s/iter; left time: 727.3041s
	iters: 200, epoch: 68 | loss: 0.4896136
	speed: 0.0173s/iter; left time: 146.4715s
Epoch: 68 cost time: 5.164787530899048
Epoch: 68, Steps: 262 | Train Loss: 0.4470790 Vali Loss: 0.2770171 Test Loss: 0.3871348
EarlyStopping counter: 20 out of 20
Early stopping
train 33661
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=22, out_features=110, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2168320.0
params:  2530.0
Trainable parameters:  2530
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6614121
	speed: 0.0219s/iter; left time: 571.8066s
	iters: 200, epoch: 1 | loss: 0.5450128
	speed: 0.0178s/iter; left time: 461.5488s
Epoch: 1 cost time: 5.048212766647339
Epoch: 1, Steps: 262 | Train Loss: 0.5552204 Vali Loss: 0.2769115 Test Loss: 0.3867931
Validation loss decreased (inf --> 0.276911).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5084886
	speed: 0.0796s/iter; left time: 2056.8430s
	iters: 200, epoch: 2 | loss: 0.5073071
	speed: 0.0190s/iter; left time: 488.1419s
Epoch: 2 cost time: 5.399768590927124
Epoch: 2, Steps: 262 | Train Loss: 0.5546070 Vali Loss: 0.2769370 Test Loss: 0.3867940
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5079407
	speed: 0.0842s/iter; left time: 2152.8428s
	iters: 200, epoch: 3 | loss: 0.4491441
	speed: 0.0183s/iter; left time: 465.9695s
Epoch: 3 cost time: 5.238964796066284
Epoch: 3, Steps: 262 | Train Loss: 0.5550578 Vali Loss: 0.2773020 Test Loss: 0.3867899
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.7401285
	speed: 0.0922s/iter; left time: 2335.1100s
	iters: 200, epoch: 4 | loss: 0.5733150
	speed: 0.0216s/iter; left time: 543.7209s
Epoch: 4 cost time: 5.836966276168823
Epoch: 4, Steps: 262 | Train Loss: 0.5546699 Vali Loss: 0.2769878 Test Loss: 0.3866702
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3707480
	speed: 0.0882s/iter; left time: 2208.6700s
	iters: 200, epoch: 5 | loss: 0.6876292
	speed: 0.0174s/iter; left time: 434.0323s
Epoch: 5 cost time: 5.164448022842407
Epoch: 5, Steps: 262 | Train Loss: 0.5539085 Vali Loss: 0.2768033 Test Loss: 0.3866493
Validation loss decreased (0.276911 --> 0.276803).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4793957
	speed: 0.0951s/iter; left time: 2356.6931s
	iters: 200, epoch: 6 | loss: 0.6351340
	speed: 0.0186s/iter; left time: 460.0274s
Epoch: 6 cost time: 6.406996488571167
Epoch: 6, Steps: 262 | Train Loss: 0.5550489 Vali Loss: 0.2772419 Test Loss: 0.3867399
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.5027962
	speed: 0.0832s/iter; left time: 2040.2126s
	iters: 200, epoch: 7 | loss: 0.7255802
	speed: 0.0165s/iter; left time: 403.4019s
Epoch: 7 cost time: 4.923261880874634
Epoch: 7, Steps: 262 | Train Loss: 0.5542171 Vali Loss: 0.2769420 Test Loss: 0.3865737
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.8183870
	speed: 0.0849s/iter; left time: 2060.4433s
	iters: 200, epoch: 8 | loss: 0.5552546
	speed: 0.0178s/iter; left time: 430.1049s
Epoch: 8 cost time: 5.373125791549683
Epoch: 8, Steps: 262 | Train Loss: 0.5544323 Vali Loss: 0.2768921 Test Loss: 0.3866048
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.6031426
	speed: 0.0834s/iter; left time: 2001.0903s
	iters: 200, epoch: 9 | loss: 0.4877104
	speed: 0.0182s/iter; left time: 436.0703s
Epoch: 9 cost time: 5.121881484985352
Epoch: 9, Steps: 262 | Train Loss: 0.5541753 Vali Loss: 0.2767425 Test Loss: 0.3866433
Validation loss decreased (0.276803 --> 0.276742).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4098077
	speed: 0.0809s/iter; left time: 1921.8101s
	iters: 200, epoch: 10 | loss: 0.3100124
	speed: 0.0167s/iter; left time: 393.8584s
Epoch: 10 cost time: 4.948642253875732
Epoch: 10, Steps: 262 | Train Loss: 0.5536734 Vali Loss: 0.2770047 Test Loss: 0.3866106
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.6062934
	speed: 0.0824s/iter; left time: 1934.2778s
	iters: 200, epoch: 11 | loss: 0.3608285
	speed: 0.0190s/iter; left time: 444.5790s
Epoch: 11 cost time: 5.542553663253784
Epoch: 11, Steps: 262 | Train Loss: 0.5542997 Vali Loss: 0.2770857 Test Loss: 0.3866168
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4859545
	speed: 0.0859s/iter; left time: 1995.6710s
	iters: 200, epoch: 12 | loss: 0.5181561
	speed: 0.0175s/iter; left time: 404.2758s
Epoch: 12 cost time: 5.159799337387085
Epoch: 12, Steps: 262 | Train Loss: 0.5542305 Vali Loss: 0.2770643 Test Loss: 0.3865819
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.5123523
	speed: 0.0832s/iter; left time: 1910.6011s
	iters: 200, epoch: 13 | loss: 0.3605205
	speed: 0.0187s/iter; left time: 428.4024s
Epoch: 13 cost time: 5.319410562515259
Epoch: 13, Steps: 262 | Train Loss: 0.5549800 Vali Loss: 0.2768121 Test Loss: 0.3866352
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.6159832
	speed: 0.0773s/iter; left time: 1754.8123s
	iters: 200, epoch: 14 | loss: 0.6463570
	speed: 0.0344s/iter; left time: 777.7363s
Epoch: 14 cost time: 6.653354167938232
Epoch: 14, Steps: 262 | Train Loss: 0.5538078 Vali Loss: 0.2768336 Test Loss: 0.3866446
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.6925561
	speed: 0.0818s/iter; left time: 1834.2476s
	iters: 200, epoch: 15 | loss: 0.4597721
	speed: 0.0255s/iter; left time: 570.1856s
Epoch: 15 cost time: 5.868541240692139
Epoch: 15, Steps: 262 | Train Loss: 0.5545678 Vali Loss: 0.2769450 Test Loss: 0.3865696
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.5580077
	speed: 0.0851s/iter; left time: 1886.2308s
	iters: 200, epoch: 16 | loss: 0.6269873
	speed: 0.0177s/iter; left time: 389.8758s
Epoch: 16 cost time: 5.208796739578247
Epoch: 16, Steps: 262 | Train Loss: 0.5540215 Vali Loss: 0.2769788 Test Loss: 0.3865955
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.6773485
	speed: 0.0870s/iter; left time: 1905.2686s
	iters: 200, epoch: 17 | loss: 0.4686847
	speed: 0.0172s/iter; left time: 374.7739s
Epoch: 17 cost time: 5.106768846511841
Epoch: 17, Steps: 262 | Train Loss: 0.5538571 Vali Loss: 0.2767158 Test Loss: 0.3866225
Validation loss decreased (0.276742 --> 0.276716).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.6257338
	speed: 0.0807s/iter; left time: 1746.8626s
	iters: 200, epoch: 18 | loss: 0.5613394
	speed: 0.0175s/iter; left time: 377.2251s
Epoch: 18 cost time: 5.247685432434082
Epoch: 18, Steps: 262 | Train Loss: 0.5546945 Vali Loss: 0.2771369 Test Loss: 0.3866049
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4580944
	speed: 0.0807s/iter; left time: 1725.4143s
	iters: 200, epoch: 19 | loss: 0.4226105
	speed: 0.0166s/iter; left time: 353.3588s
Epoch: 19 cost time: 5.033522844314575
Epoch: 19, Steps: 262 | Train Loss: 0.5548597 Vali Loss: 0.2769864 Test Loss: 0.3865997
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4145148
	speed: 0.0834s/iter; left time: 1761.6829s
	iters: 200, epoch: 20 | loss: 0.7076822
	speed: 0.0165s/iter; left time: 347.3582s
Epoch: 20 cost time: 5.026078462600708
Epoch: 20, Steps: 262 | Train Loss: 0.5544449 Vali Loss: 0.2770467 Test Loss: 0.3865967
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.6876365
	speed: 0.0813s/iter; left time: 1696.4334s
	iters: 200, epoch: 21 | loss: 0.5809259
	speed: 0.0295s/iter; left time: 612.6551s
Epoch: 21 cost time: 6.425341606140137
Epoch: 21, Steps: 262 | Train Loss: 0.5547039 Vali Loss: 0.2770036 Test Loss: 0.3865848
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4932170
	speed: 0.0803s/iter; left time: 1653.6455s
	iters: 200, epoch: 22 | loss: 0.5214444
	speed: 0.0180s/iter; left time: 369.2478s
Epoch: 22 cost time: 5.145047426223755
Epoch: 22, Steps: 262 | Train Loss: 0.5538168 Vali Loss: 0.2770921 Test Loss: 0.3865880
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.5127912
	speed: 0.0842s/iter; left time: 1713.3617s
	iters: 200, epoch: 23 | loss: 0.4628359
	speed: 0.0215s/iter; left time: 436.0755s
Epoch: 23 cost time: 5.822486162185669
Epoch: 23, Steps: 262 | Train Loss: 0.5537055 Vali Loss: 0.2769153 Test Loss: 0.3865790
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.7748645
	speed: 0.0791s/iter; left time: 1588.4304s
	iters: 200, epoch: 24 | loss: 0.6157051
	speed: 0.0165s/iter; left time: 329.7443s
Epoch: 24 cost time: 4.777600288391113
Epoch: 24, Steps: 262 | Train Loss: 0.5546008 Vali Loss: 0.2769859 Test Loss: 0.3866069
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.6887667
	speed: 0.0780s/iter; left time: 1545.2395s
	iters: 200, epoch: 25 | loss: 0.5055463
	speed: 0.0174s/iter; left time: 343.3205s
Epoch: 25 cost time: 5.0869715213775635
Epoch: 25, Steps: 262 | Train Loss: 0.5547964 Vali Loss: 0.2772076 Test Loss: 0.3865892
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.7279186
	speed: 0.0953s/iter; left time: 1862.8080s
	iters: 200, epoch: 26 | loss: 0.5488765
	speed: 0.0160s/iter; left time: 312.0103s
Epoch: 26 cost time: 6.753777980804443
Epoch: 26, Steps: 262 | Train Loss: 0.5547428 Vali Loss: 0.2769831 Test Loss: 0.3866031
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4201366
	speed: 0.1724s/iter; left time: 3324.8814s
	iters: 200, epoch: 27 | loss: 0.4235555
	speed: 0.0282s/iter; left time: 540.7666s
Epoch: 27 cost time: 10.258603811264038
Epoch: 27, Steps: 262 | Train Loss: 0.5539871 Vali Loss: 0.2771070 Test Loss: 0.3866023
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.5010804
	speed: 0.1914s/iter; left time: 3640.9617s
	iters: 200, epoch: 28 | loss: 0.3422568
	speed: 0.0552s/iter; left time: 1044.1306s
Epoch: 28 cost time: 15.85732388496399
Epoch: 28, Steps: 262 | Train Loss: 0.5534694 Vali Loss: 0.2770073 Test Loss: 0.3865854
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.6934475
	speed: 0.2393s/iter; left time: 4490.5430s
	iters: 200, epoch: 29 | loss: 0.4557901
	speed: 0.0495s/iter; left time: 924.7733s
Epoch: 29 cost time: 13.835107803344727
Epoch: 29, Steps: 262 | Train Loss: 0.5547372 Vali Loss: 0.2771432 Test Loss: 0.3865981
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.5630088
	speed: 0.2184s/iter; left time: 4041.7834s
	iters: 200, epoch: 30 | loss: 0.4398198
	speed: 0.0592s/iter; left time: 1089.4133s
Epoch: 30 cost time: 14.649806261062622
Epoch: 30, Steps: 262 | Train Loss: 0.5544599 Vali Loss: 0.2770654 Test Loss: 0.3866047
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.5676463
	speed: 0.2224s/iter; left time: 4057.3616s
	iters: 200, epoch: 31 | loss: 0.4153354
	speed: 0.0602s/iter; left time: 1091.6441s
Epoch: 31 cost time: 14.999530792236328
Epoch: 31, Steps: 262 | Train Loss: 0.5544432 Vali Loss: 0.2771225 Test Loss: 0.3865883
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4806535
	speed: 0.2324s/iter; left time: 4177.9497s
	iters: 200, epoch: 32 | loss: 0.6311101
	speed: 0.0630s/iter; left time: 1125.9118s
Epoch: 32 cost time: 16.436716079711914
Epoch: 32, Steps: 262 | Train Loss: 0.5533210 Vali Loss: 0.2770348 Test Loss: 0.3865939
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4503268
	speed: 0.2068s/iter; left time: 3663.9380s
	iters: 200, epoch: 33 | loss: 0.5223916
	speed: 0.0184s/iter; left time: 323.6268s
Epoch: 33 cost time: 8.667596817016602
Epoch: 33, Steps: 262 | Train Loss: 0.5540658 Vali Loss: 0.2771668 Test Loss: 0.3865964
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.6808984
	speed: 0.0886s/iter; left time: 1545.8196s
	iters: 200, epoch: 34 | loss: 0.4345352
	speed: 0.0168s/iter; left time: 291.0616s
Epoch: 34 cost time: 5.387043476104736
Epoch: 34, Steps: 262 | Train Loss: 0.5544535 Vali Loss: 0.2769078 Test Loss: 0.3865904
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.5745866
	speed: 0.0804s/iter; left time: 1382.7466s
	iters: 200, epoch: 35 | loss: 0.5858186
	speed: 0.0175s/iter; left time: 298.8181s
Epoch: 35 cost time: 5.0374755859375
Epoch: 35, Steps: 262 | Train Loss: 0.5537205 Vali Loss: 0.2771051 Test Loss: 0.3865940
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.5569236
	speed: 0.0808s/iter; left time: 1368.4066s
	iters: 200, epoch: 36 | loss: 0.6271709
	speed: 0.0159s/iter; left time: 267.6951s
Epoch: 36 cost time: 4.847111463546753
Epoch: 36, Steps: 262 | Train Loss: 0.5544955 Vali Loss: 0.2769836 Test Loss: 0.3865980
EarlyStopping counter: 19 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.7438300
	speed: 0.0759s/iter; left time: 1264.4067s
	iters: 200, epoch: 37 | loss: 0.6763749
	speed: 0.0167s/iter; left time: 276.3198s
Epoch: 37 cost time: 4.954385042190552
Epoch: 37, Steps: 262 | Train Loss: 0.5541362 Vali Loss: 0.2770076 Test Loss: 0.3866026
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_180_720_FITS_ETTm2_ftM_sl180_ll48_pl720_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.3839946985244751, mae:0.38792866468429565, rse:0.4980890452861786, corr:[0.54667044 0.5475467  0.54533255 0.54207706 0.53953266 0.53821445
 0.5378609  0.5377009  0.537213   0.5363099  0.53517693 0.53417045
 0.5334588  0.53295124 0.5325437  0.53195935 0.5310534  0.52988744
 0.52864337 0.527545   0.52677137 0.5263019  0.52598786 0.52568865
 0.52526295 0.5246615  0.5239826  0.52331644 0.522715   0.52214944
 0.52164155 0.5212018  0.52075285 0.5202391  0.5196334  0.5189893
 0.5182865  0.51761734 0.516958   0.5163404  0.5158173  0.5153814
 0.515012   0.5146444  0.51417524 0.5135879  0.5128687  0.5120473
 0.51114804 0.5102102  0.50929344 0.5085159  0.50785065 0.50722283
 0.5066438  0.5061521  0.5056949  0.50532734 0.50501484 0.50475705
 0.50449073 0.50425243 0.5040622  0.50382215 0.5035785  0.5033947
 0.5032343  0.503147   0.5031018  0.50308526 0.5030114  0.502865
 0.5027074  0.50249577 0.5023005  0.5020731  0.5018225  0.5014988
 0.5011405  0.5007419  0.5003095  0.49987158 0.49948183 0.49910766
 0.49871746 0.49829155 0.4978186  0.49740016 0.4970517  0.4967654
 0.49652812 0.4962461  0.4957663  0.49494147 0.49367136 0.4919504
 0.48993933 0.48801795 0.48630205 0.4847473  0.48329252 0.4818866
 0.48050207 0.47915193 0.4778123  0.47652873 0.47535604 0.4742803
 0.47318926 0.47185248 0.47042927 0.46897343 0.4676432  0.46650818
 0.46548367 0.46456563 0.46365914 0.46265325 0.46154118 0.46029568
 0.45906007 0.45799622 0.45714846 0.4564426  0.45573106 0.45486236
 0.4537814  0.4525385  0.45129412 0.45016384 0.4492578  0.44853768
 0.44793284 0.44728184 0.44664073 0.44604027 0.44546992 0.44497588
 0.44452032 0.44406945 0.44354796 0.442905   0.4421319  0.44118434
 0.44008288 0.43893877 0.43782115 0.43687472 0.4362054  0.4357184
 0.4353389  0.43507496 0.43474972 0.43432537 0.4338107  0.4331861
 0.43254858 0.4319893  0.431471   0.43102133 0.4306561  0.43034443
 0.430122   0.4298655  0.4297296  0.42967224 0.42964336 0.42966837
 0.4297281  0.42982885 0.4298956  0.42989907 0.42985985 0.42970598
 0.42950386 0.42927995 0.42913032 0.42905357 0.4290435  0.42905295
 0.42895514 0.4287042  0.4284261  0.4281809  0.42805898 0.42799312
 0.42793018 0.42775476 0.42734283 0.42656317 0.42533103 0.4236923
 0.42184764 0.42015415 0.4186319  0.41722536 0.41596365 0.41472137
 0.41342366 0.41207537 0.41072246 0.4095884  0.40864202 0.40791506
 0.4072636  0.40655884 0.40574566 0.40487677 0.4040732  0.4033779
 0.40272948 0.40205196 0.4012787  0.40038428 0.39942023 0.3984063
 0.3974261  0.3964029  0.39548412 0.3946065  0.3936734  0.3927331
 0.39174557 0.39078647 0.38997582 0.38914528 0.38826686 0.38731834
 0.38624972 0.38510376 0.38398296 0.3830398  0.3823195  0.38185087
 0.38150272 0.38120905 0.380968   0.38061854 0.38020685 0.37967572
 0.37906078 0.37837633 0.37768757 0.37719813 0.3768886  0.3767327
 0.37669834 0.37675455 0.37693188 0.37719744 0.3775632  0.37797973
 0.37830353 0.3785609  0.37866977 0.37858364 0.37835088 0.37813145
 0.37799358 0.37789306 0.37781346 0.3777662  0.3776771  0.3774833
 0.37727743 0.37715942 0.37717223 0.37727967 0.37743342 0.37755674
 0.37750793 0.37730274 0.37697613 0.37671652 0.37662083 0.37671
 0.37685606 0.37690437 0.3768206  0.37663993 0.37634826 0.37614176
 0.3760473  0.3759632  0.37577787 0.3753762  0.3746619  0.37359768
 0.37225595 0.37102607 0.36994624 0.36910555 0.36841717 0.36776668
 0.36719245 0.36657777 0.36592895 0.36529922 0.3648296  0.3644886
 0.36418432 0.36364952 0.36294237 0.3621068  0.3612057  0.36029938
 0.35949543 0.35877895 0.35804722 0.35728717 0.35650122 0.3557549
 0.35500827 0.35429913 0.3535439  0.35274822 0.3518167  0.35080364
 0.3497927  0.34886006 0.34805897 0.34737286 0.34676188 0.34613344
 0.34547812 0.3447964  0.3441602  0.34361893 0.34317484 0.34284785
 0.34264502 0.34243476 0.34216377 0.34172028 0.3410935  0.34041187
 0.33967406 0.33891186 0.33816227 0.33761612 0.33723763 0.33702654
 0.33697245 0.33707678 0.33726603 0.3375288  0.33774555 0.33792466
 0.3379787  0.33791125 0.33774605 0.33754805 0.33738914 0.3373019
 0.33724093 0.33717722 0.33700937 0.336776   0.33650455 0.3362834
 0.3362314  0.33638954 0.33670324 0.33709353 0.33742866 0.33771166
 0.3378419  0.3378467  0.33777535 0.33768672 0.33778575 0.33798656
 0.33825493 0.33856437 0.338836   0.33901677 0.3390705  0.3390156
 0.33891535 0.3387385  0.33843815 0.33791083 0.3371812  0.3362305
 0.33513018 0.33401242 0.33297354 0.33204654 0.33111796 0.3302337
 0.32933253 0.32836333 0.3273624  0.32643193 0.3255831  0.32487053
 0.32425874 0.32361227 0.32289818 0.3221944  0.3215335  0.32085901
 0.32019323 0.31942442 0.3185663  0.31766734 0.31674188 0.31581897
 0.31499833 0.31430313 0.31369013 0.3130765  0.31241167 0.31171307
 0.311031   0.31042424 0.30993015 0.30958843 0.3092627  0.30893356
 0.30851206 0.30791897 0.3072234  0.30662906 0.30617094 0.3059608
 0.30605957 0.30636653 0.30665064 0.30674237 0.30646124 0.30584043
 0.30491397 0.3039426  0.3030681  0.30249596 0.30219957 0.3020529
 0.3020324  0.30210078 0.3022684  0.30246043 0.30260277 0.30272272
 0.3027328  0.3025891  0.3022875  0.30179167 0.30120438 0.30070165
 0.3004116  0.30031067 0.3004204  0.3007095  0.3009788  0.3011948
 0.30127355 0.30123705 0.30108935 0.30089664 0.30074143 0.3006096
 0.30047628 0.30040783 0.3004475  0.30060658 0.30078292 0.30095577
 0.30108416 0.30106324 0.30089045 0.30054626 0.30015555 0.29979452
 0.29940113 0.29893783 0.29833683 0.2974539  0.2962207  0.2947043
 0.29304388 0.29152024 0.2902318  0.28923517 0.28844273 0.28770742
 0.28694132 0.28608614 0.28523472 0.28455317 0.28412792 0.2838784
 0.28367585 0.2833707  0.28293496 0.2823723  0.28175384 0.28108677
 0.28042683 0.2797199  0.2789158  0.27806243 0.27719247 0.2763736
 0.27557108 0.2748049  0.27409166 0.27337602 0.27267504 0.27201363
 0.27139282 0.27082402 0.27029374 0.26975605 0.2691916  0.26862916
 0.26809445 0.26760662 0.26718158 0.26677614 0.26639172 0.2659943
 0.26553205 0.26504567 0.26451853 0.26389495 0.26328754 0.26264438
 0.262034   0.26145014 0.26087886 0.2603485  0.2599288  0.25957724
 0.2593173  0.2591782  0.25920323 0.25929126 0.2594026  0.25935128
 0.25918913 0.2589628  0.25865212 0.25832906 0.25802243 0.25775874
 0.25750703 0.25731495 0.2572001  0.25716555 0.25714532 0.25719067
 0.2572834  0.25742096 0.2575615  0.2575999  0.25750467 0.25733733
 0.25709116 0.25695133 0.2569891  0.25722876 0.25762632 0.25804597
 0.2582924  0.25830212 0.25806487 0.25764456 0.2572038  0.25682992
 0.25659397 0.2563667  0.2559819  0.25519344 0.25389975 0.25205785
 0.24995138 0.24807474 0.2465975  0.24555208 0.24480624 0.24415775
 0.24334256 0.24232975 0.24114652 0.23992522 0.23890407 0.23824419
 0.23782283 0.23737213 0.23685136 0.23625834 0.23557356 0.2348417
 0.23409936 0.23339239 0.2327601  0.23211569 0.23146304 0.23074248
 0.22998635 0.22931422 0.22869597 0.22804616 0.22743773 0.2268294
 0.22613852 0.22546831 0.22487792 0.22434986 0.2239917  0.22372507
 0.22357069 0.22340637 0.22321092 0.22300184 0.22280395 0.22265527
 0.2224448  0.22221833 0.22181642 0.22142453 0.22111812 0.22086759
 0.22071396 0.22059324 0.22047529 0.22031704 0.22007853 0.21978353
 0.21958742 0.21968725 0.21998803 0.22036041 0.22077514 0.22099406
 0.22104307 0.22087087 0.22051698 0.22015542 0.21995997 0.21994802
 0.22010987 0.2203613  0.22060007 0.22064456 0.22047454 0.22017063
 0.21982686 0.2196629  0.21965879 0.21990265 0.22029458 0.2206567
 0.22098073 0.22118804 0.22134443 0.2216646  0.22220565 0.22287625
 0.22365941 0.22439767 0.22500448 0.22539762 0.22554861 0.22548586
 0.2252677  0.22497174 0.22455782 0.22392541 0.22295465 0.22164503
 0.2201633  0.21877956 0.21763967 0.21676755 0.21609296 0.2155095
 0.21487972 0.21417232 0.21344069 0.21274686 0.2121754  0.21178913
 0.21158603 0.21133043 0.21101835 0.21059047 0.21007079 0.20938185
 0.20855147 0.20764081 0.20672171 0.20585781 0.20508121 0.20428579
 0.20344299 0.20246996 0.20134446 0.20012945 0.19885312 0.19762586
 0.19645993 0.19542696 0.19447596 0.19364269 0.19283138 0.19199762
 0.19112256 0.19035463 0.18973807 0.1893002  0.18882853 0.18833639
 0.18770616 0.18713216 0.18712126 0.18841785 0.19146258 0.1960724 ]
