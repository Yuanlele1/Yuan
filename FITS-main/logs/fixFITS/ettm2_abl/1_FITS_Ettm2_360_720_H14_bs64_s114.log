Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=66, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_360_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_360_720_FITS_ETTm2_ftM_sl360_ll48_pl720_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33481
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=66, out_features=198, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  11708928.0
params:  13266.0
Trainable parameters:  13266
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6453212
	speed: 0.0192s/iter; left time: 500.2808s
	iters: 200, epoch: 1 | loss: 0.3289088
	speed: 0.0160s/iter; left time: 415.3222s
Epoch: 1 cost time: 4.770134925842285
Epoch: 1, Steps: 261 | Train Loss: 0.6111018 Vali Loss: 0.2843259 Test Loss: 0.3897051
Validation loss decreased (inf --> 0.284326).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4883918
	speed: 0.0712s/iter; left time: 1833.8034s
	iters: 200, epoch: 2 | loss: 0.5242199
	speed: 0.0150s/iter; left time: 383.9054s
Epoch: 2 cost time: 5.448834419250488
Epoch: 2, Steps: 261 | Train Loss: 0.5425421 Vali Loss: 0.2744556 Test Loss: 0.3782375
Validation loss decreased (0.284326 --> 0.274456).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.6785557
	speed: 0.0725s/iter; left time: 1846.2219s
	iters: 200, epoch: 3 | loss: 0.6470062
	speed: 0.0126s/iter; left time: 320.9350s
Epoch: 3 cost time: 3.838346004486084
Epoch: 3, Steps: 261 | Train Loss: 0.5328590 Vali Loss: 0.2705595 Test Loss: 0.3745212
Validation loss decreased (0.274456 --> 0.270560).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.5343820
	speed: 0.0603s/iter; left time: 1521.0199s
	iters: 200, epoch: 4 | loss: 0.4912793
	speed: 0.0131s/iter; left time: 328.1571s
Epoch: 4 cost time: 3.896846294403076
Epoch: 4, Steps: 261 | Train Loss: 0.5283820 Vali Loss: 0.2690139 Test Loss: 0.3727416
Validation loss decreased (0.270560 --> 0.269014).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.5203351
	speed: 0.0617s/iter; left time: 1540.7458s
	iters: 200, epoch: 5 | loss: 0.5831971
	speed: 0.0128s/iter; left time: 317.4696s
Epoch: 5 cost time: 3.873581886291504
Epoch: 5, Steps: 261 | Train Loss: 0.5255020 Vali Loss: 0.2676664 Test Loss: 0.3716380
Validation loss decreased (0.269014 --> 0.267666).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4126236
	speed: 0.0624s/iter; left time: 1541.4257s
	iters: 200, epoch: 6 | loss: 0.5239171
	speed: 0.0129s/iter; left time: 317.5781s
Epoch: 6 cost time: 3.913677453994751
Epoch: 6, Steps: 261 | Train Loss: 0.5240193 Vali Loss: 0.2669207 Test Loss: 0.3708145
Validation loss decreased (0.267666 --> 0.266921).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4116566
	speed: 0.0635s/iter; left time: 1552.3911s
	iters: 200, epoch: 7 | loss: 0.5885894
	speed: 0.0130s/iter; left time: 316.5141s
Epoch: 7 cost time: 4.10969614982605
Epoch: 7, Steps: 261 | Train Loss: 0.5223158 Vali Loss: 0.2664190 Test Loss: 0.3704132
Validation loss decreased (0.266921 --> 0.266419).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.5089236
	speed: 0.0648s/iter; left time: 1566.4973s
	iters: 200, epoch: 8 | loss: 0.4644398
	speed: 0.0226s/iter; left time: 544.5781s
Epoch: 8 cost time: 5.304810285568237
Epoch: 8, Steps: 261 | Train Loss: 0.5218817 Vali Loss: 0.2656438 Test Loss: 0.3699974
Validation loss decreased (0.266419 --> 0.265644).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.5843164
	speed: 0.0775s/iter; left time: 1852.7610s
	iters: 200, epoch: 9 | loss: 0.4101363
	speed: 0.0273s/iter; left time: 650.0796s
Epoch: 9 cost time: 6.610625982284546
Epoch: 9, Steps: 261 | Train Loss: 0.5208113 Vali Loss: 0.2655607 Test Loss: 0.3697022
Validation loss decreased (0.265644 --> 0.265561).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3739921
	speed: 0.0792s/iter; left time: 1873.4634s
	iters: 200, epoch: 10 | loss: 0.5280507
	speed: 0.0140s/iter; left time: 329.9741s
Epoch: 10 cost time: 4.074578285217285
Epoch: 10, Steps: 261 | Train Loss: 0.5202175 Vali Loss: 0.2652248 Test Loss: 0.3694562
Validation loss decreased (0.265561 --> 0.265225).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4825133
	speed: 0.0628s/iter; left time: 1468.6083s
	iters: 200, epoch: 11 | loss: 0.6706299
	speed: 0.0132s/iter; left time: 307.1518s
Epoch: 11 cost time: 3.9795212745666504
Epoch: 11, Steps: 261 | Train Loss: 0.5194609 Vali Loss: 0.2649214 Test Loss: 0.3693306
Validation loss decreased (0.265225 --> 0.264921).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.5548978
	speed: 0.0673s/iter; left time: 1556.4395s
	iters: 200, epoch: 12 | loss: 0.5475746
	speed: 0.0130s/iter; left time: 299.4699s
Epoch: 12 cost time: 4.169973373413086
Epoch: 12, Steps: 261 | Train Loss: 0.5190603 Vali Loss: 0.2648193 Test Loss: 0.3691700
Validation loss decreased (0.264921 --> 0.264819).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.5462547
	speed: 0.0626s/iter; left time: 1431.0049s
	iters: 200, epoch: 13 | loss: 0.3937409
	speed: 0.0129s/iter; left time: 293.8327s
Epoch: 13 cost time: 3.8721981048583984
Epoch: 13, Steps: 261 | Train Loss: 0.5188085 Vali Loss: 0.2645402 Test Loss: 0.3690540
Validation loss decreased (0.264819 --> 0.264540).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.5834906
	speed: 0.0629s/iter; left time: 1421.6462s
	iters: 200, epoch: 14 | loss: 0.5054201
	speed: 0.0131s/iter; left time: 294.1377s
Epoch: 14 cost time: 4.144710063934326
Epoch: 14, Steps: 261 | Train Loss: 0.5185814 Vali Loss: 0.2642346 Test Loss: 0.3689642
Validation loss decreased (0.264540 --> 0.264235).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.7244481
	speed: 0.0715s/iter; left time: 1597.8353s
	iters: 200, epoch: 15 | loss: 0.6560545
	speed: 0.0177s/iter; left time: 393.1951s
Epoch: 15 cost time: 4.665552854537964
Epoch: 15, Steps: 261 | Train Loss: 0.5185916 Vali Loss: 0.2642740 Test Loss: 0.3689422
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.6415636
	speed: 0.0615s/iter; left time: 1359.2883s
	iters: 200, epoch: 16 | loss: 0.5140811
	speed: 0.0129s/iter; left time: 283.4139s
Epoch: 16 cost time: 3.974001169204712
Epoch: 16, Steps: 261 | Train Loss: 0.5183983 Vali Loss: 0.2643998 Test Loss: 0.3688710
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.5269116
	speed: 0.0639s/iter; left time: 1394.6857s
	iters: 200, epoch: 17 | loss: 0.5363922
	speed: 0.0165s/iter; left time: 357.7098s
Epoch: 17 cost time: 4.655390024185181
Epoch: 17, Steps: 261 | Train Loss: 0.5180098 Vali Loss: 0.2643250 Test Loss: 0.3687729
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4552846
	speed: 0.0716s/iter; left time: 1543.7453s
	iters: 200, epoch: 18 | loss: 0.6016732
	speed: 0.0147s/iter; left time: 316.2025s
Epoch: 18 cost time: 6.0337233543396
Epoch: 18, Steps: 261 | Train Loss: 0.5178265 Vali Loss: 0.2638833 Test Loss: 0.3687444
Validation loss decreased (0.264235 --> 0.263883).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4494319
	speed: 0.0787s/iter; left time: 1677.3774s
	iters: 200, epoch: 19 | loss: 0.5236906
	speed: 0.0141s/iter; left time: 298.3606s
Epoch: 19 cost time: 4.264684677124023
Epoch: 19, Steps: 261 | Train Loss: 0.5173504 Vali Loss: 0.2640702 Test Loss: 0.3687246
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4438058
	speed: 0.0690s/iter; left time: 1450.8720s
	iters: 200, epoch: 20 | loss: 0.5668305
	speed: 0.0174s/iter; left time: 364.4345s
Epoch: 20 cost time: 4.900083065032959
Epoch: 20, Steps: 261 | Train Loss: 0.5174675 Vali Loss: 0.2639359 Test Loss: 0.3686870
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.5990322
	speed: 0.0692s/iter; left time: 1437.3209s
	iters: 200, epoch: 21 | loss: 0.4984591
	speed: 0.0128s/iter; left time: 264.9204s
Epoch: 21 cost time: 3.900911569595337
Epoch: 21, Steps: 261 | Train Loss: 0.5172725 Vali Loss: 0.2637137 Test Loss: 0.3686596
Validation loss decreased (0.263883 --> 0.263714).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4775795
	speed: 0.0626s/iter; left time: 1284.1837s
	iters: 200, epoch: 22 | loss: 0.5638391
	speed: 0.0129s/iter; left time: 262.5193s
Epoch: 22 cost time: 3.9526448249816895
Epoch: 22, Steps: 261 | Train Loss: 0.5174533 Vali Loss: 0.2636256 Test Loss: 0.3686751
Validation loss decreased (0.263714 --> 0.263626).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4892794
	speed: 0.0606s/iter; left time: 1227.3286s
	iters: 200, epoch: 23 | loss: 0.5885640
	speed: 0.0128s/iter; left time: 257.2391s
Epoch: 23 cost time: 3.8801941871643066
Epoch: 23, Steps: 261 | Train Loss: 0.5177561 Vali Loss: 0.2637065 Test Loss: 0.3686440
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4004075
	speed: 0.0604s/iter; left time: 1208.5711s
	iters: 200, epoch: 24 | loss: 0.5445691
	speed: 0.0134s/iter; left time: 267.2064s
Epoch: 24 cost time: 4.035772085189819
Epoch: 24, Steps: 261 | Train Loss: 0.5171521 Vali Loss: 0.2638644 Test Loss: 0.3686114
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4885538
	speed: 0.0639s/iter; left time: 1261.4715s
	iters: 200, epoch: 25 | loss: 0.4359414
	speed: 0.0165s/iter; left time: 323.1726s
Epoch: 25 cost time: 4.5742692947387695
Epoch: 25, Steps: 261 | Train Loss: 0.5170295 Vali Loss: 0.2638275 Test Loss: 0.3686143
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4735177
	speed: 0.0697s/iter; left time: 1357.5626s
	iters: 200, epoch: 26 | loss: 0.5340363
	speed: 0.0133s/iter; left time: 257.6522s
Epoch: 26 cost time: 4.0544068813323975
Epoch: 26, Steps: 261 | Train Loss: 0.5170441 Vali Loss: 0.2639945 Test Loss: 0.3686170
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3942850
	speed: 0.0603s/iter; left time: 1158.8507s
	iters: 200, epoch: 27 | loss: 0.4638353
	speed: 0.0154s/iter; left time: 294.5754s
Epoch: 27 cost time: 5.04267144203186
Epoch: 27, Steps: 261 | Train Loss: 0.5173532 Vali Loss: 0.2637319 Test Loss: 0.3685996
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4871303
	speed: 0.0756s/iter; left time: 1432.9843s
	iters: 200, epoch: 28 | loss: 0.5010704
	speed: 0.0153s/iter; left time: 288.0676s
Epoch: 28 cost time: 4.460221529006958
Epoch: 28, Steps: 261 | Train Loss: 0.5170903 Vali Loss: 0.2635490 Test Loss: 0.3685726
Validation loss decreased (0.263626 --> 0.263549).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3072182
	speed: 0.0672s/iter; left time: 1256.7043s
	iters: 200, epoch: 29 | loss: 0.4990591
	speed: 0.0129s/iter; left time: 239.6229s
Epoch: 29 cost time: 3.993569850921631
Epoch: 29, Steps: 261 | Train Loss: 0.5173757 Vali Loss: 0.2640623 Test Loss: 0.3685664
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4739971
	speed: 0.0606s/iter; left time: 1116.7964s
	iters: 200, epoch: 30 | loss: 0.5398146
	speed: 0.0128s/iter; left time: 234.2749s
Epoch: 30 cost time: 3.9785664081573486
Epoch: 30, Steps: 261 | Train Loss: 0.5166889 Vali Loss: 0.2637840 Test Loss: 0.3685671
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.5592784
	speed: 0.0630s/iter; left time: 1144.5769s
	iters: 200, epoch: 31 | loss: 0.5690961
	speed: 0.0159s/iter; left time: 287.8605s
Epoch: 31 cost time: 5.079829216003418
Epoch: 31, Steps: 261 | Train Loss: 0.5163251 Vali Loss: 0.2637328 Test Loss: 0.3685614
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4658184
	speed: 0.0790s/iter; left time: 1414.9132s
	iters: 200, epoch: 32 | loss: 0.4245372
	speed: 0.0131s/iter; left time: 232.6533s
Epoch: 32 cost time: 4.017962455749512
Epoch: 32, Steps: 261 | Train Loss: 0.5171014 Vali Loss: 0.2636361 Test Loss: 0.3685293
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.5459977
	speed: 0.0606s/iter; left time: 1070.1383s
	iters: 200, epoch: 33 | loss: 0.4420985
	speed: 0.0130s/iter; left time: 227.4162s
Epoch: 33 cost time: 4.0851805210113525
Epoch: 33, Steps: 261 | Train Loss: 0.5164618 Vali Loss: 0.2637717 Test Loss: 0.3685518
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.5325321
	speed: 0.0642s/iter; left time: 1117.1327s
	iters: 200, epoch: 34 | loss: 0.4872997
	speed: 0.0129s/iter; left time: 223.1501s
Epoch: 34 cost time: 3.946251153945923
Epoch: 34, Steps: 261 | Train Loss: 0.5167313 Vali Loss: 0.2635587 Test Loss: 0.3685320
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.5645939
	speed: 0.0622s/iter; left time: 1065.7485s
	iters: 200, epoch: 35 | loss: 0.5355373
	speed: 0.0129s/iter; left time: 220.1703s
Epoch: 35 cost time: 3.996047258377075
Epoch: 35, Steps: 261 | Train Loss: 0.5167452 Vali Loss: 0.2636098 Test Loss: 0.3685400
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.6091519
	speed: 0.0609s/iter; left time: 1026.8080s
	iters: 200, epoch: 36 | loss: 0.5209357
	speed: 0.0127s/iter; left time: 213.7662s
Epoch: 36 cost time: 3.915452718734741
Epoch: 36, Steps: 261 | Train Loss: 0.5166818 Vali Loss: 0.2635595 Test Loss: 0.3685353
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4332706
	speed: 0.0640s/iter; left time: 1062.7564s
	iters: 200, epoch: 37 | loss: 0.4442834
	speed: 0.0143s/iter; left time: 235.6984s
Epoch: 37 cost time: 4.3483405113220215
Epoch: 37, Steps: 261 | Train Loss: 0.5168275 Vali Loss: 0.2637541 Test Loss: 0.3685212
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3424824
	speed: 0.0716s/iter; left time: 1169.8520s
	iters: 200, epoch: 38 | loss: 0.4634486
	speed: 0.0145s/iter; left time: 235.4959s
Epoch: 38 cost time: 4.553666353225708
Epoch: 38, Steps: 261 | Train Loss: 0.5163231 Vali Loss: 0.2634509 Test Loss: 0.3685153
Validation loss decreased (0.263549 --> 0.263451).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.6253321
	speed: 0.0699s/iter; left time: 1123.8818s
	iters: 200, epoch: 39 | loss: 0.4606770
	speed: 0.0208s/iter; left time: 332.8199s
Epoch: 39 cost time: 5.538180351257324
Epoch: 39, Steps: 261 | Train Loss: 0.5165361 Vali Loss: 0.2634780 Test Loss: 0.3685069
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.5329127
	speed: 0.0789s/iter; left time: 1247.9397s
	iters: 200, epoch: 40 | loss: 0.4074523
	speed: 0.0179s/iter; left time: 282.2005s
Epoch: 40 cost time: 5.8265299797058105
Epoch: 40, Steps: 261 | Train Loss: 0.5165696 Vali Loss: 0.2634908 Test Loss: 0.3685079
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3222798
	speed: 0.0836s/iter; left time: 1301.1520s
	iters: 200, epoch: 41 | loss: 0.4773707
	speed: 0.0161s/iter; left time: 248.6392s
Epoch: 41 cost time: 4.708062171936035
Epoch: 41, Steps: 261 | Train Loss: 0.5166742 Vali Loss: 0.2638819 Test Loss: 0.3685119
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.4367946
	speed: 0.0723s/iter; left time: 1105.9124s
	iters: 200, epoch: 42 | loss: 0.5523137
	speed: 0.0166s/iter; left time: 252.4638s
Epoch: 42 cost time: 4.758337497711182
Epoch: 42, Steps: 261 | Train Loss: 0.5164777 Vali Loss: 0.2636243 Test Loss: 0.3685134
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.5452735
	speed: 0.0678s/iter; left time: 1019.4058s
	iters: 200, epoch: 43 | loss: 0.4398092
	speed: 0.0138s/iter; left time: 205.5245s
Epoch: 43 cost time: 4.21250057220459
Epoch: 43, Steps: 261 | Train Loss: 0.5165453 Vali Loss: 0.2635312 Test Loss: 0.3685054
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.4492739
	speed: 0.0683s/iter; left time: 1009.6268s
	iters: 200, epoch: 44 | loss: 0.6376963
	speed: 0.0146s/iter; left time: 214.4521s
Epoch: 44 cost time: 4.424722671508789
Epoch: 44, Steps: 261 | Train Loss: 0.5162311 Vali Loss: 0.2637526 Test Loss: 0.3685005
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.4355359
	speed: 0.0690s/iter; left time: 1001.6080s
	iters: 200, epoch: 45 | loss: 0.6037835
	speed: 0.0128s/iter; left time: 184.0878s
Epoch: 45 cost time: 3.945251226425171
Epoch: 45, Steps: 261 | Train Loss: 0.5167707 Vali Loss: 0.2635005 Test Loss: 0.3684941
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.4969302
	speed: 0.0608s/iter; left time: 867.1753s
	iters: 200, epoch: 46 | loss: 0.5694866
	speed: 0.0143s/iter; left time: 203.0713s
Epoch: 46 cost time: 4.1484174728393555
Epoch: 46, Steps: 261 | Train Loss: 0.5159834 Vali Loss: 0.2636548 Test Loss: 0.3685000
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.5977893
	speed: 0.0718s/iter; left time: 1004.4901s
	iters: 200, epoch: 47 | loss: 0.6185569
	speed: 0.0195s/iter; left time: 271.2646s
Epoch: 47 cost time: 4.9249587059021
Epoch: 47, Steps: 261 | Train Loss: 0.5170054 Vali Loss: 0.2635170 Test Loss: 0.3685027
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.6137009
	speed: 0.0683s/iter; left time: 937.9826s
	iters: 200, epoch: 48 | loss: 0.6198980
	speed: 0.0171s/iter; left time: 232.5094s
Epoch: 48 cost time: 4.455548048019409
Epoch: 48, Steps: 261 | Train Loss: 0.5165374 Vali Loss: 0.2636200 Test Loss: 0.3685056
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.5583148
	speed: 0.0709s/iter; left time: 955.1792s
	iters: 200, epoch: 49 | loss: 0.4280556
	speed: 0.0186s/iter; left time: 249.2013s
Epoch: 49 cost time: 4.82916522026062
Epoch: 49, Steps: 261 | Train Loss: 0.5164070 Vali Loss: 0.2637232 Test Loss: 0.3684937
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.4948819
	speed: 0.0734s/iter; left time: 969.4153s
	iters: 200, epoch: 50 | loss: 0.5047408
	speed: 0.0160s/iter; left time: 209.5301s
Epoch: 50 cost time: 4.607864618301392
Epoch: 50, Steps: 261 | Train Loss: 0.5167826 Vali Loss: 0.2634822 Test Loss: 0.3684871
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.3577465
	speed: 0.0672s/iter; left time: 870.4025s
	iters: 200, epoch: 51 | loss: 0.4589903
	speed: 0.0172s/iter; left time: 220.7351s
Epoch: 51 cost time: 4.6476194858551025
Epoch: 51, Steps: 261 | Train Loss: 0.5164023 Vali Loss: 0.2635601 Test Loss: 0.3684811
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.4750450
	speed: 0.0656s/iter; left time: 832.2400s
	iters: 200, epoch: 52 | loss: 0.6638484
	speed: 0.0140s/iter; left time: 176.7198s
Epoch: 52 cost time: 4.163987159729004
Epoch: 52, Steps: 261 | Train Loss: 0.5157676 Vali Loss: 0.2633844 Test Loss: 0.3684853
Validation loss decreased (0.263451 --> 0.263384).  Saving model ...
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.4832850
	speed: 0.0691s/iter; left time: 859.3472s
	iters: 200, epoch: 53 | loss: 0.5300742
	speed: 0.0155s/iter; left time: 190.6842s
Epoch: 53 cost time: 5.1679747104644775
Epoch: 53, Steps: 261 | Train Loss: 0.5166061 Vali Loss: 0.2633704 Test Loss: 0.3684829
Validation loss decreased (0.263384 --> 0.263370).  Saving model ...
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.4750019
	speed: 0.0786s/iter; left time: 956.1224s
	iters: 200, epoch: 54 | loss: 0.5113971
	speed: 0.0160s/iter; left time: 192.4944s
Epoch: 54 cost time: 4.599620819091797
Epoch: 54, Steps: 261 | Train Loss: 0.5166702 Vali Loss: 0.2635099 Test Loss: 0.3684869
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.3886450
	speed: 0.0647s/iter; left time: 770.9466s
	iters: 200, epoch: 55 | loss: 0.5830363
	speed: 0.0144s/iter; left time: 169.6960s
Epoch: 55 cost time: 4.304431915283203
Epoch: 55, Steps: 261 | Train Loss: 0.5166822 Vali Loss: 0.2638285 Test Loss: 0.3684896
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.5662272
	speed: 0.0768s/iter; left time: 893.8984s
	iters: 200, epoch: 56 | loss: 0.4693540
	speed: 0.0145s/iter; left time: 167.0380s
Epoch: 56 cost time: 4.675898551940918
Epoch: 56, Steps: 261 | Train Loss: 0.5165382 Vali Loss: 0.2634596 Test Loss: 0.3684889
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.3563140
	speed: 0.0938s/iter; left time: 1068.4314s
	iters: 200, epoch: 57 | loss: 0.4175523
	speed: 0.0132s/iter; left time: 149.0659s
Epoch: 57 cost time: 4.154690980911255
Epoch: 57, Steps: 261 | Train Loss: 0.5167694 Vali Loss: 0.2635678 Test Loss: 0.3684844
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.5435287
	speed: 0.0687s/iter; left time: 763.8961s
	iters: 200, epoch: 58 | loss: 0.6073217
	speed: 0.0151s/iter; left time: 166.5857s
Epoch: 58 cost time: 4.632916212081909
Epoch: 58, Steps: 261 | Train Loss: 0.5165220 Vali Loss: 0.2636660 Test Loss: 0.3684840
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.4399800
	speed: 0.0626s/iter; left time: 679.8554s
	iters: 200, epoch: 59 | loss: 0.4455843
	speed: 0.0128s/iter; left time: 137.9732s
Epoch: 59 cost time: 3.9173784255981445
Epoch: 59, Steps: 261 | Train Loss: 0.5158149 Vali Loss: 0.2636428 Test Loss: 0.3684843
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.5158719
	speed: 0.0652s/iter; left time: 691.6577s
	iters: 200, epoch: 60 | loss: 0.6177318
	speed: 0.0196s/iter; left time: 206.3565s
Epoch: 60 cost time: 5.285402059555054
Epoch: 60, Steps: 261 | Train Loss: 0.5163989 Vali Loss: 0.2634752 Test Loss: 0.3684821
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.4235521
	speed: 0.0705s/iter; left time: 728.9338s
	iters: 200, epoch: 61 | loss: 0.4880497
	speed: 0.0253s/iter; left time: 259.4574s
Epoch: 61 cost time: 5.683427572250366
Epoch: 61, Steps: 261 | Train Loss: 0.5163738 Vali Loss: 0.2634774 Test Loss: 0.3684835
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.4621472
	speed: 0.0756s/iter; left time: 762.3083s
	iters: 200, epoch: 62 | loss: 0.5453845
	speed: 0.0129s/iter; left time: 128.7045s
Epoch: 62 cost time: 4.002859592437744
Epoch: 62, Steps: 261 | Train Loss: 0.5168739 Vali Loss: 0.2634687 Test Loss: 0.3684829
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.5438957
	speed: 0.0798s/iter; left time: 783.5186s
	iters: 200, epoch: 63 | loss: 0.5180037
	speed: 0.0161s/iter; left time: 156.9350s
Epoch: 63 cost time: 4.71559476852417
Epoch: 63, Steps: 261 | Train Loss: 0.5158818 Vali Loss: 0.2636783 Test Loss: 0.3684824
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.5719227
	speed: 0.0673s/iter; left time: 643.5976s
	iters: 200, epoch: 64 | loss: 0.5074379
	speed: 0.0137s/iter; left time: 129.5534s
Epoch: 64 cost time: 4.079372882843018
Epoch: 64, Steps: 261 | Train Loss: 0.5164847 Vali Loss: 0.2637072 Test Loss: 0.3684822
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.4968145
	speed: 0.0710s/iter; left time: 659.9670s
	iters: 200, epoch: 65 | loss: 0.6077464
	speed: 0.0142s/iter; left time: 130.8964s
Epoch: 65 cost time: 4.107114315032959
Epoch: 65, Steps: 261 | Train Loss: 0.5165025 Vali Loss: 0.2634004 Test Loss: 0.3684826
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.6559901
	speed: 0.0613s/iter; left time: 553.7613s
	iters: 200, epoch: 66 | loss: 0.5648173
	speed: 0.0126s/iter; left time: 112.9629s
Epoch: 66 cost time: 3.9365766048431396
Epoch: 66, Steps: 261 | Train Loss: 0.5160349 Vali Loss: 0.2631776 Test Loss: 0.3684814
Validation loss decreased (0.263370 --> 0.263178).  Saving model ...
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.5745908
	speed: 0.0644s/iter; left time: 565.2852s
	iters: 200, epoch: 67 | loss: 0.5768425
	speed: 0.0145s/iter; left time: 126.1055s
Epoch: 67 cost time: 4.4044342041015625
Epoch: 67, Steps: 261 | Train Loss: 0.5166228 Vali Loss: 0.2634405 Test Loss: 0.3684817
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.4750363
	speed: 0.0681s/iter; left time: 580.0143s
	iters: 200, epoch: 68 | loss: 0.5869702
	speed: 0.0129s/iter; left time: 108.7363s
Epoch: 68 cost time: 3.906921863555908
Epoch: 68, Steps: 261 | Train Loss: 0.5160487 Vali Loss: 0.2634905 Test Loss: 0.3684784
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.6373900
	speed: 0.0614s/iter; left time: 506.6268s
	iters: 200, epoch: 69 | loss: 0.4609316
	speed: 0.0130s/iter; left time: 105.8073s
Epoch: 69 cost time: 3.9589474201202393
Epoch: 69, Steps: 261 | Train Loss: 0.5161900 Vali Loss: 0.2633329 Test Loss: 0.3684787
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.6129079
	speed: 0.0701s/iter; left time: 560.5042s
	iters: 200, epoch: 70 | loss: 0.4817743
	speed: 0.0261s/iter; left time: 205.9804s
Epoch: 70 cost time: 5.954764127731323
Epoch: 70, Steps: 261 | Train Loss: 0.5164768 Vali Loss: 0.2633291 Test Loss: 0.3684801
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.3800308
	speed: 0.0785s/iter; left time: 606.5110s
	iters: 200, epoch: 71 | loss: 0.5431076
	speed: 0.0155s/iter; left time: 118.3715s
Epoch: 71 cost time: 4.879378080368042
Epoch: 71, Steps: 261 | Train Loss: 0.5163609 Vali Loss: 0.2636199 Test Loss: 0.3684784
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.4148599
	speed: 0.0699s/iter; left time: 522.3985s
	iters: 200, epoch: 72 | loss: 0.4752956
	speed: 0.0150s/iter; left time: 110.8359s
Epoch: 72 cost time: 4.475114583969116
Epoch: 72, Steps: 261 | Train Loss: 0.5164337 Vali Loss: 0.2634986 Test Loss: 0.3684792
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.5824569
	speed: 0.0650s/iter; left time: 468.8315s
	iters: 200, epoch: 73 | loss: 0.5058042
	speed: 0.0130s/iter; left time: 92.5722s
Epoch: 73 cost time: 3.9869256019592285
Epoch: 73, Steps: 261 | Train Loss: 0.5162382 Vali Loss: 0.2634328 Test Loss: 0.3684801
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.5201199
	speed: 0.0723s/iter; left time: 502.6234s
	iters: 200, epoch: 74 | loss: 0.4403695
	speed: 0.0150s/iter; left time: 102.7940s
Epoch: 74 cost time: 6.277266979217529
Epoch: 74, Steps: 261 | Train Loss: 0.5160062 Vali Loss: 0.2633743 Test Loss: 0.3684791
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.3633373
	speed: 0.0880s/iter; left time: 588.3136s
	iters: 200, epoch: 75 | loss: 0.6041203
	speed: 0.0168s/iter; left time: 110.7879s
Epoch: 75 cost time: 5.04217791557312
Epoch: 75, Steps: 261 | Train Loss: 0.5166423 Vali Loss: 0.2635018 Test Loss: 0.3684769
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.3982541
	speed: 0.0717s/iter; left time: 460.8395s
	iters: 200, epoch: 76 | loss: 0.3814301
	speed: 0.0174s/iter; left time: 109.9067s
Epoch: 76 cost time: 4.773622035980225
Epoch: 76, Steps: 261 | Train Loss: 0.5163820 Vali Loss: 0.2632286 Test Loss: 0.3684784
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.6181064
	speed: 0.0690s/iter; left time: 425.5932s
	iters: 200, epoch: 77 | loss: 0.5925496
	speed: 0.0142s/iter; left time: 86.3414s
Epoch: 77 cost time: 4.160999298095703
Epoch: 77, Steps: 261 | Train Loss: 0.5164158 Vali Loss: 0.2635666 Test Loss: 0.3684795
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.4020235
	speed: 0.0618s/iter; left time: 365.1324s
	iters: 200, epoch: 78 | loss: 0.3749810
	speed: 0.0127s/iter; left time: 73.8119s
Epoch: 78 cost time: 3.9525413513183594
Epoch: 78, Steps: 261 | Train Loss: 0.5164750 Vali Loss: 0.2635791 Test Loss: 0.3684779
EarlyStopping counter: 12 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.4093890
	speed: 0.0604s/iter; left time: 340.7936s
	iters: 200, epoch: 79 | loss: 0.6087354
	speed: 0.0128s/iter; left time: 71.0642s
Epoch: 79 cost time: 3.9182913303375244
Epoch: 79, Steps: 261 | Train Loss: 0.5161418 Vali Loss: 0.2633554 Test Loss: 0.3684789
EarlyStopping counter: 13 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.6286200
	speed: 0.0620s/iter; left time: 333.7307s
	iters: 200, epoch: 80 | loss: 0.5114936
	speed: 0.0128s/iter; left time: 67.6254s
Epoch: 80 cost time: 3.99334716796875
Epoch: 80, Steps: 261 | Train Loss: 0.5165336 Vali Loss: 0.2633379 Test Loss: 0.3684788
EarlyStopping counter: 14 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.6060517
	speed: 0.0624s/iter; left time: 319.4402s
	iters: 200, epoch: 81 | loss: 0.6119769
	speed: 0.0230s/iter; left time: 115.6547s
Epoch: 81 cost time: 5.50246262550354
Epoch: 81, Steps: 261 | Train Loss: 0.5158908 Vali Loss: 0.2634082 Test Loss: 0.3684792
EarlyStopping counter: 15 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.6075940
	speed: 0.1177s/iter; left time: 571.9917s
	iters: 200, epoch: 82 | loss: 0.4899503
	speed: 0.0140s/iter; left time: 66.6598s
Epoch: 82 cost time: 4.687032699584961
Epoch: 82, Steps: 261 | Train Loss: 0.5160662 Vali Loss: 0.2636439 Test Loss: 0.3684770
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.3686869
	speed: 0.0720s/iter; left time: 331.0601s
	iters: 200, epoch: 83 | loss: 0.4235108
	speed: 0.0176s/iter; left time: 79.3089s
Epoch: 83 cost time: 4.847869157791138
Epoch: 83, Steps: 261 | Train Loss: 0.5164065 Vali Loss: 0.2635344 Test Loss: 0.3684771
EarlyStopping counter: 17 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.5334467
	speed: 0.0710s/iter; left time: 308.1907s
	iters: 200, epoch: 84 | loss: 0.6096568
	speed: 0.0191s/iter; left time: 80.9753s
Epoch: 84 cost time: 5.351841449737549
Epoch: 84, Steps: 261 | Train Loss: 0.5162477 Vali Loss: 0.2632765 Test Loss: 0.3684772
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.5259158
	speed: 0.0602s/iter; left time: 245.4132s
	iters: 200, epoch: 85 | loss: 0.5091057
	speed: 0.0137s/iter; left time: 54.3274s
Epoch: 85 cost time: 3.880017042160034
Epoch: 85, Steps: 261 | Train Loss: 0.5166908 Vali Loss: 0.2633414 Test Loss: 0.3684776
EarlyStopping counter: 19 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.4744267
	speed: 0.0630s/iter; left time: 240.4365s
	iters: 200, epoch: 86 | loss: 0.5239459
	speed: 0.0144s/iter; left time: 53.5485s
Epoch: 86 cost time: 4.259752035140991
Epoch: 86, Steps: 261 | Train Loss: 0.5162136 Vali Loss: 0.2634897 Test Loss: 0.3684776
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_360_720_FITS_ETTm2_ftM_sl360_ll48_pl720_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.36579015851020813, mae:0.38196948170661926, rse:0.4861389398574829, corr:[0.54699683 0.5440551  0.5390665  0.5386881  0.5398707  0.539107
 0.5373691  0.53651166 0.5367865  0.5370727  0.53649724 0.53563195
 0.53527164 0.5354714  0.5356381  0.5352114  0.53444386 0.5337993
 0.533447   0.53314215 0.53263545 0.5320039  0.5314556  0.53123015
 0.53118485 0.5310098  0.53060246 0.5300841  0.52961695 0.52921695
 0.5288322  0.52843595 0.52799886 0.5275688  0.5271888  0.5268038
 0.52628773 0.5256216  0.5249319  0.5243253  0.52383804 0.5234425
 0.52301127 0.5224708  0.52185875 0.52119243 0.5205196  0.5197711
 0.5188901  0.51798093 0.51715654 0.51653874 0.5159532  0.5152048
 0.5143246  0.51349926 0.51286626 0.5124671  0.5121833  0.51183236
 0.5113938  0.51099235 0.5107548  0.5106144  0.5104511  0.5102261
 0.5099207  0.5096377  0.50945497 0.5093551  0.5092212  0.50900304
 0.50872964 0.50847775 0.5082241  0.50789016 0.50749    0.50701636
 0.5065263  0.5060269  0.5055493  0.5050268  0.5044908  0.5039229
 0.5034014  0.5029405  0.5024578  0.50195885 0.5014287  0.50088805
 0.5003819  0.49989673 0.4993262  0.49857944 0.49753198 0.4961137
 0.49441582 0.49271733 0.49117988 0.4897881  0.48847315 0.48722157
 0.48602122 0.48481536 0.4835843  0.48241305 0.48132637 0.48031515
 0.47935966 0.47844303 0.47762665 0.47687167 0.47613573 0.47533548
 0.47447535 0.47363955 0.4728912  0.47222292 0.47163787 0.4710153
 0.47032887 0.4696102  0.46897548 0.46838358 0.46776873 0.4670926
 0.46636465 0.46553928 0.46461707 0.4636838  0.46286932 0.46218464
 0.46154636 0.46085864 0.46009094 0.45934024 0.4586268  0.4580362
 0.45745373 0.4567929  0.4560538  0.45531803 0.45466852 0.45400226
 0.45320523 0.4522342  0.45124748 0.45040423 0.4497255  0.4490787
 0.44838312 0.4476429  0.44687855 0.44621024 0.4456835  0.44519314
 0.44459936 0.44393596 0.44331908 0.44293547 0.44265154 0.44230092
 0.44184783 0.441369   0.4410598  0.44091523 0.44074187 0.44052958
 0.44023368 0.43995494 0.4397262  0.43948886 0.4391387  0.43868268
 0.43819973 0.4377698  0.43735838 0.4369038  0.43640074 0.43589813
 0.4354221  0.4349679  0.4345476  0.43410376 0.43366522 0.43328136
 0.432961   0.43261626 0.43211356 0.43130738 0.43014818 0.42858642
 0.42676702 0.42498758 0.42326608 0.42159638 0.42006344 0.41862127
 0.4172429  0.4158499  0.4144221  0.41299456 0.41161236 0.4103166
 0.4091228  0.40803704 0.4069605  0.4058781  0.40479204 0.40380493
 0.40291345 0.40211546 0.40140262 0.40069702 0.39982757 0.39882973
 0.3978153  0.3967776  0.39597446 0.3952859  0.3944525  0.3933739
 0.39224586 0.39124075 0.39048907 0.38971356 0.388781   0.38766018
 0.38654    0.3855463  0.38459685 0.38360995 0.38263926 0.38189062
 0.38139215 0.3810339  0.38066283 0.38007995 0.37935847 0.37871155
 0.3781759  0.37765095 0.37701762 0.3764863  0.37600672 0.37575862
 0.37579992 0.37587348 0.3757384  0.3753958  0.37507132 0.37500244
 0.3750336  0.37511984 0.37501884 0.37476623 0.37445635 0.3741628
 0.37395588 0.37376487 0.37362185 0.37351787 0.37332705 0.37307513
 0.37279686 0.37254423 0.37239417 0.3722709  0.3721677  0.3720032
 0.3716558  0.37117034 0.37071693 0.37049517 0.37032753 0.37011874
 0.3697668  0.3693739  0.369062   0.36882454 0.3685287  0.36819556
 0.36786917 0.3676646  0.3675577  0.36731815 0.36663696 0.36543676
 0.36391696 0.36252466 0.36135668 0.3603535  0.35950252 0.3588178
 0.35823324 0.35766226 0.35702777 0.35622105 0.35540912 0.35476604
 0.35429707 0.35384002 0.3533903  0.3529414  0.3525046  0.3521234
 0.35188663 0.3516507  0.35136488 0.3511756  0.3511392  0.35122928
 0.35124758 0.35109866 0.3507779  0.3504373  0.3501643  0.34989458
 0.34955627 0.34909305 0.34855387 0.3481074  0.3478183  0.34759104
 0.34725764 0.34685573 0.3464918  0.3462153  0.3460134  0.34589848
 0.3457734  0.34556922 0.3453386  0.34507635 0.34476233 0.34445015
 0.344026   0.34353057 0.3430724  0.34275913 0.34251308 0.34228644
 0.3420724  0.3420251  0.34210795 0.34218082 0.342178   0.34205985
 0.3419384  0.34189463 0.34189352 0.34188563 0.3418416  0.3416944
 0.34147257 0.34131446 0.341184   0.34105238 0.3408905  0.34064913
 0.3403912  0.3401556  0.3398368  0.3394814  0.3391349  0.33894205
 0.33881202 0.3387037  0.3385464  0.33832195 0.33815798 0.33799648
 0.33786944 0.3377909  0.3377673  0.3377456  0.3377     0.33764717
 0.33758518 0.33752486 0.33742198 0.33713531 0.33659583 0.33568376
 0.33449072 0.3333089  0.33230892 0.33145502 0.33060822 0.3297899
 0.32897595 0.3281377  0.32728732 0.32634738 0.32535788 0.324461
 0.32381016 0.32339162 0.32290974 0.3222845  0.32156277 0.32083094
 0.32025447 0.31977892 0.31936404 0.31901175 0.3187761  0.3186937
 0.3186317  0.3184651  0.31824636 0.31805554 0.3178734  0.31767243
 0.31741512 0.3171353  0.31686112 0.31662047 0.3164211  0.31623596
 0.31600904 0.31577122 0.31554875 0.31542462 0.3154523  0.31555954
 0.31559527 0.31553137 0.31537634 0.31516463 0.31499258 0.3148157
 0.3145149  0.31407365 0.31354356 0.31313306 0.3128275  0.31254306
 0.31216735 0.31182355 0.31147948 0.3112721  0.31108168 0.310826
 0.31047434 0.31016797 0.31003392 0.30996042 0.30981442 0.30950144
 0.30919495 0.30903372 0.30899525 0.30897647 0.3088024  0.3084462
 0.30807728 0.30784854 0.3076948  0.30751696 0.30723318 0.3067848
 0.3063597  0.30608642 0.30593646 0.30570146 0.30522078 0.3046795
 0.30422878 0.303912   0.30352968 0.30294067 0.3022206  0.30155468
 0.30106196 0.30066022 0.30016756 0.29938963 0.29825947 0.29684153
 0.29534563 0.29395694 0.2927461  0.29175082 0.29087925 0.2900116
 0.28905228 0.28802964 0.2870689  0.2863242  0.285754   0.2852069
 0.28459916 0.28393468 0.28327358 0.2826435  0.28204066 0.28140065
 0.2807625  0.28017825 0.27966914 0.27921554 0.27877665 0.27839944
 0.27810946 0.27784118 0.27762127 0.27739993 0.27711514 0.27666348
 0.27613258 0.2756589  0.27528256 0.2749388  0.27456465 0.27410758
 0.27364784 0.27320668 0.27282253 0.27249575 0.27217647 0.271897
 0.27162918 0.27142093 0.2712008  0.27093884 0.27063838 0.27026442
 0.26983938 0.2693888  0.26887265 0.26835814 0.2679631  0.26777068
 0.2676857  0.2675835  0.26744938 0.26726076 0.2671027  0.2670841
 0.2670956  0.267088   0.26699397 0.26684543 0.2666528  0.26644778
 0.26621455 0.26598087 0.26576737 0.26563814 0.26552063 0.26544055
 0.26529348 0.26506284 0.26482195 0.2646074  0.26445964 0.26429516
 0.26402447 0.26372263 0.26351026 0.26340243 0.26323855 0.26293507
 0.26257834 0.26224995 0.26203427 0.2617896  0.26145172 0.26100424
 0.26058587 0.26031098 0.26005557 0.25950623 0.25836185 0.25654757
 0.25444004 0.25264645 0.25132015 0.25024104 0.24920243 0.24822879
 0.2472793  0.2463917  0.24540451 0.24424876 0.24306802 0.24208438
 0.24126355 0.24049681 0.23973005 0.2389799  0.23825417 0.23759805
 0.23700143 0.236359   0.23565571 0.23501046 0.2346313  0.23447068
 0.2343251  0.23402618 0.23359288 0.23317678 0.23285125 0.23254193
 0.2321321  0.23161972 0.23106715 0.23056398 0.230197   0.22989196
 0.229613   0.22921841 0.22874148 0.22830017 0.22792715 0.22771093
 0.22756669 0.22751871 0.22742954 0.2272704  0.2270226  0.22670871
 0.22639535 0.22610503 0.2259126  0.22579329 0.2256117  0.22529568
 0.22509958 0.2251944  0.22539337 0.22537994 0.22517261 0.22491254
 0.22498825 0.22521068 0.22528704 0.22512797 0.2248049  0.22458543
 0.22453573 0.22464415 0.22467868 0.22448224 0.22436067 0.2242341
 0.22419408 0.22409974 0.22382465 0.2235259  0.22339468 0.22345689
 0.22371167 0.22394986 0.22402212 0.22417615 0.22450311 0.22481675
 0.22504412 0.22518322 0.22536176 0.22565065 0.22616214 0.22667184
 0.2269331  0.22694951 0.22688343 0.22658308 0.22576421 0.22434366
 0.2225107  0.22083633 0.21962985 0.21872157 0.21779089 0.2168219
 0.2158558  0.21517423 0.21484157 0.21447283 0.2138241  0.21315733
 0.21287073 0.21281058 0.21263583 0.21205881 0.21140522 0.21088962
 0.21082044 0.21082838 0.21047606 0.20996906 0.20966864 0.20984775
 0.21032757 0.21040495 0.20990413 0.20914777 0.20859571 0.20819081
 0.2077624  0.20690258 0.20585956 0.20518981 0.20488088 0.20472467
 0.20415902 0.2034451  0.20306335 0.20311056 0.20307562 0.20268755
 0.2021725  0.20209493 0.20223236 0.20206761 0.20113511 0.20156138]
