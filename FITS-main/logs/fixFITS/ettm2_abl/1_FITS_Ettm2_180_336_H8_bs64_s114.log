Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_180_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_180_336_FITS_ETTm2_ftM_sl180_ll48_pl336_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34045
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=26, out_features=74, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1723904.0
params:  1998.0
Trainable parameters:  1998
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5171384
	speed: 0.0198s/iter; left time: 523.8203s
	iters: 200, epoch: 1 | loss: 0.3877326
	speed: 0.0133s/iter; left time: 349.6066s
Epoch: 1 cost time: 4.158601522445679
Epoch: 1, Steps: 265 | Train Loss: 0.5093619 Vali Loss: 0.2303292 Test Loss: 0.3136697
Validation loss decreased (inf --> 0.230329).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3902587
	speed: 0.0697s/iter; left time: 1820.6545s
	iters: 200, epoch: 2 | loss: 0.7035113
	speed: 0.0224s/iter; left time: 584.3350s
Epoch: 2 cost time: 5.375576972961426
Epoch: 2, Steps: 265 | Train Loss: 0.4432769 Vali Loss: 0.2170951 Test Loss: 0.2982775
Validation loss decreased (0.230329 --> 0.217095).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2989564
	speed: 0.0722s/iter; left time: 1869.0709s
	iters: 200, epoch: 3 | loss: 0.3214064
	speed: 0.0132s/iter; left time: 340.6644s
Epoch: 3 cost time: 3.9968650341033936
Epoch: 3, Steps: 265 | Train Loss: 0.4327599 Vali Loss: 0.2129712 Test Loss: 0.2937126
Validation loss decreased (0.217095 --> 0.212971).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.5954744
	speed: 0.0667s/iter; left time: 1707.6771s
	iters: 200, epoch: 4 | loss: 0.5527815
	speed: 0.0132s/iter; left time: 337.5930s
Epoch: 4 cost time: 3.9707417488098145
Epoch: 4, Steps: 265 | Train Loss: 0.4279530 Vali Loss: 0.2110383 Test Loss: 0.2914509
Validation loss decreased (0.212971 --> 0.211038).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4102142
	speed: 0.0667s/iter; left time: 1690.8673s
	iters: 200, epoch: 5 | loss: 0.5166464
	speed: 0.0139s/iter; left time: 350.3995s
Epoch: 5 cost time: 4.063276529312134
Epoch: 5, Steps: 265 | Train Loss: 0.4252380 Vali Loss: 0.2099071 Test Loss: 0.2898894
Validation loss decreased (0.211038 --> 0.209907).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3427324
	speed: 0.0687s/iter; left time: 1722.1787s
	iters: 200, epoch: 6 | loss: 0.3527917
	speed: 0.0134s/iter; left time: 333.7318s
Epoch: 6 cost time: 4.0525147914886475
Epoch: 6, Steps: 265 | Train Loss: 0.4232726 Vali Loss: 0.2094508 Test Loss: 0.2889357
Validation loss decreased (0.209907 --> 0.209451).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.5340253
	speed: 0.0714s/iter; left time: 1771.6493s
	iters: 200, epoch: 7 | loss: 0.2567332
	speed: 0.0150s/iter; left time: 369.6125s
Epoch: 7 cost time: 4.647662401199341
Epoch: 7, Steps: 265 | Train Loss: 0.4223650 Vali Loss: 0.2088022 Test Loss: 0.2881916
Validation loss decreased (0.209451 --> 0.208802).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3542395
	speed: 0.0697s/iter; left time: 1709.9635s
	iters: 200, epoch: 8 | loss: 0.3076227
	speed: 0.0136s/iter; left time: 331.8080s
Epoch: 8 cost time: 4.136979103088379
Epoch: 8, Steps: 265 | Train Loss: 0.4212292 Vali Loss: 0.2084512 Test Loss: 0.2876214
Validation loss decreased (0.208802 --> 0.208451).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3611381
	speed: 0.0685s/iter; left time: 1664.4409s
	iters: 200, epoch: 9 | loss: 0.3157721
	speed: 0.0135s/iter; left time: 327.1729s
Epoch: 9 cost time: 4.059110641479492
Epoch: 9, Steps: 265 | Train Loss: 0.4203100 Vali Loss: 0.2081759 Test Loss: 0.2872683
Validation loss decreased (0.208451 --> 0.208176).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3514595
	speed: 0.0685s/iter; left time: 1645.2438s
	iters: 200, epoch: 10 | loss: 0.4100765
	speed: 0.0132s/iter; left time: 315.1668s
Epoch: 10 cost time: 3.9014902114868164
Epoch: 10, Steps: 265 | Train Loss: 0.4200244 Vali Loss: 0.2080916 Test Loss: 0.2869411
Validation loss decreased (0.208176 --> 0.208092).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3878213
	speed: 0.0681s/iter; left time: 1618.5243s
	iters: 200, epoch: 11 | loss: 0.4214498
	speed: 0.0139s/iter; left time: 328.3765s
Epoch: 11 cost time: 4.046840667724609
Epoch: 11, Steps: 265 | Train Loss: 0.4194352 Vali Loss: 0.2080303 Test Loss: 0.2866198
Validation loss decreased (0.208092 --> 0.208030).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.5497032
	speed: 0.0693s/iter; left time: 1628.0368s
	iters: 200, epoch: 12 | loss: 0.4028781
	speed: 0.0128s/iter; left time: 299.5838s
Epoch: 12 cost time: 4.012065887451172
Epoch: 12, Steps: 265 | Train Loss: 0.4191405 Vali Loss: 0.2078017 Test Loss: 0.2863488
Validation loss decreased (0.208030 --> 0.207802).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4510028
	speed: 0.0667s/iter; left time: 1549.1421s
	iters: 200, epoch: 13 | loss: 0.3071081
	speed: 0.0132s/iter; left time: 304.3490s
Epoch: 13 cost time: 3.9405577182769775
Epoch: 13, Steps: 265 | Train Loss: 0.4186483 Vali Loss: 0.2077613 Test Loss: 0.2861176
Validation loss decreased (0.207802 --> 0.207761).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4184525
	speed: 0.0721s/iter; left time: 1654.5442s
	iters: 200, epoch: 14 | loss: 0.3901223
	speed: 0.0144s/iter; left time: 328.9946s
Epoch: 14 cost time: 4.566541433334351
Epoch: 14, Steps: 265 | Train Loss: 0.4186221 Vali Loss: 0.2076460 Test Loss: 0.2860024
Validation loss decreased (0.207761 --> 0.207646).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4792789
	speed: 0.0713s/iter; left time: 1617.6312s
	iters: 200, epoch: 15 | loss: 0.4173784
	speed: 0.0133s/iter; left time: 300.1027s
Epoch: 15 cost time: 4.181215763092041
Epoch: 15, Steps: 265 | Train Loss: 0.4186936 Vali Loss: 0.2076466 Test Loss: 0.2858762
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.5005575
	speed: 0.0677s/iter; left time: 1517.5661s
	iters: 200, epoch: 16 | loss: 0.3426574
	speed: 0.0132s/iter; left time: 294.9144s
Epoch: 16 cost time: 3.9059083461761475
Epoch: 16, Steps: 265 | Train Loss: 0.4184680 Vali Loss: 0.2077161 Test Loss: 0.2857611
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2919543
	speed: 0.0661s/iter; left time: 1465.6425s
	iters: 200, epoch: 17 | loss: 0.2655241
	speed: 0.0147s/iter; left time: 324.6463s
Epoch: 17 cost time: 4.217071294784546
Epoch: 17, Steps: 265 | Train Loss: 0.4183111 Vali Loss: 0.2074672 Test Loss: 0.2856812
Validation loss decreased (0.207646 --> 0.207467).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4472433
	speed: 0.0685s/iter; left time: 1499.9027s
	iters: 200, epoch: 18 | loss: 0.6130534
	speed: 0.0131s/iter; left time: 284.7948s
Epoch: 18 cost time: 3.9545488357543945
Epoch: 18, Steps: 265 | Train Loss: 0.4181297 Vali Loss: 0.2074720 Test Loss: 0.2856323
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3600853
	speed: 0.0684s/iter; left time: 1479.7569s
	iters: 200, epoch: 19 | loss: 0.2866651
	speed: 0.0136s/iter; left time: 292.5824s
Epoch: 19 cost time: 4.172122955322266
Epoch: 19, Steps: 265 | Train Loss: 0.4175244 Vali Loss: 0.2075043 Test Loss: 0.2855127
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3965898
	speed: 0.0720s/iter; left time: 1537.4508s
	iters: 200, epoch: 20 | loss: 0.4627977
	speed: 0.0144s/iter; left time: 305.6593s
Epoch: 20 cost time: 4.4532790184021
Epoch: 20, Steps: 265 | Train Loss: 0.4169187 Vali Loss: 0.2074140 Test Loss: 0.2854533
Validation loss decreased (0.207467 --> 0.207414).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4145012
	speed: 0.0679s/iter; left time: 1431.7294s
	iters: 200, epoch: 21 | loss: 0.2819568
	speed: 0.0130s/iter; left time: 273.1265s
Epoch: 21 cost time: 3.9085633754730225
Epoch: 21, Steps: 265 | Train Loss: 0.4178825 Vali Loss: 0.2074198 Test Loss: 0.2853754
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.5406098
	speed: 0.0712s/iter; left time: 1483.0705s
	iters: 200, epoch: 22 | loss: 0.3410630
	speed: 0.0140s/iter; left time: 291.0686s
Epoch: 22 cost time: 4.404973983764648
Epoch: 22, Steps: 265 | Train Loss: 0.4172347 Vali Loss: 0.2074555 Test Loss: 0.2853075
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.5195016
	speed: 0.0714s/iter; left time: 1468.5263s
	iters: 200, epoch: 23 | loss: 0.5600983
	speed: 0.0145s/iter; left time: 297.2151s
Epoch: 23 cost time: 4.375373840332031
Epoch: 23, Steps: 265 | Train Loss: 0.4178533 Vali Loss: 0.2073250 Test Loss: 0.2852862
Validation loss decreased (0.207414 --> 0.207325).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4370160
	speed: 0.0679s/iter; left time: 1379.7702s
	iters: 200, epoch: 24 | loss: 0.4194591
	speed: 0.0130s/iter; left time: 262.4399s
Epoch: 24 cost time: 3.9586305618286133
Epoch: 24, Steps: 265 | Train Loss: 0.4170805 Vali Loss: 0.2072540 Test Loss: 0.2852589
Validation loss decreased (0.207325 --> 0.207254).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3679479
	speed: 0.0692s/iter; left time: 1386.4179s
	iters: 200, epoch: 25 | loss: 0.3069424
	speed: 0.0182s/iter; left time: 363.1566s
Epoch: 25 cost time: 5.092693090438843
Epoch: 25, Steps: 265 | Train Loss: 0.4173358 Vali Loss: 0.2073303 Test Loss: 0.2852204
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.5442666
	speed: 0.0752s/iter; left time: 1487.0032s
	iters: 200, epoch: 26 | loss: 0.3290370
	speed: 0.0134s/iter; left time: 263.1217s
Epoch: 26 cost time: 4.1819891929626465
Epoch: 26, Steps: 265 | Train Loss: 0.4170193 Vali Loss: 0.2073534 Test Loss: 0.2851961
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2547310
	speed: 0.0711s/iter; left time: 1387.1759s
	iters: 200, epoch: 27 | loss: 0.4911282
	speed: 0.0132s/iter; left time: 255.3252s
Epoch: 27 cost time: 4.034412622451782
Epoch: 27, Steps: 265 | Train Loss: 0.4172428 Vali Loss: 0.2074827 Test Loss: 0.2851798
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4065769
	speed: 0.0667s/iter; left time: 1284.4546s
	iters: 200, epoch: 28 | loss: 0.2579980
	speed: 0.0137s/iter; left time: 262.3993s
Epoch: 28 cost time: 4.0620481967926025
Epoch: 28, Steps: 265 | Train Loss: 0.4174601 Vali Loss: 0.2073654 Test Loss: 0.2851638
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4416471
	speed: 0.0680s/iter; left time: 1289.9718s
	iters: 200, epoch: 29 | loss: 0.2685081
	speed: 0.0196s/iter; left time: 370.1269s
Epoch: 29 cost time: 4.724023342132568
Epoch: 29, Steps: 265 | Train Loss: 0.4169398 Vali Loss: 0.2073975 Test Loss: 0.2851516
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4113689
	speed: 0.0700s/iter; left time: 1310.3648s
	iters: 200, epoch: 30 | loss: 0.3994496
	speed: 0.0140s/iter; left time: 260.2249s
Epoch: 30 cost time: 4.256403684616089
Epoch: 30, Steps: 265 | Train Loss: 0.4172146 Vali Loss: 0.2073621 Test Loss: 0.2850989
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.5039077
	speed: 0.0677s/iter; left time: 1248.9996s
	iters: 200, epoch: 31 | loss: 0.3218085
	speed: 0.0131s/iter; left time: 240.6473s
Epoch: 31 cost time: 3.9895095825195312
Epoch: 31, Steps: 265 | Train Loss: 0.4167962 Vali Loss: 0.2072312 Test Loss: 0.2850978
Validation loss decreased (0.207254 --> 0.207231).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3019212
	speed: 0.0668s/iter; left time: 1215.6039s
	iters: 200, epoch: 32 | loss: 0.3425247
	speed: 0.0130s/iter; left time: 235.2144s
Epoch: 32 cost time: 3.978299856185913
Epoch: 32, Steps: 265 | Train Loss: 0.4175073 Vali Loss: 0.2073508 Test Loss: 0.2850731
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.5731649
	speed: 0.0660s/iter; left time: 1182.5838s
	iters: 200, epoch: 33 | loss: 0.4347852
	speed: 0.0127s/iter; left time: 226.3070s
Epoch: 33 cost time: 3.893037796020508
Epoch: 33, Steps: 265 | Train Loss: 0.4166167 Vali Loss: 0.2072820 Test Loss: 0.2850539
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.5217326
	speed: 0.0681s/iter; left time: 1203.1627s
	iters: 200, epoch: 34 | loss: 0.3668593
	speed: 0.0133s/iter; left time: 234.2576s
Epoch: 34 cost time: 3.9651527404785156
Epoch: 34, Steps: 265 | Train Loss: 0.4164232 Vali Loss: 0.2073275 Test Loss: 0.2850518
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3622289
	speed: 0.0686s/iter; left time: 1193.2292s
	iters: 200, epoch: 35 | loss: 0.4006847
	speed: 0.0134s/iter; left time: 231.1414s
Epoch: 35 cost time: 4.081132650375366
Epoch: 35, Steps: 265 | Train Loss: 0.4156258 Vali Loss: 0.2074434 Test Loss: 0.2850319
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4786456
	speed: 0.0672s/iter; left time: 1150.7115s
	iters: 200, epoch: 36 | loss: 0.2979778
	speed: 0.0130s/iter; left time: 221.8765s
Epoch: 36 cost time: 4.010768175125122
Epoch: 36, Steps: 265 | Train Loss: 0.4159673 Vali Loss: 0.2073076 Test Loss: 0.2850086
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3346380
	speed: 0.0708s/iter; left time: 1194.0258s
	iters: 200, epoch: 37 | loss: 0.4324471
	speed: 0.0148s/iter; left time: 247.2824s
Epoch: 37 cost time: 4.466900587081909
Epoch: 37, Steps: 265 | Train Loss: 0.4166266 Vali Loss: 0.2073912 Test Loss: 0.2850024
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4463240
	speed: 0.0705s/iter; left time: 1170.0685s
	iters: 200, epoch: 38 | loss: 0.4799170
	speed: 0.0133s/iter; left time: 218.6533s
Epoch: 38 cost time: 4.215144872665405
Epoch: 38, Steps: 265 | Train Loss: 0.4170903 Vali Loss: 0.2073693 Test Loss: 0.2850000
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4336316
	speed: 0.0676s/iter; left time: 1104.3379s
	iters: 200, epoch: 39 | loss: 0.3226962
	speed: 0.0136s/iter; left time: 221.1407s
Epoch: 39 cost time: 4.096936225891113
Epoch: 39, Steps: 265 | Train Loss: 0.4169966 Vali Loss: 0.2072375 Test Loss: 0.2849916
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.3910724
	speed: 0.0689s/iter; left time: 1106.6883s
	iters: 200, epoch: 40 | loss: 0.2882740
	speed: 0.0135s/iter; left time: 215.8505s
Epoch: 40 cost time: 4.092788219451904
Epoch: 40, Steps: 265 | Train Loss: 0.4158573 Vali Loss: 0.2072369 Test Loss: 0.2849842
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.4848051
	speed: 0.0677s/iter; left time: 1069.4819s
	iters: 200, epoch: 41 | loss: 0.4251729
	speed: 0.0147s/iter; left time: 231.1905s
Epoch: 41 cost time: 4.635512113571167
Epoch: 41, Steps: 265 | Train Loss: 0.4171113 Vali Loss: 0.2071996 Test Loss: 0.2849692
Validation loss decreased (0.207231 --> 0.207200).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3700240
	speed: 0.0754s/iter; left time: 1171.0373s
	iters: 200, epoch: 42 | loss: 0.6411803
	speed: 0.0149s/iter; left time: 230.5930s
Epoch: 42 cost time: 4.496580600738525
Epoch: 42, Steps: 265 | Train Loss: 0.4160684 Vali Loss: 0.2073893 Test Loss: 0.2849592
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3242863
	speed: 0.0711s/iter; left time: 1085.2309s
	iters: 200, epoch: 43 | loss: 0.3105266
	speed: 0.0151s/iter; left time: 228.7989s
Epoch: 43 cost time: 4.489551305770874
Epoch: 43, Steps: 265 | Train Loss: 0.4168473 Vali Loss: 0.2072742 Test Loss: 0.2849579
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.4497237
	speed: 0.0706s/iter; left time: 1059.8156s
	iters: 200, epoch: 44 | loss: 0.3969588
	speed: 0.0147s/iter; left time: 219.7441s
Epoch: 44 cost time: 4.365482330322266
Epoch: 44, Steps: 265 | Train Loss: 0.4169932 Vali Loss: 0.2072565 Test Loss: 0.2849607
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.5467808
	speed: 0.0682s/iter; left time: 1005.1205s
	iters: 200, epoch: 45 | loss: 0.3876131
	speed: 0.0128s/iter; left time: 186.9215s
Epoch: 45 cost time: 3.891292095184326
Epoch: 45, Steps: 265 | Train Loss: 0.4162542 Vali Loss: 0.2072591 Test Loss: 0.2849496
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.4450209
	speed: 0.0666s/iter; left time: 963.9446s
	iters: 200, epoch: 46 | loss: 0.3655846
	speed: 0.0198s/iter; left time: 284.3172s
Epoch: 46 cost time: 6.539307117462158
Epoch: 46, Steps: 265 | Train Loss: 0.4167038 Vali Loss: 0.2075074 Test Loss: 0.2849471
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.3896990
	speed: 0.0870s/iter; left time: 1236.9519s
	iters: 200, epoch: 47 | loss: 0.3032017
	speed: 0.0132s/iter; left time: 186.3468s
Epoch: 47 cost time: 4.016770362854004
Epoch: 47, Steps: 265 | Train Loss: 0.4158157 Vali Loss: 0.2072349 Test Loss: 0.2849461
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.3549253
	speed: 0.0686s/iter; left time: 956.0190s
	iters: 200, epoch: 48 | loss: 0.5640613
	speed: 0.0134s/iter; left time: 185.9786s
Epoch: 48 cost time: 4.112852573394775
Epoch: 48, Steps: 265 | Train Loss: 0.4163681 Vali Loss: 0.2073725 Test Loss: 0.2849405
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.4865049
	speed: 0.0714s/iter; left time: 977.1361s
	iters: 200, epoch: 49 | loss: 0.3635122
	speed: 0.0137s/iter; left time: 185.6569s
Epoch: 49 cost time: 4.058932304382324
Epoch: 49, Steps: 265 | Train Loss: 0.4167051 Vali Loss: 0.2073767 Test Loss: 0.2849254
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.5693477
	speed: 0.0692s/iter; left time: 928.0565s
	iters: 200, epoch: 50 | loss: 0.3822574
	speed: 0.0132s/iter; left time: 175.5155s
Epoch: 50 cost time: 4.031463623046875
Epoch: 50, Steps: 265 | Train Loss: 0.4170159 Vali Loss: 0.2075473 Test Loss: 0.2849243
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.5997901
	speed: 0.0684s/iter; left time: 898.8848s
	iters: 200, epoch: 51 | loss: 0.5030595
	speed: 0.0133s/iter; left time: 174.1615s
Epoch: 51 cost time: 4.058528423309326
Epoch: 51, Steps: 265 | Train Loss: 0.4165396 Vali Loss: 0.2071146 Test Loss: 0.2849266
Validation loss decreased (0.207200 --> 0.207115).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.3098691
	speed: 0.0685s/iter; left time: 883.0919s
	iters: 200, epoch: 52 | loss: 0.4212623
	speed: 0.0135s/iter; left time: 172.9667s
Epoch: 52 cost time: 4.1533098220825195
Epoch: 52, Steps: 265 | Train Loss: 0.4161748 Vali Loss: 0.2073984 Test Loss: 0.2849191
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.3172360
	speed: 0.0668s/iter; left time: 843.6120s
	iters: 200, epoch: 53 | loss: 0.4580862
	speed: 0.0135s/iter; left time: 169.1940s
Epoch: 53 cost time: 3.9469900131225586
Epoch: 53, Steps: 265 | Train Loss: 0.4168232 Vali Loss: 0.2074100 Test Loss: 0.2849129
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.5271016
	speed: 0.0704s/iter; left time: 869.6936s
	iters: 200, epoch: 54 | loss: 0.3255178
	speed: 0.0148s/iter; left time: 180.9679s
Epoch: 54 cost time: 4.5327208042144775
Epoch: 54, Steps: 265 | Train Loss: 0.4159612 Vali Loss: 0.2072566 Test Loss: 0.2849113
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.5073361
	speed: 0.0742s/iter; left time: 897.7231s
	iters: 200, epoch: 55 | loss: 0.4292517
	speed: 0.0136s/iter; left time: 163.2957s
Epoch: 55 cost time: 4.366943120956421
Epoch: 55, Steps: 265 | Train Loss: 0.4166703 Vali Loss: 0.2074311 Test Loss: 0.2849170
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2479454
	speed: 0.0680s/iter; left time: 804.3433s
	iters: 200, epoch: 56 | loss: 0.3608078
	speed: 0.0135s/iter; left time: 158.6439s
Epoch: 56 cost time: 3.9490842819213867
Epoch: 56, Steps: 265 | Train Loss: 0.4170915 Vali Loss: 0.2073896 Test Loss: 0.2849133
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.5009336
	speed: 0.0662s/iter; left time: 765.6841s
	iters: 200, epoch: 57 | loss: 0.4595478
	speed: 0.0129s/iter; left time: 147.3502s
Epoch: 57 cost time: 3.8580663204193115
Epoch: 57, Steps: 265 | Train Loss: 0.4164446 Vali Loss: 0.2073234 Test Loss: 0.2849104
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.3580312
	speed: 0.0676s/iter; left time: 763.4909s
	iters: 200, epoch: 58 | loss: 0.3288819
	speed: 0.0128s/iter; left time: 143.4487s
Epoch: 58 cost time: 3.9544525146484375
Epoch: 58, Steps: 265 | Train Loss: 0.4164537 Vali Loss: 0.2073925 Test Loss: 0.2849106
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.4046296
	speed: 0.0675s/iter; left time: 744.2468s
	iters: 200, epoch: 59 | loss: 0.3891711
	speed: 0.0130s/iter; left time: 141.7028s
Epoch: 59 cost time: 4.01574182510376
Epoch: 59, Steps: 265 | Train Loss: 0.4158711 Vali Loss: 0.2072840 Test Loss: 0.2849070
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.3872407
	speed: 0.0714s/iter; left time: 768.9318s
	iters: 200, epoch: 60 | loss: 0.2998914
	speed: 0.0149s/iter; left time: 159.0875s
Epoch: 60 cost time: 4.576811075210571
Epoch: 60, Steps: 265 | Train Loss: 0.4166983 Vali Loss: 0.2072084 Test Loss: 0.2849037
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.3635214
	speed: 0.0687s/iter; left time: 721.7206s
	iters: 200, epoch: 61 | loss: 0.6170143
	speed: 0.0137s/iter; left time: 142.0641s
Epoch: 61 cost time: 4.076598405838013
Epoch: 61, Steps: 265 | Train Loss: 0.4160782 Vali Loss: 0.2071465 Test Loss: 0.2848998
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.4443442
	speed: 0.0703s/iter; left time: 719.7341s
	iters: 200, epoch: 62 | loss: 0.2932694
	speed: 0.0137s/iter; left time: 138.6932s
Epoch: 62 cost time: 4.296048879623413
Epoch: 62, Steps: 265 | Train Loss: 0.4168832 Vali Loss: 0.2072595 Test Loss: 0.2848969
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.4083581
	speed: 0.0678s/iter; left time: 675.7560s
	iters: 200, epoch: 63 | loss: 0.3633182
	speed: 0.0131s/iter; left time: 128.9153s
Epoch: 63 cost time: 4.058963298797607
Epoch: 63, Steps: 265 | Train Loss: 0.4166568 Vali Loss: 0.2072710 Test Loss: 0.2848959
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.2962845
	speed: 0.0678s/iter; left time: 658.4686s
	iters: 200, epoch: 64 | loss: 0.3285301
	speed: 0.0224s/iter; left time: 215.1603s
Epoch: 64 cost time: 6.902841091156006
Epoch: 64, Steps: 265 | Train Loss: 0.4163441 Vali Loss: 0.2072130 Test Loss: 0.2848910
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.5093008
	speed: 0.0865s/iter; left time: 816.4842s
	iters: 200, epoch: 65 | loss: 0.3963690
	speed: 0.0134s/iter; left time: 125.2018s
Epoch: 65 cost time: 3.9865829944610596
Epoch: 65, Steps: 265 | Train Loss: 0.4166464 Vali Loss: 0.2074139 Test Loss: 0.2848890
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.4064569
	speed: 0.0671s/iter; left time: 615.8928s
	iters: 200, epoch: 66 | loss: 0.4682608
	speed: 0.0128s/iter; left time: 116.1760s
Epoch: 66 cost time: 3.9233903884887695
Epoch: 66, Steps: 265 | Train Loss: 0.4164963 Vali Loss: 0.2072996 Test Loss: 0.2848903
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.4401589
	speed: 0.0667s/iter; left time: 594.5580s
	iters: 200, epoch: 67 | loss: 0.3249549
	speed: 0.0134s/iter; left time: 118.1479s
Epoch: 67 cost time: 4.006328582763672
Epoch: 67, Steps: 265 | Train Loss: 0.4170054 Vali Loss: 0.2073470 Test Loss: 0.2848888
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.4208012
	speed: 0.0684s/iter; left time: 591.4511s
	iters: 200, epoch: 68 | loss: 0.2800683
	speed: 0.0137s/iter; left time: 117.1885s
Epoch: 68 cost time: 4.104547500610352
Epoch: 68, Steps: 265 | Train Loss: 0.4161612 Vali Loss: 0.2072378 Test Loss: 0.2848869
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.3363490
	speed: 0.0683s/iter; left time: 572.6027s
	iters: 200, epoch: 69 | loss: 0.3895180
	speed: 0.0131s/iter; left time: 108.0911s
Epoch: 69 cost time: 4.364691972732544
Epoch: 69, Steps: 265 | Train Loss: 0.4161035 Vali Loss: 0.2073743 Test Loss: 0.2848851
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.4305986
	speed: 0.0713s/iter; left time: 578.2896s
	iters: 200, epoch: 70 | loss: 0.3305244
	speed: 0.0147s/iter; left time: 118.2187s
Epoch: 70 cost time: 4.1803297996521
Epoch: 70, Steps: 265 | Train Loss: 0.4168990 Vali Loss: 0.2072176 Test Loss: 0.2848844
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.2083570
	speed: 0.0669s/iter; left time: 525.3197s
	iters: 200, epoch: 71 | loss: 0.5988850
	speed: 0.0135s/iter; left time: 104.3039s
Epoch: 71 cost time: 4.043557643890381
Epoch: 71, Steps: 265 | Train Loss: 0.4166630 Vali Loss: 0.2072588 Test Loss: 0.2848850
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_180_336_FITS_ETTm2_ftM_sl180_ll48_pl336_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.2861858606338501, mae:0.33172932267189026, rse:0.43210047483444214, corr:[0.5591952  0.5616868  0.55777806 0.55396175 0.5527983  0.5531829
 0.5533361  0.5522589  0.5504923  0.54915655 0.54878986 0.54911613
 0.5493408  0.54887766 0.5478765  0.54681295 0.54608864 0.5457461
 0.5454807  0.5449694  0.5441392  0.5431935  0.54244107 0.5420882
 0.5420022  0.54187524 0.5414805  0.5407495  0.539844   0.5390209
 0.5384721  0.53818905 0.53795326 0.5375847  0.53699124 0.53629786
 0.53559774 0.53500617 0.534462   0.53389424 0.5333058  0.5327368
 0.5322593  0.53189313 0.5315641  0.5311917  0.53065866 0.5299099
 0.5289786  0.5279978  0.52712196 0.5264825  0.52599293 0.52550954
 0.5249879  0.5244648  0.52393025 0.52350163 0.5231846  0.52296203
 0.5227195  0.5224879  0.52227426 0.52202296 0.5217879  0.52162004
 0.5214899  0.5213795  0.52126014 0.5211556  0.52102226 0.52087754
 0.5207409  0.52055734 0.5203653  0.5201176  0.5198335  0.5194858
 0.5191042  0.51869404 0.5182507  0.5177899  0.5173696  0.5169852
 0.51662624 0.51624334 0.5158029  0.51536506 0.51495993 0.5145988
 0.5142899  0.5139648  0.51348394 0.5127048  0.5115398  0.5099728
 0.5081344  0.50634974 0.50471467 0.50321317 0.5017995  0.50046396
 0.49918482 0.4979409  0.4966986  0.49547186 0.49430048 0.49321222
 0.4921826  0.49106523 0.48999295 0.4889511  0.48796955 0.4870128
 0.48599356 0.4849621  0.4839443  0.48291582 0.48189044 0.4808255
 0.4798056  0.4789038  0.47812164 0.4773675  0.476547   0.47561258
 0.4745893  0.473558   0.47259936 0.47173285 0.47094598 0.47015223
 0.46933714 0.46847713 0.46773368 0.46717322 0.46671835 0.46632344
 0.46586493 0.4652832  0.46459308 0.4638799  0.4632294  0.46258658
 0.4618691  0.46100903 0.46000406 0.4590182  0.4582333  0.45765123
 0.4572577  0.4570283  0.45671588 0.45622763 0.45559382 0.45493007
 0.45438153 0.45403567 0.45377    0.45350572 0.45318684 0.45280132
 0.45247433 0.4522039  0.45216    0.45226872 0.45239052 0.4524613
 0.4524395  0.45241332 0.4524374  0.45253992 0.45271185 0.4527869
 0.45274317 0.45255515 0.45231566 0.45209837 0.45196855 0.45193338
 0.4518467  0.45160913 0.4512921  0.45095146 0.4507111  0.45054835
 0.45042747 0.45025778 0.44988096 0.44915825 0.4480212  0.44654533
 0.44494343 0.4434799  0.44213867 0.44085234 0.43963462 0.43842196
 0.43721092 0.43605608 0.43499225 0.43412662 0.43337077 0.43269688
 0.43200725 0.4312821  0.43052635 0.4298148  0.42918888 0.4285961
 0.42796257 0.4272703  0.42654335 0.42582098 0.42514586 0.42445895
 0.42375627 0.4229227  0.42208034 0.42121947 0.42028713 0.41934124
 0.41837677 0.41748145 0.4167806  0.41611907 0.41548514 0.41480458
 0.4139676  0.41300914 0.41199344 0.41111776 0.41044796 0.41005358
 0.4097857  0.4095348  0.40927708 0.40888545 0.40847158 0.40804663
 0.4076172  0.40713814 0.40660983 0.40615723 0.40580168 0.40556252
 0.4055154  0.4056653  0.40597048 0.40626466 0.406489   0.4065981
 0.40657905 0.4066553  0.4068592  0.40710315 0.4072634  0.40730345
 0.40721065 0.40700713 0.40682822 0.4068529  0.4070424  0.4072227
 0.40728518 0.4072049  0.4070716  0.40698454 0.4070617  0.40726757
 0.4073638  0.40726623 0.40691838 0.40654314 0.40632164 0.4063483
 0.4065349  0.40668604 0.4067167  0.4065908  0.40629447 0.40611002
 0.40612674 0.40622547 0.4062424  0.40600005 0.4053495  0.40426758
 0.40293884 0.40182224 0.40092325 0.40026727 0.39970008 0.39910427
 0.39854273 0.39792824 0.3972999  0.3966788  0.39619273 0.39575005
 0.39527762 0.3945951  0.39387134 0.3931808  0.39246374 0.39169425
 0.3909392  0.39019543 0.38943753 0.38868174 0.38788635 0.38703334
 0.38604835 0.3850858  0.38420662 0.3835505  0.38293272 0.38216093
 0.38104686 0.3796844  0.37838188 0.37747976 0.3770887  0.3768875
 0.37633672 0.37509844 0.3735023  0.37224278 0.3719942  0.3727772
 0.37366644 0.3734536  0.3720949  0.37089163 0.37253204 0.3781155 ]
