Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=34, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_180_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_180_336_FITS_ETTm2_ftM_sl180_ll48_pl336_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34045
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=34, out_features=97, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2955008.0
params:  3395.0
Trainable parameters:  3395
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3350635
	speed: 0.0262s/iter; left time: 690.4822s
	iters: 200, epoch: 1 | loss: 0.3608501
	speed: 0.0287s/iter; left time: 755.3509s
Epoch: 1 cost time: 6.742177724838257
Epoch: 1, Steps: 265 | Train Loss: 0.3932917 Vali Loss: 0.2398633 Test Loss: 0.3247303
Validation loss decreased (inf --> 0.239863).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3509989
	speed: 0.1906s/iter; left time: 4982.0056s
	iters: 200, epoch: 2 | loss: 0.3788162
	speed: 0.0253s/iter; left time: 659.7613s
Epoch: 2 cost time: 11.51039457321167
Epoch: 2, Steps: 265 | Train Loss: 0.3114926 Vali Loss: 0.2227698 Test Loss: 0.3037320
Validation loss decreased (0.239863 --> 0.222770).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2871585
	speed: 0.1560s/iter; left time: 4035.1372s
	iters: 200, epoch: 3 | loss: 0.2843153
	speed: 0.0387s/iter; left time: 996.1768s
Epoch: 3 cost time: 11.091777324676514
Epoch: 3, Steps: 265 | Train Loss: 0.2931842 Vali Loss: 0.2167456 Test Loss: 0.2966930
Validation loss decreased (0.222770 --> 0.216746).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2484015
	speed: 0.1689s/iter; left time: 4324.3140s
	iters: 200, epoch: 4 | loss: 0.2317320
	speed: 0.0197s/iter; left time: 501.8024s
Epoch: 4 cost time: 6.333644390106201
Epoch: 4, Steps: 265 | Train Loss: 0.2863373 Vali Loss: 0.2130966 Test Loss: 0.2929400
Validation loss decreased (0.216746 --> 0.213097).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2653976
	speed: 0.1221s/iter; left time: 3093.7363s
	iters: 200, epoch: 5 | loss: 0.2947557
	speed: 0.0298s/iter; left time: 752.3522s
Epoch: 5 cost time: 8.140073776245117
Epoch: 5, Steps: 265 | Train Loss: 0.2827712 Vali Loss: 0.2113638 Test Loss: 0.2907369
Validation loss decreased (0.213097 --> 0.211364).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2579123
	speed: 0.1266s/iter; left time: 3174.3590s
	iters: 200, epoch: 6 | loss: 0.2988794
	speed: 0.0269s/iter; left time: 672.3975s
Epoch: 6 cost time: 6.587900161743164
Epoch: 6, Steps: 265 | Train Loss: 0.2805773 Vali Loss: 0.2103523 Test Loss: 0.2894806
Validation loss decreased (0.211364 --> 0.210352).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2794670
	speed: 0.1319s/iter; left time: 3273.1980s
	iters: 200, epoch: 7 | loss: 0.1397073
	speed: 0.0228s/iter; left time: 563.0486s
Epoch: 7 cost time: 6.459261894226074
Epoch: 7, Steps: 265 | Train Loss: 0.2793389 Vali Loss: 0.2096355 Test Loss: 0.2886803
Validation loss decreased (0.210352 --> 0.209636).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2940321
	speed: 0.1721s/iter; left time: 4223.3467s
	iters: 200, epoch: 8 | loss: 0.4580378
	speed: 0.0389s/iter; left time: 951.9598s
Epoch: 8 cost time: 11.985314846038818
Epoch: 8, Steps: 265 | Train Loss: 0.2783869 Vali Loss: 0.2092037 Test Loss: 0.2881293
Validation loss decreased (0.209636 --> 0.209204).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2625398
	speed: 0.1557s/iter; left time: 3780.5619s
	iters: 200, epoch: 9 | loss: 0.2114154
	speed: 0.0210s/iter; left time: 507.8926s
Epoch: 9 cost time: 7.836591720581055
Epoch: 9, Steps: 265 | Train Loss: 0.2780414 Vali Loss: 0.2087499 Test Loss: 0.2877007
Validation loss decreased (0.209204 --> 0.208750).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1647790
	speed: 0.1163s/iter; left time: 2792.1818s
	iters: 200, epoch: 10 | loss: 0.2937341
	speed: 0.0259s/iter; left time: 620.1855s
Epoch: 10 cost time: 6.443757057189941
Epoch: 10, Steps: 265 | Train Loss: 0.2773812 Vali Loss: 0.2085569 Test Loss: 0.2873773
Validation loss decreased (0.208750 --> 0.208557).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2426966
	speed: 0.1063s/iter; left time: 2523.6911s
	iters: 200, epoch: 11 | loss: 0.2678761
	speed: 0.0262s/iter; left time: 620.2870s
Epoch: 11 cost time: 7.945709466934204
Epoch: 11, Steps: 265 | Train Loss: 0.2769143 Vali Loss: 0.2083900 Test Loss: 0.2871691
Validation loss decreased (0.208557 --> 0.208390).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3483600
	speed: 0.1172s/iter; left time: 2751.4866s
	iters: 200, epoch: 12 | loss: 0.2039803
	speed: 0.0222s/iter; left time: 518.9757s
Epoch: 12 cost time: 6.947103261947632
Epoch: 12, Steps: 265 | Train Loss: 0.2765036 Vali Loss: 0.2083095 Test Loss: 0.2868899
Validation loss decreased (0.208390 --> 0.208310).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1808297
	speed: 0.1073s/iter; left time: 2492.5615s
	iters: 200, epoch: 13 | loss: 0.2526972
	speed: 0.0193s/iter; left time: 447.2673s
Epoch: 13 cost time: 7.081209421157837
Epoch: 13, Steps: 265 | Train Loss: 0.2768377 Vali Loss: 0.2081616 Test Loss: 0.2867396
Validation loss decreased (0.208310 --> 0.208162).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2588439
	speed: 0.1158s/iter; left time: 2657.2270s
	iters: 200, epoch: 14 | loss: 0.1919059
	speed: 0.0204s/iter; left time: 465.3472s
Epoch: 14 cost time: 5.645045042037964
Epoch: 14, Steps: 265 | Train Loss: 0.2764234 Vali Loss: 0.2081303 Test Loss: 0.2866189
Validation loss decreased (0.208162 --> 0.208130).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3339646
	speed: 0.1132s/iter; left time: 2568.0925s
	iters: 200, epoch: 15 | loss: 0.2132191
	speed: 0.0196s/iter; left time: 442.0569s
Epoch: 15 cost time: 5.525403738021851
Epoch: 15, Steps: 265 | Train Loss: 0.2767211 Vali Loss: 0.2079975 Test Loss: 0.2864941
Validation loss decreased (0.208130 --> 0.207997).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3345523
	speed: 0.1070s/iter; left time: 2399.1749s
	iters: 200, epoch: 16 | loss: 0.2427683
	speed: 0.0168s/iter; left time: 376.1627s
Epoch: 16 cost time: 5.6373631954193115
Epoch: 16, Steps: 265 | Train Loss: 0.2762949 Vali Loss: 0.2080993 Test Loss: 0.2864486
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2821644
	speed: 0.0922s/iter; left time: 2044.0967s
	iters: 200, epoch: 17 | loss: 0.2782636
	speed: 0.0182s/iter; left time: 402.3009s
Epoch: 17 cost time: 6.221476078033447
Epoch: 17, Steps: 265 | Train Loss: 0.2760388 Vali Loss: 0.2080250 Test Loss: 0.2863576
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3727658
	speed: 0.1296s/iter; left time: 2837.7923s
	iters: 200, epoch: 18 | loss: 0.3281523
	speed: 0.0190s/iter; left time: 414.5685s
Epoch: 18 cost time: 5.92893123626709
Epoch: 18, Steps: 265 | Train Loss: 0.2762578 Vali Loss: 0.2076938 Test Loss: 0.2861992
Validation loss decreased (0.207997 --> 0.207694).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2285134
	speed: 0.1287s/iter; left time: 2783.3195s
	iters: 200, epoch: 19 | loss: 0.3311714
	speed: 0.0289s/iter; left time: 622.3941s
Epoch: 19 cost time: 6.642720937728882
Epoch: 19, Steps: 265 | Train Loss: 0.2763882 Vali Loss: 0.2079099 Test Loss: 0.2861699
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2568570
	speed: 0.1240s/iter; left time: 2649.8007s
	iters: 200, epoch: 20 | loss: 0.3984153
	speed: 0.0187s/iter; left time: 398.6017s
Epoch: 20 cost time: 6.808571815490723
Epoch: 20, Steps: 265 | Train Loss: 0.2763179 Vali Loss: 0.2076584 Test Loss: 0.2860797
Validation loss decreased (0.207694 --> 0.207658).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2729875
	speed: 0.1195s/iter; left time: 2521.5283s
	iters: 200, epoch: 21 | loss: 0.3940729
	speed: 0.0196s/iter; left time: 411.4561s
Epoch: 21 cost time: 6.53690505027771
Epoch: 21, Steps: 265 | Train Loss: 0.2761431 Vali Loss: 0.2075532 Test Loss: 0.2861179
Validation loss decreased (0.207658 --> 0.207553).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3128140
	speed: 0.1113s/iter; left time: 2318.0993s
	iters: 200, epoch: 22 | loss: 0.3794768
	speed: 0.0206s/iter; left time: 428.0297s
Epoch: 22 cost time: 6.249669551849365
Epoch: 22, Steps: 265 | Train Loss: 0.2759378 Vali Loss: 0.2079433 Test Loss: 0.2860506
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2273162
	speed: 0.1241s/iter; left time: 2552.7115s
	iters: 200, epoch: 23 | loss: 0.2696327
	speed: 0.0379s/iter; left time: 774.8775s
Epoch: 23 cost time: 9.956960916519165
Epoch: 23, Steps: 265 | Train Loss: 0.2757605 Vali Loss: 0.2078558 Test Loss: 0.2860029
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1848534
	speed: 0.1226s/iter; left time: 2489.7594s
	iters: 200, epoch: 24 | loss: 0.2987223
	speed: 0.0213s/iter; left time: 429.4273s
Epoch: 24 cost time: 7.622006893157959
Epoch: 24, Steps: 265 | Train Loss: 0.2757807 Vali Loss: 0.2078162 Test Loss: 0.2859500
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2326175
	speed: 0.1226s/iter; left time: 2457.0995s
	iters: 200, epoch: 25 | loss: 0.3301396
	speed: 0.0298s/iter; left time: 594.1449s
Epoch: 25 cost time: 7.954887866973877
Epoch: 25, Steps: 265 | Train Loss: 0.2759561 Vali Loss: 0.2076735 Test Loss: 0.2859248
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2457289
	speed: 0.1320s/iter; left time: 2611.0060s
	iters: 200, epoch: 26 | loss: 0.1949537
	speed: 0.0199s/iter; left time: 390.6630s
Epoch: 26 cost time: 5.970904588699341
Epoch: 26, Steps: 265 | Train Loss: 0.2759769 Vali Loss: 0.2077444 Test Loss: 0.2859301
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2893497
	speed: 0.0979s/iter; left time: 1909.2197s
	iters: 200, epoch: 27 | loss: 0.3411711
	speed: 0.0193s/iter; left time: 373.7966s
Epoch: 27 cost time: 6.031917095184326
Epoch: 27, Steps: 265 | Train Loss: 0.2757577 Vali Loss: 0.2077514 Test Loss: 0.2858626
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3660881
	speed: 0.1034s/iter; left time: 1989.7826s
	iters: 200, epoch: 28 | loss: 0.1898881
	speed: 0.0386s/iter; left time: 739.4414s
Epoch: 28 cost time: 9.466777324676514
Epoch: 28, Steps: 265 | Train Loss: 0.2759422 Vali Loss: 0.2078501 Test Loss: 0.2859060
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2520356
	speed: 0.1293s/iter; left time: 2453.3467s
	iters: 200, epoch: 29 | loss: 0.2961182
	speed: 0.0191s/iter; left time: 360.2680s
Epoch: 29 cost time: 6.12968635559082
Epoch: 29, Steps: 265 | Train Loss: 0.2756630 Vali Loss: 0.2077022 Test Loss: 0.2858614
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2848352
	speed: 0.1294s/iter; left time: 2422.7550s
	iters: 200, epoch: 30 | loss: 0.2958341
	speed: 0.0246s/iter; left time: 457.1374s
Epoch: 30 cost time: 7.552511692047119
Epoch: 30, Steps: 265 | Train Loss: 0.2756477 Vali Loss: 0.2078039 Test Loss: 0.2858524
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2727949
	speed: 0.1265s/iter; left time: 2333.3380s
	iters: 200, epoch: 31 | loss: 0.3197827
	speed: 0.0311s/iter; left time: 570.4209s
Epoch: 31 cost time: 8.12619924545288
Epoch: 31, Steps: 265 | Train Loss: 0.2760856 Vali Loss: 0.2078215 Test Loss: 0.2858503
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2422534
	speed: 0.1016s/iter; left time: 1848.3910s
	iters: 200, epoch: 32 | loss: 0.3321904
	speed: 0.0192s/iter; left time: 347.0909s
Epoch: 32 cost time: 6.016588449478149
Epoch: 32, Steps: 265 | Train Loss: 0.2756319 Vali Loss: 0.2076511 Test Loss: 0.2858267
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3144365
	speed: 0.1274s/iter; left time: 2283.8056s
	iters: 200, epoch: 33 | loss: 0.3704835
	speed: 0.0205s/iter; left time: 364.9191s
Epoch: 33 cost time: 5.650300979614258
Epoch: 33, Steps: 265 | Train Loss: 0.2756244 Vali Loss: 0.2077444 Test Loss: 0.2858140
EarlyStopping counter: 12 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1934346
	speed: 0.0936s/iter; left time: 1651.7972s
	iters: 200, epoch: 34 | loss: 0.2629437
	speed: 0.0183s/iter; left time: 320.9432s
Epoch: 34 cost time: 6.432645559310913
Epoch: 34, Steps: 265 | Train Loss: 0.2758097 Vali Loss: 0.2076291 Test Loss: 0.2858053
EarlyStopping counter: 13 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2879827
	speed: 0.1094s/iter; left time: 1903.1103s
	iters: 200, epoch: 35 | loss: 0.3431100
	speed: 0.0221s/iter; left time: 382.5216s
Epoch: 35 cost time: 6.285783290863037
Epoch: 35, Steps: 265 | Train Loss: 0.2759745 Vali Loss: 0.2078079 Test Loss: 0.2858054
EarlyStopping counter: 14 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1835627
	speed: 0.1078s/iter; left time: 1846.3696s
	iters: 200, epoch: 36 | loss: 0.2999343
	speed: 0.0196s/iter; left time: 333.2913s
Epoch: 36 cost time: 5.979830265045166
Epoch: 36, Steps: 265 | Train Loss: 0.2755399 Vali Loss: 0.2076416 Test Loss: 0.2857875
EarlyStopping counter: 15 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3439801
	speed: 0.1232s/iter; left time: 2077.4889s
	iters: 200, epoch: 37 | loss: 0.2747453
	speed: 0.0250s/iter; left time: 418.9362s
Epoch: 37 cost time: 6.101120948791504
Epoch: 37, Steps: 265 | Train Loss: 0.2760369 Vali Loss: 0.2078745 Test Loss: 0.2857922
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1987510
	speed: 0.1126s/iter; left time: 1869.4185s
	iters: 200, epoch: 38 | loss: 0.2272621
	speed: 0.0390s/iter; left time: 643.7424s
Epoch: 38 cost time: 8.439833879470825
Epoch: 38, Steps: 265 | Train Loss: 0.2754162 Vali Loss: 0.2078057 Test Loss: 0.2857787
EarlyStopping counter: 17 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3299675
	speed: 0.1559s/iter; left time: 2546.0006s
	iters: 200, epoch: 39 | loss: 0.4084955
	speed: 0.0187s/iter; left time: 302.9317s
Epoch: 39 cost time: 6.061967849731445
Epoch: 39, Steps: 265 | Train Loss: 0.2759508 Vali Loss: 0.2077758 Test Loss: 0.2857713
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2668101
	speed: 0.1087s/iter; left time: 1745.9601s
	iters: 200, epoch: 40 | loss: 0.2305122
	speed: 0.0258s/iter; left time: 412.6426s
Epoch: 40 cost time: 6.336669921875
Epoch: 40, Steps: 265 | Train Loss: 0.2756552 Vali Loss: 0.2077579 Test Loss: 0.2857758
EarlyStopping counter: 19 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3286847
	speed: 0.1223s/iter; left time: 1932.2797s
	iters: 200, epoch: 41 | loss: 0.2564496
	speed: 0.0255s/iter; left time: 400.3518s
Epoch: 41 cost time: 7.815531969070435
Epoch: 41, Steps: 265 | Train Loss: 0.2756877 Vali Loss: 0.2077622 Test Loss: 0.2857519
EarlyStopping counter: 20 out of 20
Early stopping
train 34045
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=34, out_features=97, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2955008.0
params:  3395.0
Trainable parameters:  3395
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4513217
	speed: 0.0283s/iter; left time: 747.9843s
	iters: 200, epoch: 1 | loss: 0.5024903
	speed: 0.0284s/iter; left time: 747.9472s
Epoch: 1 cost time: 7.8816609382629395
Epoch: 1, Steps: 265 | Train Loss: 0.4181337 Vali Loss: 0.2075851 Test Loss: 0.2854458
Validation loss decreased (inf --> 0.207585).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4186379
	speed: 0.1371s/iter; left time: 3584.5366s
	iters: 200, epoch: 2 | loss: 0.2909384
	speed: 0.0477s/iter; left time: 1240.9845s
Epoch: 2 cost time: 10.57335376739502
Epoch: 2, Steps: 265 | Train Loss: 0.4168295 Vali Loss: 0.2072330 Test Loss: 0.2851657
Validation loss decreased (0.207585 --> 0.207233).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3503706
	speed: 0.1146s/iter; left time: 2965.8128s
	iters: 200, epoch: 3 | loss: 0.3926938
	speed: 0.0279s/iter; left time: 718.3884s
Epoch: 3 cost time: 7.352025270462036
Epoch: 3, Steps: 265 | Train Loss: 0.4169232 Vali Loss: 0.2071819 Test Loss: 0.2850827
Validation loss decreased (0.207233 --> 0.207182).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3598132
	speed: 0.1077s/iter; left time: 2758.4225s
	iters: 200, epoch: 4 | loss: 0.3505813
	speed: 0.0198s/iter; left time: 505.1907s
Epoch: 4 cost time: 5.631084442138672
Epoch: 4, Steps: 265 | Train Loss: 0.4164293 Vali Loss: 0.2070939 Test Loss: 0.2848931
Validation loss decreased (0.207182 --> 0.207094).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3177655
	speed: 0.1309s/iter; left time: 3317.4592s
	iters: 200, epoch: 5 | loss: 0.3523268
	speed: 0.0219s/iter; left time: 552.9282s
Epoch: 5 cost time: 7.517460346221924
Epoch: 5, Steps: 265 | Train Loss: 0.4164678 Vali Loss: 0.2071098 Test Loss: 0.2847790
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4640854
	speed: 0.1157s/iter; left time: 2901.8113s
	iters: 200, epoch: 6 | loss: 0.4785508
	speed: 0.0413s/iter; left time: 1032.6728s
Epoch: 6 cost time: 8.689464807510376
Epoch: 6, Steps: 265 | Train Loss: 0.4165651 Vali Loss: 0.2069624 Test Loss: 0.2846237
Validation loss decreased (0.207094 --> 0.206962).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3131573
	speed: 0.1125s/iter; left time: 2792.1719s
	iters: 200, epoch: 7 | loss: 0.2456553
	speed: 0.0185s/iter; left time: 457.0082s
Epoch: 7 cost time: 6.429617166519165
Epoch: 7, Steps: 265 | Train Loss: 0.4162639 Vali Loss: 0.2072302 Test Loss: 0.2847390
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4011450
	speed: 0.0955s/iter; left time: 2343.6700s
	iters: 200, epoch: 8 | loss: 0.3526723
	speed: 0.0190s/iter; left time: 463.7615s
Epoch: 8 cost time: 5.719870328903198
Epoch: 8, Steps: 265 | Train Loss: 0.4160597 Vali Loss: 0.2071663 Test Loss: 0.2846931
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3890265
	speed: 0.1069s/iter; left time: 2596.5005s
	iters: 200, epoch: 9 | loss: 0.4637348
	speed: 0.0263s/iter; left time: 636.0329s
Epoch: 9 cost time: 6.718502521514893
Epoch: 9, Steps: 265 | Train Loss: 0.4153242 Vali Loss: 0.2072256 Test Loss: 0.2845305
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3894446
	speed: 0.1185s/iter; left time: 2845.4233s
	iters: 200, epoch: 10 | loss: 0.3790639
	speed: 0.0207s/iter; left time: 494.1931s
Epoch: 10 cost time: 6.803098678588867
Epoch: 10, Steps: 265 | Train Loss: 0.4157203 Vali Loss: 0.2069970 Test Loss: 0.2845845
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3588415
	speed: 0.1010s/iter; left time: 2398.1230s
	iters: 200, epoch: 11 | loss: 0.4296561
	speed: 0.0181s/iter; left time: 429.0862s
Epoch: 11 cost time: 5.673282623291016
Epoch: 11, Steps: 265 | Train Loss: 0.4160752 Vali Loss: 0.2071102 Test Loss: 0.2845351
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3601018
	speed: 0.1101s/iter; left time: 2586.6047s
	iters: 200, epoch: 12 | loss: 0.4185103
	speed: 0.0367s/iter; left time: 858.6976s
Epoch: 12 cost time: 8.122089147567749
Epoch: 12, Steps: 265 | Train Loss: 0.4157072 Vali Loss: 0.2072162 Test Loss: 0.2845683
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2946332
	speed: 0.1038s/iter; left time: 2409.4734s
	iters: 200, epoch: 13 | loss: 0.3183782
	speed: 0.0259s/iter; left time: 599.2168s
Epoch: 13 cost time: 7.779366970062256
Epoch: 13, Steps: 265 | Train Loss: 0.4163459 Vali Loss: 0.2071201 Test Loss: 0.2845677
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4533259
	speed: 0.1326s/iter; left time: 3044.1671s
	iters: 200, epoch: 14 | loss: 0.4454240
	speed: 0.0199s/iter; left time: 454.6380s
Epoch: 14 cost time: 6.525164365768433
Epoch: 14, Steps: 265 | Train Loss: 0.4159281 Vali Loss: 0.2071350 Test Loss: 0.2845494
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4058303
	speed: 0.1041s/iter; left time: 2361.6311s
	iters: 200, epoch: 15 | loss: 0.4084986
	speed: 0.0226s/iter; left time: 509.4955s
Epoch: 15 cost time: 6.408846378326416
Epoch: 15, Steps: 265 | Train Loss: 0.4160072 Vali Loss: 0.2073464 Test Loss: 0.2845475
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4632337
	speed: 0.1490s/iter; left time: 3341.1211s
	iters: 200, epoch: 16 | loss: 0.4305764
	speed: 0.0292s/iter; left time: 652.0701s
Epoch: 16 cost time: 8.763987064361572
Epoch: 16, Steps: 265 | Train Loss: 0.4160193 Vali Loss: 0.2072552 Test Loss: 0.2845296
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4385646
	speed: 0.1306s/iter; left time: 2893.7026s
	iters: 200, epoch: 17 | loss: 0.4998174
	speed: 0.0313s/iter; left time: 689.9684s
Epoch: 17 cost time: 8.017263412475586
Epoch: 17, Steps: 265 | Train Loss: 0.4158303 Vali Loss: 0.2071509 Test Loss: 0.2845480
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2788184
	speed: 0.1465s/iter; left time: 3207.5860s
	iters: 200, epoch: 18 | loss: 0.3938854
	speed: 0.0268s/iter; left time: 583.1673s
Epoch: 18 cost time: 8.404592990875244
Epoch: 18, Steps: 265 | Train Loss: 0.4159114 Vali Loss: 0.2071323 Test Loss: 0.2845057
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2817821
	speed: 0.1124s/iter; left time: 2431.0011s
	iters: 200, epoch: 19 | loss: 0.3048971
	speed: 0.0197s/iter; left time: 425.2057s
Epoch: 19 cost time: 5.709739446640015
Epoch: 19, Steps: 265 | Train Loss: 0.4159732 Vali Loss: 0.2071549 Test Loss: 0.2844839
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.5689304
	speed: 0.1271s/iter; left time: 2715.9200s
	iters: 200, epoch: 20 | loss: 0.5744295
	speed: 0.0216s/iter; left time: 460.2955s
Epoch: 20 cost time: 8.613362789154053
Epoch: 20, Steps: 265 | Train Loss: 0.4156442 Vali Loss: 0.2070622 Test Loss: 0.2844917
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.5188864
	speed: 0.1109s/iter; left time: 2340.9663s
	iters: 200, epoch: 21 | loss: 0.2745569
	speed: 0.0235s/iter; left time: 494.0721s
Epoch: 21 cost time: 6.452028274536133
Epoch: 21, Steps: 265 | Train Loss: 0.4150069 Vali Loss: 0.2069802 Test Loss: 0.2844815
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4773735
	speed: 0.1127s/iter; left time: 2348.4904s
	iters: 200, epoch: 22 | loss: 0.5396593
	speed: 0.0359s/iter; left time: 744.2871s
Epoch: 22 cost time: 7.471833229064941
Epoch: 22, Steps: 265 | Train Loss: 0.4148998 Vali Loss: 0.2070343 Test Loss: 0.2844350
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.5343627
	speed: 0.0973s/iter; left time: 2002.0418s
	iters: 200, epoch: 23 | loss: 0.3635300
	speed: 0.0268s/iter; left time: 549.0682s
Epoch: 23 cost time: 6.883777379989624
Epoch: 23, Steps: 265 | Train Loss: 0.4152458 Vali Loss: 0.2071829 Test Loss: 0.2844826
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4623792
	speed: 0.1198s/iter; left time: 2432.5538s
	iters: 200, epoch: 24 | loss: 0.3890882
	speed: 0.0193s/iter; left time: 390.0451s
Epoch: 24 cost time: 7.660181522369385
Epoch: 24, Steps: 265 | Train Loss: 0.4156161 Vali Loss: 0.2071706 Test Loss: 0.2844864
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4105027
	speed: 0.1075s/iter; left time: 2155.2664s
	iters: 200, epoch: 25 | loss: 0.3020192
	speed: 0.0202s/iter; left time: 403.7635s
Epoch: 25 cost time: 6.046380281448364
Epoch: 25, Steps: 265 | Train Loss: 0.4152340 Vali Loss: 0.2073110 Test Loss: 0.2845149
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3845692
	speed: 0.1170s/iter; left time: 2313.0047s
	iters: 200, epoch: 26 | loss: 0.3652494
	speed: 0.0218s/iter; left time: 429.6931s
Epoch: 26 cost time: 7.619458198547363
Epoch: 26, Steps: 265 | Train Loss: 0.4152439 Vali Loss: 0.2072694 Test Loss: 0.2844726
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_180_336_FITS_ETTm2_ftM_sl180_ll48_pl336_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.2858811914920807, mae:0.3314395546913147, rse:0.43187040090560913, corr:[0.56151795 0.56394523 0.55947113 0.55594903 0.5552688  0.5552238
 0.5541123  0.55239093 0.5513151  0.5510101  0.5506656  0.5498511
 0.54898167 0.5486587  0.54874223 0.5485136  0.5476106  0.546416
 0.54560417 0.54531616 0.5451047  0.54454845 0.54373723 0.543086
 0.5427347  0.5424552  0.542006   0.54133856 0.54061013 0.53994596
 0.539348   0.538762   0.5381771  0.5377231  0.5373881  0.53700036
 0.5362856  0.53534883 0.5344847  0.5339151  0.5335897  0.5333112
 0.5329036  0.5323848  0.5319214  0.53155553 0.5310467  0.5302166
 0.5291621  0.5282376  0.527642   0.527294   0.5268501  0.5260962
 0.5252602  0.5247139  0.5243973  0.5241589  0.52375823 0.5231867
 0.5226299  0.52239966 0.5224286  0.5223939  0.52221036 0.52194345
 0.5216866  0.5215392  0.52144086 0.5213302  0.5211283  0.52091026
 0.5207612  0.5206225  0.5204894  0.520257   0.5199517  0.5195761
 0.5191969  0.5188288  0.51841944 0.51794404 0.5174589  0.51699096
 0.5165802  0.5162012  0.51579756 0.51540196 0.51500845 0.51463866
 0.5143298  0.51401395 0.5135622  0.51285225 0.511789   0.51033205
 0.5085797  0.5068142  0.50508237 0.5034192  0.50191474 0.5006505
 0.49954545 0.49841553 0.49710956 0.49568847 0.4943506  0.49323067
 0.4922642  0.49125242 0.49034637 0.48952273 0.4887186  0.4877703
 0.48655006 0.48525882 0.48411343 0.48318523 0.48240092 0.48151636
 0.48051018 0.47948155 0.47855082 0.47772142 0.47691867 0.47604173
 0.47505572 0.47402743 0.47304037 0.47211137 0.47123623 0.47034448
 0.46947306 0.4686277  0.46795955 0.46746302 0.46698788 0.46655178
 0.46612272 0.46567175 0.46514463 0.46449992 0.46376896 0.46296304
 0.46215078 0.4613595  0.46052897 0.4596704  0.4588505  0.4580517
 0.4573875  0.456964   0.4565025  0.4558794  0.455182   0.45459464
 0.4542344  0.45403728 0.45372215 0.45325768 0.45280325 0.45252624
 0.4524988  0.45244455 0.45235857 0.45215854 0.45193943 0.4519456
 0.45216757 0.45244572 0.45258248 0.4525539  0.45252886 0.45255744
 0.4526682  0.45268023 0.4525152  0.4521801  0.4518582  0.45174006
 0.4516812  0.45147118 0.45113027 0.45074397 0.4505238  0.45048076
 0.45052454 0.45048726 0.4501542  0.4494146  0.44830504 0.44694263
 0.44547844 0.44408485 0.44272602 0.44141945 0.44024658 0.43911517
 0.43794674 0.4367299  0.43551525 0.43446994 0.43357104 0.4328686
 0.4322674  0.4316622  0.43096352 0.4302073  0.42948082 0.42883962
 0.4282954  0.42780516 0.42727926 0.42665428 0.42592964 0.42509243
 0.42424682 0.42332998 0.42249194 0.42168432 0.42083305 0.420005
 0.41913053 0.41822046 0.41739383 0.4165699  0.41585818 0.41523647
 0.41452688 0.41363147 0.41257417 0.41165614 0.41105488 0.41085723
 0.4107657  0.4105758  0.41027287 0.40977237 0.40927893 0.4088457
 0.40845287 0.40796375 0.4073068  0.4066627  0.40613878 0.40583
 0.4058356  0.40608272 0.40642118 0.40661627 0.4067048  0.406777
 0.4069006  0.40720403 0.40743038 0.40734953 0.40707085 0.4069314
 0.407045   0.4072405  0.40732276 0.40732777 0.40732318 0.40737334
 0.40753803 0.40772727 0.4078382  0.40780115 0.40771842 0.4076572
 0.40748364 0.40722752 0.4068948  0.4067135  0.4067235  0.40684944
 0.40693963 0.40689215 0.40681762 0.40679327 0.40673888 0.406747
 0.4067572  0.40666872 0.4065161  0.40629607 0.40586913 0.4050573
 0.40384284 0.40264636 0.4015717  0.40074867 0.4000285  0.39930606
 0.39869422 0.39814296 0.39764008 0.3971029  0.39661223 0.39611307
 0.39564958 0.3951092  0.3945678  0.39395148 0.39319164 0.39237848
 0.39165822 0.39098275 0.39021817 0.3893444  0.38841534 0.3875313
 0.38662684 0.3857772  0.38490704 0.38408107 0.38314974 0.38210064
 0.38092244 0.3797433  0.37864703 0.37766722 0.3768259  0.3762049
 0.37584403 0.37541205 0.3744628  0.37283304 0.37122896 0.37086263
 0.3719712  0.37274104 0.37151882 0.36940336 0.37058312 0.37726867]
