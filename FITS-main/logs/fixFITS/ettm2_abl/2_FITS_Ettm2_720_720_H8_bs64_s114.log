Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=74, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_720_720_FITS_ETTm2_ftM_sl720_ll48_pl720_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=74, out_features=148, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  9812992.0
params:  11100.0
Trainable parameters:  11100
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4396072
	speed: 0.0276s/iter; left time: 708.9834s
	iters: 200, epoch: 1 | loss: 0.2957340
	speed: 0.0206s/iter; left time: 526.2609s
Epoch: 1 cost time: 5.9559714794158936
Epoch: 1, Steps: 258 | Train Loss: 0.4444199 Vali Loss: 0.2998880 Test Loss: 0.3977737
Validation loss decreased (inf --> 0.299888).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3525011
	speed: 0.0875s/iter; left time: 2225.9207s
	iters: 200, epoch: 2 | loss: 0.3449480
	speed: 0.0210s/iter; left time: 531.8470s
Epoch: 2 cost time: 6.0077924728393555
Epoch: 2, Steps: 258 | Train Loss: 0.3275234 Vali Loss: 0.2835427 Test Loss: 0.3785647
Validation loss decreased (0.299888 --> 0.283543).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3144425
	speed: 0.0899s/iter; left time: 2263.5396s
	iters: 200, epoch: 3 | loss: 0.2994215
	speed: 0.0217s/iter; left time: 543.8787s
Epoch: 3 cost time: 6.252514600753784
Epoch: 3, Steps: 258 | Train Loss: 0.2959515 Vali Loss: 0.2764859 Test Loss: 0.3700947
Validation loss decreased (0.283543 --> 0.276486).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3300203
	speed: 0.0894s/iter; left time: 2229.3163s
	iters: 200, epoch: 4 | loss: 0.2252587
	speed: 0.0200s/iter; left time: 495.7052s
Epoch: 4 cost time: 5.858831405639648
Epoch: 4, Steps: 258 | Train Loss: 0.2798348 Vali Loss: 0.2728237 Test Loss: 0.3651125
Validation loss decreased (0.276486 --> 0.272824).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3631716
	speed: 0.0883s/iter; left time: 2177.7305s
	iters: 200, epoch: 5 | loss: 0.2989188
	speed: 0.0209s/iter; left time: 513.8069s
Epoch: 5 cost time: 6.030759572982788
Epoch: 5, Steps: 258 | Train Loss: 0.2710314 Vali Loss: 0.2703173 Test Loss: 0.3616149
Validation loss decreased (0.272824 --> 0.270317).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2666706
	speed: 0.0878s/iter; left time: 2144.3074s
	iters: 200, epoch: 6 | loss: 0.3026553
	speed: 0.0199s/iter; left time: 484.1739s
Epoch: 6 cost time: 5.818342924118042
Epoch: 6, Steps: 258 | Train Loss: 0.2664924 Vali Loss: 0.2681180 Test Loss: 0.3594380
Validation loss decreased (0.270317 --> 0.268118).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2042280
	speed: 0.0920s/iter; left time: 2221.7721s
	iters: 200, epoch: 7 | loss: 0.2738600
	speed: 0.0204s/iter; left time: 490.4687s
Epoch: 7 cost time: 6.0243566036224365
Epoch: 7, Steps: 258 | Train Loss: 0.2636206 Vali Loss: 0.2671340 Test Loss: 0.3581095
Validation loss decreased (0.268118 --> 0.267134).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2380278
	speed: 0.0871s/iter; left time: 2080.9738s
	iters: 200, epoch: 8 | loss: 0.2426305
	speed: 0.0202s/iter; left time: 480.2675s
Epoch: 8 cost time: 5.969228267669678
Epoch: 8, Steps: 258 | Train Loss: 0.2616058 Vali Loss: 0.2661495 Test Loss: 0.3570120
Validation loss decreased (0.267134 --> 0.266149).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2385889
	speed: 0.0882s/iter; left time: 2083.6713s
	iters: 200, epoch: 9 | loss: 0.3166419
	speed: 0.0212s/iter; left time: 499.1544s
Epoch: 9 cost time: 6.103912591934204
Epoch: 9, Steps: 258 | Train Loss: 0.2612270 Vali Loss: 0.2657191 Test Loss: 0.3565175
Validation loss decreased (0.266149 --> 0.265719).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2362209
	speed: 0.0896s/iter; left time: 2094.3252s
	iters: 200, epoch: 10 | loss: 0.2599612
	speed: 0.0207s/iter; left time: 482.0377s
Epoch: 10 cost time: 5.946670293807983
Epoch: 10, Steps: 258 | Train Loss: 0.2607828 Vali Loss: 0.2649798 Test Loss: 0.3562025
Validation loss decreased (0.265719 --> 0.264980).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1868761
	speed: 0.0869s/iter; left time: 2010.1964s
	iters: 200, epoch: 11 | loss: 0.2889309
	speed: 0.0208s/iter; left time: 479.3940s
Epoch: 11 cost time: 5.871457576751709
Epoch: 11, Steps: 258 | Train Loss: 0.2601894 Vali Loss: 0.2654213 Test Loss: 0.3557214
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2427062
	speed: 0.0891s/iter; left time: 2036.1216s
	iters: 200, epoch: 12 | loss: 0.2191669
	speed: 0.0203s/iter; left time: 462.6534s
Epoch: 12 cost time: 5.904160261154175
Epoch: 12, Steps: 258 | Train Loss: 0.2599726 Vali Loss: 0.2648243 Test Loss: 0.3554571
Validation loss decreased (0.264980 --> 0.264824).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1941884
	speed: 0.0900s/iter; left time: 2033.9133s
	iters: 200, epoch: 13 | loss: 0.2258432
	speed: 0.0203s/iter; left time: 457.7384s
Epoch: 13 cost time: 5.949399471282959
Epoch: 13, Steps: 258 | Train Loss: 0.2599214 Vali Loss: 0.2648307 Test Loss: 0.3555287
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2385326
	speed: 0.0848s/iter; left time: 1895.9751s
	iters: 200, epoch: 14 | loss: 0.3113628
	speed: 0.0205s/iter; left time: 457.0237s
Epoch: 14 cost time: 5.905593633651733
Epoch: 14, Steps: 258 | Train Loss: 0.2598431 Vali Loss: 0.2644201 Test Loss: 0.3554824
Validation loss decreased (0.264824 --> 0.264420).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2487242
	speed: 0.0887s/iter; left time: 1958.2293s
	iters: 200, epoch: 15 | loss: 0.2906695
	speed: 0.0210s/iter; left time: 461.4333s
Epoch: 15 cost time: 5.940792560577393
Epoch: 15, Steps: 258 | Train Loss: 0.2595523 Vali Loss: 0.2644797 Test Loss: 0.3551488
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2366942
	speed: 0.0885s/iter; left time: 1932.8712s
	iters: 200, epoch: 16 | loss: 0.2290751
	speed: 0.0212s/iter; left time: 461.2334s
Epoch: 16 cost time: 5.986747980117798
Epoch: 16, Steps: 258 | Train Loss: 0.2597348 Vali Loss: 0.2644439 Test Loss: 0.3551053
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2338224
	speed: 0.0929s/iter; left time: 2004.6163s
	iters: 200, epoch: 17 | loss: 0.1831010
	speed: 0.0212s/iter; left time: 454.4595s
Epoch: 17 cost time: 6.230985403060913
Epoch: 17, Steps: 258 | Train Loss: 0.2594883 Vali Loss: 0.2644808 Test Loss: 0.3551452
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2645744
	speed: 0.0912s/iter; left time: 1943.9375s
	iters: 200, epoch: 18 | loss: 0.2274856
	speed: 0.0205s/iter; left time: 435.5102s
Epoch: 18 cost time: 6.074961185455322
Epoch: 18, Steps: 258 | Train Loss: 0.2595311 Vali Loss: 0.2644512 Test Loss: 0.3550943
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2673495
	speed: 0.0887s/iter; left time: 1867.0117s
	iters: 200, epoch: 19 | loss: 0.2445470
	speed: 0.0206s/iter; left time: 431.2471s
Epoch: 19 cost time: 5.920435190200806
Epoch: 19, Steps: 258 | Train Loss: 0.2594386 Vali Loss: 0.2644096 Test Loss: 0.3551049
Validation loss decreased (0.264420 --> 0.264410).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2654310
	speed: 0.0888s/iter; left time: 1847.2244s
	iters: 200, epoch: 20 | loss: 0.1999981
	speed: 0.0205s/iter; left time: 423.7860s
Epoch: 20 cost time: 6.018541574478149
Epoch: 20, Steps: 258 | Train Loss: 0.2596828 Vali Loss: 0.2643204 Test Loss: 0.3550603
Validation loss decreased (0.264410 --> 0.264320).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2244725
	speed: 0.0880s/iter; left time: 1808.4221s
	iters: 200, epoch: 21 | loss: 0.2875315
	speed: 0.0211s/iter; left time: 430.5619s
Epoch: 21 cost time: 6.026502847671509
Epoch: 21, Steps: 258 | Train Loss: 0.2593519 Vali Loss: 0.2641205 Test Loss: 0.3548709
Validation loss decreased (0.264320 --> 0.264121).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3096650
	speed: 0.0876s/iter; left time: 1776.4633s
	iters: 200, epoch: 22 | loss: 0.2633430
	speed: 0.0205s/iter; left time: 414.1587s
Epoch: 22 cost time: 5.9419333934783936
Epoch: 22, Steps: 258 | Train Loss: 0.2596295 Vali Loss: 0.2644397 Test Loss: 0.3548148
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2606767
	speed: 0.0883s/iter; left time: 1768.0250s
	iters: 200, epoch: 23 | loss: 0.2678633
	speed: 0.0213s/iter; left time: 424.1967s
Epoch: 23 cost time: 6.052009582519531
Epoch: 23, Steps: 258 | Train Loss: 0.2594240 Vali Loss: 0.2640896 Test Loss: 0.3549321
Validation loss decreased (0.264121 --> 0.264090).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2357220
	speed: 0.0928s/iter; left time: 1835.0465s
	iters: 200, epoch: 24 | loss: 0.2846613
	speed: 0.0204s/iter; left time: 401.5275s
Epoch: 24 cost time: 5.984902381896973
Epoch: 24, Steps: 258 | Train Loss: 0.2593890 Vali Loss: 0.2642556 Test Loss: 0.3549098
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2733133
	speed: 0.0876s/iter; left time: 1709.5668s
	iters: 200, epoch: 25 | loss: 0.1880616
	speed: 0.0205s/iter; left time: 397.6984s
Epoch: 25 cost time: 5.701210021972656
Epoch: 25, Steps: 258 | Train Loss: 0.2595617 Vali Loss: 0.2640974 Test Loss: 0.3549038
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2208477
	speed: 0.0887s/iter; left time: 1706.7172s
	iters: 200, epoch: 26 | loss: 0.2778928
	speed: 0.0207s/iter; left time: 396.6645s
Epoch: 26 cost time: 5.975792169570923
Epoch: 26, Steps: 258 | Train Loss: 0.2594650 Vali Loss: 0.2639232 Test Loss: 0.3548808
Validation loss decreased (0.264090 --> 0.263923).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2150378
	speed: 0.0885s/iter; left time: 1681.2985s
	iters: 200, epoch: 27 | loss: 0.2492451
	speed: 0.0198s/iter; left time: 374.2822s
Epoch: 27 cost time: 5.762749910354614
Epoch: 27, Steps: 258 | Train Loss: 0.2594078 Vali Loss: 0.2638547 Test Loss: 0.3548321
Validation loss decreased (0.263923 --> 0.263855).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2745577
	speed: 0.0882s/iter; left time: 1652.5960s
	iters: 200, epoch: 28 | loss: 0.2782874
	speed: 0.0206s/iter; left time: 383.2640s
Epoch: 28 cost time: 5.919861316680908
Epoch: 28, Steps: 258 | Train Loss: 0.2594686 Vali Loss: 0.2641966 Test Loss: 0.3549054
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3281457
	speed: 0.0903s/iter; left time: 1668.8942s
	iters: 200, epoch: 29 | loss: 0.3139754
	speed: 0.0210s/iter; left time: 385.1051s
Epoch: 29 cost time: 6.06799578666687
Epoch: 29, Steps: 258 | Train Loss: 0.2594078 Vali Loss: 0.2642558 Test Loss: 0.3548480
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2355044
	speed: 0.0885s/iter; left time: 1612.0842s
	iters: 200, epoch: 30 | loss: 0.3010496
	speed: 0.0206s/iter; left time: 372.9394s
Epoch: 30 cost time: 5.96727991104126
Epoch: 30, Steps: 258 | Train Loss: 0.2591419 Vali Loss: 0.2639751 Test Loss: 0.3548527
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2926011
	speed: 0.0886s/iter; left time: 1590.5945s
	iters: 200, epoch: 31 | loss: 0.2468056
	speed: 0.0206s/iter; left time: 368.5990s
Epoch: 31 cost time: 5.993419170379639
Epoch: 31, Steps: 258 | Train Loss: 0.2594964 Vali Loss: 0.2643747 Test Loss: 0.3548650
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1916816
	speed: 0.0932s/iter; left time: 1650.1580s
	iters: 200, epoch: 32 | loss: 0.2880691
	speed: 0.0205s/iter; left time: 360.6716s
Epoch: 32 cost time: 5.993312835693359
Epoch: 32, Steps: 258 | Train Loss: 0.2592662 Vali Loss: 0.2643021 Test Loss: 0.3548492
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3215486
	speed: 0.0891s/iter; left time: 1553.9197s
	iters: 200, epoch: 33 | loss: 0.2328679
	speed: 0.0215s/iter; left time: 372.5199s
Epoch: 33 cost time: 5.981388807296753
Epoch: 33, Steps: 258 | Train Loss: 0.2593554 Vali Loss: 0.2641352 Test Loss: 0.3547922
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3073027
	speed: 0.0893s/iter; left time: 1535.0186s
	iters: 200, epoch: 34 | loss: 0.1980704
	speed: 0.0198s/iter; left time: 337.6520s
Epoch: 34 cost time: 5.872425317764282
Epoch: 34, Steps: 258 | Train Loss: 0.2596626 Vali Loss: 0.2642076 Test Loss: 0.3547713
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2821692
	speed: 0.0870s/iter; left time: 1473.3830s
	iters: 200, epoch: 35 | loss: 0.3344122
	speed: 0.0209s/iter; left time: 351.3571s
Epoch: 35 cost time: 5.9526755809783936
Epoch: 35, Steps: 258 | Train Loss: 0.2594099 Vali Loss: 0.2641835 Test Loss: 0.3548224
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2501912
	speed: 0.0873s/iter; left time: 1455.2287s
	iters: 200, epoch: 36 | loss: 0.2628262
	speed: 0.0211s/iter; left time: 349.4315s
Epoch: 36 cost time: 5.899171829223633
Epoch: 36, Steps: 258 | Train Loss: 0.2593219 Vali Loss: 0.2639607 Test Loss: 0.3547527
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2305594
	speed: 0.0877s/iter; left time: 1438.9597s
	iters: 200, epoch: 37 | loss: 0.2945286
	speed: 0.0209s/iter; left time: 340.4012s
Epoch: 37 cost time: 5.92407488822937
Epoch: 37, Steps: 258 | Train Loss: 0.2591015 Vali Loss: 0.2640654 Test Loss: 0.3547814
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3471187
	speed: 0.0874s/iter; left time: 1411.7043s
	iters: 200, epoch: 38 | loss: 0.3161024
	speed: 0.0208s/iter; left time: 334.2556s
Epoch: 38 cost time: 5.965863466262817
Epoch: 38, Steps: 258 | Train Loss: 0.2595249 Vali Loss: 0.2642825 Test Loss: 0.3548021
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2417092
	speed: 0.0888s/iter; left time: 1411.3722s
	iters: 200, epoch: 39 | loss: 0.2533375
	speed: 0.0201s/iter; left time: 316.9685s
Epoch: 39 cost time: 5.881226062774658
Epoch: 39, Steps: 258 | Train Loss: 0.2595035 Vali Loss: 0.2641934 Test Loss: 0.3547605
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1792795
	speed: 0.0876s/iter; left time: 1369.4003s
	iters: 200, epoch: 40 | loss: 0.3056609
	speed: 0.0210s/iter; left time: 326.4674s
Epoch: 40 cost time: 6.011051893234253
Epoch: 40, Steps: 258 | Train Loss: 0.2593673 Vali Loss: 0.2643634 Test Loss: 0.3547667
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1773555
	speed: 0.0881s/iter; left time: 1355.7791s
	iters: 200, epoch: 41 | loss: 0.2989659
	speed: 0.0212s/iter; left time: 324.1564s
Epoch: 41 cost time: 6.103068590164185
Epoch: 41, Steps: 258 | Train Loss: 0.2594365 Vali Loss: 0.2643721 Test Loss: 0.3547603
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2816464
	speed: 0.0892s/iter; left time: 1349.2552s
	iters: 200, epoch: 42 | loss: 0.1933234
	speed: 0.0208s/iter; left time: 311.9495s
Epoch: 42 cost time: 5.995176315307617
Epoch: 42, Steps: 258 | Train Loss: 0.2592014 Vali Loss: 0.2640092 Test Loss: 0.3547506
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2948582
	speed: 0.0876s/iter; left time: 1301.8291s
	iters: 200, epoch: 43 | loss: 0.3310276
	speed: 0.0209s/iter; left time: 308.8330s
Epoch: 43 cost time: 5.959291934967041
Epoch: 43, Steps: 258 | Train Loss: 0.2595205 Vali Loss: 0.2640205 Test Loss: 0.3547711
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2270492
	speed: 0.0866s/iter; left time: 1264.2539s
	iters: 200, epoch: 44 | loss: 0.2540999
	speed: 0.0202s/iter; left time: 293.2961s
Epoch: 44 cost time: 5.8065056800842285
Epoch: 44, Steps: 258 | Train Loss: 0.2593172 Vali Loss: 0.2641009 Test Loss: 0.3547530
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2555564
	speed: 0.0892s/iter; left time: 1280.0071s
	iters: 200, epoch: 45 | loss: 0.4098607
	speed: 0.0202s/iter; left time: 287.3248s
Epoch: 45 cost time: 5.978083848953247
Epoch: 45, Steps: 258 | Train Loss: 0.2592289 Vali Loss: 0.2643007 Test Loss: 0.3547538
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2407735
	speed: 0.0885s/iter; left time: 1247.2045s
	iters: 200, epoch: 46 | loss: 0.2045183
	speed: 0.0212s/iter; left time: 296.4781s
Epoch: 46 cost time: 5.973879098892212
Epoch: 46, Steps: 258 | Train Loss: 0.2591217 Vali Loss: 0.2641624 Test Loss: 0.3547605
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2073541
	speed: 0.0909s/iter; left time: 1257.6703s
	iters: 200, epoch: 47 | loss: 0.2101854
	speed: 0.0213s/iter; left time: 292.3342s
Epoch: 47 cost time: 6.163713216781616
Epoch: 47, Steps: 258 | Train Loss: 0.2593391 Vali Loss: 0.2638349 Test Loss: 0.3547157
Validation loss decreased (0.263855 --> 0.263835).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2868482
	speed: 0.0898s/iter; left time: 1218.5581s
	iters: 200, epoch: 48 | loss: 0.3350149
	speed: 0.0200s/iter; left time: 269.9406s
Epoch: 48 cost time: 5.910994529724121
Epoch: 48, Steps: 258 | Train Loss: 0.2591561 Vali Loss: 0.2640650 Test Loss: 0.3547377
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2600441
	speed: 0.0901s/iter; left time: 1199.8471s
	iters: 200, epoch: 49 | loss: 0.2730752
	speed: 0.0212s/iter; left time: 280.5203s
Epoch: 49 cost time: 6.231565713882446
Epoch: 49, Steps: 258 | Train Loss: 0.2592611 Vali Loss: 0.2639586 Test Loss: 0.3547397
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2165577
	speed: 0.0893s/iter; left time: 1165.7383s
	iters: 200, epoch: 50 | loss: 0.1934743
	speed: 0.0201s/iter; left time: 260.8915s
Epoch: 50 cost time: 6.0730156898498535
Epoch: 50, Steps: 258 | Train Loss: 0.2591707 Vali Loss: 0.2641602 Test Loss: 0.3547378
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2329571
	speed: 0.0896s/iter; left time: 1147.4974s
	iters: 200, epoch: 51 | loss: 0.2913822
	speed: 0.0207s/iter; left time: 263.2963s
Epoch: 51 cost time: 6.081681251525879
Epoch: 51, Steps: 258 | Train Loss: 0.2592726 Vali Loss: 0.2641116 Test Loss: 0.3547262
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2282417
	speed: 0.0898s/iter; left time: 1126.7355s
	iters: 200, epoch: 52 | loss: 0.2314372
	speed: 0.0212s/iter; left time: 263.9833s
Epoch: 52 cost time: 6.017754793167114
Epoch: 52, Steps: 258 | Train Loss: 0.2590942 Vali Loss: 0.2642314 Test Loss: 0.3547373
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2295348
	speed: 0.0884s/iter; left time: 1085.6821s
	iters: 200, epoch: 53 | loss: 0.3274000
	speed: 0.0336s/iter; left time: 409.0995s
Epoch: 53 cost time: 9.109797954559326
Epoch: 53, Steps: 258 | Train Loss: 0.2591897 Vali Loss: 0.2640770 Test Loss: 0.3547208
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2749785
	speed: 0.1068s/iter; left time: 1284.9780s
	iters: 200, epoch: 54 | loss: 0.2038036
	speed: 0.0207s/iter; left time: 247.4677s
Epoch: 54 cost time: 5.885926008224487
Epoch: 54, Steps: 258 | Train Loss: 0.2592194 Vali Loss: 0.2641520 Test Loss: 0.3547049
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1922884
	speed: 0.0866s/iter; left time: 1019.1929s
	iters: 200, epoch: 55 | loss: 0.2057515
	speed: 0.0211s/iter; left time: 246.7724s
Epoch: 55 cost time: 5.903276205062866
Epoch: 55, Steps: 258 | Train Loss: 0.2590942 Vali Loss: 0.2643291 Test Loss: 0.3547180
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2407173
	speed: 0.0868s/iter; left time: 999.0397s
	iters: 200, epoch: 56 | loss: 0.3875352
	speed: 0.0210s/iter; left time: 239.4391s
Epoch: 56 cost time: 5.972560167312622
Epoch: 56, Steps: 258 | Train Loss: 0.2592179 Vali Loss: 0.2640102 Test Loss: 0.3547047
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2442700
	speed: 0.0894s/iter; left time: 1006.1366s
	iters: 200, epoch: 57 | loss: 0.2729023
	speed: 0.0215s/iter; left time: 240.1868s
Epoch: 57 cost time: 6.03482460975647
Epoch: 57, Steps: 258 | Train Loss: 0.2590606 Vali Loss: 0.2641121 Test Loss: 0.3547177
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2478422
	speed: 0.0873s/iter; left time: 960.4097s
	iters: 200, epoch: 58 | loss: 0.2282424
	speed: 0.0205s/iter; left time: 223.5903s
Epoch: 58 cost time: 5.8863489627838135
Epoch: 58, Steps: 258 | Train Loss: 0.2595349 Vali Loss: 0.2639844 Test Loss: 0.3547118
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2771980
	speed: 0.0899s/iter; left time: 965.4309s
	iters: 200, epoch: 59 | loss: 0.2677664
	speed: 0.0204s/iter; left time: 216.5742s
Epoch: 59 cost time: 5.774691343307495
Epoch: 59, Steps: 258 | Train Loss: 0.2592464 Vali Loss: 0.2640147 Test Loss: 0.3547151
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.2443763
	speed: 0.0859s/iter; left time: 899.9196s
	iters: 200, epoch: 60 | loss: 0.3156030
	speed: 0.0215s/iter; left time: 222.6407s
Epoch: 60 cost time: 5.883868455886841
Epoch: 60, Steps: 258 | Train Loss: 0.2594765 Vali Loss: 0.2642099 Test Loss: 0.3547213
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.3401533
	speed: 0.0880s/iter; left time: 899.6159s
	iters: 200, epoch: 61 | loss: 0.3166957
	speed: 0.0204s/iter; left time: 206.6495s
Epoch: 61 cost time: 5.908417701721191
Epoch: 61, Steps: 258 | Train Loss: 0.2592400 Vali Loss: 0.2640564 Test Loss: 0.3547103
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1779010
	speed: 0.0871s/iter; left time: 867.5393s
	iters: 200, epoch: 62 | loss: 0.3486626
	speed: 0.0205s/iter; left time: 202.1820s
Epoch: 62 cost time: 5.77017617225647
Epoch: 62, Steps: 258 | Train Loss: 0.2592246 Vali Loss: 0.2642553 Test Loss: 0.3546985
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1747037
	speed: 0.0861s/iter; left time: 835.8154s
	iters: 200, epoch: 63 | loss: 0.2161272
	speed: 0.0196s/iter; left time: 188.4070s
Epoch: 63 cost time: 5.6591761112213135
Epoch: 63, Steps: 258 | Train Loss: 0.2593354 Vali Loss: 0.2641429 Test Loss: 0.3547081
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1848711
	speed: 0.0878s/iter; left time: 829.5904s
	iters: 200, epoch: 64 | loss: 0.1716744
	speed: 0.0211s/iter; left time: 197.1940s
Epoch: 64 cost time: 6.0841240882873535
Epoch: 64, Steps: 258 | Train Loss: 0.2591768 Vali Loss: 0.2642725 Test Loss: 0.3547076
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.2796850
	speed: 0.0869s/iter; left time: 798.3017s
	iters: 200, epoch: 65 | loss: 0.2762408
	speed: 0.0204s/iter; left time: 185.5588s
Epoch: 65 cost time: 5.988509178161621
Epoch: 65, Steps: 258 | Train Loss: 0.2593726 Vali Loss: 0.2640794 Test Loss: 0.3547030
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.2597459
	speed: 0.0879s/iter; left time: 785.2332s
	iters: 200, epoch: 66 | loss: 0.3440162
	speed: 0.0211s/iter; left time: 186.7275s
Epoch: 66 cost time: 6.006769180297852
Epoch: 66, Steps: 258 | Train Loss: 0.2591932 Vali Loss: 0.2641455 Test Loss: 0.3547117
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.2885089
	speed: 0.0887s/iter; left time: 769.6079s
	iters: 200, epoch: 67 | loss: 0.2232352
	speed: 0.0211s/iter; left time: 181.1612s
Epoch: 67 cost time: 6.109273910522461
Epoch: 67, Steps: 258 | Train Loss: 0.2592970 Vali Loss: 0.2639070 Test Loss: 0.3547076
EarlyStopping counter: 20 out of 20
Early stopping
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=74, out_features=148, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  9812992.0
params:  11100.0
Trainable parameters:  11100
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5730527
	speed: 0.0267s/iter; left time: 685.3152s
	iters: 200, epoch: 1 | loss: 0.5324033
	speed: 0.0211s/iter; left time: 539.3004s
Epoch: 1 cost time: 5.944948434829712
Epoch: 1, Steps: 258 | Train Loss: 0.4989005 Vali Loss: 0.2629022 Test Loss: 0.3541475
Validation loss decreased (inf --> 0.262902).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5903573
	speed: 0.0863s/iter; left time: 2195.7845s
	iters: 200, epoch: 2 | loss: 0.4432028
	speed: 0.0209s/iter; left time: 530.3750s
Epoch: 2 cost time: 5.870959043502808
Epoch: 2, Steps: 258 | Train Loss: 0.4980126 Vali Loss: 0.2622397 Test Loss: 0.3535724
Validation loss decreased (0.262902 --> 0.262240).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4900747
	speed: 0.0916s/iter; left time: 2305.9025s
	iters: 200, epoch: 3 | loss: 0.5144910
	speed: 0.0205s/iter; left time: 515.3327s
Epoch: 3 cost time: 6.0404462814331055
Epoch: 3, Steps: 258 | Train Loss: 0.4971877 Vali Loss: 0.2622974 Test Loss: 0.3535599
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.5991951
	speed: 0.0908s/iter; left time: 2264.4099s
	iters: 200, epoch: 4 | loss: 0.7428253
	speed: 0.0210s/iter; left time: 521.7224s
Epoch: 4 cost time: 6.14607572555542
Epoch: 4, Steps: 258 | Train Loss: 0.4964935 Vali Loss: 0.2619562 Test Loss: 0.3532057
Validation loss decreased (0.262240 --> 0.261956).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.6774918
	speed: 0.0907s/iter; left time: 2237.1585s
	iters: 200, epoch: 5 | loss: 0.4846892
	speed: 0.0202s/iter; left time: 495.2871s
Epoch: 5 cost time: 6.079953908920288
Epoch: 5, Steps: 258 | Train Loss: 0.4961571 Vali Loss: 0.2622813 Test Loss: 0.3531103
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.5861338
	speed: 0.0883s/iter; left time: 2155.0163s
	iters: 200, epoch: 6 | loss: 0.6235126
	speed: 0.0210s/iter; left time: 511.0101s
Epoch: 6 cost time: 6.003933906555176
Epoch: 6, Steps: 258 | Train Loss: 0.4968761 Vali Loss: 0.2623037 Test Loss: 0.3529725
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.6185938
	speed: 0.0868s/iter; left time: 2097.4857s
	iters: 200, epoch: 7 | loss: 0.4800644
	speed: 0.0202s/iter; left time: 486.6842s
Epoch: 7 cost time: 5.794207334518433
Epoch: 7, Steps: 258 | Train Loss: 0.4960988 Vali Loss: 0.2618999 Test Loss: 0.3530441
Validation loss decreased (0.261956 --> 0.261900).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4993497
	speed: 0.0895s/iter; left time: 2139.3912s
	iters: 200, epoch: 8 | loss: 0.6379771
	speed: 0.0298s/iter; left time: 709.4433s
Epoch: 8 cost time: 7.118549346923828
Epoch: 8, Steps: 258 | Train Loss: 0.4956946 Vali Loss: 0.2612202 Test Loss: 0.3530981
Validation loss decreased (0.261900 --> 0.261220).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3695019
	speed: 0.0909s/iter; left time: 2148.7012s
	iters: 200, epoch: 9 | loss: 0.6444737
	speed: 0.0211s/iter; left time: 496.4704s
Epoch: 9 cost time: 6.025593996047974
Epoch: 9, Steps: 258 | Train Loss: 0.4958349 Vali Loss: 0.2619109 Test Loss: 0.3529537
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.6005691
	speed: 0.0896s/iter; left time: 2093.8264s
	iters: 200, epoch: 10 | loss: 0.4472572
	speed: 0.0207s/iter; left time: 480.8879s
Epoch: 10 cost time: 5.966812610626221
Epoch: 10, Steps: 258 | Train Loss: 0.4949161 Vali Loss: 0.2616594 Test Loss: 0.3527799
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.5120903
	speed: 0.0879s/iter; left time: 2033.1070s
	iters: 200, epoch: 11 | loss: 0.3836279
	speed: 0.0210s/iter; left time: 482.5951s
Epoch: 11 cost time: 6.003330707550049
Epoch: 11, Steps: 258 | Train Loss: 0.4955498 Vali Loss: 0.2614385 Test Loss: 0.3528340
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3920491
	speed: 0.0872s/iter; left time: 1993.2708s
	iters: 200, epoch: 12 | loss: 0.5509123
	speed: 0.0208s/iter; left time: 473.5085s
Epoch: 12 cost time: 5.846827507019043
Epoch: 12, Steps: 258 | Train Loss: 0.4956154 Vali Loss: 0.2614336 Test Loss: 0.3530457
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4074639
	speed: 0.0886s/iter; left time: 2002.1317s
	iters: 200, epoch: 13 | loss: 0.4773483
	speed: 0.0212s/iter; left time: 476.7018s
Epoch: 13 cost time: 6.062056541442871
Epoch: 13, Steps: 258 | Train Loss: 0.4952577 Vali Loss: 0.2613899 Test Loss: 0.3530139
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3660896
	speed: 0.0867s/iter; left time: 1937.3521s
	iters: 200, epoch: 14 | loss: 0.3885001
	speed: 0.0209s/iter; left time: 465.8043s
Epoch: 14 cost time: 5.930952310562134
Epoch: 14, Steps: 258 | Train Loss: 0.4952751 Vali Loss: 0.2613651 Test Loss: 0.3529088
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4783268
	speed: 0.0871s/iter; left time: 1924.5639s
	iters: 200, epoch: 15 | loss: 0.5174286
	speed: 0.0209s/iter; left time: 458.7975s
Epoch: 15 cost time: 5.8840696811676025
Epoch: 15, Steps: 258 | Train Loss: 0.4952643 Vali Loss: 0.2608512 Test Loss: 0.3529649
Validation loss decreased (0.261220 --> 0.260851).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4563740
	speed: 0.0889s/iter; left time: 1941.1789s
	iters: 200, epoch: 16 | loss: 0.4176458
	speed: 0.0208s/iter; left time: 451.3084s
Epoch: 16 cost time: 5.961626052856445
Epoch: 16, Steps: 258 | Train Loss: 0.4956098 Vali Loss: 0.2613289 Test Loss: 0.3529713
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4679735
	speed: 0.0884s/iter; left time: 1907.8569s
	iters: 200, epoch: 17 | loss: 0.4974291
	speed: 0.0205s/iter; left time: 439.4753s
Epoch: 17 cost time: 5.93529486656189
Epoch: 17, Steps: 258 | Train Loss: 0.4952780 Vali Loss: 0.2615106 Test Loss: 0.3529603
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3408411
	speed: 0.0895s/iter; left time: 1907.7873s
	iters: 200, epoch: 18 | loss: 0.3498607
	speed: 0.0206s/iter; left time: 436.8938s
Epoch: 18 cost time: 5.933627128601074
Epoch: 18, Steps: 258 | Train Loss: 0.4950790 Vali Loss: 0.2613379 Test Loss: 0.3529704
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4565744
	speed: 0.0898s/iter; left time: 1890.3850s
	iters: 200, epoch: 19 | loss: 0.5688365
	speed: 0.0205s/iter; left time: 430.5039s
Epoch: 19 cost time: 6.043891906738281
Epoch: 19, Steps: 258 | Train Loss: 0.4954962 Vali Loss: 0.2612029 Test Loss: 0.3528809
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4119513
	speed: 0.0896s/iter; left time: 1863.9249s
	iters: 200, epoch: 20 | loss: 0.4014834
	speed: 0.0203s/iter; left time: 419.5827s
Epoch: 20 cost time: 5.813099145889282
Epoch: 20, Steps: 258 | Train Loss: 0.4953320 Vali Loss: 0.2612682 Test Loss: 0.3528395
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.5941651
	speed: 0.0891s/iter; left time: 1830.0225s
	iters: 200, epoch: 21 | loss: 0.4341269
	speed: 0.0209s/iter; left time: 427.3973s
Epoch: 21 cost time: 5.913706541061401
Epoch: 21, Steps: 258 | Train Loss: 0.4951648 Vali Loss: 0.2612315 Test Loss: 0.3528524
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.5580637
	speed: 0.0855s/iter; left time: 1735.0565s
	iters: 200, epoch: 22 | loss: 0.6001835
	speed: 0.0209s/iter; left time: 421.7998s
Epoch: 22 cost time: 5.9470062255859375
Epoch: 22, Steps: 258 | Train Loss: 0.4951520 Vali Loss: 0.2613691 Test Loss: 0.3528697
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4210327
	speed: 0.0885s/iter; left time: 1772.2998s
	iters: 200, epoch: 23 | loss: 0.4549128
	speed: 0.0205s/iter; left time: 409.2318s
Epoch: 23 cost time: 5.912919044494629
Epoch: 23, Steps: 258 | Train Loss: 0.4950421 Vali Loss: 0.2610460 Test Loss: 0.3528455
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4599671
	speed: 0.0863s/iter; left time: 1705.4897s
	iters: 200, epoch: 24 | loss: 0.4272065
	speed: 0.0209s/iter; left time: 411.7947s
Epoch: 24 cost time: 5.919549226760864
Epoch: 24, Steps: 258 | Train Loss: 0.4949631 Vali Loss: 0.2612326 Test Loss: 0.3529306
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4017040
	speed: 0.0882s/iter; left time: 1720.4972s
	iters: 200, epoch: 25 | loss: 0.5083485
	speed: 0.0203s/iter; left time: 393.8241s
Epoch: 25 cost time: 6.005268096923828
Epoch: 25, Steps: 258 | Train Loss: 0.4947568 Vali Loss: 0.2613571 Test Loss: 0.3528848
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.5525440
	speed: 0.0887s/iter; left time: 1707.1934s
	iters: 200, epoch: 26 | loss: 0.5442649
	speed: 0.0211s/iter; left time: 403.7754s
Epoch: 26 cost time: 5.98192572593689
Epoch: 26, Steps: 258 | Train Loss: 0.4955379 Vali Loss: 0.2610845 Test Loss: 0.3528908
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3769146
	speed: 0.0907s/iter; left time: 1721.7348s
	iters: 200, epoch: 27 | loss: 0.5772256
	speed: 0.0213s/iter; left time: 402.0053s
Epoch: 27 cost time: 6.00510835647583
Epoch: 27, Steps: 258 | Train Loss: 0.4949459 Vali Loss: 0.2611631 Test Loss: 0.3528453
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.5685955
	speed: 0.0881s/iter; left time: 1649.6386s
	iters: 200, epoch: 28 | loss: 0.5600877
	speed: 0.0205s/iter; left time: 381.7136s
Epoch: 28 cost time: 5.934328079223633
Epoch: 28, Steps: 258 | Train Loss: 0.4949325 Vali Loss: 0.2611886 Test Loss: 0.3528373
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4025182
	speed: 0.0918s/iter; left time: 1695.8652s
	iters: 200, epoch: 29 | loss: 0.4561885
	speed: 0.0208s/iter; left time: 382.3300s
Epoch: 29 cost time: 6.0508527755737305
Epoch: 29, Steps: 258 | Train Loss: 0.4951923 Vali Loss: 0.2612289 Test Loss: 0.3528107
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.5848672
	speed: 0.0886s/iter; left time: 1613.4509s
	iters: 200, epoch: 30 | loss: 0.7451360
	speed: 0.0206s/iter; left time: 373.7506s
Epoch: 30 cost time: 5.9699342250823975
Epoch: 30, Steps: 258 | Train Loss: 0.4951568 Vali Loss: 0.2612938 Test Loss: 0.3527679
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4790159
	speed: 0.0881s/iter; left time: 1581.4765s
	iters: 200, epoch: 31 | loss: 0.5872263
	speed: 0.0210s/iter; left time: 374.9230s
Epoch: 31 cost time: 6.1069793701171875
Epoch: 31, Steps: 258 | Train Loss: 0.4954237 Vali Loss: 0.2610346 Test Loss: 0.3527429
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4395804
	speed: 0.0903s/iter; left time: 1597.9318s
	iters: 200, epoch: 32 | loss: 0.5531592
	speed: 0.0202s/iter; left time: 356.3938s
Epoch: 32 cost time: 6.064080476760864
Epoch: 32, Steps: 258 | Train Loss: 0.4950686 Vali Loss: 0.2611293 Test Loss: 0.3527982
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.6507839
	speed: 0.0906s/iter; left time: 1581.1606s
	iters: 200, epoch: 33 | loss: 0.5710343
	speed: 0.0206s/iter; left time: 356.8254s
Epoch: 33 cost time: 6.017366647720337
Epoch: 33, Steps: 258 | Train Loss: 0.4949918 Vali Loss: 0.2612475 Test Loss: 0.3527852
EarlyStopping counter: 18 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4561295
	speed: 0.0880s/iter; left time: 1513.0116s
	iters: 200, epoch: 34 | loss: 0.4892105
	speed: 0.0203s/iter; left time: 347.0957s
Epoch: 34 cost time: 5.9810216426849365
Epoch: 34, Steps: 258 | Train Loss: 0.4948476 Vali Loss: 0.2612689 Test Loss: 0.3528568
EarlyStopping counter: 19 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4393286
	speed: 0.0856s/iter; left time: 1448.8201s
	iters: 200, epoch: 35 | loss: 0.4909293
	speed: 0.0209s/iter; left time: 351.3446s
Epoch: 35 cost time: 5.941388845443726
Epoch: 35, Steps: 258 | Train Loss: 0.4950199 Vali Loss: 0.2611059 Test Loss: 0.3528300
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_720_720_FITS_ETTm2_ftM_sl720_ll48_pl720_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.3496192693710327, mae:0.37871354818344116, rse:0.4752718210220337, corr:[0.5397453  0.54270875 0.54291403 0.5412939  0.53943914 0.53824097
 0.53786474 0.5380884  0.5385234  0.53877807 0.5386141  0.53804666
 0.537315   0.53665227 0.536232   0.5359903  0.5358252  0.53559804
 0.53514993 0.53441954 0.5335173  0.53256077 0.5317203  0.5311236
 0.5307467  0.53052104 0.5303247  0.5300574  0.52964956 0.52910906
 0.5284722  0.5278707  0.52733845 0.52682096 0.52631104 0.52580404
 0.5252496  0.5246654  0.52403295 0.5233895  0.52276844 0.52217007
 0.5216305  0.5211391  0.5206725  0.5201482  0.5195327  0.5188239
 0.51797783 0.5169815  0.5159123  0.5149085  0.51402885 0.5133219
 0.51280767 0.51246697 0.5122187  0.51197934 0.51171166 0.51138026
 0.51103055 0.5107243  0.51050377 0.51035243 0.5102313  0.5101441
 0.5099712  0.50974524 0.5094625  0.5091163  0.50870705 0.5082638
 0.50783527 0.5074438  0.50706726 0.50669426 0.5063088  0.5058746
 0.5054029  0.5048713  0.5042169  0.5034718  0.5026893  0.50191885
 0.5012212  0.500629   0.5000942  0.49963522 0.4991945  0.498742
 0.49826458 0.4977236  0.4970432  0.49618983 0.49513546 0.49389696
 0.4925527  0.49124736 0.489988   0.4887708  0.48760325 0.48647326
 0.48536763 0.48425597 0.48310974 0.48193422 0.4807672  0.4796721
 0.47862113 0.47761175 0.47664782 0.47571564 0.47488317 0.4741114
 0.47334662 0.472587   0.4718484  0.47109556 0.4703533  0.46956635
 0.46878466 0.46797812 0.4671853  0.46637538 0.46550974 0.46455655
 0.46356463 0.462558   0.46156806 0.4606035  0.45968905 0.4588017
 0.4579599  0.45714834 0.45637804 0.45562336 0.45485088 0.45410714
 0.45342365 0.45284197 0.452366   0.45198938 0.45168367 0.45132625
 0.45085227 0.45018414 0.44944713 0.44868946 0.44798958 0.4473399
 0.44676256 0.44624493 0.44567084 0.44496998 0.44415748 0.4433181
 0.44254366 0.44189173 0.44135225 0.4409841  0.44070238 0.4404581
 0.44018066 0.43987343 0.43954808 0.4392393  0.43893883 0.43865898
 0.43841845 0.43823466 0.43800536 0.43770838 0.43727434 0.4366977
 0.43597752 0.4351565  0.43427905 0.43339306 0.432524   0.43178305
 0.431163   0.43066728 0.43032086 0.43007284 0.42983654 0.42951864
 0.4290867  0.4284574  0.427607   0.4264869  0.4251032  0.42348787
 0.42177844 0.4202636  0.4189203  0.4177056  0.41662258 0.4155958
 0.4146063  0.41359752 0.41252857 0.41136625 0.41009957 0.40877193
 0.40745634 0.40621197 0.40505573 0.40397638 0.40303814 0.40229693
 0.40158924 0.40079266 0.39986    0.39882067 0.3977896  0.3967791
 0.3958068  0.39480844 0.3938129  0.39277026 0.39162317 0.3903619
 0.3890088  0.38765258 0.38644573 0.38535765 0.38441166 0.38366106
 0.38302124 0.38247192 0.38193846 0.38136467 0.38067347 0.3798702
 0.37896731 0.37810025 0.37737793 0.3768761  0.37664497 0.37659058
 0.376591   0.3764419  0.37603354 0.37547565 0.37474364 0.37398833
 0.37333006 0.37285948 0.37255564 0.37233073 0.37217754 0.37201652
 0.3717889  0.3715311  0.37120396 0.37087145 0.37056452 0.3703785
 0.37032497 0.37036806 0.37040913 0.37039447 0.37023342 0.36996672
 0.36960137 0.3691266  0.36862087 0.36815143 0.36772975 0.36732975
 0.36699256 0.36669677 0.36636436 0.3659962  0.36555153 0.3650133
 0.36446965 0.36389118 0.36329684 0.3628159  0.36244875 0.3622318
 0.36209258 0.36196953 0.36178127 0.36142737 0.36086926 0.36002266
 0.35900477 0.3580523  0.35723105 0.35653162 0.3559429  0.35536733
 0.35482693 0.35423893 0.35350773 0.35259444 0.3515595  0.35042107
 0.3493593  0.34842914 0.34781092 0.34745583 0.34739622 0.34753937
 0.34780765 0.34797564 0.34791863 0.34758738 0.34700528 0.34637445
 0.34573677 0.34525573 0.34494147 0.34474578 0.34463432 0.34456423
 0.34441885 0.34419385 0.34392536 0.34362787 0.34332773 0.34310722
 0.34300056 0.3430721  0.3432969  0.3435158  0.34369585 0.3437533
 0.34376433 0.3437147  0.34365517 0.3436619  0.3436816  0.34374657
 0.34377632 0.34361428 0.34329703 0.34295443 0.3426692  0.3424763
 0.3424618  0.34264645 0.34297746 0.34333012 0.34358543 0.3436916
 0.34358972 0.34330484 0.34286684 0.3423164  0.34174263 0.34120306
 0.34075776 0.3404806  0.34030634 0.34028232 0.3402362  0.3401493
 0.33998504 0.33974203 0.33944312 0.3391392  0.33884728 0.33866146
 0.3385321  0.33849218 0.33849472 0.3385332  0.33862957 0.3387412
 0.3388719  0.33906505 0.33929962 0.33951664 0.33963493 0.33965462
 0.33959624 0.3394462  0.33914015 0.33858904 0.33791298 0.3371021
 0.3363107  0.3356282  0.33509684 0.33464995 0.33416888 0.33368137
 0.33312228 0.3324967  0.33182514 0.33114043 0.3304767  0.3297915
 0.32907772 0.32837802 0.3276155  0.32681698 0.32612935 0.3255532
 0.32511714 0.32479134 0.3245873  0.32450125 0.32439303 0.32423413
 0.3239539  0.3236208  0.3232656  0.3228936  0.32258645 0.32232884
 0.32216525 0.3220846  0.32197818 0.32178754 0.3214583  0.3210471
 0.32068214 0.32045773 0.3203805  0.3204609  0.32066494 0.32093856
 0.3212455  0.32150608 0.32173118 0.32191622 0.32209027 0.32226902
 0.3224298  0.32246634 0.3223729  0.3221809  0.32196087 0.32171208
 0.3213775  0.32107806 0.32077318 0.32039157 0.31994385 0.31951085
 0.3190402  0.31860262 0.31820154 0.31781188 0.31747755 0.3171762
 0.31694087 0.31675577 0.31662458 0.31644425 0.31620198 0.31592286
 0.31560662 0.31527668 0.31493837 0.31461093 0.31439373 0.31421086
 0.3140696  0.3139452  0.31380597 0.3136168  0.31333306 0.3129688
 0.31257492 0.31218997 0.3118222  0.3114676  0.31118622 0.3109311
 0.3106731  0.31029978 0.30981982 0.3091574  0.30833298 0.3073494
 0.3062306  0.30510357 0.30395505 0.30281514 0.30173337 0.30073076
 0.29978976 0.29897472 0.298271   0.29773557 0.29727814 0.29677215
 0.29611796 0.29534236 0.29445648 0.2934276  0.29234517 0.29129547
 0.29036963 0.28952223 0.28873113 0.28806338 0.2874805  0.28705734
 0.2866847  0.28629956 0.28589806 0.28544354 0.284989   0.2845076
 0.2840014  0.2834735  0.28291237 0.282349   0.28185943 0.28148654
 0.28121293 0.2809732  0.280872   0.2808128  0.28069723 0.28047988
 0.28012177 0.27968526 0.27919585 0.2787393  0.2784259  0.27825785
 0.27816793 0.27812555 0.27805355 0.27792284 0.27775484 0.27753597
 0.2772195  0.2768192  0.27647027 0.27620125 0.2760459  0.27601716
 0.276087   0.2762305  0.27635366 0.27643645 0.27641398 0.27623352
 0.2759155  0.27555948 0.27521807 0.2749106  0.27457193 0.27421466
 0.27378032 0.27330998 0.27285847 0.27250612 0.2721693  0.271931
 0.27179137 0.27179033 0.2718362  0.2718384  0.27176216 0.27160984
 0.27142012 0.27123374 0.27112278 0.2711056  0.27116618 0.2712619
 0.2712904  0.27112594 0.27060044 0.26967272 0.26839083 0.26677725
 0.26498213 0.2633642  0.2620792  0.26115152 0.26043114 0.25977123
 0.25906962 0.25827774 0.25742573 0.2565582  0.25571638 0.25497973
 0.25434616 0.25376293 0.25327444 0.2528384  0.25243226 0.25208285
 0.2517607  0.25139174 0.2510023  0.25051707 0.24997884 0.24941294
 0.2488214  0.24827318 0.24773803 0.24720864 0.24679445 0.24654327
 0.24638894 0.2463204  0.2463529  0.24636173 0.24634811 0.2462967
 0.2462856  0.24618503 0.24604426 0.2459503  0.24590142 0.24585144
 0.24579038 0.24579157 0.24585597 0.24602723 0.24634531 0.24680834
 0.24730179 0.24768506 0.2478803  0.24796748 0.2480067  0.24805486
 0.248094   0.24815454 0.24827199 0.24825595 0.24822783 0.24814008
 0.24799626 0.24783769 0.24760379 0.24742205 0.24715853 0.24686237
 0.24651946 0.24629195 0.24614431 0.24597333 0.2458971  0.24573538
 0.24552993 0.24524179 0.24491504 0.2445961  0.24442396 0.2442941
 0.2443175  0.2444006  0.24440953 0.24442062 0.2444559  0.24446844
 0.24444585 0.24455595 0.24474855 0.2450353  0.24545816 0.24591501
 0.2462563  0.24643023 0.24633251 0.24580725 0.24484248 0.2435713
 0.24218392 0.24087453 0.23976864 0.23888305 0.23825361 0.23776989
 0.23731096 0.23677003 0.23628964 0.23576419 0.23521447 0.23460102
 0.23394573 0.23330334 0.23271921 0.23219518 0.23180941 0.23142926
 0.2310082  0.23047346 0.22976062 0.22906774 0.2284177  0.22784795
 0.22741728 0.22707857 0.22684932 0.22656524 0.22618076 0.2256316
 0.22502622 0.2242697  0.22348188 0.22280452 0.2223233  0.22207515
 0.22192562 0.22177419 0.22143774 0.22091949 0.22009504 0.2192123
 0.21857585 0.21848306 0.2189665  0.21954316 0.2190392  0.21585391]
