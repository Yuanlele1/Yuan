Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=58, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_360_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_360_336_FITS_ETTm2_ftM_sl360_ll48_pl336_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33865
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=58, out_features=112, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  5820416.0
params:  6608.0
Trainable parameters:  6608
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3317548
	speed: 0.0422s/iter; left time: 1110.8798s
	iters: 200, epoch: 1 | loss: 0.3899599
	speed: 0.0344s/iter; left time: 900.0078s
Epoch: 1 cost time: 9.854338884353638
Epoch: 1, Steps: 264 | Train Loss: 0.4767884 Vali Loss: 0.2188854 Test Loss: 0.2913644
Validation loss decreased (inf --> 0.218885).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4178445
	speed: 0.1773s/iter; left time: 4617.5584s
	iters: 200, epoch: 2 | loss: 0.4809781
	speed: 0.0423s/iter; left time: 1097.3157s
Epoch: 2 cost time: 10.667173385620117
Epoch: 2, Steps: 264 | Train Loss: 0.4200287 Vali Loss: 0.2091506 Test Loss: 0.2818376
Validation loss decreased (0.218885 --> 0.209151).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5501580
	speed: 0.1547s/iter; left time: 3986.6299s
	iters: 200, epoch: 3 | loss: 0.3523323
	speed: 0.0295s/iter; left time: 756.4904s
Epoch: 3 cost time: 9.550758123397827
Epoch: 3, Steps: 264 | Train Loss: 0.4088146 Vali Loss: 0.2054513 Test Loss: 0.2781647
Validation loss decreased (0.209151 --> 0.205451).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4778741
	speed: 0.1422s/iter; left time: 3628.2741s
	iters: 200, epoch: 4 | loss: 0.6054237
	speed: 0.0426s/iter; left time: 1083.2157s
Epoch: 4 cost time: 12.413772821426392
Epoch: 4, Steps: 264 | Train Loss: 0.4038282 Vali Loss: 0.2031348 Test Loss: 0.2761830
Validation loss decreased (0.205451 --> 0.203135).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4790649
	speed: 0.2714s/iter; left time: 6851.8877s
	iters: 200, epoch: 5 | loss: 0.4407680
	speed: 0.0305s/iter; left time: 766.4353s
Epoch: 5 cost time: 11.144136667251587
Epoch: 5, Steps: 264 | Train Loss: 0.4005466 Vali Loss: 0.2018562 Test Loss: 0.2749830
Validation loss decreased (0.203135 --> 0.201856).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3432315
	speed: 0.1885s/iter; left time: 4708.1238s
	iters: 200, epoch: 6 | loss: 0.4316312
	speed: 0.0322s/iter; left time: 801.4282s
Epoch: 6 cost time: 10.36494755744934
Epoch: 6, Steps: 264 | Train Loss: 0.3978138 Vali Loss: 0.2011226 Test Loss: 0.2742347
Validation loss decreased (0.201856 --> 0.201123).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4155006
	speed: 0.1309s/iter; left time: 3236.0076s
	iters: 200, epoch: 7 | loss: 0.3705356
	speed: 0.0351s/iter; left time: 864.8504s
Epoch: 7 cost time: 7.757704973220825
Epoch: 7, Steps: 264 | Train Loss: 0.3961801 Vali Loss: 0.2007458 Test Loss: 0.2736033
Validation loss decreased (0.201123 --> 0.200746).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3191906
	speed: 0.1134s/iter; left time: 2773.1408s
	iters: 200, epoch: 8 | loss: 0.3408472
	speed: 0.0232s/iter; left time: 564.9299s
Epoch: 8 cost time: 7.241279602050781
Epoch: 8, Steps: 264 | Train Loss: 0.3952203 Vali Loss: 0.2002117 Test Loss: 0.2733029
Validation loss decreased (0.200746 --> 0.200212).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.5266058
	speed: 0.1675s/iter; left time: 4050.7113s
	iters: 200, epoch: 9 | loss: 0.3647167
	speed: 0.0392s/iter; left time: 943.9407s
Epoch: 9 cost time: 11.836611986160278
Epoch: 9, Steps: 264 | Train Loss: 0.3943363 Vali Loss: 0.1995430 Test Loss: 0.2729571
Validation loss decreased (0.200212 --> 0.199543).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.6181886
	speed: 0.1783s/iter; left time: 4266.3833s
	iters: 200, epoch: 10 | loss: 0.3250510
	speed: 0.0230s/iter; left time: 548.6807s
Epoch: 10 cost time: 8.102187871932983
Epoch: 10, Steps: 264 | Train Loss: 0.3930778 Vali Loss: 0.1994029 Test Loss: 0.2727783
Validation loss decreased (0.199543 --> 0.199403).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4141376
	speed: 0.1427s/iter; left time: 3375.3398s
	iters: 200, epoch: 11 | loss: 0.4287096
	speed: 0.0309s/iter; left time: 727.0977s
Epoch: 11 cost time: 9.08986783027649
Epoch: 11, Steps: 264 | Train Loss: 0.3930409 Vali Loss: 0.1990579 Test Loss: 0.2726739
Validation loss decreased (0.199403 --> 0.199058).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3397926
	speed: 0.1498s/iter; left time: 3505.3758s
	iters: 200, epoch: 12 | loss: 0.3487809
	speed: 0.0353s/iter; left time: 823.0166s
Epoch: 12 cost time: 10.113230466842651
Epoch: 12, Steps: 264 | Train Loss: 0.3920688 Vali Loss: 0.1989560 Test Loss: 0.2724034
Validation loss decreased (0.199058 --> 0.198956).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2892775
	speed: 0.1857s/iter; left time: 4294.7044s
	iters: 200, epoch: 13 | loss: 0.4105550
	speed: 0.0415s/iter; left time: 956.4360s
Epoch: 13 cost time: 12.25315809249878
Epoch: 13, Steps: 264 | Train Loss: 0.3915893 Vali Loss: 0.1988838 Test Loss: 0.2722718
Validation loss decreased (0.198956 --> 0.198884).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.5721999
	speed: 0.1638s/iter; left time: 3746.0679s
	iters: 200, epoch: 14 | loss: 0.6338595
	speed: 0.0374s/iter; left time: 851.7505s
Epoch: 14 cost time: 8.656535625457764
Epoch: 14, Steps: 264 | Train Loss: 0.3917092 Vali Loss: 0.1986440 Test Loss: 0.2722887
Validation loss decreased (0.198884 --> 0.198644).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4614911
	speed: 0.1293s/iter; left time: 2921.8000s
	iters: 200, epoch: 15 | loss: 0.3488215
	speed: 0.0321s/iter; left time: 723.4403s
Epoch: 15 cost time: 8.15203070640564
Epoch: 15, Steps: 264 | Train Loss: 0.3916126 Vali Loss: 0.1985134 Test Loss: 0.2722563
Validation loss decreased (0.198644 --> 0.198513).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4647976
	speed: 0.1243s/iter; left time: 2777.4075s
	iters: 200, epoch: 16 | loss: 0.3197489
	speed: 0.0427s/iter; left time: 949.0357s
Epoch: 16 cost time: 10.576602697372437
Epoch: 16, Steps: 264 | Train Loss: 0.3914561 Vali Loss: 0.1986070 Test Loss: 0.2721704
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4960619
	speed: 0.2051s/iter; left time: 4528.0883s
	iters: 200, epoch: 17 | loss: 0.4683858
	speed: 0.0593s/iter; left time: 1303.0350s
Epoch: 17 cost time: 13.79391622543335
Epoch: 17, Steps: 264 | Train Loss: 0.3911372 Vali Loss: 0.1986054 Test Loss: 0.2720951
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3239996
	speed: 0.2740s/iter; left time: 5977.8255s
	iters: 200, epoch: 18 | loss: 0.2701473
	speed: 0.0339s/iter; left time: 736.3603s
Epoch: 18 cost time: 12.33484411239624
Epoch: 18, Steps: 264 | Train Loss: 0.3907266 Vali Loss: 0.1984399 Test Loss: 0.2720681
Validation loss decreased (0.198513 --> 0.198440).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4571498
	speed: 0.1315s/iter; left time: 2833.8955s
	iters: 200, epoch: 19 | loss: 0.4028029
	speed: 0.0344s/iter; left time: 738.3200s
Epoch: 19 cost time: 7.618955612182617
Epoch: 19, Steps: 264 | Train Loss: 0.3909168 Vali Loss: 0.1983626 Test Loss: 0.2719897
Validation loss decreased (0.198440 --> 0.198363).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3179250
	speed: 0.1624s/iter; left time: 3455.7110s
	iters: 200, epoch: 20 | loss: 0.4260889
	speed: 0.0341s/iter; left time: 723.3532s
Epoch: 20 cost time: 9.320861339569092
Epoch: 20, Steps: 264 | Train Loss: 0.3909248 Vali Loss: 0.1983522 Test Loss: 0.2719651
Validation loss decreased (0.198363 --> 0.198352).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4035368
	speed: 0.1625s/iter; left time: 3415.4078s
	iters: 200, epoch: 21 | loss: 0.5956194
	speed: 0.0348s/iter; left time: 727.8348s
Epoch: 21 cost time: 9.175684690475464
Epoch: 21, Steps: 264 | Train Loss: 0.3905886 Vali Loss: 0.1983951 Test Loss: 0.2719323
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2936658
	speed: 0.1651s/iter; left time: 3427.6468s
	iters: 200, epoch: 22 | loss: 0.5274341
	speed: 0.0381s/iter; left time: 786.5643s
Epoch: 22 cost time: 8.523349523544312
Epoch: 22, Steps: 264 | Train Loss: 0.3903449 Vali Loss: 0.1980750 Test Loss: 0.2719829
Validation loss decreased (0.198352 --> 0.198075).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4168921
	speed: 0.1423s/iter; left time: 2916.4299s
	iters: 200, epoch: 23 | loss: 0.4495974
	speed: 0.0207s/iter; left time: 421.9757s
Epoch: 23 cost time: 8.221922874450684
Epoch: 23, Steps: 264 | Train Loss: 0.3904283 Vali Loss: 0.1982446 Test Loss: 0.2719081
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2764861
	speed: 0.1620s/iter; left time: 3277.0341s
	iters: 200, epoch: 24 | loss: 0.3650291
	speed: 0.0299s/iter; left time: 601.7685s
Epoch: 24 cost time: 9.263913869857788
Epoch: 24, Steps: 264 | Train Loss: 0.3905124 Vali Loss: 0.1983144 Test Loss: 0.2718831
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4851807
	speed: 0.1501s/iter; left time: 2996.8803s
	iters: 200, epoch: 25 | loss: 0.4001576
	speed: 0.0390s/iter; left time: 775.4706s
Epoch: 25 cost time: 9.615050315856934
Epoch: 25, Steps: 264 | Train Loss: 0.3901438 Vali Loss: 0.1982716 Test Loss: 0.2719148
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4985150
	speed: 0.1735s/iter; left time: 3418.3686s
	iters: 200, epoch: 26 | loss: 0.2844780
	speed: 0.0445s/iter; left time: 871.6135s
Epoch: 26 cost time: 10.329933166503906
Epoch: 26, Steps: 264 | Train Loss: 0.3901131 Vali Loss: 0.1980294 Test Loss: 0.2718619
Validation loss decreased (0.198075 --> 0.198029).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.5233563
	speed: 0.1330s/iter; left time: 2585.7184s
	iters: 200, epoch: 27 | loss: 0.3749414
	speed: 0.0249s/iter; left time: 480.9264s
Epoch: 27 cost time: 9.900154829025269
Epoch: 27, Steps: 264 | Train Loss: 0.3899959 Vali Loss: 0.1981349 Test Loss: 0.2718412
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4624835
	speed: 0.1686s/iter; left time: 3232.0798s
	iters: 200, epoch: 28 | loss: 0.3950390
	speed: 0.0441s/iter; left time: 841.7908s
Epoch: 28 cost time: 10.962570428848267
Epoch: 28, Steps: 264 | Train Loss: 0.3894122 Vali Loss: 0.1980906 Test Loss: 0.2718064
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3513322
	speed: 0.1840s/iter; left time: 3480.1008s
	iters: 200, epoch: 29 | loss: 0.5352607
	speed: 0.0420s/iter; left time: 790.6356s
Epoch: 29 cost time: 11.64158034324646
Epoch: 29, Steps: 264 | Train Loss: 0.3895876 Vali Loss: 0.1981754 Test Loss: 0.2717779
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2878463
	speed: 0.2054s/iter; left time: 3829.7968s
	iters: 200, epoch: 30 | loss: 0.3805504
	speed: 0.0474s/iter; left time: 878.2650s
Epoch: 30 cost time: 15.24145245552063
Epoch: 30, Steps: 264 | Train Loss: 0.3900638 Vali Loss: 0.1982192 Test Loss: 0.2718358
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3263730
	speed: 0.2178s/iter; left time: 4002.9074s
	iters: 200, epoch: 31 | loss: 0.4824293
	speed: 0.0317s/iter; left time: 580.0793s
Epoch: 31 cost time: 8.42494821548462
Epoch: 31, Steps: 264 | Train Loss: 0.3895452 Vali Loss: 0.1982032 Test Loss: 0.2717766
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3010121
	speed: 0.1476s/iter; left time: 2673.8311s
	iters: 200, epoch: 32 | loss: 0.4379586
	speed: 0.0377s/iter; left time: 678.3903s
Epoch: 32 cost time: 12.578555822372437
Epoch: 32, Steps: 264 | Train Loss: 0.3899210 Vali Loss: 0.1979977 Test Loss: 0.2717594
Validation loss decreased (0.198029 --> 0.197998).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2864375
	speed: 0.2211s/iter; left time: 3947.9039s
	iters: 200, epoch: 33 | loss: 0.3212993
	speed: 0.0430s/iter; left time: 763.8903s
Epoch: 33 cost time: 12.395406007766724
Epoch: 33, Steps: 264 | Train Loss: 0.3900001 Vali Loss: 0.1980986 Test Loss: 0.2717538
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4149557
	speed: 0.1924s/iter; left time: 3383.5404s
	iters: 200, epoch: 34 | loss: 0.3012909
	speed: 0.0326s/iter; left time: 570.9444s
Epoch: 34 cost time: 10.619662284851074
Epoch: 34, Steps: 264 | Train Loss: 0.3896322 Vali Loss: 0.1980760 Test Loss: 0.2717483
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3661075
	speed: 0.1360s/iter; left time: 2356.4899s
	iters: 200, epoch: 35 | loss: 0.3546604
	speed: 0.0222s/iter; left time: 383.2448s
Epoch: 35 cost time: 8.69478726387024
Epoch: 35, Steps: 264 | Train Loss: 0.3895111 Vali Loss: 0.1980973 Test Loss: 0.2717272
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4120322
	speed: 0.1407s/iter; left time: 2400.0995s
	iters: 200, epoch: 36 | loss: 0.3655002
	speed: 0.0270s/iter; left time: 457.5217s
Epoch: 36 cost time: 7.9595441818237305
Epoch: 36, Steps: 264 | Train Loss: 0.3891451 Vali Loss: 0.1980663 Test Loss: 0.2717244
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3896953
	speed: 0.1660s/iter; left time: 2787.5851s
	iters: 200, epoch: 37 | loss: 0.3014538
	speed: 0.0459s/iter; left time: 766.1736s
Epoch: 37 cost time: 9.857908010482788
Epoch: 37, Steps: 264 | Train Loss: 0.3896183 Vali Loss: 0.1980360 Test Loss: 0.2717280
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3066486
	speed: 0.2136s/iter; left time: 3531.8297s
	iters: 200, epoch: 38 | loss: 0.4133315
	speed: 0.0520s/iter; left time: 855.2258s
Epoch: 38 cost time: 13.409102439880371
Epoch: 38, Steps: 264 | Train Loss: 0.3896254 Vali Loss: 0.1980448 Test Loss: 0.2716946
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3309094
	speed: 0.1658s/iter; left time: 2697.1332s
	iters: 200, epoch: 39 | loss: 0.5489216
	speed: 0.0236s/iter; left time: 381.5395s
Epoch: 39 cost time: 8.346071243286133
Epoch: 39, Steps: 264 | Train Loss: 0.3894012 Vali Loss: 0.1981562 Test Loss: 0.2716908
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2957962
	speed: 0.1482s/iter; left time: 2371.6695s
	iters: 200, epoch: 40 | loss: 0.3331986
	speed: 0.0226s/iter; left time: 359.9036s
Epoch: 40 cost time: 7.566913366317749
Epoch: 40, Steps: 264 | Train Loss: 0.3894826 Vali Loss: 0.1980575 Test Loss: 0.2716970
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.4123398
	speed: 0.1731s/iter; left time: 2725.4416s
	iters: 200, epoch: 41 | loss: 0.3716197
	speed: 0.0405s/iter; left time: 633.0673s
Epoch: 41 cost time: 11.632568120956421
Epoch: 41, Steps: 264 | Train Loss: 0.3890793 Vali Loss: 0.1980986 Test Loss: 0.2716831
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.5109320
	speed: 0.1774s/iter; left time: 2746.3433s
	iters: 200, epoch: 42 | loss: 0.3292684
	speed: 0.0560s/iter; left time: 861.6196s
Epoch: 42 cost time: 12.316178560256958
Epoch: 42, Steps: 264 | Train Loss: 0.3889478 Vali Loss: 0.1980136 Test Loss: 0.2716697
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3995397
	speed: 0.2376s/iter; left time: 3615.3273s
	iters: 200, epoch: 43 | loss: 0.3675854
	speed: 0.0459s/iter; left time: 693.9309s
Epoch: 43 cost time: 13.940565586090088
Epoch: 43, Steps: 264 | Train Loss: 0.3894750 Vali Loss: 0.1980125 Test Loss: 0.2716767
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.4406523
	speed: 0.1983s/iter; left time: 2963.8564s
	iters: 200, epoch: 44 | loss: 0.3349753
	speed: 0.0556s/iter; left time: 826.3036s
Epoch: 44 cost time: 12.201815843582153
Epoch: 44, Steps: 264 | Train Loss: 0.3894178 Vali Loss: 0.1978299 Test Loss: 0.2716820
Validation loss decreased (0.197998 --> 0.197830).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.3991092
	speed: 0.1702s/iter; left time: 2499.9063s
	iters: 200, epoch: 45 | loss: 0.2953210
	speed: 0.0306s/iter; left time: 446.7455s
Epoch: 45 cost time: 9.824152946472168
Epoch: 45, Steps: 264 | Train Loss: 0.3895667 Vali Loss: 0.1979578 Test Loss: 0.2716686
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.4641540
	speed: 0.1461s/iter; left time: 2106.6390s
	iters: 200, epoch: 46 | loss: 0.2420139
	speed: 0.0391s/iter; left time: 560.0840s
Epoch: 46 cost time: 10.05033826828003
Epoch: 46, Steps: 264 | Train Loss: 0.3893951 Vali Loss: 0.1980290 Test Loss: 0.2716668
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2944714
	speed: 0.1839s/iter; left time: 2603.5707s
	iters: 200, epoch: 47 | loss: 0.2712129
	speed: 0.0432s/iter; left time: 607.7329s
Epoch: 47 cost time: 12.064334154129028
Epoch: 47, Steps: 264 | Train Loss: 0.3891486 Vali Loss: 0.1978181 Test Loss: 0.2716631
Validation loss decreased (0.197830 --> 0.197818).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.4774855
	speed: 0.1537s/iter; left time: 2136.0415s
	iters: 200, epoch: 48 | loss: 0.3908594
	speed: 0.0227s/iter; left time: 313.4265s
Epoch: 48 cost time: 7.034876823425293
Epoch: 48, Steps: 264 | Train Loss: 0.3891554 Vali Loss: 0.1979186 Test Loss: 0.2716601
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.6238947
	speed: 0.1393s/iter; left time: 1898.7460s
	iters: 200, epoch: 49 | loss: 0.3850868
	speed: 0.0207s/iter; left time: 279.5263s
Epoch: 49 cost time: 6.746167182922363
Epoch: 49, Steps: 264 | Train Loss: 0.3894249 Vali Loss: 0.1978669 Test Loss: 0.2716581
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.3453086
	speed: 0.1389s/iter; left time: 1856.7100s
	iters: 200, epoch: 50 | loss: 0.3443067
	speed: 0.0419s/iter; left time: 555.4639s
Epoch: 50 cost time: 10.850110054016113
Epoch: 50, Steps: 264 | Train Loss: 0.3893573 Vali Loss: 0.1978531 Test Loss: 0.2716439
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.3730173
	speed: 0.1826s/iter; left time: 2392.6690s
	iters: 200, epoch: 51 | loss: 0.4614282
	speed: 0.0313s/iter; left time: 406.3079s
Epoch: 51 cost time: 10.94553017616272
Epoch: 51, Steps: 264 | Train Loss: 0.3890913 Vali Loss: 0.1978898 Test Loss: 0.2716576
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.4216259
	speed: 0.1822s/iter; left time: 2338.7267s
	iters: 200, epoch: 52 | loss: 0.5260342
	speed: 0.0385s/iter; left time: 490.7377s
Epoch: 52 cost time: 11.185208320617676
Epoch: 52, Steps: 264 | Train Loss: 0.3894908 Vali Loss: 0.1979351 Test Loss: 0.2716468
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.4122497
	speed: 0.1478s/iter; left time: 1858.2873s
	iters: 200, epoch: 53 | loss: 0.3243151
	speed: 0.0274s/iter; left time: 342.3809s
Epoch: 53 cost time: 9.50800895690918
Epoch: 53, Steps: 264 | Train Loss: 0.3893903 Vali Loss: 0.1979683 Test Loss: 0.2716536
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.4657555
	speed: 0.1294s/iter; left time: 1593.2982s
	iters: 200, epoch: 54 | loss: 0.3780900
	speed: 0.0404s/iter; left time: 493.8248s
Epoch: 54 cost time: 8.990722417831421
Epoch: 54, Steps: 264 | Train Loss: 0.3890396 Vali Loss: 0.1979115 Test Loss: 0.2716389
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.4504545
	speed: 0.2263s/iter; left time: 2725.8926s
	iters: 200, epoch: 55 | loss: 0.3699323
	speed: 0.0535s/iter; left time: 639.5430s
Epoch: 55 cost time: 17.437935829162598
Epoch: 55, Steps: 264 | Train Loss: 0.3878256 Vali Loss: 0.1979258 Test Loss: 0.2716355
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.3000416
	speed: 0.2218s/iter; left time: 2613.2063s
	iters: 200, epoch: 56 | loss: 0.3694913
	speed: 0.0230s/iter; left time: 268.7205s
Epoch: 56 cost time: 9.516852855682373
Epoch: 56, Steps: 264 | Train Loss: 0.3888587 Vali Loss: 0.1977806 Test Loss: 0.2716413
Validation loss decreased (0.197818 --> 0.197781).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.3208918
	speed: 0.1701s/iter; left time: 1959.1594s
	iters: 200, epoch: 57 | loss: 0.3938807
	speed: 0.0258s/iter; left time: 294.9022s
Epoch: 57 cost time: 8.912901639938354
Epoch: 57, Steps: 264 | Train Loss: 0.3892760 Vali Loss: 0.1977382 Test Loss: 0.2716375
Validation loss decreased (0.197781 --> 0.197738).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.4300314
	speed: 0.1412s/iter; left time: 1589.0860s
	iters: 200, epoch: 58 | loss: 0.3172981
	speed: 0.0233s/iter; left time: 260.3711s
Epoch: 58 cost time: 8.438857316970825
Epoch: 58, Steps: 264 | Train Loss: 0.3892934 Vali Loss: 0.1976839 Test Loss: 0.2716372
Validation loss decreased (0.197738 --> 0.197684).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.3462945
	speed: 0.1636s/iter; left time: 1797.5453s
	iters: 200, epoch: 59 | loss: 0.3810974
	speed: 0.0252s/iter; left time: 274.8726s
Epoch: 59 cost time: 7.908891201019287
Epoch: 59, Steps: 264 | Train Loss: 0.3885907 Vali Loss: 0.1978759 Test Loss: 0.2716331
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.3849303
	speed: 0.1649s/iter; left time: 1768.3459s
	iters: 200, epoch: 60 | loss: 0.4289428
	speed: 0.0386s/iter; left time: 410.4153s
Epoch: 60 cost time: 9.555585861206055
Epoch: 60, Steps: 264 | Train Loss: 0.3890757 Vali Loss: 0.1978866 Test Loss: 0.2716256
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.3748679
	speed: 0.1847s/iter; left time: 1932.5587s
	iters: 200, epoch: 61 | loss: 0.3657785
	speed: 0.0260s/iter; left time: 269.3911s
Epoch: 61 cost time: 9.874495267868042
Epoch: 61, Steps: 264 | Train Loss: 0.3892415 Vali Loss: 0.1979704 Test Loss: 0.2716219
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.4341323
	speed: 0.1541s/iter; left time: 1571.6984s
	iters: 200, epoch: 62 | loss: 0.4599248
	speed: 0.0316s/iter; left time: 318.6553s
Epoch: 62 cost time: 9.471271276473999
Epoch: 62, Steps: 264 | Train Loss: 0.3892070 Vali Loss: 0.1979326 Test Loss: 0.2716281
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.2972450
	speed: 0.1878s/iter; left time: 1865.5794s
	iters: 200, epoch: 63 | loss: 0.3104495
	speed: 0.0392s/iter; left time: 385.4614s
Epoch: 63 cost time: 14.022820234298706
Epoch: 63, Steps: 264 | Train Loss: 0.3889863 Vali Loss: 0.1979952 Test Loss: 0.2716244
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.5638734
	speed: 0.1908s/iter; left time: 1844.9214s
	iters: 200, epoch: 64 | loss: 0.2684284
	speed: 0.0450s/iter; left time: 430.7442s
Epoch: 64 cost time: 10.546475887298584
Epoch: 64, Steps: 264 | Train Loss: 0.3890182 Vali Loss: 0.1978973 Test Loss: 0.2716193
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.4020558
	speed: 0.1653s/iter; left time: 1554.2503s
	iters: 200, epoch: 65 | loss: 0.4635267
	speed: 0.0209s/iter; left time: 194.8658s
Epoch: 65 cost time: 7.670001029968262
Epoch: 65, Steps: 264 | Train Loss: 0.3887660 Vali Loss: 0.1979514 Test Loss: 0.2716209
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.4307703
	speed: 0.1328s/iter; left time: 1213.7183s
	iters: 200, epoch: 66 | loss: 0.3191729
	speed: 0.0292s/iter; left time: 264.1073s
Epoch: 66 cost time: 7.598671913146973
Epoch: 66, Steps: 264 | Train Loss: 0.3880877 Vali Loss: 0.1979247 Test Loss: 0.2716200
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.3252215
	speed: 0.1716s/iter; left time: 1523.3104s
	iters: 200, epoch: 67 | loss: 0.4027649
	speed: 0.0443s/iter; left time: 389.1394s
Epoch: 67 cost time: 14.53291940689087
Epoch: 67, Steps: 264 | Train Loss: 0.3889823 Vali Loss: 0.1978872 Test Loss: 0.2716139
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.4835640
	speed: 0.2853s/iter; left time: 2457.4065s
	iters: 200, epoch: 68 | loss: 0.3801015
	speed: 0.0374s/iter; left time: 318.4687s
Epoch: 68 cost time: 13.391669511795044
Epoch: 68, Steps: 264 | Train Loss: 0.3894861 Vali Loss: 0.1978332 Test Loss: 0.2716193
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.3578895
	speed: 0.1581s/iter; left time: 1319.6671s
	iters: 200, epoch: 69 | loss: 0.4283226
	speed: 0.0291s/iter; left time: 239.8210s
Epoch: 69 cost time: 7.912611961364746
Epoch: 69, Steps: 264 | Train Loss: 0.3889643 Vali Loss: 0.1979773 Test Loss: 0.2716190
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.4507845
	speed: 0.1389s/iter; left time: 1122.6185s
	iters: 200, epoch: 70 | loss: 0.4529908
	speed: 0.0268s/iter; left time: 213.8678s
Epoch: 70 cost time: 6.602988243103027
Epoch: 70, Steps: 264 | Train Loss: 0.3894995 Vali Loss: 0.1978331 Test Loss: 0.2716182
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.2863427
	speed: 0.1507s/iter; left time: 1178.2952s
	iters: 200, epoch: 71 | loss: 0.3498942
	speed: 0.0438s/iter; left time: 338.1252s
Epoch: 71 cost time: 12.510815143585205
Epoch: 71, Steps: 264 | Train Loss: 0.3891225 Vali Loss: 0.1978779 Test Loss: 0.2716172
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.4014929
	speed: 0.1972s/iter; left time: 1490.1773s
	iters: 200, epoch: 72 | loss: 0.4337023
	speed: 0.0323s/iter; left time: 241.0805s
Epoch: 72 cost time: 9.30907654762268
Epoch: 72, Steps: 264 | Train Loss: 0.3891986 Vali Loss: 0.1978967 Test Loss: 0.2716143
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.3567956
	speed: 0.2006s/iter; left time: 1463.3027s
	iters: 200, epoch: 73 | loss: 0.3932140
	speed: 0.0317s/iter; left time: 227.9076s
Epoch: 73 cost time: 9.638893604278564
Epoch: 73, Steps: 264 | Train Loss: 0.3891958 Vali Loss: 0.1979416 Test Loss: 0.2716151
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.3453810
	speed: 0.1540s/iter; left time: 1082.4411s
	iters: 200, epoch: 74 | loss: 0.2507014
	speed: 0.0397s/iter; left time: 275.0047s
Epoch: 74 cost time: 11.150377988815308
Epoch: 74, Steps: 264 | Train Loss: 0.3891077 Vali Loss: 0.1978932 Test Loss: 0.2716149
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.5969828
	speed: 0.1767s/iter; left time: 1195.2783s
	iters: 200, epoch: 75 | loss: 0.3061445
	speed: 0.0362s/iter; left time: 241.0316s
Epoch: 75 cost time: 12.369325399398804
Epoch: 75, Steps: 264 | Train Loss: 0.3889982 Vali Loss: 0.1979710 Test Loss: 0.2716166
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.3985184
	speed: 0.1911s/iter; left time: 1242.1819s
	iters: 200, epoch: 76 | loss: 0.3391891
	speed: 0.0436s/iter; left time: 279.2959s
Epoch: 76 cost time: 13.362512350082397
Epoch: 76, Steps: 264 | Train Loss: 0.3887816 Vali Loss: 0.1979849 Test Loss: 0.2716129
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.3443925
	speed: 0.2063s/iter; left time: 1286.5746s
	iters: 200, epoch: 77 | loss: 0.2834494
	speed: 0.0320s/iter; left time: 196.1799s
Epoch: 77 cost time: 8.690436840057373
Epoch: 77, Steps: 264 | Train Loss: 0.3890933 Vali Loss: 0.1980166 Test Loss: 0.2716122
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.2843460
	speed: 0.1558s/iter; left time: 930.7719s
	iters: 200, epoch: 78 | loss: 0.3998196
	speed: 0.0308s/iter; left time: 180.8504s
Epoch: 78 cost time: 9.204112529754639
Epoch: 78, Steps: 264 | Train Loss: 0.3890348 Vali Loss: 0.1979619 Test Loss: 0.2716129
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_360_336_FITS_ETTm2_ftM_sl360_ll48_pl336_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.27293121814727783, mae:0.32593363523483276, rse:0.4219755232334137, corr:[0.5566227  0.5590655  0.55427426 0.5521602  0.55322164 0.5544786
 0.5540414  0.55248517 0.5514437  0.55157846 0.5522472  0.5525098
 0.5520086  0.5512017  0.55075544 0.55079865 0.5509469  0.55066335
 0.5498685  0.5489562  0.54838187 0.5482547  0.54824394 0.54805183
 0.54756486 0.54696053 0.5465287  0.5463092  0.54610085 0.5456635
 0.5450221  0.54442865 0.5440381  0.5438468  0.5436447  0.5432214
 0.5425112  0.5416811  0.5409793  0.54048866 0.54013926 0.5398084
 0.5393377  0.5387126  0.5380319  0.53736216 0.53676236 0.5361477
 0.53540903 0.53458047 0.53372955 0.5330236  0.5324149  0.53179073
 0.53109586 0.5303821  0.5296914  0.52911836 0.5287127  0.52841634
 0.5281335  0.5278439  0.5275801  0.5273447  0.5271484  0.5269906
 0.5268018  0.52654606 0.52628726 0.52610284 0.5259747  0.5258547
 0.52566934 0.525402   0.5250483  0.5246329  0.5242297  0.52381706
 0.5233752  0.5228788  0.52237225 0.52183557 0.52131164 0.5207816
 0.52030176 0.51985914 0.5193944  0.51893306 0.51848406 0.5180414
 0.51759565 0.5171179  0.51652235 0.51575947 0.51477265 0.51350707
 0.51198876 0.5104229  0.50895846 0.50761735 0.50637627 0.5052361
 0.5041479  0.5029925  0.50176483 0.5005512  0.4994598  0.49851996
 0.49772373 0.49696445 0.49622425 0.495462   0.4947009  0.4939457
 0.4932003  0.49247557 0.49178275 0.4910964  0.49046743 0.4898518
 0.48923677 0.48856384 0.48790863 0.48727286 0.48663902 0.48601195
 0.48537692 0.48464617 0.4837774  0.48285243 0.4820139  0.48130557
 0.48069507 0.4801312  0.47951835 0.47886577 0.4781458  0.47749293
 0.4769074  0.4763659  0.4757628  0.47503057 0.47423372 0.47342983
 0.47269785 0.47200412 0.47130397 0.47051975 0.46963406 0.4687371
 0.4680236  0.46755427 0.46714348 0.46662956 0.46595377 0.46523833
 0.4645672  0.4640454  0.46364814 0.46335632 0.46301532 0.4625788
 0.46216667 0.46185184 0.46171358 0.461668   0.46148443 0.4612061
 0.46088    0.46066126 0.46055552 0.46045604 0.4602311  0.45983395
 0.45931906 0.45881793 0.4584183  0.45815074 0.45794898 0.45772368
 0.45734367 0.4567696  0.4561572  0.4556167  0.4552365  0.45502856
 0.4548822  0.45468578 0.4542807  0.4535429  0.45246607 0.45101228
 0.44933924 0.4477414  0.44624186 0.44477856 0.4433722  0.44195193
 0.44049633 0.4389912  0.43753162 0.43622795 0.43515483 0.43423346
 0.43331018 0.43228567 0.4310866  0.4299104  0.42892855 0.42825443
 0.42772192 0.42712083 0.42640868 0.4256457  0.42484167 0.4240787
 0.42333153 0.42236817 0.4213632  0.4203914  0.4194342  0.41845927
 0.4175473  0.41666567 0.41591242 0.4151143  0.41424295 0.4132416
 0.41216767 0.41114566 0.41015506 0.40926886 0.4085138  0.40793413
 0.40740606 0.4068586  0.40631008 0.40575176 0.4052045  0.40468952
 0.40411165 0.40342012 0.4027285  0.40229774 0.40198383 0.401793
 0.4017802  0.40180218 0.40168035 0.40140715 0.40110072 0.40094888
 0.4008516  0.40092093 0.40095785 0.40089947 0.40073168 0.40043414
 0.4001751  0.39992377 0.39976558 0.39969203 0.39961597 0.39959162
 0.39960104 0.39955524 0.39939272 0.39902306 0.3986496  0.3985336
 0.39854866 0.39852604 0.39827177 0.39788905 0.3974637  0.39723104
 0.39717928 0.39715305 0.39697048 0.3965216  0.39592022 0.39552838
 0.39549327 0.3957323  0.39591163 0.39566383 0.3947655  0.39341518
 0.39197174 0.3908938  0.39001277 0.3890564  0.38802746 0.3871595
 0.38661847 0.3863511  0.3860955  0.3854236  0.38447765 0.38361895
 0.38316935 0.3830728  0.3830533  0.3827149  0.38190377 0.38097873
 0.38054043 0.38059497 0.3808245  0.38094568 0.38074347 0.38043925
 0.3802221  0.38021767 0.38011423 0.37961736 0.37868765 0.37766606
 0.37711674 0.37712458 0.37714562 0.37669167 0.3757691  0.374984
 0.37495625 0.3756548  0.37615448 0.37549278 0.37391254 0.37309378
 0.37437573 0.37668708 0.37750873 0.37550953 0.3735241  0.37919506]
