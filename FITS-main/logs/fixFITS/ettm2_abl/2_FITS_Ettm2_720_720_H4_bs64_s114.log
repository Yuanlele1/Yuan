Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=42, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_720_720_FITS_ETTm2_ftM_sl720_ll48_pl720_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=42, out_features=84, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3161088.0
params:  3612.0
Trainable parameters:  3612
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3959976
	speed: 0.0269s/iter; left time: 691.1228s
	iters: 200, epoch: 1 | loss: 0.3483616
	speed: 0.0207s/iter; left time: 528.8008s
Epoch: 1 cost time: 5.911828994750977
Epoch: 1, Steps: 258 | Train Loss: 0.4692208 Vali Loss: 0.3049981 Test Loss: 0.4040268
Validation loss decreased (inf --> 0.304998).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3420593
	speed: 0.0744s/iter; left time: 1892.2081s
	iters: 200, epoch: 2 | loss: 0.3122115
	speed: 0.0206s/iter; left time: 521.2613s
Epoch: 2 cost time: 5.360698699951172
Epoch: 2, Steps: 258 | Train Loss: 0.3431914 Vali Loss: 0.2865755 Test Loss: 0.3804769
Validation loss decreased (0.304998 --> 0.286575).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3595525
	speed: 0.0766s/iter; left time: 1928.2804s
	iters: 200, epoch: 3 | loss: 0.2564398
	speed: 0.0189s/iter; left time: 474.6208s
Epoch: 3 cost time: 5.2767438888549805
Epoch: 3, Steps: 258 | Train Loss: 0.3065364 Vali Loss: 0.2795309 Test Loss: 0.3717619
Validation loss decreased (0.286575 --> 0.279531).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2872777
	speed: 0.0755s/iter; left time: 1882.5254s
	iters: 200, epoch: 4 | loss: 0.2787427
	speed: 0.0194s/iter; left time: 481.5920s
Epoch: 4 cost time: 5.434656143188477
Epoch: 4, Steps: 258 | Train Loss: 0.2892835 Vali Loss: 0.2752534 Test Loss: 0.3663468
Validation loss decreased (0.279531 --> 0.275253).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2876422
	speed: 0.0760s/iter; left time: 1875.9658s
	iters: 200, epoch: 5 | loss: 0.2512214
	speed: 0.0194s/iter; left time: 476.1700s
Epoch: 5 cost time: 5.358773946762085
Epoch: 5, Steps: 258 | Train Loss: 0.2796564 Vali Loss: 0.2719319 Test Loss: 0.3628044
Validation loss decreased (0.275253 --> 0.271932).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2960438
	speed: 0.0754s/iter; left time: 1841.7270s
	iters: 200, epoch: 6 | loss: 0.2543565
	speed: 0.0199s/iter; left time: 483.2442s
Epoch: 6 cost time: 5.425879001617432
Epoch: 6, Steps: 258 | Train Loss: 0.2740314 Vali Loss: 0.2701956 Test Loss: 0.3605364
Validation loss decreased (0.271932 --> 0.270196).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4450627
	speed: 0.0748s/iter; left time: 1807.2440s
	iters: 200, epoch: 7 | loss: 0.2186537
	speed: 0.0200s/iter; left time: 480.6992s
Epoch: 7 cost time: 5.295198917388916
Epoch: 7, Steps: 258 | Train Loss: 0.2708932 Vali Loss: 0.2687904 Test Loss: 0.3590929
Validation loss decreased (0.270196 --> 0.268790).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2015674
	speed: 0.0746s/iter; left time: 1782.5792s
	iters: 200, epoch: 8 | loss: 0.2238209
	speed: 0.0187s/iter; left time: 445.3719s
Epoch: 8 cost time: 5.124872207641602
Epoch: 8, Steps: 258 | Train Loss: 0.2687259 Vali Loss: 0.2681740 Test Loss: 0.3578830
Validation loss decreased (0.268790 --> 0.268174).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2270578
	speed: 0.0748s/iter; left time: 1768.8375s
	iters: 200, epoch: 9 | loss: 0.3023430
	speed: 0.0199s/iter; left time: 467.6290s
Epoch: 9 cost time: 5.341965675354004
Epoch: 9, Steps: 258 | Train Loss: 0.2675548 Vali Loss: 0.2669969 Test Loss: 0.3574264
Validation loss decreased (0.268174 --> 0.266997).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2579001
	speed: 0.0748s/iter; left time: 1748.2687s
	iters: 200, epoch: 10 | loss: 0.2439933
	speed: 0.0193s/iter; left time: 449.7178s
Epoch: 10 cost time: 5.336033821105957
Epoch: 10, Steps: 258 | Train Loss: 0.2671031 Vali Loss: 0.2666583 Test Loss: 0.3569344
Validation loss decreased (0.266997 --> 0.266658).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2204253
	speed: 0.0760s/iter; left time: 1756.5781s
	iters: 200, epoch: 11 | loss: 0.2091280
	speed: 0.0188s/iter; left time: 432.0933s
Epoch: 11 cost time: 5.266249656677246
Epoch: 11, Steps: 258 | Train Loss: 0.2668394 Vali Loss: 0.2661492 Test Loss: 0.3568511
Validation loss decreased (0.266658 --> 0.266149).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2809961
	speed: 0.0748s/iter; left time: 1710.8992s
	iters: 200, epoch: 12 | loss: 0.2967681
	speed: 0.0187s/iter; left time: 424.7453s
Epoch: 12 cost time: 5.158350944519043
Epoch: 12, Steps: 258 | Train Loss: 0.2666149 Vali Loss: 0.2664589 Test Loss: 0.3564497
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3241726
	speed: 0.0754s/iter; left time: 1703.5225s
	iters: 200, epoch: 13 | loss: 0.2936649
	speed: 0.0193s/iter; left time: 433.2402s
Epoch: 13 cost time: 5.3305699825286865
Epoch: 13, Steps: 258 | Train Loss: 0.2662423 Vali Loss: 0.2660919 Test Loss: 0.3565232
Validation loss decreased (0.266149 --> 0.266092).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2872182
	speed: 0.0734s/iter; left time: 1639.2164s
	iters: 200, epoch: 14 | loss: 0.2739943
	speed: 0.0188s/iter; left time: 418.0962s
Epoch: 14 cost time: 5.1566972732543945
Epoch: 14, Steps: 258 | Train Loss: 0.2661867 Vali Loss: 0.2659842 Test Loss: 0.3563876
Validation loss decreased (0.266092 --> 0.265984).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2500000
	speed: 0.0750s/iter; left time: 1656.1699s
	iters: 200, epoch: 15 | loss: 0.3632614
	speed: 0.0182s/iter; left time: 399.6909s
Epoch: 15 cost time: 5.212685585021973
Epoch: 15, Steps: 258 | Train Loss: 0.2660542 Vali Loss: 0.2660248 Test Loss: 0.3563401
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2930906
	speed: 0.0752s/iter; left time: 1641.6493s
	iters: 200, epoch: 16 | loss: 0.2872309
	speed: 0.0186s/iter; left time: 404.4271s
Epoch: 16 cost time: 5.101110219955444
Epoch: 16, Steps: 258 | Train Loss: 0.2659367 Vali Loss: 0.2659868 Test Loss: 0.3561332
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1937532
	speed: 0.0734s/iter; left time: 1584.3858s
	iters: 200, epoch: 17 | loss: 0.2281114
	speed: 0.0183s/iter; left time: 392.5522s
Epoch: 17 cost time: 5.126027822494507
Epoch: 17, Steps: 258 | Train Loss: 0.2661876 Vali Loss: 0.2658150 Test Loss: 0.3562751
Validation loss decreased (0.265984 --> 0.265815).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1983202
	speed: 0.0740s/iter; left time: 1576.6148s
	iters: 200, epoch: 18 | loss: 0.3367155
	speed: 0.0181s/iter; left time: 384.4557s
Epoch: 18 cost time: 5.0606303215026855
Epoch: 18, Steps: 258 | Train Loss: 0.2659193 Vali Loss: 0.2658385 Test Loss: 0.3561421
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2337408
	speed: 0.0739s/iter; left time: 1556.0558s
	iters: 200, epoch: 19 | loss: 0.2903042
	speed: 0.0203s/iter; left time: 425.7311s
Epoch: 19 cost time: 5.333730459213257
Epoch: 19, Steps: 258 | Train Loss: 0.2659489 Vali Loss: 0.2658181 Test Loss: 0.3560748
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2736508
	speed: 0.0722s/iter; left time: 1501.0239s
	iters: 200, epoch: 20 | loss: 0.2522784
	speed: 0.0190s/iter; left time: 393.5303s
Epoch: 20 cost time: 5.187911033630371
Epoch: 20, Steps: 258 | Train Loss: 0.2658569 Vali Loss: 0.2659847 Test Loss: 0.3561173
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2925351
	speed: 0.0735s/iter; left time: 1509.5407s
	iters: 200, epoch: 21 | loss: 0.2057562
	speed: 0.0191s/iter; left time: 390.8217s
Epoch: 21 cost time: 5.311945915222168
Epoch: 21, Steps: 258 | Train Loss: 0.2660444 Vali Loss: 0.2656940 Test Loss: 0.3560725
Validation loss decreased (0.265815 --> 0.265694).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3050208
	speed: 0.0747s/iter; left time: 1515.4842s
	iters: 200, epoch: 22 | loss: 0.2248582
	speed: 0.0198s/iter; left time: 399.3651s
Epoch: 22 cost time: 5.333723783493042
Epoch: 22, Steps: 258 | Train Loss: 0.2658245 Vali Loss: 0.2657296 Test Loss: 0.3560176
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2704554
	speed: 0.0765s/iter; left time: 1532.3424s
	iters: 200, epoch: 23 | loss: 0.2826579
	speed: 0.0191s/iter; left time: 379.9536s
Epoch: 23 cost time: 5.325273036956787
Epoch: 23, Steps: 258 | Train Loss: 0.2660968 Vali Loss: 0.2657451 Test Loss: 0.3559256
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3038619
	speed: 0.0742s/iter; left time: 1467.5261s
	iters: 200, epoch: 24 | loss: 0.3478159
	speed: 0.0189s/iter; left time: 371.2191s
Epoch: 24 cost time: 5.187868356704712
Epoch: 24, Steps: 258 | Train Loss: 0.2660545 Vali Loss: 0.2657406 Test Loss: 0.3559159
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2955984
	speed: 0.0743s/iter; left time: 1449.8840s
	iters: 200, epoch: 25 | loss: 0.2085292
	speed: 0.0193s/iter; left time: 375.5557s
Epoch: 25 cost time: 5.236307144165039
Epoch: 25, Steps: 258 | Train Loss: 0.2657592 Vali Loss: 0.2655023 Test Loss: 0.3559615
Validation loss decreased (0.265694 --> 0.265502).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2086144
	speed: 0.0739s/iter; left time: 1422.5166s
	iters: 200, epoch: 26 | loss: 0.2459767
	speed: 0.0186s/iter; left time: 356.6832s
Epoch: 26 cost time: 5.121495008468628
Epoch: 26, Steps: 258 | Train Loss: 0.2657107 Vali Loss: 0.2656948 Test Loss: 0.3560540
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2622039
	speed: 0.0739s/iter; left time: 1403.8317s
	iters: 200, epoch: 27 | loss: 0.2610508
	speed: 0.0196s/iter; left time: 370.2302s
Epoch: 27 cost time: 5.358098745346069
Epoch: 27, Steps: 258 | Train Loss: 0.2659899 Vali Loss: 0.2657171 Test Loss: 0.3559906
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2556165
	speed: 0.0759s/iter; left time: 1421.3216s
	iters: 200, epoch: 28 | loss: 0.3326105
	speed: 0.0191s/iter; left time: 355.6883s
Epoch: 28 cost time: 5.360362768173218
Epoch: 28, Steps: 258 | Train Loss: 0.2658084 Vali Loss: 0.2657703 Test Loss: 0.3559710
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2970731
	speed: 0.0756s/iter; left time: 1396.7405s
	iters: 200, epoch: 29 | loss: 0.2358729
	speed: 0.0187s/iter; left time: 343.2942s
Epoch: 29 cost time: 5.314306974411011
Epoch: 29, Steps: 258 | Train Loss: 0.2658164 Vali Loss: 0.2658980 Test Loss: 0.3559555
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2340505
	speed: 0.0747s/iter; left time: 1360.1788s
	iters: 200, epoch: 30 | loss: 0.2162492
	speed: 0.0194s/iter; left time: 351.0123s
Epoch: 30 cost time: 5.2947142124176025
Epoch: 30, Steps: 258 | Train Loss: 0.2659179 Vali Loss: 0.2658245 Test Loss: 0.3559294
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2070909
	speed: 0.0770s/iter; left time: 1383.7595s
	iters: 200, epoch: 31 | loss: 0.2413027
	speed: 0.0193s/iter; left time: 344.0011s
Epoch: 31 cost time: 5.378187894821167
Epoch: 31, Steps: 258 | Train Loss: 0.2658284 Vali Loss: 0.2656831 Test Loss: 0.3558614
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2132508
	speed: 0.0742s/iter; left time: 1313.8750s
	iters: 200, epoch: 32 | loss: 0.2712222
	speed: 0.0196s/iter; left time: 344.3709s
Epoch: 32 cost time: 5.352283000946045
Epoch: 32, Steps: 258 | Train Loss: 0.2658410 Vali Loss: 0.2656468 Test Loss: 0.3558771
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3027420
	speed: 0.0758s/iter; left time: 1321.5351s
	iters: 200, epoch: 33 | loss: 0.2925162
	speed: 0.0188s/iter; left time: 326.6677s
Epoch: 33 cost time: 5.205090045928955
Epoch: 33, Steps: 258 | Train Loss: 0.2658669 Vali Loss: 0.2656635 Test Loss: 0.3559368
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2046702
	speed: 0.0739s/iter; left time: 1269.3042s
	iters: 200, epoch: 34 | loss: 0.2634405
	speed: 0.0189s/iter; left time: 323.0430s
Epoch: 34 cost time: 5.246680736541748
Epoch: 34, Steps: 258 | Train Loss: 0.2657004 Vali Loss: 0.2655713 Test Loss: 0.3558688
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2340508
	speed: 0.0723s/iter; left time: 1223.9055s
	iters: 200, epoch: 35 | loss: 0.2303216
	speed: 0.0191s/iter; left time: 321.5174s
Epoch: 35 cost time: 5.197761297225952
Epoch: 35, Steps: 258 | Train Loss: 0.2656825 Vali Loss: 0.2657746 Test Loss: 0.3558610
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2537372
	speed: 0.0739s/iter; left time: 1231.4379s
	iters: 200, epoch: 36 | loss: 0.2444338
	speed: 0.0195s/iter; left time: 323.6228s
Epoch: 36 cost time: 5.1479761600494385
Epoch: 36, Steps: 258 | Train Loss: 0.2653272 Vali Loss: 0.2650785 Test Loss: 0.3558442
Validation loss decreased (0.265502 --> 0.265078).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2780319
	speed: 0.0742s/iter; left time: 1218.2440s
	iters: 200, epoch: 37 | loss: 0.2795410
	speed: 0.0185s/iter; left time: 301.0235s
Epoch: 37 cost time: 5.278750896453857
Epoch: 37, Steps: 258 | Train Loss: 0.2656733 Vali Loss: 0.2657347 Test Loss: 0.3558542
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2304797
	speed: 0.0744s/iter; left time: 1201.6387s
	iters: 200, epoch: 38 | loss: 0.2461520
	speed: 0.0193s/iter; left time: 310.1927s
Epoch: 38 cost time: 5.321942567825317
Epoch: 38, Steps: 258 | Train Loss: 0.2659222 Vali Loss: 0.2657309 Test Loss: 0.3558379
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1927487
	speed: 0.0741s/iter; left time: 1178.7078s
	iters: 200, epoch: 39 | loss: 0.2483891
	speed: 0.0194s/iter; left time: 306.2452s
Epoch: 39 cost time: 5.2787230014801025
Epoch: 39, Steps: 258 | Train Loss: 0.2658109 Vali Loss: 0.2654321 Test Loss: 0.3558561
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2692305
	speed: 0.0753s/iter; left time: 1176.9882s
	iters: 200, epoch: 40 | loss: 0.2808891
	speed: 0.0188s/iter; left time: 292.8845s
Epoch: 40 cost time: 5.319841384887695
Epoch: 40, Steps: 258 | Train Loss: 0.2656879 Vali Loss: 0.2654357 Test Loss: 0.3558721
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2343495
	speed: 0.0760s/iter; left time: 1168.2887s
	iters: 200, epoch: 41 | loss: 0.2612426
	speed: 0.0187s/iter; left time: 285.1687s
Epoch: 41 cost time: 5.285355091094971
Epoch: 41, Steps: 258 | Train Loss: 0.2656273 Vali Loss: 0.2657062 Test Loss: 0.3558351
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2298344
	speed: 0.0743s/iter; left time: 1123.0344s
	iters: 200, epoch: 42 | loss: 0.2507566
	speed: 0.0186s/iter; left time: 279.1211s
Epoch: 42 cost time: 5.108806610107422
Epoch: 42, Steps: 258 | Train Loss: 0.2658935 Vali Loss: 0.2656026 Test Loss: 0.3558341
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3120444
	speed: 0.0748s/iter; left time: 1112.1101s
	iters: 200, epoch: 43 | loss: 0.1930863
	speed: 0.0193s/iter; left time: 285.0918s
Epoch: 43 cost time: 5.320049285888672
Epoch: 43, Steps: 258 | Train Loss: 0.2659602 Vali Loss: 0.2657045 Test Loss: 0.3558007
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2103083
	speed: 0.0737s/iter; left time: 1075.9235s
	iters: 200, epoch: 44 | loss: 0.2550578
	speed: 0.0185s/iter; left time: 267.6687s
Epoch: 44 cost time: 5.107245922088623
Epoch: 44, Steps: 258 | Train Loss: 0.2656161 Vali Loss: 0.2655558 Test Loss: 0.3558196
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2694442
	speed: 0.0737s/iter; left time: 1057.8575s
	iters: 200, epoch: 45 | loss: 0.2433583
	speed: 0.0192s/iter; left time: 273.1595s
Epoch: 45 cost time: 5.1407928466796875
Epoch: 45, Steps: 258 | Train Loss: 0.2658920 Vali Loss: 0.2655149 Test Loss: 0.3558219
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.3323123
	speed: 0.0742s/iter; left time: 1045.7367s
	iters: 200, epoch: 46 | loss: 0.2393319
	speed: 0.0194s/iter; left time: 271.2217s
Epoch: 46 cost time: 5.2989771366119385
Epoch: 46, Steps: 258 | Train Loss: 0.2656347 Vali Loss: 0.2653935 Test Loss: 0.3558493
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2643282
	speed: 0.0758s/iter; left time: 1048.4120s
	iters: 200, epoch: 47 | loss: 0.2523905
	speed: 0.0186s/iter; left time: 255.6914s
Epoch: 47 cost time: 5.278136491775513
Epoch: 47, Steps: 258 | Train Loss: 0.2658951 Vali Loss: 0.2655913 Test Loss: 0.3558154
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.4213492
	speed: 0.0750s/iter; left time: 1018.2175s
	iters: 200, epoch: 48 | loss: 0.3086569
	speed: 0.0190s/iter; left time: 256.4346s
Epoch: 48 cost time: 5.1943511962890625
Epoch: 48, Steps: 258 | Train Loss: 0.2655139 Vali Loss: 0.2657806 Test Loss: 0.3558117
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2336340
	speed: 0.0745s/iter; left time: 991.5178s
	iters: 200, epoch: 49 | loss: 0.2520809
	speed: 0.0190s/iter; left time: 250.8896s
Epoch: 49 cost time: 5.234984636306763
Epoch: 49, Steps: 258 | Train Loss: 0.2656247 Vali Loss: 0.2655934 Test Loss: 0.3558118
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2370402
	speed: 0.0762s/iter; left time: 995.5553s
	iters: 200, epoch: 50 | loss: 0.1682132
	speed: 0.0188s/iter; left time: 244.1418s
Epoch: 50 cost time: 5.359442472457886
Epoch: 50, Steps: 258 | Train Loss: 0.2659051 Vali Loss: 0.2652185 Test Loss: 0.3558121
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2846354
	speed: 0.0757s/iter; left time: 968.4727s
	iters: 200, epoch: 51 | loss: 0.2666875
	speed: 0.0187s/iter; left time: 236.9692s
Epoch: 51 cost time: 5.274707078933716
Epoch: 51, Steps: 258 | Train Loss: 0.2655409 Vali Loss: 0.2656326 Test Loss: 0.3558033
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2154091
	speed: 0.0765s/iter; left time: 959.9009s
	iters: 200, epoch: 52 | loss: 0.2282841
	speed: 0.0190s/iter; left time: 236.3599s
Epoch: 52 cost time: 5.182543516159058
Epoch: 52, Steps: 258 | Train Loss: 0.2655350 Vali Loss: 0.2656381 Test Loss: 0.3558135
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2118155
	speed: 0.0743s/iter; left time: 913.1221s
	iters: 200, epoch: 53 | loss: 0.2875711
	speed: 0.0190s/iter; left time: 231.4033s
Epoch: 53 cost time: 5.338952302932739
Epoch: 53, Steps: 258 | Train Loss: 0.2657859 Vali Loss: 0.2657894 Test Loss: 0.3558085
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.3505796
	speed: 0.0740s/iter; left time: 890.0177s
	iters: 200, epoch: 54 | loss: 0.2770115
	speed: 0.0196s/iter; left time: 233.2155s
Epoch: 54 cost time: 5.257077693939209
Epoch: 54, Steps: 258 | Train Loss: 0.2657143 Vali Loss: 0.2656991 Test Loss: 0.3558129
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2513676
	speed: 0.0747s/iter; left time: 878.6468s
	iters: 200, epoch: 55 | loss: 0.2792164
	speed: 0.0194s/iter; left time: 226.6615s
Epoch: 55 cost time: 5.361870765686035
Epoch: 55, Steps: 258 | Train Loss: 0.2657189 Vali Loss: 0.2656222 Test Loss: 0.3558034
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2662174
	speed: 0.0750s/iter; left time: 863.7330s
	iters: 200, epoch: 56 | loss: 0.2417910
	speed: 0.0189s/iter; left time: 215.4107s
Epoch: 56 cost time: 5.130306720733643
Epoch: 56, Steps: 258 | Train Loss: 0.2656048 Vali Loss: 0.2655984 Test Loss: 0.3558189
EarlyStopping counter: 20 out of 20
Early stopping
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=42, out_features=84, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3161088.0
params:  3612.0
Trainable parameters:  3612
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5032052
	speed: 0.0230s/iter; left time: 590.1526s
	iters: 200, epoch: 1 | loss: 0.4337290
	speed: 0.0183s/iter; left time: 468.7785s
Epoch: 1 cost time: 5.16508674621582
Epoch: 1, Steps: 258 | Train Loss: 0.5019468 Vali Loss: 0.2643569 Test Loss: 0.3549561
Validation loss decreased (inf --> 0.264357).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5323957
	speed: 0.0781s/iter; left time: 1987.5146s
	iters: 200, epoch: 2 | loss: 0.3859109
	speed: 0.0186s/iter; left time: 471.1170s
Epoch: 2 cost time: 5.265770196914673
Epoch: 2, Steps: 258 | Train Loss: 0.5002639 Vali Loss: 0.2638884 Test Loss: 0.3548584
Validation loss decreased (0.264357 --> 0.263888).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4700419
	speed: 0.0769s/iter; left time: 1937.2168s
	iters: 200, epoch: 3 | loss: 0.3902858
	speed: 0.0189s/iter; left time: 473.9385s
Epoch: 3 cost time: 5.223853588104248
Epoch: 3, Steps: 258 | Train Loss: 0.5003161 Vali Loss: 0.2637239 Test Loss: 0.3545409
Validation loss decreased (0.263888 --> 0.263724).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4633859
	speed: 0.0763s/iter; left time: 1900.7211s
	iters: 200, epoch: 4 | loss: 0.3994495
	speed: 0.0189s/iter; left time: 470.2539s
Epoch: 4 cost time: 5.244823694229126
Epoch: 4, Steps: 258 | Train Loss: 0.4998206 Vali Loss: 0.2633933 Test Loss: 0.3543829
Validation loss decreased (0.263724 --> 0.263393).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.5208144
	speed: 0.0758s/iter; left time: 1869.5875s
	iters: 200, epoch: 5 | loss: 0.5101724
	speed: 0.0191s/iter; left time: 470.3302s
Epoch: 5 cost time: 5.20027494430542
Epoch: 5, Steps: 258 | Train Loss: 0.4989944 Vali Loss: 0.2636151 Test Loss: 0.3540632
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.6070589
	speed: 0.0776s/iter; left time: 1893.9693s
	iters: 200, epoch: 6 | loss: 0.4969824
	speed: 0.0195s/iter; left time: 473.8962s
Epoch: 6 cost time: 5.420335054397583
Epoch: 6, Steps: 258 | Train Loss: 0.4991366 Vali Loss: 0.2634301 Test Loss: 0.3541405
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4207827
	speed: 0.0775s/iter; left time: 1870.6765s
	iters: 200, epoch: 7 | loss: 0.4775302
	speed: 0.0192s/iter; left time: 462.9937s
Epoch: 7 cost time: 5.2184529304504395
Epoch: 7, Steps: 258 | Train Loss: 0.4992137 Vali Loss: 0.2633166 Test Loss: 0.3541152
Validation loss decreased (0.263393 --> 0.263317).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.5108771
	speed: 0.0778s/iter; left time: 1860.0159s
	iters: 200, epoch: 8 | loss: 0.4824473
	speed: 0.0190s/iter; left time: 451.4173s
Epoch: 8 cost time: 5.291991472244263
Epoch: 8, Steps: 258 | Train Loss: 0.4987517 Vali Loss: 0.2630433 Test Loss: 0.3539853
Validation loss decreased (0.263317 --> 0.263043).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4458431
	speed: 0.0771s/iter; left time: 1821.3524s
	iters: 200, epoch: 9 | loss: 0.4821779
	speed: 0.0188s/iter; left time: 443.1357s
Epoch: 9 cost time: 5.305176258087158
Epoch: 9, Steps: 258 | Train Loss: 0.4986789 Vali Loss: 0.2630818 Test Loss: 0.3541563
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.5776565
	speed: 0.0758s/iter; left time: 1771.2124s
	iters: 200, epoch: 10 | loss: 0.5621280
	speed: 0.0189s/iter; left time: 440.8774s
Epoch: 10 cost time: 5.241435527801514
Epoch: 10, Steps: 258 | Train Loss: 0.4989383 Vali Loss: 0.2629995 Test Loss: 0.3539711
Validation loss decreased (0.263043 --> 0.262999).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4210698
	speed: 0.0768s/iter; left time: 1775.9830s
	iters: 200, epoch: 11 | loss: 0.5139430
	speed: 0.0188s/iter; left time: 432.3929s
Epoch: 11 cost time: 5.263458013534546
Epoch: 11, Steps: 258 | Train Loss: 0.4991132 Vali Loss: 0.2625511 Test Loss: 0.3541515
Validation loss decreased (0.262999 --> 0.262551).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3796507
	speed: 0.0773s/iter; left time: 1766.4015s
	iters: 200, epoch: 12 | loss: 0.5385670
	speed: 0.0186s/iter; left time: 423.3036s
Epoch: 12 cost time: 5.1767590045928955
Epoch: 12, Steps: 258 | Train Loss: 0.4986342 Vali Loss: 0.2628941 Test Loss: 0.3541861
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.6159375
	speed: 0.0759s/iter; left time: 1715.1082s
	iters: 200, epoch: 13 | loss: 0.6179549
	speed: 0.0177s/iter; left time: 399.0253s
Epoch: 13 cost time: 5.026134252548218
Epoch: 13, Steps: 258 | Train Loss: 0.4983200 Vali Loss: 0.2628249 Test Loss: 0.3540300
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.7034040
	speed: 0.0776s/iter; left time: 1734.0291s
	iters: 200, epoch: 14 | loss: 0.5676438
	speed: 0.0190s/iter; left time: 423.0857s
Epoch: 14 cost time: 5.256489038467407
Epoch: 14, Steps: 258 | Train Loss: 0.4985928 Vali Loss: 0.2626112 Test Loss: 0.3539773
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4851724
	speed: 0.0782s/iter; left time: 1726.6383s
	iters: 200, epoch: 15 | loss: 0.6324521
	speed: 0.0186s/iter; left time: 408.5772s
Epoch: 15 cost time: 5.355432748794556
Epoch: 15, Steps: 258 | Train Loss: 0.4979896 Vali Loss: 0.2630339 Test Loss: 0.3539109
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4958774
	speed: 0.0762s/iter; left time: 1663.0220s
	iters: 200, epoch: 16 | loss: 0.4646502
	speed: 0.0185s/iter; left time: 402.5903s
Epoch: 16 cost time: 5.187298059463501
Epoch: 16, Steps: 258 | Train Loss: 0.4987552 Vali Loss: 0.2626545 Test Loss: 0.3540857
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3934902
	speed: 0.0769s/iter; left time: 1659.1511s
	iters: 200, epoch: 17 | loss: 0.4571718
	speed: 0.0186s/iter; left time: 400.4568s
Epoch: 17 cost time: 5.195986986160278
Epoch: 17, Steps: 258 | Train Loss: 0.4986183 Vali Loss: 0.2626518 Test Loss: 0.3539726
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.5025609
	speed: 0.0755s/iter; left time: 1610.0199s
	iters: 200, epoch: 18 | loss: 0.5395578
	speed: 0.0188s/iter; left time: 398.8429s
Epoch: 18 cost time: 5.280688524246216
Epoch: 18, Steps: 258 | Train Loss: 0.4983149 Vali Loss: 0.2625681 Test Loss: 0.3539751
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.5758712
	speed: 0.0773s/iter; left time: 1627.0396s
	iters: 200, epoch: 19 | loss: 0.3392253
	speed: 0.0187s/iter; left time: 391.0059s
Epoch: 19 cost time: 5.289761543273926
Epoch: 19, Steps: 258 | Train Loss: 0.4984996 Vali Loss: 0.2629215 Test Loss: 0.3539580
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4490658
	speed: 0.0773s/iter; left time: 1608.4940s
	iters: 200, epoch: 20 | loss: 0.5774052
	speed: 0.0193s/iter; left time: 400.2173s
Epoch: 20 cost time: 5.29386305809021
Epoch: 20, Steps: 258 | Train Loss: 0.4986822 Vali Loss: 0.2622756 Test Loss: 0.3540049
Validation loss decreased (0.262551 --> 0.262276).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4500356
	speed: 0.0763s/iter; left time: 1567.4608s
	iters: 200, epoch: 21 | loss: 0.4685721
	speed: 0.0191s/iter; left time: 389.6212s
Epoch: 21 cost time: 5.208195924758911
Epoch: 21, Steps: 258 | Train Loss: 0.4984645 Vali Loss: 0.2626866 Test Loss: 0.3538887
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4687520
	speed: 0.0763s/iter; left time: 1547.0535s
	iters: 200, epoch: 22 | loss: 0.5325955
	speed: 0.0192s/iter; left time: 387.4814s
Epoch: 22 cost time: 5.282566070556641
Epoch: 22, Steps: 258 | Train Loss: 0.4983469 Vali Loss: 0.2628189 Test Loss: 0.3539339
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4294164
	speed: 0.0780s/iter; left time: 1561.7368s
	iters: 200, epoch: 23 | loss: 0.3043440
	speed: 0.0186s/iter; left time: 370.6271s
Epoch: 23 cost time: 5.230327367782593
Epoch: 23, Steps: 258 | Train Loss: 0.4979459 Vali Loss: 0.2626290 Test Loss: 0.3539377
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4711986
	speed: 0.0771s/iter; left time: 1523.2070s
	iters: 200, epoch: 24 | loss: 0.3999168
	speed: 0.0190s/iter; left time: 374.2275s
Epoch: 24 cost time: 5.218315839767456
Epoch: 24, Steps: 258 | Train Loss: 0.4983367 Vali Loss: 0.2626480 Test Loss: 0.3538865
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.5818102
	speed: 0.0757s/iter; left time: 1475.9168s
	iters: 200, epoch: 25 | loss: 0.4755880
	speed: 0.0190s/iter; left time: 368.6012s
Epoch: 25 cost time: 5.257215738296509
Epoch: 25, Steps: 258 | Train Loss: 0.4979568 Vali Loss: 0.2624616 Test Loss: 0.3539455
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3824345
	speed: 0.0756s/iter; left time: 1455.1511s
	iters: 200, epoch: 26 | loss: 0.4964026
	speed: 0.0195s/iter; left time: 373.1686s
Epoch: 26 cost time: 5.3140318393707275
Epoch: 26, Steps: 258 | Train Loss: 0.4981713 Vali Loss: 0.2626344 Test Loss: 0.3539495
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3780836
	speed: 0.0769s/iter; left time: 1459.6855s
	iters: 200, epoch: 27 | loss: 0.5049471
	speed: 0.0193s/iter; left time: 364.4872s
Epoch: 27 cost time: 5.35338282585144
Epoch: 27, Steps: 258 | Train Loss: 0.4980653 Vali Loss: 0.2626962 Test Loss: 0.3539079
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.5198348
	speed: 0.0785s/iter; left time: 1470.6973s
	iters: 200, epoch: 28 | loss: 0.6047132
	speed: 0.0193s/iter; left time: 359.7383s
Epoch: 28 cost time: 5.449718475341797
Epoch: 28, Steps: 258 | Train Loss: 0.4975296 Vali Loss: 0.2627792 Test Loss: 0.3539494
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4739650
	speed: 0.0766s/iter; left time: 1414.4720s
	iters: 200, epoch: 29 | loss: 0.5053698
	speed: 0.0186s/iter; left time: 341.9956s
Epoch: 29 cost time: 5.219227313995361
Epoch: 29, Steps: 258 | Train Loss: 0.4982437 Vali Loss: 0.2626983 Test Loss: 0.3539334
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3762270
	speed: 0.0752s/iter; left time: 1369.8680s
	iters: 200, epoch: 30 | loss: 0.5388023
	speed: 0.0189s/iter; left time: 341.9497s
Epoch: 30 cost time: 5.131909608840942
Epoch: 30, Steps: 258 | Train Loss: 0.4979646 Vali Loss: 0.2624701 Test Loss: 0.3539555
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4892473
	speed: 0.0770s/iter; left time: 1382.5991s
	iters: 200, epoch: 31 | loss: 0.3323344
	speed: 0.0186s/iter; left time: 332.0652s
Epoch: 31 cost time: 5.226791858673096
Epoch: 31, Steps: 258 | Train Loss: 0.4976173 Vali Loss: 0.2625760 Test Loss: 0.3539726
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.5500597
	speed: 0.0755s/iter; left time: 1335.9837s
	iters: 200, epoch: 32 | loss: 0.4373717
	speed: 0.0187s/iter; left time: 329.4685s
Epoch: 32 cost time: 5.20302677154541
Epoch: 32, Steps: 258 | Train Loss: 0.4981366 Vali Loss: 0.2626336 Test Loss: 0.3540015
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.5797287
	speed: 0.0776s/iter; left time: 1353.2209s
	iters: 200, epoch: 33 | loss: 0.4977202
	speed: 0.0191s/iter; left time: 330.4448s
Epoch: 33 cost time: 5.323104381561279
Epoch: 33, Steps: 258 | Train Loss: 0.4971731 Vali Loss: 0.2626643 Test Loss: 0.3539668
EarlyStopping counter: 13 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.6585791
	speed: 0.0775s/iter; left time: 1332.4216s
	iters: 200, epoch: 34 | loss: 0.4412636
	speed: 0.0185s/iter; left time: 316.2728s
Epoch: 34 cost time: 5.2760255336761475
Epoch: 34, Steps: 258 | Train Loss: 0.4975121 Vali Loss: 0.2626342 Test Loss: 0.3539908
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.8174613
	speed: 0.0758s/iter; left time: 1284.0438s
	iters: 200, epoch: 35 | loss: 0.4816423
	speed: 0.0197s/iter; left time: 331.4138s
Epoch: 35 cost time: 5.29984974861145
Epoch: 35, Steps: 258 | Train Loss: 0.4982828 Vali Loss: 0.2628156 Test Loss: 0.3539861
EarlyStopping counter: 15 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4990223
	speed: 0.0770s/iter; left time: 1283.5648s
	iters: 200, epoch: 36 | loss: 0.5601350
	speed: 0.0194s/iter; left time: 322.2487s
Epoch: 36 cost time: 5.283910274505615
Epoch: 36, Steps: 258 | Train Loss: 0.4975788 Vali Loss: 0.2626085 Test Loss: 0.3539626
EarlyStopping counter: 16 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4819525
	speed: 0.0788s/iter; left time: 1293.3814s
	iters: 200, epoch: 37 | loss: 0.5759093
	speed: 0.0191s/iter; left time: 312.0171s
Epoch: 37 cost time: 5.392341375350952
Epoch: 37, Steps: 258 | Train Loss: 0.4983913 Vali Loss: 0.2626732 Test Loss: 0.3539479
EarlyStopping counter: 17 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.5526417
	speed: 0.0809s/iter; left time: 1306.5594s
	iters: 200, epoch: 38 | loss: 0.5826169
	speed: 0.0194s/iter; left time: 311.0590s
Epoch: 38 cost time: 5.524582862854004
Epoch: 38, Steps: 258 | Train Loss: 0.4973999 Vali Loss: 0.2626232 Test Loss: 0.3539567
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.5039164
	speed: 0.0775s/iter; left time: 1232.4067s
	iters: 200, epoch: 39 | loss: 0.4833562
	speed: 0.0197s/iter; left time: 311.5992s
Epoch: 39 cost time: 5.4221580028533936
Epoch: 39, Steps: 258 | Train Loss: 0.4973370 Vali Loss: 0.2625938 Test Loss: 0.3539875
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.6378551
	speed: 0.0767s/iter; left time: 1200.1568s
	iters: 200, epoch: 40 | loss: 0.3578604
	speed: 0.0187s/iter; left time: 291.0366s
Epoch: 40 cost time: 5.395636558532715
Epoch: 40, Steps: 258 | Train Loss: 0.4982251 Vali Loss: 0.2624809 Test Loss: 0.3539656
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_720_720_FITS_ETTm2_ftM_sl720_ll48_pl720_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.3507073223590851, mae:0.37956178188323975, rse:0.476010799407959, corr:[0.5357184  0.53721625 0.538692   0.5395792  0.5397036  0.5392367
 0.5384211  0.53748643 0.53660786 0.5359006  0.53540254 0.5350804
 0.5349056  0.534805   0.5347481  0.5346083  0.5343527  0.53397894
 0.5334693  0.53280634 0.5320583  0.5312509  0.5304505  0.5297364
 0.52910304 0.5285617  0.5281046  0.5277215  0.527392   0.5270959
 0.5267906  0.5265091  0.5262153  0.5258231  0.5253177  0.5247187
 0.5240309  0.52331394 0.5225735  0.52183753 0.5211233  0.5204073
 0.519704   0.51900864 0.518339   0.51767564 0.5170431  0.51646787
 0.5159106  0.51530486 0.5146361  0.51394796 0.5132355  0.51251286
 0.51180845 0.5111597  0.51057583 0.5100583  0.5096257  0.5092578
 0.50897396 0.50878084 0.50867176 0.5086059  0.508536   0.50848204
 0.5083548  0.50819004 0.5079879  0.5077332  0.5073997  0.50697595
 0.50647676 0.505906   0.5052522  0.50454324 0.50382584 0.50312436
 0.50249153 0.50193995 0.50141937 0.50094014 0.5005095  0.5001136
 0.49975002 0.4994074  0.49902406 0.49860808 0.49809104 0.49745524
 0.49671295 0.49588016 0.49490923 0.4938003  0.49256012 0.4912093
 0.489812   0.4884851  0.48723063 0.48603365 0.48489344 0.48379272
 0.48270637 0.48161098 0.48047385 0.4793005  0.478118   0.47698465
 0.47589085 0.47484714 0.47386026 0.47292444 0.4721036  0.47138155
 0.4707153  0.470107   0.46955803 0.46902058 0.4684928  0.46789175
 0.46723345 0.46647358 0.46564484 0.4647345  0.46373454 0.46263984
 0.4615191  0.4604194  0.45938635 0.45844004 0.45760503 0.4568502
 0.45617834 0.45557383 0.45503947 0.45453346 0.45399198 0.45341036
 0.45276397 0.45205677 0.45128566 0.45048898 0.44971046 0.44892025
 0.44811007 0.44722888 0.44636816 0.44553688 0.44477913 0.44407904
 0.4434724  0.44298503 0.44253698 0.44206604 0.4415467  0.44099915
 0.44044036 0.4398792  0.43928692 0.43873736 0.43821117 0.4377338
 0.43730113 0.43694308 0.4366785  0.4365139  0.43640178 0.43629906
 0.4361727  0.43602088 0.43576548 0.43541682 0.43493724 0.4343592
 0.43370458 0.43300804 0.43228886 0.43154407 0.4307743  0.43005058
 0.42936152 0.42872244 0.42816985 0.42769256 0.4272527  0.42679766
 0.42631346 0.42573237 0.4250369  0.4241699  0.42311028 0.4218301
 0.42036662 0.41890448 0.41740748 0.41585392 0.41429552 0.4127364
 0.41123724 0.4098221  0.40851104 0.40731362 0.40622443 0.40523288
 0.40432915 0.40348297 0.40263832 0.4017386  0.4008272  0.3999882
 0.39914462 0.39824587 0.39725584 0.39619258 0.39511925 0.3940209
 0.39290047 0.39171225 0.39051715 0.38932934 0.38813537 0.3869414
 0.385743   0.38455242 0.3834301  0.38229254 0.38111088 0.37993068
 0.37874138 0.3776258  0.3766285  0.3758012  0.37513274 0.37461153
 0.3741675  0.37378672 0.37344572 0.3731243  0.3728485  0.37260163
 0.37237814 0.37210545 0.37174305 0.37139377 0.3709969  0.3706029
 0.37023142 0.3699076  0.3696036  0.36928657 0.3690061  0.36875468
 0.36853275 0.36837378 0.36822513 0.36807185 0.36787745 0.36766815
 0.36744025 0.3671997  0.36692843 0.36665037 0.36634204 0.3660642
 0.3658144  0.36555865 0.3653051  0.36505467 0.36478168 0.36446315
 0.3641529  0.363854   0.36354113 0.36324015 0.36293024 0.36258984
 0.36225817 0.36189207 0.36146083 0.36103076 0.36057884 0.36014643
 0.35971874 0.35930055 0.35888633 0.3584403  0.35795623 0.35734612
 0.35666296 0.3560132  0.35540226 0.35478884 0.35414836 0.35342228
 0.3526723  0.3518996  0.35109705 0.3502782  0.3494965  0.34873894
 0.3480788  0.3474749  0.34699386 0.34657615 0.34625658 0.34601828
 0.34590217 0.34581137 0.3456861  0.3454816  0.34516147 0.34479758
 0.344332   0.34382755 0.34327275 0.34267956 0.3421051  0.3416126
 0.34119913 0.34090793 0.3407647  0.34073284 0.34076273 0.34083232
 0.34090838 0.3410111  0.34113115 0.3411917  0.34120223 0.3411295
 0.34104246 0.34092104 0.3407972  0.34073323 0.34069842 0.34074977
 0.34085503 0.34090334 0.34090233 0.3409024  0.34091285 0.3408893
 0.34084103 0.34076375 0.3406474  0.34045395 0.340171   0.33985218
 0.33951136 0.33919895 0.33892602 0.33868277 0.33847827 0.3382892
 0.33810753 0.33796495 0.3378152  0.33772603 0.33760172 0.33745334
 0.33725348 0.3369898  0.33664888 0.33624002 0.33576727 0.3353092
 0.3348635  0.33450308 0.3342334  0.33408275 0.33408347 0.33419412
 0.33439702 0.3346953  0.33504906 0.33539662 0.33566475 0.33585632
 0.3359899  0.3360506  0.3359782  0.33567023 0.33518797 0.3344851
 0.3336687  0.33282465 0.33203426 0.3313096  0.33060545 0.32999995
 0.32944366 0.32892546 0.32843333 0.32796034 0.32749915 0.3270024
 0.32645524 0.3258919  0.32524365 0.32450533 0.3237768  0.32304874
 0.32235232 0.32168812 0.32111987 0.32071728 0.32040638 0.32018894
 0.3200116  0.31989667 0.3198201  0.31973508 0.31965044 0.31953079
 0.31943315 0.31938812 0.31934634 0.31928736 0.3191689  0.3190163
 0.31889063 0.31882748 0.3188068  0.31882837 0.31888595 0.318956
 0.31903708 0.3190934  0.31914866 0.31919026 0.31923574 0.31927937
 0.31929868 0.31921175 0.3190143  0.3187284  0.31841886 0.31810397
 0.31774792 0.31746012 0.31721655 0.31696373 0.31669936 0.31648082
 0.31624776 0.3160383  0.3158416  0.3156185  0.3153892  0.315131
 0.31487507 0.31461874 0.31439337 0.31414068 0.31386548 0.31359008
 0.31330648 0.31302187 0.3127157  0.3123743  0.3120607  0.3117174
 0.31137577 0.3110314  0.31069335 0.31034994 0.30997854 0.3095787
 0.30916858 0.3087556  0.30832422 0.30784702 0.3073755  0.30688763
 0.3063925  0.30581576 0.30519328 0.30447915 0.30369523 0.30283016
 0.30188796 0.30095932 0.3000187  0.29907405 0.29814515 0.297234
 0.296311   0.2954201  0.29454726 0.29377472 0.2930681  0.29236847
 0.29162508 0.29088947 0.29016963 0.28942293 0.28867772 0.28794724
 0.2872758  0.28659773 0.28588074 0.28518412 0.2844926  0.28388882
 0.28331652 0.28274488 0.28218964 0.2816407  0.2811487  0.2806846
 0.28025404 0.27984983 0.27944407 0.27902973 0.2786274  0.27824178
 0.2778528  0.27741432 0.27702862 0.27667674 0.27634397 0.27604517
 0.2757734  0.2755643  0.27539325 0.2752728  0.27522597 0.2752186
 0.2751747  0.27508327 0.27490893 0.2746664  0.27440897 0.2741603
 0.2738892  0.27358037 0.27331653 0.27306944 0.2728425  0.27263972
 0.27246442 0.27234015 0.2722283  0.27214938 0.2720694  0.2719559
 0.27178687 0.27159962 0.2714074  0.2712143  0.2709791  0.2707295
 0.27041897 0.27007094 0.26972878 0.26945114 0.26915902 0.26891094
 0.2687264  0.26864868 0.26864287 0.26866093 0.26869053 0.26871443
 0.2687185  0.26867923 0.2685947  0.26843587 0.26818734 0.26785725
 0.26743987 0.26691028 0.26619855 0.26531157 0.26428768 0.2631011
 0.26180372 0.26059118 0.25953317 0.2586494  0.2578615  0.25709635
 0.25630537 0.2554758  0.25462326 0.25376573 0.2529269  0.25214633
 0.25142416 0.25071844 0.2500722  0.24947555 0.24892466 0.24845795
 0.24807996 0.24774627 0.24748874 0.24723804 0.24699862 0.24676293
 0.24649309 0.24620226 0.24584484 0.24539778 0.24493206 0.24449056
 0.24406163 0.24366865 0.24337234 0.2431134  0.24292377 0.24279039
 0.24277696 0.2427667  0.24277708 0.24284585 0.24295658 0.24306515
 0.24315988 0.24328923 0.24345033 0.24366502 0.24396734 0.24436747
 0.24479808 0.24516626 0.24540222 0.24555767 0.24566191 0.24574596
 0.24577387 0.24575984 0.24574889 0.24559672 0.24541931 0.24519536
 0.24495067 0.24472888 0.2444927  0.24433737 0.24415445 0.24397643
 0.24376433 0.24362423 0.24354023 0.24344788 0.24345593 0.24344195
 0.24343313 0.24338025 0.24326433 0.24307908 0.2428999  0.2426327
 0.24238692 0.2421339  0.24182826 0.24157879 0.2414246  0.2413438
 0.24131057 0.24139325 0.2415153  0.24165659 0.24182525 0.2419502
 0.24195552 0.24184994 0.24158856 0.24106793 0.24027456 0.23928404
 0.23818853 0.2370906  0.23606357 0.23512776 0.23434237 0.23366857
 0.23304918 0.23242345 0.23190716 0.2314239  0.23097095 0.2305061
 0.23002301 0.22953194 0.22903909 0.2285325  0.22806707 0.22756755
 0.227032   0.22643147 0.22573835 0.22509664 0.22450659 0.22396915
 0.22349352 0.22302473 0.2225864  0.22209825 0.2215849  0.22104263
 0.22056365 0.22006594 0.2195708  0.21908756 0.21860102 0.21812648
 0.21764486 0.21724182 0.21695827 0.21691039 0.21697454 0.2170992
 0.2171282  0.21689343 0.21622927 0.21497068 0.2128671  0.2097427 ]
