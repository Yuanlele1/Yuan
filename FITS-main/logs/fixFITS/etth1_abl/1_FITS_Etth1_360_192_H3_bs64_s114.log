Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=58, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_360_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_360_192_FITS_ETTh1_ftM_sl360_ll48_pl192_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8089
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=58, out_features=88, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4573184.0
params:  5192.0
Trainable parameters:  5192
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.8822715282440186
Epoch: 1, Steps: 63 | Train Loss: 0.6790593 Vali Loss: 1.3476900 Test Loss: 0.6567327
Validation loss decreased (inf --> 1.347690).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.004460573196411
Epoch: 2, Steps: 63 | Train Loss: 0.5283763 Vali Loss: 1.1630646 Test Loss: 0.5351124
Validation loss decreased (1.347690 --> 1.163065).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.3889431953430176
Epoch: 3, Steps: 63 | Train Loss: 0.4727456 Vali Loss: 1.0809836 Test Loss: 0.4815230
Validation loss decreased (1.163065 --> 1.080984).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.4459493160247803
Epoch: 4, Steps: 63 | Train Loss: 0.4461074 Vali Loss: 1.0342323 Test Loss: 0.4530604
Validation loss decreased (1.080984 --> 1.034232).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.9730556011199951
Epoch: 5, Steps: 63 | Train Loss: 0.4312640 Vali Loss: 1.0052218 Test Loss: 0.4370253
Validation loss decreased (1.034232 --> 1.005222).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.7221078872680664
Epoch: 6, Steps: 63 | Train Loss: 0.4225049 Vali Loss: 0.9876521 Test Loss: 0.4278980
Validation loss decreased (1.005222 --> 0.987652).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.233421564102173
Epoch: 7, Steps: 63 | Train Loss: 0.4170213 Vali Loss: 0.9752077 Test Loss: 0.4229519
Validation loss decreased (0.987652 --> 0.975208).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.768779993057251
Epoch: 8, Steps: 63 | Train Loss: 0.4136202 Vali Loss: 0.9666020 Test Loss: 0.4202871
Validation loss decreased (0.975208 --> 0.966602).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.6427531242370605
Epoch: 9, Steps: 63 | Train Loss: 0.4115775 Vali Loss: 0.9613890 Test Loss: 0.4187945
Validation loss decreased (0.966602 --> 0.961389).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.9103972911834717
Epoch: 10, Steps: 63 | Train Loss: 0.4098266 Vali Loss: 0.9568475 Test Loss: 0.4179951
Validation loss decreased (0.961389 --> 0.956847).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.8979387283325195
Epoch: 11, Steps: 63 | Train Loss: 0.4088238 Vali Loss: 0.9534298 Test Loss: 0.4173173
Validation loss decreased (0.956847 --> 0.953430).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.878575086593628
Epoch: 12, Steps: 63 | Train Loss: 0.4080740 Vali Loss: 0.9503785 Test Loss: 0.4172550
Validation loss decreased (0.953430 --> 0.950379).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.868932008743286
Epoch: 13, Steps: 63 | Train Loss: 0.4074952 Vali Loss: 0.9472659 Test Loss: 0.4167788
Validation loss decreased (0.950379 --> 0.947266).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.833707571029663
Epoch: 14, Steps: 63 | Train Loss: 0.4072282 Vali Loss: 0.9453353 Test Loss: 0.4165925
Validation loss decreased (0.947266 --> 0.945335).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.8412706851959229
Epoch: 15, Steps: 63 | Train Loss: 0.4063241 Vali Loss: 0.9438796 Test Loss: 0.4165145
Validation loss decreased (0.945335 --> 0.943880).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.5015416145324707
Epoch: 16, Steps: 63 | Train Loss: 0.4062125 Vali Loss: 0.9419116 Test Loss: 0.4163364
Validation loss decreased (0.943880 --> 0.941912).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.6645748615264893
Epoch: 17, Steps: 63 | Train Loss: 0.4059264 Vali Loss: 0.9409568 Test Loss: 0.4164011
Validation loss decreased (0.941912 --> 0.940957).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.7933692932128906
Epoch: 18, Steps: 63 | Train Loss: 0.4055818 Vali Loss: 0.9398490 Test Loss: 0.4162810
Validation loss decreased (0.940957 --> 0.939849).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.482029676437378
Epoch: 19, Steps: 63 | Train Loss: 0.4054922 Vali Loss: 0.9388741 Test Loss: 0.4161686
Validation loss decreased (0.939849 --> 0.938874).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.8468639850616455
Epoch: 20, Steps: 63 | Train Loss: 0.4052894 Vali Loss: 0.9382491 Test Loss: 0.4161992
Validation loss decreased (0.938874 --> 0.938249).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.5957362651824951
Epoch: 21, Steps: 63 | Train Loss: 0.4048187 Vali Loss: 0.9371173 Test Loss: 0.4161101
Validation loss decreased (0.938249 --> 0.937117).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.6853435039520264
Epoch: 22, Steps: 63 | Train Loss: 0.4048675 Vali Loss: 0.9368072 Test Loss: 0.4161546
Validation loss decreased (0.937117 --> 0.936807).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.0063436031341553
Epoch: 23, Steps: 63 | Train Loss: 0.4046376 Vali Loss: 0.9360226 Test Loss: 0.4160933
Validation loss decreased (0.936807 --> 0.936023).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.701495885848999
Epoch: 24, Steps: 63 | Train Loss: 0.4046833 Vali Loss: 0.9355252 Test Loss: 0.4160711
Validation loss decreased (0.936023 --> 0.935525).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.8698091506958008
Epoch: 25, Steps: 63 | Train Loss: 0.4045281 Vali Loss: 0.9346954 Test Loss: 0.4160047
Validation loss decreased (0.935525 --> 0.934695).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.6683311462402344
Epoch: 26, Steps: 63 | Train Loss: 0.4040482 Vali Loss: 0.9343997 Test Loss: 0.4159723
Validation loss decreased (0.934695 --> 0.934400).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.7975575923919678
Epoch: 27, Steps: 63 | Train Loss: 0.4042967 Vali Loss: 0.9336101 Test Loss: 0.4159109
Validation loss decreased (0.934400 --> 0.933610).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.349431037902832
Epoch: 28, Steps: 63 | Train Loss: 0.4041786 Vali Loss: 0.9334220 Test Loss: 0.4159603
Validation loss decreased (0.933610 --> 0.933422).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.0563743114471436
Epoch: 29, Steps: 63 | Train Loss: 0.4041993 Vali Loss: 0.9334996 Test Loss: 0.4159781
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.7116904258728027
Epoch: 30, Steps: 63 | Train Loss: 0.4039845 Vali Loss: 0.9330848 Test Loss: 0.4159680
Validation loss decreased (0.933422 --> 0.933085).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.3746376037597656
Epoch: 31, Steps: 63 | Train Loss: 0.4040169 Vali Loss: 0.9325794 Test Loss: 0.4159227
Validation loss decreased (0.933085 --> 0.932579).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.000241756439209
Epoch: 32, Steps: 63 | Train Loss: 0.4038467 Vali Loss: 0.9321643 Test Loss: 0.4159274
Validation loss decreased (0.932579 --> 0.932164).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.969738483428955
Epoch: 33, Steps: 63 | Train Loss: 0.4039008 Vali Loss: 0.9320710 Test Loss: 0.4158682
Validation loss decreased (0.932164 --> 0.932071).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.8670661449432373
Epoch: 34, Steps: 63 | Train Loss: 0.4037568 Vali Loss: 0.9319533 Test Loss: 0.4158773
Validation loss decreased (0.932071 --> 0.931953).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.1514732837677
Epoch: 35, Steps: 63 | Train Loss: 0.4039053 Vali Loss: 0.9313769 Test Loss: 0.4159077
Validation loss decreased (0.931953 --> 0.931377).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.875624656677246
Epoch: 36, Steps: 63 | Train Loss: 0.4036880 Vali Loss: 0.9311457 Test Loss: 0.4158821
Validation loss decreased (0.931377 --> 0.931146).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.9527561664581299
Epoch: 37, Steps: 63 | Train Loss: 0.4035587 Vali Loss: 0.9309217 Test Loss: 0.4158396
Validation loss decreased (0.931146 --> 0.930922).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.851060152053833
Epoch: 38, Steps: 63 | Train Loss: 0.4037101 Vali Loss: 0.9306313 Test Loss: 0.4158455
Validation loss decreased (0.930922 --> 0.930631).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.8509511947631836
Epoch: 39, Steps: 63 | Train Loss: 0.4036133 Vali Loss: 0.9305207 Test Loss: 0.4158053
Validation loss decreased (0.930631 --> 0.930521).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.0028698444366455
Epoch: 40, Steps: 63 | Train Loss: 0.4035552 Vali Loss: 0.9306690 Test Loss: 0.4158323
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.748344898223877
Epoch: 41, Steps: 63 | Train Loss: 0.4034489 Vali Loss: 0.9301108 Test Loss: 0.4157914
Validation loss decreased (0.930521 --> 0.930111).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.8862056732177734
Epoch: 42, Steps: 63 | Train Loss: 0.4038019 Vali Loss: 0.9301591 Test Loss: 0.4158375
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.6063241958618164
Epoch: 43, Steps: 63 | Train Loss: 0.4032927 Vali Loss: 0.9300282 Test Loss: 0.4158725
Validation loss decreased (0.930111 --> 0.930028).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.753828525543213
Epoch: 44, Steps: 63 | Train Loss: 0.4034157 Vali Loss: 0.9297924 Test Loss: 0.4158469
Validation loss decreased (0.930028 --> 0.929792).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.011152744293213
Epoch: 45, Steps: 63 | Train Loss: 0.4033957 Vali Loss: 0.9299482 Test Loss: 0.4158335
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.4819846153259277
Epoch: 46, Steps: 63 | Train Loss: 0.4036000 Vali Loss: 0.9298449 Test Loss: 0.4158429
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 3.06643009185791
Epoch: 47, Steps: 63 | Train Loss: 0.4033396 Vali Loss: 0.9299266 Test Loss: 0.4158399
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.1254405975341797
Epoch: 48, Steps: 63 | Train Loss: 0.4035594 Vali Loss: 0.9297922 Test Loss: 0.4158654
Validation loss decreased (0.929792 --> 0.929792).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.9744131565093994
Epoch: 49, Steps: 63 | Train Loss: 0.4033477 Vali Loss: 0.9292545 Test Loss: 0.4158729
Validation loss decreased (0.929792 --> 0.929255).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.1061394214630127
Epoch: 50, Steps: 63 | Train Loss: 0.4032321 Vali Loss: 0.9292977 Test Loss: 0.4158688
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.3018553256988525
Epoch: 51, Steps: 63 | Train Loss: 0.4034239 Vali Loss: 0.9289345 Test Loss: 0.4158373
Validation loss decreased (0.929255 --> 0.928934).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.3748574256896973
Epoch: 52, Steps: 63 | Train Loss: 0.4034345 Vali Loss: 0.9292083 Test Loss: 0.4158522
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.6526298522949219
Epoch: 53, Steps: 63 | Train Loss: 0.4032243 Vali Loss: 0.9293770 Test Loss: 0.4158698
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.889899492263794
Epoch: 54, Steps: 63 | Train Loss: 0.4032671 Vali Loss: 0.9290842 Test Loss: 0.4158141
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.6975905895233154
Epoch: 55, Steps: 63 | Train Loss: 0.4034313 Vali Loss: 0.9291096 Test Loss: 0.4158468
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.6058695316314697
Epoch: 56, Steps: 63 | Train Loss: 0.4030402 Vali Loss: 0.9291853 Test Loss: 0.4158281
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.691687822341919
Epoch: 57, Steps: 63 | Train Loss: 0.4031427 Vali Loss: 0.9287407 Test Loss: 0.4158403
Validation loss decreased (0.928934 --> 0.928741).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.1064651012420654
Epoch: 58, Steps: 63 | Train Loss: 0.4029927 Vali Loss: 0.9289343 Test Loss: 0.4158184
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.125103712081909
Epoch: 59, Steps: 63 | Train Loss: 0.4029718 Vali Loss: 0.9290298 Test Loss: 0.4158497
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.9362316131591797
Epoch: 60, Steps: 63 | Train Loss: 0.4031281 Vali Loss: 0.9290355 Test Loss: 0.4158563
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.9838707447052002
Epoch: 61, Steps: 63 | Train Loss: 0.4033056 Vali Loss: 0.9290287 Test Loss: 0.4158580
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.1129486560821533
Epoch: 62, Steps: 63 | Train Loss: 0.4030294 Vali Loss: 0.9286186 Test Loss: 0.4158535
Validation loss decreased (0.928741 --> 0.928619).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.4892003536224365
Epoch: 63, Steps: 63 | Train Loss: 0.4030890 Vali Loss: 0.9288344 Test Loss: 0.4158537
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.4086179733276367
Epoch: 64, Steps: 63 | Train Loss: 0.4030691 Vali Loss: 0.9289273 Test Loss: 0.4158421
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.911292314529419
Epoch: 65, Steps: 63 | Train Loss: 0.4031364 Vali Loss: 0.9288980 Test Loss: 0.4158410
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 3.3364791870117188
Epoch: 66, Steps: 63 | Train Loss: 0.4030286 Vali Loss: 0.9283859 Test Loss: 0.4158617
Validation loss decreased (0.928619 --> 0.928386).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.3709373474121094
Epoch: 67, Steps: 63 | Train Loss: 0.4028927 Vali Loss: 0.9287946 Test Loss: 0.4158474
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 3.388209819793701
Epoch: 68, Steps: 63 | Train Loss: 0.4031793 Vali Loss: 0.9286580 Test Loss: 0.4158489
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.098803997039795
Epoch: 69, Steps: 63 | Train Loss: 0.4031597 Vali Loss: 0.9287292 Test Loss: 0.4158642
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.8848602771759033
Epoch: 70, Steps: 63 | Train Loss: 0.4032794 Vali Loss: 0.9287183 Test Loss: 0.4158470
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.4721527099609375
Epoch: 71, Steps: 63 | Train Loss: 0.4031719 Vali Loss: 0.9284446 Test Loss: 0.4158473
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.2417218685150146
Epoch: 72, Steps: 63 | Train Loss: 0.4030058 Vali Loss: 0.9284391 Test Loss: 0.4158508
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.088043451309204
Epoch: 73, Steps: 63 | Train Loss: 0.4031418 Vali Loss: 0.9283304 Test Loss: 0.4158467
Validation loss decreased (0.928386 --> 0.928330).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.7980082035064697
Epoch: 74, Steps: 63 | Train Loss: 0.4030260 Vali Loss: 0.9285830 Test Loss: 0.4158446
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.790379524230957
Epoch: 75, Steps: 63 | Train Loss: 0.4031889 Vali Loss: 0.9283962 Test Loss: 0.4158513
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.074982166290283
Epoch: 76, Steps: 63 | Train Loss: 0.4032308 Vali Loss: 0.9275548 Test Loss: 0.4158494
Validation loss decreased (0.928330 --> 0.927555).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.0669808387756348
Epoch: 77, Steps: 63 | Train Loss: 0.4029041 Vali Loss: 0.9286097 Test Loss: 0.4158516
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.7523424625396729
Epoch: 78, Steps: 63 | Train Loss: 0.4029776 Vali Loss: 0.9284657 Test Loss: 0.4158533
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.098907232284546
Epoch: 79, Steps: 63 | Train Loss: 0.4031719 Vali Loss: 0.9281096 Test Loss: 0.4158470
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.757239580154419
Epoch: 80, Steps: 63 | Train Loss: 0.4032288 Vali Loss: 0.9285842 Test Loss: 0.4158449
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.799133539199829
Epoch: 81, Steps: 63 | Train Loss: 0.4030213 Vali Loss: 0.9284011 Test Loss: 0.4158473
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.994974136352539
Epoch: 82, Steps: 63 | Train Loss: 0.4031187 Vali Loss: 0.9283931 Test Loss: 0.4158462
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 3.073267936706543
Epoch: 83, Steps: 63 | Train Loss: 0.4029419 Vali Loss: 0.9282565 Test Loss: 0.4158568
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.554331064224243
Epoch: 84, Steps: 63 | Train Loss: 0.4031476 Vali Loss: 0.9283482 Test Loss: 0.4158498
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.6911301612854004
Epoch: 85, Steps: 63 | Train Loss: 0.4030225 Vali Loss: 0.9284786 Test Loss: 0.4158467
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 2.8509740829467773
Epoch: 86, Steps: 63 | Train Loss: 0.4029416 Vali Loss: 0.9283508 Test Loss: 0.4158490
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 2.763040781021118
Epoch: 87, Steps: 63 | Train Loss: 0.4028456 Vali Loss: 0.9284269 Test Loss: 0.4158496
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.8530266284942627
Epoch: 88, Steps: 63 | Train Loss: 0.4027681 Vali Loss: 0.9281240 Test Loss: 0.4158486
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.721806764602661
Epoch: 89, Steps: 63 | Train Loss: 0.4031934 Vali Loss: 0.9283203 Test Loss: 0.4158489
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 2.294020414352417
Epoch: 90, Steps: 63 | Train Loss: 0.4030651 Vali Loss: 0.9280142 Test Loss: 0.4158479
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.8651721477508545
Epoch: 91, Steps: 63 | Train Loss: 0.4029693 Vali Loss: 0.9280014 Test Loss: 0.4158513
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 2.723165988922119
Epoch: 92, Steps: 63 | Train Loss: 0.4030542 Vali Loss: 0.9283068 Test Loss: 0.4158522
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.8071625232696533
Epoch: 93, Steps: 63 | Train Loss: 0.4029944 Vali Loss: 0.9278932 Test Loss: 0.4158491
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.833056926727295
Epoch: 94, Steps: 63 | Train Loss: 0.4030349 Vali Loss: 0.9280593 Test Loss: 0.4158508
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 2.1151158809661865
Epoch: 95, Steps: 63 | Train Loss: 0.4030163 Vali Loss: 0.9282586 Test Loss: 0.4158477
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.8437201976776123
Epoch: 96, Steps: 63 | Train Loss: 0.4029083 Vali Loss: 0.9283291 Test Loss: 0.4158462
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_360_192_FITS_ETTh1_ftM_sl360_ll48_pl192_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.4115484654903412, mae:0.4188369810581207, rse:0.6092111468315125, corr:[0.2604683  0.2692242  0.2695213  0.26625767 0.2635638  0.26257348
 0.2623846  0.26247942 0.26224512 0.2618096  0.2614145  0.26107025
 0.2608193  0.2606535  0.26052356 0.26040575 0.26026335 0.26017454
 0.2601613  0.26011077 0.2599981  0.2599116  0.25991622 0.26004717
 0.26001447 0.2597611  0.2594032  0.25905156 0.25868893 0.25838652
 0.25818536 0.25804555 0.25791195 0.25769225 0.25743148 0.2572421
 0.25727004 0.25761336 0.25800753 0.25825247 0.2584012  0.25839034
 0.25832692 0.25830528 0.25827312 0.25813615 0.25796717 0.25774565
 0.25726643 0.25646153 0.25538987 0.25447845 0.25381115 0.2531946
 0.25275266 0.2525012  0.2523414  0.25218236 0.25192258 0.25170708
 0.25156948 0.25150943 0.25149843 0.25158098 0.2517038  0.2518771
 0.25209212 0.25215134 0.25217944 0.25225475 0.25228179 0.25202525
 0.25140774 0.2505826  0.24980159 0.24925354 0.24895418 0.24874957
 0.24857828 0.24834158 0.2480755  0.24776122 0.24742457 0.24718751
 0.24718393 0.24728748 0.24734913 0.24724804 0.24707796 0.24698149
 0.24685855 0.24667385 0.24650203 0.24654022 0.24685942 0.24739166
 0.24802378 0.24830127 0.24824521 0.24788544 0.24747181 0.24721353
 0.24715078 0.24724701 0.24728899 0.2471731  0.24693042 0.24662942
 0.24641018 0.24646068 0.24675867 0.24715924 0.24737729 0.24742101
 0.24737306 0.24723066 0.24702191 0.24685287 0.24678391 0.24674015
 0.24657449 0.2460507  0.24514797 0.24414821 0.24340153 0.24298756
 0.24293958 0.24302506 0.24294159 0.24255691 0.24214551 0.24187602
 0.24175481 0.24179025 0.24195933 0.24204177 0.2421528  0.24221185
 0.24224295 0.24226552 0.24232759 0.24240327 0.24238007 0.2421367
 0.24180959 0.24124286 0.24049352 0.2396636  0.2390677  0.23857957
 0.23832363 0.23837738 0.23853567 0.23870046 0.23868638 0.23854205
 0.23833558 0.23832859 0.23850115 0.2386384  0.23861024 0.23854335
 0.23843011 0.23826307 0.23827969 0.23848575 0.23873605 0.2387958
 0.23878159 0.23876826 0.23873594 0.23861827 0.2384778  0.23834974
 0.23824422 0.23823732 0.23833378 0.23860538 0.23880588 0.23866513
 0.23834245 0.2381635  0.23851235 0.23914117 0.23942225 0.23917009
 0.23850064 0.23807621 0.23879808 0.24013247 0.23953016 0.23334396]
