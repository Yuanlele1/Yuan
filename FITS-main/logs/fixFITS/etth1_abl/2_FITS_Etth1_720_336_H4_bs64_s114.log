Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=134, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_720_336_FITS_ETTh1_ftM_sl720_ll48_pl336_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=134, out_features=196, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  23532544.0
params:  26460.0
Trainable parameters:  26460
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.8664617538452148
Epoch: 1, Steps: 59 | Train Loss: 0.6917426 Vali Loss: 1.7620999 Test Loss: 0.8338407
Validation loss decreased (inf --> 1.762100).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.0081090927124023
Epoch: 2, Steps: 59 | Train Loss: 0.5457130 Vali Loss: 1.5846359 Test Loss: 0.7407942
Validation loss decreased (1.762100 --> 1.584636).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.9329674243927002
Epoch: 3, Steps: 59 | Train Loss: 0.4734915 Vali Loss: 1.5150059 Test Loss: 0.7053839
Validation loss decreased (1.584636 --> 1.515006).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.896085500717163
Epoch: 4, Steps: 59 | Train Loss: 0.4320471 Vali Loss: 1.4725050 Test Loss: 0.6867485
Validation loss decreased (1.515006 --> 1.472505).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.8938884735107422
Epoch: 5, Steps: 59 | Train Loss: 0.4033887 Vali Loss: 1.4467709 Test Loss: 0.6737820
Validation loss decreased (1.472505 --> 1.446771).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.9502148628234863
Epoch: 6, Steps: 59 | Train Loss: 0.3813961 Vali Loss: 1.4303712 Test Loss: 0.6652430
Validation loss decreased (1.446771 --> 1.430371).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.9629063606262207
Epoch: 7, Steps: 59 | Train Loss: 0.3634531 Vali Loss: 1.4154960 Test Loss: 0.6555088
Validation loss decreased (1.430371 --> 1.415496).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.03633451461792
Epoch: 8, Steps: 59 | Train Loss: 0.3481071 Vali Loss: 1.3981612 Test Loss: 0.6468909
Validation loss decreased (1.415496 --> 1.398161).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.052791118621826
Epoch: 9, Steps: 59 | Train Loss: 0.3347482 Vali Loss: 1.3929893 Test Loss: 0.6396767
Validation loss decreased (1.398161 --> 1.392989).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.9942595958709717
Epoch: 10, Steps: 59 | Train Loss: 0.3230584 Vali Loss: 1.3820724 Test Loss: 0.6319048
Validation loss decreased (1.392989 --> 1.382072).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.836064100265503
Epoch: 11, Steps: 59 | Train Loss: 0.3126132 Vali Loss: 1.3729306 Test Loss: 0.6252371
Validation loss decreased (1.382072 --> 1.372931).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.9058706760406494
Epoch: 12, Steps: 59 | Train Loss: 0.3035130 Vali Loss: 1.3656249 Test Loss: 0.6175789
Validation loss decreased (1.372931 --> 1.365625).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.9915380477905273
Epoch: 13, Steps: 59 | Train Loss: 0.2954306 Vali Loss: 1.3561885 Test Loss: 0.6123704
Validation loss decreased (1.365625 --> 1.356189).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.0056240558624268
Epoch: 14, Steps: 59 | Train Loss: 0.2879845 Vali Loss: 1.3517305 Test Loss: 0.6061324
Validation loss decreased (1.356189 --> 1.351730).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.9769937992095947
Epoch: 15, Steps: 59 | Train Loss: 0.2812100 Vali Loss: 1.3477812 Test Loss: 0.6000585
Validation loss decreased (1.351730 --> 1.347781).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.8974955081939697
Epoch: 16, Steps: 59 | Train Loss: 0.2751465 Vali Loss: 1.3357648 Test Loss: 0.5950450
Validation loss decreased (1.347781 --> 1.335765).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.9754254817962646
Epoch: 17, Steps: 59 | Train Loss: 0.2696601 Vali Loss: 1.3279638 Test Loss: 0.5894147
Validation loss decreased (1.335765 --> 1.327964).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.0087411403656006
Epoch: 18, Steps: 59 | Train Loss: 0.2648525 Vali Loss: 1.3253800 Test Loss: 0.5852192
Validation loss decreased (1.327964 --> 1.325380).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.046682119369507
Epoch: 19, Steps: 59 | Train Loss: 0.2601907 Vali Loss: 1.3251683 Test Loss: 0.5807153
Validation loss decreased (1.325380 --> 1.325168).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.084172248840332
Epoch: 20, Steps: 59 | Train Loss: 0.2560582 Vali Loss: 1.3162278 Test Loss: 0.5766955
Validation loss decreased (1.325168 --> 1.316228).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.1147265434265137
Epoch: 21, Steps: 59 | Train Loss: 0.2522052 Vali Loss: 1.3165410 Test Loss: 0.5728275
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.0769801139831543
Epoch: 22, Steps: 59 | Train Loss: 0.2486764 Vali Loss: 1.3094498 Test Loss: 0.5692011
Validation loss decreased (1.316228 --> 1.309450).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.9923629760742188
Epoch: 23, Steps: 59 | Train Loss: 0.2455804 Vali Loss: 1.3026577 Test Loss: 0.5660176
Validation loss decreased (1.309450 --> 1.302658).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.087319850921631
Epoch: 24, Steps: 59 | Train Loss: 0.2425549 Vali Loss: 1.2986351 Test Loss: 0.5627936
Validation loss decreased (1.302658 --> 1.298635).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.015761613845825
Epoch: 25, Steps: 59 | Train Loss: 0.2398401 Vali Loss: 1.3033901 Test Loss: 0.5594364
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.0000672340393066
Epoch: 26, Steps: 59 | Train Loss: 0.2372877 Vali Loss: 1.2932382 Test Loss: 0.5570835
Validation loss decreased (1.298635 --> 1.293238).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.9547200202941895
Epoch: 27, Steps: 59 | Train Loss: 0.2350797 Vali Loss: 1.2940769 Test Loss: 0.5544211
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.9787945747375488
Epoch: 28, Steps: 59 | Train Loss: 0.2327320 Vali Loss: 1.2934421 Test Loss: 0.5516191
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.961925983428955
Epoch: 29, Steps: 59 | Train Loss: 0.2307063 Vali Loss: 1.2963178 Test Loss: 0.5495762
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.0586001873016357
Epoch: 30, Steps: 59 | Train Loss: 0.2289023 Vali Loss: 1.2868229 Test Loss: 0.5477110
Validation loss decreased (1.293238 --> 1.286823).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.9118735790252686
Epoch: 31, Steps: 59 | Train Loss: 0.2270777 Vali Loss: 1.2905736 Test Loss: 0.5453638
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.915295124053955
Epoch: 32, Steps: 59 | Train Loss: 0.2255141 Vali Loss: 1.2870452 Test Loss: 0.5433756
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.0102133750915527
Epoch: 33, Steps: 59 | Train Loss: 0.2238969 Vali Loss: 1.2833681 Test Loss: 0.5415789
Validation loss decreased (1.286823 --> 1.283368).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.0290746688842773
Epoch: 34, Steps: 59 | Train Loss: 0.2225156 Vali Loss: 1.2786006 Test Loss: 0.5400190
Validation loss decreased (1.283368 --> 1.278601).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.104192018508911
Epoch: 35, Steps: 59 | Train Loss: 0.2212161 Vali Loss: 1.2792649 Test Loss: 0.5382419
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.0145044326782227
Epoch: 36, Steps: 59 | Train Loss: 0.2198360 Vali Loss: 1.2795939 Test Loss: 0.5367221
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.0299999713897705
Epoch: 37, Steps: 59 | Train Loss: 0.2186415 Vali Loss: 1.2791414 Test Loss: 0.5353684
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.9893059730529785
Epoch: 38, Steps: 59 | Train Loss: 0.2176443 Vali Loss: 1.2752038 Test Loss: 0.5340205
Validation loss decreased (1.278601 --> 1.275204).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.0747036933898926
Epoch: 39, Steps: 59 | Train Loss: 0.2165994 Vali Loss: 1.2727649 Test Loss: 0.5327291
Validation loss decreased (1.275204 --> 1.272765).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.020329713821411
Epoch: 40, Steps: 59 | Train Loss: 0.2157446 Vali Loss: 1.2766454 Test Loss: 0.5314316
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.0460598468780518
Epoch: 41, Steps: 59 | Train Loss: 0.2146258 Vali Loss: 1.2762135 Test Loss: 0.5302864
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.8719172477722168
Epoch: 42, Steps: 59 | Train Loss: 0.2138617 Vali Loss: 1.2724160 Test Loss: 0.5292965
Validation loss decreased (1.272765 --> 1.272416).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.001842498779297
Epoch: 43, Steps: 59 | Train Loss: 0.2131059 Vali Loss: 1.2725508 Test Loss: 0.5280486
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.9831995964050293
Epoch: 44, Steps: 59 | Train Loss: 0.2122315 Vali Loss: 1.2709614 Test Loss: 0.5271884
Validation loss decreased (1.272416 --> 1.270961).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.0399398803710938
Epoch: 45, Steps: 59 | Train Loss: 0.2116128 Vali Loss: 1.2733909 Test Loss: 0.5262251
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.9427015781402588
Epoch: 46, Steps: 59 | Train Loss: 0.2110721 Vali Loss: 1.2655463 Test Loss: 0.5252904
Validation loss decreased (1.270961 --> 1.265546).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.085671901702881
Epoch: 47, Steps: 59 | Train Loss: 0.2103523 Vali Loss: 1.2703373 Test Loss: 0.5245676
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.8324737548828125
Epoch: 48, Steps: 59 | Train Loss: 0.2096854 Vali Loss: 1.2688336 Test Loss: 0.5238186
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.9928851127624512
Epoch: 49, Steps: 59 | Train Loss: 0.2091950 Vali Loss: 1.2689594 Test Loss: 0.5230768
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.9490766525268555
Epoch: 50, Steps: 59 | Train Loss: 0.2085806 Vali Loss: 1.2689568 Test Loss: 0.5223606
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.0702033042907715
Epoch: 51, Steps: 59 | Train Loss: 0.2081116 Vali Loss: 1.2622916 Test Loss: 0.5217330
Validation loss decreased (1.265546 --> 1.262292).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.9559381008148193
Epoch: 52, Steps: 59 | Train Loss: 0.2074863 Vali Loss: 1.2640822 Test Loss: 0.5210192
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.9134180545806885
Epoch: 53, Steps: 59 | Train Loss: 0.2071012 Vali Loss: 1.2616497 Test Loss: 0.5204220
Validation loss decreased (1.262292 --> 1.261650).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.8131930828094482
Epoch: 54, Steps: 59 | Train Loss: 0.2066364 Vali Loss: 1.2653114 Test Loss: 0.5199395
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.9618480205535889
Epoch: 55, Steps: 59 | Train Loss: 0.2061952 Vali Loss: 1.2656342 Test Loss: 0.5192964
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.919931411743164
Epoch: 56, Steps: 59 | Train Loss: 0.2059088 Vali Loss: 1.2664198 Test Loss: 0.5189142
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.9702181816101074
Epoch: 57, Steps: 59 | Train Loss: 0.2054844 Vali Loss: 1.2633188 Test Loss: 0.5183846
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.9651963710784912
Epoch: 58, Steps: 59 | Train Loss: 0.2050508 Vali Loss: 1.2624326 Test Loss: 0.5178480
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.2054896354675293
Epoch: 59, Steps: 59 | Train Loss: 0.2048028 Vali Loss: 1.2661996 Test Loss: 0.5175366
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.0345442295074463
Epoch: 60, Steps: 59 | Train Loss: 0.2045208 Vali Loss: 1.2622298 Test Loss: 0.5170949
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.971681833267212
Epoch: 61, Steps: 59 | Train Loss: 0.2043116 Vali Loss: 1.2622432 Test Loss: 0.5166816
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.8843777179718018
Epoch: 62, Steps: 59 | Train Loss: 0.2039107 Vali Loss: 1.2622619 Test Loss: 0.5162796
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.054779291152954
Epoch: 63, Steps: 59 | Train Loss: 0.2036188 Vali Loss: 1.2620721 Test Loss: 0.5158811
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.0335440635681152
Epoch: 64, Steps: 59 | Train Loss: 0.2033886 Vali Loss: 1.2599361 Test Loss: 0.5155598
Validation loss decreased (1.261650 --> 1.259936).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.203212022781372
Epoch: 65, Steps: 59 | Train Loss: 0.2032085 Vali Loss: 1.2589808 Test Loss: 0.5152721
Validation loss decreased (1.259936 --> 1.258981).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.8865127563476562
Epoch: 66, Steps: 59 | Train Loss: 0.2030146 Vali Loss: 1.2629327 Test Loss: 0.5149685
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.0301482677459717
Epoch: 67, Steps: 59 | Train Loss: 0.2027163 Vali Loss: 1.2630095 Test Loss: 0.5147011
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.9417920112609863
Epoch: 68, Steps: 59 | Train Loss: 0.2025699 Vali Loss: 1.2609377 Test Loss: 0.5144480
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.914219617843628
Epoch: 69, Steps: 59 | Train Loss: 0.2022567 Vali Loss: 1.2583990 Test Loss: 0.5141593
Validation loss decreased (1.258981 --> 1.258399).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.0213277339935303
Epoch: 70, Steps: 59 | Train Loss: 0.2020047 Vali Loss: 1.2612406 Test Loss: 0.5139198
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.1226730346679688
Epoch: 71, Steps: 59 | Train Loss: 0.2020061 Vali Loss: 1.2550663 Test Loss: 0.5136947
Validation loss decreased (1.258399 --> 1.255066).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.9372315406799316
Epoch: 72, Steps: 59 | Train Loss: 0.2017911 Vali Loss: 1.2627677 Test Loss: 0.5134560
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.2342145442962646
Epoch: 73, Steps: 59 | Train Loss: 0.2015558 Vali Loss: 1.2618579 Test Loss: 0.5132500
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.9449372291564941
Epoch: 74, Steps: 59 | Train Loss: 0.2013986 Vali Loss: 1.2592338 Test Loss: 0.5130347
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.090620994567871
Epoch: 75, Steps: 59 | Train Loss: 0.2012686 Vali Loss: 1.2586681 Test Loss: 0.5128669
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.9749350547790527
Epoch: 76, Steps: 59 | Train Loss: 0.2011068 Vali Loss: 1.2589152 Test Loss: 0.5126581
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.0061330795288086
Epoch: 77, Steps: 59 | Train Loss: 0.2010346 Vali Loss: 1.2610220 Test Loss: 0.5124914
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.9705309867858887
Epoch: 78, Steps: 59 | Train Loss: 0.2009251 Vali Loss: 1.2612671 Test Loss: 0.5123075
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.013904571533203
Epoch: 79, Steps: 59 | Train Loss: 0.2007495 Vali Loss: 1.2568249 Test Loss: 0.5121664
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.008730173110962
Epoch: 80, Steps: 59 | Train Loss: 0.2006928 Vali Loss: 1.2620220 Test Loss: 0.5120364
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.0335898399353027
Epoch: 81, Steps: 59 | Train Loss: 0.2005267 Vali Loss: 1.2575159 Test Loss: 0.5118815
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 2.176194906234741
Epoch: 82, Steps: 59 | Train Loss: 0.2004149 Vali Loss: 1.2549932 Test Loss: 0.5117742
Validation loss decreased (1.255066 --> 1.254993).  Saving model ...
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.030085325241089
Epoch: 83, Steps: 59 | Train Loss: 0.2004207 Vali Loss: 1.2595303 Test Loss: 0.5116337
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.019224166870117
Epoch: 84, Steps: 59 | Train Loss: 0.2003289 Vali Loss: 1.2609899 Test Loss: 0.5115082
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.9014415740966797
Epoch: 85, Steps: 59 | Train Loss: 0.2000861 Vali Loss: 1.2584327 Test Loss: 0.5114017
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 2.044501781463623
Epoch: 86, Steps: 59 | Train Loss: 0.2001596 Vali Loss: 1.2560803 Test Loss: 0.5112835
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.990281581878662
Epoch: 87, Steps: 59 | Train Loss: 0.1999984 Vali Loss: 1.2593449 Test Loss: 0.5111827
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 2.155301332473755
Epoch: 88, Steps: 59 | Train Loss: 0.1999406 Vali Loss: 1.2611107 Test Loss: 0.5110752
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.848602056503296
Epoch: 89, Steps: 59 | Train Loss: 0.1999114 Vali Loss: 1.2617325 Test Loss: 0.5109686
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.9907829761505127
Epoch: 90, Steps: 59 | Train Loss: 0.1996943 Vali Loss: 1.2579950 Test Loss: 0.5108890
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.0321431159973145
Epoch: 91, Steps: 59 | Train Loss: 0.1996448 Vali Loss: 1.2558845 Test Loss: 0.5108132
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.9460654258728027
Epoch: 92, Steps: 59 | Train Loss: 0.1996691 Vali Loss: 1.2604430 Test Loss: 0.5107242
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.934896469116211
Epoch: 93, Steps: 59 | Train Loss: 0.1995989 Vali Loss: 1.2557964 Test Loss: 0.5106469
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.9910838603973389
Epoch: 94, Steps: 59 | Train Loss: 0.1995994 Vali Loss: 1.2614114 Test Loss: 0.5105667
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.8728926181793213
Epoch: 95, Steps: 59 | Train Loss: 0.1995282 Vali Loss: 1.2591817 Test Loss: 0.5105096
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.8384742736816406
Epoch: 96, Steps: 59 | Train Loss: 0.1994549 Vali Loss: 1.2579916 Test Loss: 0.5104362
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 2.0219032764434814
Epoch: 97, Steps: 59 | Train Loss: 0.1994311 Vali Loss: 1.2583181 Test Loss: 0.5103724
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.940913200378418
Epoch: 98, Steps: 59 | Train Loss: 0.1993382 Vali Loss: 1.2591646 Test Loss: 0.5103153
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.965754747390747
Epoch: 99, Steps: 59 | Train Loss: 0.1993733 Vali Loss: 1.2569321 Test Loss: 0.5102605
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.7570650577545166
Epoch: 100, Steps: 59 | Train Loss: 0.1992708 Vali Loss: 1.2618635 Test Loss: 0.5102049
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.1160680107021042e-06
train 7585
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=134, out_features=196, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  23532544.0
params:  26460.0
Trainable parameters:  26460
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.180105447769165
Epoch: 1, Steps: 59 | Train Loss: 0.4625285 Vali Loss: 1.2110668 Test Loss: 0.4641622
Validation loss decreased (inf --> 1.211067).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.9096996784210205
Epoch: 2, Steps: 59 | Train Loss: 0.4455867 Vali Loss: 1.2023159 Test Loss: 0.4485523
Validation loss decreased (1.211067 --> 1.202316).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.969132900238037
Epoch: 3, Steps: 59 | Train Loss: 0.4395465 Vali Loss: 1.2047160 Test Loss: 0.4449529
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.9975471496582031
Epoch: 4, Steps: 59 | Train Loss: 0.4377177 Vali Loss: 1.2081194 Test Loss: 0.4439923
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.924001693725586
Epoch: 5, Steps: 59 | Train Loss: 0.4370312 Vali Loss: 1.2147360 Test Loss: 0.4443349
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.037844181060791
Epoch: 6, Steps: 59 | Train Loss: 0.4367195 Vali Loss: 1.2146568 Test Loss: 0.4447230
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.082362413406372
Epoch: 7, Steps: 59 | Train Loss: 0.4361687 Vali Loss: 1.2132984 Test Loss: 0.4449975
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.920882225036621
Epoch: 8, Steps: 59 | Train Loss: 0.4358018 Vali Loss: 1.2135383 Test Loss: 0.4452488
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.870206356048584
Epoch: 9, Steps: 59 | Train Loss: 0.4357276 Vali Loss: 1.2166678 Test Loss: 0.4456042
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.0366897583007812
Epoch: 10, Steps: 59 | Train Loss: 0.4351682 Vali Loss: 1.2174082 Test Loss: 0.4459265
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.034215211868286
Epoch: 11, Steps: 59 | Train Loss: 0.4349807 Vali Loss: 1.2226782 Test Loss: 0.4458551
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.0462939739227295
Epoch: 12, Steps: 59 | Train Loss: 0.4350487 Vali Loss: 1.2191112 Test Loss: 0.4459467
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.0293331146240234
Epoch: 13, Steps: 59 | Train Loss: 0.4351766 Vali Loss: 1.2170842 Test Loss: 0.4461257
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.0242974758148193
Epoch: 14, Steps: 59 | Train Loss: 0.4350977 Vali Loss: 1.2158651 Test Loss: 0.4462402
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.8746066093444824
Epoch: 15, Steps: 59 | Train Loss: 0.4345508 Vali Loss: 1.2237194 Test Loss: 0.4464287
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.095686912536621
Epoch: 16, Steps: 59 | Train Loss: 0.4348946 Vali Loss: 1.2201827 Test Loss: 0.4463472
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.0590715408325195
Epoch: 17, Steps: 59 | Train Loss: 0.4348646 Vali Loss: 1.2178711 Test Loss: 0.4463230
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.066007614135742
Epoch: 18, Steps: 59 | Train Loss: 0.4343096 Vali Loss: 1.2195288 Test Loss: 0.4464301
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.1183228492736816
Epoch: 19, Steps: 59 | Train Loss: 0.4346779 Vali Loss: 1.2232332 Test Loss: 0.4465779
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.127091646194458
Epoch: 20, Steps: 59 | Train Loss: 0.4343859 Vali Loss: 1.2198163 Test Loss: 0.4466542
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.038486957550049
Epoch: 21, Steps: 59 | Train Loss: 0.4343636 Vali Loss: 1.2202879 Test Loss: 0.4465666
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.0149734020233154
Epoch: 22, Steps: 59 | Train Loss: 0.4343429 Vali Loss: 1.2180668 Test Loss: 0.4467147
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_720_336_FITS_ETTh1_ftM_sl720_ll48_pl336_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.4473363757133484, mae:0.4467258155345917, rse:0.6367502808570862, corr:[0.25251254 0.26050076 0.26012364 0.25607228 0.25318807 0.2523282
 0.25229582 0.25228012 0.25166354 0.2509186  0.25042015 0.25024736
 0.25051743 0.25089112 0.25109226 0.25103423 0.25058    0.249877
 0.24909718 0.24846223 0.24818102 0.24813381 0.24802981 0.24785031
 0.24775882 0.24789351 0.24805003 0.24790262 0.24740942 0.24669786
 0.2461727  0.2459709  0.24604753 0.2461018  0.24574758 0.2451542
 0.24470861 0.24459706 0.24485303 0.24525343 0.24566205 0.2458526
 0.2457255  0.24545816 0.24537791 0.24567737 0.24634294 0.24697939
 0.24705295 0.24662097 0.24557114 0.2442619  0.24299836 0.24178125
 0.24084704 0.24037099 0.24015878 0.24003108 0.23972355 0.2393896
 0.2390622  0.23896463 0.23911637 0.23959804 0.24011117 0.24035946
 0.24025333 0.23979843 0.23949467 0.23945944 0.23951131 0.23928475
 0.23879603 0.23824741 0.2378334  0.23765197 0.23735748 0.23679204
 0.2361986  0.23590665 0.23592317 0.236009   0.23577693 0.23517624
 0.23451662 0.2342007  0.2343848  0.23481399 0.23499784 0.23474245
 0.23413996 0.23366404 0.23356663 0.23385885 0.2342876  0.23482622
 0.23542216 0.2358268  0.23582013 0.23566082 0.23551665 0.23538178
 0.235292   0.2352014  0.2350301  0.23471431 0.23419313 0.2336836
 0.23351195 0.23368435 0.23407443 0.23459157 0.23491739 0.2348528
 0.23443389 0.2338455  0.23343517 0.23350024 0.23404245 0.23467794
 0.23493999 0.23445074 0.23346286 0.23257639 0.23205854 0.23165517
 0.23127624 0.23104854 0.23078755 0.23054811 0.23014376 0.22944707
 0.2285956  0.227989   0.22801442 0.22855596 0.22912218 0.22920161
 0.22872745 0.22812213 0.22795475 0.22816406 0.22820881 0.2276245
 0.22632124 0.22462027 0.22309133 0.22212884 0.22196682 0.22221772
 0.2226401  0.2231164  0.22345124 0.22350332 0.22329834 0.22319211
 0.22336267 0.22371459 0.22403352 0.22420205 0.22417028 0.22437167
 0.22478382 0.22523254 0.22542845 0.22523834 0.22470506 0.22424133
 0.22431284 0.22488755 0.22545964 0.22571121 0.22552474 0.2250655
 0.224482   0.2239586  0.2233731  0.22290911 0.22257593 0.22247152
 0.2225085  0.22260843 0.22273986 0.22287764 0.22294034 0.2228366
 0.22253208 0.22223924 0.22232038 0.22279644 0.22334196 0.223604
 0.22333902 0.22262128 0.22167099 0.22084041 0.22041872 0.22023362
 0.22003603 0.21979104 0.2194464  0.2190714  0.2187864  0.2189306
 0.21936059 0.21986601 0.22007939 0.21979551 0.21921833 0.21866766
 0.21847317 0.21851918 0.21870163 0.21878116 0.21870494 0.21847565
 0.21807714 0.21770167 0.21743022 0.21742705 0.21783456 0.21811795
 0.21803027 0.21754207 0.21676312 0.21579422 0.21473384 0.21383935
 0.21312329 0.21260256 0.21269298 0.21338132 0.21409848 0.2144391
 0.21419895 0.213599   0.2132394  0.21340707 0.21401605 0.21433598
 0.21417159 0.2136978  0.2135386  0.21399112 0.21472369 0.21511373
 0.21498002 0.21461856 0.2143094  0.2140196  0.21350545 0.2127448
 0.21188048 0.2111626  0.21112578 0.21173112 0.21264283 0.21336794
 0.21375883 0.2137507  0.21383418 0.21413974 0.21447526 0.21439452
 0.21379746 0.21277983 0.21161151 0.21076345 0.21036895 0.21053468
 0.21110661 0.2114973  0.21130899 0.21087115 0.21033461 0.210002
 0.20997056 0.210075   0.21023631 0.21047851 0.21075757 0.21092173
 0.21066014 0.20987009 0.20921674 0.20903172 0.20938718 0.20980106
 0.20989536 0.20976956 0.20939238 0.20920703 0.20905353 0.20908031
 0.20926265 0.20955203 0.20976575 0.20969981 0.20910475 0.2083523
 0.20811312 0.2084962  0.20934461 0.20965382 0.20924428 0.20854126
 0.20855503 0.20914428 0.210038   0.2101236  0.2092457  0.2081249
 0.20776844 0.2081338  0.20786966 0.20632617 0.2043758  0.20288742
 0.20243971 0.20223913 0.2015781  0.2005411  0.19966693 0.19964415
 0.20007364 0.19945677 0.19782558 0.19716655 0.19791324 0.19938588
 0.19906871 0.19590084 0.19289343 0.19375964 0.19787294 0.19437504]
