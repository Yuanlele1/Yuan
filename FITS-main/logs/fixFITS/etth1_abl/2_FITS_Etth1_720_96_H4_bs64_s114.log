Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=134, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=134, out_features=151, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  18129664.0
params:  20385.0
Trainable parameters:  20385
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.5337588787078857
Epoch: 1, Steps: 61 | Train Loss: 0.6164906 Vali Loss: 1.4141291 Test Loss: 0.8169180
Validation loss decreased (inf --> 1.414129).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.446605920791626
Epoch: 2, Steps: 61 | Train Loss: 0.4896572 Vali Loss: 1.2741957 Test Loss: 0.7418745
Validation loss decreased (1.414129 --> 1.274196).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.4046099185943604
Epoch: 3, Steps: 61 | Train Loss: 0.4236337 Vali Loss: 1.2187822 Test Loss: 0.7169297
Validation loss decreased (1.274196 --> 1.218782).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.5653982162475586
Epoch: 4, Steps: 61 | Train Loss: 0.3832356 Vali Loss: 1.1890166 Test Loss: 0.7013232
Validation loss decreased (1.218782 --> 1.189017).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.4591326713562012
Epoch: 5, Steps: 61 | Train Loss: 0.3543584 Vali Loss: 1.1731737 Test Loss: 0.6968397
Validation loss decreased (1.189017 --> 1.173174).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.4842407703399658
Epoch: 6, Steps: 61 | Train Loss: 0.3312928 Vali Loss: 1.1504186 Test Loss: 0.6860556
Validation loss decreased (1.173174 --> 1.150419).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.653371810913086
Epoch: 7, Steps: 61 | Train Loss: 0.3120282 Vali Loss: 1.1338766 Test Loss: 0.6747703
Validation loss decreased (1.150419 --> 1.133877).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.4553544521331787
Epoch: 8, Steps: 61 | Train Loss: 0.2953194 Vali Loss: 1.1153837 Test Loss: 0.6683132
Validation loss decreased (1.133877 --> 1.115384).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.566157579421997
Epoch: 9, Steps: 61 | Train Loss: 0.2806530 Vali Loss: 1.0973253 Test Loss: 0.6570510
Validation loss decreased (1.115384 --> 1.097325).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.53847336769104
Epoch: 10, Steps: 61 | Train Loss: 0.2677180 Vali Loss: 1.0824839 Test Loss: 0.6458697
Validation loss decreased (1.097325 --> 1.082484).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.5811715126037598
Epoch: 11, Steps: 61 | Train Loss: 0.2560740 Vali Loss: 1.0646766 Test Loss: 0.6372109
Validation loss decreased (1.082484 --> 1.064677).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.5392236709594727
Epoch: 12, Steps: 61 | Train Loss: 0.2455255 Vali Loss: 1.0489771 Test Loss: 0.6265013
Validation loss decreased (1.064677 --> 1.048977).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.5688953399658203
Epoch: 13, Steps: 61 | Train Loss: 0.2361148 Vali Loss: 1.0350641 Test Loss: 0.6182439
Validation loss decreased (1.048977 --> 1.035064).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.4516229629516602
Epoch: 14, Steps: 61 | Train Loss: 0.2276172 Vali Loss: 1.0181227 Test Loss: 0.6080246
Validation loss decreased (1.035064 --> 1.018123).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.4424805641174316
Epoch: 15, Steps: 61 | Train Loss: 0.2198658 Vali Loss: 1.0089185 Test Loss: 0.6005039
Validation loss decreased (1.018123 --> 1.008919).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.5282509326934814
Epoch: 16, Steps: 61 | Train Loss: 0.2127367 Vali Loss: 0.9995019 Test Loss: 0.5936158
Validation loss decreased (1.008919 --> 0.999502).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.5117759704589844
Epoch: 17, Steps: 61 | Train Loss: 0.2062746 Vali Loss: 0.9836947 Test Loss: 0.5835284
Validation loss decreased (0.999502 --> 0.983695).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.5014925003051758
Epoch: 18, Steps: 61 | Train Loss: 0.2003034 Vali Loss: 0.9768943 Test Loss: 0.5772418
Validation loss decreased (0.983695 --> 0.976894).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.486224889755249
Epoch: 19, Steps: 61 | Train Loss: 0.1948461 Vali Loss: 0.9643439 Test Loss: 0.5709447
Validation loss decreased (0.976894 --> 0.964344).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.5696065425872803
Epoch: 20, Steps: 61 | Train Loss: 0.1898192 Vali Loss: 0.9551814 Test Loss: 0.5638732
Validation loss decreased (0.964344 --> 0.955181).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.4889583587646484
Epoch: 21, Steps: 61 | Train Loss: 0.1851269 Vali Loss: 0.9455762 Test Loss: 0.5579399
Validation loss decreased (0.955181 --> 0.945576).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.649620771408081
Epoch: 22, Steps: 61 | Train Loss: 0.1808220 Vali Loss: 0.9362682 Test Loss: 0.5530930
Validation loss decreased (0.945576 --> 0.936268).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.6873199939727783
Epoch: 23, Steps: 61 | Train Loss: 0.1768893 Vali Loss: 0.9280871 Test Loss: 0.5480986
Validation loss decreased (0.936268 --> 0.928087).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.6365008354187012
Epoch: 24, Steps: 61 | Train Loss: 0.1732348 Vali Loss: 0.9221386 Test Loss: 0.5436229
Validation loss decreased (0.928087 --> 0.922139).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.6391220092773438
Epoch: 25, Steps: 61 | Train Loss: 0.1697865 Vali Loss: 0.9190508 Test Loss: 0.5390535
Validation loss decreased (0.922139 --> 0.919051).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.523277997970581
Epoch: 26, Steps: 61 | Train Loss: 0.1666215 Vali Loss: 0.9107836 Test Loss: 0.5340834
Validation loss decreased (0.919051 --> 0.910784).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.4545726776123047
Epoch: 27, Steps: 61 | Train Loss: 0.1636845 Vali Loss: 0.9036406 Test Loss: 0.5307033
Validation loss decreased (0.910784 --> 0.903641).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.4800755977630615
Epoch: 28, Steps: 61 | Train Loss: 0.1609449 Vali Loss: 0.8968109 Test Loss: 0.5269740
Validation loss decreased (0.903641 --> 0.896811).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.410684585571289
Epoch: 29, Steps: 61 | Train Loss: 0.1583619 Vali Loss: 0.8942009 Test Loss: 0.5235390
Validation loss decreased (0.896811 --> 0.894201).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.5110549926757812
Epoch: 30, Steps: 61 | Train Loss: 0.1559288 Vali Loss: 0.8930690 Test Loss: 0.5202121
Validation loss decreased (0.894201 --> 0.893069).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.717299461364746
Epoch: 31, Steps: 61 | Train Loss: 0.1537585 Vali Loss: 0.8871505 Test Loss: 0.5171234
Validation loss decreased (0.893069 --> 0.887150).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.525162696838379
Epoch: 32, Steps: 61 | Train Loss: 0.1516302 Vali Loss: 0.8826036 Test Loss: 0.5142695
Validation loss decreased (0.887150 --> 0.882604).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.5907585620880127
Epoch: 33, Steps: 61 | Train Loss: 0.1496216 Vali Loss: 0.8779120 Test Loss: 0.5112898
Validation loss decreased (0.882604 --> 0.877912).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.498830795288086
Epoch: 34, Steps: 61 | Train Loss: 0.1478410 Vali Loss: 0.8752803 Test Loss: 0.5092331
Validation loss decreased (0.877912 --> 0.875280).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.5359671115875244
Epoch: 35, Steps: 61 | Train Loss: 0.1461343 Vali Loss: 0.8719717 Test Loss: 0.5062687
Validation loss decreased (0.875280 --> 0.871972).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.484508991241455
Epoch: 36, Steps: 61 | Train Loss: 0.1445252 Vali Loss: 0.8679163 Test Loss: 0.5041754
Validation loss decreased (0.871972 --> 0.867916).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.5140864849090576
Epoch: 37, Steps: 61 | Train Loss: 0.1429884 Vali Loss: 0.8660346 Test Loss: 0.5017405
Validation loss decreased (0.867916 --> 0.866035).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.5636732578277588
Epoch: 38, Steps: 61 | Train Loss: 0.1415080 Vali Loss: 0.8621356 Test Loss: 0.5001913
Validation loss decreased (0.866035 --> 0.862136).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.6894276142120361
Epoch: 39, Steps: 61 | Train Loss: 0.1401642 Vali Loss: 0.8594670 Test Loss: 0.4978479
Validation loss decreased (0.862136 --> 0.859467).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.5882785320281982
Epoch: 40, Steps: 61 | Train Loss: 0.1388866 Vali Loss: 0.8580377 Test Loss: 0.4962070
Validation loss decreased (0.859467 --> 0.858038).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.3669652938842773
Epoch: 41, Steps: 61 | Train Loss: 0.1376779 Vali Loss: 0.8502423 Test Loss: 0.4945578
Validation loss decreased (0.858038 --> 0.850242).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.4723310470581055
Epoch: 42, Steps: 61 | Train Loss: 0.1366147 Vali Loss: 0.8498973 Test Loss: 0.4928301
Validation loss decreased (0.850242 --> 0.849897).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.487987995147705
Epoch: 43, Steps: 61 | Train Loss: 0.1355130 Vali Loss: 0.8470297 Test Loss: 0.4910680
Validation loss decreased (0.849897 --> 0.847030).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.4634404182434082
Epoch: 44, Steps: 61 | Train Loss: 0.1345383 Vali Loss: 0.8435199 Test Loss: 0.4900949
Validation loss decreased (0.847030 --> 0.843520).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.5433785915374756
Epoch: 45, Steps: 61 | Train Loss: 0.1335366 Vali Loss: 0.8419006 Test Loss: 0.4882669
Validation loss decreased (0.843520 --> 0.841901).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.504525899887085
Epoch: 46, Steps: 61 | Train Loss: 0.1326503 Vali Loss: 0.8460697 Test Loss: 0.4871012
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.6447970867156982
Epoch: 47, Steps: 61 | Train Loss: 0.1317944 Vali Loss: 0.8434865 Test Loss: 0.4857806
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.583019495010376
Epoch: 48, Steps: 61 | Train Loss: 0.1309541 Vali Loss: 0.8424528 Test Loss: 0.4847703
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.7947158813476562
Epoch: 49, Steps: 61 | Train Loss: 0.1301964 Vali Loss: 0.8397712 Test Loss: 0.4837205
Validation loss decreased (0.841901 --> 0.839771).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.5771560668945312
Epoch: 50, Steps: 61 | Train Loss: 0.1295111 Vali Loss: 0.8344224 Test Loss: 0.4822541
Validation loss decreased (0.839771 --> 0.834422).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.527834415435791
Epoch: 51, Steps: 61 | Train Loss: 0.1288319 Vali Loss: 0.8368766 Test Loss: 0.4815671
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.5807020664215088
Epoch: 52, Steps: 61 | Train Loss: 0.1282047 Vali Loss: 0.8351600 Test Loss: 0.4804952
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.5759739875793457
Epoch: 53, Steps: 61 | Train Loss: 0.1275885 Vali Loss: 0.8329464 Test Loss: 0.4797293
Validation loss decreased (0.834422 --> 0.832946).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.5303287506103516
Epoch: 54, Steps: 61 | Train Loss: 0.1269639 Vali Loss: 0.8347224 Test Loss: 0.4788420
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.7668325901031494
Epoch: 55, Steps: 61 | Train Loss: 0.1264868 Vali Loss: 0.8304164 Test Loss: 0.4778478
Validation loss decreased (0.832946 --> 0.830416).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.6492664813995361
Epoch: 56, Steps: 61 | Train Loss: 0.1259421 Vali Loss: 0.8301901 Test Loss: 0.4768934
Validation loss decreased (0.830416 --> 0.830190).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.5918011665344238
Epoch: 57, Steps: 61 | Train Loss: 0.1254478 Vali Loss: 0.8279005 Test Loss: 0.4763675
Validation loss decreased (0.830190 --> 0.827900).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.5953090190887451
Epoch: 58, Steps: 61 | Train Loss: 0.1249549 Vali Loss: 0.8245192 Test Loss: 0.4756427
Validation loss decreased (0.827900 --> 0.824519).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.6055126190185547
Epoch: 59, Steps: 61 | Train Loss: 0.1244996 Vali Loss: 0.8262844 Test Loss: 0.4750037
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.5312063694000244
Epoch: 60, Steps: 61 | Train Loss: 0.1241143 Vali Loss: 0.8282982 Test Loss: 0.4742681
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.6258869171142578
Epoch: 61, Steps: 61 | Train Loss: 0.1236918 Vali Loss: 0.8228311 Test Loss: 0.4738224
Validation loss decreased (0.824519 --> 0.822831).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.4735794067382812
Epoch: 62, Steps: 61 | Train Loss: 0.1233269 Vali Loss: 0.8278230 Test Loss: 0.4732102
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.7206213474273682
Epoch: 63, Steps: 61 | Train Loss: 0.1229644 Vali Loss: 0.8190575 Test Loss: 0.4726720
Validation loss decreased (0.822831 --> 0.819057).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.6534090042114258
Epoch: 64, Steps: 61 | Train Loss: 0.1226337 Vali Loss: 0.8211417 Test Loss: 0.4722753
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.6388838291168213
Epoch: 65, Steps: 61 | Train Loss: 0.1222559 Vali Loss: 0.8230588 Test Loss: 0.4718211
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.5415136814117432
Epoch: 66, Steps: 61 | Train Loss: 0.1219730 Vali Loss: 0.8231300 Test Loss: 0.4712336
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.5658376216888428
Epoch: 67, Steps: 61 | Train Loss: 0.1216844 Vali Loss: 0.8212284 Test Loss: 0.4708619
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.548614501953125
Epoch: 68, Steps: 61 | Train Loss: 0.1213666 Vali Loss: 0.8223318 Test Loss: 0.4702769
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.7094101905822754
Epoch: 69, Steps: 61 | Train Loss: 0.1211345 Vali Loss: 0.8210548 Test Loss: 0.4700878
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.5735270977020264
Epoch: 70, Steps: 61 | Train Loss: 0.1208203 Vali Loss: 0.8169486 Test Loss: 0.4696076
Validation loss decreased (0.819057 --> 0.816949).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.6204063892364502
Epoch: 71, Steps: 61 | Train Loss: 0.1206115 Vali Loss: 0.8197904 Test Loss: 0.4692970
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.7525367736816406
Epoch: 72, Steps: 61 | Train Loss: 0.1203964 Vali Loss: 0.8170038 Test Loss: 0.4689794
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.5946776866912842
Epoch: 73, Steps: 61 | Train Loss: 0.1201883 Vali Loss: 0.8193401 Test Loss: 0.4687082
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.526071548461914
Epoch: 74, Steps: 61 | Train Loss: 0.1200193 Vali Loss: 0.8196653 Test Loss: 0.4682740
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.760974407196045
Epoch: 75, Steps: 61 | Train Loss: 0.1197712 Vali Loss: 0.8204707 Test Loss: 0.4679984
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.499925136566162
Epoch: 76, Steps: 61 | Train Loss: 0.1196231 Vali Loss: 0.8193231 Test Loss: 0.4677297
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.626577615737915
Epoch: 77, Steps: 61 | Train Loss: 0.1194187 Vali Loss: 0.8152953 Test Loss: 0.4674714
Validation loss decreased (0.816949 --> 0.815295).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.610992670059204
Epoch: 78, Steps: 61 | Train Loss: 0.1192412 Vali Loss: 0.8169684 Test Loss: 0.4672982
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.5596115589141846
Epoch: 79, Steps: 61 | Train Loss: 0.1190716 Vali Loss: 0.8165540 Test Loss: 0.4670236
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.6010303497314453
Epoch: 80, Steps: 61 | Train Loss: 0.1189267 Vali Loss: 0.8143791 Test Loss: 0.4667037
Validation loss decreased (0.815295 --> 0.814379).  Saving model ...
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.5877556800842285
Epoch: 81, Steps: 61 | Train Loss: 0.1187998 Vali Loss: 0.8157309 Test Loss: 0.4665228
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.7211112976074219
Epoch: 82, Steps: 61 | Train Loss: 0.1186546 Vali Loss: 0.8155252 Test Loss: 0.4663233
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.4365756511688232
Epoch: 83, Steps: 61 | Train Loss: 0.1185175 Vali Loss: 0.8134263 Test Loss: 0.4661247
Validation loss decreased (0.814379 --> 0.813426).  Saving model ...
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.616694688796997
Epoch: 84, Steps: 61 | Train Loss: 0.1183739 Vali Loss: 0.8173524 Test Loss: 0.4659522
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.441547155380249
Epoch: 85, Steps: 61 | Train Loss: 0.1182420 Vali Loss: 0.8161968 Test Loss: 0.4657792
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.422057867050171
Epoch: 86, Steps: 61 | Train Loss: 0.1181788 Vali Loss: 0.8135180 Test Loss: 0.4656391
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.404083251953125
Epoch: 87, Steps: 61 | Train Loss: 0.1180546 Vali Loss: 0.8113095 Test Loss: 0.4654077
Validation loss decreased (0.813426 --> 0.811309).  Saving model ...
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.4808850288391113
Epoch: 88, Steps: 61 | Train Loss: 0.1178804 Vali Loss: 0.8169342 Test Loss: 0.4652815
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.6318464279174805
Epoch: 89, Steps: 61 | Train Loss: 0.1178410 Vali Loss: 0.8138891 Test Loss: 0.4651387
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.7322325706481934
Epoch: 90, Steps: 61 | Train Loss: 0.1177180 Vali Loss: 0.8136846 Test Loss: 0.4650457
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.527637243270874
Epoch: 91, Steps: 61 | Train Loss: 0.1176497 Vali Loss: 0.8139484 Test Loss: 0.4649048
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 2.13177752494812
Epoch: 92, Steps: 61 | Train Loss: 0.1175742 Vali Loss: 0.8124470 Test Loss: 0.4647803
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.9281070232391357
Epoch: 93, Steps: 61 | Train Loss: 0.1175015 Vali Loss: 0.8132966 Test Loss: 0.4646351
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.7986361980438232
Epoch: 94, Steps: 61 | Train Loss: 0.1173752 Vali Loss: 0.8114732 Test Loss: 0.4645156
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.979372501373291
Epoch: 95, Steps: 61 | Train Loss: 0.1173640 Vali Loss: 0.8133115 Test Loss: 0.4644058
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.942331314086914
Epoch: 96, Steps: 61 | Train Loss: 0.1172945 Vali Loss: 0.8109691 Test Loss: 0.4642790
Validation loss decreased (0.811309 --> 0.810969).  Saving model ...
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.7829201221466064
Epoch: 97, Steps: 61 | Train Loss: 0.1172205 Vali Loss: 0.8129664 Test Loss: 0.4642038
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.839689016342163
Epoch: 98, Steps: 61 | Train Loss: 0.1171549 Vali Loss: 0.8136075 Test Loss: 0.4641444
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.899115800857544
Epoch: 99, Steps: 61 | Train Loss: 0.1171060 Vali Loss: 0.8129269 Test Loss: 0.4640106
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.983830451965332
Epoch: 100, Steps: 61 | Train Loss: 0.1170349 Vali Loss: 0.8113065 Test Loss: 0.4639624
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.1160680107021042e-06
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=134, out_features=151, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  18129664.0
params:  20385.0
Trainable parameters:  20385
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.9261796474456787
Epoch: 1, Steps: 61 | Train Loss: 0.3589478 Vali Loss: 0.7050430 Test Loss: 0.3867451
Validation loss decreased (inf --> 0.705043).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.8165748119354248
Epoch: 2, Steps: 61 | Train Loss: 0.3410719 Vali Loss: 0.7023547 Test Loss: 0.3848816
Validation loss decreased (0.705043 --> 0.702355).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.1659533977508545
Epoch: 3, Steps: 61 | Train Loss: 0.3386636 Vali Loss: 0.7013452 Test Loss: 0.3852237
Validation loss decreased (0.702355 --> 0.701345).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.9899442195892334
Epoch: 4, Steps: 61 | Train Loss: 0.3377332 Vali Loss: 0.6946906 Test Loss: 0.3854457
Validation loss decreased (0.701345 --> 0.694691).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.2769150733947754
Epoch: 5, Steps: 61 | Train Loss: 0.3369352 Vali Loss: 0.6974447 Test Loss: 0.3852599
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.9288902282714844
Epoch: 6, Steps: 61 | Train Loss: 0.3365739 Vali Loss: 0.6999387 Test Loss: 0.3849159
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.8793365955352783
Epoch: 7, Steps: 61 | Train Loss: 0.3361259 Vali Loss: 0.6993635 Test Loss: 0.3840537
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.101422071456909
Epoch: 8, Steps: 61 | Train Loss: 0.3356989 Vali Loss: 0.6994259 Test Loss: 0.3844939
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.0957608222961426
Epoch: 9, Steps: 61 | Train Loss: 0.3354760 Vali Loss: 0.6961219 Test Loss: 0.3842582
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.0604379177093506
Epoch: 10, Steps: 61 | Train Loss: 0.3353206 Vali Loss: 0.6982510 Test Loss: 0.3846189
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.1789469718933105
Epoch: 11, Steps: 61 | Train Loss: 0.3352997 Vali Loss: 0.7005101 Test Loss: 0.3850152
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.0749430656433105
Epoch: 12, Steps: 61 | Train Loss: 0.3351875 Vali Loss: 0.6965134 Test Loss: 0.3844139
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.1086487770080566
Epoch: 13, Steps: 61 | Train Loss: 0.3348570 Vali Loss: 0.7020923 Test Loss: 0.3844751
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.008047580718994
Epoch: 14, Steps: 61 | Train Loss: 0.3347622 Vali Loss: 0.6985669 Test Loss: 0.3842038
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.049009084701538
Epoch: 15, Steps: 61 | Train Loss: 0.3344398 Vali Loss: 0.7007385 Test Loss: 0.3843701
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.0408363342285156
Epoch: 16, Steps: 61 | Train Loss: 0.3344391 Vali Loss: 0.6969188 Test Loss: 0.3838666
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.024466037750244
Epoch: 17, Steps: 61 | Train Loss: 0.3344606 Vali Loss: 0.6985384 Test Loss: 0.3845549
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.0568690299987793
Epoch: 18, Steps: 61 | Train Loss: 0.3341816 Vali Loss: 0.6987464 Test Loss: 0.3846885
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.9881608486175537
Epoch: 19, Steps: 61 | Train Loss: 0.3341979 Vali Loss: 0.6984747 Test Loss: 0.3843226
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.0907604694366455
Epoch: 20, Steps: 61 | Train Loss: 0.3342929 Vali Loss: 0.6965550 Test Loss: 0.3840364
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.980182409286499
Epoch: 21, Steps: 61 | Train Loss: 0.3341302 Vali Loss: 0.6994292 Test Loss: 0.3840794
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.0792617797851562
Epoch: 22, Steps: 61 | Train Loss: 0.3342333 Vali Loss: 0.6989020 Test Loss: 0.3841916
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.0423390865325928
Epoch: 23, Steps: 61 | Train Loss: 0.3339559 Vali Loss: 0.6939566 Test Loss: 0.3840928
Validation loss decreased (0.694691 --> 0.693957).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.918405294418335
Epoch: 24, Steps: 61 | Train Loss: 0.3340421 Vali Loss: 0.6982751 Test Loss: 0.3839535
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.879260778427124
Epoch: 25, Steps: 61 | Train Loss: 0.3340141 Vali Loss: 0.6968511 Test Loss: 0.3842079
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.0166492462158203
Epoch: 26, Steps: 61 | Train Loss: 0.3336021 Vali Loss: 0.6991888 Test Loss: 0.3841803
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.965008020401001
Epoch: 27, Steps: 61 | Train Loss: 0.3336969 Vali Loss: 0.6977178 Test Loss: 0.3841234
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.1212360858917236
Epoch: 28, Steps: 61 | Train Loss: 0.3338575 Vali Loss: 0.7010064 Test Loss: 0.3842826
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.8536779880523682
Epoch: 29, Steps: 61 | Train Loss: 0.3332083 Vali Loss: 0.6942564 Test Loss: 0.3844879
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.9872024059295654
Epoch: 30, Steps: 61 | Train Loss: 0.3336851 Vali Loss: 0.6985425 Test Loss: 0.3842710
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.9416863918304443
Epoch: 31, Steps: 61 | Train Loss: 0.3334622 Vali Loss: 0.6966813 Test Loss: 0.3841554
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.988818645477295
Epoch: 32, Steps: 61 | Train Loss: 0.3335767 Vali Loss: 0.6989362 Test Loss: 0.3840292
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.917165994644165
Epoch: 33, Steps: 61 | Train Loss: 0.3336799 Vali Loss: 0.6951869 Test Loss: 0.3840762
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.9007627964019775
Epoch: 34, Steps: 61 | Train Loss: 0.3334952 Vali Loss: 0.6995114 Test Loss: 0.3841064
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.0910773277282715
Epoch: 35, Steps: 61 | Train Loss: 0.3334475 Vali Loss: 0.7018859 Test Loss: 0.3841393
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.8744096755981445
Epoch: 36, Steps: 61 | Train Loss: 0.3336142 Vali Loss: 0.6994979 Test Loss: 0.3841023
EarlyStopping counter: 13 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.1064302921295166
Epoch: 37, Steps: 61 | Train Loss: 0.3334180 Vali Loss: 0.6968117 Test Loss: 0.3842087
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.047577381134033
Epoch: 38, Steps: 61 | Train Loss: 0.3334584 Vali Loss: 0.6978798 Test Loss: 0.3841322
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.9561455249786377
Epoch: 39, Steps: 61 | Train Loss: 0.3333951 Vali Loss: 0.6968198 Test Loss: 0.3841919
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.0632636547088623
Epoch: 40, Steps: 61 | Train Loss: 0.3332592 Vali Loss: 0.7000060 Test Loss: 0.3841839
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.9513745307922363
Epoch: 41, Steps: 61 | Train Loss: 0.3333421 Vali Loss: 0.6962262 Test Loss: 0.3841352
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.9163107872009277
Epoch: 42, Steps: 61 | Train Loss: 0.3333753 Vali Loss: 0.6944885 Test Loss: 0.3841482
EarlyStopping counter: 19 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.9653613567352295
Epoch: 43, Steps: 61 | Train Loss: 0.3332791 Vali Loss: 0.7000352 Test Loss: 0.3841322
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.38370048999786377, mae:0.40605008602142334, rse:0.5883747339248657, corr:[0.27156305 0.27802628 0.27889988 0.27638853 0.27340543 0.27128536
 0.26999637 0.26924744 0.26867446 0.2686453  0.26896694 0.26904482
 0.26886648 0.26867357 0.2687547  0.26913136 0.269279   0.26906967
 0.26845393 0.26765195 0.26708248 0.2670013  0.26694375 0.26706955
 0.26721585 0.26733723 0.26725858 0.26682916 0.2662292  0.26565093
 0.26530114 0.2650598  0.26497996 0.26497647 0.26481724 0.26466313
 0.26460722 0.2646224  0.2646592  0.2646654  0.26482955 0.2649489
 0.26481295 0.2645969  0.2645817  0.26479787 0.26517192 0.26536945
 0.26485497 0.26407662 0.2629327  0.26159695 0.2603366  0.25913563
 0.25832322 0.25793973 0.2576738  0.25749493 0.2571122  0.25684306
 0.2566783  0.25661302 0.25650522 0.2564116  0.25632066 0.25625408
 0.2563144  0.25619808 0.25603914 0.2560462  0.25615874 0.25587338
 0.25511333 0.2539477  0.25266936 0.2519558  0.25170988 0.2514
 0.2507222  0.2498641  0.24915896 0.24888295 0.24871658 0.2484514
 0.24831161 0.24842511 0.24871542 0.24857675 0.24795009 0.24744858
 0.24754886 0.24799769 0.24805887 0.24789616 0.24910082 0.25231597]
