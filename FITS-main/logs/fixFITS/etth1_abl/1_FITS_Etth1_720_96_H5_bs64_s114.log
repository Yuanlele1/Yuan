Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=165, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=165, out_features=187, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  27646080.0
params:  31042.0
Trainable parameters:  31042
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.6394407749176025
Epoch: 1, Steps: 61 | Train Loss: 0.5279685 Vali Loss: 0.8944467 Test Loss: 0.4474041
Validation loss decreased (inf --> 0.894447).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.6053383350372314
Epoch: 2, Steps: 61 | Train Loss: 0.3825500 Vali Loss: 0.7981052 Test Loss: 0.3937744
Validation loss decreased (0.894447 --> 0.798105).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.4680986404418945
Epoch: 3, Steps: 61 | Train Loss: 0.3580852 Vali Loss: 0.7669081 Test Loss: 0.3842171
Validation loss decreased (0.798105 --> 0.766908).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.3588309288024902
Epoch: 4, Steps: 61 | Train Loss: 0.3503165 Vali Loss: 0.7516958 Test Loss: 0.3824815
Validation loss decreased (0.766908 --> 0.751696).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.445997953414917
Epoch: 5, Steps: 61 | Train Loss: 0.3459958 Vali Loss: 0.7395145 Test Loss: 0.3817376
Validation loss decreased (0.751696 --> 0.739514).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.422940731048584
Epoch: 6, Steps: 61 | Train Loss: 0.3432389 Vali Loss: 0.7333050 Test Loss: 0.3814349
Validation loss decreased (0.739514 --> 0.733305).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.5452351570129395
Epoch: 7, Steps: 61 | Train Loss: 0.3414109 Vali Loss: 0.7237174 Test Loss: 0.3813922
Validation loss decreased (0.733305 --> 0.723717).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.5741524696350098
Epoch: 8, Steps: 61 | Train Loss: 0.3399255 Vali Loss: 0.7212289 Test Loss: 0.3815543
Validation loss decreased (0.723717 --> 0.721229).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.4219865798950195
Epoch: 9, Steps: 61 | Train Loss: 0.3388325 Vali Loss: 0.7203727 Test Loss: 0.3811154
Validation loss decreased (0.721229 --> 0.720373).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.4772307872772217
Epoch: 10, Steps: 61 | Train Loss: 0.3378670 Vali Loss: 0.7135895 Test Loss: 0.3810294
Validation loss decreased (0.720373 --> 0.713590).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.4714686870574951
Epoch: 11, Steps: 61 | Train Loss: 0.3371926 Vali Loss: 0.7160199 Test Loss: 0.3812160
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.4008352756500244
Epoch: 12, Steps: 61 | Train Loss: 0.3364594 Vali Loss: 0.7121286 Test Loss: 0.3808325
Validation loss decreased (0.713590 --> 0.712129).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.5266637802124023
Epoch: 13, Steps: 61 | Train Loss: 0.3360228 Vali Loss: 0.7120593 Test Loss: 0.3810662
Validation loss decreased (0.712129 --> 0.712059).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.670588731765747
Epoch: 14, Steps: 61 | Train Loss: 0.3352983 Vali Loss: 0.7062146 Test Loss: 0.3807381
Validation loss decreased (0.712059 --> 0.706215).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.4989755153656006
Epoch: 15, Steps: 61 | Train Loss: 0.3352867 Vali Loss: 0.7081096 Test Loss: 0.3808317
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.5202441215515137
Epoch: 16, Steps: 61 | Train Loss: 0.3347415 Vali Loss: 0.7068534 Test Loss: 0.3807073
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.5042088031768799
Epoch: 17, Steps: 61 | Train Loss: 0.3344874 Vali Loss: 0.7087178 Test Loss: 0.3808749
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.5289764404296875
Epoch: 18, Steps: 61 | Train Loss: 0.3342787 Vali Loss: 0.7054850 Test Loss: 0.3807524
Validation loss decreased (0.706215 --> 0.705485).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.402421474456787
Epoch: 19, Steps: 61 | Train Loss: 0.3340009 Vali Loss: 0.7047707 Test Loss: 0.3807301
Validation loss decreased (0.705485 --> 0.704771).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.4758639335632324
Epoch: 20, Steps: 61 | Train Loss: 0.3338197 Vali Loss: 0.7043061 Test Loss: 0.3809081
Validation loss decreased (0.704771 --> 0.704306).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.582737922668457
Epoch: 21, Steps: 61 | Train Loss: 0.3335308 Vali Loss: 0.7070072 Test Loss: 0.3807728
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.3887417316436768
Epoch: 22, Steps: 61 | Train Loss: 0.3333813 Vali Loss: 0.7060512 Test Loss: 0.3809159
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.4940617084503174
Epoch: 23, Steps: 61 | Train Loss: 0.3332502 Vali Loss: 0.7059377 Test Loss: 0.3806948
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.4590528011322021
Epoch: 24, Steps: 61 | Train Loss: 0.3330926 Vali Loss: 0.7052497 Test Loss: 0.3809552
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.383673906326294
Epoch: 25, Steps: 61 | Train Loss: 0.3329923 Vali Loss: 0.7012480 Test Loss: 0.3807410
Validation loss decreased (0.704306 --> 0.701248).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.5870258808135986
Epoch: 26, Steps: 61 | Train Loss: 0.3329049 Vali Loss: 0.7017890 Test Loss: 0.3809181
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.598757266998291
Epoch: 27, Steps: 61 | Train Loss: 0.3327393 Vali Loss: 0.7049829 Test Loss: 0.3810092
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.587186574935913
Epoch: 28, Steps: 61 | Train Loss: 0.3324252 Vali Loss: 0.7013964 Test Loss: 0.3809866
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.3345470428466797
Epoch: 29, Steps: 61 | Train Loss: 0.3326670 Vali Loss: 0.7026741 Test Loss: 0.3809867
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.4389820098876953
Epoch: 30, Steps: 61 | Train Loss: 0.3323997 Vali Loss: 0.7049645 Test Loss: 0.3810205
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.4737021923065186
Epoch: 31, Steps: 61 | Train Loss: 0.3322623 Vali Loss: 0.7019715 Test Loss: 0.3809110
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.4075872898101807
Epoch: 32, Steps: 61 | Train Loss: 0.3321933 Vali Loss: 0.7032769 Test Loss: 0.3809548
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.579949140548706
Epoch: 33, Steps: 61 | Train Loss: 0.3323038 Vali Loss: 0.7034318 Test Loss: 0.3809216
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.645522117614746
Epoch: 34, Steps: 61 | Train Loss: 0.3321954 Vali Loss: 0.6980546 Test Loss: 0.3809438
Validation loss decreased (0.701248 --> 0.698055).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.4130184650421143
Epoch: 35, Steps: 61 | Train Loss: 0.3319835 Vali Loss: 0.7025912 Test Loss: 0.3809022
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.4412205219268799
Epoch: 36, Steps: 61 | Train Loss: 0.3320902 Vali Loss: 0.7022197 Test Loss: 0.3809199
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.5101799964904785
Epoch: 37, Steps: 61 | Train Loss: 0.3319184 Vali Loss: 0.7046165 Test Loss: 0.3808548
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.5176444053649902
Epoch: 38, Steps: 61 | Train Loss: 0.3318189 Vali Loss: 0.7013701 Test Loss: 0.3810531
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.5258145332336426
Epoch: 39, Steps: 61 | Train Loss: 0.3317278 Vali Loss: 0.7015289 Test Loss: 0.3809668
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.6514763832092285
Epoch: 40, Steps: 61 | Train Loss: 0.3315544 Vali Loss: 0.7038931 Test Loss: 0.3810275
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.5766687393188477
Epoch: 41, Steps: 61 | Train Loss: 0.3318053 Vali Loss: 0.7030694 Test Loss: 0.3810915
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.4246182441711426
Epoch: 42, Steps: 61 | Train Loss: 0.3317736 Vali Loss: 0.7000475 Test Loss: 0.3809651
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.4551055431365967
Epoch: 43, Steps: 61 | Train Loss: 0.3315586 Vali Loss: 0.6983720 Test Loss: 0.3809617
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.4190473556518555
Epoch: 44, Steps: 61 | Train Loss: 0.3317134 Vali Loss: 0.7009318 Test Loss: 0.3810425
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.4295549392700195
Epoch: 45, Steps: 61 | Train Loss: 0.3317471 Vali Loss: 0.7027014 Test Loss: 0.3810528
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.513920545578003
Epoch: 46, Steps: 61 | Train Loss: 0.3316647 Vali Loss: 0.6966240 Test Loss: 0.3811496
Validation loss decreased (0.698055 --> 0.696624).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.6098504066467285
Epoch: 47, Steps: 61 | Train Loss: 0.3314080 Vali Loss: 0.7023052 Test Loss: 0.3810972
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.4669196605682373
Epoch: 48, Steps: 61 | Train Loss: 0.3315605 Vali Loss: 0.6999207 Test Loss: 0.3811143
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.417327642440796
Epoch: 49, Steps: 61 | Train Loss: 0.3314552 Vali Loss: 0.6999750 Test Loss: 0.3811362
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.4173457622528076
Epoch: 50, Steps: 61 | Train Loss: 0.3313884 Vali Loss: 0.7020133 Test Loss: 0.3811224
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.4887404441833496
Epoch: 51, Steps: 61 | Train Loss: 0.3313795 Vali Loss: 0.7011414 Test Loss: 0.3811325
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.466043472290039
Epoch: 52, Steps: 61 | Train Loss: 0.3314304 Vali Loss: 0.7032698 Test Loss: 0.3811155
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.734306812286377
Epoch: 53, Steps: 61 | Train Loss: 0.3312577 Vali Loss: 0.7014043 Test Loss: 0.3810869
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.6340131759643555
Epoch: 54, Steps: 61 | Train Loss: 0.3311990 Vali Loss: 0.7018995 Test Loss: 0.3810916
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.5170977115631104
Epoch: 55, Steps: 61 | Train Loss: 0.3313311 Vali Loss: 0.7011493 Test Loss: 0.3811646
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.421027660369873
Epoch: 56, Steps: 61 | Train Loss: 0.3311186 Vali Loss: 0.7010074 Test Loss: 0.3811356
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.4115464687347412
Epoch: 57, Steps: 61 | Train Loss: 0.3313186 Vali Loss: 0.7013173 Test Loss: 0.3810942
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.5378894805908203
Epoch: 58, Steps: 61 | Train Loss: 0.3311542 Vali Loss: 0.7010480 Test Loss: 0.3811087
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.463578462600708
Epoch: 59, Steps: 61 | Train Loss: 0.3310990 Vali Loss: 0.6986259 Test Loss: 0.3811517
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.430793285369873
Epoch: 60, Steps: 61 | Train Loss: 0.3312529 Vali Loss: 0.6999930 Test Loss: 0.3811478
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.4878277778625488
Epoch: 61, Steps: 61 | Train Loss: 0.3313218 Vali Loss: 0.6970841 Test Loss: 0.3811280
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.5048260688781738
Epoch: 62, Steps: 61 | Train Loss: 0.3311560 Vali Loss: 0.7006308 Test Loss: 0.3811281
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.5259168148040771
Epoch: 63, Steps: 61 | Train Loss: 0.3312859 Vali Loss: 0.6954532 Test Loss: 0.3811506
Validation loss decreased (0.696624 --> 0.695453).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.3704795837402344
Epoch: 64, Steps: 61 | Train Loss: 0.3311970 Vali Loss: 0.7017246 Test Loss: 0.3811039
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.4888379573822021
Epoch: 65, Steps: 61 | Train Loss: 0.3310662 Vali Loss: 0.7012760 Test Loss: 0.3811627
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.6119613647460938
Epoch: 66, Steps: 61 | Train Loss: 0.3311481 Vali Loss: 0.7012857 Test Loss: 0.3811501
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.525848388671875
Epoch: 67, Steps: 61 | Train Loss: 0.3312513 Vali Loss: 0.6983830 Test Loss: 0.3811673
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.4272620677947998
Epoch: 68, Steps: 61 | Train Loss: 0.3311199 Vali Loss: 0.7008759 Test Loss: 0.3811618
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.4652149677276611
Epoch: 69, Steps: 61 | Train Loss: 0.3310651 Vali Loss: 0.6992600 Test Loss: 0.3811467
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.4738178253173828
Epoch: 70, Steps: 61 | Train Loss: 0.3312001 Vali Loss: 0.7003105 Test Loss: 0.3811630
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.3574326038360596
Epoch: 71, Steps: 61 | Train Loss: 0.3311922 Vali Loss: 0.6996518 Test Loss: 0.3811445
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.4314517974853516
Epoch: 72, Steps: 61 | Train Loss: 0.3311623 Vali Loss: 0.7029583 Test Loss: 0.3811630
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.637601613998413
Epoch: 73, Steps: 61 | Train Loss: 0.3310849 Vali Loss: 0.7004724 Test Loss: 0.3811802
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.8221435546875
Epoch: 74, Steps: 61 | Train Loss: 0.3311573 Vali Loss: 0.6991687 Test Loss: 0.3811749
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.640176773071289
Epoch: 75, Steps: 61 | Train Loss: 0.3309968 Vali Loss: 0.7019904 Test Loss: 0.3811661
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.4121723175048828
Epoch: 76, Steps: 61 | Train Loss: 0.3310934 Vali Loss: 0.7011698 Test Loss: 0.3811627
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.4479401111602783
Epoch: 77, Steps: 61 | Train Loss: 0.3310704 Vali Loss: 0.6996957 Test Loss: 0.3811522
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.4741933345794678
Epoch: 78, Steps: 61 | Train Loss: 0.3312524 Vali Loss: 0.6991560 Test Loss: 0.3811697
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.600013256072998
Epoch: 79, Steps: 61 | Train Loss: 0.3310801 Vali Loss: 0.7005452 Test Loss: 0.3811782
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.4994142055511475
Epoch: 80, Steps: 61 | Train Loss: 0.3310982 Vali Loss: 0.6990428 Test Loss: 0.3811652
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.4596223831176758
Epoch: 81, Steps: 61 | Train Loss: 0.3310411 Vali Loss: 0.6990858 Test Loss: 0.3811763
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.414536714553833
Epoch: 82, Steps: 61 | Train Loss: 0.3311701 Vali Loss: 0.6975222 Test Loss: 0.3811655
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.5149047374725342
Epoch: 83, Steps: 61 | Train Loss: 0.3310826 Vali Loss: 0.7004811 Test Loss: 0.3811598
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.38078609108924866, mae:0.40353870391845703, rse:0.586135983467102, corr:[0.26656628 0.2774615  0.27801293 0.2770926  0.27575037 0.27339146
 0.27139047 0.2707527  0.27097446 0.27125788 0.27114135 0.27073988
 0.27064404 0.27072456 0.27085668 0.27096283 0.2709492  0.27080888
 0.27043986 0.26988932 0.2695281  0.2694377  0.26918745 0.2691377
 0.26921025 0.2691509  0.2688567  0.26854718 0.2683659  0.26811504
 0.2676388  0.26702824 0.26672488 0.26682067 0.26682925 0.26676035
 0.26667002 0.26664397 0.26666436 0.26676515 0.267158   0.2675292
 0.26751226 0.26723546 0.26713747 0.26732194 0.26768053 0.26788044
 0.26744607 0.2666739  0.2655685  0.26427498 0.26301    0.26179522
 0.26102066 0.2605736  0.2601614  0.2599599  0.25976983 0.25975126
 0.2596324  0.25948638 0.2593109  0.25914544 0.25896126 0.25906277
 0.25955364 0.25964418 0.2590749  0.25861025 0.2587409  0.25877705
 0.258057   0.2567134  0.25553495 0.25534812 0.25515446 0.2541725
 0.2530905  0.25269672 0.25241137 0.25155026 0.25049937 0.2502097
 0.25037012 0.24982496 0.24916558 0.24906564 0.24889037 0.24759303
 0.24652945 0.24701074 0.246844   0.24414544 0.24497366 0.25324517]
