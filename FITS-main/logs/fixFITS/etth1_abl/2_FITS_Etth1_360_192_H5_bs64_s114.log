Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_360_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_360_192_FITS_ETTh1_ftM_sl360_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8089
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=90, out_features=138, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  11128320.0
params:  12558.0
Trainable parameters:  12558
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.7642261981964111
Epoch: 1, Steps: 63 | Train Loss: 0.6490885 Vali Loss: 1.6479971 Test Loss: 0.8480974
Validation loss decreased (inf --> 1.647997).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.1876156330108643
Epoch: 2, Steps: 63 | Train Loss: 0.5168942 Vali Loss: 1.4790775 Test Loss: 0.7519896
Validation loss decreased (1.647997 --> 1.479077).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.292156457901001
Epoch: 3, Steps: 63 | Train Loss: 0.4470903 Vali Loss: 1.3924613 Test Loss: 0.7046185
Validation loss decreased (1.479077 --> 1.392461).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.1971712112426758
Epoch: 4, Steps: 63 | Train Loss: 0.4062873 Vali Loss: 1.3428831 Test Loss: 0.6797970
Validation loss decreased (1.392461 --> 1.342883).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.4207773208618164
Epoch: 5, Steps: 63 | Train Loss: 0.3786691 Vali Loss: 1.3061999 Test Loss: 0.6611626
Validation loss decreased (1.342883 --> 1.306200).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.3591899871826172
Epoch: 6, Steps: 63 | Train Loss: 0.3576375 Vali Loss: 1.2790437 Test Loss: 0.6469843
Validation loss decreased (1.306200 --> 1.279044).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.3560447692871094
Epoch: 7, Steps: 63 | Train Loss: 0.3403816 Vali Loss: 1.2553180 Test Loss: 0.6336265
Validation loss decreased (1.279044 --> 1.255318).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.421642780303955
Epoch: 8, Steps: 63 | Train Loss: 0.3259944 Vali Loss: 1.2346158 Test Loss: 0.6216562
Validation loss decreased (1.255318 --> 1.234616).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.248150110244751
Epoch: 9, Steps: 63 | Train Loss: 0.3133967 Vali Loss: 1.2176752 Test Loss: 0.6121417
Validation loss decreased (1.234616 --> 1.217675).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.1714882850646973
Epoch: 10, Steps: 63 | Train Loss: 0.3023966 Vali Loss: 1.2010088 Test Loss: 0.6018708
Validation loss decreased (1.217675 --> 1.201009).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.2170720100402832
Epoch: 11, Steps: 63 | Train Loss: 0.2928052 Vali Loss: 1.1873434 Test Loss: 0.5933556
Validation loss decreased (1.201009 --> 1.187343).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.5629069805145264
Epoch: 12, Steps: 63 | Train Loss: 0.2841883 Vali Loss: 1.1749526 Test Loss: 0.5854114
Validation loss decreased (1.187343 --> 1.174953).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.1849513053894043
Epoch: 13, Steps: 63 | Train Loss: 0.2766208 Vali Loss: 1.1620178 Test Loss: 0.5769572
Validation loss decreased (1.174953 --> 1.162018).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.1983869075775146
Epoch: 14, Steps: 63 | Train Loss: 0.2696170 Vali Loss: 1.1523467 Test Loss: 0.5707449
Validation loss decreased (1.162018 --> 1.152347).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.2600104808807373
Epoch: 15, Steps: 63 | Train Loss: 0.2633462 Vali Loss: 1.1417228 Test Loss: 0.5638400
Validation loss decreased (1.152347 --> 1.141723).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.2314002513885498
Epoch: 16, Steps: 63 | Train Loss: 0.2578137 Vali Loss: 1.1325895 Test Loss: 0.5577757
Validation loss decreased (1.141723 --> 1.132589).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.2325654029846191
Epoch: 17, Steps: 63 | Train Loss: 0.2528907 Vali Loss: 1.1229222 Test Loss: 0.5514562
Validation loss decreased (1.132589 --> 1.122922).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.0999500751495361
Epoch: 18, Steps: 63 | Train Loss: 0.2482655 Vali Loss: 1.1158590 Test Loss: 0.5465314
Validation loss decreased (1.122922 --> 1.115859).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.1415824890136719
Epoch: 19, Steps: 63 | Train Loss: 0.2441132 Vali Loss: 1.1085373 Test Loss: 0.5421445
Validation loss decreased (1.115859 --> 1.108537).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.162674903869629
Epoch: 20, Steps: 63 | Train Loss: 0.2401619 Vali Loss: 1.1009322 Test Loss: 0.5371773
Validation loss decreased (1.108537 --> 1.100932).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.2074921131134033
Epoch: 21, Steps: 63 | Train Loss: 0.2366647 Vali Loss: 1.0950276 Test Loss: 0.5328022
Validation loss decreased (1.100932 --> 1.095028).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.3041496276855469
Epoch: 22, Steps: 63 | Train Loss: 0.2334950 Vali Loss: 1.0887052 Test Loss: 0.5285668
Validation loss decreased (1.095028 --> 1.088705).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.7697796821594238
Epoch: 23, Steps: 63 | Train Loss: 0.2305037 Vali Loss: 1.0833141 Test Loss: 0.5250393
Validation loss decreased (1.088705 --> 1.083314).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.4225554466247559
Epoch: 24, Steps: 63 | Train Loss: 0.2276357 Vali Loss: 1.0782827 Test Loss: 0.5215419
Validation loss decreased (1.083314 --> 1.078283).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.606602668762207
Epoch: 25, Steps: 63 | Train Loss: 0.2252577 Vali Loss: 1.0726674 Test Loss: 0.5183843
Validation loss decreased (1.078283 --> 1.072667).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.4004974365234375
Epoch: 26, Steps: 63 | Train Loss: 0.2229556 Vali Loss: 1.0686457 Test Loss: 0.5149336
Validation loss decreased (1.072667 --> 1.068646).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.6276700496673584
Epoch: 27, Steps: 63 | Train Loss: 0.2207485 Vali Loss: 1.0643820 Test Loss: 0.5122632
Validation loss decreased (1.068646 --> 1.064382).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.5144100189208984
Epoch: 28, Steps: 63 | Train Loss: 0.2186401 Vali Loss: 1.0605892 Test Loss: 0.5095178
Validation loss decreased (1.064382 --> 1.060589).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.488818883895874
Epoch: 29, Steps: 63 | Train Loss: 0.2167603 Vali Loss: 1.0566448 Test Loss: 0.5070590
Validation loss decreased (1.060589 --> 1.056645).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.8006272315979004
Epoch: 30, Steps: 63 | Train Loss: 0.2151378 Vali Loss: 1.0534112 Test Loss: 0.5048530
Validation loss decreased (1.056645 --> 1.053411).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.440850019454956
Epoch: 31, Steps: 63 | Train Loss: 0.2135325 Vali Loss: 1.0497290 Test Loss: 0.5025224
Validation loss decreased (1.053411 --> 1.049729).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.4895026683807373
Epoch: 32, Steps: 63 | Train Loss: 0.2119521 Vali Loss: 1.0469511 Test Loss: 0.5003401
Validation loss decreased (1.049729 --> 1.046951).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.4925990104675293
Epoch: 33, Steps: 63 | Train Loss: 0.2104905 Vali Loss: 1.0439476 Test Loss: 0.4982066
Validation loss decreased (1.046951 --> 1.043948).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.4180779457092285
Epoch: 34, Steps: 63 | Train Loss: 0.2092472 Vali Loss: 1.0408496 Test Loss: 0.4964423
Validation loss decreased (1.043948 --> 1.040850).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.5638420581817627
Epoch: 35, Steps: 63 | Train Loss: 0.2079917 Vali Loss: 1.0388162 Test Loss: 0.4947115
Validation loss decreased (1.040850 --> 1.038816).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.4804587364196777
Epoch: 36, Steps: 63 | Train Loss: 0.2068657 Vali Loss: 1.0360178 Test Loss: 0.4929383
Validation loss decreased (1.038816 --> 1.036018).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.9414966106414795
Epoch: 37, Steps: 63 | Train Loss: 0.2057787 Vali Loss: 1.0339787 Test Loss: 0.4913993
Validation loss decreased (1.036018 --> 1.033979).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.5063931941986084
Epoch: 38, Steps: 63 | Train Loss: 0.2046715 Vali Loss: 1.0317692 Test Loss: 0.4898481
Validation loss decreased (1.033979 --> 1.031769).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.8609485626220703
Epoch: 39, Steps: 63 | Train Loss: 0.2038465 Vali Loss: 1.0293034 Test Loss: 0.4885225
Validation loss decreased (1.031769 --> 1.029303).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.493441104888916
Epoch: 40, Steps: 63 | Train Loss: 0.2028793 Vali Loss: 1.0277213 Test Loss: 0.4872594
Validation loss decreased (1.029303 --> 1.027721).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.4924037456512451
Epoch: 41, Steps: 63 | Train Loss: 0.2019144 Vali Loss: 1.0258502 Test Loss: 0.4859694
Validation loss decreased (1.027721 --> 1.025850).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.4739017486572266
Epoch: 42, Steps: 63 | Train Loss: 0.2012169 Vali Loss: 1.0241541 Test Loss: 0.4847154
Validation loss decreased (1.025850 --> 1.024154).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.3883647918701172
Epoch: 43, Steps: 63 | Train Loss: 0.2004935 Vali Loss: 1.0221456 Test Loss: 0.4836889
Validation loss decreased (1.024154 --> 1.022146).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.5126841068267822
Epoch: 44, Steps: 63 | Train Loss: 0.1998468 Vali Loss: 1.0203707 Test Loss: 0.4826149
Validation loss decreased (1.022146 --> 1.020371).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.544386625289917
Epoch: 45, Steps: 63 | Train Loss: 0.1990775 Vali Loss: 1.0195055 Test Loss: 0.4816097
Validation loss decreased (1.020371 --> 1.019506).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.594301462173462
Epoch: 46, Steps: 63 | Train Loss: 0.1983586 Vali Loss: 1.0179616 Test Loss: 0.4808162
Validation loss decreased (1.019506 --> 1.017962).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.5335028171539307
Epoch: 47, Steps: 63 | Train Loss: 0.1979107 Vali Loss: 1.0166291 Test Loss: 0.4797229
Validation loss decreased (1.017962 --> 1.016629).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.414489507675171
Epoch: 48, Steps: 63 | Train Loss: 0.1972686 Vali Loss: 1.0156062 Test Loss: 0.4789533
Validation loss decreased (1.016629 --> 1.015606).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.5276319980621338
Epoch: 49, Steps: 63 | Train Loss: 0.1968216 Vali Loss: 1.0140477 Test Loss: 0.4781955
Validation loss decreased (1.015606 --> 1.014048).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.6051294803619385
Epoch: 50, Steps: 63 | Train Loss: 0.1961509 Vali Loss: 1.0129240 Test Loss: 0.4774345
Validation loss decreased (1.014048 --> 1.012924).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.429168701171875
Epoch: 51, Steps: 63 | Train Loss: 0.1958278 Vali Loss: 1.0122988 Test Loss: 0.4766978
Validation loss decreased (1.012924 --> 1.012299).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.5051262378692627
Epoch: 52, Steps: 63 | Train Loss: 0.1953252 Vali Loss: 1.0107327 Test Loss: 0.4759607
Validation loss decreased (1.012299 --> 1.010733).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.5367412567138672
Epoch: 53, Steps: 63 | Train Loss: 0.1949159 Vali Loss: 1.0104280 Test Loss: 0.4754289
Validation loss decreased (1.010733 --> 1.010428).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.522857904434204
Epoch: 54, Steps: 63 | Train Loss: 0.1943903 Vali Loss: 1.0094283 Test Loss: 0.4747371
Validation loss decreased (1.010428 --> 1.009428).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.3616597652435303
Epoch: 55, Steps: 63 | Train Loss: 0.1941037 Vali Loss: 1.0081400 Test Loss: 0.4741640
Validation loss decreased (1.009428 --> 1.008140).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.3448576927185059
Epoch: 56, Steps: 63 | Train Loss: 0.1937807 Vali Loss: 1.0075755 Test Loss: 0.4735520
Validation loss decreased (1.008140 --> 1.007576).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.4134471416473389
Epoch: 57, Steps: 63 | Train Loss: 0.1933601 Vali Loss: 1.0067562 Test Loss: 0.4730256
Validation loss decreased (1.007576 --> 1.006756).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.52067232131958
Epoch: 58, Steps: 63 | Train Loss: 0.1931727 Vali Loss: 1.0061758 Test Loss: 0.4725579
Validation loss decreased (1.006756 --> 1.006176).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.4414255619049072
Epoch: 59, Steps: 63 | Train Loss: 0.1927284 Vali Loss: 1.0052103 Test Loss: 0.4720958
Validation loss decreased (1.006176 --> 1.005210).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.465721845626831
Epoch: 60, Steps: 63 | Train Loss: 0.1925163 Vali Loss: 1.0046608 Test Loss: 0.4716534
Validation loss decreased (1.005210 --> 1.004661).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.4495465755462646
Epoch: 61, Steps: 63 | Train Loss: 0.1921682 Vali Loss: 1.0042098 Test Loss: 0.4711826
Validation loss decreased (1.004661 --> 1.004210).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.6817708015441895
Epoch: 62, Steps: 63 | Train Loss: 0.1920274 Vali Loss: 1.0036513 Test Loss: 0.4708015
Validation loss decreased (1.004210 --> 1.003651).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.3463478088378906
Epoch: 63, Steps: 63 | Train Loss: 0.1917204 Vali Loss: 1.0030329 Test Loss: 0.4703920
Validation loss decreased (1.003651 --> 1.003033).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.4378433227539062
Epoch: 64, Steps: 63 | Train Loss: 0.1914966 Vali Loss: 1.0023218 Test Loss: 0.4699826
Validation loss decreased (1.003033 --> 1.002322).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.4705595970153809
Epoch: 65, Steps: 63 | Train Loss: 0.1912418 Vali Loss: 1.0019476 Test Loss: 0.4696680
Validation loss decreased (1.002322 --> 1.001948).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.4819402694702148
Epoch: 66, Steps: 63 | Train Loss: 0.1909773 Vali Loss: 1.0013222 Test Loss: 0.4692911
Validation loss decreased (1.001948 --> 1.001322).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.3849985599517822
Epoch: 67, Steps: 63 | Train Loss: 0.1908281 Vali Loss: 1.0009613 Test Loss: 0.4689621
Validation loss decreased (1.001322 --> 1.000961).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.1805737018585205
Epoch: 68, Steps: 63 | Train Loss: 0.1906036 Vali Loss: 1.0004042 Test Loss: 0.4686885
Validation loss decreased (1.000961 --> 1.000404).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.2977042198181152
Epoch: 69, Steps: 63 | Train Loss: 0.1904471 Vali Loss: 1.0000179 Test Loss: 0.4684095
Validation loss decreased (1.000404 --> 1.000018).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.207381248474121
Epoch: 70, Steps: 63 | Train Loss: 0.1902870 Vali Loss: 0.9994397 Test Loss: 0.4681533
Validation loss decreased (1.000018 --> 0.999440).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.1245462894439697
Epoch: 71, Steps: 63 | Train Loss: 0.1900775 Vali Loss: 0.9993260 Test Loss: 0.4678705
Validation loss decreased (0.999440 --> 0.999326).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.147409200668335
Epoch: 72, Steps: 63 | Train Loss: 0.1899131 Vali Loss: 0.9987262 Test Loss: 0.4676138
Validation loss decreased (0.999326 --> 0.998726).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.3634669780731201
Epoch: 73, Steps: 63 | Train Loss: 0.1897729 Vali Loss: 0.9984159 Test Loss: 0.4673712
Validation loss decreased (0.998726 --> 0.998416).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.1841926574707031
Epoch: 74, Steps: 63 | Train Loss: 0.1896401 Vali Loss: 0.9981146 Test Loss: 0.4671572
Validation loss decreased (0.998416 --> 0.998115).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.2216603755950928
Epoch: 75, Steps: 63 | Train Loss: 0.1893994 Vali Loss: 0.9978572 Test Loss: 0.4669642
Validation loss decreased (0.998115 --> 0.997857).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.2167294025421143
Epoch: 76, Steps: 63 | Train Loss: 0.1893389 Vali Loss: 0.9976500 Test Loss: 0.4667515
Validation loss decreased (0.997857 --> 0.997650).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.2545428276062012
Epoch: 77, Steps: 63 | Train Loss: 0.1893613 Vali Loss: 0.9970629 Test Loss: 0.4665798
Validation loss decreased (0.997650 --> 0.997063).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.2753806114196777
Epoch: 78, Steps: 63 | Train Loss: 0.1891535 Vali Loss: 0.9964867 Test Loss: 0.4663844
Validation loss decreased (0.997063 --> 0.996487).  Saving model ...
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.2697598934173584
Epoch: 79, Steps: 63 | Train Loss: 0.1890357 Vali Loss: 0.9965638 Test Loss: 0.4662184
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.219160795211792
Epoch: 80, Steps: 63 | Train Loss: 0.1889767 Vali Loss: 0.9960370 Test Loss: 0.4660392
Validation loss decreased (0.996487 --> 0.996037).  Saving model ...
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.4159023761749268
Epoch: 81, Steps: 63 | Train Loss: 0.1887313 Vali Loss: 0.9957063 Test Loss: 0.4658819
Validation loss decreased (0.996037 --> 0.995706).  Saving model ...
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.2860231399536133
Epoch: 82, Steps: 63 | Train Loss: 0.1887872 Vali Loss: 0.9960037 Test Loss: 0.4657288
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.2568151950836182
Epoch: 83, Steps: 63 | Train Loss: 0.1886088 Vali Loss: 0.9958488 Test Loss: 0.4655859
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.2472386360168457
Epoch: 84, Steps: 63 | Train Loss: 0.1885581 Vali Loss: 0.9951499 Test Loss: 0.4654610
Validation loss decreased (0.995706 --> 0.995150).  Saving model ...
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.2857227325439453
Epoch: 85, Steps: 63 | Train Loss: 0.1883738 Vali Loss: 0.9953591 Test Loss: 0.4653274
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.3188858032226562
Epoch: 86, Steps: 63 | Train Loss: 0.1884048 Vali Loss: 0.9953157 Test Loss: 0.4652069
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.2502412796020508
Epoch: 87, Steps: 63 | Train Loss: 0.1883564 Vali Loss: 0.9950759 Test Loss: 0.4650802
Validation loss decreased (0.995150 --> 0.995076).  Saving model ...
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.2354927062988281
Epoch: 88, Steps: 63 | Train Loss: 0.1882664 Vali Loss: 0.9948371 Test Loss: 0.4649697
Validation loss decreased (0.995076 --> 0.994837).  Saving model ...
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.234506368637085
Epoch: 89, Steps: 63 | Train Loss: 0.1881862 Vali Loss: 0.9948149 Test Loss: 0.4648718
Validation loss decreased (0.994837 --> 0.994815).  Saving model ...
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.4305479526519775
Epoch: 90, Steps: 63 | Train Loss: 0.1881683 Vali Loss: 0.9940314 Test Loss: 0.4647695
Validation loss decreased (0.994815 --> 0.994031).  Saving model ...
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.155815839767456
Epoch: 91, Steps: 63 | Train Loss: 0.1880613 Vali Loss: 0.9944668 Test Loss: 0.4646724
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.1496717929840088
Epoch: 92, Steps: 63 | Train Loss: 0.1879429 Vali Loss: 0.9943597 Test Loss: 0.4645857
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.2351093292236328
Epoch: 93, Steps: 63 | Train Loss: 0.1879196 Vali Loss: 0.9940139 Test Loss: 0.4644922
Validation loss decreased (0.994031 --> 0.994014).  Saving model ...
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.360548973083496
Epoch: 94, Steps: 63 | Train Loss: 0.1878588 Vali Loss: 0.9940907 Test Loss: 0.4644271
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.1695196628570557
Epoch: 95, Steps: 63 | Train Loss: 0.1878540 Vali Loss: 0.9939072 Test Loss: 0.4643328
Validation loss decreased (0.994014 --> 0.993907).  Saving model ...
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.2953569889068604
Epoch: 96, Steps: 63 | Train Loss: 0.1878635 Vali Loss: 0.9938620 Test Loss: 0.4642682
Validation loss decreased (0.993907 --> 0.993862).  Saving model ...
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.2210652828216553
Epoch: 97, Steps: 63 | Train Loss: 0.1876398 Vali Loss: 0.9937392 Test Loss: 0.4641924
Validation loss decreased (0.993862 --> 0.993739).  Saving model ...
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.2675015926361084
Epoch: 98, Steps: 63 | Train Loss: 0.1876647 Vali Loss: 0.9936726 Test Loss: 0.4641208
Validation loss decreased (0.993739 --> 0.993673).  Saving model ...
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.232537031173706
Epoch: 99, Steps: 63 | Train Loss: 0.1877873 Vali Loss: 0.9930481 Test Loss: 0.4640620
Validation loss decreased (0.993673 --> 0.993048).  Saving model ...
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.120572805404663
Epoch: 100, Steps: 63 | Train Loss: 0.1876223 Vali Loss: 0.9933749 Test Loss: 0.4639884
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8089
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=90, out_features=138, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  11128320.0
params:  12558.0
Trainable parameters:  12558
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.2179739475250244
Epoch: 1, Steps: 63 | Train Loss: 0.4193074 Vali Loss: 0.9407672 Test Loss: 0.4267820
Validation loss decreased (inf --> 0.940767).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.2516250610351562
Epoch: 2, Steps: 63 | Train Loss: 0.4042113 Vali Loss: 0.9240634 Test Loss: 0.4146665
Validation loss decreased (0.940767 --> 0.924063).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.2198846340179443
Epoch: 3, Steps: 63 | Train Loss: 0.3991690 Vali Loss: 0.9192392 Test Loss: 0.4120552
Validation loss decreased (0.924063 --> 0.919239).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.2708535194396973
Epoch: 4, Steps: 63 | Train Loss: 0.3976812 Vali Loss: 0.9178969 Test Loss: 0.4115419
Validation loss decreased (0.919239 --> 0.917897).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.166562557220459
Epoch: 5, Steps: 63 | Train Loss: 0.3971787 Vali Loss: 0.9179264 Test Loss: 0.4115988
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.2327368259429932
Epoch: 6, Steps: 63 | Train Loss: 0.3968077 Vali Loss: 0.9165237 Test Loss: 0.4113685
Validation loss decreased (0.917897 --> 0.916524).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.1311254501342773
Epoch: 7, Steps: 63 | Train Loss: 0.3964026 Vali Loss: 0.9167240 Test Loss: 0.4111430
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.301105260848999
Epoch: 8, Steps: 63 | Train Loss: 0.3962599 Vali Loss: 0.9170602 Test Loss: 0.4113229
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.207777976989746
Epoch: 9, Steps: 63 | Train Loss: 0.3959596 Vali Loss: 0.9168684 Test Loss: 0.4111232
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.1764922142028809
Epoch: 10, Steps: 63 | Train Loss: 0.3960827 Vali Loss: 0.9161128 Test Loss: 0.4111633
Validation loss decreased (0.916524 --> 0.916113).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.2090983390808105
Epoch: 11, Steps: 63 | Train Loss: 0.3960476 Vali Loss: 0.9164039 Test Loss: 0.4110344
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.1997764110565186
Epoch: 12, Steps: 63 | Train Loss: 0.3963606 Vali Loss: 0.9165828 Test Loss: 0.4113834
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.2364113330841064
Epoch: 13, Steps: 63 | Train Loss: 0.3960613 Vali Loss: 0.9163818 Test Loss: 0.4109659
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.2370729446411133
Epoch: 14, Steps: 63 | Train Loss: 0.3959958 Vali Loss: 0.9164885 Test Loss: 0.4111123
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.222782850265503
Epoch: 15, Steps: 63 | Train Loss: 0.3960391 Vali Loss: 0.9158549 Test Loss: 0.4111023
Validation loss decreased (0.916113 --> 0.915855).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.294727087020874
Epoch: 16, Steps: 63 | Train Loss: 0.3955491 Vali Loss: 0.9159918 Test Loss: 0.4111352
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.2764170169830322
Epoch: 17, Steps: 63 | Train Loss: 0.3955967 Vali Loss: 0.9157227 Test Loss: 0.4110692
Validation loss decreased (0.915855 --> 0.915723).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.165325403213501
Epoch: 18, Steps: 63 | Train Loss: 0.3956483 Vali Loss: 0.9159620 Test Loss: 0.4110970
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.1984291076660156
Epoch: 19, Steps: 63 | Train Loss: 0.3955498 Vali Loss: 0.9158177 Test Loss: 0.4110607
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.2467334270477295
Epoch: 20, Steps: 63 | Train Loss: 0.3954932 Vali Loss: 0.9158852 Test Loss: 0.4111079
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.2337591648101807
Epoch: 21, Steps: 63 | Train Loss: 0.3954892 Vali Loss: 0.9159858 Test Loss: 0.4111239
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.1896584033966064
Epoch: 22, Steps: 63 | Train Loss: 0.3954321 Vali Loss: 0.9160543 Test Loss: 0.4110674
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.3439855575561523
Epoch: 23, Steps: 63 | Train Loss: 0.3952174 Vali Loss: 0.9160359 Test Loss: 0.4111440
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.559713363647461
Epoch: 24, Steps: 63 | Train Loss: 0.3951811 Vali Loss: 0.9152836 Test Loss: 0.4110439
Validation loss decreased (0.915723 --> 0.915284).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.2894432544708252
Epoch: 25, Steps: 63 | Train Loss: 0.3953120 Vali Loss: 0.9159046 Test Loss: 0.4111297
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.2633280754089355
Epoch: 26, Steps: 63 | Train Loss: 0.3951265 Vali Loss: 0.9153389 Test Loss: 0.4111032
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.326996088027954
Epoch: 27, Steps: 63 | Train Loss: 0.3953033 Vali Loss: 0.9157147 Test Loss: 0.4111089
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.261704683303833
Epoch: 28, Steps: 63 | Train Loss: 0.3953935 Vali Loss: 0.9155965 Test Loss: 0.4112025
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.32127046585083
Epoch: 29, Steps: 63 | Train Loss: 0.3948295 Vali Loss: 0.9159480 Test Loss: 0.4110722
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.2011284828186035
Epoch: 30, Steps: 63 | Train Loss: 0.3951113 Vali Loss: 0.9159038 Test Loss: 0.4111567
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.313016414642334
Epoch: 31, Steps: 63 | Train Loss: 0.3953302 Vali Loss: 0.9157336 Test Loss: 0.4111143
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.3183338642120361
Epoch: 32, Steps: 63 | Train Loss: 0.3950323 Vali Loss: 0.9157790 Test Loss: 0.4110736
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.2894203662872314
Epoch: 33, Steps: 63 | Train Loss: 0.3951340 Vali Loss: 0.9153265 Test Loss: 0.4110347
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.3062739372253418
Epoch: 34, Steps: 63 | Train Loss: 0.3952253 Vali Loss: 0.9155747 Test Loss: 0.4110514
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.1435644626617432
Epoch: 35, Steps: 63 | Train Loss: 0.3952209 Vali Loss: 0.9157534 Test Loss: 0.4111223
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.1770949363708496
Epoch: 36, Steps: 63 | Train Loss: 0.3949563 Vali Loss: 0.9157224 Test Loss: 0.4111104
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.3334453105926514
Epoch: 37, Steps: 63 | Train Loss: 0.3952134 Vali Loss: 0.9153848 Test Loss: 0.4111236
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.3515512943267822
Epoch: 38, Steps: 63 | Train Loss: 0.3951100 Vali Loss: 0.9158559 Test Loss: 0.4111879
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.0271215438842773
Epoch: 39, Steps: 63 | Train Loss: 0.3952969 Vali Loss: 0.9157180 Test Loss: 0.4111871
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.2034351825714111
Epoch: 40, Steps: 63 | Train Loss: 0.3951997 Vali Loss: 0.9159171 Test Loss: 0.4111977
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.2083206176757812
Epoch: 41, Steps: 63 | Train Loss: 0.3950002 Vali Loss: 0.9154072 Test Loss: 0.4111935
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.2877013683319092
Epoch: 42, Steps: 63 | Train Loss: 0.3950561 Vali Loss: 0.9157346 Test Loss: 0.4111413
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.2473297119140625
Epoch: 43, Steps: 63 | Train Loss: 0.3951125 Vali Loss: 0.9155119 Test Loss: 0.4112135
EarlyStopping counter: 19 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.427945852279663
Epoch: 44, Steps: 63 | Train Loss: 0.3945897 Vali Loss: 0.9152004 Test Loss: 0.4111396
Validation loss decreased (0.915284 --> 0.915200).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.2444713115692139
Epoch: 45, Steps: 63 | Train Loss: 0.3952189 Vali Loss: 0.9153674 Test Loss: 0.4111530
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.2247800827026367
Epoch: 46, Steps: 63 | Train Loss: 0.3948781 Vali Loss: 0.9157431 Test Loss: 0.4111820
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.3455336093902588
Epoch: 47, Steps: 63 | Train Loss: 0.3950693 Vali Loss: 0.9150578 Test Loss: 0.4111485
Validation loss decreased (0.915200 --> 0.915058).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.1344420909881592
Epoch: 48, Steps: 63 | Train Loss: 0.3947934 Vali Loss: 0.9156998 Test Loss: 0.4111679
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.2298309803009033
Epoch: 49, Steps: 63 | Train Loss: 0.3950855 Vali Loss: 0.9157756 Test Loss: 0.4111564
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.2343153953552246
Epoch: 50, Steps: 63 | Train Loss: 0.3947341 Vali Loss: 0.9157560 Test Loss: 0.4111551
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.2378664016723633
Epoch: 51, Steps: 63 | Train Loss: 0.3951749 Vali Loss: 0.9154849 Test Loss: 0.4111354
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.2506325244903564
Epoch: 52, Steps: 63 | Train Loss: 0.3950788 Vali Loss: 0.9150075 Test Loss: 0.4111181
Validation loss decreased (0.915058 --> 0.915008).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.2149229049682617
Epoch: 53, Steps: 63 | Train Loss: 0.3946749 Vali Loss: 0.9156092 Test Loss: 0.4111456
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.3168935775756836
Epoch: 54, Steps: 63 | Train Loss: 0.3950299 Vali Loss: 0.9156047 Test Loss: 0.4111761
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.211461067199707
Epoch: 55, Steps: 63 | Train Loss: 0.3948473 Vali Loss: 0.9153807 Test Loss: 0.4111573
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.235093116760254
Epoch: 56, Steps: 63 | Train Loss: 0.3949326 Vali Loss: 0.9156289 Test Loss: 0.4111316
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.7024922370910645
Epoch: 57, Steps: 63 | Train Loss: 0.3949828 Vali Loss: 0.9153640 Test Loss: 0.4111121
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.3204667568206787
Epoch: 58, Steps: 63 | Train Loss: 0.3947989 Vali Loss: 0.9157406 Test Loss: 0.4111593
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.2517967224121094
Epoch: 59, Steps: 63 | Train Loss: 0.3950098 Vali Loss: 0.9157113 Test Loss: 0.4111554
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.2421073913574219
Epoch: 60, Steps: 63 | Train Loss: 0.3950153 Vali Loss: 0.9152223 Test Loss: 0.4111552
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.2452588081359863
Epoch: 61, Steps: 63 | Train Loss: 0.3947880 Vali Loss: 0.9154611 Test Loss: 0.4111430
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.2816686630249023
Epoch: 62, Steps: 63 | Train Loss: 0.3948732 Vali Loss: 0.9156083 Test Loss: 0.4111291
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.3141417503356934
Epoch: 63, Steps: 63 | Train Loss: 0.3947097 Vali Loss: 0.9155346 Test Loss: 0.4111515
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.3524689674377441
Epoch: 64, Steps: 63 | Train Loss: 0.3949227 Vali Loss: 0.9156737 Test Loss: 0.4111609
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.2283291816711426
Epoch: 65, Steps: 63 | Train Loss: 0.3947785 Vali Loss: 0.9155606 Test Loss: 0.4111612
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.3699207305908203
Epoch: 66, Steps: 63 | Train Loss: 0.3950048 Vali Loss: 0.9156374 Test Loss: 0.4111723
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.3821475505828857
Epoch: 67, Steps: 63 | Train Loss: 0.3948382 Vali Loss: 0.9150965 Test Loss: 0.4111629
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.3041367530822754
Epoch: 68, Steps: 63 | Train Loss: 0.3948303 Vali Loss: 0.9155135 Test Loss: 0.4111570
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.303300142288208
Epoch: 69, Steps: 63 | Train Loss: 0.3951054 Vali Loss: 0.9150460 Test Loss: 0.4111481
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.5118601322174072
Epoch: 70, Steps: 63 | Train Loss: 0.3944767 Vali Loss: 0.9152703 Test Loss: 0.4111473
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.3038065433502197
Epoch: 71, Steps: 63 | Train Loss: 0.3946631 Vali Loss: 0.9156626 Test Loss: 0.4111551
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.282977819442749
Epoch: 72, Steps: 63 | Train Loss: 0.3947331 Vali Loss: 0.9156905 Test Loss: 0.4111479
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_360_192_FITS_ETTh1_ftM_sl360_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.4070575535297394, mae:0.4153769314289093, rse:0.6058781147003174, corr:[0.26250792 0.26980898 0.269769   0.26980975 0.26815626 0.26542464
 0.26367098 0.2637726  0.26373824 0.26336902 0.26327097 0.26334238
 0.26328826 0.26298383 0.26281404 0.2629422  0.26286682 0.26260555
 0.26240012 0.26204482 0.26169306 0.26157576 0.26184443 0.26217762
 0.26196492 0.2616617  0.2615368  0.26132172 0.26083544 0.2604342
 0.2602716  0.26000014 0.25957268 0.25933716 0.25949118 0.25966826
 0.2597074  0.25978687 0.25997427 0.26012117 0.2602868  0.26041335
 0.2605696  0.2604706  0.26015168 0.2598758  0.26007107 0.2603328
 0.25988162 0.2589521  0.25800756 0.25735447 0.25665182 0.25568125
 0.2550582  0.25474408 0.2544853  0.25433683 0.25414827 0.25415596
 0.25412184 0.25401154 0.25384003 0.25377658 0.25388354 0.2541795
 0.254462   0.25432158 0.25415975 0.25433367 0.2546103  0.2544262
 0.25374037 0.25292423 0.2521825  0.25166443 0.25143367 0.25126788
 0.25097117 0.2504329  0.2500259  0.24985565 0.24967977 0.24940975
 0.24930096 0.24938613 0.2495078  0.24941888 0.24932979 0.24942729
 0.24939439 0.24903782 0.24871905 0.24867736 0.24892123 0.24946608
 0.25008073 0.25019225 0.25016695 0.2500976  0.2500524  0.24999271
 0.2498332  0.24971166 0.2495869  0.24949415 0.24934125 0.24908243
 0.24882269 0.24872808 0.24883407 0.24921301 0.24954885 0.24973924
 0.24972013 0.24950622 0.24925481 0.24901244 0.24879664 0.24875808
 0.24885972 0.24855253 0.24770445 0.24680084 0.24632353 0.24596326
 0.24568023 0.24554208 0.24546395 0.24521066 0.24486817 0.24456236
 0.24436419 0.24436086 0.24437417 0.24421509 0.24442087 0.24474514
 0.24494323 0.2449085  0.2448525  0.24482211 0.2446535  0.24451005
 0.24457708 0.24426119 0.24354498 0.24275695 0.2422928  0.24177995
 0.24133687 0.2412623  0.24140626 0.24158502 0.241471   0.24135509
 0.24130651 0.2413563  0.24121416 0.2410106  0.24099247 0.24113941
 0.24120206 0.24112119 0.24113446 0.24105373 0.24083875 0.24080369
 0.24112575 0.24135885 0.2414094  0.24147412 0.24150416 0.24116273
 0.24077953 0.24083948 0.24096805 0.24083371 0.24063672 0.2407495
 0.24079385 0.24028009 0.24000838 0.24052124 0.24061918 0.24012424
 0.24047458 0.24149148 0.24083394 0.23932634 0.24052525 0.23714817]
