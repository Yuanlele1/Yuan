Args in experiment:
Namespace(H_order=2, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=18, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_90_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_90_96_FITS_ETTh1_ftM_sl90_ll48_pl96_H2_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8455
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=18, out_features=37, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  596736.0
params:  703.0
Trainable parameters:  703
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.2220516204833984
Epoch: 1, Steps: 66 | Train Loss: 0.7207564 Vali Loss: 1.2141646 Test Loss: 0.7796085
Validation loss decreased (inf --> 1.214165).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.250234842300415
Epoch: 2, Steps: 66 | Train Loss: 0.5475220 Vali Loss: 0.9820919 Test Loss: 0.5790238
Validation loss decreased (1.214165 --> 0.982092).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.1625728607177734
Epoch: 3, Steps: 66 | Train Loss: 0.4648678 Vali Loss: 0.8731160 Test Loss: 0.4876233
Validation loss decreased (0.982092 --> 0.873116).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.0524182319641113
Epoch: 4, Steps: 66 | Train Loss: 0.4240905 Vali Loss: 0.8104021 Test Loss: 0.4439880
Validation loss decreased (0.873116 --> 0.810402).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 0.9691081047058105
Epoch: 5, Steps: 66 | Train Loss: 0.4027010 Vali Loss: 0.7785848 Test Loss: 0.4221829
Validation loss decreased (0.810402 --> 0.778585).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.0766096115112305
Epoch: 6, Steps: 66 | Train Loss: 0.3909174 Vali Loss: 0.7592734 Test Loss: 0.4108914
Validation loss decreased (0.778585 --> 0.759273).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 0.9666750431060791
Epoch: 7, Steps: 66 | Train Loss: 0.3839505 Vali Loss: 0.7514765 Test Loss: 0.4047528
Validation loss decreased (0.759273 --> 0.751476).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 0.9977540969848633
Epoch: 8, Steps: 66 | Train Loss: 0.3794881 Vali Loss: 0.7402633 Test Loss: 0.4011079
Validation loss decreased (0.751476 --> 0.740263).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.0468437671661377
Epoch: 9, Steps: 66 | Train Loss: 0.3763446 Vali Loss: 0.7424368 Test Loss: 0.3987797
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.1333012580871582
Epoch: 10, Steps: 66 | Train Loss: 0.3740744 Vali Loss: 0.7324517 Test Loss: 0.3971806
Validation loss decreased (0.740263 --> 0.732452).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 0.8832647800445557
Epoch: 11, Steps: 66 | Train Loss: 0.3724180 Vali Loss: 0.7323956 Test Loss: 0.3960347
Validation loss decreased (0.732452 --> 0.732396).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 0.9874322414398193
Epoch: 12, Steps: 66 | Train Loss: 0.3711018 Vali Loss: 0.7335979 Test Loss: 0.3951875
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.001253604888916
Epoch: 13, Steps: 66 | Train Loss: 0.3701309 Vali Loss: 0.7262511 Test Loss: 0.3946176
Validation loss decreased (0.732396 --> 0.726251).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.0881855487823486
Epoch: 14, Steps: 66 | Train Loss: 0.3692608 Vali Loss: 0.7264228 Test Loss: 0.3940797
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.0481278896331787
Epoch: 15, Steps: 66 | Train Loss: 0.3686080 Vali Loss: 0.7261462 Test Loss: 0.3936682
Validation loss decreased (0.726251 --> 0.726146).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.0459396839141846
Epoch: 16, Steps: 66 | Train Loss: 0.3680509 Vali Loss: 0.7253785 Test Loss: 0.3933313
Validation loss decreased (0.726146 --> 0.725379).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.0352318286895752
Epoch: 17, Steps: 66 | Train Loss: 0.3675540 Vali Loss: 0.7223841 Test Loss: 0.3930987
Validation loss decreased (0.725379 --> 0.722384).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.0004427433013916
Epoch: 18, Steps: 66 | Train Loss: 0.3671876 Vali Loss: 0.7243325 Test Loss: 0.3928699
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 0.9580204486846924
Epoch: 19, Steps: 66 | Train Loss: 0.3667679 Vali Loss: 0.7214769 Test Loss: 0.3927123
Validation loss decreased (0.722384 --> 0.721477).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 0.8975701332092285
Epoch: 20, Steps: 66 | Train Loss: 0.3664907 Vali Loss: 0.7170559 Test Loss: 0.3925771
Validation loss decreased (0.721477 --> 0.717056).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 0.9531660079956055
Epoch: 21, Steps: 66 | Train Loss: 0.3662617 Vali Loss: 0.7190126 Test Loss: 0.3924832
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.035024881362915
Epoch: 22, Steps: 66 | Train Loss: 0.3659990 Vali Loss: 0.7174973 Test Loss: 0.3923556
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.007030725479126
Epoch: 23, Steps: 66 | Train Loss: 0.3658375 Vali Loss: 0.7189074 Test Loss: 0.3923370
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 0.9704270362854004
Epoch: 24, Steps: 66 | Train Loss: 0.3655756 Vali Loss: 0.7197576 Test Loss: 0.3922365
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 0.9431777000427246
Epoch: 25, Steps: 66 | Train Loss: 0.3654680 Vali Loss: 0.7132212 Test Loss: 0.3921775
Validation loss decreased (0.717056 --> 0.713221).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 0.9895291328430176
Epoch: 26, Steps: 66 | Train Loss: 0.3653817 Vali Loss: 0.7128444 Test Loss: 0.3921231
Validation loss decreased (0.713221 --> 0.712844).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.4916901588439941
Epoch: 27, Steps: 66 | Train Loss: 0.3652090 Vali Loss: 0.7165859 Test Loss: 0.3921013
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.3292651176452637
Epoch: 28, Steps: 66 | Train Loss: 0.3650499 Vali Loss: 0.7142406 Test Loss: 0.3920567
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.0963008403778076
Epoch: 29, Steps: 66 | Train Loss: 0.3649968 Vali Loss: 0.7196308 Test Loss: 0.3920148
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.0295965671539307
Epoch: 30, Steps: 66 | Train Loss: 0.3649817 Vali Loss: 0.7140983 Test Loss: 0.3920238
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.0503666400909424
Epoch: 31, Steps: 66 | Train Loss: 0.3648524 Vali Loss: 0.7137635 Test Loss: 0.3920108
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.152115821838379
Epoch: 32, Steps: 66 | Train Loss: 0.3646937 Vali Loss: 0.7119873 Test Loss: 0.3919778
Validation loss decreased (0.712844 --> 0.711987).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.1941313743591309
Epoch: 33, Steps: 66 | Train Loss: 0.3644732 Vali Loss: 0.7136034 Test Loss: 0.3919884
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.2328646183013916
Epoch: 34, Steps: 66 | Train Loss: 0.3646159 Vali Loss: 0.7146622 Test Loss: 0.3919785
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.1910619735717773
Epoch: 35, Steps: 66 | Train Loss: 0.3644940 Vali Loss: 0.7143204 Test Loss: 0.3919773
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.1808090209960938
Epoch: 36, Steps: 66 | Train Loss: 0.3643124 Vali Loss: 0.7127637 Test Loss: 0.3919413
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.2191245555877686
Epoch: 37, Steps: 66 | Train Loss: 0.3644776 Vali Loss: 0.7135537 Test Loss: 0.3919642
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.238001823425293
Epoch: 38, Steps: 66 | Train Loss: 0.3645141 Vali Loss: 0.7122477 Test Loss: 0.3919459
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.2107219696044922
Epoch: 39, Steps: 66 | Train Loss: 0.3644359 Vali Loss: 0.7122931 Test Loss: 0.3919389
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.2434368133544922
Epoch: 40, Steps: 66 | Train Loss: 0.3642411 Vali Loss: 0.7164170 Test Loss: 0.3919788
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.1978015899658203
Epoch: 41, Steps: 66 | Train Loss: 0.3642247 Vali Loss: 0.7148868 Test Loss: 0.3919768
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.2262611389160156
Epoch: 42, Steps: 66 | Train Loss: 0.3640633 Vali Loss: 0.7162198 Test Loss: 0.3919697
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.223804235458374
Epoch: 43, Steps: 66 | Train Loss: 0.3641225 Vali Loss: 0.7078739 Test Loss: 0.3919630
Validation loss decreased (0.711987 --> 0.707874).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.2824366092681885
Epoch: 44, Steps: 66 | Train Loss: 0.3641845 Vali Loss: 0.7104346 Test Loss: 0.3919646
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.2710692882537842
Epoch: 45, Steps: 66 | Train Loss: 0.3641925 Vali Loss: 0.7181302 Test Loss: 0.3919585
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.2370975017547607
Epoch: 46, Steps: 66 | Train Loss: 0.3642338 Vali Loss: 0.7097823 Test Loss: 0.3919669
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.1951286792755127
Epoch: 47, Steps: 66 | Train Loss: 0.3641425 Vali Loss: 0.7131578 Test Loss: 0.3919598
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.1817889213562012
Epoch: 48, Steps: 66 | Train Loss: 0.3640355 Vali Loss: 0.7133359 Test Loss: 0.3919565
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.1082284450531006
Epoch: 49, Steps: 66 | Train Loss: 0.3639289 Vali Loss: 0.7142239 Test Loss: 0.3919607
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.1812551021575928
Epoch: 50, Steps: 66 | Train Loss: 0.3640809 Vali Loss: 0.7123005 Test Loss: 0.3919743
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.1630010604858398
Epoch: 51, Steps: 66 | Train Loss: 0.3640078 Vali Loss: 0.7157866 Test Loss: 0.3919679
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.2123558521270752
Epoch: 52, Steps: 66 | Train Loss: 0.3640078 Vali Loss: 0.7162871 Test Loss: 0.3919705
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.2323002815246582
Epoch: 53, Steps: 66 | Train Loss: 0.3638983 Vali Loss: 0.7175177 Test Loss: 0.3919694
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.188725233078003
Epoch: 54, Steps: 66 | Train Loss: 0.3638483 Vali Loss: 0.7123449 Test Loss: 0.3919809
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.2538812160491943
Epoch: 55, Steps: 66 | Train Loss: 0.3640356 Vali Loss: 0.7143450 Test Loss: 0.3919767
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.1833248138427734
Epoch: 56, Steps: 66 | Train Loss: 0.3640295 Vali Loss: 0.7090189 Test Loss: 0.3919793
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.2810509204864502
Epoch: 57, Steps: 66 | Train Loss: 0.3639782 Vali Loss: 0.7130922 Test Loss: 0.3919932
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.2261810302734375
Epoch: 58, Steps: 66 | Train Loss: 0.3638879 Vali Loss: 0.7139142 Test Loss: 0.3919870
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.3681371212005615
Epoch: 59, Steps: 66 | Train Loss: 0.3638430 Vali Loss: 0.7075177 Test Loss: 0.3919907
Validation loss decreased (0.707874 --> 0.707518).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.1885275840759277
Epoch: 60, Steps: 66 | Train Loss: 0.3638053 Vali Loss: 0.7125567 Test Loss: 0.3919912
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.2521007061004639
Epoch: 61, Steps: 66 | Train Loss: 0.3639652 Vali Loss: 0.7136080 Test Loss: 0.3919890
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.2273585796356201
Epoch: 62, Steps: 66 | Train Loss: 0.3639324 Vali Loss: 0.7128579 Test Loss: 0.3919970
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.2571792602539062
Epoch: 63, Steps: 66 | Train Loss: 0.3638314 Vali Loss: 0.7144040 Test Loss: 0.3919960
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.2076804637908936
Epoch: 64, Steps: 66 | Train Loss: 0.3639730 Vali Loss: 0.7161175 Test Loss: 0.3919933
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.1303107738494873
Epoch: 65, Steps: 66 | Train Loss: 0.3638146 Vali Loss: 0.7092645 Test Loss: 0.3920022
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.1397438049316406
Epoch: 66, Steps: 66 | Train Loss: 0.3638110 Vali Loss: 0.7122952 Test Loss: 0.3920065
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.1375465393066406
Epoch: 67, Steps: 66 | Train Loss: 0.3638458 Vali Loss: 0.7118158 Test Loss: 0.3920043
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 0.956357479095459
Epoch: 68, Steps: 66 | Train Loss: 0.3638943 Vali Loss: 0.7123920 Test Loss: 0.3919990
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.037412166595459
Epoch: 69, Steps: 66 | Train Loss: 0.3637221 Vali Loss: 0.7117032 Test Loss: 0.3920056
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 0.9918479919433594
Epoch: 70, Steps: 66 | Train Loss: 0.3637148 Vali Loss: 0.7089375 Test Loss: 0.3920085
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 0.9903717041015625
Epoch: 71, Steps: 66 | Train Loss: 0.3638587 Vali Loss: 0.7141435 Test Loss: 0.3920063
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.002086877822876
Epoch: 72, Steps: 66 | Train Loss: 0.3638060 Vali Loss: 0.7126219 Test Loss: 0.3920121
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.0689961910247803
Epoch: 73, Steps: 66 | Train Loss: 0.3637336 Vali Loss: 0.7135056 Test Loss: 0.3920079
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 0.9649040699005127
Epoch: 74, Steps: 66 | Train Loss: 0.3639301 Vali Loss: 0.7130893 Test Loss: 0.3920179
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 0.9765057563781738
Epoch: 75, Steps: 66 | Train Loss: 0.3638715 Vali Loss: 0.7082675 Test Loss: 0.3920151
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 0.9754054546356201
Epoch: 76, Steps: 66 | Train Loss: 0.3638869 Vali Loss: 0.7166721 Test Loss: 0.3920152
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 0.9804782867431641
Epoch: 77, Steps: 66 | Train Loss: 0.3638376 Vali Loss: 0.7116283 Test Loss: 0.3920213
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 0.9333806037902832
Epoch: 78, Steps: 66 | Train Loss: 0.3638808 Vali Loss: 0.7107375 Test Loss: 0.3920147
EarlyStopping counter: 19 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 0.9178802967071533
Epoch: 79, Steps: 66 | Train Loss: 0.3637587 Vali Loss: 0.7130511 Test Loss: 0.3920171
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_90_96_FITS_ETTh1_ftM_sl90_ll48_pl96_H2_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.39121031761169434, mae:0.398770272731781, rse:0.5941047072410583, corr:[0.26903996 0.27305162 0.27336344 0.27097243 0.26758328 0.26572037
 0.2656021  0.265068   0.2642233  0.26401743 0.26411974 0.264137
 0.26364923 0.2629136  0.26280314 0.26330814 0.2638451  0.26390553
 0.26363933 0.26366308 0.26369655 0.26337203 0.26238412 0.26108173
 0.25967544 0.25968707 0.26036268 0.2603841  0.25966698 0.25948137
 0.2601368  0.26033896 0.2601135  0.25983912 0.25964543 0.25971112
 0.25978842 0.2595547  0.25941098 0.2596733  0.26023197 0.26058522
 0.26057217 0.26059934 0.26078197 0.26068524 0.26027074 0.25935128
 0.25783426 0.25722048 0.25691944 0.25591925 0.25414124 0.25294966
 0.25326222 0.25329039 0.25282332 0.25268078 0.25285017 0.25321388
 0.25319758 0.25276992 0.25243226 0.25248212 0.252919   0.2532123
 0.25313568 0.25285468 0.2527458  0.25276113 0.25235626 0.2509787
 0.24896426 0.24817017 0.24826685 0.24817707 0.24752122 0.24709833
 0.24763428 0.24769445 0.24730349 0.24691224 0.24675302 0.24691911
 0.24694948 0.24642546 0.24587499 0.24570522 0.24606058 0.24633864
 0.24567735 0.24440378 0.24360818 0.24413654 0.24558048 0.24509846]
