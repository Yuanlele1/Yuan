Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=103, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_720_336_FITS_ETTh1_ftM_sl720_ll48_pl336_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=103, out_features=151, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  13935488.0
params:  15704.0
Trainable parameters:  15704
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 5.039137363433838
Epoch: 1, Steps: 59 | Train Loss: 0.6972650 Vali Loss: 1.7447395 Test Loss: 0.8197355
Validation loss decreased (inf --> 1.744740).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.5668792724609375
Epoch: 2, Steps: 59 | Train Loss: 0.5564985 Vali Loss: 1.5768872 Test Loss: 0.7358785
Validation loss decreased (1.744740 --> 1.576887).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 4.313807010650635
Epoch: 3, Steps: 59 | Train Loss: 0.4813903 Vali Loss: 1.5005925 Test Loss: 0.6987915
Validation loss decreased (1.576887 --> 1.500592).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 5.0909833908081055
Epoch: 4, Steps: 59 | Train Loss: 0.4371629 Vali Loss: 1.4561738 Test Loss: 0.6785980
Validation loss decreased (1.500592 --> 1.456174).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 4.7321717739105225
Epoch: 5, Steps: 59 | Train Loss: 0.4069552 Vali Loss: 1.4253163 Test Loss: 0.6642512
Validation loss decreased (1.456174 --> 1.425316).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 4.509804725646973
Epoch: 6, Steps: 59 | Train Loss: 0.3842703 Vali Loss: 1.4067571 Test Loss: 0.6543361
Validation loss decreased (1.425316 --> 1.406757).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 4.5757737159729
Epoch: 7, Steps: 59 | Train Loss: 0.3657032 Vali Loss: 1.3897866 Test Loss: 0.6452325
Validation loss decreased (1.406757 --> 1.389787).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 4.396474361419678
Epoch: 8, Steps: 59 | Train Loss: 0.3503632 Vali Loss: 1.3779547 Test Loss: 0.6372476
Validation loss decreased (1.389787 --> 1.377955).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 4.23007869720459
Epoch: 9, Steps: 59 | Train Loss: 0.3369899 Vali Loss: 1.3696744 Test Loss: 0.6286622
Validation loss decreased (1.377955 --> 1.369674).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 4.272158622741699
Epoch: 10, Steps: 59 | Train Loss: 0.3254548 Vali Loss: 1.3568436 Test Loss: 0.6217450
Validation loss decreased (1.369674 --> 1.356844).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 4.426841735839844
Epoch: 11, Steps: 59 | Train Loss: 0.3153871 Vali Loss: 1.3467443 Test Loss: 0.6146358
Validation loss decreased (1.356844 --> 1.346744).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 4.594125270843506
Epoch: 12, Steps: 59 | Train Loss: 0.3061616 Vali Loss: 1.3357655 Test Loss: 0.6084607
Validation loss decreased (1.346744 --> 1.335765).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 4.76111626625061
Epoch: 13, Steps: 59 | Train Loss: 0.2980266 Vali Loss: 1.3343778 Test Loss: 0.6020697
Validation loss decreased (1.335765 --> 1.334378).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 4.043177127838135
Epoch: 14, Steps: 59 | Train Loss: 0.2907820 Vali Loss: 1.3236616 Test Loss: 0.5965584
Validation loss decreased (1.334378 --> 1.323662).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 4.140631675720215
Epoch: 15, Steps: 59 | Train Loss: 0.2842605 Vali Loss: 1.3177236 Test Loss: 0.5907506
Validation loss decreased (1.323662 --> 1.317724).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 4.1556220054626465
Epoch: 16, Steps: 59 | Train Loss: 0.2781673 Vali Loss: 1.3103374 Test Loss: 0.5861810
Validation loss decreased (1.317724 --> 1.310337).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 4.692811727523804
Epoch: 17, Steps: 59 | Train Loss: 0.2730012 Vali Loss: 1.3088344 Test Loss: 0.5810317
Validation loss decreased (1.310337 --> 1.308834).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 4.727561712265015
Epoch: 18, Steps: 59 | Train Loss: 0.2681069 Vali Loss: 1.3036617 Test Loss: 0.5769706
Validation loss decreased (1.308834 --> 1.303662).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 4.5251686573028564
Epoch: 19, Steps: 59 | Train Loss: 0.2634950 Vali Loss: 1.2974030 Test Loss: 0.5721760
Validation loss decreased (1.303662 --> 1.297403).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.936295509338379
Epoch: 20, Steps: 59 | Train Loss: 0.2596551 Vali Loss: 1.2896239 Test Loss: 0.5683104
Validation loss decreased (1.297403 --> 1.289624).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 4.333138465881348
Epoch: 21, Steps: 59 | Train Loss: 0.2558589 Vali Loss: 1.2895283 Test Loss: 0.5646555
Validation loss decreased (1.289624 --> 1.289528).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 4.663050174713135
Epoch: 22, Steps: 59 | Train Loss: 0.2524116 Vali Loss: 1.2824851 Test Loss: 0.5614402
Validation loss decreased (1.289528 --> 1.282485).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 4.4752068519592285
Epoch: 23, Steps: 59 | Train Loss: 0.2493460 Vali Loss: 1.2854959 Test Loss: 0.5581928
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 4.272134780883789
Epoch: 24, Steps: 59 | Train Loss: 0.2464833 Vali Loss: 1.2792575 Test Loss: 0.5548033
Validation loss decreased (1.282485 --> 1.279258).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 4.282493591308594
Epoch: 25, Steps: 59 | Train Loss: 0.2437791 Vali Loss: 1.2775278 Test Loss: 0.5523602
Validation loss decreased (1.279258 --> 1.277528).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 4.490614891052246
Epoch: 26, Steps: 59 | Train Loss: 0.2412182 Vali Loss: 1.2704052 Test Loss: 0.5495403
Validation loss decreased (1.277528 --> 1.270405).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 4.536708831787109
Epoch: 27, Steps: 59 | Train Loss: 0.2389297 Vali Loss: 1.2746130 Test Loss: 0.5471702
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 4.4905242919921875
Epoch: 28, Steps: 59 | Train Loss: 0.2369986 Vali Loss: 1.2676765 Test Loss: 0.5449926
Validation loss decreased (1.270405 --> 1.267676).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 4.136005163192749
Epoch: 29, Steps: 59 | Train Loss: 0.2350350 Vali Loss: 1.2693093 Test Loss: 0.5425593
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 4.296183347702026
Epoch: 30, Steps: 59 | Train Loss: 0.2331719 Vali Loss: 1.2685446 Test Loss: 0.5404974
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 4.502000570297241
Epoch: 31, Steps: 59 | Train Loss: 0.2315133 Vali Loss: 1.2668380 Test Loss: 0.5387372
Validation loss decreased (1.267676 --> 1.266838).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 4.534519910812378
Epoch: 32, Steps: 59 | Train Loss: 0.2298729 Vali Loss: 1.2619538 Test Loss: 0.5367504
Validation loss decreased (1.266838 --> 1.261954).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 4.712653636932373
Epoch: 33, Steps: 59 | Train Loss: 0.2283999 Vali Loss: 1.2623684 Test Loss: 0.5348354
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 4.544996738433838
Epoch: 34, Steps: 59 | Train Loss: 0.2269449 Vali Loss: 1.2661082 Test Loss: 0.5337055
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 4.707627773284912
Epoch: 35, Steps: 59 | Train Loss: 0.2257428 Vali Loss: 1.2591276 Test Loss: 0.5320590
Validation loss decreased (1.261954 --> 1.259128).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 4.3858747482299805
Epoch: 36, Steps: 59 | Train Loss: 0.2243857 Vali Loss: 1.2539511 Test Loss: 0.5305876
Validation loss decreased (1.259128 --> 1.253951).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 4.440761089324951
Epoch: 37, Steps: 59 | Train Loss: 0.2233071 Vali Loss: 1.2550179 Test Loss: 0.5289761
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 4.146182060241699
Epoch: 38, Steps: 59 | Train Loss: 0.2221927 Vali Loss: 1.2572371 Test Loss: 0.5278136
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 4.690187215805054
Epoch: 39, Steps: 59 | Train Loss: 0.2213062 Vali Loss: 1.2563391 Test Loss: 0.5265764
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 4.741724967956543
Epoch: 40, Steps: 59 | Train Loss: 0.2204024 Vali Loss: 1.2535260 Test Loss: 0.5254223
Validation loss decreased (1.253951 --> 1.253526).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 4.166000843048096
Epoch: 41, Steps: 59 | Train Loss: 0.2195512 Vali Loss: 1.2564833 Test Loss: 0.5241852
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 4.979610919952393
Epoch: 42, Steps: 59 | Train Loss: 0.2186704 Vali Loss: 1.2531433 Test Loss: 0.5232695
Validation loss decreased (1.253526 --> 1.253143).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 4.922870397567749
Epoch: 43, Steps: 59 | Train Loss: 0.2179757 Vali Loss: 1.2531917 Test Loss: 0.5221888
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 5.099853992462158
Epoch: 44, Steps: 59 | Train Loss: 0.2171335 Vali Loss: 1.2571790 Test Loss: 0.5213875
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 4.283555269241333
Epoch: 45, Steps: 59 | Train Loss: 0.2165313 Vali Loss: 1.2517048 Test Loss: 0.5204040
Validation loss decreased (1.253143 --> 1.251705).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 4.360047101974487
Epoch: 46, Steps: 59 | Train Loss: 0.2157898 Vali Loss: 1.2508560 Test Loss: 0.5197240
Validation loss decreased (1.251705 --> 1.250856).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 4.83388876914978
Epoch: 47, Steps: 59 | Train Loss: 0.2151989 Vali Loss: 1.2522663 Test Loss: 0.5189949
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 4.088021993637085
Epoch: 48, Steps: 59 | Train Loss: 0.2146114 Vali Loss: 1.2492959 Test Loss: 0.5181377
Validation loss decreased (1.250856 --> 1.249296).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 4.635400295257568
Epoch: 49, Steps: 59 | Train Loss: 0.2140644 Vali Loss: 1.2518791 Test Loss: 0.5174383
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 4.550606727600098
Epoch: 50, Steps: 59 | Train Loss: 0.2135304 Vali Loss: 1.2462243 Test Loss: 0.5167796
Validation loss decreased (1.249296 --> 1.246224).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 4.703965425491333
Epoch: 51, Steps: 59 | Train Loss: 0.2130442 Vali Loss: 1.2526554 Test Loss: 0.5162299
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 4.279882431030273
Epoch: 52, Steps: 59 | Train Loss: 0.2125826 Vali Loss: 1.2532561 Test Loss: 0.5156078
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 4.244567632675171
Epoch: 53, Steps: 59 | Train Loss: 0.2121834 Vali Loss: 1.2511367 Test Loss: 0.5149463
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 4.371284246444702
Epoch: 54, Steps: 59 | Train Loss: 0.2117384 Vali Loss: 1.2469692 Test Loss: 0.5144147
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 4.423067569732666
Epoch: 55, Steps: 59 | Train Loss: 0.2114023 Vali Loss: 1.2480514 Test Loss: 0.5138832
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 4.4330973625183105
Epoch: 56, Steps: 59 | Train Loss: 0.2109528 Vali Loss: 1.2484345 Test Loss: 0.5133972
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 4.246504545211792
Epoch: 57, Steps: 59 | Train Loss: 0.2105451 Vali Loss: 1.2533563 Test Loss: 0.5129259
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 4.978669166564941
Epoch: 58, Steps: 59 | Train Loss: 0.2103794 Vali Loss: 1.2497971 Test Loss: 0.5124841
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 4.66877293586731
Epoch: 59, Steps: 59 | Train Loss: 0.2100190 Vali Loss: 1.2476753 Test Loss: 0.5121425
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 4.808302164077759
Epoch: 60, Steps: 59 | Train Loss: 0.2096355 Vali Loss: 1.2502197 Test Loss: 0.5117292
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 4.552117109298706
Epoch: 61, Steps: 59 | Train Loss: 0.2094634 Vali Loss: 1.2461792 Test Loss: 0.5114122
Validation loss decreased (1.246224 --> 1.246179).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 5.485144853591919
Epoch: 62, Steps: 59 | Train Loss: 0.2091442 Vali Loss: 1.2472798 Test Loss: 0.5109806
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 4.581648826599121
Epoch: 63, Steps: 59 | Train Loss: 0.2087838 Vali Loss: 1.2414631 Test Loss: 0.5106651
Validation loss decreased (1.246179 --> 1.241463).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 4.444122076034546
Epoch: 64, Steps: 59 | Train Loss: 0.2086112 Vali Loss: 1.2464867 Test Loss: 0.5103343
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 4.236612558364868
Epoch: 65, Steps: 59 | Train Loss: 0.2083076 Vali Loss: 1.2441987 Test Loss: 0.5100398
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 4.741767406463623
Epoch: 66, Steps: 59 | Train Loss: 0.2080829 Vali Loss: 1.2465422 Test Loss: 0.5097663
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 4.590403079986572
Epoch: 67, Steps: 59 | Train Loss: 0.2079169 Vali Loss: 1.2498173 Test Loss: 0.5094749
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 4.8729023933410645
Epoch: 68, Steps: 59 | Train Loss: 0.2076340 Vali Loss: 1.2439252 Test Loss: 0.5092002
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 4.412353038787842
Epoch: 69, Steps: 59 | Train Loss: 0.2075083 Vali Loss: 1.2414691 Test Loss: 0.5089645
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 4.605402946472168
Epoch: 70, Steps: 59 | Train Loss: 0.2074192 Vali Loss: 1.2440838 Test Loss: 0.5087097
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 4.986388921737671
Epoch: 71, Steps: 59 | Train Loss: 0.2071132 Vali Loss: 1.2434733 Test Loss: 0.5085005
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 4.8592493534088135
Epoch: 72, Steps: 59 | Train Loss: 0.2069669 Vali Loss: 1.2467600 Test Loss: 0.5082704
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 4.747735977172852
Epoch: 73, Steps: 59 | Train Loss: 0.2069199 Vali Loss: 1.2438488 Test Loss: 0.5080880
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 4.6376426219940186
Epoch: 74, Steps: 59 | Train Loss: 0.2067387 Vali Loss: 1.2388402 Test Loss: 0.5078846
Validation loss decreased (1.241463 --> 1.238840).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 4.741862058639526
Epoch: 75, Steps: 59 | Train Loss: 0.2065757 Vali Loss: 1.2471679 Test Loss: 0.5076795
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 4.679508209228516
Epoch: 76, Steps: 59 | Train Loss: 0.2064001 Vali Loss: 1.2439396 Test Loss: 0.5075321
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 4.526851177215576
Epoch: 77, Steps: 59 | Train Loss: 0.2063106 Vali Loss: 1.2467821 Test Loss: 0.5073718
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 4.470221996307373
Epoch: 78, Steps: 59 | Train Loss: 0.2060807 Vali Loss: 1.2431347 Test Loss: 0.5072111
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 4.538763046264648
Epoch: 79, Steps: 59 | Train Loss: 0.2060828 Vali Loss: 1.2453550 Test Loss: 0.5070350
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 4.381707191467285
Epoch: 80, Steps: 59 | Train Loss: 0.2060107 Vali Loss: 1.2443305 Test Loss: 0.5069030
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 5.003131866455078
Epoch: 81, Steps: 59 | Train Loss: 0.2059315 Vali Loss: 1.2443700 Test Loss: 0.5067718
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 4.296757221221924
Epoch: 82, Steps: 59 | Train Loss: 0.2057794 Vali Loss: 1.2466898 Test Loss: 0.5066468
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 4.295137405395508
Epoch: 83, Steps: 59 | Train Loss: 0.2057262 Vali Loss: 1.2443634 Test Loss: 0.5065157
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 4.5042173862457275
Epoch: 84, Steps: 59 | Train Loss: 0.2054621 Vali Loss: 1.2402694 Test Loss: 0.5064042
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 4.954874277114868
Epoch: 85, Steps: 59 | Train Loss: 0.2054424 Vali Loss: 1.2438838 Test Loss: 0.5062881
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 4.851726055145264
Epoch: 86, Steps: 59 | Train Loss: 0.2055196 Vali Loss: 1.2422661 Test Loss: 0.5061831
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 4.373947620391846
Epoch: 87, Steps: 59 | Train Loss: 0.2053656 Vali Loss: 1.2426748 Test Loss: 0.5060795
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 4.450310230255127
Epoch: 88, Steps: 59 | Train Loss: 0.2052774 Vali Loss: 1.2466825 Test Loss: 0.5059893
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 4.727490425109863
Epoch: 89, Steps: 59 | Train Loss: 0.2051912 Vali Loss: 1.2438637 Test Loss: 0.5058968
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 4.197108030319214
Epoch: 90, Steps: 59 | Train Loss: 0.2050767 Vali Loss: 1.2404813 Test Loss: 0.5058221
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 4.284873723983765
Epoch: 91, Steps: 59 | Train Loss: 0.2051181 Vali Loss: 1.2428114 Test Loss: 0.5057362
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 4.506626844406128
Epoch: 92, Steps: 59 | Train Loss: 0.2048951 Vali Loss: 1.2454594 Test Loss: 0.5056587
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 4.88605523109436
Epoch: 93, Steps: 59 | Train Loss: 0.2049284 Vali Loss: 1.2447785 Test Loss: 0.5055835
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 4.421466827392578
Epoch: 94, Steps: 59 | Train Loss: 0.2048460 Vali Loss: 1.2424234 Test Loss: 0.5055233
EarlyStopping counter: 20 out of 20
Early stopping
train 7585
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=103, out_features=151, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  13935488.0
params:  15704.0
Trainable parameters:  15704
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 4.359694480895996
Epoch: 1, Steps: 59 | Train Loss: 0.4651921 Vali Loss: 1.2085251 Test Loss: 0.4634783
Validation loss decreased (inf --> 1.208525).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.355384111404419
Epoch: 2, Steps: 59 | Train Loss: 0.4492946 Vali Loss: 1.1971549 Test Loss: 0.4488679
Validation loss decreased (1.208525 --> 1.197155).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 4.621944427490234
Epoch: 3, Steps: 59 | Train Loss: 0.4437171 Vali Loss: 1.1988320 Test Loss: 0.4456269
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
Epoch: 4 cost time: 4.21308708190918
Epoch: 4, Steps: 59 | Train Loss: 0.4418790 Vali Loss: 1.2045940 Test Loss: 0.4454664
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 4.231577396392822
Epoch: 5, Steps: 59 | Train Loss: 0.4412537 Vali Loss: 1.2088540 Test Loss: 0.4461497
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 4.478375196456909
Epoch: 6, Steps: 59 | Train Loss: 0.4406973 Vali Loss: 1.2107688 Test Loss: 0.4464848
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 4.788927316665649
Epoch: 7, Steps: 59 | Train Loss: 0.4401120 Vali Loss: 1.2111146 Test Loss: 0.4469390
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 4.3728296756744385
Epoch: 8, Steps: 59 | Train Loss: 0.4399688 Vali Loss: 1.2127711 Test Loss: 0.4474631
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 4.362743616104126
Epoch: 9, Steps: 59 | Train Loss: 0.4398139 Vali Loss: 1.2162806 Test Loss: 0.4473828
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 4.151700258255005
Epoch: 10, Steps: 59 | Train Loss: 0.4393814 Vali Loss: 1.2174805 Test Loss: 0.4478413
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 4.685164928436279
Epoch: 11, Steps: 59 | Train Loss: 0.4394793 Vali Loss: 1.2136195 Test Loss: 0.4479105
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 4.6509130001068115
Epoch: 12, Steps: 59 | Train Loss: 0.4389425 Vali Loss: 1.2191026 Test Loss: 0.4481024
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 5.276385307312012
Epoch: 13, Steps: 59 | Train Loss: 0.4389784 Vali Loss: 1.2184420 Test Loss: 0.4482370
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 4.440335035324097
Epoch: 14, Steps: 59 | Train Loss: 0.4387205 Vali Loss: 1.2164463 Test Loss: 0.4481832
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 4.253936529159546
Epoch: 15, Steps: 59 | Train Loss: 0.4387017 Vali Loss: 1.2175320 Test Loss: 0.4483894
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 4.031623363494873
Epoch: 16, Steps: 59 | Train Loss: 0.4387881 Vali Loss: 1.2168741 Test Loss: 0.4486466
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 4.328059434890747
Epoch: 17, Steps: 59 | Train Loss: 0.4386591 Vali Loss: 1.2214363 Test Loss: 0.4484517
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 4.194944858551025
Epoch: 18, Steps: 59 | Train Loss: 0.4386406 Vali Loss: 1.2182419 Test Loss: 0.4485362
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 4.048121690750122
Epoch: 19, Steps: 59 | Train Loss: 0.4384235 Vali Loss: 1.2202374 Test Loss: 0.4486121
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.433754920959473
Epoch: 20, Steps: 59 | Train Loss: 0.4384367 Vali Loss: 1.2228107 Test Loss: 0.4487232
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 4.304332494735718
Epoch: 21, Steps: 59 | Train Loss: 0.4382339 Vali Loss: 1.2237035 Test Loss: 0.4487299
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 4.566675424575806
Epoch: 22, Steps: 59 | Train Loss: 0.4382037 Vali Loss: 1.2238013 Test Loss: 0.4487596
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_720_336_FITS_ETTh1_ftM_sl720_ll48_pl336_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.44766274094581604, mae:0.4472420811653137, rse:0.6369825005531311, corr:[0.24978986 0.25830504 0.25945237 0.25647908 0.25290975 0.25050738
 0.24962148 0.24973297 0.2500863  0.25039378 0.25036913 0.2500656
 0.24978088 0.24950068 0.24912739 0.24864425 0.24804606 0.2474467
 0.24696666 0.24676163 0.24690671 0.24725555 0.24742061 0.24722974
 0.24679208 0.24639757 0.2462618  0.24623668 0.24622066 0.24615556
 0.246035   0.24577788 0.24554631 0.24538158 0.24519628 0.24510956
 0.24515194 0.2452279  0.24527836 0.24528593 0.2453478  0.24536407
 0.24526052 0.2450976  0.24494609 0.24492648 0.24513103 0.24538146
 0.24519947 0.24461429 0.24353974 0.24232024 0.24118908 0.24015059
 0.23939729 0.23906417 0.23906784 0.23927228 0.23935232 0.23929217
 0.23908035 0.23892392 0.23880476 0.23889007 0.23911767 0.23938192
 0.23964693 0.23973384 0.23982583 0.2398955  0.23987287 0.23960559
 0.23911929 0.2384784  0.23780534 0.23733322 0.23695852 0.23653086
 0.23604032 0.23555599 0.23509409 0.2346988  0.23439708 0.23427776
 0.23432475 0.2343789  0.23430249 0.23402193 0.23356582 0.23309998
 0.23270574 0.23253922 0.23252794 0.23274639 0.2331548  0.23368184
 0.23430103 0.23486419 0.23514102 0.23527698 0.23534806 0.23529328
 0.23512255 0.23485269 0.23449285 0.23416045 0.23386753 0.23370269
 0.23375924 0.23397006 0.23419476 0.2344009  0.23451069 0.23453638
 0.23457448 0.23464707 0.23480225 0.2350631  0.23537782 0.23561472
 0.23563685 0.23524764 0.23453633 0.23377086 0.23312734 0.23250458
 0.23189056 0.23133211 0.23061326 0.22992715 0.22943875 0.22923939
 0.2292917  0.22949497 0.2298303  0.23010601 0.23023097 0.23014668
 0.2298266  0.22935556 0.22889847 0.22848845 0.22810358 0.22768007
 0.22720441 0.22664908 0.22607523 0.22553079 0.22519754 0.22488016
 0.22453582 0.22426975 0.22410247 0.22406374 0.22408168 0.22416301
 0.22419748 0.22413312 0.22396173 0.22362553 0.22306871 0.22257228
 0.22201961 0.2214688  0.22104217 0.22091521 0.22116059 0.22172607
 0.22247636 0.2231353  0.2233682  0.22314243 0.2225562  0.22188976
 0.22133517 0.22110246 0.22099361 0.22098453 0.220944   0.22091778
 0.22086263 0.22080763 0.22081953 0.22100626 0.22141147 0.2219449
 0.22243404 0.22281493 0.22315893 0.22346635 0.22357243 0.22335742
 0.22282043 0.22210455 0.22124538 0.2203402  0.21958321 0.21891357
 0.21832019 0.21798709 0.21798435 0.2183405  0.21886069 0.21943969
 0.21971266 0.2195891  0.21911378 0.21851881 0.21822055 0.21831179
 0.21865569 0.2188315  0.21875514 0.21843871 0.2180454  0.2176877
 0.21733369 0.21702203 0.21654177 0.21585743 0.2152241  0.2145407
 0.21397275 0.21366681 0.2136478  0.21369976 0.2136474  0.21361245
 0.21364118 0.21366303 0.21384418 0.21414225 0.21434158 0.21450289
 0.21462162 0.21467195 0.21479431 0.21496725 0.21524003 0.21530439
 0.2152067  0.21501338 0.21494275 0.21501565 0.21512882 0.21506856
 0.2147693  0.21430822 0.21369582 0.21295163 0.212229   0.21178325
 0.2116472  0.2115531  0.21143799 0.21124578 0.21114963 0.21127349
 0.2116724  0.21204035 0.21238841 0.21260257 0.2127055  0.2126442
 0.2126227  0.2127392  0.21282583 0.21268691 0.21210906 0.21132196
 0.21078521 0.21057479 0.21043181 0.21018489 0.20946807 0.20844972
 0.20757185 0.20711212 0.20718023 0.20765018 0.20824689 0.20871921
 0.20877178 0.20830488 0.20788038 0.20783344 0.20837668 0.20917648
 0.20986721 0.21027648 0.2099538  0.2092088  0.20832172 0.20789239
 0.20794185 0.20816089 0.20826063 0.20824048 0.2081523  0.2082886
 0.20878857 0.20930147 0.20978864 0.20987804 0.209816   0.20969884
 0.20981455 0.20976011 0.20965733 0.20918413 0.20850496 0.20794503
 0.20784439 0.20805965 0.20787114 0.20692073 0.20558344 0.20402646
 0.20290235 0.20241378 0.20250487 0.20260832 0.20206176 0.20104273
 0.20029865 0.19990876 0.19985539 0.20015834 0.19964376 0.198295
 0.1966145  0.19556211 0.19608317 0.19741644 0.19647036 0.18689309]
