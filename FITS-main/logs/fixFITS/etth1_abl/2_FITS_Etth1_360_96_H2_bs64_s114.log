Args in experiment:
Namespace(H_order=2, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=42, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_360_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_360_96_FITS_ETTh1_ftM_sl360_ll48_pl96_H2_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8185
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=42, out_features=53, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1994496.0
params:  2279.0
Trainable parameters:  2279
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.4236435890197754
Epoch: 1, Steps: 63 | Train Loss: 0.6004855 Vali Loss: 1.5247917 Test Loss: 0.8796442
Validation loss decreased (inf --> 1.524792).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.3491973876953125
Epoch: 2, Steps: 63 | Train Loss: 0.4992605 Vali Loss: 1.3469061 Test Loss: 0.7778223
Validation loss decreased (1.524792 --> 1.346906).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.4020464420318604
Epoch: 3, Steps: 63 | Train Loss: 0.4341985 Vali Loss: 1.2283305 Test Loss: 0.7168964
Validation loss decreased (1.346906 --> 1.228330).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.3553674221038818
Epoch: 4, Steps: 63 | Train Loss: 0.3903523 Vali Loss: 1.1572403 Test Loss: 0.6795757
Validation loss decreased (1.228330 --> 1.157240).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.3717074394226074
Epoch: 5, Steps: 63 | Train Loss: 0.3588540 Vali Loss: 1.1108973 Test Loss: 0.6551685
Validation loss decreased (1.157240 --> 1.110897).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.3862271308898926
Epoch: 6, Steps: 63 | Train Loss: 0.3356827 Vali Loss: 1.0742115 Test Loss: 0.6368091
Validation loss decreased (1.110897 --> 1.074211).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.316108226776123
Epoch: 7, Steps: 63 | Train Loss: 0.3169287 Vali Loss: 1.0496203 Test Loss: 0.6227549
Validation loss decreased (1.074211 --> 1.049620).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.423781394958496
Epoch: 8, Steps: 63 | Train Loss: 0.3017113 Vali Loss: 1.0262654 Test Loss: 0.6098952
Validation loss decreased (1.049620 --> 1.026265).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.3141322135925293
Epoch: 9, Steps: 63 | Train Loss: 0.2882666 Vali Loss: 1.0080742 Test Loss: 0.5998884
Validation loss decreased (1.026265 --> 1.008074).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.3112139701843262
Epoch: 10, Steps: 63 | Train Loss: 0.2770638 Vali Loss: 0.9885195 Test Loss: 0.5895613
Validation loss decreased (1.008074 --> 0.988519).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.4126629829406738
Epoch: 11, Steps: 63 | Train Loss: 0.2669077 Vali Loss: 0.9764859 Test Loss: 0.5800688
Validation loss decreased (0.988519 --> 0.976486).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.381230115890503
Epoch: 12, Steps: 63 | Train Loss: 0.2581011 Vali Loss: 0.9596719 Test Loss: 0.5710983
Validation loss decreased (0.976486 --> 0.959672).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.35994553565979
Epoch: 13, Steps: 63 | Train Loss: 0.2500517 Vali Loss: 0.9475676 Test Loss: 0.5647174
Validation loss decreased (0.959672 --> 0.947568).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.3792839050292969
Epoch: 14, Steps: 63 | Train Loss: 0.2426559 Vali Loss: 0.9294871 Test Loss: 0.5566501
Validation loss decreased (0.947568 --> 0.929487).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.355189561843872
Epoch: 15, Steps: 63 | Train Loss: 0.2363976 Vali Loss: 0.9223255 Test Loss: 0.5509523
Validation loss decreased (0.929487 --> 0.922325).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.2778046131134033
Epoch: 16, Steps: 63 | Train Loss: 0.2304995 Vali Loss: 0.9125792 Test Loss: 0.5445777
Validation loss decreased (0.922325 --> 0.912579).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.3434550762176514
Epoch: 17, Steps: 63 | Train Loss: 0.2251950 Vali Loss: 0.9017364 Test Loss: 0.5381216
Validation loss decreased (0.912579 --> 0.901736).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.3482766151428223
Epoch: 18, Steps: 63 | Train Loss: 0.2202583 Vali Loss: 0.8985807 Test Loss: 0.5334681
Validation loss decreased (0.901736 --> 0.898581).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.3741815090179443
Epoch: 19, Steps: 63 | Train Loss: 0.2159569 Vali Loss: 0.8832752 Test Loss: 0.5282623
Validation loss decreased (0.898581 --> 0.883275).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.3244264125823975
Epoch: 20, Steps: 63 | Train Loss: 0.2118827 Vali Loss: 0.8774418 Test Loss: 0.5224066
Validation loss decreased (0.883275 --> 0.877442).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.3322525024414062
Epoch: 21, Steps: 63 | Train Loss: 0.2079272 Vali Loss: 0.8747720 Test Loss: 0.5186585
Validation loss decreased (0.877442 --> 0.874772).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.346120834350586
Epoch: 22, Steps: 63 | Train Loss: 0.2046959 Vali Loss: 0.8641413 Test Loss: 0.5147047
Validation loss decreased (0.874772 --> 0.864141).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.3269932270050049
Epoch: 23, Steps: 63 | Train Loss: 0.2015200 Vali Loss: 0.8599219 Test Loss: 0.5106021
Validation loss decreased (0.864141 --> 0.859922).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.3735716342926025
Epoch: 24, Steps: 63 | Train Loss: 0.1986173 Vali Loss: 0.8593066 Test Loss: 0.5076426
Validation loss decreased (0.859922 --> 0.859307).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.2009761333465576
Epoch: 25, Steps: 63 | Train Loss: 0.1957656 Vali Loss: 0.8450950 Test Loss: 0.5035400
Validation loss decreased (0.859307 --> 0.845095).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.2733879089355469
Epoch: 26, Steps: 63 | Train Loss: 0.1934935 Vali Loss: 0.8478234 Test Loss: 0.5006593
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.5694222450256348
Epoch: 27, Steps: 63 | Train Loss: 0.1908823 Vali Loss: 0.8420660 Test Loss: 0.4977513
Validation loss decreased (0.845095 --> 0.842066).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.4245407581329346
Epoch: 28, Steps: 63 | Train Loss: 0.1887796 Vali Loss: 0.8379210 Test Loss: 0.4944072
Validation loss decreased (0.842066 --> 0.837921).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.3627758026123047
Epoch: 29, Steps: 63 | Train Loss: 0.1868215 Vali Loss: 0.8314024 Test Loss: 0.4921136
Validation loss decreased (0.837921 --> 0.831402).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.4103851318359375
Epoch: 30, Steps: 63 | Train Loss: 0.1849180 Vali Loss: 0.8276868 Test Loss: 0.4896309
Validation loss decreased (0.831402 --> 0.827687).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.7407586574554443
Epoch: 31, Steps: 63 | Train Loss: 0.1831176 Vali Loss: 0.8257813 Test Loss: 0.4874444
Validation loss decreased (0.827687 --> 0.825781).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.4278407096862793
Epoch: 32, Steps: 63 | Train Loss: 0.1814557 Vali Loss: 0.8223822 Test Loss: 0.4854980
Validation loss decreased (0.825781 --> 0.822382).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.308048963546753
Epoch: 33, Steps: 63 | Train Loss: 0.1799419 Vali Loss: 0.8189040 Test Loss: 0.4831434
Validation loss decreased (0.822382 --> 0.818904).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.4357895851135254
Epoch: 34, Steps: 63 | Train Loss: 0.1784409 Vali Loss: 0.8171424 Test Loss: 0.4815992
Validation loss decreased (0.818904 --> 0.817142).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.4094328880310059
Epoch: 35, Steps: 63 | Train Loss: 0.1771230 Vali Loss: 0.8163489 Test Loss: 0.4797779
Validation loss decreased (0.817142 --> 0.816349).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.498030185699463
Epoch: 36, Steps: 63 | Train Loss: 0.1761385 Vali Loss: 0.8136777 Test Loss: 0.4777333
Validation loss decreased (0.816349 --> 0.813678).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.478450059890747
Epoch: 37, Steps: 63 | Train Loss: 0.1748942 Vali Loss: 0.8101672 Test Loss: 0.4764052
Validation loss decreased (0.813678 --> 0.810167).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.3697044849395752
Epoch: 38, Steps: 63 | Train Loss: 0.1736906 Vali Loss: 0.8051252 Test Loss: 0.4746605
Validation loss decreased (0.810167 --> 0.805125).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.3583920001983643
Epoch: 39, Steps: 63 | Train Loss: 0.1727144 Vali Loss: 0.8045968 Test Loss: 0.4734093
Validation loss decreased (0.805125 --> 0.804597).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.373732089996338
Epoch: 40, Steps: 63 | Train Loss: 0.1715439 Vali Loss: 0.8027503 Test Loss: 0.4721256
Validation loss decreased (0.804597 --> 0.802750).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.3701095581054688
Epoch: 41, Steps: 63 | Train Loss: 0.1707236 Vali Loss: 0.8004312 Test Loss: 0.4708430
Validation loss decreased (0.802750 --> 0.800431).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.4383912086486816
Epoch: 42, Steps: 63 | Train Loss: 0.1699324 Vali Loss: 0.7988663 Test Loss: 0.4693408
Validation loss decreased (0.800431 --> 0.798866).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.327521800994873
Epoch: 43, Steps: 63 | Train Loss: 0.1689942 Vali Loss: 0.7948897 Test Loss: 0.4681972
Validation loss decreased (0.798866 --> 0.794890).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.3037261962890625
Epoch: 44, Steps: 63 | Train Loss: 0.1683076 Vali Loss: 0.7935929 Test Loss: 0.4673700
Validation loss decreased (0.794890 --> 0.793593).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.4484286308288574
Epoch: 45, Steps: 63 | Train Loss: 0.1676967 Vali Loss: 0.7933913 Test Loss: 0.4663284
Validation loss decreased (0.793593 --> 0.793391).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.2584316730499268
Epoch: 46, Steps: 63 | Train Loss: 0.1669457 Vali Loss: 0.7937007 Test Loss: 0.4652885
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.271101951599121
Epoch: 47, Steps: 63 | Train Loss: 0.1661592 Vali Loss: 0.7929903 Test Loss: 0.4645038
Validation loss decreased (0.793391 --> 0.792990).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.3274869918823242
Epoch: 48, Steps: 63 | Train Loss: 0.1656378 Vali Loss: 0.7927395 Test Loss: 0.4637482
Validation loss decreased (0.792990 --> 0.792740).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.4501664638519287
Epoch: 49, Steps: 63 | Train Loss: 0.1650204 Vali Loss: 0.7920402 Test Loss: 0.4628577
Validation loss decreased (0.792740 --> 0.792040).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.2999653816223145
Epoch: 50, Steps: 63 | Train Loss: 0.1643224 Vali Loss: 0.7908958 Test Loss: 0.4620781
Validation loss decreased (0.792040 --> 0.790896).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.3867301940917969
Epoch: 51, Steps: 63 | Train Loss: 0.1638888 Vali Loss: 0.7908422 Test Loss: 0.4615271
Validation loss decreased (0.790896 --> 0.790842).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.2648780345916748
Epoch: 52, Steps: 63 | Train Loss: 0.1635373 Vali Loss: 0.7836167 Test Loss: 0.4606112
Validation loss decreased (0.790842 --> 0.783617).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.382380485534668
Epoch: 53, Steps: 63 | Train Loss: 0.1629962 Vali Loss: 0.7862670 Test Loss: 0.4599643
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.4040262699127197
Epoch: 54, Steps: 63 | Train Loss: 0.1624970 Vali Loss: 0.7823346 Test Loss: 0.4593508
Validation loss decreased (0.783617 --> 0.782335).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.295337438583374
Epoch: 55, Steps: 63 | Train Loss: 0.1623769 Vali Loss: 0.7858149 Test Loss: 0.4587111
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.369516372680664
Epoch: 56, Steps: 63 | Train Loss: 0.1618047 Vali Loss: 0.7831308 Test Loss: 0.4581656
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.3488821983337402
Epoch: 57, Steps: 63 | Train Loss: 0.1616245 Vali Loss: 0.7829632 Test Loss: 0.4576368
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.336881399154663
Epoch: 58, Steps: 63 | Train Loss: 0.1609454 Vali Loss: 0.7788103 Test Loss: 0.4570325
Validation loss decreased (0.782335 --> 0.778810).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.4166185855865479
Epoch: 59, Steps: 63 | Train Loss: 0.1607130 Vali Loss: 0.7838495 Test Loss: 0.4567061
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.458655834197998
Epoch: 60, Steps: 63 | Train Loss: 0.1602499 Vali Loss: 0.7807420 Test Loss: 0.4562508
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.4600498676300049
Epoch: 61, Steps: 63 | Train Loss: 0.1601017 Vali Loss: 0.7770817 Test Loss: 0.4558382
Validation loss decreased (0.778810 --> 0.777082).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.3511836528778076
Epoch: 62, Steps: 63 | Train Loss: 0.1597216 Vali Loss: 0.7777362 Test Loss: 0.4554558
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.3236339092254639
Epoch: 63, Steps: 63 | Train Loss: 0.1595550 Vali Loss: 0.7783169 Test Loss: 0.4551184
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.3965778350830078
Epoch: 64, Steps: 63 | Train Loss: 0.1593141 Vali Loss: 0.7777188 Test Loss: 0.4546910
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.3008575439453125
Epoch: 65, Steps: 63 | Train Loss: 0.1590908 Vali Loss: 0.7749078 Test Loss: 0.4543217
Validation loss decreased (0.777082 --> 0.774908).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.3348987102508545
Epoch: 66, Steps: 63 | Train Loss: 0.1588064 Vali Loss: 0.7739348 Test Loss: 0.4539128
Validation loss decreased (0.774908 --> 0.773935).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.3620831966400146
Epoch: 67, Steps: 63 | Train Loss: 0.1585026 Vali Loss: 0.7744876 Test Loss: 0.4535923
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.4081811904907227
Epoch: 68, Steps: 63 | Train Loss: 0.1584911 Vali Loss: 0.7756357 Test Loss: 0.4532987
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.3093554973602295
Epoch: 69, Steps: 63 | Train Loss: 0.1581695 Vali Loss: 0.7734233 Test Loss: 0.4530158
Validation loss decreased (0.773935 --> 0.773423).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.3511576652526855
Epoch: 70, Steps: 63 | Train Loss: 0.1578613 Vali Loss: 0.7753664 Test Loss: 0.4526886
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.3784658908843994
Epoch: 71, Steps: 63 | Train Loss: 0.1578526 Vali Loss: 0.7712907 Test Loss: 0.4524083
Validation loss decreased (0.773423 --> 0.771291).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.4184062480926514
Epoch: 72, Steps: 63 | Train Loss: 0.1576376 Vali Loss: 0.7728459 Test Loss: 0.4521983
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.4666571617126465
Epoch: 73, Steps: 63 | Train Loss: 0.1573077 Vali Loss: 0.7722745 Test Loss: 0.4520078
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.4217314720153809
Epoch: 74, Steps: 63 | Train Loss: 0.1574537 Vali Loss: 0.7712039 Test Loss: 0.4517610
Validation loss decreased (0.771291 --> 0.771204).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.4241094589233398
Epoch: 75, Steps: 63 | Train Loss: 0.1571119 Vali Loss: 0.7728547 Test Loss: 0.4515887
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.468775987625122
Epoch: 76, Steps: 63 | Train Loss: 0.1571043 Vali Loss: 0.7730724 Test Loss: 0.4513765
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.379701852798462
Epoch: 77, Steps: 63 | Train Loss: 0.1568268 Vali Loss: 0.7751526 Test Loss: 0.4511861
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.2987604141235352
Epoch: 78, Steps: 63 | Train Loss: 0.1567381 Vali Loss: 0.7712162 Test Loss: 0.4510475
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.313927412033081
Epoch: 79, Steps: 63 | Train Loss: 0.1565417 Vali Loss: 0.7735188 Test Loss: 0.4508329
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.3553133010864258
Epoch: 80, Steps: 63 | Train Loss: 0.1564907 Vali Loss: 0.7712283 Test Loss: 0.4506765
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.4266855716705322
Epoch: 81, Steps: 63 | Train Loss: 0.1564500 Vali Loss: 0.7717757 Test Loss: 0.4505337
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.3817353248596191
Epoch: 82, Steps: 63 | Train Loss: 0.1564324 Vali Loss: 0.7717497 Test Loss: 0.4503838
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.3358240127563477
Epoch: 83, Steps: 63 | Train Loss: 0.1564005 Vali Loss: 0.7662458 Test Loss: 0.4502073
Validation loss decreased (0.771204 --> 0.766246).  Saving model ...
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.448948860168457
Epoch: 84, Steps: 63 | Train Loss: 0.1561830 Vali Loss: 0.7707704 Test Loss: 0.4500774
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.322432041168213
Epoch: 85, Steps: 63 | Train Loss: 0.1560232 Vali Loss: 0.7670875 Test Loss: 0.4499711
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.4480745792388916
Epoch: 86, Steps: 63 | Train Loss: 0.1559100 Vali Loss: 0.7667991 Test Loss: 0.4498030
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.3788752555847168
Epoch: 87, Steps: 63 | Train Loss: 0.1558255 Vali Loss: 0.7683451 Test Loss: 0.4496990
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.4556901454925537
Epoch: 88, Steps: 63 | Train Loss: 0.1557913 Vali Loss: 0.7696786 Test Loss: 0.4495935
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.3215177059173584
Epoch: 89, Steps: 63 | Train Loss: 0.1556502 Vali Loss: 0.7722995 Test Loss: 0.4494877
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.4078233242034912
Epoch: 90, Steps: 63 | Train Loss: 0.1557561 Vali Loss: 0.7673147 Test Loss: 0.4493819
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.3733844757080078
Epoch: 91, Steps: 63 | Train Loss: 0.1556659 Vali Loss: 0.7695184 Test Loss: 0.4492805
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.3149528503417969
Epoch: 92, Steps: 63 | Train Loss: 0.1556621 Vali Loss: 0.7669969 Test Loss: 0.4491777
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.3401458263397217
Epoch: 93, Steps: 63 | Train Loss: 0.1555373 Vali Loss: 0.7629542 Test Loss: 0.4490943
Validation loss decreased (0.766246 --> 0.762954).  Saving model ...
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.285264015197754
Epoch: 94, Steps: 63 | Train Loss: 0.1553692 Vali Loss: 0.7676395 Test Loss: 0.4490154
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.3185279369354248
Epoch: 95, Steps: 63 | Train Loss: 0.1553520 Vali Loss: 0.7667770 Test Loss: 0.4489374
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.337989330291748
Epoch: 96, Steps: 63 | Train Loss: 0.1552190 Vali Loss: 0.7670124 Test Loss: 0.4488439
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.2200162410736084
Epoch: 97, Steps: 63 | Train Loss: 0.1551624 Vali Loss: 0.7650393 Test Loss: 0.4487766
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.9601008892059326
Epoch: 98, Steps: 63 | Train Loss: 0.1551858 Vali Loss: 0.7703070 Test Loss: 0.4487167
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.3695878982543945
Epoch: 99, Steps: 63 | Train Loss: 0.1551118 Vali Loss: 0.7714419 Test Loss: 0.4486531
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.386352300643921
Epoch: 100, Steps: 63 | Train Loss: 0.1550222 Vali Loss: 0.7659655 Test Loss: 0.4485777
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8185
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=42, out_features=53, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1994496.0
params:  2279.0
Trainable parameters:  2279
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.2728774547576904
Epoch: 1, Steps: 63 | Train Loss: 0.3752324 Vali Loss: 0.7036356 Test Loss: 0.4053340
Validation loss decreased (inf --> 0.703636).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.4339618682861328
Epoch: 2, Steps: 63 | Train Loss: 0.3596841 Vali Loss: 0.6974198 Test Loss: 0.3993464
Validation loss decreased (0.703636 --> 0.697420).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.268507957458496
Epoch: 3, Steps: 63 | Train Loss: 0.3580971 Vali Loss: 0.6915833 Test Loss: 0.3984526
Validation loss decreased (0.697420 --> 0.691583).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.4334304332733154
Epoch: 4, Steps: 63 | Train Loss: 0.3569666 Vali Loss: 0.6899383 Test Loss: 0.3981771
Validation loss decreased (0.691583 --> 0.689938).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.4011104106903076
Epoch: 5, Steps: 63 | Train Loss: 0.3566031 Vali Loss: 0.6915689 Test Loss: 0.3980675
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.3538875579833984
Epoch: 6, Steps: 63 | Train Loss: 0.3560098 Vali Loss: 0.6913024 Test Loss: 0.3979105
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.3605670928955078
Epoch: 7, Steps: 63 | Train Loss: 0.3551921 Vali Loss: 0.6895473 Test Loss: 0.3977321
Validation loss decreased (0.689938 --> 0.689547).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.423081874847412
Epoch: 8, Steps: 63 | Train Loss: 0.3556954 Vali Loss: 0.6920894 Test Loss: 0.3980027
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.4023535251617432
Epoch: 9, Steps: 63 | Train Loss: 0.3557535 Vali Loss: 0.6855388 Test Loss: 0.3978255
Validation loss decreased (0.689547 --> 0.685539).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.4458091259002686
Epoch: 10, Steps: 63 | Train Loss: 0.3554025 Vali Loss: 0.6872912 Test Loss: 0.3977093
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.286586046218872
Epoch: 11, Steps: 63 | Train Loss: 0.3551149 Vali Loss: 0.6881890 Test Loss: 0.3975620
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.388561725616455
Epoch: 12, Steps: 63 | Train Loss: 0.3555633 Vali Loss: 0.6885334 Test Loss: 0.3978246
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.3920423984527588
Epoch: 13, Steps: 63 | Train Loss: 0.3554524 Vali Loss: 0.6916269 Test Loss: 0.3974806
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.3058183193206787
Epoch: 14, Steps: 63 | Train Loss: 0.3553890 Vali Loss: 0.6839355 Test Loss: 0.3974729
Validation loss decreased (0.685539 --> 0.683935).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.3505702018737793
Epoch: 15, Steps: 63 | Train Loss: 0.3550690 Vali Loss: 0.6876982 Test Loss: 0.3974247
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.251056432723999
Epoch: 16, Steps: 63 | Train Loss: 0.3551748 Vali Loss: 0.6877600 Test Loss: 0.3974195
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.3560314178466797
Epoch: 17, Steps: 63 | Train Loss: 0.3547324 Vali Loss: 0.6883158 Test Loss: 0.3973833
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.3503458499908447
Epoch: 18, Steps: 63 | Train Loss: 0.3546714 Vali Loss: 0.6837733 Test Loss: 0.3971753
Validation loss decreased (0.683935 --> 0.683773).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.4842817783355713
Epoch: 19, Steps: 63 | Train Loss: 0.3549685 Vali Loss: 0.6850500 Test Loss: 0.3972866
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.3755879402160645
Epoch: 20, Steps: 63 | Train Loss: 0.3548677 Vali Loss: 0.6870601 Test Loss: 0.3974676
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.360680103302002
Epoch: 21, Steps: 63 | Train Loss: 0.3545228 Vali Loss: 0.6891220 Test Loss: 0.3973682
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.3519830703735352
Epoch: 22, Steps: 63 | Train Loss: 0.3544768 Vali Loss: 0.6881666 Test Loss: 0.3973733
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.4846224784851074
Epoch: 23, Steps: 63 | Train Loss: 0.3540210 Vali Loss: 0.6857823 Test Loss: 0.3972265
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.52809739112854
Epoch: 24, Steps: 63 | Train Loss: 0.3548548 Vali Loss: 0.6876642 Test Loss: 0.3972273
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.3227934837341309
Epoch: 25, Steps: 63 | Train Loss: 0.3543513 Vali Loss: 0.6852203 Test Loss: 0.3972838
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.4142770767211914
Epoch: 26, Steps: 63 | Train Loss: 0.3551337 Vali Loss: 0.6881608 Test Loss: 0.3973495
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.3824970722198486
Epoch: 27, Steps: 63 | Train Loss: 0.3541552 Vali Loss: 0.6862035 Test Loss: 0.3972958
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.3414978981018066
Epoch: 28, Steps: 63 | Train Loss: 0.3543785 Vali Loss: 0.6899278 Test Loss: 0.3973003
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.4314613342285156
Epoch: 29, Steps: 63 | Train Loss: 0.3538565 Vali Loss: 0.6897169 Test Loss: 0.3973792
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.26753830909729
Epoch: 30, Steps: 63 | Train Loss: 0.3543601 Vali Loss: 0.6860558 Test Loss: 0.3973097
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.384223222732544
Epoch: 31, Steps: 63 | Train Loss: 0.3541537 Vali Loss: 0.6872111 Test Loss: 0.3972215
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.4096176624298096
Epoch: 32, Steps: 63 | Train Loss: 0.3545329 Vali Loss: 0.6848242 Test Loss: 0.3973458
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.4512407779693604
Epoch: 33, Steps: 63 | Train Loss: 0.3544826 Vali Loss: 0.6850896 Test Loss: 0.3973574
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.1731932163238525
Epoch: 34, Steps: 63 | Train Loss: 0.3540389 Vali Loss: 0.6889458 Test Loss: 0.3972828
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.4497582912445068
Epoch: 35, Steps: 63 | Train Loss: 0.3544055 Vali Loss: 0.6850972 Test Loss: 0.3973458
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.4008078575134277
Epoch: 36, Steps: 63 | Train Loss: 0.3543666 Vali Loss: 0.6864302 Test Loss: 0.3974004
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.3137142658233643
Epoch: 37, Steps: 63 | Train Loss: 0.3548474 Vali Loss: 0.6868126 Test Loss: 0.3974033
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.4870448112487793
Epoch: 38, Steps: 63 | Train Loss: 0.3544606 Vali Loss: 0.6866633 Test Loss: 0.3972465
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_360_96_FITS_ETTh1_ftM_sl360_ll48_pl96_H2_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.39632105827331543, mae:0.41830259561538696, rse:0.5979728102684021, corr:[0.27288052 0.27684537 0.27745166 0.27568585 0.27298558 0.27084348
 0.26968828 0.26954204 0.26975527 0.2699946  0.270101   0.26994887
 0.26971623 0.26958263 0.2695918  0.26967224 0.26960018 0.26934275
 0.2690194  0.2686685  0.26845595 0.26851892 0.26864392 0.26877278
 0.26870573 0.26844987 0.2680449  0.26758423 0.26706174 0.26657182
 0.26619732 0.26589432 0.2656773  0.2654632  0.26530325 0.26520556
 0.2652461  0.26545638 0.26575395 0.26599365 0.26620966 0.26624966
 0.26619977 0.26616013 0.26627442 0.26654568 0.26689178 0.26701525
 0.2665619  0.26549098 0.26385555 0.2622297  0.26094314 0.260027
 0.2597026  0.25979558 0.2599737  0.26004717 0.25986594 0.25962344
 0.2593605  0.25918543 0.25914457 0.25929934 0.25954077 0.25981903
 0.2600823  0.2601187  0.26006094 0.2601554  0.26034293 0.2603556
 0.26000983 0.25934598 0.2584686  0.257574   0.25677425 0.25607565
 0.25565046 0.2553848  0.25521946 0.25503474 0.25473312 0.25436383
 0.2541523  0.25413507 0.25417942 0.25405943 0.25380576 0.25362226
 0.2535321  0.2534711  0.25349474 0.25380188 0.25414005 0.25367236]
