Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=30, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_90_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_90_96_FITS_ETTh1_ftM_sl90_ll48_pl96_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8455
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=30, out_features=62, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1666560.0
params:  1922.0
Trainable parameters:  1922
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.143444776535034
Epoch: 1, Steps: 66 | Train Loss: 0.6162966 Vali Loss: 1.0205553 Test Loss: 0.6039633
Validation loss decreased (inf --> 1.020555).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.8403842449188232
Epoch: 2, Steps: 66 | Train Loss: 0.4694874 Vali Loss: 0.8683915 Test Loss: 0.4774461
Validation loss decreased (1.020555 --> 0.868392).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.1865978240966797
Epoch: 3, Steps: 66 | Train Loss: 0.4159767 Vali Loss: 0.8055949 Test Loss: 0.4318898
Validation loss decreased (0.868392 --> 0.805595).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.6281254291534424
Epoch: 4, Steps: 66 | Train Loss: 0.3930674 Vali Loss: 0.7792984 Test Loss: 0.4125127
Validation loss decreased (0.805595 --> 0.779298).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.601980447769165
Epoch: 5, Steps: 66 | Train Loss: 0.3816387 Vali Loss: 0.7565638 Test Loss: 0.4032377
Validation loss decreased (0.779298 --> 0.756564).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.721273899078369
Epoch: 6, Steps: 66 | Train Loss: 0.3752232 Vali Loss: 0.7463706 Test Loss: 0.3983263
Validation loss decreased (0.756564 --> 0.746371).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.8550381660461426
Epoch: 7, Steps: 66 | Train Loss: 0.3711211 Vali Loss: 0.7371578 Test Loss: 0.3954540
Validation loss decreased (0.746371 --> 0.737158).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.2120654582977295
Epoch: 8, Steps: 66 | Train Loss: 0.3684131 Vali Loss: 0.7345613 Test Loss: 0.3935308
Validation loss decreased (0.737158 --> 0.734561).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.562138319015503
Epoch: 9, Steps: 66 | Train Loss: 0.3665866 Vali Loss: 0.7288433 Test Loss: 0.3923694
Validation loss decreased (0.734561 --> 0.728843).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.201922655105591
Epoch: 10, Steps: 66 | Train Loss: 0.3649909 Vali Loss: 0.7276361 Test Loss: 0.3914537
Validation loss decreased (0.728843 --> 0.727636).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.018348455429077
Epoch: 11, Steps: 66 | Train Loss: 0.3640127 Vali Loss: 0.7206137 Test Loss: 0.3907245
Validation loss decreased (0.727636 --> 0.720614).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.902787208557129
Epoch: 12, Steps: 66 | Train Loss: 0.3630323 Vali Loss: 0.7186893 Test Loss: 0.3902479
Validation loss decreased (0.720614 --> 0.718689).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.1320207118988037
Epoch: 13, Steps: 66 | Train Loss: 0.3624114 Vali Loss: 0.7261491 Test Loss: 0.3898320
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.6449031829833984
Epoch: 14, Steps: 66 | Train Loss: 0.3619069 Vali Loss: 0.7212669 Test Loss: 0.3894808
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.277273654937744
Epoch: 15, Steps: 66 | Train Loss: 0.3612642 Vali Loss: 0.7150569 Test Loss: 0.3892459
Validation loss decreased (0.718689 --> 0.715057).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 5.085550546646118
Epoch: 16, Steps: 66 | Train Loss: 0.3609621 Vali Loss: 0.7146211 Test Loss: 0.3890524
Validation loss decreased (0.715057 --> 0.714621).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 4.73932671546936
Epoch: 17, Steps: 66 | Train Loss: 0.3605257 Vali Loss: 0.7171441 Test Loss: 0.3888332
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.446779489517212
Epoch: 18, Steps: 66 | Train Loss: 0.3601902 Vali Loss: 0.7138957 Test Loss: 0.3886931
Validation loss decreased (0.714621 --> 0.713896).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.939054489135742
Epoch: 19, Steps: 66 | Train Loss: 0.3599348 Vali Loss: 0.7154468 Test Loss: 0.3886033
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.382389545440674
Epoch: 20, Steps: 66 | Train Loss: 0.3598528 Vali Loss: 0.7088669 Test Loss: 0.3884756
Validation loss decreased (0.713896 --> 0.708867).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.2858481407165527
Epoch: 21, Steps: 66 | Train Loss: 0.3596820 Vali Loss: 0.7117952 Test Loss: 0.3883138
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.7203619480133057
Epoch: 22, Steps: 66 | Train Loss: 0.3594838 Vali Loss: 0.7127410 Test Loss: 0.3882717
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.827303409576416
Epoch: 23, Steps: 66 | Train Loss: 0.3592561 Vali Loss: 0.7107537 Test Loss: 0.3882358
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.6352128982543945
Epoch: 24, Steps: 66 | Train Loss: 0.3591978 Vali Loss: 0.7118800 Test Loss: 0.3880989
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.098531484603882
Epoch: 25, Steps: 66 | Train Loss: 0.3590421 Vali Loss: 0.7143704 Test Loss: 0.3880603
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.637932538986206
Epoch: 26, Steps: 66 | Train Loss: 0.3589464 Vali Loss: 0.7076729 Test Loss: 0.3879854
Validation loss decreased (0.708867 --> 0.707673).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.118379592895508
Epoch: 27, Steps: 66 | Train Loss: 0.3587550 Vali Loss: 0.7122439 Test Loss: 0.3879873
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.8764612674713135
Epoch: 28, Steps: 66 | Train Loss: 0.3586596 Vali Loss: 0.7099629 Test Loss: 0.3879046
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.090970993041992
Epoch: 29, Steps: 66 | Train Loss: 0.3586512 Vali Loss: 0.7117120 Test Loss: 0.3878927
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 3.766288995742798
Epoch: 30, Steps: 66 | Train Loss: 0.3586596 Vali Loss: 0.7070053 Test Loss: 0.3878680
Validation loss decreased (0.707673 --> 0.707005).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.6895694732666016
Epoch: 31, Steps: 66 | Train Loss: 0.3586114 Vali Loss: 0.7126280 Test Loss: 0.3878730
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.6253297328948975
Epoch: 32, Steps: 66 | Train Loss: 0.3583293 Vali Loss: 0.7086443 Test Loss: 0.3878054
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.606454610824585
Epoch: 33, Steps: 66 | Train Loss: 0.3584207 Vali Loss: 0.7069438 Test Loss: 0.3877961
Validation loss decreased (0.707005 --> 0.706944).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.8610846996307373
Epoch: 34, Steps: 66 | Train Loss: 0.3584019 Vali Loss: 0.7129544 Test Loss: 0.3878175
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.1461400985717773
Epoch: 35, Steps: 66 | Train Loss: 0.3582484 Vali Loss: 0.7116840 Test Loss: 0.3877935
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.3397507667541504
Epoch: 36, Steps: 66 | Train Loss: 0.3582815 Vali Loss: 0.7132482 Test Loss: 0.3877799
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.090928554534912
Epoch: 37, Steps: 66 | Train Loss: 0.3581069 Vali Loss: 0.7067388 Test Loss: 0.3877329
Validation loss decreased (0.706944 --> 0.706739).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.1003334522247314
Epoch: 38, Steps: 66 | Train Loss: 0.3581339 Vali Loss: 0.7067305 Test Loss: 0.3877498
Validation loss decreased (0.706739 --> 0.706731).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.930025577545166
Epoch: 39, Steps: 66 | Train Loss: 0.3581702 Vali Loss: 0.7124745 Test Loss: 0.3877386
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.0611836910247803
Epoch: 40, Steps: 66 | Train Loss: 0.3580953 Vali Loss: 0.7090228 Test Loss: 0.3877368
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.9833054542541504
Epoch: 41, Steps: 66 | Train Loss: 0.3582058 Vali Loss: 0.7049025 Test Loss: 0.3877403
Validation loss decreased (0.706731 --> 0.704903).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.1454663276672363
Epoch: 42, Steps: 66 | Train Loss: 0.3580455 Vali Loss: 0.7115750 Test Loss: 0.3877338
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.517786979675293
Epoch: 43, Steps: 66 | Train Loss: 0.3580295 Vali Loss: 0.7094483 Test Loss: 0.3877080
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.4661614894866943
Epoch: 44, Steps: 66 | Train Loss: 0.3579453 Vali Loss: 0.7091680 Test Loss: 0.3876817
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 5.594315052032471
Epoch: 45, Steps: 66 | Train Loss: 0.3580217 Vali Loss: 0.7105919 Test Loss: 0.3877021
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 4.892384767532349
Epoch: 46, Steps: 66 | Train Loss: 0.3579926 Vali Loss: 0.7093699 Test Loss: 0.3876986
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 5.32255220413208
Epoch: 47, Steps: 66 | Train Loss: 0.3579873 Vali Loss: 0.7080812 Test Loss: 0.3876882
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 4.869452953338623
Epoch: 48, Steps: 66 | Train Loss: 0.3579033 Vali Loss: 0.7079775 Test Loss: 0.3876928
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.299370050430298
Epoch: 49, Steps: 66 | Train Loss: 0.3579246 Vali Loss: 0.7109855 Test Loss: 0.3876771
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 3.338550329208374
Epoch: 50, Steps: 66 | Train Loss: 0.3579803 Vali Loss: 0.7067655 Test Loss: 0.3876793
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.1526646614074707
Epoch: 51, Steps: 66 | Train Loss: 0.3578983 Vali Loss: 0.7091765 Test Loss: 0.3876841
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.943481683731079
Epoch: 52, Steps: 66 | Train Loss: 0.3579152 Vali Loss: 0.7072673 Test Loss: 0.3876617
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.7676951885223389
Epoch: 53, Steps: 66 | Train Loss: 0.3578546 Vali Loss: 0.7028758 Test Loss: 0.3876745
Validation loss decreased (0.704903 --> 0.702876).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.764561414718628
Epoch: 54, Steps: 66 | Train Loss: 0.3579238 Vali Loss: 0.7089382 Test Loss: 0.3876851
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.1578080654144287
Epoch: 55, Steps: 66 | Train Loss: 0.3578833 Vali Loss: 0.7061478 Test Loss: 0.3876727
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.717514991760254
Epoch: 56, Steps: 66 | Train Loss: 0.3577938 Vali Loss: 0.7044693 Test Loss: 0.3876701
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.9562561511993408
Epoch: 57, Steps: 66 | Train Loss: 0.3579739 Vali Loss: 0.7078862 Test Loss: 0.3876791
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.175145149230957
Epoch: 58, Steps: 66 | Train Loss: 0.3577954 Vali Loss: 0.7032384 Test Loss: 0.3876748
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.0386574268341064
Epoch: 59, Steps: 66 | Train Loss: 0.3578405 Vali Loss: 0.7078745 Test Loss: 0.3876831
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.101571559906006
Epoch: 60, Steps: 66 | Train Loss: 0.3577751 Vali Loss: 0.7082177 Test Loss: 0.3876688
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.316211462020874
Epoch: 61, Steps: 66 | Train Loss: 0.3579065 Vali Loss: 0.7011014 Test Loss: 0.3876679
Validation loss decreased (0.702876 --> 0.701101).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.105567693710327
Epoch: 62, Steps: 66 | Train Loss: 0.3578238 Vali Loss: 0.7038943 Test Loss: 0.3876753
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.5553038120269775
Epoch: 63, Steps: 66 | Train Loss: 0.3577334 Vali Loss: 0.7027007 Test Loss: 0.3876777
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.5539562702178955
Epoch: 64, Steps: 66 | Train Loss: 0.3576921 Vali Loss: 0.7026640 Test Loss: 0.3876780
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.304448366165161
Epoch: 65, Steps: 66 | Train Loss: 0.3578685 Vali Loss: 0.7079297 Test Loss: 0.3876648
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.1523401737213135
Epoch: 66, Steps: 66 | Train Loss: 0.3577618 Vali Loss: 0.7051641 Test Loss: 0.3876737
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.1149513721466064
Epoch: 67, Steps: 66 | Train Loss: 0.3577468 Vali Loss: 0.7080342 Test Loss: 0.3876793
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.315241575241089
Epoch: 68, Steps: 66 | Train Loss: 0.3577065 Vali Loss: 0.7068188 Test Loss: 0.3876733
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.1419320106506348
Epoch: 69, Steps: 66 | Train Loss: 0.3577785 Vali Loss: 0.7083429 Test Loss: 0.3876853
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.0075643062591553
Epoch: 70, Steps: 66 | Train Loss: 0.3578178 Vali Loss: 0.7070709 Test Loss: 0.3876736
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.318246364593506
Epoch: 71, Steps: 66 | Train Loss: 0.3576854 Vali Loss: 0.7069662 Test Loss: 0.3876738
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.2628684043884277
Epoch: 72, Steps: 66 | Train Loss: 0.3576254 Vali Loss: 0.7042849 Test Loss: 0.3876697
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.0840609073638916
Epoch: 73, Steps: 66 | Train Loss: 0.3575962 Vali Loss: 0.7088588 Test Loss: 0.3876712
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.276538610458374
Epoch: 74, Steps: 66 | Train Loss: 0.3577268 Vali Loss: 0.7020044 Test Loss: 0.3876721
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.1851541996002197
Epoch: 75, Steps: 66 | Train Loss: 0.3576658 Vali Loss: 0.7053386 Test Loss: 0.3876776
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 4.733122110366821
Epoch: 76, Steps: 66 | Train Loss: 0.3576360 Vali Loss: 0.7076797 Test Loss: 0.3876664
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.7759416103363037
Epoch: 77, Steps: 66 | Train Loss: 0.3575810 Vali Loss: 0.7012010 Test Loss: 0.3876725
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 4.292762517929077
Epoch: 78, Steps: 66 | Train Loss: 0.3576840 Vali Loss: 0.7082791 Test Loss: 0.3876708
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 4.405921936035156
Epoch: 79, Steps: 66 | Train Loss: 0.3576821 Vali Loss: 0.7107821 Test Loss: 0.3876714
EarlyStopping counter: 18 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.3767757415771484
Epoch: 80, Steps: 66 | Train Loss: 0.3578273 Vali Loss: 0.7060033 Test Loss: 0.3876742
EarlyStopping counter: 19 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.6885242462158203
Epoch: 81, Steps: 66 | Train Loss: 0.3576148 Vali Loss: 0.7068471 Test Loss: 0.3876731
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_90_96_FITS_ETTh1_ftM_sl90_ll48_pl96_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.3868670165538788, mae:0.39454466104507446, rse:0.5907976031303406, corr:[0.2698713  0.27451593 0.27225918 0.27275234 0.27004346 0.26763442
 0.26714298 0.26659203 0.26637936 0.26629418 0.26565608 0.26552746
 0.26532164 0.26497117 0.265115   0.26514345 0.2653009  0.26563713
 0.26585454 0.26570985 0.265298   0.26495168 0.26426116 0.2637299
 0.26237157 0.2613045  0.26136228 0.26188058 0.26171553 0.26157042
 0.2619544  0.26197642 0.2617653  0.26143214 0.26130602 0.26132432
 0.26105145 0.26115116 0.26141316 0.26122427 0.26146865 0.262069
 0.26247084 0.2624168  0.26232684 0.26226822 0.26191968 0.2614223
 0.26032436 0.25900438 0.25803974 0.2575794  0.2565125  0.25523368
 0.2552165  0.25507927 0.2548102  0.2549286  0.25487527 0.2547422
 0.25470194 0.25491467 0.25477067 0.25447413 0.2545929  0.25466007
 0.25498244 0.25512776 0.25489017 0.25464338 0.2541361  0.25318727
 0.2516484  0.25045988 0.24984151 0.24971405 0.24920797 0.2489702
 0.24959894 0.24952576 0.24924077 0.249195   0.24920373 0.24886625
 0.24842988 0.24867232 0.24882345 0.24817814 0.24803157 0.24825308
 0.24768288 0.24718295 0.24734725 0.24601409 0.24549505 0.24797925]
