Args in experiment:
Namespace(H_order=2, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=42, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_360_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_360_336_FITS_ETTh1_ftM_sl360_ll48_pl336_H2_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7945
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=42, out_features=81, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3048192.0
params:  3483.0
Trainable parameters:  3483
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.5794398784637451
Epoch: 1, Steps: 62 | Train Loss: 0.7351751 Vali Loss: 1.8349105 Test Loss: 0.8746460
Validation loss decreased (inf --> 1.834911).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.524953842163086
Epoch: 2, Steps: 62 | Train Loss: 0.6057135 Vali Loss: 1.6557573 Test Loss: 0.7744716
Validation loss decreased (1.834911 --> 1.655757).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.5514771938323975
Epoch: 3, Steps: 62 | Train Loss: 0.5263742 Vali Loss: 1.5599052 Test Loss: 0.7162058
Validation loss decreased (1.655757 --> 1.559905).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.5110373497009277
Epoch: 4, Steps: 62 | Train Loss: 0.4766166 Vali Loss: 1.5006685 Test Loss: 0.6794348
Validation loss decreased (1.559905 --> 1.500669).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.5422472953796387
Epoch: 5, Steps: 62 | Train Loss: 0.4437803 Vali Loss: 1.4633317 Test Loss: 0.6563905
Validation loss decreased (1.500669 --> 1.463332).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.5119140148162842
Epoch: 6, Steps: 62 | Train Loss: 0.4206277 Vali Loss: 1.4385058 Test Loss: 0.6407245
Validation loss decreased (1.463332 --> 1.438506).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.518448829650879
Epoch: 7, Steps: 62 | Train Loss: 0.4033325 Vali Loss: 1.4179665 Test Loss: 0.6268409
Validation loss decreased (1.438506 --> 1.417966).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.541144609451294
Epoch: 8, Steps: 62 | Train Loss: 0.3898732 Vali Loss: 1.4000241 Test Loss: 0.6166867
Validation loss decreased (1.417966 --> 1.400024).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.4714415073394775
Epoch: 9, Steps: 62 | Train Loss: 0.3788211 Vali Loss: 1.3809162 Test Loss: 0.6076528
Validation loss decreased (1.400024 --> 1.380916).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.429232120513916
Epoch: 10, Steps: 62 | Train Loss: 0.3694625 Vali Loss: 1.3710980 Test Loss: 0.5996765
Validation loss decreased (1.380916 --> 1.371098).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.4299352169036865
Epoch: 11, Steps: 62 | Train Loss: 0.3614677 Vali Loss: 1.3611672 Test Loss: 0.5934240
Validation loss decreased (1.371098 --> 1.361167).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.480651617050171
Epoch: 12, Steps: 62 | Train Loss: 0.3544241 Vali Loss: 1.3496261 Test Loss: 0.5861807
Validation loss decreased (1.361167 --> 1.349626).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.5683419704437256
Epoch: 13, Steps: 62 | Train Loss: 0.3482476 Vali Loss: 1.3411373 Test Loss: 0.5802900
Validation loss decreased (1.349626 --> 1.341137).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.465566873550415
Epoch: 14, Steps: 62 | Train Loss: 0.3427362 Vali Loss: 1.3341861 Test Loss: 0.5747737
Validation loss decreased (1.341137 --> 1.334186).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.372556447982788
Epoch: 15, Steps: 62 | Train Loss: 0.3378793 Vali Loss: 1.3238920 Test Loss: 0.5692939
Validation loss decreased (1.334186 --> 1.323892).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.498023509979248
Epoch: 16, Steps: 62 | Train Loss: 0.3336061 Vali Loss: 1.3203479 Test Loss: 0.5645522
Validation loss decreased (1.323892 --> 1.320348).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.3966271877288818
Epoch: 17, Steps: 62 | Train Loss: 0.3295027 Vali Loss: 1.3103573 Test Loss: 0.5598181
Validation loss decreased (1.320348 --> 1.310357).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.540431261062622
Epoch: 18, Steps: 62 | Train Loss: 0.3259445 Vali Loss: 1.3023475 Test Loss: 0.5559447
Validation loss decreased (1.310357 --> 1.302348).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.4983484745025635
Epoch: 19, Steps: 62 | Train Loss: 0.3226733 Vali Loss: 1.3007313 Test Loss: 0.5519037
Validation loss decreased (1.302348 --> 1.300731).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.5061521530151367
Epoch: 20, Steps: 62 | Train Loss: 0.3196858 Vali Loss: 1.2952311 Test Loss: 0.5483596
Validation loss decreased (1.300731 --> 1.295231).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.5379674434661865
Epoch: 21, Steps: 62 | Train Loss: 0.3169748 Vali Loss: 1.2900760 Test Loss: 0.5451820
Validation loss decreased (1.295231 --> 1.290076).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.485663890838623
Epoch: 22, Steps: 62 | Train Loss: 0.3144321 Vali Loss: 1.2884803 Test Loss: 0.5420399
Validation loss decreased (1.290076 --> 1.288480).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.5106854438781738
Epoch: 23, Steps: 62 | Train Loss: 0.3122006 Vali Loss: 1.2827008 Test Loss: 0.5391700
Validation loss decreased (1.288480 --> 1.282701).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.759242534637451
Epoch: 24, Steps: 62 | Train Loss: 0.3100092 Vali Loss: 1.2740288 Test Loss: 0.5361803
Validation loss decreased (1.282701 --> 1.274029).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 3.1864280700683594
Epoch: 25, Steps: 62 | Train Loss: 0.3081032 Vali Loss: 1.2748227 Test Loss: 0.5336677
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 4.362438201904297
Epoch: 26, Steps: 62 | Train Loss: 0.3063044 Vali Loss: 1.2704490 Test Loss: 0.5313575
Validation loss decreased (1.274029 --> 1.270449).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 3.5431602001190186
Epoch: 27, Steps: 62 | Train Loss: 0.3046412 Vali Loss: 1.2704208 Test Loss: 0.5290212
Validation loss decreased (1.270449 --> 1.270421).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.1900393962860107
Epoch: 28, Steps: 62 | Train Loss: 0.3031205 Vali Loss: 1.2563190 Test Loss: 0.5270741
Validation loss decreased (1.270421 --> 1.256319).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 5.33371639251709
Epoch: 29, Steps: 62 | Train Loss: 0.3016980 Vali Loss: 1.2586985 Test Loss: 0.5250094
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 4.019811153411865
Epoch: 30, Steps: 62 | Train Loss: 0.3004086 Vali Loss: 1.2544007 Test Loss: 0.5230447
Validation loss decreased (1.256319 --> 1.254401).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 3.183713674545288
Epoch: 31, Steps: 62 | Train Loss: 0.2990178 Vali Loss: 1.2546606 Test Loss: 0.5214829
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 3.1237733364105225
Epoch: 32, Steps: 62 | Train Loss: 0.2979446 Vali Loss: 1.2540646 Test Loss: 0.5198839
Validation loss decreased (1.254401 --> 1.254065).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.5679478645324707
Epoch: 33, Steps: 62 | Train Loss: 0.2969175 Vali Loss: 1.2543378 Test Loss: 0.5183909
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.4224207401275635
Epoch: 34, Steps: 62 | Train Loss: 0.2957305 Vali Loss: 1.2489680 Test Loss: 0.5168199
Validation loss decreased (1.254065 --> 1.248968).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.3470783233642578
Epoch: 35, Steps: 62 | Train Loss: 0.2949081 Vali Loss: 1.2407180 Test Loss: 0.5154744
Validation loss decreased (1.248968 --> 1.240718).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.4392740726470947
Epoch: 36, Steps: 62 | Train Loss: 0.2940138 Vali Loss: 1.2416898 Test Loss: 0.5141755
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.6884868144989014
Epoch: 37, Steps: 62 | Train Loss: 0.2931907 Vali Loss: 1.2395555 Test Loss: 0.5130876
Validation loss decreased (1.240718 --> 1.239555).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.5623319149017334
Epoch: 38, Steps: 62 | Train Loss: 0.2924847 Vali Loss: 1.2418352 Test Loss: 0.5118298
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.4330854415893555
Epoch: 39, Steps: 62 | Train Loss: 0.2917312 Vali Loss: 1.2372609 Test Loss: 0.5107514
Validation loss decreased (1.239555 --> 1.237261).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.6305489540100098
Epoch: 40, Steps: 62 | Train Loss: 0.2909696 Vali Loss: 1.2403802 Test Loss: 0.5097929
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.5821046829223633
Epoch: 41, Steps: 62 | Train Loss: 0.2904190 Vali Loss: 1.2385001 Test Loss: 0.5087886
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.5372459888458252
Epoch: 42, Steps: 62 | Train Loss: 0.2898127 Vali Loss: 1.2354279 Test Loss: 0.5079068
Validation loss decreased (1.237261 --> 1.235428).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.4860138893127441
Epoch: 43, Steps: 62 | Train Loss: 0.2892083 Vali Loss: 1.2355921 Test Loss: 0.5070964
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.5218331813812256
Epoch: 44, Steps: 62 | Train Loss: 0.2886143 Vali Loss: 1.2314279 Test Loss: 0.5062439
Validation loss decreased (1.235428 --> 1.231428).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.3869564533233643
Epoch: 45, Steps: 62 | Train Loss: 0.2881809 Vali Loss: 1.2306930 Test Loss: 0.5054736
Validation loss decreased (1.231428 --> 1.230693).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.4712741374969482
Epoch: 46, Steps: 62 | Train Loss: 0.2876219 Vali Loss: 1.2277446 Test Loss: 0.5047280
Validation loss decreased (1.230693 --> 1.227745).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.3799896240234375
Epoch: 47, Steps: 62 | Train Loss: 0.2872467 Vali Loss: 1.2303288 Test Loss: 0.5040105
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.4241538047790527
Epoch: 48, Steps: 62 | Train Loss: 0.2868365 Vali Loss: 1.2283444 Test Loss: 0.5034080
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.4459481239318848
Epoch: 49, Steps: 62 | Train Loss: 0.2863397 Vali Loss: 1.2312096 Test Loss: 0.5028421
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.4705171585083008
Epoch: 50, Steps: 62 | Train Loss: 0.2859635 Vali Loss: 1.2267586 Test Loss: 0.5022561
Validation loss decreased (1.227745 --> 1.226759).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.3135402202606201
Epoch: 51, Steps: 62 | Train Loss: 0.2856464 Vali Loss: 1.2214930 Test Loss: 0.5016816
Validation loss decreased (1.226759 --> 1.221493).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.2379302978515625
Epoch: 52, Steps: 62 | Train Loss: 0.2852318 Vali Loss: 1.2299910 Test Loss: 0.5012029
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.2895727157592773
Epoch: 53, Steps: 62 | Train Loss: 0.2849237 Vali Loss: 1.2262652 Test Loss: 0.5006757
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.3334391117095947
Epoch: 54, Steps: 62 | Train Loss: 0.2846849 Vali Loss: 1.2257266 Test Loss: 0.5001880
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.2183773517608643
Epoch: 55, Steps: 62 | Train Loss: 0.2844117 Vali Loss: 1.2209001 Test Loss: 0.4997658
Validation loss decreased (1.221493 --> 1.220900).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.2536299228668213
Epoch: 56, Steps: 62 | Train Loss: 0.2841090 Vali Loss: 1.2257731 Test Loss: 0.4993560
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.2658851146697998
Epoch: 57, Steps: 62 | Train Loss: 0.2839053 Vali Loss: 1.2204413 Test Loss: 0.4989190
Validation loss decreased (1.220900 --> 1.220441).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.1430320739746094
Epoch: 58, Steps: 62 | Train Loss: 0.2836238 Vali Loss: 1.2237544 Test Loss: 0.4985627
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.1826658248901367
Epoch: 59, Steps: 62 | Train Loss: 0.2833860 Vali Loss: 1.2169622 Test Loss: 0.4981624
Validation loss decreased (1.220441 --> 1.216962).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.3789126873016357
Epoch: 60, Steps: 62 | Train Loss: 0.2831640 Vali Loss: 1.2190936 Test Loss: 0.4978360
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.1913723945617676
Epoch: 61, Steps: 62 | Train Loss: 0.2829193 Vali Loss: 1.2200558 Test Loss: 0.4975147
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.2768001556396484
Epoch: 62, Steps: 62 | Train Loss: 0.2828091 Vali Loss: 1.2159237 Test Loss: 0.4972022
Validation loss decreased (1.216962 --> 1.215924).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.2381772994995117
Epoch: 63, Steps: 62 | Train Loss: 0.2824960 Vali Loss: 1.2198629 Test Loss: 0.4968889
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.317802906036377
Epoch: 64, Steps: 62 | Train Loss: 0.2823063 Vali Loss: 1.2212155 Test Loss: 0.4966206
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.1828784942626953
Epoch: 65, Steps: 62 | Train Loss: 0.2822007 Vali Loss: 1.2188150 Test Loss: 0.4963275
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.2952172756195068
Epoch: 66, Steps: 62 | Train Loss: 0.2820045 Vali Loss: 1.2202307 Test Loss: 0.4961166
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.3156957626342773
Epoch: 67, Steps: 62 | Train Loss: 0.2818734 Vali Loss: 1.2207600 Test Loss: 0.4958695
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.2776539325714111
Epoch: 68, Steps: 62 | Train Loss: 0.2817475 Vali Loss: 1.2162898 Test Loss: 0.4956333
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.308842420578003
Epoch: 69, Steps: 62 | Train Loss: 0.2816182 Vali Loss: 1.2159020 Test Loss: 0.4954082
Validation loss decreased (1.215924 --> 1.215902).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.2827248573303223
Epoch: 70, Steps: 62 | Train Loss: 0.2814349 Vali Loss: 1.2153342 Test Loss: 0.4952137
Validation loss decreased (1.215902 --> 1.215334).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.246356725692749
Epoch: 71, Steps: 62 | Train Loss: 0.2813086 Vali Loss: 1.2130020 Test Loss: 0.4950063
Validation loss decreased (1.215334 --> 1.213002).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.2373161315917969
Epoch: 72, Steps: 62 | Train Loss: 0.2812121 Vali Loss: 1.2173485 Test Loss: 0.4948283
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.3575456142425537
Epoch: 73, Steps: 62 | Train Loss: 0.2811430 Vali Loss: 1.2172674 Test Loss: 0.4946311
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.2267637252807617
Epoch: 74, Steps: 62 | Train Loss: 0.2809711 Vali Loss: 1.2084864 Test Loss: 0.4944725
Validation loss decreased (1.213002 --> 1.208486).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.1750950813293457
Epoch: 75, Steps: 62 | Train Loss: 0.2808455 Vali Loss: 1.2170560 Test Loss: 0.4943016
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.284304141998291
Epoch: 76, Steps: 62 | Train Loss: 0.2807869 Vali Loss: 1.2185487 Test Loss: 0.4941533
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.2523319721221924
Epoch: 77, Steps: 62 | Train Loss: 0.2806678 Vali Loss: 1.2152319 Test Loss: 0.4940158
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.3197174072265625
Epoch: 78, Steps: 62 | Train Loss: 0.2806432 Vali Loss: 1.2178103 Test Loss: 0.4938776
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.2563984394073486
Epoch: 79, Steps: 62 | Train Loss: 0.2804761 Vali Loss: 1.2180046 Test Loss: 0.4937441
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.1816456317901611
Epoch: 80, Steps: 62 | Train Loss: 0.2804673 Vali Loss: 1.2133995 Test Loss: 0.4936202
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.169978141784668
Epoch: 81, Steps: 62 | Train Loss: 0.2803787 Vali Loss: 1.2142069 Test Loss: 0.4935064
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.2606983184814453
Epoch: 82, Steps: 62 | Train Loss: 0.2803391 Vali Loss: 1.2141560 Test Loss: 0.4933865
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.228278636932373
Epoch: 83, Steps: 62 | Train Loss: 0.2801362 Vali Loss: 1.2137326 Test Loss: 0.4932765
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.3845264911651611
Epoch: 84, Steps: 62 | Train Loss: 0.2801333 Vali Loss: 1.2168289 Test Loss: 0.4931762
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.1798224449157715
Epoch: 85, Steps: 62 | Train Loss: 0.2800489 Vali Loss: 1.2145714 Test Loss: 0.4930807
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.241213083267212
Epoch: 86, Steps: 62 | Train Loss: 0.2800492 Vali Loss: 1.2124003 Test Loss: 0.4929797
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.2561204433441162
Epoch: 87, Steps: 62 | Train Loss: 0.2798989 Vali Loss: 1.2164400 Test Loss: 0.4929008
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.3178322315216064
Epoch: 88, Steps: 62 | Train Loss: 0.2799607 Vali Loss: 1.2099195 Test Loss: 0.4928146
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.1208364963531494
Epoch: 89, Steps: 62 | Train Loss: 0.2798673 Vali Loss: 1.2162203 Test Loss: 0.4927344
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.2285521030426025
Epoch: 90, Steps: 62 | Train Loss: 0.2798289 Vali Loss: 1.2122395 Test Loss: 0.4926644
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.2091951370239258
Epoch: 91, Steps: 62 | Train Loss: 0.2797850 Vali Loss: 1.2133528 Test Loss: 0.4925896
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.1788709163665771
Epoch: 92, Steps: 62 | Train Loss: 0.2797568 Vali Loss: 1.2113105 Test Loss: 0.4925129
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.2227420806884766
Epoch: 93, Steps: 62 | Train Loss: 0.2797985 Vali Loss: 1.2162873 Test Loss: 0.4924521
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.2555351257324219
Epoch: 94, Steps: 62 | Train Loss: 0.2796669 Vali Loss: 1.2140456 Test Loss: 0.4923936
EarlyStopping counter: 20 out of 20
Early stopping
train 7945
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=42, out_features=81, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3048192.0
params:  3483.0
Trainable parameters:  3483
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.2880523204803467
Epoch: 1, Steps: 62 | Train Loss: 0.4859302 Vali Loss: 1.1828159 Test Loss: 0.4714677
Validation loss decreased (inf --> 1.182816).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.2706656455993652
Epoch: 2, Steps: 62 | Train Loss: 0.4761296 Vali Loss: 1.1737221 Test Loss: 0.4605657
Validation loss decreased (1.182816 --> 1.173722).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.414170742034912
Epoch: 3, Steps: 62 | Train Loss: 0.4718084 Vali Loss: 1.1675677 Test Loss: 0.4555200
Validation loss decreased (1.173722 --> 1.167568).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.3684580326080322
Epoch: 4, Steps: 62 | Train Loss: 0.4695880 Vali Loss: 1.1663927 Test Loss: 0.4527210
Validation loss decreased (1.167568 --> 1.166393).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.303966999053955
Epoch: 5, Steps: 62 | Train Loss: 0.4687276 Vali Loss: 1.1623875 Test Loss: 0.4516309
Validation loss decreased (1.166393 --> 1.162387).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.3952155113220215
Epoch: 6, Steps: 62 | Train Loss: 0.4680834 Vali Loss: 1.1667489 Test Loss: 0.4508886
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.3898670673370361
Epoch: 7, Steps: 62 | Train Loss: 0.4676301 Vali Loss: 1.1663758 Test Loss: 0.4504823
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.3529915809631348
Epoch: 8, Steps: 62 | Train Loss: 0.4673073 Vali Loss: 1.1617240 Test Loss: 0.4503759
Validation loss decreased (1.162387 --> 1.161724).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.322164535522461
Epoch: 9, Steps: 62 | Train Loss: 0.4672852 Vali Loss: 1.1675649 Test Loss: 0.4502025
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.3665664196014404
Epoch: 10, Steps: 62 | Train Loss: 0.4670940 Vali Loss: 1.1641078 Test Loss: 0.4498833
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.1970558166503906
Epoch: 11, Steps: 62 | Train Loss: 0.4669742 Vali Loss: 1.1600503 Test Loss: 0.4501306
Validation loss decreased (1.161724 --> 1.160050).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.2152116298675537
Epoch: 12, Steps: 62 | Train Loss: 0.4669974 Vali Loss: 1.1597875 Test Loss: 0.4500426
Validation loss decreased (1.160050 --> 1.159788).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.287705898284912
Epoch: 13, Steps: 62 | Train Loss: 0.4668600 Vali Loss: 1.1633939 Test Loss: 0.4500334
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.24885892868042
Epoch: 14, Steps: 62 | Train Loss: 0.4668900 Vali Loss: 1.1615138 Test Loss: 0.4501167
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.2705607414245605
Epoch: 15, Steps: 62 | Train Loss: 0.4667667 Vali Loss: 1.1600668 Test Loss: 0.4499420
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.2134811878204346
Epoch: 16, Steps: 62 | Train Loss: 0.4667333 Vali Loss: 1.1657858 Test Loss: 0.4500086
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.2582855224609375
Epoch: 17, Steps: 62 | Train Loss: 0.4666101 Vali Loss: 1.1678832 Test Loss: 0.4500345
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.2491750717163086
Epoch: 18, Steps: 62 | Train Loss: 0.4664222 Vali Loss: 1.1663744 Test Loss: 0.4500181
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.3489456176757812
Epoch: 19, Steps: 62 | Train Loss: 0.4663539 Vali Loss: 1.1620941 Test Loss: 0.4499668
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.268848180770874
Epoch: 20, Steps: 62 | Train Loss: 0.4664000 Vali Loss: 1.1646190 Test Loss: 0.4500223
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.2585432529449463
Epoch: 21, Steps: 62 | Train Loss: 0.4663970 Vali Loss: 1.1647272 Test Loss: 0.4500311
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.1918251514434814
Epoch: 22, Steps: 62 | Train Loss: 0.4664078 Vali Loss: 1.1617168 Test Loss: 0.4498757
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.153947114944458
Epoch: 23, Steps: 62 | Train Loss: 0.4663760 Vali Loss: 1.1612259 Test Loss: 0.4500790
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.3089606761932373
Epoch: 24, Steps: 62 | Train Loss: 0.4663911 Vali Loss: 1.1631701 Test Loss: 0.4500965
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.1941821575164795
Epoch: 25, Steps: 62 | Train Loss: 0.4663061 Vali Loss: 1.1659409 Test Loss: 0.4500616
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.2294013500213623
Epoch: 26, Steps: 62 | Train Loss: 0.4663477 Vali Loss: 1.1676210 Test Loss: 0.4501043
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.2802865505218506
Epoch: 27, Steps: 62 | Train Loss: 0.4661688 Vali Loss: 1.1619385 Test Loss: 0.4501335
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.250239372253418
Epoch: 28, Steps: 62 | Train Loss: 0.4662117 Vali Loss: 1.1649574 Test Loss: 0.4501249
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.1626412868499756
Epoch: 29, Steps: 62 | Train Loss: 0.4661839 Vali Loss: 1.1616360 Test Loss: 0.4500900
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.2942097187042236
Epoch: 30, Steps: 62 | Train Loss: 0.4663454 Vali Loss: 1.1613978 Test Loss: 0.4501283
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.206376075744629
Epoch: 31, Steps: 62 | Train Loss: 0.4663482 Vali Loss: 1.1617862 Test Loss: 0.4501657
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.234722375869751
Epoch: 32, Steps: 62 | Train Loss: 0.4662226 Vali Loss: 1.1619326 Test Loss: 0.4501166
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_360_336_FITS_ETTh1_ftM_sl360_ll48_pl336_H2_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.44895198941230774, mae:0.44802525639533997, rse:0.6378991007804871, corr:[0.25241992 0.25735718 0.25816637 0.25616732 0.25317532 0.25073978
 0.24934469 0.2490473  0.24920315 0.24949321 0.2496776  0.24956203
 0.24932885 0.24914499 0.24903333 0.24902566 0.24900532 0.24893986
 0.24888366 0.24881358 0.24886827 0.24909267 0.24933048 0.24947278
 0.2494219  0.24912174 0.24863274 0.24805398 0.24743007 0.24684916
 0.24636702 0.24599954 0.2457665  0.24567463 0.24570936 0.24585631
 0.24608442 0.246393   0.24673766 0.24695806 0.24704437 0.24700345
 0.24695718 0.24698618 0.24717917 0.24748673 0.24781415 0.24786952
 0.24740556 0.24647154 0.24509597 0.24378708 0.24279799 0.2420906
 0.2417984  0.24179272 0.2418051  0.24170122 0.24143553 0.24119204
 0.24095142 0.24087097 0.24091943 0.24108277 0.24127254 0.24146974
 0.24167699 0.24167879 0.24163975 0.24165852 0.24166471 0.24149434
 0.24109419 0.2405066  0.23985966 0.23931111 0.23887923 0.2385209
 0.23830149 0.23813398 0.23795383 0.23771432 0.23741293 0.23715702
 0.23705779 0.23710294 0.23714776 0.23706648 0.23684114 0.23655918
 0.23624676 0.23598573 0.23585635 0.236121   0.23673742 0.23747584
 0.2382273  0.2387561  0.23902941 0.23903337 0.23888901 0.23866105
 0.23842077 0.2382352  0.23803009 0.23783472 0.23767482 0.23760507
 0.237651   0.23780364 0.23799142 0.23818514 0.23823652 0.23819189
 0.23814134 0.23803475 0.23790877 0.23781246 0.23771212 0.2374989
 0.23712079 0.23651001 0.23577894 0.23507245 0.23461746 0.2343399
 0.23421521 0.23417994 0.23403212 0.23375623 0.23350173 0.2333987
 0.23341794 0.23351958 0.23371598 0.23385136 0.2338792  0.23381087
 0.23368226 0.23351207 0.23338456 0.23339853 0.23351651 0.23352386
 0.23337951 0.23291717 0.23223191 0.23148036 0.23098312 0.2307008
 0.23063552 0.23076656 0.23090243 0.23097423 0.23092517 0.23082356
 0.23068003 0.23057254 0.2305202  0.23047395 0.23024982 0.23006211
 0.22992502 0.22985403 0.2299283  0.2302149  0.23069093 0.2311681
 0.23156871 0.2317261  0.23152223 0.23105747 0.2305829  0.23031835
 0.23032287 0.23052524 0.23071307 0.23087923 0.23097046 0.23097181
 0.23090254 0.23082492 0.23081453 0.2309023  0.23107557 0.23134626
 0.23160192 0.23171693 0.23172668 0.23167953 0.23150869 0.23118602
 0.23071074 0.23014866 0.22946109 0.22876249 0.22815324 0.2276521
 0.22726046 0.227105   0.22703256 0.22695637 0.22686121 0.2268305
 0.22685972 0.2269276  0.22703879 0.22711782 0.227156   0.22714213
 0.2270921  0.22689067 0.22664168 0.22647029 0.22636646 0.22635613
 0.22638445 0.22622149 0.2260036  0.2257199  0.22556287 0.22554724
 0.22557715 0.22559418 0.22555883 0.22539099 0.22507487 0.22479476
 0.2245791  0.22434951 0.22421756 0.22412038 0.2239308  0.22377405
 0.2237833  0.22391516 0.22420546 0.22460683 0.22505483 0.22525989
 0.22529629 0.22504902 0.2245515  0.22404863 0.22373638 0.22371309
 0.22393222 0.22427991 0.22456844 0.22455728 0.22429112 0.22395845
 0.22370721 0.22359927 0.22379123 0.22409733 0.2243818  0.2245828
 0.22467275 0.22450423 0.22426145 0.22414714 0.22420272 0.22429366
 0.22428843 0.22404379 0.22346364 0.2227064  0.22191145 0.221301
 0.22109735 0.22126704 0.22159468 0.22179015 0.22173966 0.22149266
 0.22117421 0.22088543 0.22068156 0.22062697 0.22070192 0.2208464
 0.2210066  0.22096956 0.22088483 0.22095053 0.22137462 0.22194192
 0.22263244 0.22323298 0.22352356 0.22335537 0.22293942 0.22250451
 0.22226834 0.22229196 0.22249585 0.2227744  0.22290172 0.22286637
 0.22268686 0.22238202 0.22217411 0.22209905 0.22215798 0.2222825
 0.22252727 0.22267862 0.22278047 0.22280681 0.22283247 0.22279052
 0.22284871 0.22299698 0.22281888 0.2224267  0.22197998 0.2214242
 0.22082506 0.22026144 0.21965636 0.21920374 0.21890533 0.21884227
 0.2190321  0.2192094  0.21911146 0.2188603  0.21841513 0.21815027
 0.21841528 0.21916737 0.22023481 0.22097135 0.22002302 0.21538539]
