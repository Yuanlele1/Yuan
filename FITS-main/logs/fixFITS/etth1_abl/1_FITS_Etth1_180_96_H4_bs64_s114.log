Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=42, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_180_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_180_96_FITS_ETTh1_ftM_sl180_ll48_pl96_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8365
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=42, out_features=64, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2408448.0
params:  2752.0
Trainable parameters:  2752
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.8485543727874756
Epoch: 1, Steps: 65 | Train Loss: 0.5710378 Vali Loss: 0.9878942 Test Loss: 0.5456993
Validation loss decreased (inf --> 0.987894).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.7209932804107666
Epoch: 2, Steps: 65 | Train Loss: 0.4313233 Vali Loss: 0.8428633 Test Loss: 0.4431157
Validation loss decreased (0.987894 --> 0.842863).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.0985615253448486
Epoch: 3, Steps: 65 | Train Loss: 0.3895890 Vali Loss: 0.7899588 Test Loss: 0.4109409
Validation loss decreased (0.842863 --> 0.789959).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.9238615036010742
Epoch: 4, Steps: 65 | Train Loss: 0.3734618 Vali Loss: 0.7657552 Test Loss: 0.3971496
Validation loss decreased (0.789959 --> 0.765755).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.7194221019744873
Epoch: 5, Steps: 65 | Train Loss: 0.3659636 Vali Loss: 0.7509338 Test Loss: 0.3900297
Validation loss decreased (0.765755 --> 0.750934).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.7972054481506348
Epoch: 6, Steps: 65 | Train Loss: 0.3613613 Vali Loss: 0.7432473 Test Loss: 0.3865757
Validation loss decreased (0.750934 --> 0.743247).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.665318250656128
Epoch: 7, Steps: 65 | Train Loss: 0.3582538 Vali Loss: 0.7386537 Test Loss: 0.3844250
Validation loss decreased (0.743247 --> 0.738654).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.8513658046722412
Epoch: 8, Steps: 65 | Train Loss: 0.3563753 Vali Loss: 0.7311133 Test Loss: 0.3831384
Validation loss decreased (0.738654 --> 0.731113).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.3602488040924072
Epoch: 9, Steps: 65 | Train Loss: 0.3550726 Vali Loss: 0.7322115 Test Loss: 0.3827418
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.2730422019958496
Epoch: 10, Steps: 65 | Train Loss: 0.3544920 Vali Loss: 0.7238397 Test Loss: 0.3825621
Validation loss decreased (0.731113 --> 0.723840).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.87727952003479
Epoch: 11, Steps: 65 | Train Loss: 0.3531738 Vali Loss: 0.7246824 Test Loss: 0.3825308
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.8016092777252197
Epoch: 12, Steps: 65 | Train Loss: 0.3528642 Vali Loss: 0.7253255 Test Loss: 0.3825628
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.9198501110076904
Epoch: 13, Steps: 65 | Train Loss: 0.3523471 Vali Loss: 0.7205350 Test Loss: 0.3827778
Validation loss decreased (0.723840 --> 0.720535).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.066511869430542
Epoch: 14, Steps: 65 | Train Loss: 0.3516256 Vali Loss: 0.7189419 Test Loss: 0.3826967
Validation loss decreased (0.720535 --> 0.718942).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.1885087490081787
Epoch: 15, Steps: 65 | Train Loss: 0.3517127 Vali Loss: 0.7168956 Test Loss: 0.3829222
Validation loss decreased (0.718942 --> 0.716896).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.7363994121551514
Epoch: 16, Steps: 65 | Train Loss: 0.3518096 Vali Loss: 0.7169345 Test Loss: 0.3830401
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.064432382583618
Epoch: 17, Steps: 65 | Train Loss: 0.3516796 Vali Loss: 0.7173777 Test Loss: 0.3831699
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.747779369354248
Epoch: 18, Steps: 65 | Train Loss: 0.3513809 Vali Loss: 0.7205052 Test Loss: 0.3833221
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.989908218383789
Epoch: 19, Steps: 65 | Train Loss: 0.3505308 Vali Loss: 0.7130750 Test Loss: 0.3831982
Validation loss decreased (0.716896 --> 0.713075).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.7047760486602783
Epoch: 20, Steps: 65 | Train Loss: 0.3510070 Vali Loss: 0.7146428 Test Loss: 0.3833451
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.309098243713379
Epoch: 21, Steps: 65 | Train Loss: 0.3511406 Vali Loss: 0.7108814 Test Loss: 0.3834912
Validation loss decreased (0.713075 --> 0.710881).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.5054810047149658
Epoch: 22, Steps: 65 | Train Loss: 0.3505924 Vali Loss: 0.7184755 Test Loss: 0.3835176
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.6133124828338623
Epoch: 23, Steps: 65 | Train Loss: 0.3509160 Vali Loss: 0.7152940 Test Loss: 0.3836333
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.6355764865875244
Epoch: 24, Steps: 65 | Train Loss: 0.3506306 Vali Loss: 0.7129498 Test Loss: 0.3836272
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.5350267887115479
Epoch: 25, Steps: 65 | Train Loss: 0.3504309 Vali Loss: 0.7160296 Test Loss: 0.3837390
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.0989012718200684
Epoch: 26, Steps: 65 | Train Loss: 0.3501661 Vali Loss: 0.7143856 Test Loss: 0.3837292
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.3176045417785645
Epoch: 27, Steps: 65 | Train Loss: 0.3503649 Vali Loss: 0.7141467 Test Loss: 0.3837748
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.2942538261413574
Epoch: 28, Steps: 65 | Train Loss: 0.3502964 Vali Loss: 0.7106599 Test Loss: 0.3838022
Validation loss decreased (0.710881 --> 0.710660).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.7096984386444092
Epoch: 29, Steps: 65 | Train Loss: 0.3503243 Vali Loss: 0.7111657 Test Loss: 0.3838219
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.6023783683776855
Epoch: 30, Steps: 65 | Train Loss: 0.3499977 Vali Loss: 0.7160516 Test Loss: 0.3839149
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.5502140522003174
Epoch: 31, Steps: 65 | Train Loss: 0.3503700 Vali Loss: 0.7133139 Test Loss: 0.3839276
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.6927878856658936
Epoch: 32, Steps: 65 | Train Loss: 0.3502636 Vali Loss: 0.7130224 Test Loss: 0.3838840
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.1771600246429443
Epoch: 33, Steps: 65 | Train Loss: 0.3498898 Vali Loss: 0.7095491 Test Loss: 0.3838939
Validation loss decreased (0.710660 --> 0.709549).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.7095580101013184
Epoch: 34, Steps: 65 | Train Loss: 0.3499014 Vali Loss: 0.7105817 Test Loss: 0.3839212
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.8655948638916016
Epoch: 35, Steps: 65 | Train Loss: 0.3499896 Vali Loss: 0.7098852 Test Loss: 0.3839558
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.841372013092041
Epoch: 36, Steps: 65 | Train Loss: 0.3501450 Vali Loss: 0.7166841 Test Loss: 0.3839675
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.7497148513793945
Epoch: 37, Steps: 65 | Train Loss: 0.3499428 Vali Loss: 0.7097111 Test Loss: 0.3839688
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.1129839420318604
Epoch: 38, Steps: 65 | Train Loss: 0.3497117 Vali Loss: 0.7144271 Test Loss: 0.3839851
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.4464223384857178
Epoch: 39, Steps: 65 | Train Loss: 0.3500566 Vali Loss: 0.7103304 Test Loss: 0.3840046
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.510558843612671
Epoch: 40, Steps: 65 | Train Loss: 0.3497645 Vali Loss: 0.7077197 Test Loss: 0.3840683
Validation loss decreased (0.709549 --> 0.707720).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.48721981048584
Epoch: 41, Steps: 65 | Train Loss: 0.3496500 Vali Loss: 0.7069303 Test Loss: 0.3840103
Validation loss decreased (0.707720 --> 0.706930).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.8464336395263672
Epoch: 42, Steps: 65 | Train Loss: 0.3497932 Vali Loss: 0.7089431 Test Loss: 0.3840472
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.486381769180298
Epoch: 43, Steps: 65 | Train Loss: 0.3499283 Vali Loss: 0.7113248 Test Loss: 0.3840348
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.5019397735595703
Epoch: 44, Steps: 65 | Train Loss: 0.3500042 Vali Loss: 0.7062181 Test Loss: 0.3840203
Validation loss decreased (0.706930 --> 0.706218).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 3.062808036804199
Epoch: 45, Steps: 65 | Train Loss: 0.3500109 Vali Loss: 0.7093705 Test Loss: 0.3840442
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.4241843223571777
Epoch: 46, Steps: 65 | Train Loss: 0.3496718 Vali Loss: 0.7114608 Test Loss: 0.3840446
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.8230316638946533
Epoch: 47, Steps: 65 | Train Loss: 0.3499110 Vali Loss: 0.7085557 Test Loss: 0.3840825
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.8351857662200928
Epoch: 48, Steps: 65 | Train Loss: 0.3496944 Vali Loss: 0.7036878 Test Loss: 0.3840417
Validation loss decreased (0.706218 --> 0.703688).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 3.1068968772888184
Epoch: 49, Steps: 65 | Train Loss: 0.3497196 Vali Loss: 0.7076532 Test Loss: 0.3840722
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.910665273666382
Epoch: 50, Steps: 65 | Train Loss: 0.3498721 Vali Loss: 0.7126331 Test Loss: 0.3840539
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.4885520935058594
Epoch: 51, Steps: 65 | Train Loss: 0.3501209 Vali Loss: 0.7083258 Test Loss: 0.3840730
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.375196695327759
Epoch: 52, Steps: 65 | Train Loss: 0.3497441 Vali Loss: 0.7095599 Test Loss: 0.3840518
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.680568218231201
Epoch: 53, Steps: 65 | Train Loss: 0.3498463 Vali Loss: 0.7111970 Test Loss: 0.3840443
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.6816627979278564
Epoch: 54, Steps: 65 | Train Loss: 0.3495923 Vali Loss: 0.7106514 Test Loss: 0.3840935
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.910940408706665
Epoch: 55, Steps: 65 | Train Loss: 0.3498221 Vali Loss: 0.7114677 Test Loss: 0.3840678
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.923753261566162
Epoch: 56, Steps: 65 | Train Loss: 0.3499625 Vali Loss: 0.7089455 Test Loss: 0.3840658
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.3994252681732178
Epoch: 57, Steps: 65 | Train Loss: 0.3495919 Vali Loss: 0.7099843 Test Loss: 0.3840710
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.891737461090088
Epoch: 58, Steps: 65 | Train Loss: 0.3497192 Vali Loss: 0.7083861 Test Loss: 0.3840902
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.7782914638519287
Epoch: 59, Steps: 65 | Train Loss: 0.3499165 Vali Loss: 0.7100260 Test Loss: 0.3840835
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.9701545238494873
Epoch: 60, Steps: 65 | Train Loss: 0.3495799 Vali Loss: 0.7075894 Test Loss: 0.3841035
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.7997181415557861
Epoch: 61, Steps: 65 | Train Loss: 0.3494832 Vali Loss: 0.7046906 Test Loss: 0.3840891
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.6944923400878906
Epoch: 62, Steps: 65 | Train Loss: 0.3496821 Vali Loss: 0.7093909 Test Loss: 0.3840964
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.5867016315460205
Epoch: 63, Steps: 65 | Train Loss: 0.3499499 Vali Loss: 0.7090331 Test Loss: 0.3840860
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.586674213409424
Epoch: 64, Steps: 65 | Train Loss: 0.3497954 Vali Loss: 0.7103258 Test Loss: 0.3841255
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.9061594009399414
Epoch: 65, Steps: 65 | Train Loss: 0.3498272 Vali Loss: 0.7085873 Test Loss: 0.3841110
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.380096197128296
Epoch: 66, Steps: 65 | Train Loss: 0.3492446 Vali Loss: 0.7054873 Test Loss: 0.3841172
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.789700746536255
Epoch: 67, Steps: 65 | Train Loss: 0.3494200 Vali Loss: 0.7097681 Test Loss: 0.3841283
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.1276535987854004
Epoch: 68, Steps: 65 | Train Loss: 0.3498432 Vali Loss: 0.7082288 Test Loss: 0.3841124
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_180_96_FITS_ETTh1_ftM_sl180_ll48_pl96_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.3833681643009186, mae:0.39749443531036377, rse:0.5881198644638062, corr:[0.271006   0.27672052 0.27663726 0.27543184 0.27407977 0.27217245
 0.270582   0.27035707 0.27090633 0.27095768 0.27014998 0.26979792
 0.2701783  0.26978087 0.26919025 0.26924956 0.26964787 0.26963854
 0.26933014 0.26920268 0.26929438 0.26943275 0.26937056 0.2688907
 0.2680555  0.26753953 0.26697353 0.2664314  0.26600668 0.2658411
 0.2655482  0.2649105  0.26443988 0.264551   0.26481286 0.26494136
 0.2649311  0.26486313 0.2649842  0.2651889  0.26540452 0.265636
 0.26571262 0.26564372 0.26583493 0.2662999  0.26673943 0.2663895
 0.26499248 0.26374462 0.2624288  0.26114693 0.25992686 0.25878397
 0.25808218 0.25783885 0.25771973 0.25774765 0.25760296 0.2581731
 0.25892064 0.25883198 0.25845698 0.2582162  0.25829926 0.25857878
 0.2587821  0.25856522 0.25819647 0.25810614 0.25831562 0.2578001
 0.2563891  0.2552647  0.2542959  0.25366485 0.2533736  0.25298983
 0.25253317 0.25211948 0.2519768  0.2521404  0.2517616  0.2514901
 0.25187054 0.2520724  0.2522085  0.25196108 0.25127745 0.25090674
 0.25101894 0.25072056 0.24958782 0.24853306 0.24984497 0.25188312]
