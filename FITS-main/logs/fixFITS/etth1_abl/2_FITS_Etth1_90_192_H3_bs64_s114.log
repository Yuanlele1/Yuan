Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=22, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_90_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_90_192_FITS_ETTh1_ftM_sl90_ll48_pl192_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8359
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=22, out_features=68, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1340416.0
params:  1564.0
Trainable parameters:  1564
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.3040976524353027
Epoch: 1, Steps: 65 | Train Loss: 0.8511645 Vali Loss: 1.8731368 Test Loss: 1.1268913
Validation loss decreased (inf --> 1.873137).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.407249927520752
Epoch: 2, Steps: 65 | Train Loss: 0.6906172 Vali Loss: 1.6472747 Test Loss: 0.9341273
Validation loss decreased (1.873137 --> 1.647275).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.582040786743164
Epoch: 3, Steps: 65 | Train Loss: 0.5899635 Vali Loss: 1.5060005 Test Loss: 0.8145618
Validation loss decreased (1.647275 --> 1.506001).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.2480638027191162
Epoch: 4, Steps: 65 | Train Loss: 0.5252560 Vali Loss: 1.4108881 Test Loss: 0.7345425
Validation loss decreased (1.506001 --> 1.410888).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.250394344329834
Epoch: 5, Steps: 65 | Train Loss: 0.4809054 Vali Loss: 1.3427718 Test Loss: 0.6787029
Validation loss decreased (1.410888 --> 1.342772).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.2560217380523682
Epoch: 6, Steps: 65 | Train Loss: 0.4493457 Vali Loss: 1.2919527 Test Loss: 0.6383386
Validation loss decreased (1.342772 --> 1.291953).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.2535250186920166
Epoch: 7, Steps: 65 | Train Loss: 0.4258640 Vali Loss: 1.2542003 Test Loss: 0.6075987
Validation loss decreased (1.291953 --> 1.254200).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.202035665512085
Epoch: 8, Steps: 65 | Train Loss: 0.4084289 Vali Loss: 1.2227396 Test Loss: 0.5838138
Validation loss decreased (1.254200 --> 1.222740).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.2471563816070557
Epoch: 9, Steps: 65 | Train Loss: 0.3947263 Vali Loss: 1.1996737 Test Loss: 0.5654159
Validation loss decreased (1.222740 --> 1.199674).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.3368165493011475
Epoch: 10, Steps: 65 | Train Loss: 0.3838884 Vali Loss: 1.1794138 Test Loss: 0.5503030
Validation loss decreased (1.199674 --> 1.179414).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.1981453895568848
Epoch: 11, Steps: 65 | Train Loss: 0.3752073 Vali Loss: 1.1630743 Test Loss: 0.5380002
Validation loss decreased (1.179414 --> 1.163074).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.1322641372680664
Epoch: 12, Steps: 65 | Train Loss: 0.3677733 Vali Loss: 1.1481260 Test Loss: 0.5275743
Validation loss decreased (1.163074 --> 1.148126).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.3277332782745361
Epoch: 13, Steps: 65 | Train Loss: 0.3619280 Vali Loss: 1.1360677 Test Loss: 0.5191475
Validation loss decreased (1.148126 --> 1.136068).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.3259813785552979
Epoch: 14, Steps: 65 | Train Loss: 0.3570182 Vali Loss: 1.1263126 Test Loss: 0.5121499
Validation loss decreased (1.136068 --> 1.126313).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.2524819374084473
Epoch: 15, Steps: 65 | Train Loss: 0.3526881 Vali Loss: 1.1175208 Test Loss: 0.5060278
Validation loss decreased (1.126313 --> 1.117521).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.2711217403411865
Epoch: 16, Steps: 65 | Train Loss: 0.3489597 Vali Loss: 1.1096370 Test Loss: 0.5007994
Validation loss decreased (1.117521 --> 1.109637).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.2840423583984375
Epoch: 17, Steps: 65 | Train Loss: 0.3457573 Vali Loss: 1.1021414 Test Loss: 0.4962229
Validation loss decreased (1.109637 --> 1.102141).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.2221894264221191
Epoch: 18, Steps: 65 | Train Loss: 0.3428881 Vali Loss: 1.0967687 Test Loss: 0.4922924
Validation loss decreased (1.102141 --> 1.096769).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.2528128623962402
Epoch: 19, Steps: 65 | Train Loss: 0.3402374 Vali Loss: 1.0909655 Test Loss: 0.4887860
Validation loss decreased (1.096769 --> 1.090966).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.2542693614959717
Epoch: 20, Steps: 65 | Train Loss: 0.3383219 Vali Loss: 1.0866345 Test Loss: 0.4857377
Validation loss decreased (1.090966 --> 1.086635).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.2297616004943848
Epoch: 21, Steps: 65 | Train Loss: 0.3362776 Vali Loss: 1.0812668 Test Loss: 0.4830553
Validation loss decreased (1.086635 --> 1.081267).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.1953396797180176
Epoch: 22, Steps: 65 | Train Loss: 0.3344343 Vali Loss: 1.0782658 Test Loss: 0.4807302
Validation loss decreased (1.081267 --> 1.078266).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.248450756072998
Epoch: 23, Steps: 65 | Train Loss: 0.3327604 Vali Loss: 1.0747675 Test Loss: 0.4785603
Validation loss decreased (1.078266 --> 1.074767).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.513120412826538
Epoch: 24, Steps: 65 | Train Loss: 0.3314486 Vali Loss: 1.0709358 Test Loss: 0.4766153
Validation loss decreased (1.074767 --> 1.070936).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 4.5267698764801025
Epoch: 25, Steps: 65 | Train Loss: 0.3301956 Vali Loss: 1.0681136 Test Loss: 0.4749290
Validation loss decreased (1.070936 --> 1.068114).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.2232320308685303
Epoch: 26, Steps: 65 | Train Loss: 0.3289229 Vali Loss: 1.0662915 Test Loss: 0.4734198
Validation loss decreased (1.068114 --> 1.066291).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.2118480205535889
Epoch: 27, Steps: 65 | Train Loss: 0.3277633 Vali Loss: 1.0641111 Test Loss: 0.4719980
Validation loss decreased (1.066291 --> 1.064111).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.2821719646453857
Epoch: 28, Steps: 65 | Train Loss: 0.3267807 Vali Loss: 1.0616972 Test Loss: 0.4707222
Validation loss decreased (1.064111 --> 1.061697).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.2442004680633545
Epoch: 29, Steps: 65 | Train Loss: 0.3259507 Vali Loss: 1.0599231 Test Loss: 0.4695604
Validation loss decreased (1.061697 --> 1.059923).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.294992446899414
Epoch: 30, Steps: 65 | Train Loss: 0.3247878 Vali Loss: 1.0581679 Test Loss: 0.4685197
Validation loss decreased (1.059923 --> 1.058168).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.2248647212982178
Epoch: 31, Steps: 65 | Train Loss: 0.3241984 Vali Loss: 1.0561705 Test Loss: 0.4675227
Validation loss decreased (1.058168 --> 1.056170).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.1491434574127197
Epoch: 32, Steps: 65 | Train Loss: 0.3235865 Vali Loss: 1.0545483 Test Loss: 0.4666252
Validation loss decreased (1.056170 --> 1.054548).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.7679696083068848
Epoch: 33, Steps: 65 | Train Loss: 0.3228582 Vali Loss: 1.0525076 Test Loss: 0.4658482
Validation loss decreased (1.054548 --> 1.052508).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.815656900405884
Epoch: 34, Steps: 65 | Train Loss: 0.3222614 Vali Loss: 1.0517855 Test Loss: 0.4650376
Validation loss decreased (1.052508 --> 1.051785).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.2049710750579834
Epoch: 35, Steps: 65 | Train Loss: 0.3215032 Vali Loss: 1.0509509 Test Loss: 0.4643638
Validation loss decreased (1.051785 --> 1.050951).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.2475755214691162
Epoch: 36, Steps: 65 | Train Loss: 0.3209007 Vali Loss: 1.0495183 Test Loss: 0.4637530
Validation loss decreased (1.050951 --> 1.049518).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.2708730697631836
Epoch: 37, Steps: 65 | Train Loss: 0.3206553 Vali Loss: 1.0483669 Test Loss: 0.4631057
Validation loss decreased (1.049518 --> 1.048367).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.2384331226348877
Epoch: 38, Steps: 65 | Train Loss: 0.3199910 Vali Loss: 1.0476443 Test Loss: 0.4625426
Validation loss decreased (1.048367 --> 1.047644).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.2099764347076416
Epoch: 39, Steps: 65 | Train Loss: 0.3195109 Vali Loss: 1.0467840 Test Loss: 0.4620334
Validation loss decreased (1.047644 --> 1.046784).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.208813190460205
Epoch: 40, Steps: 65 | Train Loss: 0.3192396 Vali Loss: 1.0457017 Test Loss: 0.4615646
Validation loss decreased (1.046784 --> 1.045702).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.2215344905853271
Epoch: 41, Steps: 65 | Train Loss: 0.3188127 Vali Loss: 1.0450202 Test Loss: 0.4610986
Validation loss decreased (1.045702 --> 1.045020).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.3048250675201416
Epoch: 42, Steps: 65 | Train Loss: 0.3184367 Vali Loss: 1.0440396 Test Loss: 0.4606721
Validation loss decreased (1.045020 --> 1.044040).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.2252275943756104
Epoch: 43, Steps: 65 | Train Loss: 0.3182681 Vali Loss: 1.0432022 Test Loss: 0.4602748
Validation loss decreased (1.044040 --> 1.043202).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.2135510444641113
Epoch: 44, Steps: 65 | Train Loss: 0.3178514 Vali Loss: 1.0428644 Test Loss: 0.4599074
Validation loss decreased (1.043202 --> 1.042864).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.3448657989501953
Epoch: 45, Steps: 65 | Train Loss: 0.3174388 Vali Loss: 1.0422910 Test Loss: 0.4595777
Validation loss decreased (1.042864 --> 1.042291).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.2158610820770264
Epoch: 46, Steps: 65 | Train Loss: 0.3170269 Vali Loss: 1.0414380 Test Loss: 0.4592218
Validation loss decreased (1.042291 --> 1.041438).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.2393803596496582
Epoch: 47, Steps: 65 | Train Loss: 0.3170552 Vali Loss: 1.0409292 Test Loss: 0.4589110
Validation loss decreased (1.041438 --> 1.040929).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.312692642211914
Epoch: 48, Steps: 65 | Train Loss: 0.3165910 Vali Loss: 1.0404432 Test Loss: 0.4586360
Validation loss decreased (1.040929 --> 1.040443).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.1466209888458252
Epoch: 49, Steps: 65 | Train Loss: 0.3164890 Vali Loss: 1.0400239 Test Loss: 0.4583529
Validation loss decreased (1.040443 --> 1.040024).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.1663899421691895
Epoch: 50, Steps: 65 | Train Loss: 0.3160512 Vali Loss: 1.0395768 Test Loss: 0.4580917
Validation loss decreased (1.040024 --> 1.039577).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.1989765167236328
Epoch: 51, Steps: 65 | Train Loss: 0.3159554 Vali Loss: 1.0389932 Test Loss: 0.4578539
Validation loss decreased (1.039577 --> 1.038993).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.1869165897369385
Epoch: 52, Steps: 65 | Train Loss: 0.3157204 Vali Loss: 1.0382506 Test Loss: 0.4576479
Validation loss decreased (1.038993 --> 1.038251).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.2096474170684814
Epoch: 53, Steps: 65 | Train Loss: 0.3153060 Vali Loss: 1.0378499 Test Loss: 0.4574187
Validation loss decreased (1.038251 --> 1.037850).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.2623436450958252
Epoch: 54, Steps: 65 | Train Loss: 0.3153553 Vali Loss: 1.0378435 Test Loss: 0.4572228
Validation loss decreased (1.037850 --> 1.037843).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.2575857639312744
Epoch: 55, Steps: 65 | Train Loss: 0.3152970 Vali Loss: 1.0371736 Test Loss: 0.4570150
Validation loss decreased (1.037843 --> 1.037174).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.2100400924682617
Epoch: 56, Steps: 65 | Train Loss: 0.3150605 Vali Loss: 1.0370131 Test Loss: 0.4568226
Validation loss decreased (1.037174 --> 1.037013).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.2477736473083496
Epoch: 57, Steps: 65 | Train Loss: 0.3146645 Vali Loss: 1.0368301 Test Loss: 0.4566581
Validation loss decreased (1.037013 --> 1.036830).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.1830878257751465
Epoch: 58, Steps: 65 | Train Loss: 0.3146515 Vali Loss: 1.0365657 Test Loss: 0.4564992
Validation loss decreased (1.036830 --> 1.036566).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.173579454421997
Epoch: 59, Steps: 65 | Train Loss: 0.3145103 Vali Loss: 1.0363058 Test Loss: 0.4563445
Validation loss decreased (1.036566 --> 1.036306).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.2486481666564941
Epoch: 60, Steps: 65 | Train Loss: 0.3143436 Vali Loss: 1.0359552 Test Loss: 0.4561879
Validation loss decreased (1.036306 --> 1.035955).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.2405359745025635
Epoch: 61, Steps: 65 | Train Loss: 0.3142453 Vali Loss: 1.0356028 Test Loss: 0.4560566
Validation loss decreased (1.035955 --> 1.035603).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.2422914505004883
Epoch: 62, Steps: 65 | Train Loss: 0.3140275 Vali Loss: 1.0355437 Test Loss: 0.4559201
Validation loss decreased (1.035603 --> 1.035544).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.1599078178405762
Epoch: 63, Steps: 65 | Train Loss: 0.3140624 Vali Loss: 1.0352719 Test Loss: 0.4558107
Validation loss decreased (1.035544 --> 1.035272).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.1978302001953125
Epoch: 64, Steps: 65 | Train Loss: 0.3135128 Vali Loss: 1.0348492 Test Loss: 0.4556816
Validation loss decreased (1.035272 --> 1.034849).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.2770252227783203
Epoch: 65, Steps: 65 | Train Loss: 0.3135474 Vali Loss: 1.0348966 Test Loss: 0.4555539
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.3160955905914307
Epoch: 66, Steps: 65 | Train Loss: 0.3137411 Vali Loss: 1.0345736 Test Loss: 0.4554599
Validation loss decreased (1.034849 --> 1.034574).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.2989223003387451
Epoch: 67, Steps: 65 | Train Loss: 0.3137090 Vali Loss: 1.0334290 Test Loss: 0.4553494
Validation loss decreased (1.034574 --> 1.033429).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.290623664855957
Epoch: 68, Steps: 65 | Train Loss: 0.3133909 Vali Loss: 1.0342232 Test Loss: 0.4552595
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.3973281383514404
Epoch: 69, Steps: 65 | Train Loss: 0.3132080 Vali Loss: 1.0340145 Test Loss: 0.4551574
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.190622329711914
Epoch: 70, Steps: 65 | Train Loss: 0.3134056 Vali Loss: 1.0338674 Test Loss: 0.4550788
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.2702572345733643
Epoch: 71, Steps: 65 | Train Loss: 0.3131865 Vali Loss: 1.0338266 Test Loss: 0.4549951
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.1632380485534668
Epoch: 72, Steps: 65 | Train Loss: 0.3133584 Vali Loss: 1.0336779 Test Loss: 0.4549097
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.349379301071167
Epoch: 73, Steps: 65 | Train Loss: 0.3131338 Vali Loss: 1.0331885 Test Loss: 0.4548344
Validation loss decreased (1.033429 --> 1.033188).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.1981208324432373
Epoch: 74, Steps: 65 | Train Loss: 0.3128914 Vali Loss: 1.0331831 Test Loss: 0.4547643
Validation loss decreased (1.033188 --> 1.033183).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.2882475852966309
Epoch: 75, Steps: 65 | Train Loss: 0.3131102 Vali Loss: 1.0333287 Test Loss: 0.4546942
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.2615256309509277
Epoch: 76, Steps: 65 | Train Loss: 0.3130212 Vali Loss: 1.0322977 Test Loss: 0.4546373
Validation loss decreased (1.033183 --> 1.032298).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.1868624687194824
Epoch: 77, Steps: 65 | Train Loss: 0.3128332 Vali Loss: 1.0328165 Test Loss: 0.4545757
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.293576955795288
Epoch: 78, Steps: 65 | Train Loss: 0.3129342 Vali Loss: 1.0329517 Test Loss: 0.4545090
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.1703176498413086
Epoch: 79, Steps: 65 | Train Loss: 0.3126581 Vali Loss: 1.0328524 Test Loss: 0.4544564
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.1648588180541992
Epoch: 80, Steps: 65 | Train Loss: 0.3126213 Vali Loss: 1.0323102 Test Loss: 0.4544039
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.299466848373413
Epoch: 81, Steps: 65 | Train Loss: 0.3126221 Vali Loss: 1.0325209 Test Loss: 0.4543500
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.205089807510376
Epoch: 82, Steps: 65 | Train Loss: 0.3124808 Vali Loss: 1.0326066 Test Loss: 0.4543047
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.3408410549163818
Epoch: 83, Steps: 65 | Train Loss: 0.3125646 Vali Loss: 1.0324304 Test Loss: 0.4542561
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.2818989753723145
Epoch: 84, Steps: 65 | Train Loss: 0.3127299 Vali Loss: 1.0323226 Test Loss: 0.4542114
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.1966524124145508
Epoch: 85, Steps: 65 | Train Loss: 0.3125492 Vali Loss: 1.0319692 Test Loss: 0.4541733
Validation loss decreased (1.032298 --> 1.031969).  Saving model ...
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.2984247207641602
Epoch: 86, Steps: 65 | Train Loss: 0.3124457 Vali Loss: 1.0313327 Test Loss: 0.4541346
Validation loss decreased (1.031969 --> 1.031333).  Saving model ...
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.4748828411102295
Epoch: 87, Steps: 65 | Train Loss: 0.3124075 Vali Loss: 1.0322608 Test Loss: 0.4540952
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.3138394355773926
Epoch: 88, Steps: 65 | Train Loss: 0.3122304 Vali Loss: 1.0314733 Test Loss: 0.4540635
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.2741570472717285
Epoch: 89, Steps: 65 | Train Loss: 0.3121917 Vali Loss: 1.0320383 Test Loss: 0.4540298
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.3393275737762451
Epoch: 90, Steps: 65 | Train Loss: 0.3124503 Vali Loss: 1.0320398 Test Loss: 0.4539966
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.225208044052124
Epoch: 91, Steps: 65 | Train Loss: 0.3119892 Vali Loss: 1.0318291 Test Loss: 0.4539692
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.2181847095489502
Epoch: 92, Steps: 65 | Train Loss: 0.3123053 Vali Loss: 1.0313416 Test Loss: 0.4539371
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.2500879764556885
Epoch: 93, Steps: 65 | Train Loss: 0.3121127 Vali Loss: 1.0317328 Test Loss: 0.4539118
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.2093005180358887
Epoch: 94, Steps: 65 | Train Loss: 0.3120670 Vali Loss: 1.0314051 Test Loss: 0.4538855
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.2367956638336182
Epoch: 95, Steps: 65 | Train Loss: 0.3121679 Vali Loss: 1.0317299 Test Loss: 0.4538601
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.2776069641113281
Epoch: 96, Steps: 65 | Train Loss: 0.3122200 Vali Loss: 1.0316473 Test Loss: 0.4538341
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.2579216957092285
Epoch: 97, Steps: 65 | Train Loss: 0.3121837 Vali Loss: 1.0316107 Test Loss: 0.4538122
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.2210307121276855
Epoch: 98, Steps: 65 | Train Loss: 0.3121567 Vali Loss: 1.0315518 Test Loss: 0.4537898
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.2037303447723389
Epoch: 99, Steps: 65 | Train Loss: 0.3120073 Vali Loss: 1.0315547 Test Loss: 0.4537697
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.3037910461425781
Epoch: 100, Steps: 65 | Train Loss: 0.3118616 Vali Loss: 1.0310900 Test Loss: 0.4537517
Validation loss decreased (1.031333 --> 1.031090).  Saving model ...
Updating learning rate to 3.1160680107021042e-06
train 8359
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=22, out_features=68, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1340416.0
params:  1564.0
Trainable parameters:  1564
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.2443222999572754
Epoch: 1, Steps: 65 | Train Loss: 0.4360550 Vali Loss: 1.0191914 Test Loss: 0.4469589
Validation loss decreased (inf --> 1.019191).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.251765251159668
Epoch: 2, Steps: 65 | Train Loss: 0.4311260 Vali Loss: 1.0136967 Test Loss: 0.4434356
Validation loss decreased (1.019191 --> 1.013697).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.286116361618042
Epoch: 3, Steps: 65 | Train Loss: 0.4285687 Vali Loss: 1.0098734 Test Loss: 0.4420771
Validation loss decreased (1.013697 --> 1.009873).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.2573723793029785
Epoch: 4, Steps: 65 | Train Loss: 0.4269575 Vali Loss: 1.0086192 Test Loss: 0.4408971
Validation loss decreased (1.009873 --> 1.008619).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.199033260345459
Epoch: 5, Steps: 65 | Train Loss: 0.4258582 Vali Loss: 1.0071480 Test Loss: 0.4403778
Validation loss decreased (1.008619 --> 1.007148).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.3594169616699219
Epoch: 6, Steps: 65 | Train Loss: 0.4253306 Vali Loss: 1.0066206 Test Loss: 0.4400312
Validation loss decreased (1.007148 --> 1.006621).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.1928355693817139
Epoch: 7, Steps: 65 | Train Loss: 0.4248886 Vali Loss: 1.0055544 Test Loss: 0.4398694
Validation loss decreased (1.006621 --> 1.005554).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.273503065109253
Epoch: 8, Steps: 65 | Train Loss: 0.4241547 Vali Loss: 1.0057299 Test Loss: 0.4399662
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.261981725692749
Epoch: 9, Steps: 65 | Train Loss: 0.4247756 Vali Loss: 1.0048960 Test Loss: 0.4401577
Validation loss decreased (1.005554 --> 1.004896).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.1673130989074707
Epoch: 10, Steps: 65 | Train Loss: 0.4247771 Vali Loss: 1.0049344 Test Loss: 0.4400786
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.2341411113739014
Epoch: 11, Steps: 65 | Train Loss: 0.4243763 Vali Loss: 1.0043448 Test Loss: 0.4402288
Validation loss decreased (1.004896 --> 1.004345).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.1408801078796387
Epoch: 12, Steps: 65 | Train Loss: 0.4240391 Vali Loss: 1.0043185 Test Loss: 0.4403692
Validation loss decreased (1.004345 --> 1.004318).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.8251900672912598
Epoch: 13, Steps: 65 | Train Loss: 0.4239782 Vali Loss: 1.0044336 Test Loss: 0.4403999
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.254927396774292
Epoch: 14, Steps: 65 | Train Loss: 0.4243329 Vali Loss: 1.0041192 Test Loss: 0.4404112
Validation loss decreased (1.004318 --> 1.004119).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.1832234859466553
Epoch: 15, Steps: 65 | Train Loss: 0.4241788 Vali Loss: 1.0041205 Test Loss: 0.4404409
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.2453038692474365
Epoch: 16, Steps: 65 | Train Loss: 0.4241278 Vali Loss: 1.0044626 Test Loss: 0.4404339
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 4.637896776199341
Epoch: 17, Steps: 65 | Train Loss: 0.4240382 Vali Loss: 1.0043669 Test Loss: 0.4404981
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.303086757659912
Epoch: 18, Steps: 65 | Train Loss: 0.4239676 Vali Loss: 1.0042232 Test Loss: 0.4404257
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.1489677429199219
Epoch: 19, Steps: 65 | Train Loss: 0.4236841 Vali Loss: 1.0042875 Test Loss: 0.4405245
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.225494623184204
Epoch: 20, Steps: 65 | Train Loss: 0.4238003 Vali Loss: 1.0037395 Test Loss: 0.4405648
Validation loss decreased (1.004119 --> 1.003739).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.2207670211791992
Epoch: 21, Steps: 65 | Train Loss: 0.4241449 Vali Loss: 1.0042210 Test Loss: 0.4405184
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.2083027362823486
Epoch: 22, Steps: 65 | Train Loss: 0.4237640 Vali Loss: 1.0033333 Test Loss: 0.4406756
Validation loss decreased (1.003739 --> 1.003333).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.2592930793762207
Epoch: 23, Steps: 65 | Train Loss: 0.4239194 Vali Loss: 1.0029895 Test Loss: 0.4405933
Validation loss decreased (1.003333 --> 1.002990).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.2813105583190918
Epoch: 24, Steps: 65 | Train Loss: 0.4240496 Vali Loss: 1.0036776 Test Loss: 0.4406311
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.2297608852386475
Epoch: 25, Steps: 65 | Train Loss: 0.4238053 Vali Loss: 1.0039973 Test Loss: 0.4406458
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.291536569595337
Epoch: 26, Steps: 65 | Train Loss: 0.4236365 Vali Loss: 1.0034944 Test Loss: 0.4407609
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.1490938663482666
Epoch: 27, Steps: 65 | Train Loss: 0.4241059 Vali Loss: 1.0035214 Test Loss: 0.4407257
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.1995973587036133
Epoch: 28, Steps: 65 | Train Loss: 0.4240430 Vali Loss: 1.0037403 Test Loss: 0.4406820
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.239060878753662
Epoch: 29, Steps: 65 | Train Loss: 0.4239172 Vali Loss: 1.0038348 Test Loss: 0.4406105
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.1243584156036377
Epoch: 30, Steps: 65 | Train Loss: 0.4240074 Vali Loss: 1.0038882 Test Loss: 0.4407401
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.2155253887176514
Epoch: 31, Steps: 65 | Train Loss: 0.4239153 Vali Loss: 1.0038888 Test Loss: 0.4406813
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.2886488437652588
Epoch: 32, Steps: 65 | Train Loss: 0.4238266 Vali Loss: 1.0034044 Test Loss: 0.4406818
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.6713526248931885
Epoch: 33, Steps: 65 | Train Loss: 0.4239853 Vali Loss: 1.0038707 Test Loss: 0.4406652
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.671109437942505
Epoch: 34, Steps: 65 | Train Loss: 0.4238998 Vali Loss: 1.0029936 Test Loss: 0.4407575
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.3092319965362549
Epoch: 35, Steps: 65 | Train Loss: 0.4237492 Vali Loss: 1.0033549 Test Loss: 0.4407572
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.1980865001678467
Epoch: 36, Steps: 65 | Train Loss: 0.4239776 Vali Loss: 1.0038260 Test Loss: 0.4407604
EarlyStopping counter: 13 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.316399335861206
Epoch: 37, Steps: 65 | Train Loss: 0.4239055 Vali Loss: 1.0034170 Test Loss: 0.4407762
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.8827390670776367
Epoch: 38, Steps: 65 | Train Loss: 0.4239656 Vali Loss: 1.0035608 Test Loss: 0.4407860
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.0560269355773926
Epoch: 39, Steps: 65 | Train Loss: 0.4237109 Vali Loss: 1.0034456 Test Loss: 0.4407237
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.2335317134857178
Epoch: 40, Steps: 65 | Train Loss: 0.4237612 Vali Loss: 1.0034978 Test Loss: 0.4407811
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.2512116432189941
Epoch: 41, Steps: 65 | Train Loss: 0.4238028 Vali Loss: 1.0035100 Test Loss: 0.4407823
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.1865975856781006
Epoch: 42, Steps: 65 | Train Loss: 0.4234766 Vali Loss: 1.0031118 Test Loss: 0.4407808
EarlyStopping counter: 19 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.1955947875976562
Epoch: 43, Steps: 65 | Train Loss: 0.4239574 Vali Loss: 1.0035341 Test Loss: 0.4408294
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_90_192_FITS_ETTh1_ftM_sl90_ll48_pl192_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.440185546875, mae:0.42595404386520386, rse:0.6300503015518188, corr:[0.26225013 0.2655709  0.2649769  0.26352543 0.2610674  0.25899076
 0.25842068 0.25772154 0.2571791  0.25737333 0.25719577 0.25693378
 0.25665903 0.25633457 0.2561769  0.25604144 0.25604197 0.25629672
 0.25646755 0.256286   0.2557094  0.25540408 0.25501752 0.25440294
 0.25301045 0.25251946 0.25284338 0.25307947 0.25286022 0.2528124
 0.2530583  0.25275242 0.25245863 0.25247929 0.25233185 0.25211045
 0.2519712  0.2520224  0.2522415  0.25231934 0.25247258 0.25288752
 0.2534441  0.25364023 0.25351945 0.25334027 0.25324848 0.25273517
 0.25135294 0.2504756  0.25000748 0.24925487 0.24794406 0.24682531
 0.24687417 0.2465451  0.2460352  0.24613544 0.24612553 0.24592435
 0.24560998 0.24550673 0.24546891 0.24512087 0.24503824 0.24539852
 0.24603531 0.24629603 0.24606018 0.24585469 0.24569082 0.24477632
 0.24293713 0.24189217 0.24150681 0.24116799 0.24054143 0.24018656
 0.24055395 0.24029027 0.23983304 0.2396449  0.23954563 0.23925233
 0.23898236 0.2390767  0.23945202 0.23937382 0.23919705 0.23939727
 0.23968814 0.23974986 0.23964931 0.2396993  0.23983505 0.23938534
 0.23805027 0.23745777 0.23748264 0.23706    0.23657638 0.23653391
 0.23695569 0.23673122 0.23630428 0.2362269  0.23619695 0.23595424
 0.23564512 0.23551317 0.23580287 0.23587132 0.23594467 0.23610185
 0.23646134 0.23669219 0.23676239 0.23682873 0.23657857 0.23555663
 0.23358493 0.23232025 0.23161647 0.23072846 0.23000611 0.23002274
 0.23087129 0.2310023  0.23075104 0.2306228  0.23041469 0.23022203
 0.23001882 0.22983865 0.22978963 0.22950506 0.22950189 0.229733
 0.23014022 0.2304548  0.23043247 0.23049805 0.23042062 0.22953817
 0.22761884 0.22648586 0.2261957  0.22548768 0.22458509 0.22444367
 0.22532314 0.22537923 0.2252242  0.22525555 0.22510569 0.2248525
 0.2246498  0.22463304 0.22456135 0.22420628 0.22401097 0.2241664
 0.22464082 0.22500128 0.22492665 0.22483923 0.22472851 0.22387739
 0.22217432 0.22132142 0.22122706 0.2208852  0.21999355 0.21982469
 0.220638   0.22048612 0.22007054 0.22029607 0.2206547  0.22048344
 0.22009109 0.2198353  0.21983989 0.21945903 0.21899204 0.21912163
 0.21980906 0.22030818 0.2199376  0.2194548  0.22033085 0.22150986]
