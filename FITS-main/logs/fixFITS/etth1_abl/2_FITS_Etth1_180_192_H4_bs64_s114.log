Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=42, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_180_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_180_192_FITS_ETTh1_ftM_sl180_ll48_pl192_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8269
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=42, out_features=86, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3236352.0
params:  3698.0
Trainable parameters:  3698
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.800935983657837
Epoch: 1, Steps: 64 | Train Loss: 0.6623317 Vali Loss: 1.5229843 Test Loss: 0.8225039
Validation loss decreased (inf --> 1.522984).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.418466567993164
Epoch: 2, Steps: 64 | Train Loss: 0.5161639 Vali Loss: 1.3495991 Test Loss: 0.7017066
Validation loss decreased (1.522984 --> 1.349599).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.4673638343811035
Epoch: 3, Steps: 64 | Train Loss: 0.4366619 Vali Loss: 1.2531000 Test Loss: 0.6344411
Validation loss decreased (1.349599 --> 1.253100).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.6479368209838867
Epoch: 4, Steps: 64 | Train Loss: 0.3884440 Vali Loss: 1.1921540 Test Loss: 0.5918233
Validation loss decreased (1.253100 --> 1.192154).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.9069280624389648
Epoch: 5, Steps: 64 | Train Loss: 0.3569650 Vali Loss: 1.1534808 Test Loss: 0.5657963
Validation loss decreased (1.192154 --> 1.153481).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.8289406299591064
Epoch: 6, Steps: 64 | Train Loss: 0.3353990 Vali Loss: 1.1269327 Test Loss: 0.5482660
Validation loss decreased (1.153481 --> 1.126933).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.7462735176086426
Epoch: 7, Steps: 64 | Train Loss: 0.3196036 Vali Loss: 1.1082870 Test Loss: 0.5363120
Validation loss decreased (1.126933 --> 1.108287).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.5727458000183105
Epoch: 8, Steps: 64 | Train Loss: 0.3079829 Vali Loss: 1.0935309 Test Loss: 0.5274798
Validation loss decreased (1.108287 --> 1.093531).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.171482563018799
Epoch: 9, Steps: 64 | Train Loss: 0.2988835 Vali Loss: 1.0826412 Test Loss: 0.5202243
Validation loss decreased (1.093531 --> 1.082641).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.3690454959869385
Epoch: 10, Steps: 64 | Train Loss: 0.2915847 Vali Loss: 1.0738438 Test Loss: 0.5146508
Validation loss decreased (1.082641 --> 1.073844).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.8288724422454834
Epoch: 11, Steps: 64 | Train Loss: 0.2859584 Vali Loss: 1.0664670 Test Loss: 0.5099126
Validation loss decreased (1.073844 --> 1.066467).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.665381908416748
Epoch: 12, Steps: 64 | Train Loss: 0.2810334 Vali Loss: 1.0604600 Test Loss: 0.5061096
Validation loss decreased (1.066467 --> 1.060460).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.798774242401123
Epoch: 13, Steps: 64 | Train Loss: 0.2765270 Vali Loss: 1.0543534 Test Loss: 0.5022550
Validation loss decreased (1.060460 --> 1.054353).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.9463226795196533
Epoch: 14, Steps: 64 | Train Loss: 0.2730753 Vali Loss: 1.0496837 Test Loss: 0.4990603
Validation loss decreased (1.054353 --> 1.049684).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.0887324810028076
Epoch: 15, Steps: 64 | Train Loss: 0.2698292 Vali Loss: 1.0456079 Test Loss: 0.4964275
Validation loss decreased (1.049684 --> 1.045608).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.0481340885162354
Epoch: 16, Steps: 64 | Train Loss: 0.2668156 Vali Loss: 1.0422789 Test Loss: 0.4936169
Validation loss decreased (1.045608 --> 1.042279).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.708707332611084
Epoch: 17, Steps: 64 | Train Loss: 0.2645460 Vali Loss: 1.0383726 Test Loss: 0.4912466
Validation loss decreased (1.042279 --> 1.038373).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.4546167850494385
Epoch: 18, Steps: 64 | Train Loss: 0.2623368 Vali Loss: 1.0356504 Test Loss: 0.4890877
Validation loss decreased (1.038373 --> 1.035650).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.744194746017456
Epoch: 19, Steps: 64 | Train Loss: 0.2603010 Vali Loss: 1.0328182 Test Loss: 0.4871487
Validation loss decreased (1.035650 --> 1.032818).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.547788143157959
Epoch: 20, Steps: 64 | Train Loss: 0.2587464 Vali Loss: 1.0302794 Test Loss: 0.4853594
Validation loss decreased (1.032818 --> 1.030279).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.661616802215576
Epoch: 21, Steps: 64 | Train Loss: 0.2571626 Vali Loss: 1.0274423 Test Loss: 0.4834853
Validation loss decreased (1.030279 --> 1.027442).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.6029479503631592
Epoch: 22, Steps: 64 | Train Loss: 0.2555285 Vali Loss: 1.0254703 Test Loss: 0.4817805
Validation loss decreased (1.027442 --> 1.025470).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.264357089996338
Epoch: 23, Steps: 64 | Train Loss: 0.2540757 Vali Loss: 1.0238234 Test Loss: 0.4802513
Validation loss decreased (1.025470 --> 1.023823).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.3813273906707764
Epoch: 24, Steps: 64 | Train Loss: 0.2530402 Vali Loss: 1.0220571 Test Loss: 0.4789430
Validation loss decreased (1.023823 --> 1.022057).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 3.175633668899536
Epoch: 25, Steps: 64 | Train Loss: 0.2519969 Vali Loss: 1.0202248 Test Loss: 0.4777134
Validation loss decreased (1.022057 --> 1.020225).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 4.05661940574646
Epoch: 26, Steps: 64 | Train Loss: 0.2507474 Vali Loss: 1.0186368 Test Loss: 0.4764788
Validation loss decreased (1.020225 --> 1.018637).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 3.2668356895446777
Epoch: 27, Steps: 64 | Train Loss: 0.2498272 Vali Loss: 1.0167652 Test Loss: 0.4753544
Validation loss decreased (1.018637 --> 1.016765).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.136552572250366
Epoch: 28, Steps: 64 | Train Loss: 0.2489714 Vali Loss: 1.0157092 Test Loss: 0.4743057
Validation loss decreased (1.016765 --> 1.015709).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.9220075607299805
Epoch: 29, Steps: 64 | Train Loss: 0.2482189 Vali Loss: 1.0143659 Test Loss: 0.4734026
Validation loss decreased (1.015709 --> 1.014366).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.7821805477142334
Epoch: 30, Steps: 64 | Train Loss: 0.2474090 Vali Loss: 1.0127814 Test Loss: 0.4725063
Validation loss decreased (1.014366 --> 1.012781).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.1255619525909424
Epoch: 31, Steps: 64 | Train Loss: 0.2466135 Vali Loss: 1.0120937 Test Loss: 0.4715668
Validation loss decreased (1.012781 --> 1.012094).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.0197594165802
Epoch: 32, Steps: 64 | Train Loss: 0.2460572 Vali Loss: 1.0110247 Test Loss: 0.4708120
Validation loss decreased (1.012094 --> 1.011025).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.392240047454834
Epoch: 33, Steps: 64 | Train Loss: 0.2457009 Vali Loss: 1.0100607 Test Loss: 0.4701039
Validation loss decreased (1.011025 --> 1.010061).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.4360053539276123
Epoch: 34, Steps: 64 | Train Loss: 0.2450590 Vali Loss: 1.0092845 Test Loss: 0.4694670
Validation loss decreased (1.010061 --> 1.009284).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.7796063423156738
Epoch: 35, Steps: 64 | Train Loss: 0.2442509 Vali Loss: 1.0082839 Test Loss: 0.4688542
Validation loss decreased (1.009284 --> 1.008284).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.4036478996276855
Epoch: 36, Steps: 64 | Train Loss: 0.2439715 Vali Loss: 1.0075854 Test Loss: 0.4681981
Validation loss decreased (1.008284 --> 1.007585).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 3.1546621322631836
Epoch: 37, Steps: 64 | Train Loss: 0.2435324 Vali Loss: 1.0068338 Test Loss: 0.4675295
Validation loss decreased (1.007585 --> 1.006834).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.7387683391571045
Epoch: 38, Steps: 64 | Train Loss: 0.2432220 Vali Loss: 1.0061069 Test Loss: 0.4670205
Validation loss decreased (1.006834 --> 1.006107).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.7862827777862549
Epoch: 39, Steps: 64 | Train Loss: 0.2425133 Vali Loss: 1.0054466 Test Loss: 0.4664611
Validation loss decreased (1.006107 --> 1.005447).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.5003764629364014
Epoch: 40, Steps: 64 | Train Loss: 0.2424499 Vali Loss: 1.0046364 Test Loss: 0.4659790
Validation loss decreased (1.005447 --> 1.004636).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.542968511581421
Epoch: 41, Steps: 64 | Train Loss: 0.2420325 Vali Loss: 1.0036995 Test Loss: 0.4655582
Validation loss decreased (1.004636 --> 1.003700).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.653066873550415
Epoch: 42, Steps: 64 | Train Loss: 0.2413585 Vali Loss: 1.0033842 Test Loss: 0.4651270
Validation loss decreased (1.003700 --> 1.003384).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.7939484119415283
Epoch: 43, Steps: 64 | Train Loss: 0.2414148 Vali Loss: 1.0029358 Test Loss: 0.4646271
Validation loss decreased (1.003384 --> 1.002936).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.7098493576049805
Epoch: 44, Steps: 64 | Train Loss: 0.2412164 Vali Loss: 1.0021384 Test Loss: 0.4643521
Validation loss decreased (1.002936 --> 1.002138).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.9486019611358643
Epoch: 45, Steps: 64 | Train Loss: 0.2406811 Vali Loss: 1.0021046 Test Loss: 0.4639606
Validation loss decreased (1.002138 --> 1.002105).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.5478863716125488
Epoch: 46, Steps: 64 | Train Loss: 0.2404912 Vali Loss: 1.0004529 Test Loss: 0.4636444
Validation loss decreased (1.002105 --> 1.000453).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.629263162612915
Epoch: 47, Steps: 64 | Train Loss: 0.2401319 Vali Loss: 1.0013993 Test Loss: 0.4633139
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.0331368446350098
Epoch: 48, Steps: 64 | Train Loss: 0.2398514 Vali Loss: 1.0005332 Test Loss: 0.4630218
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.8965904712677002
Epoch: 49, Steps: 64 | Train Loss: 0.2399184 Vali Loss: 1.0002290 Test Loss: 0.4626983
Validation loss decreased (1.000453 --> 1.000229).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.0801587104797363
Epoch: 50, Steps: 64 | Train Loss: 0.2396717 Vali Loss: 0.9999384 Test Loss: 0.4624326
Validation loss decreased (1.000229 --> 0.999938).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.1044042110443115
Epoch: 51, Steps: 64 | Train Loss: 0.2392912 Vali Loss: 0.9998686 Test Loss: 0.4621569
Validation loss decreased (0.999938 --> 0.999869).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.883033275604248
Epoch: 52, Steps: 64 | Train Loss: 0.2391536 Vali Loss: 0.9996966 Test Loss: 0.4619749
Validation loss decreased (0.999869 --> 0.999697).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.6332788467407227
Epoch: 53, Steps: 64 | Train Loss: 0.2391540 Vali Loss: 0.9993703 Test Loss: 0.4617040
Validation loss decreased (0.999697 --> 0.999370).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.139683961868286
Epoch: 54, Steps: 64 | Train Loss: 0.2388303 Vali Loss: 0.9989584 Test Loss: 0.4614801
Validation loss decreased (0.999370 --> 0.998958).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.032736301422119
Epoch: 55, Steps: 64 | Train Loss: 0.2387311 Vali Loss: 0.9984975 Test Loss: 0.4612599
Validation loss decreased (0.998958 --> 0.998498).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.32328724861145
Epoch: 56, Steps: 64 | Train Loss: 0.2386555 Vali Loss: 0.9983057 Test Loss: 0.4610667
Validation loss decreased (0.998498 --> 0.998306).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.3549654483795166
Epoch: 57, Steps: 64 | Train Loss: 0.2383500 Vali Loss: 0.9980893 Test Loss: 0.4608894
Validation loss decreased (0.998306 --> 0.998089).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.0113744735717773
Epoch: 58, Steps: 64 | Train Loss: 0.2381703 Vali Loss: 0.9981537 Test Loss: 0.4607021
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.8264729976654053
Epoch: 59, Steps: 64 | Train Loss: 0.2379457 Vali Loss: 0.9977577 Test Loss: 0.4605399
Validation loss decreased (0.998089 --> 0.997758).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.7893896102905273
Epoch: 60, Steps: 64 | Train Loss: 0.2379342 Vali Loss: 0.9972884 Test Loss: 0.4604053
Validation loss decreased (0.997758 --> 0.997288).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.9214446544647217
Epoch: 61, Steps: 64 | Train Loss: 0.2377274 Vali Loss: 0.9971189 Test Loss: 0.4602672
Validation loss decreased (0.997288 --> 0.997119).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.6527700424194336
Epoch: 62, Steps: 64 | Train Loss: 0.2376440 Vali Loss: 0.9972569 Test Loss: 0.4600941
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.166743040084839
Epoch: 63, Steps: 64 | Train Loss: 0.2376377 Vali Loss: 0.9971291 Test Loss: 0.4599885
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.9307374954223633
Epoch: 64, Steps: 64 | Train Loss: 0.2377609 Vali Loss: 0.9966698 Test Loss: 0.4598355
Validation loss decreased (0.997119 --> 0.996670).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.769845962524414
Epoch: 65, Steps: 64 | Train Loss: 0.2372777 Vali Loss: 0.9964622 Test Loss: 0.4597260
Validation loss decreased (0.996670 --> 0.996462).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.0026144981384277
Epoch: 66, Steps: 64 | Train Loss: 0.2375895 Vali Loss: 0.9965758 Test Loss: 0.4596033
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.9283902645111084
Epoch: 67, Steps: 64 | Train Loss: 0.2371964 Vali Loss: 0.9963577 Test Loss: 0.4594926
Validation loss decreased (0.996462 --> 0.996358).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.8071746826171875
Epoch: 68, Steps: 64 | Train Loss: 0.2373267 Vali Loss: 0.9962219 Test Loss: 0.4593842
Validation loss decreased (0.996358 --> 0.996222).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.456394910812378
Epoch: 69, Steps: 64 | Train Loss: 0.2373079 Vali Loss: 0.9963201 Test Loss: 0.4592667
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.769437551498413
Epoch: 70, Steps: 64 | Train Loss: 0.2370798 Vali Loss: 0.9958158 Test Loss: 0.4592212
Validation loss decreased (0.996222 --> 0.995816).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.0522594451904297
Epoch: 71, Steps: 64 | Train Loss: 0.2371157 Vali Loss: 0.9960756 Test Loss: 0.4591090
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.759352445602417
Epoch: 72, Steps: 64 | Train Loss: 0.2370443 Vali Loss: 0.9957555 Test Loss: 0.4590373
Validation loss decreased (0.995816 --> 0.995755).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.823228359222412
Epoch: 73, Steps: 64 | Train Loss: 0.2369774 Vali Loss: 0.9954976 Test Loss: 0.4589358
Validation loss decreased (0.995755 --> 0.995498).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.0636332035064697
Epoch: 74, Steps: 64 | Train Loss: 0.2367445 Vali Loss: 0.9957789 Test Loss: 0.4588706
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.5016541481018066
Epoch: 75, Steps: 64 | Train Loss: 0.2366295 Vali Loss: 0.9956509 Test Loss: 0.4587913
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.7592265605926514
Epoch: 76, Steps: 64 | Train Loss: 0.2369979 Vali Loss: 0.9956573 Test Loss: 0.4587331
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.5928432941436768
Epoch: 77, Steps: 64 | Train Loss: 0.2365023 Vali Loss: 0.9954644 Test Loss: 0.4586702
Validation loss decreased (0.995498 --> 0.995464).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.2106826305389404
Epoch: 78, Steps: 64 | Train Loss: 0.2367113 Vali Loss: 0.9947529 Test Loss: 0.4585943
Validation loss decreased (0.995464 --> 0.994753).  Saving model ...
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.963792085647583
Epoch: 79, Steps: 64 | Train Loss: 0.2366383 Vali Loss: 0.9952639 Test Loss: 0.4585381
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.721792221069336
Epoch: 80, Steps: 64 | Train Loss: 0.2365348 Vali Loss: 0.9948893 Test Loss: 0.4584718
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 4.858986139297485
Epoch: 81, Steps: 64 | Train Loss: 0.2365805 Vali Loss: 0.9949995 Test Loss: 0.4584314
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 2.8981211185455322
Epoch: 82, Steps: 64 | Train Loss: 0.2366276 Vali Loss: 0.9939089 Test Loss: 0.4583816
Validation loss decreased (0.994753 --> 0.993909).  Saving model ...
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.9299671649932861
Epoch: 83, Steps: 64 | Train Loss: 0.2365923 Vali Loss: 0.9949332 Test Loss: 0.4583276
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.7109251022338867
Epoch: 84, Steps: 64 | Train Loss: 0.2365803 Vali Loss: 0.9949458 Test Loss: 0.4582884
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.9562101364135742
Epoch: 85, Steps: 64 | Train Loss: 0.2361829 Vali Loss: 0.9950364 Test Loss: 0.4582393
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 2.0558619499206543
Epoch: 86, Steps: 64 | Train Loss: 0.2363526 Vali Loss: 0.9948454 Test Loss: 0.4582030
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 2.6485886573791504
Epoch: 87, Steps: 64 | Train Loss: 0.2362112 Vali Loss: 0.9948233 Test Loss: 0.4581669
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 3.051070213317871
Epoch: 88, Steps: 64 | Train Loss: 0.2365222 Vali Loss: 0.9947326 Test Loss: 0.4581347
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.2930619716644287
Epoch: 89, Steps: 64 | Train Loss: 0.2362252 Vali Loss: 0.9944838 Test Loss: 0.4580972
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 3.0886049270629883
Epoch: 90, Steps: 64 | Train Loss: 0.2363779 Vali Loss: 0.9946669 Test Loss: 0.4580590
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.6857211589813232
Epoch: 91, Steps: 64 | Train Loss: 0.2362518 Vali Loss: 0.9946958 Test Loss: 0.4580338
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 2.202838897705078
Epoch: 92, Steps: 64 | Train Loss: 0.2362406 Vali Loss: 0.9946645 Test Loss: 0.4580101
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.7143845558166504
Epoch: 93, Steps: 64 | Train Loss: 0.2358163 Vali Loss: 0.9943339 Test Loss: 0.4579727
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.9329392910003662
Epoch: 94, Steps: 64 | Train Loss: 0.2361285 Vali Loss: 0.9940594 Test Loss: 0.4579504
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.6244399547576904
Epoch: 95, Steps: 64 | Train Loss: 0.2360451 Vali Loss: 0.9944650 Test Loss: 0.4579223
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.7583706378936768
Epoch: 96, Steps: 64 | Train Loss: 0.2358747 Vali Loss: 0.9943513 Test Loss: 0.4579000
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.6695518493652344
Epoch: 97, Steps: 64 | Train Loss: 0.2359945 Vali Loss: 0.9940699 Test Loss: 0.4578777
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.7368412017822266
Epoch: 98, Steps: 64 | Train Loss: 0.2360199 Vali Loss: 0.9944469 Test Loss: 0.4578554
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.8272743225097656
Epoch: 99, Steps: 64 | Train Loss: 0.2360592 Vali Loss: 0.9944238 Test Loss: 0.4578354
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.6757214069366455
Epoch: 100, Steps: 64 | Train Loss: 0.2358939 Vali Loss: 0.9942096 Test Loss: 0.4578133
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8269
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=42, out_features=86, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3236352.0
params:  3698.0
Trainable parameters:  3698
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.8435254096984863
Epoch: 1, Steps: 64 | Train Loss: 0.4174696 Vali Loss: 0.9844550 Test Loss: 0.4461108
Validation loss decreased (inf --> 0.984455).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.9589617252349854
Epoch: 2, Steps: 64 | Train Loss: 0.4130492 Vali Loss: 0.9799383 Test Loss: 0.4406558
Validation loss decreased (0.984455 --> 0.979938).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.7181320190429688
Epoch: 3, Steps: 64 | Train Loss: 0.4098591 Vali Loss: 0.9776123 Test Loss: 0.4369664
Validation loss decreased (0.979938 --> 0.977612).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.723273515701294
Epoch: 4, Steps: 64 | Train Loss: 0.4086244 Vali Loss: 0.9745447 Test Loss: 0.4354060
Validation loss decreased (0.977612 --> 0.974545).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.3289875984191895
Epoch: 5, Steps: 64 | Train Loss: 0.4078744 Vali Loss: 0.9737573 Test Loss: 0.4343036
Validation loss decreased (0.974545 --> 0.973757).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.7035248279571533
Epoch: 6, Steps: 64 | Train Loss: 0.4071786 Vali Loss: 0.9730574 Test Loss: 0.4340945
Validation loss decreased (0.973757 --> 0.973057).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.505924701690674
Epoch: 7, Steps: 64 | Train Loss: 0.4070978 Vali Loss: 0.9722746 Test Loss: 0.4344859
Validation loss decreased (0.973057 --> 0.972275).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.840883731842041
Epoch: 8, Steps: 64 | Train Loss: 0.4071197 Vali Loss: 0.9721038 Test Loss: 0.4340074
Validation loss decreased (0.972275 --> 0.972104).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.426856279373169
Epoch: 9, Steps: 64 | Train Loss: 0.4068671 Vali Loss: 0.9719602 Test Loss: 0.4339625
Validation loss decreased (0.972104 --> 0.971960).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.2629621028900146
Epoch: 10, Steps: 64 | Train Loss: 0.4068250 Vali Loss: 0.9714128 Test Loss: 0.4343798
Validation loss decreased (0.971960 --> 0.971413).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.8327767848968506
Epoch: 11, Steps: 64 | Train Loss: 0.4069477 Vali Loss: 0.9713275 Test Loss: 0.4339047
Validation loss decreased (0.971413 --> 0.971328).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.6246588230133057
Epoch: 12, Steps: 64 | Train Loss: 0.4067378 Vali Loss: 0.9714449 Test Loss: 0.4340593
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.6326546669006348
Epoch: 13, Steps: 64 | Train Loss: 0.4065646 Vali Loss: 0.9711819 Test Loss: 0.4341317
Validation loss decreased (0.971328 --> 0.971182).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.7772116661071777
Epoch: 14, Steps: 64 | Train Loss: 0.4063566 Vali Loss: 0.9712245 Test Loss: 0.4343850
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.9497010707855225
Epoch: 15, Steps: 64 | Train Loss: 0.4065760 Vali Loss: 0.9709519 Test Loss: 0.4343323
Validation loss decreased (0.971182 --> 0.970952).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.4100382328033447
Epoch: 16, Steps: 64 | Train Loss: 0.4066990 Vali Loss: 0.9701487 Test Loss: 0.4338947
Validation loss decreased (0.970952 --> 0.970149).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.9315006732940674
Epoch: 17, Steps: 64 | Train Loss: 0.4068100 Vali Loss: 0.9707946 Test Loss: 0.4347965
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.1116864681243896
Epoch: 18, Steps: 64 | Train Loss: 0.4061962 Vali Loss: 0.9706208 Test Loss: 0.4346799
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.143099308013916
Epoch: 19, Steps: 64 | Train Loss: 0.4061750 Vali Loss: 0.9700130 Test Loss: 0.4340813
Validation loss decreased (0.970149 --> 0.970013).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.0029890537261963
Epoch: 20, Steps: 64 | Train Loss: 0.4064509 Vali Loss: 0.9701155 Test Loss: 0.4345202
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.471766471862793
Epoch: 21, Steps: 64 | Train Loss: 0.4062693 Vali Loss: 0.9698387 Test Loss: 0.4344049
Validation loss decreased (0.970013 --> 0.969839).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.023073196411133
Epoch: 22, Steps: 64 | Train Loss: 0.4059345 Vali Loss: 0.9705159 Test Loss: 0.4343209
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.3288559913635254
Epoch: 23, Steps: 64 | Train Loss: 0.4066180 Vali Loss: 0.9703832 Test Loss: 0.4344419
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.427623748779297
Epoch: 24, Steps: 64 | Train Loss: 0.4065292 Vali Loss: 0.9701675 Test Loss: 0.4343852
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.075333833694458
Epoch: 25, Steps: 64 | Train Loss: 0.4062855 Vali Loss: 0.9704667 Test Loss: 0.4343250
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.008931875228882
Epoch: 26, Steps: 64 | Train Loss: 0.4057373 Vali Loss: 0.9701303 Test Loss: 0.4343586
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.3181841373443604
Epoch: 27, Steps: 64 | Train Loss: 0.4059057 Vali Loss: 0.9703423 Test Loss: 0.4342719
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.0863776206970215
Epoch: 28, Steps: 64 | Train Loss: 0.4063070 Vali Loss: 0.9702405 Test Loss: 0.4345939
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.9926748275756836
Epoch: 29, Steps: 64 | Train Loss: 0.4060552 Vali Loss: 0.9701478 Test Loss: 0.4345577
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.7221007347106934
Epoch: 30, Steps: 64 | Train Loss: 0.4060588 Vali Loss: 0.9700215 Test Loss: 0.4345773
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.5831999778747559
Epoch: 31, Steps: 64 | Train Loss: 0.4060912 Vali Loss: 0.9696251 Test Loss: 0.4343856
Validation loss decreased (0.969839 --> 0.969625).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.3690357208251953
Epoch: 32, Steps: 64 | Train Loss: 0.4062876 Vali Loss: 0.9697498 Test Loss: 0.4344380
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.4708502292633057
Epoch: 33, Steps: 64 | Train Loss: 0.4061145 Vali Loss: 0.9697064 Test Loss: 0.4344842
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.7658343315124512
Epoch: 34, Steps: 64 | Train Loss: 0.4067336 Vali Loss: 0.9699844 Test Loss: 0.4344999
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 4.08252215385437
Epoch: 35, Steps: 64 | Train Loss: 0.4063013 Vali Loss: 0.9701133 Test Loss: 0.4344620
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.6627469062805176
Epoch: 36, Steps: 64 | Train Loss: 0.4063680 Vali Loss: 0.9698601 Test Loss: 0.4343896
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.7848331928253174
Epoch: 37, Steps: 64 | Train Loss: 0.4064279 Vali Loss: 0.9697042 Test Loss: 0.4344323
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.4703621864318848
Epoch: 38, Steps: 64 | Train Loss: 0.4062971 Vali Loss: 0.9699182 Test Loss: 0.4345204
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.3917176723480225
Epoch: 39, Steps: 64 | Train Loss: 0.4057836 Vali Loss: 0.9699653 Test Loss: 0.4344405
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 3.242154121398926
Epoch: 40, Steps: 64 | Train Loss: 0.4063436 Vali Loss: 0.9701871 Test Loss: 0.4344577
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 3.1646060943603516
Epoch: 41, Steps: 64 | Train Loss: 0.4058830 Vali Loss: 0.9695112 Test Loss: 0.4344248
Validation loss decreased (0.969625 --> 0.969511).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.8874146938323975
Epoch: 42, Steps: 64 | Train Loss: 0.4061208 Vali Loss: 0.9695884 Test Loss: 0.4344226
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.8904199600219727
Epoch: 43, Steps: 64 | Train Loss: 0.4064390 Vali Loss: 0.9695238 Test Loss: 0.4344540
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.24509859085083
Epoch: 44, Steps: 64 | Train Loss: 0.4063118 Vali Loss: 0.9696042 Test Loss: 0.4344259
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.7271735668182373
Epoch: 45, Steps: 64 | Train Loss: 0.4059008 Vali Loss: 0.9695116 Test Loss: 0.4344810
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.8732242584228516
Epoch: 46, Steps: 64 | Train Loss: 0.4060342 Vali Loss: 0.9696913 Test Loss: 0.4344313
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.8801496028900146
Epoch: 47, Steps: 64 | Train Loss: 0.4062025 Vali Loss: 0.9694954 Test Loss: 0.4344179
Validation loss decreased (0.969511 --> 0.969495).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.1523020267486572
Epoch: 48, Steps: 64 | Train Loss: 0.4060877 Vali Loss: 0.9699872 Test Loss: 0.4344149
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.593346118927002
Epoch: 49, Steps: 64 | Train Loss: 0.4060054 Vali Loss: 0.9698641 Test Loss: 0.4343873
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.810105800628662
Epoch: 50, Steps: 64 | Train Loss: 0.4057791 Vali Loss: 0.9698892 Test Loss: 0.4344604
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.7285306453704834
Epoch: 51, Steps: 64 | Train Loss: 0.4054605 Vali Loss: 0.9692757 Test Loss: 0.4345015
Validation loss decreased (0.969495 --> 0.969276).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.8412859439849854
Epoch: 52, Steps: 64 | Train Loss: 0.4067798 Vali Loss: 0.9698523 Test Loss: 0.4344768
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.7653892040252686
Epoch: 53, Steps: 64 | Train Loss: 0.4056975 Vali Loss: 0.9698888 Test Loss: 0.4344283
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.8628895282745361
Epoch: 54, Steps: 64 | Train Loss: 0.4061412 Vali Loss: 0.9698803 Test Loss: 0.4344380
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.218243360519409
Epoch: 55, Steps: 64 | Train Loss: 0.4060129 Vali Loss: 0.9694881 Test Loss: 0.4344018
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.6326537132263184
Epoch: 56, Steps: 64 | Train Loss: 0.4062849 Vali Loss: 0.9698836 Test Loss: 0.4344639
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.250396966934204
Epoch: 57, Steps: 64 | Train Loss: 0.4061450 Vali Loss: 0.9694477 Test Loss: 0.4344809
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.172567844390869
Epoch: 58, Steps: 64 | Train Loss: 0.4063030 Vali Loss: 0.9698440 Test Loss: 0.4344197
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.6342267990112305
Epoch: 59, Steps: 64 | Train Loss: 0.4062934 Vali Loss: 0.9697778 Test Loss: 0.4344574
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.3357489109039307
Epoch: 60, Steps: 64 | Train Loss: 0.4060424 Vali Loss: 0.9699265 Test Loss: 0.4344337
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.1707305908203125
Epoch: 61, Steps: 64 | Train Loss: 0.4060158 Vali Loss: 0.9699603 Test Loss: 0.4344286
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 3.162431240081787
Epoch: 62, Steps: 64 | Train Loss: 0.4062018 Vali Loss: 0.9697945 Test Loss: 0.4344597
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.569566011428833
Epoch: 63, Steps: 64 | Train Loss: 0.4062565 Vali Loss: 0.9699529 Test Loss: 0.4344303
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.111043691635132
Epoch: 64, Steps: 64 | Train Loss: 0.4062075 Vali Loss: 0.9697295 Test Loss: 0.4344255
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.8308658599853516
Epoch: 65, Steps: 64 | Train Loss: 0.4063830 Vali Loss: 0.9699246 Test Loss: 0.4344400
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.6893961429595947
Epoch: 66, Steps: 64 | Train Loss: 0.4054320 Vali Loss: 0.9698414 Test Loss: 0.4344521
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.7265310287475586
Epoch: 67, Steps: 64 | Train Loss: 0.4063145 Vali Loss: 0.9685402 Test Loss: 0.4344474
Validation loss decreased (0.969276 --> 0.968540).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.722482681274414
Epoch: 68, Steps: 64 | Train Loss: 0.4060256 Vali Loss: 0.9698967 Test Loss: 0.4344650
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.6639375686645508
Epoch: 69, Steps: 64 | Train Loss: 0.4058416 Vali Loss: 0.9690776 Test Loss: 0.4344633
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.9121739864349365
Epoch: 70, Steps: 64 | Train Loss: 0.4060834 Vali Loss: 0.9693555 Test Loss: 0.4344423
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.704465389251709
Epoch: 71, Steps: 64 | Train Loss: 0.4057682 Vali Loss: 0.9697021 Test Loss: 0.4344539
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.862623691558838
Epoch: 72, Steps: 64 | Train Loss: 0.4054676 Vali Loss: 0.9697063 Test Loss: 0.4344533
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.107969045639038
Epoch: 73, Steps: 64 | Train Loss: 0.4058014 Vali Loss: 0.9697493 Test Loss: 0.4344423
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.0014824867248535
Epoch: 74, Steps: 64 | Train Loss: 0.4059671 Vali Loss: 0.9697951 Test Loss: 0.4344545
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.5605828762054443
Epoch: 75, Steps: 64 | Train Loss: 0.4056469 Vali Loss: 0.9698555 Test Loss: 0.4344592
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.9206254482269287
Epoch: 76, Steps: 64 | Train Loss: 0.4056189 Vali Loss: 0.9695374 Test Loss: 0.4344683
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.6787450313568115
Epoch: 77, Steps: 64 | Train Loss: 0.4061977 Vali Loss: 0.9699264 Test Loss: 0.4344531
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.4542629718780518
Epoch: 78, Steps: 64 | Train Loss: 0.4061556 Vali Loss: 0.9699073 Test Loss: 0.4344684
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.9914019107818604
Epoch: 79, Steps: 64 | Train Loss: 0.4059430 Vali Loss: 0.9698769 Test Loss: 0.4344857
EarlyStopping counter: 12 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.2389636039733887
Epoch: 80, Steps: 64 | Train Loss: 0.4061550 Vali Loss: 0.9699712 Test Loss: 0.4344725
EarlyStopping counter: 13 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.8996834754943848
Epoch: 81, Steps: 64 | Train Loss: 0.4061407 Vali Loss: 0.9696343 Test Loss: 0.4344712
EarlyStopping counter: 14 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 2.349707841873169
Epoch: 82, Steps: 64 | Train Loss: 0.4060304 Vali Loss: 0.9698281 Test Loss: 0.4344603
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.9604990482330322
Epoch: 83, Steps: 64 | Train Loss: 0.4058749 Vali Loss: 0.9698939 Test Loss: 0.4344658
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.6702101230621338
Epoch: 84, Steps: 64 | Train Loss: 0.4064579 Vali Loss: 0.9695504 Test Loss: 0.4344677
EarlyStopping counter: 17 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.2654504776000977
Epoch: 85, Steps: 64 | Train Loss: 0.4055026 Vali Loss: 0.9697250 Test Loss: 0.4344735
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 3.3654935359954834
Epoch: 86, Steps: 64 | Train Loss: 0.4058540 Vali Loss: 0.9697593 Test Loss: 0.4344589
EarlyStopping counter: 19 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.8127782344818115
Epoch: 87, Steps: 64 | Train Loss: 0.4061621 Vali Loss: 0.9696118 Test Loss: 0.4344693
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_180_192_FITS_ETTh1_ftM_sl180_ll48_pl192_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.42789795994758606, mae:0.4216311573982239, rse:0.6211943030357361, corr:[0.2637919  0.2687661  0.2692653  0.26771334 0.2655782  0.26333854
 0.26186883 0.2618885  0.26241466 0.26248223 0.26183096 0.26180694
 0.2622481  0.26150307 0.26064086 0.2608176  0.26132786 0.2611807
 0.26056594 0.26015207 0.26016897 0.2604288  0.2605565  0.26016888
 0.2593131  0.25885788 0.25834566 0.2578187  0.2573659  0.25713852
 0.2568033  0.25621262 0.25589183 0.2561604  0.25643143 0.25661686
 0.25678283 0.25683722 0.25687808 0.25690433 0.25704306 0.25740477
 0.25764498 0.25758484 0.25763682 0.2579774  0.25851223 0.2583427
 0.257018   0.25572762 0.25424087 0.2528429  0.25167918 0.2506374
 0.24994662 0.24968903 0.24964496 0.24989949 0.2498406  0.25027636
 0.25080255 0.25052485 0.2501378  0.24994975 0.24995035 0.25000763
 0.25012112 0.25009662 0.25003454 0.2500781  0.25020754 0.24956569
 0.24813014 0.24704029 0.24606551 0.24542436 0.24520272 0.24496214
 0.24465753 0.24431896 0.24413668 0.24421869 0.24390152 0.24371475
 0.24399583 0.2440012  0.24397516 0.24393499 0.24384522 0.24385951
 0.24380048 0.24354498 0.24349752 0.24383181 0.24439828 0.24447493
 0.2436294  0.2428294  0.24218425 0.24147628 0.24102883 0.24076791
 0.24060164 0.24074794 0.24092425 0.24114458 0.24108465 0.24122106
 0.24138491 0.24099003 0.24067478 0.24081704 0.24100716 0.24103805
 0.24103466 0.2410907  0.24117708 0.24121979 0.2411555  0.24067813
 0.23964883 0.23875318 0.23746744 0.23616745 0.23530313 0.23499568
 0.23495144 0.23507924 0.23519842 0.23541702 0.23544648 0.2358751
 0.23657046 0.23659733 0.23649912 0.23643968 0.2364295  0.2365532
 0.23667826 0.23670098 0.23675579 0.23691411 0.23703836 0.23658405
 0.23544057 0.23443912 0.2334697  0.23225787 0.23150437 0.23113203
 0.23109314 0.23115557 0.23149838 0.23193374 0.23199676 0.23232587
 0.2328956  0.23285867 0.23264158 0.23237047 0.2321217  0.23216613
 0.23224384 0.23211887 0.23202334 0.23218518 0.2324296  0.23202932
 0.23090445 0.23009077 0.22927812 0.22842823 0.22803494 0.22793086
 0.22792858 0.22826152 0.22877206 0.22966841 0.23023108 0.23075412
 0.23147705 0.23148885 0.2313431  0.23119763 0.2308139  0.23075445
 0.23111592 0.23136249 0.23108275 0.23079136 0.2315182  0.23192324]
