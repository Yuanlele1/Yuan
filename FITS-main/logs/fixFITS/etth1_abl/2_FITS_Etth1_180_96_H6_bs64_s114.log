Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=58, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_180_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_180_96_FITS_ETTh1_ftM_sl180_ll48_pl96_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8365
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=58, out_features=88, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4573184.0
params:  5192.0
Trainable parameters:  5192
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.1710445880889893
Epoch: 1, Steps: 65 | Train Loss: 0.5768181 Vali Loss: 1.2839876 Test Loss: 0.7317642
Validation loss decreased (inf --> 1.283988).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.1318423748016357
Epoch: 2, Steps: 65 | Train Loss: 0.4308351 Vali Loss: 1.0915048 Test Loss: 0.6036068
Validation loss decreased (1.283988 --> 1.091505).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.027073860168457
Epoch: 3, Steps: 65 | Train Loss: 0.3530112 Vali Loss: 0.9919209 Test Loss: 0.5400826
Validation loss decreased (1.091505 --> 0.991921).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.0763640403747559
Epoch: 4, Steps: 65 | Train Loss: 0.3050167 Vali Loss: 0.9315283 Test Loss: 0.5038707
Validation loss decreased (0.991921 --> 0.931528).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 0.9586281776428223
Epoch: 5, Steps: 65 | Train Loss: 0.2728774 Vali Loss: 0.8955357 Test Loss: 0.4818208
Validation loss decreased (0.931528 --> 0.895536).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.005910873413086
Epoch: 6, Steps: 65 | Train Loss: 0.2502989 Vali Loss: 0.8628681 Test Loss: 0.4674042
Validation loss decreased (0.895536 --> 0.862868).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 0.9325342178344727
Epoch: 7, Steps: 65 | Train Loss: 0.2336120 Vali Loss: 0.8449402 Test Loss: 0.4572574
Validation loss decreased (0.862868 --> 0.844940).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.0178675651550293
Epoch: 8, Steps: 65 | Train Loss: 0.2208328 Vali Loss: 0.8250410 Test Loss: 0.4496450
Validation loss decreased (0.844940 --> 0.825041).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.0346014499664307
Epoch: 9, Steps: 65 | Train Loss: 0.2105208 Vali Loss: 0.8163167 Test Loss: 0.4432519
Validation loss decreased (0.825041 --> 0.816317).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.040970802307129
Epoch: 10, Steps: 65 | Train Loss: 0.2024894 Vali Loss: 0.8070397 Test Loss: 0.4392138
Validation loss decreased (0.816317 --> 0.807040).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.06864333152771
Epoch: 11, Steps: 65 | Train Loss: 0.1955441 Vali Loss: 0.8013309 Test Loss: 0.4350770
Validation loss decreased (0.807040 --> 0.801331).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.0929772853851318
Epoch: 12, Steps: 65 | Train Loss: 0.1897456 Vali Loss: 0.7954181 Test Loss: 0.4318309
Validation loss decreased (0.801331 --> 0.795418).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.061264991760254
Epoch: 13, Steps: 65 | Train Loss: 0.1848026 Vali Loss: 0.7894832 Test Loss: 0.4290332
Validation loss decreased (0.795418 --> 0.789483).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.1421608924865723
Epoch: 14, Steps: 65 | Train Loss: 0.1805312 Vali Loss: 0.7805389 Test Loss: 0.4266686
Validation loss decreased (0.789483 --> 0.780539).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.0953986644744873
Epoch: 15, Steps: 65 | Train Loss: 0.1766687 Vali Loss: 0.7744978 Test Loss: 0.4243085
Validation loss decreased (0.780539 --> 0.774498).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.0772004127502441
Epoch: 16, Steps: 65 | Train Loss: 0.1734319 Vali Loss: 0.7764844 Test Loss: 0.4224212
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.1591753959655762
Epoch: 17, Steps: 65 | Train Loss: 0.1705934 Vali Loss: 0.7735817 Test Loss: 0.4205374
Validation loss decreased (0.774498 --> 0.773582).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 0.9996922016143799
Epoch: 18, Steps: 65 | Train Loss: 0.1680282 Vali Loss: 0.7637401 Test Loss: 0.4189756
Validation loss decreased (0.773582 --> 0.763740).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.088385820388794
Epoch: 19, Steps: 65 | Train Loss: 0.1657876 Vali Loss: 0.7657140 Test Loss: 0.4175395
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 0.930246114730835
Epoch: 20, Steps: 65 | Train Loss: 0.1637811 Vali Loss: 0.7638335 Test Loss: 0.4161252
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.1338648796081543
Epoch: 21, Steps: 65 | Train Loss: 0.1618835 Vali Loss: 0.7612897 Test Loss: 0.4150234
Validation loss decreased (0.763740 --> 0.761290).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.240891933441162
Epoch: 22, Steps: 65 | Train Loss: 0.1601920 Vali Loss: 0.7621641 Test Loss: 0.4141078
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.2282707691192627
Epoch: 23, Steps: 65 | Train Loss: 0.1586999 Vali Loss: 0.7544914 Test Loss: 0.4128923
Validation loss decreased (0.761290 --> 0.754491).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.013338565826416
Epoch: 24, Steps: 65 | Train Loss: 0.1574311 Vali Loss: 0.7534388 Test Loss: 0.4118913
Validation loss decreased (0.754491 --> 0.753439).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 0.9968321323394775
Epoch: 25, Steps: 65 | Train Loss: 0.1561877 Vali Loss: 0.7498136 Test Loss: 0.4111239
Validation loss decreased (0.753439 --> 0.749814).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 0.9424121379852295
Epoch: 26, Steps: 65 | Train Loss: 0.1551100 Vali Loss: 0.7484538 Test Loss: 0.4102772
Validation loss decreased (0.749814 --> 0.748454).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 0.9906971454620361
Epoch: 27, Steps: 65 | Train Loss: 0.1541671 Vali Loss: 0.7508494 Test Loss: 0.4095406
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 0.9257111549377441
Epoch: 28, Steps: 65 | Train Loss: 0.1530364 Vali Loss: 0.7484170 Test Loss: 0.4089004
Validation loss decreased (0.748454 --> 0.748417).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.026597261428833
Epoch: 29, Steps: 65 | Train Loss: 0.1522774 Vali Loss: 0.7468318 Test Loss: 0.4082845
Validation loss decreased (0.748417 --> 0.746832).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 0.9356927871704102
Epoch: 30, Steps: 65 | Train Loss: 0.1514939 Vali Loss: 0.7480292 Test Loss: 0.4077067
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 0.9667198657989502
Epoch: 31, Steps: 65 | Train Loss: 0.1507725 Vali Loss: 0.7439140 Test Loss: 0.4071302
Validation loss decreased (0.746832 --> 0.743914).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.0184593200683594
Epoch: 32, Steps: 65 | Train Loss: 0.1499991 Vali Loss: 0.7430002 Test Loss: 0.4066871
Validation loss decreased (0.743914 --> 0.743000).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.015273094177246
Epoch: 33, Steps: 65 | Train Loss: 0.1493866 Vali Loss: 0.7429179 Test Loss: 0.4061475
Validation loss decreased (0.743000 --> 0.742918).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 0.9167754650115967
Epoch: 34, Steps: 65 | Train Loss: 0.1488366 Vali Loss: 0.7447078 Test Loss: 0.4056778
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 0.9586060047149658
Epoch: 35, Steps: 65 | Train Loss: 0.1484366 Vali Loss: 0.7431567 Test Loss: 0.4053129
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 0.8719964027404785
Epoch: 36, Steps: 65 | Train Loss: 0.1479137 Vali Loss: 0.7383726 Test Loss: 0.4048967
Validation loss decreased (0.742918 --> 0.738373).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.034287452697754
Epoch: 37, Steps: 65 | Train Loss: 0.1473288 Vali Loss: 0.7429596 Test Loss: 0.4045417
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.0028643608093262
Epoch: 38, Steps: 65 | Train Loss: 0.1470280 Vali Loss: 0.7403197 Test Loss: 0.4042100
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.1136753559112549
Epoch: 39, Steps: 65 | Train Loss: 0.1465983 Vali Loss: 0.7400572 Test Loss: 0.4038112
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 0.9623401165008545
Epoch: 40, Steps: 65 | Train Loss: 0.1461877 Vali Loss: 0.7387738 Test Loss: 0.4035377
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.0602972507476807
Epoch: 41, Steps: 65 | Train Loss: 0.1458126 Vali Loss: 0.7370704 Test Loss: 0.4032540
Validation loss decreased (0.738373 --> 0.737070).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.004591464996338
Epoch: 42, Steps: 65 | Train Loss: 0.1455401 Vali Loss: 0.7346226 Test Loss: 0.4030019
Validation loss decreased (0.737070 --> 0.734623).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 0.9397411346435547
Epoch: 43, Steps: 65 | Train Loss: 0.1452674 Vali Loss: 0.7344152 Test Loss: 0.4027242
Validation loss decreased (0.734623 --> 0.734415).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.0869617462158203
Epoch: 44, Steps: 65 | Train Loss: 0.1448867 Vali Loss: 0.7343168 Test Loss: 0.4024445
Validation loss decreased (0.734415 --> 0.734317).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.0990679264068604
Epoch: 45, Steps: 65 | Train Loss: 0.1447020 Vali Loss: 0.7346029 Test Loss: 0.4022364
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.0365517139434814
Epoch: 46, Steps: 65 | Train Loss: 0.1445041 Vali Loss: 0.7372388 Test Loss: 0.4019850
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.1047134399414062
Epoch: 47, Steps: 65 | Train Loss: 0.1442490 Vali Loss: 0.7342547 Test Loss: 0.4017770
Validation loss decreased (0.734317 --> 0.734255).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 0.993488073348999
Epoch: 48, Steps: 65 | Train Loss: 0.1440175 Vali Loss: 0.7359660 Test Loss: 0.4016275
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.0403013229370117
Epoch: 49, Steps: 65 | Train Loss: 0.1436783 Vali Loss: 0.7358346 Test Loss: 0.4014096
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.0410411357879639
Epoch: 50, Steps: 65 | Train Loss: 0.1435221 Vali Loss: 0.7347583 Test Loss: 0.4012352
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.0419368743896484
Epoch: 51, Steps: 65 | Train Loss: 0.1432961 Vali Loss: 0.7306463 Test Loss: 0.4010690
Validation loss decreased (0.734255 --> 0.730646).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 0.9943070411682129
Epoch: 52, Steps: 65 | Train Loss: 0.1432023 Vali Loss: 0.7316782 Test Loss: 0.4009274
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 0.9125304222106934
Epoch: 53, Steps: 65 | Train Loss: 0.1430874 Vali Loss: 0.7369473 Test Loss: 0.4007919
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 0.9843685626983643
Epoch: 54, Steps: 65 | Train Loss: 0.1429065 Vali Loss: 0.7329980 Test Loss: 0.4006333
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 0.9771687984466553
Epoch: 55, Steps: 65 | Train Loss: 0.1427559 Vali Loss: 0.7325965 Test Loss: 0.4004734
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.064901351928711
Epoch: 56, Steps: 65 | Train Loss: 0.1426357 Vali Loss: 0.7326074 Test Loss: 0.4003562
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.0731210708618164
Epoch: 57, Steps: 65 | Train Loss: 0.1423656 Vali Loss: 0.7332493 Test Loss: 0.4002360
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.012556791305542
Epoch: 58, Steps: 65 | Train Loss: 0.1422435 Vali Loss: 0.7358012 Test Loss: 0.4001245
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.1343939304351807
Epoch: 59, Steps: 65 | Train Loss: 0.1422567 Vali Loss: 0.7321563 Test Loss: 0.4000013
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.0678472518920898
Epoch: 60, Steps: 65 | Train Loss: 0.1420153 Vali Loss: 0.7308800 Test Loss: 0.3998998
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.0555274486541748
Epoch: 61, Steps: 65 | Train Loss: 0.1419810 Vali Loss: 0.7278423 Test Loss: 0.3998046
Validation loss decreased (0.730646 --> 0.727842).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 0.93015456199646
Epoch: 62, Steps: 65 | Train Loss: 0.1418546 Vali Loss: 0.7354549 Test Loss: 0.3997156
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.0362379550933838
Epoch: 63, Steps: 65 | Train Loss: 0.1417452 Vali Loss: 0.7253063 Test Loss: 0.3996102
Validation loss decreased (0.727842 --> 0.725306).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.0291800498962402
Epoch: 64, Steps: 65 | Train Loss: 0.1416230 Vali Loss: 0.7279966 Test Loss: 0.3995292
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.0738554000854492
Epoch: 65, Steps: 65 | Train Loss: 0.1415532 Vali Loss: 0.7342986 Test Loss: 0.3994378
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.0535666942596436
Epoch: 66, Steps: 65 | Train Loss: 0.1415025 Vali Loss: 0.7296331 Test Loss: 0.3993604
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.0373194217681885
Epoch: 67, Steps: 65 | Train Loss: 0.1412290 Vali Loss: 0.7345086 Test Loss: 0.3992829
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 0.9912774562835693
Epoch: 68, Steps: 65 | Train Loss: 0.1413256 Vali Loss: 0.7308673 Test Loss: 0.3992248
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.0579750537872314
Epoch: 69, Steps: 65 | Train Loss: 0.1412165 Vali Loss: 0.7310395 Test Loss: 0.3991508
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.0795111656188965
Epoch: 70, Steps: 65 | Train Loss: 0.1411105 Vali Loss: 0.7272354 Test Loss: 0.3990856
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.0791997909545898
Epoch: 71, Steps: 65 | Train Loss: 0.1411170 Vali Loss: 0.7243135 Test Loss: 0.3990301
Validation loss decreased (0.725306 --> 0.724313).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.0095634460449219
Epoch: 72, Steps: 65 | Train Loss: 0.1410506 Vali Loss: 0.7310705 Test Loss: 0.3989642
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.0412800312042236
Epoch: 73, Steps: 65 | Train Loss: 0.1410191 Vali Loss: 0.7285402 Test Loss: 0.3989090
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.037238359451294
Epoch: 74, Steps: 65 | Train Loss: 0.1410125 Vali Loss: 0.7279540 Test Loss: 0.3988540
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 0.9702146053314209
Epoch: 75, Steps: 65 | Train Loss: 0.1408587 Vali Loss: 0.7317137 Test Loss: 0.3988016
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.155463695526123
Epoch: 76, Steps: 65 | Train Loss: 0.1408076 Vali Loss: 0.7252726 Test Loss: 0.3987592
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.0244712829589844
Epoch: 77, Steps: 65 | Train Loss: 0.1406962 Vali Loss: 0.7293985 Test Loss: 0.3987117
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 0.9630959033966064
Epoch: 78, Steps: 65 | Train Loss: 0.1407047 Vali Loss: 0.7293057 Test Loss: 0.3986665
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.0534403324127197
Epoch: 79, Steps: 65 | Train Loss: 0.1406585 Vali Loss: 0.7304899 Test Loss: 0.3986326
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 0.9710972309112549
Epoch: 80, Steps: 65 | Train Loss: 0.1405066 Vali Loss: 0.7307531 Test Loss: 0.3985884
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.0214033126831055
Epoch: 81, Steps: 65 | Train Loss: 0.1406296 Vali Loss: 0.7255216 Test Loss: 0.3985669
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 0.987196683883667
Epoch: 82, Steps: 65 | Train Loss: 0.1406218 Vali Loss: 0.7279569 Test Loss: 0.3985202
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.1250321865081787
Epoch: 83, Steps: 65 | Train Loss: 0.1404794 Vali Loss: 0.7295026 Test Loss: 0.3984954
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.1420214176177979
Epoch: 84, Steps: 65 | Train Loss: 0.1405236 Vali Loss: 0.7283393 Test Loss: 0.3984541
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.0775177478790283
Epoch: 85, Steps: 65 | Train Loss: 0.1405428 Vali Loss: 0.7276763 Test Loss: 0.3984320
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.0524299144744873
Epoch: 86, Steps: 65 | Train Loss: 0.1401407 Vali Loss: 0.7267541 Test Loss: 0.3983971
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.0998046398162842
Epoch: 87, Steps: 65 | Train Loss: 0.1404374 Vali Loss: 0.7308686 Test Loss: 0.3983648
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.125450611114502
Epoch: 88, Steps: 65 | Train Loss: 0.1403285 Vali Loss: 0.7322578 Test Loss: 0.3983427
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.0340869426727295
Epoch: 89, Steps: 65 | Train Loss: 0.1404529 Vali Loss: 0.7303416 Test Loss: 0.3983152
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 0.9908170700073242
Epoch: 90, Steps: 65 | Train Loss: 0.1404388 Vali Loss: 0.7304359 Test Loss: 0.3982961
EarlyStopping counter: 19 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 0.9992079734802246
Epoch: 91, Steps: 65 | Train Loss: 0.1402727 Vali Loss: 0.7262065 Test Loss: 0.3982750
EarlyStopping counter: 20 out of 20
Early stopping
train 8365
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=58, out_features=88, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4573184.0
params:  5192.0
Trainable parameters:  5192
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 0.9719712734222412
Epoch: 1, Steps: 65 | Train Loss: 0.3545659 Vali Loss: 0.7143051 Test Loss: 0.3879473
Validation loss decreased (inf --> 0.714305).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.0844793319702148
Epoch: 2, Steps: 65 | Train Loss: 0.3500213 Vali Loss: 0.7103597 Test Loss: 0.3846898
Validation loss decreased (0.714305 --> 0.710360).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.0580837726593018
Epoch: 3, Steps: 65 | Train Loss: 0.3482125 Vali Loss: 0.7020380 Test Loss: 0.3836750
Validation loss decreased (0.710360 --> 0.702038).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.032886028289795
Epoch: 4, Steps: 65 | Train Loss: 0.3476389 Vali Loss: 0.7097067 Test Loss: 0.3834202
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.0511269569396973
Epoch: 5, Steps: 65 | Train Loss: 0.3474434 Vali Loss: 0.7075851 Test Loss: 0.3825665
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.0987038612365723
Epoch: 6, Steps: 65 | Train Loss: 0.3468504 Vali Loss: 0.7054572 Test Loss: 0.3826734
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 0.9704291820526123
Epoch: 7, Steps: 65 | Train Loss: 0.3469300 Vali Loss: 0.7033184 Test Loss: 0.3830085
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.068432092666626
Epoch: 8, Steps: 65 | Train Loss: 0.3467287 Vali Loss: 0.6997229 Test Loss: 0.3824545
Validation loss decreased (0.702038 --> 0.699723).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.027864694595337
Epoch: 9, Steps: 65 | Train Loss: 0.3462563 Vali Loss: 0.7066491 Test Loss: 0.3822260
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.287825345993042
Epoch: 10, Steps: 65 | Train Loss: 0.3461839 Vali Loss: 0.7064881 Test Loss: 0.3823563
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.2123026847839355
Epoch: 11, Steps: 65 | Train Loss: 0.3467505 Vali Loss: 0.7057775 Test Loss: 0.3824589
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.0765740871429443
Epoch: 12, Steps: 65 | Train Loss: 0.3463602 Vali Loss: 0.7065137 Test Loss: 0.3820397
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.1213321685791016
Epoch: 13, Steps: 65 | Train Loss: 0.3461120 Vali Loss: 0.6998779 Test Loss: 0.3820572
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.0058977603912354
Epoch: 14, Steps: 65 | Train Loss: 0.3464683 Vali Loss: 0.6992240 Test Loss: 0.3821475
Validation loss decreased (0.699723 --> 0.699224).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.0280959606170654
Epoch: 15, Steps: 65 | Train Loss: 0.3456852 Vali Loss: 0.7058762 Test Loss: 0.3820972
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.2356603145599365
Epoch: 16, Steps: 65 | Train Loss: 0.3461695 Vali Loss: 0.7047973 Test Loss: 0.3820358
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.132418155670166
Epoch: 17, Steps: 65 | Train Loss: 0.3461777 Vali Loss: 0.7037083 Test Loss: 0.3818577
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.0608816146850586
Epoch: 18, Steps: 65 | Train Loss: 0.3458469 Vali Loss: 0.7030917 Test Loss: 0.3823324
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 0.9720718860626221
Epoch: 19, Steps: 65 | Train Loss: 0.3456989 Vali Loss: 0.7027292 Test Loss: 0.3817790
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.1635088920593262
Epoch: 20, Steps: 65 | Train Loss: 0.3460718 Vali Loss: 0.7006680 Test Loss: 0.3817409
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.0028154850006104
Epoch: 21, Steps: 65 | Train Loss: 0.3458528 Vali Loss: 0.7021907 Test Loss: 0.3818292
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.1138272285461426
Epoch: 22, Steps: 65 | Train Loss: 0.3459444 Vali Loss: 0.7013977 Test Loss: 0.3818094
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.0209541320800781
Epoch: 23, Steps: 65 | Train Loss: 0.3460531 Vali Loss: 0.7033449 Test Loss: 0.3818974
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.0991158485412598
Epoch: 24, Steps: 65 | Train Loss: 0.3460181 Vali Loss: 0.6997615 Test Loss: 0.3819653
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.051645040512085
Epoch: 25, Steps: 65 | Train Loss: 0.3459840 Vali Loss: 0.6991770 Test Loss: 0.3817717
Validation loss decreased (0.699224 --> 0.699177).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 0.9680507183074951
Epoch: 26, Steps: 65 | Train Loss: 0.3456461 Vali Loss: 0.7010427 Test Loss: 0.3819043
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.048579454421997
Epoch: 27, Steps: 65 | Train Loss: 0.3455892 Vali Loss: 0.7032058 Test Loss: 0.3818027
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.114166021347046
Epoch: 28, Steps: 65 | Train Loss: 0.3459764 Vali Loss: 0.7038190 Test Loss: 0.3818871
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 0.9248383045196533
Epoch: 29, Steps: 65 | Train Loss: 0.3456229 Vali Loss: 0.7005023 Test Loss: 0.3818767
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 0.9883756637573242
Epoch: 30, Steps: 65 | Train Loss: 0.3456226 Vali Loss: 0.7031453 Test Loss: 0.3818182
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 0.9276528358459473
Epoch: 31, Steps: 65 | Train Loss: 0.3458113 Vali Loss: 0.7029213 Test Loss: 0.3818376
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 0.9987547397613525
Epoch: 32, Steps: 65 | Train Loss: 0.3455401 Vali Loss: 0.7010821 Test Loss: 0.3817692
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.0659191608428955
Epoch: 33, Steps: 65 | Train Loss: 0.3455330 Vali Loss: 0.7020406 Test Loss: 0.3818135
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 0.9665639400482178
Epoch: 34, Steps: 65 | Train Loss: 0.3456680 Vali Loss: 0.6986670 Test Loss: 0.3817993
Validation loss decreased (0.699177 --> 0.698667).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.0184338092803955
Epoch: 35, Steps: 65 | Train Loss: 0.3456668 Vali Loss: 0.6965523 Test Loss: 0.3819301
Validation loss decreased (0.698667 --> 0.696552).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.0018703937530518
Epoch: 36, Steps: 65 | Train Loss: 0.3456022 Vali Loss: 0.6969369 Test Loss: 0.3817966
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.0506377220153809
Epoch: 37, Steps: 65 | Train Loss: 0.3457417 Vali Loss: 0.6991779 Test Loss: 0.3818930
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.0808815956115723
Epoch: 38, Steps: 65 | Train Loss: 0.3458565 Vali Loss: 0.6979591 Test Loss: 0.3818230
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.003720998764038
Epoch: 39, Steps: 65 | Train Loss: 0.3456869 Vali Loss: 0.7014784 Test Loss: 0.3818628
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.0765759944915771
Epoch: 40, Steps: 65 | Train Loss: 0.3455636 Vali Loss: 0.6995273 Test Loss: 0.3818303
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.186410665512085
Epoch: 41, Steps: 65 | Train Loss: 0.3454146 Vali Loss: 0.7028748 Test Loss: 0.3818478
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.2582933902740479
Epoch: 42, Steps: 65 | Train Loss: 0.3457491 Vali Loss: 0.7023730 Test Loss: 0.3818902
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.0646610260009766
Epoch: 43, Steps: 65 | Train Loss: 0.3453190 Vali Loss: 0.7025980 Test Loss: 0.3818655
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.0264384746551514
Epoch: 44, Steps: 65 | Train Loss: 0.3456863 Vali Loss: 0.7056348 Test Loss: 0.3818490
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.1489853858947754
Epoch: 45, Steps: 65 | Train Loss: 0.3458155 Vali Loss: 0.7015332 Test Loss: 0.3818773
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.0983366966247559
Epoch: 46, Steps: 65 | Train Loss: 0.3457474 Vali Loss: 0.7026908 Test Loss: 0.3818799
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.028416395187378
Epoch: 47, Steps: 65 | Train Loss: 0.3455104 Vali Loss: 0.7065729 Test Loss: 0.3818555
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.0014643669128418
Epoch: 48, Steps: 65 | Train Loss: 0.3452366 Vali Loss: 0.7041862 Test Loss: 0.3818804
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 0.9958584308624268
Epoch: 49, Steps: 65 | Train Loss: 0.3451211 Vali Loss: 0.6990644 Test Loss: 0.3818456
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.0428009033203125
Epoch: 50, Steps: 65 | Train Loss: 0.3454541 Vali Loss: 0.7023693 Test Loss: 0.3818494
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 0.9793188571929932
Epoch: 51, Steps: 65 | Train Loss: 0.3455953 Vali Loss: 0.7015547 Test Loss: 0.3819027
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.030517339706421
Epoch: 52, Steps: 65 | Train Loss: 0.3457305 Vali Loss: 0.7023882 Test Loss: 0.3818792
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 0.9237830638885498
Epoch: 53, Steps: 65 | Train Loss: 0.3456993 Vali Loss: 0.7014527 Test Loss: 0.3818991
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.087066888809204
Epoch: 54, Steps: 65 | Train Loss: 0.3455242 Vali Loss: 0.7014810 Test Loss: 0.3818582
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.0246338844299316
Epoch: 55, Steps: 65 | Train Loss: 0.3455788 Vali Loss: 0.7000087 Test Loss: 0.3818894
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_180_96_FITS_ETTh1_ftM_sl180_ll48_pl96_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.3812185525894165, mae:0.3955332338809967, rse:0.5864686965942383, corr:[0.27168068 0.27727717 0.27654535 0.27706492 0.27486056 0.2716465
 0.27105576 0.27122685 0.2706711  0.27110568 0.27072066 0.2703493
 0.27086323 0.2702981  0.26990303 0.2702048  0.27014586 0.2699554
 0.2699302  0.26944834 0.2689066  0.26897886 0.26939115 0.26930267
 0.26849234 0.26778874 0.26718515 0.26695073 0.2663805  0.26582396
 0.26575223 0.26546705 0.26486132 0.26496297 0.26526478 0.26527312
 0.265423   0.2654504  0.26521483 0.2651965  0.26565063 0.2658993
 0.2659286  0.26610574 0.2662378  0.26635513 0.26690525 0.267054
 0.26606527 0.26464078 0.26291636 0.26180398 0.2607675  0.25939253
 0.25872752 0.2586285  0.25835148 0.2586545  0.25877455 0.2591999
 0.25958034 0.25938538 0.25912195 0.25891232 0.25893307 0.25899205
 0.25916642 0.25918332 0.25894517 0.25886947 0.25903222 0.25847605
 0.25728366 0.25619662 0.2548793  0.2543588  0.25413102 0.25355455
 0.25330666 0.2532022  0.25284678 0.25284928 0.2527038  0.25274932
 0.2528259  0.25245163 0.25262776 0.25259432 0.2520618  0.25201043
 0.2521171  0.25147477 0.25107062 0.2510001  0.2511397  0.25289777]
