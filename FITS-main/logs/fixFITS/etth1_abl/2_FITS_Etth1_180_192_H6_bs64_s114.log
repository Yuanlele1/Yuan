Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=58, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_180_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_180_192_FITS_ETTh1_ftM_sl180_ll48_pl192_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8269
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=58, out_features=119, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6184192.0
params:  7021.0
Trainable parameters:  7021
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.0666136741638184
Epoch: 1, Steps: 64 | Train Loss: 0.7086217 Vali Loss: 1.6228342 Test Loss: 0.8776724
Validation loss decreased (inf --> 1.622834).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.1724610328674316
Epoch: 2, Steps: 64 | Train Loss: 0.5392797 Vali Loss: 1.4187555 Test Loss: 0.7397700
Validation loss decreased (1.622834 --> 1.418756).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.205627202987671
Epoch: 3, Steps: 64 | Train Loss: 0.4514614 Vali Loss: 1.3067256 Test Loss: 0.6648886
Validation loss decreased (1.418756 --> 1.306726).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.1455814838409424
Epoch: 4, Steps: 64 | Train Loss: 0.3987512 Vali Loss: 1.2350180 Test Loss: 0.6178743
Validation loss decreased (1.306726 --> 1.235018).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.2540631294250488
Epoch: 5, Steps: 64 | Train Loss: 0.3645833 Vali Loss: 1.1885405 Test Loss: 0.5881014
Validation loss decreased (1.235018 --> 1.188540).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.1751275062561035
Epoch: 6, Steps: 64 | Train Loss: 0.3404693 Vali Loss: 1.1556937 Test Loss: 0.5671334
Validation loss decreased (1.188540 --> 1.155694).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.1206378936767578
Epoch: 7, Steps: 64 | Train Loss: 0.3232938 Vali Loss: 1.1315457 Test Loss: 0.5523859
Validation loss decreased (1.155694 --> 1.131546).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.0893871784210205
Epoch: 8, Steps: 64 | Train Loss: 0.3104492 Vali Loss: 1.1128061 Test Loss: 0.5410170
Validation loss decreased (1.131546 --> 1.112806).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.0069684982299805
Epoch: 9, Steps: 64 | Train Loss: 0.3000944 Vali Loss: 1.0990509 Test Loss: 0.5327349
Validation loss decreased (1.112806 --> 1.099051).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.0803349018096924
Epoch: 10, Steps: 64 | Train Loss: 0.2921517 Vali Loss: 1.0875345 Test Loss: 0.5255102
Validation loss decreased (1.099051 --> 1.087535).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.049835205078125
Epoch: 11, Steps: 64 | Train Loss: 0.2852559 Vali Loss: 1.0774758 Test Loss: 0.5195202
Validation loss decreased (1.087535 --> 1.077476).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.0843229293823242
Epoch: 12, Steps: 64 | Train Loss: 0.2796849 Vali Loss: 1.0695890 Test Loss: 0.5142879
Validation loss decreased (1.077476 --> 1.069589).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.1559200286865234
Epoch: 13, Steps: 64 | Train Loss: 0.2747882 Vali Loss: 1.0629408 Test Loss: 0.5099475
Validation loss decreased (1.069589 --> 1.062941).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 0.9561657905578613
Epoch: 14, Steps: 64 | Train Loss: 0.2705190 Vali Loss: 1.0568258 Test Loss: 0.5060754
Validation loss decreased (1.062941 --> 1.056826).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.166234016418457
Epoch: 15, Steps: 64 | Train Loss: 0.2668116 Vali Loss: 1.0520741 Test Loss: 0.5026331
Validation loss decreased (1.056826 --> 1.052074).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.0938286781311035
Epoch: 16, Steps: 64 | Train Loss: 0.2636982 Vali Loss: 1.0476347 Test Loss: 0.4995722
Validation loss decreased (1.052074 --> 1.047635).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 0.9609768390655518
Epoch: 17, Steps: 64 | Train Loss: 0.2611467 Vali Loss: 1.0425564 Test Loss: 0.4966685
Validation loss decreased (1.047635 --> 1.042556).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.270019769668579
Epoch: 18, Steps: 64 | Train Loss: 0.2583907 Vali Loss: 1.0394746 Test Loss: 0.4940006
Validation loss decreased (1.042556 --> 1.039475).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.0921857357025146
Epoch: 19, Steps: 64 | Train Loss: 0.2563292 Vali Loss: 1.0356183 Test Loss: 0.4916900
Validation loss decreased (1.039475 --> 1.035618).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.0395569801330566
Epoch: 20, Steps: 64 | Train Loss: 0.2542608 Vali Loss: 1.0328220 Test Loss: 0.4893872
Validation loss decreased (1.035618 --> 1.032822).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.0799472332000732
Epoch: 21, Steps: 64 | Train Loss: 0.2524053 Vali Loss: 1.0306031 Test Loss: 0.4873891
Validation loss decreased (1.032822 --> 1.030603).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.2093069553375244
Epoch: 22, Steps: 64 | Train Loss: 0.2506953 Vali Loss: 1.0278009 Test Loss: 0.4855765
Validation loss decreased (1.030603 --> 1.027801).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.0007054805755615
Epoch: 23, Steps: 64 | Train Loss: 0.2488620 Vali Loss: 1.0257307 Test Loss: 0.4838148
Validation loss decreased (1.027801 --> 1.025731).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.1340675354003906
Epoch: 24, Steps: 64 | Train Loss: 0.2480603 Vali Loss: 1.0232873 Test Loss: 0.4822679
Validation loss decreased (1.025731 --> 1.023287).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.1056294441223145
Epoch: 25, Steps: 64 | Train Loss: 0.2469213 Vali Loss: 1.0218401 Test Loss: 0.4807334
Validation loss decreased (1.023287 --> 1.021840).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.0911555290222168
Epoch: 26, Steps: 64 | Train Loss: 0.2455088 Vali Loss: 1.0196298 Test Loss: 0.4794306
Validation loss decreased (1.021840 --> 1.019630).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.0655810832977295
Epoch: 27, Steps: 64 | Train Loss: 0.2445488 Vali Loss: 1.0185103 Test Loss: 0.4781548
Validation loss decreased (1.019630 --> 1.018510).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.3636562824249268
Epoch: 28, Steps: 64 | Train Loss: 0.2433907 Vali Loss: 1.0167848 Test Loss: 0.4768491
Validation loss decreased (1.018510 --> 1.016785).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.2430989742279053
Epoch: 29, Steps: 64 | Train Loss: 0.2425719 Vali Loss: 1.0154016 Test Loss: 0.4757563
Validation loss decreased (1.016785 --> 1.015402).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.1869211196899414
Epoch: 30, Steps: 64 | Train Loss: 0.2419675 Vali Loss: 1.0139841 Test Loss: 0.4747436
Validation loss decreased (1.015402 --> 1.013984).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.0139143466949463
Epoch: 31, Steps: 64 | Train Loss: 0.2410682 Vali Loss: 1.0128014 Test Loss: 0.4737641
Validation loss decreased (1.013984 --> 1.012801).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.3146438598632812
Epoch: 32, Steps: 64 | Train Loss: 0.2403572 Vali Loss: 1.0113313 Test Loss: 0.4728177
Validation loss decreased (1.012801 --> 1.011331).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.272294521331787
Epoch: 33, Steps: 64 | Train Loss: 0.2398716 Vali Loss: 1.0102648 Test Loss: 0.4719459
Validation loss decreased (1.011331 --> 1.010265).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.2382354736328125
Epoch: 34, Steps: 64 | Train Loss: 0.2389963 Vali Loss: 1.0093971 Test Loss: 0.4711517
Validation loss decreased (1.010265 --> 1.009397).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.223761796951294
Epoch: 35, Steps: 64 | Train Loss: 0.2382162 Vali Loss: 1.0085604 Test Loss: 0.4703784
Validation loss decreased (1.009397 --> 1.008560).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.1233532428741455
Epoch: 36, Steps: 64 | Train Loss: 0.2378120 Vali Loss: 1.0075095 Test Loss: 0.4696679
Validation loss decreased (1.008560 --> 1.007509).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.2027249336242676
Epoch: 37, Steps: 64 | Train Loss: 0.2375882 Vali Loss: 1.0066979 Test Loss: 0.4689759
Validation loss decreased (1.007509 --> 1.006698).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.2880301475524902
Epoch: 38, Steps: 64 | Train Loss: 0.2371957 Vali Loss: 1.0056866 Test Loss: 0.4683324
Validation loss decreased (1.006698 --> 1.005687).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.1585423946380615
Epoch: 39, Steps: 64 | Train Loss: 0.2367459 Vali Loss: 1.0052011 Test Loss: 0.4677005
Validation loss decreased (1.005687 --> 1.005201).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.195981502532959
Epoch: 40, Steps: 64 | Train Loss: 0.2361233 Vali Loss: 1.0044739 Test Loss: 0.4672132
Validation loss decreased (1.005201 --> 1.004474).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.2953441143035889
Epoch: 41, Steps: 64 | Train Loss: 0.2357869 Vali Loss: 1.0042078 Test Loss: 0.4666789
Validation loss decreased (1.004474 --> 1.004208).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.301095724105835
Epoch: 42, Steps: 64 | Train Loss: 0.2355883 Vali Loss: 1.0035444 Test Loss: 0.4661684
Validation loss decreased (1.004208 --> 1.003544).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.3604555130004883
Epoch: 43, Steps: 64 | Train Loss: 0.2351860 Vali Loss: 1.0029340 Test Loss: 0.4656883
Validation loss decreased (1.003544 --> 1.002934).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 0.983306884765625
Epoch: 44, Steps: 64 | Train Loss: 0.2346985 Vali Loss: 1.0022196 Test Loss: 0.4652438
Validation loss decreased (1.002934 --> 1.002220).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.0789909362792969
Epoch: 45, Steps: 64 | Train Loss: 0.2344453 Vali Loss: 1.0015415 Test Loss: 0.4648778
Validation loss decreased (1.002220 --> 1.001541).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.1193349361419678
Epoch: 46, Steps: 64 | Train Loss: 0.2342283 Vali Loss: 1.0010686 Test Loss: 0.4644936
Validation loss decreased (1.001541 --> 1.001069).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.1341958045959473
Epoch: 47, Steps: 64 | Train Loss: 0.2340612 Vali Loss: 1.0010079 Test Loss: 0.4640492
Validation loss decreased (1.001069 --> 1.001008).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.083951711654663
Epoch: 48, Steps: 64 | Train Loss: 0.2338792 Vali Loss: 1.0002146 Test Loss: 0.4637172
Validation loss decreased (1.001008 --> 1.000215).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.1399011611938477
Epoch: 49, Steps: 64 | Train Loss: 0.2336112 Vali Loss: 1.0001978 Test Loss: 0.4634176
Validation loss decreased (1.000215 --> 1.000198).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.240025520324707
Epoch: 50, Steps: 64 | Train Loss: 0.2331646 Vali Loss: 0.9994242 Test Loss: 0.4630817
Validation loss decreased (1.000198 --> 0.999424).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.123133897781372
Epoch: 51, Steps: 64 | Train Loss: 0.2331216 Vali Loss: 0.9994181 Test Loss: 0.4627765
Validation loss decreased (0.999424 --> 0.999418).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 0.9510750770568848
Epoch: 52, Steps: 64 | Train Loss: 0.2329339 Vali Loss: 0.9987712 Test Loss: 0.4624873
Validation loss decreased (0.999418 --> 0.998771).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.0428435802459717
Epoch: 53, Steps: 64 | Train Loss: 0.2328355 Vali Loss: 0.9983992 Test Loss: 0.4622389
Validation loss decreased (0.998771 --> 0.998399).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.1850404739379883
Epoch: 54, Steps: 64 | Train Loss: 0.2324589 Vali Loss: 0.9985538 Test Loss: 0.4619884
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.1716089248657227
Epoch: 55, Steps: 64 | Train Loss: 0.2325873 Vali Loss: 0.9980530 Test Loss: 0.4617515
Validation loss decreased (0.998399 --> 0.998053).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.137754201889038
Epoch: 56, Steps: 64 | Train Loss: 0.2320376 Vali Loss: 0.9974662 Test Loss: 0.4615453
Validation loss decreased (0.998053 --> 0.997466).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.1084442138671875
Epoch: 57, Steps: 64 | Train Loss: 0.2320091 Vali Loss: 0.9972607 Test Loss: 0.4612917
Validation loss decreased (0.997466 --> 0.997261).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.1695654392242432
Epoch: 58, Steps: 64 | Train Loss: 0.2318530 Vali Loss: 0.9974490 Test Loss: 0.4610877
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.142076015472412
Epoch: 59, Steps: 64 | Train Loss: 0.2318542 Vali Loss: 0.9967877 Test Loss: 0.4609262
Validation loss decreased (0.997261 --> 0.996788).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 0.999570369720459
Epoch: 60, Steps: 64 | Train Loss: 0.2313965 Vali Loss: 0.9971456 Test Loss: 0.4607224
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.0851471424102783
Epoch: 61, Steps: 64 | Train Loss: 0.2315944 Vali Loss: 0.9969371 Test Loss: 0.4605673
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.2229714393615723
Epoch: 62, Steps: 64 | Train Loss: 0.2316929 Vali Loss: 0.9965864 Test Loss: 0.4603947
Validation loss decreased (0.996788 --> 0.996586).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.1705787181854248
Epoch: 63, Steps: 64 | Train Loss: 0.2313235 Vali Loss: 0.9960967 Test Loss: 0.4602197
Validation loss decreased (0.996586 --> 0.996097).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 0.9503195285797119
Epoch: 64, Steps: 64 | Train Loss: 0.2313126 Vali Loss: 0.9960147 Test Loss: 0.4600998
Validation loss decreased (0.996097 --> 0.996015).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.1105525493621826
Epoch: 65, Steps: 64 | Train Loss: 0.2309993 Vali Loss: 0.9956683 Test Loss: 0.4599252
Validation loss decreased (0.996015 --> 0.995668).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.0556488037109375
Epoch: 66, Steps: 64 | Train Loss: 0.2310019 Vali Loss: 0.9959642 Test Loss: 0.4598103
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.0792667865753174
Epoch: 67, Steps: 64 | Train Loss: 0.2309650 Vali Loss: 0.9953986 Test Loss: 0.4596655
Validation loss decreased (0.995668 --> 0.995399).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.052851676940918
Epoch: 68, Steps: 64 | Train Loss: 0.2308808 Vali Loss: 0.9957470 Test Loss: 0.4595618
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.0959980487823486
Epoch: 69, Steps: 64 | Train Loss: 0.2309263 Vali Loss: 0.9956099 Test Loss: 0.4594378
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.0525898933410645
Epoch: 70, Steps: 64 | Train Loss: 0.2305905 Vali Loss: 0.9954051 Test Loss: 0.4593417
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.2872745990753174
Epoch: 71, Steps: 64 | Train Loss: 0.2304011 Vali Loss: 0.9952762 Test Loss: 0.4592349
Validation loss decreased (0.995399 --> 0.995276).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.080737590789795
Epoch: 72, Steps: 64 | Train Loss: 0.2304870 Vali Loss: 0.9951747 Test Loss: 0.4591299
Validation loss decreased (0.995276 --> 0.995175).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.2075746059417725
Epoch: 73, Steps: 64 | Train Loss: 0.2303676 Vali Loss: 0.9947328 Test Loss: 0.4590180
Validation loss decreased (0.995175 --> 0.994733).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.142063856124878
Epoch: 74, Steps: 64 | Train Loss: 0.2307172 Vali Loss: 0.9949650 Test Loss: 0.4589433
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.0790095329284668
Epoch: 75, Steps: 64 | Train Loss: 0.2305536 Vali Loss: 0.9948595 Test Loss: 0.4588488
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.0677015781402588
Epoch: 76, Steps: 64 | Train Loss: 0.2300436 Vali Loss: 0.9947872 Test Loss: 0.4587684
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.0834925174713135
Epoch: 77, Steps: 64 | Train Loss: 0.2302071 Vali Loss: 0.9945746 Test Loss: 0.4586998
Validation loss decreased (0.994733 --> 0.994575).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.0273752212524414
Epoch: 78, Steps: 64 | Train Loss: 0.2300712 Vali Loss: 0.9945769 Test Loss: 0.4586169
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.0433061122894287
Epoch: 79, Steps: 64 | Train Loss: 0.2298538 Vali Loss: 0.9945519 Test Loss: 0.4585408
Validation loss decreased (0.994575 --> 0.994552).  Saving model ...
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.1735520362854004
Epoch: 80, Steps: 64 | Train Loss: 0.2298126 Vali Loss: 0.9937288 Test Loss: 0.4584854
Validation loss decreased (0.994552 --> 0.993729).  Saving model ...
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.058211088180542
Epoch: 81, Steps: 64 | Train Loss: 0.2300504 Vali Loss: 0.9937427 Test Loss: 0.4584102
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.1488652229309082
Epoch: 82, Steps: 64 | Train Loss: 0.2300950 Vali Loss: 0.9943452 Test Loss: 0.4583617
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.0735371112823486
Epoch: 83, Steps: 64 | Train Loss: 0.2299418 Vali Loss: 0.9938989 Test Loss: 0.4583043
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.09318208694458
Epoch: 84, Steps: 64 | Train Loss: 0.2298503 Vali Loss: 0.9939628 Test Loss: 0.4582558
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.1455035209655762
Epoch: 85, Steps: 64 | Train Loss: 0.2296781 Vali Loss: 0.9940492 Test Loss: 0.4582026
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.0747945308685303
Epoch: 86, Steps: 64 | Train Loss: 0.2298846 Vali Loss: 0.9942113 Test Loss: 0.4581505
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.0054495334625244
Epoch: 87, Steps: 64 | Train Loss: 0.2298304 Vali Loss: 0.9940612 Test Loss: 0.4581040
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.263413429260254
Epoch: 88, Steps: 64 | Train Loss: 0.2298866 Vali Loss: 0.9927037 Test Loss: 0.4580631
Validation loss decreased (0.993729 --> 0.992704).  Saving model ...
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.1702771186828613
Epoch: 89, Steps: 64 | Train Loss: 0.2297540 Vali Loss: 0.9939077 Test Loss: 0.4580182
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.069749355316162
Epoch: 90, Steps: 64 | Train Loss: 0.2299084 Vali Loss: 0.9934026 Test Loss: 0.4579792
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.1474552154541016
Epoch: 91, Steps: 64 | Train Loss: 0.2296483 Vali Loss: 0.9930976 Test Loss: 0.4579425
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 0.9737331867218018
Epoch: 92, Steps: 64 | Train Loss: 0.2297076 Vali Loss: 0.9935966 Test Loss: 0.4579077
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.150852918624878
Epoch: 93, Steps: 64 | Train Loss: 0.2297433 Vali Loss: 0.9932861 Test Loss: 0.4578694
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.053551435470581
Epoch: 94, Steps: 64 | Train Loss: 0.2296849 Vali Loss: 0.9937070 Test Loss: 0.4578418
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.9060075283050537
Epoch: 95, Steps: 64 | Train Loss: 0.2295626 Vali Loss: 0.9934298 Test Loss: 0.4578117
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.0129101276397705
Epoch: 96, Steps: 64 | Train Loss: 0.2295872 Vali Loss: 0.9936657 Test Loss: 0.4577839
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.1214189529418945
Epoch: 97, Steps: 64 | Train Loss: 0.2295475 Vali Loss: 0.9929273 Test Loss: 0.4577527
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.0637338161468506
Epoch: 98, Steps: 64 | Train Loss: 0.2292786 Vali Loss: 0.9930762 Test Loss: 0.4577266
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.1680145263671875
Epoch: 99, Steps: 64 | Train Loss: 0.2294930 Vali Loss: 0.9935067 Test Loss: 0.4577036
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.0479850769042969
Epoch: 100, Steps: 64 | Train Loss: 0.2295289 Vali Loss: 0.9932509 Test Loss: 0.4576850
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8269
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=58, out_features=119, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6184192.0
params:  7021.0
Trainable parameters:  7021
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.1548995971679688
Epoch: 1, Steps: 64 | Train Loss: 0.4148419 Vali Loss: 0.9827015 Test Loss: 0.4449830
Validation loss decreased (inf --> 0.982702).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.169759750366211
Epoch: 2, Steps: 64 | Train Loss: 0.4096602 Vali Loss: 0.9763369 Test Loss: 0.4391320
Validation loss decreased (0.982702 --> 0.976337).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.0426199436187744
Epoch: 3, Steps: 64 | Train Loss: 0.4075385 Vali Loss: 0.9727610 Test Loss: 0.4352694
Validation loss decreased (0.976337 --> 0.972761).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.1282002925872803
Epoch: 4, Steps: 64 | Train Loss: 0.4056321 Vali Loss: 0.9720317 Test Loss: 0.4331173
Validation loss decreased (0.972761 --> 0.972032).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.0224518775939941
Epoch: 5, Steps: 64 | Train Loss: 0.4044926 Vali Loss: 0.9710818 Test Loss: 0.4329274
Validation loss decreased (0.972032 --> 0.971082).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.00862455368042
Epoch: 6, Steps: 64 | Train Loss: 0.4046254 Vali Loss: 0.9700130 Test Loss: 0.4323898
Validation loss decreased (0.971082 --> 0.970013).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 0.9866316318511963
Epoch: 7, Steps: 64 | Train Loss: 0.4042767 Vali Loss: 0.9695598 Test Loss: 0.4321722
Validation loss decreased (0.970013 --> 0.969560).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.0769495964050293
Epoch: 8, Steps: 64 | Train Loss: 0.4041096 Vali Loss: 0.9688372 Test Loss: 0.4326291
Validation loss decreased (0.969560 --> 0.968837).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.762739896774292
Epoch: 9, Steps: 64 | Train Loss: 0.4039246 Vali Loss: 0.9691243 Test Loss: 0.4319727
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.1286225318908691
Epoch: 10, Steps: 64 | Train Loss: 0.4038912 Vali Loss: 0.9691643 Test Loss: 0.4317733
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.7073185443878174
Epoch: 11, Steps: 64 | Train Loss: 0.4037576 Vali Loss: 0.9690343 Test Loss: 0.4320448
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.0273854732513428
Epoch: 12, Steps: 64 | Train Loss: 0.4038092 Vali Loss: 0.9686583 Test Loss: 0.4319009
Validation loss decreased (0.968837 --> 0.968658).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.6842293739318848
Epoch: 13, Steps: 64 | Train Loss: 0.4034515 Vali Loss: 0.9684531 Test Loss: 0.4317200
Validation loss decreased (0.968658 --> 0.968453).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.3967366218566895
Epoch: 14, Steps: 64 | Train Loss: 0.4033546 Vali Loss: 0.9686324 Test Loss: 0.4326322
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.2487239837646484
Epoch: 15, Steps: 64 | Train Loss: 0.4038550 Vali Loss: 0.9680862 Test Loss: 0.4318853
Validation loss decreased (0.968453 --> 0.968086).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.9433670043945312
Epoch: 16, Steps: 64 | Train Loss: 0.4032156 Vali Loss: 0.9682728 Test Loss: 0.4319891
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.9470677375793457
Epoch: 17, Steps: 64 | Train Loss: 0.4033715 Vali Loss: 0.9674575 Test Loss: 0.4320802
Validation loss decreased (0.968086 --> 0.967457).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.656095266342163
Epoch: 18, Steps: 64 | Train Loss: 0.4036667 Vali Loss: 0.9675174 Test Loss: 0.4323037
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.7849717140197754
Epoch: 19, Steps: 64 | Train Loss: 0.4034718 Vali Loss: 0.9675834 Test Loss: 0.4318312
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.0089144706726074
Epoch: 20, Steps: 64 | Train Loss: 0.4034024 Vali Loss: 0.9681553 Test Loss: 0.4322822
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.5136280059814453
Epoch: 21, Steps: 64 | Train Loss: 0.4032288 Vali Loss: 0.9675948 Test Loss: 0.4321066
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.4592697620391846
Epoch: 22, Steps: 64 | Train Loss: 0.4030315 Vali Loss: 0.9679120 Test Loss: 0.4321639
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.528351306915283
Epoch: 23, Steps: 64 | Train Loss: 0.4033479 Vali Loss: 0.9674967 Test Loss: 0.4321297
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.4646058082580566
Epoch: 24, Steps: 64 | Train Loss: 0.4031648 Vali Loss: 0.9677831 Test Loss: 0.4319867
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.3847765922546387
Epoch: 25, Steps: 64 | Train Loss: 0.4028884 Vali Loss: 0.9677905 Test Loss: 0.4321531
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.3962640762329102
Epoch: 26, Steps: 64 | Train Loss: 0.4034262 Vali Loss: 0.9678272 Test Loss: 0.4319534
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.4677886962890625
Epoch: 27, Steps: 64 | Train Loss: 0.4035969 Vali Loss: 0.9674256 Test Loss: 0.4322200
Validation loss decreased (0.967457 --> 0.967426).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.3800857067108154
Epoch: 28, Steps: 64 | Train Loss: 0.4027627 Vali Loss: 0.9670357 Test Loss: 0.4320848
Validation loss decreased (0.967426 --> 0.967036).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.3908119201660156
Epoch: 29, Steps: 64 | Train Loss: 0.4032047 Vali Loss: 0.9675128 Test Loss: 0.4320339
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 3.264509916305542
Epoch: 30, Steps: 64 | Train Loss: 0.4031345 Vali Loss: 0.9674823 Test Loss: 0.4320903
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.196195363998413
Epoch: 31, Steps: 64 | Train Loss: 0.4033220 Vali Loss: 0.9675275 Test Loss: 0.4320365
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.0315032005310059
Epoch: 32, Steps: 64 | Train Loss: 0.4027488 Vali Loss: 0.9676127 Test Loss: 0.4321583
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.0706231594085693
Epoch: 33, Steps: 64 | Train Loss: 0.4032088 Vali Loss: 0.9673346 Test Loss: 0.4321379
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.1366615295410156
Epoch: 34, Steps: 64 | Train Loss: 0.4029117 Vali Loss: 0.9674953 Test Loss: 0.4320435
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.1308157444000244
Epoch: 35, Steps: 64 | Train Loss: 0.4034392 Vali Loss: 0.9675930 Test Loss: 0.4320944
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.1137030124664307
Epoch: 36, Steps: 64 | Train Loss: 0.4029800 Vali Loss: 0.9675045 Test Loss: 0.4321293
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.086512804031372
Epoch: 37, Steps: 64 | Train Loss: 0.4031834 Vali Loss: 0.9676295 Test Loss: 0.4321440
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.1577751636505127
Epoch: 38, Steps: 64 | Train Loss: 0.4032150 Vali Loss: 0.9674608 Test Loss: 0.4322045
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.0038113594055176
Epoch: 39, Steps: 64 | Train Loss: 0.4030351 Vali Loss: 0.9676114 Test Loss: 0.4321527
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.1515023708343506
Epoch: 40, Steps: 64 | Train Loss: 0.4034293 Vali Loss: 0.9673827 Test Loss: 0.4321750
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.0953881740570068
Epoch: 41, Steps: 64 | Train Loss: 0.4031669 Vali Loss: 0.9676353 Test Loss: 0.4321015
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.0097990036010742
Epoch: 42, Steps: 64 | Train Loss: 0.4027931 Vali Loss: 0.9663169 Test Loss: 0.4320796
Validation loss decreased (0.967036 --> 0.966317).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.171781063079834
Epoch: 43, Steps: 64 | Train Loss: 0.4034414 Vali Loss: 0.9673463 Test Loss: 0.4321323
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.048555850982666
Epoch: 44, Steps: 64 | Train Loss: 0.4029309 Vali Loss: 0.9675000 Test Loss: 0.4320727
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.072432518005371
Epoch: 45, Steps: 64 | Train Loss: 0.4029188 Vali Loss: 0.9674929 Test Loss: 0.4321143
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.1604750156402588
Epoch: 46, Steps: 64 | Train Loss: 0.4032289 Vali Loss: 0.9670051 Test Loss: 0.4321614
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.1542091369628906
Epoch: 47, Steps: 64 | Train Loss: 0.4030994 Vali Loss: 0.9672997 Test Loss: 0.4321050
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.0958983898162842
Epoch: 48, Steps: 64 | Train Loss: 0.4030877 Vali Loss: 0.9670908 Test Loss: 0.4321386
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.1401472091674805
Epoch: 49, Steps: 64 | Train Loss: 0.4028773 Vali Loss: 0.9669358 Test Loss: 0.4321663
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.095836877822876
Epoch: 50, Steps: 64 | Train Loss: 0.4030856 Vali Loss: 0.9674022 Test Loss: 0.4321122
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.0467617511749268
Epoch: 51, Steps: 64 | Train Loss: 0.4028520 Vali Loss: 0.9673765 Test Loss: 0.4320735
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.1343607902526855
Epoch: 52, Steps: 64 | Train Loss: 0.4026537 Vali Loss: 0.9675239 Test Loss: 0.4321350
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.1626453399658203
Epoch: 53, Steps: 64 | Train Loss: 0.4030522 Vali Loss: 0.9670292 Test Loss: 0.4321388
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.1276040077209473
Epoch: 54, Steps: 64 | Train Loss: 0.4027869 Vali Loss: 0.9672767 Test Loss: 0.4321396
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.192155361175537
Epoch: 55, Steps: 64 | Train Loss: 0.4022347 Vali Loss: 0.9673913 Test Loss: 0.4321065
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.1027462482452393
Epoch: 56, Steps: 64 | Train Loss: 0.4030617 Vali Loss: 0.9672914 Test Loss: 0.4320928
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.1873230934143066
Epoch: 57, Steps: 64 | Train Loss: 0.4029730 Vali Loss: 0.9669127 Test Loss: 0.4321296
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.158555507659912
Epoch: 58, Steps: 64 | Train Loss: 0.4026797 Vali Loss: 0.9672862 Test Loss: 0.4321344
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.1534161567687988
Epoch: 59, Steps: 64 | Train Loss: 0.4030013 Vali Loss: 0.9673642 Test Loss: 0.4321049
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.12376070022583
Epoch: 60, Steps: 64 | Train Loss: 0.4030520 Vali Loss: 0.9672396 Test Loss: 0.4321687
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.2297441959381104
Epoch: 61, Steps: 64 | Train Loss: 0.4032106 Vali Loss: 0.9669256 Test Loss: 0.4321104
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.2252755165100098
Epoch: 62, Steps: 64 | Train Loss: 0.4029387 Vali Loss: 0.9673372 Test Loss: 0.4320860
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_180_192_FITS_ETTh1_ftM_sl180_ll48_pl192_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.4255567491054535, mae:0.41962146759033203, rse:0.6194925308227539, corr:[0.26379085 0.26944166 0.26855946 0.2687279  0.2664591  0.26343086
 0.26283458 0.26280025 0.26232544 0.26302025 0.2626755  0.2623466
 0.26273748 0.2619075  0.26147506 0.26185846 0.26173395 0.2614868
 0.26145968 0.26106918 0.26069903 0.26083073 0.26113552 0.26098943
 0.26023194 0.25952104 0.25882167 0.2585452  0.25806478 0.25757763
 0.2574567  0.2571263  0.25656447 0.2567076  0.25698286 0.2571129
 0.25740102 0.25749314 0.2573653  0.25748587 0.25787538 0.25802952
 0.25811404 0.25832173 0.25835356 0.25842494 0.25900328 0.25913557
 0.25804853 0.2565356  0.25484678 0.25379854 0.25278768 0.25141305
 0.25071064 0.25058654 0.25031635 0.25068036 0.2507864  0.25109896
 0.25144753 0.25126144 0.25094453 0.25075108 0.25083664 0.2508555
 0.25095505 0.2509936  0.25080937 0.25082368 0.25107363 0.2505311
 0.24920848 0.24803098 0.24678235 0.24627702 0.24616008 0.24574801
 0.24548478 0.24530438 0.24500959 0.24500458 0.24475768 0.24466303
 0.24480288 0.24472758 0.244901   0.24490625 0.24469455 0.24471053
 0.24476713 0.24458683 0.24432224 0.24446559 0.24502519 0.24514799
 0.24448465 0.24385624 0.24314637 0.24235003 0.24195127 0.24153253
 0.24124868 0.24143875 0.24156442 0.24191919 0.24193376 0.24200463
 0.2421412  0.24172178 0.24138549 0.24154459 0.24182446 0.24183655
 0.24188137 0.24201007 0.24195316 0.24195537 0.2420822  0.24173951
 0.24073532 0.23967202 0.2383154  0.23730516 0.236419   0.23570351
 0.23562875 0.23603617 0.23605074 0.23621853 0.23636477 0.23684481
 0.237482   0.23744962 0.2372734  0.23718154 0.23734625 0.23743245
 0.23748487 0.23768415 0.23759474 0.23754342 0.2377795  0.23752269
 0.23651809 0.2354161  0.2343532  0.23335275 0.23251443 0.23173186
 0.23175652 0.23205832 0.23227285 0.23264204 0.23287527 0.23321134
 0.23357958 0.2336325  0.23361115 0.2331587  0.23299207 0.23309895
 0.23294799 0.23288028 0.23290668 0.2329483  0.23320562 0.23305322
 0.23202999 0.23088026 0.22990696 0.22949147 0.2290816  0.22834502
 0.22839573 0.22924086 0.22957638 0.23023178 0.23101044 0.23179239
 0.23232548 0.23216732 0.2323099  0.2320758  0.2315114  0.2318516
 0.23203175 0.2315268  0.23176073 0.23228084 0.2323084  0.23249634]
