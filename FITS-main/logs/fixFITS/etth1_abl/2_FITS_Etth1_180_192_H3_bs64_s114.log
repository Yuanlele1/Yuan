Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=34, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_180_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_180_192_FITS_ETTh1_ftM_sl180_ll48_pl192_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8269
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=34, out_features=70, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2132480.0
params:  2450.0
Trainable parameters:  2450
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.541736125946045
Epoch: 1, Steps: 64 | Train Loss: 0.6694184 Vali Loss: 1.5812821 Test Loss: 0.8248415
Validation loss decreased (inf --> 1.581282).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.0722076892852783
Epoch: 2, Steps: 64 | Train Loss: 0.5172728 Vali Loss: 1.3696283 Test Loss: 0.6808936
Validation loss decreased (1.581282 --> 1.369628).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.462655782699585
Epoch: 3, Steps: 64 | Train Loss: 0.4339631 Vali Loss: 1.2585442 Test Loss: 0.6066355
Validation loss decreased (1.369628 --> 1.258544).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.3712608814239502
Epoch: 4, Steps: 64 | Train Loss: 0.3831862 Vali Loss: 1.1908362 Test Loss: 0.5624022
Validation loss decreased (1.258544 --> 1.190836).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.344749927520752
Epoch: 5, Steps: 64 | Train Loss: 0.3498958 Vali Loss: 1.1478786 Test Loss: 0.5346642
Validation loss decreased (1.190836 --> 1.147879).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.5529048442840576
Epoch: 6, Steps: 64 | Train Loss: 0.3266190 Vali Loss: 1.1183355 Test Loss: 0.5163170
Validation loss decreased (1.147879 --> 1.118335).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.3098559379577637
Epoch: 7, Steps: 64 | Train Loss: 0.3096889 Vali Loss: 1.0965495 Test Loss: 0.5035766
Validation loss decreased (1.118335 --> 1.096550).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.8270883560180664
Epoch: 8, Steps: 64 | Train Loss: 0.2975787 Vali Loss: 1.0794340 Test Loss: 0.4945719
Validation loss decreased (1.096550 --> 1.079434).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.3778018951416016
Epoch: 9, Steps: 64 | Train Loss: 0.2881044 Vali Loss: 1.0678639 Test Loss: 0.4877608
Validation loss decreased (1.079434 --> 1.067864).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.386209487915039
Epoch: 10, Steps: 64 | Train Loss: 0.2806876 Vali Loss: 1.0587190 Test Loss: 0.4823644
Validation loss decreased (1.067864 --> 1.058719).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.2429747581481934
Epoch: 11, Steps: 64 | Train Loss: 0.2748759 Vali Loss: 1.0510812 Test Loss: 0.4784007
Validation loss decreased (1.058719 --> 1.051081).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.3013279438018799
Epoch: 12, Steps: 64 | Train Loss: 0.2699960 Vali Loss: 1.0449868 Test Loss: 0.4749348
Validation loss decreased (1.051081 --> 1.044987).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.4018633365631104
Epoch: 13, Steps: 64 | Train Loss: 0.2657675 Vali Loss: 1.0394282 Test Loss: 0.4721030
Validation loss decreased (1.044987 --> 1.039428).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.3567898273468018
Epoch: 14, Steps: 64 | Train Loss: 0.2625041 Vali Loss: 1.0347153 Test Loss: 0.4697674
Validation loss decreased (1.039428 --> 1.034715).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.47756028175354
Epoch: 15, Steps: 64 | Train Loss: 0.2595593 Vali Loss: 1.0308746 Test Loss: 0.4676554
Validation loss decreased (1.034715 --> 1.030875).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.4160847663879395
Epoch: 16, Steps: 64 | Train Loss: 0.2570360 Vali Loss: 1.0270251 Test Loss: 0.4658015
Validation loss decreased (1.030875 --> 1.027025).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.4481961727142334
Epoch: 17, Steps: 64 | Train Loss: 0.2550811 Vali Loss: 1.0240991 Test Loss: 0.4641391
Validation loss decreased (1.027025 --> 1.024099).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.3609950542449951
Epoch: 18, Steps: 64 | Train Loss: 0.2530184 Vali Loss: 1.0214691 Test Loss: 0.4626602
Validation loss decreased (1.024099 --> 1.021469).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.6852407455444336
Epoch: 19, Steps: 64 | Train Loss: 0.2514448 Vali Loss: 1.0186903 Test Loss: 0.4614191
Validation loss decreased (1.021469 --> 1.018690).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.0079288482666016
Epoch: 20, Steps: 64 | Train Loss: 0.2499059 Vali Loss: 1.0168532 Test Loss: 0.4601806
Validation loss decreased (1.018690 --> 1.016853).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.7511107921600342
Epoch: 21, Steps: 64 | Train Loss: 0.2484837 Vali Loss: 1.0143328 Test Loss: 0.4589817
Validation loss decreased (1.016853 --> 1.014333).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.3714523315429688
Epoch: 22, Steps: 64 | Train Loss: 0.2473902 Vali Loss: 1.0128953 Test Loss: 0.4579709
Validation loss decreased (1.014333 --> 1.012895).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.7017464637756348
Epoch: 23, Steps: 64 | Train Loss: 0.2461737 Vali Loss: 1.0108579 Test Loss: 0.4570237
Validation loss decreased (1.012895 --> 1.010858).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.3943545818328857
Epoch: 24, Steps: 64 | Train Loss: 0.2453967 Vali Loss: 1.0098209 Test Loss: 0.4562046
Validation loss decreased (1.010858 --> 1.009821).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.4188904762268066
Epoch: 25, Steps: 64 | Train Loss: 0.2445905 Vali Loss: 1.0082798 Test Loss: 0.4555059
Validation loss decreased (1.009821 --> 1.008280).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.3567626476287842
Epoch: 26, Steps: 64 | Train Loss: 0.2437219 Vali Loss: 1.0072229 Test Loss: 0.4545439
Validation loss decreased (1.008280 --> 1.007223).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.8596632480621338
Epoch: 27, Steps: 64 | Train Loss: 0.2432272 Vali Loss: 1.0055770 Test Loss: 0.4539497
Validation loss decreased (1.007223 --> 1.005577).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.8994944095611572
Epoch: 28, Steps: 64 | Train Loss: 0.2423305 Vali Loss: 1.0047647 Test Loss: 0.4534001
Validation loss decreased (1.005577 --> 1.004765).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.884570598602295
Epoch: 29, Steps: 64 | Train Loss: 0.2417463 Vali Loss: 1.0037723 Test Loss: 0.4528756
Validation loss decreased (1.004765 --> 1.003772).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.2688076496124268
Epoch: 30, Steps: 64 | Train Loss: 0.2410993 Vali Loss: 1.0028410 Test Loss: 0.4522929
Validation loss decreased (1.003772 --> 1.002841).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.2416000366210938
Epoch: 31, Steps: 64 | Train Loss: 0.2407692 Vali Loss: 1.0019128 Test Loss: 0.4518981
Validation loss decreased (1.002841 --> 1.001913).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.4478249549865723
Epoch: 32, Steps: 64 | Train Loss: 0.2401181 Vali Loss: 1.0011114 Test Loss: 0.4514324
Validation loss decreased (1.001913 --> 1.001111).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.3311121463775635
Epoch: 33, Steps: 64 | Train Loss: 0.2396193 Vali Loss: 1.0003853 Test Loss: 0.4509840
Validation loss decreased (1.001111 --> 1.000385).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.4252140522003174
Epoch: 34, Steps: 64 | Train Loss: 0.2395246 Vali Loss: 0.9998022 Test Loss: 0.4506279
Validation loss decreased (1.000385 --> 0.999802).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.5118966102600098
Epoch: 35, Steps: 64 | Train Loss: 0.2393582 Vali Loss: 0.9990857 Test Loss: 0.4502734
Validation loss decreased (0.999802 --> 0.999086).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.3985645771026611
Epoch: 36, Steps: 64 | Train Loss: 0.2389512 Vali Loss: 0.9982151 Test Loss: 0.4498783
Validation loss decreased (0.999086 --> 0.998215).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.4718308448791504
Epoch: 37, Steps: 64 | Train Loss: 0.2384271 Vali Loss: 0.9974225 Test Loss: 0.4496179
Validation loss decreased (0.998215 --> 0.997422).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.4642984867095947
Epoch: 38, Steps: 64 | Train Loss: 0.2383150 Vali Loss: 0.9970075 Test Loss: 0.4492809
Validation loss decreased (0.997422 --> 0.997008).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.201568365097046
Epoch: 39, Steps: 64 | Train Loss: 0.2381341 Vali Loss: 0.9968718 Test Loss: 0.4489704
Validation loss decreased (0.997008 --> 0.996872).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.6987178325653076
Epoch: 40, Steps: 64 | Train Loss: 0.2379257 Vali Loss: 0.9963046 Test Loss: 0.4487582
Validation loss decreased (0.996872 --> 0.996305).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.3519465923309326
Epoch: 41, Steps: 64 | Train Loss: 0.2375803 Vali Loss: 0.9959205 Test Loss: 0.4484278
Validation loss decreased (0.996305 --> 0.995921).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.3555045127868652
Epoch: 42, Steps: 64 | Train Loss: 0.2371974 Vali Loss: 0.9950130 Test Loss: 0.4482525
Validation loss decreased (0.995921 --> 0.995013).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.2635526657104492
Epoch: 43, Steps: 64 | Train Loss: 0.2368987 Vali Loss: 0.9945616 Test Loss: 0.4480476
Validation loss decreased (0.995013 --> 0.994562).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.8073859214782715
Epoch: 44, Steps: 64 | Train Loss: 0.2368999 Vali Loss: 0.9947770 Test Loss: 0.4478269
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.9722964763641357
Epoch: 45, Steps: 64 | Train Loss: 0.2366928 Vali Loss: 0.9944651 Test Loss: 0.4475997
Validation loss decreased (0.994562 --> 0.994465).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.3742756843566895
Epoch: 46, Steps: 64 | Train Loss: 0.2366194 Vali Loss: 0.9941499 Test Loss: 0.4474086
Validation loss decreased (0.994465 --> 0.994150).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.777390480041504
Epoch: 47, Steps: 64 | Train Loss: 0.2361549 Vali Loss: 0.9933494 Test Loss: 0.4472572
Validation loss decreased (0.994150 --> 0.993349).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.4234001636505127
Epoch: 48, Steps: 64 | Train Loss: 0.2362576 Vali Loss: 0.9930142 Test Loss: 0.4470800
Validation loss decreased (0.993349 --> 0.993014).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.8395805358886719
Epoch: 49, Steps: 64 | Train Loss: 0.2360931 Vali Loss: 0.9932114 Test Loss: 0.4468988
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.3105463981628418
Epoch: 50, Steps: 64 | Train Loss: 0.2359615 Vali Loss: 0.9924167 Test Loss: 0.4467841
Validation loss decreased (0.993014 --> 0.992417).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.3305041790008545
Epoch: 51, Steps: 64 | Train Loss: 0.2360396 Vali Loss: 0.9920415 Test Loss: 0.4466031
Validation loss decreased (0.992417 --> 0.992042).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.449958324432373
Epoch: 52, Steps: 64 | Train Loss: 0.2358065 Vali Loss: 0.9920573 Test Loss: 0.4465009
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.8513290882110596
Epoch: 53, Steps: 64 | Train Loss: 0.2357245 Vali Loss: 0.9917067 Test Loss: 0.4464275
Validation loss decreased (0.992042 --> 0.991707).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.3898530006408691
Epoch: 54, Steps: 64 | Train Loss: 0.2352035 Vali Loss: 0.9919612 Test Loss: 0.4463035
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.3327488899230957
Epoch: 55, Steps: 64 | Train Loss: 0.2354290 Vali Loss: 0.9912845 Test Loss: 0.4462162
Validation loss decreased (0.991707 --> 0.991284).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.3120532035827637
Epoch: 56, Steps: 64 | Train Loss: 0.2353336 Vali Loss: 0.9914889 Test Loss: 0.4460829
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.4450676441192627
Epoch: 57, Steps: 64 | Train Loss: 0.2352396 Vali Loss: 0.9912655 Test Loss: 0.4459763
Validation loss decreased (0.991284 --> 0.991266).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.3286635875701904
Epoch: 58, Steps: 64 | Train Loss: 0.2351800 Vali Loss: 0.9911860 Test Loss: 0.4458688
Validation loss decreased (0.991266 --> 0.991186).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.5631654262542725
Epoch: 59, Steps: 64 | Train Loss: 0.2352459 Vali Loss: 0.9909862 Test Loss: 0.4457752
Validation loss decreased (0.991186 --> 0.990986).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.9268765449523926
Epoch: 60, Steps: 64 | Train Loss: 0.2349893 Vali Loss: 0.9908974 Test Loss: 0.4457000
Validation loss decreased (0.990986 --> 0.990897).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.3253345489501953
Epoch: 61, Steps: 64 | Train Loss: 0.2349246 Vali Loss: 0.9905931 Test Loss: 0.4456064
Validation loss decreased (0.990897 --> 0.990593).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.3477144241333008
Epoch: 62, Steps: 64 | Train Loss: 0.2348533 Vali Loss: 0.9902099 Test Loss: 0.4455259
Validation loss decreased (0.990593 --> 0.990210).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.341905117034912
Epoch: 63, Steps: 64 | Train Loss: 0.2345976 Vali Loss: 0.9901656 Test Loss: 0.4454740
Validation loss decreased (0.990210 --> 0.990166).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.3363597393035889
Epoch: 64, Steps: 64 | Train Loss: 0.2348820 Vali Loss: 0.9904364 Test Loss: 0.4454045
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.5452096462249756
Epoch: 65, Steps: 64 | Train Loss: 0.2346248 Vali Loss: 0.9902264 Test Loss: 0.4453563
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.839097261428833
Epoch: 66, Steps: 64 | Train Loss: 0.2347273 Vali Loss: 0.9898700 Test Loss: 0.4452817
Validation loss decreased (0.990166 --> 0.989870).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.7913696765899658
Epoch: 67, Steps: 64 | Train Loss: 0.2346426 Vali Loss: 0.9895290 Test Loss: 0.4452083
Validation loss decreased (0.989870 --> 0.989529).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.170316219329834
Epoch: 68, Steps: 64 | Train Loss: 0.2345326 Vali Loss: 0.9899364 Test Loss: 0.4451709
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.384300708770752
Epoch: 69, Steps: 64 | Train Loss: 0.2346171 Vali Loss: 0.9899171 Test Loss: 0.4451198
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.4469964504241943
Epoch: 70, Steps: 64 | Train Loss: 0.2343717 Vali Loss: 0.9894267 Test Loss: 0.4450593
Validation loss decreased (0.989529 --> 0.989427).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.3778941631317139
Epoch: 71, Steps: 64 | Train Loss: 0.2344457 Vali Loss: 0.9896760 Test Loss: 0.4450297
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.251971960067749
Epoch: 72, Steps: 64 | Train Loss: 0.2345067 Vali Loss: 0.9894447 Test Loss: 0.4449902
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.9564223289489746
Epoch: 73, Steps: 64 | Train Loss: 0.2342180 Vali Loss: 0.9894184 Test Loss: 0.4449464
Validation loss decreased (0.989427 --> 0.989418).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.3035366535186768
Epoch: 74, Steps: 64 | Train Loss: 0.2343213 Vali Loss: 0.9890351 Test Loss: 0.4449084
Validation loss decreased (0.989418 --> 0.989035).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.3442959785461426
Epoch: 75, Steps: 64 | Train Loss: 0.2345679 Vali Loss: 0.9885747 Test Loss: 0.4448591
Validation loss decreased (0.989035 --> 0.988575).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.5298035144805908
Epoch: 76, Steps: 64 | Train Loss: 0.2341338 Vali Loss: 0.9888835 Test Loss: 0.4448217
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.2848796844482422
Epoch: 77, Steps: 64 | Train Loss: 0.2341662 Vali Loss: 0.9891673 Test Loss: 0.4447947
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.2569527626037598
Epoch: 78, Steps: 64 | Train Loss: 0.2342746 Vali Loss: 0.9885765 Test Loss: 0.4447629
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.3857018947601318
Epoch: 79, Steps: 64 | Train Loss: 0.2340212 Vali Loss: 0.9891680 Test Loss: 0.4447281
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.6363496780395508
Epoch: 80, Steps: 64 | Train Loss: 0.2341851 Vali Loss: 0.9886979 Test Loss: 0.4447019
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.4503874778747559
Epoch: 81, Steps: 64 | Train Loss: 0.2341727 Vali Loss: 0.9889471 Test Loss: 0.4446675
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.462247610092163
Epoch: 82, Steps: 64 | Train Loss: 0.2339675 Vali Loss: 0.9882821 Test Loss: 0.4446455
Validation loss decreased (0.988575 --> 0.988282).  Saving model ...
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.4183905124664307
Epoch: 83, Steps: 64 | Train Loss: 0.2339977 Vali Loss: 0.9882983 Test Loss: 0.4446096
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.52225661277771
Epoch: 84, Steps: 64 | Train Loss: 0.2338948 Vali Loss: 0.9881256 Test Loss: 0.4445941
Validation loss decreased (0.988282 --> 0.988126).  Saving model ...
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.3563346862792969
Epoch: 85, Steps: 64 | Train Loss: 0.2340191 Vali Loss: 0.9887741 Test Loss: 0.4445640
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.3988406658172607
Epoch: 86, Steps: 64 | Train Loss: 0.2340127 Vali Loss: 0.9884238 Test Loss: 0.4445437
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.522315502166748
Epoch: 87, Steps: 64 | Train Loss: 0.2338142 Vali Loss: 0.9887288 Test Loss: 0.4445254
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.4611480236053467
Epoch: 88, Steps: 64 | Train Loss: 0.2338447 Vali Loss: 0.9887632 Test Loss: 0.4445052
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.3420255184173584
Epoch: 89, Steps: 64 | Train Loss: 0.2338552 Vali Loss: 0.9883185 Test Loss: 0.4444825
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 2.4634172916412354
Epoch: 90, Steps: 64 | Train Loss: 0.2339554 Vali Loss: 0.9882891 Test Loss: 0.4444745
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.7395520210266113
Epoch: 91, Steps: 64 | Train Loss: 0.2337968 Vali Loss: 0.9881335 Test Loss: 0.4444542
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.9722769260406494
Epoch: 92, Steps: 64 | Train Loss: 0.2339959 Vali Loss: 0.9882313 Test Loss: 0.4444398
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.8028571605682373
Epoch: 93, Steps: 64 | Train Loss: 0.2335956 Vali Loss: 0.9885257 Test Loss: 0.4444194
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.415245771408081
Epoch: 94, Steps: 64 | Train Loss: 0.2336839 Vali Loss: 0.9884862 Test Loss: 0.4444084
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.376408338546753
Epoch: 95, Steps: 64 | Train Loss: 0.2339552 Vali Loss: 0.9880601 Test Loss: 0.4443970
Validation loss decreased (0.988126 --> 0.988060).  Saving model ...
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.5342519283294678
Epoch: 96, Steps: 64 | Train Loss: 0.2337363 Vali Loss: 0.9884758 Test Loss: 0.4443913
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.262510061264038
Epoch: 97, Steps: 64 | Train Loss: 0.2336609 Vali Loss: 0.9884441 Test Loss: 0.4443751
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.287775993347168
Epoch: 98, Steps: 64 | Train Loss: 0.2338934 Vali Loss: 0.9879516 Test Loss: 0.4443641
Validation loss decreased (0.988060 --> 0.987952).  Saving model ...
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.355975866317749
Epoch: 99, Steps: 64 | Train Loss: 0.2338159 Vali Loss: 0.9881293 Test Loss: 0.4443457
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.2943229675292969
Epoch: 100, Steps: 64 | Train Loss: 0.2335487 Vali Loss: 0.9882966 Test Loss: 0.4443391
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8269
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=34, out_features=70, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2132480.0
params:  2450.0
Trainable parameters:  2450
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.6367812156677246
Epoch: 1, Steps: 64 | Train Loss: 0.4138242 Vali Loss: 0.9797057 Test Loss: 0.4383454
Validation loss decreased (inf --> 0.979706).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.314119815826416
Epoch: 2, Steps: 64 | Train Loss: 0.4112956 Vali Loss: 0.9775679 Test Loss: 0.4376286
Validation loss decreased (0.979706 --> 0.977568).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.2013041973114014
Epoch: 3, Steps: 64 | Train Loss: 0.4104119 Vali Loss: 0.9758932 Test Loss: 0.4371881
Validation loss decreased (0.977568 --> 0.975893).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.3393621444702148
Epoch: 4, Steps: 64 | Train Loss: 0.4101091 Vali Loss: 0.9754879 Test Loss: 0.4367659
Validation loss decreased (0.975893 --> 0.975488).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.349421501159668
Epoch: 5, Steps: 64 | Train Loss: 0.4096032 Vali Loss: 0.9754430 Test Loss: 0.4365099
Validation loss decreased (0.975488 --> 0.975443).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.330885648727417
Epoch: 6, Steps: 64 | Train Loss: 0.4099783 Vali Loss: 0.9747341 Test Loss: 0.4363490
Validation loss decreased (0.975443 --> 0.974734).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.4884729385375977
Epoch: 7, Steps: 64 | Train Loss: 0.4092036 Vali Loss: 0.9746600 Test Loss: 0.4371835
Validation loss decreased (0.974734 --> 0.974660).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.4133141040802002
Epoch: 8, Steps: 64 | Train Loss: 0.4095824 Vali Loss: 0.9744341 Test Loss: 0.4370035
Validation loss decreased (0.974660 --> 0.974434).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.3674876689910889
Epoch: 9, Steps: 64 | Train Loss: 0.4096955 Vali Loss: 0.9740127 Test Loss: 0.4361179
Validation loss decreased (0.974434 --> 0.974013).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.3320093154907227
Epoch: 10, Steps: 64 | Train Loss: 0.4096594 Vali Loss: 0.9740746 Test Loss: 0.4362560
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.488673448562622
Epoch: 11, Steps: 64 | Train Loss: 0.4096789 Vali Loss: 0.9736758 Test Loss: 0.4362642
Validation loss decreased (0.974013 --> 0.973676).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.3745737075805664
Epoch: 12, Steps: 64 | Train Loss: 0.4099293 Vali Loss: 0.9731451 Test Loss: 0.4365568
Validation loss decreased (0.973676 --> 0.973145).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.386352777481079
Epoch: 13, Steps: 64 | Train Loss: 0.4093922 Vali Loss: 0.9732335 Test Loss: 0.4363006
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.2828660011291504
Epoch: 14, Steps: 64 | Train Loss: 0.4095432 Vali Loss: 0.9735036 Test Loss: 0.4362668
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.4104855060577393
Epoch: 15, Steps: 64 | Train Loss: 0.4093829 Vali Loss: 0.9727998 Test Loss: 0.4363141
Validation loss decreased (0.973145 --> 0.972800).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.601449966430664
Epoch: 16, Steps: 64 | Train Loss: 0.4090647 Vali Loss: 0.9733599 Test Loss: 0.4359830
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.3188886642456055
Epoch: 17, Steps: 64 | Train Loss: 0.4092390 Vali Loss: 0.9731849 Test Loss: 0.4364055
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.4688684940338135
Epoch: 18, Steps: 64 | Train Loss: 0.4098126 Vali Loss: 0.9731991 Test Loss: 0.4362597
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.6568036079406738
Epoch: 19, Steps: 64 | Train Loss: 0.4091187 Vali Loss: 0.9718847 Test Loss: 0.4364301
Validation loss decreased (0.972800 --> 0.971885).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.2822911739349365
Epoch: 20, Steps: 64 | Train Loss: 0.4095595 Vali Loss: 0.9731131 Test Loss: 0.4366088
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.089016914367676
Epoch: 21, Steps: 64 | Train Loss: 0.4098103 Vali Loss: 0.9731470 Test Loss: 0.4364794
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.6651227474212646
Epoch: 22, Steps: 64 | Train Loss: 0.4090679 Vali Loss: 0.9726958 Test Loss: 0.4364931
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.2194254398345947
Epoch: 23, Steps: 64 | Train Loss: 0.4093439 Vali Loss: 0.9727414 Test Loss: 0.4362229
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.3758723735809326
Epoch: 24, Steps: 64 | Train Loss: 0.4095208 Vali Loss: 0.9725429 Test Loss: 0.4363335
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.437462329864502
Epoch: 25, Steps: 64 | Train Loss: 0.4091275 Vali Loss: 0.9728712 Test Loss: 0.4360814
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.2937915325164795
Epoch: 26, Steps: 64 | Train Loss: 0.4088059 Vali Loss: 0.9722757 Test Loss: 0.4362499
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.329270362854004
Epoch: 27, Steps: 64 | Train Loss: 0.4087793 Vali Loss: 0.9723981 Test Loss: 0.4363949
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.3663601875305176
Epoch: 28, Steps: 64 | Train Loss: 0.4094233 Vali Loss: 0.9727130 Test Loss: 0.4362817
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.3464133739471436
Epoch: 29, Steps: 64 | Train Loss: 0.4093114 Vali Loss: 0.9722158 Test Loss: 0.4362116
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.2885959148406982
Epoch: 30, Steps: 64 | Train Loss: 0.4093979 Vali Loss: 0.9727219 Test Loss: 0.4362938
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.4159328937530518
Epoch: 31, Steps: 64 | Train Loss: 0.4092376 Vali Loss: 0.9728258 Test Loss: 0.4364490
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.5278196334838867
Epoch: 32, Steps: 64 | Train Loss: 0.4091030 Vali Loss: 0.9725250 Test Loss: 0.4363129
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.246212959289551
Epoch: 33, Steps: 64 | Train Loss: 0.4093363 Vali Loss: 0.9726548 Test Loss: 0.4364366
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.3579933643341064
Epoch: 34, Steps: 64 | Train Loss: 0.4089212 Vali Loss: 0.9726197 Test Loss: 0.4363280
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.3750805854797363
Epoch: 35, Steps: 64 | Train Loss: 0.4094848 Vali Loss: 0.9727422 Test Loss: 0.4363694
EarlyStopping counter: 16 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.3021907806396484
Epoch: 36, Steps: 64 | Train Loss: 0.4087372 Vali Loss: 0.9725482 Test Loss: 0.4363809
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.3840398788452148
Epoch: 37, Steps: 64 | Train Loss: 0.4094007 Vali Loss: 0.9720924 Test Loss: 0.4362898
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.3503103256225586
Epoch: 38, Steps: 64 | Train Loss: 0.4089870 Vali Loss: 0.9725579 Test Loss: 0.4363840
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.4136216640472412
Epoch: 39, Steps: 64 | Train Loss: 0.4091827 Vali Loss: 0.9723431 Test Loss: 0.4364240
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_180_192_FITS_ETTh1_ftM_sl180_ll48_pl192_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.42981159687042236, mae:0.42335203289985657, rse:0.6225817799568176, corr:[0.26465836 0.26805964 0.26859805 0.26662844 0.2636865  0.26146993
 0.26083925 0.2609605  0.26064593 0.26037976 0.2604724  0.2608253
 0.26077285 0.2599068  0.25934875 0.25961685 0.25995547 0.2597398
 0.25903913 0.25838563 0.2583053  0.2587848  0.2590784  0.2585458
 0.25733468 0.25687945 0.25682312 0.25653    0.25567892 0.25490353
 0.25471604 0.2549181  0.2549156  0.2545882  0.2543628  0.25485536
 0.2555641  0.25556841 0.255281   0.2553523  0.25587025 0.2563061
 0.25617763 0.25594425 0.25627932 0.25688136 0.25726256 0.25660184
 0.25490102 0.25377053 0.25273922 0.25142667 0.24986632 0.24855365
 0.24807468 0.24820606 0.24822995 0.24819592 0.24804181 0.24859232
 0.24932186 0.24911037 0.2485422  0.24828033 0.24845822 0.24864736
 0.24851044 0.24812408 0.24808979 0.24846308 0.24874906 0.24797805
 0.24626832 0.2451038  0.24444763 0.24399099 0.24350843 0.24296679
 0.24280503 0.24292688 0.24277496 0.24228854 0.24166441 0.24170335
 0.24238154 0.24248281 0.24227357 0.24219386 0.24228868 0.24233346
 0.24204427 0.2417047  0.24188747 0.24245453 0.24296586 0.24271472
 0.24158101 0.24090417 0.24070996 0.24027175 0.2395574  0.23889606
 0.23868953 0.23904645 0.2393513  0.23941426 0.2392468  0.23947528
 0.23980597 0.23945157 0.2389863  0.23903438 0.23941708 0.23968746
 0.23960617 0.23937657 0.23938613 0.23961851 0.239706   0.23907016
 0.23761423 0.23651212 0.23550622 0.2344727  0.23343553 0.232833
 0.23292552 0.23348066 0.23370372 0.23352726 0.23329458 0.23386154
 0.23485091 0.23494075 0.23468296 0.23460248 0.2348317  0.23514707
 0.23515368 0.23491506 0.23489247 0.23511891 0.23521636 0.23451303
 0.23306768 0.23219317 0.23164593 0.23060873 0.22953767 0.22884996
 0.229005   0.2296292  0.23018587 0.23034734 0.2301898  0.23050936
 0.23115873 0.23110901 0.23078838 0.23057292 0.23054697 0.23067448
 0.23057953 0.23034808 0.23045611 0.23084359 0.23106079 0.23035617
 0.22893253 0.22816543 0.22776373 0.22713915 0.22644547 0.22602364
 0.22626443 0.2271002  0.22766265 0.22803695 0.22834063 0.22922748
 0.23038724 0.23024976 0.22949657 0.2291501  0.2294168  0.22999765
 0.23000085 0.2292219  0.22875705 0.22946596 0.23066694 0.22968608]
