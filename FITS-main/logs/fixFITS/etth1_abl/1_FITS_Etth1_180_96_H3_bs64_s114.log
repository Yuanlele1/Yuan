Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=34, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_180_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_180_96_FITS_ETTh1_ftM_sl180_ll48_pl96_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8365
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=34, out_features=52, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1584128.0
params:  1820.0
Trainable parameters:  1820
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.262899398803711
Epoch: 1, Steps: 65 | Train Loss: 0.6310739 Vali Loss: 1.1079763 Test Loss: 0.6066000
Validation loss decreased (inf --> 1.107976).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.34633207321167
Epoch: 2, Steps: 65 | Train Loss: 0.4620581 Vali Loss: 0.8997544 Test Loss: 0.4634276
Validation loss decreased (1.107976 --> 0.899754).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.2898149490356445
Epoch: 3, Steps: 65 | Train Loss: 0.4046629 Vali Loss: 0.8236913 Test Loss: 0.4163382
Validation loss decreased (0.899754 --> 0.823691).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.2374963760375977
Epoch: 4, Steps: 65 | Train Loss: 0.3829689 Vali Loss: 0.7858196 Test Loss: 0.3989230
Validation loss decreased (0.823691 --> 0.785820).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.2968950271606445
Epoch: 5, Steps: 65 | Train Loss: 0.3728299 Vali Loss: 0.7702106 Test Loss: 0.3911578
Validation loss decreased (0.785820 --> 0.770211).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.7095541954040527
Epoch: 6, Steps: 65 | Train Loss: 0.3675494 Vali Loss: 0.7523577 Test Loss: 0.3872048
Validation loss decreased (0.770211 --> 0.752358).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.2621862888336182
Epoch: 7, Steps: 65 | Train Loss: 0.3643996 Vali Loss: 0.7503018 Test Loss: 0.3855184
Validation loss decreased (0.752358 --> 0.750302).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.1966829299926758
Epoch: 8, Steps: 65 | Train Loss: 0.3621159 Vali Loss: 0.7409958 Test Loss: 0.3843556
Validation loss decreased (0.750302 --> 0.740996).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.3775315284729004
Epoch: 9, Steps: 65 | Train Loss: 0.3602494 Vali Loss: 0.7340026 Test Loss: 0.3838436
Validation loss decreased (0.740996 --> 0.734003).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.2502598762512207
Epoch: 10, Steps: 65 | Train Loss: 0.3590932 Vali Loss: 0.7340082 Test Loss: 0.3836942
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.4339618682861328
Epoch: 11, Steps: 65 | Train Loss: 0.3584381 Vali Loss: 0.7304540 Test Loss: 0.3835309
Validation loss decreased (0.734003 --> 0.730454).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.3576533794403076
Epoch: 12, Steps: 65 | Train Loss: 0.3575791 Vali Loss: 0.7288131 Test Loss: 0.3836435
Validation loss decreased (0.730454 --> 0.728813).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.2162935733795166
Epoch: 13, Steps: 65 | Train Loss: 0.3568745 Vali Loss: 0.7296581 Test Loss: 0.3836651
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.1019790172576904
Epoch: 14, Steps: 65 | Train Loss: 0.3563186 Vali Loss: 0.7272332 Test Loss: 0.3837741
Validation loss decreased (0.728813 --> 0.727233).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.3962500095367432
Epoch: 15, Steps: 65 | Train Loss: 0.3558782 Vali Loss: 0.7218839 Test Loss: 0.3840235
Validation loss decreased (0.727233 --> 0.721884).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.2401127815246582
Epoch: 16, Steps: 65 | Train Loss: 0.3558316 Vali Loss: 0.7228696 Test Loss: 0.3841072
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.2331669330596924
Epoch: 17, Steps: 65 | Train Loss: 0.3554756 Vali Loss: 0.7248847 Test Loss: 0.3842386
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.2596652507781982
Epoch: 18, Steps: 65 | Train Loss: 0.3553998 Vali Loss: 0.7176116 Test Loss: 0.3842772
Validation loss decreased (0.721884 --> 0.717612).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.2583234310150146
Epoch: 19, Steps: 65 | Train Loss: 0.3551395 Vali Loss: 0.7194943 Test Loss: 0.3844814
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.3329427242279053
Epoch: 20, Steps: 65 | Train Loss: 0.3545322 Vali Loss: 0.7220238 Test Loss: 0.3846337
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.4788167476654053
Epoch: 21, Steps: 65 | Train Loss: 0.3545098 Vali Loss: 0.7150958 Test Loss: 0.3847664
Validation loss decreased (0.717612 --> 0.715096).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.1921963691711426
Epoch: 22, Steps: 65 | Train Loss: 0.3543526 Vali Loss: 0.7177750 Test Loss: 0.3848662
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.3376200199127197
Epoch: 23, Steps: 65 | Train Loss: 0.3540993 Vali Loss: 0.7173725 Test Loss: 0.3849765
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.3271780014038086
Epoch: 24, Steps: 65 | Train Loss: 0.3543186 Vali Loss: 0.7191541 Test Loss: 0.3850927
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.3472309112548828
Epoch: 25, Steps: 65 | Train Loss: 0.3539667 Vali Loss: 0.7173552 Test Loss: 0.3851457
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.157470464706421
Epoch: 26, Steps: 65 | Train Loss: 0.3541331 Vali Loss: 0.7196341 Test Loss: 0.3851612
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.2234148979187012
Epoch: 27, Steps: 65 | Train Loss: 0.3536979 Vali Loss: 0.7156708 Test Loss: 0.3852896
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.2300019264221191
Epoch: 28, Steps: 65 | Train Loss: 0.3535817 Vali Loss: 0.7190024 Test Loss: 0.3853497
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.2677373886108398
Epoch: 29, Steps: 65 | Train Loss: 0.3537226 Vali Loss: 0.7184317 Test Loss: 0.3854554
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.2626771926879883
Epoch: 30, Steps: 65 | Train Loss: 0.3540114 Vali Loss: 0.7135618 Test Loss: 0.3854549
Validation loss decreased (0.715096 --> 0.713562).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.2623672485351562
Epoch: 31, Steps: 65 | Train Loss: 0.3533302 Vali Loss: 0.7224334 Test Loss: 0.3855458
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.3380911350250244
Epoch: 32, Steps: 65 | Train Loss: 0.3538477 Vali Loss: 0.7171134 Test Loss: 0.3856481
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.252176284790039
Epoch: 33, Steps: 65 | Train Loss: 0.3532376 Vali Loss: 0.7204642 Test Loss: 0.3856745
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.282637596130371
Epoch: 34, Steps: 65 | Train Loss: 0.3535236 Vali Loss: 0.7107387 Test Loss: 0.3856729
Validation loss decreased (0.713562 --> 0.710739).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.2742094993591309
Epoch: 35, Steps: 65 | Train Loss: 0.3536085 Vali Loss: 0.7148269 Test Loss: 0.3857422
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.2804195880889893
Epoch: 36, Steps: 65 | Train Loss: 0.3532177 Vali Loss: 0.7189159 Test Loss: 0.3857967
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.2629904747009277
Epoch: 37, Steps: 65 | Train Loss: 0.3533668 Vali Loss: 0.7152792 Test Loss: 0.3857694
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.3313634395599365
Epoch: 38, Steps: 65 | Train Loss: 0.3535558 Vali Loss: 0.7169845 Test Loss: 0.3858347
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.2905802726745605
Epoch: 39, Steps: 65 | Train Loss: 0.3536032 Vali Loss: 0.7146522 Test Loss: 0.3858298
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.286156415939331
Epoch: 40, Steps: 65 | Train Loss: 0.3535459 Vali Loss: 0.7150058 Test Loss: 0.3858538
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.3359031677246094
Epoch: 41, Steps: 65 | Train Loss: 0.3534981 Vali Loss: 0.7148143 Test Loss: 0.3858616
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.2454640865325928
Epoch: 42, Steps: 65 | Train Loss: 0.3533033 Vali Loss: 0.7158539 Test Loss: 0.3859413
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.2485871315002441
Epoch: 43, Steps: 65 | Train Loss: 0.3538402 Vali Loss: 0.7168742 Test Loss: 0.3859321
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.238304853439331
Epoch: 44, Steps: 65 | Train Loss: 0.3534526 Vali Loss: 0.7125814 Test Loss: 0.3859785
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.5507817268371582
Epoch: 45, Steps: 65 | Train Loss: 0.3536714 Vali Loss: 0.7136760 Test Loss: 0.3860276
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.3383915424346924
Epoch: 46, Steps: 65 | Train Loss: 0.3532971 Vali Loss: 0.7094852 Test Loss: 0.3860124
Validation loss decreased (0.710739 --> 0.709485).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.4091806411743164
Epoch: 47, Steps: 65 | Train Loss: 0.3534651 Vali Loss: 0.7131160 Test Loss: 0.3860334
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.5638251304626465
Epoch: 48, Steps: 65 | Train Loss: 0.3531950 Vali Loss: 0.7147640 Test Loss: 0.3860348
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.4231350421905518
Epoch: 49, Steps: 65 | Train Loss: 0.3534915 Vali Loss: 0.7149056 Test Loss: 0.3860500
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.326355218887329
Epoch: 50, Steps: 65 | Train Loss: 0.3532758 Vali Loss: 0.7151274 Test Loss: 0.3860508
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.1686820983886719
Epoch: 51, Steps: 65 | Train Loss: 0.3536326 Vali Loss: 0.7149000 Test Loss: 0.3860608
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.2506141662597656
Epoch: 52, Steps: 65 | Train Loss: 0.3534649 Vali Loss: 0.7158670 Test Loss: 0.3860641
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.1229689121246338
Epoch: 53, Steps: 65 | Train Loss: 0.3532627 Vali Loss: 0.7110615 Test Loss: 0.3861038
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.2776427268981934
Epoch: 54, Steps: 65 | Train Loss: 0.3530596 Vali Loss: 0.7147516 Test Loss: 0.3861156
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.2049541473388672
Epoch: 55, Steps: 65 | Train Loss: 0.3534246 Vali Loss: 0.7119476 Test Loss: 0.3861223
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.273205280303955
Epoch: 56, Steps: 65 | Train Loss: 0.3532555 Vali Loss: 0.7135307 Test Loss: 0.3861248
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.2770085334777832
Epoch: 57, Steps: 65 | Train Loss: 0.3532961 Vali Loss: 0.7120292 Test Loss: 0.3861217
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.3368275165557861
Epoch: 58, Steps: 65 | Train Loss: 0.3532951 Vali Loss: 0.7141652 Test Loss: 0.3861254
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.2151288986206055
Epoch: 59, Steps: 65 | Train Loss: 0.3533243 Vali Loss: 0.7150529 Test Loss: 0.3861503
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.2938880920410156
Epoch: 60, Steps: 65 | Train Loss: 0.3535135 Vali Loss: 0.7145225 Test Loss: 0.3861505
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.8055181503295898
Epoch: 61, Steps: 65 | Train Loss: 0.3533628 Vali Loss: 0.7151465 Test Loss: 0.3861776
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.2665352821350098
Epoch: 62, Steps: 65 | Train Loss: 0.3531008 Vali Loss: 0.7113475 Test Loss: 0.3861616
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.1963295936584473
Epoch: 63, Steps: 65 | Train Loss: 0.3530473 Vali Loss: 0.7062845 Test Loss: 0.3861677
Validation loss decreased (0.709485 --> 0.706284).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.4040417671203613
Epoch: 64, Steps: 65 | Train Loss: 0.3532140 Vali Loss: 0.7116698 Test Loss: 0.3861766
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.2163028717041016
Epoch: 65, Steps: 65 | Train Loss: 0.3530360 Vali Loss: 0.7090807 Test Loss: 0.3861945
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.5836641788482666
Epoch: 66, Steps: 65 | Train Loss: 0.3531248 Vali Loss: 0.7127784 Test Loss: 0.3861826
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.430485725402832
Epoch: 67, Steps: 65 | Train Loss: 0.3530786 Vali Loss: 0.7148063 Test Loss: 0.3861928
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.220902919769287
Epoch: 68, Steps: 65 | Train Loss: 0.3531755 Vali Loss: 0.7166778 Test Loss: 0.3861753
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.4153330326080322
Epoch: 69, Steps: 65 | Train Loss: 0.3531365 Vali Loss: 0.7152873 Test Loss: 0.3861889
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.219963788986206
Epoch: 70, Steps: 65 | Train Loss: 0.3532070 Vali Loss: 0.7138809 Test Loss: 0.3862043
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.287165641784668
Epoch: 71, Steps: 65 | Train Loss: 0.3531131 Vali Loss: 0.7116150 Test Loss: 0.3862008
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.2919113636016846
Epoch: 72, Steps: 65 | Train Loss: 0.3532671 Vali Loss: 0.7113876 Test Loss: 0.3862052
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.2781541347503662
Epoch: 73, Steps: 65 | Train Loss: 0.3531080 Vali Loss: 0.7124707 Test Loss: 0.3862029
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.235853672027588
Epoch: 74, Steps: 65 | Train Loss: 0.3535299 Vali Loss: 0.7122372 Test Loss: 0.3862030
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.1191000938415527
Epoch: 75, Steps: 65 | Train Loss: 0.3531221 Vali Loss: 0.7103451 Test Loss: 0.3862155
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.2312426567077637
Epoch: 76, Steps: 65 | Train Loss: 0.3534169 Vali Loss: 0.7158372 Test Loss: 0.3862250
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.3286397457122803
Epoch: 77, Steps: 65 | Train Loss: 0.3531591 Vali Loss: 0.7138579 Test Loss: 0.3862212
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.2932302951812744
Epoch: 78, Steps: 65 | Train Loss: 0.3530426 Vali Loss: 0.7131063 Test Loss: 0.3862241
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.3157994747161865
Epoch: 79, Steps: 65 | Train Loss: 0.3534012 Vali Loss: 0.7122134 Test Loss: 0.3862244
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.2850089073181152
Epoch: 80, Steps: 65 | Train Loss: 0.3531718 Vali Loss: 0.7124293 Test Loss: 0.3862337
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.244422197341919
Epoch: 81, Steps: 65 | Train Loss: 0.3532064 Vali Loss: 0.7115302 Test Loss: 0.3862338
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.306126356124878
Epoch: 82, Steps: 65 | Train Loss: 0.3532429 Vali Loss: 0.7096475 Test Loss: 0.3862338
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.3387744426727295
Epoch: 83, Steps: 65 | Train Loss: 0.3531950 Vali Loss: 0.7118104 Test Loss: 0.3862241
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_180_96_FITS_ETTh1_ftM_sl180_ll48_pl96_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.3855103552341461, mae:0.3996008634567261, rse:0.5897607803344727, corr:[0.2718717  0.27584916 0.27572748 0.27377024 0.2716844  0.2702796
 0.2698183  0.2696875  0.26910257 0.26866242 0.26869267 0.2689938
 0.26888174 0.26798213 0.26736605 0.26755658 0.26795408 0.26797473
 0.26762927 0.2673009  0.267368   0.26777    0.267883   0.26728594
 0.26619548 0.26581287 0.2657202  0.2653263  0.26439297 0.2636018
 0.2634375  0.26363647 0.26356882 0.26306868 0.2626685  0.26301688
 0.26365402 0.26361492 0.2632992  0.26330614 0.2637919  0.26428124
 0.26429716 0.26423416 0.26460603 0.2650969  0.26525837 0.2644285
 0.26273555 0.26173702 0.26089725 0.25971204 0.25811893 0.2566591
 0.25601733 0.25604916 0.25610897 0.25616053 0.2561041  0.25666958
 0.25730178 0.25703865 0.25648966 0.25635603 0.2567644  0.25718853
 0.25717646 0.2567792  0.25662214 0.25684887 0.25697276 0.2560548
 0.25422376 0.25301647 0.25242594 0.25205544 0.25160572 0.2510774
 0.25090882 0.25096667 0.25066888 0.2501066  0.2496016  0.24994579
 0.25085735 0.2508188  0.25019744 0.2497725  0.24992114 0.25027534
 0.24982797 0.24836119 0.24718873 0.24745697 0.24940433 0.25024128]
