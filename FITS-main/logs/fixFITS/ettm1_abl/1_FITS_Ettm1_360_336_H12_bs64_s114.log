Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=58, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_360_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_360_336_FITS_ETTm1_ftM_sl360_ll48_pl336_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33865
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=58, out_features=112, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  5820416.0
params:  6608.0
Trainable parameters:  6608
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4200366
	speed: 0.0283s/iter; left time: 745.2934s
	iters: 200, epoch: 1 | loss: 0.3660594
	speed: 0.0275s/iter; left time: 719.6949s
Epoch: 1 cost time: 6.967798709869385
Epoch: 1, Steps: 264 | Train Loss: 0.4596400 Vali Loss: 0.7234665 Test Loss: 0.3961429
Validation loss decreased (inf --> 0.723466).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3473901
	speed: 0.1173s/iter; left time: 3054.2920s
	iters: 200, epoch: 2 | loss: 0.3657075
	speed: 0.0300s/iter; left time: 778.7176s
Epoch: 2 cost time: 8.289981126785278
Epoch: 2, Steps: 264 | Train Loss: 0.3634930 Vali Loss: 0.6800330 Test Loss: 0.3764315
Validation loss decreased (0.723466 --> 0.680033).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3764840
	speed: 0.1123s/iter; left time: 2893.5829s
	iters: 200, epoch: 3 | loss: 0.3348953
	speed: 0.0233s/iter; left time: 597.9207s
Epoch: 3 cost time: 6.843669414520264
Epoch: 3, Steps: 264 | Train Loss: 0.3535334 Vali Loss: 0.6684041 Test Loss: 0.3724653
Validation loss decreased (0.680033 --> 0.668404).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3449902
	speed: 0.1087s/iter; left time: 2773.2192s
	iters: 200, epoch: 4 | loss: 0.3481170
	speed: 0.0203s/iter; left time: 515.2783s
Epoch: 4 cost time: 6.218873500823975
Epoch: 4, Steps: 264 | Train Loss: 0.3503903 Vali Loss: 0.6628388 Test Loss: 0.3716698
Validation loss decreased (0.668404 --> 0.662839).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3898326
	speed: 0.1035s/iter; left time: 2613.2033s
	iters: 200, epoch: 5 | loss: 0.3121071
	speed: 0.0250s/iter; left time: 627.8467s
Epoch: 5 cost time: 6.926318168640137
Epoch: 5, Steps: 264 | Train Loss: 0.3491771 Vali Loss: 0.6600935 Test Loss: 0.3711831
Validation loss decreased (0.662839 --> 0.660094).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3341063
	speed: 0.1017s/iter; left time: 2540.7786s
	iters: 200, epoch: 6 | loss: 0.3490353
	speed: 0.0202s/iter; left time: 502.7339s
Epoch: 6 cost time: 5.824123859405518
Epoch: 6, Steps: 264 | Train Loss: 0.3484686 Vali Loss: 0.6576900 Test Loss: 0.3713176
Validation loss decreased (0.660094 --> 0.657690).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3381902
	speed: 0.0991s/iter; left time: 2449.4394s
	iters: 200, epoch: 7 | loss: 0.3623855
	speed: 0.0268s/iter; left time: 658.6109s
Epoch: 7 cost time: 7.606838941574097
Epoch: 7, Steps: 264 | Train Loss: 0.3480836 Vali Loss: 0.6576117 Test Loss: 0.3714575
Validation loss decreased (0.657690 --> 0.657612).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3410060
	speed: 0.1248s/iter; left time: 3052.3587s
	iters: 200, epoch: 8 | loss: 0.3238191
	speed: 0.0310s/iter; left time: 754.0565s
Epoch: 8 cost time: 7.654250860214233
Epoch: 8, Steps: 264 | Train Loss: 0.3477930 Vali Loss: 0.6567972 Test Loss: 0.3713607
Validation loss decreased (0.657612 --> 0.656797).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3439029
	speed: 0.1108s/iter; left time: 2679.5393s
	iters: 200, epoch: 9 | loss: 0.3659285
	speed: 0.0224s/iter; left time: 538.7430s
Epoch: 9 cost time: 6.375950336456299
Epoch: 9, Steps: 264 | Train Loss: 0.3477600 Vali Loss: 0.6562724 Test Loss: 0.3717538
Validation loss decreased (0.656797 --> 0.656272).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3546175
	speed: 0.1067s/iter; left time: 2552.4095s
	iters: 200, epoch: 10 | loss: 0.3364257
	speed: 0.0191s/iter; left time: 454.1796s
Epoch: 10 cost time: 6.130481481552124
Epoch: 10, Steps: 264 | Train Loss: 0.3475828 Vali Loss: 0.6559026 Test Loss: 0.3713600
Validation loss decreased (0.656272 --> 0.655903).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3743999
	speed: 0.1012s/iter; left time: 2394.6177s
	iters: 200, epoch: 11 | loss: 0.3339657
	speed: 0.0222s/iter; left time: 522.0868s
Epoch: 11 cost time: 6.578238487243652
Epoch: 11, Steps: 264 | Train Loss: 0.3474212 Vali Loss: 0.6549436 Test Loss: 0.3716533
Validation loss decreased (0.655903 --> 0.654944).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3105172
	speed: 0.0995s/iter; left time: 2328.1230s
	iters: 200, epoch: 12 | loss: 0.3344566
	speed: 0.0212s/iter; left time: 493.1406s
Epoch: 12 cost time: 6.009166955947876
Epoch: 12, Steps: 264 | Train Loss: 0.3474321 Vali Loss: 0.6546781 Test Loss: 0.3716486
Validation loss decreased (0.654944 --> 0.654678).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3664108
	speed: 0.1197s/iter; left time: 2769.9976s
	iters: 200, epoch: 13 | loss: 0.3501165
	speed: 0.0215s/iter; left time: 494.4258s
Epoch: 13 cost time: 6.861367225646973
Epoch: 13, Steps: 264 | Train Loss: 0.3473629 Vali Loss: 0.6545708 Test Loss: 0.3715589
Validation loss decreased (0.654678 --> 0.654571).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3534527
	speed: 0.1035s/iter; left time: 2367.0696s
	iters: 200, epoch: 14 | loss: 0.3686876
	speed: 0.0225s/iter; left time: 513.0478s
Epoch: 14 cost time: 6.457730054855347
Epoch: 14, Steps: 264 | Train Loss: 0.3473820 Vali Loss: 0.6541482 Test Loss: 0.3715787
Validation loss decreased (0.654571 --> 0.654148).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3179035
	speed: 0.1162s/iter; left time: 2625.8299s
	iters: 200, epoch: 15 | loss: 0.3411437
	speed: 0.0269s/iter; left time: 606.2871s
Epoch: 15 cost time: 6.8465259075164795
Epoch: 15, Steps: 264 | Train Loss: 0.3473526 Vali Loss: 0.6541988 Test Loss: 0.3718357
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3345411
	speed: 0.1091s/iter; left time: 2436.8859s
	iters: 200, epoch: 16 | loss: 0.3841104
	speed: 0.0194s/iter; left time: 431.7771s
Epoch: 16 cost time: 6.327575206756592
Epoch: 16, Steps: 264 | Train Loss: 0.3473561 Vali Loss: 0.6539316 Test Loss: 0.3716420
Validation loss decreased (0.654148 --> 0.653932).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3630928
	speed: 0.1062s/iter; left time: 2343.5196s
	iters: 200, epoch: 17 | loss: 0.3115473
	speed: 0.0228s/iter; left time: 501.4268s
Epoch: 17 cost time: 6.559460639953613
Epoch: 17, Steps: 264 | Train Loss: 0.3472514 Vali Loss: 0.6538077 Test Loss: 0.3718853
Validation loss decreased (0.653932 --> 0.653808).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3408684
	speed: 0.1093s/iter; left time: 2385.2207s
	iters: 200, epoch: 18 | loss: 0.3475746
	speed: 0.0230s/iter; left time: 500.1518s
Epoch: 18 cost time: 6.381085634231567
Epoch: 18, Steps: 264 | Train Loss: 0.3472782 Vali Loss: 0.6539982 Test Loss: 0.3715516
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3220958
	speed: 0.1139s/iter; left time: 2453.4767s
	iters: 200, epoch: 19 | loss: 0.3577824
	speed: 0.0231s/iter; left time: 496.1092s
Epoch: 19 cost time: 7.241929531097412
Epoch: 19, Steps: 264 | Train Loss: 0.3471931 Vali Loss: 0.6537188 Test Loss: 0.3717290
Validation loss decreased (0.653808 --> 0.653719).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4034482
	speed: 0.1107s/iter; left time: 2355.4176s
	iters: 200, epoch: 20 | loss: 0.3732414
	speed: 0.0297s/iter; left time: 628.3483s
Epoch: 20 cost time: 7.290963888168335
Epoch: 20, Steps: 264 | Train Loss: 0.3472379 Vali Loss: 0.6535075 Test Loss: 0.3717332
Validation loss decreased (0.653719 --> 0.653507).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3810585
	speed: 0.1057s/iter; left time: 2221.0987s
	iters: 200, epoch: 21 | loss: 0.3368636
	speed: 0.0217s/iter; left time: 453.2290s
Epoch: 21 cost time: 5.888005495071411
Epoch: 21, Steps: 264 | Train Loss: 0.3471549 Vali Loss: 0.6537158 Test Loss: 0.3716469
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3457483
	speed: 0.0937s/iter; left time: 1945.8562s
	iters: 200, epoch: 22 | loss: 0.3211346
	speed: 0.0190s/iter; left time: 393.4971s
Epoch: 22 cost time: 5.802715301513672
Epoch: 22, Steps: 264 | Train Loss: 0.3470608 Vali Loss: 0.6540650 Test Loss: 0.3716702
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3647984
	speed: 0.1046s/iter; left time: 2142.7910s
	iters: 200, epoch: 23 | loss: 0.3686725
	speed: 0.0202s/iter; left time: 411.0752s
Epoch: 23 cost time: 6.101165771484375
Epoch: 23, Steps: 264 | Train Loss: 0.3471177 Vali Loss: 0.6533689 Test Loss: 0.3716072
Validation loss decreased (0.653507 --> 0.653369).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3647709
	speed: 0.1014s/iter; left time: 2051.8588s
	iters: 200, epoch: 24 | loss: 0.2905962
	speed: 0.0197s/iter; left time: 396.2142s
Epoch: 24 cost time: 6.280050992965698
Epoch: 24, Steps: 264 | Train Loss: 0.3471598 Vali Loss: 0.6534733 Test Loss: 0.3717752
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3736775
	speed: 0.1113s/iter; left time: 2222.0679s
	iters: 200, epoch: 25 | loss: 0.3505922
	speed: 0.0219s/iter; left time: 435.0440s
Epoch: 25 cost time: 7.201351881027222
Epoch: 25, Steps: 264 | Train Loss: 0.3470304 Vali Loss: 0.6535755 Test Loss: 0.3716581
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3201737
	speed: 0.1047s/iter; left time: 2062.6503s
	iters: 200, epoch: 26 | loss: 0.3524674
	speed: 0.0247s/iter; left time: 485.0293s
Epoch: 26 cost time: 6.455204486846924
Epoch: 26, Steps: 264 | Train Loss: 0.3470863 Vali Loss: 0.6529407 Test Loss: 0.3717203
Validation loss decreased (0.653369 --> 0.652941).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3353884
	speed: 0.1092s/iter; left time: 2122.9755s
	iters: 200, epoch: 27 | loss: 0.3553922
	speed: 0.0206s/iter; left time: 397.8823s
Epoch: 27 cost time: 6.659910678863525
Epoch: 27, Steps: 264 | Train Loss: 0.3470103 Vali Loss: 0.6534130 Test Loss: 0.3717800
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3497495
	speed: 0.1073s/iter; left time: 2058.1339s
	iters: 200, epoch: 28 | loss: 0.3331795
	speed: 0.0236s/iter; left time: 450.5214s
Epoch: 28 cost time: 6.4833595752716064
Epoch: 28, Steps: 264 | Train Loss: 0.3471559 Vali Loss: 0.6530607 Test Loss: 0.3716953
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3690856
	speed: 0.1156s/iter; left time: 2186.1417s
	iters: 200, epoch: 29 | loss: 0.3274667
	speed: 0.0209s/iter; left time: 393.8078s
Epoch: 29 cost time: 6.507406711578369
Epoch: 29, Steps: 264 | Train Loss: 0.3470822 Vali Loss: 0.6531638 Test Loss: 0.3718602
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3643179
	speed: 0.0974s/iter; left time: 1815.3072s
	iters: 200, epoch: 30 | loss: 0.3465690
	speed: 0.0217s/iter; left time: 403.3456s
Epoch: 30 cost time: 6.041814565658569
Epoch: 30, Steps: 264 | Train Loss: 0.3470818 Vali Loss: 0.6527882 Test Loss: 0.3715579
Validation loss decreased (0.652941 --> 0.652788).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4311383
	speed: 0.1111s/iter; left time: 2042.4301s
	iters: 200, epoch: 31 | loss: 0.4002656
	speed: 0.0199s/iter; left time: 364.6215s
Epoch: 31 cost time: 5.909160614013672
Epoch: 31, Steps: 264 | Train Loss: 0.3470995 Vali Loss: 0.6530062 Test Loss: 0.3717541
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3376807
	speed: 0.1151s/iter; left time: 2085.5598s
	iters: 200, epoch: 32 | loss: 0.3612319
	speed: 0.0230s/iter; left time: 413.9899s
Epoch: 32 cost time: 6.798426866531372
Epoch: 32, Steps: 264 | Train Loss: 0.3471379 Vali Loss: 0.6541879 Test Loss: 0.3716656
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3407620
	speed: 0.1022s/iter; left time: 1824.6994s
	iters: 200, epoch: 33 | loss: 0.3322743
	speed: 0.0192s/iter; left time: 341.3499s
Epoch: 33 cost time: 5.7839579582214355
Epoch: 33, Steps: 264 | Train Loss: 0.3470070 Vali Loss: 0.6534466 Test Loss: 0.3717938
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3523881
	speed: 0.0968s/iter; left time: 1701.8899s
	iters: 200, epoch: 34 | loss: 0.3228021
	speed: 0.0200s/iter; left time: 350.3258s
Epoch: 34 cost time: 6.040240049362183
Epoch: 34, Steps: 264 | Train Loss: 0.3471177 Vali Loss: 0.6537101 Test Loss: 0.3717160
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3889109
	speed: 0.0903s/iter; left time: 1563.9656s
	iters: 200, epoch: 35 | loss: 0.3994896
	speed: 0.0220s/iter; left time: 379.6619s
Epoch: 35 cost time: 5.8997962474823
Epoch: 35, Steps: 264 | Train Loss: 0.3469883 Vali Loss: 0.6535383 Test Loss: 0.3716778
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3854157
	speed: 0.1010s/iter; left time: 1723.1775s
	iters: 200, epoch: 36 | loss: 0.3531255
	speed: 0.0318s/iter; left time: 539.6340s
Epoch: 36 cost time: 8.496248245239258
Epoch: 36, Steps: 264 | Train Loss: 0.3470057 Vali Loss: 0.6534395 Test Loss: 0.3717162
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3287331
	speed: 0.1192s/iter; left time: 2001.3644s
	iters: 200, epoch: 37 | loss: 0.3140585
	speed: 0.0284s/iter; left time: 473.8906s
Epoch: 37 cost time: 7.869782447814941
Epoch: 37, Steps: 264 | Train Loss: 0.3470086 Vali Loss: 0.6533559 Test Loss: 0.3716706
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3600153
	speed: 0.1266s/iter; left time: 2093.3349s
	iters: 200, epoch: 38 | loss: 0.3708200
	speed: 0.0221s/iter; left time: 362.8208s
Epoch: 38 cost time: 7.417353391647339
Epoch: 38, Steps: 264 | Train Loss: 0.3469462 Vali Loss: 0.6529816 Test Loss: 0.3716804
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3235244
	speed: 0.1023s/iter; left time: 1663.7269s
	iters: 200, epoch: 39 | loss: 0.3200367
	speed: 0.0205s/iter; left time: 331.2130s
Epoch: 39 cost time: 6.2403974533081055
Epoch: 39, Steps: 264 | Train Loss: 0.3470494 Vali Loss: 0.6537536 Test Loss: 0.3716626
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.3130581
	speed: 0.0988s/iter; left time: 1581.2534s
	iters: 200, epoch: 40 | loss: 0.3380934
	speed: 0.0205s/iter; left time: 325.4059s
Epoch: 40 cost time: 6.567460536956787
Epoch: 40, Steps: 264 | Train Loss: 0.3470330 Vali Loss: 0.6529861 Test Loss: 0.3717136
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3697948
	speed: 0.1046s/iter; left time: 1645.8942s
	iters: 200, epoch: 41 | loss: 0.3088323
	speed: 0.0200s/iter; left time: 312.1207s
Epoch: 41 cost time: 6.037094831466675
Epoch: 41, Steps: 264 | Train Loss: 0.3470604 Vali Loss: 0.6537806 Test Loss: 0.3717601
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3158807
	speed: 0.1000s/iter; left time: 1547.2886s
	iters: 200, epoch: 42 | loss: 0.3475128
	speed: 0.0200s/iter; left time: 308.0757s
Epoch: 42 cost time: 6.2501280307769775
Epoch: 42, Steps: 264 | Train Loss: 0.3470049 Vali Loss: 0.6530581 Test Loss: 0.3717028
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3676004
	speed: 0.1012s/iter; left time: 1539.1702s
	iters: 200, epoch: 43 | loss: 0.3890359
	speed: 0.0228s/iter; left time: 344.7617s
Epoch: 43 cost time: 6.06928277015686
Epoch: 43, Steps: 264 | Train Loss: 0.3469950 Vali Loss: 0.6528998 Test Loss: 0.3717448
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.3359167
	speed: 0.1199s/iter; left time: 1791.7907s
	iters: 200, epoch: 44 | loss: 0.3169491
	speed: 0.0261s/iter; left time: 387.5537s
Epoch: 44 cost time: 7.662231206893921
Epoch: 44, Steps: 264 | Train Loss: 0.3470905 Vali Loss: 0.6529204 Test Loss: 0.3716559
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.3516194
	speed: 0.1132s/iter; left time: 1662.8687s
	iters: 200, epoch: 45 | loss: 0.3308164
	speed: 0.0214s/iter; left time: 311.9990s
Epoch: 45 cost time: 6.391921043395996
Epoch: 45, Steps: 264 | Train Loss: 0.3468598 Vali Loss: 0.6531357 Test Loss: 0.3717742
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.3494208
	speed: 0.1068s/iter; left time: 1539.6634s
	iters: 200, epoch: 46 | loss: 0.3299153
	speed: 0.0203s/iter; left time: 291.0335s
Epoch: 46 cost time: 6.370187997817993
Epoch: 46, Steps: 264 | Train Loss: 0.3468389 Vali Loss: 0.6533926 Test Loss: 0.3716893
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.3175870
	speed: 0.1079s/iter; left time: 1527.0169s
	iters: 200, epoch: 47 | loss: 0.3211040
	speed: 0.0326s/iter; left time: 458.3057s
Epoch: 47 cost time: 7.441490888595581
Epoch: 47, Steps: 264 | Train Loss: 0.3468940 Vali Loss: 0.6534867 Test Loss: 0.3716709
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.3450062
	speed: 0.1202s/iter; left time: 1669.4363s
	iters: 200, epoch: 48 | loss: 0.3350625
	speed: 0.0218s/iter; left time: 301.2713s
Epoch: 48 cost time: 7.362423896789551
Epoch: 48, Steps: 264 | Train Loss: 0.3470182 Vali Loss: 0.6531749 Test Loss: 0.3716978
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.3032148
	speed: 0.1172s/iter; left time: 1597.3145s
	iters: 200, epoch: 49 | loss: 0.3167296
	speed: 0.0269s/iter; left time: 363.6788s
Epoch: 49 cost time: 7.074258327484131
Epoch: 49, Steps: 264 | Train Loss: 0.3470131 Vali Loss: 0.6534684 Test Loss: 0.3717742
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.3402575
	speed: 0.1136s/iter; left time: 1518.0336s
	iters: 200, epoch: 50 | loss: 0.3511151
	speed: 0.0195s/iter; left time: 258.6032s
Epoch: 50 cost time: 5.921485185623169
Epoch: 50, Steps: 264 | Train Loss: 0.3470654 Vali Loss: 0.6528895 Test Loss: 0.3717183
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_360_336_FITS_ETTm1_ftM_sl360_ll48_pl336_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.37128883600234985, mae:0.3845411539077759, rse:0.5798347592353821, corr:[0.5408051  0.5475018  0.54839313 0.5474831  0.5474497  0.5482733
 0.5489712  0.5490176  0.5487198  0.54875696 0.5494755  0.5502106
 0.5506025  0.5506185  0.5502871  0.5494932  0.54831225 0.547001
 0.54564327 0.5444804  0.54347664 0.54261386 0.5415829  0.54047
 0.5393293  0.53812474 0.5370798  0.5363209  0.5357788  0.53532827
 0.5352838  0.53579617 0.5365514  0.537116   0.53714556 0.5368465
 0.53640115 0.5359978  0.5358347  0.53587335 0.53592473 0.5357294
 0.5352454  0.5347559  0.534434   0.5343508  0.53445405 0.5344192
 0.5340993  0.5337249  0.53343755 0.5332831  0.5332615  0.53321385
 0.5331054  0.533034   0.53302145 0.5330934  0.53320944 0.533135
 0.53295654 0.53266716 0.53241676 0.5322111  0.5322056  0.5323914
 0.5325874  0.53267217 0.5328476  0.5330852  0.5333651  0.53360647
 0.53381    0.5339272  0.5338861  0.53372514 0.5335729  0.5335135
 0.53349847 0.53343636 0.5332981  0.5331247  0.53293663 0.5326872
 0.53241944 0.53201747 0.5315658  0.53107697 0.5306622  0.530523
 0.53063864 0.5308018  0.5308253  0.53068197 0.5303204  0.5297716
 0.5291698  0.5286334  0.52816224 0.5276756  0.5272884  0.5270695
 0.527008   0.526976   0.52712744 0.5274621  0.52779794 0.528191
 0.52844787 0.52869505 0.5288853  0.5290377  0.5290685  0.52908707
 0.52906644 0.529068   0.52908486 0.52914155 0.52919674 0.5293554
 0.5294944  0.52944374 0.5292526  0.52911705 0.5290033  0.5287926
 0.52848786 0.5281855  0.5279722  0.52795106 0.5281003  0.5282541
 0.5282971  0.52806205 0.52766496 0.5272174  0.5268863  0.52665067
 0.52654195 0.52644813 0.5262637  0.5261088  0.5260543  0.5261546
 0.52632165 0.5264389  0.52636665 0.5261505  0.52595997 0.5257907
 0.5257313  0.52585125 0.5259613  0.525958   0.52586675 0.52580374
 0.525786   0.5257887  0.5257482  0.525711   0.5257629  0.52588814
 0.5260886  0.5262875  0.52650964 0.5267262  0.5269225  0.52722716
 0.5276003  0.52796245 0.5282211  0.5283295  0.52823037 0.52807283
 0.52798814 0.52805924 0.5281808  0.5282473  0.5281143  0.5278809
 0.5276251  0.5275082  0.5274316  0.5273871  0.5273246  0.5272528
 0.52719605 0.52720386 0.52723825 0.5272196  0.52707464 0.52680284
 0.5264031  0.5260034  0.52558255 0.5250769  0.5245773  0.52424794
 0.52397126 0.5236212  0.52327484 0.5229801  0.5227347  0.52255315
 0.5223783  0.5219981  0.52151483 0.5209876  0.52057683 0.52035546
 0.5201496  0.5199063  0.51950234 0.5190232  0.5185023  0.51813835
 0.5179538  0.5178253  0.5176002  0.5173772  0.51712763 0.5169243
 0.5169281  0.5170781  0.51726353 0.5173481  0.5173174  0.5171097
 0.51686454 0.5167415  0.5167289  0.5166862  0.5165412  0.51622486
 0.5158921  0.5156608  0.5154848  0.51549524 0.5155619  0.51558155
 0.5155243  0.5154101  0.51531863 0.5152146  0.5150729  0.5149824
 0.5149408  0.51494664 0.51499176 0.51507616 0.5150777  0.5150674
 0.5149902  0.51497793 0.5149666  0.5149251  0.51475567 0.5146315
 0.5145383  0.514566   0.51474214 0.51500934 0.5152236  0.5155018
 0.51579136 0.516027   0.51616216 0.51632535 0.51647884 0.51652604
 0.5165791  0.51661813 0.5166101  0.51660347 0.51654243 0.5165102
 0.51641023 0.5162997  0.51607245 0.51588315 0.51571035 0.5156128
 0.5156223  0.5156161  0.51554555 0.5153396  0.5149848  0.5144431
 0.51367253 0.5128796  0.51221424 0.5115381  0.511031   0.5107006
 0.5104557  0.5100406  0.5095863  0.5091337  0.5088622  0.5087185
 0.5086224  0.508443   0.5081205  0.5077291  0.5073696  0.5071735
 0.5072123  0.5072931  0.5073111  0.5072407  0.50715417 0.507121
 0.50723714 0.5073427  0.50719756 0.5069714  0.5066555  0.5063903
 0.5062429  0.5061426  0.5059565  0.50568056 0.5053515  0.5050513
 0.5048468  0.50470066 0.5044803  0.50424534 0.50395477 0.50373614
 0.5035653  0.5034227  0.50327545 0.50334466 0.5037819  0.5037533 ]
