Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_360_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_360_336_FITS_ETTm1_ftM_sl360_ll48_pl336_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33865
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=26, out_features=50, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1164800.0
params:  1350.0
Trainable parameters:  1350
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5667251
	speed: 0.0916s/iter; left time: 2409.4233s
	iters: 200, epoch: 1 | loss: 0.4089438
	speed: 0.0878s/iter; left time: 2301.1621s
Epoch: 1 cost time: 23.43272852897644
Epoch: 1, Steps: 264 | Train Loss: 0.5086951 Vali Loss: 0.7682263 Test Loss: 0.4333490
Validation loss decreased (inf --> 0.768226).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3833473
	speed: 0.5784s/iter; left time: 15058.5708s
	iters: 200, epoch: 2 | loss: 0.4133208
	speed: 0.1123s/iter; left time: 2913.5230s
Epoch: 2 cost time: 31.594237804412842
Epoch: 2, Steps: 264 | Train Loss: 0.3797455 Vali Loss: 0.6980535 Test Loss: 0.3897616
Validation loss decreased (0.768226 --> 0.698053).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3905291
	speed: 0.4348s/iter; left time: 11205.6570s
	iters: 200, epoch: 3 | loss: 0.3621910
	speed: 0.0916s/iter; left time: 2350.4524s
Epoch: 3 cost time: 22.314338445663452
Epoch: 3, Steps: 264 | Train Loss: 0.3630874 Vali Loss: 0.6788164 Test Loss: 0.3801048
Validation loss decreased (0.698053 --> 0.678816).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3566983
	speed: 0.3483s/iter; left time: 8884.1196s
	iters: 200, epoch: 4 | loss: 0.4133371
	speed: 0.0696s/iter; left time: 1769.2298s
Epoch: 4 cost time: 25.19446587562561
Epoch: 4, Steps: 264 | Train Loss: 0.3571348 Vali Loss: 0.6699995 Test Loss: 0.3769374
Validation loss decreased (0.678816 --> 0.670000).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3578189
	speed: 0.6977s/iter; left time: 17613.1448s
	iters: 200, epoch: 5 | loss: 0.3357916
	speed: 0.1408s/iter; left time: 3539.2930s
Epoch: 5 cost time: 42.461410999298096
Epoch: 5, Steps: 264 | Train Loss: 0.3547128 Vali Loss: 0.6669196 Test Loss: 0.3755237
Validation loss decreased (0.670000 --> 0.666920).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3089920
	speed: 0.5770s/iter; left time: 14414.0616s
	iters: 200, epoch: 6 | loss: 0.3307929
	speed: 0.1688s/iter; left time: 4200.7665s
Epoch: 6 cost time: 37.693660259246826
Epoch: 6, Steps: 264 | Train Loss: 0.3533717 Vali Loss: 0.6638849 Test Loss: 0.3752354
Validation loss decreased (0.666920 --> 0.663885).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3462941
	speed: 0.5958s/iter; left time: 14726.2192s
	iters: 200, epoch: 7 | loss: 0.3698038
	speed: 0.1347s/iter; left time: 3314.9607s
Epoch: 7 cost time: 33.93984079360962
Epoch: 7, Steps: 264 | Train Loss: 0.3526916 Vali Loss: 0.6620282 Test Loss: 0.3753208
Validation loss decreased (0.663885 --> 0.662028).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3335790
	speed: 0.5987s/iter; left time: 14640.4110s
	iters: 200, epoch: 8 | loss: 0.3090008
	speed: 0.1364s/iter; left time: 3322.1670s
Epoch: 8 cost time: 37.89552569389343
Epoch: 8, Steps: 264 | Train Loss: 0.3522419 Vali Loss: 0.6618438 Test Loss: 0.3753503
Validation loss decreased (0.662028 --> 0.661844).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3592728
	speed: 0.5908s/iter; left time: 14291.6625s
	iters: 200, epoch: 9 | loss: 0.3443876
	speed: 0.1214s/iter; left time: 2924.7176s
Epoch: 9 cost time: 34.82926321029663
Epoch: 9, Steps: 264 | Train Loss: 0.3521506 Vali Loss: 0.6605560 Test Loss: 0.3759028
Validation loss decreased (0.661844 --> 0.660556).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3599259
	speed: 0.5377s/iter; left time: 12864.9478s
	iters: 200, epoch: 10 | loss: 0.3475117
	speed: 0.1277s/iter; left time: 3043.0546s
Epoch: 10 cost time: 33.30637049674988
Epoch: 10, Steps: 264 | Train Loss: 0.3518705 Vali Loss: 0.6595839 Test Loss: 0.3754665
Validation loss decreased (0.660556 --> 0.659584).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3366000
	speed: 0.5812s/iter; left time: 13750.7015s
	iters: 200, epoch: 11 | loss: 0.3312147
	speed: 0.1416s/iter; left time: 3336.9129s
Epoch: 11 cost time: 35.06536555290222
Epoch: 11, Steps: 264 | Train Loss: 0.3518489 Vali Loss: 0.6596489 Test Loss: 0.3756537
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3656487
	speed: 0.5657s/iter; left time: 13236.5529s
	iters: 200, epoch: 12 | loss: 0.3780184
	speed: 0.1213s/iter; left time: 2825.9300s
Epoch: 12 cost time: 33.11334943771362
Epoch: 12, Steps: 264 | Train Loss: 0.3517679 Vali Loss: 0.6597437 Test Loss: 0.3756976
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3468894
	speed: 0.5195s/iter; left time: 12018.4349s
	iters: 200, epoch: 13 | loss: 0.3595320
	speed: 0.1199s/iter; left time: 2760.9981s
Epoch: 13 cost time: 32.89378023147583
Epoch: 13, Steps: 264 | Train Loss: 0.3517906 Vali Loss: 0.6588275 Test Loss: 0.3758339
Validation loss decreased (0.659584 --> 0.658827).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3644637
	speed: 0.5323s/iter; left time: 12173.8294s
	iters: 200, epoch: 14 | loss: 0.3615806
	speed: 0.1338s/iter; left time: 3047.0111s
Epoch: 14 cost time: 33.278239727020264
Epoch: 14, Steps: 264 | Train Loss: 0.3515173 Vali Loss: 0.6589532 Test Loss: 0.3756489
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3719136
	speed: 0.5622s/iter; left time: 12707.9907s
	iters: 200, epoch: 15 | loss: 0.3999383
	speed: 0.1019s/iter; left time: 2293.3332s
Epoch: 15 cost time: 29.96038317680359
Epoch: 15, Steps: 264 | Train Loss: 0.3516594 Vali Loss: 0.6589304 Test Loss: 0.3758080
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3425066
	speed: 0.5429s/iter; left time: 12127.8715s
	iters: 200, epoch: 16 | loss: 0.3264251
	speed: 0.1286s/iter; left time: 2859.2894s
Epoch: 16 cost time: 34.31617259979248
Epoch: 16, Steps: 264 | Train Loss: 0.3516081 Vali Loss: 0.6587502 Test Loss: 0.3755565
Validation loss decreased (0.658827 --> 0.658750).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3550699
	speed: 0.5509s/iter; left time: 12162.0120s
	iters: 200, epoch: 17 | loss: 0.3440363
	speed: 0.1182s/iter; left time: 2597.4115s
Epoch: 17 cost time: 32.16841268539429
Epoch: 17, Steps: 264 | Train Loss: 0.3514584 Vali Loss: 0.6586923 Test Loss: 0.3757360
Validation loss decreased (0.658750 --> 0.658692).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3308086
	speed: 0.5075s/iter; left time: 11069.4178s
	iters: 200, epoch: 18 | loss: 0.3312114
	speed: 0.1180s/iter; left time: 2562.0776s
Epoch: 18 cost time: 32.194639444351196
Epoch: 18, Steps: 264 | Train Loss: 0.3514630 Vali Loss: 0.6580885 Test Loss: 0.3758008
Validation loss decreased (0.658692 --> 0.658089).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3152350
	speed: 0.5077s/iter; left time: 10940.7162s
	iters: 200, epoch: 19 | loss: 0.3349901
	speed: 0.1180s/iter; left time: 2530.8422s
Epoch: 19 cost time: 31.26170015335083
Epoch: 19, Steps: 264 | Train Loss: 0.3515772 Vali Loss: 0.6583356 Test Loss: 0.3758411
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3771309
	speed: 0.5071s/iter; left time: 10792.8333s
	iters: 200, epoch: 20 | loss: 0.3504001
	speed: 0.1122s/iter; left time: 2376.4282s
Epoch: 20 cost time: 31.082430124282837
Epoch: 20, Steps: 264 | Train Loss: 0.3515133 Vali Loss: 0.6581217 Test Loss: 0.3756566
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3219766
	speed: 0.5150s/iter; left time: 10826.0896s
	iters: 200, epoch: 21 | loss: 0.3775705
	speed: 0.1228s/iter; left time: 2569.3250s
Epoch: 21 cost time: 33.30494928359985
Epoch: 21, Steps: 264 | Train Loss: 0.3514292 Vali Loss: 0.6588986 Test Loss: 0.3757297
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3558548
	speed: 0.5573s/iter; left time: 11567.3503s
	iters: 200, epoch: 22 | loss: 0.3458171
	speed: 0.1196s/iter; left time: 2470.0216s
Epoch: 22 cost time: 33.191848278045654
Epoch: 22, Steps: 264 | Train Loss: 0.3514596 Vali Loss: 0.6585608 Test Loss: 0.3758200
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3809359
	speed: 0.5090s/iter; left time: 10431.4438s
	iters: 200, epoch: 23 | loss: 0.3593635
	speed: 0.1002s/iter; left time: 2043.8045s
Epoch: 23 cost time: 28.331844568252563
Epoch: 23, Steps: 264 | Train Loss: 0.3515434 Vali Loss: 0.6579578 Test Loss: 0.3757710
Validation loss decreased (0.658089 --> 0.657958).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3599502
	speed: 0.4559s/iter; left time: 9221.7918s
	iters: 200, epoch: 24 | loss: 0.3898505
	speed: 0.1100s/iter; left time: 2214.6041s
Epoch: 24 cost time: 31.7609384059906
Epoch: 24, Steps: 264 | Train Loss: 0.3513940 Vali Loss: 0.6581095 Test Loss: 0.3758516
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3578667
	speed: 0.5396s/iter; left time: 10772.9452s
	iters: 200, epoch: 25 | loss: 0.3713398
	speed: 0.1165s/iter; left time: 2313.9345s
Epoch: 25 cost time: 31.295459508895874
Epoch: 25, Steps: 264 | Train Loss: 0.3513804 Vali Loss: 0.6579744 Test Loss: 0.3758460
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3413992
	speed: 0.5362s/iter; left time: 10564.0633s
	iters: 200, epoch: 26 | loss: 0.3638031
	speed: 0.1130s/iter; left time: 2214.1283s
Epoch: 26 cost time: 32.60539197921753
Epoch: 26, Steps: 264 | Train Loss: 0.3513846 Vali Loss: 0.6577634 Test Loss: 0.3757803
Validation loss decreased (0.657958 --> 0.657763).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3392287
	speed: 0.5267s/iter; left time: 10237.2278s
	iters: 200, epoch: 27 | loss: 0.4076631
	speed: 0.1193s/iter; left time: 2306.2005s
Epoch: 27 cost time: 33.24945330619812
Epoch: 27, Steps: 264 | Train Loss: 0.3514316 Vali Loss: 0.6570256 Test Loss: 0.3758998
Validation loss decreased (0.657763 --> 0.657026).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3799320
	speed: 0.5172s/iter; left time: 9916.3540s
	iters: 200, epoch: 28 | loss: 0.3309468
	speed: 0.1237s/iter; left time: 2359.8788s
Epoch: 28 cost time: 32.171284198760986
Epoch: 28, Steps: 264 | Train Loss: 0.3514359 Vali Loss: 0.6578894 Test Loss: 0.3758000
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3338133
	speed: 0.5129s/iter; left time: 9698.8314s
	iters: 200, epoch: 29 | loss: 0.3302665
	speed: 0.1144s/iter; left time: 2152.2588s
Epoch: 29 cost time: 31.55907368659973
Epoch: 29, Steps: 264 | Train Loss: 0.3514387 Vali Loss: 0.6575018 Test Loss: 0.3759153
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3662226
	speed: 0.5070s/iter; left time: 9452.7148s
	iters: 200, epoch: 30 | loss: 0.3372560
	speed: 0.1194s/iter; left time: 2213.3547s
Epoch: 30 cost time: 30.767226696014404
Epoch: 30, Steps: 264 | Train Loss: 0.3513747 Vali Loss: 0.6579038 Test Loss: 0.3758568
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3551206
	speed: 0.5309s/iter; left time: 9758.5464s
	iters: 200, epoch: 31 | loss: 0.3557422
	speed: 0.1274s/iter; left time: 2329.1980s
Epoch: 31 cost time: 33.11837291717529
Epoch: 31, Steps: 264 | Train Loss: 0.3512817 Vali Loss: 0.6582224 Test Loss: 0.3758216
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3173877
	speed: 0.5009s/iter; left time: 9074.4032s
	iters: 200, epoch: 32 | loss: 0.3474465
	speed: 0.1103s/iter; left time: 1987.9714s
Epoch: 32 cost time: 32.97562599182129
Epoch: 32, Steps: 264 | Train Loss: 0.3513868 Vali Loss: 0.6580335 Test Loss: 0.3757936
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3389775
	speed: 0.5153s/iter; left time: 9199.5033s
	iters: 200, epoch: 33 | loss: 0.3254381
	speed: 0.1342s/iter; left time: 2381.5960s
Epoch: 33 cost time: 33.42141056060791
Epoch: 33, Steps: 264 | Train Loss: 0.3512940 Vali Loss: 0.6582356 Test Loss: 0.3757622
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3147989
	speed: 0.5682s/iter; left time: 9994.0165s
	iters: 200, epoch: 34 | loss: 0.3878085
	speed: 0.1317s/iter; left time: 2303.2492s
Epoch: 34 cost time: 35.118366718292236
Epoch: 34, Steps: 264 | Train Loss: 0.3513445 Vali Loss: 0.6577623 Test Loss: 0.3758995
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3602241
	speed: 0.5472s/iter; left time: 9480.8441s
	iters: 200, epoch: 35 | loss: 0.3505649
	speed: 0.1228s/iter; left time: 2115.7855s
Epoch: 35 cost time: 31.479917287826538
Epoch: 35, Steps: 264 | Train Loss: 0.3513038 Vali Loss: 0.6585676 Test Loss: 0.3757489
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3739810
	speed: 0.5578s/iter; left time: 9516.2648s
	iters: 200, epoch: 36 | loss: 0.3125348
	speed: 0.1366s/iter; left time: 2317.6932s
Epoch: 36 cost time: 37.358859062194824
Epoch: 36, Steps: 264 | Train Loss: 0.3513553 Vali Loss: 0.6569967 Test Loss: 0.3758025
Validation loss decreased (0.657026 --> 0.656997).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3784733
	speed: 0.5997s/iter; left time: 10073.2404s
	iters: 200, epoch: 37 | loss: 0.3519021
	speed: 0.1401s/iter; left time: 2339.2949s
Epoch: 37 cost time: 36.7624716758728
Epoch: 37, Steps: 264 | Train Loss: 0.3512780 Vali Loss: 0.6575051 Test Loss: 0.3758903
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3591005
	speed: 0.5759s/iter; left time: 9521.4827s
	iters: 200, epoch: 38 | loss: 0.3566222
	speed: 0.1012s/iter; left time: 1663.5925s
Epoch: 38 cost time: 29.361635446548462
Epoch: 38, Steps: 264 | Train Loss: 0.3512258 Vali Loss: 0.6573254 Test Loss: 0.3757948
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3685223
	speed: 0.3912s/iter; left time: 6364.4009s
	iters: 200, epoch: 39 | loss: 0.3658341
	speed: 0.0803s/iter; left time: 1297.9900s
Epoch: 39 cost time: 23.017322778701782
Epoch: 39, Steps: 264 | Train Loss: 0.3513436 Vali Loss: 0.6572441 Test Loss: 0.3758778
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.3501623
	speed: 0.3392s/iter; left time: 5429.2072s
	iters: 200, epoch: 40 | loss: 0.3513165
	speed: 0.0977s/iter; left time: 1553.4551s
Epoch: 40 cost time: 23.21720838546753
Epoch: 40, Steps: 264 | Train Loss: 0.3513954 Vali Loss: 0.6567010 Test Loss: 0.3758512
Validation loss decreased (0.656997 --> 0.656701).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3272914
	speed: 0.3773s/iter; left time: 5938.6019s
	iters: 200, epoch: 41 | loss: 0.3509343
	speed: 0.0917s/iter; left time: 1433.9696s
Epoch: 41 cost time: 24.882354021072388
Epoch: 41, Steps: 264 | Train Loss: 0.3511013 Vali Loss: 0.6576875 Test Loss: 0.3759031
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3451346
	speed: 0.4010s/iter; left time: 6206.4454s
	iters: 200, epoch: 42 | loss: 0.3538355
	speed: 0.0927s/iter; left time: 1425.3320s
Epoch: 42 cost time: 26.73531675338745
Epoch: 42, Steps: 264 | Train Loss: 0.3513148 Vali Loss: 0.6576685 Test Loss: 0.3758766
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3206697
	speed: 0.3677s/iter; left time: 5593.3080s
	iters: 200, epoch: 43 | loss: 0.3634786
	speed: 0.0941s/iter; left time: 1421.6169s
Epoch: 43 cost time: 26.991705894470215
Epoch: 43, Steps: 264 | Train Loss: 0.3511640 Vali Loss: 0.6578159 Test Loss: 0.3757753
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.3535748
	speed: 0.3810s/iter; left time: 5696.1422s
	iters: 200, epoch: 44 | loss: 0.3709505
	speed: 0.0911s/iter; left time: 1352.5273s
Epoch: 44 cost time: 20.21994709968567
Epoch: 44, Steps: 264 | Train Loss: 0.3512584 Vali Loss: 0.6581081 Test Loss: 0.3758110
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.3587365
	speed: 0.3510s/iter; left time: 5154.1580s
	iters: 200, epoch: 45 | loss: 0.3539762
	speed: 0.0952s/iter; left time: 1388.7043s
Epoch: 45 cost time: 24.942683935165405
Epoch: 45, Steps: 264 | Train Loss: 0.3511683 Vali Loss: 0.6579503 Test Loss: 0.3758632
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.3451954
	speed: 0.4686s/iter; left time: 6757.6889s
	iters: 200, epoch: 46 | loss: 0.3477433
	speed: 0.0995s/iter; left time: 1424.6940s
Epoch: 46 cost time: 26.370293617248535
Epoch: 46, Steps: 264 | Train Loss: 0.3511560 Vali Loss: 0.6574806 Test Loss: 0.3758247
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.3315590
	speed: 0.4887s/iter; left time: 6918.7578s
	iters: 200, epoch: 47 | loss: 0.3785808
	speed: 0.1512s/iter; left time: 2124.7228s
Epoch: 47 cost time: 36.86757278442383
Epoch: 47, Steps: 264 | Train Loss: 0.3512163 Vali Loss: 0.6575252 Test Loss: 0.3758777
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.3162503
	speed: 0.5616s/iter; left time: 7802.1308s
	iters: 200, epoch: 48 | loss: 0.3647482
	speed: 0.0972s/iter; left time: 1341.3679s
Epoch: 48 cost time: 31.411282300949097
Epoch: 48, Steps: 264 | Train Loss: 0.3512380 Vali Loss: 0.6581239 Test Loss: 0.3758669
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.4197520
	speed: 0.4861s/iter; left time: 6625.6491s
	iters: 200, epoch: 49 | loss: 0.3408188
	speed: 0.0949s/iter; left time: 1283.4972s
Epoch: 49 cost time: 27.74266290664673
Epoch: 49, Steps: 264 | Train Loss: 0.3513419 Vali Loss: 0.6579065 Test Loss: 0.3758697
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.3809572
	speed: 0.5031s/iter; left time: 6724.0058s
	iters: 200, epoch: 50 | loss: 0.4063484
	speed: 0.1519s/iter; left time: 2015.0756s
Epoch: 50 cost time: 36.95097231864929
Epoch: 50, Steps: 264 | Train Loss: 0.3512596 Vali Loss: 0.6576504 Test Loss: 0.3758542
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.3261200
	speed: 0.5822s/iter; left time: 7626.9036s
	iters: 200, epoch: 51 | loss: 0.3976152
	speed: 0.1114s/iter; left time: 1448.0855s
Epoch: 51 cost time: 31.970866918563843
Epoch: 51, Steps: 264 | Train Loss: 0.3511709 Vali Loss: 0.6571806 Test Loss: 0.3758289
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.3609479
	speed: 0.5241s/iter; left time: 6728.1815s
	iters: 200, epoch: 52 | loss: 0.3955306
	speed: 0.1229s/iter; left time: 1565.8513s
Epoch: 52 cost time: 33.341588735580444
Epoch: 52, Steps: 264 | Train Loss: 0.3512157 Vali Loss: 0.6572014 Test Loss: 0.3758607
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.3480455
	speed: 0.4732s/iter; left time: 5949.7529s
	iters: 200, epoch: 53 | loss: 0.3831190
	speed: 0.1209s/iter; left time: 1507.6177s
Epoch: 53 cost time: 30.373773097991943
Epoch: 53, Steps: 264 | Train Loss: 0.3511256 Vali Loss: 0.6577623 Test Loss: 0.3758264
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.3435571
	speed: 0.4406s/iter; left time: 5423.1366s
	iters: 200, epoch: 54 | loss: 0.3202976
	speed: 0.1033s/iter; left time: 1260.8176s
Epoch: 54 cost time: 27.919341325759888
Epoch: 54, Steps: 264 | Train Loss: 0.3513607 Vali Loss: 0.6577874 Test Loss: 0.3758292
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.3597428
	speed: 0.4967s/iter; left time: 5982.3639s
	iters: 200, epoch: 55 | loss: 0.3478162
	speed: 0.1228s/iter; left time: 1466.5339s
Epoch: 55 cost time: 32.48845553398132
Epoch: 55, Steps: 264 | Train Loss: 0.3512888 Vali Loss: 0.6577089 Test Loss: 0.3758410
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.3737564
	speed: 0.5048s/iter; left time: 5947.1847s
	iters: 200, epoch: 56 | loss: 0.3295487
	speed: 0.1062s/iter; left time: 1240.4178s
Epoch: 56 cost time: 26.510871171951294
Epoch: 56, Steps: 264 | Train Loss: 0.3511957 Vali Loss: 0.6582390 Test Loss: 0.3758483
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.3686916
	speed: 0.4724s/iter; left time: 5440.7868s
	iters: 200, epoch: 57 | loss: 0.3541617
	speed: 0.1287s/iter; left time: 1469.5511s
Epoch: 57 cost time: 34.06697726249695
Epoch: 57, Steps: 264 | Train Loss: 0.3512177 Vali Loss: 0.6577352 Test Loss: 0.3758507
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.3865574
	speed: 0.5323s/iter; left time: 5989.7352s
	iters: 200, epoch: 58 | loss: 0.3212917
	speed: 0.1377s/iter; left time: 1536.1042s
Epoch: 58 cost time: 36.55753183364868
Epoch: 58, Steps: 264 | Train Loss: 0.3513214 Vali Loss: 0.6575759 Test Loss: 0.3758741
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.3357041
	speed: 0.5745s/iter; left time: 6313.0263s
	iters: 200, epoch: 59 | loss: 0.3655725
	speed: 0.1342s/iter; left time: 1461.2322s
Epoch: 59 cost time: 32.29117202758789
Epoch: 59, Steps: 264 | Train Loss: 0.3512096 Vali Loss: 0.6580344 Test Loss: 0.3758655
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.3635210
	speed: 0.4550s/iter; left time: 4879.6093s
	iters: 200, epoch: 60 | loss: 0.3835935
	speed: 0.0878s/iter; left time: 933.2388s
Epoch: 60 cost time: 27.74659514427185
Epoch: 60, Steps: 264 | Train Loss: 0.3511420 Vali Loss: 0.6570705 Test Loss: 0.3758307
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_360_336_FITS_ETTm1_ftM_sl360_ll48_pl336_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.37563005089759827, mae:0.38822805881500244, rse:0.5832147598266602, corr:[0.5422058  0.54531133 0.54742473 0.54841423 0.5485668  0.54829675
 0.547966   0.5478488  0.5480402  0.5485503  0.54936886 0.5500886
 0.5504732  0.55035955 0.5497192  0.5485803  0.5471641  0.54568547
 0.5441524  0.54262733 0.54114336 0.53988355 0.53881735 0.5380544
 0.5375089  0.53698933 0.5364965  0.5360714  0.5356831  0.5352145
 0.5347709  0.53446555 0.5342785  0.53420866 0.534212   0.5343247
 0.53449196 0.53462774 0.53468627 0.5346057  0.53438514 0.5340177
 0.5335129  0.5329775  0.5324589  0.5320144  0.5317541  0.5316433
 0.5316414  0.53173923 0.53185403 0.5319099  0.53189075 0.53175265
 0.53150845 0.5312038  0.53084797 0.530514   0.53027457 0.53012115
 0.53011996 0.5302301  0.5304205  0.53060246 0.53080344 0.53100854
 0.5311526  0.5312008  0.53127354 0.531364   0.5314855  0.53163445
 0.531818   0.5320348  0.53223044 0.5323616  0.5324009  0.5323556
 0.5322143  0.5319744  0.5316618  0.5313026  0.53088653 0.5304267
 0.530008   0.5296287  0.5293603  0.5291727  0.52904713 0.52900976
 0.52904487 0.5290436  0.5288992  0.5286114  0.5281492  0.5275381
 0.5268869  0.52632314 0.5258779  0.5255335  0.525347   0.5253351
 0.52547    0.52564543 0.52590805 0.5262445  0.5265366  0.5268368
 0.527041   0.52722967 0.5273548  0.5274145  0.5273691  0.5273037
 0.52722716 0.5271808  0.5271473  0.5271418  0.5271418  0.5272367
 0.5273688  0.5273925  0.52727926 0.52714324 0.5269931  0.52680147
 0.5266043  0.52645504 0.5263537  0.5263142  0.5263147  0.52631485
 0.52631307 0.52625465 0.5261684  0.5260314  0.52585196 0.52559733
 0.5253106  0.52500516 0.5246876  0.5244286  0.5242523  0.5241808
 0.5241964  0.52428013 0.5243751  0.5244568  0.5245341  0.52452725
 0.52443653 0.52432334 0.52418053 0.52402794 0.52390045 0.5238674
 0.5239121  0.52403754 0.5242117  0.52441674 0.52466345 0.52489847
 0.52511084 0.52528054 0.52545714 0.52564824 0.52584016 0.52608865
 0.5263387  0.5265646  0.52677494 0.52696145 0.5270771  0.5271131
 0.5270627  0.5269639  0.526828   0.52667993 0.52649635 0.5263108
 0.52612054 0.52597696 0.52582794 0.5257115  0.52563304 0.5255969
 0.5255949  0.52561516 0.52562445 0.525603   0.5254483  0.5251631
 0.5247479  0.5243457  0.5239538  0.5234936  0.52299166 0.52256894
 0.52219135 0.52181023 0.5214818  0.5212019  0.5209247  0.5206513
 0.5203864  0.52004266 0.51966906 0.5192322  0.51876396 0.5182844
 0.51775473 0.51723045 0.51671463 0.51628953 0.5159394  0.51573926
 0.5156525  0.51560456 0.5154874  0.51539    0.5152634  0.5151034
 0.5149862  0.51489896 0.51484966 0.5148277  0.51484567 0.5148627
 0.5148703  0.5148903  0.5148712  0.5148022  0.5147046  0.51453763
 0.5143643  0.5141806  0.51394486 0.5137322  0.513533   0.5133612
 0.5132366  0.51315254 0.5131381  0.513173   0.5132184  0.5132681
 0.5132818  0.5132342  0.51312536 0.512999   0.512846   0.512713
 0.5125807  0.5125238  0.512524   0.5125725  0.5126229  0.5127146
 0.512792   0.51287353 0.5129843  0.513127   0.5132501  0.51345325
 0.5136899  0.5139484  0.51419514 0.5144462  0.51466507 0.5147764
 0.5148178  0.51479816 0.51471955 0.5146123  0.51446134 0.5143472
 0.51425403 0.51423955 0.5142048  0.5141837  0.51410943 0.5139788
 0.5138079  0.5135492  0.51320225 0.5127408  0.51217    0.51150185
 0.5107306  0.5100252  0.5094818  0.5089547  0.5084888  0.50809044
 0.50773084 0.50732595 0.5069397  0.5065525  0.5062096  0.5058755
 0.50556356 0.5052608  0.50499594 0.5048068  0.50466347 0.5045684
 0.50454706 0.5045317  0.5045316  0.5045752  0.5046634  0.504778
 0.50492245 0.50499463 0.50485057 0.5046412  0.50434315 0.5040317
 0.5037509  0.503523   0.5033358  0.50316334 0.502955   0.5026794
 0.5023471  0.50200623 0.5016837  0.50145704 0.50129503 0.50123787
 0.5012545  0.5013289  0.5013944  0.50137323 0.5011305  0.5004453 ]
