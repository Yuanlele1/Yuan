Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=74, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_720_336_FITS_ETTm1_ftM_sl720_ll48_pl336_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=74, out_features=108, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  7160832.0
params:  8100.0
Trainable parameters:  8100
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4452957
	speed: 0.0330s/iter; left time: 858.4523s
	iters: 200, epoch: 1 | loss: 0.3326326
	speed: 0.0294s/iter; left time: 761.6095s
Epoch: 1 cost time: 8.103946208953857
Epoch: 1, Steps: 261 | Train Loss: 0.4290538 Vali Loss: 0.9475956 Test Loss: 0.5617281
Validation loss decreased (inf --> 0.947596).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2601359
	speed: 0.1407s/iter; left time: 3622.2995s
	iters: 200, epoch: 2 | loss: 0.2341249
	speed: 0.0281s/iter; left time: 720.8845s
Epoch: 2 cost time: 9.016744613647461
Epoch: 2, Steps: 261 | Train Loss: 0.2577446 Vali Loss: 0.8112436 Test Loss: 0.4690296
Validation loss decreased (0.947596 --> 0.811244).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1965452
	speed: 0.1454s/iter; left time: 3704.0570s
	iters: 200, epoch: 3 | loss: 0.1881834
	speed: 0.0296s/iter; left time: 750.8284s
Epoch: 3 cost time: 8.534361600875854
Epoch: 3, Steps: 261 | Train Loss: 0.1981888 Vali Loss: 0.7595352 Test Loss: 0.4321977
Validation loss decreased (0.811244 --> 0.759535).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1820358
	speed: 0.1528s/iter; left time: 3852.8953s
	iters: 200, epoch: 4 | loss: 0.1676933
	speed: 0.0335s/iter; left time: 842.1748s
Epoch: 4 cost time: 9.493908166885376
Epoch: 4, Steps: 261 | Train Loss: 0.1694521 Vali Loss: 0.7287039 Test Loss: 0.4100682
Validation loss decreased (0.759535 --> 0.728704).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1667598
	speed: 0.1376s/iter; left time: 3435.2239s
	iters: 200, epoch: 5 | loss: 0.1530816
	speed: 0.0310s/iter; left time: 771.6213s
Epoch: 5 cost time: 9.358607292175293
Epoch: 5, Steps: 261 | Train Loss: 0.1532989 Vali Loss: 0.7117720 Test Loss: 0.3963859
Validation loss decreased (0.728704 --> 0.711772).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1574002
	speed: 0.1331s/iter; left time: 3288.1213s
	iters: 200, epoch: 6 | loss: 0.1596631
	speed: 0.0269s/iter; left time: 661.1513s
Epoch: 6 cost time: 7.940927267074585
Epoch: 6, Steps: 261 | Train Loss: 0.1435843 Vali Loss: 0.6974974 Test Loss: 0.3863757
Validation loss decreased (0.711772 --> 0.697497).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1361538
	speed: 0.1441s/iter; left time: 3521.6580s
	iters: 200, epoch: 7 | loss: 0.1313295
	speed: 0.0287s/iter; left time: 698.2642s
Epoch: 7 cost time: 8.296406030654907
Epoch: 7, Steps: 261 | Train Loss: 0.1373023 Vali Loss: 0.6912929 Test Loss: 0.3795306
Validation loss decreased (0.697497 --> 0.691293).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1380715
	speed: 0.1586s/iter; left time: 3834.6374s
	iters: 200, epoch: 8 | loss: 0.1315740
	speed: 0.0364s/iter; left time: 875.7199s
Epoch: 8 cost time: 10.265687227249146
Epoch: 8, Steps: 261 | Train Loss: 0.1332149 Vali Loss: 0.6855290 Test Loss: 0.3757802
Validation loss decreased (0.691293 --> 0.685529).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1199911
	speed: 0.1297s/iter; left time: 3100.4877s
	iters: 200, epoch: 9 | loss: 0.1235803
	speed: 0.0283s/iter; left time: 672.8067s
Epoch: 9 cost time: 8.168056964874268
Epoch: 9, Steps: 261 | Train Loss: 0.1304619 Vali Loss: 0.6819152 Test Loss: 0.3732814
Validation loss decreased (0.685529 --> 0.681915).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1205814
	speed: 0.1272s/iter; left time: 3007.6289s
	iters: 200, epoch: 10 | loss: 0.1192410
	speed: 0.0294s/iter; left time: 691.4124s
Epoch: 10 cost time: 8.286561012268066
Epoch: 10, Steps: 261 | Train Loss: 0.1285686 Vali Loss: 0.6794453 Test Loss: 0.3714890
Validation loss decreased (0.681915 --> 0.679445).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1368614
	speed: 0.1362s/iter; left time: 3184.9371s
	iters: 200, epoch: 11 | loss: 0.1362512
	speed: 0.0284s/iter; left time: 662.0227s
Epoch: 11 cost time: 9.10996150970459
Epoch: 11, Steps: 261 | Train Loss: 0.1272776 Vali Loss: 0.6773880 Test Loss: 0.3707874
Validation loss decreased (0.679445 --> 0.677388).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1233302
	speed: 0.1435s/iter; left time: 3318.8392s
	iters: 200, epoch: 12 | loss: 0.1304982
	speed: 0.0386s/iter; left time: 888.0162s
Epoch: 12 cost time: 9.712303876876831
Epoch: 12, Steps: 261 | Train Loss: 0.1263721 Vali Loss: 0.6756310 Test Loss: 0.3699576
Validation loss decreased (0.677388 --> 0.675631).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1126779
	speed: 0.1266s/iter; left time: 2894.4752s
	iters: 200, epoch: 13 | loss: 0.1334109
	speed: 0.0369s/iter; left time: 840.0951s
Epoch: 13 cost time: 9.913952112197876
Epoch: 13, Steps: 261 | Train Loss: 0.1257983 Vali Loss: 0.6749683 Test Loss: 0.3698834
Validation loss decreased (0.675631 --> 0.674968).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1214412
	speed: 0.1639s/iter; left time: 3705.9628s
	iters: 200, epoch: 14 | loss: 0.1204282
	speed: 0.0314s/iter; left time: 706.6188s
Epoch: 14 cost time: 9.471786499023438
Epoch: 14, Steps: 261 | Train Loss: 0.1253248 Vali Loss: 0.6745878 Test Loss: 0.3698708
Validation loss decreased (0.674968 --> 0.674588).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1289886
	speed: 0.1304s/iter; left time: 2913.7335s
	iters: 200, epoch: 15 | loss: 0.1145915
	speed: 0.0259s/iter; left time: 575.6573s
Epoch: 15 cost time: 7.413504123687744
Epoch: 15, Steps: 261 | Train Loss: 0.1250456 Vali Loss: 0.6745223 Test Loss: 0.3697657
Validation loss decreased (0.674588 --> 0.674522).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1263777
	speed: 0.1528s/iter; left time: 3374.1833s
	iters: 200, epoch: 16 | loss: 0.1303442
	speed: 0.0347s/iter; left time: 763.1225s
Epoch: 16 cost time: 9.046971797943115
Epoch: 16, Steps: 261 | Train Loss: 0.1248800 Vali Loss: 0.6748126 Test Loss: 0.3700310
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1183401
	speed: 0.1368s/iter; left time: 2986.2838s
	iters: 200, epoch: 17 | loss: 0.1248393
	speed: 0.0311s/iter; left time: 676.3800s
Epoch: 17 cost time: 8.593984365463257
Epoch: 17, Steps: 261 | Train Loss: 0.1247007 Vali Loss: 0.6742404 Test Loss: 0.3705902
Validation loss decreased (0.674522 --> 0.674240).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1255444
	speed: 0.1199s/iter; left time: 2586.4289s
	iters: 200, epoch: 18 | loss: 0.1329313
	speed: 0.0274s/iter; left time: 587.3343s
Epoch: 18 cost time: 7.540653944015503
Epoch: 18, Steps: 261 | Train Loss: 0.1246141 Vali Loss: 0.6757239 Test Loss: 0.3707397
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1269519
	speed: 0.1256s/iter; left time: 2676.5576s
	iters: 200, epoch: 19 | loss: 0.1135584
	speed: 0.0292s/iter; left time: 618.4567s
Epoch: 19 cost time: 8.895632266998291
Epoch: 19, Steps: 261 | Train Loss: 0.1245688 Vali Loss: 0.6746404 Test Loss: 0.3711903
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1299655
	speed: 0.1383s/iter; left time: 2909.2915s
	iters: 200, epoch: 20 | loss: 0.1162137
	speed: 0.0324s/iter; left time: 678.9009s
Epoch: 20 cost time: 9.29508662223816
Epoch: 20, Steps: 261 | Train Loss: 0.1245328 Vali Loss: 0.6739178 Test Loss: 0.3710399
Validation loss decreased (0.674240 --> 0.673918).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1138764
	speed: 0.1359s/iter; left time: 2824.5228s
	iters: 200, epoch: 21 | loss: 0.1226204
	speed: 0.0284s/iter; left time: 586.8685s
Epoch: 21 cost time: 8.695441961288452
Epoch: 21, Steps: 261 | Train Loss: 0.1245102 Vali Loss: 0.6751044 Test Loss: 0.3710787
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1223238
	speed: 0.1385s/iter; left time: 2842.3799s
	iters: 200, epoch: 22 | loss: 0.1137954
	speed: 0.0364s/iter; left time: 743.4679s
Epoch: 22 cost time: 9.639422416687012
Epoch: 22, Steps: 261 | Train Loss: 0.1244768 Vali Loss: 0.6748515 Test Loss: 0.3716202
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1255829
	speed: 0.1437s/iter; left time: 2910.9629s
	iters: 200, epoch: 23 | loss: 0.1281339
	speed: 0.0338s/iter; left time: 682.1678s
Epoch: 23 cost time: 9.90352177619934
Epoch: 23, Steps: 261 | Train Loss: 0.1244826 Vali Loss: 0.6753433 Test Loss: 0.3718719
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1171095
	speed: 0.1416s/iter; left time: 2832.2978s
	iters: 200, epoch: 24 | loss: 0.1262941
	speed: 0.0283s/iter; left time: 563.6891s
Epoch: 24 cost time: 8.85573673248291
Epoch: 24, Steps: 261 | Train Loss: 0.1244453 Vali Loss: 0.6754984 Test Loss: 0.3716721
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1311169
	speed: 0.1295s/iter; left time: 2555.4581s
	iters: 200, epoch: 25 | loss: 0.1240792
	speed: 0.0311s/iter; left time: 611.2526s
Epoch: 25 cost time: 8.542458295822144
Epoch: 25, Steps: 261 | Train Loss: 0.1244405 Vali Loss: 0.6752926 Test Loss: 0.3720304
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1210563
	speed: 0.1429s/iter; left time: 2783.3071s
	iters: 200, epoch: 26 | loss: 0.1177783
	speed: 0.0331s/iter; left time: 642.1889s
Epoch: 26 cost time: 9.583501100540161
Epoch: 26, Steps: 261 | Train Loss: 0.1244744 Vali Loss: 0.6760285 Test Loss: 0.3720490
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1237898
	speed: 0.1279s/iter; left time: 2458.3484s
	iters: 200, epoch: 27 | loss: 0.1209496
	speed: 0.0384s/iter; left time: 734.5342s
Epoch: 27 cost time: 9.305650472640991
Epoch: 27, Steps: 261 | Train Loss: 0.1244640 Vali Loss: 0.6747448 Test Loss: 0.3722962
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1274275
	speed: 0.1427s/iter; left time: 2705.3409s
	iters: 200, epoch: 28 | loss: 0.1332200
	speed: 0.0408s/iter; left time: 768.3689s
Epoch: 28 cost time: 10.647900104522705
Epoch: 28, Steps: 261 | Train Loss: 0.1244599 Vali Loss: 0.6746008 Test Loss: 0.3723726
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1176354
	speed: 0.1486s/iter; left time: 2777.0831s
	iters: 200, epoch: 29 | loss: 0.1261400
	speed: 0.0263s/iter; left time: 488.3704s
Epoch: 29 cost time: 7.853593349456787
Epoch: 29, Steps: 261 | Train Loss: 0.1243918 Vali Loss: 0.6748567 Test Loss: 0.3720381
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1323759
	speed: 0.1331s/iter; left time: 2454.0610s
	iters: 200, epoch: 30 | loss: 0.1178896
	speed: 0.0255s/iter; left time: 468.1763s
Epoch: 30 cost time: 8.120836734771729
Epoch: 30, Steps: 261 | Train Loss: 0.1244501 Vali Loss: 0.6754824 Test Loss: 0.3722365
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1274778
	speed: 0.1458s/iter; left time: 2648.6028s
	iters: 200, epoch: 31 | loss: 0.1239155
	speed: 0.0327s/iter; left time: 590.2909s
Epoch: 31 cost time: 9.756447076797485
Epoch: 31, Steps: 261 | Train Loss: 0.1243954 Vali Loss: 0.6747816 Test Loss: 0.3720486
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1216368
	speed: 0.1311s/iter; left time: 2348.8210s
	iters: 200, epoch: 32 | loss: 0.1225836
	speed: 0.0341s/iter; left time: 606.7702s
Epoch: 32 cost time: 9.628068685531616
Epoch: 32, Steps: 261 | Train Loss: 0.1244325 Vali Loss: 0.6751874 Test Loss: 0.3723513
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1404842
	speed: 0.1527s/iter; left time: 2694.2724s
	iters: 200, epoch: 33 | loss: 0.1344714
	speed: 0.0315s/iter; left time: 552.6483s
Epoch: 33 cost time: 9.01314115524292
Epoch: 33, Steps: 261 | Train Loss: 0.1244295 Vali Loss: 0.6755592 Test Loss: 0.3721485
EarlyStopping counter: 13 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1331049
	speed: 0.1368s/iter; left time: 2378.2422s
	iters: 200, epoch: 34 | loss: 0.1234605
	speed: 0.0315s/iter; left time: 543.8067s
Epoch: 34 cost time: 9.050633192062378
Epoch: 34, Steps: 261 | Train Loss: 0.1244323 Vali Loss: 0.6742215 Test Loss: 0.3721509
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1188576
	speed: 0.1362s/iter; left time: 2331.8784s
	iters: 200, epoch: 35 | loss: 0.1344755
	speed: 0.0307s/iter; left time: 522.2279s
Epoch: 35 cost time: 9.016223907470703
Epoch: 35, Steps: 261 | Train Loss: 0.1244057 Vali Loss: 0.6749746 Test Loss: 0.3722179
EarlyStopping counter: 15 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1302278
	speed: 0.1469s/iter; left time: 2476.8139s
	iters: 200, epoch: 36 | loss: 0.1276622
	speed: 0.0330s/iter; left time: 553.7018s
Epoch: 36 cost time: 9.281429529190063
Epoch: 36, Steps: 261 | Train Loss: 0.1243884 Vali Loss: 0.6748657 Test Loss: 0.3720410
EarlyStopping counter: 16 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1136034
	speed: 0.1358s/iter; left time: 2255.1839s
	iters: 200, epoch: 37 | loss: 0.1103631
	speed: 0.0310s/iter; left time: 510.9858s
Epoch: 37 cost time: 8.503342390060425
Epoch: 37, Steps: 261 | Train Loss: 0.1244217 Vali Loss: 0.6748789 Test Loss: 0.3719980
EarlyStopping counter: 17 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1306233
	speed: 0.1528s/iter; left time: 2496.6978s
	iters: 200, epoch: 38 | loss: 0.1224411
	speed: 0.0349s/iter; left time: 567.2099s
Epoch: 38 cost time: 10.947363138198853
Epoch: 38, Steps: 261 | Train Loss: 0.1244218 Vali Loss: 0.6756065 Test Loss: 0.3721588
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1237512
	speed: 0.1390s/iter; left time: 2235.5519s
	iters: 200, epoch: 39 | loss: 0.1320650
	speed: 0.0313s/iter; left time: 500.1787s
Epoch: 39 cost time: 9.005257606506348
Epoch: 39, Steps: 261 | Train Loss: 0.1244304 Vali Loss: 0.6748587 Test Loss: 0.3720553
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1221476
	speed: 0.1296s/iter; left time: 2050.1021s
	iters: 200, epoch: 40 | loss: 0.1305891
	speed: 0.0270s/iter; left time: 424.1866s
Epoch: 40 cost time: 7.945945978164673
Epoch: 40, Steps: 261 | Train Loss: 0.1243816 Vali Loss: 0.6750794 Test Loss: 0.3721052
EarlyStopping counter: 20 out of 20
Early stopping
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=74, out_features=108, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  7160832.0
params:  8100.0
Trainable parameters:  8100
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3478926
	speed: 0.0435s/iter; left time: 1131.1740s
	iters: 200, epoch: 1 | loss: 0.3287236
	speed: 0.0354s/iter; left time: 917.2427s
Epoch: 1 cost time: 9.759806871414185
Epoch: 1, Steps: 261 | Train Loss: 0.3400185 Vali Loss: 0.6607818 Test Loss: 0.3691452
Validation loss decreased (inf --> 0.660782).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3518279
	speed: 0.1423s/iter; left time: 3663.7407s
	iters: 200, epoch: 2 | loss: 0.3570088
	speed: 0.0320s/iter; left time: 819.2860s
Epoch: 2 cost time: 8.768635272979736
Epoch: 2, Steps: 261 | Train Loss: 0.3386606 Vali Loss: 0.6581183 Test Loss: 0.3685866
Validation loss decreased (0.660782 --> 0.658118).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3286140
	speed: 0.1390s/iter; left time: 3542.3441s
	iters: 200, epoch: 3 | loss: 0.3443051
	speed: 0.0301s/iter; left time: 764.1844s
Epoch: 3 cost time: 9.317148923873901
Epoch: 3, Steps: 261 | Train Loss: 0.3382374 Vali Loss: 0.6578234 Test Loss: 0.3685809
Validation loss decreased (0.658118 --> 0.657823).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3532499
	speed: 0.1302s/iter; left time: 3283.8299s
	iters: 200, epoch: 4 | loss: 0.3682789
	speed: 0.0342s/iter; left time: 859.2372s
Epoch: 4 cost time: 9.48716688156128
Epoch: 4, Steps: 261 | Train Loss: 0.3379149 Vali Loss: 0.6591086 Test Loss: 0.3679081
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3301653
	speed: 0.1391s/iter; left time: 3472.4185s
	iters: 200, epoch: 5 | loss: 0.3200273
	speed: 0.0390s/iter; left time: 969.0535s
Epoch: 5 cost time: 10.165793895721436
Epoch: 5, Steps: 261 | Train Loss: 0.3376831 Vali Loss: 0.6574615 Test Loss: 0.3674639
Validation loss decreased (0.657823 --> 0.657462).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3330222
	speed: 0.1393s/iter; left time: 3440.4558s
	iters: 200, epoch: 6 | loss: 0.3137308
	speed: 0.0326s/iter; left time: 800.6955s
Epoch: 6 cost time: 9.992584943771362
Epoch: 6, Steps: 261 | Train Loss: 0.3376119 Vali Loss: 0.6572415 Test Loss: 0.3687398
Validation loss decreased (0.657462 --> 0.657242).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3201096
	speed: 0.1349s/iter; left time: 3295.4722s
	iters: 200, epoch: 7 | loss: 0.3238470
	speed: 0.0423s/iter; left time: 1029.3327s
Epoch: 7 cost time: 10.967261791229248
Epoch: 7, Steps: 261 | Train Loss: 0.3375721 Vali Loss: 0.6569796 Test Loss: 0.3680014
Validation loss decreased (0.657242 --> 0.656980).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3634871
	speed: 0.1423s/iter; left time: 3439.8969s
	iters: 200, epoch: 8 | loss: 0.3000677
	speed: 0.0328s/iter; left time: 789.3615s
Epoch: 8 cost time: 8.849539995193481
Epoch: 8, Steps: 261 | Train Loss: 0.3373665 Vali Loss: 0.6549834 Test Loss: 0.3686802
Validation loss decreased (0.656980 --> 0.654983).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3427108
	speed: 0.1384s/iter; left time: 3308.9525s
	iters: 200, epoch: 9 | loss: 0.3550999
	speed: 0.0323s/iter; left time: 768.6658s
Epoch: 9 cost time: 9.620922565460205
Epoch: 9, Steps: 261 | Train Loss: 0.3372782 Vali Loss: 0.6572543 Test Loss: 0.3677610
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3412058
	speed: 0.1471s/iter; left time: 3479.0782s
	iters: 200, epoch: 10 | loss: 0.3640755
	speed: 0.0374s/iter; left time: 881.5223s
Epoch: 10 cost time: 10.087657928466797
Epoch: 10, Steps: 261 | Train Loss: 0.3373315 Vali Loss: 0.6546002 Test Loss: 0.3676957
Validation loss decreased (0.654983 --> 0.654600).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3471147
	speed: 0.1478s/iter; left time: 3456.9890s
	iters: 200, epoch: 11 | loss: 0.3436573
	speed: 0.0325s/iter; left time: 756.7344s
Epoch: 11 cost time: 9.408993244171143
Epoch: 11, Steps: 261 | Train Loss: 0.3371396 Vali Loss: 0.6563002 Test Loss: 0.3674392
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3759241
	speed: 0.1498s/iter; left time: 3464.5404s
	iters: 200, epoch: 12 | loss: 0.3414266
	speed: 0.0254s/iter; left time: 584.8347s
Epoch: 12 cost time: 7.567465782165527
Epoch: 12, Steps: 261 | Train Loss: 0.3372077 Vali Loss: 0.6552721 Test Loss: 0.3683309
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3288775
	speed: 0.1309s/iter; left time: 2992.6439s
	iters: 200, epoch: 13 | loss: 0.3374401
	speed: 0.0257s/iter; left time: 584.7936s
Epoch: 13 cost time: 8.141538143157959
Epoch: 13, Steps: 261 | Train Loss: 0.3372892 Vali Loss: 0.6561843 Test Loss: 0.3683197
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3284843
	speed: 0.1375s/iter; left time: 3107.6257s
	iters: 200, epoch: 14 | loss: 0.3538634
	speed: 0.0292s/iter; left time: 657.6553s
Epoch: 14 cost time: 9.340719223022461
Epoch: 14, Steps: 261 | Train Loss: 0.3372271 Vali Loss: 0.6559936 Test Loss: 0.3683706
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3423988
	speed: 0.1548s/iter; left time: 3459.9717s
	iters: 200, epoch: 15 | loss: 0.3411315
	speed: 0.0403s/iter; left time: 896.2947s
Epoch: 15 cost time: 10.03007984161377
Epoch: 15, Steps: 261 | Train Loss: 0.3369527 Vali Loss: 0.6554873 Test Loss: 0.3676168
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3410333
	speed: 0.1344s/iter; left time: 2968.2098s
	iters: 200, epoch: 16 | loss: 0.3551793
	speed: 0.0319s/iter; left time: 700.3965s
Epoch: 16 cost time: 8.928202152252197
Epoch: 16, Steps: 261 | Train Loss: 0.3371309 Vali Loss: 0.6562843 Test Loss: 0.3681954
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3086908
	speed: 0.1366s/iter; left time: 2982.1021s
	iters: 200, epoch: 17 | loss: 0.3659357
	speed: 0.0345s/iter; left time: 750.1114s
Epoch: 17 cost time: 9.330854892730713
Epoch: 17, Steps: 261 | Train Loss: 0.3370505 Vali Loss: 0.6553633 Test Loss: 0.3677936
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3311353
	speed: 0.1390s/iter; left time: 2997.0718s
	iters: 200, epoch: 18 | loss: 0.3478049
	speed: 0.0346s/iter; left time: 743.3237s
Epoch: 18 cost time: 9.090176105499268
Epoch: 18, Steps: 261 | Train Loss: 0.3371250 Vali Loss: 0.6556138 Test Loss: 0.3680009
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3207554
	speed: 0.1427s/iter; left time: 3039.6776s
	iters: 200, epoch: 19 | loss: 0.3251163
	speed: 0.0350s/iter; left time: 742.2411s
Epoch: 19 cost time: 9.057411670684814
Epoch: 19, Steps: 261 | Train Loss: 0.3369939 Vali Loss: 0.6560050 Test Loss: 0.3680097
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3634576
	speed: 0.1247s/iter; left time: 2623.1284s
	iters: 200, epoch: 20 | loss: 0.3071777
	speed: 0.0264s/iter; left time: 551.9522s
Epoch: 20 cost time: 8.089002847671509
Epoch: 20, Steps: 261 | Train Loss: 0.3370234 Vali Loss: 0.6552548 Test Loss: 0.3683803
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3584689
	speed: 0.1416s/iter; left time: 2942.5433s
	iters: 200, epoch: 21 | loss: 0.3528812
	speed: 0.0280s/iter; left time: 579.3719s
Epoch: 21 cost time: 8.455689430236816
Epoch: 21, Steps: 261 | Train Loss: 0.3369645 Vali Loss: 0.6546180 Test Loss: 0.3680338
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3150268
	speed: 0.1374s/iter; left time: 2819.5750s
	iters: 200, epoch: 22 | loss: 0.3411891
	speed: 0.0272s/iter; left time: 555.4754s
Epoch: 22 cost time: 8.049623012542725
Epoch: 22, Steps: 261 | Train Loss: 0.3368774 Vali Loss: 0.6559436 Test Loss: 0.3679745
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4074602
	speed: 0.1377s/iter; left time: 2790.3675s
	iters: 200, epoch: 23 | loss: 0.3333176
	speed: 0.0314s/iter; left time: 633.5590s
Epoch: 23 cost time: 9.713155746459961
Epoch: 23, Steps: 261 | Train Loss: 0.3369728 Vali Loss: 0.6561286 Test Loss: 0.3677754
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3358888
	speed: 0.1405s/iter; left time: 2809.5057s
	iters: 200, epoch: 24 | loss: 0.3659289
	speed: 0.0282s/iter; left time: 561.1982s
Epoch: 24 cost time: 7.78277850151062
Epoch: 24, Steps: 261 | Train Loss: 0.3368826 Vali Loss: 0.6551472 Test Loss: 0.3681443
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3563235
	speed: 0.1453s/iter; left time: 2866.9370s
	iters: 200, epoch: 25 | loss: 0.3701375
	speed: 0.0300s/iter; left time: 588.2639s
Epoch: 25 cost time: 8.834390878677368
Epoch: 25, Steps: 261 | Train Loss: 0.3370046 Vali Loss: 0.6556148 Test Loss: 0.3680162
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3118591
	speed: 0.1398s/iter; left time: 2723.6719s
	iters: 200, epoch: 26 | loss: 0.2879336
	speed: 0.0348s/iter; left time: 674.0140s
Epoch: 26 cost time: 10.3834547996521
Epoch: 26, Steps: 261 | Train Loss: 0.3369480 Vali Loss: 0.6557810 Test Loss: 0.3678246
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3639209
	speed: 0.1321s/iter; left time: 2538.0892s
	iters: 200, epoch: 27 | loss: 0.3282529
	speed: 0.0356s/iter; left time: 680.0138s
Epoch: 27 cost time: 9.460853576660156
Epoch: 27, Steps: 261 | Train Loss: 0.3368561 Vali Loss: 0.6553442 Test Loss: 0.3678562
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3488585
	speed: 0.1516s/iter; left time: 2872.7169s
	iters: 200, epoch: 28 | loss: 0.3292896
	speed: 0.0312s/iter; left time: 587.9931s
Epoch: 28 cost time: 8.315042972564697
Epoch: 28, Steps: 261 | Train Loss: 0.3367118 Vali Loss: 0.6554322 Test Loss: 0.3679009
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3475094
	speed: 0.1320s/iter; left time: 2466.7401s
	iters: 200, epoch: 29 | loss: 0.3125995
	speed: 0.0314s/iter; left time: 583.8841s
Epoch: 29 cost time: 8.370802164077759
Epoch: 29, Steps: 261 | Train Loss: 0.3367943 Vali Loss: 0.6556653 Test Loss: 0.3682897
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3416251
	speed: 0.1397s/iter; left time: 2574.1477s
	iters: 200, epoch: 30 | loss: 0.3283793
	speed: 0.0296s/iter; left time: 541.9027s
Epoch: 30 cost time: 8.818998098373413
Epoch: 30, Steps: 261 | Train Loss: 0.3368390 Vali Loss: 0.6549181 Test Loss: 0.3680846
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_720_336_FITS_ETTm1_ftM_sl720_ll48_pl336_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.36721378564834595, mae:0.38583695888519287, rse:0.5766440033912659, corr:[0.53932893 0.5471241  0.55276525 0.55545324 0.5559471  0.5557163
 0.55573297 0.55644345 0.5578317  0.5594398  0.5607372  0.5612368
 0.5609099  0.5599746  0.5587371  0.55748403 0.556397   0.55549645
 0.55463797 0.5536975  0.5526144  0.5512888  0.54972816 0.54815906
 0.54664403 0.545426   0.54462904 0.54423285 0.54427177 0.5446542
 0.5452007  0.5458208  0.54636204 0.54685235 0.54718447 0.5474598
 0.5475444  0.54747933 0.5472754  0.5468652  0.5463803  0.5458776
 0.5454786  0.5453337  0.54537344 0.54548275 0.54562765 0.5457055
 0.545603   0.54528075 0.5449039  0.5445791  0.5444096  0.5442922
 0.5441977  0.5440634  0.5438599  0.5435678  0.5432909  0.5430453
 0.5429016  0.5429061  0.54300255 0.5430492  0.5430359  0.542947
 0.5427586  0.542516   0.54230917 0.5421897  0.5422073  0.5423209
 0.54242414 0.54243964 0.5423601  0.5421591  0.5418304  0.5414401
 0.5410574  0.54074866 0.540539   0.54040813 0.5403392  0.54026705
 0.5402097  0.54014    0.540089   0.5400478  0.54004085 0.540124
 0.54027826 0.54043853 0.5405419  0.540554   0.54045105 0.5402193
 0.5399182  0.53966    0.5393572  0.53904295 0.53873557 0.5384627
 0.53826386 0.53810734 0.53803813 0.5380814  0.5381277  0.5381712
 0.5381343  0.53801996 0.5378397  0.537593   0.53730786 0.5370389
 0.53681666 0.5366648  0.5365796  0.5365266  0.5364888  0.5364889
 0.53647596 0.5363927  0.53616947 0.5358819  0.53558564 0.53530246
 0.53507996 0.5349911  0.5350181  0.5351468  0.53525764 0.53527284
 0.53521335 0.5350814  0.53484386 0.534566   0.53436637 0.53421396
 0.5342035  0.53439534 0.5346953  0.5350742  0.53547966 0.53586465
 0.5361708  0.5363054  0.53631014 0.53621364 0.5360974  0.53594697
 0.53574616 0.53554845 0.53533906 0.5351221  0.5348965  0.53476924
 0.53473973 0.5347826  0.53492206 0.5350613  0.5352368  0.53540766
 0.53556603 0.5356814  0.53576046 0.5358196  0.5358837  0.53598726
 0.5360729  0.5360866  0.53610134 0.5361508  0.53619045 0.5362231
 0.536249   0.5362625  0.53624535 0.53619003 0.5360748  0.53594536
 0.5358318  0.53579766 0.5358265  0.5359913  0.53628415 0.5366513
 0.5370222  0.53735584 0.5376147  0.5377354  0.53767425 0.5374719
 0.53714466 0.53682405 0.5364629  0.53601843 0.5354852  0.5349048
 0.5342718  0.5336136  0.53293425 0.5322663  0.53159964 0.5309208
 0.53023475 0.5295295  0.5288008  0.5280922  0.5274169  0.5267669
 0.52610934 0.52546334 0.5248262  0.52420926 0.52357876 0.52302647
 0.5226437  0.5224204  0.52237546 0.52242714 0.52253026 0.52268994
 0.5229304  0.5231417  0.5233205  0.5234872  0.52362007 0.52375513
 0.5239192  0.5241203  0.5243343  0.5244794  0.52455115 0.5245854
 0.5246175  0.5247333  0.5248357  0.52502006 0.52520376 0.5253892
 0.52552    0.52547836 0.5252834  0.5250172  0.5247678  0.5245175
 0.5242631  0.52402836 0.52381015 0.5236591  0.52353173 0.5234852
 0.52344483 0.52347314 0.523499   0.5234756  0.5234148  0.52334416
 0.5233004  0.5233235  0.52339166 0.5234686  0.52351636 0.52358073
 0.5235754  0.52348554 0.5233284  0.5231811  0.52310205 0.52311146
 0.5232691  0.5235305  0.5238276  0.52407736 0.5241965  0.52417165
 0.5239865  0.52376735 0.5235515  0.5234839  0.523569   0.5237677
 0.52402323 0.52422845 0.5242634  0.5241064  0.52374566 0.52317727
 0.52248025 0.5218402  0.52132756 0.52087    0.5204401  0.5200004
 0.5195444  0.51901436 0.5184821  0.5179315  0.5173743  0.51686156
 0.5163939  0.51598924 0.5156917  0.5154766  0.51528484 0.51503664
 0.5147969  0.5145003  0.514148   0.5137699  0.5134674  0.51324564
 0.51312244 0.51312256 0.5131549  0.5131849  0.5131784  0.513171
 0.5131611  0.5130981  0.5129925  0.5128822  0.51278234 0.5126981
 0.5126184  0.5125787  0.5125288  0.5124832  0.5124142  0.5123587
 0.5124625  0.5127105  0.5129244  0.51277775 0.5115937  0.50814676]
