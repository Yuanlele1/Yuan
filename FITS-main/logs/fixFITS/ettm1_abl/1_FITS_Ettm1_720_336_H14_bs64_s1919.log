Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=122, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=1919, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_720_336_FITS_ETTm1_ftM_sl720_ll48_pl336_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=122, out_features=178, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  19457536.0
params:  21894.0
Trainable parameters:  21894
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4053559
	speed: 0.0200s/iter; left time: 519.0859s
	iters: 200, epoch: 1 | loss: 0.3421883
	speed: 0.0146s/iter; left time: 379.4246s
Epoch: 1 cost time: 4.322169065475464
Epoch: 1, Steps: 261 | Train Loss: 0.4093155 Vali Loss: 0.7063606 Test Loss: 0.3738099
Validation loss decreased (inf --> 0.706361).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3726814
	speed: 0.0617s/iter; left time: 1588.9297s
	iters: 200, epoch: 2 | loss: 0.3460309
	speed: 0.0145s/iter; left time: 371.8042s
Epoch: 2 cost time: 4.092096328735352
Epoch: 2, Steps: 261 | Train Loss: 0.3449165 Vali Loss: 0.6783931 Test Loss: 0.3665333
Validation loss decreased (0.706361 --> 0.678393).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3373779
	speed: 0.0603s/iter; left time: 1536.3576s
	iters: 200, epoch: 3 | loss: 0.3384615
	speed: 0.0137s/iter; left time: 348.7797s
Epoch: 3 cost time: 4.067933797836304
Epoch: 3, Steps: 261 | Train Loss: 0.3399035 Vali Loss: 0.6683817 Test Loss: 0.3668524
Validation loss decreased (0.678393 --> 0.668382).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3595770
	speed: 0.0598s/iter; left time: 1507.5397s
	iters: 200, epoch: 4 | loss: 0.3258590
	speed: 0.0141s/iter; left time: 353.7876s
Epoch: 4 cost time: 4.0741658210754395
Epoch: 4, Steps: 261 | Train Loss: 0.3383966 Vali Loss: 0.6649802 Test Loss: 0.3671506
Validation loss decreased (0.668382 --> 0.664980).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3805687
	speed: 0.0628s/iter; left time: 1566.5052s
	iters: 200, epoch: 5 | loss: 0.3401476
	speed: 0.0145s/iter; left time: 361.2927s
Epoch: 5 cost time: 4.0961761474609375
Epoch: 5, Steps: 261 | Train Loss: 0.3377483 Vali Loss: 0.6599135 Test Loss: 0.3668416
Validation loss decreased (0.664980 --> 0.659914).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3518908
	speed: 0.0596s/iter; left time: 1472.3833s
	iters: 200, epoch: 6 | loss: 0.3508829
	speed: 0.0140s/iter; left time: 345.5673s
Epoch: 6 cost time: 3.979191780090332
Epoch: 6, Steps: 261 | Train Loss: 0.3372826 Vali Loss: 0.6582739 Test Loss: 0.3669393
Validation loss decreased (0.659914 --> 0.658274).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3367948
	speed: 0.0606s/iter; left time: 1481.3568s
	iters: 200, epoch: 7 | loss: 0.3187336
	speed: 0.0136s/iter; left time: 330.3654s
Epoch: 7 cost time: 4.047779083251953
Epoch: 7, Steps: 261 | Train Loss: 0.3371149 Vali Loss: 0.6588495 Test Loss: 0.3667088
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3182565
	speed: 0.0599s/iter; left time: 1447.1082s
	iters: 200, epoch: 8 | loss: 0.3659875
	speed: 0.0142s/iter; left time: 342.8151s
Epoch: 8 cost time: 4.0823655128479
Epoch: 8, Steps: 261 | Train Loss: 0.3368630 Vali Loss: 0.6574321 Test Loss: 0.3666775
Validation loss decreased (0.658274 --> 0.657432).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3373904
	speed: 0.0620s/iter; left time: 1481.4532s
	iters: 200, epoch: 9 | loss: 0.3507568
	speed: 0.0141s/iter; left time: 336.2365s
Epoch: 9 cost time: 4.18713641166687
Epoch: 9, Steps: 261 | Train Loss: 0.3367014 Vali Loss: 0.6584530 Test Loss: 0.3672040
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3338791
	speed: 0.0595s/iter; left time: 1406.7805s
	iters: 200, epoch: 10 | loss: 0.3479491
	speed: 0.0137s/iter; left time: 322.3781s
Epoch: 10 cost time: 4.040451526641846
Epoch: 10, Steps: 261 | Train Loss: 0.3366042 Vali Loss: 0.6568003 Test Loss: 0.3667412
Validation loss decreased (0.657432 --> 0.656800).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3441727
	speed: 0.0614s/iter; left time: 1435.5279s
	iters: 200, epoch: 11 | loss: 0.3175278
	speed: 0.0144s/iter; left time: 335.2209s
Epoch: 11 cost time: 4.230770587921143
Epoch: 11, Steps: 261 | Train Loss: 0.3366087 Vali Loss: 0.6545117 Test Loss: 0.3667518
Validation loss decreased (0.656800 --> 0.654512).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3146018
	speed: 0.0615s/iter; left time: 1422.1324s
	iters: 200, epoch: 12 | loss: 0.3030601
	speed: 0.0138s/iter; left time: 318.0513s
Epoch: 12 cost time: 4.166224479675293
Epoch: 12, Steps: 261 | Train Loss: 0.3364015 Vali Loss: 0.6556979 Test Loss: 0.3666305
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3528885
	speed: 0.0589s/iter; left time: 1346.5046s
	iters: 200, epoch: 13 | loss: 0.3437720
	speed: 0.0141s/iter; left time: 321.3601s
Epoch: 13 cost time: 4.0392866134643555
Epoch: 13, Steps: 261 | Train Loss: 0.3363572 Vali Loss: 0.6556487 Test Loss: 0.3665985
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3023122
	speed: 0.0591s/iter; left time: 1337.2107s
	iters: 200, epoch: 14 | loss: 0.3235608
	speed: 0.0144s/iter; left time: 323.1801s
Epoch: 14 cost time: 4.12437105178833
Epoch: 14, Steps: 261 | Train Loss: 0.3364176 Vali Loss: 0.6555225 Test Loss: 0.3666278
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3198877
	speed: 0.0610s/iter; left time: 1362.0721s
	iters: 200, epoch: 15 | loss: 0.3343179
	speed: 0.0145s/iter; left time: 323.0116s
Epoch: 15 cost time: 4.221393585205078
Epoch: 15, Steps: 261 | Train Loss: 0.3362798 Vali Loss: 0.6558759 Test Loss: 0.3665365
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3728372
	speed: 0.0602s/iter; left time: 1329.6801s
	iters: 200, epoch: 16 | loss: 0.3168437
	speed: 0.0135s/iter; left time: 296.0666s
Epoch: 16 cost time: 4.10199236869812
Epoch: 16, Steps: 261 | Train Loss: 0.3363172 Vali Loss: 0.6547104 Test Loss: 0.3670192
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3101293
	speed: 0.0611s/iter; left time: 1332.9995s
	iters: 200, epoch: 17 | loss: 0.3221366
	speed: 0.0141s/iter; left time: 305.3698s
Epoch: 17 cost time: 4.066679239273071
Epoch: 17, Steps: 261 | Train Loss: 0.3361827 Vali Loss: 0.6535688 Test Loss: 0.3667493
Validation loss decreased (0.654512 --> 0.653569).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3499496
	speed: 0.0613s/iter; left time: 1322.1850s
	iters: 200, epoch: 18 | loss: 0.2916265
	speed: 0.0144s/iter; left time: 308.6770s
Epoch: 18 cost time: 4.170593976974487
Epoch: 18, Steps: 261 | Train Loss: 0.3361950 Vali Loss: 0.6548936 Test Loss: 0.3665608
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3569002
	speed: 0.0601s/iter; left time: 1280.2827s
	iters: 200, epoch: 19 | loss: 0.3508096
	speed: 0.0135s/iter; left time: 286.7356s
Epoch: 19 cost time: 4.09830117225647
Epoch: 19, Steps: 261 | Train Loss: 0.3361633 Vali Loss: 0.6546093 Test Loss: 0.3667550
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3528463
	speed: 0.0606s/iter; left time: 1275.8842s
	iters: 200, epoch: 20 | loss: 0.3329511
	speed: 0.0142s/iter; left time: 297.4112s
Epoch: 20 cost time: 4.067269802093506
Epoch: 20, Steps: 261 | Train Loss: 0.3360740 Vali Loss: 0.6538847 Test Loss: 0.3666556
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3178208
	speed: 0.0602s/iter; left time: 1250.3183s
	iters: 200, epoch: 21 | loss: 0.3790661
	speed: 0.0137s/iter; left time: 282.8143s
Epoch: 21 cost time: 4.031585693359375
Epoch: 21, Steps: 261 | Train Loss: 0.3359810 Vali Loss: 0.6542301 Test Loss: 0.3669746
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3074244
	speed: 0.0604s/iter; left time: 1240.2343s
	iters: 200, epoch: 22 | loss: 0.3442529
	speed: 0.0143s/iter; left time: 292.6962s
Epoch: 22 cost time: 4.13882303237915
Epoch: 22, Steps: 261 | Train Loss: 0.3359282 Vali Loss: 0.6546739 Test Loss: 0.3667254
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3247190
	speed: 0.0603s/iter; left time: 1221.5797s
	iters: 200, epoch: 23 | loss: 0.3634843
	speed: 0.0147s/iter; left time: 295.8495s
Epoch: 23 cost time: 4.159994602203369
Epoch: 23, Steps: 261 | Train Loss: 0.3360240 Vali Loss: 0.6542023 Test Loss: 0.3667342
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3656222
	speed: 0.0618s/iter; left time: 1236.1143s
	iters: 200, epoch: 24 | loss: 0.3029729
	speed: 0.0146s/iter; left time: 289.7020s
Epoch: 24 cost time: 4.2590789794921875
Epoch: 24, Steps: 261 | Train Loss: 0.3359160 Vali Loss: 0.6544794 Test Loss: 0.3667876
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3381589
	speed: 0.0599s/iter; left time: 1181.4477s
	iters: 200, epoch: 25 | loss: 0.3450539
	speed: 0.0139s/iter; left time: 272.3304s
Epoch: 25 cost time: 4.088837146759033
Epoch: 25, Steps: 261 | Train Loss: 0.3359128 Vali Loss: 0.6523734 Test Loss: 0.3666835
Validation loss decreased (0.653569 --> 0.652373).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3265186
	speed: 0.0606s/iter; left time: 1179.9443s
	iters: 200, epoch: 26 | loss: 0.3106387
	speed: 0.0144s/iter; left time: 279.8234s
Epoch: 26 cost time: 4.142372131347656
Epoch: 26, Steps: 261 | Train Loss: 0.3358751 Vali Loss: 0.6547773 Test Loss: 0.3667445
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3401231
	speed: 0.0608s/iter; left time: 1168.7275s
	iters: 200, epoch: 27 | loss: 0.3279617
	speed: 0.0134s/iter; left time: 257.0771s
Epoch: 27 cost time: 4.080187559127808
Epoch: 27, Steps: 261 | Train Loss: 0.3359639 Vali Loss: 0.6540224 Test Loss: 0.3668322
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3443165
	speed: 0.0618s/iter; left time: 1170.7983s
	iters: 200, epoch: 28 | loss: 0.3122439
	speed: 0.0141s/iter; left time: 266.1650s
Epoch: 28 cost time: 4.12985372543335
Epoch: 28, Steps: 261 | Train Loss: 0.3357299 Vali Loss: 0.6537659 Test Loss: 0.3667830
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3775908
	speed: 0.0624s/iter; left time: 1166.8991s
	iters: 200, epoch: 29 | loss: 0.3411558
	speed: 0.0152s/iter; left time: 282.1895s
Epoch: 29 cost time: 4.417454719543457
Epoch: 29, Steps: 261 | Train Loss: 0.3359225 Vali Loss: 0.6542267 Test Loss: 0.3667586
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3307418
	speed: 0.0620s/iter; left time: 1142.0169s
	iters: 200, epoch: 30 | loss: 0.3204080
	speed: 0.0138s/iter; left time: 252.2630s
Epoch: 30 cost time: 4.084358215332031
Epoch: 30, Steps: 261 | Train Loss: 0.3358301 Vali Loss: 0.6543368 Test Loss: 0.3665361
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3362079
	speed: 0.0612s/iter; left time: 1112.0553s
	iters: 200, epoch: 31 | loss: 0.3600752
	speed: 0.0144s/iter; left time: 260.3969s
Epoch: 31 cost time: 4.175102233886719
Epoch: 31, Steps: 261 | Train Loss: 0.3357853 Vali Loss: 0.6540423 Test Loss: 0.3667175
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3169726
	speed: 0.0598s/iter; left time: 1071.0266s
	iters: 200, epoch: 32 | loss: 0.3519861
	speed: 0.0145s/iter; left time: 257.7952s
Epoch: 32 cost time: 4.205561876296997
Epoch: 32, Steps: 261 | Train Loss: 0.3359211 Vali Loss: 0.6539105 Test Loss: 0.3666728
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3425343
	speed: 0.0606s/iter; left time: 1068.6643s
	iters: 200, epoch: 33 | loss: 0.3275743
	speed: 0.0141s/iter; left time: 247.6297s
Epoch: 33 cost time: 4.051790475845337
Epoch: 33, Steps: 261 | Train Loss: 0.3358399 Vali Loss: 0.6548332 Test Loss: 0.3666388
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3452631
	speed: 0.0614s/iter; left time: 1067.8727s
	iters: 200, epoch: 34 | loss: 0.3074892
	speed: 0.0142s/iter; left time: 246.0174s
Epoch: 34 cost time: 4.057882785797119
Epoch: 34, Steps: 261 | Train Loss: 0.3357462 Vali Loss: 0.6541721 Test Loss: 0.3668128
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3541514
	speed: 0.0596s/iter; left time: 1021.5759s
	iters: 200, epoch: 35 | loss: 0.3164358
	speed: 0.0143s/iter; left time: 244.2191s
Epoch: 35 cost time: 4.1311211585998535
Epoch: 35, Steps: 261 | Train Loss: 0.3357950 Vali Loss: 0.6545360 Test Loss: 0.3668102
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3593860
	speed: 0.0597s/iter; left time: 1006.1204s
	iters: 200, epoch: 36 | loss: 0.3061483
	speed: 0.0140s/iter; left time: 234.4892s
Epoch: 36 cost time: 4.1833226680755615
Epoch: 36, Steps: 261 | Train Loss: 0.3358727 Vali Loss: 0.6538718 Test Loss: 0.3669460
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3468022
	speed: 0.0619s/iter; left time: 1027.3341s
	iters: 200, epoch: 37 | loss: 0.3583521
	speed: 0.0142s/iter; left time: 234.1939s
Epoch: 37 cost time: 4.18565034866333
Epoch: 37, Steps: 261 | Train Loss: 0.3357016 Vali Loss: 0.6539311 Test Loss: 0.3669153
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3298745
	speed: 0.0601s/iter; left time: 981.4771s
	iters: 200, epoch: 38 | loss: 0.3429687
	speed: 0.0143s/iter; left time: 232.2239s
Epoch: 38 cost time: 4.131873369216919
Epoch: 38, Steps: 261 | Train Loss: 0.3357712 Vali Loss: 0.6540140 Test Loss: 0.3667721
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3463046
	speed: 0.0593s/iter; left time: 954.5122s
	iters: 200, epoch: 39 | loss: 0.3408487
	speed: 0.0143s/iter; left time: 227.9432s
Epoch: 39 cost time: 4.151745080947876
Epoch: 39, Steps: 261 | Train Loss: 0.3357725 Vali Loss: 0.6535367 Test Loss: 0.3667427
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.3229066
	speed: 0.0613s/iter; left time: 969.5539s
	iters: 200, epoch: 40 | loss: 0.3142066
	speed: 0.0146s/iter; left time: 228.8197s
Epoch: 40 cost time: 4.169991493225098
Epoch: 40, Steps: 261 | Train Loss: 0.3355946 Vali Loss: 0.6538084 Test Loss: 0.3668078
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3445907
	speed: 0.0608s/iter; left time: 946.3290s
	iters: 200, epoch: 41 | loss: 0.3481067
	speed: 0.0142s/iter; left time: 219.7659s
Epoch: 41 cost time: 4.1016316413879395
Epoch: 41, Steps: 261 | Train Loss: 0.3357323 Vali Loss: 0.6544563 Test Loss: 0.3667282
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3489279
	speed: 0.0606s/iter; left time: 926.5275s
	iters: 200, epoch: 42 | loss: 0.3629806
	speed: 0.0142s/iter; left time: 215.3949s
Epoch: 42 cost time: 4.132447957992554
Epoch: 42, Steps: 261 | Train Loss: 0.3357125 Vali Loss: 0.6541196 Test Loss: 0.3666079
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3189277
	speed: 0.0610s/iter; left time: 917.2150s
	iters: 200, epoch: 43 | loss: 0.3451926
	speed: 0.0143s/iter; left time: 212.9555s
Epoch: 43 cost time: 4.096869945526123
Epoch: 43, Steps: 261 | Train Loss: 0.3357158 Vali Loss: 0.6540585 Test Loss: 0.3666963
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.3316516
	speed: 0.0613s/iter; left time: 906.5720s
	iters: 200, epoch: 44 | loss: 0.3530960
	speed: 0.0138s/iter; left time: 202.2853s
Epoch: 44 cost time: 4.179839134216309
Epoch: 44, Steps: 261 | Train Loss: 0.3357356 Vali Loss: 0.6536698 Test Loss: 0.3667685
EarlyStopping counter: 19 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.3405190
	speed: 0.0614s/iter; left time: 891.6918s
	iters: 200, epoch: 45 | loss: 0.3395176
	speed: 0.0144s/iter; left time: 207.9555s
Epoch: 45 cost time: 4.167359828948975
Epoch: 45, Steps: 261 | Train Loss: 0.3357003 Vali Loss: 0.6534944 Test Loss: 0.3667699
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_720_336_FITS_ETTm1_ftM_sl720_ll48_pl336_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.3661702871322632, mae:0.3848281800746918, rse:0.5758242011070251, corr:[0.5377884  0.54700446 0.55005145 0.5504537  0.5513961  0.5534271
 0.5552876  0.5561557  0.5564679  0.556914   0.55781305 0.5587475
 0.55927545 0.55921537 0.55865806 0.5577297  0.5565621  0.5553268
 0.55409056 0.5529168  0.55174744 0.5504226  0.54894197 0.54761434
 0.5464125  0.54547364 0.54465425 0.54373306 0.5429626  0.5426357
 0.54301625 0.544141   0.54546356 0.546489   0.5467771  0.546756
 0.54658645 0.5464619  0.54631966 0.5459667  0.54556775 0.54521084
 0.54502773 0.54505175 0.54498327 0.54473424 0.5445749  0.54466045
 0.5448548  0.5448521  0.54457825 0.5440586  0.5435941  0.54336274
 0.5434671  0.5436978  0.54377574 0.54356134 0.5432968  0.5431029
 0.5430875  0.54316646 0.54317635 0.5429682  0.54278034 0.54277956
 0.54289883 0.5429868  0.542982   0.54290783 0.54292625 0.5430709
 0.54322106 0.5432054  0.54297936 0.542546   0.5420475  0.54170686
 0.5415968  0.54164255 0.5416653  0.5415073  0.54119533 0.54082614
 0.5405905  0.5405298  0.5406283  0.54073983 0.5407953  0.540884
 0.5410208  0.54120576 0.54142123 0.541633   0.5417618  0.54173267
 0.541557   0.5413416  0.5410107  0.5406529  0.54032713 0.5400623
 0.53986794 0.53965014 0.53946286 0.5393481  0.53920054 0.53909093
 0.53898966 0.5389578  0.5389907  0.5389871  0.53886175 0.5385864
 0.5381589  0.537674   0.5372428  0.53691006 0.5366892  0.5365605
 0.53639483 0.5361272  0.5357809  0.5355762  0.53559494 0.5356831
 0.5356903  0.53562003 0.5355108  0.5354901  0.5354782  0.53535616
 0.5351008  0.53473324 0.53436077 0.53425103 0.5345655  0.53499943
 0.5353469  0.5354731  0.53533167 0.5351502  0.5351202  0.5352527
 0.53543705 0.535505   0.535512   0.53551185 0.5355686  0.5355614
 0.5354232  0.5352729  0.53517365 0.5351645  0.5351937  0.5352504
 0.53525484 0.53516686 0.535121   0.5350862  0.53513694 0.5351953
 0.5352404  0.53528374 0.535411   0.535639   0.53588396 0.53604
 0.5360401  0.53596425 0.5360696  0.53641784 0.5367811  0.53695434
 0.5368641  0.53660727 0.5363669  0.5363044  0.53637826 0.536457
 0.5363591  0.5360715  0.5357113  0.53558344 0.5358289  0.53636116
 0.53694755 0.5374244  0.5377201  0.5378434  0.53787965 0.53788966
 0.53785795 0.5377915  0.5375165  0.5369406  0.5361157  0.53520167
 0.5343321  0.5336376  0.5331345  0.5327727  0.53242135 0.5319901
 0.5314628  0.53085226 0.5302021  0.5296176  0.5291106  0.52865
 0.5281655  0.52765626 0.5270655  0.5263678  0.5255255  0.52475536
 0.52424663 0.5239627  0.52383465 0.5236857  0.52349126 0.5233738
 0.52348393 0.52371    0.5240061  0.5242657  0.5243619  0.52432126
 0.52423424 0.52420354 0.5242681  0.5243372  0.52439904 0.52449095
 0.52461433 0.52481437 0.5249203  0.5250594  0.52516735 0.5252959
 0.5254025  0.52537614 0.5252775  0.525194   0.52519566 0.5251973
 0.5251559  0.5251195  0.5250707  0.52505004 0.5249581  0.5248513
 0.5246414  0.52449375 0.52440494 0.52439034 0.52445495 0.52454275
 0.5245682  0.5245018  0.5243402  0.5241694  0.5240942  0.52424043
 0.52444404 0.5245637  0.5245684  0.5245422  0.5245535  0.52458066
 0.5246368  0.5246185  0.52448314 0.52427983 0.52406806 0.5239466
 0.5239113  0.52401793 0.5241345  0.5242657  0.52431935 0.5242887
 0.52427125 0.5243137  0.5243673  0.52440095 0.5243123  0.52399576
 0.5235196  0.5230768  0.5226917  0.52221763 0.52165437 0.5210315
 0.52043897 0.51985717 0.51938933 0.5189492  0.5184886  0.51800686
 0.517477   0.5169706  0.5165643  0.5162094  0.5158568  0.5154825
 0.51529694 0.51521707 0.5151301  0.51488394 0.51448023 0.5139597
 0.51353997 0.5134476  0.5135732  0.51374424 0.5137958  0.5137369
 0.51360893 0.513414   0.5132242  0.5130822  0.51299286 0.51294696
 0.51292074 0.51296765 0.51298356 0.51299006 0.5129793  0.51299155
 0.51309174 0.5131179  0.5130338  0.5130536  0.51284605 0.5102568 ]
