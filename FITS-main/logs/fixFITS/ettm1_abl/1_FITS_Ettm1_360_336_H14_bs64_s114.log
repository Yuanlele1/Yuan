Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=66, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_360_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_360_336_FITS_ETTm1_ftM_sl360_ll48_pl336_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33865
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=66, out_features=127, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  7510272.0
params:  8509.0
Trainable parameters:  8509
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4436508
	speed: 0.0186s/iter; left time: 489.8409s
	iters: 200, epoch: 1 | loss: 0.3731588
	speed: 0.0121s/iter; left time: 316.3900s
Epoch: 1 cost time: 3.8418729305267334
Epoch: 1, Steps: 264 | Train Loss: 0.4825665 Vali Loss: 0.7423546 Test Loss: 0.4140440
Validation loss decreased (inf --> 0.742355).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3730654
	speed: 0.0557s/iter; left time: 1450.2585s
	iters: 200, epoch: 2 | loss: 0.3735383
	speed: 0.0110s/iter; left time: 286.1465s
Epoch: 2 cost time: 3.5421857833862305
Epoch: 2, Steps: 264 | Train Loss: 0.3713361 Vali Loss: 0.6864832 Test Loss: 0.3807853
Validation loss decreased (0.742355 --> 0.686483).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3333326
	speed: 0.0551s/iter; left time: 1419.5135s
	iters: 200, epoch: 3 | loss: 0.3361675
	speed: 0.0110s/iter; left time: 282.0218s
Epoch: 3 cost time: 3.4628522396087646
Epoch: 3, Steps: 264 | Train Loss: 0.3570355 Vali Loss: 0.6705077 Test Loss: 0.3737659
Validation loss decreased (0.686483 --> 0.670508).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3519129
	speed: 0.0572s/iter; left time: 1460.1047s
	iters: 200, epoch: 4 | loss: 0.3382316
	speed: 0.0114s/iter; left time: 290.2107s
Epoch: 4 cost time: 3.6776318550109863
Epoch: 4, Steps: 264 | Train Loss: 0.3519578 Vali Loss: 0.6640114 Test Loss: 0.3719544
Validation loss decreased (0.670508 --> 0.664011).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3461596
	speed: 0.0546s/iter; left time: 1379.1872s
	iters: 200, epoch: 5 | loss: 0.3570942
	speed: 0.0117s/iter; left time: 294.9905s
Epoch: 5 cost time: 3.566365957260132
Epoch: 5, Steps: 264 | Train Loss: 0.3498959 Vali Loss: 0.6601031 Test Loss: 0.3713771
Validation loss decreased (0.664011 --> 0.660103).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3614074
	speed: 0.0540s/iter; left time: 1348.1273s
	iters: 200, epoch: 6 | loss: 0.3487708
	speed: 0.0113s/iter; left time: 279.9194s
Epoch: 6 cost time: 3.512968063354492
Epoch: 6, Steps: 264 | Train Loss: 0.3488782 Vali Loss: 0.6586061 Test Loss: 0.3712261
Validation loss decreased (0.660103 --> 0.658606).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3852027
	speed: 0.0543s/iter; left time: 1341.4073s
	iters: 200, epoch: 7 | loss: 0.3570422
	speed: 0.0110s/iter; left time: 270.1633s
Epoch: 7 cost time: 3.4797704219818115
Epoch: 7, Steps: 264 | Train Loss: 0.3482423 Vali Loss: 0.6572142 Test Loss: 0.3710796
Validation loss decreased (0.658606 --> 0.657214).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3538537
	speed: 0.0541s/iter; left time: 1322.1214s
	iters: 200, epoch: 8 | loss: 0.3078950
	speed: 0.0117s/iter; left time: 286.0987s
Epoch: 8 cost time: 3.650707244873047
Epoch: 8, Steps: 264 | Train Loss: 0.3478213 Vali Loss: 0.6563248 Test Loss: 0.3712953
Validation loss decreased (0.657214 --> 0.656325).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3252743
	speed: 0.0552s/iter; left time: 1334.6394s
	iters: 200, epoch: 9 | loss: 0.3311698
	speed: 0.0115s/iter; left time: 276.7902s
Epoch: 9 cost time: 3.5576205253601074
Epoch: 9, Steps: 264 | Train Loss: 0.3476612 Vali Loss: 0.6552991 Test Loss: 0.3711247
Validation loss decreased (0.656325 --> 0.655299).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3421178
	speed: 0.0565s/iter; left time: 1352.3092s
	iters: 200, epoch: 10 | loss: 0.3079648
	speed: 0.0134s/iter; left time: 320.4219s
Epoch: 10 cost time: 3.8921728134155273
Epoch: 10, Steps: 264 | Train Loss: 0.3474982 Vali Loss: 0.6557220 Test Loss: 0.3715100
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3312128
	speed: 0.0581s/iter; left time: 1373.6549s
	iters: 200, epoch: 11 | loss: 0.3174417
	speed: 0.0111s/iter; left time: 261.2812s
Epoch: 11 cost time: 3.4834322929382324
Epoch: 11, Steps: 264 | Train Loss: 0.3473633 Vali Loss: 0.6544641 Test Loss: 0.3712220
Validation loss decreased (0.655299 --> 0.654464).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3305463
	speed: 0.0537s/iter; left time: 1255.5918s
	iters: 200, epoch: 12 | loss: 0.3507994
	speed: 0.0109s/iter; left time: 253.5351s
Epoch: 12 cost time: 3.48683762550354
Epoch: 12, Steps: 264 | Train Loss: 0.3473988 Vali Loss: 0.6531310 Test Loss: 0.3716352
Validation loss decreased (0.654464 --> 0.653131).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3528708
	speed: 0.0548s/iter; left time: 1266.8379s
	iters: 200, epoch: 13 | loss: 0.3457263
	speed: 0.0117s/iter; left time: 269.6443s
Epoch: 13 cost time: 3.6315503120422363
Epoch: 13, Steps: 264 | Train Loss: 0.3473181 Vali Loss: 0.6529104 Test Loss: 0.3718987
Validation loss decreased (0.653131 --> 0.652910).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3595859
	speed: 0.0554s/iter; left time: 1267.9110s
	iters: 200, epoch: 14 | loss: 0.3288640
	speed: 0.0117s/iter; left time: 267.2948s
Epoch: 14 cost time: 3.5335018634796143
Epoch: 14, Steps: 264 | Train Loss: 0.3471625 Vali Loss: 0.6543096 Test Loss: 0.3715152
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3139494
	speed: 0.0547s/iter; left time: 1235.4848s
	iters: 200, epoch: 15 | loss: 0.3732670
	speed: 0.0108s/iter; left time: 243.5202s
Epoch: 15 cost time: 3.478409767150879
Epoch: 15, Steps: 264 | Train Loss: 0.3472453 Vali Loss: 0.6544275 Test Loss: 0.3715246
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3755205
	speed: 0.0536s/iter; left time: 1198.1386s
	iters: 200, epoch: 16 | loss: 0.3399557
	speed: 0.0115s/iter; left time: 255.9000s
Epoch: 16 cost time: 3.5600080490112305
Epoch: 16, Steps: 264 | Train Loss: 0.3472560 Vali Loss: 0.6534599 Test Loss: 0.3718161
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3180527
	speed: 0.0536s/iter; left time: 1182.4957s
	iters: 200, epoch: 17 | loss: 0.3316884
	speed: 0.0110s/iter; left time: 241.8419s
Epoch: 17 cost time: 3.5558905601501465
Epoch: 17, Steps: 264 | Train Loss: 0.3471747 Vali Loss: 0.6538414 Test Loss: 0.3717467
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3452574
	speed: 0.0535s/iter; left time: 1168.0581s
	iters: 200, epoch: 18 | loss: 0.3339659
	speed: 0.0107s/iter; left time: 231.8107s
Epoch: 18 cost time: 3.5025837421417236
Epoch: 18, Steps: 264 | Train Loss: 0.3471841 Vali Loss: 0.6539938 Test Loss: 0.3712891
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3651420
	speed: 0.0549s/iter; left time: 1182.1531s
	iters: 200, epoch: 19 | loss: 0.3800885
	speed: 0.0111s/iter; left time: 238.4854s
Epoch: 19 cost time: 3.540759801864624
Epoch: 19, Steps: 264 | Train Loss: 0.3470526 Vali Loss: 0.6542998 Test Loss: 0.3715078
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3263255
	speed: 0.0543s/iter; left time: 1154.9094s
	iters: 200, epoch: 20 | loss: 0.3656669
	speed: 0.0110s/iter; left time: 233.0346s
Epoch: 20 cost time: 3.5673794746398926
Epoch: 20, Steps: 264 | Train Loss: 0.3471038 Vali Loss: 0.6542171 Test Loss: 0.3715997
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3290661
	speed: 0.0578s/iter; left time: 1215.5419s
	iters: 200, epoch: 21 | loss: 0.3442844
	speed: 0.0110s/iter; left time: 230.5999s
Epoch: 21 cost time: 3.502298355102539
Epoch: 21, Steps: 264 | Train Loss: 0.3470889 Vali Loss: 0.6534970 Test Loss: 0.3715030
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3556347
	speed: 0.0547s/iter; left time: 1136.0187s
	iters: 200, epoch: 22 | loss: 0.3491498
	speed: 0.0111s/iter; left time: 228.3964s
Epoch: 22 cost time: 3.462934732437134
Epoch: 22, Steps: 264 | Train Loss: 0.3470639 Vali Loss: 0.6527846 Test Loss: 0.3715106
Validation loss decreased (0.652910 --> 0.652785).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3267840
	speed: 0.0555s/iter; left time: 1137.6908s
	iters: 200, epoch: 23 | loss: 0.3442052
	speed: 0.0118s/iter; left time: 239.8444s
Epoch: 23 cost time: 3.6841742992401123
Epoch: 23, Steps: 264 | Train Loss: 0.3469537 Vali Loss: 0.6535171 Test Loss: 0.3715563
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3422292
	speed: 0.0554s/iter; left time: 1121.4320s
	iters: 200, epoch: 24 | loss: 0.3509464
	speed: 0.0122s/iter; left time: 245.1322s
Epoch: 24 cost time: 3.7155630588531494
Epoch: 24, Steps: 264 | Train Loss: 0.3470237 Vali Loss: 0.6536679 Test Loss: 0.3714712
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3593134
	speed: 0.0556s/iter; left time: 1109.7819s
	iters: 200, epoch: 25 | loss: 0.3695975
	speed: 0.0107s/iter; left time: 213.0150s
Epoch: 25 cost time: 3.4542863368988037
Epoch: 25, Steps: 264 | Train Loss: 0.3470388 Vali Loss: 0.6537039 Test Loss: 0.3717048
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3465736
	speed: 0.0535s/iter; left time: 1053.9277s
	iters: 200, epoch: 26 | loss: 0.3249918
	speed: 0.0114s/iter; left time: 223.1475s
Epoch: 26 cost time: 3.544257640838623
Epoch: 26, Steps: 264 | Train Loss: 0.3470443 Vali Loss: 0.6531364 Test Loss: 0.3715953
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3584910
	speed: 0.0541s/iter; left time: 1050.9557s
	iters: 200, epoch: 27 | loss: 0.3452999
	speed: 0.0110s/iter; left time: 211.9392s
Epoch: 27 cost time: 3.4075498580932617
Epoch: 27, Steps: 264 | Train Loss: 0.3470203 Vali Loss: 0.6529638 Test Loss: 0.3715155
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3427519
	speed: 0.0555s/iter; left time: 1063.4082s
	iters: 200, epoch: 28 | loss: 0.3455165
	speed: 0.0113s/iter; left time: 214.7570s
Epoch: 28 cost time: 3.5906264781951904
Epoch: 28, Steps: 264 | Train Loss: 0.3468813 Vali Loss: 0.6533080 Test Loss: 0.3714722
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3768423
	speed: 0.0550s/iter; left time: 1040.4468s
	iters: 200, epoch: 29 | loss: 0.3355348
	speed: 0.0117s/iter; left time: 220.2486s
Epoch: 29 cost time: 3.4956588745117188
Epoch: 29, Steps: 264 | Train Loss: 0.3469489 Vali Loss: 0.6517794 Test Loss: 0.3716395
Validation loss decreased (0.652785 --> 0.651779).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3518471
	speed: 0.0531s/iter; left time: 989.3872s
	iters: 200, epoch: 30 | loss: 0.3537535
	speed: 0.0111s/iter; left time: 205.3640s
Epoch: 30 cost time: 3.4689838886260986
Epoch: 30, Steps: 264 | Train Loss: 0.3469321 Vali Loss: 0.6526642 Test Loss: 0.3716151
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3328492
	speed: 0.0528s/iter; left time: 970.1264s
	iters: 200, epoch: 31 | loss: 0.3262530
	speed: 0.0111s/iter; left time: 203.6937s
Epoch: 31 cost time: 3.489600896835327
Epoch: 31, Steps: 264 | Train Loss: 0.3469011 Vali Loss: 0.6526611 Test Loss: 0.3716311
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3435509
	speed: 0.0541s/iter; left time: 979.9669s
	iters: 200, epoch: 32 | loss: 0.3812565
	speed: 0.0113s/iter; left time: 203.9983s
Epoch: 32 cost time: 3.419381856918335
Epoch: 32, Steps: 264 | Train Loss: 0.3469279 Vali Loss: 0.6529220 Test Loss: 0.3716283
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3317900
	speed: 0.0538s/iter; left time: 960.4905s
	iters: 200, epoch: 33 | loss: 0.3654773
	speed: 0.0110s/iter; left time: 195.4456s
Epoch: 33 cost time: 3.4529271125793457
Epoch: 33, Steps: 264 | Train Loss: 0.3468351 Vali Loss: 0.6532866 Test Loss: 0.3716215
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3627611
	speed: 0.0568s/iter; left time: 999.2311s
	iters: 200, epoch: 34 | loss: 0.3301717
	speed: 0.0112s/iter; left time: 195.7031s
Epoch: 34 cost time: 3.5313620567321777
Epoch: 34, Steps: 264 | Train Loss: 0.3469254 Vali Loss: 0.6533726 Test Loss: 0.3715190
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3495935
	speed: 0.0541s/iter; left time: 937.3318s
	iters: 200, epoch: 35 | loss: 0.3534526
	speed: 0.0120s/iter; left time: 206.5275s
Epoch: 35 cost time: 3.695451021194458
Epoch: 35, Steps: 264 | Train Loss: 0.3468063 Vali Loss: 0.6529394 Test Loss: 0.3715986
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3477168
	speed: 0.0565s/iter; left time: 963.4267s
	iters: 200, epoch: 36 | loss: 0.3558407
	speed: 0.0114s/iter; left time: 193.7484s
Epoch: 36 cost time: 3.5473673343658447
Epoch: 36, Steps: 264 | Train Loss: 0.3469119 Vali Loss: 0.6536927 Test Loss: 0.3715930
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3889138
	speed: 0.0533s/iter; left time: 895.5331s
	iters: 200, epoch: 37 | loss: 0.2990055
	speed: 0.0111s/iter; left time: 184.9305s
Epoch: 37 cost time: 3.395932912826538
Epoch: 37, Steps: 264 | Train Loss: 0.3468731 Vali Loss: 0.6529280 Test Loss: 0.3715440
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3535258
	speed: 0.0550s/iter; left time: 908.5008s
	iters: 200, epoch: 38 | loss: 0.3320944
	speed: 0.0109s/iter; left time: 178.9024s
Epoch: 38 cost time: 3.421588182449341
Epoch: 38, Steps: 264 | Train Loss: 0.3469000 Vali Loss: 0.6529213 Test Loss: 0.3715816
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3233823
	speed: 0.0563s/iter; left time: 915.8676s
	iters: 200, epoch: 39 | loss: 0.3558507
	speed: 0.0109s/iter; left time: 176.6605s
Epoch: 39 cost time: 3.483281373977661
Epoch: 39, Steps: 264 | Train Loss: 0.3467945 Vali Loss: 0.6530540 Test Loss: 0.3715906
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.3422340
	speed: 0.0540s/iter; left time: 863.5998s
	iters: 200, epoch: 40 | loss: 0.3407862
	speed: 0.0111s/iter; left time: 177.2034s
Epoch: 40 cost time: 3.458543062210083
Epoch: 40, Steps: 264 | Train Loss: 0.3468862 Vali Loss: 0.6526628 Test Loss: 0.3716255
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3221874
	speed: 0.0545s/iter; left time: 857.2777s
	iters: 200, epoch: 41 | loss: 0.3143286
	speed: 0.0112s/iter; left time: 174.4431s
Epoch: 41 cost time: 3.450265407562256
Epoch: 41, Steps: 264 | Train Loss: 0.3467455 Vali Loss: 0.6532384 Test Loss: 0.3715781
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3307077
	speed: 0.0545s/iter; left time: 843.7204s
	iters: 200, epoch: 42 | loss: 0.3305226
	speed: 0.0109s/iter; left time: 167.9409s
Epoch: 42 cost time: 3.364799976348877
Epoch: 42, Steps: 264 | Train Loss: 0.3467845 Vali Loss: 0.6521480 Test Loss: 0.3715442
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3896847
	speed: 0.0541s/iter; left time: 823.3799s
	iters: 200, epoch: 43 | loss: 0.3376693
	speed: 0.0111s/iter; left time: 168.3280s
Epoch: 43 cost time: 3.4960591793060303
Epoch: 43, Steps: 264 | Train Loss: 0.3468587 Vali Loss: 0.6529100 Test Loss: 0.3715822
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.3615074
	speed: 0.0536s/iter; left time: 801.9563s
	iters: 200, epoch: 44 | loss: 0.2959125
	speed: 0.0108s/iter; left time: 160.1529s
Epoch: 44 cost time: 3.4056808948516846
Epoch: 44, Steps: 264 | Train Loss: 0.3467908 Vali Loss: 0.6530417 Test Loss: 0.3715528
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.3594432
	speed: 0.0525s/iter; left time: 771.3061s
	iters: 200, epoch: 45 | loss: 0.3263934
	speed: 0.0109s/iter; left time: 159.0372s
Epoch: 45 cost time: 3.396425724029541
Epoch: 45, Steps: 264 | Train Loss: 0.3469187 Vali Loss: 0.6528893 Test Loss: 0.3715854
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.3589887
	speed: 0.0528s/iter; left time: 761.5621s
	iters: 200, epoch: 46 | loss: 0.3380067
	speed: 0.0108s/iter; left time: 155.2640s
Epoch: 46 cost time: 3.500629425048828
Epoch: 46, Steps: 264 | Train Loss: 0.3468500 Vali Loss: 0.6530681 Test Loss: 0.3715853
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.3638402
	speed: 0.0533s/iter; left time: 755.1678s
	iters: 200, epoch: 47 | loss: 0.3551742
	speed: 0.0107s/iter; left time: 150.0876s
Epoch: 47 cost time: 3.3307039737701416
Epoch: 47, Steps: 264 | Train Loss: 0.3468230 Vali Loss: 0.6528087 Test Loss: 0.3715729
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.3444761
	speed: 0.0558s/iter; left time: 775.6096s
	iters: 200, epoch: 48 | loss: 0.3508390
	speed: 0.0117s/iter; left time: 161.4715s
Epoch: 48 cost time: 3.5882301330566406
Epoch: 48, Steps: 264 | Train Loss: 0.3468161 Vali Loss: 0.6525909 Test Loss: 0.3715790
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.3908896
	speed: 0.0584s/iter; left time: 795.9650s
	iters: 200, epoch: 49 | loss: 0.3471541
	speed: 0.0119s/iter; left time: 161.2175s
Epoch: 49 cost time: 3.6219637393951416
Epoch: 49, Steps: 264 | Train Loss: 0.3468708 Vali Loss: 0.6524855 Test Loss: 0.3716066
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_360_336_FITS_ETTm1_ftM_sl360_ll48_pl336_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.37136346101760864, mae:0.38442087173461914, rse:0.5798930525779724, corr:[0.54150367 0.54742694 0.5475668  0.54708844 0.5476247  0.5482803
 0.54829985 0.5481128  0.5483059  0.54887426 0.54962695 0.5501079
 0.5504853  0.5507024  0.55034536 0.54922146 0.54789853 0.54694664
 0.54607224 0.5449543  0.543502   0.5422108  0.5411924  0.54043955
 0.5395594  0.5382888  0.53700304 0.5361036  0.53561836 0.5352681
 0.5351738  0.5354624  0.5360142  0.53660655 0.5369549  0.537108
 0.5369512  0.5365054  0.5360642  0.5358075  0.5356931  0.5355027
 0.53515965 0.53492266 0.53487533 0.53494364 0.53496003 0.53462267
 0.5339903  0.5335292  0.53340214 0.5334597  0.5335101  0.53335243
 0.5330921  0.5329568  0.5329171  0.53288406 0.5328043  0.53254807
 0.53236943 0.53225404 0.53221154 0.5320762  0.53198093 0.5320261
 0.53216034 0.5323241  0.5326853  0.5330597  0.5333285  0.5334509
 0.533564   0.53371775 0.53382456 0.53382444 0.5337606  0.5336723
 0.5335159  0.53325707 0.5329518  0.53269047 0.5325013  0.5323121
 0.5321162  0.531761   0.531344   0.53088325 0.53047734 0.53032297
 0.53041214 0.53058505 0.53070635 0.53075504 0.5305976  0.53017515
 0.52958405 0.52897227 0.528392   0.5277743  0.52726734 0.5270084
 0.5270602  0.52727205 0.5276539  0.52801794 0.528145   0.5282804
 0.52843964 0.52880186 0.52915734 0.5293271  0.5291809  0.5289669
 0.52882874 0.52887684 0.5290073  0.5291318  0.5291931  0.5293778
 0.5295969  0.529622   0.5294285  0.52919376 0.5289498  0.5286963
 0.5284952  0.52835464 0.5281896  0.5280147  0.5278839  0.5278047
 0.5277839  0.52763325 0.5273839  0.5270727  0.5268559  0.5266979
 0.5266043  0.52645147 0.5261876  0.52600914 0.5259924  0.52610934
 0.52618355 0.5261243  0.5259286  0.52576023 0.5257439  0.5256978
 0.52558786 0.52553934 0.525515   0.5255336  0.5255706  0.5255945
 0.5255125  0.5253597  0.52523595 0.52530545 0.5255977  0.5259222
 0.52616143 0.52628636 0.52647805 0.52676797 0.5270292  0.52725726
 0.52740777 0.52758974 0.5279293  0.5284042  0.52873296 0.5287766
 0.52853703 0.5282501  0.52807015 0.52806413 0.52806515 0.52801937
 0.52785313 0.52771103 0.52755225 0.5274455  0.52736896 0.5273092
 0.527236   0.5271819  0.52713525 0.5270619  0.52693105 0.5267232
 0.5263917  0.5260385  0.5256549  0.5251827  0.5246914  0.52430105
 0.5239077  0.5234651  0.5231316  0.5229128  0.5226914  0.5224224
 0.52213246 0.52176654 0.5214982  0.5212447  0.52094096 0.52056575
 0.52008545 0.51969975 0.5193954  0.5191459  0.518765   0.51832986
 0.51792276 0.51760274 0.5173623  0.5172736  0.5171736  0.5170422
 0.517033   0.51713055 0.51728237 0.5173422  0.5172565  0.51696545
 0.5166687  0.5165332  0.51649594 0.51640403 0.5162467  0.51603544
 0.51595175 0.5159992  0.51594335 0.51586926 0.5157203  0.51553494
 0.5153968  0.51534075 0.5153689  0.5153364  0.5151722  0.51501554
 0.5149439  0.51500237 0.5151443  0.5152772  0.5152039  0.51501536
 0.5147217  0.5145648  0.5145171  0.5145407  0.5144968  0.5145388
 0.51459444 0.51471347 0.51490355 0.5151241  0.51526636 0.51549286
 0.5157578  0.51597744 0.51609504 0.51627785 0.51647705 0.5165533
 0.51658595 0.51654994 0.5164384  0.5163687  0.5163164  0.51635724
 0.5163345  0.5162795  0.5160909  0.51599187 0.51596344 0.5159982
 0.516044   0.5159381  0.5157126  0.5154199  0.5151368  0.5147993
 0.51421076 0.5134556  0.512691   0.51189977 0.51141495 0.51123846
 0.5111036  0.5105845  0.50991    0.5093396  0.50916463 0.50918114
 0.50906086 0.5086094  0.5079739  0.5075111  0.50735676 0.5073926
 0.50743    0.5072761  0.5070998  0.50710046 0.5073001  0.50748926
 0.50755024 0.5074084  0.5071222  0.50702566 0.506926   0.5066404
 0.50615716 0.5057055  0.50548106 0.50544965 0.5053024  0.5048468
 0.5042932  0.5040149  0.5040453  0.5042193  0.5041798  0.50405675
 0.50403386 0.5041494  0.50419384 0.50440806 0.5049994  0.50437886]
