Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_180_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_180_336_FITS_ETTm1_ftM_sl180_ll48_pl336_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34045
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=26, out_features=74, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1723904.0
params:  1998.0
Trainable parameters:  1998
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5595785
	speed: 0.0195s/iter; left time: 513.9327s
	iters: 200, epoch: 1 | loss: 0.4300941
	speed: 0.0133s/iter; left time: 350.5254s
Epoch: 1 cost time: 4.157732248306274
Epoch: 1, Steps: 265 | Train Loss: 0.5255885 Vali Loss: 0.9227125 Test Loss: 0.6157933
Validation loss decreased (inf --> 0.922713).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3684425
	speed: 0.0697s/iter; left time: 1820.5097s
	iters: 200, epoch: 2 | loss: 0.2986489
	speed: 0.0145s/iter; left time: 377.5425s
Epoch: 2 cost time: 4.224062204360962
Epoch: 2, Steps: 265 | Train Loss: 0.3350487 Vali Loss: 0.7871723 Test Loss: 0.4903664
Validation loss decreased (0.922713 --> 0.787172).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3328192
	speed: 0.0690s/iter; left time: 1784.5020s
	iters: 200, epoch: 3 | loss: 0.2744614
	speed: 0.0146s/iter; left time: 375.0779s
Epoch: 3 cost time: 4.508123874664307
Epoch: 3, Steps: 265 | Train Loss: 0.2905946 Vali Loss: 0.7380744 Test Loss: 0.4446347
Validation loss decreased (0.787172 --> 0.738074).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2764449
	speed: 0.0713s/iter; left time: 1825.6943s
	iters: 200, epoch: 4 | loss: 0.3000016
	speed: 0.0143s/iter; left time: 363.8480s
Epoch: 4 cost time: 4.274099588394165
Epoch: 4, Steps: 265 | Train Loss: 0.2732019 Vali Loss: 0.7110886 Test Loss: 0.4206250
Validation loss decreased (0.738074 --> 0.711089).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2659013
	speed: 0.0692s/iter; left time: 1752.5193s
	iters: 200, epoch: 5 | loss: 0.2791266
	speed: 0.0135s/iter; left time: 341.8818s
Epoch: 5 cost time: 4.005843162536621
Epoch: 5, Steps: 265 | Train Loss: 0.2643038 Vali Loss: 0.6956804 Test Loss: 0.4067822
Validation loss decreased (0.711089 --> 0.695680).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2621351
	speed: 0.0668s/iter; left time: 1673.9094s
	iters: 200, epoch: 6 | loss: 0.2652838
	speed: 0.0139s/iter; left time: 345.9311s
Epoch: 6 cost time: 4.045894622802734
Epoch: 6, Steps: 265 | Train Loss: 0.2590643 Vali Loss: 0.6865504 Test Loss: 0.3990347
Validation loss decreased (0.695680 --> 0.686550).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2549395
	speed: 0.0712s/iter; left time: 1765.8576s
	iters: 200, epoch: 7 | loss: 0.2480335
	speed: 0.0141s/iter; left time: 347.9088s
Epoch: 7 cost time: 4.3123509883880615
Epoch: 7, Steps: 265 | Train Loss: 0.2562853 Vali Loss: 0.6810513 Test Loss: 0.3944433
Validation loss decreased (0.686550 --> 0.681051).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2371274
	speed: 0.0654s/iter; left time: 1605.1737s
	iters: 200, epoch: 8 | loss: 0.2554474
	speed: 0.0132s/iter; left time: 323.0441s
Epoch: 8 cost time: 3.989699125289917
Epoch: 8, Steps: 265 | Train Loss: 0.2546287 Vali Loss: 0.6770269 Test Loss: 0.3918468
Validation loss decreased (0.681051 --> 0.677027).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2545494
	speed: 0.0692s/iter; left time: 1679.5864s
	iters: 200, epoch: 9 | loss: 0.2616145
	speed: 0.0131s/iter; left time: 315.9331s
Epoch: 9 cost time: 3.98073410987854
Epoch: 9, Steps: 265 | Train Loss: 0.2536059 Vali Loss: 0.6748394 Test Loss: 0.3901858
Validation loss decreased (0.677027 --> 0.674839).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2686460
	speed: 0.0675s/iter; left time: 1622.2513s
	iters: 200, epoch: 10 | loss: 0.2443444
	speed: 0.0134s/iter; left time: 321.4129s
Epoch: 10 cost time: 3.9784021377563477
Epoch: 10, Steps: 265 | Train Loss: 0.2529704 Vali Loss: 0.6742002 Test Loss: 0.3892611
Validation loss decreased (0.674839 --> 0.674200).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2572837
	speed: 0.0679s/iter; left time: 1613.7042s
	iters: 200, epoch: 11 | loss: 0.2561260
	speed: 0.0137s/iter; left time: 323.2782s
Epoch: 11 cost time: 4.188977003097534
Epoch: 11, Steps: 265 | Train Loss: 0.2527834 Vali Loss: 0.6736400 Test Loss: 0.3886301
Validation loss decreased (0.674200 --> 0.673640).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2701445
	speed: 0.0694s/iter; left time: 1630.0876s
	iters: 200, epoch: 12 | loss: 0.2492686
	speed: 0.0131s/iter; left time: 305.4888s
Epoch: 12 cost time: 3.992640733718872
Epoch: 12, Steps: 265 | Train Loss: 0.2526291 Vali Loss: 0.6730036 Test Loss: 0.3883926
Validation loss decreased (0.673640 --> 0.673004).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2719319
	speed: 0.0670s/iter; left time: 1555.8927s
	iters: 200, epoch: 13 | loss: 0.2354257
	speed: 0.0126s/iter; left time: 292.0817s
Epoch: 13 cost time: 3.9645206928253174
Epoch: 13, Steps: 265 | Train Loss: 0.2524347 Vali Loss: 0.6720975 Test Loss: 0.3881419
Validation loss decreased (0.673004 --> 0.672098).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2644014
	speed: 0.0691s/iter; left time: 1586.8053s
	iters: 200, epoch: 14 | loss: 0.2811178
	speed: 0.0129s/iter; left time: 295.4793s
Epoch: 14 cost time: 4.01481556892395
Epoch: 14, Steps: 265 | Train Loss: 0.2523747 Vali Loss: 0.6718842 Test Loss: 0.3881524
Validation loss decreased (0.672098 --> 0.671884).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2762745
	speed: 0.0691s/iter; left time: 1567.6462s
	iters: 200, epoch: 15 | loss: 0.2275357
	speed: 0.0131s/iter; left time: 295.9744s
Epoch: 15 cost time: 4.016709089279175
Epoch: 15, Steps: 265 | Train Loss: 0.2523919 Vali Loss: 0.6727079 Test Loss: 0.3880064
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2618022
	speed: 0.0668s/iter; left time: 1498.3386s
	iters: 200, epoch: 16 | loss: 0.2528754
	speed: 0.0147s/iter; left time: 327.9425s
Epoch: 16 cost time: 4.228706121444702
Epoch: 16, Steps: 265 | Train Loss: 0.2523189 Vali Loss: 0.6725752 Test Loss: 0.3878835
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2501443
	speed: 0.0702s/iter; left time: 1556.1650s
	iters: 200, epoch: 17 | loss: 0.2696266
	speed: 0.0127s/iter; left time: 279.7796s
Epoch: 17 cost time: 4.002330541610718
Epoch: 17, Steps: 265 | Train Loss: 0.2524176 Vali Loss: 0.6716867 Test Loss: 0.3880201
Validation loss decreased (0.671884 --> 0.671687).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2512707
	speed: 0.0672s/iter; left time: 1470.4847s
	iters: 200, epoch: 18 | loss: 0.2407645
	speed: 0.0133s/iter; left time: 290.5419s
Epoch: 18 cost time: 3.9648633003234863
Epoch: 18, Steps: 265 | Train Loss: 0.2523643 Vali Loss: 0.6718996 Test Loss: 0.3878883
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2543096
	speed: 0.0715s/iter; left time: 1545.5586s
	iters: 200, epoch: 19 | loss: 0.2207406
	speed: 0.0136s/iter; left time: 292.0249s
Epoch: 19 cost time: 4.0563836097717285
Epoch: 19, Steps: 265 | Train Loss: 0.2522510 Vali Loss: 0.6723478 Test Loss: 0.3877236
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2548198
	speed: 0.0683s/iter; left time: 1458.4382s
	iters: 200, epoch: 20 | loss: 0.2449070
	speed: 0.0136s/iter; left time: 288.4802s
Epoch: 20 cost time: 4.121079921722412
Epoch: 20, Steps: 265 | Train Loss: 0.2523633 Vali Loss: 0.6722488 Test Loss: 0.3879509
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2635279
	speed: 0.0676s/iter; left time: 1427.3244s
	iters: 200, epoch: 21 | loss: 0.2683538
	speed: 0.0131s/iter; left time: 275.4950s
Epoch: 21 cost time: 3.944540500640869
Epoch: 21, Steps: 265 | Train Loss: 0.2522326 Vali Loss: 0.6724477 Test Loss: 0.3879556
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2511272
	speed: 0.0684s/iter; left time: 1425.7404s
	iters: 200, epoch: 22 | loss: 0.2549620
	speed: 0.0134s/iter; left time: 278.7579s
Epoch: 22 cost time: 4.133204936981201
Epoch: 22, Steps: 265 | Train Loss: 0.2523641 Vali Loss: 0.6720926 Test Loss: 0.3878491
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2543065
	speed: 0.0714s/iter; left time: 1469.1659s
	iters: 200, epoch: 23 | loss: 0.2361836
	speed: 0.0150s/iter; left time: 307.6402s
Epoch: 23 cost time: 4.569953918457031
Epoch: 23, Steps: 265 | Train Loss: 0.2523760 Vali Loss: 0.6723205 Test Loss: 0.3878342
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2454292
	speed: 0.0693s/iter; left time: 1408.2114s
	iters: 200, epoch: 24 | loss: 0.2394603
	speed: 0.0150s/iter; left time: 303.1267s
Epoch: 24 cost time: 4.4118452072143555
Epoch: 24, Steps: 265 | Train Loss: 0.2523191 Vali Loss: 0.6721954 Test Loss: 0.3879840
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2547700
	speed: 0.0702s/iter; left time: 1406.4506s
	iters: 200, epoch: 25 | loss: 0.2727320
	speed: 0.0129s/iter; left time: 257.2839s
Epoch: 25 cost time: 3.988865852355957
Epoch: 25, Steps: 265 | Train Loss: 0.2523561 Vali Loss: 0.6722282 Test Loss: 0.3877662
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2315726
	speed: 0.0670s/iter; left time: 1324.8566s
	iters: 200, epoch: 26 | loss: 0.2316675
	speed: 0.0131s/iter; left time: 258.6272s
Epoch: 26 cost time: 3.946876287460327
Epoch: 26, Steps: 265 | Train Loss: 0.2523318 Vali Loss: 0.6724339 Test Loss: 0.3877732
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2577491
	speed: 0.0690s/iter; left time: 1345.7643s
	iters: 200, epoch: 27 | loss: 0.2558513
	speed: 0.0129s/iter; left time: 250.2382s
Epoch: 27 cost time: 4.02960467338562
Epoch: 27, Steps: 265 | Train Loss: 0.2524081 Vali Loss: 0.6725726 Test Loss: 0.3877774
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2553321
	speed: 0.0694s/iter; left time: 1334.7111s
	iters: 200, epoch: 28 | loss: 0.2402237
	speed: 0.0137s/iter; left time: 262.8915s
Epoch: 28 cost time: 4.109675168991089
Epoch: 28, Steps: 265 | Train Loss: 0.2523701 Vali Loss: 0.6722785 Test Loss: 0.3878735
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2720190
	speed: 0.0653s/iter; left time: 1239.4959s
	iters: 200, epoch: 29 | loss: 0.2831125
	speed: 0.0153s/iter; left time: 288.0370s
Epoch: 29 cost time: 4.393665790557861
Epoch: 29, Steps: 265 | Train Loss: 0.2523207 Vali Loss: 0.6722112 Test Loss: 0.3879013
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2287487
	speed: 0.0711s/iter; left time: 1330.5809s
	iters: 200, epoch: 30 | loss: 0.2559187
	speed: 0.0132s/iter; left time: 246.1758s
Epoch: 30 cost time: 3.9668073654174805
Epoch: 30, Steps: 265 | Train Loss: 0.2522618 Vali Loss: 0.6721735 Test Loss: 0.3878120
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2483385
	speed: 0.0778s/iter; left time: 1435.0015s
	iters: 200, epoch: 31 | loss: 0.2359867
	speed: 0.0216s/iter; left time: 395.8574s
Epoch: 31 cost time: 5.928966522216797
Epoch: 31, Steps: 265 | Train Loss: 0.2522738 Vali Loss: 0.6722664 Test Loss: 0.3877463
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2436414
	speed: 0.0688s/iter; left time: 1250.2955s
	iters: 200, epoch: 32 | loss: 0.2379382
	speed: 0.0130s/iter; left time: 234.3166s
Epoch: 32 cost time: 4.038654327392578
Epoch: 32, Steps: 265 | Train Loss: 0.2523044 Vali Loss: 0.6724197 Test Loss: 0.3878258
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2208840
	speed: 0.0672s/iter; left time: 1204.9069s
	iters: 200, epoch: 33 | loss: 0.2704204
	speed: 0.0128s/iter; left time: 227.2809s
Epoch: 33 cost time: 3.9797158241271973
Epoch: 33, Steps: 265 | Train Loss: 0.2523348 Vali Loss: 0.6726771 Test Loss: 0.3877355
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2460849
	speed: 0.0690s/iter; left time: 1219.0177s
	iters: 200, epoch: 34 | loss: 0.2373978
	speed: 0.0130s/iter; left time: 227.3853s
Epoch: 34 cost time: 4.035441875457764
Epoch: 34, Steps: 265 | Train Loss: 0.2523886 Vali Loss: 0.6727997 Test Loss: 0.3878411
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2283191
	speed: 0.0680s/iter; left time: 1182.7600s
	iters: 200, epoch: 35 | loss: 0.2590880
	speed: 0.0132s/iter; left time: 228.1205s
Epoch: 35 cost time: 4.0564398765563965
Epoch: 35, Steps: 265 | Train Loss: 0.2523487 Vali Loss: 0.6726792 Test Loss: 0.3878873
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2659827
	speed: 0.0710s/iter; left time: 1216.6032s
	iters: 200, epoch: 36 | loss: 0.2328623
	speed: 0.0146s/iter; left time: 247.9656s
Epoch: 36 cost time: 4.387793302536011
Epoch: 36, Steps: 265 | Train Loss: 0.2522427 Vali Loss: 0.6722155 Test Loss: 0.3877735
EarlyStopping counter: 19 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2432412
	speed: 0.0684s/iter; left time: 1152.5963s
	iters: 200, epoch: 37 | loss: 0.2371507
	speed: 0.0143s/iter; left time: 240.2254s
Epoch: 37 cost time: 4.120142221450806
Epoch: 37, Steps: 265 | Train Loss: 0.2523554 Vali Loss: 0.6723585 Test Loss: 0.3878084
EarlyStopping counter: 20 out of 20
Early stopping
train 34045
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=26, out_features=74, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1723904.0
params:  1998.0
Trainable parameters:  1998
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3725649
	speed: 0.0179s/iter; left time: 473.3578s
	iters: 200, epoch: 1 | loss: 0.3659731
	speed: 0.0135s/iter; left time: 356.1388s
Epoch: 1 cost time: 4.023828506469727
Epoch: 1, Steps: 265 | Train Loss: 0.3753240 Vali Loss: 0.6675486 Test Loss: 0.3848685
Validation loss decreased (inf --> 0.667549).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3857398
	speed: 0.0683s/iter; left time: 1784.1242s
	iters: 200, epoch: 2 | loss: 0.3649755
	speed: 0.0136s/iter; left time: 353.4991s
Epoch: 2 cost time: 4.095440864562988
Epoch: 2, Steps: 265 | Train Loss: 0.3745483 Vali Loss: 0.6672596 Test Loss: 0.3843882
Validation loss decreased (0.667549 --> 0.667260).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3749359
	speed: 0.0683s/iter; left time: 1766.8295s
	iters: 200, epoch: 3 | loss: 0.3980181
	speed: 0.0134s/iter; left time: 346.6122s
Epoch: 3 cost time: 4.155542850494385
Epoch: 3, Steps: 265 | Train Loss: 0.3741309 Vali Loss: 0.6674045 Test Loss: 0.3839298
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3558601
	speed: 0.0693s/iter; left time: 1775.4978s
	iters: 200, epoch: 4 | loss: 0.3727717
	speed: 0.0135s/iter; left time: 345.5747s
Epoch: 4 cost time: 4.075189113616943
Epoch: 4, Steps: 265 | Train Loss: 0.3742025 Vali Loss: 0.6662633 Test Loss: 0.3840396
Validation loss decreased (0.667260 --> 0.666263).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3473420
	speed: 0.0701s/iter; left time: 1776.3683s
	iters: 200, epoch: 5 | loss: 0.3534564
	speed: 0.0218s/iter; left time: 549.8842s
Epoch: 5 cost time: 5.734715700149536
Epoch: 5, Steps: 265 | Train Loss: 0.3741844 Vali Loss: 0.6665807 Test Loss: 0.3839251
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3231011
	speed: 0.1023s/iter; left time: 2565.6558s
	iters: 200, epoch: 6 | loss: 0.3441932
	speed: 0.0172s/iter; left time: 429.1453s
Epoch: 6 cost time: 7.107200622558594
Epoch: 6, Steps: 265 | Train Loss: 0.3741304 Vali Loss: 0.6663469 Test Loss: 0.3844549
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3171460
	speed: 0.0691s/iter; left time: 1714.3072s
	iters: 200, epoch: 7 | loss: 0.4108391
	speed: 0.0134s/iter; left time: 331.8426s
Epoch: 7 cost time: 3.9173386096954346
Epoch: 7, Steps: 265 | Train Loss: 0.3741520 Vali Loss: 0.6665806 Test Loss: 0.3841194
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3475983
	speed: 0.0679s/iter; left time: 1667.2217s
	iters: 200, epoch: 8 | loss: 0.4362016
	speed: 0.0133s/iter; left time: 325.3074s
Epoch: 8 cost time: 4.016591548919678
Epoch: 8, Steps: 265 | Train Loss: 0.3740432 Vali Loss: 0.6663128 Test Loss: 0.3840345
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3632563
	speed: 0.0680s/iter; left time: 1651.8140s
	iters: 200, epoch: 9 | loss: 0.3504113
	speed: 0.0130s/iter; left time: 314.5530s
Epoch: 9 cost time: 3.9177114963531494
Epoch: 9, Steps: 265 | Train Loss: 0.3741789 Vali Loss: 0.6666483 Test Loss: 0.3840942
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3438451
	speed: 0.0670s/iter; left time: 1609.8592s
	iters: 200, epoch: 10 | loss: 0.4017390
	speed: 0.0130s/iter; left time: 311.9631s
Epoch: 10 cost time: 3.9844226837158203
Epoch: 10, Steps: 265 | Train Loss: 0.3740966 Vali Loss: 0.6663309 Test Loss: 0.3841159
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3228016
	speed: 0.0679s/iter; left time: 1613.5995s
	iters: 200, epoch: 11 | loss: 0.3534140
	speed: 0.0133s/iter; left time: 315.5628s
Epoch: 11 cost time: 4.041544675827026
Epoch: 11, Steps: 265 | Train Loss: 0.3741364 Vali Loss: 0.6659514 Test Loss: 0.3837966
Validation loss decreased (0.666263 --> 0.665951).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3420408
	speed: 0.0662s/iter; left time: 1555.6313s
	iters: 200, epoch: 12 | loss: 0.3675927
	speed: 0.0132s/iter; left time: 309.5528s
Epoch: 12 cost time: 4.093412637710571
Epoch: 12, Steps: 265 | Train Loss: 0.3739771 Vali Loss: 0.6668402 Test Loss: 0.3841084
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3383410
	speed: 0.0687s/iter; left time: 1595.8335s
	iters: 200, epoch: 13 | loss: 0.3460580
	speed: 0.0138s/iter; left time: 317.9659s
Epoch: 13 cost time: 4.1219611167907715
Epoch: 13, Steps: 265 | Train Loss: 0.3739183 Vali Loss: 0.6660389 Test Loss: 0.3840515
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3594321
	speed: 0.0703s/iter; left time: 1614.2659s
	iters: 200, epoch: 14 | loss: 0.3468350
	speed: 0.0131s/iter; left time: 299.5926s
Epoch: 14 cost time: 4.079232692718506
Epoch: 14, Steps: 265 | Train Loss: 0.3738502 Vali Loss: 0.6661867 Test Loss: 0.3840641
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3529453
	speed: 0.0691s/iter; left time: 1568.3499s
	iters: 200, epoch: 15 | loss: 0.3670162
	speed: 0.0131s/iter; left time: 295.9182s
Epoch: 15 cost time: 4.050225496292114
Epoch: 15, Steps: 265 | Train Loss: 0.3740201 Vali Loss: 0.6663691 Test Loss: 0.3840573
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3771630
	speed: 0.0675s/iter; left time: 1514.3119s
	iters: 200, epoch: 16 | loss: 0.4117615
	speed: 0.0128s/iter; left time: 285.8657s
Epoch: 16 cost time: 3.9617083072662354
Epoch: 16, Steps: 265 | Train Loss: 0.3738869 Vali Loss: 0.6667943 Test Loss: 0.3842074
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3756439
	speed: 0.0680s/iter; left time: 1507.3013s
	iters: 200, epoch: 17 | loss: 0.3681393
	speed: 0.0132s/iter; left time: 290.3981s
Epoch: 17 cost time: 3.9482593536376953
Epoch: 17, Steps: 265 | Train Loss: 0.3736713 Vali Loss: 0.6653535 Test Loss: 0.3840510
Validation loss decreased (0.665951 --> 0.665353).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3943283
	speed: 0.0764s/iter; left time: 1672.1541s
	iters: 200, epoch: 18 | loss: 0.3831384
	speed: 0.0141s/iter; left time: 307.0283s
Epoch: 18 cost time: 5.074398756027222
Epoch: 18, Steps: 265 | Train Loss: 0.3738291 Vali Loss: 0.6654316 Test Loss: 0.3840805
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3768924
	speed: 0.0737s/iter; left time: 1595.2206s
	iters: 200, epoch: 19 | loss: 0.3253305
	speed: 0.0154s/iter; left time: 332.1712s
Epoch: 19 cost time: 4.533807992935181
Epoch: 19, Steps: 265 | Train Loss: 0.3738411 Vali Loss: 0.6666249 Test Loss: 0.3840395
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3668262
	speed: 0.0725s/iter; left time: 1548.7196s
	iters: 200, epoch: 20 | loss: 0.3642190
	speed: 0.0140s/iter; left time: 297.1525s
Epoch: 20 cost time: 4.205219030380249
Epoch: 20, Steps: 265 | Train Loss: 0.3737803 Vali Loss: 0.6665755 Test Loss: 0.3841532
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4174441
	speed: 0.0665s/iter; left time: 1403.5026s
	iters: 200, epoch: 21 | loss: 0.3797994
	speed: 0.0130s/iter; left time: 272.4555s
Epoch: 21 cost time: 3.9433844089508057
Epoch: 21, Steps: 265 | Train Loss: 0.3739593 Vali Loss: 0.6661119 Test Loss: 0.3840813
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3562091
	speed: 0.0674s/iter; left time: 1405.1296s
	iters: 200, epoch: 22 | loss: 0.3440889
	speed: 0.0129s/iter; left time: 267.9011s
Epoch: 22 cost time: 3.9354441165924072
Epoch: 22, Steps: 265 | Train Loss: 0.3737827 Vali Loss: 0.6661414 Test Loss: 0.3839661
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3643127
	speed: 0.0664s/iter; left time: 1366.7737s
	iters: 200, epoch: 23 | loss: 0.3285858
	speed: 0.0129s/iter; left time: 263.5228s
Epoch: 23 cost time: 3.8506698608398438
Epoch: 23, Steps: 265 | Train Loss: 0.3739209 Vali Loss: 0.6661332 Test Loss: 0.3839007
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3752397
	speed: 0.0678s/iter; left time: 1375.8048s
	iters: 200, epoch: 24 | loss: 0.3616666
	speed: 0.0175s/iter; left time: 353.3436s
Epoch: 24 cost time: 4.54327130317688
Epoch: 24, Steps: 265 | Train Loss: 0.3737270 Vali Loss: 0.6659926 Test Loss: 0.3839931
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3011724
	speed: 0.0689s/iter; left time: 1380.3682s
	iters: 200, epoch: 25 | loss: 0.3737973
	speed: 0.0131s/iter; left time: 260.7150s
Epoch: 25 cost time: 3.973590850830078
Epoch: 25, Steps: 265 | Train Loss: 0.3738028 Vali Loss: 0.6663488 Test Loss: 0.3840364
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3653146
	speed: 0.0783s/iter; left time: 1547.9364s
	iters: 200, epoch: 26 | loss: 0.4219379
	speed: 0.0133s/iter; left time: 260.9756s
Epoch: 26 cost time: 4.976110219955444
Epoch: 26, Steps: 265 | Train Loss: 0.3739067 Vali Loss: 0.6662681 Test Loss: 0.3841456
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3823451
	speed: 0.0679s/iter; left time: 1325.3803s
	iters: 200, epoch: 27 | loss: 0.3776701
	speed: 0.0347s/iter; left time: 673.5003s
Epoch: 27 cost time: 8.295843839645386
Epoch: 27, Steps: 265 | Train Loss: 0.3738741 Vali Loss: 0.6665022 Test Loss: 0.3839842
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3206728
	speed: 0.0958s/iter; left time: 1843.3760s
	iters: 200, epoch: 28 | loss: 0.3491639
	speed: 0.0150s/iter; left time: 287.1025s
Epoch: 28 cost time: 4.271319627761841
Epoch: 28, Steps: 265 | Train Loss: 0.3738596 Vali Loss: 0.6664206 Test Loss: 0.3840037
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4049329
	speed: 0.0702s/iter; left time: 1332.6846s
	iters: 200, epoch: 29 | loss: 0.3358567
	speed: 0.0133s/iter; left time: 250.4589s
Epoch: 29 cost time: 4.214867830276489
Epoch: 29, Steps: 265 | Train Loss: 0.3738312 Vali Loss: 0.6662037 Test Loss: 0.3840421
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3592043
	speed: 0.0668s/iter; left time: 1249.6102s
	iters: 200, epoch: 30 | loss: 0.3852085
	speed: 0.0130s/iter; left time: 242.5238s
Epoch: 30 cost time: 3.941016912460327
Epoch: 30, Steps: 265 | Train Loss: 0.3738390 Vali Loss: 0.6666636 Test Loss: 0.3839720
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3384580
	speed: 0.0667s/iter; left time: 1231.0261s
	iters: 200, epoch: 31 | loss: 0.3604036
	speed: 0.0131s/iter; left time: 240.4019s
Epoch: 31 cost time: 3.9497673511505127
Epoch: 31, Steps: 265 | Train Loss: 0.3737818 Vali Loss: 0.6660662 Test Loss: 0.3841057
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3797812
	speed: 0.0660s/iter; left time: 1200.7038s
	iters: 200, epoch: 32 | loss: 0.3798237
	speed: 0.0127s/iter; left time: 229.1570s
Epoch: 32 cost time: 3.890263795852661
Epoch: 32, Steps: 265 | Train Loss: 0.3736907 Vali Loss: 0.6661043 Test Loss: 0.3840247
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3834918
	speed: 0.0690s/iter; left time: 1236.5694s
	iters: 200, epoch: 33 | loss: 0.3866240
	speed: 0.0130s/iter; left time: 232.3362s
Epoch: 33 cost time: 3.987379312515259
Epoch: 33, Steps: 265 | Train Loss: 0.3738050 Vali Loss: 0.6659983 Test Loss: 0.3839844
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3550559
	speed: 0.0672s/iter; left time: 1185.9786s
	iters: 200, epoch: 34 | loss: 0.3685155
	speed: 0.0130s/iter; left time: 228.3423s
Epoch: 34 cost time: 4.01611590385437
Epoch: 34, Steps: 265 | Train Loss: 0.3737788 Vali Loss: 0.6661052 Test Loss: 0.3840151
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3689690
	speed: 0.0676s/iter; left time: 1175.3271s
	iters: 200, epoch: 35 | loss: 0.3617326
	speed: 0.0133s/iter; left time: 230.7543s
Epoch: 35 cost time: 3.9347259998321533
Epoch: 35, Steps: 265 | Train Loss: 0.3737813 Vali Loss: 0.6663001 Test Loss: 0.3840370
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3726470
	speed: 0.0687s/iter; left time: 1176.8075s
	iters: 200, epoch: 36 | loss: 0.4087268
	speed: 0.0131s/iter; left time: 223.2244s
Epoch: 36 cost time: 4.048905611038208
Epoch: 36, Steps: 265 | Train Loss: 0.3738187 Vali Loss: 0.6655316 Test Loss: 0.3840059
EarlyStopping counter: 19 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3408704
	speed: 0.0676s/iter; left time: 1139.8091s
	iters: 200, epoch: 37 | loss: 0.3765858
	speed: 0.0133s/iter; left time: 222.1266s
Epoch: 37 cost time: 3.9702112674713135
Epoch: 37, Steps: 265 | Train Loss: 0.3738921 Vali Loss: 0.6659507 Test Loss: 0.3840316
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_180_336_FITS_ETTm1_ftM_sl180_ll48_pl336_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.38405099511146545, mae:0.3901565372943878, rse:0.589715838432312, corr:[0.54360807 0.54858893 0.54762524 0.54464775 0.542825   0.54286325
 0.54362065 0.5441593  0.54392254 0.5435842  0.5437913  0.5439831
 0.5436236  0.5421532  0.5400125  0.5378605  0.5358505  0.5339791
 0.5321459  0.5302618  0.5283272  0.52630883 0.5241875  0.5219865
 0.5196824  0.5174068  0.51546586 0.5139509  0.51295143 0.51247895
 0.51266474 0.5132502  0.5137794  0.5140164  0.5138617  0.51353395
 0.51316255 0.51284826 0.5127391  0.5126453  0.5125374  0.5122732
 0.5119233  0.51169926 0.5116619  0.51181275 0.51210076 0.5123679
 0.51249945 0.51242155 0.5122907  0.51226646 0.5124326  0.5127057
 0.51297057 0.51308733 0.5131048  0.5129425  0.5127074  0.51243246
 0.51224273 0.5121604  0.5120782  0.5119337  0.51173943 0.5116934
 0.51180685 0.5120209  0.51236963 0.5127564  0.5130899  0.5132821
 0.5133199  0.51324207 0.5132258  0.51322544 0.5132723  0.5132942
 0.51323813 0.5130926  0.5129632  0.51288414 0.5128619  0.5127547
 0.51254356 0.51232266 0.51214105 0.5119072  0.51158303 0.5113357
 0.51118433 0.5111112  0.5110222  0.5108212  0.5103546  0.5095111
 0.5084339  0.50740963 0.50661504 0.5060525  0.50576127 0.50572765
 0.50585854 0.5061239  0.5066419  0.50751346 0.5086963  0.50996906
 0.5110153  0.5116089  0.511773   0.5118271  0.51184183 0.5118765
 0.5118524  0.51176816 0.5114837  0.5109727  0.51041013 0.5099298
 0.50965565 0.50941235 0.50905114 0.50859016 0.50798845 0.5073163
 0.5068107  0.5066419  0.50677586 0.5070397  0.507183   0.50701016
 0.5065318  0.50601494 0.5056081  0.50533    0.5052903  0.50532776
 0.50529623 0.5052337  0.5051279  0.5050442  0.5050387  0.50512946
 0.5052375  0.50530696 0.5051998  0.5050375  0.5050434  0.5050585
 0.50509477 0.5051524  0.50514644 0.505071   0.5048283  0.5045722
 0.5043982  0.50439966 0.5045044  0.50471646 0.50493896 0.5051212
 0.5052371  0.5052854  0.5052615  0.5053267  0.50548637 0.5057419
 0.50609726 0.50642145 0.5065957  0.50671476 0.5067162  0.50659615
 0.50645787 0.50635326 0.5063521  0.5064472  0.50647086 0.50639576
 0.50620717 0.50599426 0.50585    0.5058526  0.505964   0.50604916
 0.5060186  0.5059109  0.505897   0.5061254  0.50654274 0.506919
 0.5069605  0.5066709  0.50614136 0.50541013 0.5047295  0.5043179
 0.5041412  0.5040088  0.5038477  0.5038959  0.5039797  0.5039739
 0.5038103  0.50329536 0.5026557  0.5021811  0.5018917  0.5016851
 0.50138825 0.5009289  0.5002641  0.49940997 0.4984796  0.49761453
 0.49681515 0.4959919  0.4951945  0.49454552 0.49409366 0.4938694
 0.4938299  0.4939176  0.4939686  0.49396768 0.49395785 0.49387774
 0.49368197 0.49349812 0.49327433 0.4929987  0.49274015 0.49257046
 0.49250793 0.49254492 0.4925017  0.492486   0.4925324  0.49260876
 0.49281535 0.4929843  0.49311733 0.49313694 0.49308744 0.49303892
 0.49306774 0.49313867 0.49328387 0.49346012 0.49356177 0.49352702
 0.49339366 0.49331683 0.49325618 0.4932604  0.49326545 0.49324957
 0.49330726 0.49344516 0.49363756 0.49388972 0.4941679  0.4944885
 0.49484253 0.49506164 0.49515617 0.49519002 0.49524474 0.4952971
 0.49542898 0.4955903  0.4958127  0.4960193  0.49617535 0.49622607
 0.4962073  0.4962609  0.49637672 0.49651745 0.4966436  0.49668264
 0.49664065 0.49649492 0.496305   0.49607536 0.4957175  0.4951578
 0.49430144 0.49336037 0.49259394 0.49202904 0.491717   0.4915515
 0.49152383 0.4914642  0.49149004 0.4917096  0.4921408  0.49272218
 0.49320734 0.49329844 0.49310824 0.49282244 0.49257457 0.4924099
 0.49238917 0.49242526 0.4923636  0.49211803 0.4916688  0.49105528
 0.49037284 0.48973686 0.4893546  0.48930472 0.48925313 0.48910645
 0.4887873  0.48825762 0.48772907 0.4874576  0.4873257  0.4871952
 0.48687503 0.48634917 0.4857684  0.48541227 0.48535827 0.48545328
 0.48537004 0.4849422  0.48445666 0.48472986 0.4862711  0.4881731 ]
