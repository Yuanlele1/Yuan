Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=20, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_90_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_90_192_FITS_ETTm1_ftM_sl90_ll48_pl192_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34279
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=20, out_features=62, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1111040.0
params:  1302.0
Trainable parameters:  1302
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5219463
	speed: 0.0169s/iter; left time: 448.6365s
	iters: 200, epoch: 1 | loss: 0.4570454
	speed: 0.0109s/iter; left time: 287.9297s
Epoch: 1 cost time: 3.4791259765625
Epoch: 1, Steps: 267 | Train Loss: 0.5461746 Vali Loss: 0.6739144 Test Loss: 0.5189711
Validation loss decreased (inf --> 0.673914).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4242891
	speed: 0.0586s/iter; left time: 1542.8237s
	iters: 200, epoch: 2 | loss: 0.4113151
	speed: 0.0100s/iter; left time: 262.2245s
Epoch: 2 cost time: 3.2583017349243164
Epoch: 2, Steps: 267 | Train Loss: 0.4008911 Vali Loss: 0.5797545 Test Loss: 0.4282965
Validation loss decreased (0.673914 --> 0.579754).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3947776
	speed: 0.0574s/iter; left time: 1496.1012s
	iters: 200, epoch: 3 | loss: 0.3823195
	speed: 0.0104s/iter; left time: 271.1775s
Epoch: 3 cost time: 3.233232021331787
Epoch: 3, Steps: 267 | Train Loss: 0.3812961 Vali Loss: 0.5572930 Test Loss: 0.4078679
Validation loss decreased (0.579754 --> 0.557293).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3705750
	speed: 0.0589s/iter; left time: 1518.8893s
	iters: 200, epoch: 4 | loss: 0.3755656
	speed: 0.0099s/iter; left time: 255.1210s
Epoch: 4 cost time: 3.160806655883789
Epoch: 4, Steps: 267 | Train Loss: 0.3769391 Vali Loss: 0.5487915 Test Loss: 0.4012807
Validation loss decreased (0.557293 --> 0.548792).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3736759
	speed: 0.0572s/iter; left time: 1460.2823s
	iters: 200, epoch: 5 | loss: 0.4277518
	speed: 0.0100s/iter; left time: 255.2063s
Epoch: 5 cost time: 3.1970136165618896
Epoch: 5, Steps: 267 | Train Loss: 0.3754744 Vali Loss: 0.5466741 Test Loss: 0.3999308
Validation loss decreased (0.548792 --> 0.546674).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3520162
	speed: 0.0573s/iter; left time: 1446.8357s
	iters: 200, epoch: 6 | loss: 0.4048834
	speed: 0.0101s/iter; left time: 254.6675s
Epoch: 6 cost time: 3.2159337997436523
Epoch: 6, Steps: 267 | Train Loss: 0.3750240 Vali Loss: 0.5456978 Test Loss: 0.3998091
Validation loss decreased (0.546674 --> 0.545698).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3605330
	speed: 0.0574s/iter; left time: 1433.8071s
	iters: 200, epoch: 7 | loss: 0.3751648
	speed: 0.0100s/iter; left time: 250.0682s
Epoch: 7 cost time: 3.2072231769561768
Epoch: 7, Steps: 267 | Train Loss: 0.3748200 Vali Loss: 0.5457318 Test Loss: 0.3990973
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3640026
	speed: 0.0606s/iter; left time: 1499.9330s
	iters: 200, epoch: 8 | loss: 0.3710904
	speed: 0.0100s/iter; left time: 246.3543s
Epoch: 8 cost time: 3.287343978881836
Epoch: 8, Steps: 267 | Train Loss: 0.3747078 Vali Loss: 0.5454096 Test Loss: 0.3987545
Validation loss decreased (0.545698 --> 0.545410).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3614662
	speed: 0.0585s/iter; left time: 1430.1597s
	iters: 200, epoch: 9 | loss: 0.3338558
	speed: 0.0102s/iter; left time: 247.5851s
Epoch: 9 cost time: 3.321927547454834
Epoch: 9, Steps: 267 | Train Loss: 0.3745507 Vali Loss: 0.5448736 Test Loss: 0.3985302
Validation loss decreased (0.545410 --> 0.544874).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3390413
	speed: 0.0572s/iter; left time: 1384.3174s
	iters: 200, epoch: 10 | loss: 0.3547150
	speed: 0.0311s/iter; left time: 750.0104s
Epoch: 10 cost time: 5.229254961013794
Epoch: 10, Steps: 267 | Train Loss: 0.3744611 Vali Loss: 0.5445448 Test Loss: 0.3986276
Validation loss decreased (0.544874 --> 0.544545).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3688791
	speed: 0.0584s/iter; left time: 1398.4755s
	iters: 200, epoch: 11 | loss: 0.3508742
	speed: 0.0099s/iter; left time: 236.3768s
Epoch: 11 cost time: 3.2717583179473877
Epoch: 11, Steps: 267 | Train Loss: 0.3741931 Vali Loss: 0.5455621 Test Loss: 0.3990594
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3907530
	speed: 0.0578s/iter; left time: 1367.8029s
	iters: 200, epoch: 12 | loss: 0.3754493
	speed: 0.0100s/iter; left time: 234.5082s
Epoch: 12 cost time: 3.204677104949951
Epoch: 12, Steps: 267 | Train Loss: 0.3744320 Vali Loss: 0.5443563 Test Loss: 0.3990232
Validation loss decreased (0.544545 --> 0.544356).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3590857
	speed: 0.0574s/iter; left time: 1343.5788s
	iters: 200, epoch: 13 | loss: 0.3859404
	speed: 0.0098s/iter; left time: 229.1812s
Epoch: 13 cost time: 3.167941093444824
Epoch: 13, Steps: 267 | Train Loss: 0.3742996 Vali Loss: 0.5443782 Test Loss: 0.3988001
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3696152
	speed: 0.0580s/iter; left time: 1342.2687s
	iters: 200, epoch: 14 | loss: 0.3437457
	speed: 0.0100s/iter; left time: 230.8654s
Epoch: 14 cost time: 3.1646811962127686
Epoch: 14, Steps: 267 | Train Loss: 0.3740294 Vali Loss: 0.5444794 Test Loss: 0.3988026
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3593354
	speed: 0.0582s/iter; left time: 1329.9132s
	iters: 200, epoch: 15 | loss: 0.3709909
	speed: 0.0101s/iter; left time: 229.8979s
Epoch: 15 cost time: 3.2623116970062256
Epoch: 15, Steps: 267 | Train Loss: 0.3743588 Vali Loss: 0.5452138 Test Loss: 0.3991457
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3521594
	speed: 0.0582s/iter; left time: 1315.8148s
	iters: 200, epoch: 16 | loss: 0.3694195
	speed: 0.0100s/iter; left time: 223.9013s
Epoch: 16 cost time: 3.2186460494995117
Epoch: 16, Steps: 267 | Train Loss: 0.3743486 Vali Loss: 0.5454705 Test Loss: 0.3990811
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3569445
	speed: 0.0586s/iter; left time: 1308.5931s
	iters: 200, epoch: 17 | loss: 0.3769307
	speed: 0.0100s/iter; left time: 222.8738s
Epoch: 17 cost time: 3.2520651817321777
Epoch: 17, Steps: 267 | Train Loss: 0.3742236 Vali Loss: 0.5443739 Test Loss: 0.3988898
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4094390
	speed: 0.0572s/iter; left time: 1262.4259s
	iters: 200, epoch: 18 | loss: 0.3888664
	speed: 0.0099s/iter; left time: 218.0494s
Epoch: 18 cost time: 3.1681392192840576
Epoch: 18, Steps: 267 | Train Loss: 0.3741550 Vali Loss: 0.5438898 Test Loss: 0.3987091
Validation loss decreased (0.544356 --> 0.543890).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3446823
	speed: 0.0581s/iter; left time: 1267.0857s
	iters: 200, epoch: 19 | loss: 0.3524988
	speed: 0.0101s/iter; left time: 218.7796s
Epoch: 19 cost time: 3.3067476749420166
Epoch: 19, Steps: 267 | Train Loss: 0.3741474 Vali Loss: 0.5445170 Test Loss: 0.3986725
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3653339
	speed: 0.0574s/iter; left time: 1234.9581s
	iters: 200, epoch: 20 | loss: 0.3674060
	speed: 0.0106s/iter; left time: 228.0747s
Epoch: 20 cost time: 3.229142665863037
Epoch: 20, Steps: 267 | Train Loss: 0.3741537 Vali Loss: 0.5449438 Test Loss: 0.3988644
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3935246
	speed: 0.0582s/iter; left time: 1237.9216s
	iters: 200, epoch: 21 | loss: 0.3666756
	speed: 0.0099s/iter; left time: 209.3558s
Epoch: 21 cost time: 3.270167112350464
Epoch: 21, Steps: 267 | Train Loss: 0.3740692 Vali Loss: 0.5451372 Test Loss: 0.3990561
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4029754
	speed: 0.0560s/iter; left time: 1176.3273s
	iters: 200, epoch: 22 | loss: 0.3894961
	speed: 0.0099s/iter; left time: 207.0146s
Epoch: 22 cost time: 3.150299549102783
Epoch: 22, Steps: 267 | Train Loss: 0.3741669 Vali Loss: 0.5444155 Test Loss: 0.3988665
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3753964
	speed: 0.0567s/iter; left time: 1174.2461s
	iters: 200, epoch: 23 | loss: 0.4304434
	speed: 0.0100s/iter; left time: 206.2829s
Epoch: 23 cost time: 3.257009744644165
Epoch: 23, Steps: 267 | Train Loss: 0.3741562 Vali Loss: 0.5445978 Test Loss: 0.3986380
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3691886
	speed: 0.0583s/iter; left time: 1192.7170s
	iters: 200, epoch: 24 | loss: 0.3590004
	speed: 0.0100s/iter; left time: 203.1585s
Epoch: 24 cost time: 3.25374698638916
Epoch: 24, Steps: 267 | Train Loss: 0.3740844 Vali Loss: 0.5445502 Test Loss: 0.3991888
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4026462
	speed: 0.0582s/iter; left time: 1175.0944s
	iters: 200, epoch: 25 | loss: 0.3716277
	speed: 0.0100s/iter; left time: 200.9220s
Epoch: 25 cost time: 3.284897804260254
Epoch: 25, Steps: 267 | Train Loss: 0.3740926 Vali Loss: 0.5454469 Test Loss: 0.3988278
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3638046
	speed: 0.0660s/iter; left time: 1314.6928s
	iters: 200, epoch: 26 | loss: 0.4203738
	speed: 0.0102s/iter; left time: 201.3269s
Epoch: 26 cost time: 3.3674817085266113
Epoch: 26, Steps: 267 | Train Loss: 0.3742429 Vali Loss: 0.5447437 Test Loss: 0.3989123
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3704771
	speed: 0.0579s/iter; left time: 1139.2258s
	iters: 200, epoch: 27 | loss: 0.4007590
	speed: 0.0099s/iter; left time: 193.6561s
Epoch: 27 cost time: 3.142585515975952
Epoch: 27, Steps: 267 | Train Loss: 0.3741084 Vali Loss: 0.5444596 Test Loss: 0.3989214
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3788358
	speed: 0.0578s/iter; left time: 1120.9181s
	iters: 200, epoch: 28 | loss: 0.3518891
	speed: 0.0099s/iter; left time: 191.5720s
Epoch: 28 cost time: 3.247936248779297
Epoch: 28, Steps: 267 | Train Loss: 0.3739904 Vali Loss: 0.5447748 Test Loss: 0.3988587
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3151069
	speed: 0.0589s/iter; left time: 1127.3569s
	iters: 200, epoch: 29 | loss: 0.3469789
	speed: 0.0100s/iter; left time: 189.5923s
Epoch: 29 cost time: 3.1471452713012695
Epoch: 29, Steps: 267 | Train Loss: 0.3740195 Vali Loss: 0.5442442 Test Loss: 0.3990169
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3620460
	speed: 0.0613s/iter; left time: 1156.2985s
	iters: 200, epoch: 30 | loss: 0.3522590
	speed: 0.0101s/iter; left time: 188.6525s
Epoch: 30 cost time: 3.2779436111450195
Epoch: 30, Steps: 267 | Train Loss: 0.3740492 Vali Loss: 0.5446125 Test Loss: 0.3989497
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3379453
	speed: 0.0588s/iter; left time: 1093.8326s
	iters: 200, epoch: 31 | loss: 0.4286554
	speed: 0.0100s/iter; left time: 185.3392s
Epoch: 31 cost time: 3.292973041534424
Epoch: 31, Steps: 267 | Train Loss: 0.3740748 Vali Loss: 0.5452369 Test Loss: 0.3988890
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3687393
	speed: 0.0587s/iter; left time: 1075.4800s
	iters: 200, epoch: 32 | loss: 0.3808504
	speed: 0.0100s/iter; left time: 182.8704s
Epoch: 32 cost time: 3.2396388053894043
Epoch: 32, Steps: 267 | Train Loss: 0.3740169 Vali Loss: 0.5449779 Test Loss: 0.3989565
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3482813
	speed: 0.0589s/iter; left time: 1063.2356s
	iters: 200, epoch: 33 | loss: 0.3535621
	speed: 0.0100s/iter; left time: 179.5591s
Epoch: 33 cost time: 3.272569417953491
Epoch: 33, Steps: 267 | Train Loss: 0.3741465 Vali Loss: 0.5449121 Test Loss: 0.3989353
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3601710
	speed: 0.0590s/iter; left time: 1049.4315s
	iters: 200, epoch: 34 | loss: 0.3719948
	speed: 0.0100s/iter; left time: 176.6111s
Epoch: 34 cost time: 3.2399206161499023
Epoch: 34, Steps: 267 | Train Loss: 0.3740654 Vali Loss: 0.5448103 Test Loss: 0.3989731
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3929562
	speed: 0.0581s/iter; left time: 1018.4323s
	iters: 200, epoch: 35 | loss: 0.3667897
	speed: 0.0100s/iter; left time: 174.6856s
Epoch: 35 cost time: 3.223396062850952
Epoch: 35, Steps: 267 | Train Loss: 0.3741128 Vali Loss: 0.5445223 Test Loss: 0.3988940
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3770725
	speed: 0.0574s/iter; left time: 991.1893s
	iters: 200, epoch: 36 | loss: 0.4150079
	speed: 0.0099s/iter; left time: 169.5075s
Epoch: 36 cost time: 3.1818368434906006
Epoch: 36, Steps: 267 | Train Loss: 0.3739127 Vali Loss: 0.5445268 Test Loss: 0.3990069
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3732305
	speed: 0.0574s/iter; left time: 975.9732s
	iters: 200, epoch: 37 | loss: 0.3893699
	speed: 0.0100s/iter; left time: 168.5495s
Epoch: 37 cost time: 3.257124662399292
Epoch: 37, Steps: 267 | Train Loss: 0.3740151 Vali Loss: 0.5442763 Test Loss: 0.3989455
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3673356
	speed: 0.0583s/iter; left time: 974.5310s
	iters: 200, epoch: 38 | loss: 0.3808907
	speed: 0.0101s/iter; left time: 167.1688s
Epoch: 38 cost time: 3.2727744579315186
Epoch: 38, Steps: 267 | Train Loss: 0.3741389 Vali Loss: 0.5447471 Test Loss: 0.3989398
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_90_192_FITS_ETTm1_ftM_sl90_ll48_pl192_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.39969125390052795, mae:0.39777109026908875, rse:0.6018161773681641, corr:[0.5508872  0.5510559  0.5451111  0.5427844  0.54239833 0.5401301
 0.5366508  0.53474724 0.5341904  0.53336126 0.5321062  0.5312661
 0.5309506  0.5297305  0.5269268  0.5233609  0.52021646 0.5175235
 0.5146635  0.51142824 0.50837916 0.5058814  0.50329465 0.49991676
 0.4959896  0.49239844 0.48968515 0.48738825 0.485105   0.4829791
 0.48187596 0.4821455  0.48255342 0.48254797 0.48247272 0.48285735
 0.48312518 0.4829708  0.48241112 0.48196316 0.48208317 0.48217425
 0.48186645 0.4813836  0.4810428  0.48107782 0.48127383 0.48121452
 0.48102713 0.48125085 0.4820095  0.48262486 0.48286784 0.482891
 0.4832631  0.4838048  0.4842213  0.48433238 0.48417908 0.4841669
 0.48414806 0.4836519  0.48308524 0.48269987 0.48278007 0.4829046
 0.4826843  0.48242465 0.48269233 0.48340496 0.48390293 0.4842213
 0.48480964 0.48567358 0.4865603  0.48700246 0.4874186  0.4882313
 0.48924318 0.49010906 0.4906687  0.4908894  0.49122465 0.4917043
 0.49227083 0.49269184 0.49298906 0.493467   0.4943995  0.4955942
 0.4965525  0.4970389  0.49730396 0.4975526  0.49757847 0.4971043
 0.49619108 0.49515605 0.4941097  0.49319628 0.49277392 0.49268958
 0.49239722 0.49171603 0.4911864  0.49089637 0.49046946 0.48972544
 0.48881468 0.4879358  0.4869998  0.4858903  0.48476684 0.48388466
 0.4831891  0.48251614 0.481636   0.4805728  0.47944117 0.4783063
 0.47728038 0.4762546  0.4751412  0.4741204  0.4732543  0.47262853
 0.4722135  0.47182372 0.47146124 0.47130573 0.47141352 0.47157282
 0.4714695  0.47130468 0.471225   0.47130007 0.47134817 0.47122714
 0.47102535 0.47095123 0.4709666  0.47098398 0.47097594 0.47114322
 0.47149074 0.47189575 0.47213984 0.4721307  0.4722876  0.47262928
 0.47298044 0.47329018 0.473454   0.47355857 0.47361866 0.47367045
 0.4735705  0.47342902 0.4733944  0.47343862 0.4734255  0.47322944
 0.47308093 0.473223   0.47357935 0.47381023 0.4739477  0.4743613
 0.4752378  0.4761372  0.476597   0.47690734 0.4774636  0.47832206
 0.47890508 0.47897243 0.47892734 0.4793973  0.4802924  0.48105934
 0.48106292 0.48087656 0.48168325 0.48375693 0.48539692 0.48534983
 0.48534715 0.48792747 0.49141043 0.4920048  0.49223712 0.5015008 ]
