Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=22, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_180_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_180_336_FITS_ETTm1_ftM_sl180_ll48_pl336_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34045
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=22, out_features=63, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1241856.0
params:  1449.0
Trainable parameters:  1449
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5475075
	speed: 0.0199s/iter; left time: 526.1892s
	iters: 200, epoch: 1 | loss: 0.4223587
	speed: 0.0156s/iter; left time: 409.2147s
Epoch: 1 cost time: 4.5323240756988525
Epoch: 1, Steps: 265 | Train Loss: 0.5499518 Vali Loss: 0.7745144 Test Loss: 0.4645101
Validation loss decreased (inf --> 0.774514).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3464925
	speed: 0.0756s/iter; left time: 1975.2223s
	iters: 200, epoch: 2 | loss: 0.4337806
	speed: 0.0146s/iter; left time: 379.7228s
Epoch: 2 cost time: 4.49775242805481
Epoch: 2, Steps: 265 | Train Loss: 0.4004862 Vali Loss: 0.6983219 Test Loss: 0.4018779
Validation loss decreased (0.774514 --> 0.698322).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3560066
	speed: 0.0685s/iter; left time: 1772.4356s
	iters: 200, epoch: 3 | loss: 0.4127294
	speed: 0.0147s/iter; left time: 379.0901s
Epoch: 3 cost time: 4.522356033325195
Epoch: 3, Steps: 265 | Train Loss: 0.3819567 Vali Loss: 0.6798730 Test Loss: 0.3900041
Validation loss decreased (0.698322 --> 0.679873).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3993987
	speed: 0.0757s/iter; left time: 1937.2345s
	iters: 200, epoch: 4 | loss: 0.3497054
	speed: 0.0155s/iter; left time: 394.5233s
Epoch: 4 cost time: 5.03486967086792
Epoch: 4, Steps: 265 | Train Loss: 0.3773698 Vali Loss: 0.6735507 Test Loss: 0.3867063
Validation loss decreased (0.679873 --> 0.673551).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3297155
	speed: 0.0754s/iter; left time: 1911.6025s
	iters: 200, epoch: 5 | loss: 0.3197010
	speed: 0.0158s/iter; left time: 399.3660s
Epoch: 5 cost time: 5.1334006786346436
Epoch: 5, Steps: 265 | Train Loss: 0.3759993 Vali Loss: 0.6716585 Test Loss: 0.3854035
Validation loss decreased (0.673551 --> 0.671658).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3544313
	speed: 0.0812s/iter; left time: 2037.3556s
	iters: 200, epoch: 6 | loss: 0.3564337
	speed: 0.0152s/iter; left time: 378.7160s
Epoch: 6 cost time: 4.655486106872559
Epoch: 6, Steps: 265 | Train Loss: 0.3754169 Vali Loss: 0.6703616 Test Loss: 0.3851732
Validation loss decreased (0.671658 --> 0.670362).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3874230
	speed: 0.0726s/iter; left time: 1801.7579s
	iters: 200, epoch: 7 | loss: 0.3606138
	speed: 0.0147s/iter; left time: 362.6754s
Epoch: 7 cost time: 4.880440950393677
Epoch: 7, Steps: 265 | Train Loss: 0.3751558 Vali Loss: 0.6689378 Test Loss: 0.3850133
Validation loss decreased (0.670362 --> 0.668938).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4022477
	speed: 0.0744s/iter; left time: 1826.6860s
	iters: 200, epoch: 8 | loss: 0.3996282
	speed: 0.0143s/iter; left time: 349.9441s
Epoch: 8 cost time: 4.470932722091675
Epoch: 8, Steps: 265 | Train Loss: 0.3748043 Vali Loss: 0.6683418 Test Loss: 0.3845545
Validation loss decreased (0.668938 --> 0.668342).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4227541
	speed: 0.0839s/iter; left time: 2036.1786s
	iters: 200, epoch: 9 | loss: 0.3764034
	speed: 0.0161s/iter; left time: 388.4680s
Epoch: 9 cost time: 4.804163217544556
Epoch: 9, Steps: 265 | Train Loss: 0.3746814 Vali Loss: 0.6679257 Test Loss: 0.3843822
Validation loss decreased (0.668342 --> 0.667926).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3367004
	speed: 0.0731s/iter; left time: 1755.0356s
	iters: 200, epoch: 10 | loss: 0.3799381
	speed: 0.0160s/iter; left time: 381.9419s
Epoch: 10 cost time: 4.725726366043091
Epoch: 10, Steps: 265 | Train Loss: 0.3745962 Vali Loss: 0.6674294 Test Loss: 0.3843276
Validation loss decreased (0.667926 --> 0.667429).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3767962
	speed: 0.0698s/iter; left time: 1656.6480s
	iters: 200, epoch: 11 | loss: 0.4116304
	speed: 0.0252s/iter; left time: 595.4816s
Epoch: 11 cost time: 5.774634122848511
Epoch: 11, Steps: 265 | Train Loss: 0.3743664 Vali Loss: 0.6671093 Test Loss: 0.3846780
Validation loss decreased (0.667429 --> 0.667109).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3734727
	speed: 0.0772s/iter; left time: 1813.8747s
	iters: 200, epoch: 12 | loss: 0.3666772
	speed: 0.0160s/iter; left time: 373.1525s
Epoch: 12 cost time: 4.666771173477173
Epoch: 12, Steps: 265 | Train Loss: 0.3746042 Vali Loss: 0.6676467 Test Loss: 0.3845243
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3556923
	speed: 0.0747s/iter; left time: 1733.7731s
	iters: 200, epoch: 13 | loss: 0.4306857
	speed: 0.0157s/iter; left time: 362.1614s
Epoch: 13 cost time: 5.734609127044678
Epoch: 13, Steps: 265 | Train Loss: 0.3744848 Vali Loss: 0.6677831 Test Loss: 0.3841889
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3757294
	speed: 0.0904s/iter; left time: 2075.8178s
	iters: 200, epoch: 14 | loss: 0.3968842
	speed: 0.0160s/iter; left time: 365.1150s
Epoch: 14 cost time: 4.80512809753418
Epoch: 14, Steps: 265 | Train Loss: 0.3743243 Vali Loss: 0.6677489 Test Loss: 0.3840644
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3731647
	speed: 0.0802s/iter; left time: 1819.6267s
	iters: 200, epoch: 15 | loss: 0.4086025
	speed: 0.0185s/iter; left time: 418.5611s
Epoch: 15 cost time: 5.396024942398071
Epoch: 15, Steps: 265 | Train Loss: 0.3744790 Vali Loss: 0.6669995 Test Loss: 0.3842756
Validation loss decreased (0.667109 --> 0.666999).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3573658
	speed: 0.0788s/iter; left time: 1766.7423s
	iters: 200, epoch: 16 | loss: 0.3370900
	speed: 0.0157s/iter; left time: 349.4617s
Epoch: 16 cost time: 4.646997928619385
Epoch: 16, Steps: 265 | Train Loss: 0.3743460 Vali Loss: 0.6670269 Test Loss: 0.3841550
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3559609
	speed: 0.0741s/iter; left time: 1642.1886s
	iters: 200, epoch: 17 | loss: 0.3662015
	speed: 0.0149s/iter; left time: 328.7540s
Epoch: 17 cost time: 4.57196569442749
Epoch: 17, Steps: 265 | Train Loss: 0.3742503 Vali Loss: 0.6670442 Test Loss: 0.3840818
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3475313
	speed: 0.0735s/iter; left time: 1608.9784s
	iters: 200, epoch: 18 | loss: 0.3803108
	speed: 0.0143s/iter; left time: 312.0763s
Epoch: 18 cost time: 4.48933744430542
Epoch: 18, Steps: 265 | Train Loss: 0.3743787 Vali Loss: 0.6666697 Test Loss: 0.3842584
Validation loss decreased (0.666999 --> 0.666670).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3808249
	speed: 0.0746s/iter; left time: 1613.4421s
	iters: 200, epoch: 19 | loss: 0.4268677
	speed: 0.0157s/iter; left time: 338.6932s
Epoch: 19 cost time: 4.8834428787231445
Epoch: 19, Steps: 265 | Train Loss: 0.3744312 Vali Loss: 0.6662291 Test Loss: 0.3843707
Validation loss decreased (0.666670 --> 0.666229).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4099083
	speed: 0.0768s/iter; left time: 1641.7378s
	iters: 200, epoch: 20 | loss: 0.4191891
	speed: 0.0155s/iter; left time: 330.2808s
Epoch: 20 cost time: 4.711504220962524
Epoch: 20, Steps: 265 | Train Loss: 0.3743063 Vali Loss: 0.6676179 Test Loss: 0.3842959
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3647710
	speed: 0.0769s/iter; left time: 1623.5824s
	iters: 200, epoch: 21 | loss: 0.3786997
	speed: 0.0207s/iter; left time: 434.0324s
Epoch: 21 cost time: 5.047722816467285
Epoch: 21, Steps: 265 | Train Loss: 0.3743574 Vali Loss: 0.6670355 Test Loss: 0.3841873
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3776315
	speed: 0.0851s/iter; left time: 1772.4503s
	iters: 200, epoch: 22 | loss: 0.3529758
	speed: 0.0170s/iter; left time: 352.6822s
Epoch: 22 cost time: 5.295406341552734
Epoch: 22, Steps: 265 | Train Loss: 0.3743075 Vali Loss: 0.6667494 Test Loss: 0.3843169
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3917002
	speed: 0.0850s/iter; left time: 1748.9245s
	iters: 200, epoch: 23 | loss: 0.3829001
	speed: 0.0194s/iter; left time: 396.7830s
Epoch: 23 cost time: 6.060700178146362
Epoch: 23, Steps: 265 | Train Loss: 0.3743962 Vali Loss: 0.6672721 Test Loss: 0.3842400
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3926408
	speed: 0.0899s/iter; left time: 1825.4913s
	iters: 200, epoch: 24 | loss: 0.4034112
	speed: 0.0209s/iter; left time: 422.9832s
Epoch: 24 cost time: 6.168567180633545
Epoch: 24, Steps: 265 | Train Loss: 0.3742844 Vali Loss: 0.6662956 Test Loss: 0.3841906
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3861729
	speed: 0.0775s/iter; left time: 1552.2792s
	iters: 200, epoch: 25 | loss: 0.3494658
	speed: 0.0168s/iter; left time: 334.1874s
Epoch: 25 cost time: 4.9612157344818115
Epoch: 25, Steps: 265 | Train Loss: 0.3742938 Vali Loss: 0.6664568 Test Loss: 0.3842610
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3736637
	speed: 0.0741s/iter; left time: 1465.9546s
	iters: 200, epoch: 26 | loss: 0.3614573
	speed: 0.0158s/iter; left time: 311.3504s
Epoch: 26 cost time: 4.7710182666778564
Epoch: 26, Steps: 265 | Train Loss: 0.3741698 Vali Loss: 0.6667049 Test Loss: 0.3842472
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3801230
	speed: 0.0693s/iter; left time: 1352.7275s
	iters: 200, epoch: 27 | loss: 0.3637132
	speed: 0.0147s/iter; left time: 285.8797s
Epoch: 27 cost time: 4.321434736251831
Epoch: 27, Steps: 265 | Train Loss: 0.3742956 Vali Loss: 0.6671436 Test Loss: 0.3842936
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4022775
	speed: 0.0718s/iter; left time: 1381.2061s
	iters: 200, epoch: 28 | loss: 0.3815934
	speed: 0.0142s/iter; left time: 271.0511s
Epoch: 28 cost time: 4.386528015136719
Epoch: 28, Steps: 265 | Train Loss: 0.3743770 Vali Loss: 0.6667612 Test Loss: 0.3843221
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4073054
	speed: 0.0729s/iter; left time: 1383.4143s
	iters: 200, epoch: 29 | loss: 0.3382140
	speed: 0.0138s/iter; left time: 260.7414s
Epoch: 29 cost time: 4.1616432666778564
Epoch: 29, Steps: 265 | Train Loss: 0.3743061 Vali Loss: 0.6658872 Test Loss: 0.3843074
Validation loss decreased (0.666229 --> 0.665887).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3694609
	speed: 0.0716s/iter; left time: 1340.5840s
	iters: 200, epoch: 30 | loss: 0.3495313
	speed: 0.0146s/iter; left time: 272.3024s
Epoch: 30 cost time: 4.4423768520355225
Epoch: 30, Steps: 265 | Train Loss: 0.3743165 Vali Loss: 0.6667966 Test Loss: 0.3842420
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3927412
	speed: 0.0747s/iter; left time: 1378.0505s
	iters: 200, epoch: 31 | loss: 0.3362517
	speed: 0.0167s/iter; left time: 306.4628s
Epoch: 31 cost time: 4.809159278869629
Epoch: 31, Steps: 265 | Train Loss: 0.3742477 Vali Loss: 0.6662921 Test Loss: 0.3842168
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3628003
	speed: 0.0744s/iter; left time: 1352.7851s
	iters: 200, epoch: 32 | loss: 0.3394727
	speed: 0.0159s/iter; left time: 286.8620s
Epoch: 32 cost time: 4.936098098754883
Epoch: 32, Steps: 265 | Train Loss: 0.3741900 Vali Loss: 0.6666187 Test Loss: 0.3842088
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3511201
	speed: 0.0755s/iter; left time: 1353.3207s
	iters: 200, epoch: 33 | loss: 0.3985985
	speed: 0.0157s/iter; left time: 280.5649s
Epoch: 33 cost time: 4.515986680984497
Epoch: 33, Steps: 265 | Train Loss: 0.3743699 Vali Loss: 0.6667432 Test Loss: 0.3842921
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3670003
	speed: 0.0841s/iter; left time: 1484.2506s
	iters: 200, epoch: 34 | loss: 0.4281645
	speed: 0.0160s/iter; left time: 281.7356s
Epoch: 34 cost time: 5.637723922729492
Epoch: 34, Steps: 265 | Train Loss: 0.3741951 Vali Loss: 0.6668822 Test Loss: 0.3842989
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3831266
	speed: 0.0742s/iter; left time: 1290.0545s
	iters: 200, epoch: 35 | loss: 0.4154318
	speed: 0.0155s/iter; left time: 268.7221s
Epoch: 35 cost time: 4.650789022445679
Epoch: 35, Steps: 265 | Train Loss: 0.3742033 Vali Loss: 0.6664254 Test Loss: 0.3842607
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3860544
	speed: 0.0751s/iter; left time: 1286.8633s
	iters: 200, epoch: 36 | loss: 0.3496466
	speed: 0.0157s/iter; left time: 267.1004s
Epoch: 36 cost time: 4.748122215270996
Epoch: 36, Steps: 265 | Train Loss: 0.3741602 Vali Loss: 0.6666779 Test Loss: 0.3842118
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4882508
	speed: 0.0744s/iter; left time: 1255.1486s
	iters: 200, epoch: 37 | loss: 0.3312817
	speed: 0.0150s/iter; left time: 251.1851s
Epoch: 37 cost time: 4.588791847229004
Epoch: 37, Steps: 265 | Train Loss: 0.3743151 Vali Loss: 0.6662025 Test Loss: 0.3842586
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3978668
	speed: 0.0728s/iter; left time: 1208.5493s
	iters: 200, epoch: 38 | loss: 0.3495742
	speed: 0.0152s/iter; left time: 250.8063s
Epoch: 38 cost time: 4.580598592758179
Epoch: 38, Steps: 265 | Train Loss: 0.3741615 Vali Loss: 0.6667776 Test Loss: 0.3842740
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3908733
	speed: 0.0837s/iter; left time: 1367.6815s
	iters: 200, epoch: 39 | loss: 0.3365008
	speed: 0.0159s/iter; left time: 258.8667s
Epoch: 39 cost time: 5.886698484420776
Epoch: 39, Steps: 265 | Train Loss: 0.3742479 Vali Loss: 0.6666195 Test Loss: 0.3842199
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.3343486
	speed: 0.0832s/iter; left time: 1336.7392s
	iters: 200, epoch: 40 | loss: 0.3371294
	speed: 0.0169s/iter; left time: 269.6918s
Epoch: 40 cost time: 4.809257745742798
Epoch: 40, Steps: 265 | Train Loss: 0.3742105 Vali Loss: 0.6665226 Test Loss: 0.3842619
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3457245
	speed: 0.0755s/iter; left time: 1192.2131s
	iters: 200, epoch: 41 | loss: 0.3532257
	speed: 0.0155s/iter; left time: 242.6100s
Epoch: 41 cost time: 4.723855972290039
Epoch: 41, Steps: 265 | Train Loss: 0.3741663 Vali Loss: 0.6659914 Test Loss: 0.3842504
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3567212
	speed: 0.0767s/iter; left time: 1192.0281s
	iters: 200, epoch: 42 | loss: 0.3687378
	speed: 0.0160s/iter; left time: 247.2837s
Epoch: 42 cost time: 4.96602201461792
Epoch: 42, Steps: 265 | Train Loss: 0.3741602 Vali Loss: 0.6670782 Test Loss: 0.3842622
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.4078725
	speed: 0.0710s/iter; left time: 1084.2768s
	iters: 200, epoch: 43 | loss: 0.3343055
	speed: 0.0144s/iter; left time: 218.6004s
Epoch: 43 cost time: 4.2641212940216064
Epoch: 43, Steps: 265 | Train Loss: 0.3744086 Vali Loss: 0.6669893 Test Loss: 0.3843077
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.3542992
	speed: 0.0710s/iter; left time: 1065.7570s
	iters: 200, epoch: 44 | loss: 0.4049411
	speed: 0.0144s/iter; left time: 214.8867s
Epoch: 44 cost time: 4.3616228103637695
Epoch: 44, Steps: 265 | Train Loss: 0.3742169 Vali Loss: 0.6673759 Test Loss: 0.3842902
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.3864962
	speed: 0.0976s/iter; left time: 1439.3761s
	iters: 200, epoch: 45 | loss: 0.3690579
	speed: 0.0156s/iter; left time: 227.8899s
Epoch: 45 cost time: 6.41247820854187
Epoch: 45, Steps: 265 | Train Loss: 0.3741652 Vali Loss: 0.6669170 Test Loss: 0.3842683
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.4123363
	speed: 0.0733s/iter; left time: 1060.8566s
	iters: 200, epoch: 46 | loss: 0.3500641
	speed: 0.0154s/iter; left time: 221.1775s
Epoch: 46 cost time: 4.665737628936768
Epoch: 46, Steps: 265 | Train Loss: 0.3740629 Vali Loss: 0.6666139 Test Loss: 0.3842929
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.3780697
	speed: 0.0774s/iter; left time: 1099.8756s
	iters: 200, epoch: 47 | loss: 0.4022906
	speed: 0.0159s/iter; left time: 224.9620s
Epoch: 47 cost time: 4.654066324234009
Epoch: 47, Steps: 265 | Train Loss: 0.3741558 Vali Loss: 0.6670128 Test Loss: 0.3842577
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.4045796
	speed: 0.0944s/iter; left time: 1316.2859s
	iters: 200, epoch: 48 | loss: 0.4020002
	speed: 0.0372s/iter; left time: 515.0565s
Epoch: 48 cost time: 8.875578880310059
Epoch: 48, Steps: 265 | Train Loss: 0.3741834 Vali Loss: 0.6663144 Test Loss: 0.3842906
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.3321162
	speed: 0.0774s/iter; left time: 1058.8105s
	iters: 200, epoch: 49 | loss: 0.3413568
	speed: 0.0176s/iter; left time: 239.3660s
Epoch: 49 cost time: 5.120497226715088
Epoch: 49, Steps: 265 | Train Loss: 0.3742524 Vali Loss: 0.6663752 Test Loss: 0.3842585
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_180_336_FITS_ETTm1_ftM_sl180_ll48_pl336_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.38431045413017273, mae:0.3904600441455841, rse:0.5899149775505066, corr:[0.5457998  0.5478897  0.5471747  0.5450506  0.5430356  0.54203546
 0.54185975 0.5421934  0.5424506  0.5426946  0.5431173  0.5432961
 0.5430995  0.5420044  0.5400571  0.5377937  0.5356122  0.53372735
 0.5320915  0.5305222  0.5288643  0.52694213 0.5247352  0.5223528
 0.51986784 0.5174499  0.51540357 0.51385915 0.5129479  0.51266176
 0.51300263 0.5136348  0.51410204 0.51422375 0.51396817 0.5135352
 0.51304054 0.5125856  0.51231134 0.5120954  0.51193565 0.51171595
 0.5114636  0.5113127  0.51129776 0.5114303  0.5116934  0.51198184
 0.5121884  0.5122005  0.51208615 0.51197135 0.5119547  0.5120277
 0.5121582  0.5122555  0.5123513  0.512323   0.5121892  0.51194006
 0.5116997  0.5115488  0.5114757  0.5114695  0.5115059  0.5116605
 0.5118656  0.512048   0.5122744  0.51253563 0.51282114 0.51308084
 0.5132734  0.5133673  0.513439   0.51342946 0.51339734 0.5133437
 0.5132675  0.51316494 0.513091   0.51304036 0.51299965 0.5128562
 0.5125928  0.5122878  0.5120025  0.5116928  0.511359   0.51112676
 0.5109854  0.51086503 0.5106582  0.5103355  0.5098542  0.50915265
 0.5083095  0.5074882  0.5067765  0.50620157 0.5058909  0.50590986
 0.50619525 0.5066702  0.50733554 0.508203   0.5092346  0.5103411
 0.5113409  0.5120221  0.5122968  0.51235646 0.5122194  0.5119848
 0.51168114 0.51140875 0.51111394 0.5107633  0.5104007  0.5100237
 0.5096777  0.50925237 0.508729   0.5082291  0.50777584 0.5073915
 0.5071459  0.5070447  0.507004   0.50693965 0.50676286 0.50642824
 0.5059861  0.5056223  0.5053723  0.50516725 0.5050689  0.5049694
 0.5047936  0.50461125 0.50443417 0.5043306  0.5043487  0.50450814
 0.50473785 0.5049709  0.5050481  0.5050104  0.505007   0.5049172
 0.50480425 0.5047431  0.5047167  0.5047375  0.504683   0.5046211
 0.5045697  0.50458497 0.50462836 0.5047383  0.5048922  0.5050763
 0.5052738  0.50545704 0.5055783  0.5057254  0.5058874  0.5060822
 0.5063414  0.5065896  0.5067528  0.5068902  0.50692666 0.50683296
 0.5066671  0.50644326 0.5062307  0.5060718  0.505914   0.5057944
 0.5057085  0.50566185 0.50562936 0.50561136 0.5056011  0.50557655
 0.50555456 0.50556546 0.5056678  0.5059057  0.50622845 0.50654054
 0.5066897  0.506687   0.50648797 0.50594944 0.5052387  0.5046337
 0.5042325  0.50398487 0.5038253  0.5038805  0.5038967  0.50373286
 0.50341356 0.50283366 0.5022073  0.50173163 0.50137776 0.50110227
 0.5008099  0.500447   0.49992716 0.4991848  0.49826995 0.49731964
 0.4964376  0.49565008 0.49500826 0.4945525  0.49425143 0.4940985
 0.49406528 0.49414104 0.49420187 0.49421892 0.49419883 0.49408108
 0.49384463 0.4936098  0.4933486  0.49305785 0.49279356 0.4926095
 0.49254662 0.49262032 0.49270254 0.4928353  0.4929826  0.49305224
 0.49311656 0.49309543 0.49307054 0.4930476  0.49305522 0.49309322
 0.49315333 0.49314937 0.49311462 0.49307543 0.4930189  0.49294406
 0.4928866  0.4929311  0.49298522 0.49304065 0.4930486  0.4930292
 0.49309635 0.49328563 0.49356452 0.49389017 0.49418548 0.49445498
 0.49471515 0.4948818  0.4949972  0.49511355 0.4952603  0.4953634
 0.49545696 0.495507   0.49557385 0.4956516  0.49576303 0.49587855
 0.4960011  0.49618992 0.49637994 0.49652168 0.49659055 0.49655506
 0.49643087 0.49619177 0.4958719  0.49548003 0.49499857 0.49444297
 0.4937368  0.49301273 0.49237967 0.4917547  0.4912008  0.4907545
 0.49056578 0.4905587  0.49076536 0.4911121  0.49147052 0.49179256
 0.49201182 0.49202046 0.49197498 0.4919693  0.49200198 0.4919931
 0.4919396  0.4917789  0.4914795  0.49110827 0.4907461  0.4904676
 0.49026477 0.49003845 0.48979267 0.48957428 0.48923528 0.48887688
 0.48856547 0.48825428 0.48798645 0.48784342 0.4876926  0.487491
 0.48717734 0.48677588 0.48630285 0.48586643 0.4855274  0.48535663
 0.48537058 0.4855338  0.48572233 0.48591807 0.48620722 0.48657203]
