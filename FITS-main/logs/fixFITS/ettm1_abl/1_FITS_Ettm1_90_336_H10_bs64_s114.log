Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=20, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_90_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_90_336_FITS_ETTm1_ftM_sl90_ll48_pl336_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=20, out_features=94, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1684480.0
params:  1974.0
Trainable parameters:  1974
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.7401140
	speed: 0.0184s/iter; left time: 488.2942s
	iters: 200, epoch: 1 | loss: 0.5999693
	speed: 0.0126s/iter; left time: 332.0378s
Epoch: 1 cost time: 3.927546977996826
Epoch: 1, Steps: 266 | Train Loss: 0.6913371 Vali Loss: 0.9140160 Test Loss: 0.6356949
Validation loss decreased (inf --> 0.914016).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4813552
	speed: 0.0671s/iter; left time: 1760.0810s
	iters: 200, epoch: 2 | loss: 0.4733927
	speed: 0.0133s/iter; left time: 347.3821s
Epoch: 2 cost time: 4.032036781311035
Epoch: 2, Steps: 266 | Train Loss: 0.4747839 Vali Loss: 0.7713363 Test Loss: 0.4967417
Validation loss decreased (0.914016 --> 0.771336).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3943874
	speed: 0.0676s/iter; left time: 1755.1288s
	iters: 200, epoch: 3 | loss: 0.4374438
	speed: 0.0140s/iter; left time: 362.0145s
Epoch: 3 cost time: 4.13694167137146
Epoch: 3, Steps: 266 | Train Loss: 0.4393327 Vali Loss: 0.7287344 Test Loss: 0.4567290
Validation loss decreased (0.771336 --> 0.728734).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3972349
	speed: 0.0658s/iter; left time: 1690.6298s
	iters: 200, epoch: 4 | loss: 0.4164374
	speed: 0.0129s/iter; left time: 329.5652s
Epoch: 4 cost time: 4.045440673828125
Epoch: 4, Steps: 266 | Train Loss: 0.4292125 Vali Loss: 0.7102607 Test Loss: 0.4417053
Validation loss decreased (0.728734 --> 0.710261).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4174122
	speed: 0.0647s/iter; left time: 1644.8256s
	iters: 200, epoch: 5 | loss: 0.4087905
	speed: 0.0129s/iter; left time: 325.7260s
Epoch: 5 cost time: 4.034425258636475
Epoch: 5, Steps: 266 | Train Loss: 0.4258740 Vali Loss: 0.7015642 Test Loss: 0.4353410
Validation loss decreased (0.710261 --> 0.701564).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4144115
	speed: 0.0657s/iter; left time: 1654.0807s
	iters: 200, epoch: 6 | loss: 0.4335786
	speed: 0.0130s/iter; left time: 326.2774s
Epoch: 6 cost time: 3.9620256423950195
Epoch: 6, Steps: 266 | Train Loss: 0.4247144 Vali Loss: 0.6981491 Test Loss: 0.4329293
Validation loss decreased (0.701564 --> 0.698149).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4390951
	speed: 0.0666s/iter; left time: 1659.8333s
	iters: 200, epoch: 7 | loss: 0.4162367
	speed: 0.0125s/iter; left time: 309.3315s
Epoch: 7 cost time: 3.9518468379974365
Epoch: 7, Steps: 266 | Train Loss: 0.4240566 Vali Loss: 0.6968619 Test Loss: 0.4317918
Validation loss decreased (0.698149 --> 0.696862).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4149773
	speed: 0.0681s/iter; left time: 1677.6582s
	iters: 200, epoch: 8 | loss: 0.3925539
	speed: 0.0131s/iter; left time: 320.2761s
Epoch: 8 cost time: 4.144197940826416
Epoch: 8, Steps: 266 | Train Loss: 0.4241215 Vali Loss: 0.6949680 Test Loss: 0.4312163
Validation loss decreased (0.696862 --> 0.694968).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4075982
	speed: 0.0653s/iter; left time: 1590.8385s
	iters: 200, epoch: 9 | loss: 0.4615442
	speed: 0.0135s/iter; left time: 327.4446s
Epoch: 9 cost time: 4.1283440589904785
Epoch: 9, Steps: 266 | Train Loss: 0.4237966 Vali Loss: 0.6957064 Test Loss: 0.4313238
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4466926
	speed: 0.0661s/iter; left time: 1593.4961s
	iters: 200, epoch: 10 | loss: 0.4432197
	speed: 0.0132s/iter; left time: 317.2106s
Epoch: 10 cost time: 4.159501552581787
Epoch: 10, Steps: 266 | Train Loss: 0.4236860 Vali Loss: 0.6952252 Test Loss: 0.4310313
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4325737
	speed: 0.0654s/iter; left time: 1558.0795s
	iters: 200, epoch: 11 | loss: 0.4017110
	speed: 0.0130s/iter; left time: 307.5200s
Epoch: 11 cost time: 4.03368353843689
Epoch: 11, Steps: 266 | Train Loss: 0.4236209 Vali Loss: 0.6953498 Test Loss: 0.4311404
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3948533
	speed: 0.0666s/iter; left time: 1569.5294s
	iters: 200, epoch: 12 | loss: 0.3974405
	speed: 0.0131s/iter; left time: 307.4538s
Epoch: 12 cost time: 3.9986305236816406
Epoch: 12, Steps: 266 | Train Loss: 0.4236476 Vali Loss: 0.6943343 Test Loss: 0.4311818
Validation loss decreased (0.694968 --> 0.694334).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4111834
	speed: 0.0661s/iter; left time: 1541.6052s
	iters: 200, epoch: 13 | loss: 0.4412501
	speed: 0.0127s/iter; left time: 294.6776s
Epoch: 13 cost time: 4.038037300109863
Epoch: 13, Steps: 266 | Train Loss: 0.4235817 Vali Loss: 0.6952915 Test Loss: 0.4309826
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4142545
	speed: 0.0659s/iter; left time: 1517.6968s
	iters: 200, epoch: 14 | loss: 0.4302060
	speed: 0.0130s/iter; left time: 299.0218s
Epoch: 14 cost time: 4.062455654144287
Epoch: 14, Steps: 266 | Train Loss: 0.4234042 Vali Loss: 0.6942266 Test Loss: 0.4310632
Validation loss decreased (0.694334 --> 0.694227).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3792334
	speed: 0.0668s/iter; left time: 1522.3880s
	iters: 200, epoch: 15 | loss: 0.4218667
	speed: 0.0137s/iter; left time: 311.1348s
Epoch: 15 cost time: 4.244223594665527
Epoch: 15, Steps: 266 | Train Loss: 0.4234726 Vali Loss: 0.6938422 Test Loss: 0.4308013
Validation loss decreased (0.694227 --> 0.693842).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4182208
	speed: 0.0647s/iter; left time: 1457.4474s
	iters: 200, epoch: 16 | loss: 0.5277648
	speed: 0.0134s/iter; left time: 301.4108s
Epoch: 16 cost time: 4.040208101272583
Epoch: 16, Steps: 266 | Train Loss: 0.4235828 Vali Loss: 0.6945893 Test Loss: 0.4309608
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4149265
	speed: 0.0667s/iter; left time: 1482.6395s
	iters: 200, epoch: 17 | loss: 0.4075299
	speed: 0.0132s/iter; left time: 291.5363s
Epoch: 17 cost time: 3.9493837356567383
Epoch: 17, Steps: 266 | Train Loss: 0.4234974 Vali Loss: 0.6945620 Test Loss: 0.4310772
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4552668
	speed: 0.0660s/iter; left time: 1451.3169s
	iters: 200, epoch: 18 | loss: 0.4103892
	speed: 0.0134s/iter; left time: 293.5346s
Epoch: 18 cost time: 4.065300941467285
Epoch: 18, Steps: 266 | Train Loss: 0.4235799 Vali Loss: 0.6951177 Test Loss: 0.4311021
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4299009
	speed: 0.0654s/iter; left time: 1420.1420s
	iters: 200, epoch: 19 | loss: 0.4432063
	speed: 0.0134s/iter; left time: 289.7927s
Epoch: 19 cost time: 4.038211345672607
Epoch: 19, Steps: 266 | Train Loss: 0.4236036 Vali Loss: 0.6949445 Test Loss: 0.4312514
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4239336
	speed: 0.0657s/iter; left time: 1408.2293s
	iters: 200, epoch: 20 | loss: 0.4453255
	speed: 0.0129s/iter; left time: 275.9006s
Epoch: 20 cost time: 4.049505949020386
Epoch: 20, Steps: 266 | Train Loss: 0.4235101 Vali Loss: 0.6950367 Test Loss: 0.4310813
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4804135
	speed: 0.0650s/iter; left time: 1377.4334s
	iters: 200, epoch: 21 | loss: 0.4010171
	speed: 0.0129s/iter; left time: 272.6817s
Epoch: 21 cost time: 4.002514123916626
Epoch: 21, Steps: 266 | Train Loss: 0.4235306 Vali Loss: 0.6940037 Test Loss: 0.4310474
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4130064
	speed: 0.0669s/iter; left time: 1399.0532s
	iters: 200, epoch: 22 | loss: 0.4788954
	speed: 0.0133s/iter; left time: 277.7371s
Epoch: 22 cost time: 4.122142791748047
Epoch: 22, Steps: 266 | Train Loss: 0.4235236 Vali Loss: 0.6950893 Test Loss: 0.4307349
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4231405
	speed: 0.0676s/iter; left time: 1396.6533s
	iters: 200, epoch: 23 | loss: 0.4459441
	speed: 0.0137s/iter; left time: 282.2832s
Epoch: 23 cost time: 4.212688446044922
Epoch: 23, Steps: 266 | Train Loss: 0.4235021 Vali Loss: 0.6951190 Test Loss: 0.4310641
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4038016
	speed: 0.0696s/iter; left time: 1417.9498s
	iters: 200, epoch: 24 | loss: 0.4376676
	speed: 0.0135s/iter; left time: 273.4077s
Epoch: 24 cost time: 4.268238067626953
Epoch: 24, Steps: 266 | Train Loss: 0.4234125 Vali Loss: 0.6945451 Test Loss: 0.4310167
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4051941
	speed: 0.0659s/iter; left time: 1325.8385s
	iters: 200, epoch: 25 | loss: 0.4551813
	speed: 0.0134s/iter; left time: 267.7830s
Epoch: 25 cost time: 4.041776180267334
Epoch: 25, Steps: 266 | Train Loss: 0.4232911 Vali Loss: 0.6947202 Test Loss: 0.4310309
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4361895
	speed: 0.0676s/iter; left time: 1342.1983s
	iters: 200, epoch: 26 | loss: 0.4006723
	speed: 0.0135s/iter; left time: 267.3344s
Epoch: 26 cost time: 4.209998846054077
Epoch: 26, Steps: 266 | Train Loss: 0.4234549 Vali Loss: 0.6949527 Test Loss: 0.4311150
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3926616
	speed: 0.0674s/iter; left time: 1319.0961s
	iters: 200, epoch: 27 | loss: 0.4239100
	speed: 0.0129s/iter; left time: 252.3039s
Epoch: 27 cost time: 4.00518798828125
Epoch: 27, Steps: 266 | Train Loss: 0.4233378 Vali Loss: 0.6943778 Test Loss: 0.4310942
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4162461
	speed: 0.0669s/iter; left time: 1291.9163s
	iters: 200, epoch: 28 | loss: 0.4191952
	speed: 0.0129s/iter; left time: 248.7221s
Epoch: 28 cost time: 4.094486474990845
Epoch: 28, Steps: 266 | Train Loss: 0.4234557 Vali Loss: 0.6947101 Test Loss: 0.4312088
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4390520
	speed: 0.0652s/iter; left time: 1243.0794s
	iters: 200, epoch: 29 | loss: 0.3828447
	speed: 0.0129s/iter; left time: 243.7108s
Epoch: 29 cost time: 3.98907470703125
Epoch: 29, Steps: 266 | Train Loss: 0.4236268 Vali Loss: 0.6946178 Test Loss: 0.4310235
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4309701
	speed: 0.0662s/iter; left time: 1244.1369s
	iters: 200, epoch: 30 | loss: 0.4179992
	speed: 0.0130s/iter; left time: 242.2504s
Epoch: 30 cost time: 4.04911470413208
Epoch: 30, Steps: 266 | Train Loss: 0.4235150 Vali Loss: 0.6950748 Test Loss: 0.4311989
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4482192
	speed: 0.0643s/iter; left time: 1191.3652s
	iters: 200, epoch: 31 | loss: 0.4053073
	speed: 0.0133s/iter; left time: 244.6373s
Epoch: 31 cost time: 4.019956111907959
Epoch: 31, Steps: 266 | Train Loss: 0.4234930 Vali Loss: 0.6938217 Test Loss: 0.4310267
Validation loss decreased (0.693842 --> 0.693822).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4526278
	speed: 0.0693s/iter; left time: 1264.8957s
	iters: 200, epoch: 32 | loss: 0.4370306
	speed: 0.0136s/iter; left time: 247.0345s
Epoch: 32 cost time: 4.264127016067505
Epoch: 32, Steps: 266 | Train Loss: 0.4234793 Vali Loss: 0.6942778 Test Loss: 0.4310537
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4566915
	speed: 0.0662s/iter; left time: 1190.6354s
	iters: 200, epoch: 33 | loss: 0.4585438
	speed: 0.0138s/iter; left time: 247.3721s
Epoch: 33 cost time: 4.136492729187012
Epoch: 33, Steps: 266 | Train Loss: 0.4234448 Vali Loss: 0.6948411 Test Loss: 0.4311512
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4516579
	speed: 0.0658s/iter; left time: 1167.0508s
	iters: 200, epoch: 34 | loss: 0.4469585
	speed: 0.0131s/iter; left time: 230.0805s
Epoch: 34 cost time: 3.9713761806488037
Epoch: 34, Steps: 266 | Train Loss: 0.4233734 Vali Loss: 0.6949288 Test Loss: 0.4312509
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4448104
	speed: 0.0660s/iter; left time: 1152.5763s
	iters: 200, epoch: 35 | loss: 0.4092333
	speed: 0.0131s/iter; left time: 226.5245s
Epoch: 35 cost time: 4.075724840164185
Epoch: 35, Steps: 266 | Train Loss: 0.4234935 Vali Loss: 0.6945288 Test Loss: 0.4312613
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4107191
	speed: 0.0656s/iter; left time: 1127.5460s
	iters: 200, epoch: 36 | loss: 0.4307201
	speed: 0.0130s/iter; left time: 222.4148s
Epoch: 36 cost time: 4.013801336288452
Epoch: 36, Steps: 266 | Train Loss: 0.4235300 Vali Loss: 0.6946093 Test Loss: 0.4310441
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4003654
	speed: 0.0653s/iter; left time: 1105.3888s
	iters: 200, epoch: 37 | loss: 0.4412729
	speed: 0.0129s/iter; left time: 216.7472s
Epoch: 37 cost time: 3.9635608196258545
Epoch: 37, Steps: 266 | Train Loss: 0.4234490 Vali Loss: 0.6949055 Test Loss: 0.4311456
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4102505
	speed: 0.0655s/iter; left time: 1091.2004s
	iters: 200, epoch: 38 | loss: 0.3797901
	speed: 0.0140s/iter; left time: 231.0367s
Epoch: 38 cost time: 4.091522455215454
Epoch: 38, Steps: 266 | Train Loss: 0.4235356 Vali Loss: 0.6949576 Test Loss: 0.4311576
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4186336
	speed: 0.0675s/iter; left time: 1106.7487s
	iters: 200, epoch: 39 | loss: 0.3859098
	speed: 0.0139s/iter; left time: 226.5240s
Epoch: 39 cost time: 4.187867641448975
Epoch: 39, Steps: 266 | Train Loss: 0.4234027 Vali Loss: 0.6941720 Test Loss: 0.4311595
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.4502892
	speed: 0.0667s/iter; left time: 1075.2181s
	iters: 200, epoch: 40 | loss: 0.3843482
	speed: 0.0133s/iter; left time: 213.1380s
Epoch: 40 cost time: 4.041733741760254
Epoch: 40, Steps: 266 | Train Loss: 0.4233067 Vali Loss: 0.6955800 Test Loss: 0.4312172
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.4279912
	speed: 0.0649s/iter; left time: 1030.0314s
	iters: 200, epoch: 41 | loss: 0.4158001
	speed: 0.0131s/iter; left time: 205.6979s
Epoch: 41 cost time: 3.914032459259033
Epoch: 41, Steps: 266 | Train Loss: 0.4234168 Vali Loss: 0.6942042 Test Loss: 0.4311379
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.4413886
	speed: 0.0655s/iter; left time: 1021.6728s
	iters: 200, epoch: 42 | loss: 0.4090004
	speed: 0.0132s/iter; left time: 204.4857s
Epoch: 42 cost time: 4.068846702575684
Epoch: 42, Steps: 266 | Train Loss: 0.4235078 Vali Loss: 0.6948407 Test Loss: 0.4312973
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.4070871
	speed: 0.0642s/iter; left time: 984.8451s
	iters: 200, epoch: 43 | loss: 0.3955769
	speed: 0.0130s/iter; left time: 198.5426s
Epoch: 43 cost time: 3.954904079437256
Epoch: 43, Steps: 266 | Train Loss: 0.4232880 Vali Loss: 0.6946687 Test Loss: 0.4311625
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.4629507
	speed: 0.0667s/iter; left time: 1005.3688s
	iters: 200, epoch: 44 | loss: 0.4230283
	speed: 0.0129s/iter; left time: 193.0160s
Epoch: 44 cost time: 3.99078631401062
Epoch: 44, Steps: 266 | Train Loss: 0.4233676 Vali Loss: 0.6947765 Test Loss: 0.4312297
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.4424611
	speed: 0.0653s/iter; left time: 966.4424s
	iters: 200, epoch: 45 | loss: 0.4326779
	speed: 0.0130s/iter; left time: 191.1510s
Epoch: 45 cost time: 4.012030124664307
Epoch: 45, Steps: 266 | Train Loss: 0.4235647 Vali Loss: 0.6948567 Test Loss: 0.4312907
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.3919390
	speed: 0.0701s/iter; left time: 1017.9570s
	iters: 200, epoch: 46 | loss: 0.3953409
	speed: 0.0142s/iter; left time: 205.0066s
Epoch: 46 cost time: 4.321019649505615
Epoch: 46, Steps: 266 | Train Loss: 0.4234088 Vali Loss: 0.6945465 Test Loss: 0.4312632
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.3629594
	speed: 0.0674s/iter; left time: 961.1920s
	iters: 200, epoch: 47 | loss: 0.4636083
	speed: 0.0137s/iter; left time: 193.5460s
Epoch: 47 cost time: 4.166594982147217
Epoch: 47, Steps: 266 | Train Loss: 0.4235033 Vali Loss: 0.6943139 Test Loss: 0.4311647
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.4030405
	speed: 0.0672s/iter; left time: 941.1515s
	iters: 200, epoch: 48 | loss: 0.4671565
	speed: 0.0132s/iter; left time: 183.1002s
Epoch: 48 cost time: 4.043034315109253
Epoch: 48, Steps: 266 | Train Loss: 0.4232816 Vali Loss: 0.6943034 Test Loss: 0.4311810
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.4694640
	speed: 0.0659s/iter; left time: 904.9279s
	iters: 200, epoch: 49 | loss: 0.4483601
	speed: 0.0133s/iter; left time: 181.7987s
Epoch: 49 cost time: 3.9932868480682373
Epoch: 49, Steps: 266 | Train Loss: 0.4234443 Vali Loss: 0.6947730 Test Loss: 0.4312706
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.4159698
	speed: 0.0663s/iter; left time: 893.1098s
	iters: 200, epoch: 50 | loss: 0.4880221
	speed: 0.0136s/iter; left time: 182.0104s
Epoch: 50 cost time: 4.080476522445679
Epoch: 50, Steps: 266 | Train Loss: 0.4235972 Vali Loss: 0.6945834 Test Loss: 0.4312623
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.4257463
	speed: 0.0647s/iter; left time: 854.3445s
	iters: 200, epoch: 51 | loss: 0.4129932
	speed: 0.0132s/iter; left time: 172.3943s
Epoch: 51 cost time: 4.054594039916992
Epoch: 51, Steps: 266 | Train Loss: 0.4235370 Vali Loss: 0.6944521 Test Loss: 0.4312015
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_90_336_FITS_ETTm1_ftM_sl90_ll48_pl336_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.43112605810165405, mae:0.4187391996383667, rse:0.6248136162757874, corr:[0.5454611  0.54698366 0.5421823  0.5391976  0.53763086 0.53516704
 0.531776   0.52930254 0.5279989  0.5271265  0.52597195 0.5248237
 0.52394617 0.52267396 0.52026147 0.5167929  0.5131907  0.5101859
 0.50765324 0.50498563 0.5020423  0.49907097 0.49612907 0.49290788
 0.48932347 0.4856198  0.48243827 0.48007315 0.4783474  0.47672182
 0.47545126 0.47526115 0.47561005 0.4760824  0.47642586 0.47675097
 0.4767454  0.47671026 0.4766636  0.47651038 0.4764136  0.47618923
 0.47603062 0.47591582 0.47546256 0.47479674 0.474466   0.47467628
 0.47517863 0.4756294  0.47589287 0.47595325 0.47620448 0.4766094
 0.4771786  0.4776128  0.47800043 0.47831807 0.47829387 0.47815204
 0.47802028 0.47769123 0.4774052  0.4770222  0.47681975 0.4767354
 0.47655052 0.47636405 0.47652197 0.4770533  0.4774857  0.47785744
 0.4784372  0.47914648 0.4799459  0.48052764 0.4812205  0.482158
 0.48307914 0.4838557  0.4844693  0.4847953  0.4851031  0.48534837
 0.48565376 0.48600796 0.48644876 0.48706645 0.487956   0.48901793
 0.4899417  0.49054447 0.49095187 0.4913074  0.49148142 0.49120188
 0.49035367 0.4891892  0.48805687 0.48729247 0.4870197  0.48680568
 0.4863387  0.48575488 0.48544678 0.48518595 0.48459753 0.48374042
 0.48292926 0.48227274 0.48150083 0.48043436 0.47929493 0.47843483
 0.47776994 0.47708088 0.47606453 0.4748316  0.4736142  0.47245613
 0.47134623 0.4701098  0.46884403 0.46788973 0.4670939  0.46626255
 0.46548343 0.46494663 0.4647547  0.46478724 0.46484503 0.46488592
 0.4648749  0.46493903 0.464787   0.46433857 0.46384665 0.46364886
 0.46374485 0.4638657  0.46375602 0.46357322 0.46353757 0.4637368
 0.46391222 0.46401507 0.4641819  0.4644099  0.4648101  0.46501568
 0.46497652 0.46515787 0.46557167 0.46593657 0.46593437 0.46580157
 0.46573552 0.46579784 0.46580908 0.46571907 0.46573412 0.46584845
 0.46603122 0.46621394 0.46647266 0.4668776  0.46750376 0.4682659
 0.46900797 0.46963564 0.4701983  0.47093418 0.47172767 0.47249135
 0.47307062 0.47354186 0.4740192  0.47449255 0.47477606 0.47497648
 0.47523656 0.475727   0.4763584  0.47706363 0.47785795 0.47876963
 0.479706   0.48036882 0.48055652 0.4804741  0.48063478 0.4812385
 0.48200342 0.48268864 0.4833233  0.48419484 0.48538378 0.48656413
 0.48719114 0.4871181  0.48682567 0.48652717 0.4860915  0.48539406
 0.4844126  0.48317775 0.48170683 0.4802341  0.47884196 0.47762385
 0.47642702 0.47518802 0.47393227 0.4725809  0.47109067 0.4696053
 0.4678652  0.46604732 0.4644522  0.46335942 0.46249157 0.4616659
 0.46097937 0.46073946 0.46070227 0.4606319  0.46067783 0.46049866
 0.4601409  0.4599467  0.45992666 0.45984    0.45969227 0.45937106
 0.45900917 0.45874476 0.45852327 0.4585217  0.45873603 0.45875254
 0.45882982 0.4589683  0.4592144  0.45947552 0.45943633 0.45946628
 0.45979494 0.46035174 0.46074185 0.46100882 0.46113685 0.4614486
 0.46165717 0.46164542 0.46125707 0.46114504 0.46130747 0.4615533
 0.46183798 0.46212444 0.46220738 0.46236002 0.46276587 0.46339977
 0.46429166 0.46501395 0.46549296 0.46601692 0.46690613 0.46795878
 0.46902457 0.46979868 0.47032878 0.47072643 0.47118324 0.47171184
 0.47224048 0.47273895 0.47314692 0.47366148 0.47434375 0.4751226
 0.4758443  0.47637427 0.47665563 0.47661632 0.47609738 0.47491297
 0.47294787 0.4706087  0.4685827  0.4671429  0.4662076  0.46569484
 0.46544123 0.4652345  0.4650195  0.46466526 0.46413973 0.46350086
 0.4627234  0.461702   0.46043825 0.45908922 0.4579378  0.45700222
 0.45627937 0.4555366  0.45482543 0.4541679  0.45348346 0.45262152
 0.45159844 0.45064858 0.44990164 0.4492511  0.44834906 0.44754633
 0.44703305 0.44660026 0.4460553  0.4455944  0.4455087  0.44575706
 0.44570708 0.44530863 0.44497794 0.44508448 0.44517332 0.44469634
 0.44432047 0.44470572 0.4455215  0.4455316  0.44534403 0.4474241 ]
