Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=58, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_720_720_FITS_ETTm1_ftM_sl720_ll48_pl720_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=58, out_features=116, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6028288.0
params:  6844.0
Trainable parameters:  6844
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5114474
	speed: 0.0417s/iter; left time: 1070.8493s
	iters: 200, epoch: 1 | loss: 0.4272668
	speed: 0.0310s/iter; left time: 793.8488s
Epoch: 1 cost time: 9.162875175476074
Epoch: 1, Steps: 258 | Train Loss: 0.5318570 Vali Loss: 1.0304564 Test Loss: 0.4582899
Validation loss decreased (inf --> 1.030456).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4306965
	speed: 0.1580s/iter; left time: 4021.0116s
	iters: 200, epoch: 2 | loss: 0.4387549
	speed: 0.0419s/iter; left time: 1062.3833s
Epoch: 2 cost time: 10.705481767654419
Epoch: 2, Steps: 258 | Train Loss: 0.4185872 Vali Loss: 0.9720712 Test Loss: 0.4251601
Validation loss decreased (1.030456 --> 0.972071).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3969952
	speed: 0.1526s/iter; left time: 3842.2003s
	iters: 200, epoch: 3 | loss: 0.4024888
	speed: 0.0383s/iter; left time: 960.0892s
Epoch: 3 cost time: 10.549630880355835
Epoch: 3, Steps: 258 | Train Loss: 0.4057642 Vali Loss: 0.9537209 Test Loss: 0.4183558
Validation loss decreased (0.972071 --> 0.953721).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3981925
	speed: 0.1438s/iter; left time: 3584.4018s
	iters: 200, epoch: 4 | loss: 0.4161196
	speed: 0.0316s/iter; left time: 785.2180s
Epoch: 4 cost time: 8.588744640350342
Epoch: 4, Steps: 258 | Train Loss: 0.4018771 Vali Loss: 0.9469870 Test Loss: 0.4175852
Validation loss decreased (0.953721 --> 0.946987).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3892755
	speed: 0.1390s/iter; left time: 3428.2876s
	iters: 200, epoch: 5 | loss: 0.4142540
	speed: 0.0351s/iter; left time: 862.2187s
Epoch: 5 cost time: 9.969976663589478
Epoch: 5, Steps: 258 | Train Loss: 0.4004775 Vali Loss: 0.9433237 Test Loss: 0.4181854
Validation loss decreased (0.946987 --> 0.943324).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4092644
	speed: 0.1453s/iter; left time: 3545.9317s
	iters: 200, epoch: 6 | loss: 0.4187165
	speed: 0.0321s/iter; left time: 780.6914s
Epoch: 6 cost time: 9.411221981048584
Epoch: 6, Steps: 258 | Train Loss: 0.3999053 Vali Loss: 0.9400697 Test Loss: 0.4185416
Validation loss decreased (0.943324 --> 0.940070).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3950060
	speed: 0.1364s/iter; left time: 3295.4382s
	iters: 200, epoch: 7 | loss: 0.4231602
	speed: 0.0302s/iter; left time: 726.6568s
Epoch: 7 cost time: 8.84120798110962
Epoch: 7, Steps: 258 | Train Loss: 0.3995917 Vali Loss: 0.9392587 Test Loss: 0.4186897
Validation loss decreased (0.940070 --> 0.939259).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3819637
	speed: 0.1333s/iter; left time: 3186.0976s
	iters: 200, epoch: 8 | loss: 0.4091425
	speed: 0.0317s/iter; left time: 753.3491s
Epoch: 8 cost time: 9.05754542350769
Epoch: 8, Steps: 258 | Train Loss: 0.3993920 Vali Loss: 0.9382750 Test Loss: 0.4187571
Validation loss decreased (0.939259 --> 0.938275).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4050364
	speed: 0.1437s/iter; left time: 3397.7747s
	iters: 200, epoch: 9 | loss: 0.3903619
	speed: 0.0394s/iter; left time: 926.2438s
Epoch: 9 cost time: 10.634952306747437
Epoch: 9, Steps: 258 | Train Loss: 0.3993301 Vali Loss: 0.9366491 Test Loss: 0.4191678
Validation loss decreased (0.938275 --> 0.936649).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4482571
	speed: 0.1640s/iter; left time: 3833.6476s
	iters: 200, epoch: 10 | loss: 0.3876697
	speed: 0.0315s/iter; left time: 733.9019s
Epoch: 10 cost time: 8.983460187911987
Epoch: 10, Steps: 258 | Train Loss: 0.3990478 Vali Loss: 0.9365575 Test Loss: 0.4194377
Validation loss decreased (0.936649 --> 0.936557).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3663574
	speed: 0.1473s/iter; left time: 3405.7541s
	iters: 200, epoch: 11 | loss: 0.3790832
	speed: 0.0371s/iter; left time: 854.1907s
Epoch: 11 cost time: 10.258835792541504
Epoch: 11, Steps: 258 | Train Loss: 0.3989086 Vali Loss: 0.9355065 Test Loss: 0.4190428
Validation loss decreased (0.936557 --> 0.935507).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4171570
	speed: 0.1433s/iter; left time: 3275.4542s
	iters: 200, epoch: 12 | loss: 0.3873118
	speed: 0.0384s/iter; left time: 874.0560s
Epoch: 12 cost time: 10.28132963180542
Epoch: 12, Steps: 258 | Train Loss: 0.3989676 Vali Loss: 0.9356123 Test Loss: 0.4193765
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3682030
	speed: 0.1462s/iter; left time: 3305.2999s
	iters: 200, epoch: 13 | loss: 0.4129463
	speed: 0.0329s/iter; left time: 740.2244s
Epoch: 13 cost time: 9.52308201789856
Epoch: 13, Steps: 258 | Train Loss: 0.3989508 Vali Loss: 0.9352251 Test Loss: 0.4194010
Validation loss decreased (0.935507 --> 0.935225).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4102412
	speed: 0.1480s/iter; left time: 3307.2188s
	iters: 200, epoch: 14 | loss: 0.4230333
	speed: 0.0300s/iter; left time: 668.0463s
Epoch: 14 cost time: 9.245230913162231
Epoch: 14, Steps: 258 | Train Loss: 0.3988717 Vali Loss: 0.9347782 Test Loss: 0.4194367
Validation loss decreased (0.935225 --> 0.934778).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4129737
	speed: 0.1527s/iter; left time: 3373.3197s
	iters: 200, epoch: 15 | loss: 0.4307246
	speed: 0.0295s/iter; left time: 648.5906s
Epoch: 15 cost time: 8.399951934814453
Epoch: 15, Steps: 258 | Train Loss: 0.3988505 Vali Loss: 0.9342280 Test Loss: 0.4191903
Validation loss decreased (0.934778 --> 0.934228).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4186107
	speed: 0.1341s/iter; left time: 2928.4164s
	iters: 200, epoch: 16 | loss: 0.3870655
	speed: 0.0329s/iter; left time: 713.8777s
Epoch: 16 cost time: 9.212650299072266
Epoch: 16, Steps: 258 | Train Loss: 0.3987926 Vali Loss: 0.9350832 Test Loss: 0.4193879
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4132620
	speed: 0.1520s/iter; left time: 3279.2643s
	iters: 200, epoch: 17 | loss: 0.3788615
	speed: 0.0355s/iter; left time: 762.6536s
Epoch: 17 cost time: 10.47988486289978
Epoch: 17, Steps: 258 | Train Loss: 0.3987532 Vali Loss: 0.9352559 Test Loss: 0.4193129
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3706923
	speed: 0.1453s/iter; left time: 3097.8240s
	iters: 200, epoch: 18 | loss: 0.3968548
	speed: 0.0366s/iter; left time: 775.9766s
Epoch: 18 cost time: 9.946190595626831
Epoch: 18, Steps: 258 | Train Loss: 0.3987681 Vali Loss: 0.9342135 Test Loss: 0.4192075
Validation loss decreased (0.934228 --> 0.934213).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4220830
	speed: 0.1430s/iter; left time: 3011.4752s
	iters: 200, epoch: 19 | loss: 0.4133966
	speed: 0.0305s/iter; left time: 639.0653s
Epoch: 19 cost time: 8.522829294204712
Epoch: 19, Steps: 258 | Train Loss: 0.3986098 Vali Loss: 0.9343834 Test Loss: 0.4192138
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4118601
	speed: 0.1401s/iter; left time: 2914.1840s
	iters: 200, epoch: 20 | loss: 0.3775507
	speed: 0.0341s/iter; left time: 705.8530s
Epoch: 20 cost time: 9.540632486343384
Epoch: 20, Steps: 258 | Train Loss: 0.3987092 Vali Loss: 0.9335282 Test Loss: 0.4195207
Validation loss decreased (0.934213 --> 0.933528).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3859135
	speed: 0.1480s/iter; left time: 3039.1737s
	iters: 200, epoch: 21 | loss: 0.3931748
	speed: 0.0390s/iter; left time: 797.2919s
Epoch: 21 cost time: 11.235998630523682
Epoch: 21, Steps: 258 | Train Loss: 0.3986526 Vali Loss: 0.9346305 Test Loss: 0.4196698
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3869063
	speed: 0.1462s/iter; left time: 2965.6842s
	iters: 200, epoch: 22 | loss: 0.3844704
	speed: 0.0362s/iter; left time: 729.7232s
Epoch: 22 cost time: 10.248634099960327
Epoch: 22, Steps: 258 | Train Loss: 0.3985019 Vali Loss: 0.9338633 Test Loss: 0.4191417
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4274904
	speed: 0.1647s/iter; left time: 3297.5115s
	iters: 200, epoch: 23 | loss: 0.4355518
	speed: 0.0384s/iter; left time: 765.5851s
Epoch: 23 cost time: 10.561573266983032
Epoch: 23, Steps: 258 | Train Loss: 0.3986656 Vali Loss: 0.9340156 Test Loss: 0.4191124
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3961489
	speed: 0.1539s/iter; left time: 3042.1127s
	iters: 200, epoch: 24 | loss: 0.3710459
	speed: 0.0338s/iter; left time: 664.1711s
Epoch: 24 cost time: 10.111974954605103
Epoch: 24, Steps: 258 | Train Loss: 0.3986771 Vali Loss: 0.9343610 Test Loss: 0.4193711
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3694102
	speed: 0.1526s/iter; left time: 2977.6299s
	iters: 200, epoch: 25 | loss: 0.4087490
	speed: 0.0369s/iter; left time: 715.8760s
Epoch: 25 cost time: 10.654301881790161
Epoch: 25, Steps: 258 | Train Loss: 0.3984577 Vali Loss: 0.9340787 Test Loss: 0.4193757
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4097311
	speed: 0.1595s/iter; left time: 3070.3729s
	iters: 200, epoch: 26 | loss: 0.3792423
	speed: 0.0328s/iter; left time: 627.2561s
Epoch: 26 cost time: 10.343192338943481
Epoch: 26, Steps: 258 | Train Loss: 0.3985422 Vali Loss: 0.9337687 Test Loss: 0.4196075
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4331042
	speed: 0.1505s/iter; left time: 2858.9971s
	iters: 200, epoch: 27 | loss: 0.4015426
	speed: 0.0322s/iter; left time: 608.1251s
Epoch: 27 cost time: 9.511455774307251
Epoch: 27, Steps: 258 | Train Loss: 0.3985290 Vali Loss: 0.9335100 Test Loss: 0.4191860
Validation loss decreased (0.933528 --> 0.933510).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4155516
	speed: 0.1493s/iter; left time: 2796.3695s
	iters: 200, epoch: 28 | loss: 0.3658660
	speed: 0.0327s/iter; left time: 609.4361s
Epoch: 28 cost time: 9.419767379760742
Epoch: 28, Steps: 258 | Train Loss: 0.3985606 Vali Loss: 0.9338320 Test Loss: 0.4191965
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3891194
	speed: 0.1423s/iter; left time: 2630.0269s
	iters: 200, epoch: 29 | loss: 0.4318891
	speed: 0.0379s/iter; left time: 697.3555s
Epoch: 29 cost time: 10.774901866912842
Epoch: 29, Steps: 258 | Train Loss: 0.3984587 Vali Loss: 0.9332808 Test Loss: 0.4196061
Validation loss decreased (0.933510 --> 0.933281).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3972577
	speed: 0.1576s/iter; left time: 2871.8394s
	iters: 200, epoch: 30 | loss: 0.3942868
	speed: 0.0382s/iter; left time: 691.5130s
Epoch: 30 cost time: 11.092987060546875
Epoch: 30, Steps: 258 | Train Loss: 0.3985187 Vali Loss: 0.9342532 Test Loss: 0.4192733
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3782449
	speed: 0.1490s/iter; left time: 2676.3535s
	iters: 200, epoch: 31 | loss: 0.3740145
	speed: 0.0306s/iter; left time: 546.5891s
Epoch: 31 cost time: 8.975488901138306
Epoch: 31, Steps: 258 | Train Loss: 0.3984293 Vali Loss: 0.9334268 Test Loss: 0.4193059
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4013279
	speed: 0.1295s/iter; left time: 2292.8029s
	iters: 200, epoch: 32 | loss: 0.4140140
	speed: 0.0304s/iter; left time: 534.6804s
Epoch: 32 cost time: 8.408952236175537
Epoch: 32, Steps: 258 | Train Loss: 0.3985140 Vali Loss: 0.9332734 Test Loss: 0.4190931
Validation loss decreased (0.933281 --> 0.933273).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3927796
	speed: 0.1408s/iter; left time: 2456.7743s
	iters: 200, epoch: 33 | loss: 0.3670385
	speed: 0.0364s/iter; left time: 632.0335s
Epoch: 33 cost time: 10.040701866149902
Epoch: 33, Steps: 258 | Train Loss: 0.3985491 Vali Loss: 0.9336356 Test Loss: 0.4194683
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3939140
	speed: 0.1234s/iter; left time: 2120.4592s
	iters: 200, epoch: 34 | loss: 0.4002774
	speed: 0.0354s/iter; left time: 604.6822s
Epoch: 34 cost time: 9.542127132415771
Epoch: 34, Steps: 258 | Train Loss: 0.3985227 Vali Loss: 0.9333068 Test Loss: 0.4193347
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4292002
	speed: 0.1613s/iter; left time: 2730.6769s
	iters: 200, epoch: 35 | loss: 0.4205716
	speed: 0.0409s/iter; left time: 688.2396s
Epoch: 35 cost time: 11.211072444915771
Epoch: 35, Steps: 258 | Train Loss: 0.3983289 Vali Loss: 0.9331932 Test Loss: 0.4192495
Validation loss decreased (0.933273 --> 0.933193).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4090300
	speed: 0.1547s/iter; left time: 2579.7203s
	iters: 200, epoch: 36 | loss: 0.4122829
	speed: 0.0328s/iter; left time: 543.9394s
Epoch: 36 cost time: 9.862491846084595
Epoch: 36, Steps: 258 | Train Loss: 0.3985065 Vali Loss: 0.9337612 Test Loss: 0.4193632
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4122869
	speed: 0.1444s/iter; left time: 2370.3294s
	iters: 200, epoch: 37 | loss: 0.3916250
	speed: 0.0394s/iter; left time: 643.4465s
Epoch: 37 cost time: 10.001070737838745
Epoch: 37, Steps: 258 | Train Loss: 0.3984924 Vali Loss: 0.9334176 Test Loss: 0.4192674
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3885083
	speed: 0.1552s/iter; left time: 2506.6360s
	iters: 200, epoch: 38 | loss: 0.3929069
	speed: 0.0371s/iter; left time: 595.9197s
Epoch: 38 cost time: 10.896839618682861
Epoch: 38, Steps: 258 | Train Loss: 0.3984086 Vali Loss: 0.9333140 Test Loss: 0.4192269
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3962232
	speed: 0.1489s/iter; left time: 2366.9518s
	iters: 200, epoch: 39 | loss: 0.3983320
	speed: 0.0334s/iter; left time: 528.3150s
Epoch: 39 cost time: 10.083614587783813
Epoch: 39, Steps: 258 | Train Loss: 0.3984492 Vali Loss: 0.9337751 Test Loss: 0.4190999
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.3924799
	speed: 0.1638s/iter; left time: 2561.8691s
	iters: 200, epoch: 40 | loss: 0.3997623
	speed: 0.0322s/iter; left time: 499.7124s
Epoch: 40 cost time: 8.980205297470093
Epoch: 40, Steps: 258 | Train Loss: 0.3982776 Vali Loss: 0.9334105 Test Loss: 0.4193633
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.4032235
	speed: 0.1404s/iter; left time: 2158.9256s
	iters: 200, epoch: 41 | loss: 0.4072987
	speed: 0.0410s/iter; left time: 626.3921s
Epoch: 41 cost time: 11.451519012451172
Epoch: 41, Steps: 258 | Train Loss: 0.3984495 Vali Loss: 0.9336911 Test Loss: 0.4193108
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3995661
	speed: 0.1640s/iter; left time: 2480.6494s
	iters: 200, epoch: 42 | loss: 0.3938704
	speed: 0.0373s/iter; left time: 559.8558s
Epoch: 42 cost time: 11.120934009552002
Epoch: 42, Steps: 258 | Train Loss: 0.3982601 Vali Loss: 0.9338105 Test Loss: 0.4194103
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3556563
	speed: 0.1657s/iter; left time: 2462.6021s
	iters: 200, epoch: 43 | loss: 0.4109288
	speed: 0.0447s/iter; left time: 660.7304s
Epoch: 43 cost time: 12.735110759735107
Epoch: 43, Steps: 258 | Train Loss: 0.3984097 Vali Loss: 0.9334067 Test Loss: 0.4193732
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.3885954
	speed: 0.1643s/iter; left time: 2400.5708s
	iters: 200, epoch: 44 | loss: 0.3903658
	speed: 0.0389s/iter; left time: 564.9212s
Epoch: 44 cost time: 10.602909803390503
Epoch: 44, Steps: 258 | Train Loss: 0.3983035 Vali Loss: 0.9339856 Test Loss: 0.4193662
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.3661761
	speed: 0.1571s/iter; left time: 2254.7389s
	iters: 200, epoch: 45 | loss: 0.3996297
	speed: 0.0412s/iter; left time: 587.5853s
Epoch: 45 cost time: 11.228389739990234
Epoch: 45, Steps: 258 | Train Loss: 0.3983958 Vali Loss: 0.9335738 Test Loss: 0.4193272
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.4221869
	speed: 0.1454s/iter; left time: 2048.8182s
	iters: 200, epoch: 46 | loss: 0.3893459
	speed: 0.0358s/iter; left time: 500.4291s
Epoch: 46 cost time: 9.65702199935913
Epoch: 46, Steps: 258 | Train Loss: 0.3984211 Vali Loss: 0.9334672 Test Loss: 0.4192268
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.4066558
	speed: 0.1396s/iter; left time: 1931.5973s
	iters: 200, epoch: 47 | loss: 0.3981499
	speed: 0.0338s/iter; left time: 464.2384s
Epoch: 47 cost time: 8.73609185218811
Epoch: 47, Steps: 258 | Train Loss: 0.3983649 Vali Loss: 0.9334517 Test Loss: 0.4193675
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.3669400
	speed: 0.1243s/iter; left time: 1687.1484s
	iters: 200, epoch: 48 | loss: 0.4101508
	speed: 0.0297s/iter; left time: 399.9221s
Epoch: 48 cost time: 8.252751111984253
Epoch: 48, Steps: 258 | Train Loss: 0.3983385 Vali Loss: 0.9331658 Test Loss: 0.4193041
Validation loss decreased (0.933193 --> 0.933166).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.4008809
	speed: 0.1224s/iter; left time: 1630.2730s
	iters: 200, epoch: 49 | loss: 0.3777924
	speed: 0.0336s/iter; left time: 443.9382s
Epoch: 49 cost time: 8.576915740966797
Epoch: 49, Steps: 258 | Train Loss: 0.3982946 Vali Loss: 0.9331800 Test Loss: 0.4193641
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.3532771
	speed: 0.1457s/iter; left time: 1903.0691s
	iters: 200, epoch: 50 | loss: 0.4080784
	speed: 0.0344s/iter; left time: 446.3756s
Epoch: 50 cost time: 9.972668647766113
Epoch: 50, Steps: 258 | Train Loss: 0.3983201 Vali Loss: 0.9336264 Test Loss: 0.4193546
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.3884239
	speed: 0.1466s/iter; left time: 1875.9913s
	iters: 200, epoch: 51 | loss: 0.4218948
	speed: 0.0395s/iter; left time: 502.0202s
Epoch: 51 cost time: 11.356130123138428
Epoch: 51, Steps: 258 | Train Loss: 0.3983488 Vali Loss: 0.9333847 Test Loss: 0.4193430
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.3601581
	speed: 0.1462s/iter; left time: 1834.3701s
	iters: 200, epoch: 52 | loss: 0.3778608
	speed: 0.0371s/iter; left time: 461.6669s
Epoch: 52 cost time: 9.95349645614624
Epoch: 52, Steps: 258 | Train Loss: 0.3983777 Vali Loss: 0.9335981 Test Loss: 0.4193821
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.4247342
	speed: 0.1497s/iter; left time: 1839.2046s
	iters: 200, epoch: 53 | loss: 0.4083157
	speed: 0.0443s/iter; left time: 539.9239s
Epoch: 53 cost time: 11.690205097198486
Epoch: 53, Steps: 258 | Train Loss: 0.3983612 Vali Loss: 0.9334874 Test Loss: 0.4192928
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.3745112
	speed: 0.1587s/iter; left time: 1908.7282s
	iters: 200, epoch: 54 | loss: 0.3845751
	speed: 0.0460s/iter; left time: 549.0921s
Epoch: 54 cost time: 12.28977918624878
Epoch: 54, Steps: 258 | Train Loss: 0.3983584 Vali Loss: 0.9339297 Test Loss: 0.4193104
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.4002525
	speed: 0.1429s/iter; left time: 1681.4157s
	iters: 200, epoch: 55 | loss: 0.3781055
	speed: 0.0368s/iter; left time: 428.8746s
Epoch: 55 cost time: 10.777267217636108
Epoch: 55, Steps: 258 | Train Loss: 0.3984280 Vali Loss: 0.9333581 Test Loss: 0.4193346
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.3896226
	speed: 0.1625s/iter; left time: 1870.7445s
	iters: 200, epoch: 56 | loss: 0.3998359
	speed: 0.0383s/iter; left time: 437.1940s
Epoch: 56 cost time: 10.69584846496582
Epoch: 56, Steps: 258 | Train Loss: 0.3983542 Vali Loss: 0.9336778 Test Loss: 0.4193224
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.3932549
	speed: 0.1432s/iter; left time: 1611.7083s
	iters: 200, epoch: 57 | loss: 0.4538565
	speed: 0.0372s/iter; left time: 415.2329s
Epoch: 57 cost time: 10.106085538864136
Epoch: 57, Steps: 258 | Train Loss: 0.3985137 Vali Loss: 0.9334800 Test Loss: 0.4192993
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.4315929
	speed: 0.1536s/iter; left time: 1688.4182s
	iters: 200, epoch: 58 | loss: 0.3830967
	speed: 0.0419s/iter; left time: 456.4113s
Epoch: 58 cost time: 11.48310375213623
Epoch: 58, Steps: 258 | Train Loss: 0.3983640 Vali Loss: 0.9342726 Test Loss: 0.4193065
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.3954759
	speed: 0.1599s/iter; left time: 1716.4070s
	iters: 200, epoch: 59 | loss: 0.4149064
	speed: 0.0435s/iter; left time: 462.7467s
Epoch: 59 cost time: 11.371541500091553
Epoch: 59, Steps: 258 | Train Loss: 0.3983176 Vali Loss: 0.9335338 Test Loss: 0.4193861
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.4126257
	speed: 0.1549s/iter; left time: 1623.1140s
	iters: 200, epoch: 60 | loss: 0.4285648
	speed: 0.0280s/iter; left time: 290.8777s
Epoch: 60 cost time: 8.099460124969482
Epoch: 60, Steps: 258 | Train Loss: 0.3982856 Vali Loss: 0.9338316 Test Loss: 0.4193047
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.4162398
	speed: 0.1408s/iter; left time: 1439.5148s
	iters: 200, epoch: 61 | loss: 0.4089625
	speed: 0.0311s/iter; left time: 314.6719s
Epoch: 61 cost time: 9.053309917449951
Epoch: 61, Steps: 258 | Train Loss: 0.3982971 Vali Loss: 0.9336212 Test Loss: 0.4193337
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.3920129
	speed: 0.1308s/iter; left time: 1303.5883s
	iters: 200, epoch: 62 | loss: 0.3935939
	speed: 0.0289s/iter; left time: 284.8797s
Epoch: 62 cost time: 8.175864696502686
Epoch: 62, Steps: 258 | Train Loss: 0.3983067 Vali Loss: 0.9341565 Test Loss: 0.4193209
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.3999465
	speed: 0.1374s/iter; left time: 1333.3947s
	iters: 200, epoch: 63 | loss: 0.4176825
	speed: 0.0320s/iter; left time: 307.7955s
Epoch: 63 cost time: 9.141783714294434
Epoch: 63, Steps: 258 | Train Loss: 0.3982087 Vali Loss: 0.9331390 Test Loss: 0.4193301
Validation loss decreased (0.933166 --> 0.933139).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.4090424
	speed: 0.1494s/iter; left time: 1411.5523s
	iters: 200, epoch: 64 | loss: 0.3916003
	speed: 0.0322s/iter; left time: 301.0034s
Epoch: 64 cost time: 9.367516040802002
Epoch: 64, Steps: 258 | Train Loss: 0.3982784 Vali Loss: 0.9338191 Test Loss: 0.4193125
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.3634582
	speed: 0.1480s/iter; left time: 1360.2593s
	iters: 200, epoch: 65 | loss: 0.3920269
	speed: 0.0405s/iter; left time: 368.3606s
Epoch: 65 cost time: 11.567728281021118
Epoch: 65, Steps: 258 | Train Loss: 0.3982682 Vali Loss: 0.9333413 Test Loss: 0.4193374
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.4044622
	speed: 0.1425s/iter; left time: 1272.6688s
	iters: 200, epoch: 66 | loss: 0.4151596
	speed: 0.0301s/iter; left time: 265.8318s
Epoch: 66 cost time: 8.550781011581421
Epoch: 66, Steps: 258 | Train Loss: 0.3982765 Vali Loss: 0.9332700 Test Loss: 0.4193377
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.3985072
	speed: 0.1366s/iter; left time: 1184.7445s
	iters: 200, epoch: 67 | loss: 0.4085301
	speed: 0.0283s/iter; left time: 242.5961s
Epoch: 67 cost time: 7.984044075012207
Epoch: 67, Steps: 258 | Train Loss: 0.3983080 Vali Loss: 0.9324605 Test Loss: 0.4193180
Validation loss decreased (0.933139 --> 0.932460).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.3663188
	speed: 0.1479s/iter; left time: 1244.5747s
	iters: 200, epoch: 68 | loss: 0.3842293
	speed: 0.0312s/iter; left time: 259.1649s
Epoch: 68 cost time: 9.600252628326416
Epoch: 68, Steps: 258 | Train Loss: 0.3982618 Vali Loss: 0.9337399 Test Loss: 0.4193291
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.4172226
	speed: 0.1413s/iter; left time: 1152.4186s
	iters: 200, epoch: 69 | loss: 0.4128393
	speed: 0.0341s/iter; left time: 274.9627s
Epoch: 69 cost time: 9.843034744262695
Epoch: 69, Steps: 258 | Train Loss: 0.3982456 Vali Loss: 0.9341375 Test Loss: 0.4193593
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.4096831
	speed: 0.1536s/iter; left time: 1213.5629s
	iters: 200, epoch: 70 | loss: 0.3897958
	speed: 0.0402s/iter; left time: 313.7362s
Epoch: 70 cost time: 11.653680562973022
Epoch: 70, Steps: 258 | Train Loss: 0.3983084 Vali Loss: 0.9324044 Test Loss: 0.4193530
Validation loss decreased (0.932460 --> 0.932404).  Saving model ...
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.4085825
	speed: 0.1530s/iter; left time: 1169.3504s
	iters: 200, epoch: 71 | loss: 0.3925072
	speed: 0.0399s/iter; left time: 300.6431s
Epoch: 71 cost time: 10.420297145843506
Epoch: 71, Steps: 258 | Train Loss: 0.3983428 Vali Loss: 0.9335732 Test Loss: 0.4193542
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.3710721
	speed: 0.1612s/iter; left time: 1189.8252s
	iters: 200, epoch: 72 | loss: 0.3857120
	speed: 0.0461s/iter; left time: 335.6401s
Epoch: 72 cost time: 12.66052794456482
Epoch: 72, Steps: 258 | Train Loss: 0.3983478 Vali Loss: 0.9334401 Test Loss: 0.4193461
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.4015543
	speed: 0.1454s/iter; left time: 1035.7299s
	iters: 200, epoch: 73 | loss: 0.4084553
	speed: 0.0362s/iter; left time: 254.0363s
Epoch: 73 cost time: 10.175155401229858
Epoch: 73, Steps: 258 | Train Loss: 0.3983278 Vali Loss: 0.9333797 Test Loss: 0.4193373
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.4034804
	speed: 0.1424s/iter; left time: 977.6973s
	iters: 200, epoch: 74 | loss: 0.4114333
	speed: 0.0332s/iter; left time: 224.9805s
Epoch: 74 cost time: 10.000519037246704
Epoch: 74, Steps: 258 | Train Loss: 0.3984267 Vali Loss: 0.9339364 Test Loss: 0.4193304
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.3726113
	speed: 0.1446s/iter; left time: 955.4897s
	iters: 200, epoch: 75 | loss: 0.3871291
	speed: 0.0296s/iter; left time: 192.5368s
Epoch: 75 cost time: 8.194867849349976
Epoch: 75, Steps: 258 | Train Loss: 0.3982728 Vali Loss: 0.9328504 Test Loss: 0.4193453
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.3992090
	speed: 0.1343s/iter; left time: 853.2366s
	iters: 200, epoch: 76 | loss: 0.4140671
	speed: 0.0291s/iter; left time: 181.7004s
Epoch: 76 cost time: 8.682018995285034
Epoch: 76, Steps: 258 | Train Loss: 0.3982936 Vali Loss: 0.9337713 Test Loss: 0.4193294
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.3862738
	speed: 0.1381s/iter; left time: 841.3243s
	iters: 200, epoch: 77 | loss: 0.3997234
	speed: 0.0379s/iter; left time: 227.4023s
Epoch: 77 cost time: 10.668907880783081
Epoch: 77, Steps: 258 | Train Loss: 0.3982213 Vali Loss: 0.9320930 Test Loss: 0.4193297
Validation loss decreased (0.932404 --> 0.932093).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.4201298
	speed: 0.1559s/iter; left time: 909.9534s
	iters: 200, epoch: 78 | loss: 0.4208286
	speed: 0.0488s/iter; left time: 279.8243s
Epoch: 78 cost time: 12.853080749511719
Epoch: 78, Steps: 258 | Train Loss: 0.3983944 Vali Loss: 0.9330177 Test Loss: 0.4193331
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.3825078
	speed: 0.1534s/iter; left time: 855.4306s
	iters: 200, epoch: 79 | loss: 0.3816966
	speed: 0.0373s/iter; left time: 204.1290s
Epoch: 79 cost time: 9.724865674972534
Epoch: 79, Steps: 258 | Train Loss: 0.3983249 Vali Loss: 0.9336079 Test Loss: 0.4193450
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.3837464
	speed: 0.1306s/iter; left time: 694.7385s
	iters: 200, epoch: 80 | loss: 0.4081773
	speed: 0.0284s/iter; left time: 148.3305s
Epoch: 80 cost time: 7.828999757766724
Epoch: 80, Steps: 258 | Train Loss: 0.3982940 Vali Loss: 0.9336563 Test Loss: 0.4193452
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.4061676
	speed: 0.1372s/iter; left time: 694.4693s
	iters: 200, epoch: 81 | loss: 0.4193670
	speed: 0.0280s/iter; left time: 138.6944s
Epoch: 81 cost time: 8.22150468826294
Epoch: 81, Steps: 258 | Train Loss: 0.3981324 Vali Loss: 0.9332783 Test Loss: 0.4193402
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.3811384
	speed: 0.1279s/iter; left time: 614.1838s
	iters: 200, epoch: 82 | loss: 0.3813423
	speed: 0.0282s/iter; left time: 132.7076s
Epoch: 82 cost time: 7.90498423576355
Epoch: 82, Steps: 258 | Train Loss: 0.3983102 Vali Loss: 0.9330744 Test Loss: 0.4193461
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.3899384
	speed: 0.1518s/iter; left time: 689.8191s
	iters: 200, epoch: 83 | loss: 0.4067839
	speed: 0.0377s/iter; left time: 167.6682s
Epoch: 83 cost time: 10.621538877487183
Epoch: 83, Steps: 258 | Train Loss: 0.3982820 Vali Loss: 0.9338621 Test Loss: 0.4193531
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.3849226
	speed: 0.1415s/iter; left time: 606.4312s
	iters: 200, epoch: 84 | loss: 0.3849868
	speed: 0.0319s/iter; left time: 133.7673s
Epoch: 84 cost time: 9.181336164474487
Epoch: 84, Steps: 258 | Train Loss: 0.3983126 Vali Loss: 0.9339057 Test Loss: 0.4193523
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.3897667
	speed: 0.1375s/iter; left time: 554.0201s
	iters: 200, epoch: 85 | loss: 0.4081938
	speed: 0.0330s/iter; left time: 129.5951s
Epoch: 85 cost time: 9.400204420089722
Epoch: 85, Steps: 258 | Train Loss: 0.3983596 Vali Loss: 0.9325775 Test Loss: 0.4193426
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.4182560
	speed: 0.1339s/iter; left time: 504.8703s
	iters: 200, epoch: 86 | loss: 0.3938444
	speed: 0.0302s/iter; left time: 110.6834s
Epoch: 86 cost time: 9.033689022064209
Epoch: 86, Steps: 258 | Train Loss: 0.3982424 Vali Loss: 0.9333129 Test Loss: 0.4193451
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.3840523
	speed: 0.1568s/iter; left time: 550.8041s
	iters: 200, epoch: 87 | loss: 0.3699892
	speed: 0.0355s/iter; left time: 121.2800s
Epoch: 87 cost time: 9.985286474227905
Epoch: 87, Steps: 258 | Train Loss: 0.3982106 Vali Loss: 0.9331473 Test Loss: 0.4193475
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.4102792
	speed: 0.1414s/iter; left time: 460.2031s
	iters: 200, epoch: 88 | loss: 0.3790425
	speed: 0.0311s/iter; left time: 97.9921s
Epoch: 88 cost time: 8.884085416793823
Epoch: 88, Steps: 258 | Train Loss: 0.3982466 Vali Loss: 0.9332914 Test Loss: 0.4193417
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.3775635
	speed: 0.1492s/iter; left time: 447.2957s
	iters: 200, epoch: 89 | loss: 0.3797195
	speed: 0.0373s/iter; left time: 108.0660s
Epoch: 89 cost time: 10.418058395385742
Epoch: 89, Steps: 258 | Train Loss: 0.3981062 Vali Loss: 0.9330179 Test Loss: 0.4193460
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.4069091
	speed: 0.1382s/iter; left time: 378.5725s
	iters: 200, epoch: 90 | loss: 0.4322666
	speed: 0.0304s/iter; left time: 80.1812s
Epoch: 90 cost time: 8.720171928405762
Epoch: 90, Steps: 258 | Train Loss: 0.3983149 Vali Loss: 0.9328534 Test Loss: 0.4193423
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.204402478767869e-06
	iters: 100, epoch: 91 | loss: 0.4151974
	speed: 0.1350s/iter; left time: 334.8289s
	iters: 200, epoch: 91 | loss: 0.4186018
	speed: 0.0336s/iter; left time: 79.9259s
Epoch: 91 cost time: 9.355724096298218
Epoch: 91, Steps: 258 | Train Loss: 0.3981814 Vali Loss: 0.9335221 Test Loss: 0.4193494
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.944182354829475e-06
	iters: 100, epoch: 92 | loss: 0.3817506
	speed: 0.1449s/iter; left time: 322.1431s
	iters: 200, epoch: 92 | loss: 0.4328575
	speed: 0.0265s/iter; left time: 56.2971s
Epoch: 92 cost time: 7.790767669677734
Epoch: 92, Steps: 258 | Train Loss: 0.3983490 Vali Loss: 0.9342309 Test Loss: 0.4193564
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.696973237088e-06
	iters: 100, epoch: 93 | loss: 0.3848995
	speed: 0.1240s/iter; left time: 243.6082s
	iters: 200, epoch: 93 | loss: 0.4395759
	speed: 0.0283s/iter; left time: 52.7204s
Epoch: 93 cost time: 8.392841815948486
Epoch: 93, Steps: 258 | Train Loss: 0.3983253 Vali Loss: 0.9335368 Test Loss: 0.4193500
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.462124575233601e-06
	iters: 100, epoch: 94 | loss: 0.3959217
	speed: 0.1425s/iter; left time: 243.3256s
	iters: 200, epoch: 94 | loss: 0.3545638
	speed: 0.0326s/iter; left time: 52.3332s
Epoch: 94 cost time: 9.458710432052612
Epoch: 94, Steps: 258 | Train Loss: 0.3981658 Vali Loss: 0.9330606 Test Loss: 0.4193455
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.239018346471921e-06
	iters: 100, epoch: 95 | loss: 0.3926047
	speed: 0.1372s/iter; left time: 198.8364s
	iters: 200, epoch: 95 | loss: 0.4052913
	speed: 0.0335s/iter; left time: 45.1430s
Epoch: 95 cost time: 9.749173879623413
Epoch: 95, Steps: 258 | Train Loss: 0.3983479 Vali Loss: 0.9326137 Test Loss: 0.4193423
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.027067429148324e-06
	iters: 100, epoch: 96 | loss: 0.4080806
	speed: 0.1446s/iter; left time: 172.1693s
	iters: 200, epoch: 96 | loss: 0.4003575
	speed: 0.0364s/iter; left time: 39.7638s
Epoch: 96 cost time: 10.12631630897522
Epoch: 96, Steps: 258 | Train Loss: 0.3982639 Vali Loss: 0.9327242 Test Loss: 0.4193441
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.825714057690908e-06
	iters: 100, epoch: 97 | loss: 0.4045279
	speed: 0.1360s/iter; left time: 126.8490s
	iters: 200, epoch: 97 | loss: 0.4242437
	speed: 0.0297s/iter; left time: 24.7626s
Epoch: 97 cost time: 8.492851972579956
Epoch: 97, Steps: 258 | Train Loss: 0.3982761 Vali Loss: 0.9328775 Test Loss: 0.4193400
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_720_720_FITS_ETTm1_ftM_sl720_ll48_pl720_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.4183576703071594, mae:0.41413795948028564, rse:0.6153817772865295, corr:[0.5261845  0.5301055  0.53357714 0.5361227  0.53754276 0.53825676
 0.53859127 0.53878075 0.5390419  0.53942513 0.5399378  0.5403696
 0.5406527  0.54065055 0.5402942  0.5395814  0.53858274 0.5373554
 0.5359115  0.534318   0.53268206 0.5310598  0.5295075  0.528206
 0.5271097  0.52634877 0.52596563 0.52585226 0.52602977 0.52642506
 0.52690685 0.5274314  0.52783364 0.52813405 0.52822924 0.52825737
 0.52812165 0.52792895 0.5277263  0.52745074 0.5271783  0.5268981
 0.52665514 0.5265441  0.52651066 0.5264976  0.52653986 0.5265853
 0.52654254 0.52632076 0.5260181  0.52569264 0.5254567  0.5252376
 0.5250698  0.52492154 0.5247812  0.52461004 0.5244403  0.52422553
 0.5240319  0.5239108  0.5238788  0.5238788  0.5239671  0.5241564
 0.5243736  0.52456933 0.524738   0.524815   0.52482855 0.5247602
 0.5245959  0.5243545  0.52411664 0.52390665 0.52371514 0.5235688
 0.52346367 0.5234004  0.5233523  0.52328897 0.52320474 0.5230654
 0.5229543  0.52286536 0.52285814 0.52291965 0.52305335 0.52329767
 0.5236074  0.5238892  0.52408147 0.52412903 0.5240478  0.52381605
 0.5235217  0.5233015  0.5230789  0.52293706 0.52285236 0.52279437
 0.5227473  0.5226541  0.52251863 0.5223999  0.5222461  0.5220882
 0.5218939  0.5216933  0.5214922  0.5212719  0.5210171  0.520759
 0.52050304 0.520262   0.52004427 0.5198394  0.51963615 0.51946616
 0.51930153 0.51910734 0.5188292  0.5185242  0.51823753 0.5179706
 0.5177437  0.5176107  0.5175514  0.51756895 0.5175764  0.5175353
 0.5174689  0.51738447 0.5172578  0.51711977 0.51704246 0.516975
 0.5169598  0.51705027 0.5171939  0.5174005  0.51765126 0.51792234
 0.5181567  0.5182474  0.5182141  0.5180811  0.51792306 0.5177616
 0.5175957  0.51747894 0.5174296  0.5174281  0.51744694 0.5175213
 0.5176081  0.51767457 0.5177354  0.5177387  0.51775855 0.5178103
 0.517904   0.51803154 0.51818997 0.51836026 0.51854575 0.51875776
 0.51893526 0.51902515 0.5190748  0.519111   0.51910573 0.5190624
 0.5189985  0.5189153  0.5188367  0.5187725  0.5187142  0.51869595
 0.5187272  0.5188248  0.5189535  0.5191446  0.5193905  0.5196694
 0.51994526 0.52020013 0.5204128  0.52054024 0.52051795 0.5203557
 0.52006406 0.5197521  0.5193664  0.5188654  0.5182446  0.5175472
 0.51677465 0.5159676  0.51513517 0.514347   0.51361954 0.51297426
 0.5124149  0.5119155  0.5114316  0.51095766 0.5104467  0.5098708
 0.50919765 0.508457   0.50769746 0.50696564 0.5062681  0.50568485
 0.50528425 0.5050531  0.5049667  0.50494653 0.5049302  0.5049122
 0.50492394 0.5048972  0.50486356 0.5048532  0.504856   0.5048942
 0.5049802  0.50512105 0.50528085 0.5053973  0.5054668  0.50549275
 0.5055039  0.50556487 0.5056192  0.50575215 0.50591546 0.506131
 0.50635064 0.5064524  0.5064377  0.5063433  0.5062317  0.50609374
 0.5059528  0.5058212  0.50569826 0.50560856 0.5055254  0.5054868
 0.5054362  0.50542504 0.50542074 0.5054123  0.50541025 0.5054287
 0.5054775  0.5055717  0.50569165 0.5058032  0.5058792  0.50598425
 0.5060393  0.5060612  0.50605404 0.506053   0.5060579  0.50604045
 0.5060193  0.5059844  0.5059574  0.5059336  0.50590897 0.50589615
 0.5058718  0.50590235 0.5059347  0.50601983 0.50612634 0.5062146
 0.5063037  0.50631946 0.5062241  0.50604147 0.50574917 0.50533986
 0.50484174 0.5043534  0.5039018  0.5034434  0.50295156 0.5024282
 0.50188357 0.5012971  0.50073457 0.5002026  0.49969858 0.49925455
 0.49885935 0.49851274 0.4982442  0.49802378 0.497813   0.49755785
 0.4973128  0.4970355  0.49674052 0.49645832 0.49626392 0.49615845
 0.49614266 0.4962212  0.4963187  0.49638876 0.49640116 0.49636748
 0.49628273 0.496132   0.49593803 0.495751   0.4955954  0.4954799
 0.4954069  0.4953966  0.49540886 0.49542627 0.49539742 0.4953094
 0.49522913 0.49516162 0.4950998  0.4950661  0.49505696 0.4951352
 0.49524656 0.4952657  0.495228   0.49514526 0.49505472 0.494981
 0.49489158 0.49484465 0.49482107 0.49481577 0.49481618 0.4948319
 0.49480596 0.49476925 0.4947123  0.49462485 0.49454662 0.49448547
 0.4944276  0.4943946  0.49437046 0.4943448  0.49433544 0.49435574
 0.4943302  0.4943059  0.49426922 0.49423435 0.49420917 0.49419293
 0.4941306  0.49405998 0.4939877  0.4938919  0.49381426 0.4937804
 0.49381587 0.4939471  0.494164   0.4944732  0.4948269  0.49521038
 0.49559164 0.49591967 0.4961735  0.4962704  0.49619207 0.49598107
 0.49566734 0.49529627 0.49493864 0.4945843  0.49416542 0.49377146
 0.49338982 0.49301046 0.49262074 0.49225277 0.49186924 0.49147728
 0.4910921  0.4907265  0.49039027 0.49008724 0.48975837 0.48944876
 0.48913127 0.48885047 0.48856243 0.4883042  0.48809072 0.48795906
 0.4879049  0.48792022 0.48798227 0.4880701  0.48815277 0.48818263
 0.4882485  0.48828325 0.48834276 0.48837954 0.48841682 0.48849574
 0.48856667 0.4886563  0.48871544 0.48875082 0.48871988 0.48869163
 0.48866454 0.48867443 0.48868755 0.48876956 0.48886076 0.48903173
 0.48918813 0.4892181  0.48913458 0.4889852  0.48879394 0.48860013
 0.4884122  0.48825282 0.4881481  0.48808718 0.4880675  0.48809165
 0.48811927 0.48816314 0.48819387 0.48821586 0.4882331  0.4882299
 0.48824474 0.48826587 0.48828396 0.48828647 0.48826537 0.48828265
 0.4882662  0.48825338 0.48824304 0.48827472 0.48829263 0.48831737
 0.48831627 0.48830268 0.48824134 0.48815987 0.48807818 0.48801753
 0.48800474 0.48802432 0.48808601 0.48817357 0.48827288 0.48835826
 0.48837027 0.48831195 0.48818943 0.4879588  0.48761168 0.4871851
 0.48670897 0.48623523 0.48579252 0.48533985 0.4848183  0.4842407
 0.4836502  0.48298502 0.482284   0.48160273 0.48094156 0.4803083
 0.47973102 0.47924703 0.47884738 0.47846705 0.47806823 0.47766173
 0.4772379  0.47684318 0.47649541 0.47612765 0.4758373  0.47562075
 0.47551155 0.47550425 0.47555217 0.47567084 0.47580683 0.47597492
 0.47617072 0.47632688 0.47643176 0.47655365 0.47668308 0.47681767
 0.47692585 0.47704917 0.47721416 0.47735354 0.47744772 0.47754455
 0.4776635  0.47782287 0.4780057  0.47815868 0.47831306 0.47850338
 0.47868416 0.47878784 0.47877538 0.47871512 0.47866842 0.47863013
 0.478604   0.47857544 0.47854075 0.47850993 0.4784655  0.4784051
 0.47833255 0.4782473  0.47816923 0.4781079  0.47806782 0.4780791
 0.47812346 0.47819006 0.47826117 0.4782902  0.47827545 0.47828612
 0.4782674  0.4782477  0.47825024 0.47829613 0.4783555  0.4784263
 0.47847575 0.4785042  0.4784957  0.47846162 0.4784082  0.47833934
 0.47825542 0.4782435  0.47825626 0.47831976 0.4784255  0.47855648
 0.47867855 0.47872585 0.47869793 0.4785538  0.47827396 0.47783786
 0.47730413 0.47678456 0.47630534 0.47584227 0.47533873 0.47484472
 0.47432736 0.47379583 0.47324467 0.47268254 0.47213817 0.47158942
 0.47108746 0.47063902 0.47023195 0.46984306 0.4694773  0.46910968
 0.46873438 0.46834922 0.46799034 0.4676886  0.46745995 0.46731746
 0.46728325 0.46731862 0.4674063  0.4675159  0.4676441  0.4677323
 0.4678323  0.46791533 0.4679908  0.46807882 0.46817157 0.46830082
 0.46845606 0.46858522 0.4687164  0.46882045 0.46888766 0.46892008
 0.46895906 0.4690514  0.46915087 0.46926445 0.46946082 0.4697228
 0.46995696 0.47013572 0.47022438 0.47021404 0.47019285 0.47019348
 0.47015452 0.47011852 0.47008064 0.47000444 0.46989965 0.46973944
 0.46948707 0.46918902 0.46890673 0.46862215 0.4684222  0.46829706
 0.46824917 0.46825212 0.46829495 0.46835592 0.46840143 0.46845177
 0.46847263 0.468425   0.46835932 0.46831003 0.46827918 0.46825865
 0.4682439  0.46823615 0.46823633 0.4682525  0.4682777  0.4682932
 0.4683056  0.4683724  0.46849662 0.46864128 0.46883154 0.46903896
 0.46922678 0.46934626 0.46936962 0.4693197  0.4691491  0.46884486
 0.46843538 0.46803004 0.46766844 0.46731666 0.4669317  0.4665069
 0.46605083 0.4655501  0.46508953 0.46469027 0.46429014 0.4640073
 0.4637548  0.46356207 0.46337163 0.46319613 0.46299186 0.4627253
 0.46241558 0.4620702  0.4617687  0.4614802  0.4612851  0.46122992
 0.46128348 0.461452   0.46164942 0.4618307  0.46201044 0.4621123
 0.46219212 0.46225193 0.46232706 0.4624982  0.4627025  0.46297026
 0.46327394 0.4636236  0.4639995  0.46434447 0.46468374 0.4649795
 0.46530372 0.46566516 0.46594486 0.46618414 0.46625894 0.4658203 ]
