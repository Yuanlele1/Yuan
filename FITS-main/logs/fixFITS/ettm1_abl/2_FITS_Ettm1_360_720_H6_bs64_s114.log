Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=34, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_360_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_360_720_FITS_ETTm1_ftM_sl360_ll48_pl720_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33481
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=34, out_features=102, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3107328.0
params:  3570.0
Trainable parameters:  3570
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5868525
	speed: 0.0460s/iter; left time: 1196.4075s
	iters: 200, epoch: 1 | loss: 0.4298667
	speed: 0.0299s/iter; left time: 773.9847s
Epoch: 1 cost time: 9.428314208984375
Epoch: 1, Steps: 261 | Train Loss: 0.5631098 Vali Loss: 1.1872180 Test Loss: 0.5730786
Validation loss decreased (inf --> 1.187218).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3859018
	speed: 0.1217s/iter; left time: 3131.5878s
	iters: 200, epoch: 2 | loss: 0.3435625
	speed: 0.0220s/iter; left time: 563.3400s
Epoch: 2 cost time: 7.296852350234985
Epoch: 2, Steps: 261 | Train Loss: 0.3606070 Vali Loss: 1.0562242 Test Loss: 0.4773800
Validation loss decreased (1.187218 --> 1.056224).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3124332
	speed: 0.0980s/iter; left time: 2497.1442s
	iters: 200, epoch: 3 | loss: 0.3091004
	speed: 0.0207s/iter; left time: 525.5761s
Epoch: 3 cost time: 6.569576740264893
Epoch: 3, Steps: 261 | Train Loss: 0.3183763 Vali Loss: 1.0124341 Test Loss: 0.4506947
Validation loss decreased (1.056224 --> 1.012434).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3147825
	speed: 0.1091s/iter; left time: 2751.2523s
	iters: 200, epoch: 4 | loss: 0.2999707
	speed: 0.0312s/iter; left time: 783.3850s
Epoch: 4 cost time: 8.180460929870605
Epoch: 4, Steps: 261 | Train Loss: 0.3035355 Vali Loss: 0.9929734 Test Loss: 0.4402006
Validation loss decreased (1.012434 --> 0.992973).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2987837
	speed: 0.1197s/iter; left time: 2986.2872s
	iters: 200, epoch: 5 | loss: 0.3113392
	speed: 0.0312s/iter; left time: 775.7062s
Epoch: 5 cost time: 8.552960872650146
Epoch: 5, Steps: 261 | Train Loss: 0.2968089 Vali Loss: 0.9820153 Test Loss: 0.4356817
Validation loss decreased (0.992973 --> 0.982015).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2966205
	speed: 0.1218s/iter; left time: 3006.8367s
	iters: 200, epoch: 6 | loss: 0.3007990
	speed: 0.0250s/iter; left time: 613.9768s
Epoch: 6 cost time: 8.59837031364441
Epoch: 6, Steps: 261 | Train Loss: 0.2929949 Vali Loss: 0.9763654 Test Loss: 0.4332515
Validation loss decreased (0.982015 --> 0.976365).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2925972
	speed: 0.1250s/iter; left time: 3054.0447s
	iters: 200, epoch: 7 | loss: 0.3071028
	speed: 0.0384s/iter; left time: 935.6010s
Epoch: 7 cost time: 8.30456805229187
Epoch: 7, Steps: 261 | Train Loss: 0.2906362 Vali Loss: 0.9726040 Test Loss: 0.4316428
Validation loss decreased (0.976365 --> 0.972604).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2795117
	speed: 0.0999s/iter; left time: 2415.3893s
	iters: 200, epoch: 8 | loss: 0.2804104
	speed: 0.0206s/iter; left time: 496.3690s
Epoch: 8 cost time: 6.056993007659912
Epoch: 8, Steps: 261 | Train Loss: 0.2890409 Vali Loss: 0.9715002 Test Loss: 0.4307527
Validation loss decreased (0.972604 --> 0.971500).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3067071
	speed: 0.0967s/iter; left time: 2311.6474s
	iters: 200, epoch: 9 | loss: 0.2801845
	speed: 0.0198s/iter; left time: 470.9896s
Epoch: 9 cost time: 5.957756042480469
Epoch: 9, Steps: 261 | Train Loss: 0.2880034 Vali Loss: 0.9685792 Test Loss: 0.4304478
Validation loss decreased (0.971500 --> 0.968579).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2773716
	speed: 0.0973s/iter; left time: 2300.7361s
	iters: 200, epoch: 10 | loss: 0.2745283
	speed: 0.0197s/iter; left time: 464.2489s
Epoch: 10 cost time: 6.082082033157349
Epoch: 10, Steps: 261 | Train Loss: 0.2872880 Vali Loss: 0.9672341 Test Loss: 0.4298942
Validation loss decreased (0.968579 --> 0.967234).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2954271
	speed: 0.0980s/iter; left time: 2292.9422s
	iters: 200, epoch: 11 | loss: 0.2750217
	speed: 0.0242s/iter; left time: 564.0813s
Epoch: 11 cost time: 7.0806238651275635
Epoch: 11, Steps: 261 | Train Loss: 0.2867039 Vali Loss: 0.9665319 Test Loss: 0.4298880
Validation loss decreased (0.967234 --> 0.966532).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2819147
	speed: 0.1146s/iter; left time: 2650.6424s
	iters: 200, epoch: 12 | loss: 0.2757725
	speed: 0.0483s/iter; left time: 1111.9958s
Epoch: 12 cost time: 10.265098571777344
Epoch: 12, Steps: 261 | Train Loss: 0.2863549 Vali Loss: 0.9667273 Test Loss: 0.4295472
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2805583
	speed: 0.1172s/iter; left time: 2680.2408s
	iters: 200, epoch: 13 | loss: 0.2709991
	speed: 0.0254s/iter; left time: 577.8909s
Epoch: 13 cost time: 8.249889373779297
Epoch: 13, Steps: 261 | Train Loss: 0.2860959 Vali Loss: 0.9658935 Test Loss: 0.4296897
Validation loss decreased (0.966532 --> 0.965894).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2802640
	speed: 0.1284s/iter; left time: 2902.3196s
	iters: 200, epoch: 14 | loss: 0.2853718
	speed: 0.0280s/iter; left time: 629.1652s
Epoch: 14 cost time: 7.543641805648804
Epoch: 14, Steps: 261 | Train Loss: 0.2858512 Vali Loss: 0.9662389 Test Loss: 0.4297909
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2784280
	speed: 0.1100s/iter; left time: 2457.9774s
	iters: 200, epoch: 15 | loss: 0.2806562
	speed: 0.0328s/iter; left time: 730.4288s
Epoch: 15 cost time: 8.309918403625488
Epoch: 15, Steps: 261 | Train Loss: 0.2857702 Vali Loss: 0.9667042 Test Loss: 0.4293807
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2757038
	speed: 0.1229s/iter; left time: 2714.0150s
	iters: 200, epoch: 16 | loss: 0.2795266
	speed: 0.0409s/iter; left time: 900.0338s
Epoch: 16 cost time: 11.330374002456665
Epoch: 16, Steps: 261 | Train Loss: 0.2855336 Vali Loss: 0.9657090 Test Loss: 0.4292385
Validation loss decreased (0.965894 --> 0.965709).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2943424
	speed: 0.1413s/iter; left time: 3084.2880s
	iters: 200, epoch: 17 | loss: 0.2988829
	speed: 0.0318s/iter; left time: 690.8680s
Epoch: 17 cost time: 9.086883544921875
Epoch: 17, Steps: 261 | Train Loss: 0.2855434 Vali Loss: 0.9661902 Test Loss: 0.4293467
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2907587
	speed: 0.1559s/iter; left time: 3362.6315s
	iters: 200, epoch: 18 | loss: 0.2868058
	speed: 0.0343s/iter; left time: 736.5208s
Epoch: 18 cost time: 8.097259759902954
Epoch: 18, Steps: 261 | Train Loss: 0.2854546 Vali Loss: 0.9662048 Test Loss: 0.4294316
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2895633
	speed: 0.1068s/iter; left time: 2274.7287s
	iters: 200, epoch: 19 | loss: 0.2764019
	speed: 0.0211s/iter; left time: 446.4473s
Epoch: 19 cost time: 6.3098883628845215
Epoch: 19, Steps: 261 | Train Loss: 0.2854345 Vali Loss: 0.9656391 Test Loss: 0.4293810
Validation loss decreased (0.965709 --> 0.965639).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2846920
	speed: 0.0985s/iter; left time: 2072.3699s
	iters: 200, epoch: 20 | loss: 0.2859427
	speed: 0.0270s/iter; left time: 565.8953s
Epoch: 20 cost time: 6.877564191818237
Epoch: 20, Steps: 261 | Train Loss: 0.2854596 Vali Loss: 0.9647286 Test Loss: 0.4295472
Validation loss decreased (0.965639 --> 0.964729).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2783338
	speed: 0.0995s/iter; left time: 2067.9248s
	iters: 200, epoch: 21 | loss: 0.2992482
	speed: 0.0258s/iter; left time: 534.3156s
Epoch: 21 cost time: 6.570015907287598
Epoch: 21, Steps: 261 | Train Loss: 0.2853747 Vali Loss: 0.9660122 Test Loss: 0.4294309
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2632010
	speed: 0.1093s/iter; left time: 2241.9103s
	iters: 200, epoch: 22 | loss: 0.2871776
	speed: 0.0307s/iter; left time: 627.4844s
Epoch: 22 cost time: 7.7340357303619385
Epoch: 22, Steps: 261 | Train Loss: 0.2853907 Vali Loss: 0.9648827 Test Loss: 0.4295326
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2902836
	speed: 0.1047s/iter; left time: 2120.2723s
	iters: 200, epoch: 23 | loss: 0.2692233
	speed: 0.0434s/iter; left time: 875.7700s
Epoch: 23 cost time: 9.533342599868774
Epoch: 23, Steps: 261 | Train Loss: 0.2854195 Vali Loss: 0.9654461 Test Loss: 0.4293918
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2804740
	speed: 0.1362s/iter; left time: 2723.0421s
	iters: 200, epoch: 24 | loss: 0.2676335
	speed: 0.0324s/iter; left time: 645.1651s
Epoch: 24 cost time: 8.547525882720947
Epoch: 24, Steps: 261 | Train Loss: 0.2853816 Vali Loss: 0.9658011 Test Loss: 0.4294443
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2755840
	speed: 0.1505s/iter; left time: 2970.2842s
	iters: 200, epoch: 25 | loss: 0.2919967
	speed: 0.0298s/iter; left time: 584.7535s
Epoch: 25 cost time: 9.408994913101196
Epoch: 25, Steps: 261 | Train Loss: 0.2854242 Vali Loss: 0.9645543 Test Loss: 0.4294438
Validation loss decreased (0.964729 --> 0.964554).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2684236
	speed: 0.1091s/iter; left time: 2124.5693s
	iters: 200, epoch: 26 | loss: 0.2704538
	speed: 0.0280s/iter; left time: 543.2085s
Epoch: 26 cost time: 7.529189586639404
Epoch: 26, Steps: 261 | Train Loss: 0.2853812 Vali Loss: 0.9650761 Test Loss: 0.4295636
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2766006
	speed: 0.1046s/iter; left time: 2010.5065s
	iters: 200, epoch: 27 | loss: 0.2938227
	speed: 0.0281s/iter; left time: 537.1862s
Epoch: 27 cost time: 7.161505937576294
Epoch: 27, Steps: 261 | Train Loss: 0.2853580 Vali Loss: 0.9639539 Test Loss: 0.4296252
Validation loss decreased (0.964554 --> 0.963954).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2730053
	speed: 0.1101s/iter; left time: 2086.7289s
	iters: 200, epoch: 28 | loss: 0.2897183
	speed: 0.0365s/iter; left time: 688.3880s
Epoch: 28 cost time: 9.984463453292847
Epoch: 28, Steps: 261 | Train Loss: 0.2853908 Vali Loss: 0.9651009 Test Loss: 0.4295616
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2794893
	speed: 0.1376s/iter; left time: 2572.7353s
	iters: 200, epoch: 29 | loss: 0.2774599
	speed: 0.0423s/iter; left time: 787.0474s
Epoch: 29 cost time: 10.42292046546936
Epoch: 29, Steps: 261 | Train Loss: 0.2853197 Vali Loss: 0.9661933 Test Loss: 0.4294940
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3058025
	speed: 0.1314s/iter; left time: 2422.6223s
	iters: 200, epoch: 30 | loss: 0.2971370
	speed: 0.0385s/iter; left time: 706.3316s
Epoch: 30 cost time: 9.278543472290039
Epoch: 30, Steps: 261 | Train Loss: 0.2853687 Vali Loss: 0.9653279 Test Loss: 0.4296614
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2909997
	speed: 0.1227s/iter; left time: 2229.5324s
	iters: 200, epoch: 31 | loss: 0.2713681
	speed: 0.0198s/iter; left time: 357.6317s
Epoch: 31 cost time: 6.29834771156311
Epoch: 31, Steps: 261 | Train Loss: 0.2853474 Vali Loss: 0.9653270 Test Loss: 0.4295498
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2873244
	speed: 0.1013s/iter; left time: 1813.8735s
	iters: 200, epoch: 32 | loss: 0.2708930
	speed: 0.0224s/iter; left time: 398.0756s
Epoch: 32 cost time: 6.520336151123047
Epoch: 32, Steps: 261 | Train Loss: 0.2853658 Vali Loss: 0.9641833 Test Loss: 0.4294885
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3138183
	speed: 0.1039s/iter; left time: 1834.0422s
	iters: 200, epoch: 33 | loss: 0.2722588
	speed: 0.0211s/iter; left time: 370.2627s
Epoch: 33 cost time: 6.720807790756226
Epoch: 33, Steps: 261 | Train Loss: 0.2853429 Vali Loss: 0.9655675 Test Loss: 0.4296025
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2980965
	speed: 0.1301s/iter; left time: 2262.0135s
	iters: 200, epoch: 34 | loss: 0.3063489
	speed: 0.0409s/iter; left time: 707.6852s
Epoch: 34 cost time: 9.855287313461304
Epoch: 34, Steps: 261 | Train Loss: 0.2853705 Vali Loss: 0.9656294 Test Loss: 0.4296072
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2850975
	speed: 0.1323s/iter; left time: 2266.6318s
	iters: 200, epoch: 35 | loss: 0.2759851
	speed: 0.0262s/iter; left time: 446.0393s
Epoch: 35 cost time: 7.7675621509552
Epoch: 35, Steps: 261 | Train Loss: 0.2853834 Vali Loss: 0.9654897 Test Loss: 0.4294379
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2777446
	speed: 0.1442s/iter; left time: 2432.6205s
	iters: 200, epoch: 36 | loss: 0.2807885
	speed: 0.0266s/iter; left time: 445.8913s
Epoch: 36 cost time: 9.278326988220215
Epoch: 36, Steps: 261 | Train Loss: 0.2853451 Vali Loss: 0.9646140 Test Loss: 0.4294845
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3156045
	speed: 0.1644s/iter; left time: 2729.0756s
	iters: 200, epoch: 37 | loss: 0.2847739
	speed: 0.0226s/iter; left time: 372.4916s
Epoch: 37 cost time: 7.215516805648804
Epoch: 37, Steps: 261 | Train Loss: 0.2853432 Vali Loss: 0.9651155 Test Loss: 0.4294505
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2756418
	speed: 0.1030s/iter; left time: 1683.9206s
	iters: 200, epoch: 38 | loss: 0.2976044
	speed: 0.0234s/iter; left time: 380.5336s
Epoch: 38 cost time: 6.564831495285034
Epoch: 38, Steps: 261 | Train Loss: 0.2854013 Vali Loss: 0.9652011 Test Loss: 0.4295902
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2912727
	speed: 0.0990s/iter; left time: 1593.0207s
	iters: 200, epoch: 39 | loss: 0.2846223
	speed: 0.0283s/iter; left time: 452.8667s
Epoch: 39 cost time: 7.484665632247925
Epoch: 39, Steps: 261 | Train Loss: 0.2853297 Vali Loss: 0.9644158 Test Loss: 0.4295222
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2842311
	speed: 0.1112s/iter; left time: 1759.8721s
	iters: 200, epoch: 40 | loss: 0.2743140
	speed: 0.0295s/iter; left time: 464.0080s
Epoch: 40 cost time: 8.90748906135559
Epoch: 40, Steps: 261 | Train Loss: 0.2853732 Vali Loss: 0.9651300 Test Loss: 0.4296025
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2968847
	speed: 0.1403s/iter; left time: 2183.1442s
	iters: 200, epoch: 41 | loss: 0.3042058
	speed: 0.0285s/iter; left time: 441.0990s
Epoch: 41 cost time: 8.464911699295044
Epoch: 41, Steps: 261 | Train Loss: 0.2854173 Vali Loss: 0.9655386 Test Loss: 0.4296297
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2763943
	speed: 0.1255s/iter; left time: 1920.9115s
	iters: 200, epoch: 42 | loss: 0.2619271
	speed: 0.0290s/iter; left time: 441.5474s
Epoch: 42 cost time: 9.116388082504272
Epoch: 42, Steps: 261 | Train Loss: 0.2853579 Vali Loss: 0.9652597 Test Loss: 0.4294719
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2839063
	speed: 0.1326s/iter; left time: 1993.4796s
	iters: 200, epoch: 43 | loss: 0.2757142
	speed: 0.0204s/iter; left time: 305.2042s
Epoch: 43 cost time: 7.187063932418823
Epoch: 43, Steps: 261 | Train Loss: 0.2853718 Vali Loss: 0.9650919 Test Loss: 0.4294791
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2752121
	speed: 0.1276s/iter; left time: 1885.7040s
	iters: 200, epoch: 44 | loss: 0.2972099
	speed: 0.0223s/iter; left time: 327.1012s
Epoch: 44 cost time: 7.153339147567749
Epoch: 44, Steps: 261 | Train Loss: 0.2853653 Vali Loss: 0.9655560 Test Loss: 0.4295358
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2607870
	speed: 0.0948s/iter; left time: 1376.9312s
	iters: 200, epoch: 45 | loss: 0.2865994
	speed: 0.0190s/iter; left time: 273.4987s
Epoch: 45 cost time: 6.1102516651153564
Epoch: 45, Steps: 261 | Train Loss: 0.2854474 Vali Loss: 0.9660430 Test Loss: 0.4295362
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2995588
	speed: 0.1155s/iter; left time: 1647.0379s
	iters: 200, epoch: 46 | loss: 0.2617304
	speed: 0.0263s/iter; left time: 372.1728s
Epoch: 46 cost time: 8.044041872024536
Epoch: 46, Steps: 261 | Train Loss: 0.2853996 Vali Loss: 0.9647847 Test Loss: 0.4295250
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2668787
	speed: 0.1082s/iter; left time: 1513.7453s
	iters: 200, epoch: 47 | loss: 0.2796095
	speed: 0.0356s/iter; left time: 494.7377s
Epoch: 47 cost time: 7.954260587692261
Epoch: 47, Steps: 261 | Train Loss: 0.2853072 Vali Loss: 0.9653791 Test Loss: 0.4295276
EarlyStopping counter: 20 out of 20
Early stopping
train 33481
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=34, out_features=102, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3107328.0
params:  3570.0
Trainable parameters:  3570
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4326026
	speed: 0.0261s/iter; left time: 677.7435s
	iters: 200, epoch: 1 | loss: 0.4109628
	speed: 0.0313s/iter; left time: 810.9447s
Epoch: 1 cost time: 7.9300360679626465
Epoch: 1, Steps: 261 | Train Loss: 0.4151580 Vali Loss: 0.9625827 Test Loss: 0.4286565
Validation loss decreased (inf --> 0.962583).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4404701
	speed: 0.1568s/iter; left time: 4036.4197s
	iters: 200, epoch: 2 | loss: 0.4386552
	speed: 0.0282s/iter; left time: 721.9982s
Epoch: 2 cost time: 9.090208530426025
Epoch: 2, Steps: 261 | Train Loss: 0.4148190 Vali Loss: 0.9620999 Test Loss: 0.4283006
Validation loss decreased (0.962583 --> 0.962100).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4050130
	speed: 0.1451s/iter; left time: 3697.9049s
	iters: 200, epoch: 3 | loss: 0.4495404
	speed: 0.0316s/iter; left time: 802.6329s
Epoch: 3 cost time: 9.235454320907593
Epoch: 3, Steps: 261 | Train Loss: 0.4145253 Vali Loss: 0.9630080 Test Loss: 0.4280959
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4049311
	speed: 0.1024s/iter; left time: 2583.3316s
	iters: 200, epoch: 4 | loss: 0.3858369
	speed: 0.0245s/iter; left time: 614.6654s
Epoch: 4 cost time: 6.81008768081665
Epoch: 4, Steps: 261 | Train Loss: 0.4145532 Vali Loss: 0.9613742 Test Loss: 0.4285427
Validation loss decreased (0.962100 --> 0.961374).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4345994
	speed: 0.1119s/iter; left time: 2791.5025s
	iters: 200, epoch: 5 | loss: 0.4059480
	speed: 0.0263s/iter; left time: 653.1548s
Epoch: 5 cost time: 7.038922071456909
Epoch: 5, Steps: 261 | Train Loss: 0.4144623 Vali Loss: 0.9614457 Test Loss: 0.4281769
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3980004
	speed: 0.1167s/iter; left time: 2881.4758s
	iters: 200, epoch: 6 | loss: 0.4049840
	speed: 0.0206s/iter; left time: 507.8902s
Epoch: 6 cost time: 6.442635774612427
Epoch: 6, Steps: 261 | Train Loss: 0.4144332 Vali Loss: 0.9605886 Test Loss: 0.4280814
Validation loss decreased (0.961374 --> 0.960589).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4203860
	speed: 0.1333s/iter; left time: 3258.3678s
	iters: 200, epoch: 7 | loss: 0.4263527
	speed: 0.0350s/iter; left time: 851.3238s
Epoch: 7 cost time: 10.589181184768677
Epoch: 7, Steps: 261 | Train Loss: 0.4145357 Vali Loss: 0.9612244 Test Loss: 0.4282575
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4306992
	speed: 0.1342s/iter; left time: 3245.1109s
	iters: 200, epoch: 8 | loss: 0.3986079
	speed: 0.0337s/iter; left time: 812.0684s
Epoch: 8 cost time: 9.177711009979248
Epoch: 8, Steps: 261 | Train Loss: 0.4143151 Vali Loss: 0.9604985 Test Loss: 0.4285563
Validation loss decreased (0.960589 --> 0.960498).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4552828
	speed: 0.1110s/iter; left time: 2653.3599s
	iters: 200, epoch: 9 | loss: 0.4097984
	speed: 0.0282s/iter; left time: 670.5834s
Epoch: 9 cost time: 7.551759958267212
Epoch: 9, Steps: 261 | Train Loss: 0.4143534 Vali Loss: 0.9606120 Test Loss: 0.4280013
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4006347
	speed: 0.1350s/iter; left time: 3192.9101s
	iters: 200, epoch: 10 | loss: 0.3967119
	speed: 0.0238s/iter; left time: 559.9506s
Epoch: 10 cost time: 7.974313020706177
Epoch: 10, Steps: 261 | Train Loss: 0.4143719 Vali Loss: 0.9607145 Test Loss: 0.4280763
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4446963
	speed: 0.1026s/iter; left time: 2400.0643s
	iters: 200, epoch: 11 | loss: 0.3898000
	speed: 0.0226s/iter; left time: 525.6047s
Epoch: 11 cost time: 6.6802732944488525
Epoch: 11, Steps: 261 | Train Loss: 0.4144054 Vali Loss: 0.9617968 Test Loss: 0.4278297
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3841196
	speed: 0.1142s/iter; left time: 2642.3278s
	iters: 200, epoch: 12 | loss: 0.4094375
	speed: 0.0210s/iter; left time: 483.0063s
Epoch: 12 cost time: 7.754773139953613
Epoch: 12, Steps: 261 | Train Loss: 0.4142117 Vali Loss: 0.9614019 Test Loss: 0.4284103
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4032536
	speed: 0.1215s/iter; left time: 2779.6480s
	iters: 200, epoch: 13 | loss: 0.4032438
	speed: 0.0202s/iter; left time: 459.2626s
Epoch: 13 cost time: 8.200276136398315
Epoch: 13, Steps: 261 | Train Loss: 0.4143810 Vali Loss: 0.9622574 Test Loss: 0.4283723
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3919121
	speed: 0.1152s/iter; left time: 2605.3663s
	iters: 200, epoch: 14 | loss: 0.3825487
	speed: 0.0223s/iter; left time: 502.9048s
Epoch: 14 cost time: 6.309329032897949
Epoch: 14, Steps: 261 | Train Loss: 0.4143182 Vali Loss: 0.9613301 Test Loss: 0.4283065
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3843363
	speed: 0.0969s/iter; left time: 2166.3430s
	iters: 200, epoch: 15 | loss: 0.3936076
	speed: 0.0237s/iter; left time: 526.9831s
Epoch: 15 cost time: 7.4177305698394775
Epoch: 15, Steps: 261 | Train Loss: 0.4142841 Vali Loss: 0.9616442 Test Loss: 0.4283600
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3865357
	speed: 0.1222s/iter; left time: 2699.2912s
	iters: 200, epoch: 16 | loss: 0.4103552
	speed: 0.0336s/iter; left time: 738.8531s
Epoch: 16 cost time: 9.007525205612183
Epoch: 16, Steps: 261 | Train Loss: 0.4142438 Vali Loss: 0.9606326 Test Loss: 0.4285814
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3932956
	speed: 0.1487s/iter; left time: 3244.9463s
	iters: 200, epoch: 17 | loss: 0.3969303
	speed: 0.0302s/iter; left time: 656.3768s
Epoch: 17 cost time: 9.622858762741089
Epoch: 17, Steps: 261 | Train Loss: 0.4143240 Vali Loss: 0.9610582 Test Loss: 0.4283476
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4016350
	speed: 0.1478s/iter; left time: 3186.5903s
	iters: 200, epoch: 18 | loss: 0.4286429
	speed: 0.0291s/iter; left time: 624.4246s
Epoch: 18 cost time: 8.490134477615356
Epoch: 18, Steps: 261 | Train Loss: 0.4142861 Vali Loss: 0.9610981 Test Loss: 0.4282574
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3828659
	speed: 0.1200s/iter; left time: 2557.3337s
	iters: 200, epoch: 19 | loss: 0.4059401
	speed: 0.0277s/iter; left time: 587.1885s
Epoch: 19 cost time: 7.272625684738159
Epoch: 19, Steps: 261 | Train Loss: 0.4141453 Vali Loss: 0.9611710 Test Loss: 0.4286056
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4431317
	speed: 0.0957s/iter; left time: 2013.8397s
	iters: 200, epoch: 20 | loss: 0.3857919
	speed: 0.0221s/iter; left time: 462.8693s
Epoch: 20 cost time: 6.032563209533691
Epoch: 20, Steps: 261 | Train Loss: 0.4142617 Vali Loss: 0.9618435 Test Loss: 0.4282507
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4204270
	speed: 0.1068s/iter; left time: 2218.9047s
	iters: 200, epoch: 21 | loss: 0.4141341
	speed: 0.0248s/iter; left time: 511.9770s
Epoch: 21 cost time: 6.6406755447387695
Epoch: 21, Steps: 261 | Train Loss: 0.4141721 Vali Loss: 0.9605982 Test Loss: 0.4281448
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4241452
	speed: 0.1061s/iter; left time: 2176.5916s
	iters: 200, epoch: 22 | loss: 0.4302859
	speed: 0.0291s/iter; left time: 594.5335s
Epoch: 22 cost time: 8.471387147903442
Epoch: 22, Steps: 261 | Train Loss: 0.4142030 Vali Loss: 0.9616077 Test Loss: 0.4285097
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4291989
	speed: 0.1101s/iter; left time: 2230.7092s
	iters: 200, epoch: 23 | loss: 0.4206446
	speed: 0.0199s/iter; left time: 400.3235s
Epoch: 23 cost time: 6.238877773284912
Epoch: 23, Steps: 261 | Train Loss: 0.4142156 Vali Loss: 0.9609710 Test Loss: 0.4284614
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4437291
	speed: 0.1214s/iter; left time: 2428.1791s
	iters: 200, epoch: 24 | loss: 0.4076813
	speed: 0.0200s/iter; left time: 398.6424s
Epoch: 24 cost time: 7.4145801067352295
Epoch: 24, Steps: 261 | Train Loss: 0.4141155 Vali Loss: 0.9598027 Test Loss: 0.4283946
Validation loss decreased (0.960498 --> 0.959803).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4317066
	speed: 0.1172s/iter; left time: 2312.5145s
	iters: 200, epoch: 25 | loss: 0.3985994
	speed: 0.0345s/iter; left time: 677.6930s
Epoch: 25 cost time: 9.093733072280884
Epoch: 25, Steps: 261 | Train Loss: 0.4142640 Vali Loss: 0.9618291 Test Loss: 0.4283637
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3935950
	speed: 0.1520s/iter; left time: 2959.3784s
	iters: 200, epoch: 26 | loss: 0.4058575
	speed: 0.0395s/iter; left time: 766.0552s
Epoch: 26 cost time: 10.560039758682251
Epoch: 26, Steps: 261 | Train Loss: 0.4141661 Vali Loss: 0.9608580 Test Loss: 0.4284230
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3889222
	speed: 0.1553s/iter; left time: 2984.0956s
	iters: 200, epoch: 27 | loss: 0.3953016
	speed: 0.0294s/iter; left time: 561.3212s
Epoch: 27 cost time: 9.473459243774414
Epoch: 27, Steps: 261 | Train Loss: 0.4141770 Vali Loss: 0.9607795 Test Loss: 0.4281986
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4087574
	speed: 0.1078s/iter; left time: 2043.5326s
	iters: 200, epoch: 28 | loss: 0.4119366
	speed: 0.0257s/iter; left time: 484.0061s
Epoch: 28 cost time: 6.88462495803833
Epoch: 28, Steps: 261 | Train Loss: 0.4141967 Vali Loss: 0.9621646 Test Loss: 0.4282802
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4222802
	speed: 0.1035s/iter; left time: 1934.2109s
	iters: 200, epoch: 29 | loss: 0.4516707
	speed: 0.0243s/iter; left time: 451.6858s
Epoch: 29 cost time: 6.841002464294434
Epoch: 29, Steps: 261 | Train Loss: 0.4141225 Vali Loss: 0.9611173 Test Loss: 0.4281538
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4012909
	speed: 0.1182s/iter; left time: 2178.4678s
	iters: 200, epoch: 30 | loss: 0.3958732
	speed: 0.0318s/iter; left time: 583.8435s
Epoch: 30 cost time: 8.996276378631592
Epoch: 30, Steps: 261 | Train Loss: 0.4141572 Vali Loss: 0.9609174 Test Loss: 0.4285563
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3952969
	speed: 0.1421s/iter; left time: 2582.9545s
	iters: 200, epoch: 31 | loss: 0.4437022
	speed: 0.0330s/iter; left time: 596.8226s
Epoch: 31 cost time: 8.34116816520691
Epoch: 31, Steps: 261 | Train Loss: 0.4141316 Vali Loss: 0.9608997 Test Loss: 0.4283195
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4414650
	speed: 0.1307s/iter; left time: 2340.1846s
	iters: 200, epoch: 32 | loss: 0.3940996
	speed: 0.0336s/iter; left time: 597.7053s
Epoch: 32 cost time: 8.297350883483887
Epoch: 32, Steps: 261 | Train Loss: 0.4142836 Vali Loss: 0.9610078 Test Loss: 0.4283969
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4269347
	speed: 0.1289s/iter; left time: 2274.9881s
	iters: 200, epoch: 33 | loss: 0.4348533
	speed: 0.0284s/iter; left time: 497.9971s
Epoch: 33 cost time: 8.559709787368774
Epoch: 33, Steps: 261 | Train Loss: 0.4142334 Vali Loss: 0.9603970 Test Loss: 0.4283741
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3836860
	speed: 0.1060s/iter; left time: 1843.8049s
	iters: 200, epoch: 34 | loss: 0.4110607
	speed: 0.0202s/iter; left time: 349.4302s
Epoch: 34 cost time: 6.247281312942505
Epoch: 34, Steps: 261 | Train Loss: 0.4141058 Vali Loss: 0.9606677 Test Loss: 0.4282621
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4088787
	speed: 0.0958s/iter; left time: 1639.9474s
	iters: 200, epoch: 35 | loss: 0.3994164
	speed: 0.0262s/iter; left time: 446.4994s
Epoch: 35 cost time: 6.802202939987183
Epoch: 35, Steps: 261 | Train Loss: 0.4141360 Vali Loss: 0.9611686 Test Loss: 0.4283437
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4058128
	speed: 0.1346s/iter; left time: 2270.0399s
	iters: 200, epoch: 36 | loss: 0.4004541
	speed: 0.0254s/iter; left time: 425.5064s
Epoch: 36 cost time: 7.626570463180542
Epoch: 36, Steps: 261 | Train Loss: 0.4140764 Vali Loss: 0.9612472 Test Loss: 0.4283746
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4613369
	speed: 0.1090s/iter; left time: 1809.4285s
	iters: 200, epoch: 37 | loss: 0.4021004
	speed: 0.0225s/iter; left time: 370.9224s
Epoch: 37 cost time: 7.037603378295898
Epoch: 37, Steps: 261 | Train Loss: 0.4142883 Vali Loss: 0.9615281 Test Loss: 0.4283787
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4227788
	speed: 0.1093s/iter; left time: 1787.1284s
	iters: 200, epoch: 38 | loss: 0.4109193
	speed: 0.0255s/iter; left time: 414.5569s
Epoch: 38 cost time: 6.704108715057373
Epoch: 38, Steps: 261 | Train Loss: 0.4140856 Vali Loss: 0.9606046 Test Loss: 0.4283133
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3755684
	speed: 0.1342s/iter; left time: 2158.7463s
	iters: 200, epoch: 39 | loss: 0.4124291
	speed: 0.0202s/iter; left time: 322.0653s
Epoch: 39 cost time: 7.767296552658081
Epoch: 39, Steps: 261 | Train Loss: 0.4140707 Vali Loss: 0.9611353 Test Loss: 0.4283584
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.4393675
	speed: 0.1060s/iter; left time: 1677.3257s
	iters: 200, epoch: 40 | loss: 0.4413643
	speed: 0.0238s/iter; left time: 374.0613s
Epoch: 40 cost time: 6.497216463088989
Epoch: 40, Steps: 261 | Train Loss: 0.4140768 Vali Loss: 0.9613380 Test Loss: 0.4283055
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.4335046
	speed: 0.0964s/iter; left time: 1499.8377s
	iters: 200, epoch: 41 | loss: 0.4197786
	speed: 0.0270s/iter; left time: 416.8443s
Epoch: 41 cost time: 6.894484996795654
Epoch: 41, Steps: 261 | Train Loss: 0.4142039 Vali Loss: 0.9603093 Test Loss: 0.4283924
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.4212067
	speed: 0.1070s/iter; left time: 1637.0340s
	iters: 200, epoch: 42 | loss: 0.4064588
	speed: 0.0236s/iter; left time: 358.8353s
Epoch: 42 cost time: 7.538923263549805
Epoch: 42, Steps: 261 | Train Loss: 0.4141372 Vali Loss: 0.9610106 Test Loss: 0.4284402
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.4479905
	speed: 0.1373s/iter; left time: 2064.8460s
	iters: 200, epoch: 43 | loss: 0.3815065
	speed: 0.0338s/iter; left time: 504.3593s
Epoch: 43 cost time: 9.19343614578247
Epoch: 43, Steps: 261 | Train Loss: 0.4142163 Vali Loss: 0.9612782 Test Loss: 0.4283864
EarlyStopping counter: 19 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.4132897
	speed: 0.1229s/iter; left time: 1816.2930s
	iters: 200, epoch: 44 | loss: 0.3837208
	speed: 0.0198s/iter; left time: 291.1669s
Epoch: 44 cost time: 6.334442377090454
Epoch: 44, Steps: 261 | Train Loss: 0.4141716 Vali Loss: 0.9616602 Test Loss: 0.4284201
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_360_720_FITS_ETTm1_ftM_sl360_ll48_pl720_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.4280654788017273, mae:0.4168587327003479, rse:0.6224806308746338, corr:[0.52642304 0.53144205 0.534349   0.53509086 0.5345122  0.53370595
 0.5333286  0.53354055 0.5341186  0.5347858  0.53537834 0.5355118
 0.53518826 0.5345411  0.5336868  0.53266454 0.5316106  0.5306201
 0.52952147 0.5283076  0.52692413 0.5255979  0.52424604 0.5229888
 0.5218357  0.52073264 0.51979965 0.5191547  0.5187624  0.5184266
 0.5182673  0.5183639  0.51860565 0.518916   0.5191884  0.5194604
 0.5196765  0.51975083 0.5196527  0.5193563  0.51891357 0.51835215
 0.5177323  0.5172165  0.51688164 0.5167811  0.5169388  0.5171799
 0.51730794 0.51728386 0.5170499  0.51664937 0.51626676 0.5159784
 0.51585746 0.5159292  0.5161062  0.51630884 0.5164767  0.5164477
 0.51630455 0.51602286 0.5156979  0.51535684 0.5151765  0.5152417
 0.5154929  0.51581335 0.51622945 0.5165876  0.51682365 0.5168928
 0.5168746  0.5168432  0.5167978  0.516728   0.5166413  0.5165608
 0.5164652  0.5163424  0.51618326 0.5159816  0.5156918  0.51527035
 0.51486146 0.514455   0.51416326 0.5139698  0.5138671  0.5139065
 0.5140585  0.51416653 0.5141105  0.513851   0.5133864  0.5127563
 0.5121122  0.5115879  0.5112052  0.5109634  0.5109053  0.51101613
 0.5112289  0.5113868  0.5115746  0.51183045 0.512062   0.51238406
 0.5126784  0.5130253  0.5133103  0.51347584 0.5134355  0.51331216
 0.51313376 0.51298493 0.51286674 0.51280636 0.5127698  0.51286536
 0.51299864 0.51298577 0.51278096 0.51253283 0.51224643 0.5118939
 0.5115457  0.5112888  0.511141   0.5111161  0.5111696  0.51121914
 0.5112365  0.51112455 0.51091874 0.5106137  0.5102486  0.50982064
 0.5094289  0.5091253  0.50893176 0.5089101  0.5090127  0.5091776
 0.5092973  0.5093096  0.5091757  0.50896704 0.50880575 0.50866544
 0.50859904 0.5086955  0.5088568  0.50900614 0.5090966  0.5091498
 0.50913566 0.5090849  0.5089923  0.5089443  0.50902796 0.5092328
 0.50954366 0.5098988  0.5102923  0.5106532  0.51089627 0.51106924
 0.5111721  0.5112546  0.51139474 0.5116294  0.511878   0.5121037
 0.5122561  0.5123248  0.5122881  0.5121644  0.51190287 0.51157284
 0.51119965 0.5109121  0.51065624 0.5104955  0.510417   0.5104097
 0.5104309  0.5104627  0.510466   0.510425   0.5102323  0.50990385
 0.50948316 0.50910217 0.5087504  0.5083239  0.5078495  0.5074969
 0.5071954  0.5068617  0.5065536  0.50626445 0.5059438  0.50563866
 0.50537556 0.5050547  0.5047495  0.50439763 0.5040424  0.5037092
 0.5033152  0.5029121  0.5024767  0.50209534 0.5017305  0.5014475
 0.50121236 0.50095636 0.5005962  0.5002759  0.4999515  0.49963945
 0.49946138 0.4994039  0.4994514  0.49957797 0.49977574 0.4999359
 0.50003386 0.50006616 0.4999708  0.49972132 0.49939948 0.49902195
 0.49872562 0.49855593 0.4984637  0.4985258  0.49865288 0.49876162
 0.4987556  0.49858612 0.498324   0.4980153  0.4977105  0.4975232
 0.49746454 0.49751216 0.4976415  0.4978194  0.49792883 0.49798632
 0.4979075  0.49780008 0.49766907 0.4975652  0.4974671  0.49748576
 0.4975791  0.49776298 0.4980207  0.49830168 0.49848655 0.498679
 0.49885702 0.49904236 0.49920204 0.49942166 0.49964362 0.49977103
 0.49984613 0.4998568  0.49979338 0.49967825 0.49948478 0.499324
 0.49917045 0.49912944 0.49907207 0.49906316 0.49903646 0.49897847
 0.49893284 0.49880743 0.49860322 0.4982731  0.49780455 0.4972119
 0.4964992  0.49582815 0.4953014  0.494761   0.49428713 0.49389708
 0.49358115 0.49321368 0.49288413 0.49254423 0.49222755 0.49189958
 0.49157396 0.49126506 0.49099982 0.49079657 0.49062294 0.49047354
 0.49039096 0.4903062  0.490257   0.49027744 0.49037415 0.4904882
 0.4906102  0.4906412  0.4904618  0.49024588 0.48999146 0.48977342
 0.4896303  0.48956382 0.4895493  0.48956156 0.48955745 0.48949748
 0.48937565 0.4891908  0.48892108 0.48863015 0.4882802  0.48793998
 0.48762688 0.48738304 0.48720786 0.48710227 0.4870642  0.48706576
 0.48703584 0.48696113 0.4868542  0.48666418 0.486511   0.48647064
 0.4865032  0.48661235 0.48679522 0.48697075 0.48712328 0.48723894
 0.48722532 0.4871467  0.48703012 0.4868944  0.48682123 0.48686272
 0.48698816 0.487175   0.48740593 0.487607   0.48773515 0.48781687
 0.48783356 0.48785007 0.48788196 0.4879585  0.48805565 0.48814473
 0.48817417 0.48816127 0.48812762 0.48802638 0.48792177 0.4878486
 0.48785448 0.487919   0.4880483  0.48822573 0.48840237 0.488569
 0.48872212 0.48882908 0.4888773  0.48875925 0.48848712 0.48811653
 0.4876411  0.4871847  0.48680705 0.48642036 0.48600745 0.48570076
 0.4854724  0.48520938 0.48496065 0.48478514 0.48462352 0.4845109
 0.4843824  0.4843167  0.48427692 0.4842163  0.48407426 0.48386347
 0.48367637 0.48353004 0.48340967 0.48331627 0.48327482 0.48331365
 0.48340666 0.48338267 0.48325115 0.4831167  0.4829704  0.4828068
 0.48268312 0.48259562 0.4825939  0.4826336  0.48268884 0.48271322
 0.48265567 0.48252407 0.4822516  0.4819174  0.48154286 0.4811922
 0.4808798  0.48070526 0.48061046 0.48061237 0.48065844 0.48077953
 0.48077095 0.48059267 0.4803266  0.4800327  0.47975847 0.4796065
 0.47958162 0.4796955  0.4799114  0.48015282 0.48037788 0.48055643
 0.4805726  0.48047602 0.48028103 0.48007372 0.47993448 0.4799131
 0.48001316 0.48021057 0.48041743 0.48056588 0.48061305 0.4806029
 0.4804691  0.48035547 0.4803113  0.48043895 0.4806936  0.4810089
 0.48133257 0.48163748 0.48183066 0.4819482  0.48196757 0.48191532
 0.48183662 0.4817501  0.48166552 0.48160025 0.4815365  0.48146638
 0.48132208 0.4811097  0.48080587 0.48035854 0.47976786 0.47907507
 0.47828802 0.47753355 0.47681773 0.47611445 0.47546285 0.47490668
 0.4744546  0.47398204 0.4734949  0.4730206  0.47249937 0.47193336
 0.47143015 0.4710507  0.47074735 0.47047484 0.4703051  0.4701464
 0.47000933 0.469985   0.47007567 0.47018465 0.4703357  0.4705323
 0.47076997 0.4708794  0.47086123 0.47077212 0.47063792 0.4705476
 0.47051787 0.47054908 0.47064638 0.4708128  0.4709602  0.47107792
 0.4711048  0.4710138  0.47086266 0.47057116 0.47019312 0.46983844
 0.46953592 0.469294   0.46914223 0.46905237 0.468996   0.46901786
 0.46901035 0.46890602 0.4687282  0.4685205  0.46834677 0.46825877
 0.46827093 0.46833965 0.4684499  0.46855885 0.46862295 0.4686256
 0.4685786  0.4684533  0.46828055 0.46812066 0.4680582  0.4680927
 0.4681668  0.46824715 0.4683356  0.46838167 0.4683435  0.4683148
 0.46824542 0.46825328 0.4683707  0.46863374 0.4690029  0.4693645
 0.4696646  0.4698899  0.4700066  0.47003514 0.4699927  0.46991503
 0.46979254 0.46975634 0.46972835 0.46973255 0.46974784 0.4697401
 0.46970865 0.46957934 0.46937063 0.4690078  0.46844858 0.4676878
 0.46681178 0.46593562 0.4651875  0.4644382  0.46374205 0.46319225
 0.46278742 0.46240526 0.46209452 0.46186042 0.4616121  0.46130863
 0.46098265 0.46062323 0.46026114 0.45990816 0.45954582 0.45925793
 0.45896384 0.45880228 0.4587546  0.45882803 0.4589821  0.45923948
 0.45954412 0.4596731  0.45957544 0.45937812 0.45914018 0.4588638
 0.45861217 0.45844877 0.4583813  0.45838928 0.4584461  0.45853424
 0.45857796 0.458549   0.45844042 0.45819953 0.4579159  0.45761985
 0.45737526 0.45720577 0.4571393  0.45711145 0.4571677  0.45728466
 0.45736697 0.45740148 0.45737246 0.4572675  0.45717248 0.45712
 0.45707902 0.45704612 0.457042   0.4570328  0.45702356 0.45695817
 0.45681322 0.45663127 0.4564614  0.45632526 0.45630154 0.4563212
 0.4563623  0.45641267 0.45644233 0.45646724 0.45646057 0.45644534
 0.45648113 0.45658243 0.4567761  0.4570643  0.45736367 0.4576226
 0.45777893 0.45781654 0.45772234 0.45754787 0.45731243 0.4570889
 0.45693174 0.4569032  0.457011   0.45718315 0.45738673 0.45755205
 0.45762014 0.45755604 0.4573055  0.4568825  0.4563314  0.4556783
 0.45493937 0.4543088  0.4538215  0.45335013 0.45291293 0.45250764
 0.45210552 0.451722   0.45139518 0.45112768 0.45094293 0.4508776
 0.4508919  0.45094797 0.4510152  0.45099223 0.450872   0.45058244
 0.45028904 0.4500158  0.44978842 0.44965792 0.4495959  0.44975048
 0.45001042 0.450116   0.45001197 0.44984642 0.4496026  0.4492339
 0.44880274 0.44837788 0.44802332 0.44781044 0.4477246  0.44778973
 0.44795692 0.4481583  0.4482809  0.44825962 0.4481045  0.4478202
 0.44756323 0.44755927 0.44789696 0.4485584  0.4492979  0.44915766]
