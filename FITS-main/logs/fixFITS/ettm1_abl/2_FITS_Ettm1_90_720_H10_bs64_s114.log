Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=20, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_90_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_90_720_FITS_ETTm1_ftM_sl90_ll48_pl720_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33751
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=20, out_features=180, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3225600.0
params:  3780.0
Trainable parameters:  3780
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.9682915
	speed: 0.0218s/iter; left time: 570.6741s
	iters: 200, epoch: 1 | loss: 0.7373602
	speed: 0.0156s/iter; left time: 406.8530s
Epoch: 1 cost time: 4.7027037143707275
Epoch: 1, Steps: 263 | Train Loss: 0.9465367 Vali Loss: 1.4056238 Test Loss: 0.8692439
Validation loss decreased (inf --> 1.405624).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5539797
	speed: 0.0733s/iter; left time: 1900.6577s
	iters: 200, epoch: 2 | loss: 0.4904815
	speed: 0.0150s/iter; left time: 386.4945s
Epoch: 2 cost time: 4.559082508087158
Epoch: 2, Steps: 263 | Train Loss: 0.5417447 Vali Loss: 1.1279837 Test Loss: 0.5986738
Validation loss decreased (1.405624 --> 1.127984).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4851075
	speed: 0.0726s/iter; left time: 1864.0723s
	iters: 200, epoch: 3 | loss: 0.4383978
	speed: 0.0149s/iter; left time: 381.0139s
Epoch: 3 cost time: 4.485173940658569
Epoch: 3, Steps: 263 | Train Loss: 0.4707918 Vali Loss: 1.0670874 Test Loss: 0.5410640
Validation loss decreased (1.127984 --> 1.067087).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4471336
	speed: 0.0710s/iter; left time: 1803.2530s
	iters: 200, epoch: 4 | loss: 0.4160355
	speed: 0.0147s/iter; left time: 372.3324s
Epoch: 4 cost time: 4.635019540786743
Epoch: 4, Steps: 263 | Train Loss: 0.4538864 Vali Loss: 1.0421518 Test Loss: 0.5198284
Validation loss decreased (1.067087 --> 1.042152).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4424207
	speed: 0.0735s/iter; left time: 1849.5273s
	iters: 200, epoch: 5 | loss: 0.4644921
	speed: 0.0148s/iter; left time: 370.8436s
Epoch: 5 cost time: 4.421412944793701
Epoch: 5, Steps: 263 | Train Loss: 0.4475830 Vali Loss: 1.0306442 Test Loss: 0.5091642
Validation loss decreased (1.042152 --> 1.030644).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4124326
	speed: 0.0728s/iter; left time: 1810.9504s
	iters: 200, epoch: 6 | loss: 0.4166687
	speed: 0.0163s/iter; left time: 403.1239s
Epoch: 6 cost time: 4.787892818450928
Epoch: 6, Steps: 263 | Train Loss: 0.4445461 Vali Loss: 1.0239350 Test Loss: 0.5033004
Validation loss decreased (1.030644 --> 1.023935).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4177709
	speed: 0.0972s/iter; left time: 2393.4539s
	iters: 200, epoch: 7 | loss: 0.4029945
	speed: 0.0153s/iter; left time: 375.0353s
Epoch: 7 cost time: 4.610994815826416
Epoch: 7, Steps: 263 | Train Loss: 0.4428612 Vali Loss: 1.0198882 Test Loss: 0.5000260
Validation loss decreased (1.023935 --> 1.019888).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4616486
	speed: 0.0728s/iter; left time: 1772.6297s
	iters: 200, epoch: 8 | loss: 0.4372369
	speed: 0.0150s/iter; left time: 363.8254s
Epoch: 8 cost time: 4.418177843093872
Epoch: 8, Steps: 263 | Train Loss: 0.4423006 Vali Loss: 1.0175259 Test Loss: 0.4978819
Validation loss decreased (1.019888 --> 1.017526).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4109678
	speed: 0.0722s/iter; left time: 1739.4137s
	iters: 200, epoch: 9 | loss: 0.4522959
	speed: 0.0148s/iter; left time: 355.1043s
Epoch: 9 cost time: 4.468403577804565
Epoch: 9, Steps: 263 | Train Loss: 0.4419822 Vali Loss: 1.0169554 Test Loss: 0.4964629
Validation loss decreased (1.017526 --> 1.016955).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4550584
	speed: 0.0737s/iter; left time: 1755.9811s
	iters: 200, epoch: 10 | loss: 0.4473358
	speed: 0.0148s/iter; left time: 350.4027s
Epoch: 10 cost time: 4.383396863937378
Epoch: 10, Steps: 263 | Train Loss: 0.4417068 Vali Loss: 1.0163313 Test Loss: 0.4960831
Validation loss decreased (1.016955 --> 1.016331).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4322781
	speed: 0.0727s/iter; left time: 1714.2657s
	iters: 200, epoch: 11 | loss: 0.4488243
	speed: 0.0149s/iter; left time: 349.2332s
Epoch: 11 cost time: 4.414853572845459
Epoch: 11, Steps: 263 | Train Loss: 0.4415302 Vali Loss: 1.0159811 Test Loss: 0.4954481
Validation loss decreased (1.016331 --> 1.015981).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4561527
	speed: 0.0759s/iter; left time: 1769.6147s
	iters: 200, epoch: 12 | loss: 0.4652192
	speed: 0.0165s/iter; left time: 383.3275s
Epoch: 12 cost time: 4.836469411849976
Epoch: 12, Steps: 263 | Train Loss: 0.4416426 Vali Loss: 1.0149038 Test Loss: 0.4953927
Validation loss decreased (1.015981 --> 1.014904).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4119311
	speed: 0.0739s/iter; left time: 1702.8937s
	iters: 200, epoch: 13 | loss: 0.4499892
	speed: 0.0149s/iter; left time: 342.4192s
Epoch: 13 cost time: 4.5086891651153564
Epoch: 13, Steps: 263 | Train Loss: 0.4413608 Vali Loss: 1.0154033 Test Loss: 0.4952592
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4419670
	speed: 0.0729s/iter; left time: 1660.8256s
	iters: 200, epoch: 14 | loss: 0.4060875
	speed: 0.0148s/iter; left time: 336.6451s
Epoch: 14 cost time: 4.491007089614868
Epoch: 14, Steps: 263 | Train Loss: 0.4415581 Vali Loss: 1.0156206 Test Loss: 0.4949027
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4551681
	speed: 0.0722s/iter; left time: 1625.4179s
	iters: 200, epoch: 15 | loss: 0.4135607
	speed: 0.0149s/iter; left time: 334.7262s
Epoch: 15 cost time: 4.4957849979400635
Epoch: 15, Steps: 263 | Train Loss: 0.4414378 Vali Loss: 1.0151246 Test Loss: 0.4950646
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4445701
	speed: 0.0723s/iter; left time: 1608.6961s
	iters: 200, epoch: 16 | loss: 0.4661588
	speed: 0.0148s/iter; left time: 327.9577s
Epoch: 16 cost time: 4.432239055633545
Epoch: 16, Steps: 263 | Train Loss: 0.4414241 Vali Loss: 1.0144781 Test Loss: 0.4951444
Validation loss decreased (1.014904 --> 1.014478).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4654261
	speed: 0.0708s/iter; left time: 1557.3435s
	iters: 200, epoch: 17 | loss: 0.4263635
	speed: 0.0152s/iter; left time: 331.9159s
Epoch: 17 cost time: 4.443436861038208
Epoch: 17, Steps: 263 | Train Loss: 0.4412969 Vali Loss: 1.0151106 Test Loss: 0.4951231
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4383806
	speed: 0.0713s/iter; left time: 1549.5839s
	iters: 200, epoch: 18 | loss: 0.4581105
	speed: 0.0170s/iter; left time: 367.6378s
Epoch: 18 cost time: 4.754441022872925
Epoch: 18, Steps: 263 | Train Loss: 0.4413697 Vali Loss: 1.0149398 Test Loss: 0.4952258
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4540569
	speed: 0.0763s/iter; left time: 1638.5415s
	iters: 200, epoch: 19 | loss: 0.4451752
	speed: 0.0148s/iter; left time: 315.4251s
Epoch: 19 cost time: 4.495041131973267
Epoch: 19, Steps: 263 | Train Loss: 0.4414348 Vali Loss: 1.0143782 Test Loss: 0.4950181
Validation loss decreased (1.014478 --> 1.014378).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4372265
	speed: 0.0713s/iter; left time: 1511.8344s
	iters: 200, epoch: 20 | loss: 0.4088994
	speed: 0.0151s/iter; left time: 318.4865s
Epoch: 20 cost time: 4.485499858856201
Epoch: 20, Steps: 263 | Train Loss: 0.4413262 Vali Loss: 1.0147349 Test Loss: 0.4950289
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4769623
	speed: 0.0719s/iter; left time: 1505.9626s
	iters: 200, epoch: 21 | loss: 0.4516154
	speed: 0.0150s/iter; left time: 312.5414s
Epoch: 21 cost time: 4.464745759963989
Epoch: 21, Steps: 263 | Train Loss: 0.4412942 Vali Loss: 1.0151190 Test Loss: 0.4950466
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4424916
	speed: 0.0738s/iter; left time: 1526.8271s
	iters: 200, epoch: 22 | loss: 0.4155056
	speed: 0.0153s/iter; left time: 315.5082s
Epoch: 22 cost time: 4.62293815612793
Epoch: 22, Steps: 263 | Train Loss: 0.4413382 Vali Loss: 1.0150547 Test Loss: 0.4952607
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4082366
	speed: 0.0727s/iter; left time: 1484.7763s
	iters: 200, epoch: 23 | loss: 0.4391479
	speed: 0.0149s/iter; left time: 301.7459s
Epoch: 23 cost time: 4.437463998794556
Epoch: 23, Steps: 263 | Train Loss: 0.4413154 Vali Loss: 1.0142370 Test Loss: 0.4953821
Validation loss decreased (1.014378 --> 1.014237).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4361871
	speed: 0.0700s/iter; left time: 1409.8640s
	iters: 200, epoch: 24 | loss: 0.4559855
	speed: 0.0147s/iter; left time: 294.6986s
Epoch: 24 cost time: 4.379742622375488
Epoch: 24, Steps: 263 | Train Loss: 0.4412885 Vali Loss: 1.0146875 Test Loss: 0.4949793
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4047853
	speed: 0.0707s/iter; left time: 1406.6510s
	iters: 200, epoch: 25 | loss: 0.4563505
	speed: 0.0148s/iter; left time: 293.5297s
Epoch: 25 cost time: 4.377305746078491
Epoch: 25, Steps: 263 | Train Loss: 0.4413886 Vali Loss: 1.0154661 Test Loss: 0.4951919
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4299225
	speed: 0.0723s/iter; left time: 1419.4471s
	iters: 200, epoch: 26 | loss: 0.4330579
	speed: 0.0148s/iter; left time: 289.4461s
Epoch: 26 cost time: 4.4857823848724365
Epoch: 26, Steps: 263 | Train Loss: 0.4413354 Vali Loss: 1.0155376 Test Loss: 0.4953341
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4016663
	speed: 0.0718s/iter; left time: 1390.4287s
	iters: 200, epoch: 27 | loss: 0.4172011
	speed: 0.0150s/iter; left time: 288.5131s
Epoch: 27 cost time: 4.474729537963867
Epoch: 27, Steps: 263 | Train Loss: 0.4413412 Vali Loss: 1.0151122 Test Loss: 0.4952671
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4930418
	speed: 0.0726s/iter; left time: 1387.4522s
	iters: 200, epoch: 28 | loss: 0.4445379
	speed: 0.0149s/iter; left time: 283.0457s
Epoch: 28 cost time: 4.516412019729614
Epoch: 28, Steps: 263 | Train Loss: 0.4412257 Vali Loss: 1.0155427 Test Loss: 0.4952708
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4560134
	speed: 0.0723s/iter; left time: 1361.3808s
	iters: 200, epoch: 29 | loss: 0.4544373
	speed: 0.0150s/iter; left time: 280.2730s
Epoch: 29 cost time: 4.455590486526489
Epoch: 29, Steps: 263 | Train Loss: 0.4413501 Vali Loss: 1.0149823 Test Loss: 0.4953802
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4003147
	speed: 0.0704s/iter; left time: 1307.7029s
	iters: 200, epoch: 30 | loss: 0.4389746
	speed: 0.0143s/iter; left time: 264.4019s
Epoch: 30 cost time: 4.318169116973877
Epoch: 30, Steps: 263 | Train Loss: 0.4412851 Vali Loss: 1.0161318 Test Loss: 0.4953274
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4381117
	speed: 0.0754s/iter; left time: 1381.3577s
	iters: 200, epoch: 31 | loss: 0.4505395
	speed: 0.0169s/iter; left time: 307.1107s
Epoch: 31 cost time: 4.92182469367981
Epoch: 31, Steps: 263 | Train Loss: 0.4412535 Vali Loss: 1.0147997 Test Loss: 0.4953367
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4474444
	speed: 0.0753s/iter; left time: 1359.3835s
	iters: 200, epoch: 32 | loss: 0.4276523
	speed: 0.0149s/iter; left time: 266.6560s
Epoch: 32 cost time: 4.434978485107422
Epoch: 32, Steps: 263 | Train Loss: 0.4411671 Vali Loss: 1.0153837 Test Loss: 0.4954445
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4553235
	speed: 0.0722s/iter; left time: 1283.4226s
	iters: 200, epoch: 33 | loss: 0.4579144
	speed: 0.0150s/iter; left time: 265.8976s
Epoch: 33 cost time: 4.495903730392456
Epoch: 33, Steps: 263 | Train Loss: 0.4411403 Vali Loss: 1.0151129 Test Loss: 0.4953242
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4328257
	speed: 0.0729s/iter; left time: 1277.8053s
	iters: 200, epoch: 34 | loss: 0.4466244
	speed: 0.0148s/iter; left time: 258.3790s
Epoch: 34 cost time: 4.462619781494141
Epoch: 34, Steps: 263 | Train Loss: 0.4413986 Vali Loss: 1.0155866 Test Loss: 0.4954226
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4534552
	speed: 0.1039s/iter; left time: 1793.8632s
	iters: 200, epoch: 35 | loss: 0.4324681
	speed: 0.0155s/iter; left time: 265.4665s
Epoch: 35 cost time: 4.479766845703125
Epoch: 35, Steps: 263 | Train Loss: 0.4412304 Vali Loss: 1.0140958 Test Loss: 0.4954140
Validation loss decreased (1.014237 --> 1.014096).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4213957
	speed: 0.0716s/iter; left time: 1217.4616s
	iters: 200, epoch: 36 | loss: 0.4157372
	speed: 0.0145s/iter; left time: 244.8411s
Epoch: 36 cost time: 4.337409019470215
Epoch: 36, Steps: 263 | Train Loss: 0.4414429 Vali Loss: 1.0147488 Test Loss: 0.4954525
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4334623
	speed: 0.0722s/iter; left time: 1208.8351s
	iters: 200, epoch: 37 | loss: 0.4542684
	speed: 0.0143s/iter; left time: 238.1782s
Epoch: 37 cost time: 4.469618320465088
Epoch: 37, Steps: 263 | Train Loss: 0.4411705 Vali Loss: 1.0144241 Test Loss: 0.4954789
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4697700
	speed: 0.0783s/iter; left time: 1290.2806s
	iters: 200, epoch: 38 | loss: 0.4037933
	speed: 0.0147s/iter; left time: 240.6473s
Epoch: 38 cost time: 4.468327283859253
Epoch: 38, Steps: 263 | Train Loss: 0.4413237 Vali Loss: 1.0150325 Test Loss: 0.4955153
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4265748
	speed: 0.0717s/iter; left time: 1162.3993s
	iters: 200, epoch: 39 | loss: 0.4589160
	speed: 0.0149s/iter; left time: 239.9237s
Epoch: 39 cost time: 4.445708513259888
Epoch: 39, Steps: 263 | Train Loss: 0.4412421 Vali Loss: 1.0155377 Test Loss: 0.4955048
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.4252073
	speed: 0.0721s/iter; left time: 1149.1719s
	iters: 200, epoch: 40 | loss: 0.4600084
	speed: 0.0147s/iter; left time: 232.9651s
Epoch: 40 cost time: 4.358036279678345
Epoch: 40, Steps: 263 | Train Loss: 0.4411960 Vali Loss: 1.0158300 Test Loss: 0.4954998
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.4878301
	speed: 0.0701s/iter; left time: 1099.2425s
	iters: 200, epoch: 41 | loss: 0.4382867
	speed: 0.0150s/iter; left time: 233.9649s
Epoch: 41 cost time: 4.475868225097656
Epoch: 41, Steps: 263 | Train Loss: 0.4412526 Vali Loss: 1.0150859 Test Loss: 0.4955150
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.4351394
	speed: 0.0717s/iter; left time: 1105.3931s
	iters: 200, epoch: 42 | loss: 0.4204279
	speed: 0.0149s/iter; left time: 228.1132s
Epoch: 42 cost time: 4.447463750839233
Epoch: 42, Steps: 263 | Train Loss: 0.4413733 Vali Loss: 1.0152117 Test Loss: 0.4955412
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.4400790
	speed: 0.0717s/iter; left time: 1086.9819s
	iters: 200, epoch: 43 | loss: 0.4248345
	speed: 0.0143s/iter; left time: 215.0711s
Epoch: 43 cost time: 4.3289830684661865
Epoch: 43, Steps: 263 | Train Loss: 0.4412358 Vali Loss: 1.0151873 Test Loss: 0.4955197
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.4399664
	speed: 0.0815s/iter; left time: 1213.9729s
	iters: 200, epoch: 44 | loss: 0.4535877
	speed: 0.0155s/iter; left time: 229.4233s
Epoch: 44 cost time: 4.694192171096802
Epoch: 44, Steps: 263 | Train Loss: 0.4412043 Vali Loss: 1.0155859 Test Loss: 0.4955181
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.4537478
	speed: 0.0723s/iter; left time: 1057.9148s
	iters: 200, epoch: 45 | loss: 0.4733662
	speed: 0.0147s/iter; left time: 213.8389s
Epoch: 45 cost time: 4.4354407787323
Epoch: 45, Steps: 263 | Train Loss: 0.4412409 Vali Loss: 1.0157200 Test Loss: 0.4954906
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.4612624
	speed: 0.0761s/iter; left time: 1092.7305s
	iters: 200, epoch: 46 | loss: 0.4537812
	speed: 0.0146s/iter; left time: 207.8969s
Epoch: 46 cost time: 4.458092212677002
Epoch: 46, Steps: 263 | Train Loss: 0.4413360 Vali Loss: 1.0146517 Test Loss: 0.4955095
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.4359062
	speed: 0.0742s/iter; left time: 1045.9900s
	iters: 200, epoch: 47 | loss: 0.4371138
	speed: 0.0150s/iter; left time: 210.3447s
Epoch: 47 cost time: 4.56585431098938
Epoch: 47, Steps: 263 | Train Loss: 0.4412931 Vali Loss: 1.0157975 Test Loss: 0.4955369
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.4248775
	speed: 0.0729s/iter; left time: 1008.6424s
	iters: 200, epoch: 48 | loss: 0.4155052
	speed: 0.0310s/iter; left time: 425.2927s
Epoch: 48 cost time: 6.123356342315674
Epoch: 48, Steps: 263 | Train Loss: 0.4411234 Vali Loss: 1.0157350 Test Loss: 0.4955657
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.4083601
	speed: 0.0724s/iter; left time: 982.6226s
	iters: 200, epoch: 49 | loss: 0.4430912
	speed: 0.0151s/iter; left time: 203.4955s
Epoch: 49 cost time: 4.382293224334717
Epoch: 49, Steps: 263 | Train Loss: 0.4412601 Vali Loss: 1.0149424 Test Loss: 0.4955330
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.4037381
	speed: 0.0719s/iter; left time: 957.8802s
	iters: 200, epoch: 50 | loss: 0.4457765
	speed: 0.0150s/iter; left time: 197.7652s
Epoch: 50 cost time: 4.4760582447052
Epoch: 50, Steps: 263 | Train Loss: 0.4411987 Vali Loss: 1.0157168 Test Loss: 0.4954903
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.4402824
	speed: 0.0744s/iter; left time: 971.5681s
	iters: 200, epoch: 51 | loss: 0.4300369
	speed: 0.0164s/iter; left time: 212.6451s
Epoch: 51 cost time: 4.8725340366363525
Epoch: 51, Steps: 263 | Train Loss: 0.4412828 Vali Loss: 1.0150614 Test Loss: 0.4955189
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.4213691
	speed: 0.0770s/iter; left time: 985.2108s
	iters: 200, epoch: 52 | loss: 0.4229954
	speed: 0.0146s/iter; left time: 185.0022s
Epoch: 52 cost time: 4.478823900222778
Epoch: 52, Steps: 263 | Train Loss: 0.4413289 Vali Loss: 1.0152738 Test Loss: 0.4955451
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.4590208
	speed: 0.0724s/iter; left time: 907.4134s
	iters: 200, epoch: 53 | loss: 0.3973210
	speed: 0.0149s/iter; left time: 184.8809s
Epoch: 53 cost time: 4.427692890167236
Epoch: 53, Steps: 263 | Train Loss: 0.4413643 Vali Loss: 1.0149772 Test Loss: 0.4955661
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.4396358
	speed: 0.0727s/iter; left time: 890.9254s
	iters: 200, epoch: 54 | loss: 0.4428722
	speed: 0.0211s/iter; left time: 256.9757s
Epoch: 54 cost time: 5.284970760345459
Epoch: 54, Steps: 263 | Train Loss: 0.4412509 Vali Loss: 1.0152719 Test Loss: 0.4955906
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.4198531
	speed: 0.0917s/iter; left time: 1099.8172s
	iters: 200, epoch: 55 | loss: 0.4550692
	speed: 0.0162s/iter; left time: 192.9602s
Epoch: 55 cost time: 4.8440351486206055
Epoch: 55, Steps: 263 | Train Loss: 0.4412133 Vali Loss: 1.0147923 Test Loss: 0.4955764
EarlyStopping counter: 20 out of 20
Early stopping
train 33751
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=20, out_features=180, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3225600.0
params:  3780.0
Trainable parameters:  3780
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4815858
	speed: 0.0198s/iter; left time: 518.8667s
	iters: 200, epoch: 1 | loss: 0.5128151
	speed: 0.0156s/iter; left time: 408.1499s
Epoch: 1 cost time: 4.512363433837891
Epoch: 1, Steps: 263 | Train Loss: 0.4937076 Vali Loss: 1.0132495 Test Loss: 0.4940269
Validation loss decreased (inf --> 1.013250).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4531401
	speed: 0.0738s/iter; left time: 1913.7903s
	iters: 200, epoch: 2 | loss: 0.5086718
	speed: 0.0148s/iter; left time: 382.0383s
Epoch: 2 cost time: 4.537354469299316
Epoch: 2, Steps: 263 | Train Loss: 0.4934932 Vali Loss: 1.0129915 Test Loss: 0.4940608
Validation loss decreased (1.013250 --> 1.012992).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4959314
	speed: 0.0724s/iter; left time: 1860.1362s
	iters: 200, epoch: 3 | loss: 0.4930704
	speed: 0.0149s/iter; left time: 380.0432s
Epoch: 3 cost time: 4.4922566413879395
Epoch: 3, Steps: 263 | Train Loss: 0.4934777 Vali Loss: 1.0136006 Test Loss: 0.4945656
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4779279
	speed: 0.0730s/iter; left time: 1856.1124s
	iters: 200, epoch: 4 | loss: 0.4965629
	speed: 0.0151s/iter; left time: 382.6387s
Epoch: 4 cost time: 4.562889814376831
Epoch: 4, Steps: 263 | Train Loss: 0.4935541 Vali Loss: 1.0133970 Test Loss: 0.4942249
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.5504745
	speed: 0.0711s/iter; left time: 1787.8161s
	iters: 200, epoch: 5 | loss: 0.5162776
	speed: 0.0151s/iter; left time: 377.7515s
Epoch: 5 cost time: 4.403539419174194
Epoch: 5, Steps: 263 | Train Loss: 0.4936385 Vali Loss: 1.0134526 Test Loss: 0.4942212
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4961191
	speed: 0.0714s/iter; left time: 1775.8438s
	iters: 200, epoch: 6 | loss: 0.5013005
	speed: 0.0154s/iter; left time: 381.5005s
Epoch: 6 cost time: 4.476963043212891
Epoch: 6, Steps: 263 | Train Loss: 0.4935078 Vali Loss: 1.0132744 Test Loss: 0.4945819
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4921910
	speed: 0.0746s/iter; left time: 1837.8598s
	iters: 200, epoch: 7 | loss: 0.5040545
	speed: 0.0151s/iter; left time: 369.3989s
Epoch: 7 cost time: 4.527304410934448
Epoch: 7, Steps: 263 | Train Loss: 0.4934757 Vali Loss: 1.0134072 Test Loss: 0.4943130
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4722361
	speed: 0.0722s/iter; left time: 1758.3681s
	iters: 200, epoch: 8 | loss: 0.4756134
	speed: 0.0150s/iter; left time: 362.7063s
Epoch: 8 cost time: 4.522407531738281
Epoch: 8, Steps: 263 | Train Loss: 0.4932961 Vali Loss: 1.0147251 Test Loss: 0.4943832
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.5197045
	speed: 0.0718s/iter; left time: 1729.0278s
	iters: 200, epoch: 9 | loss: 0.4551341
	speed: 0.0150s/iter; left time: 360.3143s
Epoch: 9 cost time: 4.443151473999023
Epoch: 9, Steps: 263 | Train Loss: 0.4934685 Vali Loss: 1.0124651 Test Loss: 0.4940986
Validation loss decreased (1.012992 --> 1.012465).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4959078
	speed: 0.0740s/iter; left time: 1764.4867s
	iters: 200, epoch: 10 | loss: 0.4624697
	speed: 0.0157s/iter; left time: 373.4439s
Epoch: 10 cost time: 4.706608533859253
Epoch: 10, Steps: 263 | Train Loss: 0.4934301 Vali Loss: 1.0129263 Test Loss: 0.4947201
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.5356965
	speed: 0.0717s/iter; left time: 1689.5177s
	iters: 200, epoch: 11 | loss: 0.4836453
	speed: 0.0148s/iter; left time: 347.4748s
Epoch: 11 cost time: 4.3331990242004395
Epoch: 11, Steps: 263 | Train Loss: 0.4934654 Vali Loss: 1.0137500 Test Loss: 0.4945985
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.5298471
	speed: 0.0725s/iter; left time: 1689.2151s
	iters: 200, epoch: 12 | loss: 0.4699369
	speed: 0.0147s/iter; left time: 341.7664s
Epoch: 12 cost time: 4.493848085403442
Epoch: 12, Steps: 263 | Train Loss: 0.4932906 Vali Loss: 1.0133957 Test Loss: 0.4945040
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.5397356
	speed: 0.0718s/iter; left time: 1654.4018s
	iters: 200, epoch: 13 | loss: 0.4555848
	speed: 0.0150s/iter; left time: 345.0817s
Epoch: 13 cost time: 4.430154323577881
Epoch: 13, Steps: 263 | Train Loss: 0.4932509 Vali Loss: 1.0135866 Test Loss: 0.4945530
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4886173
	speed: 0.0711s/iter; left time: 1619.4750s
	iters: 200, epoch: 14 | loss: 0.5515106
	speed: 0.0150s/iter; left time: 340.7445s
Epoch: 14 cost time: 4.910492181777954
Epoch: 14, Steps: 263 | Train Loss: 0.4932984 Vali Loss: 1.0123317 Test Loss: 0.4946686
Validation loss decreased (1.012465 --> 1.012332).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.5132336
	speed: 0.0767s/iter; left time: 1727.3862s
	iters: 200, epoch: 15 | loss: 0.5355066
	speed: 0.0154s/iter; left time: 346.1074s
Epoch: 15 cost time: 4.577859878540039
Epoch: 15, Steps: 263 | Train Loss: 0.4931463 Vali Loss: 1.0117676 Test Loss: 0.4945903
Validation loss decreased (1.012332 --> 1.011768).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.5150254
	speed: 0.0753s/iter; left time: 1676.7430s
	iters: 200, epoch: 16 | loss: 0.4792116
	speed: 0.0165s/iter; left time: 364.7222s
Epoch: 16 cost time: 4.905519723892212
Epoch: 16, Steps: 263 | Train Loss: 0.4931851 Vali Loss: 1.0139333 Test Loss: 0.4945237
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4555010
	speed: 0.0805s/iter; left time: 1769.4740s
	iters: 200, epoch: 17 | loss: 0.4637730
	speed: 0.0169s/iter; left time: 369.0265s
Epoch: 17 cost time: 5.004889488220215
Epoch: 17, Steps: 263 | Train Loss: 0.4933340 Vali Loss: 1.0138990 Test Loss: 0.4946891
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.5031341
	speed: 0.0748s/iter; left time: 1625.4657s
	iters: 200, epoch: 18 | loss: 0.4909686
	speed: 0.0150s/iter; left time: 324.0025s
Epoch: 18 cost time: 4.5024871826171875
Epoch: 18, Steps: 263 | Train Loss: 0.4933560 Vali Loss: 1.0128859 Test Loss: 0.4947267
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4871679
	speed: 0.0712s/iter; left time: 1527.4085s
	iters: 200, epoch: 19 | loss: 0.4916819
	speed: 0.0147s/iter; left time: 314.4695s
Epoch: 19 cost time: 4.359623432159424
Epoch: 19, Steps: 263 | Train Loss: 0.4933242 Vali Loss: 1.0129373 Test Loss: 0.4947837
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4975570
	speed: 0.0723s/iter; left time: 1532.3414s
	iters: 200, epoch: 20 | loss: 0.4823332
	speed: 0.0164s/iter; left time: 345.2333s
Epoch: 20 cost time: 4.685279130935669
Epoch: 20, Steps: 263 | Train Loss: 0.4933014 Vali Loss: 1.0137542 Test Loss: 0.4947601
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4315351
	speed: 0.0800s/iter; left time: 1674.8513s
	iters: 200, epoch: 21 | loss: 0.4905931
	speed: 0.0162s/iter; left time: 338.4988s
Epoch: 21 cost time: 4.900719404220581
Epoch: 21, Steps: 263 | Train Loss: 0.4933087 Vali Loss: 1.0134193 Test Loss: 0.4946615
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4936426
	speed: 0.0746s/iter; left time: 1542.5319s
	iters: 200, epoch: 22 | loss: 0.5210832
	speed: 0.0149s/iter; left time: 307.5675s
Epoch: 22 cost time: 4.472733736038208
Epoch: 22, Steps: 263 | Train Loss: 0.4933841 Vali Loss: 1.0142021 Test Loss: 0.4947039
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.5369750
	speed: 0.0711s/iter; left time: 1452.4576s
	iters: 200, epoch: 23 | loss: 0.5134079
	speed: 0.0149s/iter; left time: 302.2004s
Epoch: 23 cost time: 4.497877836227417
Epoch: 23, Steps: 263 | Train Loss: 0.4932917 Vali Loss: 1.0129611 Test Loss: 0.4948137
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4997840
	speed: 0.0771s/iter; left time: 1553.2856s
	iters: 200, epoch: 24 | loss: 0.5202859
	speed: 0.0149s/iter; left time: 298.5109s
Epoch: 24 cost time: 4.505990266799927
Epoch: 24, Steps: 263 | Train Loss: 0.4933563 Vali Loss: 1.0129808 Test Loss: 0.4948370
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.5160815
	speed: 0.0735s/iter; left time: 1462.8302s
	iters: 200, epoch: 25 | loss: 0.5310781
	speed: 0.0147s/iter; left time: 290.5570s
Epoch: 25 cost time: 4.508241176605225
Epoch: 25, Steps: 263 | Train Loss: 0.4932848 Vali Loss: 1.0128115 Test Loss: 0.4946769
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4517852
	speed: 0.0720s/iter; left time: 1412.8342s
	iters: 200, epoch: 26 | loss: 0.4870478
	speed: 0.0151s/iter; left time: 294.1574s
Epoch: 26 cost time: 4.386782646179199
Epoch: 26, Steps: 263 | Train Loss: 0.4933183 Vali Loss: 1.0142972 Test Loss: 0.4946121
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.5291634
	speed: 0.0737s/iter; left time: 1427.0587s
	iters: 200, epoch: 27 | loss: 0.4591598
	speed: 0.0147s/iter; left time: 282.9525s
Epoch: 27 cost time: 4.5625221729278564
Epoch: 27, Steps: 263 | Train Loss: 0.4934174 Vali Loss: 1.0142382 Test Loss: 0.4946740
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4698299
	speed: 0.0718s/iter; left time: 1372.2472s
	iters: 200, epoch: 28 | loss: 0.4831910
	speed: 0.0145s/iter; left time: 275.8128s
Epoch: 28 cost time: 4.429708957672119
Epoch: 28, Steps: 263 | Train Loss: 0.4934070 Vali Loss: 1.0131558 Test Loss: 0.4947943
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4708934
	speed: 0.0728s/iter; left time: 1371.0637s
	iters: 200, epoch: 29 | loss: 0.5097948
	speed: 0.0146s/iter; left time: 273.6401s
Epoch: 29 cost time: 4.438284635543823
Epoch: 29, Steps: 263 | Train Loss: 0.4933009 Vali Loss: 1.0140295 Test Loss: 0.4947222
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.5110808
	speed: 0.0746s/iter; left time: 1386.1052s
	iters: 200, epoch: 30 | loss: 0.4945289
	speed: 0.0155s/iter; left time: 287.2041s
Epoch: 30 cost time: 4.76855731010437
Epoch: 30, Steps: 263 | Train Loss: 0.4932898 Vali Loss: 1.0142350 Test Loss: 0.4946803
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4564671
	speed: 0.0726s/iter; left time: 1328.8712s
	iters: 200, epoch: 31 | loss: 0.4970727
	speed: 0.0148s/iter; left time: 269.8880s
Epoch: 31 cost time: 4.53554892539978
Epoch: 31, Steps: 263 | Train Loss: 0.4932721 Vali Loss: 1.0133618 Test Loss: 0.4947970
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4995442
	speed: 0.0757s/iter; left time: 1365.6711s
	iters: 200, epoch: 32 | loss: 0.4906560
	speed: 0.0164s/iter; left time: 294.0867s
Epoch: 32 cost time: 4.786884546279907
Epoch: 32, Steps: 263 | Train Loss: 0.4931591 Vali Loss: 1.0131344 Test Loss: 0.4946687
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4788146
	speed: 0.0706s/iter; left time: 1254.8397s
	iters: 200, epoch: 33 | loss: 0.5156748
	speed: 0.0147s/iter; left time: 260.3622s
Epoch: 33 cost time: 4.360467433929443
Epoch: 33, Steps: 263 | Train Loss: 0.4933861 Vali Loss: 1.0135434 Test Loss: 0.4947514
EarlyStopping counter: 18 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4856786
	speed: 0.0713s/iter; left time: 1249.4310s
	iters: 200, epoch: 34 | loss: 0.5023897
	speed: 0.0146s/iter; left time: 255.0350s
Epoch: 34 cost time: 4.340688228607178
Epoch: 34, Steps: 263 | Train Loss: 0.4933642 Vali Loss: 1.0129927 Test Loss: 0.4947478
EarlyStopping counter: 19 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.5370299
	speed: 0.0713s/iter; left time: 1230.7162s
	iters: 200, epoch: 35 | loss: 0.4626461
	speed: 0.0149s/iter; left time: 254.9368s
Epoch: 35 cost time: 4.406366348266602
Epoch: 35, Steps: 263 | Train Loss: 0.4932360 Vali Loss: 1.0138941 Test Loss: 0.4947870
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_90_720_FITS_ETTm1_ftM_sl90_ll48_pl720_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.49269065260887146, mae:0.45311683416366577, rse:0.6678176522254944, corr:[0.5306162  0.53119034 0.5263989  0.5241379  0.52214414 0.5185171
 0.51501274 0.51347196 0.51261514 0.51132977 0.5098166  0.50876945
 0.5078934  0.5061657  0.5031253  0.4992694  0.4955134  0.49240154
 0.4897348  0.48697948 0.48400077 0.48102653 0.47813475 0.47498313
 0.47139272 0.46746135 0.4639783  0.46153218 0.4599665  0.4583553
 0.45676225 0.4562143  0.4564377  0.4568934  0.45705286 0.4571301
 0.457055   0.4572468  0.4574231  0.4571677  0.45680705 0.45655182
 0.45677924 0.4570971  0.45673528 0.45590582 0.45548725 0.4557779
 0.45635557 0.45674762 0.4568991  0.45692846 0.4572625  0.45772997
 0.45828632 0.4586886  0.45912012 0.45958427 0.45975333 0.4598469
 0.459934   0.45961434 0.45912302 0.45850742 0.45827138 0.4582348
 0.4578939  0.45735618 0.45741585 0.45835406 0.45948732 0.4603913
 0.4610608  0.46152544 0.46209013 0.46251178 0.46309164 0.46405065
 0.4652713  0.46652758 0.46744528 0.46772772 0.4678327  0.46792248
 0.46831146 0.4689169  0.46968073 0.47055492 0.47146967 0.4724075
 0.47331157 0.47413164 0.47483832 0.4752777  0.47536838 0.47500584
 0.47425303 0.47336856 0.47252995 0.4719117  0.47147685 0.47095284
 0.47032166 0.46974432 0.46937656 0.4689297  0.46823627 0.46752557
 0.4669648  0.4663348  0.46528986 0.46390215 0.462627   0.46180293
 0.46121094 0.4606266  0.45973763 0.45861697 0.45745036 0.45627907
 0.45513523 0.45378548 0.4523305  0.45125628 0.45048013 0.4497537
 0.4490269  0.4483576  0.44786823 0.44768187 0.44783866 0.44819728
 0.44830465 0.44815463 0.4477117  0.4472245  0.44693756 0.44690275
 0.44695216 0.44697195 0.4468873  0.44679537 0.4466959  0.44670573
 0.44679877 0.44699076 0.44721293 0.44728553 0.44758394 0.44797465
 0.44828784 0.4486896  0.4490212  0.44927433 0.44939426 0.44952822
 0.44948518 0.4492675  0.44905913 0.44915584 0.4495757  0.44980198
 0.4497181  0.44965065 0.44996157 0.45053074 0.45113987 0.45170757
 0.45236796 0.45317382 0.45392463 0.4546256  0.45526654 0.45610818
 0.45698687 0.4576958  0.45815045 0.45841032 0.45848972 0.45867938
 0.45909235 0.45978186 0.46043295 0.46095732 0.46154287 0.46240547
 0.4633926  0.4640137  0.46411732 0.46418598 0.4647017  0.4654055
 0.46584055 0.4661886  0.46668723 0.46729305 0.467867   0.46851447
 0.46897024 0.46865442 0.4676662  0.46666113 0.46595713 0.4654818
 0.46473932 0.46334532 0.46144712 0.45966682 0.45817384 0.4568986
 0.45547634 0.45389184 0.45238993 0.45099273 0.44955385 0.44808728
 0.44619268 0.4441384  0.4423728  0.44124514 0.4403766  0.43949786
 0.43869483 0.4382664  0.4379917  0.437891   0.438301   0.43853298
 0.4382339  0.437775   0.43748942 0.43738037 0.43744323 0.4373499
 0.43714434 0.43691134 0.43641445 0.43592975 0.43580544 0.43583462
 0.43617952 0.43639788 0.43644527 0.4366224  0.4368885  0.43749073
 0.43814626 0.43861914 0.43887523 0.43936852 0.43985176 0.4402407
 0.4401714  0.4399702  0.43973002 0.4399262  0.43998358 0.43967074
 0.43957672 0.4400617  0.44053954 0.44087395 0.44127443 0.44199383
 0.44327548 0.4443737  0.4449354  0.44536367 0.44631386 0.44763637
 0.4490359  0.44993967 0.45039305 0.45058733 0.4508222  0.45118755
 0.4516971  0.45239633 0.45309725 0.45386967 0.45468634 0.45552486
 0.45636833 0.45705333 0.45744255 0.4573276  0.45656046 0.45521027
 0.45339283 0.4512911  0.44918224 0.4474895  0.44655147 0.44626597
 0.44611803 0.4457258  0.44542927 0.44525337 0.4448426  0.4439844
 0.44272998 0.44134167 0.43998665 0.43865618 0.4375788  0.43675762
 0.4361468  0.43525004 0.43414527 0.43315613 0.43254107 0.43207392
 0.43132934 0.43023032 0.4291027  0.4282746  0.42748424 0.4269032
 0.4265186  0.4262389  0.42603415 0.4258347  0.4255544  0.42531902
 0.42505896 0.4249338  0.42480052 0.4246     0.424349   0.42408746
 0.42406005 0.4238925  0.42349434 0.4230141  0.42294195 0.42318293
 0.4233968  0.42308772 0.4228494  0.42286503 0.42338768 0.4239273
 0.42416057 0.4243415  0.42460638 0.4250724  0.42553133 0.42572722
 0.4255598  0.4251184  0.42479956 0.42475593 0.4249494  0.4252468
 0.42542014 0.42542696 0.42552528 0.42593274 0.42662662 0.42731512
 0.4277472  0.4280411  0.42856792 0.42944214 0.4307183  0.4319475
 0.43284282 0.4336311  0.43437132 0.43491054 0.43549663 0.43617365
 0.43711212 0.43813562 0.43932715 0.44069925 0.4422507  0.44395617
 0.44552243 0.4465692  0.44698325 0.44698694 0.4468823  0.4469635
 0.44709507 0.4469215  0.44650885 0.44637835 0.44699237 0.44824165
 0.44924244 0.44947332 0.44941092 0.44936424 0.44925016 0.44882342
 0.44798458 0.4467943  0.44524196 0.44368353 0.44242457 0.44154602
 0.44080204 0.44000164 0.43931213 0.4387262  0.43790647 0.4366287
 0.43509495 0.43340635 0.43219978 0.43189296 0.43173167 0.43130276
 0.4308932  0.43066722 0.4307978  0.43084338 0.43050015 0.4301066
 0.42983982 0.42975852 0.429567   0.4292969  0.42913973 0.42919025
 0.42919588 0.42904848 0.42847678 0.42807528 0.42792228 0.42791384
 0.42784703 0.4276816  0.4277294  0.42798918 0.4280926  0.42807424
 0.42817962 0.42871258 0.4294531  0.4301063  0.43049353 0.4306976
 0.4307366  0.43066326 0.43025702 0.429855   0.42973694 0.43000683
 0.430254   0.43039143 0.4304129  0.43068376 0.43115133 0.43177402
 0.43238735 0.4328548  0.43337774 0.434158   0.43497688 0.43559092
 0.4361173  0.43689504 0.43773806 0.43844184 0.43890533 0.43933055
 0.4400421  0.44110435 0.44245973 0.4436209  0.4443499  0.44486535
 0.44546086 0.4462152  0.44688404 0.44720072 0.44680083 0.44558102
 0.4438262  0.442203   0.44098625 0.4402335  0.43984854 0.43988717
 0.44003507 0.4400374  0.43995824 0.43957743 0.43874523 0.43753237
 0.4360954  0.43460935 0.4331521  0.43169856 0.43024662 0.42885223
 0.42757663 0.42660472 0.42586362 0.42500782 0.42405468 0.42290133
 0.4217748  0.42066586 0.41962564 0.41865715 0.41764003 0.4167508
 0.41607025 0.41580847 0.4158347  0.41603306 0.4162283  0.41643104
 0.41643414 0.41636142 0.416244   0.4158161  0.415332   0.41501433
 0.4149125  0.41505772 0.41494995 0.41456243 0.4140456  0.41377687
 0.41367775 0.4136678  0.41373742 0.41396815 0.41434643 0.4146805
 0.41488254 0.41484568 0.41498515 0.4154414  0.4158854  0.41584226
 0.41560113 0.41542462 0.4154896  0.41562802 0.4154327  0.41496775
 0.41460258 0.41468355 0.4151368  0.41563106 0.41595304 0.41631594
 0.41677    0.41712138 0.41749084 0.41807237 0.41901323 0.42011726
 0.4211457  0.42206845 0.4228709  0.42357215 0.42425388 0.42479846
 0.42515197 0.4256881  0.4265021  0.4276183  0.42878014 0.4298016
 0.43069994 0.43138784 0.43168262 0.4312807  0.4300661  0.42828128
 0.42636058 0.42468715 0.42341104 0.42243516 0.42208004 0.422409
 0.4229916  0.42335895 0.4235461  0.4235862  0.42323324 0.4223106
 0.4209093  0.41934696 0.41785437 0.4165714  0.41542178 0.41424832
 0.4131384  0.4121337  0.4111798  0.4101715  0.40910944 0.40804434
 0.40700865 0.40586662 0.40471867 0.4037316  0.40285423 0.4022478
 0.40183967 0.40160137 0.40131345 0.40108544 0.40095818 0.40119383
 0.4015785  0.4019276  0.4019953  0.4016513  0.4013796  0.40129
 0.40149778 0.40175632 0.40163028 0.4013126  0.40122202 0.40144473
 0.40155372 0.40148938 0.40160197 0.4017209  0.4017988  0.40183327
 0.40177485 0.40184477 0.40231875 0.40265208 0.4025683  0.40214053
 0.4019518  0.40222773 0.40251696 0.4021145  0.40131107 0.4007424
 0.4007168  0.40098965 0.4012385  0.40151548 0.40172607 0.40198824
 0.40231073 0.40264598 0.403067   0.4037934  0.4045701  0.40525115
 0.40570986 0.4063443  0.40726107 0.40822056 0.40893394 0.40944183
 0.4100057  0.4108022  0.41186762 0.41292682 0.41393432 0.4150024
 0.41600043 0.41664755 0.4167826  0.4163953  0.41544902 0.4138625
 0.4118239  0.4099892  0.4089083  0.4084476  0.40842673 0.4089066
 0.40979716 0.41064373 0.411027   0.41070345 0.40995005 0.4093346
 0.40890658 0.40805086 0.4063433  0.40410382 0.4022052  0.40092528
 0.39990085 0.3986311  0.3973612  0.39652583 0.39578554 0.39454058
 0.39273828 0.391128   0.39002803 0.38895074 0.38748187 0.3862105
 0.38593748 0.38613772 0.38576072 0.38443908 0.38331717 0.38373908
 0.38444403 0.38364092 0.38208184 0.38211986 0.3838309  0.38474408
 0.38418484 0.38466215 0.3871648  0.38843066 0.38754222 0.39049724]
