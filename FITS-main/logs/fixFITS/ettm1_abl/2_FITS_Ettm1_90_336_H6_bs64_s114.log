Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=16, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_90_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_90_336_FITS_ETTm1_ftM_sl90_ll48_pl336_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=16, out_features=75, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1075200.0
params:  1275.0
Trainable parameters:  1275
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.7476345
	speed: 0.0155s/iter; left time: 410.0802s
	iters: 200, epoch: 1 | loss: 0.6138043
	speed: 0.0092s/iter; left time: 243.4686s
Epoch: 1 cost time: 3.091160774230957
Epoch: 1, Steps: 266 | Train Loss: 0.6856748 Vali Loss: 1.0331514 Test Loss: 0.7568164
Validation loss decreased (inf --> 1.033151).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4699443
	speed: 0.0490s/iter; left time: 1284.3675s
	iters: 200, epoch: 2 | loss: 0.3976029
	speed: 0.0100s/iter; left time: 260.8094s
Epoch: 2 cost time: 3.2052884101867676
Epoch: 2, Steps: 266 | Train Loss: 0.4297123 Vali Loss: 0.8186939 Test Loss: 0.5474516
Validation loss decreased (1.033151 --> 0.818694).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3269021
	speed: 0.0479s/iter; left time: 1244.9745s
	iters: 200, epoch: 3 | loss: 0.3868758
	speed: 0.0098s/iter; left time: 253.7588s
Epoch: 3 cost time: 3.187452793121338
Epoch: 3, Steps: 266 | Train Loss: 0.3689127 Vali Loss: 0.7568256 Test Loss: 0.4868293
Validation loss decreased (0.818694 --> 0.756826).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3370099
	speed: 0.0530s/iter; left time: 1362.4741s
	iters: 200, epoch: 4 | loss: 0.3503529
	speed: 0.0112s/iter; left time: 286.0217s
Epoch: 4 cost time: 3.4543471336364746
Epoch: 4, Steps: 266 | Train Loss: 0.3516220 Vali Loss: 0.7303387 Test Loss: 0.4620425
Validation loss decreased (0.756826 --> 0.730339).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3746273
	speed: 0.0528s/iter; left time: 1342.5175s
	iters: 200, epoch: 5 | loss: 0.3192495
	speed: 0.0095s/iter; left time: 240.8793s
Epoch: 5 cost time: 3.232577323913574
Epoch: 5, Steps: 266 | Train Loss: 0.3450530 Vali Loss: 0.7170445 Test Loss: 0.4495122
Validation loss decreased (0.730339 --> 0.717044).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3284843
	speed: 0.0511s/iter; left time: 1286.8381s
	iters: 200, epoch: 6 | loss: 0.3128317
	speed: 0.0095s/iter; left time: 239.2867s
Epoch: 6 cost time: 3.2725934982299805
Epoch: 6, Steps: 266 | Train Loss: 0.3423958 Vali Loss: 0.7092130 Test Loss: 0.4432599
Validation loss decreased (0.717044 --> 0.709213).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3739815
	speed: 0.0501s/iter; left time: 1247.7086s
	iters: 200, epoch: 7 | loss: 0.3309435
	speed: 0.0097s/iter; left time: 240.1916s
Epoch: 7 cost time: 3.1850807666778564
Epoch: 7, Steps: 266 | Train Loss: 0.3413855 Vali Loss: 0.7060843 Test Loss: 0.4396352
Validation loss decreased (0.709213 --> 0.706084).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3487240
	speed: 0.0493s/iter; left time: 1214.4310s
	iters: 200, epoch: 8 | loss: 0.3745052
	speed: 0.0100s/iter; left time: 246.3546s
Epoch: 8 cost time: 3.219778060913086
Epoch: 8, Steps: 266 | Train Loss: 0.3408679 Vali Loss: 0.7030527 Test Loss: 0.4377119
Validation loss decreased (0.706084 --> 0.703053).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3524432
	speed: 0.0506s/iter; left time: 1234.0588s
	iters: 200, epoch: 9 | loss: 0.3471874
	speed: 0.0101s/iter; left time: 245.6791s
Epoch: 9 cost time: 3.2482750415802
Epoch: 9, Steps: 266 | Train Loss: 0.3406867 Vali Loss: 0.7018402 Test Loss: 0.4363661
Validation loss decreased (0.703053 --> 0.701840).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3353916
	speed: 0.0558s/iter; left time: 1345.0025s
	iters: 200, epoch: 10 | loss: 0.3129623
	speed: 0.0111s/iter; left time: 266.9038s
Epoch: 10 cost time: 3.583220958709717
Epoch: 10, Steps: 266 | Train Loss: 0.3406413 Vali Loss: 0.7008004 Test Loss: 0.4362269
Validation loss decreased (0.701840 --> 0.700800).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3306023
	speed: 0.0563s/iter; left time: 1341.8429s
	iters: 200, epoch: 11 | loss: 0.3419479
	speed: 0.0109s/iter; left time: 258.9509s
Epoch: 11 cost time: 3.433037281036377
Epoch: 11, Steps: 266 | Train Loss: 0.3406091 Vali Loss: 0.7015198 Test Loss: 0.4356136
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3454625
	speed: 0.0521s/iter; left time: 1227.9330s
	iters: 200, epoch: 12 | loss: 0.3215240
	speed: 0.0102s/iter; left time: 239.3037s
Epoch: 12 cost time: 3.2519371509552
Epoch: 12, Steps: 266 | Train Loss: 0.3406109 Vali Loss: 0.7010930 Test Loss: 0.4355646
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3491643
	speed: 0.0500s/iter; left time: 1164.6394s
	iters: 200, epoch: 13 | loss: 0.3420828
	speed: 0.0093s/iter; left time: 215.6246s
Epoch: 13 cost time: 3.1050872802734375
Epoch: 13, Steps: 266 | Train Loss: 0.3405959 Vali Loss: 0.7014629 Test Loss: 0.4357505
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3676712
	speed: 0.0510s/iter; left time: 1176.0889s
	iters: 200, epoch: 14 | loss: 0.3142107
	speed: 0.0097s/iter; left time: 222.9249s
Epoch: 14 cost time: 3.0821614265441895
Epoch: 14, Steps: 266 | Train Loss: 0.3405972 Vali Loss: 0.7001068 Test Loss: 0.4354006
Validation loss decreased (0.700800 --> 0.700107).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3161252
	speed: 0.0498s/iter; left time: 1133.7354s
	iters: 200, epoch: 15 | loss: 0.3195047
	speed: 0.0095s/iter; left time: 216.2703s
Epoch: 15 cost time: 3.0499887466430664
Epoch: 15, Steps: 266 | Train Loss: 0.3405398 Vali Loss: 0.7010375 Test Loss: 0.4356289
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3511006
	speed: 0.0491s/iter; left time: 1104.4637s
	iters: 200, epoch: 16 | loss: 0.3348487
	speed: 0.0094s/iter; left time: 211.2495s
Epoch: 16 cost time: 3.17716908454895
Epoch: 16, Steps: 266 | Train Loss: 0.3404904 Vali Loss: 0.7010651 Test Loss: 0.4357403
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3736015
	speed: 0.0516s/iter; left time: 1148.0951s
	iters: 200, epoch: 17 | loss: 0.3264225
	speed: 0.0097s/iter; left time: 215.6569s
Epoch: 17 cost time: 3.120628595352173
Epoch: 17, Steps: 266 | Train Loss: 0.3406226 Vali Loss: 0.7010502 Test Loss: 0.4357162
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3533900
	speed: 0.0503s/iter; left time: 1106.0723s
	iters: 200, epoch: 18 | loss: 0.3260506
	speed: 0.0100s/iter; left time: 219.4733s
Epoch: 18 cost time: 3.226992607116699
Epoch: 18, Steps: 266 | Train Loss: 0.3405689 Vali Loss: 0.7006189 Test Loss: 0.4354979
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3061126
	speed: 0.0518s/iter; left time: 1124.7694s
	iters: 200, epoch: 19 | loss: 0.3476264
	speed: 0.0097s/iter; left time: 209.5192s
Epoch: 19 cost time: 3.2884268760681152
Epoch: 19, Steps: 266 | Train Loss: 0.3404621 Vali Loss: 0.7007582 Test Loss: 0.4355159
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3837344
	speed: 0.0512s/iter; left time: 1098.4418s
	iters: 200, epoch: 20 | loss: 0.3797718
	speed: 0.0100s/iter; left time: 213.0457s
Epoch: 20 cost time: 3.264557361602783
Epoch: 20, Steps: 266 | Train Loss: 0.3404374 Vali Loss: 0.7010248 Test Loss: 0.4355766
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3487704
	speed: 0.0512s/iter; left time: 1083.9712s
	iters: 200, epoch: 21 | loss: 0.3551483
	speed: 0.0099s/iter; left time: 208.8027s
Epoch: 21 cost time: 3.2631759643554688
Epoch: 21, Steps: 266 | Train Loss: 0.3405801 Vali Loss: 0.7008801 Test Loss: 0.4355522
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3447007
	speed: 0.0512s/iter; left time: 1071.4600s
	iters: 200, epoch: 22 | loss: 0.3269665
	speed: 0.0096s/iter; left time: 200.8472s
Epoch: 22 cost time: 3.2730960845947266
Epoch: 22, Steps: 266 | Train Loss: 0.3406053 Vali Loss: 0.7009003 Test Loss: 0.4355056
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3340212
	speed: 0.0510s/iter; left time: 1053.7558s
	iters: 200, epoch: 23 | loss: 0.3570307
	speed: 0.0104s/iter; left time: 213.2618s
Epoch: 23 cost time: 3.2515511512756348
Epoch: 23, Steps: 266 | Train Loss: 0.3406486 Vali Loss: 0.7001511 Test Loss: 0.4354188
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3393885
	speed: 0.0491s/iter; left time: 999.9035s
	iters: 200, epoch: 24 | loss: 0.3353502
	speed: 0.0107s/iter; left time: 216.9814s
Epoch: 24 cost time: 3.2388737201690674
Epoch: 24, Steps: 266 | Train Loss: 0.3405801 Vali Loss: 0.7010515 Test Loss: 0.4357118
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3176094
	speed: 0.0518s/iter; left time: 1041.6915s
	iters: 200, epoch: 25 | loss: 0.3142249
	speed: 0.0105s/iter; left time: 209.3667s
Epoch: 25 cost time: 3.2882235050201416
Epoch: 25, Steps: 266 | Train Loss: 0.3404752 Vali Loss: 0.7009748 Test Loss: 0.4357451
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3688797
	speed: 0.0503s/iter; left time: 997.8062s
	iters: 200, epoch: 26 | loss: 0.3340893
	speed: 0.0103s/iter; left time: 203.4599s
Epoch: 26 cost time: 3.2487401962280273
Epoch: 26, Steps: 266 | Train Loss: 0.3405133 Vali Loss: 0.7011048 Test Loss: 0.4357711
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3116664
	speed: 0.0497s/iter; left time: 972.8862s
	iters: 200, epoch: 27 | loss: 0.3393513
	speed: 0.0101s/iter; left time: 197.7224s
Epoch: 27 cost time: 3.318159580230713
Epoch: 27, Steps: 266 | Train Loss: 0.3405429 Vali Loss: 0.7008187 Test Loss: 0.4357523
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3246906
	speed: 0.0509s/iter; left time: 983.4661s
	iters: 200, epoch: 28 | loss: 0.3583657
	speed: 0.0099s/iter; left time: 189.9377s
Epoch: 28 cost time: 3.208336591720581
Epoch: 28, Steps: 266 | Train Loss: 0.3403874 Vali Loss: 0.7014601 Test Loss: 0.4356944
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3328651
	speed: 0.0529s/iter; left time: 1007.9299s
	iters: 200, epoch: 29 | loss: 0.3296622
	speed: 0.0088s/iter; left time: 167.4415s
Epoch: 29 cost time: 3.0881404876708984
Epoch: 29, Steps: 266 | Train Loss: 0.3404048 Vali Loss: 0.7010595 Test Loss: 0.4358122
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3808091
	speed: 0.0465s/iter; left time: 874.1802s
	iters: 200, epoch: 30 | loss: 0.3166556
	speed: 0.0089s/iter; left time: 165.6760s
Epoch: 30 cost time: 2.9125471115112305
Epoch: 30, Steps: 266 | Train Loss: 0.3404086 Vali Loss: 0.7006516 Test Loss: 0.4356788
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3332154
	speed: 0.0533s/iter; left time: 987.1640s
	iters: 200, epoch: 31 | loss: 0.3281269
	speed: 0.0090s/iter; left time: 165.6361s
Epoch: 31 cost time: 3.0018374919891357
Epoch: 31, Steps: 266 | Train Loss: 0.3405618 Vali Loss: 0.7009016 Test Loss: 0.4357835
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3570785
	speed: 0.0493s/iter; left time: 900.6386s
	iters: 200, epoch: 32 | loss: 0.3083252
	speed: 0.0096s/iter; left time: 174.1349s
Epoch: 32 cost time: 3.2261056900024414
Epoch: 32, Steps: 266 | Train Loss: 0.3404229 Vali Loss: 0.7013618 Test Loss: 0.4358041
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3457517
	speed: 0.0499s/iter; left time: 898.3201s
	iters: 200, epoch: 33 | loss: 0.3682380
	speed: 0.0095s/iter; left time: 169.9287s
Epoch: 33 cost time: 3.193164587020874
Epoch: 33, Steps: 266 | Train Loss: 0.3405517 Vali Loss: 0.7007877 Test Loss: 0.4358006
EarlyStopping counter: 19 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3305196
	speed: 0.0514s/iter; left time: 910.3899s
	iters: 200, epoch: 34 | loss: 0.3611796
	speed: 0.0099s/iter; left time: 174.1110s
Epoch: 34 cost time: 3.338681221008301
Epoch: 34, Steps: 266 | Train Loss: 0.3405827 Vali Loss: 0.7007991 Test Loss: 0.4357786
EarlyStopping counter: 20 out of 20
Early stopping
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=16, out_features=75, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1075200.0
params:  1275.0
Trainable parameters:  1275
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4180418
	speed: 0.0160s/iter; left time: 423.2546s
	iters: 200, epoch: 1 | loss: 0.3885565
	speed: 0.0098s/iter; left time: 258.3947s
Epoch: 1 cost time: 3.2520346641540527
Epoch: 1, Steps: 266 | Train Loss: 0.4250124 Vali Loss: 0.6969821 Test Loss: 0.4317362
Validation loss decreased (inf --> 0.696982).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4181731
	speed: 0.0507s/iter; left time: 1330.4092s
	iters: 200, epoch: 2 | loss: 0.4006744
	speed: 0.0097s/iter; left time: 252.5863s
Epoch: 2 cost time: 3.181166410446167
Epoch: 2, Steps: 266 | Train Loss: 0.4243843 Vali Loss: 0.6958302 Test Loss: 0.4318775
Validation loss decreased (0.696982 --> 0.695830).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4529848
	speed: 0.0519s/iter; left time: 1348.1768s
	iters: 200, epoch: 3 | loss: 0.4139609
	speed: 0.0109s/iter; left time: 282.4890s
Epoch: 3 cost time: 3.406690835952759
Epoch: 3, Steps: 266 | Train Loss: 0.4241882 Vali Loss: 0.6959639 Test Loss: 0.4320382
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4454338
	speed: 0.0507s/iter; left time: 1302.8799s
	iters: 200, epoch: 4 | loss: 0.4619619
	speed: 0.0102s/iter; left time: 261.7020s
Epoch: 4 cost time: 3.267320156097412
Epoch: 4, Steps: 266 | Train Loss: 0.4242448 Vali Loss: 0.6960199 Test Loss: 0.4320101
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4307082
	speed: 0.0510s/iter; left time: 1297.8697s
	iters: 200, epoch: 5 | loss: 0.3930877
	speed: 0.0095s/iter; left time: 241.5283s
Epoch: 5 cost time: 3.0038669109344482
Epoch: 5, Steps: 266 | Train Loss: 0.4241378 Vali Loss: 0.6959999 Test Loss: 0.4322335
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4235469
	speed: 0.0504s/iter; left time: 1268.0719s
	iters: 200, epoch: 6 | loss: 0.4369061
	speed: 0.0102s/iter; left time: 256.6497s
Epoch: 6 cost time: 3.2053580284118652
Epoch: 6, Steps: 266 | Train Loss: 0.4240147 Vali Loss: 0.6954029 Test Loss: 0.4315016
Validation loss decreased (0.695830 --> 0.695403).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4121887
	speed: 0.0500s/iter; left time: 1245.3864s
	iters: 200, epoch: 7 | loss: 0.4476070
	speed: 0.0101s/iter; left time: 250.6368s
Epoch: 7 cost time: 3.177030563354492
Epoch: 7, Steps: 266 | Train Loss: 0.4241773 Vali Loss: 0.6960096 Test Loss: 0.4318047
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4502218
	speed: 0.0513s/iter; left time: 1264.2624s
	iters: 200, epoch: 8 | loss: 0.4194137
	speed: 0.0102s/iter; left time: 251.1004s
Epoch: 8 cost time: 3.2719669342041016
Epoch: 8, Steps: 266 | Train Loss: 0.4241284 Vali Loss: 0.6961895 Test Loss: 0.4321440
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4544224
	speed: 0.0505s/iter; left time: 1230.4359s
	iters: 200, epoch: 9 | loss: 0.4161494
	speed: 0.0095s/iter; left time: 231.3927s
Epoch: 9 cost time: 3.1238303184509277
Epoch: 9, Steps: 266 | Train Loss: 0.4241077 Vali Loss: 0.6966109 Test Loss: 0.4318702
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4299699
	speed: 0.0553s/iter; left time: 1333.4025s
	iters: 200, epoch: 10 | loss: 0.4320026
	speed: 0.0098s/iter; left time: 236.3373s
Epoch: 10 cost time: 3.270109176635742
Epoch: 10, Steps: 266 | Train Loss: 0.4241924 Vali Loss: 0.6961864 Test Loss: 0.4321834
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4480782
	speed: 0.0507s/iter; left time: 1208.5510s
	iters: 200, epoch: 11 | loss: 0.4166268
	speed: 0.0099s/iter; left time: 234.8783s
Epoch: 11 cost time: 3.072338342666626
Epoch: 11, Steps: 266 | Train Loss: 0.4238995 Vali Loss: 0.6956561 Test Loss: 0.4319596
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4541864
	speed: 0.0511s/iter; left time: 1205.6338s
	iters: 200, epoch: 12 | loss: 0.4097639
	speed: 0.0100s/iter; left time: 234.0357s
Epoch: 12 cost time: 3.293205499649048
Epoch: 12, Steps: 266 | Train Loss: 0.4240125 Vali Loss: 0.6954643 Test Loss: 0.4324141
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3997741
	speed: 0.0510s/iter; left time: 1189.3768s
	iters: 200, epoch: 13 | loss: 0.4606616
	speed: 0.0096s/iter; left time: 223.9444s
Epoch: 13 cost time: 3.190358877182007
Epoch: 13, Steps: 266 | Train Loss: 0.4240222 Vali Loss: 0.6953818 Test Loss: 0.4319377
Validation loss decreased (0.695403 --> 0.695382).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4096641
	speed: 0.0517s/iter; left time: 1191.6712s
	iters: 200, epoch: 14 | loss: 0.4107372
	speed: 0.0098s/iter; left time: 224.8765s
Epoch: 14 cost time: 3.2685887813568115
Epoch: 14, Steps: 266 | Train Loss: 0.4239612 Vali Loss: 0.6948361 Test Loss: 0.4316740
Validation loss decreased (0.695382 --> 0.694836).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4386187
	speed: 0.0487s/iter; left time: 1110.0699s
	iters: 200, epoch: 15 | loss: 0.4035424
	speed: 0.0093s/iter; left time: 211.8175s
Epoch: 15 cost time: 3.024343729019165
Epoch: 15, Steps: 266 | Train Loss: 0.4240419 Vali Loss: 0.6963508 Test Loss: 0.4320720
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3831844
	speed: 0.0503s/iter; left time: 1132.2724s
	iters: 200, epoch: 16 | loss: 0.4233701
	speed: 0.0097s/iter; left time: 217.8892s
Epoch: 16 cost time: 3.214811325073242
Epoch: 16, Steps: 266 | Train Loss: 0.4240504 Vali Loss: 0.6960199 Test Loss: 0.4322688
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4104833
	speed: 0.0528s/iter; left time: 1174.7720s
	iters: 200, epoch: 17 | loss: 0.4130620
	speed: 0.0110s/iter; left time: 243.2584s
Epoch: 17 cost time: 3.4376323223114014
Epoch: 17, Steps: 266 | Train Loss: 0.4238176 Vali Loss: 0.6957963 Test Loss: 0.4321501
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4353410
	speed: 0.0517s/iter; left time: 1135.2829s
	iters: 200, epoch: 18 | loss: 0.4402404
	speed: 0.0089s/iter; left time: 194.3192s
Epoch: 18 cost time: 3.051645278930664
Epoch: 18, Steps: 266 | Train Loss: 0.4239351 Vali Loss: 0.6959602 Test Loss: 0.4322830
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4325055
	speed: 0.0476s/iter; left time: 1034.1814s
	iters: 200, epoch: 19 | loss: 0.4081820
	speed: 0.0095s/iter; left time: 204.8210s
Epoch: 19 cost time: 3.0407533645629883
Epoch: 19, Steps: 266 | Train Loss: 0.4238809 Vali Loss: 0.6959007 Test Loss: 0.4321981
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4289832
	speed: 0.0506s/iter; left time: 1085.1439s
	iters: 200, epoch: 20 | loss: 0.4984702
	speed: 0.0091s/iter; left time: 195.1375s
Epoch: 20 cost time: 3.076380968093872
Epoch: 20, Steps: 266 | Train Loss: 0.4238652 Vali Loss: 0.6959252 Test Loss: 0.4321876
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3566702
	speed: 0.0492s/iter; left time: 1041.0678s
	iters: 200, epoch: 21 | loss: 0.4498220
	speed: 0.0097s/iter; left time: 204.2638s
Epoch: 21 cost time: 3.0908093452453613
Epoch: 21, Steps: 266 | Train Loss: 0.4240344 Vali Loss: 0.6956149 Test Loss: 0.4318862
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3983457
	speed: 0.0513s/iter; left time: 1073.0104s
	iters: 200, epoch: 22 | loss: 0.4336202
	speed: 0.0095s/iter; left time: 198.3305s
Epoch: 22 cost time: 3.146108627319336
Epoch: 22, Steps: 266 | Train Loss: 0.4238915 Vali Loss: 0.6961055 Test Loss: 0.4321466
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3947323
	speed: 0.0540s/iter; left time: 1115.8642s
	iters: 200, epoch: 23 | loss: 0.4659433
	speed: 0.0100s/iter; left time: 205.2261s
Epoch: 23 cost time: 3.291640281677246
Epoch: 23, Steps: 266 | Train Loss: 0.4239929 Vali Loss: 0.6960165 Test Loss: 0.4318239
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4350718
	speed: 0.0524s/iter; left time: 1067.9987s
	iters: 200, epoch: 24 | loss: 0.4337983
	speed: 0.0098s/iter; left time: 197.8506s
Epoch: 24 cost time: 3.2615227699279785
Epoch: 24, Steps: 266 | Train Loss: 0.4239628 Vali Loss: 0.6956039 Test Loss: 0.4317445
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3985611
	speed: 0.0523s/iter; left time: 1051.7746s
	iters: 200, epoch: 25 | loss: 0.4478891
	speed: 0.0098s/iter; left time: 195.5631s
Epoch: 25 cost time: 3.3098087310791016
Epoch: 25, Steps: 266 | Train Loss: 0.4238639 Vali Loss: 0.6962373 Test Loss: 0.4321287
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4774849
	speed: 0.0530s/iter; left time: 1051.3089s
	iters: 200, epoch: 26 | loss: 0.4230770
	speed: 0.0105s/iter; left time: 208.1548s
Epoch: 26 cost time: 3.4080162048339844
Epoch: 26, Steps: 266 | Train Loss: 0.4239222 Vali Loss: 0.6958073 Test Loss: 0.4321883
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4520712
	speed: 0.0527s/iter; left time: 1032.7432s
	iters: 200, epoch: 27 | loss: 0.4041387
	speed: 0.0095s/iter; left time: 184.2949s
Epoch: 27 cost time: 3.253304958343506
Epoch: 27, Steps: 266 | Train Loss: 0.4240751 Vali Loss: 0.6956673 Test Loss: 0.4320295
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4524561
	speed: 0.0502s/iter; left time: 968.9956s
	iters: 200, epoch: 28 | loss: 0.4394973
	speed: 0.0097s/iter; left time: 186.1573s
Epoch: 28 cost time: 3.0886268615722656
Epoch: 28, Steps: 266 | Train Loss: 0.4239356 Vali Loss: 0.6962537 Test Loss: 0.4320003
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4078483
	speed: 0.0509s/iter; left time: 968.9876s
	iters: 200, epoch: 29 | loss: 0.4151735
	speed: 0.0098s/iter; left time: 185.9087s
Epoch: 29 cost time: 3.2038819789886475
Epoch: 29, Steps: 266 | Train Loss: 0.4238036 Vali Loss: 0.6963667 Test Loss: 0.4321046
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4305757
	speed: 0.0503s/iter; left time: 945.2627s
	iters: 200, epoch: 30 | loss: 0.4187689
	speed: 0.0100s/iter; left time: 187.0063s
Epoch: 30 cost time: 3.2493155002593994
Epoch: 30, Steps: 266 | Train Loss: 0.4238661 Vali Loss: 0.6955358 Test Loss: 0.4320755
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4401814
	speed: 0.0512s/iter; left time: 947.3536s
	iters: 200, epoch: 31 | loss: 0.4256947
	speed: 0.0100s/iter; left time: 184.3682s
Epoch: 31 cost time: 3.295186996459961
Epoch: 31, Steps: 266 | Train Loss: 0.4238628 Vali Loss: 0.6952744 Test Loss: 0.4320312
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3996494
	speed: 0.0503s/iter; left time: 918.4345s
	iters: 200, epoch: 32 | loss: 0.4194170
	speed: 0.0094s/iter; left time: 171.1112s
Epoch: 32 cost time: 3.2220094203948975
Epoch: 32, Steps: 266 | Train Loss: 0.4239434 Vali Loss: 0.6961094 Test Loss: 0.4321548
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4814392
	speed: 0.0516s/iter; left time: 927.7038s
	iters: 200, epoch: 33 | loss: 0.4470727
	speed: 0.0101s/iter; left time: 179.8354s
Epoch: 33 cost time: 3.069554567337036
Epoch: 33, Steps: 266 | Train Loss: 0.4237785 Vali Loss: 0.6962668 Test Loss: 0.4321735
EarlyStopping counter: 19 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4167265
	speed: 0.0489s/iter; left time: 865.9993s
	iters: 200, epoch: 34 | loss: 0.4293379
	speed: 0.0098s/iter; left time: 171.8960s
Epoch: 34 cost time: 3.143284797668457
Epoch: 34, Steps: 266 | Train Loss: 0.4239686 Vali Loss: 0.6949379 Test Loss: 0.4321294
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_90_336_FITS_ETTm1_ftM_sl90_ll48_pl336_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.4317738711833954, mae:0.41920939087867737, rse:0.6252828240394592, corr:[0.54424375 0.54644436 0.54277104 0.53870845 0.53655154 0.53540415
 0.53354275 0.5310246  0.5289214  0.5277676  0.5269946  0.5259975
 0.52466947 0.52300453 0.5207226  0.5175803  0.51395017 0.51053894
 0.50764376 0.5050564  0.50246185 0.4994987  0.49602073 0.49217203
 0.48839313 0.48496497 0.48213884 0.4797998  0.47777885 0.47580725
 0.4743646  0.4742263  0.4747522  0.47522494 0.47546744 0.47577825
 0.4759576  0.47610965 0.47612858 0.47590452 0.4756812  0.47544092
 0.47540477 0.47555572 0.47547355 0.47509283 0.4746816  0.47447845
 0.47459072 0.47495517 0.47542417 0.47572845 0.47602934 0.47637683
 0.4769927  0.47767916 0.47829613 0.47865114 0.47857207 0.47842222
 0.47840935 0.47824207 0.4779507  0.47741312 0.47706524 0.4769669
 0.4768864  0.4767863  0.47688776 0.47726128 0.47765246 0.47811303
 0.4787509  0.47942588 0.4801667  0.48075274 0.4814203  0.48227808
 0.48316592 0.4839519  0.48455077 0.48484313 0.48508787 0.48526713
 0.48552176 0.4858663  0.48630688 0.48683527 0.48751536 0.4883969
 0.48936453 0.49023306 0.49089286 0.49126947 0.49125323 0.490705
 0.4897132  0.4887041  0.48786736 0.48720402 0.48683745 0.4866111
 0.48629215 0.48563442 0.48489988 0.48424947 0.48365688 0.4830929
 0.48249748 0.48180288 0.48096794 0.48002955 0.4790582  0.47814184
 0.47720477 0.4763037  0.47533926 0.4742841  0.47314975 0.4719506
 0.47078148 0.46956187 0.46834967 0.46741423 0.46668375 0.4660021
 0.46540618 0.4649706  0.46474466 0.46471274 0.46483982 0.46508536
 0.46523365 0.46526754 0.46503052 0.46458438 0.46415034 0.4639696
 0.46405742 0.46424785 0.46428263 0.4641116  0.46381807 0.46367067
 0.46377447 0.46414542 0.46461514 0.46489656 0.46514076 0.46532676
 0.46552834 0.46595743 0.4664096  0.46662268 0.4664469  0.46616876
 0.46599242 0.466028   0.466153   0.4662168  0.46623436 0.4661666
 0.4661131  0.46618766 0.46649736 0.46700764 0.46768886 0.4684845
 0.4693064  0.47005737 0.4706939  0.47132862 0.4718978  0.4724551
 0.4729696  0.47348014 0.47394446 0.47429413 0.4744634  0.47466105
 0.47498325 0.47545218 0.4759157  0.47641027 0.47707266 0.47792578
 0.47881323 0.47945318 0.47968748 0.47964054 0.4796693  0.4800587
 0.4808016  0.48186916 0.4829907  0.48402086 0.4849758  0.48591727
 0.486594   0.4867246  0.4865517  0.4863074  0.48585945 0.485096
 0.48402065 0.48274016 0.48131374 0.47988537 0.47841284 0.47704118
 0.47580805 0.47469413 0.4735867  0.47222906 0.47044727 0.46854004
 0.46663475 0.46501654 0.46379048 0.46295387 0.462216   0.46150783
 0.4609616  0.46082994 0.4608472  0.46076748 0.4607155  0.46050072
 0.46023214 0.46017787 0.4602813  0.46026006 0.46006456 0.4596717
 0.45928425 0.4590389  0.45880228 0.45868745 0.45875248 0.45871136
 0.45877442 0.45890495 0.45915455 0.45955476 0.45983154 0.46011725
 0.46048182 0.46098027 0.46146291 0.46189395 0.4619751  0.4618505
 0.46155727 0.46141112 0.46130675 0.46138042 0.4613016  0.4610425
 0.4609701  0.4612867  0.4617093  0.46216244 0.4625943  0.46303213
 0.4636907  0.46436998 0.46505126 0.4658679  0.4668728  0.46782416
 0.46872446 0.46948802 0.4701705  0.47068188 0.47103903 0.47131476
 0.4716745  0.47221428 0.47280943 0.47345278 0.47409868 0.4747601
 0.47544515 0.4760827  0.47653806 0.47660792 0.47605127 0.47468928
 0.4725912  0.4703391  0.46852383 0.46720967 0.46620378 0.46544054
 0.46496463 0.46468553 0.4646607  0.46456745 0.4640705  0.46319216
 0.46218333 0.46124843 0.4603875  0.45942107 0.45833758 0.45721373
 0.4563757  0.4557655  0.4552313  0.45456013 0.45364842 0.452576
 0.45153862 0.45071658 0.45010802 0.4495261  0.44860262 0.44756344
 0.44671032 0.44619253 0.44588447 0.44551244 0.44497123 0.44460052
 0.4446181  0.44498897 0.44506487 0.44443378 0.443415   0.44290096
 0.44356924 0.4445824  0.4447602  0.44425067 0.44537258 0.4495686 ]
