Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=18, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_90_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_90_336_FITS_ETTm1_ftM_sl90_ll48_pl336_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=18, out_features=85, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1370880.0
params:  1615.0
Trainable parameters:  1615
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6755482
	speed: 0.0223s/iter; left time: 590.0190s
	iters: 200, epoch: 1 | loss: 0.5726316
	speed: 0.0151s/iter; left time: 398.4446s
Epoch: 1 cost time: 4.691816329956055
Epoch: 1, Steps: 266 | Train Loss: 0.6746658 Vali Loss: 1.0223224 Test Loss: 0.7384691
Validation loss decreased (inf --> 1.022322).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4202875
	speed: 0.0725s/iter; left time: 1902.6942s
	iters: 200, epoch: 2 | loss: 0.3965887
	speed: 0.0145s/iter; left time: 378.9300s
Epoch: 2 cost time: 4.482527494430542
Epoch: 2, Steps: 266 | Train Loss: 0.4185816 Vali Loss: 0.8160042 Test Loss: 0.5398118
Validation loss decreased (1.022322 --> 0.816004).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3474342
	speed: 0.0734s/iter; left time: 1905.5121s
	iters: 200, epoch: 3 | loss: 0.3507191
	speed: 0.0164s/iter; left time: 425.1467s
Epoch: 3 cost time: 4.8162682056427
Epoch: 3, Steps: 266 | Train Loss: 0.3645228 Vali Loss: 0.7545654 Test Loss: 0.4834134
Validation loss decreased (0.816004 --> 0.754565).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3303326
	speed: 0.0708s/iter; left time: 1818.5066s
	iters: 200, epoch: 4 | loss: 0.3539725
	speed: 0.0149s/iter; left time: 380.6532s
Epoch: 4 cost time: 4.535531997680664
Epoch: 4, Steps: 266 | Train Loss: 0.3496010 Vali Loss: 0.7288620 Test Loss: 0.4598703
Validation loss decreased (0.754565 --> 0.728862).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3152581
	speed: 0.0743s/iter; left time: 1890.0918s
	iters: 200, epoch: 5 | loss: 0.3174538
	speed: 0.0145s/iter; left time: 366.7677s
Epoch: 5 cost time: 4.673977375030518
Epoch: 5, Steps: 266 | Train Loss: 0.3440161 Vali Loss: 0.7154629 Test Loss: 0.4477589
Validation loss decreased (0.728862 --> 0.715463).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3575916
	speed: 0.0723s/iter; left time: 1820.1705s
	iters: 200, epoch: 6 | loss: 0.3490390
	speed: 0.0147s/iter; left time: 368.8583s
Epoch: 6 cost time: 4.5666046142578125
Epoch: 6, Steps: 266 | Train Loss: 0.3417084 Vali Loss: 0.7075982 Test Loss: 0.4415104
Validation loss decreased (0.715463 --> 0.707598).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3294263
	speed: 0.0746s/iter; left time: 1859.1351s
	iters: 200, epoch: 7 | loss: 0.3236956
	speed: 0.0145s/iter; left time: 359.3218s
Epoch: 7 cost time: 4.370528221130371
Epoch: 7, Steps: 266 | Train Loss: 0.3406802 Vali Loss: 0.7040619 Test Loss: 0.4383206
Validation loss decreased (0.707598 --> 0.704062).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3503221
	speed: 0.0734s/iter; left time: 1807.4766s
	iters: 200, epoch: 8 | loss: 0.3359497
	speed: 0.0149s/iter; left time: 366.4170s
Epoch: 8 cost time: 4.49118709564209
Epoch: 8, Steps: 266 | Train Loss: 0.3402503 Vali Loss: 0.7020401 Test Loss: 0.4364641
Validation loss decreased (0.704062 --> 0.702040).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3199846
	speed: 0.0732s/iter; left time: 1783.1872s
	iters: 200, epoch: 9 | loss: 0.3210539
	speed: 0.0158s/iter; left time: 383.8569s
Epoch: 9 cost time: 4.832651376724243
Epoch: 9, Steps: 266 | Train Loss: 0.3400266 Vali Loss: 0.7013435 Test Loss: 0.4356822
Validation loss decreased (0.702040 --> 0.701344).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3448470
	speed: 0.0782s/iter; left time: 1885.7729s
	iters: 200, epoch: 10 | loss: 0.3449138
	speed: 0.0207s/iter; left time: 497.2437s
Epoch: 10 cost time: 5.32530665397644
Epoch: 10, Steps: 266 | Train Loss: 0.3399085 Vali Loss: 0.7007432 Test Loss: 0.4352231
Validation loss decreased (0.701344 --> 0.700743).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3320007
	speed: 0.0808s/iter; left time: 1926.5009s
	iters: 200, epoch: 11 | loss: 0.3560926
	speed: 0.0156s/iter; left time: 369.9953s
Epoch: 11 cost time: 5.229879140853882
Epoch: 11, Steps: 266 | Train Loss: 0.3401074 Vali Loss: 0.7007540 Test Loss: 0.4350578
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3350705
	speed: 0.0777s/iter; left time: 1831.7899s
	iters: 200, epoch: 12 | loss: 0.3267081
	speed: 0.0149s/iter; left time: 350.2730s
Epoch: 12 cost time: 4.894148826599121
Epoch: 12, Steps: 266 | Train Loss: 0.3399191 Vali Loss: 0.7007869 Test Loss: 0.4352879
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3621461
	speed: 0.0838s/iter; left time: 1952.6185s
	iters: 200, epoch: 13 | loss: 0.3180936
	speed: 0.0161s/iter; left time: 372.7792s
Epoch: 13 cost time: 4.664725065231323
Epoch: 13, Steps: 266 | Train Loss: 0.3399989 Vali Loss: 0.6997803 Test Loss: 0.4349549
Validation loss decreased (0.700743 --> 0.699780).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3731582
	speed: 0.0759s/iter; left time: 1749.9907s
	iters: 200, epoch: 14 | loss: 0.3468611
	speed: 0.0145s/iter; left time: 332.5001s
Epoch: 14 cost time: 4.638400077819824
Epoch: 14, Steps: 266 | Train Loss: 0.3398827 Vali Loss: 0.7005069 Test Loss: 0.4349167
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3346480
	speed: 0.0716s/iter; left time: 1630.0928s
	iters: 200, epoch: 15 | loss: 0.3495743
	speed: 0.0147s/iter; left time: 332.8939s
Epoch: 15 cost time: 4.494571208953857
Epoch: 15, Steps: 266 | Train Loss: 0.3400577 Vali Loss: 0.7005976 Test Loss: 0.4351759
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3296883
	speed: 0.0732s/iter; left time: 1648.1110s
	iters: 200, epoch: 16 | loss: 0.3527744
	speed: 0.0153s/iter; left time: 341.9662s
Epoch: 16 cost time: 4.706994533538818
Epoch: 16, Steps: 266 | Train Loss: 0.3400956 Vali Loss: 0.7005792 Test Loss: 0.4349644
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3566626
	speed: 0.0730s/iter; left time: 1623.7958s
	iters: 200, epoch: 17 | loss: 0.3053190
	speed: 0.0153s/iter; left time: 339.5371s
Epoch: 17 cost time: 4.733590126037598
Epoch: 17, Steps: 266 | Train Loss: 0.3399105 Vali Loss: 0.7000186 Test Loss: 0.4348334
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3346822
	speed: 0.0921s/iter; left time: 2024.8469s
	iters: 200, epoch: 18 | loss: 0.3493452
	speed: 0.0163s/iter; left time: 356.9992s
Epoch: 18 cost time: 5.334430694580078
Epoch: 18, Steps: 266 | Train Loss: 0.3400307 Vali Loss: 0.7005377 Test Loss: 0.4349951
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3392993
	speed: 0.0735s/iter; left time: 1595.8003s
	iters: 200, epoch: 19 | loss: 0.3214392
	speed: 0.0152s/iter; left time: 327.8387s
Epoch: 19 cost time: 4.8279993534088135
Epoch: 19, Steps: 266 | Train Loss: 0.3399070 Vali Loss: 0.6999627 Test Loss: 0.4349574
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3450561
	speed: 0.0843s/iter; left time: 1807.4911s
	iters: 200, epoch: 20 | loss: 0.3451740
	speed: 0.0143s/iter; left time: 305.9568s
Epoch: 20 cost time: 5.158308267593384
Epoch: 20, Steps: 266 | Train Loss: 0.3400044 Vali Loss: 0.7008365 Test Loss: 0.4352941
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3650060
	speed: 0.0711s/iter; left time: 1506.1935s
	iters: 200, epoch: 21 | loss: 0.2894316
	speed: 0.0144s/iter; left time: 303.4646s
Epoch: 21 cost time: 4.402056932449341
Epoch: 21, Steps: 266 | Train Loss: 0.3399158 Vali Loss: 0.7000359 Test Loss: 0.4349115
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3630136
	speed: 0.0716s/iter; left time: 1497.8203s
	iters: 200, epoch: 22 | loss: 0.3837070
	speed: 0.0141s/iter; left time: 293.0161s
Epoch: 22 cost time: 4.4325666427612305
Epoch: 22, Steps: 266 | Train Loss: 0.3400658 Vali Loss: 0.7006835 Test Loss: 0.4352592
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3606960
	speed: 0.0749s/iter; left time: 1547.4876s
	iters: 200, epoch: 23 | loss: 0.3773449
	speed: 0.0145s/iter; left time: 298.6977s
Epoch: 23 cost time: 4.756354093551636
Epoch: 23, Steps: 266 | Train Loss: 0.3399755 Vali Loss: 0.7000371 Test Loss: 0.4353828
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3528994
	speed: 0.0778s/iter; left time: 1585.5997s
	iters: 200, epoch: 24 | loss: 0.3225088
	speed: 0.0152s/iter; left time: 308.0007s
Epoch: 24 cost time: 4.875050067901611
Epoch: 24, Steps: 266 | Train Loss: 0.3399116 Vali Loss: 0.7005457 Test Loss: 0.4352340
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3579367
	speed: 0.0728s/iter; left time: 1465.3992s
	iters: 200, epoch: 25 | loss: 0.3389480
	speed: 0.0147s/iter; left time: 294.7771s
Epoch: 25 cost time: 4.499933481216431
Epoch: 25, Steps: 266 | Train Loss: 0.3399909 Vali Loss: 0.7007023 Test Loss: 0.4351768
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3091183
	speed: 0.0716s/iter; left time: 1420.9196s
	iters: 200, epoch: 26 | loss: 0.3024263
	speed: 0.0145s/iter; left time: 285.7416s
Epoch: 26 cost time: 4.3758015632629395
Epoch: 26, Steps: 266 | Train Loss: 0.3397882 Vali Loss: 0.7005087 Test Loss: 0.4351678
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3566938
	speed: 0.0719s/iter; left time: 1408.6815s
	iters: 200, epoch: 27 | loss: 0.3242511
	speed: 0.0144s/iter; left time: 280.5916s
Epoch: 27 cost time: 4.61687970161438
Epoch: 27, Steps: 266 | Train Loss: 0.3399827 Vali Loss: 0.7009288 Test Loss: 0.4352731
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3343934
	speed: 0.0727s/iter; left time: 1403.8718s
	iters: 200, epoch: 28 | loss: 0.3779176
	speed: 0.0143s/iter; left time: 274.8903s
Epoch: 28 cost time: 4.527625322341919
Epoch: 28, Steps: 266 | Train Loss: 0.3398779 Vali Loss: 0.6998671 Test Loss: 0.4353503
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3660532
	speed: 0.0731s/iter; left time: 1393.5492s
	iters: 200, epoch: 29 | loss: 0.3605665
	speed: 0.0166s/iter; left time: 314.0964s
Epoch: 29 cost time: 4.718443155288696
Epoch: 29, Steps: 266 | Train Loss: 0.3399799 Vali Loss: 0.7009381 Test Loss: 0.4352533
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3379387
	speed: 0.0716s/iter; left time: 1345.2115s
	iters: 200, epoch: 30 | loss: 0.3415634
	speed: 0.0144s/iter; left time: 269.8600s
Epoch: 30 cost time: 4.499791383743286
Epoch: 30, Steps: 266 | Train Loss: 0.3399596 Vali Loss: 0.7007051 Test Loss: 0.4352323
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3232069
	speed: 0.0725s/iter; left time: 1342.3750s
	iters: 200, epoch: 31 | loss: 0.3287565
	speed: 0.0158s/iter; left time: 290.1333s
Epoch: 31 cost time: 5.017382621765137
Epoch: 31, Steps: 266 | Train Loss: 0.3399107 Vali Loss: 0.6998903 Test Loss: 0.4353578
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3333045
	speed: 0.0794s/iter; left time: 1449.6535s
	iters: 200, epoch: 32 | loss: 0.3269006
	speed: 0.0221s/iter; left time: 401.6234s
Epoch: 32 cost time: 5.360791921615601
Epoch: 32, Steps: 266 | Train Loss: 0.3398634 Vali Loss: 0.7005556 Test Loss: 0.4352030
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3564308
	speed: 0.0780s/iter; left time: 1403.1504s
	iters: 200, epoch: 33 | loss: 0.3139695
	speed: 0.0162s/iter; left time: 289.2198s
Epoch: 33 cost time: 5.101074934005737
Epoch: 33, Steps: 266 | Train Loss: 0.3399101 Vali Loss: 0.7005547 Test Loss: 0.4352193
EarlyStopping counter: 20 out of 20
Early stopping
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=18, out_features=85, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1370880.0
params:  1615.0
Trainable parameters:  1615
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4177682
	speed: 0.0232s/iter; left time: 614.5287s
	iters: 200, epoch: 1 | loss: 0.4296980
	speed: 0.0163s/iter; left time: 430.0044s
Epoch: 1 cost time: 4.878462791442871
Epoch: 1, Steps: 266 | Train Loss: 0.4247208 Vali Loss: 0.6949859 Test Loss: 0.4316859
Validation loss decreased (inf --> 0.694986).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4228841
	speed: 0.0708s/iter; left time: 1857.2542s
	iters: 200, epoch: 2 | loss: 0.4012569
	speed: 0.0152s/iter; left time: 397.0789s
Epoch: 2 cost time: 4.612399339675903
Epoch: 2, Steps: 266 | Train Loss: 0.4240771 Vali Loss: 0.6943545 Test Loss: 0.4311461
Validation loss decreased (0.694986 --> 0.694354).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4311267
	speed: 0.0799s/iter; left time: 2073.8669s
	iters: 200, epoch: 3 | loss: 0.4273919
	speed: 0.0154s/iter; left time: 399.5521s
Epoch: 3 cost time: 4.604907274246216
Epoch: 3, Steps: 266 | Train Loss: 0.4241136 Vali Loss: 0.6958050 Test Loss: 0.4312375
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.5075922
	speed: 0.0712s/iter; left time: 1830.3010s
	iters: 200, epoch: 4 | loss: 0.4304426
	speed: 0.0151s/iter; left time: 386.4751s
Epoch: 4 cost time: 4.71314811706543
Epoch: 4, Steps: 266 | Train Loss: 0.4239789 Vali Loss: 0.6947224 Test Loss: 0.4304337
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4055524
	speed: 0.0774s/iter; left time: 1967.9163s
	iters: 200, epoch: 5 | loss: 0.4153574
	speed: 0.0211s/iter; left time: 533.7371s
Epoch: 5 cost time: 5.192735910415649
Epoch: 5, Steps: 266 | Train Loss: 0.4238904 Vali Loss: 0.6947640 Test Loss: 0.4313459
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4000082
	speed: 0.0742s/iter; left time: 1866.7110s
	iters: 200, epoch: 6 | loss: 0.4284219
	speed: 0.0154s/iter; left time: 385.0664s
Epoch: 6 cost time: 4.796715259552002
Epoch: 6, Steps: 266 | Train Loss: 0.4236745 Vali Loss: 0.6961476 Test Loss: 0.4316452
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3929275
	speed: 0.0788s/iter; left time: 1962.1915s
	iters: 200, epoch: 7 | loss: 0.4783123
	speed: 0.0146s/iter; left time: 363.3420s
Epoch: 7 cost time: 4.769574403762817
Epoch: 7, Steps: 266 | Train Loss: 0.4236543 Vali Loss: 0.6946391 Test Loss: 0.4315049
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4344353
	speed: 0.0703s/iter; left time: 1733.2708s
	iters: 200, epoch: 8 | loss: 0.4388060
	speed: 0.0196s/iter; left time: 481.9661s
Epoch: 8 cost time: 4.782426357269287
Epoch: 8, Steps: 266 | Train Loss: 0.4238781 Vali Loss: 0.6959854 Test Loss: 0.4318229
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4033902
	speed: 0.0698s/iter; left time: 1702.0138s
	iters: 200, epoch: 9 | loss: 0.4104082
	speed: 0.0180s/iter; left time: 437.4139s
Epoch: 9 cost time: 5.019185781478882
Epoch: 9, Steps: 266 | Train Loss: 0.4237904 Vali Loss: 0.6967487 Test Loss: 0.4323698
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4505555
	speed: 0.0783s/iter; left time: 1886.6428s
	iters: 200, epoch: 10 | loss: 0.4114224
	speed: 0.0163s/iter; left time: 391.7335s
Epoch: 10 cost time: 6.26061487197876
Epoch: 10, Steps: 266 | Train Loss: 0.4238488 Vali Loss: 0.6949942 Test Loss: 0.4312561
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3954755
	speed: 0.0922s/iter; left time: 2199.0577s
	iters: 200, epoch: 11 | loss: 0.4260532
	speed: 0.0163s/iter; left time: 386.8709s
Epoch: 11 cost time: 4.883346319198608
Epoch: 11, Steps: 266 | Train Loss: 0.4236612 Vali Loss: 0.6954235 Test Loss: 0.4315343
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4476601
	speed: 0.0820s/iter; left time: 1932.5966s
	iters: 200, epoch: 12 | loss: 0.4234694
	speed: 0.0148s/iter; left time: 347.1622s
Epoch: 12 cost time: 5.326679468154907
Epoch: 12, Steps: 266 | Train Loss: 0.4235973 Vali Loss: 0.6953678 Test Loss: 0.4317634
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4111209
	speed: 0.0742s/iter; left time: 1728.6827s
	iters: 200, epoch: 13 | loss: 0.3921053
	speed: 0.0149s/iter; left time: 346.9578s
Epoch: 13 cost time: 4.706080913543701
Epoch: 13, Steps: 266 | Train Loss: 0.4237063 Vali Loss: 0.6949995 Test Loss: 0.4315715
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4374935
	speed: 0.0794s/iter; left time: 1829.9937s
	iters: 200, epoch: 14 | loss: 0.3917465
	speed: 0.0220s/iter; left time: 505.7532s
Epoch: 14 cost time: 5.328381299972534
Epoch: 14, Steps: 266 | Train Loss: 0.4237815 Vali Loss: 0.6953331 Test Loss: 0.4314692
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3981673
	speed: 0.0759s/iter; left time: 1728.3508s
	iters: 200, epoch: 15 | loss: 0.4568624
	speed: 0.0203s/iter; left time: 460.3370s
Epoch: 15 cost time: 5.04992938041687
Epoch: 15, Steps: 266 | Train Loss: 0.4235361 Vali Loss: 0.6953377 Test Loss: 0.4314459
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4082061
	speed: 0.0742s/iter; left time: 1670.3629s
	iters: 200, epoch: 16 | loss: 0.4118421
	speed: 0.0155s/iter; left time: 347.3179s
Epoch: 16 cost time: 4.925384998321533
Epoch: 16, Steps: 266 | Train Loss: 0.4237695 Vali Loss: 0.6939218 Test Loss: 0.4310975
Validation loss decreased (0.694354 --> 0.693922).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4133432
	speed: 0.0735s/iter; left time: 1636.0607s
	iters: 200, epoch: 17 | loss: 0.4549869
	speed: 0.0155s/iter; left time: 343.3033s
Epoch: 17 cost time: 4.527781963348389
Epoch: 17, Steps: 266 | Train Loss: 0.4237195 Vali Loss: 0.6949860 Test Loss: 0.4314806
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4259816
	speed: 0.0721s/iter; left time: 1584.5867s
	iters: 200, epoch: 18 | loss: 0.4124725
	speed: 0.0155s/iter; left time: 339.9985s
Epoch: 18 cost time: 4.647992134094238
Epoch: 18, Steps: 266 | Train Loss: 0.4236950 Vali Loss: 0.6945710 Test Loss: 0.4316167
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4536989
	speed: 0.0731s/iter; left time: 1586.3283s
	iters: 200, epoch: 19 | loss: 0.4279892
	speed: 0.0185s/iter; left time: 399.5468s
Epoch: 19 cost time: 5.188042640686035
Epoch: 19, Steps: 266 | Train Loss: 0.4236882 Vali Loss: 0.6957030 Test Loss: 0.4316497
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4402910
	speed: 0.0773s/iter; left time: 1657.6741s
	iters: 200, epoch: 20 | loss: 0.3792170
	speed: 0.0154s/iter; left time: 327.7752s
Epoch: 20 cost time: 4.652595281600952
Epoch: 20, Steps: 266 | Train Loss: 0.4237639 Vali Loss: 0.6936717 Test Loss: 0.4316315
Validation loss decreased (0.693922 --> 0.693672).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3748413
	speed: 0.0750s/iter; left time: 1588.6241s
	iters: 200, epoch: 21 | loss: 0.4371796
	speed: 0.0191s/iter; left time: 401.7255s
Epoch: 21 cost time: 5.376135349273682
Epoch: 21, Steps: 266 | Train Loss: 0.4237135 Vali Loss: 0.6954626 Test Loss: 0.4319049
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4331192
	speed: 0.0813s/iter; left time: 1700.0413s
	iters: 200, epoch: 22 | loss: 0.4063551
	speed: 0.0144s/iter; left time: 300.2817s
Epoch: 22 cost time: 4.678671598434448
Epoch: 22, Steps: 266 | Train Loss: 0.4235919 Vali Loss: 0.6957947 Test Loss: 0.4315309
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4235016
	speed: 0.0738s/iter; left time: 1523.4833s
	iters: 200, epoch: 23 | loss: 0.4102109
	speed: 0.0157s/iter; left time: 323.3564s
Epoch: 23 cost time: 4.698245525360107
Epoch: 23, Steps: 266 | Train Loss: 0.4235891 Vali Loss: 0.6951131 Test Loss: 0.4317485
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4107183
	speed: 0.0757s/iter; left time: 1543.8727s
	iters: 200, epoch: 24 | loss: 0.4309381
	speed: 0.0226s/iter; left time: 458.9695s
Epoch: 24 cost time: 5.276423692703247
Epoch: 24, Steps: 266 | Train Loss: 0.4237129 Vali Loss: 0.6950581 Test Loss: 0.4316066
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4084393
	speed: 0.0812s/iter; left time: 1634.0916s
	iters: 200, epoch: 25 | loss: 0.4480187
	speed: 0.0154s/iter; left time: 308.3784s
Epoch: 25 cost time: 4.696670293807983
Epoch: 25, Steps: 266 | Train Loss: 0.4236077 Vali Loss: 0.6951708 Test Loss: 0.4316235
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4345273
	speed: 0.0761s/iter; left time: 1511.2548s
	iters: 200, epoch: 26 | loss: 0.4497557
	speed: 0.0164s/iter; left time: 323.4156s
Epoch: 26 cost time: 4.689032554626465
Epoch: 26, Steps: 266 | Train Loss: 0.4236373 Vali Loss: 0.6956391 Test Loss: 0.4316442
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3931666
	speed: 0.0771s/iter; left time: 1510.9480s
	iters: 200, epoch: 27 | loss: 0.4290217
	speed: 0.0155s/iter; left time: 302.4697s
Epoch: 27 cost time: 4.916656494140625
Epoch: 27, Steps: 266 | Train Loss: 0.4236540 Vali Loss: 0.6953607 Test Loss: 0.4317254
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4386593
	speed: 0.0739s/iter; left time: 1427.7894s
	iters: 200, epoch: 28 | loss: 0.4067630
	speed: 0.0178s/iter; left time: 341.5059s
Epoch: 28 cost time: 4.921972990036011
Epoch: 28, Steps: 266 | Train Loss: 0.4237168 Vali Loss: 0.6941580 Test Loss: 0.4316811
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3886625
	speed: 0.0749s/iter; left time: 1427.3343s
	iters: 200, epoch: 29 | loss: 0.5097684
	speed: 0.0239s/iter; left time: 453.1900s
Epoch: 29 cost time: 5.628311634063721
Epoch: 29, Steps: 266 | Train Loss: 0.4237885 Vali Loss: 0.6957323 Test Loss: 0.4317301
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4293461
	speed: 0.0729s/iter; left time: 1368.6765s
	iters: 200, epoch: 30 | loss: 0.4411868
	speed: 0.0271s/iter; left time: 505.8675s
Epoch: 30 cost time: 5.744267702102661
Epoch: 30, Steps: 266 | Train Loss: 0.4235193 Vali Loss: 0.6949303 Test Loss: 0.4318680
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4152758
	speed: 0.0757s/iter; left time: 1401.3195s
	iters: 200, epoch: 31 | loss: 0.4046513
	speed: 0.0153s/iter; left time: 281.9949s
Epoch: 31 cost time: 4.788309335708618
Epoch: 31, Steps: 266 | Train Loss: 0.4236737 Vali Loss: 0.6949505 Test Loss: 0.4316615
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3910808
	speed: 0.0739s/iter; left time: 1348.7808s
	iters: 200, epoch: 32 | loss: 0.3825889
	speed: 0.0185s/iter; left time: 336.1147s
Epoch: 32 cost time: 5.067349910736084
Epoch: 32, Steps: 266 | Train Loss: 0.4236267 Vali Loss: 0.6950724 Test Loss: 0.4317328
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4543296
	speed: 0.0745s/iter; left time: 1339.4035s
	iters: 200, epoch: 33 | loss: 0.4207411
	speed: 0.0154s/iter; left time: 275.7818s
Epoch: 33 cost time: 4.603333950042725
Epoch: 33, Steps: 266 | Train Loss: 0.4237538 Vali Loss: 0.6948335 Test Loss: 0.4317098
EarlyStopping counter: 13 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4566704
	speed: 0.0701s/iter; left time: 1242.7164s
	iters: 200, epoch: 34 | loss: 0.3975501
	speed: 0.0202s/iter; left time: 356.6603s
Epoch: 34 cost time: 5.445537328720093
Epoch: 34, Steps: 266 | Train Loss: 0.4235019 Vali Loss: 0.6956592 Test Loss: 0.4315045
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4319299
	speed: 0.0900s/iter; left time: 1571.4505s
	iters: 200, epoch: 35 | loss: 0.3943331
	speed: 0.0150s/iter; left time: 260.1342s
Epoch: 35 cost time: 5.6860857009887695
Epoch: 35, Steps: 266 | Train Loss: 0.4236414 Vali Loss: 0.6957708 Test Loss: 0.4316445
EarlyStopping counter: 15 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4592221
	speed: 0.0803s/iter; left time: 1380.0001s
	iters: 200, epoch: 36 | loss: 0.3859333
	speed: 0.0156s/iter; left time: 266.1229s
Epoch: 36 cost time: 4.9296863079071045
Epoch: 36, Steps: 266 | Train Loss: 0.4235441 Vali Loss: 0.6955394 Test Loss: 0.4316681
EarlyStopping counter: 16 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3853863
	speed: 0.0820s/iter; left time: 1388.4327s
	iters: 200, epoch: 37 | loss: 0.4113323
	speed: 0.0174s/iter; left time: 292.9481s
Epoch: 37 cost time: 5.437297344207764
Epoch: 37, Steps: 266 | Train Loss: 0.4237330 Vali Loss: 0.6955032 Test Loss: 0.4316961
EarlyStopping counter: 17 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.5079339
	speed: 0.0755s/iter; left time: 1257.0960s
	iters: 200, epoch: 38 | loss: 0.4075943
	speed: 0.0145s/iter; left time: 239.7543s
Epoch: 38 cost time: 4.530063629150391
Epoch: 38, Steps: 266 | Train Loss: 0.4235842 Vali Loss: 0.6947389 Test Loss: 0.4316802
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3766384
	speed: 0.0822s/iter; left time: 1348.2473s
	iters: 200, epoch: 39 | loss: 0.3731336
	speed: 0.0150s/iter; left time: 244.7744s
Epoch: 39 cost time: 4.9950151443481445
Epoch: 39, Steps: 266 | Train Loss: 0.4234894 Vali Loss: 0.6952322 Test Loss: 0.4316801
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.4143145
	speed: 0.0737s/iter; left time: 1188.9240s
	iters: 200, epoch: 40 | loss: 0.3933526
	speed: 0.0161s/iter; left time: 258.7833s
Epoch: 40 cost time: 4.598772287368774
Epoch: 40, Steps: 266 | Train Loss: 0.4235408 Vali Loss: 0.6947546 Test Loss: 0.4316444
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_90_336_FITS_ETTm1_ftM_sl90_ll48_pl336_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.4317325949668884, mae:0.4193023443222046, rse:0.625252902507782, corr:[0.5449475  0.5459683  0.5414707  0.53873444 0.5376902  0.53594726
 0.5329227  0.5303696  0.52908725 0.52828646 0.5272388  0.52589107
 0.5245475  0.5229843  0.5205379  0.5172271  0.51375926 0.5106938
 0.5079361  0.50508744 0.50207585 0.49905342 0.49606696 0.49282858
 0.48920292 0.48528135 0.481783   0.47922558 0.4774774  0.47582784
 0.47444728 0.47421476 0.4746834  0.4751687  0.4753732  0.475632
 0.47581664 0.47606298 0.47615233 0.47589388 0.47558126 0.47529915
 0.47531134 0.4754677  0.47523475 0.47463775 0.474176   0.47415558
 0.47451428 0.47502008 0.47550014 0.47576946 0.47611666 0.47653094
 0.47713557 0.47766262 0.47807658 0.47832695 0.47823843 0.47810015
 0.47801453 0.4777158  0.47746798 0.4772398  0.47723824 0.47714362
 0.47665867 0.4761459  0.47625452 0.47703338 0.47776824 0.47820643
 0.47855464 0.47902587 0.47989178 0.4807665  0.48156345 0.48226175
 0.4828656  0.48353457 0.48427072 0.4848025  0.48523608 0.48547786
 0.48573142 0.4861327  0.4867344  0.48743036 0.48812622 0.48881152
 0.4895141  0.49024725 0.49096182 0.49144924 0.49145758 0.49087253
 0.48985445 0.4887976  0.4878487  0.4870209  0.48649344 0.48616627
 0.48585886 0.48540896 0.4850252  0.48469156 0.48419285 0.48345724
 0.48259136 0.48175493 0.4809502  0.4800662  0.4790673  0.4780727
 0.47712162 0.47631952 0.47546008 0.47445303 0.47337192 0.47229594
 0.47127527 0.47007182 0.46871364 0.46759555 0.4667459  0.46603984
 0.46549028 0.46511066 0.46488371 0.46476898 0.4647592  0.46486163
 0.4648788  0.46486366 0.46473    0.46454188 0.4643979  0.4643439
 0.4642721  0.46411806 0.46391636 0.46387446 0.46399596 0.4641889
 0.46427208 0.46434233 0.464547   0.46478057 0.46509546 0.46522155
 0.46516734 0.46533355 0.46570095 0.46601108 0.4659585  0.4657423
 0.4655819  0.46565646 0.46585485 0.46598536 0.4660105  0.46586847
 0.46573153 0.46579242 0.46616113 0.46676022 0.4675289  0.46835062
 0.46906832 0.4695773  0.4699594  0.47055253 0.47133264 0.4722018
 0.47289202 0.47334746 0.47366583 0.47399843 0.47433642 0.4747398
 0.475126   0.4755228  0.47595128 0.4765856  0.47747332 0.47840542
 0.47913176 0.4795283  0.47967833 0.4797864  0.4800706  0.4806064
 0.48130736 0.48219743 0.48318785 0.48423305 0.4852899  0.4862595
 0.48676953 0.48664746 0.48637694 0.4861795  0.48575935 0.4849129
 0.4837595  0.48256853 0.48137102 0.48010576 0.4785973  0.4770629
 0.47571376 0.47463983 0.47366542 0.4723958  0.47066164 0.46888638
 0.4671714  0.46568263 0.4644005  0.46334282 0.4623215  0.46142918
 0.46085516 0.46075907 0.46072027 0.4604862  0.4603851  0.46028742
 0.4601777  0.4601588  0.46013123 0.45993498 0.45969912 0.45939404
 0.45909187 0.458833   0.45855913 0.45854336 0.4588269  0.45891783
 0.45892483 0.45890993 0.45912758 0.45960993 0.45988744 0.46002504
 0.46022788 0.4607223  0.46131477 0.46177334 0.46165094 0.46127382
 0.46095768 0.46109504 0.4613054  0.4614804  0.46127558 0.46092954
 0.46102285 0.461608   0.4620296  0.46214965 0.4622411  0.4626833
 0.46370128 0.4647183  0.4654178  0.46600464 0.46683747 0.4678225
 0.46884063 0.46957943 0.47009885 0.47054374 0.47112024 0.47177425
 0.47232988 0.47269905 0.4729141  0.47332248 0.4740815  0.4750609
 0.4759476  0.4765128  0.4767202  0.47658    0.47601613 0.47484523
 0.47291008 0.4705639  0.46847206 0.4669488  0.46595073 0.46538386
 0.46512225 0.46499667 0.46502075 0.46489474 0.46437204 0.46354762
 0.46264914 0.46173695 0.46065706 0.4593088  0.4580013  0.45703325
 0.45653215 0.45599896 0.45513785 0.4540609  0.4531686  0.45259154
 0.45200258 0.45107168 0.44989887 0.44896227 0.4483182  0.4478941
 0.4472919  0.44644886 0.44582415 0.44575468 0.44587788 0.44556406
 0.44458163 0.44382426 0.44393405 0.4444471  0.44427335 0.44330236
 0.44303814 0.44419077 0.4455005  0.44535026 0.44529778 0.448718  ]
