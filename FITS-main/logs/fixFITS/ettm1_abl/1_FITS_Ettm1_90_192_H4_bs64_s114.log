Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=14, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_90_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_90_192_FITS_ETTm1_ftM_sl90_ll48_pl192_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34279
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=14, out_features=43, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  539392.0
params:  645.0
Trainable parameters:  645
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5634964
	speed: 0.0714s/iter; left time: 1898.2629s
	iters: 200, epoch: 1 | loss: 0.5177501
	speed: 0.0851s/iter; left time: 2254.0929s
Epoch: 1 cost time: 20.553174257278442
Epoch: 1, Steps: 267 | Train Loss: 0.5752405 Vali Loss: 0.6879790 Test Loss: 0.5383173
Validation loss decreased (inf --> 0.687979).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3928742
	speed: 0.3451s/iter; left time: 9087.5175s
	iters: 200, epoch: 2 | loss: 0.3724795
	speed: 0.0859s/iter; left time: 2252.3700s
Epoch: 2 cost time: 20.81094527244568
Epoch: 2, Steps: 267 | Train Loss: 0.4075867 Vali Loss: 0.5785149 Test Loss: 0.4306819
Validation loss decreased (0.687979 --> 0.578515).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3814263
	speed: 0.3453s/iter; left time: 9000.2877s
	iters: 200, epoch: 3 | loss: 0.3932843
	speed: 0.0966s/iter; left time: 2508.8053s
Epoch: 3 cost time: 26.095885038375854
Epoch: 3, Steps: 267 | Train Loss: 0.3835216 Vali Loss: 0.5575742 Test Loss: 0.4106800
Validation loss decreased (0.578515 --> 0.557574).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3511715
	speed: 0.4214s/iter; left time: 10872.0366s
	iters: 200, epoch: 4 | loss: 0.4341361
	speed: 0.0971s/iter; left time: 2495.1685s
Epoch: 4 cost time: 25.27280044555664
Epoch: 4, Steps: 267 | Train Loss: 0.3788782 Vali Loss: 0.5515799 Test Loss: 0.4044238
Validation loss decreased (0.557574 --> 0.551580).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3684562
	speed: 0.4179s/iter; left time: 10669.1427s
	iters: 200, epoch: 5 | loss: 0.3649172
	speed: 0.0951s/iter; left time: 2417.7097s
Epoch: 5 cost time: 28.056087255477905
Epoch: 5, Steps: 267 | Train Loss: 0.3772274 Vali Loss: 0.5495461 Test Loss: 0.4018586
Validation loss decreased (0.551580 --> 0.549546).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3767555
	speed: 0.4475s/iter; left time: 11306.0327s
	iters: 200, epoch: 6 | loss: 0.3693714
	speed: 0.0909s/iter; left time: 2286.7385s
Epoch: 6 cost time: 25.650250911712646
Epoch: 6, Steps: 267 | Train Loss: 0.3765333 Vali Loss: 0.5483124 Test Loss: 0.4014044
Validation loss decreased (0.549546 --> 0.548312).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3727548
	speed: 0.3823s/iter; left time: 9557.7941s
	iters: 200, epoch: 7 | loss: 0.4025485
	speed: 0.0999s/iter; left time: 2486.5773s
Epoch: 7 cost time: 26.53953194618225
Epoch: 7, Steps: 267 | Train Loss: 0.3762421 Vali Loss: 0.5478454 Test Loss: 0.4006997
Validation loss decreased (0.548312 --> 0.547845).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3340937
	speed: 0.4414s/iter; left time: 10915.6091s
	iters: 200, epoch: 8 | loss: 0.3584529
	speed: 0.0932s/iter; left time: 2295.0513s
Epoch: 8 cost time: 24.381556034088135
Epoch: 8, Steps: 267 | Train Loss: 0.3759054 Vali Loss: 0.5462039 Test Loss: 0.4007430
Validation loss decreased (0.547845 --> 0.546204).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4488259
	speed: 0.4042s/iter; left time: 9888.6279s
	iters: 200, epoch: 9 | loss: 0.4033048
	speed: 0.0917s/iter; left time: 2235.3535s
Epoch: 9 cost time: 26.90419578552246
Epoch: 9, Steps: 267 | Train Loss: 0.3757749 Vali Loss: 0.5476002 Test Loss: 0.4009535
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3474497
	speed: 0.4059s/iter; left time: 9822.6603s
	iters: 200, epoch: 10 | loss: 0.3387910
	speed: 0.0857s/iter; left time: 2064.6258s
Epoch: 10 cost time: 24.213584184646606
Epoch: 10, Steps: 267 | Train Loss: 0.3755578 Vali Loss: 0.5472569 Test Loss: 0.4006190
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3751852
	speed: 0.3647s/iter; left time: 8727.9956s
	iters: 200, epoch: 11 | loss: 0.3444944
	speed: 0.0924s/iter; left time: 2201.6028s
Epoch: 11 cost time: 21.286526918411255
Epoch: 11, Steps: 267 | Train Loss: 0.3755743 Vali Loss: 0.5475634 Test Loss: 0.4014645
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3438912
	speed: 0.3050s/iter; left time: 7217.4390s
	iters: 200, epoch: 12 | loss: 0.3950946
	speed: 0.0696s/iter; left time: 1640.2651s
Epoch: 12 cost time: 19.852817058563232
Epoch: 12, Steps: 267 | Train Loss: 0.3755950 Vali Loss: 0.5458741 Test Loss: 0.4005184
Validation loss decreased (0.546204 --> 0.545874).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3574239
	speed: 0.3306s/iter; left time: 7735.1940s
	iters: 200, epoch: 13 | loss: 0.4064360
	speed: 0.0857s/iter; left time: 1997.0556s
Epoch: 13 cost time: 21.507403135299683
Epoch: 13, Steps: 267 | Train Loss: 0.3755498 Vali Loss: 0.5461077 Test Loss: 0.3999464
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4060858
	speed: 0.3187s/iter; left time: 7372.5382s
	iters: 200, epoch: 14 | loss: 0.3958183
	speed: 0.0708s/iter; left time: 1629.9130s
Epoch: 14 cost time: 21.166425228118896
Epoch: 14, Steps: 267 | Train Loss: 0.3754600 Vali Loss: 0.5461631 Test Loss: 0.4002551
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3964696
	speed: 0.3345s/iter; left time: 7646.6231s
	iters: 200, epoch: 15 | loss: 0.3714966
	speed: 0.0754s/iter; left time: 1716.5655s
Epoch: 15 cost time: 20.137626886367798
Epoch: 15, Steps: 267 | Train Loss: 0.3752748 Vali Loss: 0.5466622 Test Loss: 0.4004020
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3796230
	speed: 0.3144s/iter; left time: 7103.6443s
	iters: 200, epoch: 16 | loss: 0.3397487
	speed: 0.0800s/iter; left time: 1799.2654s
Epoch: 16 cost time: 20.301477670669556
Epoch: 16, Steps: 267 | Train Loss: 0.3753327 Vali Loss: 0.5452618 Test Loss: 0.4001576
Validation loss decreased (0.545874 --> 0.545262).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3924068
	speed: 0.2893s/iter; left time: 6460.7542s
	iters: 200, epoch: 17 | loss: 0.3590444
	speed: 0.0788s/iter; left time: 1751.8433s
Epoch: 17 cost time: 22.577725648880005
Epoch: 17, Steps: 267 | Train Loss: 0.3750461 Vali Loss: 0.5460890 Test Loss: 0.4002213
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3970134
	speed: 0.3874s/iter; left time: 8547.7737s
	iters: 200, epoch: 18 | loss: 0.3561381
	speed: 0.0684s/iter; left time: 1501.7127s
Epoch: 18 cost time: 21.691576957702637
Epoch: 18, Steps: 267 | Train Loss: 0.3752355 Vali Loss: 0.5462567 Test Loss: 0.4002428
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3873807
	speed: 0.3763s/iter; left time: 8200.7950s
	iters: 200, epoch: 19 | loss: 0.3655808
	speed: 0.0884s/iter; left time: 1918.6715s
Epoch: 19 cost time: 25.487831592559814
Epoch: 19, Steps: 267 | Train Loss: 0.3752354 Vali Loss: 0.5464470 Test Loss: 0.3999704
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3802251
	speed: 0.4165s/iter; left time: 8967.3628s
	iters: 200, epoch: 20 | loss: 0.3988546
	speed: 0.0733s/iter; left time: 1569.7654s
Epoch: 20 cost time: 23.727031707763672
Epoch: 20, Steps: 267 | Train Loss: 0.3752870 Vali Loss: 0.5458781 Test Loss: 0.4002936
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3848282
	speed: 0.3878s/iter; left time: 8245.1733s
	iters: 200, epoch: 21 | loss: 0.4003489
	speed: 0.0913s/iter; left time: 1932.8196s
Epoch: 21 cost time: 24.41535997390747
Epoch: 21, Steps: 267 | Train Loss: 0.3751214 Vali Loss: 0.5471039 Test Loss: 0.4004855
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3849792
	speed: 0.3960s/iter; left time: 8314.3681s
	iters: 200, epoch: 22 | loss: 0.3928096
	speed: 0.0959s/iter; left time: 2004.6622s
Epoch: 22 cost time: 24.022204399108887
Epoch: 22, Steps: 267 | Train Loss: 0.3751402 Vali Loss: 0.5467094 Test Loss: 0.4002157
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3667234
	speed: 0.3680s/iter; left time: 7628.4450s
	iters: 200, epoch: 23 | loss: 0.3735970
	speed: 0.0772s/iter; left time: 1592.7811s
Epoch: 23 cost time: 21.918575763702393
Epoch: 23, Steps: 267 | Train Loss: 0.3750126 Vali Loss: 0.5462557 Test Loss: 0.4003209
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3825389
	speed: 0.3800s/iter; left time: 7775.7670s
	iters: 200, epoch: 24 | loss: 0.3955905
	speed: 0.0821s/iter; left time: 1672.4420s
Epoch: 24 cost time: 24.460813522338867
Epoch: 24, Steps: 267 | Train Loss: 0.3751664 Vali Loss: 0.5456089 Test Loss: 0.4001137
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4001594
	speed: 0.4325s/iter; left time: 8732.9810s
	iters: 200, epoch: 25 | loss: 0.3798774
	speed: 0.0874s/iter; left time: 1755.4860s
Epoch: 25 cost time: 24.755385398864746
Epoch: 25, Steps: 267 | Train Loss: 0.3751863 Vali Loss: 0.5454873 Test Loss: 0.4000486
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3590329
	speed: 0.4104s/iter; left time: 8177.1731s
	iters: 200, epoch: 26 | loss: 0.3911934
	speed: 0.0911s/iter; left time: 1806.9213s
Epoch: 26 cost time: 24.78384804725647
Epoch: 26, Steps: 267 | Train Loss: 0.3753069 Vali Loss: 0.5468979 Test Loss: 0.4002676
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3533091
	speed: 0.3948s/iter; left time: 7761.6790s
	iters: 200, epoch: 27 | loss: 0.3469068
	speed: 0.0871s/iter; left time: 1704.4034s
Epoch: 27 cost time: 24.213860273361206
Epoch: 27, Steps: 267 | Train Loss: 0.3750126 Vali Loss: 0.5465226 Test Loss: 0.4004109
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3630190
	speed: 0.3879s/iter; left time: 7522.3740s
	iters: 200, epoch: 28 | loss: 0.3436545
	speed: 0.0785s/iter; left time: 1515.0044s
Epoch: 28 cost time: 22.478298664093018
Epoch: 28, Steps: 267 | Train Loss: 0.3749369 Vali Loss: 0.5457280 Test Loss: 0.4003442
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3953343
	speed: 0.3841s/iter; left time: 7346.4392s
	iters: 200, epoch: 29 | loss: 0.3762523
	speed: 0.0942s/iter; left time: 1791.4528s
Epoch: 29 cost time: 25.849989414215088
Epoch: 29, Steps: 267 | Train Loss: 0.3749906 Vali Loss: 0.5469981 Test Loss: 0.4005917
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3943731
	speed: 0.3894s/iter; left time: 7343.2339s
	iters: 200, epoch: 30 | loss: 0.4119250
	speed: 0.0777s/iter; left time: 1456.9957s
Epoch: 30 cost time: 22.18154215812683
Epoch: 30, Steps: 267 | Train Loss: 0.3752579 Vali Loss: 0.5464535 Test Loss: 0.4004169
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3974558
	speed: 0.3441s/iter; left time: 6396.8274s
	iters: 200, epoch: 31 | loss: 0.3611810
	speed: 0.1204s/iter; left time: 2226.2564s
Epoch: 31 cost time: 28.716355800628662
Epoch: 31, Steps: 267 | Train Loss: 0.3750527 Vali Loss: 0.5461898 Test Loss: 0.4003077
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3844454
	speed: 0.5339s/iter; left time: 9782.9385s
	iters: 200, epoch: 32 | loss: 0.3909457
	speed: 0.0776s/iter; left time: 1414.7192s
Epoch: 32 cost time: 20.75049328804016
Epoch: 32, Steps: 267 | Train Loss: 0.3751031 Vali Loss: 0.5460955 Test Loss: 0.4001715
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4282353
	speed: 0.3432s/iter; left time: 6197.8550s
	iters: 200, epoch: 33 | loss: 0.3395789
	speed: 0.0942s/iter; left time: 1690.7537s
Epoch: 33 cost time: 22.8145112991333
Epoch: 33, Steps: 267 | Train Loss: 0.3751165 Vali Loss: 0.5464054 Test Loss: 0.4003282
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4052668
	speed: 0.3822s/iter; left time: 6798.6471s
	iters: 200, epoch: 34 | loss: 0.3568658
	speed: 0.0882s/iter; left time: 1561.0477s
Epoch: 34 cost time: 22.97743058204651
Epoch: 34, Steps: 267 | Train Loss: 0.3750078 Vali Loss: 0.5464049 Test Loss: 0.4004065
EarlyStopping counter: 18 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3421218
	speed: 0.3823s/iter; left time: 6699.0567s
	iters: 200, epoch: 35 | loss: 0.4172546
	speed: 0.0756s/iter; left time: 1316.3923s
Epoch: 35 cost time: 21.83396577835083
Epoch: 35, Steps: 267 | Train Loss: 0.3749569 Vali Loss: 0.5466297 Test Loss: 0.4003890
EarlyStopping counter: 19 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3545316
	speed: 0.3398s/iter; left time: 5864.0820s
	iters: 200, epoch: 36 | loss: 0.3538049
	speed: 0.0929s/iter; left time: 1593.2574s
Epoch: 36 cost time: 24.29584312438965
Epoch: 36, Steps: 267 | Train Loss: 0.3751410 Vali Loss: 0.5461398 Test Loss: 0.4002745
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_90_192_FITS_ETTm1_ftM_sl90_ll48_pl192_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.40114161372184753, mae:0.39880335330963135, rse:0.6029070615768433, corr:[0.5494037  0.55196434 0.548628   0.5431765  0.5397587  0.5388686
 0.5381277  0.5363475  0.533951   0.53190094 0.5307208  0.53010213
 0.5292864  0.52780247 0.5255045  0.5225004  0.51934457 0.5165079
 0.513919   0.5112448  0.5083299  0.5050944  0.50168175 0.4983103
 0.49510187 0.49192247 0.48886958 0.4861155  0.48393536 0.48232296
 0.48146075 0.48163348 0.4821576  0.4824915  0.4825141  0.48245722
 0.4823176  0.48235297 0.4825647  0.48273566 0.48277017 0.4824411
 0.48195025 0.48157823 0.4813366  0.48129383 0.48143613 0.48158213
 0.48161125 0.48159656 0.48170203 0.48194832 0.48244587 0.48302066
 0.48358214 0.48393902 0.48414668 0.48424944 0.48418447 0.48410663
 0.48400706 0.4836301  0.4831419  0.48259437 0.4823576  0.48239112
 0.48242128 0.48240092 0.4825339  0.48290026 0.48331103 0.48379907
 0.4844462  0.48512548 0.48586702 0.4865054  0.4871912  0.48794013
 0.48863432 0.48924464 0.4898053  0.49025962 0.49075004 0.4911573
 0.49150577 0.49183887 0.4922761  0.49288112 0.49367818 0.49457705
 0.495383   0.49594638 0.49631983 0.49663302 0.4968975  0.49683312
 0.49618083 0.4951292  0.4940163  0.4931489  0.49280035 0.49272975
 0.49252188 0.49184152 0.49105924 0.49047935 0.49001098 0.48946524
 0.4887201  0.48778862 0.48679927 0.48591265 0.48516926 0.4844887
 0.48369578 0.4827906  0.48172528 0.48054263 0.47931525 0.4781097
 0.47702724 0.4760222  0.47508016 0.47428596 0.473523   0.47269255
 0.47192588 0.4714136  0.47125873 0.4713762  0.47156927 0.4716796
 0.4715616  0.4713541  0.4711153  0.47094044 0.47085252 0.4708047
 0.47068936 0.47049162 0.47027194 0.47018167 0.47026116 0.47050625
 0.47077566 0.4710041  0.47116846 0.4712397  0.4714274  0.4716944
 0.4719946  0.4723765  0.47266513 0.4727375  0.47255552 0.4723471
 0.4722718  0.47239384 0.4725782  0.47269    0.4727512  0.47273445
 0.47271213 0.47279415 0.47308192 0.473541   0.47410065 0.47465545
 0.4751418  0.4755982  0.47612163 0.47685233 0.4776542  0.47840297
 0.47892442 0.479252   0.47954458 0.4799523  0.48051828 0.48133904
 0.4821771  0.4827164  0.48278528 0.48282847 0.48360696 0.48547736
 0.48780975 0.4892939  0.48919803 0.4887637  0.4917939  0.49994892]
