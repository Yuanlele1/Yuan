Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=30, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_180_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_180_336_FITS_ETTm1_ftM_sl180_ll48_pl336_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34045
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=30, out_features=86, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2311680.0
params:  2666.0
Trainable parameters:  2666
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5275800
	speed: 0.0185s/iter; left time: 489.6721s
	iters: 200, epoch: 1 | loss: 0.4222695
	speed: 0.0136s/iter; left time: 357.0141s
Epoch: 1 cost time: 4.097882270812988
Epoch: 1, Steps: 265 | Train Loss: 0.5232344 Vali Loss: 0.9020605 Test Loss: 0.5905370
Validation loss decreased (inf --> 0.902061).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3410054
	speed: 0.0691s/iter; left time: 1807.0579s
	iters: 200, epoch: 2 | loss: 0.3004620
	speed: 0.0135s/iter; left time: 351.1695s
Epoch: 2 cost time: 4.13689112663269
Epoch: 2, Steps: 265 | Train Loss: 0.3283618 Vali Loss: 0.7802101 Test Loss: 0.4809212
Validation loss decreased (0.902061 --> 0.780210).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2807567
	speed: 0.0693s/iter; left time: 1792.3458s
	iters: 200, epoch: 3 | loss: 0.3037544
	speed: 0.0134s/iter; left time: 346.1758s
Epoch: 3 cost time: 4.165980100631714
Epoch: 3, Steps: 265 | Train Loss: 0.2871004 Vali Loss: 0.7344960 Test Loss: 0.4404350
Validation loss decreased (0.780210 --> 0.734496).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2395268
	speed: 0.0687s/iter; left time: 1758.2548s
	iters: 200, epoch: 4 | loss: 0.2738274
	speed: 0.0135s/iter; left time: 343.0789s
Epoch: 4 cost time: 4.133747816085815
Epoch: 4, Steps: 265 | Train Loss: 0.2710984 Vali Loss: 0.7092334 Test Loss: 0.4177496
Validation loss decreased (0.734496 --> 0.709233).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2558047
	speed: 0.0675s/iter; left time: 1711.0610s
	iters: 200, epoch: 5 | loss: 0.2427572
	speed: 0.0150s/iter; left time: 379.5992s
Epoch: 5 cost time: 5.2965803146362305
Epoch: 5, Steps: 265 | Train Loss: 0.2625872 Vali Loss: 0.6942062 Test Loss: 0.4053854
Validation loss decreased (0.709233 --> 0.694206).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2518336
	speed: 0.0784s/iter; left time: 1964.7663s
	iters: 200, epoch: 6 | loss: 0.2585106
	speed: 0.0127s/iter; left time: 317.9660s
Epoch: 6 cost time: 3.879887342453003
Epoch: 6, Steps: 265 | Train Loss: 0.2580499 Vali Loss: 0.6854856 Test Loss: 0.3980862
Validation loss decreased (0.694206 --> 0.685486).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2292071
	speed: 0.0654s/iter; left time: 1622.5944s
	iters: 200, epoch: 7 | loss: 0.2353677
	speed: 0.0134s/iter; left time: 330.0403s
Epoch: 7 cost time: 3.997680902481079
Epoch: 7, Steps: 265 | Train Loss: 0.2551943 Vali Loss: 0.6807760 Test Loss: 0.3936271
Validation loss decreased (0.685486 --> 0.680776).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2363781
	speed: 0.0689s/iter; left time: 1690.7744s
	iters: 200, epoch: 8 | loss: 0.2438760
	speed: 0.0140s/iter; left time: 341.2577s
Epoch: 8 cost time: 4.083713531494141
Epoch: 8, Steps: 265 | Train Loss: 0.2535619 Vali Loss: 0.6765228 Test Loss: 0.3913728
Validation loss decreased (0.680776 --> 0.676523).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2536156
	speed: 0.0677s/iter; left time: 1643.4593s
	iters: 200, epoch: 9 | loss: 0.2295092
	speed: 0.0128s/iter; left time: 308.5311s
Epoch: 9 cost time: 3.9841818809509277
Epoch: 9, Steps: 265 | Train Loss: 0.2526952 Vali Loss: 0.6750215 Test Loss: 0.3897358
Validation loss decreased (0.676523 --> 0.675021).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2460235
	speed: 0.0684s/iter; left time: 1642.6079s
	iters: 200, epoch: 10 | loss: 0.2559986
	speed: 0.0133s/iter; left time: 318.5908s
Epoch: 10 cost time: 4.039238929748535
Epoch: 10, Steps: 265 | Train Loss: 0.2521088 Vali Loss: 0.6739603 Test Loss: 0.3886305
Validation loss decreased (0.675021 --> 0.673960).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2413635
	speed: 0.0693s/iter; left time: 1646.6559s
	iters: 200, epoch: 11 | loss: 0.2704052
	speed: 0.0150s/iter; left time: 354.1786s
Epoch: 11 cost time: 4.401709318161011
Epoch: 11, Steps: 265 | Train Loss: 0.2518661 Vali Loss: 0.6727360 Test Loss: 0.3883414
Validation loss decreased (0.673960 --> 0.672736).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2559878
	speed: 0.0733s/iter; left time: 1722.0240s
	iters: 200, epoch: 12 | loss: 0.2517335
	speed: 0.0147s/iter; left time: 344.4280s
Epoch: 12 cost time: 4.483604431152344
Epoch: 12, Steps: 265 | Train Loss: 0.2516758 Vali Loss: 0.6727303 Test Loss: 0.3878240
Validation loss decreased (0.672736 --> 0.672730).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2586569
	speed: 0.0711s/iter; left time: 1650.0823s
	iters: 200, epoch: 13 | loss: 0.2493503
	speed: 0.0130s/iter; left time: 301.0339s
Epoch: 13 cost time: 3.9762604236602783
Epoch: 13, Steps: 265 | Train Loss: 0.2515851 Vali Loss: 0.6730433 Test Loss: 0.3878097
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2223961
	speed: 0.0668s/iter; left time: 1534.4342s
	iters: 200, epoch: 14 | loss: 0.2481704
	speed: 0.0133s/iter; left time: 303.5677s
Epoch: 14 cost time: 4.017992258071899
Epoch: 14, Steps: 265 | Train Loss: 0.2514922 Vali Loss: 0.6727567 Test Loss: 0.3877429
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2454762
	speed: 0.0680s/iter; left time: 1541.9338s
	iters: 200, epoch: 15 | loss: 0.2511367
	speed: 0.0129s/iter; left time: 291.1194s
Epoch: 15 cost time: 4.049785852432251
Epoch: 15, Steps: 265 | Train Loss: 0.2515931 Vali Loss: 0.6726965 Test Loss: 0.3876106
Validation loss decreased (0.672730 --> 0.672696).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2682347
	speed: 0.0684s/iter; left time: 1534.7879s
	iters: 200, epoch: 16 | loss: 0.2615429
	speed: 0.0134s/iter; left time: 300.0187s
Epoch: 16 cost time: 3.95668363571167
Epoch: 16, Steps: 265 | Train Loss: 0.2515849 Vali Loss: 0.6719818 Test Loss: 0.3877221
Validation loss decreased (0.672696 --> 0.671982).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2569031
	speed: 0.0664s/iter; left time: 1472.5046s
	iters: 200, epoch: 17 | loss: 0.2369826
	speed: 0.0134s/iter; left time: 294.6646s
Epoch: 17 cost time: 3.9835517406463623
Epoch: 17, Steps: 265 | Train Loss: 0.2515421 Vali Loss: 0.6715195 Test Loss: 0.3878586
Validation loss decreased (0.671982 --> 0.671520).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2849921
	speed: 0.0678s/iter; left time: 1483.8591s
	iters: 200, epoch: 18 | loss: 0.2801784
	speed: 0.0146s/iter; left time: 319.0886s
Epoch: 18 cost time: 4.233543395996094
Epoch: 18, Steps: 265 | Train Loss: 0.2514862 Vali Loss: 0.6716719 Test Loss: 0.3877076
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2622162
	speed: 0.0712s/iter; left time: 1539.1137s
	iters: 200, epoch: 19 | loss: 0.2511962
	speed: 0.0148s/iter; left time: 317.6816s
Epoch: 19 cost time: 4.286417245864868
Epoch: 19, Steps: 265 | Train Loss: 0.2516219 Vali Loss: 0.6716323 Test Loss: 0.3873736
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2417009
	speed: 0.0725s/iter; left time: 1549.9423s
	iters: 200, epoch: 20 | loss: 0.2501136
	speed: 0.0162s/iter; left time: 345.1521s
Epoch: 20 cost time: 4.75017237663269
Epoch: 20, Steps: 265 | Train Loss: 0.2514468 Vali Loss: 0.6720034 Test Loss: 0.3875784
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2608345
	speed: 0.0717s/iter; left time: 1512.5949s
	iters: 200, epoch: 21 | loss: 0.2594953
	speed: 0.0131s/iter; left time: 275.6047s
Epoch: 21 cost time: 4.0303099155426025
Epoch: 21, Steps: 265 | Train Loss: 0.2514911 Vali Loss: 0.6717258 Test Loss: 0.3874761
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2350223
	speed: 0.0684s/iter; left time: 1426.1027s
	iters: 200, epoch: 22 | loss: 0.2623112
	speed: 0.0152s/iter; left time: 314.8507s
Epoch: 22 cost time: 4.306009769439697
Epoch: 22, Steps: 265 | Train Loss: 0.2515369 Vali Loss: 0.6721778 Test Loss: 0.3875894
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2652138
	speed: 0.0687s/iter; left time: 1413.4988s
	iters: 200, epoch: 23 | loss: 0.2696857
	speed: 0.0134s/iter; left time: 274.7514s
Epoch: 23 cost time: 3.977369785308838
Epoch: 23, Steps: 265 | Train Loss: 0.2515240 Vali Loss: 0.6721936 Test Loss: 0.3877560
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2329981
	speed: 0.0674s/iter; left time: 1368.6728s
	iters: 200, epoch: 24 | loss: 0.2339509
	speed: 0.0135s/iter; left time: 272.9651s
Epoch: 24 cost time: 4.082413196563721
Epoch: 24, Steps: 265 | Train Loss: 0.2515079 Vali Loss: 0.6715342 Test Loss: 0.3875855
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2324491
	speed: 0.0726s/iter; left time: 1455.7992s
	iters: 200, epoch: 25 | loss: 0.2566955
	speed: 0.0149s/iter; left time: 296.2560s
Epoch: 25 cost time: 4.5384392738342285
Epoch: 25, Steps: 265 | Train Loss: 0.2515213 Vali Loss: 0.6718788 Test Loss: 0.3877016
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2489516
	speed: 0.0696s/iter; left time: 1376.3080s
	iters: 200, epoch: 26 | loss: 0.2112000
	speed: 0.0133s/iter; left time: 261.1961s
Epoch: 26 cost time: 4.008913516998291
Epoch: 26, Steps: 265 | Train Loss: 0.2514446 Vali Loss: 0.6708201 Test Loss: 0.3875819
Validation loss decreased (0.671520 --> 0.670820).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2517360
	speed: 0.0675s/iter; left time: 1317.8117s
	iters: 200, epoch: 27 | loss: 0.2598819
	speed: 0.0130s/iter; left time: 253.2615s
Epoch: 27 cost time: 4.006000995635986
Epoch: 27, Steps: 265 | Train Loss: 0.2516150 Vali Loss: 0.6718876 Test Loss: 0.3876428
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2579033
	speed: 0.0694s/iter; left time: 1335.0827s
	iters: 200, epoch: 28 | loss: 0.2756185
	speed: 0.0156s/iter; left time: 298.4536s
Epoch: 28 cost time: 4.51098895072937
Epoch: 28, Steps: 265 | Train Loss: 0.2514203 Vali Loss: 0.6724768 Test Loss: 0.3877101
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2388057
	speed: 0.0703s/iter; left time: 1333.5804s
	iters: 200, epoch: 29 | loss: 0.2850897
	speed: 0.0138s/iter; left time: 260.1258s
Epoch: 29 cost time: 4.146471977233887
Epoch: 29, Steps: 265 | Train Loss: 0.2515265 Vali Loss: 0.6717093 Test Loss: 0.3876288
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2376994
	speed: 0.0679s/iter; left time: 1270.2393s
	iters: 200, epoch: 30 | loss: 0.2814198
	speed: 0.0134s/iter; left time: 248.6776s
Epoch: 30 cost time: 4.058380126953125
Epoch: 30, Steps: 265 | Train Loss: 0.2515294 Vali Loss: 0.6715567 Test Loss: 0.3875552
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2442164
	speed: 0.0691s/iter; left time: 1275.5227s
	iters: 200, epoch: 31 | loss: 0.2594479
	speed: 0.0138s/iter; left time: 252.5733s
Epoch: 31 cost time: 4.206138610839844
Epoch: 31, Steps: 265 | Train Loss: 0.2515423 Vali Loss: 0.6717165 Test Loss: 0.3875409
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2351664
	speed: 0.0684s/iter; left time: 1243.8244s
	iters: 200, epoch: 32 | loss: 0.2354154
	speed: 0.0135s/iter; left time: 243.4867s
Epoch: 32 cost time: 4.082406282424927
Epoch: 32, Steps: 265 | Train Loss: 0.2514639 Vali Loss: 0.6710400 Test Loss: 0.3875411
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2360036
	speed: 0.0685s/iter; left time: 1226.7064s
	iters: 200, epoch: 33 | loss: 0.2646482
	speed: 0.0135s/iter; left time: 239.7814s
Epoch: 33 cost time: 4.045271873474121
Epoch: 33, Steps: 265 | Train Loss: 0.2514231 Vali Loss: 0.6707617 Test Loss: 0.3875778
Validation loss decreased (0.670820 --> 0.670762).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2451960
	speed: 0.0694s/iter; left time: 1224.4998s
	iters: 200, epoch: 34 | loss: 0.2765696
	speed: 0.0132s/iter; left time: 231.1141s
Epoch: 34 cost time: 4.128597736358643
Epoch: 34, Steps: 265 | Train Loss: 0.2514916 Vali Loss: 0.6718376 Test Loss: 0.3875816
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2277137
	speed: 0.0685s/iter; left time: 1191.7095s
	iters: 200, epoch: 35 | loss: 0.2634636
	speed: 0.0133s/iter; left time: 229.4875s
Epoch: 35 cost time: 4.011907339096069
Epoch: 35, Steps: 265 | Train Loss: 0.2515349 Vali Loss: 0.6716180 Test Loss: 0.3875393
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2618344
	speed: 0.0699s/iter; left time: 1196.8536s
	iters: 200, epoch: 36 | loss: 0.2515700
	speed: 0.0133s/iter; left time: 226.1524s
Epoch: 36 cost time: 4.076789379119873
Epoch: 36, Steps: 265 | Train Loss: 0.2514841 Vali Loss: 0.6723692 Test Loss: 0.3875715
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2669533
	speed: 0.0683s/iter; left time: 1151.8781s
	iters: 200, epoch: 37 | loss: 0.2453117
	speed: 0.0131s/iter; left time: 219.2599s
Epoch: 37 cost time: 3.9514169692993164
Epoch: 37, Steps: 265 | Train Loss: 0.2515530 Vali Loss: 0.6714793 Test Loss: 0.3876224
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2456265
	speed: 0.0657s/iter; left time: 1091.1281s
	iters: 200, epoch: 38 | loss: 0.2542335
	speed: 0.0127s/iter; left time: 209.3202s
Epoch: 38 cost time: 3.842831611633301
Epoch: 38, Steps: 265 | Train Loss: 0.2514684 Vali Loss: 0.6714329 Test Loss: 0.3876140
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2372939
	speed: 0.0653s/iter; left time: 1065.9805s
	iters: 200, epoch: 39 | loss: 0.2883762
	speed: 0.0132s/iter; left time: 214.4556s
Epoch: 39 cost time: 3.9803967475891113
Epoch: 39, Steps: 265 | Train Loss: 0.2514530 Vali Loss: 0.6716367 Test Loss: 0.3875672
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2334135
	speed: 0.0667s/iter; left time: 1071.6091s
	iters: 200, epoch: 40 | loss: 0.2496496
	speed: 0.0129s/iter; left time: 206.3971s
Epoch: 40 cost time: 3.8562183380126953
Epoch: 40, Steps: 265 | Train Loss: 0.2514445 Vali Loss: 0.6720532 Test Loss: 0.3875812
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2442836
	speed: 0.0676s/iter; left time: 1068.7213s
	iters: 200, epoch: 41 | loss: 0.2360453
	speed: 0.0133s/iter; left time: 209.2346s
Epoch: 41 cost time: 3.967118263244629
Epoch: 41, Steps: 265 | Train Loss: 0.2514586 Vali Loss: 0.6715918 Test Loss: 0.3875768
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2440255
	speed: 0.0670s/iter; left time: 1041.2598s
	iters: 200, epoch: 42 | loss: 0.2705758
	speed: 0.0133s/iter; left time: 205.2229s
Epoch: 42 cost time: 4.0046515464782715
Epoch: 42, Steps: 265 | Train Loss: 0.2515352 Vali Loss: 0.6724355 Test Loss: 0.3875754
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2190950
	speed: 0.0700s/iter; left time: 1069.6759s
	iters: 200, epoch: 43 | loss: 0.2348849
	speed: 0.0139s/iter; left time: 211.2295s
Epoch: 43 cost time: 4.388489007949829
Epoch: 43, Steps: 265 | Train Loss: 0.2515849 Vali Loss: 0.6722710 Test Loss: 0.3876143
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2502824
	speed: 0.0692s/iter; left time: 1038.5461s
	iters: 200, epoch: 44 | loss: 0.2585421
	speed: 0.0133s/iter; left time: 198.2065s
Epoch: 44 cost time: 4.030677080154419
Epoch: 44, Steps: 265 | Train Loss: 0.2513888 Vali Loss: 0.6719731 Test Loss: 0.3876024
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2339749
	speed: 0.0672s/iter; left time: 990.6880s
	iters: 200, epoch: 45 | loss: 0.2399920
	speed: 0.0131s/iter; left time: 191.5007s
Epoch: 45 cost time: 3.971224546432495
Epoch: 45, Steps: 265 | Train Loss: 0.2514825 Vali Loss: 0.6715056 Test Loss: 0.3875787
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2329897
	speed: 0.0660s/iter; left time: 956.1237s
	iters: 200, epoch: 46 | loss: 0.2457119
	speed: 0.0132s/iter; left time: 189.5290s
Epoch: 46 cost time: 3.929720878601074
Epoch: 46, Steps: 265 | Train Loss: 0.2514064 Vali Loss: 0.6721846 Test Loss: 0.3876057
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2442175
	speed: 0.0669s/iter; left time: 950.4589s
	iters: 200, epoch: 47 | loss: 0.2521222
	speed: 0.0130s/iter; left time: 183.4656s
Epoch: 47 cost time: 3.9467625617980957
Epoch: 47, Steps: 265 | Train Loss: 0.2514444 Vali Loss: 0.6718025 Test Loss: 0.3876091
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2429798
	speed: 0.0671s/iter; left time: 936.4319s
	iters: 200, epoch: 48 | loss: 0.2293478
	speed: 0.0128s/iter; left time: 176.8293s
Epoch: 48 cost time: 3.872206211090088
Epoch: 48, Steps: 265 | Train Loss: 0.2515096 Vali Loss: 0.6713614 Test Loss: 0.3876088
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2420122
	speed: 0.0677s/iter; left time: 926.5871s
	iters: 200, epoch: 49 | loss: 0.2228586
	speed: 0.0134s/iter; left time: 182.1163s
Epoch: 49 cost time: 4.059375524520874
Epoch: 49, Steps: 265 | Train Loss: 0.2514380 Vali Loss: 0.6714737 Test Loss: 0.3875735
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2555453
	speed: 0.0669s/iter; left time: 897.5611s
	iters: 200, epoch: 50 | loss: 0.2619100
	speed: 0.0131s/iter; left time: 174.9529s
Epoch: 50 cost time: 4.035970687866211
Epoch: 50, Steps: 265 | Train Loss: 0.2513784 Vali Loss: 0.6719773 Test Loss: 0.3875655
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2327623
	speed: 0.0676s/iter; left time: 889.6024s
	iters: 200, epoch: 51 | loss: 0.2564989
	speed: 0.0129s/iter; left time: 168.9926s
Epoch: 51 cost time: 4.036463737487793
Epoch: 51, Steps: 265 | Train Loss: 0.2514090 Vali Loss: 0.6723133 Test Loss: 0.3875920
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2754668
	speed: 0.0681s/iter; left time: 877.3225s
	iters: 200, epoch: 52 | loss: 0.2637983
	speed: 0.0131s/iter; left time: 168.1209s
Epoch: 52 cost time: 4.0038206577301025
Epoch: 52, Steps: 265 | Train Loss: 0.2514983 Vali Loss: 0.6713386 Test Loss: 0.3875920
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2377008
	speed: 0.0704s/iter; left time: 888.5480s
	iters: 200, epoch: 53 | loss: 0.2529913
	speed: 0.0170s/iter; left time: 212.8426s
Epoch: 53 cost time: 4.686843156814575
Epoch: 53, Steps: 265 | Train Loss: 0.2514336 Vali Loss: 0.6715587 Test Loss: 0.3875848
EarlyStopping counter: 20 out of 20
Early stopping
train 34045
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=30, out_features=86, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2311680.0
params:  2666.0
Trainable parameters:  2666
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3357726
	speed: 0.0196s/iter; left time: 516.4501s
	iters: 200, epoch: 1 | loss: 0.3643259
	speed: 0.0133s/iter; left time: 350.4618s
Epoch: 1 cost time: 4.199551820755005
Epoch: 1, Steps: 265 | Train Loss: 0.3749124 Vali Loss: 0.6671094 Test Loss: 0.3844352
Validation loss decreased (inf --> 0.667109).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3919825
	speed: 0.0683s/iter; left time: 1784.5205s
	iters: 200, epoch: 2 | loss: 0.3788678
	speed: 0.0131s/iter; left time: 341.6393s
Epoch: 2 cost time: 4.075589656829834
Epoch: 2, Steps: 265 | Train Loss: 0.3743539 Vali Loss: 0.6676647 Test Loss: 0.3845834
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3804908
	speed: 0.0674s/iter; left time: 1742.6187s
	iters: 200, epoch: 3 | loss: 0.3379455
	speed: 0.0138s/iter; left time: 354.6747s
Epoch: 3 cost time: 4.0755414962768555
Epoch: 3, Steps: 265 | Train Loss: 0.3739536 Vali Loss: 0.6679287 Test Loss: 0.3840448
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3855154
	speed: 0.0681s/iter; left time: 1744.9996s
	iters: 200, epoch: 4 | loss: 0.3855260
	speed: 0.0136s/iter; left time: 346.4370s
Epoch: 4 cost time: 4.054751634597778
Epoch: 4, Steps: 265 | Train Loss: 0.3738170 Vali Loss: 0.6667047 Test Loss: 0.3839725
Validation loss decreased (0.667109 --> 0.666705).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3995270
	speed: 0.0687s/iter; left time: 1740.6368s
	iters: 200, epoch: 5 | loss: 0.3770527
	speed: 0.0134s/iter; left time: 338.7270s
Epoch: 5 cost time: 4.152461051940918
Epoch: 5, Steps: 265 | Train Loss: 0.3739274 Vali Loss: 0.6659855 Test Loss: 0.3841323
Validation loss decreased (0.666705 --> 0.665985).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3685038
	speed: 0.0687s/iter; left time: 1723.2118s
	iters: 200, epoch: 6 | loss: 0.3944746
	speed: 0.0135s/iter; left time: 336.7170s
Epoch: 6 cost time: 4.0749382972717285
Epoch: 6, Steps: 265 | Train Loss: 0.3737639 Vali Loss: 0.6659193 Test Loss: 0.3841233
Validation loss decreased (0.665985 --> 0.665919).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3655641
	speed: 0.0695s/iter; left time: 1725.0347s
	iters: 200, epoch: 7 | loss: 0.4185547
	speed: 0.0135s/iter; left time: 333.6969s
Epoch: 7 cost time: 4.129885911941528
Epoch: 7, Steps: 265 | Train Loss: 0.3737951 Vali Loss: 0.6660839 Test Loss: 0.3841222
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3880895
	speed: 0.0703s/iter; left time: 1725.0934s
	iters: 200, epoch: 8 | loss: 0.3679329
	speed: 0.0137s/iter; left time: 333.8188s
Epoch: 8 cost time: 4.303335189819336
Epoch: 8, Steps: 265 | Train Loss: 0.3738799 Vali Loss: 0.6660694 Test Loss: 0.3838640
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3822009
	speed: 0.0718s/iter; left time: 1742.2099s
	iters: 200, epoch: 9 | loss: 0.3588733
	speed: 0.0152s/iter; left time: 367.7869s
Epoch: 9 cost time: 4.6228346824646
Epoch: 9, Steps: 265 | Train Loss: 0.3738402 Vali Loss: 0.6649307 Test Loss: 0.3838683
Validation loss decreased (0.665919 --> 0.664931).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3539962
	speed: 0.0705s/iter; left time: 1693.2388s
	iters: 200, epoch: 10 | loss: 0.3520654
	speed: 0.0134s/iter; left time: 321.6268s
Epoch: 10 cost time: 4.092317819595337
Epoch: 10, Steps: 265 | Train Loss: 0.3736945 Vali Loss: 0.6651804 Test Loss: 0.3839390
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3632187
	speed: 0.0721s/iter; left time: 1713.5548s
	iters: 200, epoch: 11 | loss: 0.3466414
	speed: 0.0151s/iter; left time: 358.2121s
Epoch: 11 cost time: 4.645596265792847
Epoch: 11, Steps: 265 | Train Loss: 0.3737127 Vali Loss: 0.6658880 Test Loss: 0.3838859
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3972001
	speed: 0.0715s/iter; left time: 1679.0833s
	iters: 200, epoch: 12 | loss: 0.3773782
	speed: 0.0155s/iter; left time: 362.7747s
Epoch: 12 cost time: 4.633671760559082
Epoch: 12, Steps: 265 | Train Loss: 0.3737097 Vali Loss: 0.6660213 Test Loss: 0.3838239
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3910283
	speed: 0.0730s/iter; left time: 1695.9384s
	iters: 200, epoch: 13 | loss: 0.3748383
	speed: 0.0157s/iter; left time: 362.1879s
Epoch: 13 cost time: 4.659911870956421
Epoch: 13, Steps: 265 | Train Loss: 0.3733657 Vali Loss: 0.6658151 Test Loss: 0.3837908
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3720490
	speed: 0.0696s/iter; left time: 1596.6451s
	iters: 200, epoch: 14 | loss: 0.3799674
	speed: 0.0137s/iter; left time: 312.2207s
Epoch: 14 cost time: 4.073257684707642
Epoch: 14, Steps: 265 | Train Loss: 0.3736766 Vali Loss: 0.6652120 Test Loss: 0.3840573
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3721043
	speed: 0.0728s/iter; left time: 1652.5186s
	iters: 200, epoch: 15 | loss: 0.3669434
	speed: 0.0154s/iter; left time: 347.0083s
Epoch: 15 cost time: 4.759881496429443
Epoch: 15, Steps: 265 | Train Loss: 0.3737105 Vali Loss: 0.6653080 Test Loss: 0.3837259
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3704739
	speed: 0.0705s/iter; left time: 1581.3088s
	iters: 200, epoch: 16 | loss: 0.3405709
	speed: 0.0131s/iter; left time: 292.4676s
Epoch: 16 cost time: 4.037138223648071
Epoch: 16, Steps: 265 | Train Loss: 0.3735204 Vali Loss: 0.6657531 Test Loss: 0.3839469
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4016209
	speed: 0.0669s/iter; left time: 1482.6151s
	iters: 200, epoch: 17 | loss: 0.4086190
	speed: 0.0134s/iter; left time: 296.4751s
Epoch: 17 cost time: 3.991952896118164
Epoch: 17, Steps: 265 | Train Loss: 0.3732412 Vali Loss: 0.6647443 Test Loss: 0.3839192
Validation loss decreased (0.664931 --> 0.664744).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4262131
	speed: 0.0672s/iter; left time: 1472.3440s
	iters: 200, epoch: 18 | loss: 0.3644211
	speed: 0.0146s/iter; left time: 318.2220s
Epoch: 18 cost time: 4.02178168296814
Epoch: 18, Steps: 265 | Train Loss: 0.3736164 Vali Loss: 0.6654627 Test Loss: 0.3838917
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3590159
	speed: 0.0668s/iter; left time: 1443.9862s
	iters: 200, epoch: 19 | loss: 0.3470204
	speed: 0.0130s/iter; left time: 280.8297s
Epoch: 19 cost time: 3.9681997299194336
Epoch: 19, Steps: 265 | Train Loss: 0.3736423 Vali Loss: 0.6645558 Test Loss: 0.3837747
Validation loss decreased (0.664744 --> 0.664556).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3596445
	speed: 0.0684s/iter; left time: 1461.2445s
	iters: 200, epoch: 20 | loss: 0.3424910
	speed: 0.0137s/iter; left time: 291.1358s
Epoch: 20 cost time: 4.0002570152282715
Epoch: 20, Steps: 265 | Train Loss: 0.3738068 Vali Loss: 0.6661943 Test Loss: 0.3837793
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4047922
	speed: 0.0674s/iter; left time: 1423.2287s
	iters: 200, epoch: 21 | loss: 0.3723510
	speed: 0.0132s/iter; left time: 276.9433s
Epoch: 21 cost time: 3.998020887374878
Epoch: 21, Steps: 265 | Train Loss: 0.3737276 Vali Loss: 0.6657031 Test Loss: 0.3837715
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4065149
	speed: 0.0674s/iter; left time: 1405.2875s
	iters: 200, epoch: 22 | loss: 0.3560804
	speed: 0.0132s/iter; left time: 274.1739s
Epoch: 22 cost time: 3.9412033557891846
Epoch: 22, Steps: 265 | Train Loss: 0.3734936 Vali Loss: 0.6655899 Test Loss: 0.3838942
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3468211
	speed: 0.0681s/iter; left time: 1401.4019s
	iters: 200, epoch: 23 | loss: 0.3576365
	speed: 0.0132s/iter; left time: 270.4600s
Epoch: 23 cost time: 4.029727220535278
Epoch: 23, Steps: 265 | Train Loss: 0.3736817 Vali Loss: 0.6653585 Test Loss: 0.3838309
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3708284
	speed: 0.0669s/iter; left time: 1358.5484s
	iters: 200, epoch: 24 | loss: 0.3521922
	speed: 0.0138s/iter; left time: 279.6386s
Epoch: 24 cost time: 4.152604341506958
Epoch: 24, Steps: 265 | Train Loss: 0.3735578 Vali Loss: 0.6651974 Test Loss: 0.3840181
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3518688
	speed: 0.0693s/iter; left time: 1387.8696s
	iters: 200, epoch: 25 | loss: 0.4133165
	speed: 0.0135s/iter; left time: 269.9643s
Epoch: 25 cost time: 4.094860076904297
Epoch: 25, Steps: 265 | Train Loss: 0.3736894 Vali Loss: 0.6657889 Test Loss: 0.3838277
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4051538
	speed: 0.0684s/iter; left time: 1353.2476s
	iters: 200, epoch: 26 | loss: 0.4053558
	speed: 0.0136s/iter; left time: 268.5246s
Epoch: 26 cost time: 4.0622241497039795
Epoch: 26, Steps: 265 | Train Loss: 0.3735883 Vali Loss: 0.6660066 Test Loss: 0.3838698
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3458641
	speed: 0.0679s/iter; left time: 1324.8744s
	iters: 200, epoch: 27 | loss: 0.3722247
	speed: 0.0137s/iter; left time: 266.0941s
Epoch: 27 cost time: 4.092378616333008
Epoch: 27, Steps: 265 | Train Loss: 0.3736071 Vali Loss: 0.6660275 Test Loss: 0.3838413
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3753958
	speed: 0.0689s/iter; left time: 1326.5505s
	iters: 200, epoch: 28 | loss: 0.3635104
	speed: 0.0138s/iter; left time: 264.5702s
Epoch: 28 cost time: 4.171180486679077
Epoch: 28, Steps: 265 | Train Loss: 0.3734117 Vali Loss: 0.6657325 Test Loss: 0.3838693
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3590992
	speed: 0.0695s/iter; left time: 1319.5837s
	iters: 200, epoch: 29 | loss: 0.3236559
	speed: 0.0139s/iter; left time: 262.2580s
Epoch: 29 cost time: 4.207107067108154
Epoch: 29, Steps: 265 | Train Loss: 0.3735011 Vali Loss: 0.6662441 Test Loss: 0.3838679
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3704011
	speed: 0.0667s/iter; left time: 1247.4814s
	iters: 200, epoch: 30 | loss: 0.3742784
	speed: 0.0133s/iter; left time: 248.0906s
Epoch: 30 cost time: 3.9172418117523193
Epoch: 30, Steps: 265 | Train Loss: 0.3735255 Vali Loss: 0.6660668 Test Loss: 0.3838862
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3821660
	speed: 0.0666s/iter; left time: 1229.1446s
	iters: 200, epoch: 31 | loss: 0.3719852
	speed: 0.0134s/iter; left time: 245.4973s
Epoch: 31 cost time: 3.9855239391326904
Epoch: 31, Steps: 265 | Train Loss: 0.3734970 Vali Loss: 0.6656671 Test Loss: 0.3838524
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3718472
	speed: 0.0688s/iter; left time: 1251.6570s
	iters: 200, epoch: 32 | loss: 0.3860247
	speed: 0.0131s/iter; left time: 236.4937s
Epoch: 32 cost time: 4.094564199447632
Epoch: 32, Steps: 265 | Train Loss: 0.3734905 Vali Loss: 0.6658661 Test Loss: 0.3839360
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4027835
	speed: 0.0680s/iter; left time: 1218.3793s
	iters: 200, epoch: 33 | loss: 0.4045643
	speed: 0.0135s/iter; left time: 239.8381s
Epoch: 33 cost time: 4.058342933654785
Epoch: 33, Steps: 265 | Train Loss: 0.3737587 Vali Loss: 0.6656229 Test Loss: 0.3838544
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3587331
	speed: 0.0667s/iter; left time: 1178.4270s
	iters: 200, epoch: 34 | loss: 0.4010489
	speed: 0.0135s/iter; left time: 236.6985s
Epoch: 34 cost time: 3.957200765609741
Epoch: 34, Steps: 265 | Train Loss: 0.3734839 Vali Loss: 0.6659942 Test Loss: 0.3838780
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3987528
	speed: 0.0681s/iter; left time: 1185.0543s
	iters: 200, epoch: 35 | loss: 0.4254803
	speed: 0.0137s/iter; left time: 237.6802s
Epoch: 35 cost time: 4.105686664581299
Epoch: 35, Steps: 265 | Train Loss: 0.3736759 Vali Loss: 0.6651387 Test Loss: 0.3838678
EarlyStopping counter: 16 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3790695
	speed: 0.0696s/iter; left time: 1191.2003s
	iters: 200, epoch: 36 | loss: 0.3725452
	speed: 0.0134s/iter; left time: 228.0389s
Epoch: 36 cost time: 4.130083322525024
Epoch: 36, Steps: 265 | Train Loss: 0.3735266 Vali Loss: 0.6654699 Test Loss: 0.3838302
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3922252
	speed: 0.0685s/iter; left time: 1154.3781s
	iters: 200, epoch: 37 | loss: 0.3455558
	speed: 0.0135s/iter; left time: 225.5876s
Epoch: 37 cost time: 4.068299055099487
Epoch: 37, Steps: 265 | Train Loss: 0.3735741 Vali Loss: 0.6658102 Test Loss: 0.3838187
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3461892
	speed: 0.0673s/iter; left time: 1117.7295s
	iters: 200, epoch: 38 | loss: 0.4432100
	speed: 0.0136s/iter; left time: 224.0670s
Epoch: 38 cost time: 3.992410898208618
Epoch: 38, Steps: 265 | Train Loss: 0.3735490 Vali Loss: 0.6653296 Test Loss: 0.3838699
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3691196
	speed: 0.0675s/iter; left time: 1102.3507s
	iters: 200, epoch: 39 | loss: 0.3369000
	speed: 0.0139s/iter; left time: 225.4389s
Epoch: 39 cost time: 4.033596754074097
Epoch: 39, Steps: 265 | Train Loss: 0.3736659 Vali Loss: 0.6658956 Test Loss: 0.3838588
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_180_336_FITS_ETTm1_ftM_sl180_ll48_pl336_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.38377588987350464, mae:0.3900737464427948, rse:0.5895045399665833, corr:[0.5443122  0.5490042  0.54692435 0.5443382  0.54378355 0.5443481
 0.544266   0.5434054  0.5424527  0.5424768  0.54337186 0.54383814
 0.5434363  0.54196036 0.5399545  0.5379111  0.53593767 0.5341181
 0.5324196  0.53072107 0.5289116  0.52686554 0.52460635 0.5222521
 0.51982945 0.51747835 0.51549524 0.5138932  0.51274085 0.51207584
 0.512113   0.512711   0.5134167  0.5138746  0.51386434 0.5135693
 0.51310366 0.5126302  0.5123865  0.5122014  0.51209366 0.5119177
 0.5117309  0.5117195  0.5118476  0.5120321  0.51222384 0.51233995
 0.5123726  0.51232266 0.5123111  0.512371   0.5124835  0.51253104
 0.5124961  0.5123867  0.51237804 0.51236844 0.51238793 0.51233786
 0.5122442  0.5121134  0.51195717 0.5118396  0.5117904  0.5119229
 0.5120992  0.51218957 0.51231897 0.51254374 0.5128899  0.51323724
 0.5134518  0.51343817 0.51332664 0.5131191  0.51302063 0.5130669
 0.5131802  0.5132356  0.51322716 0.5131511  0.51307005 0.5128917
 0.51263213 0.5124062  0.512249   0.5120231  0.5116624  0.5113467
 0.51110023 0.5109231  0.5107719  0.5106513  0.510463   0.51004094
 0.5093346  0.5083964  0.5073113  0.506242   0.5055829  0.5055906
 0.50615597 0.5069341  0.507678   0.5083569  0.50912845 0.5101223
 0.51121867 0.51208293 0.5124894  0.5126063  0.51251704 0.5124033
 0.5123081  0.51228064 0.5121103  0.5116715  0.5110935  0.510528
 0.5101724  0.50989276 0.50954056 0.50910765 0.5085174  0.5078423
 0.50734836 0.5071685  0.5071663  0.5071046  0.50681496 0.5063223
 0.5058508  0.5056665  0.5056303  0.5054291  0.50512975 0.50477016
 0.5045193  0.5045908  0.5048426  0.5050318  0.5050132  0.5048645
 0.50476223 0.5048956  0.5051131  0.505311   0.5054903  0.5053764
 0.50514376 0.50502396 0.5050564  0.505198   0.5052062  0.50514275
 0.5050475  0.5050136  0.5049823  0.50499696 0.5049832  0.5049524
 0.5049786  0.5051304  0.5053789  0.50577486 0.5061553  0.5064241
 0.50661504 0.5067078  0.506684   0.5067168  0.506734   0.50667185
 0.50657135 0.50642025 0.506304   0.506292   0.50630367 0.5063502
 0.50634956 0.5062741  0.5061293  0.5060303  0.5060694  0.5062264
 0.5063934  0.5064573  0.50644284 0.50646913 0.50661355 0.50682425
 0.50690305 0.506776   0.50637704 0.5056441  0.50483376 0.5042609
 0.50397456 0.50381684 0.5036874  0.50377434 0.5039045  0.5039562
 0.5038587  0.5034467  0.50297886 0.50264883 0.50237    0.50206125
 0.50166285 0.5012124  0.50064677 0.49985722 0.49886134 0.49781886
 0.4968945  0.49611196 0.4954736  0.49494025 0.49443972 0.49407092
 0.4939663  0.49416888 0.49442223 0.49451166 0.49434635 0.49391174
 0.49339256 0.49314287 0.49311888 0.4931156  0.49301475 0.49281555
 0.49261108 0.49254167 0.49248934 0.49255094 0.49267474 0.49272612
 0.492817   0.49283892 0.49287182 0.49283355 0.4927484  0.49267477
 0.49269348 0.49277034 0.4929563  0.49318972 0.49332026 0.49325904
 0.49306723 0.49295378 0.49290434 0.4929696  0.49300992 0.49294963
 0.49290588 0.49295253 0.49312922 0.4934454  0.49378195 0.4940811
 0.49432072 0.49440297 0.49447292 0.49467632 0.4950503  0.49540466
 0.49567476 0.49574724 0.49574062 0.49574634 0.49588263 0.49609035
 0.4962807  0.49645486 0.4965366  0.49656942 0.49665508 0.496793
 0.49694067 0.49693307 0.4967407  0.49638644 0.495926   0.4953896
 0.49463436 0.49372828 0.49284092 0.49205402 0.49156973 0.4913941
 0.49147028 0.49147227 0.4914325  0.49149618 0.49178088 0.49228844
 0.49276114 0.4928803  0.4927607  0.49259418 0.4924847  0.49242273
 0.4924007  0.49229148 0.49199465 0.49157938 0.49117428 0.49085298
 0.4905645  0.49015296 0.48965272 0.489222   0.48881537 0.4886578
 0.4887033  0.48861703 0.48823887 0.48773304 0.48722053 0.4869581
 0.48689514 0.48675743 0.48620442 0.48533678 0.48463988 0.48455557
 0.48494655 0.4851853  0.48480448 0.48454428 0.48570573 0.4880675 ]
