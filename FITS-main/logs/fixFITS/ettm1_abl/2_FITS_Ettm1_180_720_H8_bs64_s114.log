Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_180_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_180_720_FITS_ETTm1_ftM_sl180_ll48_pl720_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33661
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=26, out_features=130, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3028480.0
params:  3510.0
Trainable parameters:  3510
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.7294621
	speed: 0.0211s/iter; left time: 549.9807s
	iters: 200, epoch: 1 | loss: 0.5300852
	speed: 0.0151s/iter; left time: 391.7486s
Epoch: 1 cost time: 4.611732482910156
Epoch: 1, Steps: 262 | Train Loss: 0.7059889 Vali Loss: 1.2553194 Test Loss: 0.6772463
Validation loss decreased (inf --> 1.255319).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4772386
	speed: 0.0714s/iter; left time: 1845.0885s
	iters: 200, epoch: 2 | loss: 0.4176377
	speed: 0.0152s/iter; left time: 392.0892s
Epoch: 2 cost time: 4.623724460601807
Epoch: 2, Steps: 262 | Train Loss: 0.4387427 Vali Loss: 1.0838454 Test Loss: 0.5237775
Validation loss decreased (1.255319 --> 1.083845).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3724109
	speed: 0.0778s/iter; left time: 1989.6769s
	iters: 200, epoch: 3 | loss: 0.4195664
	speed: 0.0153s/iter; left time: 389.7457s
Epoch: 3 cost time: 4.738075494766235
Epoch: 3, Steps: 262 | Train Loss: 0.3908196 Vali Loss: 1.0363536 Test Loss: 0.4837589
Validation loss decreased (1.083845 --> 1.036354).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4001928
	speed: 0.0766s/iter; left time: 1938.2458s
	iters: 200, epoch: 4 | loss: 0.3830027
	speed: 0.0167s/iter; left time: 421.8980s
Epoch: 4 cost time: 4.959405183792114
Epoch: 4, Steps: 262 | Train Loss: 0.3756461 Vali Loss: 1.0129015 Test Loss: 0.4657740
Validation loss decreased (1.036354 --> 1.012902).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3404315
	speed: 0.0743s/iter; left time: 1862.0972s
	iters: 200, epoch: 5 | loss: 0.3479878
	speed: 0.0153s/iter; left time: 382.1326s
Epoch: 5 cost time: 4.483124256134033
Epoch: 5, Steps: 262 | Train Loss: 0.3682038 Vali Loss: 1.0008425 Test Loss: 0.4566355
Validation loss decreased (1.012902 --> 1.000842).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3580210
	speed: 0.0758s/iter; left time: 1878.5136s
	iters: 200, epoch: 6 | loss: 0.3603879
	speed: 0.0151s/iter; left time: 373.4475s
Epoch: 6 cost time: 4.571799993515015
Epoch: 6, Steps: 262 | Train Loss: 0.3642822 Vali Loss: 0.9929718 Test Loss: 0.4518304
Validation loss decreased (1.000842 --> 0.992972).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3552777
	speed: 0.0731s/iter; left time: 1793.9255s
	iters: 200, epoch: 7 | loss: 0.3784066
	speed: 0.0158s/iter; left time: 386.5919s
Epoch: 7 cost time: 4.504247665405273
Epoch: 7, Steps: 262 | Train Loss: 0.3619637 Vali Loss: 0.9898330 Test Loss: 0.4491554
Validation loss decreased (0.992972 --> 0.989833).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3521119
	speed: 0.0821s/iter; left time: 1992.9128s
	iters: 200, epoch: 8 | loss: 0.3876118
	speed: 0.0165s/iter; left time: 399.8038s
Epoch: 8 cost time: 4.834931135177612
Epoch: 8, Steps: 262 | Train Loss: 0.3606754 Vali Loss: 0.9868142 Test Loss: 0.4476496
Validation loss decreased (0.989833 --> 0.986814).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3466208
	speed: 0.0736s/iter; left time: 1767.0699s
	iters: 200, epoch: 9 | loss: 0.3833285
	speed: 0.0150s/iter; left time: 357.6609s
Epoch: 9 cost time: 4.47641396522522
Epoch: 9, Steps: 262 | Train Loss: 0.3599241 Vali Loss: 0.9844036 Test Loss: 0.4469692
Validation loss decreased (0.986814 --> 0.984404).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3682794
	speed: 0.0729s/iter; left time: 1731.7586s
	iters: 200, epoch: 10 | loss: 0.3696269
	speed: 0.0148s/iter; left time: 350.8025s
Epoch: 10 cost time: 4.49547553062439
Epoch: 10, Steps: 262 | Train Loss: 0.3594420 Vali Loss: 0.9841133 Test Loss: 0.4468560
Validation loss decreased (0.984404 --> 0.984113).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3409779
	speed: 0.0739s/iter; left time: 1734.7195s
	iters: 200, epoch: 11 | loss: 0.3552402
	speed: 0.0151s/iter; left time: 352.8984s
Epoch: 11 cost time: 4.4891839027404785
Epoch: 11, Steps: 262 | Train Loss: 0.3592902 Vali Loss: 0.9845650 Test Loss: 0.4467514
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3809252
	speed: 0.0710s/iter; left time: 1649.4331s
	iters: 200, epoch: 12 | loss: 0.3429647
	speed: 0.0149s/iter; left time: 345.2871s
Epoch: 12 cost time: 4.361833095550537
Epoch: 12, Steps: 262 | Train Loss: 0.3593091 Vali Loss: 0.9842649 Test Loss: 0.4467617
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3385191
	speed: 0.0741s/iter; left time: 1701.9193s
	iters: 200, epoch: 13 | loss: 0.3339868
	speed: 0.0151s/iter; left time: 345.5664s
Epoch: 13 cost time: 4.5662522315979
Epoch: 13, Steps: 262 | Train Loss: 0.3592467 Vali Loss: 0.9828379 Test Loss: 0.4466294
Validation loss decreased (0.984113 --> 0.982838).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3221371
	speed: 0.0733s/iter; left time: 1663.9341s
	iters: 200, epoch: 14 | loss: 0.3770743
	speed: 0.0153s/iter; left time: 346.7025s
Epoch: 14 cost time: 4.581456661224365
Epoch: 14, Steps: 262 | Train Loss: 0.3591476 Vali Loss: 0.9831696 Test Loss: 0.4469971
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3510688
	speed: 0.0737s/iter; left time: 1653.3376s
	iters: 200, epoch: 15 | loss: 0.3393212
	speed: 0.0164s/iter; left time: 366.6463s
Epoch: 15 cost time: 4.877870082855225
Epoch: 15, Steps: 262 | Train Loss: 0.3592243 Vali Loss: 0.9835909 Test Loss: 0.4467167
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3873286
	speed: 0.0796s/iter; left time: 1764.1849s
	iters: 200, epoch: 16 | loss: 0.3535103
	speed: 0.0154s/iter; left time: 338.8429s
Epoch: 16 cost time: 4.6243720054626465
Epoch: 16, Steps: 262 | Train Loss: 0.3592238 Vali Loss: 0.9830915 Test Loss: 0.4467564
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3872711
	speed: 0.0759s/iter; left time: 1663.8134s
	iters: 200, epoch: 17 | loss: 0.3579621
	speed: 0.0149s/iter; left time: 325.8470s
Epoch: 17 cost time: 4.664632558822632
Epoch: 17, Steps: 262 | Train Loss: 0.3592299 Vali Loss: 0.9826990 Test Loss: 0.4467912
Validation loss decreased (0.982838 --> 0.982699).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3904259
	speed: 0.0761s/iter; left time: 1646.6092s
	iters: 200, epoch: 18 | loss: 0.3593202
	speed: 0.0150s/iter; left time: 322.7517s
Epoch: 18 cost time: 4.51744818687439
Epoch: 18, Steps: 262 | Train Loss: 0.3590981 Vali Loss: 0.9825069 Test Loss: 0.4467819
Validation loss decreased (0.982699 --> 0.982507).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3719550
	speed: 0.0721s/iter; left time: 1541.3890s
	iters: 200, epoch: 19 | loss: 0.3523170
	speed: 0.0153s/iter; left time: 325.0570s
Epoch: 19 cost time: 4.4836745262146
Epoch: 19, Steps: 262 | Train Loss: 0.3590373 Vali Loss: 0.9830503 Test Loss: 0.4468469
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3532618
	speed: 0.0741s/iter; left time: 1565.6970s
	iters: 200, epoch: 20 | loss: 0.3507389
	speed: 0.0149s/iter; left time: 312.2838s
Epoch: 20 cost time: 4.592096567153931
Epoch: 20, Steps: 262 | Train Loss: 0.3590695 Vali Loss: 0.9829442 Test Loss: 0.4467179
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3981985
	speed: 0.0729s/iter; left time: 1521.4211s
	iters: 200, epoch: 21 | loss: 0.3364604
	speed: 0.0149s/iter; left time: 310.1600s
Epoch: 21 cost time: 4.484238147735596
Epoch: 21, Steps: 262 | Train Loss: 0.3590950 Vali Loss: 0.9828046 Test Loss: 0.4469075
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3610972
	speed: 0.0727s/iter; left time: 1498.5182s
	iters: 200, epoch: 22 | loss: 0.3545291
	speed: 0.0151s/iter; left time: 310.1043s
Epoch: 22 cost time: 4.47498893737793
Epoch: 22, Steps: 262 | Train Loss: 0.3590815 Vali Loss: 0.9837483 Test Loss: 0.4468910
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3695101
	speed: 0.0714s/iter; left time: 1452.3137s
	iters: 200, epoch: 23 | loss: 0.3299584
	speed: 0.0150s/iter; left time: 304.4188s
Epoch: 23 cost time: 4.477868318557739
Epoch: 23, Steps: 262 | Train Loss: 0.3591718 Vali Loss: 0.9834179 Test Loss: 0.4467857
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3746881
	speed: 0.0729s/iter; left time: 1464.4697s
	iters: 200, epoch: 24 | loss: 0.3511550
	speed: 0.0150s/iter; left time: 298.8036s
Epoch: 24 cost time: 4.501530647277832
Epoch: 24, Steps: 262 | Train Loss: 0.3591996 Vali Loss: 0.9825965 Test Loss: 0.4468268
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3558162
	speed: 0.0720s/iter; left time: 1425.7392s
	iters: 200, epoch: 25 | loss: 0.3788992
	speed: 0.0153s/iter; left time: 301.5106s
Epoch: 25 cost time: 4.5410706996917725
Epoch: 25, Steps: 262 | Train Loss: 0.3591227 Vali Loss: 0.9833515 Test Loss: 0.4468510
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3125259
	speed: 0.0724s/iter; left time: 1415.2734s
	iters: 200, epoch: 26 | loss: 0.3588515
	speed: 0.0149s/iter; left time: 289.6069s
Epoch: 26 cost time: 4.500052452087402
Epoch: 26, Steps: 262 | Train Loss: 0.3590601 Vali Loss: 0.9829254 Test Loss: 0.4468969
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3763274
	speed: 0.0735s/iter; left time: 1417.9867s
	iters: 200, epoch: 27 | loss: 0.3071683
	speed: 0.0154s/iter; left time: 295.8412s
Epoch: 27 cost time: 4.585115909576416
Epoch: 27, Steps: 262 | Train Loss: 0.3591300 Vali Loss: 0.9831777 Test Loss: 0.4469335
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3585782
	speed: 0.0731s/iter; left time: 1390.9401s
	iters: 200, epoch: 28 | loss: 0.3836912
	speed: 0.0149s/iter; left time: 282.4900s
Epoch: 28 cost time: 4.5490498542785645
Epoch: 28, Steps: 262 | Train Loss: 0.3589914 Vali Loss: 0.9830747 Test Loss: 0.4468828
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3320386
	speed: 0.0753s/iter; left time: 1412.7809s
	iters: 200, epoch: 29 | loss: 0.4044612
	speed: 0.0163s/iter; left time: 303.4086s
Epoch: 29 cost time: 4.733252048492432
Epoch: 29, Steps: 262 | Train Loss: 0.3591298 Vali Loss: 0.9837178 Test Loss: 0.4468544
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3552620
	speed: 0.0711s/iter; left time: 1316.3868s
	iters: 200, epoch: 30 | loss: 0.3740551
	speed: 0.0151s/iter; left time: 278.1873s
Epoch: 30 cost time: 4.409912347793579
Epoch: 30, Steps: 262 | Train Loss: 0.3590685 Vali Loss: 0.9826333 Test Loss: 0.4469316
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3895189
	speed: 0.0754s/iter; left time: 1375.6771s
	iters: 200, epoch: 31 | loss: 0.3727534
	speed: 0.0167s/iter; left time: 302.7128s
Epoch: 31 cost time: 4.957554340362549
Epoch: 31, Steps: 262 | Train Loss: 0.3589981 Vali Loss: 0.9839110 Test Loss: 0.4468960
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3744142
	speed: 0.0730s/iter; left time: 1312.6739s
	iters: 200, epoch: 32 | loss: 0.3652032
	speed: 0.0148s/iter; left time: 264.4364s
Epoch: 32 cost time: 4.467201471328735
Epoch: 32, Steps: 262 | Train Loss: 0.3589308 Vali Loss: 0.9834965 Test Loss: 0.4469071
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3346279
	speed: 0.0737s/iter; left time: 1305.7052s
	iters: 200, epoch: 33 | loss: 0.3578593
	speed: 0.0149s/iter; left time: 262.3213s
Epoch: 33 cost time: 4.516758918762207
Epoch: 33, Steps: 262 | Train Loss: 0.3590381 Vali Loss: 0.9831158 Test Loss: 0.4468834
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3278679
	speed: 0.0714s/iter; left time: 1246.0766s
	iters: 200, epoch: 34 | loss: 0.3389760
	speed: 0.0159s/iter; left time: 276.7092s
Epoch: 34 cost time: 4.556822776794434
Epoch: 34, Steps: 262 | Train Loss: 0.3590913 Vali Loss: 0.9833757 Test Loss: 0.4469470
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3876520
	speed: 0.0750s/iter; left time: 1289.9826s
	iters: 200, epoch: 35 | loss: 0.3459710
	speed: 0.0170s/iter; left time: 290.1358s
Epoch: 35 cost time: 4.9355223178863525
Epoch: 35, Steps: 262 | Train Loss: 0.3589872 Vali Loss: 0.9838645 Test Loss: 0.4469588
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3568325
	speed: 0.0772s/iter; left time: 1306.5191s
	iters: 200, epoch: 36 | loss: 0.3482308
	speed: 0.0153s/iter; left time: 256.8264s
Epoch: 36 cost time: 4.541807174682617
Epoch: 36, Steps: 262 | Train Loss: 0.3590992 Vali Loss: 0.9834158 Test Loss: 0.4469155
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3655644
	speed: 0.0735s/iter; left time: 1225.1025s
	iters: 200, epoch: 37 | loss: 0.3667805
	speed: 0.0151s/iter; left time: 249.8857s
Epoch: 37 cost time: 4.550554275512695
Epoch: 37, Steps: 262 | Train Loss: 0.3591444 Vali Loss: 0.9832596 Test Loss: 0.4468825
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3629243
	speed: 0.0714s/iter; left time: 1171.8855s
	iters: 200, epoch: 38 | loss: 0.3426256
	speed: 0.0155s/iter; left time: 252.4742s
Epoch: 38 cost time: 4.508870601654053
Epoch: 38, Steps: 262 | Train Loss: 0.3590653 Vali Loss: 0.9830219 Test Loss: 0.4468828
EarlyStopping counter: 20 out of 20
Early stopping
train 33661
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=26, out_features=130, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3028480.0
params:  3510.0
Trainable parameters:  3510
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4371405
	speed: 0.0213s/iter; left time: 555.3203s
	iters: 200, epoch: 1 | loss: 0.3830235
	speed: 0.0149s/iter; left time: 388.5464s
Epoch: 1 cost time: 4.548511028289795
Epoch: 1, Steps: 262 | Train Loss: 0.4433366 Vali Loss: 0.9815961 Test Loss: 0.4455749
Validation loss decreased (inf --> 0.981596).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4251792
	speed: 0.0726s/iter; left time: 1876.0702s
	iters: 200, epoch: 2 | loss: 0.4451734
	speed: 0.0150s/iter; left time: 386.7430s
Epoch: 2 cost time: 4.51573634147644
Epoch: 2, Steps: 262 | Train Loss: 0.4428877 Vali Loss: 0.9813943 Test Loss: 0.4452377
Validation loss decreased (0.981596 --> 0.981394).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4030819
	speed: 0.0726s/iter; left time: 1857.0136s
	iters: 200, epoch: 3 | loss: 0.4323415
	speed: 0.0151s/iter; left time: 385.3408s
Epoch: 3 cost time: 4.555784225463867
Epoch: 3, Steps: 262 | Train Loss: 0.4429830 Vali Loss: 0.9809817 Test Loss: 0.4453766
Validation loss decreased (0.981394 --> 0.980982).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4561724
	speed: 0.0739s/iter; left time: 1871.3984s
	iters: 200, epoch: 4 | loss: 0.4831623
	speed: 0.0149s/iter; left time: 376.1819s
Epoch: 4 cost time: 4.485083103179932
Epoch: 4, Steps: 262 | Train Loss: 0.4428561 Vali Loss: 0.9797404 Test Loss: 0.4454467
Validation loss decreased (0.980982 --> 0.979740).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4688313
	speed: 0.0734s/iter; left time: 1838.2887s
	iters: 200, epoch: 5 | loss: 0.4869078
	speed: 0.0155s/iter; left time: 386.5059s
Epoch: 5 cost time: 4.595449209213257
Epoch: 5, Steps: 262 | Train Loss: 0.4428671 Vali Loss: 0.9802974 Test Loss: 0.4453420
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4462944
	speed: 0.0795s/iter; left time: 1970.6693s
	iters: 200, epoch: 6 | loss: 0.4639087
	speed: 0.0239s/iter; left time: 589.9918s
Epoch: 6 cost time: 5.826414585113525
Epoch: 6, Steps: 262 | Train Loss: 0.4427012 Vali Loss: 0.9803210 Test Loss: 0.4452567
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4653851
	speed: 0.1022s/iter; left time: 2505.8176s
	iters: 200, epoch: 7 | loss: 0.3952175
	speed: 0.0152s/iter; left time: 372.3242s
Epoch: 7 cost time: 4.5778703689575195
Epoch: 7, Steps: 262 | Train Loss: 0.4428825 Vali Loss: 0.9799181 Test Loss: 0.4454364
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4563170
	speed: 0.0723s/iter; left time: 1753.7526s
	iters: 200, epoch: 8 | loss: 0.4611471
	speed: 0.0150s/iter; left time: 361.7545s
Epoch: 8 cost time: 4.470581293106079
Epoch: 8, Steps: 262 | Train Loss: 0.4429776 Vali Loss: 0.9802678 Test Loss: 0.4453057
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4720927
	speed: 0.0733s/iter; left time: 1758.4328s
	iters: 200, epoch: 9 | loss: 0.4548533
	speed: 0.0147s/iter; left time: 351.7982s
Epoch: 9 cost time: 4.4332969188690186
Epoch: 9, Steps: 262 | Train Loss: 0.4427234 Vali Loss: 0.9807626 Test Loss: 0.4455178
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4195785
	speed: 0.0733s/iter; left time: 1740.9434s
	iters: 200, epoch: 10 | loss: 0.4148772
	speed: 0.0149s/iter; left time: 351.1256s
Epoch: 10 cost time: 4.440544843673706
Epoch: 10, Steps: 262 | Train Loss: 0.4426672 Vali Loss: 0.9805033 Test Loss: 0.4455563
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4426115
	speed: 0.0726s/iter; left time: 1705.5360s
	iters: 200, epoch: 11 | loss: 0.4024538
	speed: 0.0151s/iter; left time: 353.6336s
Epoch: 11 cost time: 4.438101530075073
Epoch: 11, Steps: 262 | Train Loss: 0.4427832 Vali Loss: 0.9806219 Test Loss: 0.4452502
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4041946
	speed: 0.0748s/iter; left time: 1736.1125s
	iters: 200, epoch: 12 | loss: 0.4299521
	speed: 0.0168s/iter; left time: 388.6689s
Epoch: 12 cost time: 4.91021728515625
Epoch: 12, Steps: 262 | Train Loss: 0.4427893 Vali Loss: 0.9806779 Test Loss: 0.4454042
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4422391
	speed: 0.0818s/iter; left time: 1877.0121s
	iters: 200, epoch: 13 | loss: 0.4408355
	speed: 0.0164s/iter; left time: 374.4281s
Epoch: 13 cost time: 4.82989501953125
Epoch: 13, Steps: 262 | Train Loss: 0.4428286 Vali Loss: 0.9812263 Test Loss: 0.4456303
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4915919
	speed: 0.0730s/iter; left time: 1657.1695s
	iters: 200, epoch: 14 | loss: 0.4699653
	speed: 0.0151s/iter; left time: 340.4515s
Epoch: 14 cost time: 4.622851133346558
Epoch: 14, Steps: 262 | Train Loss: 0.4427369 Vali Loss: 0.9801266 Test Loss: 0.4454651
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4366695
	speed: 0.0833s/iter; left time: 1868.0140s
	iters: 200, epoch: 15 | loss: 0.4565752
	speed: 0.0153s/iter; left time: 341.5316s
Epoch: 15 cost time: 5.043645143508911
Epoch: 15, Steps: 262 | Train Loss: 0.4426587 Vali Loss: 0.9805955 Test Loss: 0.4453825
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4442610
	speed: 0.0725s/iter; left time: 1606.4936s
	iters: 200, epoch: 16 | loss: 0.4192517
	speed: 0.0152s/iter; left time: 336.5169s
Epoch: 16 cost time: 4.579668045043945
Epoch: 16, Steps: 262 | Train Loss: 0.4426893 Vali Loss: 0.9796930 Test Loss: 0.4455737
Validation loss decreased (0.979740 --> 0.979693).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4336356
	speed: 0.0727s/iter; left time: 1592.3420s
	iters: 200, epoch: 17 | loss: 0.4114504
	speed: 0.0152s/iter; left time: 331.1136s
Epoch: 17 cost time: 4.5336198806762695
Epoch: 17, Steps: 262 | Train Loss: 0.4425212 Vali Loss: 0.9804927 Test Loss: 0.4455709
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4363281
	speed: 0.1020s/iter; left time: 2207.4347s
	iters: 200, epoch: 18 | loss: 0.4621337
	speed: 0.0438s/iter; left time: 942.8177s
Epoch: 18 cost time: 11.171369791030884
Epoch: 18, Steps: 262 | Train Loss: 0.4426732 Vali Loss: 0.9804103 Test Loss: 0.4454579
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4490043
	speed: 0.0883s/iter; left time: 1887.6058s
	iters: 200, epoch: 19 | loss: 0.4902734
	speed: 0.0147s/iter; left time: 313.6987s
Epoch: 19 cost time: 4.489284038543701
Epoch: 19, Steps: 262 | Train Loss: 0.4424987 Vali Loss: 0.9812773 Test Loss: 0.4454063
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4401160
	speed: 0.0893s/iter; left time: 1885.4199s
	iters: 200, epoch: 20 | loss: 0.4378980
	speed: 0.0154s/iter; left time: 323.7391s
Epoch: 20 cost time: 6.1405346393585205
Epoch: 20, Steps: 262 | Train Loss: 0.4427257 Vali Loss: 0.9802983 Test Loss: 0.4454549
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4527650
	speed: 0.0745s/iter; left time: 1553.1990s
	iters: 200, epoch: 21 | loss: 0.4359407
	speed: 0.0149s/iter; left time: 309.6198s
Epoch: 21 cost time: 4.570189952850342
Epoch: 21, Steps: 262 | Train Loss: 0.4426783 Vali Loss: 0.9806571 Test Loss: 0.4456800
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4073585
	speed: 0.0727s/iter; left time: 1497.7434s
	iters: 200, epoch: 22 | loss: 0.4763205
	speed: 0.0161s/iter; left time: 329.1265s
Epoch: 22 cost time: 4.680353879928589
Epoch: 22, Steps: 262 | Train Loss: 0.4427559 Vali Loss: 0.9802942 Test Loss: 0.4455234
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4325324
	speed: 0.0770s/iter; left time: 1566.8456s
	iters: 200, epoch: 23 | loss: 0.4399265
	speed: 0.0208s/iter; left time: 419.9599s
Epoch: 23 cost time: 5.163107633590698
Epoch: 23, Steps: 262 | Train Loss: 0.4427164 Vali Loss: 0.9796649 Test Loss: 0.4454028
Validation loss decreased (0.979693 --> 0.979665).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4386573
	speed: 0.0732s/iter; left time: 1469.3455s
	iters: 200, epoch: 24 | loss: 0.4252439
	speed: 0.0154s/iter; left time: 306.6780s
Epoch: 24 cost time: 4.583780765533447
Epoch: 24, Steps: 262 | Train Loss: 0.4426202 Vali Loss: 0.9799340 Test Loss: 0.4455400
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4237269
	speed: 0.0730s/iter; left time: 1446.8186s
	iters: 200, epoch: 25 | loss: 0.3990263
	speed: 0.0148s/iter; left time: 292.4648s
Epoch: 25 cost time: 4.438327312469482
Epoch: 25, Steps: 262 | Train Loss: 0.4427493 Vali Loss: 0.9801652 Test Loss: 0.4455391
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4523576
	speed: 0.0763s/iter; left time: 1492.1971s
	iters: 200, epoch: 26 | loss: 0.4339623
	speed: 0.0176s/iter; left time: 342.4197s
Epoch: 26 cost time: 5.048551559448242
Epoch: 26, Steps: 262 | Train Loss: 0.4426155 Vali Loss: 0.9802968 Test Loss: 0.4455472
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4235699
	speed: 0.0765s/iter; left time: 1476.5134s
	iters: 200, epoch: 27 | loss: 0.4762401
	speed: 0.0149s/iter; left time: 285.0156s
Epoch: 27 cost time: 4.51301908493042
Epoch: 27, Steps: 262 | Train Loss: 0.4425629 Vali Loss: 0.9803352 Test Loss: 0.4455625
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4101852
	speed: 0.0747s/iter; left time: 1421.3921s
	iters: 200, epoch: 28 | loss: 0.4365758
	speed: 0.0152s/iter; left time: 287.6938s
Epoch: 28 cost time: 4.504473686218262
Epoch: 28, Steps: 262 | Train Loss: 0.4424638 Vali Loss: 0.9805303 Test Loss: 0.4455082
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4356774
	speed: 0.0750s/iter; left time: 1408.2403s
	iters: 200, epoch: 29 | loss: 0.4964873
	speed: 0.0150s/iter; left time: 279.6771s
Epoch: 29 cost time: 4.561324119567871
Epoch: 29, Steps: 262 | Train Loss: 0.4426127 Vali Loss: 0.9809724 Test Loss: 0.4455491
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4263302
	speed: 0.0765s/iter; left time: 1415.4408s
	iters: 200, epoch: 30 | loss: 0.4513008
	speed: 0.0163s/iter; left time: 300.3657s
Epoch: 30 cost time: 4.869322776794434
Epoch: 30, Steps: 262 | Train Loss: 0.4425880 Vali Loss: 0.9802533 Test Loss: 0.4454880
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4706296
	speed: 0.0751s/iter; left time: 1369.3211s
	iters: 200, epoch: 31 | loss: 0.4442412
	speed: 0.0151s/iter; left time: 273.2196s
Epoch: 31 cost time: 4.503126859664917
Epoch: 31, Steps: 262 | Train Loss: 0.4426492 Vali Loss: 0.9805522 Test Loss: 0.4455497
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4197167
	speed: 0.0733s/iter; left time: 1316.9949s
	iters: 200, epoch: 32 | loss: 0.4578376
	speed: 0.0153s/iter; left time: 272.7306s
Epoch: 32 cost time: 4.533851861953735
Epoch: 32, Steps: 262 | Train Loss: 0.4424904 Vali Loss: 0.9804750 Test Loss: 0.4455580
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4295008
	speed: 0.0748s/iter; left time: 1324.8233s
	iters: 200, epoch: 33 | loss: 0.4724222
	speed: 0.0150s/iter; left time: 264.1815s
Epoch: 33 cost time: 4.5028276443481445
Epoch: 33, Steps: 262 | Train Loss: 0.4426321 Vali Loss: 0.9805421 Test Loss: 0.4454879
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4169812
	speed: 0.0734s/iter; left time: 1281.8177s
	iters: 200, epoch: 34 | loss: 0.4537324
	speed: 0.0151s/iter; left time: 261.6397s
Epoch: 34 cost time: 4.615212917327881
Epoch: 34, Steps: 262 | Train Loss: 0.4426410 Vali Loss: 0.9806760 Test Loss: 0.4454625
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4471525
	speed: 0.0762s/iter; left time: 1310.8496s
	iters: 200, epoch: 35 | loss: 0.4037422
	speed: 0.0165s/iter; left time: 281.8090s
Epoch: 35 cost time: 4.962558269500732
Epoch: 35, Steps: 262 | Train Loss: 0.4423156 Vali Loss: 0.9802549 Test Loss: 0.4455323
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4206614
	speed: 0.0751s/iter; left time: 1271.6025s
	iters: 200, epoch: 36 | loss: 0.4420538
	speed: 0.0153s/iter; left time: 257.6195s
Epoch: 36 cost time: 4.510418176651001
Epoch: 36, Steps: 262 | Train Loss: 0.4426446 Vali Loss: 0.9804932 Test Loss: 0.4455334
EarlyStopping counter: 13 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4463069
	speed: 0.0743s/iter; left time: 1238.8046s
	iters: 200, epoch: 37 | loss: 0.4615129
	speed: 0.0166s/iter; left time: 274.2781s
Epoch: 37 cost time: 4.755944490432739
Epoch: 37, Steps: 262 | Train Loss: 0.4426309 Vali Loss: 0.9796602 Test Loss: 0.4455510
Validation loss decreased (0.979665 --> 0.979660).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4406561
	speed: 0.0762s/iter; left time: 1249.4513s
	iters: 200, epoch: 38 | loss: 0.4279581
	speed: 0.0154s/iter; left time: 250.9864s
Epoch: 38 cost time: 4.554526329040527
Epoch: 38, Steps: 262 | Train Loss: 0.4425253 Vali Loss: 0.9806865 Test Loss: 0.4455754
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4616385
	speed: 0.0774s/iter; left time: 1249.8083s
	iters: 200, epoch: 39 | loss: 0.4232955
	speed: 0.0150s/iter; left time: 241.2202s
Epoch: 39 cost time: 4.552514314651489
Epoch: 39, Steps: 262 | Train Loss: 0.4425112 Vali Loss: 0.9816922 Test Loss: 0.4455282
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.4914726
	speed: 0.0743s/iter; left time: 1180.2888s
	iters: 200, epoch: 40 | loss: 0.4068668
	speed: 0.0151s/iter; left time: 239.0071s
Epoch: 40 cost time: 4.60472846031189
Epoch: 40, Steps: 262 | Train Loss: 0.4426099 Vali Loss: 0.9808266 Test Loss: 0.4455770
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.4442656
	speed: 0.0745s/iter; left time: 1163.0239s
	iters: 200, epoch: 41 | loss: 0.4470008
	speed: 0.0150s/iter; left time: 233.0608s
Epoch: 41 cost time: 4.515812397003174
Epoch: 41, Steps: 262 | Train Loss: 0.4425846 Vali Loss: 0.9810997 Test Loss: 0.4455391
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.4200246
	speed: 0.0719s/iter; left time: 1104.2247s
	iters: 200, epoch: 42 | loss: 0.4336831
	speed: 0.0149s/iter; left time: 226.6414s
Epoch: 42 cost time: 4.440065622329712
Epoch: 42, Steps: 262 | Train Loss: 0.4427215 Vali Loss: 0.9803408 Test Loss: 0.4455579
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.4205772
	speed: 0.0733s/iter; left time: 1106.4659s
	iters: 200, epoch: 43 | loss: 0.4638155
	speed: 0.0146s/iter; left time: 219.6618s
Epoch: 43 cost time: 4.484568119049072
Epoch: 43, Steps: 262 | Train Loss: 0.4424344 Vali Loss: 0.9809208 Test Loss: 0.4455771
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.4429846
	speed: 0.0731s/iter; left time: 1085.1169s
	iters: 200, epoch: 44 | loss: 0.4408195
	speed: 0.0147s/iter; left time: 216.8856s
Epoch: 44 cost time: 4.463959217071533
Epoch: 44, Steps: 262 | Train Loss: 0.4424294 Vali Loss: 0.9808000 Test Loss: 0.4455386
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.4332118
	speed: 0.0733s/iter; left time: 1068.5277s
	iters: 200, epoch: 45 | loss: 0.4115975
	speed: 0.0152s/iter; left time: 219.6904s
Epoch: 45 cost time: 5.3145482540130615
Epoch: 45, Steps: 262 | Train Loss: 0.4425526 Vali Loss: 0.9809024 Test Loss: 0.4455317
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.4821917
	speed: 0.0907s/iter; left time: 1297.2937s
	iters: 200, epoch: 46 | loss: 0.4340328
	speed: 0.0178s/iter; left time: 253.1471s
Epoch: 46 cost time: 5.167642831802368
Epoch: 46, Steps: 262 | Train Loss: 0.4425587 Vali Loss: 0.9807345 Test Loss: 0.4455669
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.4658547
	speed: 0.0743s/iter; left time: 1044.1542s
	iters: 200, epoch: 47 | loss: 0.4346159
	speed: 0.0150s/iter; left time: 209.5791s
Epoch: 47 cost time: 4.413627624511719
Epoch: 47, Steps: 262 | Train Loss: 0.4425645 Vali Loss: 0.9807151 Test Loss: 0.4455630
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.4422933
	speed: 0.0726s/iter; left time: 1000.7565s
	iters: 200, epoch: 48 | loss: 0.4479001
	speed: 0.0149s/iter; left time: 203.3005s
Epoch: 48 cost time: 4.47417426109314
Epoch: 48, Steps: 262 | Train Loss: 0.4426372 Vali Loss: 0.9802606 Test Loss: 0.4455924
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.3727193
	speed: 0.0757s/iter; left time: 1023.5211s
	iters: 200, epoch: 49 | loss: 0.4668209
	speed: 0.0172s/iter; left time: 231.1663s
Epoch: 49 cost time: 4.978076696395874
Epoch: 49, Steps: 262 | Train Loss: 0.4425102 Vali Loss: 0.9807166 Test Loss: 0.4455591
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.4771048
	speed: 0.0740s/iter; left time: 981.3541s
	iters: 200, epoch: 50 | loss: 0.4066853
	speed: 0.0149s/iter; left time: 195.6271s
Epoch: 50 cost time: 4.377605676651001
Epoch: 50, Steps: 262 | Train Loss: 0.4426262 Vali Loss: 0.9796209 Test Loss: 0.4455559
Validation loss decreased (0.979660 --> 0.979621).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.4712633
	speed: 0.0732s/iter; left time: 951.3620s
	iters: 200, epoch: 51 | loss: 0.4163828
	speed: 0.0149s/iter; left time: 192.4669s
Epoch: 51 cost time: 4.4929656982421875
Epoch: 51, Steps: 262 | Train Loss: 0.4426346 Vali Loss: 0.9815012 Test Loss: 0.4455721
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.4654078
	speed: 0.0754s/iter; left time: 960.1496s
	iters: 200, epoch: 52 | loss: 0.4474501
	speed: 0.0149s/iter; left time: 188.3894s
Epoch: 52 cost time: 4.490842342376709
Epoch: 52, Steps: 262 | Train Loss: 0.4423893 Vali Loss: 0.9810165 Test Loss: 0.4455573
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.3993781
	speed: 0.0738s/iter; left time: 921.3385s
	iters: 200, epoch: 53 | loss: 0.4645273
	speed: 0.0148s/iter; left time: 183.5815s
Epoch: 53 cost time: 4.4493162631988525
Epoch: 53, Steps: 262 | Train Loss: 0.4426465 Vali Loss: 0.9805615 Test Loss: 0.4455784
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.4236468
	speed: 0.0741s/iter; left time: 904.6172s
	iters: 200, epoch: 54 | loss: 0.4023557
	speed: 0.0150s/iter; left time: 182.1605s
Epoch: 54 cost time: 4.530096530914307
Epoch: 54, Steps: 262 | Train Loss: 0.4424271 Vali Loss: 0.9806911 Test Loss: 0.4455811
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.4279885
	speed: 0.0718s/iter; left time: 858.2364s
	iters: 200, epoch: 55 | loss: 0.4653344
	speed: 0.0149s/iter; left time: 176.2429s
Epoch: 55 cost time: 4.398276329040527
Epoch: 55, Steps: 262 | Train Loss: 0.4424953 Vali Loss: 0.9802057 Test Loss: 0.4455683
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.4182304
	speed: 0.0736s/iter; left time: 860.9114s
	iters: 200, epoch: 56 | loss: 0.4318574
	speed: 0.0149s/iter; left time: 172.3730s
Epoch: 56 cost time: 4.519314289093018
Epoch: 56, Steps: 262 | Train Loss: 0.4423908 Vali Loss: 0.9803461 Test Loss: 0.4455641
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.4886379
	speed: 0.0735s/iter; left time: 840.4656s
	iters: 200, epoch: 57 | loss: 0.4376304
	speed: 0.0152s/iter; left time: 172.3912s
Epoch: 57 cost time: 4.517882823944092
Epoch: 57, Steps: 262 | Train Loss: 0.4424737 Vali Loss: 0.9807811 Test Loss: 0.4455634
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.4085052
	speed: 0.0749s/iter; left time: 836.0884s
	iters: 200, epoch: 58 | loss: 0.4478528
	speed: 0.0152s/iter; left time: 168.6863s
Epoch: 58 cost time: 4.529792785644531
Epoch: 58, Steps: 262 | Train Loss: 0.4425092 Vali Loss: 0.9802269 Test Loss: 0.4455622
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.4515409
	speed: 0.0740s/iter; left time: 806.6901s
	iters: 200, epoch: 59 | loss: 0.4610376
	speed: 0.0147s/iter; left time: 158.4199s
Epoch: 59 cost time: 4.517793416976929
Epoch: 59, Steps: 262 | Train Loss: 0.4425223 Vali Loss: 0.9803743 Test Loss: 0.4455629
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.4656234
	speed: 0.0716s/iter; left time: 762.2584s
	iters: 200, epoch: 60 | loss: 0.4578702
	speed: 0.0152s/iter; left time: 160.6277s
Epoch: 60 cost time: 4.508023262023926
Epoch: 60, Steps: 262 | Train Loss: 0.4424720 Vali Loss: 0.9806458 Test Loss: 0.4455636
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.4213759
	speed: 0.0738s/iter; left time: 765.8587s
	iters: 200, epoch: 61 | loss: 0.4101385
	speed: 0.0151s/iter; left time: 155.0439s
Epoch: 61 cost time: 4.4449121952056885
Epoch: 61, Steps: 262 | Train Loss: 0.4425327 Vali Loss: 0.9798106 Test Loss: 0.4455708
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.4404292
	speed: 0.0726s/iter; left time: 734.4450s
	iters: 200, epoch: 62 | loss: 0.4178701
	speed: 0.0151s/iter; left time: 151.7094s
Epoch: 62 cost time: 4.433924674987793
Epoch: 62, Steps: 262 | Train Loss: 0.4424759 Vali Loss: 0.9809850 Test Loss: 0.4455758
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.4014098
	speed: 0.0782s/iter; left time: 770.4911s
	iters: 200, epoch: 63 | loss: 0.4632193
	speed: 0.0150s/iter; left time: 146.2404s
Epoch: 63 cost time: 4.586593866348267
Epoch: 63, Steps: 262 | Train Loss: 0.4424548 Vali Loss: 0.9802092 Test Loss: 0.4455719
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.4178703
	speed: 0.0782s/iter; left time: 750.6523s
	iters: 200, epoch: 64 | loss: 0.4362496
	speed: 0.0164s/iter; left time: 155.9841s
Epoch: 64 cost time: 4.888721466064453
Epoch: 64, Steps: 262 | Train Loss: 0.4425521 Vali Loss: 0.9806068 Test Loss: 0.4455677
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.4315346
	speed: 0.0750s/iter; left time: 700.1290s
	iters: 200, epoch: 65 | loss: 0.4158314
	speed: 0.0149s/iter; left time: 137.3728s
Epoch: 65 cost time: 4.512887954711914
Epoch: 65, Steps: 262 | Train Loss: 0.4423196 Vali Loss: 0.9804410 Test Loss: 0.4455713
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.4364094
	speed: 0.0767s/iter; left time: 695.6784s
	iters: 200, epoch: 66 | loss: 0.4321755
	speed: 0.0167s/iter; left time: 150.1616s
Epoch: 66 cost time: 4.813074827194214
Epoch: 66, Steps: 262 | Train Loss: 0.4424709 Vali Loss: 0.9807042 Test Loss: 0.4455662
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.4567145
	speed: 0.0865s/iter; left time: 761.6772s
	iters: 200, epoch: 67 | loss: 0.4748519
	speed: 0.0155s/iter; left time: 135.2844s
Epoch: 67 cost time: 5.1105873584747314
Epoch: 67, Steps: 262 | Train Loss: 0.4426383 Vali Loss: 0.9811174 Test Loss: 0.4455837
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.4457565
	speed: 0.0717s/iter; left time: 612.8575s
	iters: 200, epoch: 68 | loss: 0.4762677
	speed: 0.0150s/iter; left time: 126.4369s
Epoch: 68 cost time: 4.445861101150513
Epoch: 68, Steps: 262 | Train Loss: 0.4423981 Vali Loss: 0.9810563 Test Loss: 0.4455723
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.4918466
	speed: 0.0796s/iter; left time: 659.0943s
	iters: 200, epoch: 69 | loss: 0.4203587
	speed: 0.0149s/iter; left time: 121.8136s
Epoch: 69 cost time: 4.496908187866211
Epoch: 69, Steps: 262 | Train Loss: 0.4425288 Vali Loss: 0.9805862 Test Loss: 0.4455746
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.4270904
	speed: 0.0726s/iter; left time: 582.4082s
	iters: 200, epoch: 70 | loss: 0.4238943
	speed: 0.0149s/iter; left time: 117.9223s
Epoch: 70 cost time: 4.434183835983276
Epoch: 70, Steps: 262 | Train Loss: 0.4425341 Vali Loss: 0.9806614 Test Loss: 0.4455668
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_180_720_FITS_ETTm1_ftM_sl180_ll48_pl720_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.44370609521865845, mae:0.4249497652053833, rse:0.6337507367134094, corr:[0.5297831  0.533464   0.5316708  0.52875024 0.5272328  0.5272906
 0.5276608  0.5276547  0.52704835 0.5267334  0.5272004  0.52758896
 0.52728707 0.52582175 0.5236822  0.5215093  0.5194767  0.51757604
 0.5157339  0.5138808  0.51196533 0.5099155  0.5077415  0.50553006
 0.50325227 0.50097805 0.4989474  0.4972485  0.49604297 0.4954491
 0.49565703 0.4963408  0.4969397  0.49717283 0.4969626  0.49659237
 0.49621207 0.49590063 0.4957849  0.49566424 0.49553546 0.49528158
 0.494996   0.49487934 0.49494907 0.49516058 0.49543545 0.49564758
 0.4957413  0.4956956  0.4956652  0.4957465  0.49596527 0.4961954
 0.49633965 0.49631613 0.49626085 0.49612445 0.49600226 0.49587607
 0.4958244  0.49581257 0.4957175  0.49552557 0.49529827 0.49527058
 0.495454   0.4957324  0.4960991  0.49643046 0.49668947 0.4968179
 0.4968532  0.49685028 0.49697134 0.4970888  0.49719295 0.4972085
 0.4971209  0.49697033 0.49688756 0.49690127 0.49698406 0.4969287
 0.4967243  0.4964527  0.49620575 0.4959338  0.49562415 0.4954601
 0.4954239  0.49544042 0.495369   0.4951065  0.49461618 0.4938221
 0.49285644 0.49191183 0.49104625 0.4903424  0.4899279  0.4899312
 0.49030703 0.49092367 0.49172246 0.49265796 0.49366885 0.4946656
 0.4955285  0.49612495 0.49640495 0.4965781  0.49659762 0.49649417
 0.496236   0.4959453  0.49557194 0.4951015  0.49464092 0.4942097
 0.4938562  0.49338865 0.4927518  0.49211583 0.49150172 0.49092293
 0.4904757  0.49020648 0.49005958 0.48998043 0.4898972  0.48974147
 0.48950735 0.4893197  0.48910582 0.4887502  0.48842108 0.4881035
 0.4878149  0.48768267 0.487667   0.48772043 0.48779917 0.48791227
 0.48803338 0.48817787 0.48820257 0.4881774  0.48827827 0.48825884
 0.4881592  0.48807952 0.48802173 0.48803568 0.4879807  0.48795223
 0.48794898 0.48801658 0.48804438 0.48809013 0.48814055 0.488231
 0.48838854 0.48861012 0.4888287  0.48914084 0.48947874 0.4897852
 0.490083   0.4902964  0.49036297 0.4904606  0.49052864 0.49051088
 0.49045035 0.49032757 0.49020958 0.49013984 0.49001062 0.4898591
 0.4896873  0.489526   0.489363   0.48923534 0.48915648 0.48911625
 0.4891132  0.48919043 0.48939645 0.48972368 0.49001276 0.49011466
 0.48995808 0.48970127 0.48941183 0.48892084 0.48829496 0.48771018
 0.4871908  0.4866973  0.48624796 0.48615456 0.4861669  0.48611048
 0.48591205 0.48538715 0.48474574 0.4842241  0.48379123 0.4833863
 0.48290038 0.4823289  0.48162904 0.48076618 0.4797934  0.47883886
 0.4779432  0.47704417 0.4761948  0.4755021  0.4749764  0.47465822
 0.4745608  0.47464895 0.47472784 0.47473314 0.4746784  0.4744909
 0.47416958 0.47392607 0.47372836 0.47351074 0.4732863  0.4730905
 0.4729497  0.47291893 0.472847   0.472879   0.473013   0.47314093
 0.473326   0.4733748  0.473377   0.47330984 0.47325507 0.47327465
 0.47338262 0.47345027 0.47348845 0.47349185 0.47344077 0.4733604
 0.47331294 0.47341743 0.47351053 0.4735696  0.47348267 0.47328585
 0.47321105 0.4733414  0.47364813 0.47407246 0.47448677 0.474862
 0.47521427 0.47541147 0.47551826 0.47564444 0.4758393  0.47598943
 0.4761391  0.47623116 0.47639102 0.47659382 0.47685054 0.47707558
 0.47723383 0.47742805 0.47760656 0.47775227 0.4778794  0.4779279
 0.4779392  0.47782612 0.47765902 0.4774544  0.47715807 0.47675714
 0.476137   0.4754373  0.47479692 0.47414955 0.47358975 0.4731679
 0.4730703  0.47315776 0.4734669  0.47392192 0.47437525 0.474798
 0.47509456 0.4751346  0.4750717  0.47501394 0.4749868  0.47492388
 0.47483516 0.4746612  0.47436318 0.47400615 0.47366294 0.47336376
 0.4730695  0.47267985 0.472289   0.47204876 0.47175503 0.47153282
 0.47138903 0.4711914  0.47095266 0.47081107 0.4706427  0.47044432
 0.47017825 0.46986076 0.46947038 0.4690664  0.46865734 0.46831518
 0.46807864 0.4679859  0.46790355 0.4678062  0.4677777  0.4678307
 0.46798557 0.46816486 0.46826228 0.4682444  0.4682419  0.46818414
 0.4681007  0.46805418 0.46812925 0.4682714  0.46835622 0.4684021
 0.4683765  0.46839592 0.46850336 0.4685673  0.46857104 0.4685187
 0.46846452 0.46855    0.46868965 0.46891052 0.46914065 0.46934405
 0.46942425 0.4694826  0.4694852  0.4695004  0.46953997 0.46955767
 0.46951813 0.4695389  0.46967602 0.4698769  0.4701376  0.47034937
 0.47052768 0.47070435 0.4709504  0.47121027 0.47144553 0.4716522
 0.47178355 0.47185427 0.4719893  0.4721549  0.472301   0.47232458
 0.47210807 0.47158182 0.47103354 0.47044414 0.46987507 0.46960413
 0.46967006 0.47003314 0.47047278 0.47111675 0.47181803 0.47248644
 0.47292376 0.4730447  0.47288245 0.4727386  0.47261348 0.47254106
 0.47248363 0.47234434 0.47208408 0.4717339  0.47129375 0.47081852
 0.47035208 0.46985057 0.46938238 0.46902794 0.46880516 0.46866417
 0.46864367 0.46858364 0.46850047 0.4683524  0.4680881  0.46785167
 0.4675318  0.46725318 0.4669826  0.46670875 0.46639714 0.4661149
 0.4658068  0.46561137 0.46551153 0.46556082 0.46568298 0.46592194
 0.46608192 0.46614593 0.46610218 0.4660284  0.4658672  0.46578735
 0.46571255 0.4656716  0.465724   0.46583834 0.46593466 0.46600527
 0.4660512  0.46611938 0.46615383 0.46622717 0.46626037 0.46621582
 0.4662272  0.46635082 0.46653262 0.46675533 0.46690905 0.46714285
 0.46734703 0.4674169  0.46735567 0.4672733  0.46713042 0.46699148
 0.4669317  0.46698305 0.46709067 0.46728352 0.4674947  0.46762118
 0.46768126 0.4677355  0.46785685 0.46794277 0.46802297 0.4680767
 0.46799135 0.46778163 0.46746022 0.46701103 0.46639365 0.4655627
 0.46449405 0.46328452 0.4620821  0.46099234 0.4600492  0.45937
 0.45896807 0.45857492 0.45837992 0.45831177 0.45828846 0.45822665
 0.4581946  0.45801845 0.45766476 0.4572959  0.45701227 0.45676738
 0.45651183 0.4562271  0.45587024 0.45541015 0.45495105 0.4544708
 0.45404026 0.4536342  0.45326412 0.4530268  0.45283595 0.45270497
 0.45258373 0.45247853 0.45238677 0.4524139  0.45248094 0.45248255
 0.45231676 0.4520716  0.4517585  0.45133933 0.4509158  0.45062432
 0.45041963 0.45030543 0.45019734 0.45005855 0.4500012  0.45009074
 0.45022032 0.45031643 0.4502763  0.4501372  0.45004034 0.45003456
 0.4501117  0.4501877  0.45034564 0.45045164 0.45046657 0.4504026
 0.4503557  0.45025355 0.4501994  0.4501422  0.45006317 0.44999763
 0.4499813  0.4500665  0.45026252 0.45050538 0.450741   0.45101717
 0.45123965 0.4513147  0.45129526 0.4513372  0.4514102  0.45149866
 0.45162773 0.45180506 0.45195383 0.4521094  0.45224512 0.45237964
 0.45243415 0.45256245 0.4526705  0.45275486 0.45278734 0.45277366
 0.45267025 0.45241314 0.4520581  0.45157522 0.45087463 0.44989076
 0.4485808  0.44713297 0.4457904  0.4445458  0.44356236 0.44298083
 0.44280276 0.44291264 0.4432205  0.44357002 0.44396868 0.44434196
 0.44464213 0.44472784 0.44461644 0.44444796 0.44425637 0.44403172
 0.44372955 0.44340837 0.44312334 0.4428183  0.44247782 0.44199577
 0.4414809  0.44093078 0.4404244  0.44018254 0.44014108 0.44020265
 0.44027972 0.44034293 0.4403254  0.44026768 0.4402435  0.44029605
 0.44025797 0.44002092 0.43969664 0.43928406 0.4389046  0.43859333
 0.43849033 0.43855494 0.4386694  0.43874484 0.4388033  0.43889496
 0.43898806 0.43908694 0.43915626 0.43914142 0.43910393 0.4390581
 0.43895423 0.4388278  0.4387138  0.43863213 0.43864176 0.43856144
 0.43835178 0.43815804 0.43798694 0.43787852 0.4379568  0.438054
 0.43816864 0.4383135  0.43848422 0.4387157  0.4389978  0.43937498
 0.4397698  0.43999943 0.44009912 0.4401654  0.44019175 0.44023323
 0.4403171  0.44049916 0.44075805 0.4410339  0.44128528 0.44145092
 0.4415051  0.44154516 0.4416471  0.44175503 0.4419123  0.44203508
 0.4420057  0.44178212 0.44136745 0.44086087 0.44031802 0.43968448
 0.43887153 0.43796366 0.4370401  0.43616676 0.43555027 0.43525207
 0.43526396 0.43556893 0.4359846  0.4364001  0.43675497 0.4372336
 0.43774998 0.43795502 0.43790087 0.43768772 0.43738788 0.43701872
 0.43661648 0.4361852  0.43576786 0.4353338  0.43481743 0.434292
 0.43372563 0.43308866 0.43256286 0.4322349  0.43205303 0.4318772
 0.4316285  0.43124595 0.43090737 0.43077517 0.4307508  0.43077135
 0.43062496 0.43012598 0.42950493 0.42906177 0.42904913 0.42941973
 0.42988598 0.4300877  0.4299975  0.4303059  0.43166107 0.43365672]
