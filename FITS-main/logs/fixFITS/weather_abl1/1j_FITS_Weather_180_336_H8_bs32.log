Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=144, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='weather.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=21, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=True, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Weather_180_j336_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=3, pred_len=336, root_path='./dataset/', seed=2021, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Weather_180_j336_H8_FITS_custom_ftM_sl180_ll48_pl336_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36372
val 4935
test 10204
Model(
  (freq_upsampler): ModuleList(
    (0): Linear(in_features=26, out_features=74, bias=True)
    (1): Linear(in_features=26, out_features=74, bias=True)
    (2): Linear(in_features=26, out_features=74, bias=True)
    (3): Linear(in_features=26, out_features=74, bias=True)
    (4): Linear(in_features=26, out_features=74, bias=True)
    (5): Linear(in_features=26, out_features=74, bias=True)
    (6): Linear(in_features=26, out_features=74, bias=True)
    (7): Linear(in_features=26, out_features=74, bias=True)
    (8): Linear(in_features=26, out_features=74, bias=True)
    (9): Linear(in_features=26, out_features=74, bias=True)
    (10): Linear(in_features=26, out_features=74, bias=True)
    (11): Linear(in_features=26, out_features=74, bias=True)
    (12): Linear(in_features=26, out_features=74, bias=True)
    (13): Linear(in_features=26, out_features=74, bias=True)
    (14): Linear(in_features=26, out_features=74, bias=True)
    (15): Linear(in_features=26, out_features=74, bias=True)
    (16): Linear(in_features=26, out_features=74, bias=True)
    (17): Linear(in_features=26, out_features=74, bias=True)
    (18): Linear(in_features=26, out_features=74, bias=True)
    (19): Linear(in_features=26, out_features=74, bias=True)
    (20): Linear(in_features=26, out_features=74, bias=True)
  )
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2585856.0
params:  41958.0
Trainable parameters:  41958
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.9135305
	speed: 0.0308s/iter; left time: 1746.9661s
	iters: 200, epoch: 1 | loss: 0.5512427
	speed: 0.0264s/iter; left time: 1494.8971s
	iters: 300, epoch: 1 | loss: 0.5537506
	speed: 0.0257s/iter; left time: 1453.9800s
	iters: 400, epoch: 1 | loss: 0.4839939
	speed: 0.0306s/iter; left time: 1727.3020s
	iters: 500, epoch: 1 | loss: 0.6153277
	speed: 0.0330s/iter; left time: 1856.2853s
Epoch: 1 cost time: 16.431105136871338
Epoch: 1, Steps: 568 | Train Loss: 0.7036409 Vali Loss: 0.5826959 Test Loss: 0.2722041
Validation loss decreased (inf --> 0.582696).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5425307
	speed: 0.1197s/iter; left time: 6718.2445s
	iters: 200, epoch: 2 | loss: 0.4635211
	speed: 0.0241s/iter; left time: 1348.3014s
	iters: 300, epoch: 2 | loss: 0.4643278
	speed: 0.0292s/iter; left time: 1634.4406s
	iters: 400, epoch: 2 | loss: 0.4674126
	speed: 0.0260s/iter; left time: 1448.9224s
	iters: 500, epoch: 2 | loss: 0.4554194
	speed: 0.0317s/iter; left time: 1766.7663s
Epoch: 2 cost time: 16.28567886352539
Epoch: 2, Steps: 568 | Train Loss: 0.5771291 Vali Loss: 0.5657632 Test Loss: 0.2658160
Validation loss decreased (0.582696 --> 0.565763).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5125340
	speed: 0.1061s/iter; left time: 5896.0757s
	iters: 200, epoch: 3 | loss: 0.7405769
	speed: 0.0256s/iter; left time: 1418.4926s
	iters: 300, epoch: 3 | loss: 0.4639314
	speed: 0.0264s/iter; left time: 1458.9330s
	iters: 400, epoch: 3 | loss: 0.6141985
	speed: 0.0291s/iter; left time: 1610.9102s
	iters: 500, epoch: 3 | loss: 0.5528342
	speed: 0.0291s/iter; left time: 1604.3658s
Epoch: 3 cost time: 15.754979372024536
Epoch: 3, Steps: 568 | Train Loss: 0.5656297 Vali Loss: 0.5607138 Test Loss: 0.2626978
Validation loss decreased (0.565763 --> 0.560714).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4449675
	speed: 0.1306s/iter; left time: 7182.3500s
	iters: 200, epoch: 4 | loss: 0.6347958
	speed: 0.0271s/iter; left time: 1485.2126s
	iters: 300, epoch: 4 | loss: 0.4179896
	speed: 0.0257s/iter; left time: 1410.3933s
	iters: 400, epoch: 4 | loss: 0.6000134
	speed: 0.0299s/iter; left time: 1635.4498s
	iters: 500, epoch: 4 | loss: 0.8546742
	speed: 0.0263s/iter; left time: 1435.1030s
Epoch: 4 cost time: 15.880499839782715
Epoch: 4, Steps: 568 | Train Loss: 0.5614378 Vali Loss: 0.5582259 Test Loss: 0.2607725
Validation loss decreased (0.560714 --> 0.558226).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.6520236
	speed: 0.1139s/iter; left time: 6201.0641s
	iters: 200, epoch: 5 | loss: 0.5085785
	speed: 0.0257s/iter; left time: 1393.5704s
	iters: 300, epoch: 5 | loss: 0.5424896
	speed: 0.0248s/iter; left time: 1347.3243s
	iters: 400, epoch: 5 | loss: 0.4322929
	speed: 0.0296s/iter; left time: 1600.0876s
	iters: 500, epoch: 5 | loss: 0.5107464
	speed: 0.0272s/iter; left time: 1469.4630s
Epoch: 5 cost time: 16.161779642105103
Epoch: 5, Steps: 568 | Train Loss: 0.5589145 Vali Loss: 0.5567009 Test Loss: 0.2593327
Validation loss decreased (0.558226 --> 0.556701).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.5783460
	speed: 0.1265s/iter; left time: 6813.8790s
	iters: 200, epoch: 6 | loss: 0.7592102
	speed: 0.0252s/iter; left time: 1352.1392s
	iters: 300, epoch: 6 | loss: 0.6753230
	speed: 0.0306s/iter; left time: 1641.6759s
	iters: 400, epoch: 6 | loss: 0.4594080
	speed: 0.0300s/iter; left time: 1607.6176s
	iters: 500, epoch: 6 | loss: 0.7979091
	speed: 0.0274s/iter; left time: 1463.1206s
Epoch: 6 cost time: 16.460163116455078
Epoch: 6, Steps: 568 | Train Loss: 0.5575035 Vali Loss: 0.5552061 Test Loss: 0.2581443
Validation loss decreased (0.556701 --> 0.555206).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.5897242
	speed: 0.1162s/iter; left time: 6192.4204s
	iters: 200, epoch: 7 | loss: 0.7865702
	speed: 0.0306s/iter; left time: 1625.5106s
	iters: 300, epoch: 7 | loss: 0.3843389
	speed: 0.0281s/iter; left time: 1491.9093s
	iters: 400, epoch: 7 | loss: 0.4624426
	speed: 0.0289s/iter; left time: 1533.3179s
	iters: 500, epoch: 7 | loss: 0.5665343
	speed: 0.0293s/iter; left time: 1550.4410s
Epoch: 7 cost time: 16.966447591781616
Epoch: 7, Steps: 568 | Train Loss: 0.5562980 Vali Loss: 0.5545832 Test Loss: 0.2573784
Validation loss decreased (0.555206 --> 0.554583).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4734069
	speed: 0.1253s/iter; left time: 6604.2279s
	iters: 200, epoch: 8 | loss: 0.4303743
	speed: 0.0267s/iter; left time: 1405.1308s
	iters: 300, epoch: 8 | loss: 0.5031522
	speed: 0.0275s/iter; left time: 1442.9326s
	iters: 400, epoch: 8 | loss: 0.4563629
	speed: 0.0275s/iter; left time: 1440.0154s
	iters: 500, epoch: 8 | loss: 0.6089236
	speed: 0.0249s/iter; left time: 1304.0029s
Epoch: 8 cost time: 16.11340832710266
Epoch: 8, Steps: 568 | Train Loss: 0.5553807 Vali Loss: 0.5529592 Test Loss: 0.2565216
Validation loss decreased (0.554583 --> 0.552959).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4497679
	speed: 0.1133s/iter; left time: 5908.8142s
	iters: 200, epoch: 9 | loss: 0.6934608
	speed: 0.0267s/iter; left time: 1389.8372s
	iters: 300, epoch: 9 | loss: 0.4199274
	speed: 0.0285s/iter; left time: 1480.5793s
	iters: 400, epoch: 9 | loss: 0.5395929
	speed: 0.0294s/iter; left time: 1522.3314s
	iters: 500, epoch: 9 | loss: 0.4450253
	speed: 0.0281s/iter; left time: 1456.1749s
Epoch: 9 cost time: 16.098953247070312
Epoch: 9, Steps: 568 | Train Loss: 0.5545781 Vali Loss: 0.5526266 Test Loss: 0.2559570
Validation loss decreased (0.552959 --> 0.552627).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.7008252
	speed: 0.1119s/iter; left time: 5770.7287s
	iters: 200, epoch: 10 | loss: 0.5868019
	speed: 0.0249s/iter; left time: 1284.2985s
	iters: 300, epoch: 10 | loss: 0.5935289
	speed: 0.0266s/iter; left time: 1366.4767s
	iters: 400, epoch: 10 | loss: 0.5882279
	speed: 0.0280s/iter; left time: 1433.6807s
	iters: 500, epoch: 10 | loss: 0.4545104
	speed: 0.0306s/iter; left time: 1564.1252s
Epoch: 10 cost time: 16.354656457901
Epoch: 10, Steps: 568 | Train Loss: 0.5538540 Vali Loss: 0.5518992 Test Loss: 0.2553487
Validation loss decreased (0.552627 --> 0.551899).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4448167
	speed: 0.1146s/iter; left time: 5849.0659s
	iters: 200, epoch: 11 | loss: 0.4974289
	speed: 0.0262s/iter; left time: 1332.5702s
	iters: 300, epoch: 11 | loss: 0.4913108
	speed: 0.0268s/iter; left time: 1363.9027s
	iters: 400, epoch: 11 | loss: 0.5774093
	speed: 0.0259s/iter; left time: 1312.3421s
	iters: 500, epoch: 11 | loss: 0.5564764
	speed: 0.0261s/iter; left time: 1322.4641s
Epoch: 11 cost time: 15.034989356994629
Epoch: 11, Steps: 568 | Train Loss: 0.5533953 Vali Loss: 0.5516779 Test Loss: 0.2550199
Validation loss decreased (0.551899 --> 0.551678).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.6441182
	speed: 0.1138s/iter; left time: 5740.8955s
	iters: 200, epoch: 12 | loss: 0.6840795
	speed: 0.0259s/iter; left time: 1302.9148s
	iters: 300, epoch: 12 | loss: 0.6066927
	speed: 0.0268s/iter; left time: 1348.7144s
	iters: 400, epoch: 12 | loss: 0.4767550
	speed: 0.0270s/iter; left time: 1356.6328s
	iters: 500, epoch: 12 | loss: 0.6666858
	speed: 0.0268s/iter; left time: 1342.1660s
Epoch: 12 cost time: 15.627765893936157
Epoch: 12, Steps: 568 | Train Loss: 0.5529347 Vali Loss: 0.5513731 Test Loss: 0.2546834
Validation loss decreased (0.551678 --> 0.551373).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.6652399
	speed: 0.1120s/iter; left time: 5586.3637s
	iters: 200, epoch: 13 | loss: 0.4195710
	speed: 0.0239s/iter; left time: 1191.5161s
	iters: 300, epoch: 13 | loss: 0.4307302
	speed: 0.0267s/iter; left time: 1327.9098s
	iters: 400, epoch: 13 | loss: 0.4499876
	speed: 0.0255s/iter; left time: 1263.2018s
	iters: 500, epoch: 13 | loss: 0.5003945
	speed: 0.0263s/iter; left time: 1302.0543s
Epoch: 13 cost time: 15.158732652664185
Epoch: 13, Steps: 568 | Train Loss: 0.5525157 Vali Loss: 0.5506936 Test Loss: 0.2542354
Validation loss decreased (0.551373 --> 0.550694).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.6564524
	speed: 0.1162s/iter; left time: 5732.6680s
	iters: 200, epoch: 14 | loss: 0.4454537
	speed: 0.0253s/iter; left time: 1244.4297s
	iters: 300, epoch: 14 | loss: 0.6026784
	speed: 0.0264s/iter; left time: 1297.2518s
	iters: 400, epoch: 14 | loss: 0.5357950
	speed: 0.0266s/iter; left time: 1305.3105s
	iters: 500, epoch: 14 | loss: 0.5549983
	speed: 0.0237s/iter; left time: 1159.2451s
Epoch: 14 cost time: 14.57194972038269
Epoch: 14, Steps: 568 | Train Loss: 0.5521884 Vali Loss: 0.5498341 Test Loss: 0.2539415
Validation loss decreased (0.550694 --> 0.549834).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4859962
	speed: 0.1140s/iter; left time: 5558.2701s
	iters: 200, epoch: 15 | loss: 0.7099583
	speed: 0.0262s/iter; left time: 1276.9374s
	iters: 300, epoch: 15 | loss: 0.4607726
	speed: 0.0276s/iter; left time: 1339.9562s
	iters: 400, epoch: 15 | loss: 0.5696310
	speed: 0.0256s/iter; left time: 1239.0581s
	iters: 500, epoch: 15 | loss: 0.6855583
	speed: 0.0253s/iter; left time: 1223.5601s
Epoch: 15 cost time: 15.284481763839722
Epoch: 15, Steps: 568 | Train Loss: 0.5516449 Vali Loss: 0.5485085 Test Loss: 0.2537637
Validation loss decreased (0.549834 --> 0.548508).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.5151182
	speed: 0.1063s/iter; left time: 5119.3543s
	iters: 200, epoch: 16 | loss: 0.8877438
	speed: 0.0260s/iter; left time: 1251.5553s
	iters: 300, epoch: 16 | loss: 0.5020171
	speed: 0.0267s/iter; left time: 1283.4041s
	iters: 400, epoch: 16 | loss: 0.4643318
	speed: 0.0287s/iter; left time: 1373.2617s
	iters: 500, epoch: 16 | loss: 0.6235307
	speed: 0.0348s/iter; left time: 1663.3289s
Epoch: 16 cost time: 16.465775728225708
Epoch: 16, Steps: 568 | Train Loss: 0.5515634 Vali Loss: 0.5492871 Test Loss: 0.2536011
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.6163586
	speed: 0.1098s/iter; left time: 5228.0575s
	iters: 200, epoch: 17 | loss: 0.4285764
	speed: 0.0289s/iter; left time: 1373.7512s
	iters: 300, epoch: 17 | loss: 0.4325365
	speed: 0.0269s/iter; left time: 1275.5236s
	iters: 400, epoch: 17 | loss: 0.4668815
	speed: 0.0287s/iter; left time: 1356.1911s
	iters: 500, epoch: 17 | loss: 0.4824388
	speed: 0.0272s/iter; left time: 1282.3909s
Epoch: 17 cost time: 16.080814838409424
Epoch: 17, Steps: 568 | Train Loss: 0.5512993 Vali Loss: 0.5496812 Test Loss: 0.2533924
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4785683
	speed: 0.1102s/iter; left time: 5184.3977s
	iters: 200, epoch: 18 | loss: 0.6797647
	speed: 0.0228s/iter; left time: 1072.6808s
	iters: 300, epoch: 18 | loss: 0.6647401
	speed: 0.0262s/iter; left time: 1229.6114s
	iters: 400, epoch: 18 | loss: 0.5842177
	speed: 0.0257s/iter; left time: 1202.4953s
	iters: 500, epoch: 18 | loss: 0.4928947
	speed: 0.0265s/iter; left time: 1235.1827s
Epoch: 18 cost time: 14.981849908828735
Epoch: 18, Steps: 568 | Train Loss: 0.5510040 Vali Loss: 0.5493566 Test Loss: 0.2531696
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Weather_180_j336_H8_FITS_custom_ftM_sl180_ll48_pl336_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10204
mse:0.2540653645992279, mae:0.28382694721221924, rse:0.6620004177093506, corr:[0.47824985 0.4784143  0.47692797 0.47593242 0.47554705 0.47501191
 0.47379062 0.47221145 0.4708039  0.46984416 0.4692894  0.46873796
 0.4678494  0.4666688  0.46546832 0.46448225 0.4636781  0.46273413
 0.46159416 0.46025568 0.45898178 0.45793575 0.4571675  0.45635688
 0.4551961  0.4536723  0.45200437 0.450477   0.449334   0.4484938
 0.44778785 0.44685304 0.4456763  0.44432366 0.44318804 0.44234774
 0.44175452 0.4410838  0.4401974  0.43907732 0.43790928 0.43692344
 0.4361968  0.43562835 0.43500632 0.43426138 0.43340117 0.43255252
 0.43177253 0.4311828  0.43072256 0.43015045 0.42948508 0.42866218
 0.4278548  0.4271896  0.42665952 0.42621648 0.42580634 0.42529204
 0.4246689  0.4240053  0.42353263 0.42318213 0.42291412 0.42260137
 0.4221809  0.42170927 0.4213021  0.42091945 0.4206821  0.42041698
 0.42013204 0.41982841 0.41945443 0.41908848 0.41880202 0.41863555
 0.41845897 0.41823906 0.4180535  0.4179251  0.4177652  0.41761822
 0.41752544 0.41754958 0.4176274  0.4176169  0.41758278 0.4175105
 0.41742072 0.4173956  0.41736686 0.41734117 0.41735786 0.41742793
 0.4174522  0.41745865 0.4174531  0.417399   0.4173566  0.41731957
 0.41735232 0.41748074 0.41765827 0.41776156 0.41773954 0.4176818
 0.41758913 0.417465   0.41731486 0.41717848 0.4170347  0.41694963
 0.41689292 0.41682878 0.41676602 0.41672668 0.4166767  0.41656756
 0.41648734 0.41644567 0.41638702 0.4163288  0.41624087 0.41616836
 0.41611257 0.41597176 0.41575602 0.41547683 0.4151432  0.4148153
 0.414524   0.41424346 0.41402292 0.41379458 0.41352767 0.41325107
 0.41297    0.4126595  0.41238874 0.41212517 0.4118426  0.41148552
 0.41102192 0.41048956 0.40998432 0.40944016 0.40890205 0.40834525
 0.4077885  0.40717533 0.4065108  0.4058083  0.40504187 0.40432867
 0.40375763 0.40322134 0.40265167 0.40200827 0.40131316 0.40054858
 0.39976615 0.3990778  0.39846224 0.39790702 0.39730102 0.39659798
 0.39582133 0.39501682 0.394273   0.39362302 0.39290473 0.3922009
 0.39144573 0.39068875 0.38999787 0.38947162 0.38911304 0.38877288
 0.38839737 0.3878045  0.38705206 0.38631386 0.38578117 0.38544592
 0.38522604 0.38498148 0.38464686 0.38429534 0.38390476 0.3835447
 0.38327566 0.38302374 0.38273627 0.38236374 0.3819119  0.38155964
 0.38137695 0.38131347 0.3812733  0.38115057 0.38082394 0.3803527
 0.37986115 0.37946987 0.37920615 0.37905714 0.37892085 0.3787492
 0.37853163 0.37825412 0.3779818  0.3777143  0.3774455  0.3771464
 0.3769001  0.37674353 0.37664688 0.37664372 0.37667918 0.37675345
 0.3767295  0.3766632  0.376575   0.37654632 0.3766251  0.3768532
 0.37703845 0.37712386 0.37706855 0.37702495 0.37697074 0.3769873
 0.37710705 0.37727237 0.3773843  0.37746388 0.37753862 0.37768635
 0.37799567 0.37840456 0.3788868  0.37927234 0.37960356 0.37984443
 0.38002494 0.38013116 0.3802305  0.38039532 0.38049537 0.38045204
 0.38028616 0.38007292 0.37986895 0.37966284 0.37947363 0.3793233
 0.37921518 0.37917176 0.37912142 0.37903526 0.37897122 0.37895155
 0.37893185 0.37889025 0.37885872 0.37875384 0.37861553 0.37837347
 0.37809703 0.3777982  0.3775532  0.3773894  0.3772656  0.3771597
 0.37698615 0.3766436  0.37619558 0.37568417 0.37527812 0.3749544
 0.37472185 0.37442705 0.37396574 0.37343025 0.3728518  0.372316
 0.37183306 0.3713757  0.37083018 0.37009773 0.36925268 0.36844465
 0.36772627 0.3671518  0.36665198 0.36603835 0.36518165 0.3642008
 0.36310786 0.3621148  0.3613481  0.36072907 0.36015314 0.35939005
 0.35857195 0.35772473 0.3570855  0.35664108 0.3562798  0.3557775
 0.35502005 0.35406378 0.35307372 0.35225683 0.3517969  0.3515275
 0.35120717 0.3506125  0.3497347  0.3488157  0.34813637 0.34769416
 0.3473367  0.3468333  0.34608787 0.34539557 0.34498176 0.34505442
 0.3453266  0.34536237 0.3447795  0.34399688 0.34375083 0.34468195]
