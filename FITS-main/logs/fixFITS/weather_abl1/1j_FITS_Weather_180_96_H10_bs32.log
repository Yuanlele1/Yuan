Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=144, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=30, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='weather.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=21, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=True, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Weather_180_j96_H10', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=2021, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Weather_180_j96_H10_FITS_custom_ftM_sl180_ll48_pl96_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36612
val 5175
test 10444
Model(
  (freq_upsampler): ModuleList(
    (0): Linear(in_features=30, out_features=46, bias=True)
    (1): Linear(in_features=30, out_features=46, bias=True)
    (2): Linear(in_features=30, out_features=46, bias=True)
    (3): Linear(in_features=30, out_features=46, bias=True)
    (4): Linear(in_features=30, out_features=46, bias=True)
    (5): Linear(in_features=30, out_features=46, bias=True)
    (6): Linear(in_features=30, out_features=46, bias=True)
    (7): Linear(in_features=30, out_features=46, bias=True)
    (8): Linear(in_features=30, out_features=46, bias=True)
    (9): Linear(in_features=30, out_features=46, bias=True)
    (10): Linear(in_features=30, out_features=46, bias=True)
    (11): Linear(in_features=30, out_features=46, bias=True)
    (12): Linear(in_features=30, out_features=46, bias=True)
    (13): Linear(in_features=30, out_features=46, bias=True)
    (14): Linear(in_features=30, out_features=46, bias=True)
    (15): Linear(in_features=30, out_features=46, bias=True)
    (16): Linear(in_features=30, out_features=46, bias=True)
    (17): Linear(in_features=30, out_features=46, bias=True)
    (18): Linear(in_features=30, out_features=46, bias=True)
    (19): Linear(in_features=30, out_features=46, bias=True)
    (20): Linear(in_features=30, out_features=46, bias=True)
  )
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1854720.0
params:  29946.0
Trainable parameters:  29946
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4853378
	speed: 0.0270s/iter; left time: 1541.6309s
	iters: 200, epoch: 1 | loss: 0.4819802
	speed: 0.0246s/iter; left time: 1400.6016s
	iters: 300, epoch: 1 | loss: 0.3805628
	speed: 0.0235s/iter; left time: 1339.9697s
	iters: 400, epoch: 1 | loss: 0.4770105
	speed: 0.0357s/iter; left time: 2026.9300s
	iters: 500, epoch: 1 | loss: 0.9213667
	speed: 0.0254s/iter; left time: 1440.1170s
Epoch: 1 cost time: 15.43789529800415
Epoch: 1, Steps: 572 | Train Loss: 0.5337021 Vali Loss: 0.4155744 Test Loss: 0.1697892
Validation loss decreased (inf --> 0.415574).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4154169
	speed: 0.1128s/iter; left time: 6375.7462s
	iters: 200, epoch: 2 | loss: 0.3559425
	speed: 0.0241s/iter; left time: 1357.8707s
	iters: 300, epoch: 2 | loss: 0.3689346
	speed: 0.0265s/iter; left time: 1491.3537s
	iters: 400, epoch: 2 | loss: 0.2927845
	speed: 0.0238s/iter; left time: 1335.4900s
	iters: 500, epoch: 2 | loss: 0.7442082
	speed: 0.0216s/iter; left time: 1211.2003s
Epoch: 2 cost time: 13.987144231796265
Epoch: 2, Steps: 572 | Train Loss: 0.4416842 Vali Loss: 0.4025024 Test Loss: 0.1630278
Validation loss decreased (0.415574 --> 0.402502).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4527657
	speed: 0.1051s/iter; left time: 5880.3704s
	iters: 200, epoch: 3 | loss: 0.3095290
	speed: 0.0264s/iter; left time: 1475.8172s
	iters: 300, epoch: 3 | loss: 0.3680945
	speed: 0.0267s/iter; left time: 1489.0251s
	iters: 400, epoch: 3 | loss: 0.8259100
	speed: 0.0237s/iter; left time: 1317.0768s
	iters: 500, epoch: 3 | loss: 0.7890439
	speed: 0.0242s/iter; left time: 1344.0552s
Epoch: 3 cost time: 14.948783159255981
Epoch: 3, Steps: 572 | Train Loss: 0.4329866 Vali Loss: 0.3975974 Test Loss: 0.1596467
Validation loss decreased (0.402502 --> 0.397597).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2912141
	speed: 0.1024s/iter; left time: 5671.5660s
	iters: 200, epoch: 4 | loss: 0.3154810
	speed: 0.0238s/iter; left time: 1317.1457s
	iters: 300, epoch: 4 | loss: 0.3552728
	speed: 0.0229s/iter; left time: 1262.7456s
	iters: 400, epoch: 4 | loss: 0.3050542
	speed: 0.0301s/iter; left time: 1660.1058s
	iters: 500, epoch: 4 | loss: 0.2028380
	speed: 0.0259s/iter; left time: 1426.3842s
Epoch: 4 cost time: 15.445446252822876
Epoch: 4, Steps: 572 | Train Loss: 0.4289581 Vali Loss: 0.3966186 Test Loss: 0.1580452
Validation loss decreased (0.397597 --> 0.396619).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4140904
	speed: 0.1084s/iter; left time: 5941.9755s
	iters: 200, epoch: 5 | loss: 0.3968297
	speed: 0.0230s/iter; left time: 1260.2330s
	iters: 300, epoch: 5 | loss: 0.8528615
	speed: 0.0259s/iter; left time: 1415.1687s
	iters: 400, epoch: 5 | loss: 0.3650085
	speed: 0.0234s/iter; left time: 1276.1706s
	iters: 500, epoch: 5 | loss: 0.2592345
	speed: 0.0232s/iter; left time: 1262.1984s
Epoch: 5 cost time: 13.828438997268677
Epoch: 5, Steps: 572 | Train Loss: 0.4265120 Vali Loss: 0.3921174 Test Loss: 0.1567296
Validation loss decreased (0.396619 --> 0.392117).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4130599
	speed: 0.1018s/iter; left time: 5521.7540s
	iters: 200, epoch: 6 | loss: 0.4239705
	speed: 0.0224s/iter; left time: 1215.3327s
	iters: 300, epoch: 6 | loss: 0.3379898
	speed: 0.0227s/iter; left time: 1224.8511s
	iters: 400, epoch: 6 | loss: 0.3785559
	speed: 0.0237s/iter; left time: 1279.8352s
	iters: 500, epoch: 6 | loss: 0.8446258
	speed: 0.0244s/iter; left time: 1314.9638s
Epoch: 6 cost time: 13.73444414138794
Epoch: 6, Steps: 572 | Train Loss: 0.4248013 Vali Loss: 0.3948351 Test Loss: 0.1558780
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4232295
	speed: 0.1029s/iter; left time: 5524.6410s
	iters: 200, epoch: 7 | loss: 0.3773133
	speed: 0.0241s/iter; left time: 1293.3459s
	iters: 300, epoch: 7 | loss: 0.2826768
	speed: 0.0335s/iter; left time: 1793.5236s
	iters: 400, epoch: 7 | loss: 0.3385316
	speed: 0.0220s/iter; left time: 1176.5431s
	iters: 500, epoch: 7 | loss: 0.2509481
	speed: 0.0219s/iter; left time: 1165.7156s
Epoch: 7 cost time: 14.459648847579956
Epoch: 7, Steps: 572 | Train Loss: 0.4234640 Vali Loss: 0.3949113 Test Loss: 0.1551043
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4199619
	speed: 0.1010s/iter; left time: 5364.6296s
	iters: 200, epoch: 8 | loss: 0.7396135
	speed: 0.0224s/iter; left time: 1188.9037s
	iters: 300, epoch: 8 | loss: 0.4033441
	speed: 0.0254s/iter; left time: 1341.5814s
	iters: 400, epoch: 8 | loss: 0.3537515
	speed: 0.0236s/iter; left time: 1246.5266s
	iters: 500, epoch: 8 | loss: 0.2772680
	speed: 0.0221s/iter; left time: 1163.6544s
Epoch: 8 cost time: 13.881150484085083
Epoch: 8, Steps: 572 | Train Loss: 0.4224839 Vali Loss: 0.3934652 Test Loss: 0.1546184
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Weather_180_j96_H10_FITS_custom_ftM_sl180_ll48_pl96_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
mse:0.15737152099609375, mae:0.20642277598381042, rse:0.5227755308151245, corr:[0.47701472 0.4802471  0.47852874 0.4765717  0.47614795 0.4763576
 0.47573736 0.47417971 0.47249398 0.47141936 0.47097388 0.4704316
 0.4693164  0.46790716 0.46675047 0.4660214  0.4653383  0.46415922
 0.4626646  0.46122104 0.46017492 0.45941532 0.45861423 0.45745978
 0.45607325 0.45482036 0.45382914 0.4528859  0.45169997 0.45021048
 0.44890344 0.44804007 0.44757944 0.44697875 0.44602835 0.444711
 0.44345754 0.44254074 0.44199577 0.44145665 0.4405948  0.43944904
 0.4383635  0.43765053 0.43725777 0.4369033  0.4362331  0.43523479
 0.43415877 0.43339851 0.43299457 0.43253702 0.43185413 0.43084943
 0.42991433 0.42932495 0.4289943  0.4286881  0.42823637 0.42764604
 0.42712447 0.42675862 0.42657655 0.42623377 0.42562702 0.4248856
 0.42431834 0.42412126 0.4242055  0.42410895 0.42370066 0.42299384
 0.42237556 0.42211753 0.42208058 0.42196956 0.4216343  0.42119953
 0.42079738 0.42062297 0.42065215 0.42062613 0.42035225 0.41994658
 0.41968167 0.41981712 0.4201967  0.42040068 0.4203339  0.42001197
 0.4198049  0.41995463 0.42002884 0.41966754 0.41888797 0.4191429 ]
