Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=144, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=40, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='weather.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=21, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=True, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Weather_360_j720_H10', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=3, pred_len=720, root_path='./dataset/', seed=2021, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Weather_360_j720_H10_FITS_custom_ftM_sl360_ll48_pl720_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 35808
val 4551
test 9820
Model(
  (freq_upsampler): ModuleList(
    (0): Linear(in_features=40, out_features=120, bias=True)
    (1): Linear(in_features=40, out_features=120, bias=True)
    (2): Linear(in_features=40, out_features=120, bias=True)
    (3): Linear(in_features=40, out_features=120, bias=True)
    (4): Linear(in_features=40, out_features=120, bias=True)
    (5): Linear(in_features=40, out_features=120, bias=True)
    (6): Linear(in_features=40, out_features=120, bias=True)
    (7): Linear(in_features=40, out_features=120, bias=True)
    (8): Linear(in_features=40, out_features=120, bias=True)
    (9): Linear(in_features=40, out_features=120, bias=True)
    (10): Linear(in_features=40, out_features=120, bias=True)
    (11): Linear(in_features=40, out_features=120, bias=True)
    (12): Linear(in_features=40, out_features=120, bias=True)
    (13): Linear(in_features=40, out_features=120, bias=True)
    (14): Linear(in_features=40, out_features=120, bias=True)
    (15): Linear(in_features=40, out_features=120, bias=True)
    (16): Linear(in_features=40, out_features=120, bias=True)
    (17): Linear(in_features=40, out_features=120, bias=True)
    (18): Linear(in_features=40, out_features=120, bias=True)
    (19): Linear(in_features=40, out_features=120, bias=True)
    (20): Linear(in_features=40, out_features=120, bias=True)
  )
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6451200.0
params:  103320.0
Trainable parameters:  103320
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.8830966
	speed: 0.0421s/iter; left time: 2350.9873s
	iters: 200, epoch: 1 | loss: 0.8091922
	speed: 0.0399s/iter; left time: 2220.4444s
	iters: 300, epoch: 1 | loss: 0.7847300
	speed: 0.0451s/iter; left time: 2506.4274s
	iters: 400, epoch: 1 | loss: 0.6833286
	speed: 0.0334s/iter; left time: 1852.2114s
	iters: 500, epoch: 1 | loss: 0.6309395
	speed: 0.0597s/iter; left time: 3306.6173s
Epoch: 1 cost time: 26.080917358398438
Epoch: 1, Steps: 559 | Train Loss: 0.7163102 Vali Loss: 0.6661459 Test Loss: 0.3330393
Validation loss decreased (inf --> 0.666146).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4556860
	speed: 0.2049s/iter; left time: 11317.7353s
	iters: 200, epoch: 2 | loss: 0.5770733
	speed: 0.0322s/iter; left time: 1773.0637s
	iters: 300, epoch: 2 | loss: 0.6644664
	speed: 0.0358s/iter; left time: 1968.8819s
	iters: 400, epoch: 2 | loss: 0.5393006
	speed: 0.0425s/iter; left time: 2332.3032s
	iters: 500, epoch: 2 | loss: 0.6224908
	speed: 0.0418s/iter; left time: 2292.1361s
Epoch: 2 cost time: 22.52197813987732
Epoch: 2, Steps: 559 | Train Loss: 0.6096512 Vali Loss: 0.6548133 Test Loss: 0.3269819
Validation loss decreased (0.666146 --> 0.654813).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5317697
	speed: 0.1502s/iter; left time: 8213.5818s
	iters: 200, epoch: 3 | loss: 0.5373986
	speed: 0.0302s/iter; left time: 1648.7366s
	iters: 300, epoch: 3 | loss: 0.5670685
	speed: 0.0318s/iter; left time: 1734.3397s
	iters: 400, epoch: 3 | loss: 0.5488141
	speed: 0.0305s/iter; left time: 1659.1165s
	iters: 500, epoch: 3 | loss: 0.5662322
	speed: 0.0305s/iter; left time: 1656.2492s
Epoch: 3 cost time: 17.578810930252075
Epoch: 3, Steps: 559 | Train Loss: 0.6014467 Vali Loss: 0.6510458 Test Loss: 0.3243975
Validation loss decreased (0.654813 --> 0.651046).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.6666752
	speed: 0.1463s/iter; left time: 7918.2331s
	iters: 200, epoch: 4 | loss: 0.5703626
	speed: 0.0465s/iter; left time: 2514.4485s
	iters: 300, epoch: 4 | loss: 0.5755745
	speed: 0.0430s/iter; left time: 2316.9310s
	iters: 400, epoch: 4 | loss: 0.5959628
	speed: 0.0299s/iter; left time: 1608.1141s
	iters: 500, epoch: 4 | loss: 0.8057847
	speed: 0.0547s/iter; left time: 2936.6157s
Epoch: 4 cost time: 24.60513687133789
Epoch: 4, Steps: 559 | Train Loss: 0.5984146 Vali Loss: 0.6479182 Test Loss: 0.3228265
Validation loss decreased (0.651046 --> 0.647918).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.5067623
	speed: 0.1533s/iter; left time: 8210.9810s
	iters: 200, epoch: 5 | loss: 0.5804208
	speed: 0.0329s/iter; left time: 1760.2304s
	iters: 300, epoch: 5 | loss: 0.5978677
	speed: 0.0312s/iter; left time: 1666.6458s
	iters: 400, epoch: 5 | loss: 0.5224499
	speed: 0.0337s/iter; left time: 1796.9980s
	iters: 500, epoch: 5 | loss: 0.5416637
	speed: 0.0614s/iter; left time: 3264.0295s
Epoch: 5 cost time: 23.603695154190063
Epoch: 5, Steps: 559 | Train Loss: 0.5967412 Vali Loss: 0.6469205 Test Loss: 0.3217182
Validation loss decreased (0.647918 --> 0.646921).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.6378091
	speed: 0.1456s/iter; left time: 7719.6084s
	iters: 200, epoch: 6 | loss: 0.6063759
	speed: 0.0390s/iter; left time: 2065.4014s
	iters: 300, epoch: 6 | loss: 0.6566355
	speed: 0.0312s/iter; left time: 1648.0864s
	iters: 400, epoch: 6 | loss: 0.6029607
	speed: 0.0341s/iter; left time: 1796.6824s
	iters: 500, epoch: 6 | loss: 0.6538891
	speed: 0.0465s/iter; left time: 2448.5593s
Epoch: 6 cost time: 21.181421518325806
Epoch: 6, Steps: 559 | Train Loss: 0.5957502 Vali Loss: 0.6447710 Test Loss: 0.3210784
Validation loss decreased (0.646921 --> 0.644771).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.5213408
	speed: 0.1349s/iter; left time: 7077.0877s
	iters: 200, epoch: 7 | loss: 0.5709700
	speed: 0.0350s/iter; left time: 1833.7861s
	iters: 300, epoch: 7 | loss: 0.5499173
	speed: 0.0300s/iter; left time: 1567.3795s
	iters: 400, epoch: 7 | loss: 0.5951563
	speed: 0.0339s/iter; left time: 1765.4717s
	iters: 500, epoch: 7 | loss: 0.6621954
	speed: 0.0347s/iter; left time: 1803.4353s
Epoch: 7 cost time: 18.55031967163086
Epoch: 7, Steps: 559 | Train Loss: 0.5949078 Vali Loss: 0.6437954 Test Loss: 0.3205396
Validation loss decreased (0.644771 --> 0.643795).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.5129592
	speed: 0.1297s/iter; left time: 6727.7058s
	iters: 200, epoch: 8 | loss: 0.5727342
	speed: 0.0296s/iter; left time: 1535.2086s
	iters: 300, epoch: 8 | loss: 0.5927829
	speed: 0.0305s/iter; left time: 1577.0692s
	iters: 400, epoch: 8 | loss: 0.6092683
	speed: 0.0311s/iter; left time: 1602.0108s
	iters: 500, epoch: 8 | loss: 0.6975182
	speed: 0.0352s/iter; left time: 1810.2983s
Epoch: 8 cost time: 17.82559609413147
Epoch: 8, Steps: 559 | Train Loss: 0.5943017 Vali Loss: 0.6428560 Test Loss: 0.3201597
Validation loss decreased (0.643795 --> 0.642856).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.6003944
	speed: 0.1430s/iter; left time: 7341.9719s
	iters: 200, epoch: 9 | loss: 0.5336397
	speed: 0.0289s/iter; left time: 1478.0265s
	iters: 300, epoch: 9 | loss: 0.6054116
	speed: 0.0300s/iter; left time: 1536.2479s
	iters: 400, epoch: 9 | loss: 0.4990773
	speed: 0.0310s/iter; left time: 1581.7002s
	iters: 500, epoch: 9 | loss: 0.4533708
	speed: 0.0468s/iter; left time: 2385.4794s
Epoch: 9 cost time: 20.532773971557617
Epoch: 9, Steps: 559 | Train Loss: 0.5938146 Vali Loss: 0.6423816 Test Loss: 0.3195919
Validation loss decreased (0.642856 --> 0.642382).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.6042448
	speed: 0.1624s/iter; left time: 8245.6770s
	iters: 200, epoch: 10 | loss: 0.6173134
	speed: 0.0418s/iter; left time: 2117.7081s
	iters: 300, epoch: 10 | loss: 0.5496900
	speed: 0.0306s/iter; left time: 1549.3597s
	iters: 400, epoch: 10 | loss: 0.4562837
	speed: 0.0306s/iter; left time: 1545.3668s
	iters: 500, epoch: 10 | loss: 0.6744426
	speed: 0.0326s/iter; left time: 1644.5307s
Epoch: 10 cost time: 18.789576530456543
Epoch: 10, Steps: 559 | Train Loss: 0.5932550 Vali Loss: 0.6427701 Test Loss: 0.3195599
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4487405
	speed: 0.1236s/iter; left time: 6207.8051s
	iters: 200, epoch: 11 | loss: 0.5511633
	speed: 0.0295s/iter; left time: 1478.3793s
	iters: 300, epoch: 11 | loss: 0.6537800
	speed: 0.0273s/iter; left time: 1367.0447s
	iters: 400, epoch: 11 | loss: 0.5353714
	speed: 0.0273s/iter; left time: 1364.0208s
	iters: 500, epoch: 11 | loss: 0.6904572
	speed: 0.0296s/iter; left time: 1475.7034s
Epoch: 11 cost time: 16.339207649230957
Epoch: 11, Steps: 559 | Train Loss: 0.5931133 Vali Loss: 0.6415262 Test Loss: 0.3192534
Validation loss decreased (0.642382 --> 0.641526).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.5506815
	speed: 0.1401s/iter; left time: 6957.5386s
	iters: 200, epoch: 12 | loss: 0.5709980
	speed: 0.0286s/iter; left time: 1418.1475s
	iters: 300, epoch: 12 | loss: 0.7960825
	speed: 0.0307s/iter; left time: 1519.2901s
	iters: 400, epoch: 12 | loss: 0.4961250
	speed: 0.0321s/iter; left time: 1584.7355s
	iters: 500, epoch: 12 | loss: 0.4795207
	speed: 0.0320s/iter; left time: 1577.8071s
Epoch: 12 cost time: 19.468390226364136
Epoch: 12, Steps: 559 | Train Loss: 0.5927815 Vali Loss: 0.6415244 Test Loss: 0.3190462
Validation loss decreased (0.641526 --> 0.641524).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.6698909
	speed: 0.1493s/iter; left time: 7331.5146s
	iters: 200, epoch: 13 | loss: 0.5914497
	speed: 0.0335s/iter; left time: 1640.2403s
	iters: 300, epoch: 13 | loss: 0.6303253
	speed: 0.0457s/iter; left time: 2231.9902s
	iters: 400, epoch: 13 | loss: 0.5758984
	speed: 0.0361s/iter; left time: 1761.7470s
	iters: 500, epoch: 13 | loss: 0.6629493
	speed: 0.0367s/iter; left time: 1788.2786s
Epoch: 13 cost time: 20.80596685409546
Epoch: 13, Steps: 559 | Train Loss: 0.5923466 Vali Loss: 0.6413053 Test Loss: 0.3188601
Validation loss decreased (0.641524 --> 0.641305).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.5456992
	speed: 0.1574s/iter; left time: 7636.9455s
	iters: 200, epoch: 14 | loss: 0.6447361
	speed: 0.0309s/iter; left time: 1496.9490s
	iters: 300, epoch: 14 | loss: 0.4817141
	speed: 0.0330s/iter; left time: 1596.4476s
	iters: 400, epoch: 14 | loss: 0.5366367
	speed: 0.0380s/iter; left time: 1830.9107s
	iters: 500, epoch: 14 | loss: 0.6185068
	speed: 0.0330s/iter; left time: 1590.4621s
Epoch: 14 cost time: 19.195481300354004
Epoch: 14, Steps: 559 | Train Loss: 0.5923353 Vali Loss: 0.6407327 Test Loss: 0.3187281
Validation loss decreased (0.641305 --> 0.640733).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.5374742
	speed: 0.1409s/iter; left time: 6760.9863s
	iters: 200, epoch: 15 | loss: 0.5325534
	speed: 0.0353s/iter; left time: 1688.7689s
	iters: 300, epoch: 15 | loss: 0.5322006
	speed: 0.0327s/iter; left time: 1562.6352s
	iters: 400, epoch: 15 | loss: 0.5848743
	speed: 0.0392s/iter; left time: 1870.3040s
	iters: 500, epoch: 15 | loss: 0.6401233
	speed: 0.0313s/iter; left time: 1486.7628s
Epoch: 15 cost time: 19.290043592453003
Epoch: 15, Steps: 559 | Train Loss: 0.5918907 Vali Loss: 0.6406450 Test Loss: 0.3185301
Validation loss decreased (0.640733 --> 0.640645).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4678996
	speed: 0.1331s/iter; left time: 6310.3400s
	iters: 200, epoch: 16 | loss: 0.5569337
	speed: 0.0409s/iter; left time: 1935.4440s
	iters: 300, epoch: 16 | loss: 0.5562930
	speed: 0.0330s/iter; left time: 1559.3977s
	iters: 400, epoch: 16 | loss: 0.5033980
	speed: 0.0298s/iter; left time: 1405.1173s
	iters: 500, epoch: 16 | loss: 0.6083860
	speed: 0.0324s/iter; left time: 1521.8626s
Epoch: 16 cost time: 18.745208740234375
Epoch: 16, Steps: 559 | Train Loss: 0.5920232 Vali Loss: 0.6407494 Test Loss: 0.3184824
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.6747114
	speed: 0.1287s/iter; left time: 6032.4801s
	iters: 200, epoch: 17 | loss: 0.5732895
	speed: 0.0304s/iter; left time: 1420.2294s
	iters: 300, epoch: 17 | loss: 0.5002753
	speed: 0.0420s/iter; left time: 1961.0777s
	iters: 400, epoch: 17 | loss: 0.7852460
	speed: 0.0367s/iter; left time: 1710.5463s
	iters: 500, epoch: 17 | loss: 0.6142278
	speed: 0.0377s/iter; left time: 1750.6171s
Epoch: 17 cost time: 20.726919412612915
Epoch: 17, Steps: 559 | Train Loss: 0.5918841 Vali Loss: 0.6400472 Test Loss: 0.3183355
Validation loss decreased (0.640645 --> 0.640047).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.5793372
	speed: 0.1896s/iter; left time: 8777.8026s
	iters: 200, epoch: 18 | loss: 0.5335951
	speed: 0.0330s/iter; left time: 1524.2953s
	iters: 300, epoch: 18 | loss: 0.4517948
	speed: 0.0390s/iter; left time: 1796.9252s
	iters: 400, epoch: 18 | loss: 0.6623277
	speed: 0.0313s/iter; left time: 1441.4716s
	iters: 500, epoch: 18 | loss: 0.5787392
	speed: 0.0374s/iter; left time: 1718.5268s
Epoch: 18 cost time: 21.106733322143555
Epoch: 18, Steps: 559 | Train Loss: 0.5914826 Vali Loss: 0.6401894 Test Loss: 0.3182733
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.6545323
	speed: 0.1440s/iter; left time: 6587.9009s
	iters: 200, epoch: 19 | loss: 0.7145253
	speed: 0.0298s/iter; left time: 1358.8442s
	iters: 300, epoch: 19 | loss: 0.7829359
	speed: 0.0294s/iter; left time: 1337.6595s
	iters: 400, epoch: 19 | loss: 0.7366415
	speed: 0.0397s/iter; left time: 1804.5801s
	iters: 500, epoch: 19 | loss: 0.5202297
	speed: 0.0295s/iter; left time: 1337.0199s
Epoch: 19 cost time: 18.082956790924072
Epoch: 19, Steps: 559 | Train Loss: 0.5914295 Vali Loss: 0.6397510 Test Loss: 0.3181743
Validation loss decreased (0.640047 --> 0.639751).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.6568142
	speed: 0.1244s/iter; left time: 5620.0307s
	iters: 200, epoch: 20 | loss: 0.6203437
	speed: 0.0288s/iter; left time: 1298.8225s
	iters: 300, epoch: 20 | loss: 0.5100477
	speed: 0.0312s/iter; left time: 1405.1697s
	iters: 400, epoch: 20 | loss: 0.5075516
	speed: 0.0352s/iter; left time: 1579.4825s
	iters: 500, epoch: 20 | loss: 0.5860211
	speed: 0.0328s/iter; left time: 1467.4380s
Epoch: 20 cost time: 20.045555114746094
Epoch: 20, Steps: 559 | Train Loss: 0.5913919 Vali Loss: 0.6395267 Test Loss: 0.3180985
Validation loss decreased (0.639751 --> 0.639527).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.6041662
	speed: 0.1711s/iter; left time: 7632.4397s
	iters: 200, epoch: 21 | loss: 0.6575701
	speed: 0.0459s/iter; left time: 2041.5550s
	iters: 300, epoch: 21 | loss: 0.5616119
	speed: 0.0374s/iter; left time: 1660.0520s
	iters: 400, epoch: 21 | loss: 0.6314891
	speed: 0.0373s/iter; left time: 1655.3514s
	iters: 500, epoch: 21 | loss: 0.5694479
	speed: 0.0304s/iter; left time: 1346.1624s
Epoch: 21 cost time: 20.931868076324463
Epoch: 21, Steps: 559 | Train Loss: 0.5912045 Vali Loss: 0.6397671 Test Loss: 0.3180675
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4313920
	speed: 0.1364s/iter; left time: 6011.6600s
	iters: 200, epoch: 22 | loss: 0.4813193
	speed: 0.0302s/iter; left time: 1329.1390s
	iters: 300, epoch: 22 | loss: 0.4983063
	speed: 0.0447s/iter; left time: 1960.2863s
	iters: 400, epoch: 22 | loss: 0.4967671
	speed: 0.0389s/iter; left time: 1700.2012s
	iters: 500, epoch: 22 | loss: 0.6081465
	speed: 0.0328s/iter; left time: 1432.5609s
Epoch: 22 cost time: 20.62887668609619
Epoch: 22, Steps: 559 | Train Loss: 0.5910536 Vali Loss: 0.6396163 Test Loss: 0.3180148
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4882293
	speed: 0.1681s/iter; left time: 7312.3594s
	iters: 200, epoch: 23 | loss: 0.5649998
	speed: 0.0362s/iter; left time: 1571.6586s
	iters: 300, epoch: 23 | loss: 0.5932109
	speed: 0.0335s/iter; left time: 1451.9862s
	iters: 400, epoch: 23 | loss: 0.6164025
	speed: 0.0326s/iter; left time: 1407.8183s
	iters: 500, epoch: 23 | loss: 0.5000412
	speed: 0.0325s/iter; left time: 1401.2064s
Epoch: 23 cost time: 19.638324737548828
Epoch: 23, Steps: 559 | Train Loss: 0.5908428 Vali Loss: 0.6392729 Test Loss: 0.3179040
Validation loss decreased (0.639527 --> 0.639273).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.5202476
	speed: 0.1383s/iter; left time: 5940.7496s
	iters: 200, epoch: 24 | loss: 0.8196424
	speed: 0.0337s/iter; left time: 1445.5115s
	iters: 300, epoch: 24 | loss: 0.5402482
	speed: 0.0301s/iter; left time: 1288.6627s
	iters: 400, epoch: 24 | loss: 0.4791157
	speed: 0.0311s/iter; left time: 1325.0485s
	iters: 500, epoch: 24 | loss: 0.7574204
	speed: 0.0321s/iter; left time: 1363.6219s
Epoch: 24 cost time: 18.347219705581665
Epoch: 24, Steps: 559 | Train Loss: 0.5907758 Vali Loss: 0.6391866 Test Loss: 0.3178500
Validation loss decreased (0.639273 --> 0.639187).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.6553816
	speed: 0.1419s/iter; left time: 6014.8838s
	iters: 200, epoch: 25 | loss: 0.5372205
	speed: 0.0324s/iter; left time: 1369.6597s
	iters: 300, epoch: 25 | loss: 0.5555069
	speed: 0.0292s/iter; left time: 1233.4950s
	iters: 400, epoch: 25 | loss: 0.5284354
	speed: 0.0302s/iter; left time: 1270.8778s
	iters: 500, epoch: 25 | loss: 0.5899259
	speed: 0.0466s/iter; left time: 1955.9863s
Epoch: 25 cost time: 19.986597061157227
Epoch: 25, Steps: 559 | Train Loss: 0.5910455 Vali Loss: 0.6388003 Test Loss: 0.3177655
Validation loss decreased (0.639187 --> 0.638800).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.6308168
	speed: 0.1515s/iter; left time: 6335.0951s
	iters: 200, epoch: 26 | loss: 0.5006277
	speed: 0.0487s/iter; left time: 2030.1342s
	iters: 300, epoch: 26 | loss: 0.6450078
	speed: 0.0410s/iter; left time: 1704.7760s
	iters: 400, epoch: 26 | loss: 0.4746643
	speed: 0.0398s/iter; left time: 1653.7922s
	iters: 500, epoch: 26 | loss: 0.5590633
	speed: 0.0314s/iter; left time: 1300.5194s
Epoch: 26 cost time: 22.437387466430664
Epoch: 26, Steps: 559 | Train Loss: 0.5908371 Vali Loss: 0.6394053 Test Loss: 0.3178197
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.6127497
	speed: 0.1568s/iter; left time: 6471.4353s
	iters: 200, epoch: 27 | loss: 0.6176055
	speed: 0.0314s/iter; left time: 1291.7038s
	iters: 300, epoch: 27 | loss: 0.6128550
	speed: 0.0341s/iter; left time: 1399.8840s
	iters: 400, epoch: 27 | loss: 0.5992669
	speed: 0.0296s/iter; left time: 1211.3259s
	iters: 500, epoch: 27 | loss: 0.5995368
	speed: 0.0325s/iter; left time: 1328.7296s
Epoch: 27 cost time: 18.621474742889404
Epoch: 27, Steps: 559 | Train Loss: 0.5906917 Vali Loss: 0.6388111 Test Loss: 0.3177215
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.8108479
	speed: 0.1465s/iter; left time: 5963.9815s
	iters: 200, epoch: 28 | loss: 0.6732385
	speed: 0.0349s/iter; left time: 1419.1861s
	iters: 300, epoch: 28 | loss: 0.4859890
	speed: 0.0316s/iter; left time: 1281.8845s
	iters: 400, epoch: 28 | loss: 0.6368017
	speed: 0.0319s/iter; left time: 1287.7102s
	iters: 500, epoch: 28 | loss: 0.6886597
	speed: 0.0409s/iter; left time: 1648.4675s
Epoch: 28 cost time: 21.06322956085205
Epoch: 28, Steps: 559 | Train Loss: 0.5904963 Vali Loss: 0.6387708 Test Loss: 0.3176591
Validation loss decreased (0.638800 --> 0.638771).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.5590023
	speed: 0.1458s/iter; left time: 5854.3702s
	iters: 200, epoch: 29 | loss: 0.6048367
	speed: 0.0314s/iter; left time: 1255.6691s
	iters: 300, epoch: 29 | loss: 0.6100625
	speed: 0.0313s/iter; left time: 1251.5455s
	iters: 400, epoch: 29 | loss: 0.6093387
	speed: 0.0310s/iter; left time: 1236.6955s
	iters: 500, epoch: 29 | loss: 0.5654106
	speed: 0.0370s/iter; left time: 1468.7295s
Epoch: 29 cost time: 18.58243441581726
Epoch: 29, Steps: 559 | Train Loss: 0.5905825 Vali Loss: 0.6391958 Test Loss: 0.3176669
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.5682001
	speed: 0.1567s/iter; left time: 6205.1955s
	iters: 200, epoch: 30 | loss: 0.6631541
	speed: 0.0345s/iter; left time: 1362.4463s
	iters: 300, epoch: 30 | loss: 0.4832880
	speed: 0.0348s/iter; left time: 1370.0292s
	iters: 400, epoch: 30 | loss: 0.6371309
	speed: 0.0387s/iter; left time: 1520.1628s
	iters: 500, epoch: 30 | loss: 0.4970454
	speed: 0.0326s/iter; left time: 1277.2356s
Epoch: 30 cost time: 20.74009370803833
Epoch: 30, Steps: 559 | Train Loss: 0.5905939 Vali Loss: 0.6390668 Test Loss: 0.3176501
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4678871
	speed: 0.1543s/iter; left time: 6022.4616s
	iters: 200, epoch: 31 | loss: 0.4798793
	speed: 0.0348s/iter; left time: 1356.3182s
	iters: 300, epoch: 31 | loss: 0.5766869
	speed: 0.0324s/iter; left time: 1256.3038s
	iters: 400, epoch: 31 | loss: 0.6159019
	speed: 0.0352s/iter; left time: 1362.4156s
	iters: 500, epoch: 31 | loss: 0.6246664
	speed: 0.0319s/iter; left time: 1234.1491s
Epoch: 31 cost time: 18.750128507614136
Epoch: 31, Steps: 559 | Train Loss: 0.5904110 Vali Loss: 0.6390492 Test Loss: 0.3176082
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Weather_360_j720_H10_FITS_custom_ftM_sl360_ll48_pl720_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
mse:0.31720370054244995, mae:0.332040399312973, rse:0.7411416172981262, corr:[0.47457686 0.4736465  0.47247982 0.4719459  0.47173572 0.47139776
 0.4707528  0.4697492  0.4685462  0.4674069  0.46651158 0.46596828
 0.4654996  0.4649518  0.46417215 0.46310496 0.46189842 0.46071684
 0.4597482  0.45898417 0.4583043  0.45756376 0.45668897 0.45561236
 0.45441252 0.45323262 0.4521761  0.4513021  0.45061198 0.4500019
 0.44941497 0.44868156 0.4478598  0.44696584 0.44617927 0.44550106
 0.44503415 0.44463146 0.4441703  0.44364277 0.44300693 0.4424147
 0.44176736 0.44116297 0.44056448 0.4399826  0.43942463 0.4389359
 0.43827605 0.43750873 0.43674728 0.43610537 0.43562552 0.4352743
 0.4350285  0.43478003 0.4344712  0.43404728 0.43373394 0.43343797
 0.4332194  0.4329705  0.43281636 0.43264934 0.4324993  0.43234813
 0.43212372 0.43175656 0.4313903  0.43109286 0.4309307  0.4307539
 0.4306178  0.4305311  0.43034092 0.43005756 0.42975783 0.42952228
 0.42935085 0.42921406 0.42916736 0.4291595  0.42914653 0.42913017
 0.42907035 0.42896515 0.42880502 0.42856157 0.42832273 0.4280866
 0.42793712 0.42788848 0.42787054 0.4278604  0.42779723 0.42766163
 0.4274651  0.4272242  0.42704237 0.4269077  0.4268615  0.42685285
 0.42686737 0.4268076  0.4265867  0.4262371  0.42579123 0.425396
 0.4250784  0.4249053  0.4248422  0.424791   0.42465463 0.42447466
 0.42421266 0.4239254  0.4236738  0.42346895 0.42330447 0.423149
 0.4230085  0.42288905 0.42276314 0.42262676 0.42247817 0.42232028
 0.42218485 0.42202494 0.42185566 0.42165533 0.42140374 0.42112324
 0.4208293  0.4204943  0.42016765 0.4198007  0.4194583  0.41912395
 0.41881052 0.4185316  0.41830027 0.41811198 0.41799217 0.4178294
 0.41762084 0.41736126 0.41706604 0.41674763 0.41640016 0.41603184
 0.4156132  0.4151922  0.41475517 0.414394   0.4140124  0.41359496
 0.41317287 0.41267836 0.41217726 0.4116665  0.4111921  0.41076422
 0.41037565 0.4099816  0.40957358 0.40914702 0.4086785  0.40813535
 0.407554   0.40695012 0.4063378  0.40575916 0.40523455 0.40484974
 0.40448686 0.40416485 0.40380237 0.40342978 0.4030498  0.40264618
 0.40223643 0.40178108 0.4013097  0.40082604 0.40038946 0.39999166
 0.39963716 0.39928985 0.3989351  0.3986318  0.3983092  0.3979899
 0.3977279  0.39745578 0.39714366 0.39686516 0.39658314 0.39638096
 0.39628196 0.3962349  0.39622858 0.39618248 0.39616236 0.3960682
 0.39593863 0.39576483 0.39558062 0.39536348 0.3951352  0.394919
 0.39471507 0.39448592 0.3942371  0.394022   0.39378992 0.3935437
 0.39329067 0.39308512 0.39291683 0.3927447  0.3925697  0.3923672
 0.3921654  0.39192975 0.39166752 0.39134467 0.39107326 0.390811
 0.39056534 0.39030796 0.39006373 0.38979965 0.38947588 0.3890692
 0.38862664 0.3882211  0.3878354  0.38748756 0.38712698 0.38676113
 0.38643208 0.38616782 0.38590774 0.38569912 0.38552284 0.3852972
 0.38500953 0.3846388  0.38419756 0.3837575  0.38331825 0.3829335
 0.38261172 0.38223934 0.38188002 0.38153693 0.38117197 0.38081324
 0.38045475 0.38009247 0.3797188  0.37935632 0.37903    0.37877715
 0.37858763 0.37844005 0.37828177 0.3781131  0.3778731  0.37755737
 0.37715122 0.37671906 0.3762611  0.3757855  0.3753013  0.37482587
 0.37435865 0.3738589  0.37334856 0.3728609  0.3723598  0.37188426
 0.37139064 0.37085697 0.37028313 0.369731   0.36915037 0.3685094
 0.36781856 0.36712635 0.36638397 0.36559787 0.36480963 0.36413628
 0.36347333 0.36286494 0.3622536  0.36163127 0.36094764 0.3602225
 0.35939848 0.3585193  0.3576557  0.35685906 0.3561479  0.35549223
 0.3548943  0.3542678  0.35364357 0.3530027  0.35241312 0.3518182
 0.35121104 0.35061657 0.35003302 0.34944928 0.34888324 0.34825543
 0.34759465 0.34689057 0.34616852 0.34545994 0.34484443 0.34431145
 0.34387848 0.34354442 0.34321356 0.34291205 0.34261885 0.3422976
 0.34198844 0.341685   0.34139177 0.34117383 0.340965   0.3408045
 0.3406344  0.34050426 0.3404127  0.3402912  0.34012672 0.33997455
 0.33977985 0.33950436 0.3392353  0.33896235 0.33872443 0.33851174
 0.33835062 0.33819664 0.3380541  0.3378195  0.33762884 0.33744067
 0.33730033 0.3372628  0.33732903 0.33742666 0.33755058 0.33759913
 0.3375312  0.337384   0.33717144 0.33694866 0.3367298  0.33658397
 0.33648357 0.33639872 0.33632877 0.33619648 0.3360116  0.33578017
 0.33549675 0.33517522 0.33486092 0.33456707 0.3343905  0.33422324
 0.33403915 0.33377776 0.3334956  0.33323947 0.33301055 0.3327597
 0.3324901  0.3322149  0.33196333 0.33172402 0.33152962 0.3313336
 0.33111164 0.33090046 0.3306948  0.33048645 0.33026055 0.3300125
 0.32973725 0.32941824 0.32911983 0.3288118  0.32854038 0.32828766
 0.328105   0.32792458 0.3277476  0.32749626 0.32721987 0.32689106
 0.32656342 0.32627785 0.32604736 0.32580596 0.32561058 0.32545525
 0.3253125  0.32517713 0.32506296 0.32495117 0.32475805 0.3245174
 0.32421896 0.323896   0.32351083 0.32315248 0.322776   0.3223853
 0.32199913 0.32166457 0.3213098  0.3209052  0.3204537  0.31998062
 0.31949607 0.31895995 0.31841794 0.3178836  0.3173183  0.31673592
 0.31613547 0.3155019  0.31483936 0.31414083 0.31342006 0.31255898
 0.31166077 0.31076694 0.30986542 0.3090718  0.3083716  0.307762
 0.30721644 0.30671835 0.3062422  0.30578107 0.3053898  0.30503395
 0.30471632 0.30441684 0.3040042  0.30353853 0.3029941  0.30249017
 0.30200663 0.30158752 0.30125973 0.30101052 0.3007828  0.3005403
 0.30027407 0.30000618 0.29970035 0.29938436 0.29910558 0.29890844
 0.29881254 0.2987121  0.2985998  0.298512   0.298419   0.29827988
 0.29818907 0.2981082  0.29801708 0.29797968 0.29793704 0.29792067
 0.29782218 0.2976778  0.29752037 0.29737064 0.2972108  0.29704624
 0.29691982 0.29684648 0.29680517 0.29678017 0.29668835 0.29656214
 0.2964077  0.2962493  0.29608503 0.2959423  0.29582492 0.2957425
 0.2956866  0.2956382  0.29557222 0.29543334 0.29524064 0.29499516
 0.29470897 0.2943835  0.29404682 0.29368418 0.2933056  0.29294443
 0.2925942  0.29225773 0.29191667 0.29156825 0.2912235  0.29084912
 0.29046664 0.2901053  0.28973594 0.2893795  0.28898892 0.28859386
 0.28819758 0.28781277 0.2873995  0.28700835 0.28664228 0.28628007
 0.285942   0.28561702 0.28530362 0.28500643 0.28467673 0.28432018
 0.2839563  0.28360042 0.28327486 0.2829975  0.28277278 0.28259113
 0.28245413 0.28233835 0.28224537 0.28208882 0.28192353 0.28173712
 0.28154695 0.2813354  0.28113276 0.28089583 0.28065625 0.28038093
 0.28005028 0.27971765 0.2793859  0.27906865 0.2787186  0.27834988
 0.27798012 0.27763033 0.27730495 0.2769812  0.27664217 0.27631408
 0.27596146 0.2755962  0.27517304 0.2746763  0.27412984 0.2735168
 0.2728722  0.27224118 0.27164128 0.2710585  0.2705158  0.27003455
 0.26955467 0.2690486  0.2684822  0.26786742 0.26717007 0.26648065
 0.26582608 0.26524165 0.2646549  0.2640927  0.2635129  0.26294196
 0.26233187 0.26164776 0.26094848 0.26027516 0.25964028 0.25908592
 0.25858763 0.25806943 0.2575133  0.2569038  0.25628683 0.25571045
 0.25517696 0.2547377  0.2543406  0.25395495 0.25356638 0.2531655
 0.25271967 0.25228864 0.2519346  0.2515256  0.25122958 0.25095877
 0.25078425 0.25067076 0.2504913  0.2503726  0.25027227 0.25022927
 0.25022128 0.25021285 0.25025162 0.2503126  0.25039378 0.25043193
 0.2503657  0.25022593 0.25009272 0.24992283 0.24981344 0.24978033
 0.24983065 0.24990395 0.25004825 0.25012678 0.25012612 0.2500416
 0.25001225 0.24995854 0.2499675  0.25000334 0.2501379  0.2503154
 0.25054702 0.25075597 0.25094527 0.25105736 0.25112635 0.25109613
 0.25100046 0.25083068 0.25064942 0.25047046 0.25031483 0.25023502
 0.25015047 0.25008696 0.24996264 0.24975885 0.24947314 0.24911411
 0.24873264 0.24840829 0.24815173 0.24792819 0.24774002 0.24751231
 0.24726816 0.24698526 0.24666579 0.2463207  0.24597973 0.24569725
 0.24543513 0.24518426 0.24492441 0.24466003 0.24439639 0.24410905
 0.24386393 0.2436912  0.24360068 0.2435642  0.2435612  0.24350987
 0.24337392 0.24315365 0.24294071 0.24280341 0.24279617 0.24289332
 0.24306059 0.24316585 0.24313438 0.24292547 0.24254222 0.24207942
 0.2417213  0.24159189 0.24169132 0.2419594  0.24220443 0.24226229
 0.24208347 0.24170406 0.24123764 0.24088274 0.24061789 0.2404457
 0.24021792 0.2399572  0.23963115 0.23930958 0.23909666 0.23893122]
