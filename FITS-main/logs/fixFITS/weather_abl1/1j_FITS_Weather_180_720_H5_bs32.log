Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=144, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=20, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='weather.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=21, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=True, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Weather_180_j720_H5', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=3, pred_len=720, root_path='./dataset/', seed=2021, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Weather_180_j720_H5_FITS_custom_ftM_sl180_ll48_pl720_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 35988
val 4551
test 9820
Model(
  (freq_upsampler): ModuleList(
    (0): Linear(in_features=20, out_features=100, bias=True)
    (1): Linear(in_features=20, out_features=100, bias=True)
    (2): Linear(in_features=20, out_features=100, bias=True)
    (3): Linear(in_features=20, out_features=100, bias=True)
    (4): Linear(in_features=20, out_features=100, bias=True)
    (5): Linear(in_features=20, out_features=100, bias=True)
    (6): Linear(in_features=20, out_features=100, bias=True)
    (7): Linear(in_features=20, out_features=100, bias=True)
    (8): Linear(in_features=20, out_features=100, bias=True)
    (9): Linear(in_features=20, out_features=100, bias=True)
    (10): Linear(in_features=20, out_features=100, bias=True)
    (11): Linear(in_features=20, out_features=100, bias=True)
    (12): Linear(in_features=20, out_features=100, bias=True)
    (13): Linear(in_features=20, out_features=100, bias=True)
    (14): Linear(in_features=20, out_features=100, bias=True)
    (15): Linear(in_features=20, out_features=100, bias=True)
    (16): Linear(in_features=20, out_features=100, bias=True)
    (17): Linear(in_features=20, out_features=100, bias=True)
    (18): Linear(in_features=20, out_features=100, bias=True)
    (19): Linear(in_features=20, out_features=100, bias=True)
    (20): Linear(in_features=20, out_features=100, bias=True)
  )
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2688000.0
params:  44100.0
Trainable parameters:  44100
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 1.0697031
	speed: 0.0633s/iter; left time: 3548.8434s
	iters: 200, epoch: 1 | loss: 0.9893290
	speed: 0.0405s/iter; left time: 2269.8036s
	iters: 300, epoch: 1 | loss: 0.9397349
	speed: 0.0418s/iter; left time: 2335.8019s
	iters: 400, epoch: 1 | loss: 0.7888908
	speed: 0.0428s/iter; left time: 2388.9133s
	iters: 500, epoch: 1 | loss: 0.7332113
	speed: 0.0491s/iter; left time: 2735.2298s
Epoch: 1 cost time: 26.945085287094116
Epoch: 1, Steps: 562 | Train Loss: 0.8712606 Vali Loss: 0.7146810 Test Loss: 0.3506956
Validation loss decreased (inf --> 0.714681).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.8095289
	speed: 0.1942s/iter; left time: 10787.7497s
	iters: 200, epoch: 2 | loss: 0.5866401
	speed: 0.0451s/iter; left time: 2501.2980s
	iters: 300, epoch: 2 | loss: 0.5746601
	speed: 0.0377s/iter; left time: 2088.4227s
	iters: 400, epoch: 2 | loss: 0.5689932
	speed: 0.0431s/iter; left time: 2378.9210s
	iters: 500, epoch: 2 | loss: 0.5612254
	speed: 0.0402s/iter; left time: 2217.2479s
Epoch: 2 cost time: 24.695417881011963
Epoch: 2, Steps: 562 | Train Loss: 0.6677009 Vali Loss: 0.6883199 Test Loss: 0.3433688
Validation loss decreased (0.714681 --> 0.688320).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5973525
	speed: 0.1614s/iter; left time: 8874.6571s
	iters: 200, epoch: 3 | loss: 0.6253489
	speed: 0.0399s/iter; left time: 2189.7517s
	iters: 300, epoch: 3 | loss: 0.6966333
	speed: 0.0367s/iter; left time: 2010.2967s
	iters: 400, epoch: 3 | loss: 0.7572540
	speed: 0.0514s/iter; left time: 2810.6888s
	iters: 500, epoch: 3 | loss: 0.6956621
	speed: 0.0466s/iter; left time: 2541.3101s
Epoch: 3 cost time: 24.313069105148315
Epoch: 3, Steps: 562 | Train Loss: 0.6490357 Vali Loss: 0.6842698 Test Loss: 0.3409195
Validation loss decreased (0.688320 --> 0.684270).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.6162874
	speed: 0.1803s/iter; left time: 9808.8819s
	iters: 200, epoch: 4 | loss: 0.7897860
	speed: 0.0437s/iter; left time: 2372.4162s
	iters: 300, epoch: 4 | loss: 0.5861049
	speed: 0.0383s/iter; left time: 2073.8312s
	iters: 400, epoch: 4 | loss: 0.5782363
	speed: 0.0407s/iter; left time: 2201.1945s
	iters: 500, epoch: 4 | loss: 0.6253163
	speed: 0.0346s/iter; left time: 1867.3063s
Epoch: 4 cost time: 23.329144954681396
Epoch: 4, Steps: 562 | Train Loss: 0.6438456 Vali Loss: 0.6813285 Test Loss: 0.3392709
Validation loss decreased (0.684270 --> 0.681328).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.7935787
	speed: 0.1958s/iter; left time: 10542.0437s
	iters: 200, epoch: 5 | loss: 0.5264485
	speed: 0.0524s/iter; left time: 2819.1067s
	iters: 300, epoch: 5 | loss: 0.6982130
	speed: 0.0388s/iter; left time: 2082.9188s
	iters: 400, epoch: 5 | loss: 0.6992416
	speed: 0.0511s/iter; left time: 2735.7108s
	iters: 500, epoch: 5 | loss: 0.6683472
	speed: 0.0449s/iter; left time: 2401.1351s
Epoch: 5 cost time: 26.35245656967163
Epoch: 5, Steps: 562 | Train Loss: 0.6413459 Vali Loss: 0.6802964 Test Loss: 0.3381990
Validation loss decreased (0.681328 --> 0.680296).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.6888213
	speed: 0.2017s/iter; left time: 10746.1871s
	iters: 200, epoch: 6 | loss: 0.5998443
	speed: 0.0362s/iter; left time: 1926.0716s
	iters: 300, epoch: 6 | loss: 0.7305678
	speed: 0.0329s/iter; left time: 1747.3844s
	iters: 400, epoch: 6 | loss: 0.5516807
	speed: 0.0441s/iter; left time: 2335.8026s
	iters: 500, epoch: 6 | loss: 0.6778178
	speed: 0.0456s/iter; left time: 2411.9785s
Epoch: 6 cost time: 24.561625719070435
Epoch: 6, Steps: 562 | Train Loss: 0.6398695 Vali Loss: 0.6786238 Test Loss: 0.3373173
Validation loss decreased (0.680296 --> 0.678624).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.6394604
	speed: 0.1890s/iter; left time: 9967.7362s
	iters: 200, epoch: 7 | loss: 0.7273247
	speed: 0.0455s/iter; left time: 2396.2660s
	iters: 300, epoch: 7 | loss: 0.5754172
	speed: 0.0431s/iter; left time: 2265.1509s
	iters: 400, epoch: 7 | loss: 0.6460263
	speed: 0.0458s/iter; left time: 2398.7175s
	iters: 500, epoch: 7 | loss: 0.6352880
	speed: 0.0396s/iter; left time: 2070.2226s
Epoch: 7 cost time: 25.702909231185913
Epoch: 7, Steps: 562 | Train Loss: 0.6385372 Vali Loss: 0.6778048 Test Loss: 0.3365732
Validation loss decreased (0.678624 --> 0.677805).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.6568065
	speed: 0.1851s/iter; left time: 9658.2966s
	iters: 200, epoch: 8 | loss: 0.5919651
	speed: 0.0474s/iter; left time: 2467.5273s
	iters: 300, epoch: 8 | loss: 0.6073128
	speed: 0.0412s/iter; left time: 2141.9795s
	iters: 400, epoch: 8 | loss: 0.6587610
	speed: 0.0444s/iter; left time: 2302.8706s
	iters: 500, epoch: 8 | loss: 0.5353674
	speed: 0.0375s/iter; left time: 1940.3720s
Epoch: 8 cost time: 24.141021728515625
Epoch: 8, Steps: 562 | Train Loss: 0.6378172 Vali Loss: 0.6770829 Test Loss: 0.3360004
Validation loss decreased (0.677805 --> 0.677083).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.5581698
	speed: 0.1676s/iter; left time: 8651.1122s
	iters: 200, epoch: 9 | loss: 0.8476697
	speed: 0.0452s/iter; left time: 2325.9486s
	iters: 300, epoch: 9 | loss: 0.6682580
	speed: 0.0450s/iter; left time: 2310.7886s
	iters: 400, epoch: 9 | loss: 0.6551403
	speed: 0.0360s/iter; left time: 1844.7702s
	iters: 500, epoch: 9 | loss: 0.6136012
	speed: 0.0339s/iter; left time: 1733.8728s
Epoch: 9 cost time: 22.47068500518799
Epoch: 9, Steps: 562 | Train Loss: 0.6370929 Vali Loss: 0.6767624 Test Loss: 0.3355343
Validation loss decreased (0.677083 --> 0.676762).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.5571126
	speed: 0.1726s/iter; left time: 8811.6648s
	iters: 200, epoch: 10 | loss: 0.5913295
	speed: 0.0569s/iter; left time: 2897.5356s
	iters: 300, epoch: 10 | loss: 0.7345119
	speed: 0.0582s/iter; left time: 2957.3650s
	iters: 400, epoch: 10 | loss: 0.5986908
	speed: 0.0425s/iter; left time: 2157.0867s
	iters: 500, epoch: 10 | loss: 0.7026187
	speed: 0.0415s/iter; left time: 2102.8233s
Epoch: 10 cost time: 26.727710723876953
Epoch: 10, Steps: 562 | Train Loss: 0.6365580 Vali Loss: 0.6763607 Test Loss: 0.3350819
Validation loss decreased (0.676762 --> 0.676361).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.5127198
	speed: 0.1555s/iter; left time: 7849.3902s
	iters: 200, epoch: 11 | loss: 0.5452566
	speed: 0.0420s/iter; left time: 2115.4202s
	iters: 300, epoch: 11 | loss: 0.6006244
	speed: 0.0487s/iter; left time: 2446.6999s
	iters: 400, epoch: 11 | loss: 0.8036728
	speed: 0.0443s/iter; left time: 2221.7641s
	iters: 500, epoch: 11 | loss: 0.6397620
	speed: 0.0451s/iter; left time: 2256.9850s
Epoch: 11 cost time: 26.472322940826416
Epoch: 11, Steps: 562 | Train Loss: 0.6359756 Vali Loss: 0.6753166 Test Loss: 0.3347348
Validation loss decreased (0.676361 --> 0.675317).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.7161216
	speed: 0.1905s/iter; left time: 9509.8756s
	iters: 200, epoch: 12 | loss: 0.5765421
	speed: 0.0364s/iter; left time: 1811.2017s
	iters: 300, epoch: 12 | loss: 0.6147782
	speed: 0.0396s/iter; left time: 1966.5998s
	iters: 400, epoch: 12 | loss: 0.5925044
	speed: 0.0425s/iter; left time: 2106.6699s
	iters: 500, epoch: 12 | loss: 0.5356021
	speed: 0.0487s/iter; left time: 2413.2923s
Epoch: 12 cost time: 23.555225133895874
Epoch: 12, Steps: 562 | Train Loss: 0.6355317 Vali Loss: 0.6744479 Test Loss: 0.3344282
Validation loss decreased (0.675317 --> 0.674448).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.6907337
	speed: 0.1800s/iter; left time: 8882.7475s
	iters: 200, epoch: 13 | loss: 0.5459839
	speed: 0.0392s/iter; left time: 1929.7587s
	iters: 300, epoch: 13 | loss: 0.5911353
	speed: 0.0367s/iter; left time: 1804.5204s
	iters: 400, epoch: 13 | loss: 0.7774627
	speed: 0.0415s/iter; left time: 2037.0428s
	iters: 500, epoch: 13 | loss: 0.7174615
	speed: 0.0479s/iter; left time: 2343.6996s
Epoch: 13 cost time: 24.552709102630615
Epoch: 13, Steps: 562 | Train Loss: 0.6351763 Vali Loss: 0.6743659 Test Loss: 0.3341733
Validation loss decreased (0.674448 --> 0.674366).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.7372823
	speed: 0.1794s/iter; left time: 8754.8041s
	iters: 200, epoch: 14 | loss: 0.5230576
	speed: 0.0426s/iter; left time: 2072.4051s
	iters: 300, epoch: 14 | loss: 0.6548332
	speed: 0.0475s/iter; left time: 2309.4017s
	iters: 400, epoch: 14 | loss: 0.5872038
	speed: 0.0348s/iter; left time: 1686.8445s
	iters: 500, epoch: 14 | loss: 0.6433686
	speed: 0.0418s/iter; left time: 2020.6717s
Epoch: 14 cost time: 23.287290573120117
Epoch: 14, Steps: 562 | Train Loss: 0.6348682 Vali Loss: 0.6737598 Test Loss: 0.3339498
Validation loss decreased (0.674366 --> 0.673760).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.6900775
	speed: 0.1723s/iter; left time: 8311.6687s
	iters: 200, epoch: 15 | loss: 0.5775259
	speed: 0.0352s/iter; left time: 1693.2029s
	iters: 300, epoch: 15 | loss: 0.5632865
	speed: 0.0408s/iter; left time: 1961.6496s
	iters: 400, epoch: 15 | loss: 0.6836843
	speed: 0.0405s/iter; left time: 1939.9614s
	iters: 500, epoch: 15 | loss: 0.5921295
	speed: 0.0373s/iter; left time: 1782.5823s
Epoch: 15 cost time: 22.43956995010376
Epoch: 15, Steps: 562 | Train Loss: 0.6344262 Vali Loss: 0.6736897 Test Loss: 0.3337466
Validation loss decreased (0.673760 --> 0.673690).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.6072165
	speed: 0.1677s/iter; left time: 7993.0988s
	iters: 200, epoch: 16 | loss: 0.6737297
	speed: 0.0407s/iter; left time: 1935.2902s
	iters: 300, epoch: 16 | loss: 0.6152518
	speed: 0.0425s/iter; left time: 2015.3978s
	iters: 400, epoch: 16 | loss: 0.5444119
	speed: 0.0408s/iter; left time: 1931.5484s
	iters: 500, epoch: 16 | loss: 0.6324758
	speed: 0.0396s/iter; left time: 1869.8446s
Epoch: 16 cost time: 23.30602502822876
Epoch: 16, Steps: 562 | Train Loss: 0.6342636 Vali Loss: 0.6733851 Test Loss: 0.3335507
Validation loss decreased (0.673690 --> 0.673385).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.5976479
	speed: 0.1830s/iter; left time: 8621.5953s
	iters: 200, epoch: 17 | loss: 0.6521097
	speed: 0.0354s/iter; left time: 1666.1960s
	iters: 300, epoch: 17 | loss: 0.6276633
	speed: 0.0431s/iter; left time: 2023.3161s
	iters: 400, epoch: 17 | loss: 0.6104903
	speed: 0.0380s/iter; left time: 1780.1235s
	iters: 500, epoch: 17 | loss: 0.5189074
	speed: 0.0424s/iter; left time: 1978.3936s
Epoch: 17 cost time: 23.653895139694214
Epoch: 17, Steps: 562 | Train Loss: 0.6339825 Vali Loss: 0.6731654 Test Loss: 0.3334095
Validation loss decreased (0.673385 --> 0.673165).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.6000267
	speed: 0.1632s/iter; left time: 7595.4139s
	iters: 200, epoch: 18 | loss: 0.5459605
	speed: 0.0382s/iter; left time: 1775.1786s
	iters: 300, epoch: 18 | loss: 0.5563454
	speed: 0.0345s/iter; left time: 1596.8788s
	iters: 400, epoch: 18 | loss: 0.7455266
	speed: 0.0347s/iter; left time: 1605.8938s
	iters: 500, epoch: 18 | loss: 0.6782733
	speed: 0.0383s/iter; left time: 1769.5581s
Epoch: 18 cost time: 20.523186445236206
Epoch: 18, Steps: 562 | Train Loss: 0.6336852 Vali Loss: 0.6729175 Test Loss: 0.3332008
Validation loss decreased (0.673165 --> 0.672917).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.5578721
	speed: 0.1657s/iter; left time: 7621.7890s
	iters: 200, epoch: 19 | loss: 0.7588515
	speed: 0.0426s/iter; left time: 1953.1598s
	iters: 300, epoch: 19 | loss: 0.8856396
	speed: 0.0397s/iter; left time: 1818.6583s
	iters: 400, epoch: 19 | loss: 0.6719273
	speed: 0.0431s/iter; left time: 1967.4607s
	iters: 500, epoch: 19 | loss: 0.5374362
	speed: 0.0441s/iter; left time: 2012.2113s
Epoch: 19 cost time: 23.974649906158447
Epoch: 19, Steps: 562 | Train Loss: 0.6336013 Vali Loss: 0.6727651 Test Loss: 0.3330714
Validation loss decreased (0.672917 --> 0.672765).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4798543
	speed: 0.1680s/iter; left time: 7629.1994s
	iters: 200, epoch: 20 | loss: 0.6348233
	speed: 0.0475s/iter; left time: 2151.9310s
	iters: 300, epoch: 20 | loss: 0.6731173
	speed: 0.0323s/iter; left time: 1461.7354s
	iters: 400, epoch: 20 | loss: 0.5855742
	speed: 0.0428s/iter; left time: 1931.0173s
	iters: 500, epoch: 20 | loss: 0.6804253
	speed: 0.0414s/iter; left time: 1862.0981s
Epoch: 20 cost time: 24.22465682029724
Epoch: 20, Steps: 562 | Train Loss: 0.6333186 Vali Loss: 0.6726391 Test Loss: 0.3329757
Validation loss decreased (0.672765 --> 0.672639).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.7251213
	speed: 0.1791s/iter; left time: 8034.6040s
	iters: 200, epoch: 21 | loss: 0.6224511
	speed: 0.0355s/iter; left time: 1589.6485s
	iters: 300, epoch: 21 | loss: 0.7161257
	speed: 0.0524s/iter; left time: 2341.8534s
	iters: 400, epoch: 21 | loss: 0.7281294
	speed: 0.0429s/iter; left time: 1912.4457s
	iters: 500, epoch: 21 | loss: 0.5514598
	speed: 0.0418s/iter; left time: 1858.9941s
Epoch: 21 cost time: 24.46322774887085
Epoch: 21, Steps: 562 | Train Loss: 0.6331243 Vali Loss: 0.6723403 Test Loss: 0.3328255
Validation loss decreased (0.672639 --> 0.672340).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.5877610
	speed: 0.1844s/iter; left time: 8168.1329s
	iters: 200, epoch: 22 | loss: 0.8599904
	speed: 0.0400s/iter; left time: 1768.9538s
	iters: 300, epoch: 22 | loss: 0.6021402
	speed: 0.0370s/iter; left time: 1632.9929s
	iters: 400, epoch: 22 | loss: 0.6560423
	speed: 0.0363s/iter; left time: 1596.9366s
	iters: 500, epoch: 22 | loss: 0.7824489
	speed: 0.0311s/iter; left time: 1367.0401s
Epoch: 22 cost time: 20.819277048110962
Epoch: 22, Steps: 562 | Train Loss: 0.6329573 Vali Loss: 0.6713629 Test Loss: 0.3327419
Validation loss decreased (0.672340 --> 0.671363).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.5941691
	speed: 0.1785s/iter; left time: 7808.4135s
	iters: 200, epoch: 23 | loss: 0.5556355
	speed: 0.0501s/iter; left time: 2185.3552s
	iters: 300, epoch: 23 | loss: 0.5671605
	speed: 0.0518s/iter; left time: 2257.3088s
	iters: 400, epoch: 23 | loss: 0.6988121
	speed: 0.0345s/iter; left time: 1497.0693s
	iters: 500, epoch: 23 | loss: 0.5452157
	speed: 0.0355s/iter; left time: 1540.6178s
Epoch: 23 cost time: 23.74562907218933
Epoch: 23, Steps: 562 | Train Loss: 0.6329535 Vali Loss: 0.6713198 Test Loss: 0.3326514
Validation loss decreased (0.671363 --> 0.671320).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.6216736
	speed: 0.2021s/iter; left time: 8725.2073s
	iters: 200, epoch: 24 | loss: 0.7192528
	speed: 0.0371s/iter; left time: 1596.1076s
	iters: 300, epoch: 24 | loss: 0.5879819
	speed: 0.0382s/iter; left time: 1640.4653s
	iters: 400, epoch: 24 | loss: 0.7033640
	speed: 0.0383s/iter; left time: 1641.1799s
	iters: 500, epoch: 24 | loss: 0.8488241
	speed: 0.0407s/iter; left time: 1741.4700s
Epoch: 24 cost time: 24.030357360839844
Epoch: 24, Steps: 562 | Train Loss: 0.6325771 Vali Loss: 0.6719313 Test Loss: 0.3325998
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.6456059
	speed: 0.1916s/iter; left time: 8166.0075s
	iters: 200, epoch: 25 | loss: 0.6895605
	speed: 0.0375s/iter; left time: 1595.0297s
	iters: 300, epoch: 25 | loss: 0.6533388
	speed: 0.0417s/iter; left time: 1768.4738s
	iters: 400, epoch: 25 | loss: 0.5859746
	speed: 0.0432s/iter; left time: 1827.2839s
	iters: 500, epoch: 25 | loss: 0.6148627
	speed: 0.0441s/iter; left time: 1862.8441s
Epoch: 25 cost time: 23.562005043029785
Epoch: 25, Steps: 562 | Train Loss: 0.6325621 Vali Loss: 0.6715775 Test Loss: 0.3325228
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.7027499
	speed: 0.1830s/iter; left time: 7695.7294s
	iters: 200, epoch: 26 | loss: 0.5769132
	speed: 0.0398s/iter; left time: 1671.4037s
	iters: 300, epoch: 26 | loss: 0.6791548
	speed: 0.0435s/iter; left time: 1821.8681s
	iters: 400, epoch: 26 | loss: 0.7474608
	speed: 0.0402s/iter; left time: 1679.5046s
	iters: 500, epoch: 26 | loss: 0.7164849
	speed: 0.0354s/iter; left time: 1472.7050s
Epoch: 26 cost time: 23.16541886329651
Epoch: 26, Steps: 562 | Train Loss: 0.6325052 Vali Loss: 0.6710885 Test Loss: 0.3324042
Validation loss decreased (0.671320 --> 0.671089).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.6280739
	speed: 0.1834s/iter; left time: 7608.0803s
	iters: 200, epoch: 27 | loss: 0.6681222
	speed: 0.0505s/iter; left time: 2088.5045s
	iters: 300, epoch: 27 | loss: 0.6538656
	speed: 0.0386s/iter; left time: 1594.0323s
	iters: 400, epoch: 27 | loss: 0.7087849
	speed: 0.0325s/iter; left time: 1339.8756s
	iters: 500, epoch: 27 | loss: 0.6010727
	speed: 0.0540s/iter; left time: 2220.3954s
Epoch: 27 cost time: 26.102917671203613
Epoch: 27, Steps: 562 | Train Loss: 0.6324225 Vali Loss: 0.6710737 Test Loss: 0.3323240
Validation loss decreased (0.671089 --> 0.671074).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.6066529
	speed: 0.1737s/iter; left time: 7109.4884s
	iters: 200, epoch: 28 | loss: 0.6338496
	speed: 0.0458s/iter; left time: 1870.6342s
	iters: 300, epoch: 28 | loss: 0.5920008
	speed: 0.0384s/iter; left time: 1563.6549s
	iters: 400, epoch: 28 | loss: 0.7341741
	speed: 0.0398s/iter; left time: 1617.3625s
	iters: 500, epoch: 28 | loss: 0.6438082
	speed: 0.0330s/iter; left time: 1338.7007s
Epoch: 28 cost time: 22.366090297698975
Epoch: 28, Steps: 562 | Train Loss: 0.6322907 Vali Loss: 0.6711892 Test Loss: 0.3322593
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.6914113
	speed: 0.1617s/iter; left time: 6526.9474s
	iters: 200, epoch: 29 | loss: 0.6121927
	speed: 0.0384s/iter; left time: 1546.5550s
	iters: 300, epoch: 29 | loss: 0.6368227
	speed: 0.0472s/iter; left time: 1896.0121s
	iters: 400, epoch: 29 | loss: 0.5883579
	speed: 0.0407s/iter; left time: 1631.5475s
	iters: 500, epoch: 29 | loss: 0.5695353
	speed: 0.0422s/iter; left time: 1688.3613s
Epoch: 29 cost time: 24.172667741775513
Epoch: 29, Steps: 562 | Train Loss: 0.6321752 Vali Loss: 0.6710200 Test Loss: 0.3322001
Validation loss decreased (0.671074 --> 0.671020).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4865273
	speed: 0.1611s/iter; left time: 6410.7099s
	iters: 200, epoch: 30 | loss: 0.6869688
	speed: 0.0376s/iter; left time: 1491.4688s
	iters: 300, epoch: 30 | loss: 0.5595368
	speed: 0.0400s/iter; left time: 1584.1175s
	iters: 400, epoch: 30 | loss: 0.6112629
	speed: 0.0438s/iter; left time: 1732.2050s
	iters: 500, epoch: 30 | loss: 0.6198208
	speed: 0.0374s/iter; left time: 1474.0231s
Epoch: 30 cost time: 21.854430198669434
Epoch: 30, Steps: 562 | Train Loss: 0.6321188 Vali Loss: 0.6705503 Test Loss: 0.3321729
Validation loss decreased (0.671020 --> 0.670550).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.5997930
	speed: 0.1709s/iter; left time: 6705.6470s
	iters: 200, epoch: 31 | loss: 0.6572589
	speed: 0.0382s/iter; left time: 1495.8115s
	iters: 300, epoch: 31 | loss: 0.8303757
	speed: 0.0364s/iter; left time: 1422.7494s
	iters: 400, epoch: 31 | loss: 0.7573555
	speed: 0.0374s/iter; left time: 1455.4416s
	iters: 500, epoch: 31 | loss: 0.6282098
	speed: 0.0353s/iter; left time: 1371.6898s
Epoch: 31 cost time: 21.09960436820984
Epoch: 31, Steps: 562 | Train Loss: 0.6318964 Vali Loss: 0.6706343 Test Loss: 0.3321090
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.6295029
	speed: 0.1646s/iter; left time: 6367.8397s
	iters: 200, epoch: 32 | loss: 0.6152085
	speed: 0.0426s/iter; left time: 1643.1138s
	iters: 300, epoch: 32 | loss: 0.7760521
	speed: 0.0419s/iter; left time: 1614.0922s
	iters: 400, epoch: 32 | loss: 0.5956318
	speed: 0.0345s/iter; left time: 1323.9393s
	iters: 500, epoch: 32 | loss: 0.5654212
	speed: 0.0356s/iter; left time: 1364.5387s
Epoch: 32 cost time: 22.10973572731018
Epoch: 32, Steps: 562 | Train Loss: 0.6318896 Vali Loss: 0.6704406 Test Loss: 0.3320597
Validation loss decreased (0.670550 --> 0.670441).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.5440847
	speed: 0.1567s/iter; left time: 5972.4420s
	iters: 200, epoch: 33 | loss: 0.7192600
	speed: 0.0445s/iter; left time: 1690.3610s
	iters: 300, epoch: 33 | loss: 0.5225018
	speed: 0.0395s/iter; left time: 1499.0663s
	iters: 400, epoch: 33 | loss: 0.7128131
	speed: 0.0391s/iter; left time: 1480.3866s
	iters: 500, epoch: 33 | loss: 0.7856652
	speed: 0.0386s/iter; left time: 1457.1115s
Epoch: 33 cost time: 23.100692749023438
Epoch: 33, Steps: 562 | Train Loss: 0.6317756 Vali Loss: 0.6707608 Test Loss: 0.3320051
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.6978901
	speed: 0.1691s/iter; left time: 6351.9539s
	iters: 200, epoch: 34 | loss: 0.5915402
	speed: 0.0379s/iter; left time: 1418.9472s
	iters: 300, epoch: 34 | loss: 0.7900000
	speed: 0.0443s/iter; left time: 1654.6100s
	iters: 400, epoch: 34 | loss: 0.6369339
	speed: 0.0425s/iter; left time: 1584.3757s
	iters: 500, epoch: 34 | loss: 0.5965759
	speed: 0.0485s/iter; left time: 1800.2768s
Epoch: 34 cost time: 25.15848398208618
Epoch: 34, Steps: 562 | Train Loss: 0.6318136 Vali Loss: 0.6703140 Test Loss: 0.3319771
Validation loss decreased (0.670441 --> 0.670314).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.5903319
	speed: 0.1830s/iter; left time: 6770.2464s
	iters: 200, epoch: 35 | loss: 0.5364038
	speed: 0.0399s/iter; left time: 1470.5472s
	iters: 300, epoch: 35 | loss: 0.6953794
	speed: 0.0443s/iter; left time: 1629.1309s
	iters: 400, epoch: 35 | loss: 0.6139295
	speed: 0.0420s/iter; left time: 1542.1001s
	iters: 500, epoch: 35 | loss: 0.7033527
	speed: 0.0377s/iter; left time: 1379.2626s
Epoch: 35 cost time: 23.210752964019775
Epoch: 35, Steps: 562 | Train Loss: 0.6316666 Vali Loss: 0.6701465 Test Loss: 0.3319480
Validation loss decreased (0.670314 --> 0.670147).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.6383694
	speed: 0.1830s/iter; left time: 6667.7800s
	iters: 200, epoch: 36 | loss: 0.7644860
	speed: 0.0374s/iter; left time: 1359.3637s
	iters: 300, epoch: 36 | loss: 0.6510619
	speed: 0.0371s/iter; left time: 1345.9466s
	iters: 400, epoch: 36 | loss: 0.8005206
	speed: 0.0407s/iter; left time: 1470.2728s
	iters: 500, epoch: 36 | loss: 0.6001865
	speed: 0.0361s/iter; left time: 1302.1103s
Epoch: 36 cost time: 22.560702800750732
Epoch: 36, Steps: 562 | Train Loss: 0.6316638 Vali Loss: 0.6698702 Test Loss: 0.3318973
Validation loss decreased (0.670147 --> 0.669870).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4741186
	speed: 0.1840s/iter; left time: 6600.3754s
	iters: 200, epoch: 37 | loss: 0.7363657
	speed: 0.0440s/iter; left time: 1573.1661s
	iters: 300, epoch: 37 | loss: 0.8447243
	speed: 0.0459s/iter; left time: 1637.4443s
	iters: 400, epoch: 37 | loss: 0.6692541
	speed: 0.0453s/iter; left time: 1611.1668s
	iters: 500, epoch: 37 | loss: 0.5491961
	speed: 0.0466s/iter; left time: 1651.5746s
Epoch: 37 cost time: 25.046124696731567
Epoch: 37, Steps: 562 | Train Loss: 0.6314403 Vali Loss: 0.6705239 Test Loss: 0.3318466
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.6570405
	speed: 0.1850s/iter; left time: 6531.8172s
	iters: 200, epoch: 38 | loss: 0.7096980
	speed: 0.0455s/iter; left time: 1603.0876s
	iters: 300, epoch: 38 | loss: 0.6100843
	speed: 0.0398s/iter; left time: 1397.8906s
	iters: 400, epoch: 38 | loss: 0.5875298
	speed: 0.0426s/iter; left time: 1491.3913s
	iters: 500, epoch: 38 | loss: 0.6974426
	speed: 0.0446s/iter; left time: 1558.0063s
Epoch: 38 cost time: 25.29832100868225
Epoch: 38, Steps: 562 | Train Loss: 0.6313366 Vali Loss: 0.6705156 Test Loss: 0.3318321
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.5998748
	speed: 0.1769s/iter; left time: 6147.1024s
	iters: 200, epoch: 39 | loss: 0.5855392
	speed: 0.0383s/iter; left time: 1328.5717s
	iters: 300, epoch: 39 | loss: 0.7211056
	speed: 0.0409s/iter; left time: 1413.1946s
	iters: 400, epoch: 39 | loss: 0.6692134
	speed: 0.0573s/iter; left time: 1973.9766s
	iters: 500, epoch: 39 | loss: 0.6756473
	speed: 0.0474s/iter; left time: 1626.6055s
Epoch: 39 cost time: 26.50699520111084
Epoch: 39, Steps: 562 | Train Loss: 0.6314790 Vali Loss: 0.6703772 Test Loss: 0.3318141
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Weather_180_j720_H5_FITS_custom_ftM_sl180_ll48_pl720_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
mse:0.3310984969139099, mae:0.3354928195476532, rse:0.7572001218795776, corr:[0.47510043 0.47562504 0.47501808 0.47430167 0.4736172  0.47291026
 0.4720914  0.47112077 0.47002253 0.46883658 0.46780524 0.4669744
 0.4661739  0.46533805 0.46435264 0.46321288 0.46199065 0.460703
 0.45954534 0.458492   0.45750067 0.45644262 0.45529985 0.45400032
 0.45256904 0.45115104 0.44985965 0.44869387 0.44768062 0.44669098
 0.44572163 0.4446576  0.44356593 0.44242108 0.44136953 0.44039938
 0.4395356  0.43866268 0.43778005 0.4368532  0.43591583 0.4350236
 0.43417576 0.43336177 0.4325747  0.43185946 0.4311841  0.43050647
 0.42973167 0.42890513 0.42812982 0.42735565 0.4267343  0.42617056
 0.42569777 0.42526457 0.4247536  0.4241918  0.42365667 0.42312938
 0.4226268  0.4221302  0.4217418  0.42136946 0.42099681 0.42059955
 0.42018214 0.41978973 0.41946647 0.41912422 0.41887105 0.41857278
 0.4182836  0.41801006 0.417695   0.41735935 0.41705984 0.41684267
 0.41665313 0.41649994 0.4164004  0.4162831  0.41607788 0.41586238
 0.41570938 0.41568133 0.41574836 0.41577423 0.41581154 0.41582164
 0.4158033  0.4158219  0.41582692 0.4158248  0.415867   0.41596308
 0.41601196 0.41604397 0.41606003 0.41604334 0.41604498 0.4160427
 0.41608632 0.41620708 0.41637373 0.41647983 0.41648078 0.4164379
 0.41634268 0.41623005 0.41611427 0.41600466 0.41585827 0.41574973
 0.41567084 0.4156121  0.4155715  0.41555664 0.41551065 0.4153997
 0.4153128  0.41526756 0.41520697 0.41516125 0.4150711  0.41496283
 0.41484192 0.41465092 0.41441813 0.41415802 0.4138726  0.41359323
 0.41332355 0.41301686 0.4127399  0.41245592 0.41216332 0.41189712
 0.41165084 0.41137016 0.41109234 0.410782   0.41043425 0.41003448
 0.40956038 0.40904528 0.40855825 0.40801927 0.40744892 0.40683427
 0.40622565 0.4056173  0.40503943 0.40447366 0.40384972 0.403195
 0.40256992 0.40191397 0.40122467 0.40053082 0.3998765  0.39920178
 0.3984918  0.39779598 0.3970825  0.39639354 0.3956925  0.39496967
 0.3942267  0.39346412 0.39269572 0.39197397 0.39119166 0.39047968
 0.38980108 0.38914537 0.38848826 0.3878428  0.38722554 0.3865825
 0.38599056 0.38534576 0.38469127 0.38409194 0.38362113 0.38323078
 0.38288778 0.38252372 0.3821136  0.38172904 0.381315   0.38088915
 0.38050926 0.3801398  0.37981573 0.37949276 0.3791175  0.37878624
 0.3784875  0.37818938 0.3778808  0.377611   0.37730148 0.3769833
 0.37667587 0.3763687  0.3760334  0.37569612 0.37534073 0.37500942
 0.37474176 0.37447536 0.37423477 0.37398896 0.3737352  0.37345538
 0.3732257  0.37305668 0.3729048  0.37278843 0.3726799  0.372646
 0.37259313 0.37257144 0.3725285  0.37249213 0.3724848  0.37259978
 0.3727131  0.3728272  0.37289014 0.37299484 0.37300894 0.37296978
 0.3729222  0.37291253 0.37294048 0.37307566 0.37331513 0.37357974
 0.3739074  0.3741993  0.37448514 0.3746945  0.3749112  0.37511212
 0.3752887  0.37535673 0.37535122 0.37539858 0.37540835 0.3753345
 0.37518534 0.3749844  0.3747032  0.3743536  0.3740245  0.37381363
 0.3737182  0.37366012 0.3735404  0.37335968 0.3731857  0.37305158
 0.37293783 0.37283453 0.37276894 0.37265927 0.3725025  0.37223014
 0.37192452 0.3715905  0.37129906 0.37104973 0.37076885 0.3704798
 0.3701721  0.36977127 0.36932623 0.36881316 0.36833245 0.3678656
 0.367478   0.3670833  0.36662406 0.36615783 0.3656067  0.3649612
 0.36423194 0.36346698 0.3626894  0.36187026 0.36105567 0.36030808
 0.35953793 0.3587493  0.35796833 0.35716057 0.3562993  0.3554722
 0.35456702 0.35362887 0.35270596 0.35182592 0.35106862 0.35031146
 0.34966147 0.34898648 0.34832048 0.347607   0.34689644 0.3461621
 0.3454308  0.3447405  0.34403422 0.3432714  0.34253627 0.341795
 0.34106773 0.34033865 0.3396086  0.33890104 0.33825982 0.3376161
 0.33701795 0.33646625 0.33593506 0.3355401  0.33521864 0.3349885
 0.33473608 0.3344694  0.33414003 0.33389655 0.33367133 0.33344978
 0.33321154 0.3329798  0.33281073 0.33258465 0.3323096  0.33203822
 0.33175653 0.33144745 0.33118552 0.33097908 0.33082572 0.33070564
 0.33062842 0.33049628 0.3303388  0.3300988  0.32990313 0.32976782
 0.32963246 0.3295652  0.32951164 0.32946032 0.32941046 0.32937437
 0.32930568 0.32925186 0.32922676 0.32920536 0.32922783 0.32928357
 0.3293227  0.32935935 0.32938996 0.32941824 0.32949504 0.32967076
 0.32993686 0.33025306 0.33054602 0.3308607  0.3311753  0.3314275
 0.33162606 0.33175105 0.3318039  0.33183223 0.33198357 0.3321786
 0.33237824 0.3325579  0.33271244 0.3328328  0.3328795  0.33283278
 0.33273226 0.33267394 0.33268356 0.3328193  0.3329991  0.33318663
 0.33331394 0.33335555 0.33335444 0.33324668 0.33307356 0.33283028
 0.33261427 0.332372   0.33212066 0.3318073  0.3315032  0.33111414
 0.33075848 0.3304034  0.330126   0.32983568 0.32956925 0.3293096
 0.32905585 0.328851   0.32868132 0.3284986  0.32827067 0.32801235
 0.32770088 0.32742882 0.32713026 0.32687268 0.32657257 0.32616565
 0.32571533 0.32526323 0.32476485 0.3241854  0.3235489  0.3229564
 0.3224019  0.321788   0.32119602 0.3206373  0.32002324 0.31932944
 0.31854695 0.31768247 0.31677598 0.31584612 0.3148713  0.31380087
 0.3127159  0.31165013 0.31056723 0.30959368 0.30861744 0.30775347
 0.30688787 0.30603343 0.30514634 0.30422744 0.30331764 0.30243403
 0.30159792 0.30083972 0.30010352 0.2994616  0.2987952  0.29816088
 0.29745242 0.29673788 0.29605806 0.29543298 0.29484236 0.29431194
 0.29383805 0.29344282 0.29303873 0.29264376 0.2922511  0.29188284
 0.29148698 0.2911339  0.29075712 0.2904477  0.2901738  0.2898937
 0.28962848 0.28935498 0.28905287 0.28872886 0.28835428 0.28800663
 0.28761366 0.28723055 0.28690815 0.2866511  0.2864286  0.28618342
 0.28588533 0.28554603 0.2852192  0.2849543  0.28473267 0.28457117
 0.28448108 0.28442672 0.2843792  0.28429928 0.28417918 0.28406498
 0.28397876 0.2839924  0.2840826  0.28418422 0.2843227  0.28441164
 0.28452536 0.2846264  0.2847417  0.28481156 0.28484946 0.28495237
 0.2850344  0.28512117 0.28518313 0.2852089  0.28521624 0.2851461
 0.28501204 0.28487316 0.28473628 0.2846523  0.28454605 0.2844537
 0.28441036 0.28448495 0.28451604 0.2845256  0.28455666 0.28452814
 0.2845586  0.28458107 0.28462595 0.28465664 0.28468716 0.2846245
 0.28450528 0.28436607 0.28415948 0.28398648 0.28382823 0.2837041
 0.28362554 0.28354412 0.2834959  0.28340402 0.28329    0.28317457
 0.28304893 0.28290948 0.28281012 0.28264698 0.28255674 0.2824476
 0.28225374 0.2819664  0.28164747 0.28141272 0.28114396 0.28086632
 0.28055716 0.2802166  0.27982736 0.2793287  0.27883163 0.2783477
 0.27788883 0.27746838 0.27706042 0.27658236 0.2760713  0.27548367
 0.27485707 0.27417335 0.273455   0.27272305 0.27199566 0.27130434
 0.27062523 0.26996398 0.26928627 0.26854807 0.2677373  0.26693207
 0.26612282 0.2654009  0.26469076 0.26400372 0.26335463 0.262749
 0.2621041  0.26135853 0.26060468 0.25988618 0.25921318 0.2585923
 0.25800472 0.25736454 0.2566393  0.25586557 0.255028   0.25423825
 0.25350842 0.25284848 0.25226247 0.25174275 0.25124195 0.25073856
 0.25022206 0.24970552 0.24915099 0.248529   0.24793863 0.24742441
 0.2469489  0.24657607 0.2462632  0.24596584 0.24572048 0.24546625
 0.24516068 0.24479099 0.24441294 0.24400257 0.2437644  0.24357289
 0.24351954 0.24354726 0.24361843 0.24366325 0.24370477 0.24376932
 0.24393594 0.24417068 0.24436355 0.24448048 0.24453063 0.24454889
 0.24456958 0.24452601 0.2444777  0.24448404 0.24458578 0.24476917
 0.2450538  0.24539629 0.24575645 0.24602501 0.24618797 0.2462443
 0.24630825 0.2462922  0.24636215 0.2465657  0.24689615 0.24724653
 0.24762966 0.24788247 0.24798223 0.24801104 0.24800923 0.24802823
 0.24812981 0.24833328 0.24861754 0.24888234 0.2490464  0.24903402
 0.24891168 0.24876349 0.24863581 0.24859354 0.24861324 0.24876754
 0.24894443 0.24913219 0.2492481  0.24926835 0.249183   0.24899013
 0.24881631 0.24868158 0.24863696 0.24864662 0.24864048 0.24861099
 0.24840824 0.2480549  0.24761562 0.24718265 0.24685097 0.24665481
 0.24664955 0.24672006 0.24674664 0.24662784 0.24635501 0.24593942
 0.24556568 0.24535295 0.24529806 0.24541453 0.24554059 0.24558823
 0.24546282 0.24520098 0.24491538 0.24489772 0.24508211 0.2454192
 0.2456118  0.24556966 0.24511631 0.2444136  0.24372122 0.24336348]
