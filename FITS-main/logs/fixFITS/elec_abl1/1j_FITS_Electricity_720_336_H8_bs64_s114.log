Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=258, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_720_j336_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_720_j336_H8_FITS_custom_ftM_sl720_ll48_pl336_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17357
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=258, out_features=378, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4007066112.0
params:  97902.0
Trainable parameters:  97902
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4603653
	speed: 0.8659s/iter; left time: 11603.4682s
Epoch: 1 cost time: 120.83895754814148
Epoch: 1, Steps: 135 | Train Loss: 0.6260243 Vali Loss: 0.3151202 Test Loss: 0.3783557
Validation loss decreased (inf --> 0.315120).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2553878
	speed: 2.1157s/iter; left time: 28067.1286s
Epoch: 2 cost time: 136.63944721221924
Epoch: 2, Steps: 135 | Train Loss: 0.2940996 Vali Loss: 0.1865802 Test Loss: 0.2269204
Validation loss decreased (0.315120 --> 0.186580).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1784789
	speed: 2.3820s/iter; left time: 31277.9317s
Epoch: 3 cost time: 140.5252547264099
Epoch: 3, Steps: 135 | Train Loss: 0.2061014 Vali Loss: 0.1528056 Test Loss: 0.1844499
Validation loss decreased (0.186580 --> 0.152806).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1688544
	speed: 2.1334s/iter; left time: 27725.7931s
Epoch: 4 cost time: 129.34990763664246
Epoch: 4, Steps: 135 | Train Loss: 0.1834608 Vali Loss: 0.1458583 Test Loss: 0.1741366
Validation loss decreased (0.152806 --> 0.145858).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1780663
	speed: 2.2626s/iter; left time: 29098.7399s
Epoch: 5 cost time: 140.172057390213
Epoch: 5, Steps: 135 | Train Loss: 0.1780673 Vali Loss: 0.1442514 Test Loss: 0.1715645
Validation loss decreased (0.145858 --> 0.144251).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1695435
	speed: 2.2911s/iter; left time: 29156.8523s
Epoch: 6 cost time: 136.84286737442017
Epoch: 6, Steps: 135 | Train Loss: 0.1766884 Vali Loss: 0.1440717 Test Loss: 0.1707569
Validation loss decreased (0.144251 --> 0.144072).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1860803
	speed: 2.2736s/iter; left time: 28626.8113s
Epoch: 7 cost time: 145.4189989566803
Epoch: 7, Steps: 135 | Train Loss: 0.1760417 Vali Loss: 0.1439626 Test Loss: 0.1703778
Validation loss decreased (0.144072 --> 0.143963).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1673902
	speed: 2.2610s/iter; left time: 28162.9770s
Epoch: 8 cost time: 132.18392252922058
Epoch: 8, Steps: 135 | Train Loss: 0.1756445 Vali Loss: 0.1436723 Test Loss: 0.1701483
Validation loss decreased (0.143963 --> 0.143672).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1773447
	speed: 2.3098s/iter; left time: 28459.6023s
Epoch: 9 cost time: 141.17580676078796
Epoch: 9, Steps: 135 | Train Loss: 0.1754540 Vali Loss: 0.1435834 Test Loss: 0.1700119
Validation loss decreased (0.143672 --> 0.143583).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1738093
	speed: 2.3489s/iter; left time: 28623.3342s
Epoch: 10 cost time: 143.1031777858734
Epoch: 10, Steps: 135 | Train Loss: 0.1751007 Vali Loss: 0.1436321 Test Loss: 0.1698693
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1743086
	speed: 2.4089s/iter; left time: 29029.4188s
Epoch: 11 cost time: 146.3479790687561
Epoch: 11, Steps: 135 | Train Loss: 0.1751294 Vali Loss: 0.1435347 Test Loss: 0.1697569
Validation loss decreased (0.143583 --> 0.143535).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1679046
	speed: 2.3646s/iter; left time: 28176.9775s
Epoch: 12 cost time: 149.8045539855957
Epoch: 12, Steps: 135 | Train Loss: 0.1749530 Vali Loss: 0.1433548 Test Loss: 0.1697273
Validation loss decreased (0.143535 --> 0.143355).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1800750
	speed: 2.3470s/iter; left time: 27650.1003s
Epoch: 13 cost time: 138.708411693573
Epoch: 13, Steps: 135 | Train Loss: 0.1748647 Vali Loss: 0.1434869 Test Loss: 0.1697057
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1695877
	speed: 2.2644s/iter; left time: 26370.7143s
Epoch: 14 cost time: 136.14403820037842
Epoch: 14, Steps: 135 | Train Loss: 0.1747768 Vali Loss: 0.1434997 Test Loss: 0.1696162
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1637894
	speed: 2.3733s/iter; left time: 27318.4860s
Epoch: 15 cost time: 142.81886529922485
Epoch: 15, Steps: 135 | Train Loss: 0.1746539 Vali Loss: 0.1435716 Test Loss: 0.1695808
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1653073
	speed: 2.2344s/iter; left time: 25418.7529s
Epoch: 16 cost time: 139.81626725196838
Epoch: 16, Steps: 135 | Train Loss: 0.1746345 Vali Loss: 0.1432993 Test Loss: 0.1695551
Validation loss decreased (0.143355 --> 0.143299).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1731224
	speed: 2.2434s/iter; left time: 25217.9258s
Epoch: 17 cost time: 134.75250029563904
Epoch: 17, Steps: 135 | Train Loss: 0.1745923 Vali Loss: 0.1432756 Test Loss: 0.1695398
Validation loss decreased (0.143299 --> 0.143276).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1642740
	speed: 2.2513s/iter; left time: 25002.7345s
Epoch: 18 cost time: 137.98908591270447
Epoch: 18, Steps: 135 | Train Loss: 0.1744994 Vali Loss: 0.1433951 Test Loss: 0.1695072
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1950141
	speed: 2.3179s/iter; left time: 25429.7843s
Epoch: 19 cost time: 138.19540524482727
Epoch: 19, Steps: 135 | Train Loss: 0.1745234 Vali Loss: 0.1436514 Test Loss: 0.1695095
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1763012
	speed: 2.2679s/iter; left time: 24574.9830s
Epoch: 20 cost time: 136.21987628936768
Epoch: 20, Steps: 135 | Train Loss: 0.1744732 Vali Loss: 0.1432058 Test Loss: 0.1694530
Validation loss decreased (0.143276 --> 0.143206).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1754218
	speed: 2.3081s/iter; left time: 24699.1083s
Epoch: 21 cost time: 141.98180389404297
Epoch: 21, Steps: 135 | Train Loss: 0.1744880 Vali Loss: 0.1433112 Test Loss: 0.1694376
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1750936
	speed: 2.4320s/iter; left time: 25696.6498s
Epoch: 22 cost time: 145.41954851150513
Epoch: 22, Steps: 135 | Train Loss: 0.1744003 Vali Loss: 0.1430029 Test Loss: 0.1694287
Validation loss decreased (0.143206 --> 0.143003).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1714434
	speed: 2.2522s/iter; left time: 23492.4158s
Epoch: 23 cost time: 134.2481017112732
Epoch: 23, Steps: 135 | Train Loss: 0.1743254 Vali Loss: 0.1434482 Test Loss: 0.1694232
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1681245
	speed: 2.3110s/iter; left time: 23793.7459s
Epoch: 24 cost time: 144.15901613235474
Epoch: 24, Steps: 135 | Train Loss: 0.1744227 Vali Loss: 0.1432738 Test Loss: 0.1694296
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1686174
	speed: 2.3789s/iter; left time: 24172.5023s
Epoch: 25 cost time: 142.2321002483368
Epoch: 25, Steps: 135 | Train Loss: 0.1742795 Vali Loss: 0.1432312 Test Loss: 0.1694248
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1643581
	speed: 2.2728s/iter; left time: 22786.8084s
Epoch: 26 cost time: 134.67516565322876
Epoch: 26, Steps: 135 | Train Loss: 0.1742871 Vali Loss: 0.1435740 Test Loss: 0.1694058
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1730317
	speed: 2.3099s/iter; left time: 22847.2777s
Epoch: 27 cost time: 147.8409070968628
Epoch: 27, Steps: 135 | Train Loss: 0.1742886 Vali Loss: 0.1430799 Test Loss: 0.1693980
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1790357
	speed: 2.3747s/iter; left time: 23167.3596s
Epoch: 28 cost time: 142.11866784095764
Epoch: 28, Steps: 135 | Train Loss: 0.1743495 Vali Loss: 0.1433542 Test Loss: 0.1693634
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1691490
	speed: 2.2720s/iter; left time: 21859.2549s
Epoch: 29 cost time: 134.92861342430115
Epoch: 29, Steps: 135 | Train Loss: 0.1742765 Vali Loss: 0.1432147 Test Loss: 0.1693505
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1834118
	speed: 2.2181s/iter; left time: 21040.4231s
Epoch: 30 cost time: 137.20341229438782
Epoch: 30, Steps: 135 | Train Loss: 0.1742763 Vali Loss: 0.1432198 Test Loss: 0.1693404
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1778577
	speed: 2.1862s/iter; left time: 20443.5868s
Epoch: 31 cost time: 130.86023116111755
Epoch: 31, Steps: 135 | Train Loss: 0.1741744 Vali Loss: 0.1430703 Test Loss: 0.1693488
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1746185
	speed: 1.9796s/iter; left time: 18243.7643s
Epoch: 32 cost time: 120.05107188224792
Epoch: 32, Steps: 135 | Train Loss: 0.1742322 Vali Loss: 0.1430221 Test Loss: 0.1693361
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1760811
	speed: 2.0294s/iter; left time: 18428.9059s
Epoch: 33 cost time: 123.39114904403687
Epoch: 33, Steps: 135 | Train Loss: 0.1742228 Vali Loss: 0.1430862 Test Loss: 0.1693277
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1743445
	speed: 1.9999s/iter; left time: 17891.2900s
Epoch: 34 cost time: 117.54047536849976
Epoch: 34, Steps: 135 | Train Loss: 0.1742360 Vali Loss: 0.1432350 Test Loss: 0.1693677
EarlyStopping counter: 12 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1638173
	speed: 1.8862s/iter; left time: 16618.8766s
Epoch: 35 cost time: 107.11961603164673
Epoch: 35, Steps: 135 | Train Loss: 0.1742104 Vali Loss: 0.1429663 Test Loss: 0.1693414
Validation loss decreased (0.143003 --> 0.142966).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1855868
	speed: 1.5155s/iter; left time: 13148.5059s
Epoch: 36 cost time: 88.40813064575195
Epoch: 36, Steps: 135 | Train Loss: 0.1741131 Vali Loss: 0.1430363 Test Loss: 0.1693211
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1811038
	speed: 1.6846s/iter; left time: 14388.3710s
Epoch: 37 cost time: 103.43671083450317
Epoch: 37, Steps: 135 | Train Loss: 0.1741536 Vali Loss: 0.1430238 Test Loss: 0.1693407
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1737183
	speed: 1.7970s/iter; left time: 15105.2299s
Epoch: 38 cost time: 107.78792786598206
Epoch: 38, Steps: 135 | Train Loss: 0.1741549 Vali Loss: 0.1430821 Test Loss: 0.1693129
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1682975
	speed: 1.7119s/iter; left time: 14159.4993s
Epoch: 39 cost time: 100.69522166252136
Epoch: 39, Steps: 135 | Train Loss: 0.1741692 Vali Loss: 0.1433168 Test Loss: 0.1693266
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1776502
	speed: 1.6977s/iter; left time: 13812.3598s
Epoch: 40 cost time: 103.17578482627869
Epoch: 40, Steps: 135 | Train Loss: 0.1740845 Vali Loss: 0.1434620 Test Loss: 0.1693171
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1773209
	speed: 1.3952s/iter; left time: 11162.6682s
Epoch: 41 cost time: 63.41000580787659
Epoch: 41, Steps: 135 | Train Loss: 0.1741360 Vali Loss: 0.1434232 Test Loss: 0.1692994
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1653803
	speed: 0.9704s/iter; left time: 7633.3775s
Epoch: 42 cost time: 62.00706934928894
Epoch: 42, Steps: 135 | Train Loss: 0.1741334 Vali Loss: 0.1429500 Test Loss: 0.1693081
Validation loss decreased (0.142966 --> 0.142950).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1679304
	speed: 1.0092s/iter; left time: 7802.0433s
Epoch: 43 cost time: 60.283408641815186
Epoch: 43, Steps: 135 | Train Loss: 0.1740474 Vali Loss: 0.1432970 Test Loss: 0.1693109
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1724031
	speed: 0.9206s/iter; left time: 6993.0356s
Epoch: 44 cost time: 54.61124110221863
Epoch: 44, Steps: 135 | Train Loss: 0.1741720 Vali Loss: 0.1431650 Test Loss: 0.1693147
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1633620
	speed: 0.9197s/iter; left time: 6862.1384s
Epoch: 45 cost time: 58.34241318702698
Epoch: 45, Steps: 135 | Train Loss: 0.1740767 Vali Loss: 0.1429465 Test Loss: 0.1693169
Validation loss decreased (0.142950 --> 0.142947).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1602909
	speed: 0.9515s/iter; left time: 6970.7476s
Epoch: 46 cost time: 57.191216230392456
Epoch: 46, Steps: 135 | Train Loss: 0.1741602 Vali Loss: 0.1433205 Test Loss: 0.1693022
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1684373
	speed: 0.9349s/iter; left time: 6723.0757s
Epoch: 47 cost time: 57.25434970855713
Epoch: 47, Steps: 135 | Train Loss: 0.1740844 Vali Loss: 0.1430680 Test Loss: 0.1693036
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1865560
	speed: 0.9325s/iter; left time: 6579.7851s
Epoch: 48 cost time: 56.08258819580078
Epoch: 48, Steps: 135 | Train Loss: 0.1740651 Vali Loss: 0.1429348 Test Loss: 0.1693080
Validation loss decreased (0.142947 --> 0.142935).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1626394
	speed: 0.9145s/iter; left time: 6329.1012s
Epoch: 49 cost time: 55.45481038093567
Epoch: 49, Steps: 135 | Train Loss: 0.1740018 Vali Loss: 0.1432142 Test Loss: 0.1692908
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1773111
	speed: 0.9709s/iter; left time: 6588.2557s
Epoch: 50 cost time: 60.73117113113403
Epoch: 50, Steps: 135 | Train Loss: 0.1741082 Vali Loss: 0.1432103 Test Loss: 0.1692933
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1753912
	speed: 0.9639s/iter; left time: 6410.7056s
Epoch: 51 cost time: 60.28607702255249
Epoch: 51, Steps: 135 | Train Loss: 0.1741221 Vali Loss: 0.1427609 Test Loss: 0.1692943
Validation loss decreased (0.142935 --> 0.142761).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1604073
	speed: 0.9715s/iter; left time: 6330.5429s
Epoch: 52 cost time: 57.45009756088257
Epoch: 52, Steps: 135 | Train Loss: 0.1740578 Vali Loss: 0.1432903 Test Loss: 0.1693012
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1587385
	speed: 0.9561s/iter; left time: 6101.1659s
Epoch: 53 cost time: 56.82236671447754
Epoch: 53, Steps: 135 | Train Loss: 0.1739923 Vali Loss: 0.1428852 Test Loss: 0.1692869
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1693425
	speed: 1.0130s/iter; left time: 6327.0937s
Epoch: 54 cost time: 61.69651770591736
Epoch: 54, Steps: 135 | Train Loss: 0.1740067 Vali Loss: 0.1431013 Test Loss: 0.1692896
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1753260
	speed: 0.9776s/iter; left time: 5973.8521s
Epoch: 55 cost time: 58.92589616775513
Epoch: 55, Steps: 135 | Train Loss: 0.1740982 Vali Loss: 0.1428588 Test Loss: 0.1692959
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1672679
	speed: 0.9582s/iter; left time: 5725.9477s
Epoch: 56 cost time: 58.424691677093506
Epoch: 56, Steps: 135 | Train Loss: 0.1740260 Vali Loss: 0.1429372 Test Loss: 0.1692925
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.1682245
	speed: 1.0464s/iter; left time: 6111.9716s
Epoch: 57 cost time: 71.79595232009888
Epoch: 57, Steps: 135 | Train Loss: 0.1740674 Vali Loss: 0.1430390 Test Loss: 0.1692854
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1647416
	speed: 1.2378s/iter; left time: 7063.1547s
Epoch: 58 cost time: 73.23214769363403
Epoch: 58, Steps: 135 | Train Loss: 0.1740763 Vali Loss: 0.1430071 Test Loss: 0.1692870
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1679353
	speed: 1.3355s/iter; left time: 7440.1186s
Epoch: 59 cost time: 81.89028692245483
Epoch: 59, Steps: 135 | Train Loss: 0.1740851 Vali Loss: 0.1432982 Test Loss: 0.1692789
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1675964
	speed: 1.2687s/iter; left time: 6896.5847s
Epoch: 60 cost time: 83.29456901550293
Epoch: 60, Steps: 135 | Train Loss: 0.1740886 Vali Loss: 0.1428049 Test Loss: 0.1692794
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1748524
	speed: 1.4287s/iter; left time: 7573.6056s
Epoch: 61 cost time: 87.51668953895569
Epoch: 61, Steps: 135 | Train Loss: 0.1740733 Vali Loss: 0.1427795 Test Loss: 0.1692878
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1638541
	speed: 1.3277s/iter; left time: 6858.7883s
Epoch: 62 cost time: 72.58752799034119
Epoch: 62, Steps: 135 | Train Loss: 0.1740602 Vali Loss: 0.1428018 Test Loss: 0.1692802
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1755256
	speed: 1.3229s/iter; left time: 6655.4929s
Epoch: 63 cost time: 82.16851329803467
Epoch: 63, Steps: 135 | Train Loss: 0.1740142 Vali Loss: 0.1433623 Test Loss: 0.1692773
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1603177
	speed: 1.3149s/iter; left time: 6437.5788s
Epoch: 64 cost time: 78.67095184326172
Epoch: 64, Steps: 135 | Train Loss: 0.1740352 Vali Loss: 0.1432593 Test Loss: 0.1692748
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.1817773
	speed: 1.3977s/iter; left time: 6654.5481s
Epoch: 65 cost time: 82.6193528175354
Epoch: 65, Steps: 135 | Train Loss: 0.1741111 Vali Loss: 0.1430146 Test Loss: 0.1692840
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.1813024
	speed: 1.2865s/iter; left time: 5951.3866s
Epoch: 66 cost time: 84.11798357963562
Epoch: 66, Steps: 135 | Train Loss: 0.1740678 Vali Loss: 0.1431139 Test Loss: 0.1692699
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.1669427
	speed: 1.3922s/iter; left time: 6252.4232s
Epoch: 67 cost time: 86.23184156417847
Epoch: 67, Steps: 135 | Train Loss: 0.1739859 Vali Loss: 0.1433880 Test Loss: 0.1692705
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.1750260
	speed: 1.3016s/iter; left time: 5669.6407s
Epoch: 68 cost time: 73.79820561408997
Epoch: 68, Steps: 135 | Train Loss: 0.1739746 Vali Loss: 0.1431382 Test Loss: 0.1692743
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.1664153
	speed: 1.3049s/iter; left time: 5508.1261s
Epoch: 69 cost time: 83.43014717102051
Epoch: 69, Steps: 135 | Train Loss: 0.1740249 Vali Loss: 0.1431762 Test Loss: 0.1692737
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.1652841
	speed: 1.3845s/iter; left time: 5656.9160s
Epoch: 70 cost time: 85.72194266319275
Epoch: 70, Steps: 135 | Train Loss: 0.1740704 Vali Loss: 0.1429252 Test Loss: 0.1692736
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.1638136
	speed: 1.4279s/iter; left time: 5641.7883s
Epoch: 71 cost time: 86.97525668144226
Epoch: 71, Steps: 135 | Train Loss: 0.1740737 Vali Loss: 0.1429627 Test Loss: 0.1692742
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_720_j336_H8_FITS_custom_ftM_sl720_ll48_pl336_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4925
mse:0.1670873910188675, mae:0.26378026604652405, rse:0.40683016180992126, corr:[0.45977157 0.46086332 0.46251377 0.46256155 0.46357337 0.46336487
 0.46353254 0.46360746 0.46319693 0.4631969  0.4630329  0.46287486
 0.4628934  0.4628533  0.46288985 0.46297717 0.4630415  0.4630153
 0.46300092 0.46301547 0.4628288  0.4627828  0.46300143 0.46314248
 0.4633255  0.46366024 0.46366698 0.46364588 0.4636619  0.46343517
 0.46325454 0.4632014  0.46303207 0.4629365  0.46289295 0.46283263
 0.46284136 0.46287236 0.46289477 0.4629138  0.46294793 0.462945
 0.46284485 0.46273354 0.46263558 0.46250877 0.46255276 0.46267253
 0.4626746  0.4628607  0.4630221  0.46289444 0.4627817  0.4627589
 0.46265498 0.46259245 0.46253482 0.46244255 0.46243578 0.46245906
 0.46244296 0.46244162 0.46248472 0.46250153 0.46246427 0.46246353
 0.46240154 0.4621667  0.46199661 0.46190473 0.4618546  0.4619697
 0.46206215 0.4620435  0.46208397 0.46211725 0.46196827 0.46188983
 0.4619005  0.46180004 0.46171987 0.4616912  0.4616595  0.4616965
 0.46170983 0.46163887 0.46164712 0.46170455 0.46165657 0.46157128
 0.4616081  0.4616159  0.46154293 0.46157813 0.4616405  0.4616644
 0.46174556 0.46183494 0.46181393 0.4618025  0.46177337 0.4616927
 0.46165144 0.4616129  0.4615175  0.46150488 0.46151856 0.461472
 0.46142694 0.4614283  0.4614299  0.46141684 0.46142823 0.46141386
 0.46137178 0.4612952  0.46120426 0.46116775 0.4612563  0.4614251
 0.46156752 0.46166325 0.46171424 0.46168703 0.4616584  0.4616709
 0.46162468 0.46158636 0.4615789  0.46151987 0.4614676  0.46146014
 0.4613923  0.4613388  0.4614153  0.4614475  0.46140814 0.46143764
 0.46142265 0.46119675 0.4610367  0.46096456 0.46081734 0.4608058
 0.46089914 0.46094978 0.46100065 0.4610618  0.46103963 0.4610061
 0.46099803 0.46097142 0.4609253  0.4609005  0.46088138 0.46085677
 0.46084765 0.46081793 0.46079576 0.46085498 0.46092647 0.4609023
 0.46088892 0.46075112 0.46055347 0.4604897  0.4604631  0.4603892
 0.46034682 0.46041638 0.46041587 0.46033633 0.46023604 0.4601404
 0.46003744 0.4599408  0.45985568 0.45976368 0.4596373  0.45953786
 0.45942846 0.45933807 0.45929748 0.45921558 0.45911613 0.45901465
 0.45887253 0.4587273  0.45862162 0.4585094  0.45845926 0.45852143
 0.45861265 0.45875442 0.45885688 0.45890495 0.4588381  0.45874202
 0.45868215 0.45863396 0.45856082 0.45844448 0.45830312 0.45824465
 0.45823276 0.45815727 0.4581162  0.4581035  0.4580875  0.45809603
 0.4580734  0.45792812 0.4578178  0.4577948  0.45779428 0.4579027
 0.45802456 0.45815086 0.45829967 0.45838657 0.45833674 0.45827544
 0.4582538  0.45821866 0.45817298 0.4581038  0.45801973 0.4579386
 0.45787224 0.45779473 0.45775217 0.4577942  0.45784602 0.45778567
 0.45770606 0.45762107 0.45747247 0.45739597 0.45746088 0.4575501
 0.45767054 0.45782855 0.4579004  0.45796606 0.45793697 0.45782447
 0.45777878 0.45773357 0.45763692 0.45754004 0.45745596 0.4573726
 0.45729414 0.45728725 0.4573073  0.45725727 0.45723957 0.45724517
 0.45719954 0.45723173 0.45733047 0.457325   0.4573772  0.45755005
 0.45761925 0.45770687 0.45779678 0.4577772  0.45774192 0.45771942
 0.45759535 0.45746425 0.45734778 0.45720667 0.45712554 0.45710123
 0.45701823 0.4569247  0.45702597 0.45711398 0.45704874 0.45707297
 0.45714504 0.4570302  0.45703402 0.45716727 0.45717627 0.45734152
 0.4575927  0.4576136  0.45765045 0.4576942  0.45760918 0.45754844
 0.457447   0.45724636 0.4570824  0.45694467 0.45676914 0.4566308
 0.4566476  0.45669094 0.45662108 0.45671558 0.45689687 0.45680264
 0.4567572  0.45672637 0.45644572 0.45635816 0.45644855 0.45641074
 0.45649123 0.45658484 0.45651197 0.45652273 0.45638692 0.45618445
 0.45613497 0.4559608  0.45581618 0.45580295 0.45579487 0.455824
 0.4558317  0.45604545 0.45618016 0.4560025  0.45625472 0.45609134
 0.45557874 0.45586887 0.45528778 0.45562407 0.45594943 0.4563447 ]
