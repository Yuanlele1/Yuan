Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=74, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_360_j720_H4', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_360_j720_H4_FITS_custom_ftM_sl360_ll48_pl720_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17333
val 1913
test 4541
Model(
  (freq_upsampler): Linear(in_features=74, out_features=222, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  674993664.0
params:  16650.0
Trainable parameters:  16650
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 1.0202001
	speed: 1.0987s/iter; left time: 14723.6796s
Epoch: 1 cost time: 147.85006499290466
Epoch: 1, Steps: 135 | Train Loss: 1.2083073 Vali Loss: 0.7890687 Test Loss: 0.9201331
Validation loss decreased (inf --> 0.789069).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.7232388
	speed: 2.3298s/iter; left time: 30906.5414s
Epoch: 2 cost time: 131.3790545463562
Epoch: 2, Steps: 135 | Train Loss: 0.7800106 Vali Loss: 0.6272715 Test Loss: 0.7416977
Validation loss decreased (0.789069 --> 0.627272).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.6210873
	speed: 2.3155s/iter; left time: 30405.4678s
Epoch: 3 cost time: 133.1863570213318
Epoch: 3, Steps: 135 | Train Loss: 0.6553021 Vali Loss: 0.5587222 Test Loss: 0.6650938
Validation loss decreased (0.627272 --> 0.558722).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.5818937
	speed: 2.2388s/iter; left time: 29095.6056s
Epoch: 4 cost time: 136.5333182811737
Epoch: 4, Steps: 135 | Train Loss: 0.5839642 Vali Loss: 0.5065388 Test Loss: 0.6057158
Validation loss decreased (0.558722 --> 0.506539).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.5034015
	speed: 1.9693s/iter; left time: 25327.6806s
Epoch: 5 cost time: 106.6048800945282
Epoch: 5, Steps: 135 | Train Loss: 0.5273929 Vali Loss: 0.4637924 Test Loss: 0.5562416
Validation loss decreased (0.506539 --> 0.463792).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4721756
	speed: 1.6949s/iter; left time: 21568.6784s
Epoch: 6 cost time: 99.19531011581421
Epoch: 6, Steps: 135 | Train Loss: 0.4800315 Vali Loss: 0.4263317 Test Loss: 0.5130131
Validation loss decreased (0.463792 --> 0.426332).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4365937
	speed: 1.7813s/iter; left time: 22428.1992s
Epoch: 7 cost time: 113.66665720939636
Epoch: 7, Steps: 135 | Train Loss: 0.4397867 Vali Loss: 0.3955078 Test Loss: 0.4773071
Validation loss decreased (0.426332 --> 0.395508).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4030233
	speed: 2.1484s/iter; left time: 26760.4603s
Epoch: 8 cost time: 127.83605718612671
Epoch: 8, Steps: 135 | Train Loss: 0.4053626 Vali Loss: 0.3690615 Test Loss: 0.4465829
Validation loss decreased (0.395508 --> 0.369061).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3750784
	speed: 1.8339s/iter; left time: 22595.5686s
Epoch: 9 cost time: 117.87745666503906
Epoch: 9, Steps: 135 | Train Loss: 0.3758245 Vali Loss: 0.3450308 Test Loss: 0.4184285
Validation loss decreased (0.369061 --> 0.345031).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3583724
	speed: 2.0412s/iter; left time: 24874.5782s
Epoch: 10 cost time: 122.45990943908691
Epoch: 10, Steps: 135 | Train Loss: 0.3503002 Vali Loss: 0.3259397 Test Loss: 0.3959415
Validation loss decreased (0.345031 --> 0.325940).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3287408
	speed: 1.9839s/iter; left time: 23907.6929s
Epoch: 11 cost time: 120.03540754318237
Epoch: 11, Steps: 135 | Train Loss: 0.3283147 Vali Loss: 0.3087875 Test Loss: 0.3754259
Validation loss decreased (0.325940 --> 0.308787).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3093431
	speed: 2.1165s/iter; left time: 25219.7332s
Epoch: 12 cost time: 130.7124307155609
Epoch: 12, Steps: 135 | Train Loss: 0.3092308 Vali Loss: 0.2939596 Test Loss: 0.3581601
Validation loss decreased (0.308787 --> 0.293960).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2786701
	speed: 2.1103s/iter; left time: 24861.9460s
Epoch: 13 cost time: 113.25622391700745
Epoch: 13, Steps: 135 | Train Loss: 0.2926146 Vali Loss: 0.2810342 Test Loss: 0.3423292
Validation loss decreased (0.293960 --> 0.281034).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2674755
	speed: 1.5541s/iter; left time: 18098.8331s
Epoch: 14 cost time: 95.25202512741089
Epoch: 14, Steps: 135 | Train Loss: 0.2780772 Vali Loss: 0.2701373 Test Loss: 0.3290932
Validation loss decreased (0.281034 --> 0.270137).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2729558
	speed: 1.7290s/iter; left time: 19902.2509s
Epoch: 15 cost time: 107.74690818786621
Epoch: 15, Steps: 135 | Train Loss: 0.2654010 Vali Loss: 0.2602014 Test Loss: 0.3170348
Validation loss decreased (0.270137 --> 0.260201).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2534282
	speed: 1.6790s/iter; left time: 19100.3861s
Epoch: 16 cost time: 94.06971263885498
Epoch: 16, Steps: 135 | Train Loss: 0.2542619 Vali Loss: 0.2519334 Test Loss: 0.3069430
Validation loss decreased (0.260201 --> 0.251933).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2263228
	speed: 1.6219s/iter; left time: 18231.5161s
Epoch: 17 cost time: 91.95351457595825
Epoch: 17, Steps: 135 | Train Loss: 0.2446237 Vali Loss: 0.2446562 Test Loss: 0.2979554
Validation loss decreased (0.251933 --> 0.244656).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2356678
	speed: 1.4307s/iter; left time: 15888.8089s
Epoch: 18 cost time: 88.23768520355225
Epoch: 18, Steps: 135 | Train Loss: 0.2361359 Vali Loss: 0.2383658 Test Loss: 0.2898260
Validation loss decreased (0.244656 --> 0.238366).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2274297
	speed: 1.4204s/iter; left time: 15583.4819s
Epoch: 19 cost time: 84.98518300056458
Epoch: 19, Steps: 135 | Train Loss: 0.2285943 Vali Loss: 0.2324531 Test Loss: 0.2829306
Validation loss decreased (0.238366 --> 0.232453).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2182954
	speed: 1.4889s/iter; left time: 16133.2682s
Epoch: 20 cost time: 93.46388578414917
Epoch: 20, Steps: 135 | Train Loss: 0.2220172 Vali Loss: 0.2274384 Test Loss: 0.2765464
Validation loss decreased (0.232453 --> 0.227438).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2137616
	speed: 1.4916s/iter; left time: 15961.7057s
Epoch: 21 cost time: 92.99158692359924
Epoch: 21, Steps: 135 | Train Loss: 0.2161806 Vali Loss: 0.2233240 Test Loss: 0.2710494
Validation loss decreased (0.227438 --> 0.223324).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2112959
	speed: 1.4861s/iter; left time: 15702.0763s
Epoch: 22 cost time: 84.63343167304993
Epoch: 22, Steps: 135 | Train Loss: 0.2110420 Vali Loss: 0.2195581 Test Loss: 0.2661924
Validation loss decreased (0.223324 --> 0.219558).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2082571
	speed: 1.4540s/iter; left time: 15166.6682s
Epoch: 23 cost time: 85.11836457252502
Epoch: 23, Steps: 135 | Train Loss: 0.2064944 Vali Loss: 0.2160425 Test Loss: 0.2617578
Validation loss decreased (0.219558 --> 0.216043).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1916894
	speed: 1.3805s/iter; left time: 14213.4315s
Epoch: 24 cost time: 81.00100231170654
Epoch: 24, Steps: 135 | Train Loss: 0.2025603 Vali Loss: 0.2133144 Test Loss: 0.2579912
Validation loss decreased (0.216043 --> 0.213314).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2020237
	speed: 1.3602s/iter; left time: 13820.8442s
Epoch: 25 cost time: 82.04688930511475
Epoch: 25, Steps: 135 | Train Loss: 0.1989181 Vali Loss: 0.2108379 Test Loss: 0.2546418
Validation loss decreased (0.213314 --> 0.210838).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2071847
	speed: 1.3296s/iter; left time: 13330.8829s
Epoch: 26 cost time: 82.42865920066833
Epoch: 26, Steps: 135 | Train Loss: 0.1958184 Vali Loss: 0.2085201 Test Loss: 0.2516257
Validation loss decreased (0.210838 --> 0.208520).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1944613
	speed: 1.3219s/iter; left time: 13074.9826s
Epoch: 27 cost time: 76.70130896568298
Epoch: 27, Steps: 135 | Train Loss: 0.1930138 Vali Loss: 0.2066660 Test Loss: 0.2489560
Validation loss decreased (0.208520 --> 0.206666).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1819428
	speed: 1.3597s/iter; left time: 13265.4872s
Epoch: 28 cost time: 85.42007327079773
Epoch: 28, Steps: 135 | Train Loss: 0.1905269 Vali Loss: 0.2048788 Test Loss: 0.2465747
Validation loss decreased (0.206666 --> 0.204879).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1889558
	speed: 1.3495s/iter; left time: 12983.7520s
Epoch: 29 cost time: 78.40104675292969
Epoch: 29, Steps: 135 | Train Loss: 0.1883191 Vali Loss: 0.2034212 Test Loss: 0.2442333
Validation loss decreased (0.204879 --> 0.203421).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1809634
	speed: 1.3426s/iter; left time: 12735.4480s
Epoch: 30 cost time: 80.49520540237427
Epoch: 30, Steps: 135 | Train Loss: 0.1863736 Vali Loss: 0.2020818 Test Loss: 0.2423761
Validation loss decreased (0.203421 --> 0.202082).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1724187
	speed: 1.3279s/iter; left time: 12417.4662s
Epoch: 31 cost time: 76.59728527069092
Epoch: 31, Steps: 135 | Train Loss: 0.1846448 Vali Loss: 0.2005362 Test Loss: 0.2407013
Validation loss decreased (0.202082 --> 0.200536).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1865267
	speed: 1.2409s/iter; left time: 11436.5578s
Epoch: 32 cost time: 75.54759383201599
Epoch: 32, Steps: 135 | Train Loss: 0.1831214 Vali Loss: 0.1998834 Test Loss: 0.2391392
Validation loss decreased (0.200536 --> 0.199883).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1864265
	speed: 1.3641s/iter; left time: 12387.8093s
Epoch: 33 cost time: 80.45826244354248
Epoch: 33, Steps: 135 | Train Loss: 0.1816626 Vali Loss: 0.1989106 Test Loss: 0.2378329
Validation loss decreased (0.199883 --> 0.198911).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1747548
	speed: 1.3467s/iter; left time: 12047.4722s
Epoch: 34 cost time: 82.29428362846375
Epoch: 34, Steps: 135 | Train Loss: 0.1804892 Vali Loss: 0.1980945 Test Loss: 0.2366238
Validation loss decreased (0.198911 --> 0.198095).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1749231
	speed: 1.2787s/iter; left time: 11266.2030s
Epoch: 35 cost time: 72.42915987968445
Epoch: 35, Steps: 135 | Train Loss: 0.1793877 Vali Loss: 0.1972988 Test Loss: 0.2354441
Validation loss decreased (0.198095 --> 0.197299).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1699388
	speed: 1.3258s/iter; left time: 11502.3326s
Epoch: 36 cost time: 90.81578373908997
Epoch: 36, Steps: 135 | Train Loss: 0.1783546 Vali Loss: 0.1965585 Test Loss: 0.2344653
Validation loss decreased (0.197299 --> 0.196558).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1709915
	speed: 1.7059s/iter; left time: 14570.3466s
Epoch: 37 cost time: 103.91610550880432
Epoch: 37, Steps: 135 | Train Loss: 0.1774827 Vali Loss: 0.1960116 Test Loss: 0.2335790
Validation loss decreased (0.196558 --> 0.196012).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1664864
	speed: 1.6606s/iter; left time: 13959.3266s
Epoch: 38 cost time: 97.36379075050354
Epoch: 38, Steps: 135 | Train Loss: 0.1767410 Vali Loss: 0.1956966 Test Loss: 0.2328252
Validation loss decreased (0.196012 --> 0.195697).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1805313
	speed: 1.9869s/iter; left time: 16433.4057s
Epoch: 39 cost time: 140.23944735527039
Epoch: 39, Steps: 135 | Train Loss: 0.1760354 Vali Loss: 0.1954343 Test Loss: 0.2320899
Validation loss decreased (0.195697 --> 0.195434).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1738129
	speed: 2.5018s/iter; left time: 20354.7664s
Epoch: 40 cost time: 140.40131163597107
Epoch: 40, Steps: 135 | Train Loss: 0.1754216 Vali Loss: 0.1950090 Test Loss: 0.2314302
Validation loss decreased (0.195434 --> 0.195009).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1763550
	speed: 2.6983s/iter; left time: 21588.9220s
Epoch: 41 cost time: 157.78205013275146
Epoch: 41, Steps: 135 | Train Loss: 0.1748350 Vali Loss: 0.1942663 Test Loss: 0.2308484
Validation loss decreased (0.195009 --> 0.194266).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1722086
	speed: 2.8226s/iter; left time: 22202.4700s
Epoch: 42 cost time: 165.32150197029114
Epoch: 42, Steps: 135 | Train Loss: 0.1743832 Vali Loss: 0.1944184 Test Loss: 0.2302938
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1854096
	speed: 2.9085s/iter; left time: 22485.8614s
Epoch: 43 cost time: 164.1581313610077
Epoch: 43, Steps: 135 | Train Loss: 0.1738794 Vali Loss: 0.1939975 Test Loss: 0.2298096
Validation loss decreased (0.194266 --> 0.193998).  Saving model ...
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1675551
	speed: 2.5976s/iter; left time: 19731.2686s
Epoch: 44 cost time: 136.73290395736694
Epoch: 44, Steps: 135 | Train Loss: 0.1735431 Vali Loss: 0.1942247 Test Loss: 0.2294009
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1623216
	speed: 2.8365s/iter; left time: 21163.2865s
Epoch: 45 cost time: 163.46049189567566
Epoch: 45, Steps: 135 | Train Loss: 0.1731269 Vali Loss: 0.1934887 Test Loss: 0.2290540
Validation loss decreased (0.193998 --> 0.193489).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1729638
	speed: 2.9221s/iter; left time: 21407.4343s
Epoch: 46 cost time: 168.196941614151
Epoch: 46, Steps: 135 | Train Loss: 0.1728219 Vali Loss: 0.1932758 Test Loss: 0.2286900
Validation loss decreased (0.193489 --> 0.193276).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1718363
	speed: 2.9365s/iter; left time: 21116.2221s
Epoch: 47 cost time: 172.4497790336609
Epoch: 47, Steps: 135 | Train Loss: 0.1725473 Vali Loss: 0.1933059 Test Loss: 0.2283701
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1709441
	speed: 2.6782s/iter; left time: 18897.0466s
Epoch: 48 cost time: 146.66465544700623
Epoch: 48, Steps: 135 | Train Loss: 0.1722932 Vali Loss: 0.1932755 Test Loss: 0.2280845
Validation loss decreased (0.193276 --> 0.193276).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1710522
	speed: 2.4506s/iter; left time: 16960.9166s
Epoch: 49 cost time: 147.03840923309326
Epoch: 49, Steps: 135 | Train Loss: 0.1720570 Vali Loss: 0.1929102 Test Loss: 0.2278076
Validation loss decreased (0.193276 --> 0.192910).  Saving model ...
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1759681
	speed: 2.2336s/iter; left time: 15157.4559s
Epoch: 50 cost time: 125.7425765991211
Epoch: 50, Steps: 135 | Train Loss: 0.1718581 Vali Loss: 0.1931018 Test Loss: 0.2275875
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1667989
	speed: 2.5236s/iter; left time: 16784.6920s
Epoch: 51 cost time: 166.71732807159424
Epoch: 51, Steps: 135 | Train Loss: 0.1716258 Vali Loss: 0.1927536 Test Loss: 0.2273662
Validation loss decreased (0.192910 --> 0.192754).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1702082
	speed: 3.0466s/iter; left time: 19851.7075s
Epoch: 52 cost time: 183.67673087120056
Epoch: 52, Steps: 135 | Train Loss: 0.1714429 Vali Loss: 0.1928895 Test Loss: 0.2271797
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1635552
	speed: 3.0283s/iter; left time: 19323.4343s
Epoch: 53 cost time: 176.7276999950409
Epoch: 53, Steps: 135 | Train Loss: 0.1713395 Vali Loss: 0.1928333 Test Loss: 0.2270050
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1718999
	speed: 3.3979s/iter; left time: 21223.3070s
Epoch: 54 cost time: 217.71226334571838
Epoch: 54, Steps: 135 | Train Loss: 0.1711866 Vali Loss: 0.1927376 Test Loss: 0.2268743
Validation loss decreased (0.192754 --> 0.192738).  Saving model ...
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1763022
	speed: 3.8715s/iter; left time: 23658.6972s
Epoch: 55 cost time: 225.3868486881256
Epoch: 55, Steps: 135 | Train Loss: 0.1710609 Vali Loss: 0.1926303 Test Loss: 0.2267167
Validation loss decreased (0.192738 --> 0.192630).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1620861
	speed: 2.7348s/iter; left time: 16343.4108s
Epoch: 56 cost time: 148.38532066345215
Epoch: 56, Steps: 135 | Train Loss: 0.1709982 Vali Loss: 0.1926515 Test Loss: 0.2265801
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.1657253
	speed: 3.6051s/iter; left time: 21057.4694s
Epoch: 57 cost time: 222.22002744674683
Epoch: 57, Steps: 135 | Train Loss: 0.1708679 Vali Loss: 0.1927275 Test Loss: 0.2264790
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1813504
	speed: 3.9641s/iter; left time: 22619.0943s
Epoch: 58 cost time: 239.94703364372253
Epoch: 58, Steps: 135 | Train Loss: 0.1708046 Vali Loss: 0.1927812 Test Loss: 0.2263596
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1663157
	speed: 3.9772s/iter; left time: 22157.1964s
Epoch: 59 cost time: 239.31290793418884
Epoch: 59, Steps: 135 | Train Loss: 0.1707178 Vali Loss: 0.1927631 Test Loss: 0.2262677
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1661662
	speed: 4.0409s/iter; left time: 21966.1816s
Epoch: 60 cost time: 237.88134813308716
Epoch: 60, Steps: 135 | Train Loss: 0.1706494 Vali Loss: 0.1929840 Test Loss: 0.2261830
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1576430
	speed: 3.3557s/iter; left time: 17788.5940s
Epoch: 61 cost time: 165.75296902656555
Epoch: 61, Steps: 135 | Train Loss: 0.1705810 Vali Loss: 0.1926600 Test Loss: 0.2260964
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1713802
	speed: 2.6550s/iter; left time: 13715.6830s
Epoch: 62 cost time: 151.39165043830872
Epoch: 62, Steps: 135 | Train Loss: 0.1705201 Vali Loss: 0.1928396 Test Loss: 0.2260216
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1760276
	speed: 2.5530s/iter; left time: 12844.3312s
Epoch: 63 cost time: 166.33177733421326
Epoch: 63, Steps: 135 | Train Loss: 0.1704569 Vali Loss: 0.1927192 Test Loss: 0.2259560
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1712790
	speed: 3.1980s/iter; left time: 15657.1775s
Epoch: 64 cost time: 185.8963692188263
Epoch: 64, Steps: 135 | Train Loss: 0.1703853 Vali Loss: 0.1927305 Test Loss: 0.2258951
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.1719884
	speed: 3.0027s/iter; left time: 14295.8367s
Epoch: 65 cost time: 168.34823489189148
Epoch: 65, Steps: 135 | Train Loss: 0.1704032 Vali Loss: 0.1926120 Test Loss: 0.2258368
Validation loss decreased (0.192630 --> 0.192612).  Saving model ...
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.1635181
	speed: 2.9593s/iter; left time: 13689.5754s
Epoch: 66 cost time: 175.35229992866516
Epoch: 66, Steps: 135 | Train Loss: 0.1703573 Vali Loss: 0.1925308 Test Loss: 0.2257889
Validation loss decreased (0.192612 --> 0.192531).  Saving model ...
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.1658739
	speed: 3.0192s/iter; left time: 13559.2474s
Epoch: 67 cost time: 172.9895429611206
Epoch: 67, Steps: 135 | Train Loss: 0.1703105 Vali Loss: 0.1928909 Test Loss: 0.2257406
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.1663961
	speed: 2.5123s/iter; left time: 10943.3858s
Epoch: 68 cost time: 147.52365636825562
Epoch: 68, Steps: 135 | Train Loss: 0.1702808 Vali Loss: 0.1928325 Test Loss: 0.2256997
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.1616249
	speed: 2.9047s/iter; left time: 12260.6434s
Epoch: 69 cost time: 182.42074131965637
Epoch: 69, Steps: 135 | Train Loss: 0.1702833 Vali Loss: 0.1926623 Test Loss: 0.2256593
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.1590538
	speed: 2.4804s/iter; left time: 10134.8339s
Epoch: 70 cost time: 146.9641773700714
Epoch: 70, Steps: 135 | Train Loss: 0.1702441 Vali Loss: 0.1925452 Test Loss: 0.2256233
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.1704534
	speed: 2.8498s/iter; left time: 11259.5589s
Epoch: 71 cost time: 201.65518164634705
Epoch: 71, Steps: 135 | Train Loss: 0.1702196 Vali Loss: 0.1925141 Test Loss: 0.2255909
Validation loss decreased (0.192531 --> 0.192514).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.1733885
	speed: 3.5159s/iter; left time: 13416.5259s
Epoch: 72 cost time: 204.25228357315063
Epoch: 72, Steps: 135 | Train Loss: 0.1701917 Vali Loss: 0.1930753 Test Loss: 0.2255585
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.1823089
	speed: 3.2166s/iter; left time: 11840.3208s
Epoch: 73 cost time: 181.3393964767456
Epoch: 73, Steps: 135 | Train Loss: 0.1702220 Vali Loss: 0.1931179 Test Loss: 0.2255327
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.1726143
	speed: 2.4097s/iter; left time: 8544.8737s
Epoch: 74 cost time: 139.91276741027832
Epoch: 74, Steps: 135 | Train Loss: 0.1701794 Vali Loss: 0.1925794 Test Loss: 0.2255059
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.1620919
	speed: 2.7989s/iter; left time: 9546.8841s
Epoch: 75 cost time: 149.112242937088
Epoch: 75, Steps: 135 | Train Loss: 0.1701299 Vali Loss: 0.1928623 Test Loss: 0.2254822
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.1617025
	speed: 1.7853s/iter; left time: 5848.6160s
Epoch: 76 cost time: 105.67194962501526
Epoch: 76, Steps: 135 | Train Loss: 0.1701024 Vali Loss: 0.1929057 Test Loss: 0.2254624
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.1672813
	speed: 2.5086s/iter; left time: 7879.4032s
Epoch: 77 cost time: 158.24068522453308
Epoch: 77, Steps: 135 | Train Loss: 0.1701314 Vali Loss: 0.1926424 Test Loss: 0.2254419
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.1731899
	speed: 2.6072s/iter; left time: 7837.1094s
Epoch: 78 cost time: 134.6845784187317
Epoch: 78, Steps: 135 | Train Loss: 0.1701182 Vali Loss: 0.1926428 Test Loss: 0.2254214
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.1686882
	speed: 2.1867s/iter; left time: 6278.1305s
Epoch: 79 cost time: 140.98089790344238
Epoch: 79, Steps: 135 | Train Loss: 0.1701623 Vali Loss: 0.1927055 Test Loss: 0.2254065
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.1693995
	speed: 2.0514s/iter; left time: 5612.5459s
Epoch: 80 cost time: 121.52285099029541
Epoch: 80, Steps: 135 | Train Loss: 0.1700666 Vali Loss: 0.1929753 Test Loss: 0.2253912
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.1610470
	speed: 2.0751s/iter; left time: 5397.4140s
Epoch: 81 cost time: 119.34419226646423
Epoch: 81, Steps: 135 | Train Loss: 0.1701139 Vali Loss: 0.1931177 Test Loss: 0.2253788
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.1726335
	speed: 2.0339s/iter; left time: 5015.5049s
Epoch: 82 cost time: 117.89856028556824
Epoch: 82, Steps: 135 | Train Loss: 0.1700757 Vali Loss: 0.1926470 Test Loss: 0.2253652
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.1687646
	speed: 2.1155s/iter; left time: 4931.2641s
Epoch: 83 cost time: 112.86458253860474
Epoch: 83, Steps: 135 | Train Loss: 0.1700679 Vali Loss: 0.1928479 Test Loss: 0.2253519
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.1715571
	speed: 1.9635s/iter; left time: 4311.8992s
Epoch: 84 cost time: 115.3520028591156
Epoch: 84, Steps: 135 | Train Loss: 0.1700830 Vali Loss: 0.1928082 Test Loss: 0.2253398
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.1675674
	speed: 2.1678s/iter; left time: 4467.8333s
Epoch: 85 cost time: 119.43201494216919
Epoch: 85, Steps: 135 | Train Loss: 0.1701230 Vali Loss: 0.1930519 Test Loss: 0.2253290
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.1679886
	speed: 1.8838s/iter; left time: 3628.1936s
Epoch: 86 cost time: 109.10358214378357
Epoch: 86, Steps: 135 | Train Loss: 0.1700441 Vali Loss: 0.1928840 Test Loss: 0.2253202
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.1640624
	speed: 1.8195s/iter; left time: 3258.7709s
Epoch: 87 cost time: 104.353187084198
Epoch: 87, Steps: 135 | Train Loss: 0.1700313 Vali Loss: 0.1930362 Test Loss: 0.2253130
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.1705028
	speed: 1.7160s/iter; left time: 2841.6712s
Epoch: 88 cost time: 100.38756132125854
Epoch: 88, Steps: 135 | Train Loss: 0.1700604 Vali Loss: 0.1929400 Test Loss: 0.2253042
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.1676444
	speed: 1.5655s/iter; left time: 2381.1915s
Epoch: 89 cost time: 84.89342832565308
Epoch: 89, Steps: 135 | Train Loss: 0.1700138 Vali Loss: 0.1926498 Test Loss: 0.2252969
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.1636860
	speed: 1.6261s/iter; left time: 2253.7136s
Epoch: 90 cost time: 101.88747835159302
Epoch: 90, Steps: 135 | Train Loss: 0.1700657 Vali Loss: 0.1929346 Test Loss: 0.2252902
EarlyStopping counter: 19 out of 20
Updating learning rate to 5.204402478767869e-06
	iters: 100, epoch: 91 | loss: 0.1723078
	speed: 1.3529s/iter; left time: 1692.4469s
Epoch: 91 cost time: 74.4727852344513
Epoch: 91, Steps: 135 | Train Loss: 0.1699939 Vali Loss: 0.1927871 Test Loss: 0.2252840
EarlyStopping counter: 20 out of 20
Early stopping
train 17333
val 1913
test 4541
Model(
  (freq_upsampler): Linear(in_features=74, out_features=222, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  674993664.0
params:  16650.0
Trainable parameters:  16650
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2358100
	speed: 0.8629s/iter; left time: 11564.0551s
Epoch: 1 cost time: 113.1364541053772
Epoch: 1, Steps: 135 | Train Loss: 0.2382490 Vali Loss: 0.1928803 Test Loss: 0.2247445
Validation loss decreased (inf --> 0.192880).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2375153
	speed: 2.8549s/iter; left time: 37872.6721s
Epoch: 2 cost time: 188.78042197227478
Epoch: 2, Steps: 135 | Train Loss: 0.2380081 Vali Loss: 0.1924877 Test Loss: 0.2247095
Validation loss decreased (0.192880 --> 0.192488).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2492456
	speed: 3.2800s/iter; left time: 43069.7279s
Epoch: 3 cost time: 204.13243532180786
Epoch: 3, Steps: 135 | Train Loss: 0.2378885 Vali Loss: 0.1923996 Test Loss: 0.2247076
Validation loss decreased (0.192488 --> 0.192400).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2229667
	speed: 3.6473s/iter; left time: 47400.8379s
Epoch: 4 cost time: 217.18857216835022
Epoch: 4, Steps: 135 | Train Loss: 0.2379248 Vali Loss: 0.1925189 Test Loss: 0.2245915
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2413407
	speed: 3.5987s/iter; left time: 46283.3048s
Epoch: 5 cost time: 207.07798886299133
Epoch: 5, Steps: 135 | Train Loss: 0.2378552 Vali Loss: 0.1923444 Test Loss: 0.2246504
Validation loss decreased (0.192400 --> 0.192344).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2623547
	speed: 3.6144s/iter; left time: 45996.3611s
Epoch: 6 cost time: 215.28086614608765
Epoch: 6, Steps: 135 | Train Loss: 0.2379101 Vali Loss: 0.1923126 Test Loss: 0.2246344
Validation loss decreased (0.192344 --> 0.192313).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2271141
	speed: 3.3449s/iter; left time: 42116.1469s
Epoch: 7 cost time: 192.41153264045715
Epoch: 7, Steps: 135 | Train Loss: 0.2378551 Vali Loss: 0.1923804 Test Loss: 0.2245869
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2295615
	speed: 3.2725s/iter; left time: 40762.1604s
Epoch: 8 cost time: 188.0853660106659
Epoch: 8, Steps: 135 | Train Loss: 0.2379059 Vali Loss: 0.1922356 Test Loss: 0.2246263
Validation loss decreased (0.192313 --> 0.192236).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2522131
	speed: 3.4497s/iter; left time: 42503.6188s
Epoch: 9 cost time: 191.35374355316162
Epoch: 9, Steps: 135 | Train Loss: 0.2378545 Vali Loss: 0.1926898 Test Loss: 0.2245760
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2557489
	speed: 3.2305s/iter; left time: 39366.5681s
Epoch: 10 cost time: 184.56237149238586
Epoch: 10, Steps: 135 | Train Loss: 0.2378209 Vali Loss: 0.1923397 Test Loss: 0.2245362
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2397038
	speed: 3.3702s/iter; left time: 40614.0901s
Epoch: 11 cost time: 195.25203323364258
Epoch: 11, Steps: 135 | Train Loss: 0.2378591 Vali Loss: 0.1921115 Test Loss: 0.2246553
Validation loss decreased (0.192236 --> 0.192111).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2437387
	speed: 3.3053s/iter; left time: 39386.5342s
Epoch: 12 cost time: 196.4217984676361
Epoch: 12, Steps: 135 | Train Loss: 0.2378489 Vali Loss: 0.1921043 Test Loss: 0.2246077
Validation loss decreased (0.192111 --> 0.192104).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2352419
	speed: 3.2717s/iter; left time: 38543.5412s
Epoch: 13 cost time: 199.14567375183105
Epoch: 13, Steps: 135 | Train Loss: 0.2378152 Vali Loss: 0.1922070 Test Loss: 0.2246453
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2392883
	speed: 3.4147s/iter; left time: 39767.0295s
Epoch: 14 cost time: 203.0392599105835
Epoch: 14, Steps: 135 | Train Loss: 0.2377911 Vali Loss: 0.1925659 Test Loss: 0.2245679
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2375061
	speed: 3.3530s/iter; left time: 38596.8630s
Epoch: 15 cost time: 197.551744222641
Epoch: 15, Steps: 135 | Train Loss: 0.2377874 Vali Loss: 0.1923037 Test Loss: 0.2246153
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2440066
	speed: 3.3890s/iter; left time: 38553.6513s
Epoch: 16 cost time: 196.8513000011444
Epoch: 16, Steps: 135 | Train Loss: 0.2377799 Vali Loss: 0.1919732 Test Loss: 0.2245852
Validation loss decreased (0.192104 --> 0.191973).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2258381
	speed: 3.1327s/iter; left time: 35214.8643s
Epoch: 17 cost time: 174.54514288902283
Epoch: 17, Steps: 135 | Train Loss: 0.2377695 Vali Loss: 0.1921616 Test Loss: 0.2245640
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2400277
	speed: 3.0020s/iter; left time: 33339.8763s
Epoch: 18 cost time: 166.71212077140808
Epoch: 18, Steps: 135 | Train Loss: 0.2377731 Vali Loss: 0.1921397 Test Loss: 0.2245825
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2291221
	speed: 2.9876s/iter; left time: 32776.7210s
Epoch: 19 cost time: 180.73104763031006
Epoch: 19, Steps: 135 | Train Loss: 0.2377288 Vali Loss: 0.1923500 Test Loss: 0.2245823
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2232361
	speed: 2.9047s/iter; left time: 31474.8886s
Epoch: 20 cost time: 164.69424700737
Epoch: 20, Steps: 135 | Train Loss: 0.2377299 Vali Loss: 0.1921787 Test Loss: 0.2245347
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2466065
	speed: 2.6114s/iter; left time: 27945.0224s
Epoch: 21 cost time: 162.43854093551636
Epoch: 21, Steps: 135 | Train Loss: 0.2377936 Vali Loss: 0.1919812 Test Loss: 0.2245777
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2418503
	speed: 2.6612s/iter; left time: 28118.0719s
Epoch: 22 cost time: 152.98856139183044
Epoch: 22, Steps: 135 | Train Loss: 0.2377224 Vali Loss: 0.1921605 Test Loss: 0.2245274
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2426375
	speed: 2.5690s/iter; left time: 26797.0212s
Epoch: 23 cost time: 151.41073870658875
Epoch: 23, Steps: 135 | Train Loss: 0.2377790 Vali Loss: 0.1919917 Test Loss: 0.2245611
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2360344
	speed: 2.6515s/iter; left time: 27299.3691s
Epoch: 24 cost time: 162.97076988220215
Epoch: 24, Steps: 135 | Train Loss: 0.2377191 Vali Loss: 0.1923731 Test Loss: 0.2245726
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2306916
	speed: 2.7474s/iter; left time: 27916.1253s
Epoch: 25 cost time: 168.65882515907288
Epoch: 25, Steps: 135 | Train Loss: 0.2377623 Vali Loss: 0.1919639 Test Loss: 0.2245813
Validation loss decreased (0.191973 --> 0.191964).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2323507
	speed: 2.7880s/iter; left time: 27952.0839s
Epoch: 26 cost time: 163.1659917831421
Epoch: 26, Steps: 135 | Train Loss: 0.2377115 Vali Loss: 0.1918031 Test Loss: 0.2245658
Validation loss decreased (0.191964 --> 0.191803).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2379371
	speed: 2.7453s/iter; left time: 27153.9174s
Epoch: 27 cost time: 165.57461953163147
Epoch: 27, Steps: 135 | Train Loss: 0.2376936 Vali Loss: 0.1920901 Test Loss: 0.2245473
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2346037
	speed: 2.7262s/iter; left time: 26596.6294s
Epoch: 28 cost time: 161.5600335597992
Epoch: 28, Steps: 135 | Train Loss: 0.2377099 Vali Loss: 0.1919262 Test Loss: 0.2245535
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2384011
	speed: 2.5243s/iter; left time: 24286.2383s
Epoch: 29 cost time: 145.20890974998474
Epoch: 29, Steps: 135 | Train Loss: 0.2376358 Vali Loss: 0.1919435 Test Loss: 0.2245670
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2291817
	speed: 2.3120s/iter; left time: 21931.7066s
Epoch: 30 cost time: 138.18828773498535
Epoch: 30, Steps: 135 | Train Loss: 0.2377614 Vali Loss: 0.1920600 Test Loss: 0.2245536
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2385025
	speed: 2.2801s/iter; left time: 21321.2974s
Epoch: 31 cost time: 138.16226935386658
Epoch: 31, Steps: 135 | Train Loss: 0.2377475 Vali Loss: 0.1921094 Test Loss: 0.2245674
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2303748
	speed: 2.3414s/iter; left time: 21578.4347s
Epoch: 32 cost time: 140.17162895202637
Epoch: 32, Steps: 135 | Train Loss: 0.2376641 Vali Loss: 0.1917033 Test Loss: 0.2245799
Validation loss decreased (0.191803 --> 0.191703).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2488537
	speed: 2.3260s/iter; left time: 21122.4864s
Epoch: 33 cost time: 144.06324911117554
Epoch: 33, Steps: 135 | Train Loss: 0.2376814 Vali Loss: 0.1919662 Test Loss: 0.2245568
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2390738
	speed: 2.3954s/iter; left time: 21429.2650s
Epoch: 34 cost time: 139.42845225334167
Epoch: 34, Steps: 135 | Train Loss: 0.2376328 Vali Loss: 0.1918112 Test Loss: 0.2245461
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2524770
	speed: 2.3705s/iter; left time: 20886.6017s
Epoch: 35 cost time: 139.12913417816162
Epoch: 35, Steps: 135 | Train Loss: 0.2376284 Vali Loss: 0.1920520 Test Loss: 0.2245469
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2320157
	speed: 2.3536s/iter; left time: 20419.4551s
Epoch: 36 cost time: 135.65127635002136
Epoch: 36, Steps: 135 | Train Loss: 0.2377432 Vali Loss: 0.1920919 Test Loss: 0.2245743
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2273385
	speed: 2.3126s/iter; left time: 19751.7195s
Epoch: 37 cost time: 136.8342125415802
Epoch: 37, Steps: 135 | Train Loss: 0.2376674 Vali Loss: 0.1919167 Test Loss: 0.2245502
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2488244
	speed: 2.1879s/iter; left time: 18391.0995s
Epoch: 38 cost time: 137.32911038398743
Epoch: 38, Steps: 135 | Train Loss: 0.2376600 Vali Loss: 0.1919806 Test Loss: 0.2245623
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2451072
	speed: 2.3321s/iter; left time: 19288.9000s
Epoch: 39 cost time: 133.42806434631348
Epoch: 39, Steps: 135 | Train Loss: 0.2376127 Vali Loss: 0.1920122 Test Loss: 0.2245630
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2299935
	speed: 2.2506s/iter; left time: 18311.1859s
Epoch: 40 cost time: 132.37521290779114
Epoch: 40, Steps: 135 | Train Loss: 0.2376316 Vali Loss: 0.1919497 Test Loss: 0.2245570
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2366467
	speed: 2.2807s/iter; left time: 18247.7067s
Epoch: 41 cost time: 132.45107245445251
Epoch: 41, Steps: 135 | Train Loss: 0.2376360 Vali Loss: 0.1920826 Test Loss: 0.2245674
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2441479
	speed: 2.1923s/iter; left time: 17244.2812s
Epoch: 42 cost time: 133.21248269081116
Epoch: 42, Steps: 135 | Train Loss: 0.2376858 Vali Loss: 0.1919303 Test Loss: 0.2245564
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2201305
	speed: 2.3526s/iter; left time: 18187.5905s
Epoch: 43 cost time: 140.37848663330078
Epoch: 43, Steps: 135 | Train Loss: 0.2376560 Vali Loss: 0.1918436 Test Loss: 0.2245656
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2470816
	speed: 2.3701s/iter; left time: 18003.4771s
Epoch: 44 cost time: 137.08712577819824
Epoch: 44, Steps: 135 | Train Loss: 0.2377006 Vali Loss: 0.1918519 Test Loss: 0.2245587
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2408508
	speed: 2.3278s/iter; left time: 17367.9763s
Epoch: 45 cost time: 133.39148616790771
Epoch: 45, Steps: 135 | Train Loss: 0.2376481 Vali Loss: 0.1921674 Test Loss: 0.2245532
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2470395
	speed: 2.3736s/iter; left time: 17388.7399s
Epoch: 46 cost time: 136.59095406532288
Epoch: 46, Steps: 135 | Train Loss: 0.2376980 Vali Loss: 0.1919480 Test Loss: 0.2245637
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2319897
	speed: 2.2531s/iter; left time: 16201.8588s
Epoch: 47 cost time: 134.9912872314453
Epoch: 47, Steps: 135 | Train Loss: 0.2376709 Vali Loss: 0.1921919 Test Loss: 0.2245601
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2332104
	speed: 2.2682s/iter; left time: 16004.7211s
Epoch: 48 cost time: 136.36320233345032
Epoch: 48, Steps: 135 | Train Loss: 0.2376258 Vali Loss: 0.1921555 Test Loss: 0.2245562
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2309879
	speed: 2.1485s/iter; left time: 14870.0892s
Epoch: 49 cost time: 120.51183938980103
Epoch: 49, Steps: 135 | Train Loss: 0.2375933 Vali Loss: 0.1917636 Test Loss: 0.2245614
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2330101
	speed: 1.9053s/iter; left time: 12929.6340s
Epoch: 50 cost time: 108.1256730556488
Epoch: 50, Steps: 135 | Train Loss: 0.2376633 Vali Loss: 0.1918792 Test Loss: 0.2245599
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2369303
	speed: 1.8061s/iter; left time: 12012.1212s
Epoch: 51 cost time: 108.34390568733215
Epoch: 51, Steps: 135 | Train Loss: 0.2376390 Vali Loss: 0.1919867 Test Loss: 0.2245643
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2289031
	speed: 1.8051s/iter; left time: 11762.1413s
Epoch: 52 cost time: 110.13664412498474
Epoch: 52, Steps: 135 | Train Loss: 0.2377007 Vali Loss: 0.1919570 Test Loss: 0.2245579
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_360_j720_H4_FITS_custom_ftM_sl360_ll48_pl720_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
mse:0.22298772633075714, mae:0.3167051672935486, rse:0.4710509181022644, corr:[0.44584343 0.44884562 0.4491354  0.4492906  0.44958195 0.4496344
 0.44948277 0.4493132  0.44918528 0.44905192 0.44890887 0.44882816
 0.4488216  0.44881773 0.44879347 0.44876552 0.44873092 0.44868866
 0.44860765 0.44842094 0.44823986 0.44823372 0.44839057 0.44855067
 0.44861963 0.4487523  0.44877696 0.44869307 0.44860324 0.44853422
 0.44842014 0.44825295 0.44807395 0.4479482  0.44787997 0.44785398
 0.44782615 0.44777283 0.44772506 0.4477068  0.447693   0.4476647
 0.44761494 0.44750068 0.44739196 0.4473759  0.44742972 0.4475127
 0.44760478 0.4477582  0.44781932 0.44775593 0.44768545 0.44764084
 0.447595   0.4475049  0.4473967  0.44730985 0.44723654 0.44719073
 0.44715363 0.44710875 0.44707328 0.4470549  0.4470396  0.44702032
 0.44698414 0.44686043 0.44674534 0.44671667 0.44676173 0.44682205
 0.44687533 0.44696304 0.4469613  0.44688064 0.44681197 0.4467877
 0.4467545  0.44666526 0.44654334 0.44645327 0.44640902 0.44640392
 0.44639608 0.44635776 0.4463193  0.44630706 0.44631442 0.44632003
 0.4463101  0.44623184 0.4461327  0.44612515 0.44617355 0.44623774
 0.4463019  0.44638962 0.4463874  0.4463     0.44621837 0.44618514
 0.44617522 0.44614086 0.44604337 0.4459317  0.44585723 0.44582388
 0.44580176 0.44578448 0.4457721  0.4457692  0.4457569  0.44574332
 0.44569397 0.44556946 0.44548374 0.44550556 0.44559494 0.44571775
 0.4458466  0.44597358 0.44602692 0.446017   0.44598296 0.44595858
 0.44593993 0.44589064 0.44580957 0.4457253  0.4456598  0.44563442
 0.44564047 0.44563642 0.4456225  0.44561884 0.44563094 0.44566584
 0.44572884 0.44576564 0.4457782  0.44583502 0.4460223  0.44632414
 0.44664335 0.4468655  0.4469572  0.44698584 0.44698992 0.44699478
 0.4469924  0.44696116 0.44689333 0.44679254 0.4466806  0.4465977
 0.44656998 0.44657385 0.44660679 0.44662234 0.44660342 0.44657865
 0.44660056 0.4465873  0.4465174  0.44642946 0.4463405  0.44624457
 0.4461146  0.44605204 0.44592163 0.44575015 0.44562128 0.4455229
 0.44540927 0.4452703  0.44513804 0.44503996 0.44496936 0.44491503
 0.44487387 0.44483417 0.44481528 0.4448095  0.44477725 0.44472697
 0.4446525  0.4444616  0.44426477 0.44417724 0.44417006 0.44416934
 0.4441531  0.4441955  0.4441762  0.4440945  0.44401583 0.4439597
 0.44388258 0.4437638  0.44362885 0.44351467 0.4434284  0.44339997
 0.44341606 0.4434244  0.44342607 0.44343218 0.4434291  0.44342288
 0.44339943 0.4432556  0.44308773 0.44302124 0.44302613 0.44305494
 0.4431065  0.44321445 0.44325536 0.44320872 0.44313914 0.44308928
 0.44302794 0.4429429  0.44285414 0.44274527 0.44265303 0.44258526
 0.44255015 0.44253856 0.44254944 0.4425586  0.44254807 0.44251007
 0.4424751  0.44235584 0.4422383  0.44219157 0.44220522 0.44223323
 0.44228148 0.44238722 0.4424316  0.4423988  0.44235304 0.44232452
 0.44227785 0.44218242 0.44208    0.441995   0.4419376  0.44191742
 0.4419031  0.44187889 0.44185174 0.44183847 0.441827   0.44180998
 0.4417838  0.44171935 0.44166213 0.4416579  0.44168636 0.44171688
 0.44175655 0.44183475 0.44186577 0.4418362  0.4417801  0.44173172
 0.44167212 0.4415998  0.44150728 0.4414063  0.44133762 0.44130054
 0.44128597 0.4412659  0.4412552  0.44125038 0.44124964 0.4412587
 0.44123137 0.4411213  0.44104823 0.4410834  0.44118452 0.44130054
 0.4414232  0.44155428 0.44163015 0.44165108 0.4416479  0.44163093
 0.44159114 0.44152185 0.44143668 0.44136065 0.44129685 0.44126356
 0.4412542  0.44122943 0.44119325 0.44116175 0.44114733 0.44117367
 0.44125125 0.44131213 0.44133872 0.44139236 0.44154063 0.44177726
 0.44204852 0.44225183 0.44236773 0.4424372  0.4424725  0.44248784
 0.4424748  0.44242594 0.4423597  0.44227687 0.4421864  0.44210678
 0.44206774 0.44205943 0.44207966 0.44208378 0.44205147 0.4420157
 0.44201082 0.4419481  0.44179973 0.44165292 0.44150192 0.44135174
 0.4412042  0.44115493 0.44106182 0.4409219  0.44080433 0.44069782
 0.44057578 0.44042668 0.44027567 0.4401451  0.4400361  0.4399601
 0.43992484 0.43990466 0.4399085  0.43990818 0.43987387 0.4398235
 0.4397721  0.43964773 0.43951124 0.439473   0.43947405 0.43946174
 0.4394251  0.4394574  0.43944484 0.43937224 0.43929338 0.4392258
 0.439129   0.4389894  0.4388448  0.43872088 0.43861967 0.43857074
 0.4385749  0.43858108 0.43858242 0.4385766  0.438551   0.43850508
 0.4384476  0.43832058 0.43820497 0.43818468 0.43821293 0.43824285
 0.4382845  0.43837819 0.4384365  0.43839958 0.43833163 0.43826628
 0.43819687 0.43813187 0.43806812 0.43801242 0.43796462 0.43792185
 0.43789008 0.43784603 0.4378135  0.4378037  0.43780744 0.43781546
 0.43780962 0.43770483 0.43756327 0.43750152 0.43749827 0.43750954
 0.43754673 0.437636   0.43770057 0.43770218 0.4376725  0.43763986
 0.43757024 0.43745497 0.43734518 0.4372908  0.4372793  0.4372729
 0.43727717 0.437259   0.43723977 0.43723664 0.4372473  0.4372765
 0.4372884  0.43721804 0.437135   0.43712482 0.43717065 0.4372146
 0.4372555  0.4373156  0.43734038 0.4373161  0.4372837  0.43725294
 0.43720904 0.4371248  0.43702328 0.4369287  0.43686724 0.43684614
 0.43684897 0.43685168 0.43685162 0.43684348 0.43682635 0.43683982
 0.43684012 0.43676913 0.4367182  0.43674445 0.43683028 0.43693182
 0.4370635  0.43719822 0.43728182 0.4373191  0.43732706 0.43732008
 0.4372939  0.43722355 0.43713224 0.4370524  0.43700084 0.43699434
 0.437028   0.4370387  0.43704093 0.437051   0.43708017 0.43713918
 0.43723398 0.4372924  0.4372962  0.43733522 0.43749332 0.43774807
 0.43803602 0.4382346  0.43832582 0.43836293 0.43836898 0.43837222
 0.43836856 0.43834665 0.4383066  0.4382462  0.43817538 0.4381265
 0.4381126  0.4381201  0.43815598 0.43817568 0.43815443 0.4381266
 0.43811497 0.43802896 0.4378804  0.43772924 0.43757418 0.4374083
 0.43722484 0.43712738 0.4370256  0.436919   0.43682876 0.43674678
 0.43663332 0.43647784 0.43631738 0.4361889  0.43610492 0.4360664
 0.43607506 0.43609035 0.4361087  0.436119   0.43609133 0.43605196
 0.4359965  0.43584406 0.43567196 0.43557143 0.43550634 0.43543407
 0.4353624  0.43537292 0.43537852 0.4353213  0.43523234 0.43514174
 0.43503234 0.43490022 0.43475825 0.4346465  0.43456107 0.43451858
 0.43450627 0.434498   0.43450606 0.4345202  0.43451232 0.43447843
 0.43439442 0.43422648 0.4341307  0.43412867 0.4341661  0.4341821
 0.43417078 0.43416938 0.43414718 0.43406498 0.4339781  0.43391082
 0.4338701  0.43382734 0.43375114 0.43363783 0.43353277 0.43346396
 0.43343136 0.43338287 0.43333736 0.43328953 0.4332191  0.4331248
 0.4330405  0.43293703 0.43284333 0.43280745 0.4328097  0.43279666
 0.4328002  0.43285972 0.4329003  0.4328641  0.4327999  0.4327345
 0.43266433 0.43255034 0.43241248 0.43229392 0.43220928 0.4321796
 0.43218988 0.43218482 0.43217665 0.43216488 0.43215215 0.4321431
 0.43214417 0.43211475 0.4320875  0.43209937 0.43211696 0.43211317
 0.43211663 0.43216503 0.432183   0.43215564 0.4321246  0.43210438
 0.432077   0.4320071  0.43189925 0.4317923  0.43171638 0.431682
 0.43167353 0.43166557 0.43166277 0.4316708  0.4316566  0.4316408
 0.4316134  0.4315426  0.43151617 0.4315953  0.4317051  0.43179432
 0.4318855  0.43196896 0.43200964 0.4319912  0.4319609  0.43194342
 0.43192336 0.4318649  0.43177512 0.4316806  0.4316043  0.4315761
 0.43158683 0.431589   0.4316107  0.43164513 0.4316715  0.43168262
 0.4317107  0.4317484  0.4318024  0.43192375 0.43213156 0.43237484
 0.43260688 0.43274707 0.43281114 0.4328491  0.43286216 0.43285644
 0.4328175  0.43273142 0.43262115 0.4325089  0.43242863 0.43239173
 0.43237412 0.43235043 0.43234158 0.43235418 0.43236938 0.4323847
 0.43240336 0.43234256 0.43223625 0.4321251  0.43198982 0.43179643
 0.43154123 0.43139088 0.43128085 0.4311518  0.4310172  0.4308734
 0.43071163 0.43051657 0.43030924 0.43012866 0.43000838 0.42995426
 0.4299581  0.42576087 0.42578247 0.4299727  0.4299958  0.4279117
 0.42577183 0.4256078  0.4296244  0.42539963 0.42542526 0.4254072
 0.4253155  0.42528033 0.42525142 0.42516586 0.42504543 0.42492995
 0.424816   0.4246694  0.42445323 0.42422053 0.42406985 0.42406005
 0.42410734 0.42410216 0.4240421  0.42401224 0.4240227  0.42401817
 0.42395645 0.4238584  0.42390007 0.4240076  0.42407662 0.42812437]
