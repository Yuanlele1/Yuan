Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_360_j192_H6', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_360_j192_H6_FITS_custom_ftM_sl360_ll48_pl192_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17861
val 2441
test 5069
Model(
  (freq_upsampler): Linear(in_features=106, out_features=162, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  705563136.0
params:  17334.0
Trainable parameters:  17334
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5213739
	speed: 0.5855s/iter; left time: 8079.8018s
Epoch: 1 cost time: 81.74949789047241
Epoch: 1, Steps: 139 | Train Loss: 0.7115017 Vali Loss: 0.3639598 Test Loss: 0.4264577
Validation loss decreased (inf --> 0.363960).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2880396
	speed: 1.2465s/iter; left time: 17029.5821s
Epoch: 2 cost time: 72.50863480567932
Epoch: 2, Steps: 139 | Train Loss: 0.3221650 Vali Loss: 0.2041920 Test Loss: 0.2434148
Validation loss decreased (0.363960 --> 0.204192).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2012128
	speed: 1.1743s/iter; left time: 15879.7752s
Epoch: 3 cost time: 72.39862871170044
Epoch: 3, Steps: 139 | Train Loss: 0.2086817 Vali Loss: 0.1551974 Test Loss: 0.1857115
Validation loss decreased (0.204192 --> 0.155197).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1757767
	speed: 1.2164s/iter; left time: 16280.2223s
Epoch: 4 cost time: 74.83190751075745
Epoch: 4, Steps: 139 | Train Loss: 0.1752721 Vali Loss: 0.1424685 Test Loss: 0.1699734
Validation loss decreased (0.155197 --> 0.142468).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1683588
	speed: 1.2503s/iter; left time: 16559.9530s
Epoch: 5 cost time: 78.15790510177612
Epoch: 5, Steps: 139 | Train Loss: 0.1665159 Vali Loss: 0.1393287 Test Loss: 0.1658215
Validation loss decreased (0.142468 --> 0.139329).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1586550
	speed: 1.2201s/iter; left time: 15991.0804s
Epoch: 6 cost time: 75.67674994468689
Epoch: 6, Steps: 139 | Train Loss: 0.1640596 Vali Loss: 0.1382954 Test Loss: 0.1644483
Validation loss decreased (0.139329 --> 0.138295).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1679790
	speed: 1.2490s/iter; left time: 16195.2435s
Epoch: 7 cost time: 73.72696113586426
Epoch: 7, Steps: 139 | Train Loss: 0.1630983 Vali Loss: 0.1377989 Test Loss: 0.1637318
Validation loss decreased (0.138295 --> 0.137799).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1540636
	speed: 1.2068s/iter; left time: 15481.1600s
Epoch: 8 cost time: 76.72053694725037
Epoch: 8, Steps: 139 | Train Loss: 0.1625229 Vali Loss: 0.1373911 Test Loss: 0.1632777
Validation loss decreased (0.137799 --> 0.137391).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1727377
	speed: 1.2536s/iter; left time: 15906.3115s
Epoch: 9 cost time: 78.10861301422119
Epoch: 9, Steps: 139 | Train Loss: 0.1620922 Vali Loss: 0.1370840 Test Loss: 0.1629939
Validation loss decreased (0.137391 --> 0.137084).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1619037
	speed: 1.2278s/iter; left time: 15409.2544s
Epoch: 10 cost time: 77.29674744606018
Epoch: 10, Steps: 139 | Train Loss: 0.1618062 Vali Loss: 0.1369176 Test Loss: 0.1627523
Validation loss decreased (0.137084 --> 0.136918).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1662715
	speed: 1.2744s/iter; left time: 15816.6811s
Epoch: 11 cost time: 75.97370409965515
Epoch: 11, Steps: 139 | Train Loss: 0.1616576 Vali Loss: 0.1367058 Test Loss: 0.1625863
Validation loss decreased (0.136918 --> 0.136706).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1545296
	speed: 1.2899s/iter; left time: 15829.7992s
Epoch: 12 cost time: 84.43688917160034
Epoch: 12, Steps: 139 | Train Loss: 0.1614277 Vali Loss: 0.1366424 Test Loss: 0.1624525
Validation loss decreased (0.136706 --> 0.136642).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1658188
	speed: 1.2818s/iter; left time: 15551.9536s
Epoch: 13 cost time: 77.69219946861267
Epoch: 13, Steps: 139 | Train Loss: 0.1612640 Vali Loss: 0.1365488 Test Loss: 0.1623580
Validation loss decreased (0.136642 --> 0.136549).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1708406
	speed: 1.3022s/iter; left time: 15618.0038s
Epoch: 14 cost time: 78.0420184135437
Epoch: 14, Steps: 139 | Train Loss: 0.1612447 Vali Loss: 0.1364147 Test Loss: 0.1622947
Validation loss decreased (0.136549 --> 0.136415).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1625813
	speed: 1.2401s/iter; left time: 14701.4273s
Epoch: 15 cost time: 78.3354332447052
Epoch: 15, Steps: 139 | Train Loss: 0.1611203 Vali Loss: 0.1363709 Test Loss: 0.1622262
Validation loss decreased (0.136415 --> 0.136371).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1568195
	speed: 1.3020s/iter; left time: 15254.5481s
Epoch: 16 cost time: 80.34128522872925
Epoch: 16, Steps: 139 | Train Loss: 0.1610956 Vali Loss: 0.1363585 Test Loss: 0.1621965
Validation loss decreased (0.136371 --> 0.136358).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1571009
	speed: 1.2288s/iter; left time: 14225.8285s
Epoch: 17 cost time: 75.02537250518799
Epoch: 17, Steps: 139 | Train Loss: 0.1609838 Vali Loss: 0.1363372 Test Loss: 0.1621571
Validation loss decreased (0.136358 --> 0.136337).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1616638
	speed: 1.2013s/iter; left time: 13740.1360s
Epoch: 18 cost time: 72.97583508491516
Epoch: 18, Steps: 139 | Train Loss: 0.1609704 Vali Loss: 0.1363353 Test Loss: 0.1621216
Validation loss decreased (0.136337 --> 0.136335).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1544834
	speed: 1.1958s/iter; left time: 13511.2833s
Epoch: 19 cost time: 74.38413667678833
Epoch: 19, Steps: 139 | Train Loss: 0.1609890 Vali Loss: 0.1362941 Test Loss: 0.1621164
Validation loss decreased (0.136335 --> 0.136294).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1543645
	speed: 1.1890s/iter; left time: 13269.6902s
Epoch: 20 cost time: 74.95620250701904
Epoch: 20, Steps: 139 | Train Loss: 0.1609900 Vali Loss: 0.1362851 Test Loss: 0.1621074
Validation loss decreased (0.136294 --> 0.136285).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1760466
	speed: 1.2467s/iter; left time: 13739.4625s
Epoch: 21 cost time: 78.87866044044495
Epoch: 21, Steps: 139 | Train Loss: 0.1609758 Vali Loss: 0.1361866 Test Loss: 0.1620885
Validation loss decreased (0.136285 --> 0.136187).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1501769
	speed: 1.2391s/iter; left time: 13483.4381s
Epoch: 22 cost time: 74.04268145561218
Epoch: 22, Steps: 139 | Train Loss: 0.1609509 Vali Loss: 0.1362096 Test Loss: 0.1620650
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1622814
	speed: 1.2297s/iter; left time: 13210.2372s
Epoch: 23 cost time: 78.06435084342957
Epoch: 23, Steps: 139 | Train Loss: 0.1609056 Vali Loss: 0.1362247 Test Loss: 0.1620559
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1565824
	speed: 1.1945s/iter; left time: 12666.2376s
Epoch: 24 cost time: 72.5917797088623
Epoch: 24, Steps: 139 | Train Loss: 0.1608603 Vali Loss: 0.1361413 Test Loss: 0.1620262
Validation loss decreased (0.136187 --> 0.136141).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1540681
	speed: 1.2153s/iter; left time: 12717.7132s
Epoch: 25 cost time: 73.87330532073975
Epoch: 25, Steps: 139 | Train Loss: 0.1609196 Vali Loss: 0.1362102 Test Loss: 0.1620267
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1595439
	speed: 1.1943s/iter; left time: 12332.2160s
Epoch: 26 cost time: 72.14656066894531
Epoch: 26, Steps: 139 | Train Loss: 0.1608525 Vali Loss: 0.1361448 Test Loss: 0.1620196
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1552511
	speed: 1.2584s/iter; left time: 12819.2334s
Epoch: 27 cost time: 77.69154334068298
Epoch: 27, Steps: 139 | Train Loss: 0.1608845 Vali Loss: 0.1361856 Test Loss: 0.1620050
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1642357
	speed: 1.2250s/iter; left time: 12308.6393s
Epoch: 28 cost time: 77.1372606754303
Epoch: 28, Steps: 139 | Train Loss: 0.1608678 Vali Loss: 0.1361773 Test Loss: 0.1620030
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1640883
	speed: 1.1979s/iter; left time: 11870.2168s
Epoch: 29 cost time: 72.10267519950867
Epoch: 29, Steps: 139 | Train Loss: 0.1607930 Vali Loss: 0.1361147 Test Loss: 0.1620015
Validation loss decreased (0.136141 --> 0.136115).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1548925
	speed: 1.1609s/iter; left time: 11341.8165s
Epoch: 30 cost time: 73.08826088905334
Epoch: 30, Steps: 139 | Train Loss: 0.1608118 Vali Loss: 0.1361551 Test Loss: 0.1619905
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1593514
	speed: 1.2637s/iter; left time: 12170.5343s
Epoch: 31 cost time: 75.17188882827759
Epoch: 31, Steps: 139 | Train Loss: 0.1608550 Vali Loss: 0.1361376 Test Loss: 0.1619811
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1601996
	speed: 1.2385s/iter; left time: 11755.8470s
Epoch: 32 cost time: 75.91671919822693
Epoch: 32, Steps: 139 | Train Loss: 0.1608039 Vali Loss: 0.1361591 Test Loss: 0.1619881
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1583769
	speed: 1.1751s/iter; left time: 10991.0921s
Epoch: 33 cost time: 71.23119068145752
Epoch: 33, Steps: 139 | Train Loss: 0.1607963 Vali Loss: 0.1361100 Test Loss: 0.1619597
Validation loss decreased (0.136115 --> 0.136110).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1599141
	speed: 1.2223s/iter; left time: 11262.1445s
Epoch: 34 cost time: 74.52731585502625
Epoch: 34, Steps: 139 | Train Loss: 0.1607962 Vali Loss: 0.1360713 Test Loss: 0.1619572
Validation loss decreased (0.136110 --> 0.136071).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1664053
	speed: 1.1985s/iter; left time: 10876.7969s
Epoch: 35 cost time: 73.42258930206299
Epoch: 35, Steps: 139 | Train Loss: 0.1608106 Vali Loss: 0.1361029 Test Loss: 0.1619639
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1649216
	speed: 1.2093s/iter; left time: 10806.0146s
Epoch: 36 cost time: 72.36380314826965
Epoch: 36, Steps: 139 | Train Loss: 0.1607976 Vali Loss: 0.1359989 Test Loss: 0.1619604
Validation loss decreased (0.136071 --> 0.135999).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1684492
	speed: 1.1369s/iter; left time: 10001.5875s
Epoch: 37 cost time: 71.13965845108032
Epoch: 37, Steps: 139 | Train Loss: 0.1607792 Vali Loss: 0.1361259 Test Loss: 0.1619556
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1472688
	speed: 1.1646s/iter; left time: 10082.7681s
Epoch: 38 cost time: 69.46982979774475
Epoch: 38, Steps: 139 | Train Loss: 0.1607738 Vali Loss: 0.1361028 Test Loss: 0.1619421
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1697990
	speed: 1.1842s/iter; left time: 10088.4327s
Epoch: 39 cost time: 73.76200556755066
Epoch: 39, Steps: 139 | Train Loss: 0.1608085 Vali Loss: 0.1360584 Test Loss: 0.1619475
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1529777
	speed: 1.1620s/iter; left time: 9737.6570s
Epoch: 40 cost time: 69.34653735160828
Epoch: 40, Steps: 139 | Train Loss: 0.1607518 Vali Loss: 0.1360884 Test Loss: 0.1619499
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1689872
	speed: 1.1633s/iter; left time: 9586.8776s
Epoch: 41 cost time: 74.37131357192993
Epoch: 41, Steps: 139 | Train Loss: 0.1607375 Vali Loss: 0.1360538 Test Loss: 0.1619385
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1653699
	speed: 1.1441s/iter; left time: 9269.5925s
Epoch: 42 cost time: 67.93306183815002
Epoch: 42, Steps: 139 | Train Loss: 0.1607377 Vali Loss: 0.1360863 Test Loss: 0.1619286
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1616699
	speed: 1.1609s/iter; left time: 9244.2381s
Epoch: 43 cost time: 68.912770986557
Epoch: 43, Steps: 139 | Train Loss: 0.1608152 Vali Loss: 0.1360810 Test Loss: 0.1619269
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1591792
	speed: 1.1906s/iter; left time: 9315.0560s
Epoch: 44 cost time: 75.63108587265015
Epoch: 44, Steps: 139 | Train Loss: 0.1607005 Vali Loss: 0.1360801 Test Loss: 0.1619254
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1633078
	speed: 1.1379s/iter; left time: 8745.0962s
Epoch: 45 cost time: 68.59999442100525
Epoch: 45, Steps: 139 | Train Loss: 0.1607290 Vali Loss: 0.1361261 Test Loss: 0.1619255
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1576039
	speed: 1.1360s/iter; left time: 8571.9719s
Epoch: 46 cost time: 70.49140071868896
Epoch: 46, Steps: 139 | Train Loss: 0.1607163 Vali Loss: 0.1360695 Test Loss: 0.1619274
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1589635
	speed: 1.0930s/iter; left time: 8095.7096s
Epoch: 47 cost time: 67.80999088287354
Epoch: 47, Steps: 139 | Train Loss: 0.1607334 Vali Loss: 0.1360594 Test Loss: 0.1619256
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1524501
	speed: 1.1545s/iter; left time: 8390.7553s
Epoch: 48 cost time: 72.2461564540863
Epoch: 48, Steps: 139 | Train Loss: 0.1607070 Vali Loss: 0.1361182 Test Loss: 0.1619200
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1679176
	speed: 1.0921s/iter; left time: 7785.6629s
Epoch: 49 cost time: 64.97289490699768
Epoch: 49, Steps: 139 | Train Loss: 0.1607211 Vali Loss: 0.1361304 Test Loss: 0.1619165
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1610647
	speed: 1.1483s/iter; left time: 8026.9653s
Epoch: 50 cost time: 71.82214307785034
Epoch: 50, Steps: 139 | Train Loss: 0.1607913 Vali Loss: 0.1360900 Test Loss: 0.1619125
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1633938
	speed: 1.1739s/iter; left time: 8042.2998s
Epoch: 51 cost time: 70.52233839035034
Epoch: 51, Steps: 139 | Train Loss: 0.1607791 Vali Loss: 0.1360358 Test Loss: 0.1619177
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1542975
	speed: 1.2284s/iter; left time: 8245.0041s
Epoch: 52 cost time: 75.66880893707275
Epoch: 52, Steps: 139 | Train Loss: 0.1607516 Vali Loss: 0.1360140 Test Loss: 0.1619136
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1537152
	speed: 1.1834s/iter; left time: 7778.5469s
Epoch: 53 cost time: 70.86886954307556
Epoch: 53, Steps: 139 | Train Loss: 0.1607514 Vali Loss: 0.1360581 Test Loss: 0.1619081
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1613262
	speed: 1.2341s/iter; left time: 7940.0009s
Epoch: 54 cost time: 73.81982660293579
Epoch: 54, Steps: 139 | Train Loss: 0.1607671 Vali Loss: 0.1360752 Test Loss: 0.1619113
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1649474
	speed: 1.1595s/iter; left time: 7298.8487s
Epoch: 55 cost time: 69.25135135650635
Epoch: 55, Steps: 139 | Train Loss: 0.1606822 Vali Loss: 0.1360230 Test Loss: 0.1619097
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1648680
	speed: 1.1972s/iter; left time: 7369.8914s
Epoch: 56 cost time: 73.05745673179626
Epoch: 56, Steps: 139 | Train Loss: 0.1607630 Vali Loss: 0.1361102 Test Loss: 0.1619104
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_360_j192_H6_FITS_custom_ftM_sl360_ll48_pl192_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5069
mse:0.15914186835289001, mae:0.25654885172843933, rse:0.39663824439048767, corr:[0.4633751  0.4641804  0.46597612 0.46672103 0.46648046 0.4671243
 0.46744677 0.4668811  0.46657637 0.4665951  0.46636343 0.46606764
 0.46597856 0.465987   0.46599415 0.46593985 0.46585524 0.46588752
 0.46584547 0.4655833  0.46548134 0.4655322  0.465539   0.46568927
 0.46599963 0.46626663 0.46615824 0.46602663 0.46606475 0.4659849
 0.4657069  0.46554002 0.46548942 0.46533793 0.46510282 0.46500355
 0.46500143 0.4649152  0.46476445 0.46463782 0.46453136 0.464398
 0.46422827 0.46406698 0.4640022  0.46393412 0.46387026 0.4640085
 0.46423548 0.4643536  0.46434122 0.46436095 0.4643668  0.46420956
 0.4640438  0.4640073  0.46398136 0.4638642  0.46376428 0.46378127
 0.463822   0.4637837  0.4637266  0.46370378 0.4636879  0.4636531
 0.46356827 0.46342543 0.46332625 0.463219   0.4631834  0.46335834
 0.46351126 0.46353728 0.4635336  0.46356392 0.46352127 0.46341398
 0.46337387 0.46338752 0.4633208  0.46321288 0.46314213 0.46313497
 0.46314648 0.46311325 0.46306044 0.46303844 0.46302727 0.46300566
 0.462949   0.46281692 0.4626787  0.46258166 0.46260732 0.4627875
 0.46285778 0.46282744 0.46285638 0.46291876 0.46288168 0.46281704
 0.4628528  0.46289068 0.46278125 0.46264112 0.46259382 0.46260563
 0.46256837 0.46247005 0.46240908 0.46244746 0.46246287 0.46241817
 0.46244344 0.46251065 0.46253642 0.46252066 0.46260628 0.46283376
 0.46294993 0.46300113 0.46309915 0.46314785 0.46307167 0.46303886
 0.46309856 0.4630922  0.4629984  0.46293822 0.46290743 0.462859
 0.46278915 0.4627318  0.46273613 0.46277088 0.46273592 0.46269816
 0.4627543  0.4627516  0.4627077  0.46269408 0.4628264  0.46314982
 0.46342906 0.46363002 0.46382418 0.46388397 0.46379146 0.4637688
 0.46382025 0.4637636  0.46361214 0.46352664 0.4635266  0.46350864
 0.46341446 0.46333942 0.46342796 0.4635468  0.46352237 0.46349013
 0.46352214 0.46337733 0.46313295 0.46297652 0.462924   0.46293822
 0.4628313  0.46279874 0.4627155  0.46248683 0.4622507  0.46211997
 0.4619792  0.46174076 0.4615268  0.46147352 0.4614539  0.46138224
 0.4613738  0.46151802 0.46163318 0.46148977 0.46129867 0.461427
 0.46133527 0.46069938 0.46062055 0.46078318 0.4603193  0.46138933]
