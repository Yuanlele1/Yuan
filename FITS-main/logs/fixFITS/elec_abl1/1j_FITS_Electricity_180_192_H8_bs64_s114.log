Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=74, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_180_j192_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_180_j192_H8_FITS_custom_ftM_sl180_ll48_pl192_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18041
val 2441
test 5069
Model(
  (freq_upsampler): Linear(in_features=74, out_features=152, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  462157824.0
params:  11400.0
Trainable parameters:  11400
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3904215
	speed: 0.5844s/iter; left time: 8124.1386s
Epoch: 1 cost time: 81.60864639282227
Epoch: 1, Steps: 140 | Train Loss: 0.5701384 Vali Loss: 0.2759551 Test Loss: 0.3056005
Validation loss decreased (inf --> 0.275955).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2368762
	speed: 1.2301s/iter; left time: 16928.0108s
Epoch: 2 cost time: 71.5581464767456
Epoch: 2, Steps: 140 | Train Loss: 0.2630017 Vali Loss: 0.2007957 Test Loss: 0.2271979
Validation loss decreased (0.275955 --> 0.200796).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2206938
	speed: 1.1606s/iter; left time: 15808.5661s
Epoch: 3 cost time: 65.37429070472717
Epoch: 3, Steps: 140 | Train Loss: 0.2137779 Vali Loss: 0.1739584 Test Loss: 0.2010528
Validation loss decreased (0.200796 --> 0.173958).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1841382
	speed: 1.1474s/iter; left time: 15468.1725s
Epoch: 4 cost time: 68.63436007499695
Epoch: 4, Steps: 140 | Train Loss: 0.1930028 Vali Loss: 0.1610253 Test Loss: 0.1885137
Validation loss decreased (0.173958 --> 0.161025).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2032334
	speed: 1.1675s/iter; left time: 15575.8904s
Epoch: 5 cost time: 70.10041427612305
Epoch: 5, Steps: 140 | Train Loss: 0.1828160 Vali Loss: 0.1545086 Test Loss: 0.1821173
Validation loss decreased (0.161025 --> 0.154509).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1742876
	speed: 1.1641s/iter; left time: 15367.6882s
Epoch: 6 cost time: 67.78853917121887
Epoch: 6, Steps: 140 | Train Loss: 0.1775822 Vali Loss: 0.1510762 Test Loss: 0.1786532
Validation loss decreased (0.154509 --> 0.151076).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1872227
	speed: 1.1366s/iter; left time: 14845.1067s
Epoch: 7 cost time: 64.74598574638367
Epoch: 7, Steps: 140 | Train Loss: 0.1748030 Vali Loss: 0.1492345 Test Loss: 0.1766974
Validation loss decreased (0.151076 --> 0.149234).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1688715
	speed: 1.1064s/iter; left time: 14296.1092s
Epoch: 8 cost time: 63.64709520339966
Epoch: 8, Steps: 140 | Train Loss: 0.1730878 Vali Loss: 0.1480758 Test Loss: 0.1754246
Validation loss decreased (0.149234 --> 0.148076).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1725959
	speed: 0.8671s/iter; left time: 11082.6412s
Epoch: 9 cost time: 45.21908926963806
Epoch: 9, Steps: 140 | Train Loss: 0.1720004 Vali Loss: 0.1472600 Test Loss: 0.1745509
Validation loss decreased (0.148076 --> 0.147260).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1778530
	speed: 0.7379s/iter; left time: 9327.4960s
Epoch: 10 cost time: 41.573742628097534
Epoch: 10, Steps: 140 | Train Loss: 0.1712634 Vali Loss: 0.1466485 Test Loss: 0.1739027
Validation loss decreased (0.147260 --> 0.146648).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1613872
	speed: 0.7153s/iter; left time: 8942.3170s
Epoch: 11 cost time: 42.31222462654114
Epoch: 11, Steps: 140 | Train Loss: 0.1706685 Vali Loss: 0.1461145 Test Loss: 0.1734282
Validation loss decreased (0.146648 --> 0.146114).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1759549
	speed: 0.7070s/iter; left time: 8739.4126s
Epoch: 12 cost time: 43.460726737976074
Epoch: 12, Steps: 140 | Train Loss: 0.1701373 Vali Loss: 0.1457348 Test Loss: 0.1730545
Validation loss decreased (0.146114 --> 0.145735).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1643842
	speed: 0.7353s/iter; left time: 8986.6002s
Epoch: 13 cost time: 44.35930824279785
Epoch: 13, Steps: 140 | Train Loss: 0.1698933 Vali Loss: 0.1454837 Test Loss: 0.1727430
Validation loss decreased (0.145735 --> 0.145484).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1707352
	speed: 0.7149s/iter; left time: 8636.8263s
Epoch: 14 cost time: 41.5128378868103
Epoch: 14, Steps: 140 | Train Loss: 0.1695280 Vali Loss: 0.1453228 Test Loss: 0.1724969
Validation loss decreased (0.145484 --> 0.145323).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1650594
	speed: 0.7474s/iter; left time: 8925.2442s
Epoch: 15 cost time: 43.72217130661011
Epoch: 15, Steps: 140 | Train Loss: 0.1693117 Vali Loss: 0.1450404 Test Loss: 0.1723105
Validation loss decreased (0.145323 --> 0.145040).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1678046
	speed: 0.7134s/iter; left time: 8418.3577s
Epoch: 16 cost time: 43.079923152923584
Epoch: 16, Steps: 140 | Train Loss: 0.1691642 Vali Loss: 0.1448784 Test Loss: 0.1721520
Validation loss decreased (0.145040 --> 0.144878).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1570584
	speed: 0.8341s/iter; left time: 9726.0670s
Epoch: 17 cost time: 62.39576554298401
Epoch: 17, Steps: 140 | Train Loss: 0.1690256 Vali Loss: 0.1446985 Test Loss: 0.1720230
Validation loss decreased (0.144878 --> 0.144698).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1728633
	speed: 1.1590s/iter; left time: 13353.2240s
Epoch: 18 cost time: 66.98951148986816
Epoch: 18, Steps: 140 | Train Loss: 0.1689368 Vali Loss: 0.1446660 Test Loss: 0.1719180
Validation loss decreased (0.144698 --> 0.144666).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1631869
	speed: 1.1788s/iter; left time: 13416.1886s
Epoch: 19 cost time: 68.48044991493225
Epoch: 19, Steps: 140 | Train Loss: 0.1687842 Vali Loss: 0.1445275 Test Loss: 0.1718111
Validation loss decreased (0.144666 --> 0.144528).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1744249
	speed: 0.9328s/iter; left time: 10485.8103s
Epoch: 20 cost time: 43.47007942199707
Epoch: 20, Steps: 140 | Train Loss: 0.1686686 Vali Loss: 0.1444484 Test Loss: 0.1717407
Validation loss decreased (0.144528 --> 0.144448).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1766063
	speed: 0.7116s/iter; left time: 7900.0175s
Epoch: 21 cost time: 40.702067136764526
Epoch: 21, Steps: 140 | Train Loss: 0.1684968 Vali Loss: 0.1443528 Test Loss: 0.1716840
Validation loss decreased (0.144448 --> 0.144353).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1706009
	speed: 0.7557s/iter; left time: 8283.0185s
Epoch: 22 cost time: 43.050504207611084
Epoch: 22, Steps: 140 | Train Loss: 0.1686539 Vali Loss: 0.1442583 Test Loss: 0.1716129
Validation loss decreased (0.144353 --> 0.144258).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1563102
	speed: 0.7316s/iter; left time: 7916.6098s
Epoch: 23 cost time: 42.565187215805054
Epoch: 23, Steps: 140 | Train Loss: 0.1685196 Vali Loss: 0.1442530 Test Loss: 0.1715633
Validation loss decreased (0.144258 --> 0.144253).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1705405
	speed: 0.7051s/iter; left time: 7531.4980s
Epoch: 24 cost time: 42.67326498031616
Epoch: 24, Steps: 140 | Train Loss: 0.1684701 Vali Loss: 0.1442959 Test Loss: 0.1715270
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1766804
	speed: 0.7633s/iter; left time: 8045.5211s
Epoch: 25 cost time: 43.92409014701843
Epoch: 25, Steps: 140 | Train Loss: 0.1684243 Vali Loss: 0.1442873 Test Loss: 0.1715017
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1636575
	speed: 0.7078s/iter; left time: 7361.7646s
Epoch: 26 cost time: 43.52473163604736
Epoch: 26, Steps: 140 | Train Loss: 0.1683916 Vali Loss: 0.1442163 Test Loss: 0.1714485
Validation loss decreased (0.144253 --> 0.144216).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1659466
	speed: 0.7453s/iter; left time: 7647.8607s
Epoch: 27 cost time: 43.77557992935181
Epoch: 27, Steps: 140 | Train Loss: 0.1683730 Vali Loss: 0.1441392 Test Loss: 0.1714280
Validation loss decreased (0.144216 --> 0.144139).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1615665
	speed: 0.7307s/iter; left time: 7395.5863s
Epoch: 28 cost time: 44.430943965911865
Epoch: 28, Steps: 140 | Train Loss: 0.1683701 Vali Loss: 0.1441087 Test Loss: 0.1714042
Validation loss decreased (0.144139 --> 0.144109).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1673497
	speed: 0.7721s/iter; left time: 7706.2005s
Epoch: 29 cost time: 44.13960385322571
Epoch: 29, Steps: 140 | Train Loss: 0.1682902 Vali Loss: 0.1440189 Test Loss: 0.1713820
Validation loss decreased (0.144109 --> 0.144019).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1640811
	speed: 0.7333s/iter; left time: 7216.6944s
Epoch: 30 cost time: 44.329697132110596
Epoch: 30, Steps: 140 | Train Loss: 0.1683678 Vali Loss: 0.1440212 Test Loss: 0.1713657
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1646604
	speed: 0.7419s/iter; left time: 7196.7333s
Epoch: 31 cost time: 45.01904487609863
Epoch: 31, Steps: 140 | Train Loss: 0.1682052 Vali Loss: 0.1440240 Test Loss: 0.1713490
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1678883
	speed: 0.7837s/iter; left time: 7492.9750s
Epoch: 32 cost time: 46.01849722862244
Epoch: 32, Steps: 140 | Train Loss: 0.1682619 Vali Loss: 0.1439740 Test Loss: 0.1713291
Validation loss decreased (0.144019 --> 0.143974).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1639117
	speed: 0.7739s/iter; left time: 7290.9326s
Epoch: 33 cost time: 44.949854135513306
Epoch: 33, Steps: 140 | Train Loss: 0.1682567 Vali Loss: 0.1439252 Test Loss: 0.1713195
Validation loss decreased (0.143974 --> 0.143925).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1687014
	speed: 0.7110s/iter; left time: 6598.7210s
Epoch: 34 cost time: 41.5800085067749
Epoch: 34, Steps: 140 | Train Loss: 0.1682322 Vali Loss: 0.1439751 Test Loss: 0.1712907
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1736534
	speed: 0.7251s/iter; left time: 6628.5765s
Epoch: 35 cost time: 42.12955141067505
Epoch: 35, Steps: 140 | Train Loss: 0.1682479 Vali Loss: 0.1439841 Test Loss: 0.1712789
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1697480
	speed: 0.7025s/iter; left time: 6323.4491s
Epoch: 36 cost time: 41.30058693885803
Epoch: 36, Steps: 140 | Train Loss: 0.1681665 Vali Loss: 0.1440064 Test Loss: 0.1712753
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1607726
	speed: 0.6988s/iter; left time: 6192.4138s
Epoch: 37 cost time: 42.08979868888855
Epoch: 37, Steps: 140 | Train Loss: 0.1681909 Vali Loss: 0.1439455 Test Loss: 0.1712616
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1586602
	speed: 0.6729s/iter; left time: 5868.6443s
Epoch: 38 cost time: 39.39325761795044
Epoch: 38, Steps: 140 | Train Loss: 0.1681882 Vali Loss: 0.1439466 Test Loss: 0.1712567
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1609622
	speed: 0.7189s/iter; left time: 6168.4798s
Epoch: 39 cost time: 41.62075448036194
Epoch: 39, Steps: 140 | Train Loss: 0.1682057 Vali Loss: 0.1439476 Test Loss: 0.1712497
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1664357
	speed: 0.6823s/iter; left time: 5759.6163s
Epoch: 40 cost time: 39.54993295669556
Epoch: 40, Steps: 140 | Train Loss: 0.1681358 Vali Loss: 0.1439091 Test Loss: 0.1712373
Validation loss decreased (0.143925 --> 0.143909).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1655513
	speed: 0.7037s/iter; left time: 5841.4310s
Epoch: 41 cost time: 44.018736600875854
Epoch: 41, Steps: 140 | Train Loss: 0.1681493 Vali Loss: 0.1439593 Test Loss: 0.1712272
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1621761
	speed: 0.7365s/iter; left time: 6010.9448s
Epoch: 42 cost time: 40.96068596839905
Epoch: 42, Steps: 140 | Train Loss: 0.1681452 Vali Loss: 0.1439027 Test Loss: 0.1712223
Validation loss decreased (0.143909 --> 0.143903).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1681044
	speed: 0.9091s/iter; left time: 7291.9740s
Epoch: 43 cost time: 68.03543448448181
Epoch: 43, Steps: 140 | Train Loss: 0.1681497 Vali Loss: 0.1438922 Test Loss: 0.1712132
Validation loss decreased (0.143903 --> 0.143892).  Saving model ...
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1680474
	speed: 1.1044s/iter; left time: 8703.6548s
Epoch: 44 cost time: 65.1254813671112
Epoch: 44, Steps: 140 | Train Loss: 0.1680332 Vali Loss: 0.1439169 Test Loss: 0.1712043
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1807392
	speed: 1.1097s/iter; left time: 8590.0011s
Epoch: 45 cost time: 65.39540815353394
Epoch: 45, Steps: 140 | Train Loss: 0.1681151 Vali Loss: 0.1438128 Test Loss: 0.1712019
Validation loss decreased (0.143892 --> 0.143813).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1639678
	speed: 1.0611s/iter; left time: 8065.5509s
Epoch: 46 cost time: 63.778993368148804
Epoch: 46, Steps: 140 | Train Loss: 0.1681573 Vali Loss: 0.1439440 Test Loss: 0.1711991
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1720357
	speed: 1.0863s/iter; left time: 8104.7048s
Epoch: 47 cost time: 61.49892497062683
Epoch: 47, Steps: 140 | Train Loss: 0.1681161 Vali Loss: 0.1438648 Test Loss: 0.1711914
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1689940
	speed: 1.0313s/iter; left time: 7550.4825s
Epoch: 48 cost time: 60.86968421936035
Epoch: 48, Steps: 140 | Train Loss: 0.1680205 Vali Loss: 0.1439058 Test Loss: 0.1711880
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1789454
	speed: 1.0055s/iter; left time: 7220.4036s
Epoch: 49 cost time: 58.864174127578735
Epoch: 49, Steps: 140 | Train Loss: 0.1681432 Vali Loss: 0.1438910 Test Loss: 0.1711792
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1645813
	speed: 0.9395s/iter; left time: 6614.6941s
Epoch: 50 cost time: 55.03070068359375
Epoch: 50, Steps: 140 | Train Loss: 0.1680659 Vali Loss: 0.1438895 Test Loss: 0.1711803
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1638992
	speed: 0.9202s/iter; left time: 6350.2827s
Epoch: 51 cost time: 55.59508013725281
Epoch: 51, Steps: 140 | Train Loss: 0.1680760 Vali Loss: 0.1438663 Test Loss: 0.1711843
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1772233
	speed: 0.7198s/iter; left time: 4866.3239s
Epoch: 52 cost time: 31.6503586769104
Epoch: 52, Steps: 140 | Train Loss: 0.1680233 Vali Loss: 0.1439101 Test Loss: 0.1711723
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1686223
	speed: 0.6977s/iter; left time: 4619.7485s
Epoch: 53 cost time: 45.004897594451904
Epoch: 53, Steps: 140 | Train Loss: 0.1681455 Vali Loss: 0.1438599 Test Loss: 0.1711700
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1817245
	speed: 0.5442s/iter; left time: 3527.2598s
Epoch: 54 cost time: 32.286696672439575
Epoch: 54, Steps: 140 | Train Loss: 0.1679928 Vali Loss: 0.1438471 Test Loss: 0.1711673
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1746530
	speed: 0.6494s/iter; left time: 4118.0665s
Epoch: 55 cost time: 49.120442390441895
Epoch: 55, Steps: 140 | Train Loss: 0.1680185 Vali Loss: 0.1438929 Test Loss: 0.1711653
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1842928
	speed: 0.9886s/iter; left time: 6130.2762s
Epoch: 56 cost time: 59.047592639923096
Epoch: 56, Steps: 140 | Train Loss: 0.1680920 Vali Loss: 0.1438014 Test Loss: 0.1711668
Validation loss decreased (0.143813 --> 0.143801).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.1796936
	speed: 1.0503s/iter; left time: 6365.8623s
Epoch: 57 cost time: 61.05734848976135
Epoch: 57, Steps: 140 | Train Loss: 0.1681082 Vali Loss: 0.1438453 Test Loss: 0.1711607
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1712494
	speed: 1.0019s/iter; left time: 5932.1236s
Epoch: 58 cost time: 58.11596727371216
Epoch: 58, Steps: 140 | Train Loss: 0.1680486 Vali Loss: 0.1438597 Test Loss: 0.1711583
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1700500
	speed: 1.0594s/iter; left time: 6124.2525s
Epoch: 59 cost time: 62.21610450744629
Epoch: 59, Steps: 140 | Train Loss: 0.1680637 Vali Loss: 0.1437985 Test Loss: 0.1711527
Validation loss decreased (0.143801 --> 0.143798).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1762240
	speed: 1.0421s/iter; left time: 5878.5655s
Epoch: 60 cost time: 63.80889892578125
Epoch: 60, Steps: 140 | Train Loss: 0.1680028 Vali Loss: 0.1438363 Test Loss: 0.1711495
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1767120
	speed: 1.0554s/iter; left time: 5805.5245s
Epoch: 61 cost time: 59.437211990356445
Epoch: 61, Steps: 140 | Train Loss: 0.1681130 Vali Loss: 0.1438782 Test Loss: 0.1711506
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1732765
	speed: 1.0192s/iter; left time: 5463.7144s
Epoch: 62 cost time: 62.42962455749512
Epoch: 62, Steps: 140 | Train Loss: 0.1681161 Vali Loss: 0.1437845 Test Loss: 0.1711513
Validation loss decreased (0.143798 --> 0.143784).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1609439
	speed: 1.0309s/iter; left time: 5382.1052s
Epoch: 63 cost time: 60.630430698394775
Epoch: 63, Steps: 140 | Train Loss: 0.1680690 Vali Loss: 0.1438169 Test Loss: 0.1711484
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1675344
	speed: 0.9953s/iter; left time: 5056.9395s
Epoch: 64 cost time: 57.85965132713318
Epoch: 64, Steps: 140 | Train Loss: 0.1679495 Vali Loss: 0.1438869 Test Loss: 0.1711443
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.1641224
	speed: 1.0488s/iter; left time: 5182.1473s
Epoch: 65 cost time: 62.21011924743652
Epoch: 65, Steps: 140 | Train Loss: 0.1680719 Vali Loss: 0.1438563 Test Loss: 0.1711434
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.1759553
	speed: 1.0536s/iter; left time: 5058.3830s
Epoch: 66 cost time: 61.26305413246155
Epoch: 66, Steps: 140 | Train Loss: 0.1680279 Vali Loss: 0.1439002 Test Loss: 0.1711423
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.1728526
	speed: 0.9279s/iter; left time: 4325.0953s
Epoch: 67 cost time: 52.63388705253601
Epoch: 67, Steps: 140 | Train Loss: 0.1680563 Vali Loss: 0.1438741 Test Loss: 0.1711442
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.1704834
	speed: 0.9090s/iter; left time: 4109.5854s
Epoch: 68 cost time: 54.49575185775757
Epoch: 68, Steps: 140 | Train Loss: 0.1680287 Vali Loss: 0.1438287 Test Loss: 0.1711415
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.1745381
	speed: 0.9179s/iter; left time: 4021.4695s
Epoch: 69 cost time: 54.552083253860474
Epoch: 69, Steps: 140 | Train Loss: 0.1680577 Vali Loss: 0.1438641 Test Loss: 0.1711403
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.1812644
	speed: 1.0528s/iter; left time: 4464.9083s
Epoch: 70 cost time: 62.20085263252258
Epoch: 70, Steps: 140 | Train Loss: 0.1679786 Vali Loss: 0.1438680 Test Loss: 0.1711369
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.1577863
	speed: 1.0171s/iter; left time: 4171.0350s
Epoch: 71 cost time: 57.89079761505127
Epoch: 71, Steps: 140 | Train Loss: 0.1680120 Vali Loss: 0.1438360 Test Loss: 0.1711363
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.1695389
	speed: 0.9491s/iter; left time: 3759.4658s
Epoch: 72 cost time: 46.159417390823364
Epoch: 72, Steps: 140 | Train Loss: 0.1680533 Vali Loss: 0.1438449 Test Loss: 0.1711373
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.1654195
	speed: 0.7573s/iter; left time: 2893.6934s
Epoch: 73 cost time: 45.37428689002991
Epoch: 73, Steps: 140 | Train Loss: 0.1680436 Vali Loss: 0.1438436 Test Loss: 0.1711378
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.1646079
	speed: 0.7135s/iter; left time: 2626.4650s
Epoch: 74 cost time: 40.65925717353821
Epoch: 74, Steps: 140 | Train Loss: 0.1679987 Vali Loss: 0.1437859 Test Loss: 0.1711366
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.1647535
	speed: 0.6438s/iter; left time: 2279.6108s
Epoch: 75 cost time: 37.05858397483826
Epoch: 75, Steps: 140 | Train Loss: 0.1680319 Vali Loss: 0.1438349 Test Loss: 0.1711355
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.1717804
	speed: 0.7076s/iter; left time: 2406.4207s
Epoch: 76 cost time: 41.39923930168152
Epoch: 76, Steps: 140 | Train Loss: 0.1680364 Vali Loss: 0.1437859 Test Loss: 0.1711343
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.1586203
	speed: 0.6858s/iter; left time: 2236.5543s
Epoch: 77 cost time: 40.70197916030884
Epoch: 77, Steps: 140 | Train Loss: 0.1680325 Vali Loss: 0.1438891 Test Loss: 0.1711340
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.1744531
	speed: 0.7067s/iter; left time: 2205.5490s
Epoch: 78 cost time: 41.97676467895508
Epoch: 78, Steps: 140 | Train Loss: 0.1680714 Vali Loss: 0.1438134 Test Loss: 0.1711360
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.1714668
	speed: 0.6366s/iter; left time: 1897.5838s
Epoch: 79 cost time: 39.414018630981445
Epoch: 79, Steps: 140 | Train Loss: 0.1680549 Vali Loss: 0.1438214 Test Loss: 0.1711338
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.1664205
	speed: 0.7385s/iter; left time: 2098.0759s
Epoch: 80 cost time: 42.742942333221436
Epoch: 80, Steps: 140 | Train Loss: 0.1679940 Vali Loss: 0.1438735 Test Loss: 0.1711319
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.1725198
	speed: 0.6927s/iter; left time: 1871.0544s
Epoch: 81 cost time: 40.04637551307678
Epoch: 81, Steps: 140 | Train Loss: 0.1680713 Vali Loss: 0.1438633 Test Loss: 0.1711325
EarlyStopping counter: 19 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.1725838
	speed: 0.6406s/iter; left time: 1640.4760s
Epoch: 82 cost time: 36.34907364845276
Epoch: 82, Steps: 140 | Train Loss: 0.1680484 Vali Loss: 0.1437869 Test Loss: 0.1711312
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_180_j192_H8_FITS_custom_ftM_sl180_ll48_pl192_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5069
mse:0.16849800944328308, mae:0.2612108290195465, rse:0.4081311821937561, corr:[0.46323645 0.4661261  0.46583    0.46597803 0.46626064 0.46598342
 0.4662246  0.4660154  0.46569955 0.4656693  0.46532556 0.46502876
 0.46502647 0.46466526 0.46478537 0.4645205  0.46447515 0.4644864
 0.4643724  0.46431664 0.46433467 0.46449974 0.46500963 0.46507263
 0.4647523  0.46459708 0.46433797 0.4643288  0.46407863 0.46396503
 0.4639144  0.46373203 0.46356657 0.46335447 0.46314472 0.46291465
 0.46283993 0.46262407 0.46255428 0.46234122 0.46227306 0.4621221
 0.46196327 0.46193007 0.46186966 0.46189025 0.46213785 0.46222144
 0.4620807  0.46206152 0.46190974 0.46188223 0.46173292 0.46167755
 0.46164617 0.46155974 0.46151474 0.4614679  0.46145198 0.46129924
 0.46134079 0.4612657  0.46125922 0.4611847  0.46121863 0.46118945
 0.4610843  0.46103808 0.46092996 0.46088293 0.46107173 0.46111274
 0.46093187 0.46098873 0.46085402 0.46082935 0.4607767  0.46070227
 0.46071285 0.4606814  0.460625   0.4605512  0.46056375 0.46047884
 0.46050462 0.46047497 0.4604989  0.4603939  0.46043238 0.4605002
 0.46036026 0.46024793 0.4601501  0.4600416  0.46019867 0.460278
 0.4600559  0.46013886 0.46008167 0.4600231  0.46005416 0.46005303
 0.46003485 0.45999643 0.45999545 0.4599908  0.45997626 0.45991686
 0.4599829  0.45992497 0.45999426 0.45997947 0.45991352 0.45996806
 0.45991382 0.4598589  0.4599014  0.4598413  0.45990542 0.46004662
 0.45988497 0.45997873 0.46006423 0.46005428 0.46011153 0.4601776
 0.46015933 0.46019968 0.4602576  0.4602337  0.46023414 0.46028334
 0.46041518 0.46037912 0.46040443 0.46041095 0.46034202 0.46042052
 0.46037346 0.46019745 0.46019927 0.46014294 0.4602577  0.46048766
 0.4603947  0.4604433  0.46055925 0.4605893  0.4605928  0.46067518
 0.46068564 0.4607101  0.4607882  0.4609032  0.46100453 0.4611064
 0.46144405 0.4616243  0.46160215 0.46170676 0.4617299  0.4619112
 0.46200508 0.46185017 0.46192256 0.46204096 0.4624593  0.46225637
 0.46147785 0.4609179  0.46066585 0.46033466 0.459995   0.45980895
 0.45960414 0.45943046 0.45926747 0.4591476  0.45910344 0.45910102
 0.45928863 0.45912325 0.45922554 0.45917666 0.4588488  0.4588709
 0.4586314  0.458252   0.45842955 0.45834038 0.45858145 0.45834026]
