Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=42, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_180_j336_H4', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_180_j336_H4_FITS_custom_ftM_sl180_ll48_pl336_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17897
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=42, out_features=120, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  207083520.0
params:  5160.0
Trainable parameters:  5160
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6017864
	speed: 0.6757s/iter; left time: 9325.7908s
Epoch: 1 cost time: 93.59095668792725
Epoch: 1, Steps: 139 | Train Loss: 0.8378680 Vali Loss: 0.4134481 Test Loss: 0.4557107
Validation loss decreased (inf --> 0.413448).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3305839
	speed: 1.5832s/iter; left time: 21629.8231s
Epoch: 2 cost time: 84.01781034469604
Epoch: 2, Steps: 139 | Train Loss: 0.3704238 Vali Loss: 0.2631584 Test Loss: 0.2909104
Validation loss decreased (0.413448 --> 0.263158).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2537789
	speed: 1.4657s/iter; left time: 19821.2762s
Epoch: 3 cost time: 82.5634241104126
Epoch: 3, Steps: 139 | Train Loss: 0.2766938 Vali Loss: 0.2211961 Test Loss: 0.2475882
Validation loss decreased (0.263158 --> 0.221196).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2442508
	speed: 1.5047s/iter; left time: 20138.3443s
Epoch: 4 cost time: 85.40598583221436
Epoch: 4, Steps: 139 | Train Loss: 0.2451749 Vali Loss: 0.2017059 Test Loss: 0.2283431
Validation loss decreased (0.221196 --> 0.201706).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2306641
	speed: 1.4705s/iter; left time: 19476.3962s
Epoch: 5 cost time: 86.32001280784607
Epoch: 5, Steps: 139 | Train Loss: 0.2290967 Vali Loss: 0.1903965 Test Loss: 0.2174401
Validation loss decreased (0.201706 --> 0.190397).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2212380
	speed: 1.5708s/iter; left time: 20586.9146s
Epoch: 6 cost time: 91.75390672683716
Epoch: 6, Steps: 139 | Train Loss: 0.2194355 Vali Loss: 0.1837945 Test Loss: 0.2107970
Validation loss decreased (0.190397 --> 0.183794).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2131628
	speed: 1.4347s/iter; left time: 18603.3870s
Epoch: 7 cost time: 75.36505508422852
Epoch: 7, Steps: 139 | Train Loss: 0.2135796 Vali Loss: 0.1795064 Test Loss: 0.2065521
Validation loss decreased (0.183794 --> 0.179506).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2042996
	speed: 1.4175s/iter; left time: 18183.0720s
Epoch: 8 cost time: 84.2305257320404
Epoch: 8, Steps: 139 | Train Loss: 0.2097578 Vali Loss: 0.1770397 Test Loss: 0.2037957
Validation loss decreased (0.179506 --> 0.177040).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2102280
	speed: 1.4179s/iter; left time: 17991.6143s
Epoch: 9 cost time: 85.40969491004944
Epoch: 9, Steps: 139 | Train Loss: 0.2073961 Vali Loss: 0.1750313 Test Loss: 0.2019556
Validation loss decreased (0.177040 --> 0.175031).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1928970
	speed: 1.4507s/iter; left time: 18205.9500s
Epoch: 10 cost time: 81.71635389328003
Epoch: 10, Steps: 139 | Train Loss: 0.2057663 Vali Loss: 0.1739292 Test Loss: 0.2006396
Validation loss decreased (0.175031 --> 0.173929).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2086713
	speed: 1.4683s/iter; left time: 18223.6399s
Epoch: 11 cost time: 80.71751570701599
Epoch: 11, Steps: 139 | Train Loss: 0.2046447 Vali Loss: 0.1728307 Test Loss: 0.1997348
Validation loss decreased (0.173929 --> 0.172831).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2004476
	speed: 1.4329s/iter; left time: 17585.0054s
Epoch: 12 cost time: 86.11223673820496
Epoch: 12, Steps: 139 | Train Loss: 0.2037780 Vali Loss: 0.1724750 Test Loss: 0.1990209
Validation loss decreased (0.172831 --> 0.172475).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1907389
	speed: 1.6869s/iter; left time: 20466.6169s
Epoch: 13 cost time: 108.1878890991211
Epoch: 13, Steps: 139 | Train Loss: 0.2030562 Vali Loss: 0.1720662 Test Loss: 0.1984767
Validation loss decreased (0.172475 --> 0.172066).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1963657
	speed: 1.8824s/iter; left time: 22577.8114s
Epoch: 14 cost time: 107.72489213943481
Epoch: 14, Steps: 139 | Train Loss: 0.2025663 Vali Loss: 0.1715171 Test Loss: 0.1980532
Validation loss decreased (0.172066 --> 0.171517).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2114966
	speed: 1.8703s/iter; left time: 22172.6153s
Epoch: 15 cost time: 111.75677752494812
Epoch: 15, Steps: 139 | Train Loss: 0.2022290 Vali Loss: 0.1710927 Test Loss: 0.1977105
Validation loss decreased (0.171517 --> 0.171093).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1913885
	speed: 1.9423s/iter; left time: 22755.8148s
Epoch: 16 cost time: 113.02988386154175
Epoch: 16, Steps: 139 | Train Loss: 0.2020182 Vali Loss: 0.1710017 Test Loss: 0.1974499
Validation loss decreased (0.171093 --> 0.171002).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2087388
	speed: 1.8284s/iter; left time: 21167.2944s
Epoch: 17 cost time: 95.72770237922668
Epoch: 17, Steps: 139 | Train Loss: 0.2017306 Vali Loss: 0.1708270 Test Loss: 0.1972093
Validation loss decreased (0.171002 --> 0.170827).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1949094
	speed: 1.6027s/iter; left time: 18331.9301s
Epoch: 18 cost time: 97.15209627151489
Epoch: 18, Steps: 139 | Train Loss: 0.2015133 Vali Loss: 0.1706438 Test Loss: 0.1970144
Validation loss decreased (0.170827 --> 0.170644).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1990512
	speed: 1.7103s/iter; left time: 19324.5093s
Epoch: 19 cost time: 95.79128670692444
Epoch: 19, Steps: 139 | Train Loss: 0.2012535 Vali Loss: 0.1703469 Test Loss: 0.1968692
Validation loss decreased (0.170644 --> 0.170347).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2030393
	speed: 1.6611s/iter; left time: 18537.5801s
Epoch: 20 cost time: 96.98183751106262
Epoch: 20, Steps: 139 | Train Loss: 0.2011618 Vali Loss: 0.1703047 Test Loss: 0.1967249
Validation loss decreased (0.170347 --> 0.170305).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2037414
	speed: 1.6828s/iter; left time: 18545.7918s
Epoch: 21 cost time: 92.67733573913574
Epoch: 21, Steps: 139 | Train Loss: 0.2010558 Vali Loss: 0.1700262 Test Loss: 0.1966025
Validation loss decreased (0.170305 --> 0.170026).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1959756
	speed: 1.7811s/iter; left time: 19381.9354s
Epoch: 22 cost time: 114.23523902893066
Epoch: 22, Steps: 139 | Train Loss: 0.2008911 Vali Loss: 0.1702557 Test Loss: 0.1965036
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2025875
	speed: 1.9015s/iter; left time: 20427.6219s
Epoch: 23 cost time: 102.49174737930298
Epoch: 23, Steps: 139 | Train Loss: 0.2007775 Vali Loss: 0.1699433 Test Loss: 0.1964096
Validation loss decreased (0.170026 --> 0.169943).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2009693
	speed: 1.5931s/iter; left time: 16892.9785s
Epoch: 24 cost time: 95.17896962165833
Epoch: 24, Steps: 139 | Train Loss: 0.2006712 Vali Loss: 0.1698191 Test Loss: 0.1963489
Validation loss decreased (0.169943 --> 0.169819).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2000356
	speed: 1.5857s/iter; left time: 16594.2017s
Epoch: 25 cost time: 90.52812695503235
Epoch: 25, Steps: 139 | Train Loss: 0.2006545 Vali Loss: 0.1695857 Test Loss: 0.1962738
Validation loss decreased (0.169819 --> 0.169586).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2094738
	speed: 1.6445s/iter; left time: 16981.2980s
Epoch: 26 cost time: 91.39287614822388
Epoch: 26, Steps: 139 | Train Loss: 0.2005573 Vali Loss: 0.1696577 Test Loss: 0.1962304
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2142398
	speed: 1.4644s/iter; left time: 14917.4747s
Epoch: 27 cost time: 76.94451451301575
Epoch: 27, Steps: 139 | Train Loss: 0.2005290 Vali Loss: 0.1698233 Test Loss: 0.1961673
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2069639
	speed: 1.3392s/iter; left time: 13456.6051s
Epoch: 28 cost time: 77.77653455734253
Epoch: 28, Steps: 139 | Train Loss: 0.2004292 Vali Loss: 0.1694996 Test Loss: 0.1961282
Validation loss decreased (0.169586 --> 0.169500).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1983162
	speed: 1.3365s/iter; left time: 13243.3214s
Epoch: 29 cost time: 76.03932690620422
Epoch: 29, Steps: 139 | Train Loss: 0.2004453 Vali Loss: 0.1697363 Test Loss: 0.1960870
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1955754
	speed: 1.3158s/iter; left time: 12855.6171s
Epoch: 30 cost time: 70.04723739624023
Epoch: 30, Steps: 139 | Train Loss: 0.2004075 Vali Loss: 0.1697169 Test Loss: 0.1960513
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1992445
	speed: 1.3067s/iter; left time: 12584.7708s
Epoch: 31 cost time: 77.91148042678833
Epoch: 31, Steps: 139 | Train Loss: 0.2003847 Vali Loss: 0.1698225 Test Loss: 0.1960303
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1973311
	speed: 1.3238s/iter; left time: 12565.8398s
Epoch: 32 cost time: 77.51466417312622
Epoch: 32, Steps: 139 | Train Loss: 0.2003491 Vali Loss: 0.1694648 Test Loss: 0.1959973
Validation loss decreased (0.169500 --> 0.169465).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1956252
	speed: 1.3459s/iter; left time: 12587.9018s
Epoch: 33 cost time: 72.71236610412598
Epoch: 33, Steps: 139 | Train Loss: 0.2002602 Vali Loss: 0.1695903 Test Loss: 0.1959800
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2060004
	speed: 1.3189s/iter; left time: 12152.1256s
Epoch: 34 cost time: 80.45419478416443
Epoch: 34, Steps: 139 | Train Loss: 0.2002940 Vali Loss: 0.1695766 Test Loss: 0.1959663
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1986988
	speed: 1.3314s/iter; left time: 12082.4984s
Epoch: 35 cost time: 75.3635082244873
Epoch: 35, Steps: 139 | Train Loss: 0.2002446 Vali Loss: 0.1698603 Test Loss: 0.1959344
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2021563
	speed: 1.3574s/iter; left time: 12130.0666s
Epoch: 36 cost time: 76.47092580795288
Epoch: 36, Steps: 139 | Train Loss: 0.2003477 Vali Loss: 0.1694785 Test Loss: 0.1959269
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1947642
	speed: 1.3023s/iter; left time: 11456.1828s
Epoch: 37 cost time: 75.27277565002441
Epoch: 37, Steps: 139 | Train Loss: 0.2001962 Vali Loss: 0.1693260 Test Loss: 0.1959057
Validation loss decreased (0.169465 --> 0.169326).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2020867
	speed: 1.3159s/iter; left time: 11392.7855s
Epoch: 38 cost time: 73.31003141403198
Epoch: 38, Steps: 139 | Train Loss: 0.2002526 Vali Loss: 0.1695009 Test Loss: 0.1958955
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2096699
	speed: 1.3277s/iter; left time: 11311.0757s
Epoch: 39 cost time: 76.25862264633179
Epoch: 39, Steps: 139 | Train Loss: 0.2002136 Vali Loss: 0.1694409 Test Loss: 0.1958869
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2083707
	speed: 1.2799s/iter; left time: 10725.7907s
Epoch: 40 cost time: 73.50240159034729
Epoch: 40, Steps: 139 | Train Loss: 0.2002736 Vali Loss: 0.1693488 Test Loss: 0.1958715
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1919003
	speed: 1.2983s/iter; left time: 10698.9654s
Epoch: 41 cost time: 72.75756978988647
Epoch: 41, Steps: 139 | Train Loss: 0.2001042 Vali Loss: 0.1693499 Test Loss: 0.1958774
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2034882
	speed: 1.3049s/iter; left time: 10572.4486s
Epoch: 42 cost time: 75.73814082145691
Epoch: 42, Steps: 139 | Train Loss: 0.2001562 Vali Loss: 0.1694378 Test Loss: 0.1958555
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1980523
	speed: 1.3072s/iter; left time: 10408.9547s
Epoch: 43 cost time: 75.87116575241089
Epoch: 43, Steps: 139 | Train Loss: 0.2001098 Vali Loss: 0.1694344 Test Loss: 0.1958512
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2106851
	speed: 1.3048s/iter; left time: 10208.7312s
Epoch: 44 cost time: 76.65921974182129
Epoch: 44, Steps: 139 | Train Loss: 0.2000465 Vali Loss: 0.1693428 Test Loss: 0.1958565
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1988436
	speed: 1.4272s/iter; left time: 10967.7959s
Epoch: 45 cost time: 78.75733065605164
Epoch: 45, Steps: 139 | Train Loss: 0.2001269 Vali Loss: 0.1692459 Test Loss: 0.1958335
Validation loss decreased (0.169326 --> 0.169246).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1989185
	speed: 1.4093s/iter; left time: 10634.4722s
Epoch: 46 cost time: 80.84284973144531
Epoch: 46, Steps: 139 | Train Loss: 0.2001386 Vali Loss: 0.1694679 Test Loss: 0.1958293
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1940728
	speed: 1.4096s/iter; left time: 10440.6177s
Epoch: 47 cost time: 82.21363854408264
Epoch: 47, Steps: 139 | Train Loss: 0.2000584 Vali Loss: 0.1693935 Test Loss: 0.1958306
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1987899
	speed: 1.3871s/iter; left time: 10081.3345s
Epoch: 48 cost time: 81.92413759231567
Epoch: 48, Steps: 139 | Train Loss: 0.2001568 Vali Loss: 0.1694854 Test Loss: 0.1958327
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2024933
	speed: 1.4393s/iter; left time: 10260.8924s
Epoch: 49 cost time: 83.29249024391174
Epoch: 49, Steps: 139 | Train Loss: 0.2001539 Vali Loss: 0.1696466 Test Loss: 0.1958182
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2063059
	speed: 1.3846s/iter; left time: 9678.0104s
Epoch: 50 cost time: 78.91650438308716
Epoch: 50, Steps: 139 | Train Loss: 0.2001817 Vali Loss: 0.1694347 Test Loss: 0.1958121
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2066929
	speed: 1.3917s/iter; left time: 9534.6761s
Epoch: 51 cost time: 77.75813126564026
Epoch: 51, Steps: 139 | Train Loss: 0.2000298 Vali Loss: 0.1691742 Test Loss: 0.1958169
Validation loss decreased (0.169246 --> 0.169174).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1972743
	speed: 1.2392s/iter; left time: 8317.3218s
Epoch: 52 cost time: 74.12604355812073
Epoch: 52, Steps: 139 | Train Loss: 0.2001632 Vali Loss: 0.1691370 Test Loss: 0.1958093
Validation loss decreased (0.169174 --> 0.169137).  Saving model ...
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1890813
	speed: 1.2919s/iter; left time: 8491.6357s
Epoch: 53 cost time: 69.51338815689087
Epoch: 53, Steps: 139 | Train Loss: 0.2001762 Vali Loss: 0.1693961 Test Loss: 0.1958010
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1992416
	speed: 1.2331s/iter; left time: 7933.8996s
Epoch: 54 cost time: 72.66773772239685
Epoch: 54, Steps: 139 | Train Loss: 0.2000594 Vali Loss: 0.1690814 Test Loss: 0.1958029
Validation loss decreased (0.169137 --> 0.169081).  Saving model ...
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2003517
	speed: 1.2954s/iter; left time: 8154.6615s
Epoch: 55 cost time: 71.91143655776978
Epoch: 55, Steps: 139 | Train Loss: 0.2000793 Vali Loss: 0.1693174 Test Loss: 0.1957975
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1892950
	speed: 1.0977s/iter; left time: 6757.5966s
Epoch: 56 cost time: 59.92483305931091
Epoch: 56, Steps: 139 | Train Loss: 0.2000699 Vali Loss: 0.1692509 Test Loss: 0.1957988
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2114913
	speed: 0.9774s/iter; left time: 5881.2434s
Epoch: 57 cost time: 58.27959752082825
Epoch: 57, Steps: 139 | Train Loss: 0.2001807 Vali Loss: 0.1693923 Test Loss: 0.1957925
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1951308
	speed: 0.9806s/iter; left time: 5763.7098s
Epoch: 58 cost time: 54.91902709007263
Epoch: 58, Steps: 139 | Train Loss: 0.2001189 Vali Loss: 0.1692446 Test Loss: 0.1957955
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1963334
	speed: 1.0087s/iter; left time: 5789.0366s
Epoch: 59 cost time: 57.040026903152466
Epoch: 59, Steps: 139 | Train Loss: 0.2001049 Vali Loss: 0.1692961 Test Loss: 0.1957951
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1985313
	speed: 1.0098s/iter; left time: 5655.0046s
Epoch: 60 cost time: 60.86741352081299
Epoch: 60, Steps: 139 | Train Loss: 0.2001261 Vali Loss: 0.1694457 Test Loss: 0.1957911
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1977588
	speed: 0.9796s/iter; left time: 5349.6175s
Epoch: 61 cost time: 58.527429819107056
Epoch: 61, Steps: 139 | Train Loss: 0.2001423 Vali Loss: 0.1691403 Test Loss: 0.1957838
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1954386
	speed: 0.9805s/iter; left time: 5218.3519s
Epoch: 62 cost time: 55.45143103599548
Epoch: 62, Steps: 139 | Train Loss: 0.2000416 Vali Loss: 0.1692835 Test Loss: 0.1957844
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.2059497
	speed: 0.9595s/iter; left time: 4973.2613s
Epoch: 63 cost time: 55.21327257156372
Epoch: 63, Steps: 139 | Train Loss: 0.2001770 Vali Loss: 0.1693979 Test Loss: 0.1957819
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.2012097
	speed: 0.9927s/iter; left time: 5007.2031s
Epoch: 64 cost time: 57.291682720184326
Epoch: 64, Steps: 139 | Train Loss: 0.2000645 Vali Loss: 0.1692936 Test Loss: 0.1957872
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.2063992
	speed: 0.9302s/iter; left time: 4562.5551s
Epoch: 65 cost time: 53.728421449661255
Epoch: 65, Steps: 139 | Train Loss: 0.2001912 Vali Loss: 0.1690479 Test Loss: 0.1957808
Validation loss decreased (0.169081 --> 0.169048).  Saving model ...
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.1967272
	speed: 0.9348s/iter; left time: 4455.2466s
Epoch: 66 cost time: 51.24470329284668
Epoch: 66, Steps: 139 | Train Loss: 0.2000687 Vali Loss: 0.1694302 Test Loss: 0.1957801
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.1913539
	speed: 0.9110s/iter; left time: 4215.2731s
Epoch: 67 cost time: 55.47582173347473
Epoch: 67, Steps: 139 | Train Loss: 0.2000691 Vali Loss: 0.1692345 Test Loss: 0.1957817
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.1961924
	speed: 1.4903s/iter; left time: 6688.4612s
Epoch: 68 cost time: 93.69328927993774
Epoch: 68, Steps: 139 | Train Loss: 0.2000634 Vali Loss: 0.1693604 Test Loss: 0.1957794
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.2047263
	speed: 1.5364s/iter; left time: 6681.8188s
Epoch: 69 cost time: 93.19974637031555
Epoch: 69, Steps: 139 | Train Loss: 0.1999789 Vali Loss: 0.1693704 Test Loss: 0.1957761
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.1922045
	speed: 1.6006s/iter; left time: 6738.6347s
Epoch: 70 cost time: 90.48326134681702
Epoch: 70, Steps: 139 | Train Loss: 0.2000940 Vali Loss: 0.1693441 Test Loss: 0.1957776
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.1889726
	speed: 1.3993s/iter; left time: 5696.5928s
Epoch: 71 cost time: 80.27262663841248
Epoch: 71, Steps: 139 | Train Loss: 0.2000677 Vali Loss: 0.1694345 Test Loss: 0.1957752
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.1877024
	speed: 1.3091s/iter; left time: 5147.4571s
Epoch: 72 cost time: 75.62615466117859
Epoch: 72, Steps: 139 | Train Loss: 0.1999297 Vali Loss: 0.1694553 Test Loss: 0.1957794
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.1982040
	speed: 1.3799s/iter; left time: 5233.9162s
Epoch: 73 cost time: 77.66421556472778
Epoch: 73, Steps: 139 | Train Loss: 0.2000460 Vali Loss: 0.1692210 Test Loss: 0.1957776
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.1953109
	speed: 1.3476s/iter; left time: 4924.0748s
Epoch: 74 cost time: 78.91631507873535
Epoch: 74, Steps: 139 | Train Loss: 0.2000807 Vali Loss: 0.1692377 Test Loss: 0.1957754
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.2086510
	speed: 1.3751s/iter; left time: 4833.6392s
Epoch: 75 cost time: 76.54870939254761
Epoch: 75, Steps: 139 | Train Loss: 0.2000707 Vali Loss: 0.1693298 Test Loss: 0.1957724
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.1992305
	speed: 1.2556s/iter; left time: 4238.8314s
Epoch: 76 cost time: 70.80365204811096
Epoch: 76, Steps: 139 | Train Loss: 0.2000051 Vali Loss: 0.1692427 Test Loss: 0.1957764
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.1890352
	speed: 1.1323s/iter; left time: 3665.1668s
Epoch: 77 cost time: 66.30266976356506
Epoch: 77, Steps: 139 | Train Loss: 0.2000052 Vali Loss: 0.1696018 Test Loss: 0.1957739
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.1948055
	speed: 1.2030s/iter; left time: 3726.8337s
Epoch: 78 cost time: 69.95032954216003
Epoch: 78, Steps: 139 | Train Loss: 0.1999817 Vali Loss: 0.1691576 Test Loss: 0.1957750
EarlyStopping counter: 13 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.1976425
	speed: 1.1627s/iter; left time: 3440.4616s
Epoch: 79 cost time: 64.73929405212402
Epoch: 79, Steps: 139 | Train Loss: 0.2000196 Vali Loss: 0.1694441 Test Loss: 0.1957732
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.1997242
	speed: 1.1492s/iter; left time: 3240.7903s
Epoch: 80 cost time: 63.875035762786865
Epoch: 80, Steps: 139 | Train Loss: 0.1999656 Vali Loss: 0.1691811 Test Loss: 0.1957746
EarlyStopping counter: 15 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.2053913
	speed: 1.1944s/iter; left time: 3202.1856s
Epoch: 81 cost time: 71.26341414451599
Epoch: 81, Steps: 139 | Train Loss: 0.2000805 Vali Loss: 0.1690473 Test Loss: 0.1957741
Validation loss decreased (0.169048 --> 0.169047).  Saving model ...
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.2050518
	speed: 1.2504s/iter; left time: 3178.4417s
Epoch: 82 cost time: 73.94603395462036
Epoch: 82, Steps: 139 | Train Loss: 0.2000353 Vali Loss: 0.1692638 Test Loss: 0.1957700
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.1936192
	speed: 1.6109s/iter; left time: 3871.0572s
Epoch: 83 cost time: 98.06185865402222
Epoch: 83, Steps: 139 | Train Loss: 0.2000852 Vali Loss: 0.1692755 Test Loss: 0.1957716
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.1929550
	speed: 1.6844s/iter; left time: 3813.5278s
Epoch: 84 cost time: 97.56109952926636
Epoch: 84, Steps: 139 | Train Loss: 0.2000136 Vali Loss: 0.1691925 Test Loss: 0.1957730
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.2028587
	speed: 1.7090s/iter; left time: 3631.7252s
Epoch: 85 cost time: 93.99872899055481
Epoch: 85, Steps: 139 | Train Loss: 0.2000940 Vali Loss: 0.1694321 Test Loss: 0.1957714
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.1919425
	speed: 1.7249s/iter; left time: 3425.6341s
Epoch: 86 cost time: 97.94339895248413
Epoch: 86, Steps: 139 | Train Loss: 0.1999986 Vali Loss: 0.1694007 Test Loss: 0.1957707
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.2238646
	speed: 1.6423s/iter; left time: 3033.3796s
Epoch: 87 cost time: 87.94989013671875
Epoch: 87, Steps: 139 | Train Loss: 0.1999510 Vali Loss: 0.1691690 Test Loss: 0.1957718
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.2085368
	speed: 1.4875s/iter; left time: 2540.6434s
Epoch: 88 cost time: 86.31707262992859
Epoch: 88, Steps: 139 | Train Loss: 0.1999968 Vali Loss: 0.1694967 Test Loss: 0.1957704
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.1873358
	speed: 1.4228s/iter; left time: 2232.3716s
Epoch: 89 cost time: 82.75380206108093
Epoch: 89, Steps: 139 | Train Loss: 0.2000719 Vali Loss: 0.1693013 Test Loss: 0.1957696
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.1936128
	speed: 1.5452s/iter; left time: 2209.5775s
Epoch: 90 cost time: 90.11566662788391
Epoch: 90, Steps: 139 | Train Loss: 0.2000624 Vali Loss: 0.1693604 Test Loss: 0.1957697
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.204402478767869e-06
	iters: 100, epoch: 91 | loss: 0.2078231
	speed: 1.5552s/iter; left time: 2007.7096s
Epoch: 91 cost time: 87.33196902275085
Epoch: 91, Steps: 139 | Train Loss: 0.1999656 Vali Loss: 0.1695239 Test Loss: 0.1957700
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.944182354829475e-06
	iters: 100, epoch: 92 | loss: 0.2055947
	speed: 1.5005s/iter; left time: 1728.5350s
Epoch: 92 cost time: 87.94414734840393
Epoch: 92, Steps: 139 | Train Loss: 0.2001009 Vali Loss: 0.1694197 Test Loss: 0.1957697
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.696973237088e-06
	iters: 100, epoch: 93 | loss: 0.2044842
	speed: 1.4549s/iter; left time: 1473.8161s
Epoch: 93 cost time: 86.14821934700012
Epoch: 93, Steps: 139 | Train Loss: 0.2001509 Vali Loss: 0.1692186 Test Loss: 0.1957688
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.462124575233601e-06
	iters: 100, epoch: 94 | loss: 0.2157484
	speed: 1.5209s/iter; left time: 1329.2961s
Epoch: 94 cost time: 86.63532829284668
Epoch: 94, Steps: 139 | Train Loss: 0.2000383 Vali Loss: 0.1693182 Test Loss: 0.1957688
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.239018346471921e-06
	iters: 100, epoch: 95 | loss: 0.2211128
	speed: 1.4867s/iter; left time: 1092.6976s
Epoch: 95 cost time: 83.63347434997559
Epoch: 95, Steps: 139 | Train Loss: 0.2000244 Vali Loss: 0.1694860 Test Loss: 0.1957686
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.027067429148324e-06
	iters: 100, epoch: 96 | loss: 0.2031142
	speed: 1.5193s/iter; left time: 905.5111s
Epoch: 96 cost time: 88.24149656295776
Epoch: 96, Steps: 139 | Train Loss: 0.2000549 Vali Loss: 0.1691874 Test Loss: 0.1957680
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.825714057690908e-06
	iters: 100, epoch: 97 | loss: 0.1946309
	speed: 1.5116s/iter; left time: 690.7878s
Epoch: 97 cost time: 90.88338041305542
Epoch: 97, Steps: 139 | Train Loss: 0.2000191 Vali Loss: 0.1693096 Test Loss: 0.1957689
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.6344283548063623e-06
	iters: 100, epoch: 98 | loss: 0.1997491
	speed: 1.5421s/iter; left time: 490.4007s
Epoch: 98 cost time: 86.32997751235962
Epoch: 98, Steps: 139 | Train Loss: 0.1999824 Vali Loss: 0.1693478 Test Loss: 0.1957688
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.452706937066044e-06
	iters: 100, epoch: 99 | loss: 0.2016263
	speed: 1.5476s/iter; left time: 277.0145s
Epoch: 99 cost time: 87.40385961532593
Epoch: 99, Steps: 139 | Train Loss: 0.2000777 Vali Loss: 0.1692569 Test Loss: 0.1957682
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.2800715902127414e-06
	iters: 100, epoch: 100 | loss: 0.1980011
	speed: 1.3817s/iter; left time: 55.2667s
Epoch: 100 cost time: 76.23622989654541
Epoch: 100, Steps: 139 | Train Loss: 0.2000913 Vali Loss: 0.1689797 Test Loss: 0.1957679
Validation loss decreased (0.169047 --> 0.168980).  Saving model ...
Updating learning rate to 3.1160680107021042e-06
>>>>>>>testing : Electricity_180_j336_H4_FITS_custom_ftM_sl180_ll48_pl336_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4925
mse:0.19383522868156433, mae:0.29013004899024963, rse:0.4381851553916931, corr:[0.45861244 0.45995775 0.46063083 0.46085948 0.46112305 0.46118832
 0.46081218 0.46041983 0.4603317  0.46007648 0.45956275 0.4593889
 0.4595269  0.45917106 0.45894358 0.45903715 0.45910776 0.4591314
 0.45914367 0.45902145 0.45895046 0.45929036 0.4596749  0.45954433
 0.45904747 0.45893565 0.45883322 0.45862043 0.458485   0.45844862
 0.4583019  0.45808592 0.45799044 0.45793018 0.45772517 0.4575756
 0.45765886 0.45753253 0.45741308 0.4573587  0.45733157 0.45734033
 0.45733556 0.45721728 0.45709762 0.45716694 0.45729846 0.45729128
 0.45712173 0.4570936  0.45698524 0.45685568 0.45679754 0.45676127
 0.45668194 0.45665142 0.4567081  0.45672014 0.45661458 0.45650226
 0.45653078 0.456473   0.4565053  0.45651618 0.4564102  0.45632774
 0.45624736 0.45606995 0.45593196 0.45599842 0.45608097 0.4559547
 0.45574057 0.4557821  0.45572466 0.45556334 0.4555247  0.4555731
 0.45552853 0.45543787 0.45547363 0.45551643 0.4554452  0.45539904
 0.45548242 0.4553584  0.45526886 0.45528498 0.45529783 0.45526505
 0.4552493  0.45520964 0.45515665 0.45525774 0.45542702 0.45541778
 0.4552005  0.45520306 0.45520183 0.45512477 0.4550856  0.4551282
 0.455154   0.4551434  0.45517954 0.45522124 0.45516157 0.45510203
 0.45519808 0.45516032 0.4551216  0.45506462 0.4549921  0.45495784
 0.45493475 0.4548031  0.45463297 0.45463362 0.45473075 0.45477158
 0.4546968  0.45482233 0.4548843  0.45487866 0.45494455 0.45503557
 0.45504516 0.45503053 0.45511878 0.45519245 0.45515624 0.45513847
 0.45524746 0.45520788 0.45516866 0.4551504  0.45511103 0.45506844
 0.4550166  0.45489264 0.4548114  0.45497668 0.4552205  0.4552802
 0.45515227 0.45528105 0.45541844 0.4554441  0.45548004 0.45559797
 0.4556703  0.4556728  0.45571274 0.45577967 0.45582435 0.45594522
 0.45621097 0.45639682 0.45638964 0.45624053 0.45629916 0.4565267
 0.45665237 0.45659873 0.45680195 0.457359   0.4575812  0.45710954
 0.45641616 0.45594072 0.45555258 0.4552402  0.4550327  0.45486042
 0.4546903  0.45456904 0.45448098 0.4542933  0.45398715 0.45375928
 0.4537383  0.4535709  0.4534467  0.4533629  0.45323426 0.45314115
 0.45311886 0.45307162 0.4530618  0.45325106 0.45336998 0.45310265
 0.4526532  0.45254797 0.4524365  0.45222706 0.4521272  0.45212904
 0.45204467 0.45187846 0.45179355 0.4517294  0.4515642  0.45144913
 0.45153224 0.45137385 0.45129183 0.4513817  0.45146963 0.45148876
 0.45147786 0.4514139  0.45135334 0.45142955 0.45156428 0.45155054
 0.45129588 0.45126686 0.45122874 0.45109603 0.45101854 0.4510408
 0.45103    0.45096663 0.4509482  0.4509105  0.45077774 0.45066497
 0.45079055 0.45074725 0.45069042 0.45066229 0.45065054 0.45068413
 0.4507132  0.4506177  0.4504906  0.45052603 0.45062244 0.45059258
 0.45037425 0.4504093  0.45040464 0.4502944  0.45027697 0.45034248
 0.45032027 0.4502176  0.45022395 0.45025623 0.45017374 0.4500733
 0.4501681  0.4500776  0.45004562 0.4501239  0.45013496 0.45006165
 0.45005706 0.45012176 0.45014304 0.45021364 0.45034006 0.45035225
 0.45011532 0.4501546  0.45019183 0.45009008 0.4500537  0.45016417
 0.45019847 0.45007414 0.44998688 0.4500008  0.44996142 0.4499162
 0.45008272 0.4500008  0.44988605 0.4498911  0.4499631  0.45000952
 0.44999203 0.44987017 0.44971526 0.44969627 0.4498287  0.4499409
 0.44978926 0.44990146 0.45002383 0.45002922 0.4500222  0.45005593
 0.45007297 0.45004916 0.45008183 0.4501196  0.45005015 0.45003295
 0.45032316 0.45044598 0.45045638 0.45041728 0.45037854 0.45040402
 0.45044953 0.4503813  0.45023432 0.4502648  0.45043743 0.4505542
 0.4504214  0.45050135 0.45056975 0.45055258 0.45060486 0.45064506
 0.45049483 0.4503569  0.45054674 0.4508712  0.45105505 0.45125636
 0.45175502 0.45214394 0.45238402 0.45247942 0.45241496 0.45224938
 0.45220578 0.45222586 0.4521659  0.4522663  0.4527481  0.45131075]
