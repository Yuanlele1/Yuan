Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_360_j336_H6', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_360_j336_H6_FITS_custom_ftM_sl360_ll48_pl336_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17717
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=106, out_features=204, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  888486912.0
params:  21828.0
Trainable parameters:  21828
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6106046
	speed: 0.7243s/iter; left time: 9923.0805s
Epoch: 1 cost time: 101.01084876060486
Epoch: 1, Steps: 138 | Train Loss: 0.7893555 Vali Loss: 0.4524722 Test Loss: 0.5303362
Validation loss decreased (inf --> 0.452472).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3926066
	speed: 1.6234s/iter; left time: 22018.6782s
Epoch: 2 cost time: 94.26384663581848
Epoch: 2, Steps: 138 | Train Loss: 0.4385896 Vali Loss: 0.2959464 Test Loss: 0.3499997
Validation loss decreased (0.452472 --> 0.295946).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2753823
	speed: 1.6404s/iter; left time: 22022.0248s
Epoch: 3 cost time: 97.34865736961365
Epoch: 3, Steps: 138 | Train Loss: 0.3059452 Vali Loss: 0.2188567 Test Loss: 0.2598507
Validation loss decreased (0.295946 --> 0.218857).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2310818
	speed: 1.6912s/iter; left time: 22470.3721s
Epoch: 4 cost time: 100.25743341445923
Epoch: 4, Steps: 138 | Train Loss: 0.2403680 Vali Loss: 0.1818569 Test Loss: 0.2157731
Validation loss decreased (0.218857 --> 0.181857).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2122510
	speed: 1.6776s/iter; left time: 22059.3546s
Epoch: 5 cost time: 101.89956641197205
Epoch: 5, Steps: 138 | Train Loss: 0.2092204 Vali Loss: 0.1651008 Test Loss: 0.1951537
Validation loss decreased (0.181857 --> 0.165101).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1931396
	speed: 1.6633s/iter; left time: 21641.1514s
Epoch: 6 cost time: 98.25466871261597
Epoch: 6, Steps: 138 | Train Loss: 0.1951614 Vali Loss: 0.1577740 Test Loss: 0.1858692
Validation loss decreased (0.165101 --> 0.157774).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1867622
	speed: 1.7119s/iter; left time: 22037.8572s
Epoch: 7 cost time: 100.9973406791687
Epoch: 7, Steps: 138 | Train Loss: 0.1890481 Vali Loss: 0.1550450 Test Loss: 0.1817031
Validation loss decreased (0.157774 --> 0.155045).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1865300
	speed: 1.7583s/iter; left time: 22391.4260s
Epoch: 8 cost time: 103.64806127548218
Epoch: 8, Steps: 138 | Train Loss: 0.1863668 Vali Loss: 0.1535904 Test Loss: 0.1798285
Validation loss decreased (0.155045 --> 0.153590).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1977959
	speed: 1.7465s/iter; left time: 22000.5295s
Epoch: 9 cost time: 105.84826374053955
Epoch: 9, Steps: 138 | Train Loss: 0.1851751 Vali Loss: 0.1529482 Test Loss: 0.1789090
Validation loss decreased (0.153590 --> 0.152948).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1712257
	speed: 1.7355s/iter; left time: 21622.0025s
Epoch: 10 cost time: 105.25560879707336
Epoch: 10, Steps: 138 | Train Loss: 0.1845419 Vali Loss: 0.1529260 Test Loss: 0.1784135
Validation loss decreased (0.152948 --> 0.152926).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1905998
	speed: 1.6821s/iter; left time: 20724.9483s
Epoch: 11 cost time: 100.20475220680237
Epoch: 11, Steps: 138 | Train Loss: 0.1842661 Vali Loss: 0.1524560 Test Loss: 0.1781544
Validation loss decreased (0.152926 --> 0.152456).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1935300
	speed: 1.7355s/iter; left time: 21143.2047s
Epoch: 12 cost time: 103.00133991241455
Epoch: 12, Steps: 138 | Train Loss: 0.1841086 Vali Loss: 0.1526109 Test Loss: 0.1779805
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1831202
	speed: 1.6760s/iter; left time: 20187.6384s
Epoch: 13 cost time: 99.22311067581177
Epoch: 13, Steps: 138 | Train Loss: 0.1839683 Vali Loss: 0.1523965 Test Loss: 0.1778609
Validation loss decreased (0.152456 --> 0.152396).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1909853
	speed: 1.5972s/iter; left time: 19018.2253s
Epoch: 14 cost time: 96.86701369285583
Epoch: 14, Steps: 138 | Train Loss: 0.1838573 Vali Loss: 0.1525604 Test Loss: 0.1778141
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1730668
	speed: 1.6440s/iter; left time: 19348.0164s
Epoch: 15 cost time: 96.808922290802
Epoch: 15, Steps: 138 | Train Loss: 0.1838736 Vali Loss: 0.1524314 Test Loss: 0.1777395
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1907629
	speed: 1.7099s/iter; left time: 19888.2067s
Epoch: 16 cost time: 99.95367956161499
Epoch: 16, Steps: 138 | Train Loss: 0.1837917 Vali Loss: 0.1523832 Test Loss: 0.1776989
Validation loss decreased (0.152396 --> 0.152383).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1697203
	speed: 1.6833s/iter; left time: 19346.4896s
Epoch: 17 cost time: 102.12818956375122
Epoch: 17, Steps: 138 | Train Loss: 0.1837560 Vali Loss: 0.1521466 Test Loss: 0.1776604
Validation loss decreased (0.152383 --> 0.152147).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1865890
	speed: 1.6249s/iter; left time: 18451.1203s
Epoch: 18 cost time: 96.34366297721863
Epoch: 18, Steps: 138 | Train Loss: 0.1838015 Vali Loss: 0.1523485 Test Loss: 0.1776268
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1866765
	speed: 1.5832s/iter; left time: 17759.2552s
Epoch: 19 cost time: 88.96841502189636
Epoch: 19, Steps: 138 | Train Loss: 0.1836409 Vali Loss: 0.1523445 Test Loss: 0.1776246
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1916600
	speed: 1.5869s/iter; left time: 17581.7027s
Epoch: 20 cost time: 90.37716817855835
Epoch: 20, Steps: 138 | Train Loss: 0.1836889 Vali Loss: 0.1522933 Test Loss: 0.1776152
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1714553
	speed: 1.5574s/iter; left time: 17039.9851s
Epoch: 21 cost time: 92.60159921646118
Epoch: 21, Steps: 138 | Train Loss: 0.1836007 Vali Loss: 0.1522674 Test Loss: 0.1775943
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1837149
	speed: 1.5595s/iter; left time: 16847.2428s
Epoch: 22 cost time: 90.85285973548889
Epoch: 22, Steps: 138 | Train Loss: 0.1836519 Vali Loss: 0.1522093 Test Loss: 0.1775699
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2019041
	speed: 1.6344s/iter; left time: 17430.8822s
Epoch: 23 cost time: 95.55442333221436
Epoch: 23, Steps: 138 | Train Loss: 0.1836431 Vali Loss: 0.1521225 Test Loss: 0.1775683
Validation loss decreased (0.152147 --> 0.152122).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1755543
	speed: 1.6400s/iter; left time: 17264.7904s
Epoch: 24 cost time: 96.22335433959961
Epoch: 24, Steps: 138 | Train Loss: 0.1835744 Vali Loss: 0.1519942 Test Loss: 0.1775408
Validation loss decreased (0.152122 --> 0.151994).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1955745
	speed: 1.6003s/iter; left time: 16625.4607s
Epoch: 25 cost time: 96.73601746559143
Epoch: 25, Steps: 138 | Train Loss: 0.1835671 Vali Loss: 0.1522873 Test Loss: 0.1775343
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1826798
	speed: 1.6124s/iter; left time: 16528.6692s
Epoch: 26 cost time: 94.57883644104004
Epoch: 26, Steps: 138 | Train Loss: 0.1834832 Vali Loss: 0.1523588 Test Loss: 0.1775477
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1917848
	speed: 1.5966s/iter; left time: 16146.2017s
Epoch: 27 cost time: 92.48074245452881
Epoch: 27, Steps: 138 | Train Loss: 0.1835228 Vali Loss: 0.1520158 Test Loss: 0.1775266
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1781200
	speed: 1.5705s/iter; left time: 15665.9131s
Epoch: 28 cost time: 92.25750803947449
Epoch: 28, Steps: 138 | Train Loss: 0.1834815 Vali Loss: 0.1522390 Test Loss: 0.1775197
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1895938
	speed: 1.5372s/iter; left time: 15121.1167s
Epoch: 29 cost time: 94.57804346084595
Epoch: 29, Steps: 138 | Train Loss: 0.1834895 Vali Loss: 0.1517885 Test Loss: 0.1775146
Validation loss decreased (0.151994 --> 0.151789).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1849763
	speed: 1.5435s/iter; left time: 14970.6079s
Epoch: 30 cost time: 88.00215482711792
Epoch: 30, Steps: 138 | Train Loss: 0.1834958 Vali Loss: 0.1521451 Test Loss: 0.1774940
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1845402
	speed: 1.5895s/iter; left time: 15197.5579s
Epoch: 31 cost time: 95.72920632362366
Epoch: 31, Steps: 138 | Train Loss: 0.1834676 Vali Loss: 0.1520016 Test Loss: 0.1774936
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1782904
	speed: 1.5388s/iter; left time: 14500.5261s
Epoch: 32 cost time: 90.70990443229675
Epoch: 32, Steps: 138 | Train Loss: 0.1834932 Vali Loss: 0.1521121 Test Loss: 0.1774936
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1920249
	speed: 1.5040s/iter; left time: 13964.4205s
Epoch: 33 cost time: 91.05949974060059
Epoch: 33, Steps: 138 | Train Loss: 0.1834733 Vali Loss: 0.1520614 Test Loss: 0.1774853
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1767168
	speed: 1.5181s/iter; left time: 13886.0647s
Epoch: 34 cost time: 89.12448334693909
Epoch: 34, Steps: 138 | Train Loss: 0.1834754 Vali Loss: 0.1522411 Test Loss: 0.1774770
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1911045
	speed: 1.5465s/iter; left time: 13932.0150s
Epoch: 35 cost time: 88.54674816131592
Epoch: 35, Steps: 138 | Train Loss: 0.1834605 Vali Loss: 0.1520967 Test Loss: 0.1774754
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1974835
	speed: 1.5258s/iter; left time: 13535.2262s
Epoch: 36 cost time: 92.47593760490417
Epoch: 36, Steps: 138 | Train Loss: 0.1834454 Vali Loss: 0.1521975 Test Loss: 0.1774666
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1792116
	speed: 1.4619s/iter; left time: 12766.7356s
Epoch: 37 cost time: 89.3343813419342
Epoch: 37, Steps: 138 | Train Loss: 0.1834354 Vali Loss: 0.1521341 Test Loss: 0.1774709
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1810713
	speed: 1.5364s/iter; left time: 13205.7140s
Epoch: 38 cost time: 89.44143509864807
Epoch: 38, Steps: 138 | Train Loss: 0.1833767 Vali Loss: 0.1520230 Test Loss: 0.1774751
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1805151
	speed: 1.6044s/iter; left time: 13568.6002s
Epoch: 39 cost time: 95.61924028396606
Epoch: 39, Steps: 138 | Train Loss: 0.1834789 Vali Loss: 0.1522119 Test Loss: 0.1774590
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1877996
	speed: 1.5504s/iter; left time: 12897.4273s
Epoch: 40 cost time: 95.32212400436401
Epoch: 40, Steps: 138 | Train Loss: 0.1834135 Vali Loss: 0.1520063 Test Loss: 0.1774661
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1898841
	speed: 1.5760s/iter; left time: 12893.2089s
Epoch: 41 cost time: 90.75003719329834
Epoch: 41, Steps: 138 | Train Loss: 0.1834374 Vali Loss: 0.1519834 Test Loss: 0.1774630
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1887484
	speed: 1.5481s/iter; left time: 12451.1073s
Epoch: 42 cost time: 93.40291380882263
Epoch: 42, Steps: 138 | Train Loss: 0.1833869 Vali Loss: 0.1520309 Test Loss: 0.1774685
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1705132
	speed: 1.4864s/iter; left time: 11750.2904s
Epoch: 43 cost time: 78.40159821510315
Epoch: 43, Steps: 138 | Train Loss: 0.1833901 Vali Loss: 0.1518804 Test Loss: 0.1774610
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1827830
	speed: 1.2436s/iter; left time: 9658.9943s
Epoch: 44 cost time: 77.95595192909241
Epoch: 44, Steps: 138 | Train Loss: 0.1833657 Vali Loss: 0.1520773 Test Loss: 0.1774512
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1935136
	speed: 1.2004s/iter; left time: 9158.1138s
Epoch: 45 cost time: 69.69097399711609
Epoch: 45, Steps: 138 | Train Loss: 0.1833862 Vali Loss: 0.1520113 Test Loss: 0.1774514
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1787506
	speed: 1.2011s/iter; left time: 8997.7211s
Epoch: 46 cost time: 69.43748497962952
Epoch: 46, Steps: 138 | Train Loss: 0.1833827 Vali Loss: 0.1521951 Test Loss: 0.1774446
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1827253
	speed: 1.1439s/iter; left time: 8410.9656s
Epoch: 47 cost time: 65.87274312973022
Epoch: 47, Steps: 138 | Train Loss: 0.1833736 Vali Loss: 0.1517037 Test Loss: 0.1774507
Validation loss decreased (0.151789 --> 0.151704).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1968176
	speed: 1.1435s/iter; left time: 8250.2273s
Epoch: 48 cost time: 65.98865723609924
Epoch: 48, Steps: 138 | Train Loss: 0.1834354 Vali Loss: 0.1521243 Test Loss: 0.1774485
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1795827
	speed: 1.1253s/iter; left time: 7963.6680s
Epoch: 49 cost time: 67.56248950958252
Epoch: 49, Steps: 138 | Train Loss: 0.1833950 Vali Loss: 0.1520871 Test Loss: 0.1774415
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1720011
	speed: 1.1557s/iter; left time: 8019.0626s
Epoch: 50 cost time: 66.3898093700409
Epoch: 50, Steps: 138 | Train Loss: 0.1834027 Vali Loss: 0.1519141 Test Loss: 0.1774407
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1730714
	speed: 1.1997s/iter; left time: 8159.1360s
Epoch: 51 cost time: 72.80639576911926
Epoch: 51, Steps: 138 | Train Loss: 0.1834290 Vali Loss: 0.1521395 Test Loss: 0.1774466
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1975910
	speed: 1.1986s/iter; left time: 7986.1716s
Epoch: 52 cost time: 74.15591645240784
Epoch: 52, Steps: 138 | Train Loss: 0.1834323 Vali Loss: 0.1518943 Test Loss: 0.1774398
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1989147
	speed: 1.1544s/iter; left time: 7532.2083s
Epoch: 53 cost time: 71.20255303382874
Epoch: 53, Steps: 138 | Train Loss: 0.1834122 Vali Loss: 0.1519935 Test Loss: 0.1774395
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1831074
	speed: 1.1675s/iter; left time: 7456.9988s
Epoch: 54 cost time: 67.13422632217407
Epoch: 54, Steps: 138 | Train Loss: 0.1834034 Vali Loss: 0.1522205 Test Loss: 0.1774385
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1850684
	speed: 1.1622s/iter; left time: 7262.7111s
Epoch: 55 cost time: 69.89802479743958
Epoch: 55, Steps: 138 | Train Loss: 0.1833728 Vali Loss: 0.1518658 Test Loss: 0.1774405
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1799165
	speed: 1.1664s/iter; left time: 7128.0045s
Epoch: 56 cost time: 70.30503535270691
Epoch: 56, Steps: 138 | Train Loss: 0.1834116 Vali Loss: 0.1519317 Test Loss: 0.1774358
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.1807202
	speed: 1.1663s/iter; left time: 6966.4559s
Epoch: 57 cost time: 70.37337613105774
Epoch: 57, Steps: 138 | Train Loss: 0.1834121 Vali Loss: 0.1519683 Test Loss: 0.1774355
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1791490
	speed: 1.1446s/iter; left time: 6678.6747s
Epoch: 58 cost time: 64.5252046585083
Epoch: 58, Steps: 138 | Train Loss: 0.1833933 Vali Loss: 0.1518944 Test Loss: 0.1774359
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1873508
	speed: 1.1917s/iter; left time: 6789.0615s
Epoch: 59 cost time: 69.2608425617218
Epoch: 59, Steps: 138 | Train Loss: 0.1833924 Vali Loss: 0.1522258 Test Loss: 0.1774266
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1768402
	speed: 1.1693s/iter; left time: 6500.0487s
Epoch: 60 cost time: 70.45511317253113
Epoch: 60, Steps: 138 | Train Loss: 0.1833533 Vali Loss: 0.1521106 Test Loss: 0.1774247
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1879181
	speed: 1.1711s/iter; left time: 6348.3294s
Epoch: 61 cost time: 69.35792779922485
Epoch: 61, Steps: 138 | Train Loss: 0.1833908 Vali Loss: 0.1519436 Test Loss: 0.1774256
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.2010173
	speed: 1.2006s/iter; left time: 6342.5319s
Epoch: 62 cost time: 69.11823225021362
Epoch: 62, Steps: 138 | Train Loss: 0.1833943 Vali Loss: 0.1518130 Test Loss: 0.1774255
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1817510
	speed: 1.2040s/iter; left time: 6194.8124s
Epoch: 63 cost time: 73.77053380012512
Epoch: 63, Steps: 138 | Train Loss: 0.1834284 Vali Loss: 0.1518321 Test Loss: 0.1774254
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1751208
	speed: 1.0966s/iter; left time: 5490.5709s
Epoch: 64 cost time: 58.02148365974426
Epoch: 64, Steps: 138 | Train Loss: 0.1833887 Vali Loss: 0.1519807 Test Loss: 0.1774239
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.1817031
	speed: 0.8257s/iter; left time: 4020.2945s
Epoch: 65 cost time: 49.025837421417236
Epoch: 65, Steps: 138 | Train Loss: 0.1833860 Vali Loss: 0.1520805 Test Loss: 0.1774224
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.1754667
	speed: 0.8190s/iter; left time: 3874.6031s
Epoch: 66 cost time: 46.02556133270264
Epoch: 66, Steps: 138 | Train Loss: 0.1833685 Vali Loss: 0.1521118 Test Loss: 0.1774244
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.1834916
	speed: 0.8285s/iter; left time: 3805.0902s
Epoch: 67 cost time: 48.52901816368103
Epoch: 67, Steps: 138 | Train Loss: 0.1833918 Vali Loss: 0.1522409 Test Loss: 0.1774230
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_360_j336_H6_FITS_custom_ftM_sl360_ll48_pl336_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4925
mse:0.1753116250038147, mae:0.27236637473106384, rse:0.4167221784591675, corr:[0.4591602  0.45868075 0.46127433 0.46218595 0.46199355 0.46269268
 0.46304396 0.46251836 0.4620059  0.46179003 0.46158108 0.46129417
 0.46109104 0.46111262 0.46127093 0.4613317  0.46129775 0.46134058
 0.46133456 0.4611499  0.46108663 0.46114925 0.46114984 0.46129677
 0.46160442 0.4618897  0.4617791  0.46159235 0.4615638  0.46146154
 0.4611449  0.46089658 0.46082774 0.46076426 0.4606255  0.46054882
 0.46058404 0.46064994 0.46069723 0.46071157 0.46071184 0.4607185
 0.46065822 0.46048445 0.4603753  0.4602837  0.46018493 0.46032333
 0.4605683  0.46065074 0.46051368 0.4604182  0.46040988 0.46027878
 0.4600716  0.45996815 0.45996264 0.45994148 0.45989117 0.45989352
 0.4599514  0.46002123 0.460058   0.46003968 0.46001095 0.46003014
 0.45995605 0.45971137 0.45953527 0.45941362 0.4593536  0.4594638
 0.45958078 0.45956972 0.45948038 0.4594302  0.4593524  0.45922047
 0.45914766 0.45915604 0.45912775 0.4590611  0.4590256  0.45904532
 0.4590798  0.45908275 0.45906675 0.45904353 0.45902225 0.45900938
 0.4590179  0.4590035  0.45897087 0.4589193  0.45892474 0.45908278
 0.45916986 0.45912683 0.45909503 0.45912588 0.45907265 0.45894763
 0.45892042 0.4589776  0.45895296 0.45888457 0.45887157 0.45890483
 0.4589224  0.45891348 0.45890316 0.4589003  0.45888498 0.45886713
 0.45885408 0.45875618 0.45865434 0.45856673 0.45857838 0.45880884
 0.45897362 0.45895556 0.45894298 0.45901176 0.45900348 0.45892975
 0.45893654 0.458986   0.45897347 0.45893064 0.4589057  0.4588946
 0.45888773 0.45888323 0.45886183 0.45883468 0.4588256  0.45883593
 0.45880365 0.45868784 0.45862594 0.45856524 0.45857656 0.4588975
 0.45924488 0.45937738 0.4594698  0.4595937  0.45959678 0.45953587
 0.45954558 0.45959258 0.45956674 0.45951238 0.45949432 0.45950407
 0.45949167 0.459449   0.45942736 0.45942312 0.45942977 0.4594667
 0.45946014 0.45927832 0.4591617  0.4590727  0.45895347 0.45891422
 0.4588058  0.45867574 0.458557   0.45845953 0.4583332  0.45820022
 0.45813406 0.4580882  0.45798057 0.4578525  0.45773414 0.45764354
 0.45755297 0.45742568 0.457308   0.4572215  0.45709723 0.45694128
 0.45680282 0.45663935 0.4564984  0.45641547 0.45640498 0.45645672
 0.45645744 0.45648792 0.45652762 0.45652452 0.4564504  0.45638824
 0.45635176 0.45628688 0.4561694  0.45606622 0.45598456 0.45595407
 0.45593548 0.45586902 0.45579046 0.45573956 0.45571554 0.45571342
 0.45567706 0.455525   0.45539126 0.4553321  0.45534667 0.45546606
 0.45558697 0.45573443 0.45584202 0.4558426  0.45577636 0.4557628
 0.45577815 0.45574814 0.45566112 0.45555958 0.4555021  0.45545572
 0.4553979  0.45533228 0.4552978  0.4552859  0.45526278 0.45523438
 0.45517996 0.4550068  0.45484728 0.45478958 0.45483452 0.45495728
 0.45503908 0.4551459  0.45523417 0.45524114 0.45519584 0.45519096
 0.45520282 0.45515215 0.45505285 0.4549541  0.45486754 0.45479846
 0.45472693 0.4546611  0.45462275 0.45461428 0.45458215 0.45455348
 0.45458674 0.4546066  0.45459834 0.45462644 0.454708   0.45481375
 0.45488024 0.4550002  0.4550929  0.45508605 0.45503294 0.45504454
 0.4550365  0.4549383  0.4547934  0.45467833 0.45460024 0.4545115
 0.45443037 0.4543812  0.45440096 0.45442998 0.45440844 0.45441118
 0.45447737 0.45441684 0.4543249  0.45433256 0.45445898 0.45464882
 0.45479986 0.45496088 0.45504603 0.4550144  0.45496628 0.45496136
 0.45490408 0.45475104 0.45459688 0.4545001  0.45438963 0.45428357
 0.45422053 0.45420393 0.4542538  0.45431495 0.45431152 0.4543444
 0.45442778 0.45438185 0.45431498 0.45437416 0.45456374 0.45488045
 0.45521867 0.455423   0.4554393  0.4553305  0.45523685 0.45517218
 0.4550193  0.45484066 0.4547782  0.454752   0.4546509  0.45458433
 0.45466936 0.454868   0.455031   0.4549971  0.45492405 0.45504373
 0.45497173 0.4543928  0.45429048 0.4544089  0.45372954 0.45466456]
