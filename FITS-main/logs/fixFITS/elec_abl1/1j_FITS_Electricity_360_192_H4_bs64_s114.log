Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=74, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_360_j192_H4', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_360_j192_H4_FITS_custom_ftM_sl360_ll48_pl192_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17861
val 2441
test 5069
Model(
  (freq_upsampler): Linear(in_features=74, out_features=113, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  343577856.0
params:  8475.0
Trainable parameters:  8475
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6663536
	speed: 0.6825s/iter; left time: 9418.5899s
Epoch: 1 cost time: 96.05515623092651
Epoch: 1, Steps: 139 | Train Loss: 0.8622160 Vali Loss: 0.4540402 Test Loss: 0.5295917
Validation loss decreased (inf --> 0.454040).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3494058
	speed: 1.4141s/iter; left time: 19318.9128s
Epoch: 2 cost time: 80.38883996009827
Epoch: 2, Steps: 139 | Train Loss: 0.4016394 Vali Loss: 0.2521221 Test Loss: 0.2988683
Validation loss decreased (0.454040 --> 0.252122).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2295058
	speed: 1.3813s/iter; left time: 18679.4605s
Epoch: 3 cost time: 86.686767578125
Epoch: 3, Steps: 139 | Train Loss: 0.2502143 Vali Loss: 0.1800512 Test Loss: 0.2145632
Validation loss decreased (0.252122 --> 0.180051).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1904833
	speed: 1.3946s/iter; left time: 18664.6582s
Epoch: 4 cost time: 84.19566321372986
Epoch: 4, Steps: 139 | Train Loss: 0.1972632 Vali Loss: 0.1570310 Test Loss: 0.1866969
Validation loss decreased (0.180051 --> 0.157031).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1827982
	speed: 1.3855s/iter; left time: 18350.3601s
Epoch: 5 cost time: 84.84135961532593
Epoch: 5, Steps: 139 | Train Loss: 0.1805109 Vali Loss: 0.1503880 Test Loss: 0.1782995
Validation loss decreased (0.157031 --> 0.150388).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1726180
	speed: 1.4255s/iter; left time: 18682.7974s
Epoch: 6 cost time: 87.00780010223389
Epoch: 6, Steps: 139 | Train Loss: 0.1756389 Vali Loss: 0.1484958 Test Loss: 0.1757413
Validation loss decreased (0.150388 --> 0.148496).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1677397
	speed: 1.3845s/iter; left time: 17952.8339s
Epoch: 7 cost time: 79.49158048629761
Epoch: 7, Steps: 139 | Train Loss: 0.1740028 Vali Loss: 0.1478045 Test Loss: 0.1748177
Validation loss decreased (0.148496 --> 0.147805).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1837547
	speed: 1.4025s/iter; left time: 17991.7156s
Epoch: 8 cost time: 89.27837419509888
Epoch: 8, Steps: 139 | Train Loss: 0.1733441 Vali Loss: 0.1474601 Test Loss: 0.1743454
Validation loss decreased (0.147805 --> 0.147460).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1673357
	speed: 1.4295s/iter; left time: 18138.4246s
Epoch: 9 cost time: 90.3901674747467
Epoch: 9, Steps: 139 | Train Loss: 0.1728782 Vali Loss: 0.1472345 Test Loss: 0.1740542
Validation loss decreased (0.147460 --> 0.147235).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1683571
	speed: 1.4422s/iter; left time: 18099.3274s
Epoch: 10 cost time: 90.75335955619812
Epoch: 10, Steps: 139 | Train Loss: 0.1725737 Vali Loss: 0.1469931 Test Loss: 0.1738306
Validation loss decreased (0.147235 --> 0.146993).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1697700
	speed: 1.4629s/iter; left time: 18155.7488s
Epoch: 11 cost time: 87.38849306106567
Epoch: 11, Steps: 139 | Train Loss: 0.1723223 Vali Loss: 0.1468303 Test Loss: 0.1736251
Validation loss decreased (0.146993 --> 0.146830).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1730154
	speed: 1.4475s/iter; left time: 17764.1314s
Epoch: 12 cost time: 82.28900837898254
Epoch: 12, Steps: 139 | Train Loss: 0.1721054 Vali Loss: 0.1467590 Test Loss: 0.1734811
Validation loss decreased (0.146830 --> 0.146759).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1647569
	speed: 1.4173s/iter; left time: 17195.7515s
Epoch: 13 cost time: 88.16147899627686
Epoch: 13, Steps: 139 | Train Loss: 0.1719982 Vali Loss: 0.1466472 Test Loss: 0.1733905
Validation loss decreased (0.146759 --> 0.146647).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1668898
	speed: 1.3275s/iter; left time: 15922.1076s
Epoch: 14 cost time: 82.14410924911499
Epoch: 14, Steps: 139 | Train Loss: 0.1719395 Vali Loss: 0.1465939 Test Loss: 0.1732727
Validation loss decreased (0.146647 --> 0.146594).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1610066
	speed: 1.3977s/iter; left time: 16570.0148s
Epoch: 15 cost time: 84.46988606452942
Epoch: 15, Steps: 139 | Train Loss: 0.1718526 Vali Loss: 0.1465110 Test Loss: 0.1732275
Validation loss decreased (0.146594 --> 0.146511).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1674464
	speed: 1.3674s/iter; left time: 16020.9429s
Epoch: 16 cost time: 83.38842105865479
Epoch: 16, Steps: 139 | Train Loss: 0.1716594 Vali Loss: 0.1464212 Test Loss: 0.1731606
Validation loss decreased (0.146511 --> 0.146421).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1776292
	speed: 1.3615s/iter; left time: 15762.2271s
Epoch: 17 cost time: 80.63175296783447
Epoch: 17, Steps: 139 | Train Loss: 0.1716800 Vali Loss: 0.1463100 Test Loss: 0.1730843
Validation loss decreased (0.146421 --> 0.146310).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1658553
	speed: 1.3088s/iter; left time: 14969.6835s
Epoch: 18 cost time: 80.82755136489868
Epoch: 18, Steps: 139 | Train Loss: 0.1716114 Vali Loss: 0.1463564 Test Loss: 0.1730675
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1775768
	speed: 1.3466s/iter; left time: 15215.6637s
Epoch: 19 cost time: 80.60322284698486
Epoch: 19, Steps: 139 | Train Loss: 0.1715229 Vali Loss: 0.1463258 Test Loss: 0.1730297
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1714527
	speed: 1.3217s/iter; left time: 14749.6279s
Epoch: 20 cost time: 80.06496357917786
Epoch: 20, Steps: 139 | Train Loss: 0.1715155 Vali Loss: 0.1461795 Test Loss: 0.1729914
Validation loss decreased (0.146310 --> 0.146179).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1734535
	speed: 1.4139s/iter; left time: 15582.9067s
Epoch: 21 cost time: 87.09629654884338
Epoch: 21, Steps: 139 | Train Loss: 0.1714682 Vali Loss: 0.1462608 Test Loss: 0.1729863
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1682447
	speed: 1.3930s/iter; left time: 15158.6183s
Epoch: 22 cost time: 83.71106719970703
Epoch: 22, Steps: 139 | Train Loss: 0.1713930 Vali Loss: 0.1462034 Test Loss: 0.1729754
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1721211
	speed: 1.4408s/iter; left time: 15478.2867s
Epoch: 23 cost time: 89.14287853240967
Epoch: 23, Steps: 139 | Train Loss: 0.1714050 Vali Loss: 0.1462183 Test Loss: 0.1729536
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1701405
	speed: 1.3672s/iter; left time: 14497.7999s
Epoch: 24 cost time: 85.08039712905884
Epoch: 24, Steps: 139 | Train Loss: 0.1714278 Vali Loss: 0.1462050 Test Loss: 0.1729036
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1731129
	speed: 1.4244s/iter; left time: 14905.8560s
Epoch: 25 cost time: 83.91732978820801
Epoch: 25, Steps: 139 | Train Loss: 0.1713730 Vali Loss: 0.1462074 Test Loss: 0.1728921
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1764896
	speed: 1.4334s/iter; left time: 14800.8743s
Epoch: 26 cost time: 86.47994804382324
Epoch: 26, Steps: 139 | Train Loss: 0.1713187 Vali Loss: 0.1461811 Test Loss: 0.1729029
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1733056
	speed: 1.4126s/iter; left time: 14390.2099s
Epoch: 27 cost time: 87.7361855506897
Epoch: 27, Steps: 139 | Train Loss: 0.1713472 Vali Loss: 0.1461960 Test Loss: 0.1728897
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1712723
	speed: 1.4182s/iter; left time: 14249.6726s
Epoch: 28 cost time: 83.50763607025146
Epoch: 28, Steps: 139 | Train Loss: 0.1714040 Vali Loss: 0.1461519 Test Loss: 0.1728809
Validation loss decreased (0.146179 --> 0.146152).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1709397
	speed: 1.3569s/iter; left time: 13445.4006s
Epoch: 29 cost time: 85.07387638092041
Epoch: 29, Steps: 139 | Train Loss: 0.1713440 Vali Loss: 0.1461638 Test Loss: 0.1728703
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1736411
	speed: 1.3760s/iter; left time: 13443.0350s
Epoch: 30 cost time: 79.40101194381714
Epoch: 30, Steps: 139 | Train Loss: 0.1713654 Vali Loss: 0.1461113 Test Loss: 0.1728585
Validation loss decreased (0.146152 --> 0.146111).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1760741
	speed: 1.3558s/iter; left time: 13057.3429s
Epoch: 31 cost time: 85.62542343139648
Epoch: 31, Steps: 139 | Train Loss: 0.1713254 Vali Loss: 0.1461122 Test Loss: 0.1728543
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1746237
	speed: 1.4018s/iter; left time: 13305.7760s
Epoch: 32 cost time: 85.42738556861877
Epoch: 32, Steps: 139 | Train Loss: 0.1713412 Vali Loss: 0.1461431 Test Loss: 0.1728596
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1698896
	speed: 1.3758s/iter; left time: 12867.6706s
Epoch: 33 cost time: 80.7298231124878
Epoch: 33, Steps: 139 | Train Loss: 0.1713232 Vali Loss: 0.1460256 Test Loss: 0.1728465
Validation loss decreased (0.146111 --> 0.146026).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1608558
	speed: 1.3320s/iter; left time: 12273.2120s
Epoch: 34 cost time: 84.42286562919617
Epoch: 34, Steps: 139 | Train Loss: 0.1713107 Vali Loss: 0.1461043 Test Loss: 0.1728445
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1625571
	speed: 1.4510s/iter; left time: 13167.9517s
Epoch: 35 cost time: 86.37138104438782
Epoch: 35, Steps: 139 | Train Loss: 0.1713083 Vali Loss: 0.1461128 Test Loss: 0.1728514
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1575923
	speed: 1.4044s/iter; left time: 12549.2854s
Epoch: 36 cost time: 85.27611422538757
Epoch: 36, Steps: 139 | Train Loss: 0.1713192 Vali Loss: 0.1460901 Test Loss: 0.1728450
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1733065
	speed: 1.3703s/iter; left time: 12054.8173s
Epoch: 37 cost time: 83.66629910469055
Epoch: 37, Steps: 139 | Train Loss: 0.1712944 Vali Loss: 0.1461007 Test Loss: 0.1728478
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1681283
	speed: 1.3363s/iter; left time: 11569.6290s
Epoch: 38 cost time: 78.75521779060364
Epoch: 38, Steps: 139 | Train Loss: 0.1712938 Vali Loss: 0.1461795 Test Loss: 0.1728353
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1706865
	speed: 1.3980s/iter; left time: 11909.8802s
Epoch: 39 cost time: 85.49214243888855
Epoch: 39, Steps: 139 | Train Loss: 0.1712910 Vali Loss: 0.1461251 Test Loss: 0.1728360
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1678547
	speed: 1.4014s/iter; left time: 11743.7222s
Epoch: 40 cost time: 81.79370474815369
Epoch: 40, Steps: 139 | Train Loss: 0.1712658 Vali Loss: 0.1460752 Test Loss: 0.1728316
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1639208
	speed: 1.3339s/iter; left time: 10992.3910s
Epoch: 41 cost time: 79.00953340530396
Epoch: 41, Steps: 139 | Train Loss: 0.1713345 Vali Loss: 0.1460662 Test Loss: 0.1728263
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1696394
	speed: 1.2558s/iter; left time: 10174.7225s
Epoch: 42 cost time: 76.35702610015869
Epoch: 42, Steps: 139 | Train Loss: 0.1712227 Vali Loss: 0.1460823 Test Loss: 0.1728220
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1708497
	speed: 1.2299s/iter; left time: 9793.3779s
Epoch: 43 cost time: 77.32677984237671
Epoch: 43, Steps: 139 | Train Loss: 0.1712931 Vali Loss: 0.1460724 Test Loss: 0.1728245
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1816974
	speed: 1.6266s/iter; left time: 12726.7109s
Epoch: 44 cost time: 96.79816579818726
Epoch: 44, Steps: 139 | Train Loss: 0.1712826 Vali Loss: 0.1460694 Test Loss: 0.1728240
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1631608
	speed: 1.5090s/iter; left time: 11596.3532s
Epoch: 45 cost time: 94.87381958961487
Epoch: 45, Steps: 139 | Train Loss: 0.1712638 Vali Loss: 0.1460690 Test Loss: 0.1728278
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1659998
	speed: 1.6060s/iter; left time: 12118.6162s
Epoch: 46 cost time: 95.62801098823547
Epoch: 46, Steps: 139 | Train Loss: 0.1712228 Vali Loss: 0.1461126 Test Loss: 0.1728107
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1643962
	speed: 1.6019s/iter; left time: 11865.5731s
Epoch: 47 cost time: 96.71159243583679
Epoch: 47, Steps: 139 | Train Loss: 0.1712656 Vali Loss: 0.1460938 Test Loss: 0.1728086
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1625192
	speed: 1.6005s/iter; left time: 11632.3335s
Epoch: 48 cost time: 96.02574062347412
Epoch: 48, Steps: 139 | Train Loss: 0.1712981 Vali Loss: 0.1461481 Test Loss: 0.1728127
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1731280
	speed: 1.5813s/iter; left time: 11273.1909s
Epoch: 49 cost time: 96.32067894935608
Epoch: 49, Steps: 139 | Train Loss: 0.1712791 Vali Loss: 0.1460532 Test Loss: 0.1728084
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1678872
	speed: 1.6872s/iter; left time: 11793.7052s
Epoch: 50 cost time: 106.6559088230133
Epoch: 50, Steps: 139 | Train Loss: 0.1712663 Vali Loss: 0.1460769 Test Loss: 0.1728069
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1693556
	speed: 1.6618s/iter; left time: 11384.7508s
Epoch: 51 cost time: 104.13926005363464
Epoch: 51, Steps: 139 | Train Loss: 0.1712328 Vali Loss: 0.1460494 Test Loss: 0.1728081
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1795195
	speed: 1.5831s/iter; left time: 10625.4823s
Epoch: 52 cost time: 96.86450433731079
Epoch: 52, Steps: 139 | Train Loss: 0.1711994 Vali Loss: 0.1459653 Test Loss: 0.1728107
Validation loss decreased (0.146026 --> 0.145965).  Saving model ...
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1776966
	speed: 1.6090s/iter; left time: 10575.7423s
Epoch: 53 cost time: 99.84491324424744
Epoch: 53, Steps: 139 | Train Loss: 0.1712356 Vali Loss: 0.1460085 Test Loss: 0.1728112
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1700288
	speed: 1.7058s/iter; left time: 10974.9438s
Epoch: 54 cost time: 106.149001121521
Epoch: 54, Steps: 139 | Train Loss: 0.1712460 Vali Loss: 0.1461087 Test Loss: 0.1728076
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1724315
	speed: 1.6449s/iter; left time: 10354.6692s
Epoch: 55 cost time: 99.75892090797424
Epoch: 55, Steps: 139 | Train Loss: 0.1712966 Vali Loss: 0.1460536 Test Loss: 0.1728041
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1802118
	speed: 1.6242s/iter; left time: 9998.6383s
Epoch: 56 cost time: 97.20639991760254
Epoch: 56, Steps: 139 | Train Loss: 0.1712432 Vali Loss: 0.1460726 Test Loss: 0.1728038
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.1736805
	speed: 1.6333s/iter; left time: 9827.8593s
Epoch: 57 cost time: 100.75490188598633
Epoch: 57, Steps: 139 | Train Loss: 0.1712540 Vali Loss: 0.1460782 Test Loss: 0.1728034
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1735997
	speed: 1.6581s/iter; left time: 9746.2061s
Epoch: 58 cost time: 105.83999180793762
Epoch: 58, Steps: 139 | Train Loss: 0.1712320 Vali Loss: 0.1460375 Test Loss: 0.1727990
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1742427
	speed: 1.7363s/iter; left time: 9964.5086s
Epoch: 59 cost time: 106.55113244056702
Epoch: 59, Steps: 139 | Train Loss: 0.1712871 Vali Loss: 0.1460206 Test Loss: 0.1728029
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1634364
	speed: 1.6592s/iter; left time: 9291.7266s
Epoch: 60 cost time: 100.41641736030579
Epoch: 60, Steps: 139 | Train Loss: 0.1712262 Vali Loss: 0.1461007 Test Loss: 0.1727980
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1784903
	speed: 1.6131s/iter; left time: 8809.0409s
Epoch: 61 cost time: 96.96774864196777
Epoch: 61, Steps: 139 | Train Loss: 0.1712863 Vali Loss: 0.1460663 Test Loss: 0.1727982
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1696006
	speed: 1.5677s/iter; left time: 8343.5414s
Epoch: 62 cost time: 94.48968076705933
Epoch: 62, Steps: 139 | Train Loss: 0.1712958 Vali Loss: 0.1460071 Test Loss: 0.1727984
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1626693
	speed: 1.5176s/iter; left time: 7865.7803s
Epoch: 63 cost time: 92.47522282600403
Epoch: 63, Steps: 139 | Train Loss: 0.1712102 Vali Loss: 0.1460904 Test Loss: 0.1728014
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1626216
	speed: 1.4963s/iter; left time: 7547.4917s
Epoch: 64 cost time: 89.60121989250183
Epoch: 64, Steps: 139 | Train Loss: 0.1711986 Vali Loss: 0.1460654 Test Loss: 0.1727992
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.1733711
	speed: 1.5314s/iter; left time: 7511.3916s
Epoch: 65 cost time: 97.13532042503357
Epoch: 65, Steps: 139 | Train Loss: 0.1713197 Vali Loss: 0.1461086 Test Loss: 0.1728022
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.1713925
	speed: 1.5226s/iter; left time: 7256.7789s
Epoch: 66 cost time: 89.76099491119385
Epoch: 66, Steps: 139 | Train Loss: 0.1712130 Vali Loss: 0.1460856 Test Loss: 0.1727950
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.1729027
	speed: 1.5216s/iter; left time: 7040.6336s
Epoch: 67 cost time: 92.13217234611511
Epoch: 67, Steps: 139 | Train Loss: 0.1712277 Vali Loss: 0.1460447 Test Loss: 0.1727959
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.1697483
	speed: 1.3914s/iter; left time: 6244.5918s
Epoch: 68 cost time: 81.61409521102905
Epoch: 68, Steps: 139 | Train Loss: 0.1712510 Vali Loss: 0.1460472 Test Loss: 0.1727959
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.1653472
	speed: 1.3638s/iter; left time: 5931.1515s
Epoch: 69 cost time: 81.846843957901
Epoch: 69, Steps: 139 | Train Loss: 0.1712506 Vali Loss: 0.1460301 Test Loss: 0.1727956
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.1754630
	speed: 1.4911s/iter; left time: 6277.6288s
Epoch: 70 cost time: 91.95268106460571
Epoch: 70, Steps: 139 | Train Loss: 0.1712461 Vali Loss: 0.1460150 Test Loss: 0.1727976
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.1675157
	speed: 1.4753s/iter; left time: 6005.9761s
Epoch: 71 cost time: 90.65023612976074
Epoch: 71, Steps: 139 | Train Loss: 0.1712204 Vali Loss: 0.1460400 Test Loss: 0.1727971
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.1753629
	speed: 1.4657s/iter; left time: 5763.2634s
Epoch: 72 cost time: 89.43111371994019
Epoch: 72, Steps: 139 | Train Loss: 0.1712682 Vali Loss: 0.1460195 Test Loss: 0.1727982
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_360_j192_H4_FITS_custom_ftM_sl360_ll48_pl192_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5069
mse:0.17001691460609436, mae:0.27307066321372986, rse:0.4099665582180023, corr:[0.46258667 0.46438506 0.4644866  0.46566704 0.46665177 0.4666386
 0.46615958 0.465834   0.46575415 0.4656949  0.46548796 0.46522513
 0.46509367 0.46511394 0.46521032 0.4652611  0.46519423 0.4650976
 0.46500784 0.46486694 0.4648058  0.4648569  0.46497717 0.46509498
 0.4651492  0.46532652 0.46546295 0.4654219  0.46520415 0.4649452
 0.46476406 0.46470213 0.46464908 0.4645234  0.46432653 0.46416065
 0.4640975  0.4640916  0.46406955 0.46397188 0.46378347 0.46356767
 0.46340302 0.46327966 0.46317673 0.4631174  0.4631465  0.46322787
 0.46332046 0.46347836 0.46357676 0.46351588 0.4633615  0.46321777
 0.463161   0.46316656 0.46316803 0.4631165  0.46302748 0.46297073
 0.46298832 0.463037   0.46306938 0.46303603 0.46294147 0.4628506
 0.4627713  0.4626546  0.46253824 0.4624726  0.46246275 0.46250257
 0.46256122 0.46267435 0.46273354 0.4626769  0.46256003 0.46247748
 0.46247163 0.46251246 0.4625207  0.46247613 0.46239    0.4623225
 0.46231693 0.46234584 0.46236777 0.4623435  0.4622675  0.46218464
 0.46209472 0.4619616  0.46183437 0.4618061  0.46183935 0.46190956
 0.4619988  0.46213618 0.4622167  0.46219498 0.46211338 0.4620478
 0.46204248 0.46207964 0.46207777 0.4620116  0.46189186 0.46177906
 0.4617212  0.4617264  0.46175623 0.4617567  0.46168956 0.46160865
 0.46159637 0.46162105 0.46165827 0.4617174  0.46181926 0.46196106
 0.4621049  0.46225458 0.46236047 0.46239024 0.46235391 0.46231806
 0.46232474 0.46234828 0.4623427  0.46226537 0.46210483 0.46195564
 0.4619031  0.46193942 0.46200025 0.46200636 0.46194026 0.46188152
 0.46188062 0.46184492 0.4617826  0.4617843  0.4619454  0.4622618
 0.4626103  0.4628845  0.46305835 0.46312666 0.46310267 0.46304786
 0.46300727 0.46298477 0.4629546  0.4628592  0.46269104 0.46254098
 0.46250215 0.46257687 0.46271127 0.4627873  0.46275717 0.462704
 0.46267444 0.46258947 0.46241978 0.4622528  0.46216643 0.46216315
 0.46209112 0.46208498 0.46199778 0.4617923  0.46155748 0.46136603
 0.4612269  0.46110806 0.46092287 0.46067408 0.46045375 0.4603993
 0.4605528  0.4607916  0.46091968 0.46083742 0.46058458 0.4604048
 0.46041557 0.460372   0.46004817 0.4595957  0.45983565 0.460502  ]
