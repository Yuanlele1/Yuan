Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_360_j720_H6', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_360_j720_H6_FITS_custom_ftM_sl360_ll48_pl720_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17333
val 1913
test 4541
Model(
  (freq_upsampler): Linear(in_features=106, out_features=318, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1384994304.0
params:  34026.0
Trainable parameters:  34026
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.8485736
	speed: 0.8885s/iter; left time: 11906.2054s
Epoch: 1 cost time: 120.69440340995789
Epoch: 1, Steps: 135 | Train Loss: 1.0673130 Vali Loss: 0.6955439 Test Loss: 0.8155220
Validation loss decreased (inf --> 0.695544).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6601629
	speed: 2.1060s/iter; left time: 27937.8423s
Epoch: 2 cost time: 123.87370324134827
Epoch: 2, Steps: 135 | Train Loss: 0.6842767 Vali Loss: 0.5660751 Test Loss: 0.6720088
Validation loss decreased (0.695544 --> 0.566075).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5664436
	speed: 2.0580s/iter; left time: 27023.0843s
Epoch: 3 cost time: 116.59976387023926
Epoch: 3, Steps: 135 | Train Loss: 0.5841191 Vali Loss: 0.5047571 Test Loss: 0.6029141
Validation loss decreased (0.566075 --> 0.504757).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.5096083
	speed: 2.1499s/iter; left time: 27940.1221s
Epoch: 4 cost time: 128.80080604553223
Epoch: 4, Steps: 135 | Train Loss: 0.5192219 Vali Loss: 0.4555165 Test Loss: 0.5464960
Validation loss decreased (0.504757 --> 0.455516).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4553629
	speed: 2.0907s/iter; left time: 26888.4293s
Epoch: 5 cost time: 117.44665575027466
Epoch: 5, Steps: 135 | Train Loss: 0.4666622 Vali Loss: 0.4157099 Test Loss: 0.5002815
Validation loss decreased (0.455516 --> 0.415710).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4063239
	speed: 2.0764s/iter; left time: 26423.6677s
Epoch: 6 cost time: 124.33063745498657
Epoch: 6, Steps: 135 | Train Loss: 0.4228579 Vali Loss: 0.3826332 Test Loss: 0.4624663
Validation loss decreased (0.415710 --> 0.382633).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3755875
	speed: 2.0313s/iter; left time: 25575.5469s
Epoch: 7 cost time: 118.50342297554016
Epoch: 7, Steps: 135 | Train Loss: 0.3859271 Vali Loss: 0.3527882 Test Loss: 0.4277668
Validation loss decreased (0.382633 --> 0.352788).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3430097
	speed: 2.0081s/iter; left time: 25013.1811s
Epoch: 8 cost time: 117.42911219596863
Epoch: 8, Steps: 135 | Train Loss: 0.3547744 Vali Loss: 0.3295126 Test Loss: 0.4002632
Validation loss decreased (0.352788 --> 0.329513).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3194289
	speed: 2.1394s/iter; left time: 26360.0120s
Epoch: 9 cost time: 125.65416836738586
Epoch: 9, Steps: 135 | Train Loss: 0.3281992 Vali Loss: 0.3087243 Test Loss: 0.3756222
Validation loss decreased (0.329513 --> 0.308724).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3025255
	speed: 2.0750s/iter; left time: 25286.4519s
Epoch: 10 cost time: 123.46526718139648
Epoch: 10, Steps: 135 | Train Loss: 0.3054720 Vali Loss: 0.2910621 Test Loss: 0.3548114
Validation loss decreased (0.308724 --> 0.291062).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2785738
	speed: 2.0633s/iter; left time: 24864.5193s
Epoch: 11 cost time: 120.39799427986145
Epoch: 11, Steps: 135 | Train Loss: 0.2859772 Vali Loss: 0.2762977 Test Loss: 0.3370696
Validation loss decreased (0.291062 --> 0.276298).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2676788
	speed: 2.0599s/iter; left time: 24546.3459s
Epoch: 12 cost time: 116.26812291145325
Epoch: 12, Steps: 135 | Train Loss: 0.2692651 Vali Loss: 0.2639845 Test Loss: 0.3217711
Validation loss decreased (0.276298 --> 0.263984).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2620306
	speed: 2.0080s/iter; left time: 23655.7386s
Epoch: 13 cost time: 115.52977871894836
Epoch: 13, Steps: 135 | Train Loss: 0.2547149 Vali Loss: 0.2528120 Test Loss: 0.3084944
Validation loss decreased (0.263984 --> 0.252812).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2286955
	speed: 1.9685s/iter; left time: 22924.6708s
Epoch: 14 cost time: 113.92749190330505
Epoch: 14, Steps: 135 | Train Loss: 0.2422395 Vali Loss: 0.2433601 Test Loss: 0.2968423
Validation loss decreased (0.252812 --> 0.243360).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2426421
	speed: 1.9281s/iter; left time: 22194.6968s
Epoch: 15 cost time: 112.57435488700867
Epoch: 15, Steps: 135 | Train Loss: 0.2314557 Vali Loss: 0.2348395 Test Loss: 0.2866077
Validation loss decreased (0.243360 --> 0.234840).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2214672
	speed: 1.9439s/iter; left time: 22113.4160s
Epoch: 16 cost time: 112.80728650093079
Epoch: 16, Steps: 135 | Train Loss: 0.2221253 Vali Loss: 0.2278662 Test Loss: 0.2777920
Validation loss decreased (0.234840 --> 0.227866).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2081145
	speed: 1.9299s/iter; left time: 21694.4301s
Epoch: 17 cost time: 109.27381086349487
Epoch: 17, Steps: 135 | Train Loss: 0.2140138 Vali Loss: 0.2220263 Test Loss: 0.2703404
Validation loss decreased (0.227866 --> 0.222026).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2048718
	speed: 1.9487s/iter; left time: 21642.6992s
Epoch: 18 cost time: 116.8176805973053
Epoch: 18, Steps: 135 | Train Loss: 0.2069482 Vali Loss: 0.2165147 Test Loss: 0.2637518
Validation loss decreased (0.222026 --> 0.216515).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1981657
	speed: 1.8990s/iter; left time: 20833.3872s
Epoch: 19 cost time: 110.24888181686401
Epoch: 19, Steps: 135 | Train Loss: 0.2007971 Vali Loss: 0.2122481 Test Loss: 0.2580038
Validation loss decreased (0.216515 --> 0.212248).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1945909
	speed: 1.8714s/iter; left time: 20278.9121s
Epoch: 20 cost time: 112.14910221099854
Epoch: 20, Steps: 135 | Train Loss: 0.1954411 Vali Loss: 0.2080596 Test Loss: 0.2527771
Validation loss decreased (0.212248 --> 0.208060).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1909826
	speed: 1.8352s/iter; left time: 19638.2557s
Epoch: 21 cost time: 110.3380491733551
Epoch: 21, Steps: 135 | Train Loss: 0.1907549 Vali Loss: 0.2048512 Test Loss: 0.2484255
Validation loss decreased (0.208060 --> 0.204851).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1854623
	speed: 1.9423s/iter; left time: 20522.1931s
Epoch: 22 cost time: 114.14465355873108
Epoch: 22, Steps: 135 | Train Loss: 0.1867254 Vali Loss: 0.2019536 Test Loss: 0.2446751
Validation loss decreased (0.204851 --> 0.201954).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1775087
	speed: 1.9687s/iter; left time: 20535.5928s
Epoch: 23 cost time: 113.86287236213684
Epoch: 23, Steps: 135 | Train Loss: 0.1831490 Vali Loss: 0.1994297 Test Loss: 0.2409871
Validation loss decreased (0.201954 --> 0.199430).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1734261
	speed: 1.9809s/iter; left time: 20395.3669s
Epoch: 24 cost time: 118.28106832504272
Epoch: 24, Steps: 135 | Train Loss: 0.1800435 Vali Loss: 0.1969305 Test Loss: 0.2380919
Validation loss decreased (0.199430 --> 0.196931).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1874845
	speed: 2.0000s/iter; left time: 20321.6313s
Epoch: 25 cost time: 117.80110192298889
Epoch: 25, Steps: 135 | Train Loss: 0.1773367 Vali Loss: 0.1954380 Test Loss: 0.2354478
Validation loss decreased (0.196931 --> 0.195438).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1751775
	speed: 1.9776s/iter; left time: 19827.4463s
Epoch: 26 cost time: 117.92951917648315
Epoch: 26, Steps: 135 | Train Loss: 0.1749452 Vali Loss: 0.1936903 Test Loss: 0.2332492
Validation loss decreased (0.195438 --> 0.193690).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1677210
	speed: 2.1065s/iter; left time: 20835.8115s
Epoch: 27 cost time: 123.71466636657715
Epoch: 27, Steps: 135 | Train Loss: 0.1728779 Vali Loss: 0.1922945 Test Loss: 0.2312071
Validation loss decreased (0.193690 --> 0.192294).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1631684
	speed: 2.0017s/iter; left time: 19528.1612s
Epoch: 28 cost time: 114.88813877105713
Epoch: 28, Steps: 135 | Train Loss: 0.1710180 Vali Loss: 0.1911247 Test Loss: 0.2294266
Validation loss decreased (0.192294 --> 0.191125).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1727194
	speed: 1.9992s/iter; left time: 19234.2510s
Epoch: 29 cost time: 118.90587949752808
Epoch: 29, Steps: 135 | Train Loss: 0.1694206 Vali Loss: 0.1900440 Test Loss: 0.2277263
Validation loss decreased (0.191125 --> 0.190044).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1609174
	speed: 2.0302s/iter; left time: 19258.3273s
Epoch: 30 cost time: 118.18410611152649
Epoch: 30, Steps: 135 | Train Loss: 0.1679427 Vali Loss: 0.1889831 Test Loss: 0.2264270
Validation loss decreased (0.190044 --> 0.188983).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1586130
	speed: 2.0245s/iter; left time: 18931.2312s
Epoch: 31 cost time: 119.59754776954651
Epoch: 31, Steps: 135 | Train Loss: 0.1667496 Vali Loss: 0.1882416 Test Loss: 0.2250130
Validation loss decreased (0.188983 --> 0.188242).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1546240
	speed: 2.0758s/iter; left time: 19130.2835s
Epoch: 32 cost time: 121.46256446838379
Epoch: 32, Steps: 135 | Train Loss: 0.1656921 Vali Loss: 0.1870947 Test Loss: 0.2239865
Validation loss decreased (0.188242 --> 0.187095).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1622134
	speed: 2.0551s/iter; left time: 18662.3953s
Epoch: 33 cost time: 119.09514832496643
Epoch: 33, Steps: 135 | Train Loss: 0.1647446 Vali Loss: 0.1868625 Test Loss: 0.2230601
Validation loss decreased (0.187095 --> 0.186863).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1665086
	speed: 2.0670s/iter; left time: 18491.2120s
Epoch: 34 cost time: 123.50230073928833
Epoch: 34, Steps: 135 | Train Loss: 0.1639394 Vali Loss: 0.1866470 Test Loss: 0.2222073
Validation loss decreased (0.186863 --> 0.186647).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1553567
	speed: 2.0600s/iter; left time: 18150.5736s
Epoch: 35 cost time: 120.26499819755554
Epoch: 35, Steps: 135 | Train Loss: 0.1632432 Vali Loss: 0.1861006 Test Loss: 0.2214821
Validation loss decreased (0.186647 --> 0.186101).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1622893
	speed: 2.0670s/iter; left time: 17933.4451s
Epoch: 36 cost time: 118.75199842453003
Epoch: 36, Steps: 135 | Train Loss: 0.1626008 Vali Loss: 0.1859643 Test Loss: 0.2208312
Validation loss decreased (0.186101 --> 0.185964).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1612907
	speed: 2.0398s/iter; left time: 17421.7862s
Epoch: 37 cost time: 118.8152756690979
Epoch: 37, Steps: 135 | Train Loss: 0.1619976 Vali Loss: 0.1852282 Test Loss: 0.2202167
Validation loss decreased (0.185964 --> 0.185228).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1658267
	speed: 2.0073s/iter; left time: 16873.3212s
Epoch: 38 cost time: 120.99142980575562
Epoch: 38, Steps: 135 | Train Loss: 0.1615167 Vali Loss: 0.1852276 Test Loss: 0.2197389
Validation loss decreased (0.185228 --> 0.185228).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1666664
	speed: 2.0349s/iter; left time: 16830.7178s
Epoch: 39 cost time: 122.19664764404297
Epoch: 39, Steps: 135 | Train Loss: 0.1610473 Vali Loss: 0.1852089 Test Loss: 0.2192557
Validation loss decreased (0.185228 --> 0.185209).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1647017
	speed: 2.0525s/iter; left time: 16699.3595s
Epoch: 40 cost time: 121.4488570690155
Epoch: 40, Steps: 135 | Train Loss: 0.1607109 Vali Loss: 0.1850220 Test Loss: 0.2188280
Validation loss decreased (0.185209 --> 0.185022).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1554554
	speed: 2.0198s/iter; left time: 16160.6169s
Epoch: 41 cost time: 117.29444241523743
Epoch: 41, Steps: 135 | Train Loss: 0.1603479 Vali Loss: 0.1843433 Test Loss: 0.2184914
Validation loss decreased (0.185022 --> 0.184343).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1586975
	speed: 2.0208s/iter; left time: 15896.0017s
Epoch: 42 cost time: 118.20217180252075
Epoch: 42, Steps: 135 | Train Loss: 0.1601027 Vali Loss: 0.1846270 Test Loss: 0.2181501
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1472909
	speed: 2.0246s/iter; left time: 15652.2715s
Epoch: 43 cost time: 116.75496220588684
Epoch: 43, Steps: 135 | Train Loss: 0.1597817 Vali Loss: 0.1848125 Test Loss: 0.2178477
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1647438
	speed: 2.0099s/iter; left time: 15267.0448s
Epoch: 44 cost time: 119.89630317687988
Epoch: 44, Steps: 135 | Train Loss: 0.1595782 Vali Loss: 0.1848640 Test Loss: 0.2175933
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1678414
	speed: 2.1044s/iter; left time: 15701.0521s
Epoch: 45 cost time: 125.20891547203064
Epoch: 45, Steps: 135 | Train Loss: 0.1593901 Vali Loss: 0.1844393 Test Loss: 0.2173368
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1607532
	speed: 2.1187s/iter; left time: 15521.3819s
Epoch: 46 cost time: 123.13674640655518
Epoch: 46, Steps: 135 | Train Loss: 0.1591724 Vali Loss: 0.1844194 Test Loss: 0.2171798
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1552225
	speed: 2.0485s/iter; left time: 14730.8542s
Epoch: 47 cost time: 121.85241460800171
Epoch: 47, Steps: 135 | Train Loss: 0.1590567 Vali Loss: 0.1838834 Test Loss: 0.2169967
Validation loss decreased (0.184343 --> 0.183883).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1537153
	speed: 2.1058s/iter; left time: 14858.8737s
Epoch: 48 cost time: 124.42227864265442
Epoch: 48, Steps: 135 | Train Loss: 0.1589033 Vali Loss: 0.1838025 Test Loss: 0.2168203
Validation loss decreased (0.183883 --> 0.183802).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1525620
	speed: 2.1346s/iter; left time: 14773.4924s
Epoch: 49 cost time: 124.40262508392334
Epoch: 49, Steps: 135 | Train Loss: 0.1588127 Vali Loss: 0.1839419 Test Loss: 0.2167059
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1546157
	speed: 2.0684s/iter; left time: 14036.0788s
Epoch: 50 cost time: 122.64193725585938
Epoch: 50, Steps: 135 | Train Loss: 0.1587154 Vali Loss: 0.1840225 Test Loss: 0.2165572
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1566368
	speed: 2.0896s/iter; left time: 13898.0955s
Epoch: 51 cost time: 121.91527533531189
Epoch: 51, Steps: 135 | Train Loss: 0.1586024 Vali Loss: 0.1838753 Test Loss: 0.2164493
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1579625
	speed: 2.0815s/iter; left time: 13562.9136s
Epoch: 52 cost time: 121.2144365310669
Epoch: 52, Steps: 135 | Train Loss: 0.1585291 Vali Loss: 0.1840101 Test Loss: 0.2163528
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1561262
	speed: 2.0835s/iter; left time: 13294.5772s
Epoch: 53 cost time: 122.86624097824097
Epoch: 53, Steps: 135 | Train Loss: 0.1584157 Vali Loss: 0.1841761 Test Loss: 0.2162616
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1562968
	speed: 2.0892s/iter; left time: 13048.8510s
Epoch: 54 cost time: 121.9352536201477
Epoch: 54, Steps: 135 | Train Loss: 0.1583951 Vali Loss: 0.1843634 Test Loss: 0.2161732
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1558544
	speed: 2.0697s/iter; left time: 12647.6773s
Epoch: 55 cost time: 118.87044167518616
Epoch: 55, Steps: 135 | Train Loss: 0.1583374 Vali Loss: 0.1842566 Test Loss: 0.2161084
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1591952
	speed: 2.0302s/iter; left time: 12132.5613s
Epoch: 56 cost time: 118.97180557250977
Epoch: 56, Steps: 135 | Train Loss: 0.1583118 Vali Loss: 0.1840038 Test Loss: 0.2160370
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.1603439
	speed: 2.0814s/iter; left time: 12157.3388s
Epoch: 57 cost time: 121.51120567321777
Epoch: 57, Steps: 135 | Train Loss: 0.1582415 Vali Loss: 0.1840116 Test Loss: 0.2159826
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1509304
	speed: 2.0372s/iter; left time: 11624.3498s
Epoch: 58 cost time: 120.65212440490723
Epoch: 58, Steps: 135 | Train Loss: 0.1581891 Vali Loss: 0.1842982 Test Loss: 0.2159306
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1513894
	speed: 2.0666s/iter; left time: 11512.8863s
Epoch: 59 cost time: 120.85014247894287
Epoch: 59, Steps: 135 | Train Loss: 0.1581521 Vali Loss: 0.1840187 Test Loss: 0.2158862
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1652381
	speed: 2.0445s/iter; left time: 11114.1164s
Epoch: 60 cost time: 117.14448499679565
Epoch: 60, Steps: 135 | Train Loss: 0.1581675 Vali Loss: 0.1840911 Test Loss: 0.2158523
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1509851
	speed: 2.0392s/iter; left time: 10809.8598s
Epoch: 61 cost time: 120.37102961540222
Epoch: 61, Steps: 135 | Train Loss: 0.1581300 Vali Loss: 0.1838187 Test Loss: 0.2158145
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1589363
	speed: 2.0469s/iter; left time: 10574.2351s
Epoch: 62 cost time: 121.04866909980774
Epoch: 62, Steps: 135 | Train Loss: 0.1581047 Vali Loss: 0.1843953 Test Loss: 0.2157757
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1568221
	speed: 2.1027s/iter; left time: 10578.5488s
Epoch: 63 cost time: 122.59163641929626
Epoch: 63, Steps: 135 | Train Loss: 0.1581237 Vali Loss: 0.1842067 Test Loss: 0.2157517
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1598263
	speed: 2.0775s/iter; left time: 10171.5488s
Epoch: 64 cost time: 123.27499318122864
Epoch: 64, Steps: 135 | Train Loss: 0.1581125 Vali Loss: 0.1841966 Test Loss: 0.2157163
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.1568784
	speed: 2.0802s/iter; left time: 9903.6715s
Epoch: 65 cost time: 122.63718271255493
Epoch: 65, Steps: 135 | Train Loss: 0.1580584 Vali Loss: 0.1842680 Test Loss: 0.2156985
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.1510289
	speed: 2.0663s/iter; left time: 9558.4953s
Epoch: 66 cost time: 119.61936616897583
Epoch: 66, Steps: 135 | Train Loss: 0.1580866 Vali Loss: 0.1840820 Test Loss: 0.2156765
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.1584700
	speed: 2.0894s/iter; left time: 9383.5167s
Epoch: 67 cost time: 122.34657621383667
Epoch: 67, Steps: 135 | Train Loss: 0.1580454 Vali Loss: 0.1843913 Test Loss: 0.2156618
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.1586966
	speed: 2.1406s/iter; left time: 9324.3076s
Epoch: 68 cost time: 123.959388256073
Epoch: 68, Steps: 135 | Train Loss: 0.1580283 Vali Loss: 0.1842529 Test Loss: 0.2156400
EarlyStopping counter: 20 out of 20
Early stopping
train 17333
val 1913
test 4541
Model(
  (freq_upsampler): Linear(in_features=106, out_features=318, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1384994304.0
params:  34026.0
Trainable parameters:  34026
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2325346
	speed: 0.9021s/iter; left time: 12088.3759s
Epoch: 1 cost time: 122.38702917098999
Epoch: 1, Steps: 135 | Train Loss: 0.2291404 Vali Loss: 0.1842325 Test Loss: 0.2150831
Validation loss decreased (inf --> 0.184232).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2177368
	speed: 2.0309s/iter; left time: 26941.3446s
Epoch: 2 cost time: 120.54316663742065
Epoch: 2, Steps: 135 | Train Loss: 0.2287619 Vali Loss: 0.1836064 Test Loss: 0.2149945
Validation loss decreased (0.184232 --> 0.183606).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2173703
	speed: 2.0252s/iter; left time: 26592.9230s
Epoch: 3 cost time: 118.45097637176514
Epoch: 3, Steps: 135 | Train Loss: 0.2287696 Vali Loss: 0.1839473 Test Loss: 0.2149945
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2361272
	speed: 2.0224s/iter; left time: 26282.9178s
Epoch: 4 cost time: 119.57115316390991
Epoch: 4, Steps: 135 | Train Loss: 0.2287395 Vali Loss: 0.1838934 Test Loss: 0.2150220
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2318114
	speed: 2.0190s/iter; left time: 25966.5480s
Epoch: 5 cost time: 120.15021800994873
Epoch: 5, Steps: 135 | Train Loss: 0.2286879 Vali Loss: 0.1836729 Test Loss: 0.2149422
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2384177
	speed: 2.0542s/iter; left time: 26141.1584s
Epoch: 6 cost time: 117.30586886405945
Epoch: 6, Steps: 135 | Train Loss: 0.2286883 Vali Loss: 0.1837453 Test Loss: 0.2149960
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2232948
	speed: 2.0514s/iter; left time: 25829.2186s
Epoch: 7 cost time: 121.72077465057373
Epoch: 7, Steps: 135 | Train Loss: 0.2286247 Vali Loss: 0.1838432 Test Loss: 0.2149494
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2260104
	speed: 2.1176s/iter; left time: 26377.4225s
Epoch: 8 cost time: 123.33249640464783
Epoch: 8, Steps: 135 | Train Loss: 0.2286440 Vali Loss: 0.1838994 Test Loss: 0.2149187
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2260252
	speed: 2.0333s/iter; left time: 25052.7724s
Epoch: 9 cost time: 122.13295578956604
Epoch: 9, Steps: 135 | Train Loss: 0.2286552 Vali Loss: 0.1837720 Test Loss: 0.2149522
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2260416
	speed: 2.0640s/iter; left time: 25152.1509s
Epoch: 10 cost time: 119.37157273292542
Epoch: 10, Steps: 135 | Train Loss: 0.2285890 Vali Loss: 0.1841965 Test Loss: 0.2149176
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2253864
	speed: 1.9836s/iter; left time: 23904.0566s
Epoch: 11 cost time: 114.84473013877869
Epoch: 11, Steps: 135 | Train Loss: 0.2285646 Vali Loss: 0.1836512 Test Loss: 0.2149397
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2219998
	speed: 2.0736s/iter; left time: 24708.9145s
Epoch: 12 cost time: 123.11054396629333
Epoch: 12, Steps: 135 | Train Loss: 0.2285756 Vali Loss: 0.1836973 Test Loss: 0.2149839
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2203577
	speed: 1.9285s/iter; left time: 22719.9990s
Epoch: 13 cost time: 108.23377513885498
Epoch: 13, Steps: 135 | Train Loss: 0.2285457 Vali Loss: 0.1837018 Test Loss: 0.2149185
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2196639
	speed: 1.9579s/iter; left time: 22801.3580s
Epoch: 14 cost time: 113.73201513290405
Epoch: 14, Steps: 135 | Train Loss: 0.2285656 Vali Loss: 0.1838439 Test Loss: 0.2149362
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2235076
	speed: 1.5932s/iter; left time: 18339.2551s
Epoch: 15 cost time: 86.94213008880615
Epoch: 15, Steps: 135 | Train Loss: 0.2285623 Vali Loss: 0.1835064 Test Loss: 0.2149255
Validation loss decreased (0.183606 --> 0.183506).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2406469
	speed: 1.4625s/iter; left time: 16637.9563s
Epoch: 16 cost time: 84.76939082145691
Epoch: 16, Steps: 135 | Train Loss: 0.2285763 Vali Loss: 0.1834728 Test Loss: 0.2149261
Validation loss decreased (0.183506 --> 0.183473).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2203766
	speed: 1.5306s/iter; left time: 17205.6138s
Epoch: 17 cost time: 90.25421524047852
Epoch: 17, Steps: 135 | Train Loss: 0.2284891 Vali Loss: 0.1837651 Test Loss: 0.2148630
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2383338
	speed: 1.4891s/iter; left time: 16537.3922s
Epoch: 18 cost time: 85.06737661361694
Epoch: 18, Steps: 135 | Train Loss: 0.2285572 Vali Loss: 0.1837532 Test Loss: 0.2148761
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2307878
	speed: 1.4642s/iter; left time: 16064.1891s
Epoch: 19 cost time: 87.8663809299469
Epoch: 19, Steps: 135 | Train Loss: 0.2285249 Vali Loss: 0.1835099 Test Loss: 0.2148896
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2225872
	speed: 1.5158s/iter; left time: 16425.7010s
Epoch: 20 cost time: 88.07711219787598
Epoch: 20, Steps: 135 | Train Loss: 0.2284823 Vali Loss: 0.1836074 Test Loss: 0.2148792
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2305553
	speed: 1.5926s/iter; left time: 17042.1677s
Epoch: 21 cost time: 94.49108719825745
Epoch: 21, Steps: 135 | Train Loss: 0.2285313 Vali Loss: 0.1835566 Test Loss: 0.2148979
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2381970
	speed: 1.5357s/iter; left time: 16226.3831s
Epoch: 22 cost time: 91.8905725479126
Epoch: 22, Steps: 135 | Train Loss: 0.2285190 Vali Loss: 0.1832214 Test Loss: 0.2149001
Validation loss decreased (0.183473 --> 0.183221).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2179112
	speed: 1.5187s/iter; left time: 15841.8410s
Epoch: 23 cost time: 87.36016035079956
Epoch: 23, Steps: 135 | Train Loss: 0.2284602 Vali Loss: 0.1835825 Test Loss: 0.2149074
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2231122
	speed: 1.4995s/iter; left time: 15439.1262s
Epoch: 24 cost time: 89.19081568717957
Epoch: 24, Steps: 135 | Train Loss: 0.2284635 Vali Loss: 0.1835790 Test Loss: 0.2148821
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2236376
	speed: 1.5126s/iter; left time: 15369.8412s
Epoch: 25 cost time: 89.1682665348053
Epoch: 25, Steps: 135 | Train Loss: 0.2285007 Vali Loss: 0.1835027 Test Loss: 0.2148742
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2238202
	speed: 1.5782s/iter; left time: 15823.5159s
Epoch: 26 cost time: 92.9775333404541
Epoch: 26, Steps: 135 | Train Loss: 0.2283834 Vali Loss: 0.1832305 Test Loss: 0.2149002
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2314678
	speed: 1.5782s/iter; left time: 15609.9437s
Epoch: 27 cost time: 93.36734104156494
Epoch: 27, Steps: 135 | Train Loss: 0.2284962 Vali Loss: 0.1834994 Test Loss: 0.2148616
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2311216
	speed: 1.5843s/iter; left time: 15456.3662s
Epoch: 28 cost time: 95.4801676273346
Epoch: 28, Steps: 135 | Train Loss: 0.2284813 Vali Loss: 0.1832223 Test Loss: 0.2148567
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2313581
	speed: 1.5589s/iter; left time: 14997.9592s
Epoch: 29 cost time: 92.74050688743591
Epoch: 29, Steps: 135 | Train Loss: 0.2285114 Vali Loss: 0.1836295 Test Loss: 0.2148665
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2178801
	speed: 1.5675s/iter; left time: 14869.3595s
Epoch: 30 cost time: 91.32870101928711
Epoch: 30, Steps: 135 | Train Loss: 0.2284111 Vali Loss: 0.1834097 Test Loss: 0.2148877
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2382182
	speed: 1.5409s/iter; left time: 14408.4930s
Epoch: 31 cost time: 91.49370574951172
Epoch: 31, Steps: 135 | Train Loss: 0.2283903 Vali Loss: 0.1836079 Test Loss: 0.2148761
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2293259
	speed: 1.2785s/iter; left time: 11782.2011s
Epoch: 32 cost time: 64.99604654312134
Epoch: 32, Steps: 135 | Train Loss: 0.2284656 Vali Loss: 0.1833386 Test Loss: 0.2148804
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2222412
	speed: 1.0492s/iter; left time: 9527.9830s
Epoch: 33 cost time: 63.41431665420532
Epoch: 33, Steps: 135 | Train Loss: 0.2284205 Vali Loss: 0.1833509 Test Loss: 0.2148401
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2292446
	speed: 1.0604s/iter; left time: 9486.3964s
Epoch: 34 cost time: 63.51121115684509
Epoch: 34, Steps: 135 | Train Loss: 0.2284415 Vali Loss: 0.1835743 Test Loss: 0.2148603
EarlyStopping counter: 12 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2374329
	speed: 1.0760s/iter; left time: 9480.4844s
Epoch: 35 cost time: 61.674819231033325
Epoch: 35, Steps: 135 | Train Loss: 0.2284301 Vali Loss: 0.1834857 Test Loss: 0.2148696
EarlyStopping counter: 13 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2247249
	speed: 1.0688s/iter; left time: 9273.1311s
Epoch: 36 cost time: 63.90290904045105
Epoch: 36, Steps: 135 | Train Loss: 0.2283975 Vali Loss: 0.1832654 Test Loss: 0.2148676
EarlyStopping counter: 14 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2287497
	speed: 1.0779s/iter; left time: 9206.6079s
Epoch: 37 cost time: 63.987287759780884
Epoch: 37, Steps: 135 | Train Loss: 0.2284508 Vali Loss: 0.1834730 Test Loss: 0.2148919
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2309137
	speed: 1.0721s/iter; left time: 9012.3620s
Epoch: 38 cost time: 62.45347213745117
Epoch: 38, Steps: 135 | Train Loss: 0.2284509 Vali Loss: 0.1832757 Test Loss: 0.2148683
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2220024
	speed: 1.0783s/iter; left time: 8918.6589s
Epoch: 39 cost time: 65.35722351074219
Epoch: 39, Steps: 135 | Train Loss: 0.2284354 Vali Loss: 0.1833178 Test Loss: 0.2148592
EarlyStopping counter: 17 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2260030
	speed: 1.1073s/iter; left time: 9008.7047s
Epoch: 40 cost time: 66.24474024772644
Epoch: 40, Steps: 135 | Train Loss: 0.2284392 Vali Loss: 0.1834009 Test Loss: 0.2148778
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2202528
	speed: 1.0871s/iter; left time: 8698.2567s
Epoch: 41 cost time: 64.02493739128113
Epoch: 41, Steps: 135 | Train Loss: 0.2283957 Vali Loss: 0.1831682 Test Loss: 0.2148836
Validation loss decreased (0.183221 --> 0.183168).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2383559
	speed: 1.1390s/iter; left time: 8959.0886s
Epoch: 42 cost time: 67.80048489570618
Epoch: 42, Steps: 135 | Train Loss: 0.2284126 Vali Loss: 0.1833078 Test Loss: 0.2148686
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2548707
	speed: 1.1001s/iter; left time: 8505.1134s
Epoch: 43 cost time: 64.54215121269226
Epoch: 43, Steps: 135 | Train Loss: 0.2284146 Vali Loss: 0.1835140 Test Loss: 0.2148628
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2334028
	speed: 1.1035s/iter; left time: 8381.8727s
Epoch: 44 cost time: 65.02975630760193
Epoch: 44, Steps: 135 | Train Loss: 0.2283709 Vali Loss: 0.1834553 Test Loss: 0.2148751
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2272809
	speed: 1.0648s/iter; left time: 7944.7431s
Epoch: 45 cost time: 60.88109850883484
Epoch: 45, Steps: 135 | Train Loss: 0.2284017 Vali Loss: 0.1833029 Test Loss: 0.2148678
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2219929
	speed: 1.0377s/iter; left time: 7602.4963s
Epoch: 46 cost time: 60.1391966342926
Epoch: 46, Steps: 135 | Train Loss: 0.2283609 Vali Loss: 0.1832419 Test Loss: 0.2148667
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2305357
	speed: 1.0054s/iter; left time: 7229.5799s
Epoch: 47 cost time: 59.5737202167511
Epoch: 47, Steps: 135 | Train Loss: 0.2283781 Vali Loss: 0.1831555 Test Loss: 0.2148588
Validation loss decreased (0.183168 --> 0.183156).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2365252
	speed: 1.0486s/iter; left time: 7398.6875s
Epoch: 48 cost time: 61.26814889907837
Epoch: 48, Steps: 135 | Train Loss: 0.2283361 Vali Loss: 0.1833773 Test Loss: 0.2148637
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2236674
	speed: 1.0634s/iter; left time: 7359.4508s
Epoch: 49 cost time: 62.09450006484985
Epoch: 49, Steps: 135 | Train Loss: 0.2284258 Vali Loss: 0.1835105 Test Loss: 0.2148609
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2356384
	speed: 1.0735s/iter; left time: 7284.6825s
Epoch: 50 cost time: 62.19843339920044
Epoch: 50, Steps: 135 | Train Loss: 0.2284019 Vali Loss: 0.1832590 Test Loss: 0.2148707
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2327417
	speed: 1.0378s/iter; left time: 6902.5609s
Epoch: 51 cost time: 62.49584341049194
Epoch: 51, Steps: 135 | Train Loss: 0.2283931 Vali Loss: 0.1833366 Test Loss: 0.2148709
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2334411
	speed: 1.0711s/iter; left time: 6979.3817s
Epoch: 52 cost time: 62.80815362930298
Epoch: 52, Steps: 135 | Train Loss: 0.2284601 Vali Loss: 0.1834408 Test Loss: 0.2148737
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2270727
	speed: 1.0578s/iter; left time: 6749.7880s
Epoch: 53 cost time: 62.45338439941406
Epoch: 53, Steps: 135 | Train Loss: 0.2283118 Vali Loss: 0.1829842 Test Loss: 0.2148679
Validation loss decreased (0.183156 --> 0.182984).  Saving model ...
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2386810
	speed: 1.0624s/iter; left time: 6635.5773s
Epoch: 54 cost time: 61.477697134017944
Epoch: 54, Steps: 135 | Train Loss: 0.2284009 Vali Loss: 0.1830866 Test Loss: 0.2148658
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2341261
	speed: 1.0358s/iter; left time: 6329.8807s
Epoch: 55 cost time: 59.56129336357117
Epoch: 55, Steps: 135 | Train Loss: 0.2284569 Vali Loss: 0.1835610 Test Loss: 0.2148713
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2375187
	speed: 1.0164s/iter; left time: 6074.0285s
Epoch: 56 cost time: 61.384116649627686
Epoch: 56, Steps: 135 | Train Loss: 0.2284266 Vali Loss: 0.1831268 Test Loss: 0.2148667
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2418472
	speed: 1.0208s/iter; left time: 5962.5031s
Epoch: 57 cost time: 59.27606511116028
Epoch: 57, Steps: 135 | Train Loss: 0.2283503 Vali Loss: 0.1834537 Test Loss: 0.2148664
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2218126
	speed: 1.0346s/iter; left time: 5903.4756s
Epoch: 58 cost time: 62.19227647781372
Epoch: 58, Steps: 135 | Train Loss: 0.2284021 Vali Loss: 0.1835399 Test Loss: 0.2148574
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2209923
	speed: 1.0787s/iter; left time: 6009.2429s
Epoch: 59 cost time: 63.081276416778564
Epoch: 59, Steps: 135 | Train Loss: 0.2283208 Vali Loss: 0.1835884 Test Loss: 0.2148644
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.2329434
	speed: 1.0716s/iter; left time: 5825.0681s
Epoch: 60 cost time: 64.15046119689941
Epoch: 60, Steps: 135 | Train Loss: 0.2283845 Vali Loss: 0.1832666 Test Loss: 0.2148683
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.2198147
	speed: 1.0529s/iter; left time: 5581.2766s
Epoch: 61 cost time: 62.09737586975098
Epoch: 61, Steps: 135 | Train Loss: 0.2284459 Vali Loss: 0.1834110 Test Loss: 0.2148669
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.2294866
	speed: 1.0352s/iter; left time: 5347.7725s
Epoch: 62 cost time: 59.75208497047424
Epoch: 62, Steps: 135 | Train Loss: 0.2283629 Vali Loss: 0.1834336 Test Loss: 0.2148603
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.2212048
	speed: 0.9635s/iter; left time: 4847.2184s
Epoch: 63 cost time: 50.84131979942322
Epoch: 63, Steps: 135 | Train Loss: 0.2283884 Vali Loss: 0.1834925 Test Loss: 0.2148629
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.2202636
	speed: 0.8428s/iter; left time: 4126.5165s
Epoch: 64 cost time: 51.13606548309326
Epoch: 64, Steps: 135 | Train Loss: 0.2283996 Vali Loss: 0.1831261 Test Loss: 0.2148652
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.2144220
	speed: 0.8190s/iter; left time: 3899.2891s
Epoch: 65 cost time: 46.26862549781799
Epoch: 65, Steps: 135 | Train Loss: 0.2283561 Vali Loss: 0.1831313 Test Loss: 0.2148651
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.2308326
	speed: 0.8082s/iter; left time: 3738.9247s
Epoch: 66 cost time: 47.44405388832092
Epoch: 66, Steps: 135 | Train Loss: 0.2283717 Vali Loss: 0.1829149 Test Loss: 0.2148683
Validation loss decreased (0.182984 --> 0.182915).  Saving model ...
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.2427708
	speed: 0.8071s/iter; left time: 3624.7398s
Epoch: 67 cost time: 50.941986083984375
Epoch: 67, Steps: 135 | Train Loss: 0.2283595 Vali Loss: 0.1833217 Test Loss: 0.2148664
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.2324170
	speed: 0.8676s/iter; left time: 3779.3842s
Epoch: 68 cost time: 50.70115828514099
Epoch: 68, Steps: 135 | Train Loss: 0.2283740 Vali Loss: 0.1835059 Test Loss: 0.2148675
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.2351271
	speed: 0.8326s/iter; left time: 3514.3855s
Epoch: 69 cost time: 51.72226142883301
Epoch: 69, Steps: 135 | Train Loss: 0.2283283 Vali Loss: 0.1831484 Test Loss: 0.2148639
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.2248364
	speed: 0.8814s/iter; left time: 3601.2302s
Epoch: 70 cost time: 50.81927418708801
Epoch: 70, Steps: 135 | Train Loss: 0.2283572 Vali Loss: 0.1832205 Test Loss: 0.2148608
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.2372215
	speed: 0.8616s/iter; left time: 3404.2787s
Epoch: 71 cost time: 51.17452692985535
Epoch: 71, Steps: 135 | Train Loss: 0.2284095 Vali Loss: 0.1832357 Test Loss: 0.2148614
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.2164126
	speed: 0.8718s/iter; left time: 3326.6812s
Epoch: 72 cost time: 50.49158477783203
Epoch: 72, Steps: 135 | Train Loss: 0.2283346 Vali Loss: 0.1833215 Test Loss: 0.2148634
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.2327119
	speed: 0.8495s/iter; left time: 3127.1008s
Epoch: 73 cost time: 51.57101225852966
Epoch: 73, Steps: 135 | Train Loss: 0.2284072 Vali Loss: 0.1830264 Test Loss: 0.2148627
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.2199366
	speed: 0.8571s/iter; left time: 3039.4411s
Epoch: 74 cost time: 51.098148584365845
Epoch: 74, Steps: 135 | Train Loss: 0.2283942 Vali Loss: 0.1833484 Test Loss: 0.2148629
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.2232812
	speed: 0.8798s/iter; left time: 3000.8470s
Epoch: 75 cost time: 51.89675974845886
Epoch: 75, Steps: 135 | Train Loss: 0.2283460 Vali Loss: 0.1834541 Test Loss: 0.2148634
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.2259376
	speed: 0.8717s/iter; left time: 2855.6830s
Epoch: 76 cost time: 52.30010223388672
Epoch: 76, Steps: 135 | Train Loss: 0.2283413 Vali Loss: 0.1833622 Test Loss: 0.2148640
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.2229271
	speed: 0.8707s/iter; left time: 2734.7799s
Epoch: 77 cost time: 51.468661308288574
Epoch: 77, Steps: 135 | Train Loss: 0.2283540 Vali Loss: 0.1828790 Test Loss: 0.2148654
Validation loss decreased (0.182915 --> 0.182879).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.2162497
	speed: 0.8757s/iter; left time: 2632.2567s
Epoch: 78 cost time: 51.75095558166504
Epoch: 78, Steps: 135 | Train Loss: 0.2284181 Vali Loss: 0.1832845 Test Loss: 0.2148638
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.2217177
	speed: 0.8583s/iter; left time: 2464.1900s
Epoch: 79 cost time: 48.56148719787598
Epoch: 79, Steps: 135 | Train Loss: 0.2283799 Vali Loss: 0.1833559 Test Loss: 0.2148640
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.2412358
	speed: 0.8739s/iter; left time: 2390.9539s
Epoch: 80 cost time: 52.10338878631592
Epoch: 80, Steps: 135 | Train Loss: 0.2283284 Vali Loss: 0.1836220 Test Loss: 0.2148636
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.2205959
	speed: 0.8771s/iter; left time: 2281.3862s
Epoch: 81 cost time: 50.0797917842865
Epoch: 81, Steps: 135 | Train Loss: 0.2283886 Vali Loss: 0.1833193 Test Loss: 0.2148634
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.2341301
	speed: 0.8777s/iter; left time: 2164.3255s
Epoch: 82 cost time: 52.5827534198761
Epoch: 82, Steps: 135 | Train Loss: 0.2283521 Vali Loss: 0.1834720 Test Loss: 0.2148639
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.2383620
	speed: 0.8973s/iter; left time: 2091.6017s
Epoch: 83 cost time: 51.17744731903076
Epoch: 83, Steps: 135 | Train Loss: 0.2284114 Vali Loss: 0.1835933 Test Loss: 0.2148640
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.2276314
	speed: 0.8542s/iter; left time: 1875.8193s
Epoch: 84 cost time: 51.104939460754395
Epoch: 84, Steps: 135 | Train Loss: 0.2284073 Vali Loss: 0.1831781 Test Loss: 0.2148635
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.2390342
	speed: 0.8891s/iter; left time: 1832.4628s
Epoch: 85 cost time: 53.161879777908325
Epoch: 85, Steps: 135 | Train Loss: 0.2282740 Vali Loss: 0.1832894 Test Loss: 0.2148640
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.2321710
	speed: 0.8865s/iter; left time: 1707.4505s
Epoch: 86 cost time: 51.73195505142212
Epoch: 86, Steps: 135 | Train Loss: 0.2284196 Vali Loss: 0.1835443 Test Loss: 0.2148639
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.2304104
	speed: 0.8484s/iter; left time: 1519.4873s
Epoch: 87 cost time: 51.08311700820923
Epoch: 87, Steps: 135 | Train Loss: 0.2283713 Vali Loss: 0.1832280 Test Loss: 0.2148633
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.2224453
	speed: 0.8385s/iter; left time: 1388.4763s
Epoch: 88 cost time: 47.04230308532715
Epoch: 88, Steps: 135 | Train Loss: 0.2283737 Vali Loss: 0.1835339 Test Loss: 0.2148630
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.2264779
	speed: 0.8227s/iter; left time: 1251.3634s
Epoch: 89 cost time: 49.143725633621216
Epoch: 89, Steps: 135 | Train Loss: 0.2284593 Vali Loss: 0.1832684 Test Loss: 0.2148634
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.2134950
	speed: 0.8675s/iter; left time: 1202.4028s
Epoch: 90 cost time: 51.18983054161072
Epoch: 90, Steps: 135 | Train Loss: 0.2284539 Vali Loss: 0.1834676 Test Loss: 0.2148636
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.204402478767869e-06
	iters: 100, epoch: 91 | loss: 0.2216499
	speed: 0.8803s/iter; left time: 1101.2359s
Epoch: 91 cost time: 52.1879723072052
Epoch: 91, Steps: 135 | Train Loss: 0.2284229 Vali Loss: 0.1832058 Test Loss: 0.2148630
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.944182354829475e-06
	iters: 100, epoch: 92 | loss: 0.2298067
	speed: 0.9029s/iter; left time: 1007.5994s
Epoch: 92 cost time: 53.37815809249878
Epoch: 92, Steps: 135 | Train Loss: 0.2283307 Vali Loss: 0.1833477 Test Loss: 0.2148632
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.696973237088e-06
	iters: 100, epoch: 93 | loss: 0.2278933
	speed: 0.9195s/iter; left time: 902.0772s
Epoch: 93 cost time: 53.601980686187744
Epoch: 93, Steps: 135 | Train Loss: 0.2283766 Vali Loss: 0.1831764 Test Loss: 0.2148634
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.462124575233601e-06
	iters: 100, epoch: 94 | loss: 0.2259934
	speed: 0.8360s/iter; left time: 707.2409s
Epoch: 94 cost time: 48.826642990112305
Epoch: 94, Steps: 135 | Train Loss: 0.2283960 Vali Loss: 0.1837035 Test Loss: 0.2148633
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.239018346471921e-06
	iters: 100, epoch: 95 | loss: 0.2450781
	speed: 0.8304s/iter; left time: 590.4309s
Epoch: 95 cost time: 48.0165958404541
Epoch: 95, Steps: 135 | Train Loss: 0.2284249 Vali Loss: 0.1831401 Test Loss: 0.2148638
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.027067429148324e-06
	iters: 100, epoch: 96 | loss: 0.2151462
	speed: 0.8376s/iter; left time: 482.4320s
Epoch: 96 cost time: 51.835575580596924
Epoch: 96, Steps: 135 | Train Loss: 0.2284078 Vali Loss: 0.1835561 Test Loss: 0.2148633
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.825714057690908e-06
	iters: 100, epoch: 97 | loss: 0.2311235
	speed: 0.8575s/iter; left time: 378.1616s
Epoch: 97 cost time: 50.001598834991455
Epoch: 97, Steps: 135 | Train Loss: 0.2283772 Vali Loss: 0.1833411 Test Loss: 0.2148634
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_360_j720_H6_FITS_custom_ftM_sl360_ll48_pl720_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
mse:0.21326632797718048, mae:0.3028782904148102, rse:0.46066850423812866, corr:[0.44589975 0.4489815  0.44946152 0.4498779  0.44991955 0.44995752
 0.44996324 0.44977686 0.44963577 0.44951317 0.449323   0.44923264
 0.44919717 0.44910833 0.44906744 0.44907653 0.44900393 0.44893286
 0.44891378 0.44876167 0.44859904 0.44857448 0.44864887 0.44877666
 0.44888905 0.44907427 0.44910395 0.44906288 0.44901624 0.44892874
 0.44879332 0.4486671  0.44854563 0.44842374 0.44830444 0.44821602
 0.44814762 0.4481087  0.4480902  0.44805667 0.44800392 0.44798145
 0.4479497  0.44778973 0.44767576 0.44766515 0.4476906  0.44778487
 0.44790608 0.44805506 0.44809848 0.4480587  0.44800162 0.4479291
 0.44786304 0.44777805 0.4476855  0.44760507 0.44752124 0.44747287
 0.44743574 0.4474135  0.44740868 0.44740078 0.4473695  0.44734466
 0.44731316 0.44715887 0.44706184 0.44704822 0.44707203 0.44712952
 0.4471841  0.4472663  0.44727102 0.4472158  0.4471421  0.44708204
 0.44701537 0.44691607 0.4468139  0.44674894 0.44669145 0.4466444
 0.44661495 0.44659096 0.44656798 0.4465576  0.44656318 0.4465698
 0.44656092 0.44645873 0.44638544 0.44639763 0.446437   0.4465059
 0.44656497 0.44664785 0.4466745  0.44663137 0.44656298 0.44650218
 0.44645163 0.44639346 0.4463042  0.44622597 0.4461655  0.4461144
 0.44607055 0.44605446 0.44605955 0.4460796  0.44606468 0.4460381
 0.44600338 0.44588456 0.44582307 0.445841   0.4459027  0.44602817
 0.44615    0.4462608  0.4463178  0.44632465 0.44629154 0.4462658
 0.4462437  0.44618976 0.44612697 0.4460748  0.44601738 0.44597387
 0.4459612  0.4459599  0.4459643  0.44598013 0.4459744  0.44595858
 0.44599947 0.44606304 0.44614303 0.44620112 0.44630244 0.4465856
 0.44691524 0.4471109  0.44719934 0.44724438 0.4472275  0.44720438
 0.44718036 0.4471349  0.4470761  0.44700867 0.44692394 0.4468647
 0.44685486 0.44684172 0.44684064 0.4468381  0.4468325  0.44684786
 0.44689834 0.44685844 0.44681057 0.44675827 0.44663417 0.44651118
 0.44635645 0.44626594 0.44613564 0.44601285 0.44590548 0.44578582
 0.44566494 0.44554594 0.44542047 0.4453007  0.44520304 0.44514573
 0.44511992 0.44509578 0.4450845  0.44508353 0.4450556  0.44503865
 0.4450044  0.4448001  0.44462872 0.44455737 0.44451803 0.44450134
 0.4444845  0.4445316  0.44451568 0.44445884 0.44438955 0.44430953
 0.44419983 0.44408783 0.44399908 0.44391304 0.44380537 0.44374576
 0.44373626 0.4437248  0.4437161  0.44372213 0.44371772 0.44371277
 0.44368038 0.44348824 0.44333947 0.44330218 0.4433151  0.44336843
 0.44343245 0.4435268  0.4435456  0.44350848 0.44345304 0.44339877
 0.4433281  0.44325793 0.44320002 0.44311464 0.44304216 0.44299677
 0.44296852 0.44295093 0.44295013 0.44294533 0.4429267  0.44290137
 0.44287673 0.44271624 0.44260556 0.4425832  0.44260013 0.44264024
 0.4426888  0.44277412 0.44278848 0.44274676 0.44269165 0.4426359
 0.44256514 0.44248447 0.4424098  0.44232494 0.4422478  0.44221476
 0.44219458 0.442177   0.44216394 0.44216427 0.44215786 0.4421551
 0.44214797 0.44206846 0.44202363 0.44203025 0.44204664 0.44208267
 0.44214404 0.44223043 0.44224507 0.44221595 0.44217518 0.44213423
 0.4420594  0.44197953 0.44189197 0.44179332 0.44172844 0.44169003
 0.44167355 0.4416706  0.44168398 0.44168934 0.4416815  0.44168964
 0.44166243 0.44151977 0.44145724 0.44148323 0.44153652 0.44164538
 0.44179133 0.44192845 0.44197932 0.44198367 0.44197285 0.44195968
 0.44192347 0.44185823 0.44177943 0.44171083 0.44164675 0.44160372
 0.44159257 0.44160238 0.4416149  0.44161546 0.44160584 0.4416117
 0.44164807 0.44168624 0.44177368 0.44185123 0.44192737 0.44216314
 0.44248438 0.44268233 0.44276625 0.44281086 0.44280148 0.4427797
 0.44274724 0.4426818  0.44261095 0.4425499  0.44248283 0.44240797
 0.44236284 0.44235888 0.44239008 0.4423967  0.44238457 0.44240776
 0.44242716 0.4423124  0.4421917  0.44210777 0.44194624 0.44177562
 0.4416187  0.44156155 0.4414399  0.44130433 0.44120154 0.44108236
 0.4409389  0.44078597 0.44064203 0.44050688 0.4403784  0.44029334
 0.4402581  0.44024032 0.44024277 0.44024047 0.4402183  0.44021702
 0.4402106  0.4400763  0.43997425 0.4399731  0.43996024 0.439919
 0.43986607 0.4399048  0.4398807  0.43980137 0.4397158  0.4396318
 0.43950844 0.43936622 0.4392518  0.43914264 0.43901932 0.43894354
 0.4389231  0.43890592 0.43889093 0.4388812  0.4388646  0.43885303
 0.43883476 0.43870428 0.43861037 0.43860376 0.43862265 0.4386538
 0.43868396 0.43875375 0.4387872  0.4387627  0.4387237  0.4386645
 0.438565   0.43847167 0.43839    0.43830845 0.4382276  0.43817896
 0.43817466 0.4381736  0.43816698 0.43815926 0.43814155 0.43812647
 0.438113   0.43799815 0.4379141  0.43791687 0.43794706 0.4379818
 0.4380223  0.43809715 0.43813303 0.4381162  0.43807673 0.43805403
 0.43799865 0.43789557 0.4377796  0.43770987 0.4376769  0.43764442
 0.43764815 0.43765166 0.4376623  0.4376718  0.4376638  0.4376677
 0.43767855 0.43759483 0.43752807 0.43752307 0.43756205 0.43761775
 0.43765604 0.43771175 0.43774304 0.4377413  0.43772835 0.4377035
 0.43765482 0.4375781  0.43749514 0.4374007  0.43732628 0.43730396
 0.43731058 0.43731275 0.4373188  0.43733475 0.43732512 0.43731642
 0.43728822 0.437177   0.43712372 0.43713084 0.43719065 0.43731987
 0.43747947 0.4376089  0.4376694  0.4376943  0.4376947  0.43768805
 0.43766198 0.43760958 0.43755737 0.437493   0.43741602 0.43737963
 0.43739852 0.43740183 0.43740287 0.4374245  0.43745008 0.43746388
 0.43750912 0.43757895 0.4376799  0.4377631  0.43786308 0.43811592
 0.43843126 0.43861791 0.4386904  0.4387312  0.43873882 0.43873984
 0.4387105  0.43865395 0.43860224 0.4385457  0.43847564 0.4384373
 0.43843487 0.43843758 0.4384661  0.43848696 0.43848246 0.43851057
 0.43854037 0.4384224  0.43830985 0.43823737 0.43809515 0.43791363
 0.4377003  0.4375874  0.43746623 0.43734625 0.43724313 0.4371464
 0.43702614 0.43688482 0.43674496 0.43660823 0.43649215 0.43643382
 0.43643016 0.43642458 0.43642718 0.4364331  0.43640646 0.4364071
 0.4364032  0.43623698 0.4360839  0.43603292 0.43600056 0.4359318
 0.43582857 0.4358179  0.43580577 0.43574402 0.43566352 0.4355891
 0.43548766 0.4353603  0.43521616 0.4350809  0.43497297 0.43494296
 0.4349438  0.4349246  0.4349109  0.43490356 0.43487146 0.4348519
 0.43481842 0.43466803 0.4345819  0.43456867 0.4345913  0.43461424
 0.43460688 0.43461022 0.43458712 0.43452486 0.43446574 0.4343915
 0.43430617 0.4342214  0.43413538 0.43401545 0.43388754 0.43379572
 0.43374255 0.4336784  0.43363926 0.4335999  0.43351257 0.4333912
 0.43330273 0.43320596 0.43313393 0.43311316 0.43312868 0.43316713
 0.4332234  0.4332936  0.433313   0.43329436 0.43326858 0.4332162
 0.43314296 0.43305376 0.43295074 0.43283823 0.43273395 0.4326863
 0.43267998 0.4326543  0.43263775 0.43262708 0.4326039  0.4325817
 0.43256792 0.43249342 0.43244946 0.43245357 0.43246713 0.43249047
 0.43253252 0.43260452 0.4326246  0.4326081  0.4325841  0.43253464
 0.432463   0.43237987 0.43228614 0.43218315 0.43209094 0.43203008
 0.43200606 0.4320088  0.43202305 0.4320283  0.4319983  0.43199596
 0.43199438 0.43189275 0.43183425 0.431866   0.4319334  0.43206418
 0.43223464 0.4323637  0.43243086 0.43245623 0.43245062 0.43242133
 0.43238166 0.43231785 0.43223307 0.43214735 0.4320745  0.43203136
 0.43202022 0.43201464 0.43201405 0.43199983 0.4319898  0.43200526
 0.4320569  0.43211937 0.4322108  0.43230566 0.43243366 0.432701
 0.43298006 0.43310454 0.4331605  0.43321785 0.43320617 0.43316263
 0.43312523 0.43307188 0.43300197 0.4329224  0.43284002 0.43277118
 0.43274298 0.43274546 0.43275046 0.4327424  0.4327476  0.43279365
 0.43282828 0.43271792 0.43262863 0.432563   0.43242922 0.4322529
 0.43198386 0.43179655 0.4316484  0.42733178 0.4313847  0.43124783
 0.42691892 0.4267668  0.43079272 0.42645964 0.42634368 0.42626014
 0.42624137 0.42622843 0.4262089  0.42619762 0.42619622 0.4262088
 0.42617    0.42599407 0.4258562  0.4257997  0.4257656  0.42573962
 0.42565367 0.42560402 0.42555708 0.42548317 0.4253743  0.42528072
 0.42517364 0.4250143  0.42486513 0.42476737 0.42465404 0.42458415
 0.4246094  0.4246051  0.42454106 0.4245528  0.4245579  0.4245075
 0.4245251  0.4244464  0.4243306  0.42435557 0.4244124  0.42423943]
