Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_90_j336_H4', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_90_j336_H4_FITS_custom_ftM_sl90_ll48_pl336_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17987
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=26, out_features=123, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  131399424.0
params:  3321.0
Trainable parameters:  3321
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.8782322
	speed: 0.7375s/iter; left time: 10251.9238s
Epoch: 1 cost time: 101.04961729049683
Epoch: 1, Steps: 140 | Train Loss: 1.1816773 Vali Loss: 0.6005591 Test Loss: 0.6822847
Validation loss decreased (inf --> 0.600559).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4821807
	speed: 1.8020s/iter; left time: 24797.4403s
Epoch: 2 cost time: 103.84279274940491
Epoch: 2, Steps: 140 | Train Loss: 0.5385630 Vali Loss: 0.3658726 Test Loss: 0.4148011
Validation loss decreased (0.600559 --> 0.365873).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3447949
	speed: 1.7984s/iter; left time: 24495.5460s
Epoch: 3 cost time: 101.3665087223053
Epoch: 3, Steps: 140 | Train Loss: 0.3702142 Vali Loss: 0.2834847 Test Loss: 0.3201778
Validation loss decreased (0.365873 --> 0.283485).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3014988
	speed: 1.8944s/iter; left time: 25538.3156s
Epoch: 4 cost time: 103.97439503669739
Epoch: 4, Steps: 140 | Train Loss: 0.3060166 Vali Loss: 0.2495109 Test Loss: 0.2808832
Validation loss decreased (0.283485 --> 0.249511).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2753094
	speed: 1.7790s/iter; left time: 23734.2697s
Epoch: 5 cost time: 100.92988610267639
Epoch: 5, Steps: 140 | Train Loss: 0.2781094 Vali Loss: 0.2331881 Test Loss: 0.2625581
Validation loss decreased (0.249511 --> 0.233188).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2536550
	speed: 1.6749s/iter; left time: 22110.7779s
Epoch: 6 cost time: 95.63919281959534
Epoch: 6, Steps: 140 | Train Loss: 0.2642787 Vali Loss: 0.2245189 Test Loss: 0.2527259
Validation loss decreased (0.233188 --> 0.224519).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2571536
	speed: 1.7393s/iter; left time: 22717.5746s
Epoch: 7 cost time: 97.14138078689575
Epoch: 7, Steps: 140 | Train Loss: 0.2562544 Vali Loss: 0.2191012 Test Loss: 0.2466368
Validation loss decreased (0.224519 --> 0.219101).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2602613
	speed: 1.7450s/iter; left time: 22546.6076s
Epoch: 8 cost time: 100.88746166229248
Epoch: 8, Steps: 140 | Train Loss: 0.2510920 Vali Loss: 0.2151751 Test Loss: 0.2425246
Validation loss decreased (0.219101 --> 0.215175).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2493331
	speed: 1.7670s/iter; left time: 22583.8323s
Epoch: 9 cost time: 102.88444256782532
Epoch: 9, Steps: 140 | Train Loss: 0.2474314 Vali Loss: 0.2125444 Test Loss: 0.2395536
Validation loss decreased (0.215175 --> 0.212544).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2565127
	speed: 1.7824s/iter; left time: 22530.7428s
Epoch: 10 cost time: 99.83810472488403
Epoch: 10, Steps: 140 | Train Loss: 0.2447613 Vali Loss: 0.2106074 Test Loss: 0.2373285
Validation loss decreased (0.212544 --> 0.210607).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2362108
	speed: 1.7271s/iter; left time: 21591.0947s
Epoch: 11 cost time: 98.81860947608948
Epoch: 11, Steps: 140 | Train Loss: 0.2426350 Vali Loss: 0.2089541 Test Loss: 0.2355956
Validation loss decreased (0.210607 --> 0.208954).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2461475
	speed: 1.7272s/iter; left time: 21349.6716s
Epoch: 12 cost time: 99.5990834236145
Epoch: 12, Steps: 140 | Train Loss: 0.2410790 Vali Loss: 0.2074104 Test Loss: 0.2342331
Validation loss decreased (0.208954 --> 0.207410).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2447419
	speed: 1.7908s/iter; left time: 21885.0152s
Epoch: 13 cost time: 101.2542736530304
Epoch: 13, Steps: 140 | Train Loss: 0.2397623 Vali Loss: 0.2065079 Test Loss: 0.2331391
Validation loss decreased (0.207410 --> 0.206508).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2386826
	speed: 1.6553s/iter; left time: 19998.0356s
Epoch: 14 cost time: 86.25832319259644
Epoch: 14, Steps: 140 | Train Loss: 0.2387686 Vali Loss: 0.2053865 Test Loss: 0.2322270
Validation loss decreased (0.206508 --> 0.205386).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2330969
	speed: 1.2469s/iter; left time: 14889.2465s
Epoch: 15 cost time: 70.87933039665222
Epoch: 15, Steps: 140 | Train Loss: 0.2378594 Vali Loss: 0.2050233 Test Loss: 0.2314611
Validation loss decreased (0.205386 --> 0.205023).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2318165
	speed: 1.2956s/iter; left time: 15289.7730s
Epoch: 16 cost time: 74.78394913673401
Epoch: 16, Steps: 140 | Train Loss: 0.2372336 Vali Loss: 0.2043061 Test Loss: 0.2308400
Validation loss decreased (0.205023 --> 0.204306).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2500851
	speed: 1.2052s/iter; left time: 14054.0241s
Epoch: 17 cost time: 68.46808528900146
Epoch: 17, Steps: 140 | Train Loss: 0.2365434 Vali Loss: 0.2036351 Test Loss: 0.2302851
Validation loss decreased (0.204306 --> 0.203635).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2435375
	speed: 1.1840s/iter; left time: 13640.5752s
Epoch: 18 cost time: 67.6074047088623
Epoch: 18, Steps: 140 | Train Loss: 0.2359551 Vali Loss: 0.2034940 Test Loss: 0.2298103
Validation loss decreased (0.203635 --> 0.203494).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2416000
	speed: 1.2022s/iter; left time: 13682.3051s
Epoch: 19 cost time: 68.57498288154602
Epoch: 19, Steps: 140 | Train Loss: 0.2355355 Vali Loss: 0.2027301 Test Loss: 0.2293831
Validation loss decreased (0.203494 --> 0.202730).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2287323
	speed: 1.2623s/iter; left time: 14189.3730s
Epoch: 20 cost time: 73.1841356754303
Epoch: 20, Steps: 140 | Train Loss: 0.2350846 Vali Loss: 0.2025017 Test Loss: 0.2290169
Validation loss decreased (0.202730 --> 0.202502).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2249640
	speed: 1.1815s/iter; left time: 13115.6596s
Epoch: 21 cost time: 69.79661178588867
Epoch: 21, Steps: 140 | Train Loss: 0.2347957 Vali Loss: 0.2020677 Test Loss: 0.2286832
Validation loss decreased (0.202502 --> 0.202068).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2415590
	speed: 1.1893s/iter; left time: 13035.8917s
Epoch: 22 cost time: 67.77245116233826
Epoch: 22, Steps: 140 | Train Loss: 0.2343775 Vali Loss: 0.2018047 Test Loss: 0.2283774
Validation loss decreased (0.202068 --> 0.201805).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2311217
	speed: 1.1383s/iter; left time: 12317.0086s
Epoch: 23 cost time: 62.494479179382324
Epoch: 23, Steps: 140 | Train Loss: 0.2340418 Vali Loss: 0.2017186 Test Loss: 0.2281156
Validation loss decreased (0.201805 --> 0.201719).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2416634
	speed: 1.1085s/iter; left time: 11839.5750s
Epoch: 24 cost time: 68.43615770339966
Epoch: 24, Steps: 140 | Train Loss: 0.2337882 Vali Loss: 0.2015995 Test Loss: 0.2278530
Validation loss decreased (0.201719 --> 0.201600).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2292975
	speed: 1.1602s/iter; left time: 12229.8864s
Epoch: 25 cost time: 68.28975319862366
Epoch: 25, Steps: 140 | Train Loss: 0.2335711 Vali Loss: 0.2011760 Test Loss: 0.2276336
Validation loss decreased (0.201600 --> 0.201176).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2386934
	speed: 1.1741s/iter; left time: 12211.5332s
Epoch: 26 cost time: 67.61853361129761
Epoch: 26, Steps: 140 | Train Loss: 0.2332720 Vali Loss: 0.2011929 Test Loss: 0.2274252
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2251411
	speed: 1.2311s/iter; left time: 12632.0966s
Epoch: 27 cost time: 74.26043629646301
Epoch: 27, Steps: 140 | Train Loss: 0.2331481 Vali Loss: 0.2010317 Test Loss: 0.2272431
Validation loss decreased (0.201176 --> 0.201032).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2279854
	speed: 1.4233s/iter; left time: 14405.5446s
Epoch: 28 cost time: 87.06366205215454
Epoch: 28, Steps: 140 | Train Loss: 0.2329247 Vali Loss: 0.2011013 Test Loss: 0.2270683
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2269085
	speed: 1.5496s/iter; left time: 15466.4537s
Epoch: 29 cost time: 90.63790607452393
Epoch: 29, Steps: 140 | Train Loss: 0.2327420 Vali Loss: 0.2004896 Test Loss: 0.2269020
Validation loss decreased (0.201032 --> 0.200490).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2235340
	speed: 1.4869s/iter; left time: 14632.9077s
Epoch: 30 cost time: 80.00161838531494
Epoch: 30, Steps: 140 | Train Loss: 0.2326003 Vali Loss: 0.2006905 Test Loss: 0.2267635
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2237894
	speed: 1.5652s/iter; left time: 15183.8261s
Epoch: 31 cost time: 88.79593563079834
Epoch: 31, Steps: 140 | Train Loss: 0.2324244 Vali Loss: 0.2005309 Test Loss: 0.2266321
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2283782
	speed: 1.5225s/iter; left time: 14556.4105s
Epoch: 32 cost time: 85.84511542320251
Epoch: 32, Steps: 140 | Train Loss: 0.2322758 Vali Loss: 0.2006932 Test Loss: 0.2265096
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2303675
	speed: 1.4795s/iter; left time: 13938.7472s
Epoch: 33 cost time: 84.76803612709045
Epoch: 33, Steps: 140 | Train Loss: 0.2322277 Vali Loss: 0.2001277 Test Loss: 0.2263946
Validation loss decreased (0.200490 --> 0.200128).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2248257
	speed: 1.4945s/iter; left time: 13870.7240s
Epoch: 34 cost time: 85.47491407394409
Epoch: 34, Steps: 140 | Train Loss: 0.2319639 Vali Loss: 0.2003908 Test Loss: 0.2262889
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2353754
	speed: 1.4823s/iter; left time: 13549.7544s
Epoch: 35 cost time: 86.5656168460846
Epoch: 35, Steps: 140 | Train Loss: 0.2319666 Vali Loss: 0.2001928 Test Loss: 0.2261926
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2314854
	speed: 1.4561s/iter; left time: 13106.5253s
Epoch: 36 cost time: 79.61334133148193
Epoch: 36, Steps: 140 | Train Loss: 0.2318337 Vali Loss: 0.1998695 Test Loss: 0.2261101
Validation loss decreased (0.200128 --> 0.199870).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2377266
	speed: 1.2449s/iter; left time: 11031.4718s
Epoch: 37 cost time: 71.5125241279602
Epoch: 37, Steps: 140 | Train Loss: 0.2316418 Vali Loss: 0.1999271 Test Loss: 0.2260249
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2211959
	speed: 1.3791s/iter; left time: 12027.3698s
Epoch: 38 cost time: 74.88537693023682
Epoch: 38, Steps: 140 | Train Loss: 0.2317178 Vali Loss: 0.1997002 Test Loss: 0.2259490
Validation loss decreased (0.199870 --> 0.199700).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2272580
	speed: 1.0429s/iter; left time: 8948.8175s
Epoch: 39 cost time: 59.82338213920593
Epoch: 39, Steps: 140 | Train Loss: 0.2316133 Vali Loss: 0.1995876 Test Loss: 0.2258923
Validation loss decreased (0.199700 --> 0.199588).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2194621
	speed: 1.0075s/iter; left time: 8504.2427s
Epoch: 40 cost time: 61.14288139343262
Epoch: 40, Steps: 140 | Train Loss: 0.2315563 Vali Loss: 0.1997378 Test Loss: 0.2258270
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2381567
	speed: 1.1426s/iter; left time: 9484.6506s
Epoch: 41 cost time: 66.67719507217407
Epoch: 41, Steps: 140 | Train Loss: 0.2313974 Vali Loss: 0.1998659 Test Loss: 0.2257667
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2432927
	speed: 1.1602s/iter; left time: 9468.3149s
Epoch: 42 cost time: 65.73611068725586
Epoch: 42, Steps: 140 | Train Loss: 0.2314263 Vali Loss: 0.1994746 Test Loss: 0.2257206
Validation loss decreased (0.199588 --> 0.199475).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2265436
	speed: 1.1231s/iter; left time: 9008.2474s
Epoch: 43 cost time: 66.08279967308044
Epoch: 43, Steps: 140 | Train Loss: 0.2313786 Vali Loss: 0.1994012 Test Loss: 0.2256733
Validation loss decreased (0.199475 --> 0.199401).  Saving model ...
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2389893
	speed: 1.1009s/iter; left time: 8676.5733s
Epoch: 44 cost time: 64.89801025390625
Epoch: 44, Steps: 140 | Train Loss: 0.2312859 Vali Loss: 0.1993374 Test Loss: 0.2256289
Validation loss decreased (0.199401 --> 0.199337).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2263380
	speed: 1.3386s/iter; left time: 10361.9149s
Epoch: 45 cost time: 73.27565026283264
Epoch: 45, Steps: 140 | Train Loss: 0.2312375 Vali Loss: 0.1996372 Test Loss: 0.2255905
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2177408
	speed: 1.2288s/iter; left time: 9340.1075s
Epoch: 46 cost time: 71.11790537834167
Epoch: 46, Steps: 140 | Train Loss: 0.2312068 Vali Loss: 0.1994879 Test Loss: 0.2255566
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2300621
	speed: 1.1362s/iter; left time: 8477.2203s
Epoch: 47 cost time: 63.75142240524292
Epoch: 47, Steps: 140 | Train Loss: 0.2311917 Vali Loss: 0.1996261 Test Loss: 0.2255192
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2229849
	speed: 1.1794s/iter; left time: 8634.0925s
Epoch: 48 cost time: 67.57562184333801
Epoch: 48, Steps: 140 | Train Loss: 0.2311644 Vali Loss: 0.1992297 Test Loss: 0.2254911
Validation loss decreased (0.199337 --> 0.199230).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2393801
	speed: 1.1371s/iter; left time: 8165.6273s
Epoch: 49 cost time: 63.52644991874695
Epoch: 49, Steps: 140 | Train Loss: 0.2310774 Vali Loss: 0.1993821 Test Loss: 0.2254620
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2295983
	speed: 1.1974s/iter; left time: 8430.9992s
Epoch: 50 cost time: 66.41751337051392
Epoch: 50, Steps: 140 | Train Loss: 0.2310393 Vali Loss: 0.1995767 Test Loss: 0.2254359
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2306773
	speed: 1.1669s/iter; left time: 8052.7677s
Epoch: 51 cost time: 66.73536276817322
Epoch: 51, Steps: 140 | Train Loss: 0.2311067 Vali Loss: 0.1994491 Test Loss: 0.2254143
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2396297
	speed: 1.1855s/iter; left time: 8014.9215s
Epoch: 52 cost time: 65.11509084701538
Epoch: 52, Steps: 140 | Train Loss: 0.2310653 Vali Loss: 0.1993989 Test Loss: 0.2253935
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2251526
	speed: 1.2220s/iter; left time: 8090.6921s
Epoch: 53 cost time: 66.39060974121094
Epoch: 53, Steps: 140 | Train Loss: 0.2310666 Vali Loss: 0.1994263 Test Loss: 0.2253800
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2322823
	speed: 1.1867s/iter; left time: 7690.7191s
Epoch: 54 cost time: 71.76614713668823
Epoch: 54, Steps: 140 | Train Loss: 0.2310283 Vali Loss: 0.1993183 Test Loss: 0.2253611
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2187192
	speed: 1.1664s/iter; left time: 7395.8433s
Epoch: 55 cost time: 66.9358263015747
Epoch: 55, Steps: 140 | Train Loss: 0.2310046 Vali Loss: 0.1990289 Test Loss: 0.2253441
Validation loss decreased (0.199230 --> 0.199029).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2314913
	speed: 1.1554s/iter; left time: 7164.6961s
Epoch: 56 cost time: 61.08150243759155
Epoch: 56, Steps: 140 | Train Loss: 0.2309514 Vali Loss: 0.1992755 Test Loss: 0.2253290
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2277249
	speed: 0.9816s/iter; left time: 5949.6309s
Epoch: 57 cost time: 57.71019411087036
Epoch: 57, Steps: 140 | Train Loss: 0.2308946 Vali Loss: 0.1991526 Test Loss: 0.2253177
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2257335
	speed: 0.9400s/iter; left time: 5565.5111s
Epoch: 58 cost time: 52.16842341423035
Epoch: 58, Steps: 140 | Train Loss: 0.2309062 Vali Loss: 0.1992661 Test Loss: 0.2253048
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2401729
	speed: 0.9872s/iter; left time: 5707.2373s
Epoch: 59 cost time: 52.9187376499176
Epoch: 59, Steps: 140 | Train Loss: 0.2309437 Vali Loss: 0.1991205 Test Loss: 0.2252926
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.2276525
	speed: 0.9750s/iter; left time: 5499.8712s
Epoch: 60 cost time: 56.010576248168945
Epoch: 60, Steps: 140 | Train Loss: 0.2309074 Vali Loss: 0.1988124 Test Loss: 0.2252861
Validation loss decreased (0.199029 --> 0.198812).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.2310569
	speed: 0.9939s/iter; left time: 5467.4774s
Epoch: 61 cost time: 52.82674288749695
Epoch: 61, Steps: 140 | Train Loss: 0.2309266 Vali Loss: 0.1992740 Test Loss: 0.2252722
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.2265861
	speed: 0.9532s/iter; left time: 5110.0412s
Epoch: 62 cost time: 54.45422863960266
Epoch: 62, Steps: 140 | Train Loss: 0.2308632 Vali Loss: 0.1989943 Test Loss: 0.2252649
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.2266200
	speed: 0.9330s/iter; left time: 4871.2974s
Epoch: 63 cost time: 55.425188302993774
Epoch: 63, Steps: 140 | Train Loss: 0.2309235 Vali Loss: 0.1992709 Test Loss: 0.2252594
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.2301116
	speed: 0.9932s/iter; left time: 5046.4422s
Epoch: 64 cost time: 58.28851294517517
Epoch: 64, Steps: 140 | Train Loss: 0.2308702 Vali Loss: 0.1993092 Test Loss: 0.2252513
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.2299992
	speed: 0.9849s/iter; left time: 4866.2538s
Epoch: 65 cost time: 56.20806431770325
Epoch: 65, Steps: 140 | Train Loss: 0.2308054 Vali Loss: 0.1995061 Test Loss: 0.2252471
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.2352369
	speed: 0.9900s/iter; left time: 4752.8996s
Epoch: 66 cost time: 56.200016498565674
Epoch: 66, Steps: 140 | Train Loss: 0.2308076 Vali Loss: 0.1990581 Test Loss: 0.2252403
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.2277060
	speed: 0.9585s/iter; left time: 4467.5569s
Epoch: 67 cost time: 60.57514500617981
Epoch: 67, Steps: 140 | Train Loss: 0.2309491 Vali Loss: 0.1990322 Test Loss: 0.2252341
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.2304845
	speed: 0.9700s/iter; left time: 4385.5188s
Epoch: 68 cost time: 55.71259832382202
Epoch: 68, Steps: 140 | Train Loss: 0.2308279 Vali Loss: 0.1988541 Test Loss: 0.2252276
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.2269425
	speed: 0.9691s/iter; left time: 4245.6762s
Epoch: 69 cost time: 55.63816452026367
Epoch: 69, Steps: 140 | Train Loss: 0.2308261 Vali Loss: 0.1990143 Test Loss: 0.2252254
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.2291359
	speed: 0.8883s/iter; left time: 3767.0898s
Epoch: 70 cost time: 48.04492664337158
Epoch: 70, Steps: 140 | Train Loss: 0.2309011 Vali Loss: 0.1990830 Test Loss: 0.2252212
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.2348873
	speed: 0.7412s/iter; left time: 3039.7138s
Epoch: 71 cost time: 41.01808500289917
Epoch: 71, Steps: 140 | Train Loss: 0.2308605 Vali Loss: 0.1987136 Test Loss: 0.2252170
Validation loss decreased (0.198812 --> 0.198714).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.2387822
	speed: 0.7403s/iter; left time: 2932.2813s
Epoch: 72 cost time: 43.34970736503601
Epoch: 72, Steps: 140 | Train Loss: 0.2308054 Vali Loss: 0.1992811 Test Loss: 0.2252130
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.2267168
	speed: 0.7843s/iter; left time: 2996.8803s
Epoch: 73 cost time: 45.89655613899231
Epoch: 73, Steps: 140 | Train Loss: 0.2307943 Vali Loss: 0.1993236 Test Loss: 0.2252111
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.2299978
	speed: 0.7648s/iter; left time: 2815.2572s
Epoch: 74 cost time: 42.14396667480469
Epoch: 74, Steps: 140 | Train Loss: 0.2308557 Vali Loss: 0.1989021 Test Loss: 0.2252080
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.2461021
	speed: 0.6906s/iter; left time: 2445.3325s
Epoch: 75 cost time: 41.57986116409302
Epoch: 75, Steps: 140 | Train Loss: 0.2308780 Vali Loss: 0.1988824 Test Loss: 0.2252057
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.2195220
	speed: 0.7423s/iter; left time: 2524.3972s
Epoch: 76 cost time: 42.709328174591064
Epoch: 76, Steps: 140 | Train Loss: 0.2307773 Vali Loss: 0.1988277 Test Loss: 0.2252024
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.2365075
	speed: 0.7761s/iter; left time: 2530.8442s
Epoch: 77 cost time: 43.54424691200256
Epoch: 77, Steps: 140 | Train Loss: 0.2308273 Vali Loss: 0.1991642 Test Loss: 0.2251999
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.2303568
	speed: 0.7392s/iter; left time: 2306.9286s
Epoch: 78 cost time: 41.35528492927551
Epoch: 78, Steps: 140 | Train Loss: 0.2307450 Vali Loss: 0.1989206 Test Loss: 0.2251974
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.2361271
	speed: 0.7310s/iter; left time: 2179.0210s
Epoch: 79 cost time: 42.107582092285156
Epoch: 79, Steps: 140 | Train Loss: 0.2308040 Vali Loss: 0.1990820 Test Loss: 0.2251964
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.2156841
	speed: 0.7182s/iter; left time: 2040.4147s
Epoch: 80 cost time: 41.99847412109375
Epoch: 80, Steps: 140 | Train Loss: 0.2307493 Vali Loss: 0.1986689 Test Loss: 0.2251933
Validation loss decreased (0.198714 --> 0.198669).  Saving model ...
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.2343997
	speed: 0.7518s/iter; left time: 2030.5542s
Epoch: 81 cost time: 42.80621123313904
Epoch: 81, Steps: 140 | Train Loss: 0.2308471 Vali Loss: 0.1991115 Test Loss: 0.2251929
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.2281872
	speed: 0.7243s/iter; left time: 1854.8136s
Epoch: 82 cost time: 41.805310010910034
Epoch: 82, Steps: 140 | Train Loss: 0.2307342 Vali Loss: 0.1990754 Test Loss: 0.2251910
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.2370031
	speed: 0.7378s/iter; left time: 1786.2807s
Epoch: 83 cost time: 41.26007032394409
Epoch: 83, Steps: 140 | Train Loss: 0.2308177 Vali Loss: 0.1994399 Test Loss: 0.2251890
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.2356264
	speed: 0.7411s/iter; left time: 1690.4748s
Epoch: 84 cost time: 42.5008749961853
Epoch: 84, Steps: 140 | Train Loss: 0.2307988 Vali Loss: 0.1992138 Test Loss: 0.2251878
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.2245448
	speed: 0.6784s/iter; left time: 1452.3712s
Epoch: 85 cost time: 37.35377836227417
Epoch: 85, Steps: 140 | Train Loss: 0.2308425 Vali Loss: 0.1993466 Test Loss: 0.2251865
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.2347711
	speed: 0.6691s/iter; left time: 1338.8382s
Epoch: 86 cost time: 36.18299150466919
Epoch: 86, Steps: 140 | Train Loss: 0.2307851 Vali Loss: 0.1992718 Test Loss: 0.2251855
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.2255757
	speed: 0.6836s/iter; left time: 1272.2510s
Epoch: 87 cost time: 39.23768663406372
Epoch: 87, Steps: 140 | Train Loss: 0.2308272 Vali Loss: 0.1989441 Test Loss: 0.2251849
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.2402799
	speed: 0.6875s/iter; left time: 1183.2396s
Epoch: 88 cost time: 38.86423110961914
Epoch: 88, Steps: 140 | Train Loss: 0.2308362 Vali Loss: 0.1991871 Test Loss: 0.2251841
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.2334109
	speed: 0.6804s/iter; left time: 1075.6628s
Epoch: 89 cost time: 39.15485239028931
Epoch: 89, Steps: 140 | Train Loss: 0.2308149 Vali Loss: 0.1990773 Test Loss: 0.2251831
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.2456820
	speed: 0.6434s/iter; left time: 927.1371s
Epoch: 90 cost time: 33.9549400806427
Epoch: 90, Steps: 140 | Train Loss: 0.2307208 Vali Loss: 0.1988954 Test Loss: 0.2251820
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.204402478767869e-06
	iters: 100, epoch: 91 | loss: 0.2270379
	speed: 0.5809s/iter; left time: 755.8044s
Epoch: 91 cost time: 32.48809051513672
Epoch: 91, Steps: 140 | Train Loss: 0.2308042 Vali Loss: 0.1990621 Test Loss: 0.2251814
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.944182354829475e-06
	iters: 100, epoch: 92 | loss: 0.2273735
	speed: 0.5521s/iter; left time: 640.9795s
Epoch: 92 cost time: 30.944074153900146
Epoch: 92, Steps: 140 | Train Loss: 0.2307109 Vali Loss: 0.1990849 Test Loss: 0.2251801
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.696973237088e-06
	iters: 100, epoch: 93 | loss: 0.2323997
	speed: 0.5454s/iter; left time: 556.8536s
Epoch: 93 cost time: 30.96685814857483
Epoch: 93, Steps: 140 | Train Loss: 0.2308227 Vali Loss: 0.1990140 Test Loss: 0.2251793
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.462124575233601e-06
	iters: 100, epoch: 94 | loss: 0.2317725
	speed: 0.5469s/iter; left time: 481.7893s
Epoch: 94 cost time: 29.97891092300415
Epoch: 94, Steps: 140 | Train Loss: 0.2308072 Vali Loss: 0.1989959 Test Loss: 0.2251788
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.239018346471921e-06
	iters: 100, epoch: 95 | loss: 0.2359641
	speed: 0.5406s/iter; left time: 400.5598s
Epoch: 95 cost time: 30.067975759506226
Epoch: 95, Steps: 140 | Train Loss: 0.2308387 Vali Loss: 0.1990061 Test Loss: 0.2251780
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.027067429148324e-06
	iters: 100, epoch: 96 | loss: 0.2284445
	speed: 0.5575s/iter; left time: 335.0414s
Epoch: 96 cost time: 32.201109886169434
Epoch: 96, Steps: 140 | Train Loss: 0.2308129 Vali Loss: 0.1992584 Test Loss: 0.2251778
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.825714057690908e-06
	iters: 100, epoch: 97 | loss: 0.2241877
	speed: 0.5405s/iter; left time: 249.1592s
Epoch: 97 cost time: 30.01666760444641
Epoch: 97, Steps: 140 | Train Loss: 0.2308260 Vali Loss: 0.1989417 Test Loss: 0.2251766
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.6344283548063623e-06
	iters: 100, epoch: 98 | loss: 0.2259550
	speed: 0.5482s/iter; left time: 175.9654s
Epoch: 98 cost time: 30.040913581848145
Epoch: 98, Steps: 140 | Train Loss: 0.2308696 Vali Loss: 0.1994577 Test Loss: 0.2251764
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.452706937066044e-06
	iters: 100, epoch: 99 | loss: 0.2351614
	speed: 0.5523s/iter; left time: 99.9640s
Epoch: 99 cost time: 30.980210304260254
Epoch: 99, Steps: 140 | Train Loss: 0.2307766 Vali Loss: 0.1990259 Test Loss: 0.2251760
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.2800715902127414e-06
	iters: 100, epoch: 100 | loss: 0.2166247
	speed: 0.5540s/iter; left time: 22.7144s
Epoch: 100 cost time: 32.090447187423706
Epoch: 100, Steps: 140 | Train Loss: 0.2308557 Vali Loss: 0.1991284 Test Loss: 0.2251755
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_90_j336_H4_FITS_custom_ftM_sl90_ll48_pl336_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4925
mse:0.22375229001045227, mae:0.30599749088287354, rse:0.4707876145839691, corr:[0.45508936 0.45238793 0.45186538 0.4514065  0.45003927 0.44888034
 0.44959262 0.44870764 0.44718215 0.44634005 0.4457621  0.4451503
 0.44486776 0.44443533 0.44400436 0.44396317 0.444013   0.4441368
 0.444371   0.44436213 0.44426897 0.44425544 0.44399568 0.44281614
 0.440369   0.43911815 0.43813932 0.43703082 0.43639618 0.43650505
 0.4376945  0.43772003 0.43729183 0.43699104 0.43672663 0.4363143
 0.43624496 0.43617526 0.4358479  0.435707   0.4358026  0.43586364
 0.43594527 0.43608454 0.43620592 0.43628463 0.43626785 0.4359176
 0.43462047 0.43427658 0.43435946 0.43452984 0.43525994 0.436722
 0.43902865 0.4404389  0.4408671  0.44068235 0.4405235  0.44023275
 0.43999988 0.4399143  0.439859   0.43999088 0.44023928 0.44042304
 0.44062316 0.4408804  0.44121623 0.44155318 0.44194248 0.442333
 0.44230437 0.4429131  0.44365507 0.44472134 0.44647804 0.44898456
 0.4522829  0.4547863  0.45564654 0.45506412 0.45458433 0.45421886
 0.45380026 0.45356727 0.4534869  0.4535914  0.45390573 0.45412004
 0.4543366  0.45462146 0.45475322 0.45483527 0.45504633 0.4551268
 0.45472512 0.45472145 0.4547975  0.45469463 0.45463356 0.45482814
 0.45530987 0.45530868 0.45507362 0.45459667 0.45423365 0.45397475
 0.45373362 0.4536598  0.45368427 0.45374545 0.45400104 0.45419216
 0.45428634 0.4544435  0.45448473 0.4544606  0.45463243 0.4548411
 0.45451263 0.45447338 0.4545839  0.45454141 0.45439947 0.454419
 0.45472467 0.4545549  0.45428786 0.45394522 0.45362064 0.4534463
 0.45333308 0.45333362 0.4534503  0.45356676 0.4538588  0.45417368
 0.45430323 0.45443407 0.45450485 0.45445994 0.4544588  0.45445722
 0.45397303 0.453763   0.45379284 0.45378712 0.45368472 0.4537147
 0.45405325 0.45396453 0.45367676 0.45325476 0.45285824 0.4526722
 0.4526115  0.45267424 0.4529047  0.4531011  0.45344386 0.45395842
 0.45418632 0.45410976 0.45406717 0.45374846 0.45250887 0.45016468
 0.44717205 0.44493273 0.44332767 0.44190004 0.44076687 0.44009262
 0.440103   0.43974105 0.43940315 0.43895224 0.4384688  0.4382624
 0.43819898 0.43799838 0.4378091  0.4375466  0.43748286 0.4375276
 0.43731257 0.43709728 0.43701375 0.4366936  0.43577248 0.43415397
 0.43186137 0.43035042 0.42934778 0.42859313 0.4281265  0.42835358
 0.42950952 0.42995796 0.43010387 0.4299344  0.4295958  0.42951182
 0.42964315 0.4295486  0.4293742  0.42923126 0.42924976 0.4293208
 0.4291886  0.42914894 0.42932007 0.42931014 0.428967   0.42848563
 0.4274565  0.42695177 0.42695257 0.4274059  0.42815012 0.42959753
 0.43205008 0.433737   0.4344896  0.43454146 0.43429077 0.4341455
 0.43416938 0.43405852 0.43395507 0.43403357 0.43426013 0.43447447
 0.4345282  0.43469462 0.43512022 0.4354049  0.43558192 0.43595192
 0.43608534 0.43656978 0.43733737 0.43865177 0.44032505 0.44274375
 0.44622046 0.4488685  0.44984975 0.44960704 0.44914845 0.44880643
 0.44863638 0.4484479  0.44830492 0.44839886 0.44862875 0.4488227
 0.44898582 0.44917086 0.4493294  0.44943962 0.44956478 0.44956377
 0.4492553  0.44920677 0.44916713 0.44918856 0.4492572  0.44941515
 0.44993046 0.4500389  0.44988024 0.44963992 0.44923308 0.448834
 0.44879562 0.44876897 0.4486136  0.4486361  0.44883418 0.44898486
 0.44905055 0.44905397 0.4490756  0.4491114  0.44921958 0.4492739
 0.4490348  0.44907844 0.44904757 0.4490125  0.44910824 0.44916323
 0.4494382  0.44932547 0.44910014 0.44900888 0.4487173  0.44832748
 0.44841564 0.4485865  0.44845068 0.44848934 0.44877827 0.44897738
 0.4489948  0.44894087 0.44897556 0.44902283 0.4489807  0.4487518
 0.44833526 0.4483144  0.4481539  0.448046   0.44824675 0.4482841
 0.44853538 0.4486592  0.44857556 0.4484514  0.44823322 0.44793755
 0.4482121  0.44844118 0.44808266 0.44821012 0.44872597 0.44863012
 0.44828677 0.44825056 0.44829288 0.4475783  0.44696966 0.44644752]
