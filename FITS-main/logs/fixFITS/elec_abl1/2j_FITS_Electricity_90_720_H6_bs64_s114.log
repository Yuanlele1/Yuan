Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=34, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_90_j720_H6', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_90_j720_H6_FITS_custom_ftM_sl90_ll48_pl720_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17603
val 1913
test 4541
Model(
  (freq_upsampler): Linear(in_features=34, out_features=306, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  427479552.0
params:  10710.0
Trainable parameters:  10710
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 1.2804630
	speed: 0.8788s/iter; left time: 11952.2089s
Epoch: 1 cost time: 120.21658515930176
Epoch: 1, Steps: 137 | Train Loss: 1.7903905 Vali Loss: 0.9227248 Test Loss: 1.0173275
Validation loss decreased (inf --> 0.922725).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6969067
	speed: 2.0904s/iter; left time: 28145.4789s
Epoch: 2 cost time: 118.6341598033905
Epoch: 2, Steps: 137 | Train Loss: 0.7906624 Vali Loss: 0.5655356 Test Loss: 0.6323795
Validation loss decreased (0.922725 --> 0.565536).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5000097
	speed: 2.0267s/iter; left time: 27009.8686s
Epoch: 3 cost time: 115.45722818374634
Epoch: 3, Steps: 137 | Train Loss: 0.5357972 Vali Loss: 0.4270205 Test Loss: 0.4811259
Validation loss decreased (0.565536 --> 0.427020).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3995587
	speed: 1.9945s/iter; left time: 26307.7496s
Epoch: 4 cost time: 114.13980174064636
Epoch: 4, Steps: 137 | Train Loss: 0.4236647 Vali Loss: 0.3557403 Test Loss: 0.4024865
Validation loss decreased (0.427020 --> 0.355740).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3551066
	speed: 2.0290s/iter; left time: 26483.9193s
Epoch: 5 cost time: 115.19282913208008
Epoch: 5, Steps: 137 | Train Loss: 0.3633093 Vali Loss: 0.3158384 Test Loss: 0.3576102
Validation loss decreased (0.355740 --> 0.315838).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3198245
	speed: 1.9415s/iter; left time: 25076.4221s
Epoch: 6 cost time: 112.22526216506958
Epoch: 6, Steps: 137 | Train Loss: 0.3280756 Vali Loss: 0.2914428 Test Loss: 0.3306215
Validation loss decreased (0.315838 --> 0.291443).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2963545
	speed: 1.9875s/iter; left time: 25397.7023s
Epoch: 7 cost time: 110.58947443962097
Epoch: 7, Steps: 137 | Train Loss: 0.3063297 Vali Loss: 0.2767811 Test Loss: 0.3136292
Validation loss decreased (0.291443 --> 0.276781).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3030957
	speed: 1.9509s/iter; left time: 24662.8683s
Epoch: 8 cost time: 110.567800283432
Epoch: 8, Steps: 137 | Train Loss: 0.2923427 Vali Loss: 0.2670522 Test Loss: 0.3024059
Validation loss decreased (0.276781 --> 0.267052).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2767700
	speed: 1.8923s/iter; left time: 23663.4980s
Epoch: 9 cost time: 107.7124514579773
Epoch: 9, Steps: 137 | Train Loss: 0.2829941 Vali Loss: 0.2602608 Test Loss: 0.2947159
Validation loss decreased (0.267052 --> 0.260261).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2833373
	speed: 1.9520s/iter; left time: 24142.2951s
Epoch: 10 cost time: 113.37565231323242
Epoch: 10, Steps: 137 | Train Loss: 0.2764079 Vali Loss: 0.2550246 Test Loss: 0.2892016
Validation loss decreased (0.260261 --> 0.255025).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2678007
	speed: 1.9301s/iter; left time: 23607.2832s
Epoch: 11 cost time: 107.5160539150238
Epoch: 11, Steps: 137 | Train Loss: 0.2715192 Vali Loss: 0.2509954 Test Loss: 0.2850757
Validation loss decreased (0.255025 --> 0.250995).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2685459
	speed: 1.8766s/iter; left time: 22695.1791s
Epoch: 12 cost time: 102.31750798225403
Epoch: 12, Steps: 137 | Train Loss: 0.2679976 Vali Loss: 0.2484825 Test Loss: 0.2819518
Validation loss decreased (0.250995 --> 0.248483).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2656971
	speed: 1.8541s/iter; left time: 22169.7779s
Epoch: 13 cost time: 110.57745504379272
Epoch: 13, Steps: 137 | Train Loss: 0.2651304 Vali Loss: 0.2460137 Test Loss: 0.2795128
Validation loss decreased (0.248483 --> 0.246014).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2690906
	speed: 1.9499s/iter; left time: 23047.7631s
Epoch: 14 cost time: 111.23648285865784
Epoch: 14, Steps: 137 | Train Loss: 0.2628961 Vali Loss: 0.2447114 Test Loss: 0.2775182
Validation loss decreased (0.246014 --> 0.244711).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2551839
	speed: 1.9609s/iter; left time: 22908.7394s
Epoch: 15 cost time: 108.77588725090027
Epoch: 15, Steps: 137 | Train Loss: 0.2611150 Vali Loss: 0.2433411 Test Loss: 0.2758998
Validation loss decreased (0.244711 --> 0.243341).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2526564
	speed: 1.7824s/iter; left time: 20579.0726s
Epoch: 16 cost time: 93.18933629989624
Epoch: 16, Steps: 137 | Train Loss: 0.2595218 Vali Loss: 0.2424281 Test Loss: 0.2745694
Validation loss decreased (0.243341 --> 0.242428).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2630750
	speed: 1.7164s/iter; left time: 19582.1632s
Epoch: 17 cost time: 97.11597728729248
Epoch: 17, Steps: 137 | Train Loss: 0.2583262 Vali Loss: 0.2412318 Test Loss: 0.2734367
Validation loss decreased (0.242428 --> 0.241232).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2463145
	speed: 1.5718s/iter; left time: 17717.6144s
Epoch: 18 cost time: 88.48583817481995
Epoch: 18, Steps: 137 | Train Loss: 0.2573419 Vali Loss: 0.2406686 Test Loss: 0.2724827
Validation loss decreased (0.241232 --> 0.240669).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2694564
	speed: 1.5532s/iter; left time: 17294.9875s
Epoch: 19 cost time: 90.77524638175964
Epoch: 19, Steps: 137 | Train Loss: 0.2564036 Vali Loss: 0.2394810 Test Loss: 0.2717106
Validation loss decreased (0.240669 --> 0.239481).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2545571
	speed: 1.5010s/iter; left time: 16508.3474s
Epoch: 20 cost time: 82.17136311531067
Epoch: 20, Steps: 137 | Train Loss: 0.2556131 Vali Loss: 0.2388652 Test Loss: 0.2709859
Validation loss decreased (0.239481 --> 0.238865).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2504409
	speed: 1.4609s/iter; left time: 15866.6355s
Epoch: 21 cost time: 81.3261981010437
Epoch: 21, Steps: 137 | Train Loss: 0.2550209 Vali Loss: 0.2384619 Test Loss: 0.2703513
Validation loss decreased (0.238865 --> 0.238462).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2505844
	speed: 1.4229s/iter; left time: 15259.3851s
Epoch: 22 cost time: 88.6564633846283
Epoch: 22, Steps: 137 | Train Loss: 0.2544257 Vali Loss: 0.2376842 Test Loss: 0.2697989
Validation loss decreased (0.238462 --> 0.237684).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2411339
	speed: 1.5362s/iter; left time: 16263.3465s
Epoch: 23 cost time: 91.10215020179749
Epoch: 23, Steps: 137 | Train Loss: 0.2539138 Vali Loss: 0.2375022 Test Loss: 0.2693390
Validation loss decreased (0.237684 --> 0.237502).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2528395
	speed: 1.5505s/iter; left time: 16202.9268s
Epoch: 24 cost time: 90.3187963962555
Epoch: 24, Steps: 137 | Train Loss: 0.2534247 Vali Loss: 0.2370320 Test Loss: 0.2689078
Validation loss decreased (0.237502 --> 0.237032).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2590628
	speed: 1.5649s/iter; left time: 16138.8953s
Epoch: 25 cost time: 86.39284992218018
Epoch: 25, Steps: 137 | Train Loss: 0.2530503 Vali Loss: 0.2369375 Test Loss: 0.2685393
Validation loss decreased (0.237032 --> 0.236937).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2456005
	speed: 1.5498s/iter; left time: 15770.7681s
Epoch: 26 cost time: 87.19055533409119
Epoch: 26, Steps: 137 | Train Loss: 0.2526918 Vali Loss: 0.2363854 Test Loss: 0.2681842
Validation loss decreased (0.236937 --> 0.236385).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2609459
	speed: 1.4567s/iter; left time: 14623.6128s
Epoch: 27 cost time: 84.15573382377625
Epoch: 27, Steps: 137 | Train Loss: 0.2523298 Vali Loss: 0.2364335 Test Loss: 0.2678589
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2618479
	speed: 1.5113s/iter; left time: 14964.3981s
Epoch: 28 cost time: 89.0402307510376
Epoch: 28, Steps: 137 | Train Loss: 0.2519705 Vali Loss: 0.2354293 Test Loss: 0.2675906
Validation loss decreased (0.236385 --> 0.235429).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2284965
	speed: 1.4912s/iter; left time: 14561.3979s
Epoch: 29 cost time: 88.87759637832642
Epoch: 29, Steps: 137 | Train Loss: 0.2517208 Vali Loss: 0.2347959 Test Loss: 0.2673241
Validation loss decreased (0.235429 --> 0.234796).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2507801
	speed: 1.5038s/iter; left time: 14478.8191s
Epoch: 30 cost time: 83.27822279930115
Epoch: 30, Steps: 137 | Train Loss: 0.2515039 Vali Loss: 0.2353312 Test Loss: 0.2671007
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2489806
	speed: 1.4665s/iter; left time: 13918.4832s
Epoch: 31 cost time: 83.85840368270874
Epoch: 31, Steps: 137 | Train Loss: 0.2512665 Vali Loss: 0.2347326 Test Loss: 0.2668759
Validation loss decreased (0.234796 --> 0.234733).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2501484
	speed: 1.5155s/iter; left time: 14175.6075s
Epoch: 32 cost time: 84.68699502944946
Epoch: 32, Steps: 137 | Train Loss: 0.2509988 Vali Loss: 0.2350182 Test Loss: 0.2666628
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2370473
	speed: 1.4435s/iter; left time: 13305.1900s
Epoch: 33 cost time: 79.86910009384155
Epoch: 33, Steps: 137 | Train Loss: 0.2508282 Vali Loss: 0.2351756 Test Loss: 0.2664806
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2424903
	speed: 1.4419s/iter; left time: 13092.9047s
Epoch: 34 cost time: 81.93693900108337
Epoch: 34, Steps: 137 | Train Loss: 0.2506686 Vali Loss: 0.2344866 Test Loss: 0.2662854
Validation loss decreased (0.234733 --> 0.234487).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2551899
	speed: 1.3805s/iter; left time: 12346.2198s
Epoch: 35 cost time: 79.79933309555054
Epoch: 35, Steps: 137 | Train Loss: 0.2504622 Vali Loss: 0.2346099 Test Loss: 0.2661303
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2562574
	speed: 1.3953s/iter; left time: 12286.5731s
Epoch: 36 cost time: 80.3572428226471
Epoch: 36, Steps: 137 | Train Loss: 0.2503060 Vali Loss: 0.2342706 Test Loss: 0.2659760
Validation loss decreased (0.234487 --> 0.234271).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2491864
	speed: 1.3369s/iter; left time: 11589.8886s
Epoch: 37 cost time: 74.60425209999084
Epoch: 37, Steps: 137 | Train Loss: 0.2501663 Vali Loss: 0.2337388 Test Loss: 0.2658245
Validation loss decreased (0.234271 --> 0.233739).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2543202
	speed: 1.3399s/iter; left time: 11432.3893s
Epoch: 38 cost time: 79.48860788345337
Epoch: 38, Steps: 137 | Train Loss: 0.2500517 Vali Loss: 0.2342609 Test Loss: 0.2656927
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2439989
	speed: 1.4140s/iter; left time: 11870.5136s
Epoch: 39 cost time: 79.80059337615967
Epoch: 39, Steps: 137 | Train Loss: 0.2499396 Vali Loss: 0.2340478 Test Loss: 0.2655593
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2605258
	speed: 1.1982s/iter; left time: 9895.0396s
Epoch: 40 cost time: 68.02940273284912
Epoch: 40, Steps: 137 | Train Loss: 0.2497317 Vali Loss: 0.2332720 Test Loss: 0.2654527
Validation loss decreased (0.233739 --> 0.233272).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2510082
	speed: 1.1183s/iter; left time: 9081.4806s
Epoch: 41 cost time: 59.86449861526489
Epoch: 41, Steps: 137 | Train Loss: 0.2496775 Vali Loss: 0.2333994 Test Loss: 0.2653352
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2495051
	speed: 1.0801s/iter; left time: 8623.6481s
Epoch: 42 cost time: 64.26912760734558
Epoch: 42, Steps: 137 | Train Loss: 0.2495024 Vali Loss: 0.2336705 Test Loss: 0.2652248
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2472346
	speed: 1.1329s/iter; left time: 8889.6748s
Epoch: 43 cost time: 64.7954306602478
Epoch: 43, Steps: 137 | Train Loss: 0.2494752 Vali Loss: 0.2334197 Test Loss: 0.2651291
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2412797
	speed: 1.0242s/iter; left time: 7896.5518s
Epoch: 44 cost time: 56.986096143722534
Epoch: 44, Steps: 137 | Train Loss: 0.2493857 Vali Loss: 0.2337180 Test Loss: 0.2650316
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2546325
	speed: 1.0222s/iter; left time: 7741.1584s
Epoch: 45 cost time: 59.102843284606934
Epoch: 45, Steps: 137 | Train Loss: 0.2492959 Vali Loss: 0.2335135 Test Loss: 0.2649367
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2542161
	speed: 1.3749s/iter; left time: 10224.0484s
Epoch: 46 cost time: 88.57576131820679
Epoch: 46, Steps: 137 | Train Loss: 0.2491019 Vali Loss: 0.2329572 Test Loss: 0.2648520
Validation loss decreased (0.233272 --> 0.232957).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2488774
	speed: 1.5679s/iter; left time: 11444.2696s
Epoch: 47 cost time: 89.9730429649353
Epoch: 47, Steps: 137 | Train Loss: 0.2491126 Vali Loss: 0.2326297 Test Loss: 0.2647761
Validation loss decreased (0.232957 --> 0.232630).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2429885
	speed: 1.5013s/iter; left time: 10751.9851s
Epoch: 48 cost time: 84.84264826774597
Epoch: 48, Steps: 137 | Train Loss: 0.2490093 Vali Loss: 0.2333270 Test Loss: 0.2646897
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2478851
	speed: 1.4992s/iter; left time: 10531.6411s
Epoch: 49 cost time: 85.1454725265503
Epoch: 49, Steps: 137 | Train Loss: 0.2489521 Vali Loss: 0.2325486 Test Loss: 0.2646152
Validation loss decreased (0.232630 --> 0.232549).  Saving model ...
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2446689
	speed: 1.4495s/iter; left time: 9984.1600s
Epoch: 50 cost time: 85.1683497428894
Epoch: 50, Steps: 137 | Train Loss: 0.2488500 Vali Loss: 0.2329355 Test Loss: 0.2645438
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2406438
	speed: 1.5099s/iter; left time: 10193.4818s
Epoch: 51 cost time: 94.81176781654358
Epoch: 51, Steps: 137 | Train Loss: 0.2488108 Vali Loss: 0.2330251 Test Loss: 0.2644875
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2532250
	speed: 1.6555s/iter; left time: 10949.3590s
Epoch: 52 cost time: 93.58280515670776
Epoch: 52, Steps: 137 | Train Loss: 0.2487375 Vali Loss: 0.2326160 Test Loss: 0.2644158
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2467898
	speed: 1.5844s/iter; left time: 10261.9806s
Epoch: 53 cost time: 91.16757082939148
Epoch: 53, Steps: 137 | Train Loss: 0.2485945 Vali Loss: 0.2323217 Test Loss: 0.2643675
Validation loss decreased (0.232549 --> 0.232322).  Saving model ...
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2435050
	speed: 1.5957s/iter; left time: 10116.9149s
Epoch: 54 cost time: 86.9767861366272
Epoch: 54, Steps: 137 | Train Loss: 0.2485766 Vali Loss: 0.2326234 Test Loss: 0.2643212
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2474872
	speed: 1.6086s/iter; left time: 9978.1583s
Epoch: 55 cost time: 90.49572968482971
Epoch: 55, Steps: 137 | Train Loss: 0.2485142 Vali Loss: 0.2325110 Test Loss: 0.2642626
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2582202
	speed: 1.5422s/iter; left time: 9355.0671s
Epoch: 56 cost time: 80.06598234176636
Epoch: 56, Steps: 137 | Train Loss: 0.2484689 Vali Loss: 0.2325304 Test Loss: 0.2642179
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2534014
	speed: 1.4323s/iter; left time: 8492.3780s
Epoch: 57 cost time: 81.29622459411621
Epoch: 57, Steps: 137 | Train Loss: 0.2484705 Vali Loss: 0.2325968 Test Loss: 0.2641712
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2399499
	speed: 1.4241s/iter; left time: 8248.2774s
Epoch: 58 cost time: 81.30811977386475
Epoch: 58, Steps: 137 | Train Loss: 0.2484427 Vali Loss: 0.2324272 Test Loss: 0.2641247
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2524970
	speed: 1.4303s/iter; left time: 8088.1643s
Epoch: 59 cost time: 82.01937294006348
Epoch: 59, Steps: 137 | Train Loss: 0.2483559 Vali Loss: 0.2322582 Test Loss: 0.2640876
Validation loss decreased (0.232322 --> 0.232258).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.2590938
	speed: 1.7065s/iter; left time: 9416.6419s
Epoch: 60 cost time: 97.79144787788391
Epoch: 60, Steps: 137 | Train Loss: 0.2483193 Vali Loss: 0.2323758 Test Loss: 0.2640424
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.2485675
	speed: 1.6401s/iter; left time: 8825.4294s
Epoch: 61 cost time: 93.28644919395447
Epoch: 61, Steps: 137 | Train Loss: 0.2482648 Vali Loss: 0.2326991 Test Loss: 0.2640065
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.2375357
	speed: 1.5465s/iter; left time: 8109.7230s
Epoch: 62 cost time: 88.11869025230408
Epoch: 62, Steps: 137 | Train Loss: 0.2482464 Vali Loss: 0.2321606 Test Loss: 0.2639717
Validation loss decreased (0.232258 --> 0.232161).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.2597408
	speed: 1.6463s/iter; left time: 8407.5040s
Epoch: 63 cost time: 94.89417958259583
Epoch: 63, Steps: 137 | Train Loss: 0.2482808 Vali Loss: 0.2324445 Test Loss: 0.2639395
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.2457570
	speed: 1.6826s/iter; left time: 8362.6760s
Epoch: 64 cost time: 95.35116767883301
Epoch: 64, Steps: 137 | Train Loss: 0.2481159 Vali Loss: 0.2320573 Test Loss: 0.2639138
Validation loss decreased (0.232161 --> 0.232057).  Saving model ...
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.2537023
	speed: 1.4406s/iter; left time: 6962.3575s
Epoch: 65 cost time: 74.1386182308197
Epoch: 65, Steps: 137 | Train Loss: 0.2481223 Vali Loss: 0.2325744 Test Loss: 0.2638841
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.2546225
	speed: 1.3113s/iter; left time: 6157.8199s
Epoch: 66 cost time: 74.32271194458008
Epoch: 66, Steps: 137 | Train Loss: 0.2481563 Vali Loss: 0.2325896 Test Loss: 0.2638583
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.2511106
	speed: 1.3091s/iter; left time: 5968.0245s
Epoch: 67 cost time: 71.42551040649414
Epoch: 67, Steps: 137 | Train Loss: 0.2480662 Vali Loss: 0.2322830 Test Loss: 0.2638344
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.2468894
	speed: 1.3159s/iter; left time: 5819.0305s
Epoch: 68 cost time: 75.43332099914551
Epoch: 68, Steps: 137 | Train Loss: 0.2480724 Vali Loss: 0.2326765 Test Loss: 0.2638051
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.2558233
	speed: 1.3321s/iter; left time: 5708.0549s
Epoch: 69 cost time: 76.72986674308777
Epoch: 69, Steps: 137 | Train Loss: 0.2481149 Vali Loss: 0.2323775 Test Loss: 0.2637855
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.2490989
	speed: 1.2820s/iter; left time: 5317.9050s
Epoch: 70 cost time: 71.31783652305603
Epoch: 70, Steps: 137 | Train Loss: 0.2480542 Vali Loss: 0.2319637 Test Loss: 0.2637695
Validation loss decreased (0.232057 --> 0.231964).  Saving model ...
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.2503914
	speed: 1.3126s/iter; left time: 5264.7644s
Epoch: 71 cost time: 77.01237368583679
Epoch: 71, Steps: 137 | Train Loss: 0.2480308 Vali Loss: 0.2322014 Test Loss: 0.2637508
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.2421587
	speed: 1.3679s/iter; left time: 5299.1822s
Epoch: 72 cost time: 76.93664050102234
Epoch: 72, Steps: 137 | Train Loss: 0.2479759 Vali Loss: 0.2320500 Test Loss: 0.2637312
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.2384502
	speed: 1.3087s/iter; left time: 4890.5211s
Epoch: 73 cost time: 73.9028811454773
Epoch: 73, Steps: 137 | Train Loss: 0.2480048 Vali Loss: 0.2322872 Test Loss: 0.2637130
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.2537921
	speed: 1.3401s/iter; left time: 4824.5305s
Epoch: 74 cost time: 76.6778016090393
Epoch: 74, Steps: 137 | Train Loss: 0.2479671 Vali Loss: 0.2323377 Test Loss: 0.2636980
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.2517994
	speed: 1.3189s/iter; left time: 4567.3084s
Epoch: 75 cost time: 78.6926782131195
Epoch: 75, Steps: 137 | Train Loss: 0.2480315 Vali Loss: 0.2322468 Test Loss: 0.2636825
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.2407748
	speed: 1.3657s/iter; left time: 4542.4650s
Epoch: 76 cost time: 78.73812055587769
Epoch: 76, Steps: 137 | Train Loss: 0.2479556 Vali Loss: 0.2318366 Test Loss: 0.2636663
Validation loss decreased (0.231964 --> 0.231837).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.2502792
	speed: 1.3727s/iter; left time: 4377.5456s
Epoch: 77 cost time: 76.44806861877441
Epoch: 77, Steps: 137 | Train Loss: 0.2478813 Vali Loss: 0.2324456 Test Loss: 0.2636515
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.2584153
	speed: 1.3593s/iter; left time: 4148.4602s
Epoch: 78 cost time: 79.5235390663147
Epoch: 78, Steps: 137 | Train Loss: 0.2478386 Vali Loss: 0.2320902 Test Loss: 0.2636399
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.2509403
	speed: 1.3935s/iter; left time: 4062.0454s
Epoch: 79 cost time: 77.94808626174927
Epoch: 79, Steps: 137 | Train Loss: 0.2477955 Vali Loss: 0.2319274 Test Loss: 0.2636287
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.2504004
	speed: 1.1891s/iter; left time: 3303.2643s
Epoch: 80 cost time: 64.44994282722473
Epoch: 80, Steps: 137 | Train Loss: 0.2478587 Vali Loss: 0.2324740 Test Loss: 0.2636155
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.2417168
	speed: 1.0517s/iter; left time: 2777.5327s
Epoch: 81 cost time: 60.59204602241516
Epoch: 81, Steps: 137 | Train Loss: 0.2479416 Vali Loss: 0.2322720 Test Loss: 0.2636065
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.2399107
	speed: 1.0438s/iter; left time: 2613.5689s
Epoch: 82 cost time: 60.504568338394165
Epoch: 82, Steps: 137 | Train Loss: 0.2477929 Vali Loss: 0.2321083 Test Loss: 0.2635974
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.2441282
	speed: 1.0148s/iter; left time: 2402.0527s
Epoch: 83 cost time: 58.212674140930176
Epoch: 83, Steps: 137 | Train Loss: 0.2478509 Vali Loss: 0.2318243 Test Loss: 0.2635874
Validation loss decreased (0.231837 --> 0.231824).  Saving model ...
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.2539999
	speed: 0.9472s/iter; left time: 2112.3212s
Epoch: 84 cost time: 45.93366885185242
Epoch: 84, Steps: 137 | Train Loss: 0.2477531 Vali Loss: 0.2321198 Test Loss: 0.2635800
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.2617033
	speed: 0.7469s/iter; left time: 1563.2763s
Epoch: 85 cost time: 42.751300573349
Epoch: 85, Steps: 137 | Train Loss: 0.2477437 Vali Loss: 0.2317218 Test Loss: 0.2635716
Validation loss decreased (0.231824 --> 0.231722).  Saving model ...
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.2596393
	speed: 0.7569s/iter; left time: 1480.4403s
Epoch: 86 cost time: 42.56836795806885
Epoch: 86, Steps: 137 | Train Loss: 0.2477146 Vali Loss: 0.2319005 Test Loss: 0.2635653
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.2379131
	speed: 0.7552s/iter; left time: 1373.6956s
Epoch: 87 cost time: 42.663766860961914
Epoch: 87, Steps: 137 | Train Loss: 0.2478443 Vali Loss: 0.2317880 Test Loss: 0.2635585
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.2472952
	speed: 0.7654s/iter; left time: 1287.3795s
Epoch: 88 cost time: 44.335103273391724
Epoch: 88, Steps: 137 | Train Loss: 0.2477418 Vali Loss: 0.2322883 Test Loss: 0.2635503
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.2551957
	speed: 0.7603s/iter; left time: 1174.7177s
Epoch: 89 cost time: 43.78601670265198
Epoch: 89, Steps: 137 | Train Loss: 0.2477761 Vali Loss: 0.2321755 Test Loss: 0.2635463
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.2489632
	speed: 0.7625s/iter; left time: 1073.5565s
Epoch: 90 cost time: 42.535815477371216
Epoch: 90, Steps: 137 | Train Loss: 0.2477676 Vali Loss: 0.2316609 Test Loss: 0.2635384
Validation loss decreased (0.231722 --> 0.231661).  Saving model ...
Updating learning rate to 5.204402478767869e-06
	iters: 100, epoch: 91 | loss: 0.2494995
	speed: 0.7565s/iter; left time: 961.4711s
Epoch: 91 cost time: 42.44951057434082
Epoch: 91, Steps: 137 | Train Loss: 0.2476825 Vali Loss: 0.2316963 Test Loss: 0.2635349
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.944182354829475e-06
	iters: 100, epoch: 92 | loss: 0.2518699
	speed: 0.7617s/iter; left time: 863.7415s
Epoch: 92 cost time: 44.06578040122986
Epoch: 92, Steps: 137 | Train Loss: 0.2476794 Vali Loss: 0.2317767 Test Loss: 0.2635285
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.696973237088e-06
	iters: 100, epoch: 93 | loss: 0.2458522
	speed: 0.7701s/iter; left time: 767.8070s
Epoch: 93 cost time: 44.26032495498657
Epoch: 93, Steps: 137 | Train Loss: 0.2477377 Vali Loss: 0.2320914 Test Loss: 0.2635223
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.462124575233601e-06
	iters: 100, epoch: 94 | loss: 0.2373838
	speed: 0.7516s/iter; left time: 646.3506s
Epoch: 94 cost time: 43.04163336753845
Epoch: 94, Steps: 137 | Train Loss: 0.2478165 Vali Loss: 0.2315457 Test Loss: 0.2635183
Validation loss decreased (0.231661 --> 0.231546).  Saving model ...
Updating learning rate to 4.239018346471921e-06
	iters: 100, epoch: 95 | loss: 0.2394025
	speed: 0.7649s/iter; left time: 553.0008s
Epoch: 95 cost time: 43.234739780426025
Epoch: 95, Steps: 137 | Train Loss: 0.2477703 Vali Loss: 0.2321953 Test Loss: 0.2635132
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.027067429148324e-06
	iters: 100, epoch: 96 | loss: 0.2628045
	speed: 0.7681s/iter; left time: 450.0982s
Epoch: 96 cost time: 43.396050214767456
Epoch: 96, Steps: 137 | Train Loss: 0.2476855 Vali Loss: 0.2318200 Test Loss: 0.2635092
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.825714057690908e-06
	iters: 100, epoch: 97 | loss: 0.2488882
	speed: 0.7565s/iter; left time: 339.6760s
Epoch: 97 cost time: 43.612178564071655
Epoch: 97, Steps: 137 | Train Loss: 0.2477265 Vali Loss: 0.2321145 Test Loss: 0.2635052
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.6344283548063623e-06
	iters: 100, epoch: 98 | loss: 0.2485274
	speed: 0.7509s/iter; left time: 234.2827s
Epoch: 98 cost time: 42.74971103668213
Epoch: 98, Steps: 137 | Train Loss: 0.2477260 Vali Loss: 0.2317720 Test Loss: 0.2635010
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.452706937066044e-06
	iters: 100, epoch: 99 | loss: 0.2440859
	speed: 0.7719s/iter; left time: 135.0803s
Epoch: 99 cost time: 44.06137275695801
Epoch: 99, Steps: 137 | Train Loss: 0.2477421 Vali Loss: 0.2315333 Test Loss: 0.2634974
Validation loss decreased (0.231546 --> 0.231533).  Saving model ...
Updating learning rate to 3.2800715902127414e-06
	iters: 100, epoch: 100 | loss: 0.2461672
	speed: 0.7713s/iter; left time: 29.3102s
Epoch: 100 cost time: 43.37333035469055
Epoch: 100, Steps: 137 | Train Loss: 0.2476875 Vali Loss: 0.2322873 Test Loss: 0.2634947
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1160680107021042e-06
train 17603
val 1913
test 4541
Model(
  (freq_upsampler): Linear(in_features=34, out_features=306, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  427479552.0
params:  10710.0
Trainable parameters:  10710
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2718097
	speed: 0.3145s/iter; left time: 4277.0808s
Epoch: 1 cost time: 42.76005291938782
Epoch: 1, Steps: 137 | Train Loss: 0.2766732 Vali Loss: 0.2315151 Test Loss: 0.2628470
Validation loss decreased (inf --> 0.231515).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2680045
	speed: 0.7616s/iter; left time: 10254.3621s
Epoch: 2 cost time: 44.10381865501404
Epoch: 2, Steps: 137 | Train Loss: 0.2763984 Vali Loss: 0.2312546 Test Loss: 0.2627822
Validation loss decreased (0.231515 --> 0.231255).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2656315
	speed: 0.7648s/iter; left time: 10191.9348s
Epoch: 3 cost time: 42.40187406539917
Epoch: 3, Steps: 137 | Train Loss: 0.2763488 Vali Loss: 0.2308092 Test Loss: 0.2626318
Validation loss decreased (0.231255 --> 0.230809).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2718253
	speed: 0.7482s/iter; left time: 9869.2093s
Epoch: 4 cost time: 42.54861307144165
Epoch: 4, Steps: 137 | Train Loss: 0.2762602 Vali Loss: 0.2312260 Test Loss: 0.2626847
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2816478
	speed: 0.7587s/iter; left time: 9903.6557s
Epoch: 5 cost time: 44.57408380508423
Epoch: 5, Steps: 137 | Train Loss: 0.2762601 Vali Loss: 0.2308907 Test Loss: 0.2626201
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2868988
	speed: 0.7647s/iter; left time: 9876.5031s
Epoch: 6 cost time: 43.57115912437439
Epoch: 6, Steps: 137 | Train Loss: 0.2761587 Vali Loss: 0.2308778 Test Loss: 0.2626501
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2723375
	speed: 0.7709s/iter; left time: 9851.4434s
Epoch: 7 cost time: 42.442275285720825
Epoch: 7, Steps: 137 | Train Loss: 0.2761902 Vali Loss: 0.2311194 Test Loss: 0.2626530
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2806817
	speed: 0.7537s/iter; left time: 9528.3016s
Epoch: 8 cost time: 42.62760663032532
Epoch: 8, Steps: 137 | Train Loss: 0.2762140 Vali Loss: 0.2313761 Test Loss: 0.2626359
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2919235
	speed: 0.7555s/iter; left time: 9447.2682s
Epoch: 9 cost time: 43.532795667648315
Epoch: 9, Steps: 137 | Train Loss: 0.2762011 Vali Loss: 0.2308850 Test Loss: 0.2626248
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2621490
	speed: 0.7570s/iter; left time: 9362.4289s
Epoch: 10 cost time: 42.66921949386597
Epoch: 10, Steps: 137 | Train Loss: 0.2761741 Vali Loss: 0.2308595 Test Loss: 0.2626623
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2769330
	speed: 0.7531s/iter; left time: 9210.8614s
Epoch: 11 cost time: 42.55027747154236
Epoch: 11, Steps: 137 | Train Loss: 0.2761952 Vali Loss: 0.2307043 Test Loss: 0.2626489
Validation loss decreased (0.230809 --> 0.230704).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2768770
	speed: 0.7637s/iter; left time: 9236.6559s
Epoch: 12 cost time: 43.38083243370056
Epoch: 12, Steps: 137 | Train Loss: 0.2761732 Vali Loss: 0.2312578 Test Loss: 0.2626374
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2713692
	speed: 0.7716s/iter; left time: 9226.6115s
Epoch: 13 cost time: 44.785499572753906
Epoch: 13, Steps: 137 | Train Loss: 0.2761836 Vali Loss: 0.2311169 Test Loss: 0.2626288
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2844216
	speed: 0.7657s/iter; left time: 9050.2541s
Epoch: 14 cost time: 42.827415227890015
Epoch: 14, Steps: 137 | Train Loss: 0.2761408 Vali Loss: 0.2309721 Test Loss: 0.2625700
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2627775
	speed: 0.7725s/iter; left time: 9024.6275s
Epoch: 15 cost time: 44.236122131347656
Epoch: 15, Steps: 137 | Train Loss: 0.2760789 Vali Loss: 0.2307124 Test Loss: 0.2626616
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2765100
	speed: 0.7428s/iter; left time: 8576.3224s
Epoch: 16 cost time: 41.0568790435791
Epoch: 16, Steps: 137 | Train Loss: 0.2761127 Vali Loss: 0.2306863 Test Loss: 0.2625864
Validation loss decreased (0.230704 --> 0.230686).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2773297
	speed: 0.7149s/iter; left time: 8155.9883s
Epoch: 17 cost time: 41.163814067840576
Epoch: 17, Steps: 137 | Train Loss: 0.2760375 Vali Loss: 0.2311730 Test Loss: 0.2625976
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2660829
	speed: 0.7259s/iter; left time: 8182.1044s
Epoch: 18 cost time: 40.9544951915741
Epoch: 18, Steps: 137 | Train Loss: 0.2760891 Vali Loss: 0.2310989 Test Loss: 0.2626283
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2805600
	speed: 0.6895s/iter; left time: 7678.0707s
Epoch: 19 cost time: 37.876604318618774
Epoch: 19, Steps: 137 | Train Loss: 0.2759617 Vali Loss: 0.2307942 Test Loss: 0.2626274
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2725051
	speed: 0.6871s/iter; left time: 7557.0738s
Epoch: 20 cost time: 39.48248076438904
Epoch: 20, Steps: 137 | Train Loss: 0.2760538 Vali Loss: 0.2311230 Test Loss: 0.2625953
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2731655
	speed: 0.6742s/iter; left time: 7322.4669s
Epoch: 21 cost time: 38.02087593078613
Epoch: 21, Steps: 137 | Train Loss: 0.2760753 Vali Loss: 0.2303550 Test Loss: 0.2626512
Validation loss decreased (0.230686 --> 0.230355).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2714588
	speed: 0.6783s/iter; left time: 7273.8199s
Epoch: 22 cost time: 38.49297475814819
Epoch: 22, Steps: 137 | Train Loss: 0.2760782 Vali Loss: 0.2305834 Test Loss: 0.2626079
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2740228
	speed: 0.6851s/iter; left time: 7252.9104s
Epoch: 23 cost time: 39.70465803146362
Epoch: 23, Steps: 137 | Train Loss: 0.2761295 Vali Loss: 0.2310863 Test Loss: 0.2626112
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2811873
	speed: 0.6983s/iter; left time: 7297.7189s
Epoch: 24 cost time: 38.195114612579346
Epoch: 24, Steps: 137 | Train Loss: 0.2760148 Vali Loss: 0.2309925 Test Loss: 0.2626010
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2727466
	speed: 0.6845s/iter; left time: 7058.8924s
Epoch: 25 cost time: 39.080795764923096
Epoch: 25, Steps: 137 | Train Loss: 0.2761512 Vali Loss: 0.2307723 Test Loss: 0.2626299
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2767192
	speed: 0.6961s/iter; left time: 7083.6179s
Epoch: 26 cost time: 40.162899017333984
Epoch: 26, Steps: 137 | Train Loss: 0.2761456 Vali Loss: 0.2304650 Test Loss: 0.2626502
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2770278
	speed: 0.6904s/iter; left time: 6930.5457s
Epoch: 27 cost time: 38.72324323654175
Epoch: 27, Steps: 137 | Train Loss: 0.2760631 Vali Loss: 0.2310762 Test Loss: 0.2625965
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2843078
	speed: 0.6767s/iter; left time: 6700.4291s
Epoch: 28 cost time: 38.176056146621704
Epoch: 28, Steps: 137 | Train Loss: 0.2759975 Vali Loss: 0.2305750 Test Loss: 0.2626099
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2916154
	speed: 0.6842s/iter; left time: 6681.4787s
Epoch: 29 cost time: 39.31035494804382
Epoch: 29, Steps: 137 | Train Loss: 0.2760463 Vali Loss: 0.2310443 Test Loss: 0.2626072
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2671524
	speed: 0.6861s/iter; left time: 6605.3417s
Epoch: 30 cost time: 38.812992334365845
Epoch: 30, Steps: 137 | Train Loss: 0.2761508 Vali Loss: 0.2306237 Test Loss: 0.2626274
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2768798
	speed: 0.6893s/iter; left time: 6542.5561s
Epoch: 31 cost time: 39.72565054893494
Epoch: 31, Steps: 137 | Train Loss: 0.2760483 Vali Loss: 0.2304836 Test Loss: 0.2625817
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2727615
	speed: 0.6916s/iter; left time: 6469.5273s
Epoch: 32 cost time: 38.9495735168457
Epoch: 32, Steps: 137 | Train Loss: 0.2761043 Vali Loss: 0.2310785 Test Loss: 0.2626137
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2858279
	speed: 0.6730s/iter; left time: 6203.4447s
Epoch: 33 cost time: 38.072389125823975
Epoch: 33, Steps: 137 | Train Loss: 0.2760942 Vali Loss: 0.2303976 Test Loss: 0.2626044
EarlyStopping counter: 12 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2787132
	speed: 0.6731s/iter; left time: 6112.1110s
Epoch: 34 cost time: 38.35668921470642
Epoch: 34, Steps: 137 | Train Loss: 0.2761114 Vali Loss: 0.2307602 Test Loss: 0.2626037
EarlyStopping counter: 13 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2680723
	speed: 0.6768s/iter; left time: 6052.4357s
Epoch: 35 cost time: 38.61649298667908
Epoch: 35, Steps: 137 | Train Loss: 0.2760751 Vali Loss: 0.2303441 Test Loss: 0.2626115
Validation loss decreased (0.230355 --> 0.230344).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2696183
	speed: 0.6849s/iter; left time: 6031.4150s
Epoch: 36 cost time: 39.031466245651245
Epoch: 36, Steps: 137 | Train Loss: 0.2760454 Vali Loss: 0.2306737 Test Loss: 0.2625799
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2714158
	speed: 0.6737s/iter; left time: 5840.5147s
Epoch: 37 cost time: 38.41914415359497
Epoch: 37, Steps: 137 | Train Loss: 0.2759998 Vali Loss: 0.2305184 Test Loss: 0.2626082
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2836441
	speed: 0.6846s/iter; left time: 5840.9478s
Epoch: 38 cost time: 40.182393074035645
Epoch: 38, Steps: 137 | Train Loss: 0.2760608 Vali Loss: 0.2308842 Test Loss: 0.2626048
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2794428
	speed: 0.6864s/iter; left time: 5762.2062s
Epoch: 39 cost time: 38.329692363739014
Epoch: 39, Steps: 137 | Train Loss: 0.2760189 Vali Loss: 0.2305620 Test Loss: 0.2626154
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2852349
	speed: 0.6685s/iter; left time: 5520.1764s
Epoch: 40 cost time: 37.23959946632385
Epoch: 40, Steps: 137 | Train Loss: 0.2761093 Vali Loss: 0.2304674 Test Loss: 0.2625972
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2662122
	speed: 0.6472s/iter; left time: 5255.6689s
Epoch: 41 cost time: 36.99001908302307
Epoch: 41, Steps: 137 | Train Loss: 0.2760317 Vali Loss: 0.2304911 Test Loss: 0.2625872
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2920872
	speed: 0.6701s/iter; left time: 5349.7968s
Epoch: 42 cost time: 38.215447425842285
Epoch: 42, Steps: 137 | Train Loss: 0.2760212 Vali Loss: 0.2310420 Test Loss: 0.2625965
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2924677
	speed: 0.6835s/iter; left time: 5363.5076s
Epoch: 43 cost time: 37.96476125717163
Epoch: 43, Steps: 137 | Train Loss: 0.2759356 Vali Loss: 0.2306902 Test Loss: 0.2626042
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2881364
	speed: 0.6921s/iter; left time: 5335.8906s
Epoch: 44 cost time: 39.29309272766113
Epoch: 44, Steps: 137 | Train Loss: 0.2761169 Vali Loss: 0.2304460 Test Loss: 0.2625827
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2832732
	speed: 0.6931s/iter; left time: 5249.0733s
Epoch: 45 cost time: 39.16259479522705
Epoch: 45, Steps: 137 | Train Loss: 0.2760009 Vali Loss: 0.2309362 Test Loss: 0.2625909
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2760663
	speed: 0.6972s/iter; left time: 5184.5210s
Epoch: 46 cost time: 39.23035287857056
Epoch: 46, Steps: 137 | Train Loss: 0.2760712 Vali Loss: 0.2309107 Test Loss: 0.2626020
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2736433
	speed: 0.6814s/iter; left time: 4973.2108s
Epoch: 47 cost time: 39.74211859703064
Epoch: 47, Steps: 137 | Train Loss: 0.2760736 Vali Loss: 0.2304800 Test Loss: 0.2626027
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2744377
	speed: 0.7132s/iter; left time: 5107.6647s
Epoch: 48 cost time: 40.68093776702881
Epoch: 48, Steps: 137 | Train Loss: 0.2759669 Vali Loss: 0.2306784 Test Loss: 0.2625983
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2926006
	speed: 0.6948s/iter; left time: 4881.0140s
Epoch: 49 cost time: 39.14540934562683
Epoch: 49, Steps: 137 | Train Loss: 0.2760343 Vali Loss: 0.2309304 Test Loss: 0.2625896
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2712133
	speed: 0.6901s/iter; left time: 4753.5329s
Epoch: 50 cost time: 39.84050512313843
Epoch: 50, Steps: 137 | Train Loss: 0.2760353 Vali Loss: 0.2309587 Test Loss: 0.2626086
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2717038
	speed: 0.7059s/iter; left time: 4765.4049s
Epoch: 51 cost time: 38.99909424781799
Epoch: 51, Steps: 137 | Train Loss: 0.2760667 Vali Loss: 0.2308853 Test Loss: 0.2626077
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2805200
	speed: 0.6920s/iter; left time: 4577.0692s
Epoch: 52 cost time: 38.90117168426514
Epoch: 52, Steps: 137 | Train Loss: 0.2759665 Vali Loss: 0.2306038 Test Loss: 0.2626043
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2882085
	speed: 0.6918s/iter; left time: 4480.6117s
Epoch: 53 cost time: 39.2378351688385
Epoch: 53, Steps: 137 | Train Loss: 0.2760091 Vali Loss: 0.2303767 Test Loss: 0.2625953
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2690310
	speed: 0.7028s/iter; left time: 4455.7282s
Epoch: 54 cost time: 40.771764039993286
Epoch: 54, Steps: 137 | Train Loss: 0.2760083 Vali Loss: 0.2305290 Test Loss: 0.2625925
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2745419
	speed: 0.7363s/iter; left time: 4567.1993s
Epoch: 55 cost time: 42.19899368286133
Epoch: 55, Steps: 137 | Train Loss: 0.2760434 Vali Loss: 0.2306553 Test Loss: 0.2625989
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_90_j720_H6_FITS_custom_ftM_sl90_ll48_pl720_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
mse:0.2612851560115814, mae:0.3321111798286438, rse:0.5098996758460999, corr:[0.4415901  0.44199616 0.44082472 0.4396966  0.43844584 0.43766573
 0.43740976 0.43668875 0.43573564 0.43491775 0.4341345  0.4336663
 0.43340212 0.43278342 0.43286517 0.4323031  0.43231425 0.43252802
 0.43251112 0.4326223  0.43239868 0.4324607  0.4322383  0.431012
 0.4290818  0.42776805 0.42663336 0.42573774 0.42529407 0.42542723
 0.42631182 0.42665783 0.4262472  0.42595634 0.4255989  0.42523065
 0.42519316 0.424845   0.42486212 0.42442313 0.42430082 0.4244632
 0.42436877 0.42440626 0.42445722 0.4247969  0.42481455 0.42440012
 0.42352644 0.42318407 0.42308226 0.4232975  0.42414054 0.42562133
 0.42769897 0.42912638 0.42927244 0.4292878  0.42913234 0.42887798
 0.42883322 0.42849857 0.4286757  0.42864403 0.42873108 0.42896044
 0.42914534 0.42940894 0.4296912  0.43024158 0.43063408 0.43098098
 0.43119633 0.43173584 0.43243194 0.4335296  0.43527442 0.43781757
 0.44088206 0.44328675 0.4435777  0.44331872 0.44299307 0.4425367
 0.44238213 0.44205564 0.44227287 0.44222912 0.4423957  0.442751
 0.4428076  0.44286713 0.4429587  0.443126   0.4432894  0.44330728
 0.44309622 0.44312212 0.442952   0.44294786 0.4430228  0.44310364
 0.44344825 0.4435407  0.44311905 0.44278997 0.44244772 0.4421045
 0.44206244 0.44175816 0.441994   0.44200626 0.442138   0.44242552
 0.44243965 0.44249746 0.44252375 0.44262537 0.44282126 0.44291067
 0.44266757 0.4427468  0.44268766 0.44265708 0.44262168 0.44257513
 0.4427954  0.4427371  0.4423424  0.44209707 0.44176716 0.4414717
 0.4415514  0.44134322 0.44159442 0.44163272 0.44182622 0.4421522
 0.4422553  0.4425228  0.4427119  0.44283527 0.4429323  0.44288766
 0.44255236 0.44245604 0.4423339  0.44229856 0.44232824 0.44230428
 0.44251308 0.44254023 0.44208091 0.44178417 0.44140947 0.44105208
 0.44120544 0.44111702 0.44141224 0.44150802 0.44174877 0.44209135
 0.44232306 0.44253677 0.44229424 0.44210237 0.4414214  0.43903804
 0.43620363 0.43400547 0.43234608 0.4308723  0.42978266 0.4292539
 0.42912632 0.4288024  0.42823622 0.4277858  0.42747298 0.42717308
 0.42715868 0.42685747 0.42688563 0.42645133 0.4264581  0.42672378
 0.426493   0.4263174  0.4260178  0.4259143  0.42539698 0.42372572
 0.4216095  0.42022502 0.41909906 0.4182019  0.41785157 0.4182515
 0.4191959  0.41972378 0.41953817 0.41930068 0.41910857 0.41886452
 0.41905677 0.4188372  0.41885623 0.41851297 0.418418   0.4185591
 0.41842654 0.41840315 0.4183082  0.41849345 0.41848648 0.4179404
 0.41698286 0.41655195 0.41658482 0.41688377 0.41773856 0.41936836
 0.421467   0.42309994 0.42340395 0.42346826 0.423493   0.42323834
 0.42320693 0.4229709  0.42316198 0.4231218  0.4231711  0.4233835
 0.42359006 0.4237899  0.42391726 0.42446125 0.4249456  0.42522854
 0.4253769  0.42590746 0.4265861  0.42762387 0.42943332 0.43201712
 0.43511996 0.43765423 0.4379936  0.43775073 0.43756184 0.43720248
 0.43711245 0.43677917 0.4369297  0.43682522 0.43703926 0.43739146
 0.43738666 0.43748915 0.4375854  0.43776435 0.4379766  0.43796012
 0.43770498 0.43771014 0.4376232  0.43763393 0.4376872  0.43778405
 0.43819776 0.4383389  0.4378626  0.43760192 0.43736243 0.43700412
 0.43693337 0.43659768 0.43682322 0.43676478 0.43687755 0.43716276
 0.43711132 0.43716484 0.43727645 0.43739504 0.43753463 0.4376323
 0.437477   0.4374912  0.4373519  0.43728364 0.43732092 0.43733966
 0.43765512 0.4376137  0.4371251  0.43702438 0.4367961  0.43647647
 0.43657756 0.43632638 0.43655336 0.436632   0.43674633 0.4369897
 0.43711773 0.43732578 0.43748155 0.4376829  0.43777457 0.43765512
 0.437336   0.43723392 0.43712002 0.43705812 0.43711716 0.43708575
 0.43734008 0.43736026 0.43683314 0.43668246 0.43640122 0.4359859
 0.43610796 0.4359484  0.4361931  0.43625194 0.4364808  0.43686983
 0.43710086 0.4371841  0.43681842 0.4365874  0.43570903 0.43309608
 0.43027195 0.4280621  0.4263122  0.42489776 0.4238418  0.42319807
 0.42310476 0.42292    0.4223634  0.4218599  0.42147505 0.4211303
 0.42109984 0.42074168 0.42074543 0.42039967 0.42031562 0.4204497
 0.42040443 0.42031196 0.4198512  0.41972747 0.41920608 0.41739368
 0.41513434 0.41363135 0.41251072 0.41165465 0.41133177 0.4117093
 0.41266224 0.413175   0.4128877  0.41264275 0.4124661  0.4121673
 0.4123334  0.41217914 0.4122157  0.41188738 0.41176513 0.411929
 0.4118598  0.41184333 0.41170874 0.41193324 0.411917   0.41126359
 0.4102639  0.40985492 0.40995276 0.41039184 0.41147417 0.41322476
 0.4153916  0.4170704  0.4173937  0.41750923 0.41749385 0.41715732
 0.41715512 0.41694817 0.41708687 0.41703618 0.41712642 0.41738817
 0.4175519  0.4177998  0.4180561  0.41862288 0.41900793 0.41925368
 0.4194879  0.4200555  0.42088133 0.42215237 0.4241307  0.42693332
 0.43021992 0.43276018 0.43318236 0.43301243 0.4329138  0.43257773
 0.43247557 0.4321536  0.4323009  0.4322412  0.4324063  0.4327311
 0.43279964 0.43296868 0.43307352 0.43322128 0.4334464  0.43340886
 0.43315852 0.43321323 0.4331672  0.43315062 0.4332522  0.43347606
 0.43396    0.4340697  0.43363905 0.43342632 0.43314892 0.43279043
 0.43273893 0.43243518 0.43262658 0.43260416 0.4326539  0.4329446
 0.43299216 0.43302554 0.4330654  0.4332322  0.433483   0.43354496
 0.43332317 0.43339175 0.4333868  0.43337685 0.43342283 0.43340304
 0.43361163 0.4335612  0.43316576 0.43301255 0.43269664 0.4323875
 0.43249243 0.4322675  0.4324901  0.432548   0.43268907 0.4330285
 0.43315208 0.4334022  0.43367034 0.43391016 0.4340364  0.43388888
 0.4335252  0.43344915 0.43337086 0.4332995  0.4333698  0.4334103
 0.43365818 0.43366686 0.43320292 0.43300164 0.43270484 0.43236297
 0.43247023 0.43230888 0.43252712 0.4326295  0.4329219  0.43327856
 0.43342257 0.43354252 0.43330193 0.43306637 0.4322709  0.42977893
 0.42688873 0.42460418 0.42285898 0.42139396 0.4162806  0.4157962
 0.41556343 0.41525444 0.41479725 0.4142777  0.418074   0.41784826
 0.4178077  0.41739222 0.41737166 0.4170734  0.41693625 0.41294324
 0.41279808 0.41258198 0.41225067 0.41210613 0.41153803 0.40969402
 0.40730754 0.40572947 0.4046479  0.40375906 0.40341642 0.40383828
 0.40474105 0.40514693 0.40484244 0.4045096  0.4043196  0.40410078
 0.40421408 0.40402117 0.40412226 0.4038416  0.4036822  0.40394908
 0.40389335 0.4037834  0.40374228 0.40401027 0.40399295 0.4033218
 0.40230805 0.4018213  0.40184858 0.40229887 0.40341222 0.40504417
 0.40709913 0.40877688 0.40906918 0.40895766 0.40893337 0.4086563
 0.40850234 0.4081931  0.40830028 0.40820348 0.4082286  0.4083997
 0.40847838 0.40869948 0.40894407 0.40944648 0.40986267 0.4101176
 0.41032308 0.4108988  0.41178584 0.41299307 0.41487783 0.41756874
 0.4207607  0.4232591  0.42369536 0.4235197  0.42325488 0.42287475
 0.422772   0.42247057 0.42260945 0.42245272 0.4225813  0.4229392
 0.42298174 0.42315423 0.42331672 0.42347077 0.42368296 0.42362553
 0.42336527 0.4233471  0.423279   0.42327505 0.42336768 0.42351806
 0.4239167  0.42403403 0.42358944 0.42333615 0.4230764  0.42269054
 0.42261663 0.42231852 0.422452   0.42240855 0.42259857 0.42287898
 0.42280662 0.42290115 0.42302203 0.4231373  0.4233363  0.42338985
 0.42320618 0.4232602  0.4232268  0.42322764 0.42335558 0.4233577
 0.42351398 0.42347857 0.42308447 0.42290577 0.42257532 0.42219216
 0.42225188 0.42207175 0.42222393 0.42217276 0.42237177 0.42267576
 0.42278865 0.42307582 0.42321387 0.42341018 0.42356494 0.4233591
 0.42299393 0.42288202 0.42275128 0.4227217  0.42290074 0.42296904
 0.4231827  0.42322    0.42277738 0.42258498 0.42229396 0.4219309
 0.42200455 0.4218509  0.4220304  0.42208257 0.4223373  0.42265928
 0.42281833 0.42291045 0.42258623 0.42233923 0.4215639  0.41896206
 0.4159549  0.4135499  0.41170678 0.41041967 0.409556   0.40899312
 0.4089041  0.4086379  0.40805835 0.40756565 0.40720224 0.40684637
 0.40671715 0.40636456 0.40628597 0.40596634 0.40589926 0.40588245
 0.4057844  0.40574    0.40531844 0.40520367 0.40471163 0.4029227
 0.40064833 0.39908007 0.39794657 0.39713755 0.39691988 0.3973349
 0.39820948 0.39844638 0.39823872 0.39799652 0.39742768 0.39698565
 0.39692524 0.39650288 0.3963366  0.3959592  0.39581057 0.39605743
 0.39598894 0.39613715 0.3965629  0.39677632 0.39762577 0.3969619 ]
