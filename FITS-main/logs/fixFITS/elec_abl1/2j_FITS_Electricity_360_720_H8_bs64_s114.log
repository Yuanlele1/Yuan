Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=138, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_360_j720_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_360_j720_H8_FITS_custom_ftM_sl360_ll48_pl720_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17333
val 1913
test 4541
Model(
  (freq_upsampler): Linear(in_features=138, out_features=414, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2347439616.0
params:  57546.0
Trainable parameters:  57546
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.9028501
	speed: 0.7094s/iter; left time: 9506.1067s
Epoch: 1 cost time: 94.46766400337219
Epoch: 1, Steps: 135 | Train Loss: 1.1235642 Vali Loss: 0.7283118 Test Loss: 0.8539516
Validation loss decreased (inf --> 0.728312).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6915330
	speed: 1.6265s/iter; left time: 21577.0164s
Epoch: 2 cost time: 94.61117434501648
Epoch: 2, Steps: 135 | Train Loss: 0.7364699 Vali Loss: 0.6118323 Test Loss: 0.7247756
Validation loss decreased (0.728312 --> 0.611832).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.6326206
	speed: 1.6569s/iter; left time: 21756.5063s
Epoch: 3 cost time: 95.2509171962738
Epoch: 3, Steps: 135 | Train Loss: 0.6376309 Vali Loss: 0.5489058 Test Loss: 0.6536218
Validation loss decreased (0.611832 --> 0.548906).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.5361352
	speed: 1.5939s/iter; left time: 20714.6236s
Epoch: 4 cost time: 92.78115057945251
Epoch: 4, Steps: 135 | Train Loss: 0.5686717 Vali Loss: 0.4972718 Test Loss: 0.5950396
Validation loss decreased (0.548906 --> 0.497272).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.5078447
	speed: 1.6728s/iter; left time: 21513.4561s
Epoch: 5 cost time: 98.55797910690308
Epoch: 5, Steps: 135 | Train Loss: 0.5117285 Vali Loss: 0.4528019 Test Loss: 0.5439170
Validation loss decreased (0.497272 --> 0.452802).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4498386
	speed: 1.6198s/iter; left time: 20614.1968s
Epoch: 6 cost time: 94.6678113937378
Epoch: 6, Steps: 135 | Train Loss: 0.4639413 Vali Loss: 0.4157414 Test Loss: 0.5011632
Validation loss decreased (0.452802 --> 0.415741).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4104643
	speed: 1.7111s/iter; left time: 21544.0797s
Epoch: 7 cost time: 101.91367983818054
Epoch: 7, Steps: 135 | Train Loss: 0.4234380 Vali Loss: 0.3836405 Test Loss: 0.4641714
Validation loss decreased (0.415741 --> 0.383640).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3838943
	speed: 1.6028s/iter; left time: 19964.3403s
Epoch: 8 cost time: 91.9277229309082
Epoch: 8, Steps: 135 | Train Loss: 0.3887385 Vali Loss: 0.3570309 Test Loss: 0.4333669
Validation loss decreased (0.383640 --> 0.357031).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3673216
	speed: 1.6110s/iter; left time: 19848.7637s
Epoch: 9 cost time: 92.95323443412781
Epoch: 9, Steps: 135 | Train Loss: 0.3591239 Vali Loss: 0.3344990 Test Loss: 0.4066331
Validation loss decreased (0.357031 --> 0.334499).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3260173
	speed: 1.7161s/iter; left time: 20912.9787s
Epoch: 10 cost time: 106.84911584854126
Epoch: 10, Steps: 135 | Train Loss: 0.3334914 Vali Loss: 0.3137144 Test Loss: 0.3823389
Validation loss decreased (0.334499 --> 0.313714).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3063325
	speed: 1.8412s/iter; left time: 22188.4567s
Epoch: 11 cost time: 109.65981793403625
Epoch: 11, Steps: 135 | Train Loss: 0.3113443 Vali Loss: 0.2968357 Test Loss: 0.3618801
Validation loss decreased (0.313714 --> 0.296836).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2861246
	speed: 1.9139s/iter; left time: 22805.7194s
Epoch: 12 cost time: 110.9579873085022
Epoch: 12, Steps: 135 | Train Loss: 0.2922020 Vali Loss: 0.2819975 Test Loss: 0.3445626
Validation loss decreased (0.296836 --> 0.281998).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2723118
	speed: 1.8233s/iter; left time: 21480.1445s
Epoch: 13 cost time: 102.45702910423279
Epoch: 13, Steps: 135 | Train Loss: 0.2754773 Vali Loss: 0.2692039 Test Loss: 0.3291310
Validation loss decreased (0.281998 --> 0.269204).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2512957
	speed: 1.8552s/iter; left time: 21605.1985s
Epoch: 14 cost time: 108.65485167503357
Epoch: 14, Steps: 135 | Train Loss: 0.2609664 Vali Loss: 0.2581002 Test Loss: 0.3154668
Validation loss decreased (0.269204 --> 0.258100).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2365574
	speed: 1.8459s/iter; left time: 21248.1210s
Epoch: 15 cost time: 105.69510698318481
Epoch: 15, Steps: 135 | Train Loss: 0.2483094 Vali Loss: 0.2485854 Test Loss: 0.3038399
Validation loss decreased (0.258100 --> 0.248585).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2248473
	speed: 1.7152s/iter; left time: 19512.2865s
Epoch: 16 cost time: 101.55101990699768
Epoch: 16, Steps: 135 | Train Loss: 0.2372001 Vali Loss: 0.2398826 Test Loss: 0.2930655
Validation loss decreased (0.248585 --> 0.239883).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2163852
	speed: 1.7230s/iter; left time: 19368.6142s
Epoch: 17 cost time: 99.24171733856201
Epoch: 17, Steps: 135 | Train Loss: 0.2274905 Vali Loss: 0.2325543 Test Loss: 0.2844238
Validation loss decreased (0.239883 --> 0.232554).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2156704
	speed: 1.7077s/iter; left time: 18965.2789s
Epoch: 18 cost time: 99.82047128677368
Epoch: 18, Steps: 135 | Train Loss: 0.2189791 Vali Loss: 0.2260915 Test Loss: 0.2762819
Validation loss decreased (0.232554 --> 0.226091).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2180670
	speed: 1.7946s/iter; left time: 19688.8367s
Epoch: 19 cost time: 100.00282740592957
Epoch: 19, Steps: 135 | Train Loss: 0.2115878 Vali Loss: 0.2207837 Test Loss: 0.2696390
Validation loss decreased (0.226091 --> 0.220784).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2066973
	speed: 1.8385s/iter; left time: 19922.4421s
Epoch: 20 cost time: 108.18027853965759
Epoch: 20, Steps: 135 | Train Loss: 0.2049347 Vali Loss: 0.2159726 Test Loss: 0.2632176
Validation loss decreased (0.220784 --> 0.215973).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1885060
	speed: 1.7337s/iter; left time: 18552.4228s
Epoch: 21 cost time: 104.89413380622864
Epoch: 21, Steps: 135 | Train Loss: 0.1991279 Vali Loss: 0.2115779 Test Loss: 0.2577131
Validation loss decreased (0.215973 --> 0.211578).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1991864
	speed: 1.8135s/iter; left time: 19161.0872s
Epoch: 22 cost time: 102.69189214706421
Epoch: 22, Steps: 135 | Train Loss: 0.1940200 Vali Loss: 0.2081753 Test Loss: 0.2529931
Validation loss decreased (0.211578 --> 0.208175).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1976093
	speed: 1.8735s/iter; left time: 19542.3169s
Epoch: 23 cost time: 110.21591663360596
Epoch: 23, Steps: 135 | Train Loss: 0.1895110 Vali Loss: 0.2045147 Test Loss: 0.2486693
Validation loss decreased (0.208175 --> 0.204515).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1897709
	speed: 1.8657s/iter; left time: 19209.2042s
Epoch: 24 cost time: 111.39622211456299
Epoch: 24, Steps: 135 | Train Loss: 0.1855455 Vali Loss: 0.2018872 Test Loss: 0.2449396
Validation loss decreased (0.204515 --> 0.201887).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1707160
	speed: 1.8185s/iter; left time: 18477.8146s
Epoch: 25 cost time: 101.2148687839508
Epoch: 25, Steps: 135 | Train Loss: 0.1820654 Vali Loss: 0.1991504 Test Loss: 0.2413819
Validation loss decreased (0.201887 --> 0.199150).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1758677
	speed: 1.7441s/iter; left time: 17485.8605s
Epoch: 26 cost time: 99.57160949707031
Epoch: 26, Steps: 135 | Train Loss: 0.1789422 Vali Loss: 0.1967869 Test Loss: 0.2382265
Validation loss decreased (0.199150 --> 0.196787).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1693954
	speed: 1.7849s/iter; left time: 17654.0915s
Epoch: 27 cost time: 109.22834277153015
Epoch: 27, Steps: 135 | Train Loss: 0.1761151 Vali Loss: 0.1950881 Test Loss: 0.2358304
Validation loss decreased (0.196787 --> 0.195088).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1670340
	speed: 1.7755s/iter; left time: 17321.3104s
Epoch: 28 cost time: 102.70835065841675
Epoch: 28, Steps: 135 | Train Loss: 0.1737256 Vali Loss: 0.1935839 Test Loss: 0.2333512
Validation loss decreased (0.195088 --> 0.193584).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1744656
	speed: 1.7141s/iter; left time: 16491.8133s
Epoch: 29 cost time: 98.83440232276917
Epoch: 29, Steps: 135 | Train Loss: 0.1715011 Vali Loss: 0.1921702 Test Loss: 0.2313853
Validation loss decreased (0.193584 --> 0.192170).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1685504
	speed: 1.7055s/iter; left time: 16178.1755s
Epoch: 30 cost time: 100.73338913917542
Epoch: 30, Steps: 135 | Train Loss: 0.1695696 Vali Loss: 0.1904004 Test Loss: 0.2293576
Validation loss decreased (0.192170 --> 0.190400).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1602700
	speed: 1.7143s/iter; left time: 16030.3394s
Epoch: 31 cost time: 98.43797326087952
Epoch: 31, Steps: 135 | Train Loss: 0.1678857 Vali Loss: 0.1892740 Test Loss: 0.2277516
Validation loss decreased (0.190400 --> 0.189274).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1694138
	speed: 1.7338s/iter; left time: 15978.8145s
Epoch: 32 cost time: 99.25294971466064
Epoch: 32, Steps: 135 | Train Loss: 0.1663482 Vali Loss: 0.1885343 Test Loss: 0.2261638
Validation loss decreased (0.189274 --> 0.188534).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1705516
	speed: 1.6889s/iter; left time: 15337.3460s
Epoch: 33 cost time: 99.54679131507874
Epoch: 33, Steps: 135 | Train Loss: 0.1650083 Vali Loss: 0.1874734 Test Loss: 0.2248493
Validation loss decreased (0.188534 --> 0.187473).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1601359
	speed: 1.7292s/iter; left time: 15469.4100s
Epoch: 34 cost time: 103.1623866558075
Epoch: 34, Steps: 135 | Train Loss: 0.1637813 Vali Loss: 0.1867351 Test Loss: 0.2237215
Validation loss decreased (0.187473 --> 0.186735).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1636263
	speed: 1.8506s/iter; left time: 16305.2455s
Epoch: 35 cost time: 108.87778997421265
Epoch: 35, Steps: 135 | Train Loss: 0.1627403 Vali Loss: 0.1859755 Test Loss: 0.2225991
Validation loss decreased (0.186735 --> 0.185976).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1559678
	speed: 1.9375s/iter; left time: 16809.4536s
Epoch: 36 cost time: 108.2928409576416
Epoch: 36, Steps: 135 | Train Loss: 0.1617338 Vali Loss: 0.1854547 Test Loss: 0.2215655
Validation loss decreased (0.185976 --> 0.185455).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1564847
	speed: 1.7880s/iter; left time: 15271.3118s
Epoch: 37 cost time: 109.56745147705078
Epoch: 37, Steps: 135 | Train Loss: 0.1609042 Vali Loss: 0.1848291 Test Loss: 0.2207488
Validation loss decreased (0.185455 --> 0.184829).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1615798
	speed: 1.8159s/iter; left time: 15264.6239s
Epoch: 38 cost time: 104.837153673172
Epoch: 38, Steps: 135 | Train Loss: 0.1601521 Vali Loss: 0.1845274 Test Loss: 0.2199136
Validation loss decreased (0.184829 --> 0.184527).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1604954
	speed: 1.7974s/iter; left time: 14866.4623s
Epoch: 39 cost time: 103.63920640945435
Epoch: 39, Steps: 135 | Train Loss: 0.1594294 Vali Loss: 0.1841924 Test Loss: 0.2192255
Validation loss decreased (0.184527 --> 0.184192).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1697749
	speed: 1.7644s/iter; left time: 14355.1607s
Epoch: 40 cost time: 106.3164598941803
Epoch: 40, Steps: 135 | Train Loss: 0.1588329 Vali Loss: 0.1838821 Test Loss: 0.2185754
Validation loss decreased (0.184192 --> 0.183882).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1639542
	speed: 1.7788s/iter; left time: 14232.5218s
Epoch: 41 cost time: 99.27485370635986
Epoch: 41, Steps: 135 | Train Loss: 0.1582956 Vali Loss: 0.1831523 Test Loss: 0.2180015
Validation loss decreased (0.183882 --> 0.183152).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1597478
	speed: 1.7353s/iter; left time: 13649.8018s
Epoch: 42 cost time: 100.22893714904785
Epoch: 42, Steps: 135 | Train Loss: 0.1578307 Vali Loss: 0.1831680 Test Loss: 0.2175447
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1518924
	speed: 1.9717s/iter; left time: 15243.0562s
Epoch: 43 cost time: 131.87789011001587
Epoch: 43, Steps: 135 | Train Loss: 0.1573767 Vali Loss: 0.1831375 Test Loss: 0.2170565
Validation loss decreased (0.183152 --> 0.183138).  Saving model ...
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1552724
	speed: 2.2430s/iter; left time: 17037.8891s
Epoch: 44 cost time: 133.56841802597046
Epoch: 44, Steps: 135 | Train Loss: 0.1569659 Vali Loss: 0.1825981 Test Loss: 0.2166685
Validation loss decreased (0.183138 --> 0.182598).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1532862
	speed: 2.2761s/iter; left time: 16982.1053s
Epoch: 45 cost time: 133.66885209083557
Epoch: 45, Steps: 135 | Train Loss: 0.1566583 Vali Loss: 0.1826022 Test Loss: 0.2162980
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1624105
	speed: 2.2307s/iter; left time: 16341.9510s
Epoch: 46 cost time: 133.06866002082825
Epoch: 46, Steps: 135 | Train Loss: 0.1563608 Vali Loss: 0.1824244 Test Loss: 0.2159169
Validation loss decreased (0.182598 --> 0.182424).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1487129
	speed: 2.3697s/iter; left time: 17040.3362s
Epoch: 47 cost time: 135.8124008178711
Epoch: 47, Steps: 135 | Train Loss: 0.1560509 Vali Loss: 0.1822835 Test Loss: 0.2156333
Validation loss decreased (0.182424 --> 0.182284).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1559142
	speed: 2.3114s/iter; left time: 16309.1615s
Epoch: 48 cost time: 135.51854062080383
Epoch: 48, Steps: 135 | Train Loss: 0.1558414 Vali Loss: 0.1823226 Test Loss: 0.2153726
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1522044
	speed: 2.2938s/iter; left time: 15875.3522s
Epoch: 49 cost time: 129.83841347694397
Epoch: 49, Steps: 135 | Train Loss: 0.1556254 Vali Loss: 0.1817094 Test Loss: 0.2151156
Validation loss decreased (0.182284 --> 0.181709).  Saving model ...
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1485222
	speed: 2.3705s/iter; left time: 16086.3742s
Epoch: 50 cost time: 140.69021368026733
Epoch: 50, Steps: 135 | Train Loss: 0.1554160 Vali Loss: 0.1818669 Test Loss: 0.2149262
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1581365
	speed: 2.2905s/iter; left time: 15233.9440s
Epoch: 51 cost time: 130.90109205245972
Epoch: 51, Steps: 135 | Train Loss: 0.1552363 Vali Loss: 0.1820565 Test Loss: 0.2147117
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1518776
	speed: 2.3201s/iter; left time: 15118.0465s
Epoch: 52 cost time: 142.8669900894165
Epoch: 52, Steps: 135 | Train Loss: 0.1550824 Vali Loss: 0.1818413 Test Loss: 0.2145361
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1470045
	speed: 2.3445s/iter; left time: 14960.5380s
Epoch: 53 cost time: 140.79003834724426
Epoch: 53, Steps: 135 | Train Loss: 0.1549302 Vali Loss: 0.1817998 Test Loss: 0.2143765
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1491471
	speed: 2.4040s/iter; left time: 15015.4054s
Epoch: 54 cost time: 134.65391397476196
Epoch: 54, Steps: 135 | Train Loss: 0.1547853 Vali Loss: 0.1815648 Test Loss: 0.2142158
Validation loss decreased (0.181709 --> 0.181565).  Saving model ...
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1570706
	speed: 2.2870s/iter; left time: 13975.7213s
Epoch: 55 cost time: 136.99264693260193
Epoch: 55, Steps: 135 | Train Loss: 0.1547198 Vali Loss: 0.1818840 Test Loss: 0.2140659
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1649391
	speed: 2.2572s/iter; left time: 13489.2110s
Epoch: 56 cost time: 127.09297561645508
Epoch: 56, Steps: 135 | Train Loss: 0.1545533 Vali Loss: 0.1819284 Test Loss: 0.2139475
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.1534884
	speed: 2.1333s/iter; left time: 12460.7107s
Epoch: 57 cost time: 124.70859551429749
Epoch: 57, Steps: 135 | Train Loss: 0.1544994 Vali Loss: 0.1815699 Test Loss: 0.2138269
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1505828
	speed: 2.1991s/iter; left time: 12548.2894s
Epoch: 58 cost time: 129.55356359481812
Epoch: 58, Steps: 135 | Train Loss: 0.1544225 Vali Loss: 0.1817477 Test Loss: 0.2137324
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1502040
	speed: 2.1653s/iter; left time: 12062.9179s
Epoch: 59 cost time: 122.62123775482178
Epoch: 59, Steps: 135 | Train Loss: 0.1542944 Vali Loss: 0.1816513 Test Loss: 0.2136398
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1561773
	speed: 2.0467s/iter; left time: 11125.7956s
Epoch: 60 cost time: 116.98977422714233
Epoch: 60, Steps: 135 | Train Loss: 0.1542723 Vali Loss: 0.1816244 Test Loss: 0.2135501
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1467810
	speed: 1.9898s/iter; left time: 10547.9130s
Epoch: 61 cost time: 121.0950882434845
Epoch: 61, Steps: 135 | Train Loss: 0.1542481 Vali Loss: 0.1815100 Test Loss: 0.2134747
Validation loss decreased (0.181565 --> 0.181510).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1618421
	speed: 2.1097s/iter; left time: 10898.9611s
Epoch: 62 cost time: 124.54848313331604
Epoch: 62, Steps: 135 | Train Loss: 0.1541649 Vali Loss: 0.1816424 Test Loss: 0.2134071
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1545608
	speed: 2.1266s/iter; left time: 10699.1052s
Epoch: 63 cost time: 123.75032067298889
Epoch: 63, Steps: 135 | Train Loss: 0.1540974 Vali Loss: 0.1815049 Test Loss: 0.2133436
Validation loss decreased (0.181510 --> 0.181505).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1580274
	speed: 1.9712s/iter; left time: 9650.8361s
Epoch: 64 cost time: 116.26441287994385
Epoch: 64, Steps: 135 | Train Loss: 0.1540705 Vali Loss: 0.1814244 Test Loss: 0.2132919
Validation loss decreased (0.181505 --> 0.181424).  Saving model ...
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.1587781
	speed: 1.9680s/iter; left time: 9369.6339s
Epoch: 65 cost time: 117.20819187164307
Epoch: 65, Steps: 135 | Train Loss: 0.1540423 Vali Loss: 0.1816217 Test Loss: 0.2132372
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.1609282
	speed: 2.0314s/iter; left time: 9397.4424s
Epoch: 66 cost time: 116.16062378883362
Epoch: 66, Steps: 135 | Train Loss: 0.1539859 Vali Loss: 0.1815094 Test Loss: 0.2131911
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.1608878
	speed: 1.9648s/iter; left time: 8823.8661s
Epoch: 67 cost time: 112.58679246902466
Epoch: 67, Steps: 135 | Train Loss: 0.1539881 Vali Loss: 0.1817266 Test Loss: 0.2131447
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.1500379
	speed: 2.0547s/iter; left time: 8950.3811s
Epoch: 68 cost time: 119.92681360244751
Epoch: 68, Steps: 135 | Train Loss: 0.1539401 Vali Loss: 0.1816986 Test Loss: 0.2131095
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.1509020
	speed: 1.9683s/iter; left time: 8308.2172s
Epoch: 69 cost time: 115.88791537284851
Epoch: 69, Steps: 135 | Train Loss: 0.1539159 Vali Loss: 0.1817874 Test Loss: 0.2130697
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.1461282
	speed: 2.0065s/iter; left time: 8198.4629s
Epoch: 70 cost time: 110.5383620262146
Epoch: 70, Steps: 135 | Train Loss: 0.1538468 Vali Loss: 0.1821135 Test Loss: 0.2130366
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.1513286
	speed: 1.7814s/iter; left time: 7038.1145s
Epoch: 71 cost time: 104.74884581565857
Epoch: 71, Steps: 135 | Train Loss: 0.1538692 Vali Loss: 0.1815891 Test Loss: 0.2130061
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.1602640
	speed: 1.8116s/iter; left time: 6913.0637s
Epoch: 72 cost time: 107.43233704566956
Epoch: 72, Steps: 135 | Train Loss: 0.1538723 Vali Loss: 0.1815259 Test Loss: 0.2129801
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.1520738
	speed: 1.8150s/iter; left time: 6680.9186s
Epoch: 73 cost time: 106.61817479133606
Epoch: 73, Steps: 135 | Train Loss: 0.1538797 Vali Loss: 0.1815047 Test Loss: 0.2129533
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.1657427
	speed: 1.7254s/iter; left time: 6118.3479s
Epoch: 74 cost time: 100.27924633026123
Epoch: 74, Steps: 135 | Train Loss: 0.1538243 Vali Loss: 0.1817160 Test Loss: 0.2129294
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.1546144
	speed: 1.7892s/iter; left time: 6102.8209s
Epoch: 75 cost time: 108.3554573059082
Epoch: 75, Steps: 135 | Train Loss: 0.1538366 Vali Loss: 0.1820009 Test Loss: 0.2129094
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.1528906
	speed: 1.8348s/iter; left time: 6010.8338s
Epoch: 76 cost time: 103.71917009353638
Epoch: 76, Steps: 135 | Train Loss: 0.1537956 Vali Loss: 0.1815601 Test Loss: 0.2128894
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.1429316
	speed: 1.8537s/iter; left time: 5822.4137s
Epoch: 77 cost time: 113.20934748649597
Epoch: 77, Steps: 135 | Train Loss: 0.1537975 Vali Loss: 0.1818895 Test Loss: 0.2128699
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.1498224
	speed: 1.9815s/iter; left time: 5956.4000s
Epoch: 78 cost time: 111.71622681617737
Epoch: 78, Steps: 135 | Train Loss: 0.1538023 Vali Loss: 0.1816684 Test Loss: 0.2128540
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.1544864
	speed: 1.8802s/iter; left time: 5397.9386s
Epoch: 79 cost time: 110.4602701663971
Epoch: 79, Steps: 135 | Train Loss: 0.1537374 Vali Loss: 0.1818017 Test Loss: 0.2128406
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.1580604
	speed: 1.5388s/iter; left time: 4210.0498s
Epoch: 80 cost time: 85.58253860473633
Epoch: 80, Steps: 135 | Train Loss: 0.1537393 Vali Loss: 0.1816909 Test Loss: 0.2128254
EarlyStopping counter: 16 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.1474025
	speed: 1.4421s/iter; left time: 3750.8347s
Epoch: 81 cost time: 83.04658246040344
Epoch: 81, Steps: 135 | Train Loss: 0.1537777 Vali Loss: 0.1821471 Test Loss: 0.2128141
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.1482593
	speed: 1.4344s/iter; left time: 3537.2579s
Epoch: 82 cost time: 83.4224214553833
Epoch: 82, Steps: 135 | Train Loss: 0.1537217 Vali Loss: 0.1817650 Test Loss: 0.2128019
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.1532401
	speed: 1.3800s/iter; left time: 3216.8526s
Epoch: 83 cost time: 80.89016151428223
Epoch: 83, Steps: 135 | Train Loss: 0.1537101 Vali Loss: 0.1821541 Test Loss: 0.2127903
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.1488977
	speed: 1.4766s/iter; left time: 3242.6724s
Epoch: 84 cost time: 100.13538122177124
Epoch: 84, Steps: 135 | Train Loss: 0.1537312 Vali Loss: 0.1818634 Test Loss: 0.2127794
EarlyStopping counter: 20 out of 20
Early stopping
train 17333
val 1913
test 4541
Model(
  (freq_upsampler): Linear(in_features=138, out_features=414, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2347439616.0
params:  57546.0
Trainable parameters:  57546
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2432602
	speed: 0.8132s/iter; left time: 10897.9746s
Epoch: 1 cost time: 108.4056441783905
Epoch: 1, Steps: 135 | Train Loss: 0.2264376 Vali Loss: 0.1817236 Test Loss: 0.2122278
Validation loss decreased (inf --> 0.181724).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2274277
	speed: 1.7466s/iter; left time: 23170.1971s
Epoch: 2 cost time: 95.59774613380432
Epoch: 2, Steps: 135 | Train Loss: 0.2262435 Vali Loss: 0.1817286 Test Loss: 0.2122181
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2270360
	speed: 1.4874s/iter; left time: 19531.5721s
Epoch: 3 cost time: 88.8238377571106
Epoch: 3, Steps: 135 | Train Loss: 0.2262300 Vali Loss: 0.1814772 Test Loss: 0.2121147
Validation loss decreased (0.181724 --> 0.181477).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2232683
	speed: 1.5247s/iter; left time: 19814.9226s
Epoch: 4 cost time: 86.86567878723145
Epoch: 4, Steps: 135 | Train Loss: 0.2261398 Vali Loss: 0.1813240 Test Loss: 0.2121540
Validation loss decreased (0.181477 --> 0.181324).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2168740
	speed: 1.5322s/iter; left time: 19705.9251s
Epoch: 5 cost time: 91.85397386550903
Epoch: 5, Steps: 135 | Train Loss: 0.2261307 Vali Loss: 0.1811778 Test Loss: 0.2120825
Validation loss decreased (0.181324 --> 0.181178).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2258826
	speed: 1.6509s/iter; left time: 21009.1204s
Epoch: 6 cost time: 95.03437113761902
Epoch: 6, Steps: 135 | Train Loss: 0.2260233 Vali Loss: 0.1812683 Test Loss: 0.2121710
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2263592
	speed: 1.5177s/iter; left time: 19109.8282s
Epoch: 7 cost time: 88.24911737442017
Epoch: 7, Steps: 135 | Train Loss: 0.2260820 Vali Loss: 0.1814522 Test Loss: 0.2120623
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2226446
	speed: 1.5723s/iter; left time: 19584.1035s
Epoch: 8 cost time: 89.94482803344727
Epoch: 8, Steps: 135 | Train Loss: 0.2261088 Vali Loss: 0.1811154 Test Loss: 0.2120922
Validation loss decreased (0.181178 --> 0.181115).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2238679
	speed: 1.4717s/iter; left time: 18132.9778s
Epoch: 9 cost time: 82.62107610702515
Epoch: 9, Steps: 135 | Train Loss: 0.2261052 Vali Loss: 0.1814086 Test Loss: 0.2121358
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2354802
	speed: 1.3932s/iter; left time: 16977.4211s
Epoch: 10 cost time: 83.34573245048523
Epoch: 10, Steps: 135 | Train Loss: 0.2260174 Vali Loss: 0.1810640 Test Loss: 0.2121173
Validation loss decreased (0.181115 --> 0.181064).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2297626
	speed: 1.4327s/iter; left time: 17265.2777s
Epoch: 11 cost time: 83.07184362411499
Epoch: 11, Steps: 135 | Train Loss: 0.2259939 Vali Loss: 0.1811126 Test Loss: 0.2120682
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2271734
	speed: 1.4725s/iter; left time: 17546.3912s
Epoch: 12 cost time: 88.77479958534241
Epoch: 12, Steps: 135 | Train Loss: 0.2260051 Vali Loss: 0.1813570 Test Loss: 0.2120184
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2279293
	speed: 1.4431s/iter; left time: 17001.0455s
Epoch: 13 cost time: 82.43457818031311
Epoch: 13, Steps: 135 | Train Loss: 0.2259002 Vali Loss: 0.1815316 Test Loss: 0.2120924
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2126566
	speed: 1.4961s/iter; left time: 17423.9374s
Epoch: 14 cost time: 88.52656197547913
Epoch: 14, Steps: 135 | Train Loss: 0.2259378 Vali Loss: 0.1812539 Test Loss: 0.2120742
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2368434
	speed: 1.4302s/iter; left time: 16462.5931s
Epoch: 15 cost time: 80.78743696212769
Epoch: 15, Steps: 135 | Train Loss: 0.2259279 Vali Loss: 0.1813399 Test Loss: 0.2120961
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2198071
	speed: 1.3787s/iter; left time: 15683.8372s
Epoch: 16 cost time: 79.0214831829071
Epoch: 16, Steps: 135 | Train Loss: 0.2259763 Vali Loss: 0.1812808 Test Loss: 0.2120603
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2127528
	speed: 1.3650s/iter; left time: 15344.4268s
Epoch: 17 cost time: 80.42985320091248
Epoch: 17, Steps: 135 | Train Loss: 0.2258888 Vali Loss: 0.1809852 Test Loss: 0.2120857
Validation loss decreased (0.181064 --> 0.180985).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2265445
	speed: 1.4227s/iter; left time: 15800.5381s
Epoch: 18 cost time: 85.60447311401367
Epoch: 18, Steps: 135 | Train Loss: 0.2259195 Vali Loss: 0.1808143 Test Loss: 0.2121186
Validation loss decreased (0.180985 --> 0.180814).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2311456
	speed: 1.4042s/iter; left time: 15405.2810s
Epoch: 19 cost time: 79.48818159103394
Epoch: 19, Steps: 135 | Train Loss: 0.2259224 Vali Loss: 0.1813043 Test Loss: 0.2120792
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2212695
	speed: 1.4135s/iter; left time: 15316.6487s
Epoch: 20 cost time: 82.68987274169922
Epoch: 20, Steps: 135 | Train Loss: 0.2258971 Vali Loss: 0.1811255 Test Loss: 0.2120816
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2303831
	speed: 1.3884s/iter; left time: 14857.5620s
Epoch: 21 cost time: 80.85539436340332
Epoch: 21, Steps: 135 | Train Loss: 0.2259526 Vali Loss: 0.1811307 Test Loss: 0.2120944
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2370872
	speed: 1.2795s/iter; left time: 13518.6967s
Epoch: 22 cost time: 75.08462166786194
Epoch: 22, Steps: 135 | Train Loss: 0.2258521 Vali Loss: 0.1811000 Test Loss: 0.2120806
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2182294
	speed: 1.3090s/iter; left time: 13654.3335s
Epoch: 23 cost time: 72.4297468662262
Epoch: 23, Steps: 135 | Train Loss: 0.2259131 Vali Loss: 0.1806753 Test Loss: 0.2121027
Validation loss decreased (0.180814 --> 0.180675).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2172798
	speed: 1.2237s/iter; left time: 12598.7099s
Epoch: 24 cost time: 72.6893401145935
Epoch: 24, Steps: 135 | Train Loss: 0.2259292 Vali Loss: 0.1812188 Test Loss: 0.2120390
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2265042
	speed: 1.2946s/iter; left time: 13154.5863s
Epoch: 25 cost time: 75.75118231773376
Epoch: 25, Steps: 135 | Train Loss: 0.2258673 Vali Loss: 0.1809047 Test Loss: 0.2120426
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2297403
	speed: 1.3546s/iter; left time: 13581.0572s
Epoch: 26 cost time: 80.28366827964783
Epoch: 26, Steps: 135 | Train Loss: 0.2258970 Vali Loss: 0.1806744 Test Loss: 0.2121068
Validation loss decreased (0.180675 --> 0.180674).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2293454
	speed: 1.2922s/iter; left time: 12781.4015s
Epoch: 27 cost time: 74.00059270858765
Epoch: 27, Steps: 135 | Train Loss: 0.2258944 Vali Loss: 0.1808742 Test Loss: 0.2120705
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2189299
	speed: 1.2005s/iter; left time: 11711.6527s
Epoch: 28 cost time: 69.22590732574463
Epoch: 28, Steps: 135 | Train Loss: 0.2258632 Vali Loss: 0.1810305 Test Loss: 0.2120773
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2322019
	speed: 1.2030s/iter; left time: 11574.1087s
Epoch: 29 cost time: 67.85925698280334
Epoch: 29, Steps: 135 | Train Loss: 0.2258361 Vali Loss: 0.1809295 Test Loss: 0.2120500
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2222714
	speed: 1.1351s/iter; left time: 10768.0018s
Epoch: 30 cost time: 65.95358490943909
Epoch: 30, Steps: 135 | Train Loss: 0.2258548 Vali Loss: 0.1809102 Test Loss: 0.2120518
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2152869
	speed: 1.1669s/iter; left time: 10911.8980s
Epoch: 31 cost time: 69.12918591499329
Epoch: 31, Steps: 135 | Train Loss: 0.2257528 Vali Loss: 0.1811791 Test Loss: 0.2120736
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2225543
	speed: 1.1552s/iter; left time: 10646.3728s
Epoch: 32 cost time: 66.47458457946777
Epoch: 32, Steps: 135 | Train Loss: 0.2258065 Vali Loss: 0.1811078 Test Loss: 0.2120502
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2303282
	speed: 1.1420s/iter; left time: 10370.4671s
Epoch: 33 cost time: 67.54020595550537
Epoch: 33, Steps: 135 | Train Loss: 0.2258271 Vali Loss: 0.1807617 Test Loss: 0.2120517
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2310151
	speed: 1.1618s/iter; left time: 10393.8569s
Epoch: 34 cost time: 65.38343238830566
Epoch: 34, Steps: 135 | Train Loss: 0.2258667 Vali Loss: 0.1808704 Test Loss: 0.2120528
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2201281
	speed: 1.1559s/iter; left time: 10185.0230s
Epoch: 35 cost time: 68.00362491607666
Epoch: 35, Steps: 135 | Train Loss: 0.2258301 Vali Loss: 0.1810328 Test Loss: 0.2120547
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2224613
	speed: 1.1497s/iter; left time: 9974.6452s
Epoch: 36 cost time: 67.05115628242493
Epoch: 36, Steps: 135 | Train Loss: 0.2258715 Vali Loss: 0.1808465 Test Loss: 0.2120669
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2189378
	speed: 1.1823s/iter; left time: 10098.2294s
Epoch: 37 cost time: 69.82346248626709
Epoch: 37, Steps: 135 | Train Loss: 0.2258413 Vali Loss: 0.1808817 Test Loss: 0.2120508
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2326543
	speed: 0.9581s/iter; left time: 8053.9220s
Epoch: 38 cost time: 57.10093665122986
Epoch: 38, Steps: 135 | Train Loss: 0.2258449 Vali Loss: 0.1806929 Test Loss: 0.2120699
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2240210
	speed: 1.1263s/iter; left time: 9315.6098s
Epoch: 39 cost time: 69.91653823852539
Epoch: 39, Steps: 135 | Train Loss: 0.2258260 Vali Loss: 0.1809914 Test Loss: 0.2120525
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2350356
	speed: 1.1579s/iter; left time: 9421.0057s
Epoch: 40 cost time: 68.60935306549072
Epoch: 40, Steps: 135 | Train Loss: 0.2258449 Vali Loss: 0.1808649 Test Loss: 0.2120479
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2253755
	speed: 1.1387s/iter; left time: 9110.6892s
Epoch: 41 cost time: 66.14790654182434
Epoch: 41, Steps: 135 | Train Loss: 0.2257930 Vali Loss: 0.1811467 Test Loss: 0.2120435
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2410203
	speed: 1.0620s/iter; left time: 8353.8021s
Epoch: 42 cost time: 61.14572215080261
Epoch: 42, Steps: 135 | Train Loss: 0.2258115 Vali Loss: 0.1808269 Test Loss: 0.2120326
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2139644
	speed: 0.9552s/iter; left time: 7384.3445s
Epoch: 43 cost time: 57.747804164886475
Epoch: 43, Steps: 135 | Train Loss: 0.2258358 Vali Loss: 0.1807651 Test Loss: 0.2120582
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2231002
	speed: 1.4922s/iter; left time: 11335.0639s
Epoch: 44 cost time: 90.62532234191895
Epoch: 44, Steps: 135 | Train Loss: 0.2258665 Vali Loss: 0.1810255 Test Loss: 0.2120572
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2217133
	speed: 1.4648s/iter; left time: 10928.7611s
Epoch: 45 cost time: 82.52128148078918
Epoch: 45, Steps: 135 | Train Loss: 0.2257708 Vali Loss: 0.1807830 Test Loss: 0.2120609
EarlyStopping counter: 19 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2263513
	speed: 1.4185s/iter; left time: 10392.1635s
Epoch: 46 cost time: 88.96564221382141
Epoch: 46, Steps: 135 | Train Loss: 0.2257925 Vali Loss: 0.1804919 Test Loss: 0.2120521
Validation loss decreased (0.180674 --> 0.180492).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2270440
	speed: 1.3592s/iter; left time: 9773.7292s
Epoch: 47 cost time: 77.03869414329529
Epoch: 47, Steps: 135 | Train Loss: 0.2257913 Vali Loss: 0.1810145 Test Loss: 0.2120574
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2249142
	speed: 1.3954s/iter; left time: 9846.1682s
Epoch: 48 cost time: 84.5063099861145
Epoch: 48, Steps: 135 | Train Loss: 0.2257850 Vali Loss: 0.1813667 Test Loss: 0.2120443
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2184673
	speed: 1.3038s/iter; left time: 9023.2994s
Epoch: 49 cost time: 78.41486406326294
Epoch: 49, Steps: 135 | Train Loss: 0.2257960 Vali Loss: 0.1807692 Test Loss: 0.2120429
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2282749
	speed: 1.3893s/iter; left time: 9427.7283s
Epoch: 50 cost time: 82.31995749473572
Epoch: 50, Steps: 135 | Train Loss: 0.2257482 Vali Loss: 0.1808982 Test Loss: 0.2120437
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2281006
	speed: 1.3551s/iter; left time: 9013.0908s
Epoch: 51 cost time: 79.92510795593262
Epoch: 51, Steps: 135 | Train Loss: 0.2257846 Vali Loss: 0.1810043 Test Loss: 0.2120477
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2328912
	speed: 1.4493s/iter; left time: 9443.7300s
Epoch: 52 cost time: 85.59307837486267
Epoch: 52, Steps: 135 | Train Loss: 0.2257730 Vali Loss: 0.1809280 Test Loss: 0.2120443
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2335864
	speed: 1.4100s/iter; left time: 8997.0299s
Epoch: 53 cost time: 79.36265587806702
Epoch: 53, Steps: 135 | Train Loss: 0.2257928 Vali Loss: 0.1812523 Test Loss: 0.2120446
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2375846
	speed: 1.4128s/iter; left time: 8824.3084s
Epoch: 54 cost time: 89.84960579872131
Epoch: 54, Steps: 135 | Train Loss: 0.2257623 Vali Loss: 0.1808638 Test Loss: 0.2120428
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2273171
	speed: 1.5653s/iter; left time: 9565.5175s
Epoch: 55 cost time: 93.63273096084595
Epoch: 55, Steps: 135 | Train Loss: 0.2257670 Vali Loss: 0.1811070 Test Loss: 0.2120460
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2219429
	speed: 1.4723s/iter; left time: 8798.5855s
Epoch: 56 cost time: 80.28802990913391
Epoch: 56, Steps: 135 | Train Loss: 0.2258471 Vali Loss: 0.1809802 Test Loss: 0.2120416
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2293030
	speed: 1.5548s/iter; left time: 9081.4306s
Epoch: 57 cost time: 90.12910413742065
Epoch: 57, Steps: 135 | Train Loss: 0.2258448 Vali Loss: 0.1808932 Test Loss: 0.2120429
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2163179
	speed: 1.4037s/iter; left time: 8009.6794s
Epoch: 58 cost time: 81.56413125991821
Epoch: 58, Steps: 135 | Train Loss: 0.2258456 Vali Loss: 0.1808042 Test Loss: 0.2120401
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2331705
	speed: 1.4457s/iter; left time: 8053.8400s
Epoch: 59 cost time: 86.09649062156677
Epoch: 59, Steps: 135 | Train Loss: 0.2257779 Vali Loss: 0.1807500 Test Loss: 0.2120479
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.2346638
	speed: 1.4021s/iter; left time: 7622.0004s
Epoch: 60 cost time: 80.58183073997498
Epoch: 60, Steps: 135 | Train Loss: 0.2258612 Vali Loss: 0.1806621 Test Loss: 0.2120445
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.2253175
	speed: 1.4855s/iter; left time: 7874.5809s
Epoch: 61 cost time: 86.91343283653259
Epoch: 61, Steps: 135 | Train Loss: 0.2257496 Vali Loss: 0.1810182 Test Loss: 0.2120434
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.2252533
	speed: 1.2347s/iter; left time: 6378.2369s
Epoch: 62 cost time: 72.51321411132812
Epoch: 62, Steps: 135 | Train Loss: 0.2258333 Vali Loss: 0.1808093 Test Loss: 0.2120449
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.2339101
	speed: 1.3493s/iter; left time: 6788.3046s
Epoch: 63 cost time: 81.56897115707397
Epoch: 63, Steps: 135 | Train Loss: 0.2257018 Vali Loss: 0.1809306 Test Loss: 0.2120455
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.2212781
	speed: 1.5838s/iter; left time: 7754.1214s
Epoch: 64 cost time: 105.00391149520874
Epoch: 64, Steps: 135 | Train Loss: 0.2256959 Vali Loss: 0.1807986 Test Loss: 0.2120409
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.2244094
	speed: 1.8738s/iter; left time: 8921.2908s
Epoch: 65 cost time: 110.85112190246582
Epoch: 65, Steps: 135 | Train Loss: 0.2257619 Vali Loss: 0.1807130 Test Loss: 0.2120417
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.2445851
	speed: 1.8531s/iter; left time: 8572.2424s
Epoch: 66 cost time: 108.66375064849854
Epoch: 66, Steps: 135 | Train Loss: 0.2258089 Vali Loss: 0.1806633 Test Loss: 0.2120418
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_360_j720_H8_FITS_custom_ftM_sl360_ll48_pl720_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
mse:0.2104509174823761, mae:0.29866352677345276, rse:0.4576176702976227, corr:[0.44591597 0.4489282  0.4499911  0.45029747 0.4503587  0.45036453
 0.450338   0.45025352 0.4500546  0.44994938 0.4498015  0.44972068
 0.4496309  0.449556   0.44958863 0.4495076  0.44943187 0.44943878
 0.4493616  0.44920477 0.4490516  0.44899103 0.44898808 0.44909805
 0.44924143 0.44937918 0.44947436 0.4494936  0.44941577 0.44937387
 0.44925517 0.44908118 0.44895777 0.4488354  0.44868618 0.44859263
 0.4485567  0.44853824 0.44851053 0.4484802  0.44843337 0.44840378
 0.4483519  0.44819307 0.44807956 0.44807673 0.448086   0.4481798
 0.44827467 0.44839075 0.44846407 0.44843036 0.44836506 0.44829077
 0.44821987 0.4481178  0.44802257 0.44795966 0.44786426 0.447835
 0.44783387 0.4477896  0.4477663  0.44776282 0.4477455  0.44774172
 0.44770235 0.44755417 0.4474464  0.4474452  0.44750214 0.44754928
 0.4475741  0.44766417 0.44769758 0.44766653 0.44756657 0.44745874
 0.44739372 0.4473155  0.44723782 0.4471826  0.44708952 0.44702017
 0.44701496 0.44702542 0.44701254 0.44698825 0.44699585 0.44699523
 0.44695815 0.44687057 0.44679493 0.44680727 0.4468711  0.44693446
 0.4469613  0.4470289  0.44706234 0.44701344 0.4469537  0.4469176
 0.44683865 0.44676176 0.44668528 0.44658664 0.44653898 0.44650698
 0.4464273  0.44642916 0.44644943 0.44642633 0.44642562 0.44646716
 0.44642684 0.44628784 0.4462541  0.44631562 0.4463437  0.44644165
 0.4465821  0.4466735  0.44674808 0.44676661 0.44671348 0.4467026
 0.4466842  0.44661802 0.4465471  0.44648215 0.4464372  0.4464024
 0.44640324 0.44641617 0.44636348 0.44633994 0.44635963 0.4463588
 0.4464044  0.44646657 0.4465268  0.44665372 0.44676825 0.4469789
 0.44730234 0.44751686 0.44761714 0.44762856 0.44763026 0.44763586
 0.44758675 0.44756553 0.44753695 0.44743854 0.4473511  0.44728282
 0.44725233 0.4472439  0.44726512 0.44724914 0.44723204 0.4472562
 0.44726896 0.44720873 0.4471597  0.44711402 0.44701988 0.44688272
 0.44668335 0.44659042 0.44655547 0.44643584 0.44627342 0.4461595
 0.4460432  0.44590664 0.4458034  0.44571272 0.4456015  0.445531
 0.44552067 0.4454975  0.44547987 0.44546863 0.4454452  0.4454658
 0.4454425  0.44522843 0.4450187  0.44495985 0.44496745 0.44493243
 0.4448358  0.44485188 0.44491127 0.4448981  0.44478855 0.4446917
 0.44462696 0.4445298  0.44442493 0.4443515  0.4442443  0.44416115
 0.44413757 0.444129   0.4441188  0.4440999  0.44406947 0.44407427
 0.444062   0.44387478 0.4437009  0.4436728  0.44369033 0.4437121
 0.44375545 0.4438672  0.44392863 0.44389346 0.4438003  0.4437368
 0.44369352 0.44362375 0.4435335  0.44347358 0.44345754 0.44338664
 0.44333225 0.4433438  0.44333062 0.44329393 0.4433034  0.44329914
 0.44325516 0.4430985  0.4429816  0.44294867 0.44297904 0.44302845
 0.44303805 0.44313002 0.4432106  0.44315296 0.44304797 0.4430238
 0.4429669  0.442874   0.44282612 0.44276133 0.44267035 0.4426327
 0.44261545 0.44258913 0.4425596  0.44254214 0.44252327 0.44251597
 0.44247845 0.44239128 0.4423797  0.4424149  0.44243827 0.442456
 0.44245708 0.44255358 0.44264907 0.4426147  0.44250843 0.44245058
 0.4423611  0.44227958 0.44223854 0.44216448 0.44207156 0.44201073
 0.44198126 0.44198573 0.44204357 0.44203103 0.44198954 0.44205657
 0.442033   0.4418703  0.44183502 0.44187167 0.44190902 0.44203246
 0.44221175 0.44233444 0.44238514 0.44242483 0.44241455 0.44238412
 0.44236887 0.44231662 0.4422243  0.44216573 0.442114   0.4420882
 0.44207954 0.442079   0.44208297 0.44205725 0.44204256 0.4420574
 0.44209555 0.44213974 0.44217762 0.4423143  0.44246653 0.4426305
 0.44291672 0.4431252  0.44320628 0.4432102  0.44317812 0.44315478
 0.44311455 0.44306672 0.44301036 0.44291842 0.44285983 0.44281128
 0.44274315 0.44273254 0.44278118 0.44277793 0.442794   0.44283232
 0.44281718 0.4427181  0.44257754 0.44250128 0.4424288  0.44222885
 0.44194588 0.4418722  0.44183663 0.44170997 0.44155714 0.44143268
 0.44131976 0.44117764 0.44101095 0.4408571  0.44073784 0.44068617
 0.4406626  0.44062608 0.44060808 0.44060528 0.4406124  0.4406264
 0.44061336 0.44049472 0.44036484 0.44034728 0.44034848 0.44027552
 0.44017464 0.4402349  0.4402722  0.44021213 0.44010696 0.44000274
 0.4398998  0.43978173 0.43964672 0.4395218  0.43941528 0.4393499
 0.4393184  0.439277   0.43924648 0.43926135 0.43926907 0.4392579
 0.43923938 0.43911266 0.43901116 0.4390047  0.43899962 0.43902197
 0.43906638 0.43915424 0.43921205 0.43918315 0.4391133  0.4390409
 0.4389873  0.43892813 0.43880093 0.43869644 0.43863302 0.43857294
 0.4385466  0.43852904 0.4385267  0.4385315  0.4385157  0.43853807
 0.43856955 0.43845284 0.4383327  0.43833777 0.43836638 0.43837446
 0.43841055 0.43851048 0.43855968 0.43855643 0.43851662 0.43846098
 0.43841982 0.43835574 0.43819904 0.43810102 0.43808666 0.43804243
 0.4380119  0.4380213  0.43807447 0.43807563 0.43805647 0.43808582
 0.4380758  0.43798903 0.43795517 0.43796444 0.43798885 0.43801314
 0.43802726 0.43812373 0.43819538 0.43816    0.43811446 0.4380897
 0.43801674 0.43792292 0.4378724  0.43780646 0.43774062 0.4377026
 0.4376574  0.4376563  0.43768322 0.43766177 0.43763724 0.43767405
 0.43765286 0.43756062 0.43754017 0.43757036 0.43762657 0.4377361
 0.4378593  0.43798125 0.43812364 0.43816933 0.43810856 0.43808258
 0.43807197 0.4380429  0.43800068 0.43790522 0.43782008 0.4378002
 0.43781406 0.43783668 0.43784735 0.43782535 0.43782526 0.43786
 0.43791935 0.43798324 0.43808097 0.43822977 0.43833077 0.43854064
 0.4388397  0.4390141  0.4391186  0.43917656 0.439173   0.43913507
 0.43907985 0.4390512  0.43900737 0.43891624 0.43883944 0.4388112
 0.43880293 0.43878576 0.4388309  0.43887064 0.43885478 0.43889284
 0.43892115 0.43879744 0.4386735  0.43861273 0.43851486 0.43832016
 0.43803763 0.4379344  0.43788886 0.43777895 0.43765485 0.43754455
 0.43743682 0.43730426 0.43712634 0.4369739  0.43689433 0.43686363
 0.43681943 0.4367537  0.43678012 0.4368237  0.43677756 0.43677393
 0.43676937 0.4366138  0.43645495 0.43639705 0.4363721  0.43631846
 0.43620643 0.4361822  0.436196   0.4361763  0.43608496 0.43596104
 0.4358708  0.4357616  0.4355935  0.43546146 0.4353611  0.43530226
 0.4352801  0.43527398 0.43526205 0.43523052 0.43522787 0.43525806
 0.43520603 0.4350528  0.43496802 0.43495882 0.43500784 0.4350416
 0.43500364 0.43502936 0.4350891  0.4350287  0.4349048  0.4348197
 0.4347746  0.4346892  0.43458396 0.43444675 0.43429226 0.4341818
 0.43414378 0.43411845 0.4340734  0.4339915  0.43393427 0.43384865
 0.4337099  0.43357715 0.43352652 0.4335197  0.43350127 0.43352184
 0.4335714  0.4336431  0.43369582 0.43366522 0.43359715 0.43356758
 0.43355772 0.43351123 0.43338305 0.43318954 0.4330551  0.4330385
 0.43302184 0.432962   0.4329697  0.43297598 0.43293124 0.43291518
 0.4329071  0.43283165 0.4327983  0.4328126  0.43284717 0.4329024
 0.4329257  0.43298715 0.43301937 0.4329754  0.43293825 0.43289635
 0.43280247 0.43271413 0.4326461  0.43254068 0.43243605 0.43241918
 0.43242162 0.43236816 0.43236953 0.43240616 0.43235505 0.4323722
 0.43237564 0.43226287 0.4322344  0.43228298 0.4323446  0.43247455
 0.43264797 0.43279806 0.43288246 0.43289214 0.4328723  0.43280327
 0.43274817 0.4327182  0.43264475 0.43253958 0.43243793 0.43242085
 0.4324359  0.4324228  0.4324574  0.43242994 0.43236378 0.4323781
 0.4324191  0.43250757 0.43262944 0.4327438  0.43284607 0.43305087
 0.43334877 0.43348667 0.43352365 0.43358082 0.43355644 0.43349302
 0.43346068 0.43341133 0.4333623  0.43327987 0.43318284 0.43315968
 0.43314654 0.43313235 0.43318456 0.4332011  0.43319792 0.4331985
 0.43316296 0.43308234 0.43297938 0.43292162 0.43287537 0.4326576
 0.43231028 0.43215224 0.43202093 0.43187374 0.43175513 0.43160057
 0.4272639  0.43132055 0.42698383 0.42682347 0.42669958 0.42663905
 0.42868572 0.42656675 0.4265945  0.42657745 0.42659545 0.4266237
 0.42653322 0.42634255 0.4261828  0.42614126 0.42612824 0.42610836
 0.4260407  0.42599228 0.42596042 0.42587975 0.4257475  0.4256736
 0.42554182 0.4254194  0.42528972 0.42508316 0.42501178 0.42500973
 0.4249675  0.4248874  0.4248701  0.42494616 0.4248848  0.42493847
 0.42492992 0.4247357  0.4247417  0.4247427  0.4248286  0.4246832 ]
