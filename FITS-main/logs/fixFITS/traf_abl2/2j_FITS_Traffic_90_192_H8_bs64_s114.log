Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=42, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_90_j192_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=10, pred_len=192, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_90_j192_H8_FITS_custom_ftM_sl90_ll48_pl192_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11999
val 1565
test 3317
Model(
  (freq_upsampler): Linear(in_features=42, out_features=131, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  607068672.0
params:  5633.0
Trainable parameters:  5633
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 17.497058391571045
Epoch: 1, Steps: 93 | Train Loss: 1.2776013 Vali Loss: 1.2923933 Test Loss: 1.5322645
Validation loss decreased (inf --> 1.292393).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 17.688008785247803
Epoch: 2, Steps: 93 | Train Loss: 0.7956684 Vali Loss: 0.9728506 Test Loss: 1.1530567
Validation loss decreased (1.292393 --> 0.972851).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 17.19714069366455
Epoch: 3, Steps: 93 | Train Loss: 0.5960007 Vali Loss: 0.8204279 Test Loss: 0.9732485
Validation loss decreased (0.972851 --> 0.820428).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 17.41765522956848
Epoch: 4, Steps: 93 | Train Loss: 0.4939725 Vali Loss: 0.7357969 Test Loss: 0.8753825
Validation loss decreased (0.820428 --> 0.735797).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 17.413338899612427
Epoch: 5, Steps: 93 | Train Loss: 0.4348164 Vali Loss: 0.6843204 Test Loss: 0.8162148
Validation loss decreased (0.735797 --> 0.684320).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 17.22115969657898
Epoch: 6, Steps: 93 | Train Loss: 0.3975603 Vali Loss: 0.6511095 Test Loss: 0.7779613
Validation loss decreased (0.684320 --> 0.651110).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 17.282618045806885
Epoch: 7, Steps: 93 | Train Loss: 0.3724517 Vali Loss: 0.6279032 Test Loss: 0.7513057
Validation loss decreased (0.651110 --> 0.627903).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 17.854872941970825
Epoch: 8, Steps: 93 | Train Loss: 0.3545533 Vali Loss: 0.6111934 Test Loss: 0.7319202
Validation loss decreased (0.627903 --> 0.611193).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 17.351966381072998
Epoch: 9, Steps: 93 | Train Loss: 0.3413491 Vali Loss: 0.5979443 Test Loss: 0.7171339
Validation loss decreased (0.611193 --> 0.597944).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 17.47489619255066
Epoch: 10, Steps: 93 | Train Loss: 0.3310518 Vali Loss: 0.5880380 Test Loss: 0.7056119
Validation loss decreased (0.597944 --> 0.588038).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 17.127585649490356
Epoch: 11, Steps: 93 | Train Loss: 0.3229338 Vali Loss: 0.5790672 Test Loss: 0.6960903
Validation loss decreased (0.588038 --> 0.579067).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 16.752833127975464
Epoch: 12, Steps: 93 | Train Loss: 0.3164505 Vali Loss: 0.5725467 Test Loss: 0.6883104
Validation loss decreased (0.579067 --> 0.572547).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 16.84758162498474
Epoch: 13, Steps: 93 | Train Loss: 0.3109157 Vali Loss: 0.5664030 Test Loss: 0.6816152
Validation loss decreased (0.572547 --> 0.566403).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 16.49504065513611
Epoch: 14, Steps: 93 | Train Loss: 0.3062795 Vali Loss: 0.5615869 Test Loss: 0.6760110
Validation loss decreased (0.566403 --> 0.561587).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 17.439011335372925
Epoch: 15, Steps: 93 | Train Loss: 0.3023488 Vali Loss: 0.5571656 Test Loss: 0.6709928
Validation loss decreased (0.561587 --> 0.557166).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 16.912065982818604
Epoch: 16, Steps: 93 | Train Loss: 0.2989009 Vali Loss: 0.5530154 Test Loss: 0.6666953
Validation loss decreased (0.557166 --> 0.553015).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 17.135511875152588
Epoch: 17, Steps: 93 | Train Loss: 0.2960030 Vali Loss: 0.5500635 Test Loss: 0.6628878
Validation loss decreased (0.553015 --> 0.550063).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 16.64783525466919
Epoch: 18, Steps: 93 | Train Loss: 0.2932902 Vali Loss: 0.5467197 Test Loss: 0.6595832
Validation loss decreased (0.550063 --> 0.546720).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 17.845337867736816
Epoch: 19, Steps: 93 | Train Loss: 0.2909743 Vali Loss: 0.5445333 Test Loss: 0.6566325
Validation loss decreased (0.546720 --> 0.544533).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 17.294738292694092
Epoch: 20, Steps: 93 | Train Loss: 0.2890766 Vali Loss: 0.5414901 Test Loss: 0.6539825
Validation loss decreased (0.544533 --> 0.541490).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 17.852571964263916
Epoch: 21, Steps: 93 | Train Loss: 0.2872359 Vali Loss: 0.5395306 Test Loss: 0.6516050
Validation loss decreased (0.541490 --> 0.539531).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 17.601487398147583
Epoch: 22, Steps: 93 | Train Loss: 0.2855860 Vali Loss: 0.5375918 Test Loss: 0.6495389
Validation loss decreased (0.539531 --> 0.537592).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 17.493664264678955
Epoch: 23, Steps: 93 | Train Loss: 0.2841489 Vali Loss: 0.5361368 Test Loss: 0.6476735
Validation loss decreased (0.537592 --> 0.536137).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 17.228974103927612
Epoch: 24, Steps: 93 | Train Loss: 0.2828625 Vali Loss: 0.5350068 Test Loss: 0.6459246
Validation loss decreased (0.536137 --> 0.535007).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 17.737574815750122
Epoch: 25, Steps: 93 | Train Loss: 0.2816549 Vali Loss: 0.5329472 Test Loss: 0.6443701
Validation loss decreased (0.535007 --> 0.532947).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 17.387040615081787
Epoch: 26, Steps: 93 | Train Loss: 0.2806058 Vali Loss: 0.5320683 Test Loss: 0.6429830
Validation loss decreased (0.532947 --> 0.532068).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 16.969378232955933
Epoch: 27, Steps: 93 | Train Loss: 0.2796276 Vali Loss: 0.5311983 Test Loss: 0.6416957
Validation loss decreased (0.532068 --> 0.531198).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 17.082012176513672
Epoch: 28, Steps: 93 | Train Loss: 0.2788036 Vali Loss: 0.5300429 Test Loss: 0.6405536
Validation loss decreased (0.531198 --> 0.530043).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 16.91490936279297
Epoch: 29, Steps: 93 | Train Loss: 0.2779430 Vali Loss: 0.5282960 Test Loss: 0.6394923
Validation loss decreased (0.530043 --> 0.528296).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 17.44857883453369
Epoch: 30, Steps: 93 | Train Loss: 0.2771793 Vali Loss: 0.5278863 Test Loss: 0.6384639
Validation loss decreased (0.528296 --> 0.527886).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 16.912954092025757
Epoch: 31, Steps: 93 | Train Loss: 0.2765900 Vali Loss: 0.5264407 Test Loss: 0.6375829
Validation loss decreased (0.527886 --> 0.526441).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 17.19716763496399
Epoch: 32, Steps: 93 | Train Loss: 0.2758934 Vali Loss: 0.5262982 Test Loss: 0.6367172
Validation loss decreased (0.526441 --> 0.526298).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 17.440486192703247
Epoch: 33, Steps: 93 | Train Loss: 0.2752873 Vali Loss: 0.5244313 Test Loss: 0.6360060
Validation loss decreased (0.526298 --> 0.524431).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 17.378469944000244
Epoch: 34, Steps: 93 | Train Loss: 0.2748387 Vali Loss: 0.5253122 Test Loss: 0.6352301
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 17.295016288757324
Epoch: 35, Steps: 93 | Train Loss: 0.2742996 Vali Loss: 0.5240312 Test Loss: 0.6345974
Validation loss decreased (0.524431 --> 0.524031).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 17.443468809127808
Epoch: 36, Steps: 93 | Train Loss: 0.2738228 Vali Loss: 0.5234932 Test Loss: 0.6339874
Validation loss decreased (0.524031 --> 0.523493).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 17.321364879608154
Epoch: 37, Steps: 93 | Train Loss: 0.2734699 Vali Loss: 0.5232781 Test Loss: 0.6334444
Validation loss decreased (0.523493 --> 0.523278).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 16.922974348068237
Epoch: 38, Steps: 93 | Train Loss: 0.2730786 Vali Loss: 0.5221735 Test Loss: 0.6329159
Validation loss decreased (0.523278 --> 0.522173).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 16.785459518432617
Epoch: 39, Steps: 93 | Train Loss: 0.2726514 Vali Loss: 0.5220905 Test Loss: 0.6324196
Validation loss decreased (0.522173 --> 0.522090).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 17.688045263290405
Epoch: 40, Steps: 93 | Train Loss: 0.2723881 Vali Loss: 0.5213528 Test Loss: 0.6319523
Validation loss decreased (0.522090 --> 0.521353).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 17.2204909324646
Epoch: 41, Steps: 93 | Train Loss: 0.2720067 Vali Loss: 0.5211596 Test Loss: 0.6315306
Validation loss decreased (0.521353 --> 0.521160).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 17.178704500198364
Epoch: 42, Steps: 93 | Train Loss: 0.2717069 Vali Loss: 0.5206879 Test Loss: 0.6311163
Validation loss decreased (0.521160 --> 0.520688).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 17.330251693725586
Epoch: 43, Steps: 93 | Train Loss: 0.2714864 Vali Loss: 0.5207959 Test Loss: 0.6307417
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 17.368430137634277
Epoch: 44, Steps: 93 | Train Loss: 0.2711457 Vali Loss: 0.5209649 Test Loss: 0.6303829
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 17.165810346603394
Epoch: 45, Steps: 93 | Train Loss: 0.2709293 Vali Loss: 0.5203558 Test Loss: 0.6300669
Validation loss decreased (0.520688 --> 0.520356).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 17.17724347114563
Epoch: 46, Steps: 93 | Train Loss: 0.2707041 Vali Loss: 0.5192990 Test Loss: 0.6297503
Validation loss decreased (0.520356 --> 0.519299).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 17.583415269851685
Epoch: 47, Steps: 93 | Train Loss: 0.2705146 Vali Loss: 0.5199316 Test Loss: 0.6294595
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 16.888497352600098
Epoch: 48, Steps: 93 | Train Loss: 0.2702831 Vali Loss: 0.5190873 Test Loss: 0.6291670
Validation loss decreased (0.519299 --> 0.519087).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 17.47776484489441
Epoch: 49, Steps: 93 | Train Loss: 0.2700280 Vali Loss: 0.5182585 Test Loss: 0.6289090
Validation loss decreased (0.519087 --> 0.518259).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 17.969658851623535
Epoch: 50, Steps: 93 | Train Loss: 0.2698266 Vali Loss: 0.5181416 Test Loss: 0.6286646
Validation loss decreased (0.518259 --> 0.518142).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 15.323856115341187
Epoch: 51, Steps: 93 | Train Loss: 0.2697755 Vali Loss: 0.5184416 Test Loss: 0.6284314
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 18.840185403823853
Epoch: 52, Steps: 93 | Train Loss: 0.2695551 Vali Loss: 0.5183634 Test Loss: 0.6282365
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 18.72939109802246
Epoch: 53, Steps: 93 | Train Loss: 0.2693942 Vali Loss: 0.5175845 Test Loss: 0.6280125
Validation loss decreased (0.518142 --> 0.517585).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 19.031816482543945
Epoch: 54, Steps: 93 | Train Loss: 0.2692682 Vali Loss: 0.5165524 Test Loss: 0.6278045
Validation loss decreased (0.517585 --> 0.516552).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 19.223989725112915
Epoch: 55, Steps: 93 | Train Loss: 0.2690948 Vali Loss: 0.5167030 Test Loss: 0.6276124
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 18.486067056655884
Epoch: 56, Steps: 93 | Train Loss: 0.2690025 Vali Loss: 0.5169531 Test Loss: 0.6274633
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 18.937666416168213
Epoch: 57, Steps: 93 | Train Loss: 0.2687891 Vali Loss: 0.5171893 Test Loss: 0.6272865
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 19.218529224395752
Epoch: 58, Steps: 93 | Train Loss: 0.2686652 Vali Loss: 0.5166292 Test Loss: 0.6271517
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 18.75468611717224
Epoch: 59, Steps: 93 | Train Loss: 0.2686160 Vali Loss: 0.5172781 Test Loss: 0.6270043
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 19.392549991607666
Epoch: 60, Steps: 93 | Train Loss: 0.2684152 Vali Loss: 0.5160279 Test Loss: 0.6268755
Validation loss decreased (0.516552 --> 0.516028).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 19.32008171081543
Epoch: 61, Steps: 93 | Train Loss: 0.2683281 Vali Loss: 0.5170046 Test Loss: 0.6267405
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 18.659193754196167
Epoch: 62, Steps: 93 | Train Loss: 0.2682668 Vali Loss: 0.5162579 Test Loss: 0.6266140
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 18.47927212715149
Epoch: 63, Steps: 93 | Train Loss: 0.2682232 Vali Loss: 0.5160034 Test Loss: 0.6264881
Validation loss decreased (0.516028 --> 0.516003).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 18.258920431137085
Epoch: 64, Steps: 93 | Train Loss: 0.2681816 Vali Loss: 0.5159690 Test Loss: 0.6263720
Validation loss decreased (0.516003 --> 0.515969).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 17.99668288230896
Epoch: 65, Steps: 93 | Train Loss: 0.2680618 Vali Loss: 0.5157393 Test Loss: 0.6262761
Validation loss decreased (0.515969 --> 0.515739).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 17.59873127937317
Epoch: 66, Steps: 93 | Train Loss: 0.2679829 Vali Loss: 0.5156403 Test Loss: 0.6261812
Validation loss decreased (0.515739 --> 0.515640).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 17.139841556549072
Epoch: 67, Steps: 93 | Train Loss: 0.2679597 Vali Loss: 0.5159799 Test Loss: 0.6260757
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 18.217232942581177
Epoch: 68, Steps: 93 | Train Loss: 0.2679267 Vali Loss: 0.5149388 Test Loss: 0.6259772
Validation loss decreased (0.515640 --> 0.514939).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 17.43061137199402
Epoch: 69, Steps: 93 | Train Loss: 0.2677612 Vali Loss: 0.5162143 Test Loss: 0.6258978
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 17.757656574249268
Epoch: 70, Steps: 93 | Train Loss: 0.2677224 Vali Loss: 0.5151549 Test Loss: 0.6258228
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 18.215872526168823
Epoch: 71, Steps: 93 | Train Loss: 0.2675754 Vali Loss: 0.5156585 Test Loss: 0.6257549
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 17.5144202709198
Epoch: 72, Steps: 93 | Train Loss: 0.2675835 Vali Loss: 0.5160761 Test Loss: 0.6256757
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 18.04127025604248
Epoch: 73, Steps: 93 | Train Loss: 0.2675004 Vali Loss: 0.5155813 Test Loss: 0.6256140
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 17.676008939743042
Epoch: 74, Steps: 93 | Train Loss: 0.2674945 Vali Loss: 0.5150555 Test Loss: 0.6255459
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 17.704941034317017
Epoch: 75, Steps: 93 | Train Loss: 0.2673899 Vali Loss: 0.5155757 Test Loss: 0.6254877
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 18.096758365631104
Epoch: 76, Steps: 93 | Train Loss: 0.2673420 Vali Loss: 0.5153705 Test Loss: 0.6254295
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 17.2697274684906
Epoch: 77, Steps: 93 | Train Loss: 0.2672984 Vali Loss: 0.5152743 Test Loss: 0.6253833
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 18.262715339660645
Epoch: 78, Steps: 93 | Train Loss: 0.2672860 Vali Loss: 0.5151566 Test Loss: 0.6253235
EarlyStopping counter: 10 out of 10
Early stopping
train 11999
val 1565
test 3317
Model(
  (freq_upsampler): Linear(in_features=42, out_features=131, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  607068672.0
params:  5633.0
Trainable parameters:  5633
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 17.749932527542114
Epoch: 1, Steps: 93 | Train Loss: 0.3857111 Vali Loss: 0.5104851 Test Loss: 0.6213445
Validation loss decreased (inf --> 0.510485).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 17.6841082572937
Epoch: 2, Steps: 93 | Train Loss: 0.3835194 Vali Loss: 0.5101778 Test Loss: 0.6211013
Validation loss decreased (0.510485 --> 0.510178).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 18.22091579437256
Epoch: 3, Steps: 93 | Train Loss: 0.3831467 Vali Loss: 0.5084499 Test Loss: 0.6202081
Validation loss decreased (0.510178 --> 0.508450).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 18.14345908164978
Epoch: 4, Steps: 93 | Train Loss: 0.3830700 Vali Loss: 0.5083790 Test Loss: 0.6202267
Validation loss decreased (0.508450 --> 0.508379).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 17.70772385597229
Epoch: 5, Steps: 93 | Train Loss: 0.3829570 Vali Loss: 0.5091622 Test Loss: 0.6204668
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 17.31890034675598
Epoch: 6, Steps: 93 | Train Loss: 0.3830073 Vali Loss: 0.5089464 Test Loss: 0.6204981
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 17.6883487701416
Epoch: 7, Steps: 93 | Train Loss: 0.3829517 Vali Loss: 0.5086237 Test Loss: 0.6204143
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 17.232046127319336
Epoch: 8, Steps: 93 | Train Loss: 0.3830250 Vali Loss: 0.5088674 Test Loss: 0.6201120
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 17.792638063430786
Epoch: 9, Steps: 93 | Train Loss: 0.3829209 Vali Loss: 0.5089216 Test Loss: 0.6201487
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 17.5072124004364
Epoch: 10, Steps: 93 | Train Loss: 0.3830497 Vali Loss: 0.5092721 Test Loss: 0.6203718
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 17.839975595474243
Epoch: 11, Steps: 93 | Train Loss: 0.3827314 Vali Loss: 0.5089960 Test Loss: 0.6202945
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 17.891384840011597
Epoch: 12, Steps: 93 | Train Loss: 0.3827889 Vali Loss: 0.5087871 Test Loss: 0.6201810
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 17.51051425933838
Epoch: 13, Steps: 93 | Train Loss: 0.3828228 Vali Loss: 0.5082232 Test Loss: 0.6202374
Validation loss decreased (0.508379 --> 0.508223).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 17.03020191192627
Epoch: 14, Steps: 93 | Train Loss: 0.3828510 Vali Loss: 0.5085893 Test Loss: 0.6201597
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 17.060815811157227
Epoch: 15, Steps: 93 | Train Loss: 0.3827977 Vali Loss: 0.5079595 Test Loss: 0.6201963
Validation loss decreased (0.508223 --> 0.507959).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 16.979925870895386
Epoch: 16, Steps: 93 | Train Loss: 0.3829008 Vali Loss: 0.5096740 Test Loss: 0.6200891
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 16.994571685791016
Epoch: 17, Steps: 93 | Train Loss: 0.3827813 Vali Loss: 0.5087994 Test Loss: 0.6202548
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 17.524869203567505
Epoch: 18, Steps: 93 | Train Loss: 0.3827900 Vali Loss: 0.5088153 Test Loss: 0.6201202
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 17.106881618499756
Epoch: 19, Steps: 93 | Train Loss: 0.3827375 Vali Loss: 0.5086601 Test Loss: 0.6201472
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 17.033915996551514
Epoch: 20, Steps: 93 | Train Loss: 0.3827023 Vali Loss: 0.5088887 Test Loss: 0.6199833
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 17.44567060470581
Epoch: 21, Steps: 93 | Train Loss: 0.3828088 Vali Loss: 0.5085225 Test Loss: 0.6201003
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 17.063315391540527
Epoch: 22, Steps: 93 | Train Loss: 0.3826968 Vali Loss: 0.5090815 Test Loss: 0.6203262
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 17.22247338294983
Epoch: 23, Steps: 93 | Train Loss: 0.3826006 Vali Loss: 0.5088228 Test Loss: 0.6200241
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 17.569465160369873
Epoch: 24, Steps: 93 | Train Loss: 0.3827501 Vali Loss: 0.5090699 Test Loss: 0.6200029
EarlyStopping counter: 9 out of 10
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 17.163317441940308
Epoch: 25, Steps: 93 | Train Loss: 0.3828291 Vali Loss: 0.5091426 Test Loss: 0.6200498
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : Traffic_90_j192_H8_FITS_custom_ftM_sl90_ll48_pl192_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3317
mse:0.620002806186676, mae:0.3732178509235382, rse:0.6498690247535706, corr:[0.2648927  0.2844659  0.2847777  0.283348   0.28308326 0.28404263
 0.28590044 0.28646055 0.28546652 0.28533247 0.2846342  0.2840315
 0.28356287 0.28313982 0.2833878  0.28338438 0.28430703 0.28547552
 0.28665376 0.2879968  0.28994125 0.2904286  0.2904742  0.29038712
 0.29466867 0.2983956  0.29746923 0.29587603 0.29638067 0.2980135
 0.29928195 0.30044866 0.30049467 0.30006376 0.29978934 0.29936165
 0.2990603  0.29841995 0.29807958 0.2980377  0.29863295 0.299563
 0.3001046  0.3000522  0.30063656 0.30047715 0.3004472  0.29902765
 0.2984867  0.29712996 0.29559255 0.29519942 0.29329872 0.28917477
 0.2872714  0.2881409  0.28875074 0.28807366 0.28672823 0.28618756
 0.2855516  0.284891   0.2843706  0.28451848 0.2848465  0.28572506
 0.2862876  0.28629547 0.2861972  0.2862441  0.28583428 0.2839277
 0.28156832 0.2800255  0.27970484 0.2806307  0.28188834 0.28193554
 0.28295523 0.28489164 0.28536814 0.2855272  0.28450528 0.2831126
 0.2817799  0.28099802 0.28047743 0.28012356 0.27994508 0.28036928
 0.28043744 0.28098097 0.28111452 0.28181535 0.282076   0.28167656
 0.2813307  0.2811434  0.2810578  0.2807504  0.28080934 0.28146234
 0.28272724 0.2840327  0.2832747  0.28328773 0.28271824 0.2817781
 0.2811157  0.28062427 0.28049105 0.2805689  0.28054142 0.28110665
 0.2813329  0.2817559  0.281869   0.28219715 0.28334033 0.28326285
 0.28313696 0.28321868 0.28351822 0.2834362  0.28315705 0.28316975
 0.28346032 0.28323692 0.2817588  0.2818053  0.28179377 0.28114524
 0.28069127 0.27997342 0.28010926 0.2807434  0.28129038 0.28172588
 0.2823917  0.28280106 0.28303137 0.2835449  0.28410614 0.282767
 0.28162852 0.28129336 0.2815859  0.281811   0.28179848 0.28184947
 0.2824675  0.2825781  0.28202608 0.2817749  0.2813064  0.28090286
 0.28059825 0.28052658 0.2810217  0.2811732  0.2822856  0.2829416
 0.28380486 0.28462663 0.28619185 0.28662068 0.28575143 0.284225
 0.28336447 0.2823921  0.28060383 0.2793123  0.2799299  0.28150874
 0.28435585 0.28622082 0.28639886 0.28705865 0.28764775 0.2877549
 0.2873486  0.2863471  0.2859461  0.28540957 0.2852515  0.28516582
 0.28448778 0.2845803  0.2848663  0.28533974 0.28457695 0.28421202]
