Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=138, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_360_j192_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=10, pred_len=192, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_360_j192_H8_FITS_custom_ftM_sl360_ll48_pl192_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11729
val 1565
test 3317
Model(
  (freq_upsampler): Linear(in_features=138, out_features=211, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3212763648.0
params:  29329.0
Trainable parameters:  29329
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 68.83559226989746
Epoch: 1, Steps: 91 | Train Loss: 1.1325283 Vali Loss: 1.1861151 Test Loss: 1.3883712
Validation loss decreased (inf --> 1.186115).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 73.75607013702393
Epoch: 2, Steps: 91 | Train Loss: 0.8285221 Vali Loss: 1.0210266 Test Loss: 1.1947682
Validation loss decreased (1.186115 --> 1.021027).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 75.61163401603699
Epoch: 3, Steps: 91 | Train Loss: 0.7128649 Vali Loss: 0.9422712 Test Loss: 1.1039728
Validation loss decreased (1.021027 --> 0.942271).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 70.80843615531921
Epoch: 4, Steps: 91 | Train Loss: 0.6412071 Vali Loss: 0.8872945 Test Loss: 1.0403818
Validation loss decreased (0.942271 --> 0.887294).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 72.72557163238525
Epoch: 5, Steps: 91 | Train Loss: 0.5845315 Vali Loss: 0.8381528 Test Loss: 0.9841190
Validation loss decreased (0.887294 --> 0.838153).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 68.45213651657104
Epoch: 6, Steps: 91 | Train Loss: 0.5367217 Vali Loss: 0.7954745 Test Loss: 0.9350072
Validation loss decreased (0.838153 --> 0.795474).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 64.04321932792664
Epoch: 7, Steps: 91 | Train Loss: 0.4957089 Vali Loss: 0.7590837 Test Loss: 0.8926278
Validation loss decreased (0.795474 --> 0.759084).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 64.50052213668823
Epoch: 8, Steps: 91 | Train Loss: 0.4599341 Vali Loss: 0.7232108 Test Loss: 0.8518057
Validation loss decreased (0.759084 --> 0.723211).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 65.57780289649963
Epoch: 9, Steps: 91 | Train Loss: 0.4287268 Vali Loss: 0.6930731 Test Loss: 0.8163357
Validation loss decreased (0.723211 --> 0.693073).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 66.15797185897827
Epoch: 10, Steps: 91 | Train Loss: 0.4011473 Vali Loss: 0.6669714 Test Loss: 0.7867432
Validation loss decreased (0.693073 --> 0.666971).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 66.54071950912476
Epoch: 11, Steps: 91 | Train Loss: 0.3768052 Vali Loss: 0.6416457 Test Loss: 0.7578126
Validation loss decreased (0.666971 --> 0.641646).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 70.21541047096252
Epoch: 12, Steps: 91 | Train Loss: 0.3550908 Vali Loss: 0.6208271 Test Loss: 0.7338247
Validation loss decreased (0.641646 --> 0.620827).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 71.31816697120667
Epoch: 13, Steps: 91 | Train Loss: 0.3357674 Vali Loss: 0.5986189 Test Loss: 0.7078561
Validation loss decreased (0.620827 --> 0.598619).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 66.98455286026001
Epoch: 14, Steps: 91 | Train Loss: 0.3183915 Vali Loss: 0.5824569 Test Loss: 0.6893606
Validation loss decreased (0.598619 --> 0.582457).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 71.78048610687256
Epoch: 15, Steps: 91 | Train Loss: 0.3028541 Vali Loss: 0.5655236 Test Loss: 0.6704716
Validation loss decreased (0.582457 --> 0.565524).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 70.99638056755066
Epoch: 16, Steps: 91 | Train Loss: 0.2887764 Vali Loss: 0.5500925 Test Loss: 0.6526256
Validation loss decreased (0.565524 --> 0.550093).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 68.20660591125488
Epoch: 17, Steps: 91 | Train Loss: 0.2760856 Vali Loss: 0.5376118 Test Loss: 0.6379274
Validation loss decreased (0.550093 --> 0.537612).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 66.96420454978943
Epoch: 18, Steps: 91 | Train Loss: 0.2645145 Vali Loss: 0.5255550 Test Loss: 0.6242256
Validation loss decreased (0.537612 --> 0.525555).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 68.56057858467102
Epoch: 19, Steps: 91 | Train Loss: 0.2541082 Vali Loss: 0.5137975 Test Loss: 0.6112357
Validation loss decreased (0.525555 --> 0.513797).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 61.586352825164795
Epoch: 20, Steps: 91 | Train Loss: 0.2445706 Vali Loss: 0.5048139 Test Loss: 0.6009525
Validation loss decreased (0.513797 --> 0.504814).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 65.61093735694885
Epoch: 21, Steps: 91 | Train Loss: 0.2358639 Vali Loss: 0.4939822 Test Loss: 0.5889965
Validation loss decreased (0.504814 --> 0.493982).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 66.84433722496033
Epoch: 22, Steps: 91 | Train Loss: 0.2279454 Vali Loss: 0.4861512 Test Loss: 0.5799316
Validation loss decreased (0.493982 --> 0.486151).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 67.28544354438782
Epoch: 23, Steps: 91 | Train Loss: 0.2206907 Vali Loss: 0.4791411 Test Loss: 0.5708836
Validation loss decreased (0.486151 --> 0.479141).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 65.17573475837708
Epoch: 24, Steps: 91 | Train Loss: 0.2139590 Vali Loss: 0.4709264 Test Loss: 0.5624033
Validation loss decreased (0.479141 --> 0.470926).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 65.37988686561584
Epoch: 25, Steps: 91 | Train Loss: 0.2078595 Vali Loss: 0.4645462 Test Loss: 0.5552759
Validation loss decreased (0.470926 --> 0.464546).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 67.1496753692627
Epoch: 26, Steps: 91 | Train Loss: 0.2022022 Vali Loss: 0.4586650 Test Loss: 0.5483703
Validation loss decreased (0.464546 --> 0.458665).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 62.855793952941895
Epoch: 27, Steps: 91 | Train Loss: 0.1969752 Vali Loss: 0.4523971 Test Loss: 0.5410777
Validation loss decreased (0.458665 --> 0.452397).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 63.506311893463135
Epoch: 28, Steps: 91 | Train Loss: 0.1921779 Vali Loss: 0.4478519 Test Loss: 0.5358187
Validation loss decreased (0.452397 --> 0.447852).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 60.54017114639282
Epoch: 29, Steps: 91 | Train Loss: 0.1877136 Vali Loss: 0.4433462 Test Loss: 0.5306870
Validation loss decreased (0.447852 --> 0.443346).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 62.60564136505127
Epoch: 30, Steps: 91 | Train Loss: 0.1835857 Vali Loss: 0.4378060 Test Loss: 0.5249327
Validation loss decreased (0.443346 --> 0.437806).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 65.94434881210327
Epoch: 31, Steps: 91 | Train Loss: 0.1797501 Vali Loss: 0.4337889 Test Loss: 0.5204601
Validation loss decreased (0.437806 --> 0.433789).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 63.14783692359924
Epoch: 32, Steps: 91 | Train Loss: 0.1761943 Vali Loss: 0.4301047 Test Loss: 0.5161299
Validation loss decreased (0.433789 --> 0.430105).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 63.89026999473572
Epoch: 33, Steps: 91 | Train Loss: 0.1729052 Vali Loss: 0.4262975 Test Loss: 0.5121065
Validation loss decreased (0.430105 --> 0.426298).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 63.763325929641724
Epoch: 34, Steps: 91 | Train Loss: 0.1698079 Vali Loss: 0.4231853 Test Loss: 0.5084241
Validation loss decreased (0.426298 --> 0.423185).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 62.47699809074402
Epoch: 35, Steps: 91 | Train Loss: 0.1669111 Vali Loss: 0.4197914 Test Loss: 0.5050654
Validation loss decreased (0.423185 --> 0.419791).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 62.41664147377014
Epoch: 36, Steps: 91 | Train Loss: 0.1642665 Vali Loss: 0.4174917 Test Loss: 0.5016278
Validation loss decreased (0.419791 --> 0.417492).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 62.895742416381836
Epoch: 37, Steps: 91 | Train Loss: 0.1617657 Vali Loss: 0.4141825 Test Loss: 0.4984455
Validation loss decreased (0.417492 --> 0.414183).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 62.72337198257446
Epoch: 38, Steps: 91 | Train Loss: 0.1594728 Vali Loss: 0.4115773 Test Loss: 0.4956086
Validation loss decreased (0.414183 --> 0.411577).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 65.5331244468689
Epoch: 39, Steps: 91 | Train Loss: 0.1572638 Vali Loss: 0.4096391 Test Loss: 0.4931492
Validation loss decreased (0.411577 --> 0.409639).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 61.0145046710968
Epoch: 40, Steps: 91 | Train Loss: 0.1552346 Vali Loss: 0.4069281 Test Loss: 0.4906244
Validation loss decreased (0.409639 --> 0.406928).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 61.15721774101257
Epoch: 41, Steps: 91 | Train Loss: 0.1533031 Vali Loss: 0.4050185 Test Loss: 0.4883633
Validation loss decreased (0.406928 --> 0.405018).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 60.61641001701355
Epoch: 42, Steps: 91 | Train Loss: 0.1514947 Vali Loss: 0.4033781 Test Loss: 0.4862867
Validation loss decreased (0.405018 --> 0.403378).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 60.2423210144043
Epoch: 43, Steps: 91 | Train Loss: 0.1498344 Vali Loss: 0.4012341 Test Loss: 0.4840198
Validation loss decreased (0.403378 --> 0.401234).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 59.608452558517456
Epoch: 44, Steps: 91 | Train Loss: 0.1482391 Vali Loss: 0.3992435 Test Loss: 0.4822859
Validation loss decreased (0.401234 --> 0.399244).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 60.85175323486328
Epoch: 45, Steps: 91 | Train Loss: 0.1467333 Vali Loss: 0.3979223 Test Loss: 0.4803407
Validation loss decreased (0.399244 --> 0.397922).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 59.30859661102295
Epoch: 46, Steps: 91 | Train Loss: 0.1453470 Vali Loss: 0.3960063 Test Loss: 0.4786673
Validation loss decreased (0.397922 --> 0.396006).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 56.03714108467102
Epoch: 47, Steps: 91 | Train Loss: 0.1440332 Vali Loss: 0.3947612 Test Loss: 0.4771190
Validation loss decreased (0.396006 --> 0.394761).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 55.866790533065796
Epoch: 48, Steps: 91 | Train Loss: 0.1427951 Vali Loss: 0.3934467 Test Loss: 0.4755428
Validation loss decreased (0.394761 --> 0.393447).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 57.02606749534607
Epoch: 49, Steps: 91 | Train Loss: 0.1416406 Vali Loss: 0.3921509 Test Loss: 0.4741023
Validation loss decreased (0.393447 --> 0.392151).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 54.89125943183899
Epoch: 50, Steps: 91 | Train Loss: 0.1405043 Vali Loss: 0.3914379 Test Loss: 0.4729691
Validation loss decreased (0.392151 --> 0.391438).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 49.30018067359924
Epoch: 51, Steps: 91 | Train Loss: 0.1394452 Vali Loss: 0.3905456 Test Loss: 0.4715947
Validation loss decreased (0.391438 --> 0.390546).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 81.88455271720886
Epoch: 52, Steps: 91 | Train Loss: 0.1385112 Vali Loss: 0.3889387 Test Loss: 0.4705627
Validation loss decreased (0.390546 --> 0.388939).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 78.89626860618591
Epoch: 53, Steps: 91 | Train Loss: 0.1375609 Vali Loss: 0.3876896 Test Loss: 0.4693617
Validation loss decreased (0.388939 --> 0.387690).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 77.95574069023132
Epoch: 54, Steps: 91 | Train Loss: 0.1366721 Vali Loss: 0.3868171 Test Loss: 0.4683892
Validation loss decreased (0.387690 --> 0.386817).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 79.8548367023468
Epoch: 55, Steps: 91 | Train Loss: 0.1358523 Vali Loss: 0.3854670 Test Loss: 0.4673609
Validation loss decreased (0.386817 --> 0.385467).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 90.27775740623474
Epoch: 56, Steps: 91 | Train Loss: 0.1350828 Vali Loss: 0.3846699 Test Loss: 0.4664888
Validation loss decreased (0.385467 --> 0.384670).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 79.40964150428772
Epoch: 57, Steps: 91 | Train Loss: 0.1343379 Vali Loss: 0.3841375 Test Loss: 0.4656121
Validation loss decreased (0.384670 --> 0.384138).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 79.67506527900696
Epoch: 58, Steps: 91 | Train Loss: 0.1336404 Vali Loss: 0.3835418 Test Loss: 0.4647777
Validation loss decreased (0.384138 --> 0.383542).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 78.67318987846375
Epoch: 59, Steps: 91 | Train Loss: 0.1329645 Vali Loss: 0.3830974 Test Loss: 0.4640161
Validation loss decreased (0.383542 --> 0.383097).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 88.99080729484558
Epoch: 60, Steps: 91 | Train Loss: 0.1323577 Vali Loss: 0.3825126 Test Loss: 0.4632550
Validation loss decreased (0.383097 --> 0.382513).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 83.53893876075745
Epoch: 61, Steps: 91 | Train Loss: 0.1317763 Vali Loss: 0.3816029 Test Loss: 0.4625421
Validation loss decreased (0.382513 --> 0.381603).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 80.34147262573242
Epoch: 62, Steps: 91 | Train Loss: 0.1312181 Vali Loss: 0.3810840 Test Loss: 0.4619472
Validation loss decreased (0.381603 --> 0.381084).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 82.69237995147705
Epoch: 63, Steps: 91 | Train Loss: 0.1306706 Vali Loss: 0.3804184 Test Loss: 0.4612544
Validation loss decreased (0.381084 --> 0.380418).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 81.11347723007202
Epoch: 64, Steps: 91 | Train Loss: 0.1301798 Vali Loss: 0.3798892 Test Loss: 0.4606549
Validation loss decreased (0.380418 --> 0.379889).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 85.04566049575806
Epoch: 65, Steps: 91 | Train Loss: 0.1296899 Vali Loss: 0.3793319 Test Loss: 0.4600922
Validation loss decreased (0.379889 --> 0.379332).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 82.26216125488281
Epoch: 66, Steps: 91 | Train Loss: 0.1292433 Vali Loss: 0.3786859 Test Loss: 0.4595867
Validation loss decreased (0.379332 --> 0.378686).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 78.7249014377594
Epoch: 67, Steps: 91 | Train Loss: 0.1287780 Vali Loss: 0.3781815 Test Loss: 0.4590639
Validation loss decreased (0.378686 --> 0.378181).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 79.9719467163086
Epoch: 68, Steps: 91 | Train Loss: 0.1284069 Vali Loss: 0.3777345 Test Loss: 0.4585733
Validation loss decreased (0.378181 --> 0.377735).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 87.84767603874207
Epoch: 69, Steps: 91 | Train Loss: 0.1279879 Vali Loss: 0.3770136 Test Loss: 0.4581047
Validation loss decreased (0.377735 --> 0.377014).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 99.33487248420715
Epoch: 70, Steps: 91 | Train Loss: 0.1276787 Vali Loss: 0.3771892 Test Loss: 0.4577358
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 83.74763298034668
Epoch: 71, Steps: 91 | Train Loss: 0.1272732 Vali Loss: 0.3766658 Test Loss: 0.4572873
Validation loss decreased (0.377014 --> 0.376666).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 82.72374987602234
Epoch: 72, Steps: 91 | Train Loss: 0.1269321 Vali Loss: 0.3763374 Test Loss: 0.4569283
Validation loss decreased (0.376666 --> 0.376337).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 119.21977519989014
Epoch: 73, Steps: 91 | Train Loss: 0.1266137 Vali Loss: 0.3760941 Test Loss: 0.4565821
Validation loss decreased (0.376337 --> 0.376094).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 82.78194212913513
Epoch: 74, Steps: 91 | Train Loss: 0.1263361 Vali Loss: 0.3755727 Test Loss: 0.4562074
Validation loss decreased (0.376094 --> 0.375573).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 86.31663537025452
Epoch: 75, Steps: 91 | Train Loss: 0.1260428 Vali Loss: 0.3752595 Test Loss: 0.4558554
Validation loss decreased (0.375573 --> 0.375260).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 88.48832082748413
Epoch: 76, Steps: 91 | Train Loss: 0.1257674 Vali Loss: 0.3747469 Test Loss: 0.4555496
Validation loss decreased (0.375260 --> 0.374747).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 88.39334297180176
Epoch: 77, Steps: 91 | Train Loss: 0.1255408 Vali Loss: 0.3742280 Test Loss: 0.4552660
Validation loss decreased (0.374747 --> 0.374228).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 86.02043557167053
Epoch: 78, Steps: 91 | Train Loss: 0.1253300 Vali Loss: 0.3742899 Test Loss: 0.4549767
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 88.12022709846497
Epoch: 79, Steps: 91 | Train Loss: 0.1250615 Vali Loss: 0.3741468 Test Loss: 0.4546962
Validation loss decreased (0.374228 --> 0.374147).  Saving model ...
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 87.68182277679443
Epoch: 80, Steps: 91 | Train Loss: 0.1248426 Vali Loss: 0.3734930 Test Loss: 0.4544573
Validation loss decreased (0.374147 --> 0.373493).  Saving model ...
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 82.55320763587952
Epoch: 81, Steps: 91 | Train Loss: 0.1246476 Vali Loss: 0.3738765 Test Loss: 0.4542201
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 103.98339867591858
Epoch: 82, Steps: 91 | Train Loss: 0.1244674 Vali Loss: 0.3734151 Test Loss: 0.4539905
Validation loss decreased (0.373493 --> 0.373415).  Saving model ...
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 84.4194564819336
Epoch: 83, Steps: 91 | Train Loss: 0.1242531 Vali Loss: 0.3733646 Test Loss: 0.4537719
Validation loss decreased (0.373415 --> 0.373365).  Saving model ...
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 88.20036172866821
Epoch: 84, Steps: 91 | Train Loss: 0.1240734 Vali Loss: 0.3727461 Test Loss: 0.4535637
Validation loss decreased (0.373365 --> 0.372746).  Saving model ...
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 86.11063981056213
Epoch: 85, Steps: 91 | Train Loss: 0.1239011 Vali Loss: 0.3728993 Test Loss: 0.4533548
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 84.95792651176453
Epoch: 86, Steps: 91 | Train Loss: 0.1237184 Vali Loss: 0.3726824 Test Loss: 0.4531686
Validation loss decreased (0.372746 --> 0.372682).  Saving model ...
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 86.30155062675476
Epoch: 87, Steps: 91 | Train Loss: 0.1235824 Vali Loss: 0.3722359 Test Loss: 0.4530045
Validation loss decreased (0.372682 --> 0.372236).  Saving model ...
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 89.40177845954895
Epoch: 88, Steps: 91 | Train Loss: 0.1234391 Vali Loss: 0.3727403 Test Loss: 0.4528353
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 82.73848104476929
Epoch: 89, Steps: 91 | Train Loss: 0.1232901 Vali Loss: 0.3719521 Test Loss: 0.4526657
Validation loss decreased (0.372236 --> 0.371952).  Saving model ...
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 79.30712628364563
Epoch: 90, Steps: 91 | Train Loss: 0.1231928 Vali Loss: 0.3719606 Test Loss: 0.4525220
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 77.55189919471741
Epoch: 91, Steps: 91 | Train Loss: 0.1230440 Vali Loss: 0.3726314 Test Loss: 0.4523805
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 78.40917301177979
Epoch: 92, Steps: 91 | Train Loss: 0.1229386 Vali Loss: 0.3718494 Test Loss: 0.4522294
Validation loss decreased (0.371952 --> 0.371849).  Saving model ...
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 80.27785086631775
Epoch: 93, Steps: 91 | Train Loss: 0.1228003 Vali Loss: 0.3716756 Test Loss: 0.4521071
Validation loss decreased (0.371849 --> 0.371676).  Saving model ...
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 84.99285531044006
Epoch: 94, Steps: 91 | Train Loss: 0.1227495 Vali Loss: 0.3713507 Test Loss: 0.4519853
Validation loss decreased (0.371676 --> 0.371351).  Saving model ...
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 82.63326930999756
Epoch: 95, Steps: 91 | Train Loss: 0.1226036 Vali Loss: 0.3715276 Test Loss: 0.4518658
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 79.60852551460266
Epoch: 96, Steps: 91 | Train Loss: 0.1225169 Vali Loss: 0.3713566 Test Loss: 0.4517635
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 76.58984088897705
Epoch: 97, Steps: 91 | Train Loss: 0.1224187 Vali Loss: 0.3711579 Test Loss: 0.4516485
Validation loss decreased (0.371351 --> 0.371158).  Saving model ...
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 78.76545095443726
Epoch: 98, Steps: 91 | Train Loss: 0.1223359 Vali Loss: 0.3713908 Test Loss: 0.4515545
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 76.73330211639404
Epoch: 99, Steps: 91 | Train Loss: 0.1222620 Vali Loss: 0.3710469 Test Loss: 0.4514596
Validation loss decreased (0.371158 --> 0.371047).  Saving model ...
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 80.086660861969
Epoch: 100, Steps: 91 | Train Loss: 0.1221670 Vali Loss: 0.3710930 Test Loss: 0.4513726
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.1160680107021042e-06
train 11729
val 1565
test 3317
Model(
  (freq_upsampler): Linear(in_features=138, out_features=211, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3212763648.0
params:  29329.0
Trainable parameters:  29329
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 85.65221834182739
Epoch: 1, Steps: 91 | Train Loss: 0.2609897 Vali Loss: 0.3417454 Test Loss: 0.4240789
Validation loss decreased (inf --> 0.341745).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 74.98947954177856
Epoch: 2, Steps: 91 | Train Loss: 0.2536465 Vali Loss: 0.3411524 Test Loss: 0.4243825
Validation loss decreased (0.341745 --> 0.341152).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 78.91065001487732
Epoch: 3, Steps: 91 | Train Loss: 0.2534164 Vali Loss: 0.3405414 Test Loss: 0.4241496
Validation loss decreased (0.341152 --> 0.340541).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 73.24170875549316
Epoch: 4, Steps: 91 | Train Loss: 0.2532783 Vali Loss: 0.3401363 Test Loss: 0.4241697
Validation loss decreased (0.340541 --> 0.340136).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 80.49296998977661
Epoch: 5, Steps: 91 | Train Loss: 0.2532207 Vali Loss: 0.3408217 Test Loss: 0.4239412
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 72.37935876846313
Epoch: 6, Steps: 91 | Train Loss: 0.2530958 Vali Loss: 0.3403687 Test Loss: 0.4238238
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 65.85075044631958
Epoch: 7, Steps: 91 | Train Loss: 0.2531483 Vali Loss: 0.3403691 Test Loss: 0.4238785
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 64.94885063171387
Epoch: 8, Steps: 91 | Train Loss: 0.2531389 Vali Loss: 0.3406113 Test Loss: 0.4238724
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 77.38469099998474
Epoch: 9, Steps: 91 | Train Loss: 0.2529933 Vali Loss: 0.3403637 Test Loss: 0.4236026
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 68.94776630401611
Epoch: 10, Steps: 91 | Train Loss: 0.2529629 Vali Loss: 0.3403520 Test Loss: 0.4237801
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 71.76642203330994
Epoch: 11, Steps: 91 | Train Loss: 0.2529079 Vali Loss: 0.3404841 Test Loss: 0.4238518
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 67.49612498283386
Epoch: 12, Steps: 91 | Train Loss: 0.2529673 Vali Loss: 0.3402877 Test Loss: 0.4235967
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 69.69254207611084
Epoch: 13, Steps: 91 | Train Loss: 0.2529515 Vali Loss: 0.3403107 Test Loss: 0.4237206
EarlyStopping counter: 9 out of 10
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 71.70932865142822
Epoch: 14, Steps: 91 | Train Loss: 0.2529352 Vali Loss: 0.3399794 Test Loss: 0.4235161
Validation loss decreased (0.340136 --> 0.339979).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 66.7134017944336
Epoch: 15, Steps: 91 | Train Loss: 0.2529096 Vali Loss: 0.3401029 Test Loss: 0.4236282
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 69.57813763618469
Epoch: 16, Steps: 91 | Train Loss: 0.2529038 Vali Loss: 0.3397582 Test Loss: 0.4235896
Validation loss decreased (0.339979 --> 0.339758).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 68.90207839012146
Epoch: 17, Steps: 91 | Train Loss: 0.2529257 Vali Loss: 0.3401147 Test Loss: 0.4232898
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 70.26663398742676
Epoch: 18, Steps: 91 | Train Loss: 0.2528144 Vali Loss: 0.3400971 Test Loss: 0.4234110
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 70.3754825592041
Epoch: 19, Steps: 91 | Train Loss: 0.2527454 Vali Loss: 0.3402995 Test Loss: 0.4235756
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 67.4893410205841
Epoch: 20, Steps: 91 | Train Loss: 0.2528188 Vali Loss: 0.3397657 Test Loss: 0.4234182
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 72.49972772598267
Epoch: 21, Steps: 91 | Train Loss: 0.2528379 Vali Loss: 0.3403261 Test Loss: 0.4234358
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 72.7631585597992
Epoch: 22, Steps: 91 | Train Loss: 0.2528645 Vali Loss: 0.3400336 Test Loss: 0.4234866
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 69.48522853851318
Epoch: 23, Steps: 91 | Train Loss: 0.2528116 Vali Loss: 0.3405614 Test Loss: 0.4234122
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 67.15984869003296
Epoch: 24, Steps: 91 | Train Loss: 0.2527552 Vali Loss: 0.3396181 Test Loss: 0.4233640
Validation loss decreased (0.339758 --> 0.339618).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 67.63368082046509
Epoch: 25, Steps: 91 | Train Loss: 0.2528041 Vali Loss: 0.3403330 Test Loss: 0.4234385
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 61.10373640060425
Epoch: 26, Steps: 91 | Train Loss: 0.2527692 Vali Loss: 0.3399388 Test Loss: 0.4234249
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 56.23456692695618
Epoch: 27, Steps: 91 | Train Loss: 0.2527721 Vali Loss: 0.3399345 Test Loss: 0.4234150
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 51.27866220474243
Epoch: 28, Steps: 91 | Train Loss: 0.2527379 Vali Loss: 0.3402915 Test Loss: 0.4234121
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 53.964921712875366
Epoch: 29, Steps: 91 | Train Loss: 0.2527651 Vali Loss: 0.3402781 Test Loss: 0.4234321
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 56.19957137107849
Epoch: 30, Steps: 91 | Train Loss: 0.2528094 Vali Loss: 0.3400171 Test Loss: 0.4233707
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 54.86985492706299
Epoch: 31, Steps: 91 | Train Loss: 0.2526960 Vali Loss: 0.3396640 Test Loss: 0.4233682
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 53.310012102127075
Epoch: 32, Steps: 91 | Train Loss: 0.2527274 Vali Loss: 0.3399188 Test Loss: 0.4233373
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 50.717426776885986
Epoch: 33, Steps: 91 | Train Loss: 0.2527179 Vali Loss: 0.3400276 Test Loss: 0.4232771
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 47.15898394584656
Epoch: 34, Steps: 91 | Train Loss: 0.2527380 Vali Loss: 0.3400588 Test Loss: 0.4232813
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : Traffic_360_j192_H8_FITS_custom_ftM_sl360_ll48_pl192_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3317
mse:0.42233628034591675, mae:0.2844044864177704, rse:0.5363622903823853, corr:[0.27507868 0.2891629  0.28953257 0.2892798  0.28934523 0.2890914
 0.28917077 0.28935632 0.28912613 0.2888191  0.28864002 0.2886935
 0.28897    0.28883123 0.28849742 0.28840432 0.28845546 0.28864905
 0.28859627 0.2883644  0.2883861  0.2882539  0.28792176 0.28831196
 0.2894995  0.28973004 0.28966713 0.2894057  0.28924927 0.28912196
 0.28865498 0.28863537 0.28905475 0.28884616 0.2884144  0.28838012
 0.28834242 0.28830191 0.28851834 0.28865755 0.28876516 0.28896445
 0.28890738 0.2886792  0.28846496 0.2880967  0.2876905  0.28749153
 0.28769967 0.28807646 0.28854322 0.28851765 0.288533   0.28865725
 0.28838858 0.28818575 0.28833848 0.28834704 0.2881663  0.28804713
 0.28797004 0.2878896  0.28787094 0.28781998 0.28772688 0.28761828
 0.2874285  0.28744185 0.28758895 0.2874146  0.28706113 0.28694132
 0.28691384 0.2871419  0.28756675 0.28759697 0.28736135 0.28727934
 0.2872279  0.28701386 0.2869461  0.28706527 0.28691772 0.28658763
 0.2865073  0.286461   0.28638607 0.28658226 0.286844   0.28677222
 0.2865464  0.28655288 0.28663114 0.2865217  0.28646484 0.28663036
 0.28651032 0.28628847 0.28628638 0.28648186 0.28643826 0.28618497
 0.28611588 0.28600252 0.2857419  0.28575978 0.28581452 0.2856011
 0.28574443 0.286139   0.28603888 0.2858491  0.28603417 0.28622627
 0.28627416 0.28616905 0.2858874  0.2858425  0.28597924 0.2857904
 0.28551492 0.28573743 0.28595614 0.28597948 0.28596365 0.28591624
 0.2860898  0.28629854 0.28622684 0.2861676  0.28624085 0.28616792
 0.28605807 0.28604314 0.2860498  0.28620324 0.28636795 0.28623116
 0.2862234  0.28632522 0.28618562 0.28619277 0.2863596  0.28648403
 0.28675398 0.28721803 0.28746778 0.28749987 0.28753015 0.28753585
 0.28732586 0.28710896 0.28717652 0.28727287 0.28726095 0.28729534
 0.28727558 0.28719756 0.28728184 0.28752783 0.28785485 0.28813842
 0.28815854 0.2881179  0.288173   0.28800428 0.28778264 0.28838465
 0.28940573 0.28895313 0.28868565 0.2885475  0.288294   0.28829747
 0.28809926 0.28787786 0.28815562 0.2881564  0.2880783  0.288154
 0.28787398 0.2878772  0.28824604 0.28837058 0.2886181  0.2885518
 0.28806564 0.28801087 0.28774658 0.28739828 0.2870765  0.2877302 ]
