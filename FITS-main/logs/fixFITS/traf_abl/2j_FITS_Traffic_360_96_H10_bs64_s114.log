Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=170, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_360_j96_H10', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=10, pred_len=96, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_360_j96_H10_FITS_custom_ftM_sl360_ll48_pl96_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11825
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=170, out_features=215, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4032780800.0
params:  36765.0
Trainable parameters:  36765
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 63.469465494155884
Epoch: 1, Steps: 92 | Train Loss: 1.1484300 Vali Loss: 1.2279940 Test Loss: 1.4048129
Validation loss decreased (inf --> 1.227994).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 65.7087926864624
Epoch: 2, Steps: 92 | Train Loss: 0.8763679 Vali Loss: 1.0894421 Test Loss: 1.2432510
Validation loss decreased (1.227994 --> 1.089442).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 61.758564472198486
Epoch: 3, Steps: 92 | Train Loss: 0.7672938 Vali Loss: 1.0183997 Test Loss: 1.1590909
Validation loss decreased (1.089442 --> 1.018400).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 62.35927605628967
Epoch: 4, Steps: 92 | Train Loss: 0.6917028 Vali Loss: 0.9606048 Test Loss: 1.0937213
Validation loss decreased (1.018400 --> 0.960605).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 61.564350843429565
Epoch: 5, Steps: 92 | Train Loss: 0.6290310 Vali Loss: 0.9113219 Test Loss: 1.0372335
Validation loss decreased (0.960605 --> 0.911322).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 65.6946074962616
Epoch: 6, Steps: 92 | Train Loss: 0.5753751 Vali Loss: 0.8670413 Test Loss: 0.9883347
Validation loss decreased (0.911322 --> 0.867041).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 61.72143197059631
Epoch: 7, Steps: 92 | Train Loss: 0.5286974 Vali Loss: 0.8266020 Test Loss: 0.9425895
Validation loss decreased (0.867041 --> 0.826602).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 64.63653206825256
Epoch: 8, Steps: 92 | Train Loss: 0.4878470 Vali Loss: 0.7906456 Test Loss: 0.9021308
Validation loss decreased (0.826602 --> 0.790646).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 63.56904673576355
Epoch: 9, Steps: 92 | Train Loss: 0.4519522 Vali Loss: 0.7564394 Test Loss: 0.8641590
Validation loss decreased (0.790646 --> 0.756439).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 69.65873742103577
Epoch: 10, Steps: 92 | Train Loss: 0.4201111 Vali Loss: 0.7273936 Test Loss: 0.8307238
Validation loss decreased (0.756439 --> 0.727394).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 63.52990221977234
Epoch: 11, Steps: 92 | Train Loss: 0.3918929 Vali Loss: 0.7002616 Test Loss: 0.8008971
Validation loss decreased (0.727394 --> 0.700262).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 64.3246431350708
Epoch: 12, Steps: 92 | Train Loss: 0.3667092 Vali Loss: 0.6749384 Test Loss: 0.7736487
Validation loss decreased (0.700262 --> 0.674938).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 64.4538221359253
Epoch: 13, Steps: 92 | Train Loss: 0.3441947 Vali Loss: 0.6546659 Test Loss: 0.7502339
Validation loss decreased (0.674938 --> 0.654666).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 67.01253747940063
Epoch: 14, Steps: 92 | Train Loss: 0.3239786 Vali Loss: 0.6336086 Test Loss: 0.7274221
Validation loss decreased (0.654666 --> 0.633609).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 66.32239174842834
Epoch: 15, Steps: 92 | Train Loss: 0.3057212 Vali Loss: 0.6156273 Test Loss: 0.7074603
Validation loss decreased (0.633609 --> 0.615627).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 62.24696636199951
Epoch: 16, Steps: 92 | Train Loss: 0.2893096 Vali Loss: 0.5991865 Test Loss: 0.6884840
Validation loss decreased (0.615627 --> 0.599186).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 63.541306018829346
Epoch: 17, Steps: 92 | Train Loss: 0.2744246 Vali Loss: 0.5814720 Test Loss: 0.6697242
Validation loss decreased (0.599186 --> 0.581472).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 63.330440282821655
Epoch: 18, Steps: 92 | Train Loss: 0.2609528 Vali Loss: 0.5692146 Test Loss: 0.6551468
Validation loss decreased (0.581472 --> 0.569215).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 63.6590211391449
Epoch: 19, Steps: 92 | Train Loss: 0.2486481 Vali Loss: 0.5560675 Test Loss: 0.6411031
Validation loss decreased (0.569215 --> 0.556068).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 60.28751516342163
Epoch: 20, Steps: 92 | Train Loss: 0.2375042 Vali Loss: 0.5452243 Test Loss: 0.6287262
Validation loss decreased (0.556068 --> 0.545224).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 62.18456053733826
Epoch: 21, Steps: 92 | Train Loss: 0.2272599 Vali Loss: 0.5343263 Test Loss: 0.6166297
Validation loss decreased (0.545224 --> 0.534326).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 62.887665033340454
Epoch: 22, Steps: 92 | Train Loss: 0.2179308 Vali Loss: 0.5231588 Test Loss: 0.6059591
Validation loss decreased (0.534326 --> 0.523159).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 64.02512121200562
Epoch: 23, Steps: 92 | Train Loss: 0.2093508 Vali Loss: 0.5138889 Test Loss: 0.5944317
Validation loss decreased (0.523159 --> 0.513889).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 61.61237573623657
Epoch: 24, Steps: 92 | Train Loss: 0.2014834 Vali Loss: 0.5059319 Test Loss: 0.5865348
Validation loss decreased (0.513889 --> 0.505932).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 57.29519724845886
Epoch: 25, Steps: 92 | Train Loss: 0.1942278 Vali Loss: 0.4982768 Test Loss: 0.5767369
Validation loss decreased (0.505932 --> 0.498277).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 55.94062066078186
Epoch: 26, Steps: 92 | Train Loss: 0.1875469 Vali Loss: 0.4907831 Test Loss: 0.5684730
Validation loss decreased (0.498277 --> 0.490783).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 55.49288606643677
Epoch: 27, Steps: 92 | Train Loss: 0.1814077 Vali Loss: 0.4841670 Test Loss: 0.5615674
Validation loss decreased (0.490783 --> 0.484167).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 56.48613429069519
Epoch: 28, Steps: 92 | Train Loss: 0.1757103 Vali Loss: 0.4789220 Test Loss: 0.5551278
Validation loss decreased (0.484167 --> 0.478922).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 54.675761461257935
Epoch: 29, Steps: 92 | Train Loss: 0.1704339 Vali Loss: 0.4723964 Test Loss: 0.5484220
Validation loss decreased (0.478922 --> 0.472396).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 55.79720735549927
Epoch: 30, Steps: 92 | Train Loss: 0.1655530 Vali Loss: 0.4679864 Test Loss: 0.5422397
Validation loss decreased (0.472396 --> 0.467986).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 60.040242195129395
Epoch: 31, Steps: 92 | Train Loss: 0.1610144 Vali Loss: 0.4602447 Test Loss: 0.5376166
Validation loss decreased (0.467986 --> 0.460245).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 55.27322506904602
Epoch: 32, Steps: 92 | Train Loss: 0.1568013 Vali Loss: 0.4572055 Test Loss: 0.5322463
Validation loss decreased (0.460245 --> 0.457206).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 55.91823101043701
Epoch: 33, Steps: 92 | Train Loss: 0.1528551 Vali Loss: 0.4530796 Test Loss: 0.5274866
Validation loss decreased (0.457206 --> 0.453080).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 56.06440615653992
Epoch: 34, Steps: 92 | Train Loss: 0.1492131 Vali Loss: 0.4499275 Test Loss: 0.5234576
Validation loss decreased (0.453080 --> 0.449928).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 56.529680013656616
Epoch: 35, Steps: 92 | Train Loss: 0.1458232 Vali Loss: 0.4445210 Test Loss: 0.5195599
Validation loss decreased (0.449928 --> 0.444521).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 58.873984813690186
Epoch: 36, Steps: 92 | Train Loss: 0.1426416 Vali Loss: 0.4404872 Test Loss: 0.5147468
Validation loss decreased (0.444521 --> 0.440487).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 58.66378045082092
Epoch: 37, Steps: 92 | Train Loss: 0.1396780 Vali Loss: 0.4383575 Test Loss: 0.5115269
Validation loss decreased (0.440487 --> 0.438357).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 72.92542004585266
Epoch: 38, Steps: 92 | Train Loss: 0.1368894 Vali Loss: 0.4355990 Test Loss: 0.5081921
Validation loss decreased (0.438357 --> 0.435599).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 69.18095397949219
Epoch: 39, Steps: 92 | Train Loss: 0.1343046 Vali Loss: 0.4331334 Test Loss: 0.5051457
Validation loss decreased (0.435599 --> 0.433133).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 72.77129292488098
Epoch: 40, Steps: 92 | Train Loss: 0.1318407 Vali Loss: 0.4292214 Test Loss: 0.5020053
Validation loss decreased (0.433133 --> 0.429221).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 70.60646748542786
Epoch: 41, Steps: 92 | Train Loss: 0.1295639 Vali Loss: 0.4267659 Test Loss: 0.4993379
Validation loss decreased (0.429221 --> 0.426766).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 76.59090971946716
Epoch: 42, Steps: 92 | Train Loss: 0.1273951 Vali Loss: 0.4235134 Test Loss: 0.4968041
Validation loss decreased (0.426766 --> 0.423513).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 84.72520852088928
Epoch: 43, Steps: 92 | Train Loss: 0.1253938 Vali Loss: 0.4211097 Test Loss: 0.4938788
Validation loss decreased (0.423513 --> 0.421110).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 74.86728239059448
Epoch: 44, Steps: 92 | Train Loss: 0.1235051 Vali Loss: 0.4203955 Test Loss: 0.4919782
Validation loss decreased (0.421110 --> 0.420395).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 133.56707978248596
Epoch: 45, Steps: 92 | Train Loss: 0.1217436 Vali Loss: 0.4179058 Test Loss: 0.4899414
Validation loss decreased (0.420395 --> 0.417906).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 101.9663610458374
Epoch: 46, Steps: 92 | Train Loss: 0.1200785 Vali Loss: 0.4160083 Test Loss: 0.4880307
Validation loss decreased (0.417906 --> 0.416008).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 76.27435088157654
Epoch: 47, Steps: 92 | Train Loss: 0.1184761 Vali Loss: 0.4138329 Test Loss: 0.4861414
Validation loss decreased (0.416008 --> 0.413833).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 81.16733431816101
Epoch: 48, Steps: 92 | Train Loss: 0.1169877 Vali Loss: 0.4108427 Test Loss: 0.4841521
Validation loss decreased (0.413833 --> 0.410843).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 80.15530633926392
Epoch: 49, Steps: 92 | Train Loss: 0.1155906 Vali Loss: 0.4105365 Test Loss: 0.4823984
Validation loss decreased (0.410843 --> 0.410537).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 79.70651626586914
Epoch: 50, Steps: 92 | Train Loss: 0.1142687 Vali Loss: 0.4085852 Test Loss: 0.4808548
Validation loss decreased (0.410537 --> 0.408585).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 86.2541389465332
Epoch: 51, Steps: 92 | Train Loss: 0.1130109 Vali Loss: 0.4081856 Test Loss: 0.4796392
Validation loss decreased (0.408585 --> 0.408186).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 76.8639509677887
Epoch: 52, Steps: 92 | Train Loss: 0.1118285 Vali Loss: 0.4066066 Test Loss: 0.4781392
Validation loss decreased (0.408186 --> 0.406607).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 85.328453540802
Epoch: 53, Steps: 92 | Train Loss: 0.1107391 Vali Loss: 0.4052815 Test Loss: 0.4767056
Validation loss decreased (0.406607 --> 0.405282).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 74.48214221000671
Epoch: 54, Steps: 92 | Train Loss: 0.1096672 Vali Loss: 0.4035364 Test Loss: 0.4754721
Validation loss decreased (0.405282 --> 0.403536).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 73.91976523399353
Epoch: 55, Steps: 92 | Train Loss: 0.1086763 Vali Loss: 0.4031235 Test Loss: 0.4742987
Validation loss decreased (0.403536 --> 0.403123).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 92.3258364200592
Epoch: 56, Steps: 92 | Train Loss: 0.1077404 Vali Loss: 0.4016203 Test Loss: 0.4731209
Validation loss decreased (0.403123 --> 0.401620).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 84.37350416183472
Epoch: 57, Steps: 92 | Train Loss: 0.1068573 Vali Loss: 0.4015352 Test Loss: 0.4720903
Validation loss decreased (0.401620 --> 0.401535).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 90.37506699562073
Epoch: 58, Steps: 92 | Train Loss: 0.1060080 Vali Loss: 0.3996079 Test Loss: 0.4711195
Validation loss decreased (0.401535 --> 0.399608).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 77.76293110847473
Epoch: 59, Steps: 92 | Train Loss: 0.1052033 Vali Loss: 0.3981771 Test Loss: 0.4700945
Validation loss decreased (0.399608 --> 0.398177).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 80.73519706726074
Epoch: 60, Steps: 92 | Train Loss: 0.1044679 Vali Loss: 0.3984672 Test Loss: 0.4692176
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 80.90882515907288
Epoch: 61, Steps: 92 | Train Loss: 0.1037460 Vali Loss: 0.3970504 Test Loss: 0.4685534
Validation loss decreased (0.398177 --> 0.397050).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 103.52501082420349
Epoch: 62, Steps: 92 | Train Loss: 0.1030532 Vali Loss: 0.3952757 Test Loss: 0.4676423
Validation loss decreased (0.397050 --> 0.395276).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 74.96869564056396
Epoch: 63, Steps: 92 | Train Loss: 0.1024266 Vali Loss: 0.3961110 Test Loss: 0.4667522
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 114.6376256942749
Epoch: 64, Steps: 92 | Train Loss: 0.1018060 Vali Loss: 0.3942332 Test Loss: 0.4660657
Validation loss decreased (0.395276 --> 0.394233).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 73.4585440158844
Epoch: 65, Steps: 92 | Train Loss: 0.1012205 Vali Loss: 0.3939211 Test Loss: 0.4654309
Validation loss decreased (0.394233 --> 0.393921).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 107.92312240600586
Epoch: 66, Steps: 92 | Train Loss: 0.1006875 Vali Loss: 0.3929330 Test Loss: 0.4647451
Validation loss decreased (0.393921 --> 0.392933).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 104.45134043693542
Epoch: 67, Steps: 92 | Train Loss: 0.1001841 Vali Loss: 0.3936177 Test Loss: 0.4641207
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 79.48488163948059
Epoch: 68, Steps: 92 | Train Loss: 0.0996703 Vali Loss: 0.3923178 Test Loss: 0.4635639
Validation loss decreased (0.392933 --> 0.392318).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 79.30337953567505
Epoch: 69, Steps: 92 | Train Loss: 0.0992019 Vali Loss: 0.3919872 Test Loss: 0.4630207
Validation loss decreased (0.392318 --> 0.391987).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 76.70190119743347
Epoch: 70, Steps: 92 | Train Loss: 0.0987831 Vali Loss: 0.3903495 Test Loss: 0.4625000
Validation loss decreased (0.391987 --> 0.390349).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 93.1097424030304
Epoch: 71, Steps: 92 | Train Loss: 0.0983569 Vali Loss: 0.3908468 Test Loss: 0.4620019
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 88.03295612335205
Epoch: 72, Steps: 92 | Train Loss: 0.0979415 Vali Loss: 0.3903435 Test Loss: 0.4616011
Validation loss decreased (0.390349 --> 0.390343).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 82.26072812080383
Epoch: 73, Steps: 92 | Train Loss: 0.0975795 Vali Loss: 0.3896028 Test Loss: 0.4611359
Validation loss decreased (0.390343 --> 0.389603).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 77.3691258430481
Epoch: 74, Steps: 92 | Train Loss: 0.0972142 Vali Loss: 0.3898794 Test Loss: 0.4606726
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 122.43301725387573
Epoch: 75, Steps: 92 | Train Loss: 0.0968723 Vali Loss: 0.3901226 Test Loss: 0.4602364
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 166.70234370231628
Epoch: 76, Steps: 92 | Train Loss: 0.0965521 Vali Loss: 0.3884156 Test Loss: 0.4599293
Validation loss decreased (0.389603 --> 0.388416).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 129.6729724407196
Epoch: 77, Steps: 92 | Train Loss: 0.0962419 Vali Loss: 0.3895899 Test Loss: 0.4595251
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 133.9020574092865
Epoch: 78, Steps: 92 | Train Loss: 0.0959282 Vali Loss: 0.3885268 Test Loss: 0.4592482
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 131.03715109825134
Epoch: 79, Steps: 92 | Train Loss: 0.0956747 Vali Loss: 0.3890407 Test Loss: 0.4589233
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 132.1692497730255
Epoch: 80, Steps: 92 | Train Loss: 0.0953942 Vali Loss: 0.3874554 Test Loss: 0.4585637
Validation loss decreased (0.388416 --> 0.387455).  Saving model ...
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 124.71221160888672
Epoch: 81, Steps: 92 | Train Loss: 0.0951646 Vali Loss: 0.3880568 Test Loss: 0.4583247
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 123.68221068382263
Epoch: 82, Steps: 92 | Train Loss: 0.0949024 Vali Loss: 0.3882991 Test Loss: 0.4580090
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 128.97672152519226
Epoch: 83, Steps: 92 | Train Loss: 0.0946877 Vali Loss: 0.3863218 Test Loss: 0.4577621
Validation loss decreased (0.387455 --> 0.386322).  Saving model ...
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 127.69042468070984
Epoch: 84, Steps: 92 | Train Loss: 0.0944701 Vali Loss: 0.3862666 Test Loss: 0.4575113
Validation loss decreased (0.386322 --> 0.386267).  Saving model ...
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 129.39998650550842
Epoch: 85, Steps: 92 | Train Loss: 0.0942677 Vali Loss: 0.3862135 Test Loss: 0.4572885
Validation loss decreased (0.386267 --> 0.386214).  Saving model ...
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 128.83187460899353
Epoch: 86, Steps: 92 | Train Loss: 0.0940804 Vali Loss: 0.3858744 Test Loss: 0.4570480
Validation loss decreased (0.386214 --> 0.385874).  Saving model ...
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 130.06357860565186
Epoch: 87, Steps: 92 | Train Loss: 0.0938986 Vali Loss: 0.3854908 Test Loss: 0.4568529
Validation loss decreased (0.385874 --> 0.385491).  Saving model ...
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 129.3974449634552
Epoch: 88, Steps: 92 | Train Loss: 0.0937099 Vali Loss: 0.3846535 Test Loss: 0.4566457
Validation loss decreased (0.385491 --> 0.384653).  Saving model ...
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 130.12781691551208
Epoch: 89, Steps: 92 | Train Loss: 0.0935450 Vali Loss: 0.3853399 Test Loss: 0.4564601
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 129.7279396057129
Epoch: 90, Steps: 92 | Train Loss: 0.0933907 Vali Loss: 0.3848764 Test Loss: 0.4562495
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 127.85558223724365
Epoch: 91, Steps: 92 | Train Loss: 0.0932321 Vali Loss: 0.3835055 Test Loss: 0.4560984
Validation loss decreased (0.384653 --> 0.383505).  Saving model ...
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 135.0563201904297
Epoch: 92, Steps: 92 | Train Loss: 0.0931079 Vali Loss: 0.3848954 Test Loss: 0.4559396
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 134.90363073349
Epoch: 93, Steps: 92 | Train Loss: 0.0929721 Vali Loss: 0.3844634 Test Loss: 0.4557695
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 129.71085786819458
Epoch: 94, Steps: 92 | Train Loss: 0.0928166 Vali Loss: 0.3849595 Test Loss: 0.4556328
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 131.53520464897156
Epoch: 95, Steps: 92 | Train Loss: 0.0927127 Vali Loss: 0.3835092 Test Loss: 0.4554806
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 120.8424072265625
Epoch: 96, Steps: 92 | Train Loss: 0.0926097 Vali Loss: 0.3846965 Test Loss: 0.4553547
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 124.71047878265381
Epoch: 97, Steps: 92 | Train Loss: 0.0924795 Vali Loss: 0.3831963 Test Loss: 0.4552526
Validation loss decreased (0.383505 --> 0.383196).  Saving model ...
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 115.59037232398987
Epoch: 98, Steps: 92 | Train Loss: 0.0923870 Vali Loss: 0.3852544 Test Loss: 0.4551054
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 121.13061738014221
Epoch: 99, Steps: 92 | Train Loss: 0.0922940 Vali Loss: 0.3842450 Test Loss: 0.4549906
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 120.69000625610352
Epoch: 100, Steps: 92 | Train Loss: 0.0921903 Vali Loss: 0.3834289 Test Loss: 0.4548758
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.1160680107021042e-06
train 11825
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=170, out_features=215, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4032780800.0
params:  36765.0
Trainable parameters:  36765
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 123.19329714775085
Epoch: 1, Steps: 92 | Train Loss: 0.2565321 Vali Loss: 0.3377824 Test Loss: 0.4136959
Validation loss decreased (inf --> 0.337782).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 115.35219407081604
Epoch: 2, Steps: 92 | Train Loss: 0.2477498 Vali Loss: 0.3374585 Test Loss: 0.4127730
Validation loss decreased (0.337782 --> 0.337459).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 114.4823112487793
Epoch: 3, Steps: 92 | Train Loss: 0.2473775 Vali Loss: 0.3369242 Test Loss: 0.4122536
Validation loss decreased (0.337459 --> 0.336924).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 102.0667040348053
Epoch: 4, Steps: 92 | Train Loss: 0.2470550 Vali Loss: 0.3378483 Test Loss: 0.4119044
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 143.25175952911377
Epoch: 5, Steps: 92 | Train Loss: 0.2469782 Vali Loss: 0.3379104 Test Loss: 0.4121347
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 141.76050114631653
Epoch: 6, Steps: 92 | Train Loss: 0.2468137 Vali Loss: 0.3382375 Test Loss: 0.4119594
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 140.9066505432129
Epoch: 7, Steps: 92 | Train Loss: 0.2468957 Vali Loss: 0.3368833 Test Loss: 0.4119811
Validation loss decreased (0.336924 --> 0.336883).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 144.7101411819458
Epoch: 8, Steps: 92 | Train Loss: 0.2468048 Vali Loss: 0.3373560 Test Loss: 0.4118458
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 128.89706897735596
Epoch: 9, Steps: 92 | Train Loss: 0.2466837 Vali Loss: 0.3356572 Test Loss: 0.4117348
Validation loss decreased (0.336883 --> 0.335657).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 119.46039986610413
Epoch: 10, Steps: 92 | Train Loss: 0.2467910 Vali Loss: 0.3370106 Test Loss: 0.4115748
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 129.76574182510376
Epoch: 11, Steps: 92 | Train Loss: 0.2465960 Vali Loss: 0.3366101 Test Loss: 0.4115560
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 122.42442297935486
Epoch: 12, Steps: 92 | Train Loss: 0.2466114 Vali Loss: 0.3363136 Test Loss: 0.4115452
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 122.10824418067932
Epoch: 13, Steps: 92 | Train Loss: 0.2466039 Vali Loss: 0.3370068 Test Loss: 0.4113943
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 128.59320259094238
Epoch: 14, Steps: 92 | Train Loss: 0.2465658 Vali Loss: 0.3360025 Test Loss: 0.4114303
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 128.57600235939026
Epoch: 15, Steps: 92 | Train Loss: 0.2465973 Vali Loss: 0.3366643 Test Loss: 0.4115658
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 118.86903023719788
Epoch: 16, Steps: 92 | Train Loss: 0.2464880 Vali Loss: 0.3360551 Test Loss: 0.4112629
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 126.78961896896362
Epoch: 17, Steps: 92 | Train Loss: 0.2465409 Vali Loss: 0.3365910 Test Loss: 0.4114011
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 121.96175813674927
Epoch: 18, Steps: 92 | Train Loss: 0.2464002 Vali Loss: 0.3354652 Test Loss: 0.4112032
Validation loss decreased (0.335657 --> 0.335465).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 242.30844473838806
Epoch: 19, Steps: 92 | Train Loss: 0.2464627 Vali Loss: 0.3369406 Test Loss: 0.4113551
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 163.38055205345154
Epoch: 20, Steps: 92 | Train Loss: 0.2463558 Vali Loss: 0.3360552 Test Loss: 0.4114958
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 196.52171206474304
Epoch: 21, Steps: 92 | Train Loss: 0.2464387 Vali Loss: 0.3358301 Test Loss: 0.4113497
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 103.84791946411133
Epoch: 22, Steps: 92 | Train Loss: 0.2464641 Vali Loss: 0.3364647 Test Loss: 0.4111470
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 92.22887802124023
Epoch: 23, Steps: 92 | Train Loss: 0.2464064 Vali Loss: 0.3367597 Test Loss: 0.4112717
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 105.23903965950012
Epoch: 24, Steps: 92 | Train Loss: 0.2464050 Vali Loss: 0.3359420 Test Loss: 0.4112191
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 91.08562278747559
Epoch: 25, Steps: 92 | Train Loss: 0.2463568 Vali Loss: 0.3356720 Test Loss: 0.4111944
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 104.14679074287415
Epoch: 26, Steps: 92 | Train Loss: 0.2463707 Vali Loss: 0.3361232 Test Loss: 0.4111736
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 113.09484934806824
Epoch: 27, Steps: 92 | Train Loss: 0.2464101 Vali Loss: 0.3369198 Test Loss: 0.4112623
EarlyStopping counter: 9 out of 10
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 118.86861538887024
Epoch: 28, Steps: 92 | Train Loss: 0.2462396 Vali Loss: 0.3372529 Test Loss: 0.4111522
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : Traffic_360_j96_H10_FITS_custom_ftM_sl360_ll48_pl96_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3413
mse:0.40961387753486633, mae:0.27929964661598206, rse:0.5299571752548218, corr:[0.27398047 0.29143456 0.29193056 0.29143155 0.29103497 0.2914583
 0.2914603  0.29133177 0.29149017 0.29163477 0.2917582  0.29160854
 0.29121447 0.29059196 0.29080173 0.29061788 0.29065618 0.29098508
 0.2908456  0.29110825 0.29133084 0.2910233  0.29076332 0.29109728
 0.2924214  0.29291064 0.2924179  0.29154885 0.29139006 0.29145527
 0.29137778 0.29110518 0.29090565 0.29073238 0.2906825  0.2909999
 0.2911079  0.29098448 0.29113945 0.2912153  0.2909272  0.29112965
 0.2911785  0.2908864  0.2904435  0.2902156  0.29047772 0.29062054
 0.2912976  0.29130477 0.29119    0.2906558  0.29051274 0.2908841
 0.29094136 0.29064587 0.29003638 0.29020998 0.29025173 0.29011574
 0.29041654 0.29004794 0.2906684  0.29137924 0.29105565 0.29090473
 0.29086277 0.29099286 0.29087755 0.2911072  0.2910108  0.29081547
 0.29085395 0.2906273  0.290632   0.2903313  0.2901245  0.29002923
 0.29010695 0.29016015 0.2897907  0.2900266  0.29022044 0.29008207
 0.29001385 0.2898588  0.2898209  0.29023746 0.29019395 0.2898981
 0.2896794  0.28890324 0.2891411  0.28873047 0.2899966  0.28963766]
