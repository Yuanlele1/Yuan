Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=74, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_180_j336_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=10, pred_len=336, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_180_j336_H8_FITS_custom_ftM_sl180_ll48_pl336_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11765
val 1421
test 3173
Model(
  (freq_upsampler): Linear(in_features=74, out_features=212, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1730951168.0
params:  15900.0
Trainable parameters:  15900
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 58.348212480545044
Epoch: 1, Steps: 91 | Train Loss: 1.2587695 Vali Loss: 1.2002301 Test Loss: 1.4548311
Validation loss decreased (inf --> 1.200230).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 63.620150566101074
Epoch: 2, Steps: 91 | Train Loss: 0.7476810 Vali Loss: 0.8871308 Test Loss: 1.0824124
Validation loss decreased (1.200230 --> 0.887131).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 57.06137728691101
Epoch: 3, Steps: 91 | Train Loss: 0.5555562 Vali Loss: 0.7397719 Test Loss: 0.9097273
Validation loss decreased (0.887131 --> 0.739772).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 53.60029053688049
Epoch: 4, Steps: 91 | Train Loss: 0.4602777 Vali Loss: 0.6585423 Test Loss: 0.8147804
Validation loss decreased (0.739772 --> 0.658542).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 52.38011860847473
Epoch: 5, Steps: 91 | Train Loss: 0.4053921 Vali Loss: 0.6087442 Test Loss: 0.7560067
Validation loss decreased (0.658542 --> 0.608744).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 49.73776149749756
Epoch: 6, Steps: 91 | Train Loss: 0.3697251 Vali Loss: 0.5741160 Test Loss: 0.7148291
Validation loss decreased (0.608744 --> 0.574116).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 53.197957277297974
Epoch: 7, Steps: 91 | Train Loss: 0.3441228 Vali Loss: 0.5483833 Test Loss: 0.6840842
Validation loss decreased (0.574116 --> 0.548383).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 56.45402145385742
Epoch: 8, Steps: 91 | Train Loss: 0.3245719 Vali Loss: 0.5287346 Test Loss: 0.6591684
Validation loss decreased (0.548383 --> 0.528735).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 55.473769664764404
Epoch: 9, Steps: 91 | Train Loss: 0.3089418 Vali Loss: 0.5126538 Test Loss: 0.6390007
Validation loss decreased (0.528735 --> 0.512654).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 50.62002491950989
Epoch: 10, Steps: 91 | Train Loss: 0.2961408 Vali Loss: 0.4985362 Test Loss: 0.6215509
Validation loss decreased (0.512654 --> 0.498536).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 57.40548372268677
Epoch: 11, Steps: 91 | Train Loss: 0.2853329 Vali Loss: 0.4869365 Test Loss: 0.6066927
Validation loss decreased (0.498536 --> 0.486936).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 58.09982419013977
Epoch: 12, Steps: 91 | Train Loss: 0.2761729 Vali Loss: 0.4771789 Test Loss: 0.5941095
Validation loss decreased (0.486936 --> 0.477179).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 52.300381898880005
Epoch: 13, Steps: 91 | Train Loss: 0.2682265 Vali Loss: 0.4684644 Test Loss: 0.5835472
Validation loss decreased (0.477179 --> 0.468464).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 52.276161193847656
Epoch: 14, Steps: 91 | Train Loss: 0.2613946 Vali Loss: 0.4609815 Test Loss: 0.5737761
Validation loss decreased (0.468464 --> 0.460981).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 57.8556272983551
Epoch: 15, Steps: 91 | Train Loss: 0.2554300 Vali Loss: 0.4541169 Test Loss: 0.5652655
Validation loss decreased (0.460981 --> 0.454117).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 55.128822565078735
Epoch: 16, Steps: 91 | Train Loss: 0.2501514 Vali Loss: 0.4484487 Test Loss: 0.5579185
Validation loss decreased (0.454117 --> 0.448449).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 50.55387473106384
Epoch: 17, Steps: 91 | Train Loss: 0.2455218 Vali Loss: 0.4437464 Test Loss: 0.5514783
Validation loss decreased (0.448449 --> 0.443746).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 52.37871217727661
Epoch: 18, Steps: 91 | Train Loss: 0.2414143 Vali Loss: 0.4391998 Test Loss: 0.5458183
Validation loss decreased (0.443746 --> 0.439200).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 53.16130876541138
Epoch: 19, Steps: 91 | Train Loss: 0.2377389 Vali Loss: 0.4348881 Test Loss: 0.5404733
Validation loss decreased (0.439200 --> 0.434888).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 52.89325952529907
Epoch: 20, Steps: 91 | Train Loss: 0.2344788 Vali Loss: 0.4315011 Test Loss: 0.5357818
Validation loss decreased (0.434888 --> 0.431501).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 48.392454385757446
Epoch: 21, Steps: 91 | Train Loss: 0.2315304 Vali Loss: 0.4280880 Test Loss: 0.5318357
Validation loss decreased (0.431501 --> 0.428088).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 47.59415030479431
Epoch: 22, Steps: 91 | Train Loss: 0.2288843 Vali Loss: 0.4253363 Test Loss: 0.5278674
Validation loss decreased (0.428088 --> 0.425336).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 49.09971380233765
Epoch: 23, Steps: 91 | Train Loss: 0.2265160 Vali Loss: 0.4227000 Test Loss: 0.5243698
Validation loss decreased (0.425336 --> 0.422700).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 49.052624225616455
Epoch: 24, Steps: 91 | Train Loss: 0.2243185 Vali Loss: 0.4196751 Test Loss: 0.5212609
Validation loss decreased (0.422700 --> 0.419675).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 51.95948648452759
Epoch: 25, Steps: 91 | Train Loss: 0.2223588 Vali Loss: 0.4175842 Test Loss: 0.5184937
Validation loss decreased (0.419675 --> 0.417584).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 48.21895217895508
Epoch: 26, Steps: 91 | Train Loss: 0.2204690 Vali Loss: 0.4159668 Test Loss: 0.5160220
Validation loss decreased (0.417584 --> 0.415967).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 57.659369468688965
Epoch: 27, Steps: 91 | Train Loss: 0.2188984 Vali Loss: 0.4139046 Test Loss: 0.5136642
Validation loss decreased (0.415967 --> 0.413905).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 50.053653955459595
Epoch: 28, Steps: 91 | Train Loss: 0.2174339 Vali Loss: 0.4122949 Test Loss: 0.5114357
Validation loss decreased (0.413905 --> 0.412295).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 54.82894706726074
Epoch: 29, Steps: 91 | Train Loss: 0.2160224 Vali Loss: 0.4106971 Test Loss: 0.5095014
Validation loss decreased (0.412295 --> 0.410697).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 47.57100176811218
Epoch: 30, Steps: 91 | Train Loss: 0.2148019 Vali Loss: 0.4091369 Test Loss: 0.5076889
Validation loss decreased (0.410697 --> 0.409137).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 53.06587195396423
Epoch: 31, Steps: 91 | Train Loss: 0.2136431 Vali Loss: 0.4081106 Test Loss: 0.5060573
Validation loss decreased (0.409137 --> 0.408111).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 49.77052283287048
Epoch: 32, Steps: 91 | Train Loss: 0.2124862 Vali Loss: 0.4065959 Test Loss: 0.5045404
Validation loss decreased (0.408111 --> 0.406596).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 51.28985333442688
Epoch: 33, Steps: 91 | Train Loss: 0.2115650 Vali Loss: 0.4059092 Test Loss: 0.5032202
Validation loss decreased (0.406596 --> 0.405909).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 51.98457479476929
Epoch: 34, Steps: 91 | Train Loss: 0.2106107 Vali Loss: 0.4046517 Test Loss: 0.5018817
Validation loss decreased (0.405909 --> 0.404652).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 53.470046043395996
Epoch: 35, Steps: 91 | Train Loss: 0.2097354 Vali Loss: 0.4040213 Test Loss: 0.5007005
Validation loss decreased (0.404652 --> 0.404021).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 66.38191175460815
Epoch: 36, Steps: 91 | Train Loss: 0.2089329 Vali Loss: 0.4028852 Test Loss: 0.4995805
Validation loss decreased (0.404021 --> 0.402885).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 52.42319703102112
Epoch: 37, Steps: 91 | Train Loss: 0.2082762 Vali Loss: 0.4025220 Test Loss: 0.4985693
Validation loss decreased (0.402885 --> 0.402522).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 56.23600387573242
Epoch: 38, Steps: 91 | Train Loss: 0.2075807 Vali Loss: 0.4013341 Test Loss: 0.4976186
Validation loss decreased (0.402522 --> 0.401334).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 57.524048805236816
Epoch: 39, Steps: 91 | Train Loss: 0.2070249 Vali Loss: 0.4007594 Test Loss: 0.4967512
Validation loss decreased (0.401334 --> 0.400759).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 52.68860983848572
Epoch: 40, Steps: 91 | Train Loss: 0.2064303 Vali Loss: 0.4000714 Test Loss: 0.4959367
Validation loss decreased (0.400759 --> 0.400071).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 51.80927562713623
Epoch: 41, Steps: 91 | Train Loss: 0.2058526 Vali Loss: 0.3993556 Test Loss: 0.4951237
Validation loss decreased (0.400071 --> 0.399356).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 47.754069566726685
Epoch: 42, Steps: 91 | Train Loss: 0.2053871 Vali Loss: 0.3991696 Test Loss: 0.4944623
Validation loss decreased (0.399356 --> 0.399170).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 47.6145544052124
Epoch: 43, Steps: 91 | Train Loss: 0.2048463 Vali Loss: 0.3985305 Test Loss: 0.4938161
Validation loss decreased (0.399170 --> 0.398530).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 49.1880316734314
Epoch: 44, Steps: 91 | Train Loss: 0.2044223 Vali Loss: 0.3977632 Test Loss: 0.4931300
Validation loss decreased (0.398530 --> 0.397763).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 51.82338547706604
Epoch: 45, Steps: 91 | Train Loss: 0.2039745 Vali Loss: 0.3973594 Test Loss: 0.4926028
Validation loss decreased (0.397763 --> 0.397359).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 51.706467390060425
Epoch: 46, Steps: 91 | Train Loss: 0.2036117 Vali Loss: 0.3972519 Test Loss: 0.4920903
Validation loss decreased (0.397359 --> 0.397252).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 52.85837769508362
Epoch: 47, Steps: 91 | Train Loss: 0.2032990 Vali Loss: 0.3965133 Test Loss: 0.4915804
Validation loss decreased (0.397252 --> 0.396513).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 52.20563769340515
Epoch: 48, Steps: 91 | Train Loss: 0.2028777 Vali Loss: 0.3960354 Test Loss: 0.4911153
Validation loss decreased (0.396513 --> 0.396035).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 52.4134361743927
Epoch: 49, Steps: 91 | Train Loss: 0.2025343 Vali Loss: 0.3958681 Test Loss: 0.4906634
Validation loss decreased (0.396035 --> 0.395868).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 53.91785287857056
Epoch: 50, Steps: 91 | Train Loss: 0.2022326 Vali Loss: 0.3956861 Test Loss: 0.4902539
Validation loss decreased (0.395868 --> 0.395686).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 52.944801330566406
Epoch: 51, Steps: 91 | Train Loss: 0.2019966 Vali Loss: 0.3952966 Test Loss: 0.4898512
Validation loss decreased (0.395686 --> 0.395297).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 52.21143651008606
Epoch: 52, Steps: 91 | Train Loss: 0.2017395 Vali Loss: 0.3947260 Test Loss: 0.4895028
Validation loss decreased (0.395297 --> 0.394726).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 47.32515096664429
Epoch: 53, Steps: 91 | Train Loss: 0.2015081 Vali Loss: 0.3945055 Test Loss: 0.4891682
Validation loss decreased (0.394726 --> 0.394505).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 42.24409484863281
Epoch: 54, Steps: 91 | Train Loss: 0.2012535 Vali Loss: 0.3940638 Test Loss: 0.4888669
Validation loss decreased (0.394505 --> 0.394064).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 43.72039723396301
Epoch: 55, Steps: 91 | Train Loss: 0.2010112 Vali Loss: 0.3944056 Test Loss: 0.4885446
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 40.674293994903564
Epoch: 56, Steps: 91 | Train Loss: 0.2009090 Vali Loss: 0.3938470 Test Loss: 0.4882686
Validation loss decreased (0.394064 --> 0.393847).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 41.94716715812683
Epoch: 57, Steps: 91 | Train Loss: 0.2006063 Vali Loss: 0.3938613 Test Loss: 0.4880284
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 44.195932388305664
Epoch: 58, Steps: 91 | Train Loss: 0.2004190 Vali Loss: 0.3934540 Test Loss: 0.4877603
Validation loss decreased (0.393847 --> 0.393454).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 42.950443983078
Epoch: 59, Steps: 91 | Train Loss: 0.2003147 Vali Loss: 0.3934946 Test Loss: 0.4875388
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 45.31877517700195
Epoch: 60, Steps: 91 | Train Loss: 0.2001386 Vali Loss: 0.3935357 Test Loss: 0.4873026
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 46.617823362350464
