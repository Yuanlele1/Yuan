Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=138, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_360_j96_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=10, pred_len=96, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_360_j96_H8_FITS_custom_ftM_sl360_ll48_pl96_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11825
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=138, out_features=174, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2649388032.0
params:  24186.0
Trainable parameters:  24186
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 60.71731638908386
Epoch: 1, Steps: 92 | Train Loss: 1.0465680 Vali Loss: 1.0751613 Test Loss: 1.2455857
Validation loss decreased (inf --> 1.075161).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 67.08904790878296
Epoch: 2, Steps: 92 | Train Loss: 0.7766701 Vali Loss: 0.9553068 Test Loss: 1.1025541
Validation loss decreased (1.075161 --> 0.955307).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 62.839967489242554
Epoch: 3, Steps: 92 | Train Loss: 0.6666235 Vali Loss: 0.8917747 Test Loss: 1.0291811
Validation loss decreased (0.955307 --> 0.891775).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 60.67790865898132
Epoch: 4, Steps: 92 | Train Loss: 0.5949224 Vali Loss: 0.8403544 Test Loss: 0.9694889
Validation loss decreased (0.891775 --> 0.840354).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 60.98039746284485
Epoch: 5, Steps: 92 | Train Loss: 0.5373253 Vali Loss: 0.7966719 Test Loss: 0.9208657
Validation loss decreased (0.840354 --> 0.796672).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 63.19481635093689
Epoch: 6, Steps: 92 | Train Loss: 0.4884890 Vali Loss: 0.7585201 Test Loss: 0.8762528
Validation loss decreased (0.796672 --> 0.758520).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 73.11270642280579
Epoch: 7, Steps: 92 | Train Loss: 0.4464086 Vali Loss: 0.7191669 Test Loss: 0.8336617
Validation loss decreased (0.758520 --> 0.719167).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 58.265718936920166
Epoch: 8, Steps: 92 | Train Loss: 0.4098643 Vali Loss: 0.6913405 Test Loss: 0.7993277
Validation loss decreased (0.719167 --> 0.691341).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 61.600728273391724
Epoch: 9, Steps: 92 | Train Loss: 0.3779872 Vali Loss: 0.6628351 Test Loss: 0.7682827
Validation loss decreased (0.691341 --> 0.662835).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 59.85436010360718
Epoch: 10, Steps: 92 | Train Loss: 0.3499736 Vali Loss: 0.6364598 Test Loss: 0.7393540
Validation loss decreased (0.662835 --> 0.636460).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 57.42765927314758
Epoch: 11, Steps: 92 | Train Loss: 0.3252072 Vali Loss: 0.6132417 Test Loss: 0.7133353
Validation loss decreased (0.636460 --> 0.613242).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 58.83337163925171
Epoch: 12, Steps: 92 | Train Loss: 0.3033006 Vali Loss: 0.5942076 Test Loss: 0.6912179
Validation loss decreased (0.613242 --> 0.594208).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 59.198739767074585
Epoch: 13, Steps: 92 | Train Loss: 0.2838883 Vali Loss: 0.5760188 Test Loss: 0.6696001
Validation loss decreased (0.594208 --> 0.576019).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 63.25144362449646
Epoch: 14, Steps: 92 | Train Loss: 0.2665812 Vali Loss: 0.5592326 Test Loss: 0.6512768
Validation loss decreased (0.576019 --> 0.559233).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 63.55243539810181
Epoch: 15, Steps: 92 | Train Loss: 0.2510534 Vali Loss: 0.5435514 Test Loss: 0.6343361
Validation loss decreased (0.559233 --> 0.543551).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 59.74375557899475
Epoch: 16, Steps: 92 | Train Loss: 0.2371571 Vali Loss: 0.5311185 Test Loss: 0.6191893
Validation loss decreased (0.543551 --> 0.531118).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 63.11233043670654
Epoch: 17, Steps: 92 | Train Loss: 0.2246379 Vali Loss: 0.5171819 Test Loss: 0.6053347
Validation loss decreased (0.531118 --> 0.517182).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 65.35162448883057
Epoch: 18, Steps: 92 | Train Loss: 0.2133587 Vali Loss: 0.5063795 Test Loss: 0.5916318
Validation loss decreased (0.517182 --> 0.506380).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 57.880908250808716
Epoch: 19, Steps: 92 | Train Loss: 0.2031757 Vali Loss: 0.4957769 Test Loss: 0.5796600
Validation loss decreased (0.506380 --> 0.495777).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 63.27512192726135
Epoch: 20, Steps: 92 | Train Loss: 0.1939250 Vali Loss: 0.4840693 Test Loss: 0.5684922
Validation loss decreased (0.495777 --> 0.484069).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 60.26414680480957
Epoch: 21, Steps: 92 | Train Loss: 0.1855496 Vali Loss: 0.4756795 Test Loss: 0.5590944
Validation loss decreased (0.484069 --> 0.475680).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 62.385377407073975
Epoch: 22, Steps: 92 | Train Loss: 0.1779405 Vali Loss: 0.4687004 Test Loss: 0.5500175
Validation loss decreased (0.475680 --> 0.468700).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 58.405447006225586
Epoch: 23, Steps: 92 | Train Loss: 0.1709623 Vali Loss: 0.4612513 Test Loss: 0.5414658
Validation loss decreased (0.468700 --> 0.461251).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 58.94042778015137
Epoch: 24, Steps: 92 | Train Loss: 0.1646406 Vali Loss: 0.4539890 Test Loss: 0.5343665
Validation loss decreased (0.461251 --> 0.453989).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 61.52165651321411
Epoch: 25, Steps: 92 | Train Loss: 0.1588569 Vali Loss: 0.4487287 Test Loss: 0.5277707
Validation loss decreased (0.453989 --> 0.448729).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 58.82689809799194
Epoch: 26, Steps: 92 | Train Loss: 0.1534878 Vali Loss: 0.4418207 Test Loss: 0.5211537
Validation loss decreased (0.448729 --> 0.441821).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 56.57572269439697
Epoch: 27, Steps: 92 | Train Loss: 0.1486362 Vali Loss: 0.4374661 Test Loss: 0.5152848
Validation loss decreased (0.441821 --> 0.437466).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 59.455923557281494
Epoch: 28, Steps: 92 | Train Loss: 0.1441310 Vali Loss: 0.4338457 Test Loss: 0.5102201
Validation loss decreased (0.437466 --> 0.433846).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 57.80856537818909
Epoch: 29, Steps: 92 | Train Loss: 0.1400042 Vali Loss: 0.4282511 Test Loss: 0.5053203
Validation loss decreased (0.433846 --> 0.428251).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 60.5091986656189
Epoch: 30, Steps: 92 | Train Loss: 0.1361845 Vali Loss: 0.4253152 Test Loss: 0.5009626
Validation loss decreased (0.428251 --> 0.425315).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 56.68247890472412
Epoch: 31, Steps: 92 | Train Loss: 0.1326650 Vali Loss: 0.4190640 Test Loss: 0.4957381
Validation loss decreased (0.425315 --> 0.419064).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 55.64035224914551
Epoch: 32, Steps: 92 | Train Loss: 0.1293939 Vali Loss: 0.4168156 Test Loss: 0.4923400
Validation loss decreased (0.419064 --> 0.416816).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 56.24374771118164
Epoch: 33, Steps: 92 | Train Loss: 0.1263576 Vali Loss: 0.4121865 Test Loss: 0.4887796
Validation loss decreased (0.416816 --> 0.412187).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 56.277111768722534
Epoch: 34, Steps: 92 | Train Loss: 0.1235901 Vali Loss: 0.4101981 Test Loss: 0.4856103
Validation loss decreased (0.412187 --> 0.410198).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 56.441641092300415
Epoch: 35, Steps: 92 | Train Loss: 0.1209909 Vali Loss: 0.4063270 Test Loss: 0.4820376
Validation loss decreased (0.410198 --> 0.406327).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 56.37502193450928
Epoch: 36, Steps: 92 | Train Loss: 0.1185741 Vali Loss: 0.4038999 Test Loss: 0.4792543
Validation loss decreased (0.406327 --> 0.403900).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 58.22349762916565
Epoch: 37, Steps: 92 | Train Loss: 0.1163168 Vali Loss: 0.4017863 Test Loss: 0.4765906
Validation loss decreased (0.403900 --> 0.401786).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 54.85286092758179
Epoch: 38, Steps: 92 | Train Loss: 0.1142294 Vali Loss: 0.3991976 Test Loss: 0.4739949
Validation loss decreased (0.401786 --> 0.399198).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 56.95520877838135
Epoch: 39, Steps: 92 | Train Loss: 0.1122757 Vali Loss: 0.3978417 Test Loss: 0.4715923
Validation loss decreased (0.399198 --> 0.397842).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 55.40369892120361
Epoch: 40, Steps: 92 | Train Loss: 0.1104367 Vali Loss: 0.3954724 Test Loss: 0.4694320
Validation loss decreased (0.397842 --> 0.395472).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 54.08238935470581
Epoch: 41, Steps: 92 | Train Loss: 0.1087201 Vali Loss: 0.3937286 Test Loss: 0.4670479
Validation loss decreased (0.395472 --> 0.393729).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 54.67857360839844
Epoch: 42, Steps: 92 | Train Loss: 0.1071164 Vali Loss: 0.3908487 Test Loss: 0.4651951
Validation loss decreased (0.393729 --> 0.390849).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 56.26710224151611
Epoch: 43, Steps: 92 | Train Loss: 0.1056264 Vali Loss: 0.3888609 Test Loss: 0.4634098
Validation loss decreased (0.390849 --> 0.388861).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 57.23111081123352
Epoch: 44, Steps: 92 | Train Loss: 0.1042610 Vali Loss: 0.3882795 Test Loss: 0.4617572
Validation loss decreased (0.388861 --> 0.388280).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 56.2483344078064
Epoch: 45, Steps: 92 | Train Loss: 0.1029522 Vali Loss: 0.3877212 Test Loss: 0.4604080
Validation loss decreased (0.388280 --> 0.387721).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 55.382585287094116
Epoch: 46, Steps: 92 | Train Loss: 0.1017121 Vali Loss: 0.3850097 Test Loss: 0.4586293
Validation loss decreased (0.387721 --> 0.385010).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 57.98005557060242
Epoch: 47, Steps: 92 | Train Loss: 0.1005346 Vali Loss: 0.3832490 Test Loss: 0.4575107
Validation loss decreased (0.385010 --> 0.383249).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 52.74854588508606
Epoch: 48, Steps: 92 | Train Loss: 0.0994940 Vali Loss: 0.3828281 Test Loss: 0.4564123
Validation loss decreased (0.383249 --> 0.382828).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 58.205148696899414
Epoch: 49, Steps: 92 | Train Loss: 0.0984407 Vali Loss: 0.3824470 Test Loss: 0.4549293
Validation loss decreased (0.382828 --> 0.382447).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 53.85478854179382
Epoch: 50, Steps: 92 | Train Loss: 0.0974963 Vali Loss: 0.3800861 Test Loss: 0.4536995
Validation loss decreased (0.382447 --> 0.380086).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 53.199700593948364
Epoch: 51, Steps: 92 | Train Loss: 0.0965962 Vali Loss: 0.3789366 Test Loss: 0.4524820
Validation loss decreased (0.380086 --> 0.378937).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 52.363266944885254
Epoch: 52, Steps: 92 | Train Loss: 0.0957431 Vali Loss: 0.3793330 Test Loss: 0.4518401
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 51.39677548408508
Epoch: 53, Steps: 92 | Train Loss: 0.0949425 Vali Loss: 0.3773602 Test Loss: 0.4505942
Validation loss decreased (0.378937 --> 0.377360).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 51.92941164970398
Epoch: 54, Steps: 92 | Train Loss: 0.0941864 Vali Loss: 0.3768610 Test Loss: 0.4498142
Validation loss decreased (0.377360 --> 0.376861).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 48.94223928451538
Epoch: 55, Steps: 92 | Train Loss: 0.0934770 Vali Loss: 0.3757398 Test Loss: 0.4491228
Validation loss decreased (0.376861 --> 0.375740).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 50.97081971168518
Epoch: 56, Steps: 92 | Train Loss: 0.0927949 Vali Loss: 0.3752511 Test Loss: 0.4480779
Validation loss decreased (0.375740 --> 0.375251).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 54.044601917266846
Epoch: 57, Steps: 92 | Train Loss: 0.0921470 Vali Loss: 0.3759978 Test Loss: 0.4474002
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 46.37626910209656
Epoch: 58, Steps: 92 | Train Loss: 0.0915523 Vali Loss: 0.3736271 Test Loss: 0.4467669
Validation loss decreased (0.375251 --> 0.373627).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 53.208980083465576
Epoch: 59, Steps: 92 | Train Loss: 0.0909933 Vali Loss: 0.3735569 Test Loss: 0.4461549
Validation loss decreased (0.373627 --> 0.373557).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 73.08607912063599
Epoch: 60, Steps: 92 | Train Loss: 0.0904526 Vali Loss: 0.3729477 Test Loss: 0.4454036
Validation loss decreased (0.373557 --> 0.372948).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 78.46986627578735
Epoch: 61, Steps: 92 | Train Loss: 0.0899326 Vali Loss: 0.3722874 Test Loss: 0.4448658
Validation loss decreased (0.372948 --> 0.372287).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 72.02338767051697
Epoch: 62, Steps: 92 | Train Loss: 0.0894509 Vali Loss: 0.3707713 Test Loss: 0.4442681
Validation loss decreased (0.372287 --> 0.370771).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 85.54251337051392
Epoch: 63, Steps: 92 | Train Loss: 0.0890088 Vali Loss: 0.3716571 Test Loss: 0.4437406
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 74.27046012878418
Epoch: 64, Steps: 92 | Train Loss: 0.0885489 Vali Loss: 0.3706226 Test Loss: 0.4432110
Validation loss decreased (0.370771 --> 0.370623).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 72.26463174819946
Epoch: 65, Steps: 92 | Train Loss: 0.0881724 Vali Loss: 0.3697073 Test Loss: 0.4427639
Validation loss decreased (0.370623 --> 0.369707).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 71.74863767623901
Epoch: 66, Steps: 92 | Train Loss: 0.0877716 Vali Loss: 0.3701535 Test Loss: 0.4422981
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 70.13704252243042
Epoch: 67, Steps: 92 | Train Loss: 0.0874152 Vali Loss: 0.3684375 Test Loss: 0.4418518
Validation loss decreased (0.369707 --> 0.368438).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 71.72926378250122
Epoch: 68, Steps: 92 | Train Loss: 0.0870647 Vali Loss: 0.3693114 Test Loss: 0.4414686
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 73.02525997161865
Epoch: 69, Steps: 92 | Train Loss: 0.0867238 Vali Loss: 0.3683596 Test Loss: 0.4410497
Validation loss decreased (0.368438 --> 0.368360).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 72.7620153427124
Epoch: 70, Steps: 92 | Train Loss: 0.0864246 Vali Loss: 0.3682737 Test Loss: 0.4407492
Validation loss decreased (0.368360 --> 0.368274).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 73.19579195976257
Epoch: 71, Steps: 92 | Train Loss: 0.0861202 Vali Loss: 0.3677692 Test Loss: 0.4403843
Validation loss decreased (0.368274 --> 0.367769).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 71.30994033813477
Epoch: 72, Steps: 92 | Train Loss: 0.0858437 Vali Loss: 0.3668741 Test Loss: 0.4400532
Validation loss decreased (0.367769 --> 0.366874).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 79.81569123268127
Epoch: 73, Steps: 92 | Train Loss: 0.0855621 Vali Loss: 0.3684151 Test Loss: 0.4397132
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 68.76851725578308
Epoch: 74, Steps: 92 | Train Loss: 0.0853284 Vali Loss: 0.3672148 Test Loss: 0.4394175
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 73.43881702423096
Epoch: 75, Steps: 92 | Train Loss: 0.0850839 Vali Loss: 0.3665107 Test Loss: 0.4391269
Validation loss decreased (0.366874 --> 0.366511).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 70.79648447036743
Epoch: 76, Steps: 92 | Train Loss: 0.0848439 Vali Loss: 0.3672968 Test Loss: 0.4389135
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 73.06881046295166
Epoch: 77, Steps: 92 | Train Loss: 0.0846544 Vali Loss: 0.3675481 Test Loss: 0.4386441
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 72.29869723320007
Epoch: 78, Steps: 92 | Train Loss: 0.0844334 Vali Loss: 0.3671318 Test Loss: 0.4384081
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 73.10431599617004
Epoch: 79, Steps: 92 | Train Loss: 0.0842383 Vali Loss: 0.3650634 Test Loss: 0.4381838
Validation loss decreased (0.366511 --> 0.365063).  Saving model ...
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 74.57735991477966
Epoch: 80, Steps: 92 | Train Loss: 0.0840622 Vali Loss: 0.3659894 Test Loss: 0.4379809
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 78.21103525161743
Epoch: 81, Steps: 92 | Train Loss: 0.0838789 Vali Loss: 0.3659285 Test Loss: 0.4377769
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 89.52327847480774
Epoch: 82, Steps: 92 | Train Loss: 0.0837165 Vali Loss: 0.3650662 Test Loss: 0.4376043
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 72.79839849472046
Epoch: 83, Steps: 92 | Train Loss: 0.0835580 Vali Loss: 0.3645159 Test Loss: 0.4373911
Validation loss decreased (0.365063 --> 0.364516).  Saving model ...
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 75.65427374839783
Epoch: 84, Steps: 92 | Train Loss: 0.0834040 Vali Loss: 0.3644018 Test Loss: 0.4372179
Validation loss decreased (0.364516 --> 0.364402).  Saving model ...
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 80.40084600448608
Epoch: 85, Steps: 92 | Train Loss: 0.0832700 Vali Loss: 0.3651265 Test Loss: 0.4370625
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 75.90108108520508
Epoch: 86, Steps: 92 | Train Loss: 0.0831259 Vali Loss: 0.3659393 Test Loss: 0.4369092
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 79.31432604789734
Epoch: 87, Steps: 92 | Train Loss: 0.0829999 Vali Loss: 0.3644609 Test Loss: 0.4367622
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 79.91999340057373
Epoch: 88, Steps: 92 | Train Loss: 0.0828800 Vali Loss: 0.3644723 Test Loss: 0.4366337
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 76.39910173416138
Epoch: 89, Steps: 92 | Train Loss: 0.0827574 Vali Loss: 0.3628745 Test Loss: 0.4364897
Validation loss decreased (0.364402 --> 0.362875).  Saving model ...
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 75.22718834877014
Epoch: 90, Steps: 92 | Train Loss: 0.0826602 Vali Loss: 0.3640882 Test Loss: 0.4363724
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 73.72876071929932
Epoch: 91, Steps: 92 | Train Loss: 0.0825460 Vali Loss: 0.3640065 Test Loss: 0.4362653
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 76.57961845397949
Epoch: 92, Steps: 92 | Train Loss: 0.0824218 Vali Loss: 0.3635415 Test Loss: 0.4361407
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 79.12210774421692
Epoch: 93, Steps: 92 | Train Loss: 0.0823391 Vali Loss: 0.3641478 Test Loss: 0.4360434
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 72.79727292060852
Epoch: 94, Steps: 92 | Train Loss: 0.0822439 Vali Loss: 0.3633828 Test Loss: 0.4359269
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 79.51407122612
Epoch: 95, Steps: 92 | Train Loss: 0.0821664 Vali Loss: 0.3634382 Test Loss: 0.4358424
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 75.32708072662354
Epoch: 96, Steps: 92 | Train Loss: 0.0820998 Vali Loss: 0.3631507 Test Loss: 0.4357419
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 73.30102777481079
Epoch: 97, Steps: 92 | Train Loss: 0.0820204 Vali Loss: 0.3630682 Test Loss: 0.4356481
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 76.40765047073364
Epoch: 98, Steps: 92 | Train Loss: 0.0819317 Vali Loss: 0.3636465 Test Loss: 0.4355722
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 71.50860333442688
Epoch: 99, Steps: 92 | Train Loss: 0.0818712 Vali Loss: 0.3637131 Test Loss: 0.4354911
EarlyStopping counter: 10 out of 10
Early stopping
train 11825
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=138, out_features=174, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2649388032.0
params:  24186.0
Trainable parameters:  24186
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 76.46522378921509
Epoch: 1, Steps: 92 | Train Loss: 0.2530733 Vali Loss: 0.3393400 Test Loss: 0.4147198
Validation loss decreased (inf --> 0.339340).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 75.68710041046143
Epoch: 2, Steps: 92 | Train Loss: 0.2484786 Vali Loss: 0.3389855 Test Loss: 0.4138437
Validation loss decreased (0.339340 --> 0.338986).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 71.30398321151733
Epoch: 3, Steps: 92 | Train Loss: 0.2481353 Vali Loss: 0.3370189 Test Loss: 0.4135612
Validation loss decreased (0.338986 --> 0.337019).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 72.73805069923401
Epoch: 4, Steps: 92 | Train Loss: 0.2479492 Vali Loss: 0.3372630 Test Loss: 0.4129843
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 70.31764531135559
Epoch: 5, Steps: 92 | Train Loss: 0.2477594 Vali Loss: 0.3379481 Test Loss: 0.4133152
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 72.72693181037903
Epoch: 6, Steps: 92 | Train Loss: 0.2477278 Vali Loss: 0.3382430 Test Loss: 0.4129138
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 103.18371629714966
Epoch: 7, Steps: 92 | Train Loss: 0.2475451 Vali Loss: 0.3371092 Test Loss: 0.4129128
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 93.15977096557617
Epoch: 8, Steps: 92 | Train Loss: 0.2474545 Vali Loss: 0.3371434 Test Loss: 0.4127751
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 73.89756727218628
Epoch: 9, Steps: 92 | Train Loss: 0.2474321 Vali Loss: 0.3368482 Test Loss: 0.4127218
Validation loss decreased (0.337019 --> 0.336848).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 72.29624319076538
Epoch: 10, Steps: 92 | Train Loss: 0.2474528 Vali Loss: 0.3373993 Test Loss: 0.4128094
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 66.68722200393677
Epoch: 11, Steps: 92 | Train Loss: 0.2473423 Vali Loss: 0.3371505 Test Loss: 0.4127360
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 67.725257396698
Epoch: 12, Steps: 92 | Train Loss: 0.2473485 Vali Loss: 0.3375932 Test Loss: 0.4123509
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 67.16222286224365
Epoch: 13, Steps: 92 | Train Loss: 0.2472947 Vali Loss: 0.3383187 Test Loss: 0.4124801
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 76.32718634605408
Epoch: 14, Steps: 92 | Train Loss: 0.2473262 Vali Loss: 0.3367072 Test Loss: 0.4123852
Validation loss decreased (0.336848 --> 0.336707).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 70.30507111549377
Epoch: 15, Steps: 92 | Train Loss: 0.2472182 Vali Loss: 0.3377663 Test Loss: 0.4122583
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 77.68694710731506
Epoch: 16, Steps: 92 | Train Loss: 0.2472430 Vali Loss: 0.3385115 Test Loss: 0.4120640
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 68.71345472335815
Epoch: 17, Steps: 92 | Train Loss: 0.2472447 Vali Loss: 0.3375368 Test Loss: 0.4122706
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 70.40429711341858
Epoch: 18, Steps: 92 | Train Loss: 0.2472972 Vali Loss: 0.3371025 Test Loss: 0.4123484
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 72.16646695137024
Epoch: 19, Steps: 92 | Train Loss: 0.2471492 Vali Loss: 0.3362977 Test Loss: 0.4121031
Validation loss decreased (0.336707 --> 0.336298).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 70.22668766975403
Epoch: 20, Steps: 92 | Train Loss: 0.2471550 Vali Loss: 0.3371181 Test Loss: 0.4120970
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 65.45715856552124
Epoch: 21, Steps: 92 | Train Loss: 0.2470933 Vali Loss: 0.3379297 Test Loss: 0.4122684
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 70.80438995361328
Epoch: 22, Steps: 92 | Train Loss: 0.2471688 Vali Loss: 0.3372062 Test Loss: 0.4121199
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 67.36373949050903
Epoch: 23, Steps: 92 | Train Loss: 0.2470948 Vali Loss: 0.3374635 Test Loss: 0.4120932
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 58.64072251319885
Epoch: 24, Steps: 92 | Train Loss: 0.2471160 Vali Loss: 0.3369115 Test Loss: 0.4122074
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 64.41669654846191
Epoch: 25, Steps: 92 | Train Loss: 0.2471312 Vali Loss: 0.3374380 Test Loss: 0.4120860
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 59.24388909339905
Epoch: 26, Steps: 92 | Train Loss: 0.2469822 Vali Loss: 0.3378905 Test Loss: 0.4121775
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 62.12637901306152
Epoch: 27, Steps: 92 | Train Loss: 0.2470536 Vali Loss: 0.3361195 Test Loss: 0.4120438
Validation loss decreased (0.336298 --> 0.336120).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 62.01918363571167
Epoch: 28, Steps: 92 | Train Loss: 0.2470947 Vali Loss: 0.3378147 Test Loss: 0.4121721
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 62.21903920173645
Epoch: 29, Steps: 92 | Train Loss: 0.2470976 Vali Loss: 0.3363709 Test Loss: 0.4121756
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 62.91456127166748
Epoch: 30, Steps: 92 | Train Loss: 0.2470484 Vali Loss: 0.3373488 Test Loss: 0.4118778
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 59.78868293762207
Epoch: 31, Steps: 92 | Train Loss: 0.2469645 Vali Loss: 0.3378876 Test Loss: 0.4121259
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 63.35082936286926
Epoch: 32, Steps: 92 | Train Loss: 0.2469393 Vali Loss: 0.3378746 Test Loss: 0.4121263
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 59.87357425689697
Epoch: 33, Steps: 92 | Train Loss: 0.2470332 Vali Loss: 0.3365920 Test Loss: 0.4120878
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 59.769564390182495
Epoch: 34, Steps: 92 | Train Loss: 0.2470135 Vali Loss: 0.3377912 Test Loss: 0.4121351
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 61.34874963760376
Epoch: 35, Steps: 92 | Train Loss: 0.2468382 Vali Loss: 0.3362086 Test Loss: 0.4120457
EarlyStopping counter: 8 out of 10
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 62.16885042190552
Epoch: 36, Steps: 92 | Train Loss: 0.2469880 Vali Loss: 0.3358085 Test Loss: 0.4120905
Validation loss decreased (0.336120 --> 0.335809).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 61.43277668952942
Epoch: 37, Steps: 92 | Train Loss: 0.2469889 Vali Loss: 0.3356524 Test Loss: 0.4120201
Validation loss decreased (0.335809 --> 0.335652).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 58.718817949295044
Epoch: 38, Steps: 92 | Train Loss: 0.2469490 Vali Loss: 0.3361560 Test Loss: 0.4120577
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 60.85656476020813
Epoch: 39, Steps: 92 | Train Loss: 0.2469328 Vali Loss: 0.3362977 Test Loss: 0.4120663
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 59.96342086791992
Epoch: 40, Steps: 92 | Train Loss: 0.2468964 Vali Loss: 0.3372850 Test Loss: 0.4121220
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 63.74243783950806
Epoch: 41, Steps: 92 | Train Loss: 0.2469623 Vali Loss: 0.3372417 Test Loss: 0.4120335
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 64.45314145088196
Epoch: 42, Steps: 92 | Train Loss: 0.2468791 Vali Loss: 0.3378935 Test Loss: 0.4120042
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 61.820292472839355
Epoch: 43, Steps: 92 | Train Loss: 0.2470046 Vali Loss: 0.3372875 Test Loss: 0.4121313
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 63.84397053718567
Epoch: 44, Steps: 92 | Train Loss: 0.2469569 Vali Loss: 0.3372219 Test Loss: 0.4121053
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 64.24769353866577
Epoch: 45, Steps: 92 | Train Loss: 0.2469968 Vali Loss: 0.3372031 Test Loss: 0.4119807
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 52.10271334648132
Epoch: 46, Steps: 92 | Train Loss: 0.2469728 Vali Loss: 0.3374855 Test Loss: 0.4120342
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 56.32063150405884
Epoch: 47, Steps: 92 | Train Loss: 0.2469641 Vali Loss: 0.3358976 Test Loss: 0.4119971
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : Traffic_360_j96_H8_FITS_custom_ftM_sl360_ll48_pl96_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3413
mse:0.4104578197002411, mae:0.2803087532520294, rse:0.5305028557777405, corr:[0.2774086  0.2919222  0.29248446 0.29226404 0.29209077 0.29190204
 0.29181835 0.2917797  0.29178092 0.29175612 0.29168952 0.2915624
 0.29140154 0.2912874  0.29129994 0.29127315 0.2913091  0.29157618
 0.2916242  0.2913663  0.29124948 0.2910921  0.29071    0.2909385
 0.29212138 0.29234314 0.29221642 0.29209256 0.29193974 0.29174137
 0.29155886 0.291473   0.2913953  0.2914858  0.29166907 0.29152775
 0.2913789  0.29143053 0.29152173 0.29173478 0.29191682 0.2917745
 0.29150364 0.29143614 0.291539   0.29155254 0.29132295 0.2911437
 0.29148632 0.29161498 0.29150966 0.29141647 0.29149008 0.2914584
 0.29135635 0.29120514 0.29115278 0.29133454 0.29132372 0.29116634
 0.2912227  0.2911456  0.29108697 0.29123187 0.29132268 0.2914243
 0.29138672 0.29118955 0.2911777  0.29117343 0.29090366 0.29082257
 0.29089794 0.29079816 0.29083872 0.29096505 0.29067022 0.2904603
 0.29059324 0.29048535 0.29031542 0.2903106  0.29040125 0.29053682
 0.29031324 0.29012495 0.29030222 0.29028973 0.2903015  0.29013458
 0.28985757 0.2900046  0.28975525 0.28968254 0.28967005 0.29007393]
