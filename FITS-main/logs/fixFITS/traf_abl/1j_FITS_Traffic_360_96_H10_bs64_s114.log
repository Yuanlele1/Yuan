Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=170, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_360_j96_H10', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=10, pred_len=96, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_360_j96_H10_FITS_custom_ftM_sl360_ll48_pl96_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11825
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=170, out_features=215, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4032780800.0
params:  36765.0
Trainable parameters:  36765
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 46.241777181625366
Epoch: 1, Steps: 92 | Train Loss: 0.7974394 Vali Loss: 0.6204088 Test Loss: 0.7164388
Validation loss decreased (inf --> 0.620409).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 42.90718650817871
Epoch: 2, Steps: 92 | Train Loss: 0.3864552 Vali Loss: 0.4125542 Test Loss: 0.4864813
Validation loss decreased (0.620409 --> 0.412554).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 45.253477811813354
Epoch: 3, Steps: 92 | Train Loss: 0.2830213 Vali Loss: 0.3564015 Test Loss: 0.4275416
Validation loss decreased (0.412554 --> 0.356402).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 44.22557353973389
Epoch: 4, Steps: 92 | Train Loss: 0.2563180 Vali Loss: 0.3430150 Test Loss: 0.4158702
Validation loss decreased (0.356402 --> 0.343015).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 45.44115614891052
Epoch: 5, Steps: 92 | Train Loss: 0.2501821 Vali Loss: 0.3396711 Test Loss: 0.4139615
Validation loss decreased (0.343015 --> 0.339671).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 43.53907632827759
Epoch: 6, Steps: 92 | Train Loss: 0.2487285 Vali Loss: 0.3377519 Test Loss: 0.4136454
Validation loss decreased (0.339671 --> 0.337752).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 44.93711709976196
Epoch: 7, Steps: 92 | Train Loss: 0.2482840 Vali Loss: 0.3379230 Test Loss: 0.4134298
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 44.078845262527466
Epoch: 8, Steps: 92 | Train Loss: 0.2479566 Vali Loss: 0.3393216 Test Loss: 0.4133177
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 46.73988962173462
Epoch: 9, Steps: 92 | Train Loss: 0.2477307 Vali Loss: 0.3373258 Test Loss: 0.4130641
Validation loss decreased (0.337752 --> 0.337326).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 42.96351385116577
Epoch: 10, Steps: 92 | Train Loss: 0.2475941 Vali Loss: 0.3377880 Test Loss: 0.4128523
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 43.922399044036865
Epoch: 11, Steps: 92 | Train Loss: 0.2474653 Vali Loss: 0.3375401 Test Loss: 0.4125841
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 47.332119941711426
Epoch: 12, Steps: 92 | Train Loss: 0.2473194 Vali Loss: 0.3368432 Test Loss: 0.4124956
Validation loss decreased (0.337326 --> 0.336843).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 54.33896565437317
Epoch: 13, Steps: 92 | Train Loss: 0.2473290 Vali Loss: 0.3374994 Test Loss: 0.4123923
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 46.9510395526886
Epoch: 14, Steps: 92 | Train Loss: 0.2472713 Vali Loss: 0.3362623 Test Loss: 0.4123732
Validation loss decreased (0.336843 --> 0.336262).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 49.06961488723755
Epoch: 15, Steps: 92 | Train Loss: 0.2470733 Vali Loss: 0.3366819 Test Loss: 0.4121570
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 73.80967164039612
Epoch: 16, Steps: 92 | Train Loss: 0.2470102 Vali Loss: 0.3373508 Test Loss: 0.4121239
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 65.4396619796753
Epoch: 17, Steps: 92 | Train Loss: 0.2469476 Vali Loss: 0.3368457 Test Loss: 0.4120097
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 63.75432848930359
Epoch: 18, Steps: 92 | Train Loss: 0.2469380 Vali Loss: 0.3370521 Test Loss: 0.4120827
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 64.80814242362976
Epoch: 19, Steps: 92 | Train Loss: 0.2467687 Vali Loss: 0.3373295 Test Loss: 0.4118814
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 83.41671299934387
Epoch: 20, Steps: 92 | Train Loss: 0.2469525 Vali Loss: 0.3373139 Test Loss: 0.4120089
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 74.54232406616211
Epoch: 21, Steps: 92 | Train Loss: 0.2467703 Vali Loss: 0.3366604 Test Loss: 0.4119081
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 68.28856563568115
Epoch: 22, Steps: 92 | Train Loss: 0.2468552 Vali Loss: 0.3356877 Test Loss: 0.4118383
Validation loss decreased (0.336262 --> 0.335688).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 68.29410648345947
Epoch: 23, Steps: 92 | Train Loss: 0.2467685 Vali Loss: 0.3363440 Test Loss: 0.4117955
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 111.72717118263245
Epoch: 24, Steps: 92 | Train Loss: 0.2467434 Vali Loss: 0.3362998 Test Loss: 0.4116364
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 116.6355049610138
Epoch: 25, Steps: 92 | Train Loss: 0.2466588 Vali Loss: 0.3366483 Test Loss: 0.4116747
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 114.54454922676086
Epoch: 26, Steps: 92 | Train Loss: 0.2466650 Vali Loss: 0.3376351 Test Loss: 0.4116682
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 114.53237271308899
Epoch: 27, Steps: 92 | Train Loss: 0.2466807 Vali Loss: 0.3367556 Test Loss: 0.4116316
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 75.76060461997986
Epoch: 28, Steps: 92 | Train Loss: 0.2466340 Vali Loss: 0.3367967 Test Loss: 0.4116838
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 70.80165457725525
Epoch: 29, Steps: 92 | Train Loss: 0.2465862 Vali Loss: 0.3367539 Test Loss: 0.4116055
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 70.7853844165802
Epoch: 30, Steps: 92 | Train Loss: 0.2466203 Vali Loss: 0.3385482 Test Loss: 0.4115732
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 71.58678936958313
Epoch: 31, Steps: 92 | Train Loss: 0.2466438 Vali Loss: 0.3351948 Test Loss: 0.4115450
Validation loss decreased (0.335688 --> 0.335195).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 72.79387903213501
Epoch: 32, Steps: 92 | Train Loss: 0.2465885 Vali Loss: 0.3367546 Test Loss: 0.4115061
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 70.62977075576782
Epoch: 33, Steps: 92 | Train Loss: 0.2464516 Vali Loss: 0.3369696 Test Loss: 0.4115350
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 105.66795039176941
Epoch: 34, Steps: 92 | Train Loss: 0.2465370 Vali Loss: 0.3376795 Test Loss: 0.4115365
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 108.82667303085327
Epoch: 35, Steps: 92 | Train Loss: 0.2465051 Vali Loss: 0.3359121 Test Loss: 0.4114095
EarlyStopping counter: 4 out of 10
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 66.21525239944458
Epoch: 36, Steps: 92 | Train Loss: 0.2465153 Vali Loss: 0.3354386 Test Loss: 0.4114966
EarlyStopping counter: 5 out of 10
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 75.61833214759827
Epoch: 37, Steps: 92 | Train Loss: 0.2465621 Vali Loss: 0.3370208 Test Loss: 0.4115097
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 71.35518741607666
Epoch: 38, Steps: 92 | Train Loss: 0.2465343 Vali Loss: 0.3372750 Test Loss: 0.4114985
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 66.58318758010864
Epoch: 39, Steps: 92 | Train Loss: 0.2465176 Vali Loss: 0.3375492 Test Loss: 0.4114496
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 66.77251744270325
Epoch: 40, Steps: 92 | Train Loss: 0.2463996 Vali Loss: 0.3368769 Test Loss: 0.4114471
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 65.92363810539246
Epoch: 41, Steps: 92 | Train Loss: 0.2464589 Vali Loss: 0.3369629 Test Loss: 0.4113713
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : Traffic_360_j96_H10_FITS_custom_ftM_sl360_ll48_pl96_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3413
mse:0.40994834899902344, mae:0.27993243932724, rse:0.5301735401153564, corr:[0.27512705 0.29092214 0.28949642 0.2913857  0.29072154 0.29198763
 0.292224   0.29225576 0.29282242 0.291997   0.2924318  0.2912065
 0.29182038 0.29081184 0.2905905  0.2901362  0.2900415  0.2904625
 0.28999108 0.29040185 0.29008043 0.29046503 0.28977224 0.2901331
 0.29164267 0.29226384 0.2926425  0.29211867 0.29239795 0.2916552
 0.2916468  0.29102713 0.2910987  0.29114816 0.2905727  0.29081875
 0.29020506 0.29050598 0.289784   0.29010227 0.2905154  0.2905654
 0.2912463  0.29103285 0.29127002 0.29110217 0.2914922  0.2912661
 0.29165438 0.291904   0.2916746  0.29167306 0.29092693 0.29112148
 0.2905237  0.29039    0.29031542 0.29015222 0.29045773 0.28982705
 0.29041234 0.29034516 0.2908638  0.2907571  0.2909515  0.29142106
 0.29086295 0.2912694  0.29094023 0.29133502 0.29089558 0.29071444
 0.29043663 0.28999853 0.29027683 0.2897677  0.29022726 0.28944045
 0.2897349  0.2893336  0.28933313 0.2897139  0.28956956 0.29056922
 0.2899849  0.29122666 0.29043537 0.2911656  0.29073882 0.29082838
 0.2906293  0.28881016 0.2888385  0.28657603 0.2887804  0.29069707]
