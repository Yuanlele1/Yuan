Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=258, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_720_j192_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_720_j192_H8_FITS_custom_ftM_sl720_ll48_pl192_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17501
val 2441
test 5069
Model(
  (freq_upsampler): Linear(in_features=258, out_features=326, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3455829504.0
params:  84434.0
Trainable parameters:  84434
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3681455
	speed: 0.6223s/iter; left time: 8401.5861s
Epoch: 1 cost time: 89.55450773239136
Epoch: 1, Steps: 136 | Train Loss: 0.5616759 Vali Loss: 0.2349336 Test Loss: 0.2834876
Validation loss decreased (inf --> 0.234934).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1815507
	speed: 1.6742s/iter; left time: 22375.8727s
Epoch: 2 cost time: 108.2318172454834
Epoch: 2, Steps: 136 | Train Loss: 0.2105961 Vali Loss: 0.1399779 Test Loss: 0.1713951
Validation loss decreased (0.234934 --> 0.139978).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1649361
	speed: 1.7273s/iter; left time: 22850.2896s
Epoch: 3 cost time: 105.12589359283447
Epoch: 3, Steps: 136 | Train Loss: 0.1620467 Vali Loss: 0.1304722 Test Loss: 0.1585389
Validation loss decreased (0.139978 --> 0.130472).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1654411
	speed: 1.7365s/iter; left time: 22735.6894s
Epoch: 4 cost time: 106.92801809310913
Epoch: 4, Steps: 136 | Train Loss: 0.1563742 Vali Loss: 0.1292178 Test Loss: 0.1566232
Validation loss decreased (0.130472 --> 0.129218).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1666573
	speed: 1.7048s/iter; left time: 22089.6604s
Epoch: 5 cost time: 105.62275695800781
Epoch: 5, Steps: 136 | Train Loss: 0.1549395 Vali Loss: 0.1287210 Test Loss: 0.1559068
Validation loss decreased (0.129218 --> 0.128721).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1511210
	speed: 1.6475s/iter; left time: 21123.0630s
Epoch: 6 cost time: 94.5725908279419
Epoch: 6, Steps: 136 | Train Loss: 0.1542354 Vali Loss: 0.1284858 Test Loss: 0.1555022
Validation loss decreased (0.128721 --> 0.128486).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1567819
	speed: 1.7219s/iter; left time: 21842.1867s
Epoch: 7 cost time: 111.43958187103271
Epoch: 7, Steps: 136 | Train Loss: 0.1536570 Vali Loss: 0.1281700 Test Loss: 0.1551973
Validation loss decreased (0.128486 --> 0.128170).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1594242
	speed: 2.1123s/iter; left time: 26507.4030s
Epoch: 8 cost time: 130.21753525733948
Epoch: 8, Steps: 136 | Train Loss: 0.1533750 Vali Loss: 0.1280612 Test Loss: 0.1549793
Validation loss decreased (0.128170 --> 0.128061).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1480512
	speed: 2.1928s/iter; left time: 27219.3935s
Epoch: 9 cost time: 130.34154796600342
Epoch: 9, Steps: 136 | Train Loss: 0.1530764 Vali Loss: 0.1279028 Test Loss: 0.1548985
Validation loss decreased (0.128061 --> 0.127903).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1497961
	speed: 1.8791s/iter; left time: 23069.7952s
Epoch: 10 cost time: 103.60321998596191
Epoch: 10, Steps: 136 | Train Loss: 0.1529348 Vali Loss: 0.1278569 Test Loss: 0.1547245
Validation loss decreased (0.127903 --> 0.127857).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1489512
	speed: 2.1087s/iter; left time: 25602.1954s
Epoch: 11 cost time: 162.32889437675476
Epoch: 11, Steps: 136 | Train Loss: 0.1528538 Vali Loss: 0.1277412 Test Loss: 0.1545964
Validation loss decreased (0.127857 --> 0.127741).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1586242
	speed: 2.7147s/iter; left time: 32590.0308s
Epoch: 12 cost time: 155.85807704925537
Epoch: 12, Steps: 136 | Train Loss: 0.1526772 Vali Loss: 0.1278512 Test Loss: 0.1545886
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1643963
	speed: 2.6812s/iter; left time: 31823.1632s
Epoch: 13 cost time: 170.3766016960144
Epoch: 13, Steps: 136 | Train Loss: 0.1525912 Vali Loss: 0.1276582 Test Loss: 0.1545730
Validation loss decreased (0.127741 --> 0.127658).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1545935
	speed: 2.7153s/iter; left time: 31858.3447s
Epoch: 14 cost time: 171.10743927955627
Epoch: 14, Steps: 136 | Train Loss: 0.1525184 Vali Loss: 0.1276505 Test Loss: 0.1545056
Validation loss decreased (0.127658 --> 0.127650).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1488415
	speed: 2.9079s/iter; left time: 33722.5733s
Epoch: 15 cost time: 172.50154304504395
Epoch: 15, Steps: 136 | Train Loss: 0.1525303 Vali Loss: 0.1275930 Test Loss: 0.1544530
Validation loss decreased (0.127650 --> 0.127593).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1537359
	speed: 2.8255s/iter; left time: 32383.5384s
Epoch: 16 cost time: 174.44131803512573
Epoch: 16, Steps: 136 | Train Loss: 0.1524145 Vali Loss: 0.1276072 Test Loss: 0.1544317
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1506557
	speed: 2.8681s/iter; left time: 32481.4561s
Epoch: 17 cost time: 178.8306303024292
Epoch: 17, Steps: 136 | Train Loss: 0.1524338 Vali Loss: 0.1275884 Test Loss: 0.1544113
Validation loss decreased (0.127593 --> 0.127588).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1526580
	speed: 2.9749s/iter; left time: 33286.4177s
Epoch: 18 cost time: 169.63104581832886
Epoch: 18, Steps: 136 | Train Loss: 0.1523432 Vali Loss: 0.1275765 Test Loss: 0.1543814
Validation loss decreased (0.127588 --> 0.127576).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1530752
	speed: 2.9412s/iter; left time: 32508.5931s
Epoch: 19 cost time: 197.17131161689758
Epoch: 19, Steps: 136 | Train Loss: 0.1523156 Vali Loss: 0.1274892 Test Loss: 0.1543738
Validation loss decreased (0.127576 --> 0.127489).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1578510
	speed: 3.2862s/iter; left time: 35875.4493s
Epoch: 20 cost time: 182.381285905838
Epoch: 20, Steps: 136 | Train Loss: 0.1522815 Vali Loss: 0.1275835 Test Loss: 0.1543186
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1385231
	speed: 2.5175s/iter; left time: 27140.9654s
Epoch: 21 cost time: 152.3545205593109
Epoch: 21, Steps: 136 | Train Loss: 0.1523441 Vali Loss: 0.1275614 Test Loss: 0.1543463
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1598198
	speed: 2.4701s/iter; left time: 26294.5518s
Epoch: 22 cost time: 141.01837801933289
Epoch: 22, Steps: 136 | Train Loss: 0.1522625 Vali Loss: 0.1275938 Test Loss: 0.1543082
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1531310
	speed: 2.1077s/iter; left time: 22149.3121s
Epoch: 23 cost time: 125.78241658210754
Epoch: 23, Steps: 136 | Train Loss: 0.1522021 Vali Loss: 0.1274599 Test Loss: 0.1542965
Validation loss decreased (0.127489 --> 0.127460).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1546579
	speed: 2.0397s/iter; left time: 21157.7724s
Epoch: 24 cost time: 135.2458245754242
Epoch: 24, Steps: 136 | Train Loss: 0.1522023 Vali Loss: 0.1275605 Test Loss: 0.1542780
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1487847
	speed: 2.2241s/iter; left time: 22768.3210s
Epoch: 25 cost time: 129.74527406692505
Epoch: 25, Steps: 136 | Train Loss: 0.1521433 Vali Loss: 0.1274081 Test Loss: 0.1542481
Validation loss decreased (0.127460 --> 0.127408).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1528193
	speed: 2.3642s/iter; left time: 23880.5714s
Epoch: 26 cost time: 140.17811584472656
Epoch: 26, Steps: 136 | Train Loss: 0.1521719 Vali Loss: 0.1275221 Test Loss: 0.1542267
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1554460
	speed: 2.2943s/iter; left time: 22862.4346s
Epoch: 27 cost time: 142.36791729927063
Epoch: 27, Steps: 136 | Train Loss: 0.1521536 Vali Loss: 0.1274790 Test Loss: 0.1542646
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1533669
	speed: 2.2903s/iter; left time: 22511.0051s
Epoch: 28 cost time: 148.94078302383423
Epoch: 28, Steps: 136 | Train Loss: 0.1521019 Vali Loss: 0.1274429 Test Loss: 0.1542419
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1453153
	speed: 2.3583s/iter; left time: 22859.2217s
Epoch: 29 cost time: 145.21090936660767
Epoch: 29, Steps: 136 | Train Loss: 0.1521195 Vali Loss: 0.1275007 Test Loss: 0.1542045
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1530819
	speed: 2.2106s/iter; left time: 21126.2466s
Epoch: 30 cost time: 140.33481097221375
Epoch: 30, Steps: 136 | Train Loss: 0.1521316 Vali Loss: 0.1273962 Test Loss: 0.1542083
Validation loss decreased (0.127408 --> 0.127396).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1456680
	speed: 2.4172s/iter; left time: 22772.8078s
Epoch: 31 cost time: 128.72996258735657
Epoch: 31, Steps: 136 | Train Loss: 0.1520701 Vali Loss: 0.1273857 Test Loss: 0.1542154
Validation loss decreased (0.127396 --> 0.127386).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1489589
	speed: 1.6514s/iter; left time: 15333.3083s
Epoch: 32 cost time: 101.70250129699707
Epoch: 32, Steps: 136 | Train Loss: 0.1520202 Vali Loss: 0.1274406 Test Loss: 0.1541951
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1369739
	speed: 1.7720s/iter; left time: 16211.7863s
Epoch: 33 cost time: 106.28713822364807
Epoch: 33, Steps: 136 | Train Loss: 0.1521186 Vali Loss: 0.1273908 Test Loss: 0.1541765
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1440286
	speed: 1.7091s/iter; left time: 15403.9935s
Epoch: 34 cost time: 108.34690642356873
Epoch: 34, Steps: 136 | Train Loss: 0.1521010 Vali Loss: 0.1272772 Test Loss: 0.1541609
Validation loss decreased (0.127386 --> 0.127277).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1510931
	speed: 1.6812s/iter; left time: 14924.2347s
Epoch: 35 cost time: 106.78875803947449
Epoch: 35, Steps: 136 | Train Loss: 0.1520528 Vali Loss: 0.1272984 Test Loss: 0.1541715
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1536089
	speed: 1.6577s/iter; left time: 14489.7623s
Epoch: 36 cost time: 104.29083752632141
Epoch: 36, Steps: 136 | Train Loss: 0.1520639 Vali Loss: 0.1273073 Test Loss: 0.1541475
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1450827
	speed: 1.7977s/iter; left time: 15468.9810s
Epoch: 37 cost time: 111.68071389198303
Epoch: 37, Steps: 136 | Train Loss: 0.1520529 Vali Loss: 0.1274160 Test Loss: 0.1541565
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1521609
	speed: 1.7889s/iter; left time: 15150.5847s
Epoch: 38 cost time: 108.63650369644165
Epoch: 38, Steps: 136 | Train Loss: 0.1520058 Vali Loss: 0.1273970 Test Loss: 0.1541610
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1639942
	speed: 1.6703s/iter; left time: 13918.6023s
Epoch: 39 cost time: 105.51138043403625
Epoch: 39, Steps: 136 | Train Loss: 0.1520739 Vali Loss: 0.1273563 Test Loss: 0.1541557
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1511790
	speed: 1.6810s/iter; left time: 13778.8858s
Epoch: 40 cost time: 106.0813570022583
Epoch: 40, Steps: 136 | Train Loss: 0.1519911 Vali Loss: 0.1274438 Test Loss: 0.1541544
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1560321
	speed: 1.6862s/iter; left time: 13592.1392s
Epoch: 41 cost time: 102.1377420425415
Epoch: 41, Steps: 136 | Train Loss: 0.1520417 Vali Loss: 0.1273356 Test Loss: 0.1541502
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1660550
	speed: 1.5725s/iter; left time: 12462.0098s
Epoch: 42 cost time: 92.30487012863159
Epoch: 42, Steps: 136 | Train Loss: 0.1520067 Vali Loss: 0.1273719 Test Loss: 0.1541442
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1526063
	speed: 1.5131s/iter; left time: 11785.2060s
Epoch: 43 cost time: 99.97707962989807
Epoch: 43, Steps: 136 | Train Loss: 0.1520117 Vali Loss: 0.1273980 Test Loss: 0.1541426
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1481943
	speed: 1.6658s/iter; left time: 12748.6751s
Epoch: 44 cost time: 96.10871124267578
Epoch: 44, Steps: 136 | Train Loss: 0.1520348 Vali Loss: 0.1273786 Test Loss: 0.1541473
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1584100
	speed: 1.5521s/iter; left time: 11667.2104s
Epoch: 45 cost time: 96.20352816581726
Epoch: 45, Steps: 136 | Train Loss: 0.1520560 Vali Loss: 0.1273143 Test Loss: 0.1541499
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1457773
	speed: 1.4122s/iter; left time: 10423.5161s
Epoch: 46 cost time: 92.8027331829071
Epoch: 46, Steps: 136 | Train Loss: 0.1520351 Vali Loss: 0.1274591 Test Loss: 0.1541413
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1537938
	speed: 1.4694s/iter; left time: 10645.6695s
Epoch: 47 cost time: 89.431560754776
Epoch: 47, Steps: 136 | Train Loss: 0.1520011 Vali Loss: 0.1273633 Test Loss: 0.1541412
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1557848
	speed: 1.5925s/iter; left time: 11321.1594s
Epoch: 48 cost time: 98.52273321151733
Epoch: 48, Steps: 136 | Train Loss: 0.1519873 Vali Loss: 0.1273651 Test Loss: 0.1541286
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1465567
	speed: 1.7022s/iter; left time: 11869.7839s
Epoch: 49 cost time: 108.51020932197571
Epoch: 49, Steps: 136 | Train Loss: 0.1519573 Vali Loss: 0.1272983 Test Loss: 0.1541326
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1505701
	speed: 1.5636s/iter; left time: 10690.5655s
Epoch: 50 cost time: 94.86066126823425
Epoch: 50, Steps: 136 | Train Loss: 0.1519940 Vali Loss: 0.1273793 Test Loss: 0.1541232
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1572277
	speed: 1.5138s/iter; left time: 10144.2654s
Epoch: 51 cost time: 96.22549104690552
Epoch: 51, Steps: 136 | Train Loss: 0.1519892 Vali Loss: 0.1273203 Test Loss: 0.1541302
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1440937
	speed: 1.5184s/iter; left time: 9968.0517s
Epoch: 52 cost time: 91.74596405029297
Epoch: 52, Steps: 136 | Train Loss: 0.1519670 Vali Loss: 0.1273302 Test Loss: 0.1541270
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1574706
	speed: 1.4821s/iter; left time: 9528.2339s
Epoch: 53 cost time: 94.40187072753906
Epoch: 53, Steps: 136 | Train Loss: 0.1520440 Vali Loss: 0.1273454 Test Loss: 0.1541157
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1669926
	speed: 1.4979s/iter; left time: 9426.3353s
Epoch: 54 cost time: 92.21576714515686
Epoch: 54, Steps: 136 | Train Loss: 0.1520021 Vali Loss: 0.1273708 Test Loss: 0.1541193
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_720_j192_H8_FITS_custom_ftM_sl720_ll48_pl192_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5069
mse:0.15128356218338013, mae:0.24790848791599274, rse:0.3867214322090149, corr:[0.46408567 0.46538574 0.46725458 0.46724376 0.46831247 0.46820995
 0.46818796 0.46836615 0.4679754  0.4678748  0.46791625 0.4678134
 0.4676788  0.46773264 0.46782947 0.4677353  0.46773067 0.46771663
 0.46757963 0.46753114 0.46741623 0.4673208  0.46748084 0.46773782
 0.4680198  0.46834415 0.4683282  0.46823806 0.4682477  0.46809033
 0.46788794 0.46783328 0.4677107  0.46749422 0.46731964 0.46729454
 0.46725968 0.46718487 0.46717155 0.46707624 0.4669672  0.46688876
 0.46667147 0.4665089  0.46649346 0.46636996 0.4663719  0.46659586
 0.46672183 0.46684605 0.46694022 0.46688274 0.46680805 0.46673068
 0.4665895  0.46653548 0.4665522  0.4665022  0.4664011  0.46638858
 0.46643808 0.46639687 0.46641147 0.46645695 0.46637115 0.46636248
 0.46634373 0.46605363 0.4659236  0.4659051  0.46573085 0.46587223
 0.46614787 0.4661385  0.46610254 0.46614927 0.46605343 0.46596202
 0.46595484 0.46589884 0.46584395 0.4658378  0.46582088 0.4657606
 0.4657359  0.4657706  0.46572623 0.46569934 0.46576828 0.46570957
 0.4655867  0.46549192 0.46531194 0.46523163 0.46527562 0.4653217
 0.46547842 0.4656225  0.46556133 0.46556285 0.46559626 0.4655093
 0.46545377 0.46545756 0.4653891  0.46531808 0.46529707 0.46531585
 0.46525684 0.46518496 0.46521792 0.46520793 0.46515056 0.46511725
 0.46507248 0.46510458 0.46517643 0.4651279  0.46518728 0.4654672
 0.46565822 0.46574184 0.46586832 0.4658635  0.46576583 0.465775
 0.46577063 0.4656787  0.46562812 0.46558163 0.4654008  0.46529528
 0.4653142  0.46522194 0.46519506 0.46530008 0.46529078 0.46532294
 0.46541595 0.46517828 0.4649921  0.46499124 0.46487004 0.46496367
 0.4651653  0.46513602 0.46512815 0.46525097 0.4652481  0.4651806
 0.46514377 0.4650656  0.4649565  0.46488917 0.46478906 0.46465302
 0.46472004 0.46483484 0.46476942 0.46487865 0.46509847 0.46500412
 0.4649604  0.46488672 0.4645302  0.46443334 0.46445978 0.46439627
 0.46444356 0.4644928  0.46437854 0.46439448 0.46428394 0.463946
 0.46375003 0.4636593  0.46345815 0.4633138  0.4632753  0.46320543
 0.46317682 0.46347046 0.4634287  0.46313316 0.46344706 0.46330756
 0.46288925 0.46305215 0.46237049 0.4629003  0.46299353 0.4635373 ]
