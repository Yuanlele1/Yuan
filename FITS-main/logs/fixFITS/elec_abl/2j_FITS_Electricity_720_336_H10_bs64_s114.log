Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=320, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_720_j336_H10', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_720_j336_H10_FITS_custom_ftM_sl720_ll48_pl336_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17357
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=320, out_features=469, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6166487040.0
params:  150549.0
Trainable parameters:  150549
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6996817
	speed: 0.7344s/iter; left time: 9841.6853s
Epoch: 1 cost time: 96.22510051727295
Epoch: 1, Steps: 135 | Train Loss: 0.8302913 Vali Loss: 0.6294429 Test Loss: 0.7300372
Validation loss decreased (inf --> 0.629443).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5878541
	speed: 1.4829s/iter; left time: 19671.7571s
Epoch: 2 cost time: 88.51537656784058
Epoch: 2, Steps: 135 | Train Loss: 0.6151779 Vali Loss: 0.5540031 Test Loss: 0.6443761
Validation loss decreased (0.629443 --> 0.554003).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4976290
	speed: 1.5831s/iter; left time: 20787.2146s
Epoch: 3 cost time: 114.28437352180481
Epoch: 3, Steps: 135 | Train Loss: 0.5261951 Vali Loss: 0.4919574 Test Loss: 0.5748482
Validation loss decreased (0.554003 --> 0.491957).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4357173
	speed: 2.2089s/iter; left time: 28707.1330s
Epoch: 4 cost time: 117.6532051563263
Epoch: 4, Steps: 135 | Train Loss: 0.4556733 Vali Loss: 0.4437802 Test Loss: 0.5209824
Validation loss decreased (0.491957 --> 0.443780).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3832786
	speed: 1.5610s/iter; left time: 20075.5185s
Epoch: 5 cost time: 92.7452278137207
Epoch: 5, Steps: 135 | Train Loss: 0.3977253 Vali Loss: 0.4028412 Test Loss: 0.4753466
Validation loss decreased (0.443780 --> 0.402841).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3319526
	speed: 1.5238s/iter; left time: 19392.1259s
Epoch: 6 cost time: 91.54154205322266
Epoch: 6, Steps: 135 | Train Loss: 0.3494926 Vali Loss: 0.3645346 Test Loss: 0.4320406
Validation loss decreased (0.402841 --> 0.364535).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3025044
	speed: 1.8257s/iter; left time: 22987.7689s
Epoch: 7 cost time: 118.77544212341309
Epoch: 7, Steps: 135 | Train Loss: 0.3088966 Vali Loss: 0.3344750 Test Loss: 0.3979784
Validation loss decreased (0.364535 --> 0.334475).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2658999
	speed: 2.0478s/iter; left time: 25507.6264s
Epoch: 8 cost time: 123.20183944702148
Epoch: 8, Steps: 135 | Train Loss: 0.2745857 Vali Loss: 0.3088096 Test Loss: 0.3683173
Validation loss decreased (0.334475 --> 0.308810).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2357946
	speed: 1.9421s/iter; left time: 23928.7276s
Epoch: 9 cost time: 116.5237946510315
Epoch: 9, Steps: 135 | Train Loss: 0.2454755 Vali Loss: 0.2849837 Test Loss: 0.3416396
Validation loss decreased (0.308810 --> 0.284984).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2228222
	speed: 1.9451s/iter; left time: 23703.5503s
Epoch: 10 cost time: 120.78610897064209
Epoch: 10, Steps: 135 | Train Loss: 0.2206118 Vali Loss: 0.2668913 Test Loss: 0.3209486
Validation loss decreased (0.284984 --> 0.266891).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1905887
	speed: 1.8755s/iter; left time: 22601.4140s
Epoch: 11 cost time: 108.67256021499634
Epoch: 11, Steps: 135 | Train Loss: 0.1993097 Vali Loss: 0.2508262 Test Loss: 0.3024429
Validation loss decreased (0.266891 --> 0.250826).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1804764
	speed: 1.9385s/iter; left time: 23099.2036s
Epoch: 12 cost time: 115.9844536781311
Epoch: 12, Steps: 135 | Train Loss: 0.1810050 Vali Loss: 0.2362047 Test Loss: 0.2851862
Validation loss decreased (0.250826 --> 0.236205).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1652115
	speed: 1.9102s/iter; left time: 22503.5354s
Epoch: 13 cost time: 109.64399909973145
Epoch: 13, Steps: 135 | Train Loss: 0.1652408 Vali Loss: 0.2241696 Test Loss: 0.2715096
Validation loss decreased (0.236205 --> 0.224170).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1546085
	speed: 1.9167s/iter; left time: 22321.4825s
Epoch: 14 cost time: 117.79481339454651
Epoch: 14, Steps: 135 | Train Loss: 0.1515986 Vali Loss: 0.2127269 Test Loss: 0.2581614
Validation loss decreased (0.224170 --> 0.212727).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1407567
	speed: 1.8965s/iter; left time: 21830.6477s
Epoch: 15 cost time: 121.18752837181091
Epoch: 15, Steps: 135 | Train Loss: 0.1398379 Vali Loss: 0.2036296 Test Loss: 0.2475351
Validation loss decreased (0.212727 --> 0.203630).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1325325
	speed: 1.8344s/iter; left time: 20867.9802s
Epoch: 16 cost time: 105.70311141014099
Epoch: 16, Steps: 135 | Train Loss: 0.1295611 Vali Loss: 0.1958103 Test Loss: 0.2382372
Validation loss decreased (0.203630 --> 0.195810).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1178999
	speed: 1.9001s/iter; left time: 21358.8340s
Epoch: 17 cost time: 120.54730653762817
Epoch: 17, Steps: 135 | Train Loss: 0.1207133 Vali Loss: 0.1894743 Test Loss: 0.2303241
Validation loss decreased (0.195810 --> 0.189474).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1093275
	speed: 2.0028s/iter; left time: 22243.4124s
Epoch: 18 cost time: 112.99761152267456
Epoch: 18, Steps: 135 | Train Loss: 0.1129997 Vali Loss: 0.1825820 Test Loss: 0.2220037
Validation loss decreased (0.189474 --> 0.182582).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1043127
	speed: 1.9929s/iter; left time: 21864.3573s
Epoch: 19 cost time: 118.51788854598999
Epoch: 19, Steps: 135 | Train Loss: 0.1062613 Vali Loss: 0.1781787 Test Loss: 0.2169261
Validation loss decreased (0.182582 --> 0.178179).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1015771
	speed: 1.8115s/iter; left time: 19629.7747s
Epoch: 20 cost time: 111.29161143302917
Epoch: 20, Steps: 135 | Train Loss: 0.1003990 Vali Loss: 0.1734099 Test Loss: 0.2109646
Validation loss decreased (0.178179 --> 0.173410).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.0943994
	speed: 2.0276s/iter; left time: 21697.3514s
Epoch: 21 cost time: 156.01280426979065
Epoch: 21, Steps: 135 | Train Loss: 0.0952379 Vali Loss: 0.1692990 Test Loss: 0.2061325
Validation loss decreased (0.173410 --> 0.169299).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.0871131
	speed: 3.3266s/iter; left time: 35148.5991s
Epoch: 22 cost time: 161.12922358512878
Epoch: 22, Steps: 135 | Train Loss: 0.0907286 Vali Loss: 0.1660116 Test Loss: 0.2020980
Validation loss decreased (0.169299 --> 0.166012).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.0887295
	speed: 3.4768s/iter; left time: 36266.4050s
Epoch: 23 cost time: 241.12765073776245
Epoch: 23, Steps: 135 | Train Loss: 0.0868084 Vali Loss: 0.1625210 Test Loss: 0.1978997
Validation loss decreased (0.166012 --> 0.162521).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.0814133
	speed: 2.7124s/iter; left time: 27926.5195s
Epoch: 24 cost time: 145.2654583454132
Epoch: 24, Steps: 135 | Train Loss: 0.0833647 Vali Loss: 0.1602114 Test Loss: 0.1945146
Validation loss decreased (0.162521 --> 0.160211).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.0807090
	speed: 2.4345s/iter; left time: 24737.1947s
Epoch: 25 cost time: 148.34214091300964
Epoch: 25, Steps: 135 | Train Loss: 0.0803453 Vali Loss: 0.1576473 Test Loss: 0.1917477
Validation loss decreased (0.160211 --> 0.157647).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.0759550
	speed: 1.9226s/iter; left time: 19275.6627s
Epoch: 26 cost time: 113.09065556526184
Epoch: 26, Steps: 135 | Train Loss: 0.0776861 Vali Loss: 0.1558972 Test Loss: 0.1890924
Validation loss decreased (0.157647 --> 0.155897).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.0762625
	speed: 1.9753s/iter; left time: 19537.8709s
Epoch: 27 cost time: 121.12342500686646
Epoch: 27, Steps: 135 | Train Loss: 0.0753580 Vali Loss: 0.1541276 Test Loss: 0.1869094
Validation loss decreased (0.155897 --> 0.154128).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.0716570
	speed: 2.4455s/iter; left time: 23858.1120s
Epoch: 28 cost time: 157.23940467834473
Epoch: 28, Steps: 135 | Train Loss: 0.0733129 Vali Loss: 0.1523959 Test Loss: 0.1847856
Validation loss decreased (0.154128 --> 0.152396).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.0697703
	speed: 2.1029s/iter; left time: 20232.3186s
Epoch: 29 cost time: 127.77370738983154
Epoch: 29, Steps: 135 | Train Loss: 0.0715012 Vali Loss: 0.1511335 Test Loss: 0.1833141
Validation loss decreased (0.152396 --> 0.151134).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.0690518
	speed: 2.0388s/iter; left time: 19339.6490s
Epoch: 30 cost time: 120.51007080078125
Epoch: 30, Steps: 135 | Train Loss: 0.0699176 Vali Loss: 0.1499584 Test Loss: 0.1813833
Validation loss decreased (0.151134 --> 0.149958).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.0666757
	speed: 1.9957s/iter; left time: 18662.0119s
Epoch: 31 cost time: 119.8389322757721
Epoch: 31, Steps: 135 | Train Loss: 0.0685028 Vali Loss: 0.1488919 Test Loss: 0.1799847
Validation loss decreased (0.149958 --> 0.148892).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.0658153
	speed: 3.3669s/iter; left time: 31029.3804s
Epoch: 32 cost time: 225.01471972465515
Epoch: 32, Steps: 135 | Train Loss: 0.0672671 Vali Loss: 0.1480582 Test Loss: 0.1790104
Validation loss decreased (0.148892 --> 0.148058).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.0656111
	speed: 2.6460s/iter; left time: 24028.5486s
Epoch: 33 cost time: 115.85794591903687
Epoch: 33, Steps: 135 | Train Loss: 0.0661701 Vali Loss: 0.1472712 Test Loss: 0.1778636
Validation loss decreased (0.148058 --> 0.147271).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.0639993
	speed: 2.0261s/iter; left time: 18125.9314s
Epoch: 34 cost time: 119.95338463783264
Epoch: 34, Steps: 135 | Train Loss: 0.0652047 Vali Loss: 0.1464524 Test Loss: 0.1768324
Validation loss decreased (0.147271 --> 0.146452).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.0633416
	speed: 3.3123s/iter; left time: 29185.0022s
Epoch: 35 cost time: 231.80072402954102
Epoch: 35, Steps: 135 | Train Loss: 0.0643618 Vali Loss: 0.1458937 Test Loss: 0.1758868
Validation loss decreased (0.146452 --> 0.145894).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.0613444
	speed: 3.4245s/iter; left time: 29710.8875s
Epoch: 36 cost time: 166.96351981163025
Epoch: 36, Steps: 135 | Train Loss: 0.0636316 Vali Loss: 0.1456136 Test Loss: 0.1753632
Validation loss decreased (0.145894 --> 0.145614).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.0650385
	speed: 2.0090s/iter; left time: 17159.1657s
Epoch: 37 cost time: 112.67279863357544
Epoch: 37, Steps: 135 | Train Loss: 0.0629792 Vali Loss: 0.1451815 Test Loss: 0.1745283
Validation loss decreased (0.145614 --> 0.145182).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.0629157
	speed: 1.8913s/iter; left time: 15898.4621s
Epoch: 38 cost time: 116.8432788848877
Epoch: 38, Steps: 135 | Train Loss: 0.0623750 Vali Loss: 0.1444961 Test Loss: 0.1739517
Validation loss decreased (0.145182 --> 0.144496).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.0612170
	speed: 2.9948s/iter; left time: 24769.8342s
Epoch: 39 cost time: 213.4980812072754
Epoch: 39, Steps: 135 | Train Loss: 0.0618911 Vali Loss: 0.1441870 Test Loss: 0.1733642
Validation loss decreased (0.144496 --> 0.144187).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.0606785
	speed: 2.2716s/iter; left time: 18481.8461s
Epoch: 40 cost time: 112.86381793022156
Epoch: 40, Steps: 135 | Train Loss: 0.0614334 Vali Loss: 0.1442179 Test Loss: 0.1729556
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.0624503
	speed: 1.8769s/iter; left time: 15017.2779s
Epoch: 41 cost time: 118.36890530586243
Epoch: 41, Steps: 135 | Train Loss: 0.0610248 Vali Loss: 0.1437391 Test Loss: 0.1725526
Validation loss decreased (0.144187 --> 0.143739).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.0655509
	speed: 1.8893s/iter; left time: 14860.8851s
Epoch: 42 cost time: 109.35798048973083
Epoch: 42, Steps: 135 | Train Loss: 0.0606462 Vali Loss: 0.1437381 Test Loss: 0.1722359
Validation loss decreased (0.143739 --> 0.143738).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.0613457
	speed: 1.9441s/iter; left time: 15029.5504s
Epoch: 43 cost time: 122.40305542945862
Epoch: 43, Steps: 135 | Train Loss: 0.0603565 Vali Loss: 0.1434651 Test Loss: 0.1718438
Validation loss decreased (0.143738 --> 0.143465).  Saving model ...
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.0601091
	speed: 2.2578s/iter; left time: 17150.0911s
Epoch: 44 cost time: 130.3511528968811
Epoch: 44, Steps: 135 | Train Loss: 0.0600831 Vali Loss: 0.1433756 Test Loss: 0.1715133
Validation loss decreased (0.143465 --> 0.143376).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.0641098
	speed: 1.9357s/iter; left time: 14442.5046s
Epoch: 45 cost time: 107.37449336051941
Epoch: 45, Steps: 135 | Train Loss: 0.0598402 Vali Loss: 0.1429824 Test Loss: 0.1712596
Validation loss decreased (0.143376 --> 0.142982).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.0603849
	speed: 1.9140s/iter; left time: 14022.2665s
Epoch: 46 cost time: 133.50726675987244
Epoch: 46, Steps: 135 | Train Loss: 0.0596263 Vali Loss: 0.1429197 Test Loss: 0.1710929
Validation loss decreased (0.142982 --> 0.142920).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.0600669
	speed: 1.9084s/iter; left time: 13723.0654s
Epoch: 47 cost time: 98.86222791671753
Epoch: 47, Steps: 135 | Train Loss: 0.0594477 Vali Loss: 0.1426591 Test Loss: 0.1707884
Validation loss decreased (0.142920 --> 0.142659).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.0590439
	speed: 1.9227s/iter; left time: 13566.2273s
Epoch: 48 cost time: 154.820148229599
Epoch: 48, Steps: 135 | Train Loss: 0.0592561 Vali Loss: 0.1425899 Test Loss: 0.1706832
Validation loss decreased (0.142659 --> 0.142590).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.0575958
	speed: 2.1583s/iter; left time: 14937.8590s
Epoch: 49 cost time: 103.87282395362854
Epoch: 49, Steps: 135 | Train Loss: 0.0591312 Vali Loss: 0.1425634 Test Loss: 0.1704680
Validation loss decreased (0.142590 --> 0.142563).  Saving model ...
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.0623015
	speed: 1.8324s/iter; left time: 12434.5955s
Epoch: 50 cost time: 125.820876121521
Epoch: 50, Steps: 135 | Train Loss: 0.0589852 Vali Loss: 0.1426212 Test Loss: 0.1703087
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.0578204
	speed: 2.0699s/iter; left time: 13766.6123s
Epoch: 51 cost time: 97.43108201026917
Epoch: 51, Steps: 135 | Train Loss: 0.0588652 Vali Loss: 0.1424356 Test Loss: 0.1701703
Validation loss decreased (0.142563 --> 0.142436).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.0594137
	speed: 1.5404s/iter; left time: 10037.4577s
Epoch: 52 cost time: 96.02631187438965
Epoch: 52, Steps: 135 | Train Loss: 0.0587696 Vali Loss: 0.1425501 Test Loss: 0.1700327
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.0614406
	speed: 1.5890s/iter; left time: 10139.3652s
Epoch: 53 cost time: 93.6935122013092
Epoch: 53, Steps: 135 | Train Loss: 0.0586722 Vali Loss: 0.1422883 Test Loss: 0.1699452
Validation loss decreased (0.142436 --> 0.142288).  Saving model ...
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.0587711
	speed: 1.4954s/iter; left time: 9340.1456s
Epoch: 54 cost time: 89.36986589431763
Epoch: 54, Steps: 135 | Train Loss: 0.0586097 Vali Loss: 0.1424798 Test Loss: 0.1698629
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.0552994
	speed: 1.6421s/iter; left time: 10034.8966s
Epoch: 55 cost time: 101.20985817909241
Epoch: 55, Steps: 135 | Train Loss: 0.0585199 Vali Loss: 0.1423424 Test Loss: 0.1697802
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.0573233
	speed: 1.9641s/iter; left time: 11737.2835s
Epoch: 56 cost time: 122.78617119789124
Epoch: 56, Steps: 135 | Train Loss: 0.0584820 Vali Loss: 0.1423128 Test Loss: 0.1696676
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.0619119
	speed: 1.5562s/iter; left time: 9089.8602s
Epoch: 57 cost time: 88.43837428092957
Epoch: 57, Steps: 135 | Train Loss: 0.0584144 Vali Loss: 0.1424551 Test Loss: 0.1696045
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.0547257
	speed: 1.6801s/iter; left time: 9586.5614s
Epoch: 58 cost time: 104.3347635269165
Epoch: 58, Steps: 135 | Train Loss: 0.0583696 Vali Loss: 0.1421245 Test Loss: 0.1695503
Validation loss decreased (0.142288 --> 0.142125).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.0609294
	speed: 1.4632s/iter; left time: 8151.7437s
Epoch: 59 cost time: 88.38315677642822
Epoch: 59, Steps: 135 | Train Loss: 0.0582991 Vali Loss: 0.1424005 Test Loss: 0.1694954
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.0565456
	speed: 1.5447s/iter; left time: 8396.7685s
Epoch: 60 cost time: 94.38883948326111
Epoch: 60, Steps: 135 | Train Loss: 0.0583009 Vali Loss: 0.1422415 Test Loss: 0.1694412
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.0577052
	speed: 1.8570s/iter; left time: 9843.7810s
Epoch: 61 cost time: 112.94849371910095
Epoch: 61, Steps: 135 | Train Loss: 0.0582627 Vali Loss: 0.1423229 Test Loss: 0.1693763
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.0579915
	speed: 2.0124s/iter; left time: 10395.8069s
Epoch: 62 cost time: 142.3426525592804
Epoch: 62, Steps: 135 | Train Loss: 0.0582335 Vali Loss: 0.1421760 Test Loss: 0.1693470
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.0567321
	speed: 1.9138s/iter; left time: 9628.5476s
Epoch: 63 cost time: 93.79105305671692
Epoch: 63, Steps: 135 | Train Loss: 0.0581892 Vali Loss: 0.1423673 Test Loss: 0.1693213
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.0633309
	speed: 1.5162s/iter; left time: 7423.2312s
Epoch: 64 cost time: 90.32478451728821
Epoch: 64, Steps: 135 | Train Loss: 0.0581823 Vali Loss: 0.1420478 Test Loss: 0.1692808
Validation loss decreased (0.142125 --> 0.142048).  Saving model ...
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.0618972
	speed: 1.4748s/iter; left time: 7021.6549s
Epoch: 65 cost time: 90.57124614715576
Epoch: 65, Steps: 135 | Train Loss: 0.0581583 Vali Loss: 0.1427101 Test Loss: 0.1692493
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.0561363
	speed: 1.4812s/iter; left time: 6852.1550s
Epoch: 66 cost time: 85.18714189529419
Epoch: 66, Steps: 135 | Train Loss: 0.0581579 Vali Loss: 0.1424134 Test Loss: 0.1692210
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.0565250
	speed: 1.4523s/iter; left time: 6522.0851s
Epoch: 67 cost time: 96.42660665512085
Epoch: 67, Steps: 135 | Train Loss: 0.0581364 Vali Loss: 0.1423234 Test Loss: 0.1691972
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.0581278
	speed: 1.6735s/iter; left time: 7289.7401s
Epoch: 68 cost time: 97.02421975135803
Epoch: 68, Steps: 135 | Train Loss: 0.0581236 Vali Loss: 0.1424055 Test Loss: 0.1691724
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.0583010
	speed: 1.4596s/iter; left time: 6160.8774s
Epoch: 69 cost time: 88.0906114578247
Epoch: 69, Steps: 135 | Train Loss: 0.0580823 Vali Loss: 0.1422094 Test Loss: 0.1691487
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.0581423
	speed: 1.4870s/iter; left time: 6075.9805s
Epoch: 70 cost time: 95.19909477233887
Epoch: 70, Steps: 135 | Train Loss: 0.0581033 Vali Loss: 0.1424325 Test Loss: 0.1691314
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.0635250
	speed: 1.6364s/iter; left time: 6465.3339s
Epoch: 71 cost time: 89.97947192192078
Epoch: 71, Steps: 135 | Train Loss: 0.0581093 Vali Loss: 0.1421942 Test Loss: 0.1691131
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.0566058
	speed: 1.3708s/iter; left time: 5230.9167s
Epoch: 72 cost time: 79.83329725265503
Epoch: 72, Steps: 135 | Train Loss: 0.0580992 Vali Loss: 0.1425056 Test Loss: 0.1690913
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.0591632
	speed: 1.5675s/iter; left time: 5769.9828s
Epoch: 73 cost time: 92.18262553215027
Epoch: 73, Steps: 135 | Train Loss: 0.0580517 Vali Loss: 0.1423465 Test Loss: 0.1690840
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.0520961
	speed: 1.4262s/iter; left time: 5057.2803s
Epoch: 74 cost time: 83.06781768798828
Epoch: 74, Steps: 135 | Train Loss: 0.0580913 Vali Loss: 0.1424058 Test Loss: 0.1690736
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.0594123
	speed: 1.4023s/iter; left time: 4783.1985s
Epoch: 75 cost time: 89.13510131835938
Epoch: 75, Steps: 135 | Train Loss: 0.0580730 Vali Loss: 0.1420714 Test Loss: 0.1690594
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.0558753
	speed: 1.5261s/iter; left time: 4999.4603s
Epoch: 76 cost time: 93.56548929214478
Epoch: 76, Steps: 135 | Train Loss: 0.0580886 Vali Loss: 0.1423692 Test Loss: 0.1690446
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.0580149
	speed: 1.4284s/iter; left time: 4486.5671s
Epoch: 77 cost time: 88.28651833534241
Epoch: 77, Steps: 135 | Train Loss: 0.0580469 Vali Loss: 0.1425186 Test Loss: 0.1690348
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.0620310
	speed: 1.4525s/iter; left time: 4366.3437s
Epoch: 78 cost time: 85.43322920799255
Epoch: 78, Steps: 135 | Train Loss: 0.0580394 Vali Loss: 0.1420950 Test Loss: 0.1690315
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.0559159
	speed: 1.4162s/iter; left time: 4065.9873s
Epoch: 79 cost time: 87.27405858039856
Epoch: 79, Steps: 135 | Train Loss: 0.0580418 Vali Loss: 0.1424385 Test Loss: 0.1690222
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.0599933
	speed: 1.4720s/iter; left time: 4027.5086s
Epoch: 80 cost time: 91.97735285758972
Epoch: 80, Steps: 135 | Train Loss: 0.0580281 Vali Loss: 0.1423344 Test Loss: 0.1690148
EarlyStopping counter: 16 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.0590839
	speed: 1.4411s/iter; left time: 3748.3071s
Epoch: 81 cost time: 85.52365183830261
Epoch: 81, Steps: 135 | Train Loss: 0.0580475 Vali Loss: 0.1423338 Test Loss: 0.1690053
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.0594160
	speed: 1.4659s/iter; left time: 3614.7994s
Epoch: 82 cost time: 88.69846224784851
Epoch: 82, Steps: 135 | Train Loss: 0.0580485 Vali Loss: 0.1422478 Test Loss: 0.1690006
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.0587456
	speed: 1.4446s/iter; left time: 3367.2968s
Epoch: 83 cost time: 84.46678423881531
Epoch: 83, Steps: 135 | Train Loss: 0.0580409 Vali Loss: 0.1421551 Test Loss: 0.1689933
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.0594587
	speed: 1.4107s/iter; left time: 3097.8671s
Epoch: 84 cost time: 86.54026126861572
Epoch: 84, Steps: 135 | Train Loss: 0.0580564 Vali Loss: 0.1423051 Test Loss: 0.1689895
EarlyStopping counter: 20 out of 20
Early stopping
train 17357
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=320, out_features=469, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6166487040.0
params:  150549.0
Trainable parameters:  150549
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.1767586
	speed: 0.6127s/iter; left time: 8210.9612s
Epoch: 1 cost time: 82.63754200935364
Epoch: 1, Steps: 135 | Train Loss: 0.1732980 Vali Loss: 0.1418686 Test Loss: 0.1679549
Validation loss decreased (inf --> 0.141869).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1751056
	speed: 1.4264s/iter; left time: 18922.6322s
Epoch: 2 cost time: 86.37224650382996
Epoch: 2, Steps: 135 | Train Loss: 0.1728650 Vali Loss: 0.1413604 Test Loss: 0.1677360
Validation loss decreased (0.141869 --> 0.141360).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1593228
	speed: 1.4920s/iter; left time: 19591.1251s
Epoch: 3 cost time: 87.9695794582367
Epoch: 3, Steps: 135 | Train Loss: 0.1727127 Vali Loss: 0.1414731 Test Loss: 0.1677411
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1861999
	speed: 1.4670s/iter; left time: 19065.5681s
Epoch: 4 cost time: 92.41160225868225
Epoch: 4, Steps: 135 | Train Loss: 0.1724957 Vali Loss: 0.1416450 Test Loss: 0.1676303
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1762136
	speed: 1.5802s/iter; left time: 20322.9174s
Epoch: 5 cost time: 101.17139339447021
Epoch: 5, Steps: 135 | Train Loss: 0.1725326 Vali Loss: 0.1414806 Test Loss: 0.1676331
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1807488
	speed: 1.3697s/iter; left time: 17430.2840s
Epoch: 6 cost time: 73.78259611129761
Epoch: 6, Steps: 135 | Train Loss: 0.1725056 Vali Loss: 0.1415679 Test Loss: 0.1676344
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1728982
	speed: 1.2451s/iter; left time: 15676.4778s
Epoch: 7 cost time: 75.286625623703
Epoch: 7, Steps: 135 | Train Loss: 0.1724546 Vali Loss: 0.1415758 Test Loss: 0.1676348
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1693697
	speed: 1.1975s/iter; left time: 14915.5004s
Epoch: 8 cost time: 70.49746203422546
Epoch: 8, Steps: 135 | Train Loss: 0.1723915 Vali Loss: 0.1409303 Test Loss: 0.1675539
Validation loss decreased (0.141360 --> 0.140930).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1758365
	speed: 1.1251s/iter; left time: 13862.7404s
Epoch: 9 cost time: 67.14858436584473
Epoch: 9, Steps: 135 | Train Loss: 0.1723833 Vali Loss: 0.1411217 Test Loss: 0.1674499
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1614579
	speed: 1.1077s/iter; left time: 13498.7164s
Epoch: 10 cost time: 66.95150756835938
Epoch: 10, Steps: 135 | Train Loss: 0.1723046 Vali Loss: 0.1412492 Test Loss: 0.1674198
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1777032
	speed: 1.1642s/iter; left time: 14029.6404s
Epoch: 11 cost time: 71.57503128051758
Epoch: 11, Steps: 135 | Train Loss: 0.1723588 Vali Loss: 0.1414101 Test Loss: 0.1674750
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1800023
	speed: 1.1746s/iter; left time: 13997.1064s
Epoch: 12 cost time: 68.96255040168762
Epoch: 12, Steps: 135 | Train Loss: 0.1722429 Vali Loss: 0.1414943 Test Loss: 0.1674011
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1672607
	speed: 1.1160s/iter; left time: 13147.2636s
Epoch: 13 cost time: 67.74733853340149
Epoch: 13, Steps: 135 | Train Loss: 0.1722928 Vali Loss: 0.1409888 Test Loss: 0.1673671
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1829157
	speed: 1.1822s/iter; left time: 13768.3189s
Epoch: 14 cost time: 79.9033191204071
Epoch: 14, Steps: 135 | Train Loss: 0.1723156 Vali Loss: 0.1412832 Test Loss: 0.1673950
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1755395
	speed: 1.4965s/iter; left time: 17226.3729s
Epoch: 15 cost time: 90.50624918937683
Epoch: 15, Steps: 135 | Train Loss: 0.1722618 Vali Loss: 0.1409408 Test Loss: 0.1674225
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1796155
	speed: 1.4875s/iter; left time: 16921.5279s
Epoch: 16 cost time: 87.86390280723572
Epoch: 16, Steps: 135 | Train Loss: 0.1722035 Vali Loss: 0.1411681 Test Loss: 0.1674075
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1764107
	speed: 1.5699s/iter; left time: 17646.8793s
Epoch: 17 cost time: 93.9438247680664
Epoch: 17, Steps: 135 | Train Loss: 0.1722556 Vali Loss: 0.1412142 Test Loss: 0.1673773
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1683843
	speed: 1.5448s/iter; left time: 17156.5250s
Epoch: 18 cost time: 87.7233464717865
Epoch: 18, Steps: 135 | Train Loss: 0.1722383 Vali Loss: 0.1410004 Test Loss: 0.1673628
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1726136
	speed: 1.3829s/iter; left time: 15171.6232s
Epoch: 19 cost time: 85.05478882789612
Epoch: 19, Steps: 135 | Train Loss: 0.1722388 Vali Loss: 0.1411775 Test Loss: 0.1673644
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1809136
	speed: 1.4039s/iter; left time: 15212.6134s
Epoch: 20 cost time: 85.24878025054932
Epoch: 20, Steps: 135 | Train Loss: 0.1721394 Vali Loss: 0.1409348 Test Loss: 0.1673611
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1673132
	speed: 1.6919s/iter; left time: 18105.2440s
Epoch: 21 cost time: 126.6787416934967
Epoch: 21, Steps: 135 | Train Loss: 0.1722507 Vali Loss: 0.1410068 Test Loss: 0.1673920
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1657568
	speed: 1.8206s/iter; left time: 19236.4898s
Epoch: 22 cost time: 92.3445553779602
Epoch: 22, Steps: 135 | Train Loss: 0.1721228 Vali Loss: 0.1415518 Test Loss: 0.1673555
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1647141
	speed: 1.5013s/iter; left time: 15660.5188s
Epoch: 23 cost time: 88.8228850364685
Epoch: 23, Steps: 135 | Train Loss: 0.1721788 Vali Loss: 0.1412056 Test Loss: 0.1673510
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1729750
	speed: 1.5054s/iter; left time: 15500.0895s
Epoch: 24 cost time: 89.05299997329712
Epoch: 24, Steps: 135 | Train Loss: 0.1721718 Vali Loss: 0.1411889 Test Loss: 0.1673583
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1777052
	speed: 1.4081s/iter; left time: 14307.2507s
Epoch: 25 cost time: 85.30484890937805
Epoch: 25, Steps: 135 | Train Loss: 0.1721670 Vali Loss: 0.1412366 Test Loss: 0.1673758
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1790095
	speed: 1.4714s/iter; left time: 14751.8657s
Epoch: 26 cost time: 90.20198559761047
Epoch: 26, Steps: 135 | Train Loss: 0.1721364 Vali Loss: 0.1411847 Test Loss: 0.1673648
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1696336
	speed: 1.5208s/iter; left time: 15042.5294s
Epoch: 27 cost time: 87.47321081161499
Epoch: 27, Steps: 135 | Train Loss: 0.1721273 Vali Loss: 0.1410789 Test Loss: 0.1672965
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1729881
	speed: 1.4860s/iter; left time: 14497.5098s
Epoch: 28 cost time: 83.45698690414429
Epoch: 28, Steps: 135 | Train Loss: 0.1721982 Vali Loss: 0.1413682 Test Loss: 0.1673314
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_720_j336_H10_FITS_custom_ftM_sl720_ll48_pl336_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4925
mse:0.16535258293151855, mae:0.2608104646205902, rse:0.40471264719963074, corr:[0.45850223 0.46145454 0.46322283 0.46357304 0.4639421  0.46399185
 0.46409756 0.463798   0.46373293 0.46351972 0.4635923  0.46346146
 0.46358782 0.46342403 0.4635514  0.46362215 0.46373966 0.46362853
 0.46353218 0.46339697 0.46301842 0.46315616 0.46302095 0.46327242
 0.463407   0.46359068 0.46394297 0.46396175 0.46385276 0.46378294
 0.46354574 0.4632984  0.4633941  0.46337157 0.4632017  0.46308437
 0.46312073 0.46307883 0.46320948 0.46326488 0.4631132  0.46321303
 0.4632348  0.4630986  0.46292055 0.46289194 0.46276364 0.4626987
 0.46283832 0.46286952 0.46305978 0.4631734  0.46298915 0.46272877
 0.4627899  0.46281248 0.46279192 0.46270677 0.46269584 0.46275306
 0.4626928  0.4626855  0.4626693  0.4628123  0.46279553 0.46275774
 0.4627495  0.46253783 0.46233523 0.46229652 0.4623593  0.4624058
 0.46239352 0.46234035 0.4624374  0.46235868 0.46222347 0.46218482
 0.46211067 0.46202078 0.46200266 0.46197572 0.46183857 0.46194
 0.4617833  0.46174106 0.46200168 0.4619159  0.46191365 0.46192646
 0.46199343 0.4620142  0.46198308 0.46201858 0.4620091  0.4620863
 0.46203682 0.461964   0.4619329  0.4619923  0.46202964 0.4618584
 0.46191815 0.46194014 0.46160984 0.46156958 0.46149078 0.46145278
 0.46167523 0.46156394 0.4616898  0.46192324 0.46176773 0.46176714
 0.46187034 0.46160525 0.4615437  0.4617158  0.4616182  0.46167564
 0.4618331  0.46192813 0.46190646 0.46178344 0.46177515 0.46178415
 0.46184212 0.46171927 0.46157596 0.46153295 0.46148607 0.4612546
 0.46119323 0.46125656 0.4613193  0.46160778 0.46152824 0.46155852
 0.46167132 0.4613957  0.46121752 0.46128538 0.46129566 0.46115404
 0.46119457 0.46128836 0.46130243 0.4612799  0.4613054  0.46108755
 0.46103436 0.46107945 0.46090823 0.46096602 0.4607296  0.46067366
 0.4608241  0.46079698 0.46091986 0.4609948  0.46098617 0.46096927
 0.46100822 0.4608501  0.46086532 0.461058   0.46096832 0.46086004
 0.46086833 0.4609653  0.4609917  0.4608566  0.4607065  0.46062925
 0.46034124 0.46011075 0.46012634 0.45979053 0.45946792 0.45942375
 0.4592506  0.45915297 0.45924005 0.45926508 0.4592203  0.4591418
 0.4590412  0.458913   0.45869353 0.45863828 0.45872697 0.4588408
 0.45887706 0.4589521  0.45901647 0.45894656 0.45887846 0.45879242
 0.45876428 0.4587247  0.4585916  0.4585942  0.4584461  0.45823324
 0.45837703 0.4583111  0.45810542 0.45827138 0.45826012 0.4580674
 0.45813128 0.45806342 0.45789176 0.45781648 0.45775667 0.45800307
 0.45806375 0.4581717  0.45848563 0.4584162  0.4583385  0.45818686
 0.45811763 0.45818698 0.45816988 0.45809332 0.45802215 0.4580963
 0.4580516  0.4579912  0.45801562 0.45810047 0.45809323 0.45801744
 0.45809337 0.4579251  0.45769045 0.45767355 0.4577205  0.45783165
 0.45811126 0.4580593  0.4579518  0.45811996 0.458061   0.45780408
 0.45782506 0.457869   0.45765063 0.45758337 0.4573545  0.45719072
 0.45735785 0.45733893 0.4573823  0.45735237 0.45724902 0.45726532
 0.45739463 0.4575054  0.45759425 0.45763507 0.4575092  0.4576437
 0.45775104 0.45772347 0.4578282  0.45794958 0.4578246  0.45767507
 0.45764476 0.4575263  0.45744202 0.4573874  0.4573062  0.4572758
 0.4573672  0.45726    0.457275   0.45745197 0.45735428 0.4573816
 0.45742065 0.4571463  0.45708513 0.45729545 0.45730403 0.45745754
 0.4576213  0.4576494  0.4577351  0.4577448  0.45779753 0.4575483
 0.4575419  0.45739368 0.45730865 0.45734394 0.45710024 0.45713526
 0.45700622 0.4569007  0.45687902 0.45698878 0.45704338 0.45702422
 0.45699263 0.45669052 0.4565123  0.4563821  0.45639467 0.4564692
 0.45664638 0.456799   0.45683986 0.4567727  0.4569005  0.4567462
 0.45652708 0.4565683  0.4561793  0.45630676 0.45614958 0.4562229
 0.4563896  0.45614237 0.4561606  0.45627567 0.4562404  0.45610473
 0.4561316  0.45592964 0.45619506 0.45610052 0.45651236 0.45616263]
