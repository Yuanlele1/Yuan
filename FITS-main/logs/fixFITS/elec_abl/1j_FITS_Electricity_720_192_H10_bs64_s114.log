Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=320, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_720_j192_H10', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_720_j192_H10_FITS_custom_ftM_sl720_ll48_pl192_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17501
val 2441
test 5069
Model(
  (freq_upsampler): Linear(in_features=320, out_features=405, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  5325004800.0
params:  130005.0
Trainable parameters:  130005
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3663308
	speed: 1.2351s/iter; left time: 16675.3861s
Epoch: 1 cost time: 165.16246008872986
Epoch: 1, Steps: 136 | Train Loss: 0.5605721 Vali Loss: 0.2384217 Test Loss: 0.2876537
Validation loss decreased (inf --> 0.238422).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1947405
	speed: 2.7515s/iter; left time: 36773.4640s
Epoch: 2 cost time: 172.29498100280762
Epoch: 2, Steps: 136 | Train Loss: 0.2117124 Vali Loss: 0.1386990 Test Loss: 0.1699839
Validation loss decreased (0.238422 --> 0.138699).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1583138
	speed: 2.6283s/iter; left time: 34770.0393s
Epoch: 3 cost time: 160.21499919891357
Epoch: 3, Steps: 136 | Train Loss: 0.1600525 Vali Loss: 0.1283269 Test Loss: 0.1561435
Validation loss decreased (0.138699 --> 0.128327).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1591530
	speed: 2.6561s/iter; left time: 34776.0465s
Epoch: 4 cost time: 168.4176435470581
Epoch: 4, Steps: 136 | Train Loss: 0.1540054 Vali Loss: 0.1271500 Test Loss: 0.1543038
Validation loss decreased (0.128327 --> 0.127150).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1537805
	speed: 2.5559s/iter; left time: 33117.0154s
Epoch: 5 cost time: 156.75573229789734
Epoch: 5, Steps: 136 | Train Loss: 0.1527953 Vali Loss: 0.1267007 Test Loss: 0.1536825
Validation loss decreased (0.127150 --> 0.126701).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1549111
	speed: 2.5434s/iter; left time: 32608.7743s
Epoch: 6 cost time: 157.80005264282227
Epoch: 6, Steps: 136 | Train Loss: 0.1520603 Vali Loss: 0.1263235 Test Loss: 0.1532919
Validation loss decreased (0.126701 --> 0.126324).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1492247
	speed: 2.4142s/iter; left time: 30624.6822s
Epoch: 7 cost time: 144.17762398719788
Epoch: 7, Steps: 136 | Train Loss: 0.1516546 Vali Loss: 0.1262316 Test Loss: 0.1530851
Validation loss decreased (0.126324 --> 0.126232).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1491908
	speed: 2.4863s/iter; left time: 31201.1121s
Epoch: 8 cost time: 158.11092925071716
Epoch: 8, Steps: 136 | Train Loss: 0.1513985 Vali Loss: 0.1261067 Test Loss: 0.1529091
Validation loss decreased (0.126232 --> 0.126107).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1584432
	speed: 2.4848s/iter; left time: 30844.4323s
Epoch: 9 cost time: 156.02128410339355
Epoch: 9, Steps: 136 | Train Loss: 0.1511205 Vali Loss: 0.1259168 Test Loss: 0.1527378
Validation loss decreased (0.126107 --> 0.125917).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1605521
	speed: 2.4485s/iter; left time: 30060.0040s
Epoch: 10 cost time: 148.87889552116394
Epoch: 10, Steps: 136 | Train Loss: 0.1509265 Vali Loss: 0.1258931 Test Loss: 0.1526569
Validation loss decreased (0.125917 --> 0.125893).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1625321
	speed: 2.1205s/iter; left time: 25744.8425s
Epoch: 11 cost time: 116.10085678100586
Epoch: 11, Steps: 136 | Train Loss: 0.1507627 Vali Loss: 0.1258539 Test Loss: 0.1525820
Validation loss decreased (0.125893 --> 0.125854).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1497782
	speed: 1.8145s/iter; left time: 21783.3269s
Epoch: 12 cost time: 114.9240255355835
Epoch: 12, Steps: 136 | Train Loss: 0.1506812 Vali Loss: 0.1257607 Test Loss: 0.1525584
Validation loss decreased (0.125854 --> 0.125761).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1469118
	speed: 1.8255s/iter; left time: 21666.5081s
Epoch: 13 cost time: 116.6169650554657
Epoch: 13, Steps: 136 | Train Loss: 0.1506199 Vali Loss: 0.1257057 Test Loss: 0.1524499
Validation loss decreased (0.125761 --> 0.125706).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1496736
	speed: 1.8043s/iter; left time: 21170.1732s
Epoch: 14 cost time: 116.55334377288818
Epoch: 14, Steps: 136 | Train Loss: 0.1505319 Vali Loss: 0.1256806 Test Loss: 0.1524412
Validation loss decreased (0.125706 --> 0.125681).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1627796
	speed: 1.7700s/iter; left time: 20526.5227s
Epoch: 15 cost time: 104.58114743232727
Epoch: 15, Steps: 136 | Train Loss: 0.1505334 Vali Loss: 0.1256020 Test Loss: 0.1523704
Validation loss decreased (0.125681 --> 0.125602).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1448064
	speed: 1.7222s/iter; left time: 19737.8874s
Epoch: 16 cost time: 112.1025161743164
Epoch: 16, Steps: 136 | Train Loss: 0.1504316 Vali Loss: 0.1255924 Test Loss: 0.1523037
Validation loss decreased (0.125602 --> 0.125592).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1456109
	speed: 1.8295s/iter; left time: 20718.9785s
Epoch: 17 cost time: 113.14175939559937
Epoch: 17, Steps: 136 | Train Loss: 0.1503549 Vali Loss: 0.1256068 Test Loss: 0.1523455
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1391965
	speed: 1.6081s/iter; left time: 17992.8488s
Epoch: 18 cost time: 92.17383313179016
Epoch: 18, Steps: 136 | Train Loss: 0.1504065 Vali Loss: 0.1255193 Test Loss: 0.1523029
Validation loss decreased (0.125592 --> 0.125519).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1475557
	speed: 1.5266s/iter; left time: 16873.0744s
Epoch: 19 cost time: 100.27185893058777
Epoch: 19, Steps: 136 | Train Loss: 0.1503281 Vali Loss: 0.1256027 Test Loss: 0.1522921
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1563723
	speed: 1.5440s/iter; left time: 16856.3320s
Epoch: 20 cost time: 93.85758185386658
Epoch: 20, Steps: 136 | Train Loss: 0.1502520 Vali Loss: 0.1255679 Test Loss: 0.1522674
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1544440
	speed: 1.4263s/iter; left time: 15377.3122s
Epoch: 21 cost time: 88.82523036003113
Epoch: 21, Steps: 136 | Train Loss: 0.1503236 Vali Loss: 0.1255093 Test Loss: 0.1522729
Validation loss decreased (0.125519 --> 0.125509).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1579686
	speed: 1.4461s/iter; left time: 15393.9926s
Epoch: 22 cost time: 89.78323817253113
Epoch: 22, Steps: 136 | Train Loss: 0.1502697 Vali Loss: 0.1255029 Test Loss: 0.1522559
Validation loss decreased (0.125509 --> 0.125503).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1461715
	speed: 1.5440s/iter; left time: 16226.4165s
Epoch: 23 cost time: 99.54864239692688
Epoch: 23, Steps: 136 | Train Loss: 0.1502592 Vali Loss: 0.1255220 Test Loss: 0.1522087
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1421712
	speed: 1.4859s/iter; left time: 15412.7664s
Epoch: 24 cost time: 87.9783411026001
Epoch: 24, Steps: 136 | Train Loss: 0.1501432 Vali Loss: 0.1254721 Test Loss: 0.1522153
Validation loss decreased (0.125503 --> 0.125472).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1432084
	speed: 1.4895s/iter; left time: 15247.9664s
Epoch: 25 cost time: 90.75613307952881
Epoch: 25, Steps: 136 | Train Loss: 0.1501662 Vali Loss: 0.1255157 Test Loss: 0.1522100
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1454143
	speed: 1.4943s/iter; left time: 15094.0252s
Epoch: 26 cost time: 93.90837931632996
Epoch: 26, Steps: 136 | Train Loss: 0.1501710 Vali Loss: 0.1255236 Test Loss: 0.1522199
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1497026
	speed: 1.4086s/iter; left time: 14036.4979s
Epoch: 27 cost time: 84.74025559425354
Epoch: 27, Steps: 136 | Train Loss: 0.1501622 Vali Loss: 0.1254605 Test Loss: 0.1521755
Validation loss decreased (0.125472 --> 0.125460).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1540311
	speed: 1.3778s/iter; left time: 13542.3293s
Epoch: 28 cost time: 87.05928254127502
Epoch: 28, Steps: 136 | Train Loss: 0.1501485 Vali Loss: 0.1253721 Test Loss: 0.1521782
Validation loss decreased (0.125460 --> 0.125372).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1428828
	speed: 1.3861s/iter; left time: 13435.4431s
Epoch: 29 cost time: 87.59215378761292
Epoch: 29, Steps: 136 | Train Loss: 0.1500531 Vali Loss: 0.1254573 Test Loss: 0.1521237
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1438818
	speed: 1.4840s/iter; left time: 14182.3775s
Epoch: 30 cost time: 86.26921391487122
Epoch: 30, Steps: 136 | Train Loss: 0.1501814 Vali Loss: 0.1254339 Test Loss: 0.1521488
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1460288
	speed: 1.4277s/iter; left time: 13450.6685s
Epoch: 31 cost time: 89.77719068527222
Epoch: 31, Steps: 136 | Train Loss: 0.1501106 Vali Loss: 0.1254574 Test Loss: 0.1521268
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1622786
	speed: 1.4117s/iter; left time: 13107.9597s
Epoch: 32 cost time: 87.12947201728821
Epoch: 32, Steps: 136 | Train Loss: 0.1501705 Vali Loss: 0.1253844 Test Loss: 0.1521704
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1543322
	speed: 1.4415s/iter; left time: 13188.6214s
Epoch: 33 cost time: 86.80546975135803
Epoch: 33, Steps: 136 | Train Loss: 0.1500474 Vali Loss: 0.1255061 Test Loss: 0.1521401
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1579383
	speed: 1.4641s/iter; left time: 13195.7920s
Epoch: 34 cost time: 91.29458260536194
Epoch: 34, Steps: 136 | Train Loss: 0.1500443 Vali Loss: 0.1255202 Test Loss: 0.1521131
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1551987
	speed: 1.4142s/iter; left time: 12553.7105s
Epoch: 35 cost time: 88.63627195358276
Epoch: 35, Steps: 136 | Train Loss: 0.1500377 Vali Loss: 0.1254634 Test Loss: 0.1521229
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1679611
	speed: 1.4270s/iter; left time: 12473.5280s
Epoch: 36 cost time: 86.98829984664917
Epoch: 36, Steps: 136 | Train Loss: 0.1500386 Vali Loss: 0.1254484 Test Loss: 0.1521265
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1409132
	speed: 1.3946s/iter; left time: 12000.6550s
Epoch: 37 cost time: 87.88848066329956
Epoch: 37, Steps: 136 | Train Loss: 0.1500687 Vali Loss: 0.1253959 Test Loss: 0.1521284
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1441987
	speed: 1.4783s/iter; left time: 12520.0146s
Epoch: 38 cost time: 87.15367937088013
Epoch: 38, Steps: 136 | Train Loss: 0.1501126 Vali Loss: 0.1254408 Test Loss: 0.1521037
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1547071
	speed: 1.5084s/iter; left time: 12569.1434s
Epoch: 39 cost time: 96.47750520706177
Epoch: 39, Steps: 136 | Train Loss: 0.1500726 Vali Loss: 0.1253860 Test Loss: 0.1521014
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1456300
	speed: 1.5118s/iter; left time: 12391.8516s
Epoch: 40 cost time: 93.36851382255554
Epoch: 40, Steps: 136 | Train Loss: 0.1500628 Vali Loss: 0.1253975 Test Loss: 0.1521083
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1454445
	speed: 1.4423s/iter; left time: 11626.1219s
Epoch: 41 cost time: 87.17990565299988
Epoch: 41, Steps: 136 | Train Loss: 0.1501005 Vali Loss: 0.1254727 Test Loss: 0.1520912
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1508026
	speed: 1.3082s/iter; left time: 10367.4195s
Epoch: 42 cost time: 81.78903651237488
Epoch: 42, Steps: 136 | Train Loss: 0.1500430 Vali Loss: 0.1254252 Test Loss: 0.1521014
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1443753
	speed: 1.2901s/iter; left time: 10048.9567s
Epoch: 43 cost time: 78.40893864631653
Epoch: 43, Steps: 136 | Train Loss: 0.1500127 Vali Loss: 0.1253754 Test Loss: 0.1520937
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1603630
	speed: 1.3090s/iter; left time: 10017.8904s
Epoch: 44 cost time: 81.74851417541504
Epoch: 44, Steps: 136 | Train Loss: 0.1500190 Vali Loss: 0.1253316 Test Loss: 0.1520859
Validation loss decreased (0.125372 --> 0.125332).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1519583
	speed: 1.2859s/iter; left time: 9666.4351s
Epoch: 45 cost time: 81.36845254898071
Epoch: 45, Steps: 136 | Train Loss: 0.1500368 Vali Loss: 0.1253107 Test Loss: 0.1520846
Validation loss decreased (0.125332 --> 0.125311).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1558755
	speed: 1.2914s/iter; left time: 9532.1913s
Epoch: 46 cost time: 81.19702315330505
Epoch: 46, Steps: 136 | Train Loss: 0.1499896 Vali Loss: 0.1254214 Test Loss: 0.1520946
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1635579
	speed: 1.3237s/iter; left time: 9590.3086s
Epoch: 47 cost time: 78.08255624771118
Epoch: 47, Steps: 136 | Train Loss: 0.1500531 Vali Loss: 0.1253906 Test Loss: 0.1520852
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1623961
	speed: 1.3520s/iter; left time: 9611.1961s
Epoch: 48 cost time: 83.83896279335022
Epoch: 48, Steps: 136 | Train Loss: 0.1499543 Vali Loss: 0.1253848 Test Loss: 0.1520693
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1410539
	speed: 1.3549s/iter; left time: 9447.6807s
Epoch: 49 cost time: 83.2203643321991
Epoch: 49, Steps: 136 | Train Loss: 0.1500010 Vali Loss: 0.1252789 Test Loss: 0.1520691
Validation loss decreased (0.125311 --> 0.125279).  Saving model ...
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1433251
	speed: 1.3552s/iter; left time: 9265.4336s
Epoch: 50 cost time: 86.59068274497986
Epoch: 50, Steps: 136 | Train Loss: 0.1500529 Vali Loss: 0.1253637 Test Loss: 0.1520785
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1464583
	speed: 1.1591s/iter; left time: 7767.1790s
Epoch: 51 cost time: 57.48130440711975
Epoch: 51, Steps: 136 | Train Loss: 0.1500293 Vali Loss: 0.1252255 Test Loss: 0.1520788
Validation loss decreased (0.125279 --> 0.125225).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1569304
	speed: 0.8932s/iter; left time: 5863.6898s
Epoch: 52 cost time: 56.57412552833557
Epoch: 52, Steps: 136 | Train Loss: 0.1499882 Vali Loss: 0.1253081 Test Loss: 0.1520751
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1471186
	speed: 0.8983s/iter; left time: 5775.2009s
Epoch: 53 cost time: 55.41260814666748
Epoch: 53, Steps: 136 | Train Loss: 0.1499899 Vali Loss: 0.1253515 Test Loss: 0.1520764
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1563982
	speed: 1.0812s/iter; left time: 6803.9606s
Epoch: 54 cost time: 80.80456686019897
Epoch: 54, Steps: 136 | Train Loss: 0.1500437 Vali Loss: 0.1253402 Test Loss: 0.1520707
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1528797
	speed: 1.3249s/iter; left time: 8157.4034s
Epoch: 55 cost time: 79.12985348701477
Epoch: 55, Steps: 136 | Train Loss: 0.1500022 Vali Loss: 0.1252913 Test Loss: 0.1520740
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1528452
	speed: 1.4127s/iter; left time: 8505.8542s
Epoch: 56 cost time: 91.81625533103943
Epoch: 56, Steps: 136 | Train Loss: 0.1499450 Vali Loss: 0.1254277 Test Loss: 0.1520746
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.1557482
	speed: 1.4231s/iter; left time: 8375.1839s
Epoch: 57 cost time: 91.37809491157532
Epoch: 57, Steps: 136 | Train Loss: 0.1499747 Vali Loss: 0.1252772 Test Loss: 0.1520691
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1633519
	speed: 1.4485s/iter; left time: 8327.5895s
Epoch: 58 cost time: 85.405442237854
Epoch: 58, Steps: 136 | Train Loss: 0.1499104 Vali Loss: 0.1253664 Test Loss: 0.1520630
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1475136
	speed: 1.3341s/iter; left time: 7488.4706s
Epoch: 59 cost time: 83.16729307174683
Epoch: 59, Steps: 136 | Train Loss: 0.1499673 Vali Loss: 0.1253059 Test Loss: 0.1520647
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1449722
	speed: 1.3362s/iter; left time: 7318.3406s
Epoch: 60 cost time: 84.37204885482788
Epoch: 60, Steps: 136 | Train Loss: 0.1500199 Vali Loss: 0.1254241 Test Loss: 0.1520660
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1535599
	speed: 1.3237s/iter; left time: 7069.9286s
Epoch: 61 cost time: 82.13321280479431
Epoch: 61, Steps: 136 | Train Loss: 0.1499512 Vali Loss: 0.1252875 Test Loss: 0.1520728
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1413162
	speed: 1.3712s/iter; left time: 7137.2998s
Epoch: 62 cost time: 88.78339219093323
Epoch: 62, Steps: 136 | Train Loss: 0.1499725 Vali Loss: 0.1253252 Test Loss: 0.1520656
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1548401
	speed: 1.6047s/iter; left time: 8134.3095s
Epoch: 63 cost time: 99.2393901348114
Epoch: 63, Steps: 136 | Train Loss: 0.1498712 Vali Loss: 0.1252627 Test Loss: 0.1520620
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1504719
	speed: 1.4281s/iter; left time: 7044.9017s
Epoch: 64 cost time: 92.54655289649963
Epoch: 64, Steps: 136 | Train Loss: 0.1499750 Vali Loss: 0.1253034 Test Loss: 0.1520669
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.1510210
	speed: 1.4060s/iter; left time: 6744.7147s
Epoch: 65 cost time: 83.46720004081726
Epoch: 65, Steps: 136 | Train Loss: 0.1499628 Vali Loss: 0.1253408 Test Loss: 0.1520623
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.1540221
	speed: 1.3504s/iter; left time: 6294.1255s
Epoch: 66 cost time: 83.80855751037598
Epoch: 66, Steps: 136 | Train Loss: 0.1499606 Vali Loss: 0.1253704 Test Loss: 0.1520586
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.1481136
	speed: 1.3115s/iter; left time: 5934.6568s
Epoch: 67 cost time: 81.7563087940216
Epoch: 67, Steps: 136 | Train Loss: 0.1499036 Vali Loss: 0.1253950 Test Loss: 0.1520577
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.1453693
	speed: 1.3767s/iter; left time: 6042.5272s
Epoch: 68 cost time: 87.80151891708374
Epoch: 68, Steps: 136 | Train Loss: 0.1499751 Vali Loss: 0.1253243 Test Loss: 0.1520529
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.1482958
	speed: 1.3485s/iter; left time: 5734.9879s
Epoch: 69 cost time: 82.21249961853027
Epoch: 69, Steps: 136 | Train Loss: 0.1499927 Vali Loss: 0.1253874 Test Loss: 0.1520567
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.1572088
	speed: 1.4161s/iter; left time: 5830.1069s
Epoch: 70 cost time: 86.9027669429779
Epoch: 70, Steps: 136 | Train Loss: 0.1499810 Vali Loss: 0.1253403 Test Loss: 0.1520569
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.1537399
	speed: 1.2244s/iter; left time: 4874.5193s
Epoch: 71 cost time: 69.06747150421143
Epoch: 71, Steps: 136 | Train Loss: 0.1499606 Vali Loss: 0.1254191 Test Loss: 0.1520540
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_720_j192_H10_FITS_custom_ftM_sl720_ll48_pl192_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5069
mse:0.14919130504131317, mae:0.2441745549440384, rse:0.38403791189193726, corr:[0.46391106 0.46655917 0.46686718 0.46808514 0.46811157 0.4686443
 0.46851328 0.46857005 0.46836078 0.4682868  0.46827838 0.46802714
 0.46812376 0.4680311  0.4680123  0.46804115 0.4680184  0.4680054
 0.46781364 0.46768844 0.46754014 0.46749458 0.46771154 0.46784845
 0.4682269  0.46844015 0.46855956 0.4685908  0.46833134 0.46831948
 0.46816418 0.46803427 0.4678544  0.4677101  0.46769336 0.46753392
 0.46747664 0.4674097  0.46734253 0.4673003  0.46713454 0.46702674
 0.466911   0.46676105 0.4667145  0.466603   0.46664092 0.46675232
 0.46691617 0.46710426 0.4671787  0.46724886 0.46710944 0.46703002
 0.46700606 0.46681917 0.4667995  0.46671236 0.4666665  0.46666163
 0.4665974  0.4666203  0.46656677 0.4665812  0.46659485 0.46650442
 0.46644118 0.46630418 0.466231   0.46612883 0.46610138 0.46625936
 0.46629116 0.46641275 0.46644005 0.46637958 0.4663833  0.46627283
 0.46630445 0.46626413 0.46611485 0.4661078  0.46607336 0.46604887
 0.4660202  0.46602005 0.4660145  0.46595562 0.46598917 0.46595478
 0.46587488 0.4656832  0.4655045  0.46553266 0.46547514 0.46562117
 0.4657502  0.46582595 0.4659981  0.465886   0.4658197  0.46577263
 0.46571583 0.46570495 0.4655859  0.4655829  0.46546558 0.46540576
 0.46539363 0.4652867  0.46539503 0.46536982 0.46535483 0.46537176
 0.4652943  0.4654179  0.46538028 0.46539265 0.4655479  0.46566886
 0.46592024 0.46596026 0.4659936  0.4660357  0.4659293  0.46590242
 0.46586004 0.46579328 0.46579733 0.46570423 0.4656838  0.46558714
 0.4655953  0.4655572  0.465492   0.4656022  0.46551004 0.46564925
 0.46564654 0.4654723  0.46538797 0.46525383 0.46526462 0.46528387
 0.46537608 0.46544963 0.4655058  0.46549526 0.46542987 0.4653806
 0.46535945 0.46521086 0.46519575 0.46519184 0.46508834 0.46508121
 0.46496746 0.4650506  0.46499014 0.46508312 0.46512908 0.46515766
 0.46522602 0.46484283 0.46476626 0.46456692 0.46453673 0.4646829
 0.4646126  0.4646668  0.46470553 0.4646195  0.464412   0.4642389
 0.4641162  0.46395478 0.4638028  0.46372938 0.4635908  0.4636907
 0.46357408 0.46372172 0.46368125 0.46368045 0.46371707 0.46342185
 0.46357235 0.46297786 0.46330023 0.46292195 0.46396127 0.46367443]
