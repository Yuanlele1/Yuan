Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=320, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_720_j720_H10', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_720_j720_H10_FITS_custom_ftM_sl720_ll48_pl720_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 16973
val 1913
test 4541
Model(
  (freq_upsampler): Linear(in_features=320, out_features=640, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  8414822400.0
params:  205440.0
Trainable parameters:  205440
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.7978461
	speed: 0.9104s/iter; left time: 11927.6186s
Epoch: 1 cost time: 119.02897047996521
Epoch: 1, Steps: 132 | Train Loss: 0.9481212 Vali Loss: 0.6874282 Test Loss: 0.8092501
Validation loss decreased (inf --> 0.687428).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6590961
	speed: 2.5230s/iter; left time: 32720.3738s
Epoch: 2 cost time: 171.99292922019958
Epoch: 2, Steps: 132 | Train Loss: 0.6952132 Vali Loss: 0.6072754 Test Loss: 0.7187948
Validation loss decreased (0.687428 --> 0.607275).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5913050
	speed: 2.7545s/iter; left time: 35359.3438s
Epoch: 3 cost time: 152.31549048423767
Epoch: 3, Steps: 132 | Train Loss: 0.6069724 Vali Loss: 0.5470710 Test Loss: 0.6506842
Validation loss decreased (0.607275 --> 0.547071).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.5114778
	speed: 2.2492s/iter; left time: 28576.4817s
Epoch: 4 cost time: 153.33087038993835
Epoch: 4, Steps: 132 | Train Loss: 0.5365404 Vali Loss: 0.4953300 Test Loss: 0.5920591
Validation loss decreased (0.547071 --> 0.495330).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4652142
	speed: 2.7765s/iter; left time: 34909.5081s
Epoch: 5 cost time: 174.36284017562866
Epoch: 5, Steps: 132 | Train Loss: 0.4783011 Vali Loss: 0.4525211 Test Loss: 0.5432646
Validation loss decreased (0.495330 --> 0.452521).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4166102
	speed: 3.1260s/iter; left time: 38890.4359s
Epoch: 6 cost time: 173.18465065956116
Epoch: 6, Steps: 132 | Train Loss: 0.4294711 Vali Loss: 0.4157009 Test Loss: 0.5009783
Validation loss decreased (0.452521 --> 0.415701).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3802603
	speed: 2.3536s/iter; left time: 28970.9375s
Epoch: 7 cost time: 163.43042659759521
Epoch: 7, Steps: 132 | Train Loss: 0.3882400 Vali Loss: 0.3843556 Test Loss: 0.4648145
Validation loss decreased (0.415701 --> 0.384356).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3425629
	speed: 2.9597s/iter; left time: 36040.1206s
Epoch: 8 cost time: 151.006094455719
Epoch: 8, Steps: 132 | Train Loss: 0.3529737 Vali Loss: 0.3568584 Test Loss: 0.4332637
Validation loss decreased (0.384356 --> 0.356858).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3114154
	speed: 2.3362s/iter; left time: 28139.7873s
Epoch: 9 cost time: 139.43138146400452
Epoch: 9, Steps: 132 | Train Loss: 0.3228324 Vali Loss: 0.3343502 Test Loss: 0.4069546
Validation loss decreased (0.356858 --> 0.334350).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2864716
	speed: 2.2929s/iter; left time: 27315.8143s
Epoch: 10 cost time: 136.63275909423828
Epoch: 10, Steps: 132 | Train Loss: 0.2969121 Vali Loss: 0.3141672 Test Loss: 0.3838427
Validation loss decreased (0.334350 --> 0.314167).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2677057
	speed: 2.3607s/iter; left time: 27811.0689s
Epoch: 11 cost time: 141.5813970565796
Epoch: 11, Steps: 132 | Train Loss: 0.2745721 Vali Loss: 0.2961442 Test Loss: 0.3621133
Validation loss decreased (0.314167 --> 0.296144).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2439407
	speed: 2.4185s/iter; left time: 28173.3109s
Epoch: 12 cost time: 132.26235365867615
Epoch: 12, Steps: 132 | Train Loss: 0.2550606 Vali Loss: 0.2809270 Test Loss: 0.3444587
Validation loss decreased (0.296144 --> 0.280927).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2342402
	speed: 2.3007s/iter; left time: 26497.2644s
Epoch: 13 cost time: 131.71532273292542
Epoch: 13, Steps: 132 | Train Loss: 0.2382095 Vali Loss: 0.2676837 Test Loss: 0.3285299
Validation loss decreased (0.280927 --> 0.267684).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2156464
	speed: 2.3122s/iter; left time: 26323.8923s
Epoch: 14 cost time: 137.56941747665405
Epoch: 14, Steps: 132 | Train Loss: 0.2235027 Vali Loss: 0.2567654 Test Loss: 0.3154704
Validation loss decreased (0.267684 --> 0.256765).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2091759
	speed: 2.3007s/iter; left time: 25889.7757s
Epoch: 15 cost time: 136.04629802703857
Epoch: 15, Steps: 132 | Train Loss: 0.2106764 Vali Loss: 0.2465999 Test Loss: 0.3031912
Validation loss decreased (0.256765 --> 0.246600).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2055451
	speed: 2.5022s/iter; left time: 27827.1557s
Epoch: 16 cost time: 146.51128554344177
Epoch: 16, Steps: 132 | Train Loss: 0.1993953 Vali Loss: 0.2379186 Test Loss: 0.2927705
Validation loss decreased (0.246600 --> 0.237919).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1896481
	speed: 2.4280s/iter; left time: 26681.1480s
Epoch: 17 cost time: 168.43140721321106
Epoch: 17, Steps: 132 | Train Loss: 0.1895485 Vali Loss: 0.2301819 Test Loss: 0.2832516
Validation loss decreased (0.237919 --> 0.230182).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1813734
	speed: 3.4333s/iter; left time: 37275.4566s
Epoch: 18 cost time: 144.60431671142578
Epoch: 18, Steps: 132 | Train Loss: 0.1808716 Vali Loss: 0.2237148 Test Loss: 0.2751287
Validation loss decreased (0.230182 --> 0.223715).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1675183
	speed: 2.3387s/iter; left time: 25082.1402s
Epoch: 19 cost time: 149.58200979232788
Epoch: 19, Steps: 132 | Train Loss: 0.1731838 Vali Loss: 0.2175864 Test Loss: 0.2678861
Validation loss decreased (0.223715 --> 0.217586).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1639997
	speed: 3.5908s/iter; left time: 38036.9317s
Epoch: 20 cost time: 232.2183449268341
Epoch: 20, Steps: 132 | Train Loss: 0.1664511 Vali Loss: 0.2128943 Test Loss: 0.2616520
Validation loss decreased (0.217586 --> 0.212894).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1592143
	speed: 2.9170s/iter; left time: 30514.8785s
Epoch: 21 cost time: 165.58415579795837
Epoch: 21, Steps: 132 | Train Loss: 0.1604959 Vali Loss: 0.2081466 Test Loss: 0.2558485
Validation loss decreased (0.212894 --> 0.208147).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1468683
	speed: 2.5956s/iter; left time: 26810.2617s
Epoch: 22 cost time: 162.8797640800476
Epoch: 22, Steps: 132 | Train Loss: 0.1552704 Vali Loss: 0.2042168 Test Loss: 0.2506489
Validation loss decreased (0.208147 --> 0.204217).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1517323
	speed: 3.4788s/iter; left time: 35473.7694s
Epoch: 23 cost time: 172.3005928993225
Epoch: 23, Steps: 132 | Train Loss: 0.1506791 Vali Loss: 0.2005987 Test Loss: 0.2461815
Validation loss decreased (0.204217 --> 0.200599).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1432399
	speed: 2.4167s/iter; left time: 24324.0486s
Epoch: 24 cost time: 139.97125339508057
Epoch: 24, Steps: 132 | Train Loss: 0.1465065 Vali Loss: 0.1979218 Test Loss: 0.2425378
Validation loss decreased (0.200599 --> 0.197922).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1473332
	speed: 2.4240s/iter; left time: 24077.2168s
Epoch: 25 cost time: 140.42481184005737
Epoch: 25, Steps: 132 | Train Loss: 0.1428716 Vali Loss: 0.1952387 Test Loss: 0.2388602
Validation loss decreased (0.197922 --> 0.195239).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1470348
	speed: 2.9810s/iter; left time: 29216.6299s
Epoch: 26 cost time: 230.629323720932
Epoch: 26, Steps: 132 | Train Loss: 0.1395912 Vali Loss: 0.1924924 Test Loss: 0.2356683
Validation loss decreased (0.195239 --> 0.192492).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1391836
	speed: 4.0227s/iter; left time: 38895.3142s
Epoch: 27 cost time: 195.22669434547424
Epoch: 27, Steps: 132 | Train Loss: 0.1366921 Vali Loss: 0.1909043 Test Loss: 0.2329322
Validation loss decreased (0.192492 --> 0.190904).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1317876
	speed: 2.3066s/iter; left time: 21997.8468s
Epoch: 28 cost time: 136.20249199867249
Epoch: 28, Steps: 132 | Train Loss: 0.1340843 Vali Loss: 0.1889102 Test Loss: 0.2303738
Validation loss decreased (0.190904 --> 0.188910).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1338459
	speed: 2.6660s/iter; left time: 25074.1768s
Epoch: 29 cost time: 152.29893374443054
Epoch: 29, Steps: 132 | Train Loss: 0.1318006 Vali Loss: 0.1871366 Test Loss: 0.2280735
Validation loss decreased (0.188910 --> 0.187137).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1293195
	speed: 2.5330s/iter; left time: 23488.4065s
Epoch: 30 cost time: 171.66641879081726
Epoch: 30, Steps: 132 | Train Loss: 0.1297131 Vali Loss: 0.1856661 Test Loss: 0.2259790
Validation loss decreased (0.187137 --> 0.185666).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1288409
	speed: 2.7010s/iter; left time: 24690.0033s
Epoch: 31 cost time: 138.98804569244385
Epoch: 31, Steps: 132 | Train Loss: 0.1279138 Vali Loss: 0.1846329 Test Loss: 0.2242598
Validation loss decreased (0.185666 --> 0.184633).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1234392
	speed: 2.2766s/iter; left time: 20509.8499s
Epoch: 32 cost time: 138.3764247894287
Epoch: 32, Steps: 132 | Train Loss: 0.1262651 Vali Loss: 0.1830632 Test Loss: 0.2224979
Validation loss decreased (0.184633 --> 0.183063).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1246827
	speed: 2.4157s/iter; left time: 21444.0556s
Epoch: 33 cost time: 149.1672682762146
Epoch: 33, Steps: 132 | Train Loss: 0.1248458 Vali Loss: 0.1826561 Test Loss: 0.2210903
Validation loss decreased (0.183063 --> 0.182656).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1272747
	speed: 3.0049s/iter; left time: 26277.7885s
Epoch: 34 cost time: 216.1234757900238
Epoch: 34, Steps: 132 | Train Loss: 0.1235310 Vali Loss: 0.1817027 Test Loss: 0.2198132
Validation loss decreased (0.182656 --> 0.181703).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1270196
	speed: 4.0853s/iter; left time: 35186.7259s
Epoch: 35 cost time: 279.3697385787964
Epoch: 35, Steps: 132 | Train Loss: 0.1223014 Vali Loss: 0.1806007 Test Loss: 0.2186336
Validation loss decreased (0.181703 --> 0.180601).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1155063
	speed: 4.0312s/iter; left time: 34188.3106s
Epoch: 36 cost time: 188.4630103111267
Epoch: 36, Steps: 132 | Train Loss: 0.1213072 Vali Loss: 0.1802326 Test Loss: 0.2176413
Validation loss decreased (0.180601 --> 0.180233).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1178961
	speed: 2.8054s/iter; left time: 23422.1742s
Epoch: 37 cost time: 225.1971526145935
Epoch: 37, Steps: 132 | Train Loss: 0.1203049 Vali Loss: 0.1794812 Test Loss: 0.2166529
Validation loss decreased (0.180233 --> 0.179481).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1229018
	speed: 2.6793s/iter; left time: 22016.1864s
Epoch: 38 cost time: 134.20410132408142
Epoch: 38, Steps: 132 | Train Loss: 0.1194835 Vali Loss: 0.1787130 Test Loss: 0.2158708
Validation loss decreased (0.179481 --> 0.178713).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1144838
	speed: 2.2101s/iter; left time: 17868.5327s
Epoch: 39 cost time: 130.6157021522522
Epoch: 39, Steps: 132 | Train Loss: 0.1186988 Vali Loss: 0.1786608 Test Loss: 0.2149490
Validation loss decreased (0.178713 --> 0.178661).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1146999
	speed: 2.5861s/iter; left time: 20566.9162s
Epoch: 40 cost time: 137.84430050849915
Epoch: 40, Steps: 132 | Train Loss: 0.1179950 Vali Loss: 0.1782822 Test Loss: 0.2143009
Validation loss decreased (0.178661 --> 0.178282).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1164202
	speed: 2.2309s/iter; left time: 17447.5409s
Epoch: 41 cost time: 148.1989459991455
Epoch: 41, Steps: 132 | Train Loss: 0.1174562 Vali Loss: 0.1778881 Test Loss: 0.2135704
Validation loss decreased (0.178282 --> 0.177888).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1176223
	speed: 2.3145s/iter; left time: 17796.0191s
Epoch: 42 cost time: 145.52709436416626
Epoch: 42, Steps: 132 | Train Loss: 0.1169294 Vali Loss: 0.1775458 Test Loss: 0.2130068
Validation loss decreased (0.177888 --> 0.177546).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1148891
	speed: 2.1785s/iter; left time: 16462.9310s
Epoch: 43 cost time: 114.5441164970398
Epoch: 43, Steps: 132 | Train Loss: 0.1163878 Vali Loss: 0.1771474 Test Loss: 0.2125058
Validation loss decreased (0.177546 --> 0.177147).  Saving model ...
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1127420
	speed: 1.9256s/iter; left time: 14297.4202s
Epoch: 44 cost time: 119.13134598731995
Epoch: 44, Steps: 132 | Train Loss: 0.1159286 Vali Loss: 0.1769900 Test Loss: 0.2120246
Validation loss decreased (0.177147 --> 0.176990).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1115230
	speed: 1.9674s/iter; left time: 14348.5636s
Epoch: 45 cost time: 108.94272899627686
Epoch: 45, Steps: 132 | Train Loss: 0.1155118 Vali Loss: 0.1765628 Test Loss: 0.2116278
Validation loss decreased (0.176990 --> 0.176563).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1151818
	speed: 2.1129s/iter; left time: 15130.6332s
Epoch: 46 cost time: 153.85385918617249
Epoch: 46, Steps: 132 | Train Loss: 0.1151514 Vali Loss: 0.1764400 Test Loss: 0.2112200
Validation loss decreased (0.176563 --> 0.176440).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1114672
	speed: 2.7146s/iter; left time: 19080.7503s
Epoch: 47 cost time: 157.92664337158203
Epoch: 47, Steps: 132 | Train Loss: 0.1148278 Vali Loss: 0.1764550 Test Loss: 0.2108926
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1103004
	speed: 2.0410s/iter; left time: 14077.0040s
Epoch: 48 cost time: 119.36023116111755
Epoch: 48, Steps: 132 | Train Loss: 0.1145880 Vali Loss: 0.1763152 Test Loss: 0.2105380
Validation loss decreased (0.176440 --> 0.176315).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1209729
	speed: 1.8068s/iter; left time: 12222.7826s
Epoch: 49 cost time: 104.74771332740784
Epoch: 49, Steps: 132 | Train Loss: 0.1142679 Vali Loss: 0.1760377 Test Loss: 0.2102206
Validation loss decreased (0.176315 --> 0.176038).  Saving model ...
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1163838
	speed: 1.9517s/iter; left time: 12945.6688s
Epoch: 50 cost time: 121.26532626152039
Epoch: 50, Steps: 132 | Train Loss: 0.1140585 Vali Loss: 0.1760969 Test Loss: 0.2100234
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1139385
	speed: 1.8938s/iter; left time: 12311.8564s
Epoch: 51 cost time: 112.42672848701477
Epoch: 51, Steps: 132 | Train Loss: 0.1138130 Vali Loss: 0.1759157 Test Loss: 0.2097380
Validation loss decreased (0.176038 --> 0.175916).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1149295
	speed: 2.2743s/iter; left time: 14485.1286s
Epoch: 52 cost time: 158.90572381019592
Epoch: 52, Steps: 132 | Train Loss: 0.1136639 Vali Loss: 0.1759634 Test Loss: 0.2095204
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1090152
	speed: 2.2425s/iter; left time: 13986.2863s
Epoch: 53 cost time: 120.1709291934967
Epoch: 53, Steps: 132 | Train Loss: 0.1134886 Vali Loss: 0.1757677 Test Loss: 0.2093107
Validation loss decreased (0.175916 --> 0.175768).  Saving model ...
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1108563
	speed: 1.9685s/iter; left time: 12017.9869s
Epoch: 54 cost time: 121.79053735733032
Epoch: 54, Steps: 132 | Train Loss: 0.1133249 Vali Loss: 0.1758580 Test Loss: 0.2091450
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1108081
	speed: 1.9373s/iter; left time: 11571.7012s
Epoch: 55 cost time: 109.53624606132507
Epoch: 55, Steps: 132 | Train Loss: 0.1131855 Vali Loss: 0.1756397 Test Loss: 0.2089776
Validation loss decreased (0.175768 --> 0.175640).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1161372
	speed: 2.0046s/iter; left time: 11708.7553s
Epoch: 56 cost time: 138.70381474494934
Epoch: 56, Steps: 132 | Train Loss: 0.1130282 Vali Loss: 0.1755291 Test Loss: 0.2088262
Validation loss decreased (0.175640 --> 0.175529).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.1091466
	speed: 2.1177s/iter; left time: 12089.8354s
Epoch: 57 cost time: 113.99530053138733
Epoch: 57, Steps: 132 | Train Loss: 0.1128636 Vali Loss: 0.1756507 Test Loss: 0.2086659
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1142405
	speed: 1.8855s/iter; left time: 10515.1562s
Epoch: 58 cost time: 114.26991987228394
Epoch: 58, Steps: 132 | Train Loss: 0.1128194 Vali Loss: 0.1755590 Test Loss: 0.2085480
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1189626
	speed: 1.8571s/iter; left time: 10112.0702s
Epoch: 59 cost time: 111.8534460067749
Epoch: 59, Steps: 132 | Train Loss: 0.1126982 Vali Loss: 0.1757543 Test Loss: 0.2084233
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1178356
	speed: 1.8323s/iter; left time: 9735.0095s
Epoch: 60 cost time: 105.41447377204895
Epoch: 60, Steps: 132 | Train Loss: 0.1125728 Vali Loss: 0.1755017 Test Loss: 0.2083332
Validation loss decreased (0.175529 --> 0.175502).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1175874
	speed: 1.7605s/iter; left time: 9121.2272s
Epoch: 61 cost time: 112.00062489509583
Epoch: 61, Steps: 132 | Train Loss: 0.1125053 Vali Loss: 0.1753655 Test Loss: 0.2082285
Validation loss decreased (0.175502 --> 0.175366).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1095443
	speed: 2.6065s/iter; left time: 13160.3075s
Epoch: 62 cost time: 156.8554766178131
Epoch: 62, Steps: 132 | Train Loss: 0.1124547 Vali Loss: 0.1755898 Test Loss: 0.2081384
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1101419
	speed: 2.0726s/iter; left time: 10190.7738s
Epoch: 63 cost time: 103.91963005065918
Epoch: 63, Steps: 132 | Train Loss: 0.1124170 Vali Loss: 0.1754737 Test Loss: 0.2080508
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1109331
	speed: 1.7747s/iter; left time: 8492.0175s
Epoch: 64 cost time: 109.1040780544281
Epoch: 64, Steps: 132 | Train Loss: 0.1123301 Vali Loss: 0.1758274 Test Loss: 0.2079819
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.1172024
	speed: 1.7916s/iter; left time: 8336.2208s
Epoch: 65 cost time: 107.08449578285217
Epoch: 65, Steps: 132 | Train Loss: 0.1122903 Vali Loss: 0.1753407 Test Loss: 0.2079082
Validation loss decreased (0.175366 --> 0.175341).  Saving model ...
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.1167198
	speed: 1.7739s/iter; left time: 8019.9509s
Epoch: 66 cost time: 102.17025995254517
Epoch: 66, Steps: 132 | Train Loss: 0.1121932 Vali Loss: 0.1754334 Test Loss: 0.2078521
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.1103555
	speed: 1.7400s/iter; left time: 7637.0130s
Epoch: 67 cost time: 104.80738162994385
Epoch: 67, Steps: 132 | Train Loss: 0.1122227 Vali Loss: 0.1756557 Test Loss: 0.2077909
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.1131909
	speed: 1.7987s/iter; left time: 7657.0744s
Epoch: 68 cost time: 107.45014476776123
Epoch: 68, Steps: 132 | Train Loss: 0.1121530 Vali Loss: 0.1757436 Test Loss: 0.2077339
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.1098659
	speed: 1.7835s/iter; left time: 7356.9562s
Epoch: 69 cost time: 108.93592810630798
Epoch: 69, Steps: 132 | Train Loss: 0.1120989 Vali Loss: 0.1755358 Test Loss: 0.2076918
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.1135427
	speed: 1.7018s/iter; left time: 6795.3507s
Epoch: 70 cost time: 96.87455654144287
Epoch: 70, Steps: 132 | Train Loss: 0.1120948 Vali Loss: 0.1755539 Test Loss: 0.2076429
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.1094082
	speed: 1.5828s/iter; left time: 6111.1914s
Epoch: 71 cost time: 92.33541917800903
Epoch: 71, Steps: 132 | Train Loss: 0.1120449 Vali Loss: 0.1754140 Test Loss: 0.2075946
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.1157424
	speed: 1.5011s/iter; left time: 5597.6373s
Epoch: 72 cost time: 86.18342614173889
Epoch: 72, Steps: 132 | Train Loss: 0.1119872 Vali Loss: 0.1753393 Test Loss: 0.2075576
Validation loss decreased (0.175341 --> 0.175339).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.1106381
	speed: 1.4202s/iter; left time: 5108.2941s
Epoch: 73 cost time: 84.81918931007385
Epoch: 73, Steps: 132 | Train Loss: 0.1120059 Vali Loss: 0.1756044 Test Loss: 0.2075220
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.1154370
	speed: 1.4200s/iter; left time: 4920.3309s
Epoch: 74 cost time: 85.40091943740845
Epoch: 74, Steps: 132 | Train Loss: 0.1119434 Vali Loss: 0.1758188 Test Loss: 0.2074932
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.1114241
	speed: 1.3743s/iter; left time: 4580.5011s
Epoch: 75 cost time: 77.69447231292725
Epoch: 75, Steps: 132 | Train Loss: 0.1119572 Vali Loss: 0.1757084 Test Loss: 0.2074609
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.1140050
	speed: 1.4322s/iter; left time: 4584.3688s
Epoch: 76 cost time: 83.68858790397644
Epoch: 76, Steps: 132 | Train Loss: 0.1119210 Vali Loss: 0.1757899 Test Loss: 0.2074310
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.1119046
	speed: 2.0277s/iter; left time: 6222.8749s
Epoch: 77 cost time: 179.69201040267944
Epoch: 77, Steps: 132 | Train Loss: 0.1119006 Vali Loss: 0.1753211 Test Loss: 0.2074063
Validation loss decreased (0.175339 --> 0.175321).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.1105166
	speed: 3.1827s/iter; left time: 9347.5151s
Epoch: 78 cost time: 150.0917055606842
Epoch: 78, Steps: 132 | Train Loss: 0.1118785 Vali Loss: 0.1755259 Test Loss: 0.2073827
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.1118017
	speed: 2.0105s/iter; left time: 5639.5333s
Epoch: 79 cost time: 108.44859147071838
Epoch: 79, Steps: 132 | Train Loss: 0.1119228 Vali Loss: 0.1758149 Test Loss: 0.2073587
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.1119138
	speed: 1.7756s/iter; left time: 4746.0909s
Epoch: 80 cost time: 105.48945927619934
Epoch: 80, Steps: 132 | Train Loss: 0.1118417 Vali Loss: 0.1756565 Test Loss: 0.2073350
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.1136004
	speed: 1.8062s/iter; left time: 4589.6736s
Epoch: 81 cost time: 110.34287786483765
Epoch: 81, Steps: 132 | Train Loss: 0.1118717 Vali Loss: 0.1756890 Test Loss: 0.2073186
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.1110528
	speed: 1.8118s/iter; left time: 4364.6209s
Epoch: 82 cost time: 103.72247743606567
Epoch: 82, Steps: 132 | Train Loss: 0.1118654 Vali Loss: 0.1751632 Test Loss: 0.2072992
Validation loss decreased (0.175321 --> 0.175163).  Saving model ...
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.1202262
	speed: 1.8680s/iter; left time: 4253.4824s
Epoch: 83 cost time: 108.33329439163208
Epoch: 83, Steps: 132 | Train Loss: 0.1118328 Vali Loss: 0.1758201 Test Loss: 0.2072818
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.1065977
	speed: 1.9403s/iter; left time: 4161.8785s
Epoch: 84 cost time: 106.88776707649231
Epoch: 84, Steps: 132 | Train Loss: 0.1118417 Vali Loss: 0.1754924 Test Loss: 0.2072683
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.1056331
	speed: 1.8084s/iter; left time: 3640.3070s
Epoch: 85 cost time: 109.32409858703613
Epoch: 85, Steps: 132 | Train Loss: 0.1118103 Vali Loss: 0.1755974 Test Loss: 0.2072524
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.1107250
	speed: 1.8929s/iter; left time: 3560.5909s
Epoch: 86 cost time: 108.04567170143127
Epoch: 86, Steps: 132 | Train Loss: 0.1118455 Vali Loss: 0.1756829 Test Loss: 0.2072385
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.1095915
	speed: 1.8722s/iter; left time: 3274.5566s
Epoch: 87 cost time: 112.79729962348938
Epoch: 87, Steps: 132 | Train Loss: 0.1118236 Vali Loss: 0.1754522 Test Loss: 0.2072278
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.1196937
	speed: 1.7469s/iter; left time: 2824.7407s
Epoch: 88 cost time: 101.49417448043823
Epoch: 88, Steps: 132 | Train Loss: 0.1117674 Vali Loss: 0.1755967 Test Loss: 0.2072148
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.1173038
	speed: 1.7886s/iter; left time: 2656.0509s
Epoch: 89 cost time: 99.60071539878845
Epoch: 89, Steps: 132 | Train Loss: 0.1117820 Vali Loss: 0.1756528 Test Loss: 0.2072056
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.1067398
	speed: 1.6798s/iter; left time: 2272.7670s
Epoch: 90 cost time: 100.5661301612854
Epoch: 90, Steps: 132 | Train Loss: 0.1118032 Vali Loss: 0.1755998 Test Loss: 0.2071943
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.204402478767869e-06
	iters: 100, epoch: 91 | loss: 0.1054815
	speed: 1.7534s/iter; left time: 2140.9534s
Epoch: 91 cost time: 110.97859263420105
Epoch: 91, Steps: 132 | Train Loss: 0.1117639 Vali Loss: 0.1757105 Test Loss: 0.2071856
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.944182354829475e-06
	iters: 100, epoch: 92 | loss: 0.1211430
	speed: 2.2230s/iter; left time: 2420.8318s
Epoch: 92 cost time: 136.50117373466492
Epoch: 92, Steps: 132 | Train Loss: 0.1117916 Vali Loss: 0.1757927 Test Loss: 0.2071774
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.696973237088e-06
	iters: 100, epoch: 93 | loss: 0.1143693
	speed: 2.2810s/iter; left time: 2182.9589s
Epoch: 93 cost time: 140.42462873458862
Epoch: 93, Steps: 132 | Train Loss: 0.1117448 Vali Loss: 0.1757658 Test Loss: 0.2071690
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.462124575233601e-06
	iters: 100, epoch: 94 | loss: 0.1086016
	speed: 2.2568s/iter; left time: 1861.8515s
Epoch: 94 cost time: 136.8281102180481
Epoch: 94, Steps: 132 | Train Loss: 0.1117651 Vali Loss: 0.1757754 Test Loss: 0.2071620
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.239018346471921e-06
	iters: 100, epoch: 95 | loss: 0.1166834
	speed: 2.2368s/iter; left time: 1550.0704s
Epoch: 95 cost time: 135.8783824443817
Epoch: 95, Steps: 132 | Train Loss: 0.1118038 Vali Loss: 0.1759295 Test Loss: 0.2071534
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.027067429148324e-06
	iters: 100, epoch: 96 | loss: 0.1181490
	speed: 2.2713s/iter; left time: 1274.2171s
Epoch: 96 cost time: 137.76030588150024
Epoch: 96, Steps: 132 | Train Loss: 0.1117838 Vali Loss: 0.1758067 Test Loss: 0.2071489
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.825714057690908e-06
	iters: 100, epoch: 97 | loss: 0.1140139
	speed: 2.1987s/iter; left time: 943.2232s
Epoch: 97 cost time: 136.5563507080078
Epoch: 97, Steps: 132 | Train Loss: 0.1117735 Vali Loss: 0.1754115 Test Loss: 0.2071412
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.6344283548063623e-06
	iters: 100, epoch: 98 | loss: 0.1160885
	speed: 1.9803s/iter; left time: 588.1630s
Epoch: 98 cost time: 93.44428253173828
Epoch: 98, Steps: 132 | Train Loss: 0.1117575 Vali Loss: 0.1757163 Test Loss: 0.2071353
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.452706937066044e-06
	iters: 100, epoch: 99 | loss: 0.1135190
	speed: 1.6541s/iter; left time: 272.9237s
Epoch: 99 cost time: 93.31326174736023
Epoch: 99, Steps: 132 | Train Loss: 0.1117605 Vali Loss: 0.1758914 Test Loss: 0.2071307
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.2800715902127414e-06
	iters: 100, epoch: 100 | loss: 0.1050854
	speed: 1.7163s/iter; left time: 56.6390s
Epoch: 100 cost time: 114.49798512458801
Epoch: 100, Steps: 132 | Train Loss: 0.1117883 Vali Loss: 0.1758178 Test Loss: 0.2071257
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.1160680107021042e-06
train 16973
val 1913
test 4541
Model(
  (freq_upsampler): Linear(in_features=320, out_features=640, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  8414822400.0
params:  205440.0
Trainable parameters:  205440
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2222258
	speed: 1.0696s/iter; left time: 14012.7736s
Epoch: 1 cost time: 139.23924160003662
Epoch: 1, Steps: 132 | Train Loss: 0.2184783 Vali Loss: 0.1757660 Test Loss: 0.2061582
Validation loss decreased (inf --> 0.175766).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2181715
	speed: 2.2074s/iter; left time: 28627.6560s
Epoch: 2 cost time: 133.20323777198792
Epoch: 2, Steps: 132 | Train Loss: 0.2180086 Vali Loss: 0.1751417 Test Loss: 0.2059028
Validation loss decreased (0.175766 --> 0.175142).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2099667
	speed: 2.1649s/iter; left time: 27790.7765s
Epoch: 3 cost time: 129.96324014663696
Epoch: 3, Steps: 132 | Train Loss: 0.2178015 Vali Loss: 0.1751117 Test Loss: 0.2057909
Validation loss decreased (0.175142 --> 0.175112).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2125303
	speed: 1.6863s/iter; left time: 21424.3818s
Epoch: 4 cost time: 104.01239538192749
Epoch: 4, Steps: 132 | Train Loss: 0.2176957 Vali Loss: 0.1750868 Test Loss: 0.2059910
Validation loss decreased (0.175112 --> 0.175087).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2181586
	speed: 1.8937s/iter; left time: 23809.3760s
Epoch: 5 cost time: 122.44899249076843
Epoch: 5, Steps: 132 | Train Loss: 0.2176906 Vali Loss: 0.1748058 Test Loss: 0.2057959
Validation loss decreased (0.175087 --> 0.174806).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2204247
	speed: 2.0313s/iter; left time: 25271.7232s
Epoch: 6 cost time: 116.20078873634338
Epoch: 6, Steps: 132 | Train Loss: 0.2176481 Vali Loss: 0.1749792 Test Loss: 0.2057244
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2151156
	speed: 2.0711s/iter; left time: 25492.5557s
Epoch: 7 cost time: 110.40162253379822
Epoch: 7, Steps: 132 | Train Loss: 0.2174358 Vali Loss: 0.1748014 Test Loss: 0.2058106
Validation loss decreased (0.174806 --> 0.174801).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2122569
	speed: 1.6230s/iter; left time: 19762.6670s
Epoch: 8 cost time: 98.20285296440125
Epoch: 8, Steps: 132 | Train Loss: 0.2174594 Vali Loss: 0.1749895 Test Loss: 0.2056399
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2038995
	speed: 1.6930s/iter; left time: 20391.6042s
Epoch: 9 cost time: 106.97714495658875
Epoch: 9, Steps: 132 | Train Loss: 0.2173623 Vali Loss: 0.1750209 Test Loss: 0.2056597
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2213709
	speed: 1.8411s/iter; left time: 21933.2833s
Epoch: 10 cost time: 109.58123850822449
Epoch: 10, Steps: 132 | Train Loss: 0.2174641 Vali Loss: 0.1747564 Test Loss: 0.2057281
Validation loss decreased (0.174801 --> 0.174756).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2074709
	speed: 1.5194s/iter; left time: 17900.1452s
Epoch: 11 cost time: 72.68945121765137
Epoch: 11, Steps: 132 | Train Loss: 0.2173413 Vali Loss: 0.1750561 Test Loss: 0.2056682
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2053605
	speed: 1.0987s/iter; left time: 12798.9731s
Epoch: 12 cost time: 67.26978015899658
Epoch: 12, Steps: 132 | Train Loss: 0.2173513 Vali Loss: 0.1747421 Test Loss: 0.2056306
Validation loss decreased (0.174756 --> 0.174742).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2040043
	speed: 1.0946s/iter; left time: 12606.8283s
Epoch: 13 cost time: 66.1019549369812
Epoch: 13, Steps: 132 | Train Loss: 0.2174284 Vali Loss: 0.1747741 Test Loss: 0.2056506
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2129216
	speed: 1.0977s/iter; left time: 12497.2599s
Epoch: 14 cost time: 64.46119093894958
Epoch: 14, Steps: 132 | Train Loss: 0.2173425 Vali Loss: 0.1750601 Test Loss: 0.2056236
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2182725
	speed: 1.0843s/iter; left time: 12201.4776s
Epoch: 15 cost time: 66.44193601608276
Epoch: 15, Steps: 132 | Train Loss: 0.2173569 Vali Loss: 0.1747452 Test Loss: 0.2056207
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2145190
	speed: 1.0901s/iter; left time: 12123.0352s
Epoch: 16 cost time: 67.30591487884521
Epoch: 16, Steps: 132 | Train Loss: 0.2173282 Vali Loss: 0.1747774 Test Loss: 0.2056314
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2188702
	speed: 1.0103s/iter; left time: 11102.4023s
Epoch: 17 cost time: 58.0172381401062
Epoch: 17, Steps: 132 | Train Loss: 0.2172657 Vali Loss: 0.1747272 Test Loss: 0.2056499
Validation loss decreased (0.174742 --> 0.174727).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2217066
	speed: 0.9689s/iter; left time: 10518.9086s
Epoch: 18 cost time: 57.19231677055359
Epoch: 18, Steps: 132 | Train Loss: 0.2172800 Vali Loss: 0.1747443 Test Loss: 0.2056204
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2104037
	speed: 0.9556s/iter; left time: 10249.1340s
Epoch: 19 cost time: 58.15568780899048
Epoch: 19, Steps: 132 | Train Loss: 0.2173290 Vali Loss: 0.1749208 Test Loss: 0.2055721
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2302482
	speed: 0.9268s/iter; left time: 9817.8385s
Epoch: 20 cost time: 56.237024784088135
Epoch: 20, Steps: 132 | Train Loss: 0.2173301 Vali Loss: 0.1746305 Test Loss: 0.2056260
Validation loss decreased (0.174727 --> 0.174631).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2265444
	speed: 0.9440s/iter; left time: 9874.9769s
Epoch: 21 cost time: 56.189361333847046
Epoch: 21, Steps: 132 | Train Loss: 0.2173051 Vali Loss: 0.1744061 Test Loss: 0.2055988
Validation loss decreased (0.174631 --> 0.174406).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2199189
	speed: 0.9534s/iter; left time: 9848.1758s
Epoch: 22 cost time: 57.45981740951538
Epoch: 22, Steps: 132 | Train Loss: 0.2171991 Vali Loss: 0.1749443 Test Loss: 0.2056070
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2220937
	speed: 0.9055s/iter; left time: 9233.8173s
Epoch: 23 cost time: 52.88865256309509
Epoch: 23, Steps: 132 | Train Loss: 0.2172547 Vali Loss: 0.1746081 Test Loss: 0.2055756
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2081542
	speed: 0.9252s/iter; left time: 9311.8515s
Epoch: 24 cost time: 56.34485721588135
Epoch: 24, Steps: 132 | Train Loss: 0.2171923 Vali Loss: 0.1744427 Test Loss: 0.2055746
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2206055
	speed: 0.9284s/iter; left time: 9221.6382s
Epoch: 25 cost time: 55.86331129074097
Epoch: 25, Steps: 132 | Train Loss: 0.2172496 Vali Loss: 0.1748261 Test Loss: 0.2055755
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2246182
	speed: 0.8342s/iter; left time: 8176.3532s
Epoch: 26 cost time: 45.467331886291504
Epoch: 26, Steps: 132 | Train Loss: 0.2172802 Vali Loss: 0.1746243 Test Loss: 0.2056364
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2215869
	speed: 0.7579s/iter; left time: 7328.0332s
Epoch: 27 cost time: 44.929994344711304
Epoch: 27, Steps: 132 | Train Loss: 0.2173167 Vali Loss: 0.1746239 Test Loss: 0.2055981
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2289925
	speed: 0.7637s/iter; left time: 7282.9531s
Epoch: 28 cost time: 46.354010820388794
Epoch: 28, Steps: 132 | Train Loss: 0.2171770 Vali Loss: 0.1747328 Test Loss: 0.2055605
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2141240
	speed: 0.7902s/iter; left time: 7432.2334s
Epoch: 29 cost time: 47.52112650871277
Epoch: 29, Steps: 132 | Train Loss: 0.2171985 Vali Loss: 0.1743814 Test Loss: 0.2055663
Validation loss decreased (0.174406 --> 0.174381).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2258281
	speed: 0.8096s/iter; left time: 7506.9696s
Epoch: 30 cost time: 47.69937300682068
Epoch: 30, Steps: 132 | Train Loss: 0.2171471 Vali Loss: 0.1744910 Test Loss: 0.2055567
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2211604
	speed: 0.8001s/iter; left time: 7313.3624s
Epoch: 31 cost time: 47.147955894470215
Epoch: 31, Steps: 132 | Train Loss: 0.2171380 Vali Loss: 0.1746746 Test Loss: 0.2055518
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2258224
	speed: 0.8163s/iter; left time: 7353.7861s
Epoch: 32 cost time: 49.19148588180542
Epoch: 32, Steps: 132 | Train Loss: 0.2171866 Vali Loss: 0.1744063 Test Loss: 0.2055629
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2115449
	speed: 0.8048s/iter; left time: 7144.0350s
Epoch: 33 cost time: 48.368736028671265
Epoch: 33, Steps: 132 | Train Loss: 0.2171784 Vali Loss: 0.1743610 Test Loss: 0.2055458
Validation loss decreased (0.174381 --> 0.174361).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2027392
	speed: 0.8053s/iter; left time: 7042.3291s
Epoch: 34 cost time: 48.71164107322693
Epoch: 34, Steps: 132 | Train Loss: 0.2171180 Vali Loss: 0.1744712 Test Loss: 0.2055528
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2249454
	speed: 0.8020s/iter; left time: 6908.0334s
Epoch: 35 cost time: 47.59896636009216
Epoch: 35, Steps: 132 | Train Loss: 0.2171720 Vali Loss: 0.1745719 Test Loss: 0.2055477
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2140918
	speed: 0.8050s/iter; left time: 6826.8547s
Epoch: 36 cost time: 48.01897644996643
Epoch: 36, Steps: 132 | Train Loss: 0.2171720 Vali Loss: 0.1746731 Test Loss: 0.2055470
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2169460
	speed: 0.8072s/iter; left time: 6739.1155s
Epoch: 37 cost time: 48.50496745109558
Epoch: 37, Steps: 132 | Train Loss: 0.2171408 Vali Loss: 0.1745471 Test Loss: 0.2055729
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2167761
	speed: 0.8037s/iter; left time: 6603.8048s
Epoch: 38 cost time: 47.65442967414856
Epoch: 38, Steps: 132 | Train Loss: 0.2171209 Vali Loss: 0.1747072 Test Loss: 0.2055373
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2170837
	speed: 0.8025s/iter; left time: 6488.3830s
Epoch: 39 cost time: 48.53514862060547
Epoch: 39, Steps: 132 | Train Loss: 0.2171219 Vali Loss: 0.1744740 Test Loss: 0.2055433
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2106716
	speed: 0.8098s/iter; left time: 6440.0767s
Epoch: 40 cost time: 48.899354219436646
Epoch: 40, Steps: 132 | Train Loss: 0.2171077 Vali Loss: 0.1745496 Test Loss: 0.2055361
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2186852
	speed: 0.7974s/iter; left time: 6236.7624s
Epoch: 41 cost time: 47.41044020652771
Epoch: 41, Steps: 132 | Train Loss: 0.2172152 Vali Loss: 0.1746740 Test Loss: 0.2055279
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1933131
	speed: 0.7903s/iter; left time: 6076.7038s
Epoch: 42 cost time: 46.57035255432129
Epoch: 42, Steps: 132 | Train Loss: 0.2172077 Vali Loss: 0.1743613 Test Loss: 0.2055544
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2210929
	speed: 0.8027s/iter; left time: 6066.3728s
Epoch: 43 cost time: 47.484781980514526
Epoch: 43, Steps: 132 | Train Loss: 0.2171180 Vali Loss: 0.1744976 Test Loss: 0.2055085
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2156986
	speed: 0.8108s/iter; left time: 6019.9713s
Epoch: 44 cost time: 47.33913326263428
Epoch: 44, Steps: 132 | Train Loss: 0.2171600 Vali Loss: 0.1746920 Test Loss: 0.2055092
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2202495
	speed: 0.8055s/iter; left time: 5874.7476s
Epoch: 45 cost time: 48.43237066268921
Epoch: 45, Steps: 132 | Train Loss: 0.2170992 Vali Loss: 0.1743338 Test Loss: 0.2055255
Validation loss decreased (0.174361 --> 0.174334).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2069197
	speed: 0.7850s/iter; left time: 5621.2942s
Epoch: 46 cost time: 44.56787705421448
Epoch: 46, Steps: 132 | Train Loss: 0.2170191 Vali Loss: 0.1744516 Test Loss: 0.2055204
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2179148
	speed: 0.7315s/iter; left time: 5141.7290s
Epoch: 47 cost time: 44.28120827674866
Epoch: 47, Steps: 132 | Train Loss: 0.2169838 Vali Loss: 0.1748658 Test Loss: 0.2055128
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2230806
	speed: 0.9963s/iter; left time: 6871.2740s
Epoch: 48 cost time: 71.39024567604065
Epoch: 48, Steps: 132 | Train Loss: 0.2170983 Vali Loss: 0.1745372 Test Loss: 0.2055151
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2330992
	speed: 1.1468s/iter; left time: 7758.3949s
Epoch: 49 cost time: 70.09436345100403
Epoch: 49, Steps: 132 | Train Loss: 0.2170548 Vali Loss: 0.1746294 Test Loss: 0.2055232
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2124074
	speed: 1.1822s/iter; left time: 7841.8025s
Epoch: 50 cost time: 70.81645703315735
Epoch: 50, Steps: 132 | Train Loss: 0.2171268 Vali Loss: 0.1744195 Test Loss: 0.2055321
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2115174
	speed: 1.1884s/iter; left time: 7725.5262s
Epoch: 51 cost time: 70.98163151741028
Epoch: 51, Steps: 132 | Train Loss: 0.2170242 Vali Loss: 0.1745128 Test Loss: 0.2055272
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2206777
	speed: 1.1936s/iter; left time: 7601.9676s
Epoch: 52 cost time: 70.59365940093994
Epoch: 52, Steps: 132 | Train Loss: 0.2171072 Vali Loss: 0.1742845 Test Loss: 0.2055133
Validation loss decreased (0.174334 --> 0.174285).  Saving model ...
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2231100
	speed: 1.1967s/iter; left time: 7463.8783s
Epoch: 53 cost time: 71.80373883247375
Epoch: 53, Steps: 132 | Train Loss: 0.2170066 Vali Loss: 0.1743548 Test Loss: 0.2055267
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2200181
	speed: 1.1978s/iter; left time: 7312.5617s
Epoch: 54 cost time: 73.30079126358032
Epoch: 54, Steps: 132 | Train Loss: 0.2170758 Vali Loss: 0.1745161 Test Loss: 0.2055150
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2155003
	speed: 1.1762s/iter; left time: 7025.5108s
Epoch: 55 cost time: 71.59280347824097
Epoch: 55, Steps: 132 | Train Loss: 0.2170320 Vali Loss: 0.1744725 Test Loss: 0.2055281
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2186547
	speed: 1.1528s/iter; left time: 6733.4826s
Epoch: 56 cost time: 69.82210659980774
Epoch: 56, Steps: 132 | Train Loss: 0.2171097 Vali Loss: 0.1741751 Test Loss: 0.2055313
Validation loss decreased (0.174285 --> 0.174175).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2191498
	speed: 1.8173s/iter; left time: 10374.8363s
Epoch: 57 cost time: 128.39966869354248
Epoch: 57, Steps: 132 | Train Loss: 0.2170663 Vali Loss: 0.1743417 Test Loss: 0.2055186
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2229148
	speed: 1.8045s/iter; left time: 10063.8740s
Epoch: 58 cost time: 110.21782445907593
Epoch: 58, Steps: 132 | Train Loss: 0.2170461 Vali Loss: 0.1746745 Test Loss: 0.2055187
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2144239
	speed: 1.8255s/iter; left time: 9939.7667s
Epoch: 59 cost time: 104.1818995475769
Epoch: 59, Steps: 132 | Train Loss: 0.2170496 Vali Loss: 0.1746541 Test Loss: 0.2055221
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.2144108
	speed: 1.9360s/iter; left time: 10285.9701s
Epoch: 60 cost time: 133.563640832901
Epoch: 60, Steps: 132 | Train Loss: 0.2170372 Vali Loss: 0.1745244 Test Loss: 0.2055195
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.2163784
	speed: 2.2524s/iter; left time: 11669.7418s
Epoch: 61 cost time: 115.0141110420227
Epoch: 61, Steps: 132 | Train Loss: 0.2170697 Vali Loss: 0.1745666 Test Loss: 0.2055213
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.2321691
	speed: 1.8432s/iter; left time: 9306.1131s
Epoch: 62 cost time: 109.25737476348877
Epoch: 62, Steps: 132 | Train Loss: 0.2170948 Vali Loss: 0.1743826 Test Loss: 0.2055230
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.2157124
	speed: 1.8743s/iter; left time: 9215.9040s
Epoch: 63 cost time: 117.71995401382446
Epoch: 63, Steps: 132 | Train Loss: 0.2170478 Vali Loss: 0.1744430 Test Loss: 0.2055226
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.2245494
	speed: 2.0663s/iter; left time: 9887.1553s
Epoch: 64 cost time: 123.50140643119812
Epoch: 64, Steps: 132 | Train Loss: 0.2171043 Vali Loss: 0.1746042 Test Loss: 0.2055248
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.2166279
	speed: 2.0303s/iter; left time: 9447.0001s
Epoch: 65 cost time: 117.48340821266174
Epoch: 65, Steps: 132 | Train Loss: 0.2169304 Vali Loss: 0.1745341 Test Loss: 0.2055186
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.2270147
	speed: 1.9651s/iter; left time: 8884.2609s
Epoch: 66 cost time: 117.63582849502563
Epoch: 66, Steps: 132 | Train Loss: 0.2170236 Vali Loss: 0.1741827 Test Loss: 0.2055212
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.2154498
	speed: 2.0653s/iter; left time: 9064.5464s
Epoch: 67 cost time: 132.53021121025085
Epoch: 67, Steps: 132 | Train Loss: 0.2170531 Vali Loss: 0.1747818 Test Loss: 0.2055227
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.2167893
	speed: 2.6720s/iter; left time: 11374.8734s
Epoch: 68 cost time: 164.4218249320984
Epoch: 68, Steps: 132 | Train Loss: 0.2170616 Vali Loss: 0.1744141 Test Loss: 0.2055207
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.2096141
	speed: 2.2914s/iter; left time: 9451.9937s
Epoch: 69 cost time: 114.37194967269897
Epoch: 69, Steps: 132 | Train Loss: 0.2170680 Vali Loss: 0.1744610 Test Loss: 0.2055183
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.2308484
	speed: 1.9980s/iter; left time: 7977.8965s
Epoch: 70 cost time: 115.47888898849487
Epoch: 70, Steps: 132 | Train Loss: 0.2170764 Vali Loss: 0.1745283 Test Loss: 0.2055230
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.2217140
	speed: 1.9534s/iter; left time: 7541.9932s
Epoch: 71 cost time: 115.62045764923096
Epoch: 71, Steps: 132 | Train Loss: 0.2170276 Vali Loss: 0.1745386 Test Loss: 0.2055231
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.2321262
	speed: 1.9646s/iter; left time: 7325.8843s
Epoch: 72 cost time: 117.39533877372742
Epoch: 72, Steps: 132 | Train Loss: 0.2170563 Vali Loss: 0.1745329 Test Loss: 0.2055217
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.2225618
	speed: 1.8571s/iter; left time: 6679.8197s
Epoch: 73 cost time: 118.32433128356934
Epoch: 73, Steps: 132 | Train Loss: 0.2170693 Vali Loss: 0.1743349 Test Loss: 0.2055189
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.2130917
	speed: 1.8499s/iter; left time: 6409.7383s
Epoch: 74 cost time: 108.42431282997131
Epoch: 74, Steps: 132 | Train Loss: 0.2169802 Vali Loss: 0.1746367 Test Loss: 0.2055186
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.2101150
	speed: 1.8142s/iter; left time: 6046.5823s
Epoch: 75 cost time: 105.41999769210815
Epoch: 75, Steps: 132 | Train Loss: 0.2169467 Vali Loss: 0.1742334 Test Loss: 0.2055201
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.2189196
	speed: 1.6916s/iter; left time: 5414.7764s
Epoch: 76 cost time: 96.92352533340454
Epoch: 76, Steps: 132 | Train Loss: 0.2170590 Vali Loss: 0.1741582 Test Loss: 0.2055210
Validation loss decreased (0.174175 --> 0.174158).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.2152232
	speed: 1.6355s/iter; left time: 5019.3227s
Epoch: 77 cost time: 99.16262173652649
Epoch: 77, Steps: 132 | Train Loss: 0.2170409 Vali Loss: 0.1742509 Test Loss: 0.2055231
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.2218515
	speed: 1.7477s/iter; left time: 5133.0707s
Epoch: 78 cost time: 115.25281095504761
Epoch: 78, Steps: 132 | Train Loss: 0.2170395 Vali Loss: 0.1746118 Test Loss: 0.2055162
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.2057818
	speed: 2.1633s/iter; left time: 6068.1889s
Epoch: 79 cost time: 125.55866312980652
Epoch: 79, Steps: 132 | Train Loss: 0.2169537 Vali Loss: 0.1742706 Test Loss: 0.2055180
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.2227124
	speed: 2.0616s/iter; left time: 5510.6363s
Epoch: 80 cost time: 124.95512199401855
Epoch: 80, Steps: 132 | Train Loss: 0.2170971 Vali Loss: 0.1746731 Test Loss: 0.2055197
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.2139320
	speed: 1.9886s/iter; left time: 5052.9076s
Epoch: 81 cost time: 120.43917274475098
Epoch: 81, Steps: 132 | Train Loss: 0.2170181 Vali Loss: 0.1744661 Test Loss: 0.2055191
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.2231803
	speed: 1.6590s/iter; left time: 3996.4501s
Epoch: 82 cost time: 79.50581502914429
Epoch: 82, Steps: 132 | Train Loss: 0.2170969 Vali Loss: 0.1744134 Test Loss: 0.2055195
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.2143774
	speed: 1.3662s/iter; left time: 3110.9239s
Epoch: 83 cost time: 84.99711680412292
Epoch: 83, Steps: 132 | Train Loss: 0.2170218 Vali Loss: 0.1746549 Test Loss: 0.2055162
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.2216797
	speed: 1.1025s/iter; left time: 2364.8550s
Epoch: 84 cost time: 60.7047963142395
Epoch: 84, Steps: 132 | Train Loss: 0.2170009 Vali Loss: 0.1743145 Test Loss: 0.2055196
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.2167863
	speed: 0.9440s/iter; left time: 1900.3361s
Epoch: 85 cost time: 56.8042950630188
Epoch: 85, Steps: 132 | Train Loss: 0.2171392 Vali Loss: 0.1745498 Test Loss: 0.2055193
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.2202265
	speed: 0.8939s/iter; left time: 1681.3954s
Epoch: 86 cost time: 54.06361746788025
Epoch: 86, Steps: 132 | Train Loss: 0.2170429 Vali Loss: 0.1743261 Test Loss: 0.2055195
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.2234843
	speed: 0.8963s/iter; left time: 1567.6971s
Epoch: 87 cost time: 54.978071212768555
Epoch: 87, Steps: 132 | Train Loss: 0.2169921 Vali Loss: 0.1742984 Test Loss: 0.2055185
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.2277054
	speed: 0.8922s/iter; left time: 1442.7491s
Epoch: 88 cost time: 55.800257444381714
Epoch: 88, Steps: 132 | Train Loss: 0.2171630 Vali Loss: 0.1744318 Test Loss: 0.2055194
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.2141829
	speed: 0.8753s/iter; left time: 1299.8712s
Epoch: 89 cost time: 53.7962691783905
Epoch: 89, Steps: 132 | Train Loss: 0.2169650 Vali Loss: 0.1742138 Test Loss: 0.2055173
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.2122549
	speed: 0.8799s/iter; left time: 1190.4585s
Epoch: 90 cost time: 52.60393667221069
Epoch: 90, Steps: 132 | Train Loss: 0.2170398 Vali Loss: 0.1746031 Test Loss: 0.2055195
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.204402478767869e-06
	iters: 100, epoch: 91 | loss: 0.2236563
	speed: 0.8819s/iter; left time: 1076.8144s
Epoch: 91 cost time: 53.35351037979126
Epoch: 91, Steps: 132 | Train Loss: 0.2171230 Vali Loss: 0.1742706 Test Loss: 0.2055205
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.944182354829475e-06
	iters: 100, epoch: 92 | loss: 0.2203855
	speed: 0.8701s/iter; left time: 947.5256s
Epoch: 92 cost time: 51.47467279434204
Epoch: 92, Steps: 132 | Train Loss: 0.2170822 Vali Loss: 0.1748076 Test Loss: 0.2055207
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.696973237088e-06
	iters: 100, epoch: 93 | loss: 0.2167344
	speed: 0.8959s/iter; left time: 857.3719s
Epoch: 93 cost time: 52.642882347106934
Epoch: 93, Steps: 132 | Train Loss: 0.2169436 Vali Loss: 0.1746740 Test Loss: 0.2055200
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.462124575233601e-06
	iters: 100, epoch: 94 | loss: 0.2030469
	speed: 0.8757s/iter; left time: 722.4487s
Epoch: 94 cost time: 52.30490708351135
Epoch: 94, Steps: 132 | Train Loss: 0.2170472 Vali Loss: 0.1745688 Test Loss: 0.2055207
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.239018346471921e-06
	iters: 100, epoch: 95 | loss: 0.2137042
	speed: 0.8851s/iter; left time: 613.3408s
Epoch: 95 cost time: 53.612781047821045
Epoch: 95, Steps: 132 | Train Loss: 0.2170564 Vali Loss: 0.1742501 Test Loss: 0.2055204
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.027067429148324e-06
	iters: 100, epoch: 96 | loss: 0.2162107
	speed: 0.8894s/iter; left time: 498.9672s
Epoch: 96 cost time: 53.26068902015686
Epoch: 96, Steps: 132 | Train Loss: 0.2170721 Vali Loss: 0.1742457 Test Loss: 0.2055197
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_720_j720_H10_FITS_custom_ftM_sl720_ll48_pl720_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
mse:0.20381644368171692, mae:0.2927771806716919, rse:0.4503467381000519, corr:[0.44658482 0.44971603 0.45086363 0.45130765 0.4513695  0.45148504
 0.45142522 0.45138517 0.45115122 0.4511347  0.45096123 0.45093876
 0.4508332  0.4508289  0.4507903  0.4507902  0.4507627  0.45070708
 0.45070156 0.45054966 0.45048583 0.45045698 0.45055512 0.45061487
 0.45075226 0.45101446 0.45127028 0.4512879  0.45122078 0.4511463
 0.45099857 0.45090854 0.45076427 0.45066345 0.45052516 0.45047283
 0.45040765 0.4503868  0.45036915 0.45031795 0.45031363 0.4502998
 0.45029315 0.45013264 0.45005122 0.45001453 0.45005774 0.45013094
 0.45021576 0.450418   0.45057732 0.45058694 0.4505056  0.4504545
 0.45037097 0.45029876 0.45020473 0.45013526 0.45007026 0.45000705
 0.44997495 0.44993362 0.44992682 0.4499151  0.44993412 0.4499005
 0.44985402 0.4497324  0.4496452  0.44965404 0.44966182 0.44972292
 0.44974634 0.44988284 0.449958   0.44992095 0.44984904 0.44978204
 0.44971937 0.44958767 0.44950038 0.44943333 0.4493793  0.44931018
 0.44926882 0.44924998 0.44927436 0.44928527 0.449248   0.4492588
 0.4492365  0.4491674  0.4490565  0.44906676 0.44911128 0.4491369
 0.44918337 0.44928935 0.44939607 0.4493307  0.44927722 0.44922993
 0.44917455 0.44908813 0.4490166  0.44893306 0.44882065 0.448797
 0.44872722 0.44872138 0.44872093 0.44873223 0.44871745 0.44869873
 0.4486766  0.4485553  0.44851267 0.44853202 0.4485928  0.44867542
 0.4488716  0.44896582 0.44903845 0.44901302 0.44897094 0.44894394
 0.44888115 0.44884416 0.44876206 0.4486745  0.44857585 0.44849876
 0.44849354 0.44851324 0.44853118 0.44854438 0.44856828 0.44857135
 0.4486064  0.44861883 0.44866458 0.44868672 0.44868988 0.44869506
 0.44867355 0.44873926 0.44879982 0.44881037 0.44877842 0.44873795
 0.44867834 0.44860616 0.44857183 0.4484887  0.44840086 0.4483569
 0.44833416 0.44832614 0.44835213 0.4483725  0.44840923 0.44845888
 0.44849268 0.448468   0.4484383  0.44840243 0.4483572  0.44824332
 0.44801375 0.44803634 0.44817114 0.44812378 0.44803846 0.44795242
 0.44785568 0.4477391  0.4476282  0.4475147  0.44741952 0.44736698
 0.44732204 0.4473238  0.44731334 0.4473187  0.44731104 0.4473125
 0.44724646 0.44705284 0.44689807 0.44681564 0.44681743 0.44681066
 0.44677562 0.44687942 0.44701406 0.4470119  0.44695187 0.44686863
 0.44674468 0.4466646  0.4465953  0.44648823 0.44638664 0.44633192
 0.44629988 0.44629928 0.44629171 0.44629055 0.44629654 0.4462984
 0.44626635 0.44606602 0.4459251  0.44588315 0.44590312 0.44593588
 0.4459659  0.44610235 0.4462452  0.4462373  0.4461471  0.44611922
 0.44605747 0.44596943 0.44592857 0.44587266 0.44578013 0.4457103
 0.44568676 0.44565508 0.44564596 0.44564578 0.44566265 0.4456243
 0.44559634 0.44546005 0.44533265 0.44530016 0.4453038  0.44534132
 0.4453864  0.4455199  0.4456169  0.44561064 0.44555652 0.44549295
 0.4454416  0.44536513 0.44529766 0.44519493 0.4450962  0.44505718
 0.44503683 0.44498855 0.44498402 0.44498676 0.44494876 0.44497788
 0.44494224 0.44484594 0.4447912  0.44479832 0.44484097 0.4448559
 0.44492114 0.44504514 0.44514778 0.445135   0.44508192 0.4450174
 0.44497597 0.44488212 0.4447866  0.44470322 0.44458613 0.44456705
 0.44453648 0.4445222  0.4445416  0.44454998 0.44456026 0.44454187
 0.4444876  0.44436502 0.4443351  0.4443839  0.44446146 0.44452566
 0.44476345 0.4449102  0.44496486 0.44496745 0.4449221  0.4448969
 0.44484547 0.44478738 0.44470844 0.44461253 0.44450897 0.44445515
 0.4444553  0.44442388 0.44442874 0.44442976 0.44444847 0.44445133
 0.4444804  0.44448867 0.44448054 0.44454467 0.44455528 0.4445332
 0.44449618 0.44457683 0.44467223 0.44466963 0.4446192  0.4445672
 0.4445392  0.4444384  0.44440284 0.44432822 0.444233   0.44418982
 0.44414145 0.44413432 0.44416222 0.44418478 0.44420287 0.44425544
 0.44425127 0.44417703 0.44408306 0.4440145  0.44400245 0.4438354
 0.44357616 0.44360942 0.4437179  0.4436708  0.44356716 0.4434753
 0.44335204 0.4432123  0.44307104 0.44295558 0.44283098 0.44276217
 0.4427077  0.44268894 0.44269252 0.4427008  0.44269305 0.44267967
 0.44268423 0.44254848 0.44245905 0.4424514  0.44247505 0.4424664
 0.442385   0.4424711  0.4425708  0.4425576  0.44246066 0.44238654
 0.4422875  0.44217336 0.4420933  0.4419894  0.4418621  0.4418041
 0.44179857 0.44177404 0.44178447 0.44174153 0.4417458  0.4417541
 0.4417181  0.44161066 0.44149938 0.44150752 0.44151905 0.44151926
 0.44153914 0.44161963 0.44172412 0.44173583 0.44167906 0.4416363
 0.44155896 0.44148502 0.44143724 0.4413263  0.4412419  0.4412065
 0.44116667 0.441174   0.44117984 0.44118217 0.44117463 0.44117942
 0.4411544  0.44104517 0.44092876 0.44090408 0.44095325 0.44095182
 0.44096792 0.4410789  0.4411739  0.4411717  0.44115293 0.44113037
 0.44104865 0.44098517 0.44085974 0.44076148 0.4407314  0.44070113
 0.44071198 0.44070873 0.44069266 0.44072777 0.44074637 0.44073924
 0.4407327  0.4406078  0.44054964 0.44056696 0.44059741 0.44061244
 0.4406604  0.4407852  0.44087702 0.44085822 0.4408301  0.44080627
 0.44074807 0.44067538 0.4405935  0.44051734 0.44042662 0.4403908
 0.44038707 0.4403623  0.44042158 0.4404371  0.4404018  0.44043338
 0.44042537 0.44027683 0.4401912  0.4402173  0.44026637 0.44036695
 0.44057277 0.44069102 0.44076714 0.4408097  0.44079542 0.44077772
 0.4407527  0.44065863 0.44059116 0.44049522 0.4403793  0.44033203
 0.44036394 0.4403675  0.44041163 0.4404681  0.4404789  0.44050655
 0.4404999  0.44051242 0.4405289  0.44054234 0.44057307 0.44057718
 0.4405541  0.44060794 0.4407048  0.44071293 0.44069767 0.44066748
 0.44062382 0.44057146 0.44053057 0.4404628  0.44037673 0.4403593
 0.44036934 0.44040686 0.44041243 0.44044888 0.44048765 0.4405154
 0.4405495  0.4404173  0.4403256  0.44029304 0.44025123 0.44007552
 0.4398135  0.43980926 0.43986803 0.43985224 0.43977305 0.43970394
 0.43959877 0.4394619  0.43933555 0.4392211  0.4391063  0.4390462
 0.4390261  0.43902004 0.4390375  0.43902853 0.43900803 0.4389989
 0.4389537  0.43881422 0.43866012 0.4385792  0.43857646 0.43852603
 0.4384104  0.43846458 0.43855205 0.43856886 0.43851757 0.43843392
 0.43834415 0.4382312  0.43809244 0.43796447 0.43784487 0.43776983
 0.43776882 0.43776974 0.43777525 0.43777978 0.43773568 0.43770185
 0.43764815 0.4375133  0.4374319  0.43742552 0.4374333  0.43742043
 0.43742102 0.437469   0.43752253 0.4374969  0.4373821  0.43732584
 0.43727696 0.4371788  0.4371401  0.43699443 0.43683422 0.4367634
 0.43668917 0.43663234 0.43658796 0.43654898 0.43647757 0.43633282
 0.43621063 0.4361356  0.43607432 0.43604064 0.43607798 0.43608615
 0.43607575 0.4361688  0.4362759  0.43626285 0.43624172 0.43615702
 0.43607336 0.43600786 0.4358777  0.43580568 0.43568632 0.4356201
 0.43562064 0.43558738 0.43556476 0.43556285 0.43555295 0.43550354
 0.43550205 0.43539962 0.43533733 0.4353574  0.4353804  0.43534368
 0.43537855 0.4355067  0.43555987 0.43555844 0.43549225 0.43544504
 0.43539336 0.43528906 0.43516615 0.43505397 0.43498152 0.43494254
 0.43492472 0.43490848 0.43495196 0.43493164 0.43490946 0.43492207
 0.43488982 0.43479803 0.43471235 0.43477276 0.43482077 0.43487266
 0.4350797  0.4352075  0.4352528  0.4352509  0.43523374 0.4351725
 0.4351311  0.43502998 0.4349441  0.4348098  0.43472484 0.43468004
 0.434648   0.43465862 0.4346455  0.4346838  0.4346663  0.43466967
 0.43466705 0.43466866 0.43469608 0.43472528 0.43475714 0.43471062
 0.43469423 0.43475577 0.4348344  0.4348288  0.4348287  0.43477297
 0.43470877 0.43464923 0.43453163 0.43447348 0.4343678  0.43433672
 0.43431845 0.4343426  0.43436202 0.43439424 0.43442744 0.4344212
 0.43446556 0.43432787 0.4342798  0.43424064 0.4342483  0.4341257
 0.43379635 0.43376014 0.4337924  0.43372497 0.4336103  0.4335239
 0.4333744  0.43326    0.43309128 0.4329531  0.43287238 0.43277323
 0.43274775 0.43267334 0.43271378 0.43271777 0.43270862 0.43268356
 0.4326571  0.43248028 0.43231508 0.43232659 0.43231046 0.43229723
 0.43220633 0.43226555 0.43231356 0.43228516 0.43214354 0.43208605
 0.43200824 0.43186492 0.43177965 0.43164513 0.42947856 0.4314643
 0.42729917 0.4314292  0.42731306 0.43143097 0.42733902 0.42727095
 0.42732924 0.42715037 0.42715108 0.42715442 0.42705885 0.4270972 ]
