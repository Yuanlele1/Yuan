Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=258, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_720_j336_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_720_j336_H8_FITS_custom_ftM_sl720_ll48_pl336_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17357
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=258, out_features=378, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4007066112.0
params:  97902.0
Trainable parameters:  97902
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4603653
	speed: 0.6765s/iter; left time: 9065.9733s
Epoch: 1 cost time: 91.57023191452026
Epoch: 1, Steps: 135 | Train Loss: 0.6260243 Vali Loss: 0.3151202 Test Loss: 0.3783557
Validation loss decreased (inf --> 0.315120).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2553878
	speed: 1.3990s/iter; left time: 18559.5783s
Epoch: 2 cost time: 75.5783281326294
Epoch: 2, Steps: 135 | Train Loss: 0.2940996 Vali Loss: 0.1865802 Test Loss: 0.2269204
Validation loss decreased (0.315120 --> 0.186580).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1784789
	speed: 1.4972s/iter; left time: 19659.9894s
Epoch: 3 cost time: 106.53590798377991
Epoch: 3, Steps: 135 | Train Loss: 0.2061014 Vali Loss: 0.1528056 Test Loss: 0.1844499
Validation loss decreased (0.186580 --> 0.152806).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1688544
	speed: 1.7781s/iter; left time: 23107.8280s
Epoch: 4 cost time: 91.2033269405365
Epoch: 4, Steps: 135 | Train Loss: 0.1834608 Vali Loss: 0.1458583 Test Loss: 0.1741366
Validation loss decreased (0.152806 --> 0.145858).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1780663
	speed: 1.3352s/iter; left time: 17172.2115s
Epoch: 5 cost time: 79.85910153388977
Epoch: 5, Steps: 135 | Train Loss: 0.1780673 Vali Loss: 0.1442514 Test Loss: 0.1715645
Validation loss decreased (0.145858 --> 0.144251).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1695435
	speed: 1.4384s/iter; left time: 18305.1147s
Epoch: 6 cost time: 83.18551898002625
Epoch: 6, Steps: 135 | Train Loss: 0.1766884 Vali Loss: 0.1440717 Test Loss: 0.1707569
Validation loss decreased (0.144251 --> 0.144072).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1860803
	speed: 1.5062s/iter; left time: 18964.5514s
Epoch: 7 cost time: 96.19596433639526
Epoch: 7, Steps: 135 | Train Loss: 0.1760417 Vali Loss: 0.1439626 Test Loss: 0.1703778
Validation loss decreased (0.144072 --> 0.143963).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1673902
	speed: 1.8817s/iter; left time: 23438.2554s
Epoch: 8 cost time: 117.92852187156677
Epoch: 8, Steps: 135 | Train Loss: 0.1756445 Vali Loss: 0.1436723 Test Loss: 0.1701482
Validation loss decreased (0.143963 --> 0.143672).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1773447
	speed: 2.3621s/iter; left time: 29103.7015s
Epoch: 9 cost time: 180.86585402488708
Epoch: 9, Steps: 135 | Train Loss: 0.1754540 Vali Loss: 0.1435834 Test Loss: 0.1700119
Validation loss decreased (0.143672 --> 0.143583).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1738093
	speed: 2.6956s/iter; left time: 32848.7433s
Epoch: 10 cost time: 139.92436957359314
Epoch: 10, Steps: 135 | Train Loss: 0.1751007 Vali Loss: 0.1436321 Test Loss: 0.1698693
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1743086
	speed: 2.2736s/iter; left time: 27398.7247s
Epoch: 11 cost time: 180.31477904319763
Epoch: 11, Steps: 135 | Train Loss: 0.1751294 Vali Loss: 0.1435347 Test Loss: 0.1697569
Validation loss decreased (0.143583 --> 0.143535).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1679046
	speed: 2.7172s/iter; left time: 32378.5583s
Epoch: 12 cost time: 100.07999777793884
Epoch: 12, Steps: 135 | Train Loss: 0.1749530 Vali Loss: 0.1433548 Test Loss: 0.1697273
Validation loss decreased (0.143535 --> 0.143355).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1800750
	speed: 1.6043s/iter; left time: 18900.0034s
Epoch: 13 cost time: 100.8297860622406
Epoch: 13, Steps: 135 | Train Loss: 0.1748647 Vali Loss: 0.1434869 Test Loss: 0.1697057
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1695877
	speed: 1.9051s/iter; left time: 22186.8992s
Epoch: 14 cost time: 129.44759321212769
Epoch: 14, Steps: 135 | Train Loss: 0.1747768 Vali Loss: 0.1434997 Test Loss: 0.1696162
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1637894
	speed: 1.7337s/iter; left time: 19956.0991s
Epoch: 15 cost time: 108.57839298248291
Epoch: 15, Steps: 135 | Train Loss: 0.1746539 Vali Loss: 0.1435716 Test Loss: 0.1695808
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1653073
	speed: 3.1589s/iter; left time: 35935.1780s
Epoch: 16 cost time: 183.05758380889893
Epoch: 16, Steps: 135 | Train Loss: 0.1746345 Vali Loss: 0.1432993 Test Loss: 0.1695551
Validation loss decreased (0.143355 --> 0.143299).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1731224
	speed: 1.7257s/iter; left time: 19398.2071s
Epoch: 17 cost time: 107.32814359664917
Epoch: 17, Steps: 135 | Train Loss: 0.1745923 Vali Loss: 0.1432756 Test Loss: 0.1695398
Validation loss decreased (0.143299 --> 0.143276).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1642740
	speed: 1.4621s/iter; left time: 16237.7033s
Epoch: 18 cost time: 92.54505038261414
Epoch: 18, Steps: 135 | Train Loss: 0.1744994 Vali Loss: 0.1433951 Test Loss: 0.1695072
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1950141
	speed: 2.7606s/iter; left time: 30286.9649s
Epoch: 19 cost time: 212.21194171905518
Epoch: 19, Steps: 135 | Train Loss: 0.1745234 Vali Loss: 0.1436514 Test Loss: 0.1695095
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1763012
	speed: 3.4564s/iter; left time: 37453.1794s
Epoch: 20 cost time: 212.3105742931366
Epoch: 20, Steps: 135 | Train Loss: 0.1744732 Vali Loss: 0.1432057 Test Loss: 0.1694530
Validation loss decreased (0.143276 --> 0.143206).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1754218
	speed: 3.9086s/iter; left time: 41825.6013s
Epoch: 21 cost time: 244.28994989395142
Epoch: 21, Steps: 135 | Train Loss: 0.1744880 Vali Loss: 0.1433112 Test Loss: 0.1694376
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1750936
	speed: 3.1486s/iter; left time: 33268.0897s
Epoch: 22 cost time: 169.12188124656677
Epoch: 22, Steps: 135 | Train Loss: 0.1744003 Vali Loss: 0.1430029 Test Loss: 0.1694287
Validation loss decreased (0.143206 --> 0.143003).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1714434
	speed: 3.1435s/iter; left time: 32789.3909s
Epoch: 23 cost time: 185.41058468818665
Epoch: 23, Steps: 135 | Train Loss: 0.1743254 Vali Loss: 0.1434482 Test Loss: 0.1694232
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1681245
	speed: 1.9695s/iter; left time: 20277.5313s
Epoch: 24 cost time: 112.37587976455688
Epoch: 24, Steps: 135 | Train Loss: 0.1744227 Vali Loss: 0.1432738 Test Loss: 0.1694296
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1686174
	speed: 1.8450s/iter; left time: 18747.3042s
Epoch: 25 cost time: 104.7008605003357
Epoch: 25, Steps: 135 | Train Loss: 0.1742795 Vali Loss: 0.1432312 Test Loss: 0.1694248
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1643581
	speed: 2.6006s/iter; left time: 26074.0900s
Epoch: 26 cost time: 166.32966685295105
Epoch: 26, Steps: 135 | Train Loss: 0.1742871 Vali Loss: 0.1435740 Test Loss: 0.1694058
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1730317
	speed: 2.8217s/iter; left time: 27909.4275s
Epoch: 27 cost time: 147.29903316497803
Epoch: 27, Steps: 135 | Train Loss: 0.1742886 Vali Loss: 0.1430799 Test Loss: 0.1693980
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1790357
	speed: 1.6820s/iter; left time: 16409.8793s
Epoch: 28 cost time: 112.78239703178406
Epoch: 28, Steps: 135 | Train Loss: 0.1743495 Vali Loss: 0.1433542 Test Loss: 0.1693634
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1691490
	speed: 3.0077s/iter; left time: 28937.3718s
Epoch: 29 cost time: 196.89438128471375
Epoch: 29, Steps: 135 | Train Loss: 0.1742765 Vali Loss: 0.1432147 Test Loss: 0.1693505
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1834118
	speed: 2.8878s/iter; left time: 27393.8148s
Epoch: 30 cost time: 156.99131441116333
Epoch: 30, Steps: 135 | Train Loss: 0.1742763 Vali Loss: 0.1432198 Test Loss: 0.1693404
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1778577
	speed: 2.6237s/iter; left time: 24534.0050s
Epoch: 31 cost time: 173.75434947013855
Epoch: 31, Steps: 135 | Train Loss: 0.1741744 Vali Loss: 0.1430703 Test Loss: 0.1693488
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1746185
	speed: 2.1198s/iter; left time: 19535.7870s
Epoch: 32 cost time: 109.20938754081726
Epoch: 32, Steps: 135 | Train Loss: 0.1742322 Vali Loss: 0.1430221 Test Loss: 0.1693361
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1760811
	speed: 2.0085s/iter; left time: 18238.8949s
Epoch: 33 cost time: 123.67677354812622
Epoch: 33, Steps: 135 | Train Loss: 0.1742228 Vali Loss: 0.1430862 Test Loss: 0.1693277
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1743445
	speed: 1.7843s/iter; left time: 15962.2624s
Epoch: 34 cost time: 108.91583371162415
Epoch: 34, Steps: 135 | Train Loss: 0.1742360 Vali Loss: 0.1432350 Test Loss: 0.1693677
EarlyStopping counter: 12 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1638173
	speed: 1.8937s/iter; left time: 16684.9884s
Epoch: 35 cost time: 121.2261803150177
Epoch: 35, Steps: 135 | Train Loss: 0.1742104 Vali Loss: 0.1429663 Test Loss: 0.1693414
Validation loss decreased (0.143003 --> 0.142966).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1855868
	speed: 2.1839s/iter; left time: 18947.3693s
Epoch: 36 cost time: 127.56712293624878
Epoch: 36, Steps: 135 | Train Loss: 0.1741131 Vali Loss: 0.1430363 Test Loss: 0.1693211
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1811038
	speed: 2.1529s/iter; left time: 18387.7074s
Epoch: 37 cost time: 129.89550805091858
Epoch: 37, Steps: 135 | Train Loss: 0.1741536 Vali Loss: 0.1430238 Test Loss: 0.1693407
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1737183
	speed: 1.7221s/iter; left time: 14476.1980s
Epoch: 38 cost time: 100.81789302825928
Epoch: 38, Steps: 135 | Train Loss: 0.1741549 Vali Loss: 0.1430821 Test Loss: 0.1693129
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1682975
	speed: 1.7793s/iter; left time: 14716.8844s
Epoch: 39 cost time: 108.8779685497284
Epoch: 39, Steps: 135 | Train Loss: 0.1741692 Vali Loss: 0.1433168 Test Loss: 0.1693266
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1776502
	speed: 2.0524s/iter; left time: 16698.2397s
Epoch: 40 cost time: 117.3441870212555
Epoch: 40, Steps: 135 | Train Loss: 0.1740845 Vali Loss: 0.1434620 Test Loss: 0.1693171
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1773209
	speed: 1.7987s/iter; left time: 14391.1845s
Epoch: 41 cost time: 114.64902687072754
Epoch: 41, Steps: 135 | Train Loss: 0.1741360 Vali Loss: 0.1434232 Test Loss: 0.1692994
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1653803
	speed: 1.7418s/iter; left time: 13701.0770s
Epoch: 42 cost time: 106.4268159866333
Epoch: 42, Steps: 135 | Train Loss: 0.1741334 Vali Loss: 0.1429500 Test Loss: 0.1693081
Validation loss decreased (0.142966 --> 0.142950).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1679304
	speed: 2.3926s/iter; left time: 18497.4818s
Epoch: 43 cost time: 157.14529514312744
Epoch: 43, Steps: 135 | Train Loss: 0.1740474 Vali Loss: 0.1432970 Test Loss: 0.1693109
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1724031
	speed: 2.1365s/iter; left time: 16229.2050s
Epoch: 44 cost time: 118.20596981048584
Epoch: 44, Steps: 135 | Train Loss: 0.1741720 Vali Loss: 0.1431650 Test Loss: 0.1693147
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1633620
	speed: 2.2278s/iter; left time: 16621.4510s
Epoch: 45 cost time: 134.0237853527069
Epoch: 45, Steps: 135 | Train Loss: 0.1740767 Vali Loss: 0.1429465 Test Loss: 0.1693169
Validation loss decreased (0.142950 --> 0.142947).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1602909
	speed: 2.2357s/iter; left time: 16378.9933s
Epoch: 46 cost time: 128.75519561767578
Epoch: 46, Steps: 135 | Train Loss: 0.1741602 Vali Loss: 0.1433205 Test Loss: 0.1693021
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1684373
	speed: 1.9902s/iter; left time: 14311.8438s
Epoch: 47 cost time: 123.16637945175171
Epoch: 47, Steps: 135 | Train Loss: 0.1740844 Vali Loss: 0.1430680 Test Loss: 0.1693036
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1865560
	speed: 1.9880s/iter; left time: 14027.4169s
Epoch: 48 cost time: 123.48946714401245
Epoch: 48, Steps: 135 | Train Loss: 0.1740651 Vali Loss: 0.1429348 Test Loss: 0.1693080
Validation loss decreased (0.142947 --> 0.142935).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1626394
	speed: 1.9533s/iter; left time: 13518.9298s
Epoch: 49 cost time: 114.66967630386353
Epoch: 49, Steps: 135 | Train Loss: 0.1740018 Vali Loss: 0.1432142 Test Loss: 0.1692908
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1773111
	speed: 1.9240s/iter; left time: 13056.4036s
Epoch: 50 cost time: 121.97332835197449
Epoch: 50, Steps: 135 | Train Loss: 0.1741082 Vali Loss: 0.1432103 Test Loss: 0.1692933
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1753912
	speed: 1.8727s/iter; left time: 12455.5703s
Epoch: 51 cost time: 115.30334997177124
Epoch: 51, Steps: 135 | Train Loss: 0.1741221 Vali Loss: 0.1427609 Test Loss: 0.1692943
Validation loss decreased (0.142935 --> 0.142761).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1604073
	speed: 1.8042s/iter; left time: 11755.8906s
Epoch: 52 cost time: 108.76020908355713
Epoch: 52, Steps: 135 | Train Loss: 0.1740578 Vali Loss: 0.1432903 Test Loss: 0.1693012
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1587385
	speed: 1.8358s/iter; left time: 11714.0140s
Epoch: 53 cost time: 118.3202018737793
Epoch: 53, Steps: 135 | Train Loss: 0.1739923 Vali Loss: 0.1428852 Test Loss: 0.1692869
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1693425
	speed: 1.9181s/iter; left time: 11980.5990s
Epoch: 54 cost time: 113.25664949417114
Epoch: 54, Steps: 135 | Train Loss: 0.1740067 Vali Loss: 0.1431013 Test Loss: 0.1692896
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1753260
	speed: 1.8370s/iter; left time: 11225.8525s
Epoch: 55 cost time: 111.5303053855896
Epoch: 55, Steps: 135 | Train Loss: 0.1740982 Vali Loss: 0.1428588 Test Loss: 0.1692959
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1672679
	speed: 1.7626s/iter; left time: 10533.0299s
Epoch: 56 cost time: 112.19662880897522
Epoch: 56, Steps: 135 | Train Loss: 0.1740260 Vali Loss: 0.1429372 Test Loss: 0.1692925
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.1682245
	speed: 1.8955s/iter; left time: 11071.5667s
Epoch: 57 cost time: 117.55484199523926
Epoch: 57, Steps: 135 | Train Loss: 0.1740674 Vali Loss: 0.1430390 Test Loss: 0.1692854
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1647416
	speed: 1.7919s/iter; left time: 10224.5852s
Epoch: 58 cost time: 109.88845705986023
Epoch: 58, Steps: 135 | Train Loss: 0.1740763 Vali Loss: 0.1430071 Test Loss: 0.1692870
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1679353
	speed: 1.8178s/iter; left time: 10126.8156s
Epoch: 59 cost time: 110.30775928497314
Epoch: 59, Steps: 135 | Train Loss: 0.1740851 Vali Loss: 0.1432982 Test Loss: 0.1692789
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1675964
	speed: 1.8423s/iter; left time: 10014.8744s
Epoch: 60 cost time: 114.06179189682007
Epoch: 60, Steps: 135 | Train Loss: 0.1740886 Vali Loss: 0.1428049 Test Loss: 0.1692794
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1748524
	speed: 1.7359s/iter; left time: 9201.8144s
Epoch: 61 cost time: 109.31685018539429
Epoch: 61, Steps: 135 | Train Loss: 0.1740733 Vali Loss: 0.1427795 Test Loss: 0.1692878
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1638541
	speed: 1.8315s/iter; left time: 9461.6451s
Epoch: 62 cost time: 108.17468738555908
Epoch: 62, Steps: 135 | Train Loss: 0.1740602 Vali Loss: 0.1428018 Test Loss: 0.1692802
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1755256
	speed: 1.7369s/iter; left time: 8738.2818s
Epoch: 63 cost time: 105.32201743125916
Epoch: 63, Steps: 135 | Train Loss: 0.1740142 Vali Loss: 0.1433623 Test Loss: 0.1692773
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1603177
	speed: 1.8083s/iter; left time: 8853.6607s
Epoch: 64 cost time: 113.98491287231445
Epoch: 64, Steps: 135 | Train Loss: 0.1740352 Vali Loss: 0.1432593 Test Loss: 0.1692748
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.1817773
	speed: 1.7559s/iter; left time: 8360.0394s
Epoch: 65 cost time: 108.49425005912781
Epoch: 65, Steps: 135 | Train Loss: 0.1741111 Vali Loss: 0.1430146 Test Loss: 0.1692840
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.1813024
	speed: 2.1446s/iter; left time: 9920.9186s
Epoch: 66 cost time: 141.29583048820496
Epoch: 66, Steps: 135 | Train Loss: 0.1740678 Vali Loss: 0.1431139 Test Loss: 0.1692699
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.1669427
	speed: 1.8168s/iter; left time: 8159.3342s
Epoch: 67 cost time: 121.00207543373108
Epoch: 67, Steps: 135 | Train Loss: 0.1739859 Vali Loss: 0.1433880 Test Loss: 0.1692705
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.1750260
	speed: 2.4099s/iter; left time: 10497.6062s
Epoch: 68 cost time: 157.93508315086365
Epoch: 68, Steps: 135 | Train Loss: 0.1739746 Vali Loss: 0.1431382 Test Loss: 0.1692743
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.1664153
	speed: 2.0767s/iter; left time: 8765.8264s
Epoch: 69 cost time: 106.86425161361694
Epoch: 69, Steps: 135 | Train Loss: 0.1740249 Vali Loss: 0.1431762 Test Loss: 0.1692737
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.1652841
	speed: 1.7819s/iter; left time: 7280.8194s
Epoch: 70 cost time: 110.12858557701111
Epoch: 70, Steps: 135 | Train Loss: 0.1740704 Vali Loss: 0.1429252 Test Loss: 0.1692736
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.1638136
	speed: 1.7211s/iter; left time: 6800.1075s
Epoch: 71 cost time: 105.92361807823181
Epoch: 71, Steps: 135 | Train Loss: 0.1740737 Vali Loss: 0.1429627 Test Loss: 0.1692742
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_720_j336_H8_FITS_custom_ftM_sl720_ll48_pl336_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4925
mse:0.1670873910188675, mae:0.26378026604652405, rse:0.40683016180992126, corr:[0.45977157 0.46086332 0.46251377 0.46256155 0.46357337 0.46336487
 0.46353254 0.46360746 0.46319693 0.4631969  0.4630329  0.46287486
 0.4628934  0.4628533  0.46288985 0.46297717 0.4630415  0.4630153
 0.46300092 0.46301547 0.4628288  0.4627828  0.46300143 0.46314248
 0.4633255  0.46366024 0.46366698 0.46364588 0.4636619  0.46343517
 0.46325454 0.4632014  0.46303207 0.4629365  0.46289295 0.46283263
 0.46284136 0.46287236 0.46289477 0.4629138  0.46294793 0.462945
 0.46284485 0.46273354 0.46263558 0.46250877 0.46255276 0.46267253
 0.4626746  0.4628607  0.4630221  0.46289444 0.4627817  0.4627589
 0.46265498 0.46259245 0.46253482 0.46244255 0.46243578 0.46245906
 0.46244296 0.46244162 0.46248472 0.46250153 0.46246427 0.46246353
 0.46240154 0.4621667  0.46199661 0.46190473 0.4618546  0.4619697
 0.46206215 0.4620435  0.46208397 0.46211725 0.46196827 0.46188983
 0.4619005  0.46180004 0.46171987 0.4616912  0.4616595  0.4616965
 0.46170983 0.46163887 0.46164712 0.46170455 0.46165657 0.46157128
 0.4616081  0.4616159  0.46154293 0.46157813 0.4616405  0.4616644
 0.46174556 0.46183494 0.46181393 0.4618025  0.46177337 0.4616927
 0.46165144 0.4616129  0.4615175  0.46150488 0.46151856 0.461472
 0.46142694 0.4614283  0.4614299  0.46141684 0.46142823 0.46141386
 0.46137178 0.4612952  0.46120426 0.46116775 0.4612563  0.4614251
 0.46156752 0.46166325 0.46171424 0.46168703 0.4616584  0.4616709
 0.46162468 0.46158636 0.4615789  0.46151987 0.4614676  0.46146014
 0.4613923  0.4613388  0.4614153  0.4614475  0.46140814 0.46143764
 0.46142265 0.46119675 0.4610367  0.46096456 0.46081734 0.4608058
 0.46089914 0.46094978 0.46100065 0.4610618  0.46103963 0.4610061
 0.46099803 0.46097142 0.4609253  0.4609005  0.46088138 0.46085677
 0.46084765 0.46081793 0.46079576 0.46085498 0.46092647 0.4609023
 0.46088892 0.46075112 0.46055347 0.4604897  0.4604631  0.4603892
 0.46034682 0.46041638 0.46041587 0.46033633 0.46023604 0.4601404
 0.46003744 0.4599408  0.45985568 0.45976368 0.4596373  0.45953786
 0.45942846 0.45933807 0.45929748 0.45921558 0.45911613 0.45901465
 0.45887253 0.4587273  0.45862162 0.4585094  0.45845926 0.45852143
 0.45861265 0.45875442 0.45885688 0.45890495 0.4588381  0.45874202
 0.45868215 0.45863396 0.45856082 0.45844448 0.45830312 0.45824465
 0.45823276 0.45815727 0.4581162  0.4581035  0.4580875  0.45809603
 0.4580734  0.45792812 0.4578178  0.4577948  0.45779428 0.4579027
 0.45802456 0.45815086 0.45829967 0.45838657 0.45833674 0.45827544
 0.4582538  0.45821866 0.45817298 0.4581038  0.45801973 0.4579386
 0.45787224 0.45779473 0.45775217 0.4577942  0.45784602 0.45778567
 0.45770606 0.45762107 0.45747247 0.45739597 0.45746088 0.4575501
 0.45767054 0.45782855 0.4579004  0.45796606 0.45793697 0.45782447
 0.45777878 0.45773357 0.45763692 0.45754004 0.45745596 0.4573726
 0.45729414 0.45728725 0.4573073  0.45725727 0.45723957 0.45724517
 0.45719954 0.45723173 0.45733047 0.457325   0.4573772  0.45755005
 0.45761925 0.45770687 0.45779678 0.4577772  0.45774192 0.45771942
 0.45759535 0.45746425 0.45734778 0.45720667 0.45712554 0.45710123
 0.45701823 0.4569247  0.45702597 0.45711398 0.45704874 0.45707297
 0.45714504 0.4570302  0.45703402 0.45716727 0.45717627 0.45734152
 0.4575927  0.4576136  0.45765045 0.4576942  0.45760918 0.45754844
 0.457447   0.45724636 0.4570824  0.45694467 0.45676914 0.4566308
 0.4566476  0.45669094 0.45662108 0.45671558 0.45689687 0.45680264
 0.4567572  0.45672637 0.45644572 0.45635816 0.45644855 0.45641074
 0.45649123 0.45658484 0.45651197 0.45652273 0.45638692 0.45618445
 0.45613497 0.4559608  0.45581618 0.45580295 0.45579487 0.455824
 0.4558317  0.45604545 0.45618016 0.4560025  0.45625472 0.45609134
 0.45557874 0.45586887 0.45528778 0.45562407 0.45594943 0.4563447 ]
