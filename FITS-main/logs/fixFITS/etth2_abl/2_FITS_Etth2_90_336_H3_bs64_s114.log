Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=22, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_90_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_90_336_FITS_ETTh2_ftM_sl90_ll48_pl336_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8215
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=22, out_features=104, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2050048.0
params:  2392.0
Trainable parameters:  2392
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.5871686935424805
Epoch: 1, Steps: 64 | Train Loss: 0.8579075 Vali Loss: 0.5128789 Test Loss: 0.6032141
Validation loss decreased (inf --> 0.512879).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.4295454025268555
Epoch: 2, Steps: 64 | Train Loss: 0.7397255 Vali Loss: 0.4696051 Test Loss: 0.5472972
Validation loss decreased (0.512879 --> 0.469605).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.0182363986968994
Epoch: 3, Steps: 64 | Train Loss: 0.6722349 Vali Loss: 0.4463672 Test Loss: 0.5127667
Validation loss decreased (0.469605 --> 0.446367).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.048781394958496
Epoch: 4, Steps: 64 | Train Loss: 0.6302364 Vali Loss: 0.4251458 Test Loss: 0.4901316
Validation loss decreased (0.446367 --> 0.425146).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.6474013328552246
Epoch: 5, Steps: 64 | Train Loss: 0.6020886 Vali Loss: 0.4167587 Test Loss: 0.4747730
Validation loss decreased (0.425146 --> 0.416759).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.110609531402588
Epoch: 6, Steps: 64 | Train Loss: 0.5834789 Vali Loss: 0.4057286 Test Loss: 0.4640425
Validation loss decreased (0.416759 --> 0.405729).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.8811030387878418
Epoch: 7, Steps: 64 | Train Loss: 0.5702900 Vali Loss: 0.3986130 Test Loss: 0.4562301
Validation loss decreased (0.405729 --> 0.398613).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.7881786823272705
Epoch: 8, Steps: 64 | Train Loss: 0.5598787 Vali Loss: 0.3946014 Test Loss: 0.4505258
Validation loss decreased (0.398613 --> 0.394601).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.6055536270141602
Epoch: 9, Steps: 64 | Train Loss: 0.5537370 Vali Loss: 0.3896041 Test Loss: 0.4462402
Validation loss decreased (0.394601 --> 0.389604).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.7649755477905273
Epoch: 10, Steps: 64 | Train Loss: 0.5485946 Vali Loss: 0.3880612 Test Loss: 0.4430572
Validation loss decreased (0.389604 --> 0.388061).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.2095704078674316
Epoch: 11, Steps: 64 | Train Loss: 0.5450319 Vali Loss: 0.3845700 Test Loss: 0.4404818
Validation loss decreased (0.388061 --> 0.384570).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.6790721416473389
Epoch: 12, Steps: 64 | Train Loss: 0.5414021 Vali Loss: 0.3826839 Test Loss: 0.4384312
Validation loss decreased (0.384570 --> 0.382684).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.8931083679199219
Epoch: 13, Steps: 64 | Train Loss: 0.5387935 Vali Loss: 0.3823597 Test Loss: 0.4368407
Validation loss decreased (0.382684 --> 0.382360).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.8975110054016113
Epoch: 14, Steps: 64 | Train Loss: 0.5372901 Vali Loss: 0.3798389 Test Loss: 0.4355344
Validation loss decreased (0.382360 --> 0.379839).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.763366460800171
Epoch: 15, Steps: 64 | Train Loss: 0.5361715 Vali Loss: 0.3808539 Test Loss: 0.4344401
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.6005587577819824
Epoch: 16, Steps: 64 | Train Loss: 0.5345186 Vali Loss: 0.3791662 Test Loss: 0.4334859
Validation loss decreased (0.379839 --> 0.379166).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.7569444179534912
Epoch: 17, Steps: 64 | Train Loss: 0.5334761 Vali Loss: 0.3766830 Test Loss: 0.4326903
Validation loss decreased (0.379166 --> 0.376683).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.704758405685425
Epoch: 18, Steps: 64 | Train Loss: 0.5322947 Vali Loss: 0.3782214 Test Loss: 0.4319795
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.1017327308654785
Epoch: 19, Steps: 64 | Train Loss: 0.5309684 Vali Loss: 0.3757370 Test Loss: 0.4314273
Validation loss decreased (0.376683 --> 0.375737).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.2582859992980957
Epoch: 20, Steps: 64 | Train Loss: 0.5307756 Vali Loss: 0.3750984 Test Loss: 0.4309132
Validation loss decreased (0.375737 --> 0.375098).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.177959680557251
Epoch: 21, Steps: 64 | Train Loss: 0.5290714 Vali Loss: 0.3739550 Test Loss: 0.4303966
Validation loss decreased (0.375098 --> 0.373955).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.7592039108276367
Epoch: 22, Steps: 64 | Train Loss: 0.5292671 Vali Loss: 0.3769954 Test Loss: 0.4300206
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.0259454250335693
Epoch: 23, Steps: 64 | Train Loss: 0.5280239 Vali Loss: 0.3717695 Test Loss: 0.4296416
Validation loss decreased (0.373955 --> 0.371770).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.068110466003418
Epoch: 24, Steps: 64 | Train Loss: 0.5276045 Vali Loss: 0.3741142 Test Loss: 0.4293433
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.7042796611785889
Epoch: 25, Steps: 64 | Train Loss: 0.5277453 Vali Loss: 0.3722091 Test Loss: 0.4290313
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.0462119579315186
Epoch: 26, Steps: 64 | Train Loss: 0.5265429 Vali Loss: 0.3725257 Test Loss: 0.4287925
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.6994848251342773
Epoch: 27, Steps: 64 | Train Loss: 0.5263232 Vali Loss: 0.3739070 Test Loss: 0.4284995
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.8914730548858643
Epoch: 28, Steps: 64 | Train Loss: 0.5267456 Vali Loss: 0.3713044 Test Loss: 0.4282939
Validation loss decreased (0.371770 --> 0.371304).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.966428279876709
Epoch: 29, Steps: 64 | Train Loss: 0.5259265 Vali Loss: 0.3714535 Test Loss: 0.4280600
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.3008439540863037
Epoch: 30, Steps: 64 | Train Loss: 0.5260506 Vali Loss: 0.3709546 Test Loss: 0.4278684
Validation loss decreased (0.371304 --> 0.370955).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.0218398571014404
Epoch: 31, Steps: 64 | Train Loss: 0.5255572 Vali Loss: 0.3743513 Test Loss: 0.4277080
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.7729036808013916
Epoch: 32, Steps: 64 | Train Loss: 0.5252629 Vali Loss: 0.3721421 Test Loss: 0.4275756
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.94307541847229
Epoch: 33, Steps: 64 | Train Loss: 0.5256063 Vali Loss: 0.3719018 Test Loss: 0.4273966
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.8127081394195557
Epoch: 34, Steps: 64 | Train Loss: 0.5243507 Vali Loss: 0.3713175 Test Loss: 0.4272369
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.13682222366333
Epoch: 35, Steps: 64 | Train Loss: 0.5238560 Vali Loss: 0.3707303 Test Loss: 0.4271106
Validation loss decreased (0.370955 --> 0.370730).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.1577253341674805
Epoch: 36, Steps: 64 | Train Loss: 0.5246694 Vali Loss: 0.3714911 Test Loss: 0.4269966
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.0101115703582764
Epoch: 37, Steps: 64 | Train Loss: 0.5244991 Vali Loss: 0.3697425 Test Loss: 0.4268917
Validation loss decreased (0.370730 --> 0.369742).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.8311643600463867
Epoch: 38, Steps: 64 | Train Loss: 0.5244583 Vali Loss: 0.3688581 Test Loss: 0.4267542
Validation loss decreased (0.369742 --> 0.368858).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.9946701526641846
Epoch: 39, Steps: 64 | Train Loss: 0.5230287 Vali Loss: 0.3685390 Test Loss: 0.4266535
Validation loss decreased (0.368858 --> 0.368539).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.2728068828582764
Epoch: 40, Steps: 64 | Train Loss: 0.5243107 Vali Loss: 0.3709552 Test Loss: 0.4265679
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.2451016902923584
Epoch: 41, Steps: 64 | Train Loss: 0.5229625 Vali Loss: 0.3706587 Test Loss: 0.4264828
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.9035003185272217
Epoch: 42, Steps: 64 | Train Loss: 0.5231288 Vali Loss: 0.3722949 Test Loss: 0.4264030
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.138044834136963
Epoch: 43, Steps: 64 | Train Loss: 0.5229093 Vali Loss: 0.3662744 Test Loss: 0.4263013
Validation loss decreased (0.368539 --> 0.366274).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.8050708770751953
Epoch: 44, Steps: 64 | Train Loss: 0.5233787 Vali Loss: 0.3672580 Test Loss: 0.4262369
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.5287103652954102
Epoch: 45, Steps: 64 | Train Loss: 0.5231542 Vali Loss: 0.3677460 Test Loss: 0.4261607
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.1175177097320557
Epoch: 46, Steps: 64 | Train Loss: 0.5233673 Vali Loss: 0.3717811 Test Loss: 0.4261054
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.9323244094848633
Epoch: 47, Steps: 64 | Train Loss: 0.5230651 Vali Loss: 0.3686566 Test Loss: 0.4260479
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.0166056156158447
Epoch: 48, Steps: 64 | Train Loss: 0.5233871 Vali Loss: 0.3710551 Test Loss: 0.4259843
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.1517651081085205
Epoch: 49, Steps: 64 | Train Loss: 0.5227069 Vali Loss: 0.3703611 Test Loss: 0.4259409
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.078260660171509
Epoch: 50, Steps: 64 | Train Loss: 0.5233068 Vali Loss: 0.3722994 Test Loss: 0.4258793
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.1818602085113525
Epoch: 51, Steps: 64 | Train Loss: 0.5214681 Vali Loss: 0.3680569 Test Loss: 0.4258322
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.030674934387207
Epoch: 52, Steps: 64 | Train Loss: 0.5214210 Vali Loss: 0.3711423 Test Loss: 0.4257857
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.2857978343963623
Epoch: 53, Steps: 64 | Train Loss: 0.5229542 Vali Loss: 0.3690203 Test Loss: 0.4257455
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.9378790855407715
Epoch: 54, Steps: 64 | Train Loss: 0.5223188 Vali Loss: 0.3671366 Test Loss: 0.4257025
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.806119680404663
Epoch: 55, Steps: 64 | Train Loss: 0.5233053 Vali Loss: 0.3666419 Test Loss: 0.4256639
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.5637426376342773
Epoch: 56, Steps: 64 | Train Loss: 0.5210965 Vali Loss: 0.3671465 Test Loss: 0.4256283
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.7403180599212646
Epoch: 57, Steps: 64 | Train Loss: 0.5231647 Vali Loss: 0.3679456 Test Loss: 0.4255936
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.3910281658172607
Epoch: 58, Steps: 64 | Train Loss: 0.5228916 Vali Loss: 0.3689139 Test Loss: 0.4255545
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.2415432929992676
Epoch: 59, Steps: 64 | Train Loss: 0.5218522 Vali Loss: 0.3693495 Test Loss: 0.4255267
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.1559300422668457
Epoch: 60, Steps: 64 | Train Loss: 0.5225982 Vali Loss: 0.3684517 Test Loss: 0.4254955
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.7217133045196533
Epoch: 61, Steps: 64 | Train Loss: 0.5220910 Vali Loss: 0.3669647 Test Loss: 0.4254705
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.844144582748413
Epoch: 62, Steps: 64 | Train Loss: 0.5219646 Vali Loss: 0.3688827 Test Loss: 0.4254443
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.482466220855713
Epoch: 63, Steps: 64 | Train Loss: 0.5221526 Vali Loss: 0.3683808 Test Loss: 0.4254148
EarlyStopping counter: 20 out of 20
Early stopping
train 8215
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=22, out_features=104, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2050048.0
params:  2392.0
Trainable parameters:  2392
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.069394588470459
Epoch: 1, Steps: 64 | Train Loss: 0.6551478 Vali Loss: 0.3677384 Test Loss: 0.4247019
Validation loss decreased (inf --> 0.367738).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.837045669555664
Epoch: 2, Steps: 64 | Train Loss: 0.6540027 Vali Loss: 0.3666079 Test Loss: 0.4238513
Validation loss decreased (0.367738 --> 0.366608).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.8302624225616455
Epoch: 3, Steps: 64 | Train Loss: 0.6535515 Vali Loss: 0.3668279 Test Loss: 0.4232922
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.8651087284088135
Epoch: 4, Steps: 64 | Train Loss: 0.6503259 Vali Loss: 0.3657705 Test Loss: 0.4228807
Validation loss decreased (0.366608 --> 0.365770).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.7674846649169922
Epoch: 5, Steps: 64 | Train Loss: 0.6510565 Vali Loss: 0.3646649 Test Loss: 0.4226542
Validation loss decreased (0.365770 --> 0.364665).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.777616262435913
Epoch: 6, Steps: 64 | Train Loss: 0.6508242 Vali Loss: 0.3662533 Test Loss: 0.4223665
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.7189810276031494
Epoch: 7, Steps: 64 | Train Loss: 0.6506846 Vali Loss: 0.3644871 Test Loss: 0.4223108
Validation loss decreased (0.364665 --> 0.364487).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.815669059753418
Epoch: 8, Steps: 64 | Train Loss: 0.6498409 Vali Loss: 0.3655117 Test Loss: 0.4220688
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.7560780048370361
Epoch: 9, Steps: 64 | Train Loss: 0.6497472 Vali Loss: 0.3645326 Test Loss: 0.4220272
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.328287124633789
Epoch: 10, Steps: 64 | Train Loss: 0.6488936 Vali Loss: 0.3625000 Test Loss: 0.4219193
Validation loss decreased (0.364487 --> 0.362500).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.8687827587127686
Epoch: 11, Steps: 64 | Train Loss: 0.6489383 Vali Loss: 0.3662279 Test Loss: 0.4218534
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.8637018203735352
Epoch: 12, Steps: 64 | Train Loss: 0.6489334 Vali Loss: 0.3664997 Test Loss: 0.4217693
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.2565786838531494
Epoch: 13, Steps: 64 | Train Loss: 0.6487954 Vali Loss: 0.3648143 Test Loss: 0.4217041
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.8911616802215576
Epoch: 14, Steps: 64 | Train Loss: 0.6480402 Vali Loss: 0.3634791 Test Loss: 0.4216766
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.6135854721069336
Epoch: 15, Steps: 64 | Train Loss: 0.6483841 Vali Loss: 0.3627721 Test Loss: 0.4216278
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.0785610675811768
Epoch: 16, Steps: 64 | Train Loss: 0.6488152 Vali Loss: 0.3623562 Test Loss: 0.4215314
Validation loss decreased (0.362500 --> 0.362356).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.1340973377227783
Epoch: 17, Steps: 64 | Train Loss: 0.6479859 Vali Loss: 0.3637331 Test Loss: 0.4215368
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.6963932514190674
Epoch: 18, Steps: 64 | Train Loss: 0.6475188 Vali Loss: 0.3639751 Test Loss: 0.4215069
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.0740323066711426
Epoch: 19, Steps: 64 | Train Loss: 0.6470394 Vali Loss: 0.3619002 Test Loss: 0.4214668
Validation loss decreased (0.362356 --> 0.361900).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.071596145629883
Epoch: 20, Steps: 64 | Train Loss: 0.6488551 Vali Loss: 0.3620812 Test Loss: 0.4214320
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.841597557067871
Epoch: 21, Steps: 64 | Train Loss: 0.6479467 Vali Loss: 0.3597510 Test Loss: 0.4214171
Validation loss decreased (0.361900 --> 0.359751).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.6704227924346924
Epoch: 22, Steps: 64 | Train Loss: 0.6478773 Vali Loss: 0.3621734 Test Loss: 0.4214074
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.754892110824585
Epoch: 23, Steps: 64 | Train Loss: 0.6484063 Vali Loss: 0.3643321 Test Loss: 0.4213876
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.643303394317627
Epoch: 24, Steps: 64 | Train Loss: 0.6466737 Vali Loss: 0.3618059 Test Loss: 0.4213567
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.6495552062988281
Epoch: 25, Steps: 64 | Train Loss: 0.6476065 Vali Loss: 0.3626796 Test Loss: 0.4213173
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.9450178146362305
Epoch: 26, Steps: 64 | Train Loss: 0.6468717 Vali Loss: 0.3586052 Test Loss: 0.4213665
Validation loss decreased (0.359751 --> 0.358605).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.7323074340820312
Epoch: 27, Steps: 64 | Train Loss: 0.6463685 Vali Loss: 0.3639999 Test Loss: 0.4213564
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.1638548374176025
Epoch: 28, Steps: 64 | Train Loss: 0.6479144 Vali Loss: 0.3645269 Test Loss: 0.4213320
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.6781373023986816
Epoch: 29, Steps: 64 | Train Loss: 0.6469182 Vali Loss: 0.3649692 Test Loss: 0.4212839
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.9328029155731201
Epoch: 30, Steps: 64 | Train Loss: 0.6473444 Vali Loss: 0.3647421 Test Loss: 0.4212777
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.155435562133789
Epoch: 31, Steps: 64 | Train Loss: 0.6459082 Vali Loss: 0.3618872 Test Loss: 0.4212676
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.9592399597167969
Epoch: 32, Steps: 64 | Train Loss: 0.6467699 Vali Loss: 0.3655275 Test Loss: 0.4212593
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.99812650680542
Epoch: 33, Steps: 64 | Train Loss: 0.6470204 Vali Loss: 0.3615948 Test Loss: 0.4212135
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.089235782623291
Epoch: 34, Steps: 64 | Train Loss: 0.6462164 Vali Loss: 0.3628023 Test Loss: 0.4212132
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.1184113025665283
Epoch: 35, Steps: 64 | Train Loss: 0.6471959 Vali Loss: 0.3619901 Test Loss: 0.4212325
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.8227035999298096
Epoch: 36, Steps: 64 | Train Loss: 0.6450014 Vali Loss: 0.3652711 Test Loss: 0.4212237
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.2262487411499023
Epoch: 37, Steps: 64 | Train Loss: 0.6461995 Vali Loss: 0.3643340 Test Loss: 0.4212197
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.4177205562591553
Epoch: 38, Steps: 64 | Train Loss: 0.6471635 Vali Loss: 0.3619403 Test Loss: 0.4212122
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.4074037075042725
Epoch: 39, Steps: 64 | Train Loss: 0.6463148 Vali Loss: 0.3643729 Test Loss: 0.4211971
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.7701530456542969
Epoch: 40, Steps: 64 | Train Loss: 0.6473275 Vali Loss: 0.3626333 Test Loss: 0.4211911
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.1966280937194824
Epoch: 41, Steps: 64 | Train Loss: 0.6474835 Vali Loss: 0.3637935 Test Loss: 0.4212187
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 3.254171371459961
Epoch: 42, Steps: 64 | Train Loss: 0.6471874 Vali Loss: 0.3607488 Test Loss: 0.4211739
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 5.2797532081604
Epoch: 43, Steps: 64 | Train Loss: 0.6462603 Vali Loss: 0.3623966 Test Loss: 0.4211954
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 6.676310062408447
Epoch: 44, Steps: 64 | Train Loss: 0.6463700 Vali Loss: 0.3634383 Test Loss: 0.4211817
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 5.821658372879028
Epoch: 45, Steps: 64 | Train Loss: 0.6473973 Vali Loss: 0.3638787 Test Loss: 0.4211740
EarlyStopping counter: 19 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 5.830734729766846
Epoch: 46, Steps: 64 | Train Loss: 0.6468067 Vali Loss: 0.3655403 Test Loss: 0.4211776
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_90_336_FITS_ETTh2_ftM_sl90_ll48_pl336_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.4166446924209595, mae:0.4251883924007416, rse:0.5160864591598511, corr:[0.26322937 0.2661211  0.2633347  0.26244947 0.26192465 0.26022
 0.2587996  0.25792566 0.2571789  0.25583145 0.254629   0.25330576
 0.25166622 0.25010988 0.24914296 0.24868102 0.24806078 0.24723175
 0.24644692 0.24548692 0.24437128 0.24319932 0.2420241  0.24038216
 0.23756541 0.23529708 0.23346111 0.23226891 0.23116216 0.2299992
 0.22926494 0.22810845 0.22692388 0.22583404 0.22501184 0.22394021
 0.22264616 0.22177045 0.22085282 0.21981002 0.21904452 0.21867105
 0.2183289  0.21727037 0.2161941  0.21538502 0.21421784 0.21183221
 0.20814538 0.20546444 0.20312932 0.20085011 0.19886902 0.19723633
 0.19594766 0.19345884 0.1916086  0.19039613 0.18981634 0.18866308
 0.18712899 0.18672107 0.18671274 0.18644771 0.18597597 0.18579738
 0.18541998 0.18427013 0.18322127 0.1828548  0.18210687 0.18034548
 0.17744786 0.1759154  0.17467767 0.1732693  0.17210315 0.17193218
 0.17216979 0.17096587 0.17010985 0.1699275  0.16996276 0.1692897
 0.16828413 0.16813871 0.16843247 0.16832587 0.16767004 0.16723989
 0.1672281  0.16667375 0.1660895  0.16578464 0.16555844 0.16458677
 0.16210784 0.16002029 0.15860671 0.15754305 0.15644349 0.1556865
 0.15610823 0.15553826 0.15511458 0.15485181 0.15519322 0.15517314
 0.15428545 0.15362279 0.15313087 0.15291227 0.15242839 0.15183952
 0.15156774 0.15098803 0.15027453 0.14903265 0.14728345 0.14535716
 0.142702   0.14040624 0.1384055  0.13745856 0.13649915 0.1355304
 0.13502192 0.13415861 0.13384512 0.13354911 0.13327503 0.13258494
 0.1317917  0.13127524 0.1307411  0.13018739 0.12979576 0.12951054
 0.12903701 0.12812155 0.12768039 0.12726401 0.12581442 0.12327931
 0.11978104 0.1172327  0.1149646  0.11335089 0.11224493 0.11145331
 0.1112045  0.11027887 0.10995432 0.10983663 0.10973124 0.10913426
 0.10849319 0.10848592 0.10851397 0.10844674 0.10828797 0.1081122
 0.10788068 0.10723342 0.10712921 0.1072255  0.10666153 0.10481857
 0.10181357 0.0999689  0.09832489 0.09698569 0.09606145 0.09574966
 0.09616917 0.0957357  0.09563592 0.09567627 0.0959302  0.09548586
 0.09477022 0.0947082  0.09483038 0.09505259 0.09502438 0.09519407
 0.09556488 0.09548739 0.09557344 0.09614499 0.09634341 0.09548734
 0.09351517 0.09268949 0.09217737 0.09166311 0.09147657 0.0917552
 0.09294356 0.09333329 0.09370913 0.09399567 0.09445567 0.09437194
 0.09383611 0.09358536 0.09345207 0.09351311 0.0934496  0.0935923
 0.09379527 0.09377719 0.09383767 0.09379315 0.09337143 0.09190349
 0.08940642 0.08769081 0.08632085 0.08546837 0.08475072 0.08491932
 0.08619821 0.08733034 0.08821625 0.08827128 0.08796198 0.08729003
 0.08685992 0.08674584 0.08650064 0.08633652 0.08657745 0.08714768
 0.08764325 0.08793475 0.08818491 0.08838996 0.08798523 0.08675944
 0.08440908 0.08302803 0.08190069 0.08121884 0.08112503 0.08193043
 0.08379835 0.08466296 0.08545758 0.08607473 0.08644209 0.08619436
 0.08598419 0.08686496 0.08754668 0.08806825 0.08849294 0.08940885
 0.0899101  0.08995531 0.09015945 0.09068494 0.09083381 0.0900704
 0.08854156 0.0880821  0.08809532 0.08807568 0.08807081 0.0890127
 0.09072242 0.09134282 0.09196088 0.09258243 0.09304016 0.09251082
 0.09206092 0.09225319 0.09267914 0.09264283 0.09249154 0.09273299
 0.09318259 0.09309454 0.093147   0.0935153  0.0935829  0.09301988
 0.09166609 0.09098342 0.090493   0.09005301 0.08983275 0.08979261
 0.09027972 0.0901954  0.09089468 0.09193525 0.09253271 0.09196082
 0.09130251 0.09196357 0.09293217 0.0932963  0.09323002 0.09404932
 0.09523141 0.09546653 0.09579302 0.09634203 0.0965597  0.09572978
 0.09386411 0.09344752 0.09332269 0.09314742 0.09282552 0.09337992
 0.09490953 0.09538034 0.09609373 0.09729665 0.09842966 0.09797265
 0.09693304 0.09699968 0.09783904 0.09790368 0.09720749 0.09743227
 0.09838337 0.09791671 0.09698265 0.09753839 0.09902114 0.09819478]
