Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=0, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=196, out_features=222, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  38986752.0
params:  43734.0
Trainable parameters:  43734
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.5447123050689697
Epoch: 1, Steps: 61 | Train Loss: 0.5519803 Vali Loss: 0.3934826 Test Loss: 0.3883989
Validation loss decreased (inf --> 0.393483).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.3841228485107422
Epoch: 2, Steps: 61 | Train Loss: 0.4239087 Vali Loss: 0.3398600 Test Loss: 0.3496014
Validation loss decreased (0.393483 --> 0.339860).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.3769118785858154
Epoch: 3, Steps: 61 | Train Loss: 0.3608664 Vali Loss: 0.3215057 Test Loss: 0.3365227
Validation loss decreased (0.339860 --> 0.321506).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.4234356880187988
Epoch: 4, Steps: 61 | Train Loss: 0.3228644 Vali Loss: 0.3168986 Test Loss: 0.3322966
Validation loss decreased (0.321506 --> 0.316899).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.355715274810791
Epoch: 5, Steps: 61 | Train Loss: 0.2958535 Vali Loss: 0.3134468 Test Loss: 0.3296292
Validation loss decreased (0.316899 --> 0.313447).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.2700238227844238
Epoch: 6, Steps: 61 | Train Loss: 0.2743553 Vali Loss: 0.3102456 Test Loss: 0.3280142
Validation loss decreased (0.313447 --> 0.310246).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.459336757659912
Epoch: 7, Steps: 61 | Train Loss: 0.2570530 Vali Loss: 0.3077917 Test Loss: 0.3261996
Validation loss decreased (0.310246 --> 0.307792).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.387446403503418
Epoch: 8, Steps: 61 | Train Loss: 0.2417466 Vali Loss: 0.3058114 Test Loss: 0.3244205
Validation loss decreased (0.307792 --> 0.305811).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.46091628074646
Epoch: 9, Steps: 61 | Train Loss: 0.2287429 Vali Loss: 0.3023171 Test Loss: 0.3227237
Validation loss decreased (0.305811 --> 0.302317).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.601693630218506
Epoch: 10, Steps: 61 | Train Loss: 0.2173227 Vali Loss: 0.2998021 Test Loss: 0.3207986
Validation loss decreased (0.302317 --> 0.299802).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.389472484588623
Epoch: 11, Steps: 61 | Train Loss: 0.2068674 Vali Loss: 0.2971934 Test Loss: 0.3188727
Validation loss decreased (0.299802 --> 0.297193).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.2805843353271484
Epoch: 12, Steps: 61 | Train Loss: 0.1980021 Vali Loss: 0.2941425 Test Loss: 0.3168963
Validation loss decreased (0.297193 --> 0.294142).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.3518786430358887
Epoch: 13, Steps: 61 | Train Loss: 0.1897737 Vali Loss: 0.2921363 Test Loss: 0.3151725
Validation loss decreased (0.294142 --> 0.292136).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.2959158420562744
Epoch: 14, Steps: 61 | Train Loss: 0.1823999 Vali Loss: 0.2896652 Test Loss: 0.3133029
Validation loss decreased (0.292136 --> 0.289665).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.3504650592803955
Epoch: 15, Steps: 61 | Train Loss: 0.1757859 Vali Loss: 0.2874363 Test Loss: 0.3116947
Validation loss decreased (0.289665 --> 0.287436).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.3133628368377686
Epoch: 16, Steps: 61 | Train Loss: 0.1695442 Vali Loss: 0.2836775 Test Loss: 0.3101744
Validation loss decreased (0.287436 --> 0.283677).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.3045508861541748
Epoch: 17, Steps: 61 | Train Loss: 0.1639959 Vali Loss: 0.2817485 Test Loss: 0.3085977
Validation loss decreased (0.283677 --> 0.281749).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.2986884117126465
Epoch: 18, Steps: 61 | Train Loss: 0.1588988 Vali Loss: 0.2804170 Test Loss: 0.3072749
Validation loss decreased (0.281749 --> 0.280417).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.3380153179168701
Epoch: 19, Steps: 61 | Train Loss: 0.1546092 Vali Loss: 0.2781437 Test Loss: 0.3056791
Validation loss decreased (0.280417 --> 0.278144).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.3782501220703125
Epoch: 20, Steps: 61 | Train Loss: 0.1501363 Vali Loss: 0.2767414 Test Loss: 0.3044976
Validation loss decreased (0.278144 --> 0.276741).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.3713257312774658
Epoch: 21, Steps: 61 | Train Loss: 0.1464128 Vali Loss: 0.2753083 Test Loss: 0.3034845
Validation loss decreased (0.276741 --> 0.275308).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.434098243713379
Epoch: 22, Steps: 61 | Train Loss: 0.1427499 Vali Loss: 0.2725851 Test Loss: 0.3023434
Validation loss decreased (0.275308 --> 0.272585).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.4301185607910156
Epoch: 23, Steps: 61 | Train Loss: 0.1396158 Vali Loss: 0.2710926 Test Loss: 0.3011942
Validation loss decreased (0.272585 --> 0.271093).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.4318549633026123
Epoch: 24, Steps: 61 | Train Loss: 0.1366224 Vali Loss: 0.2695412 Test Loss: 0.3003402
Validation loss decreased (0.271093 --> 0.269541).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.3429243564605713
Epoch: 25, Steps: 61 | Train Loss: 0.1337784 Vali Loss: 0.2695516 Test Loss: 0.2994314
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.3344035148620605
Epoch: 26, Steps: 61 | Train Loss: 0.1311603 Vali Loss: 0.2682586 Test Loss: 0.2985658
Validation loss decreased (0.269541 --> 0.268259).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.3863322734832764
Epoch: 27, Steps: 61 | Train Loss: 0.1287137 Vali Loss: 0.2670416 Test Loss: 0.2977869
Validation loss decreased (0.268259 --> 0.267042).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.3113601207733154
Epoch: 28, Steps: 61 | Train Loss: 0.1264802 Vali Loss: 0.2643517 Test Loss: 0.2970273
Validation loss decreased (0.267042 --> 0.264352).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.4581563472747803
Epoch: 29, Steps: 61 | Train Loss: 0.1245032 Vali Loss: 0.2646340 Test Loss: 0.2963310
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.445589542388916
Epoch: 30, Steps: 61 | Train Loss: 0.1224868 Vali Loss: 0.2633407 Test Loss: 0.2956895
Validation loss decreased (0.264352 --> 0.263341).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.2992894649505615
Epoch: 31, Steps: 61 | Train Loss: 0.1207176 Vali Loss: 0.2616944 Test Loss: 0.2950794
Validation loss decreased (0.263341 --> 0.261694).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.2923994064331055
Epoch: 32, Steps: 61 | Train Loss: 0.1190390 Vali Loss: 0.2614405 Test Loss: 0.2945132
Validation loss decreased (0.261694 --> 0.261441).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.402256965637207
Epoch: 33, Steps: 61 | Train Loss: 0.1175216 Vali Loss: 0.2613405 Test Loss: 0.2939444
Validation loss decreased (0.261441 --> 0.261341).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.4422187805175781
Epoch: 34, Steps: 61 | Train Loss: 0.1160776 Vali Loss: 0.2604760 Test Loss: 0.2934290
Validation loss decreased (0.261341 --> 0.260476).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.3494596481323242
Epoch: 35, Steps: 61 | Train Loss: 0.1146795 Vali Loss: 0.2599387 Test Loss: 0.2929442
Validation loss decreased (0.260476 --> 0.259939).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.3104288578033447
Epoch: 36, Steps: 61 | Train Loss: 0.1134559 Vali Loss: 0.2582429 Test Loss: 0.2925523
Validation loss decreased (0.259939 --> 0.258243).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.3932054042816162
Epoch: 37, Steps: 61 | Train Loss: 0.1121813 Vali Loss: 0.2587701 Test Loss: 0.2920835
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.3694326877593994
Epoch: 38, Steps: 61 | Train Loss: 0.1110742 Vali Loss: 0.2585000 Test Loss: 0.2916816
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.3347477912902832
Epoch: 39, Steps: 61 | Train Loss: 0.1099996 Vali Loss: 0.2572190 Test Loss: 0.2912670
Validation loss decreased (0.258243 --> 0.257219).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.3146018981933594
Epoch: 40, Steps: 61 | Train Loss: 0.1089608 Vali Loss: 0.2566806 Test Loss: 0.2909511
Validation loss decreased (0.257219 --> 0.256681).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.2718520164489746
Epoch: 41, Steps: 61 | Train Loss: 0.1080434 Vali Loss: 0.2550393 Test Loss: 0.2906062
Validation loss decreased (0.256681 --> 0.255039).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.2726099491119385
Epoch: 42, Steps: 61 | Train Loss: 0.1071276 Vali Loss: 0.2562042 Test Loss: 0.2903104
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.253699779510498
Epoch: 43, Steps: 61 | Train Loss: 0.1064059 Vali Loss: 0.2550406 Test Loss: 0.2899674
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.38319730758667
Epoch: 44, Steps: 61 | Train Loss: 0.1055911 Vali Loss: 0.2534551 Test Loss: 0.2897112
Validation loss decreased (0.255039 --> 0.253455).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.274656057357788
Epoch: 45, Steps: 61 | Train Loss: 0.1048628 Vali Loss: 0.2529060 Test Loss: 0.2894430
Validation loss decreased (0.253455 --> 0.252906).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.3470103740692139
Epoch: 46, Steps: 61 | Train Loss: 0.1041089 Vali Loss: 0.2546342 Test Loss: 0.2891921
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.28163480758667
Epoch: 47, Steps: 61 | Train Loss: 0.1033890 Vali Loss: 0.2533860 Test Loss: 0.2889783
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.446082592010498
Epoch: 48, Steps: 61 | Train Loss: 0.1029314 Vali Loss: 0.2532142 Test Loss: 0.2887010
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.4069435596466064
Epoch: 49, Steps: 61 | Train Loss: 0.1022702 Vali Loss: 0.2534891 Test Loss: 0.2885194
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.3765332698822021
Epoch: 50, Steps: 61 | Train Loss: 0.1017316 Vali Loss: 0.2519650 Test Loss: 0.2883206
Validation loss decreased (0.252906 --> 0.251965).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.3961818218231201
Epoch: 51, Steps: 61 | Train Loss: 0.1011775 Vali Loss: 0.2526819 Test Loss: 0.2881255
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.3272504806518555
Epoch: 52, Steps: 61 | Train Loss: 0.1007092 Vali Loss: 0.2512406 Test Loss: 0.2879685
Validation loss decreased (0.251965 --> 0.251241).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.2779431343078613
Epoch: 53, Steps: 61 | Train Loss: 0.1002062 Vali Loss: 0.2509693 Test Loss: 0.2877741
Validation loss decreased (0.251241 --> 0.250969).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.3906233310699463
Epoch: 54, Steps: 61 | Train Loss: 0.0997979 Vali Loss: 0.2506036 Test Loss: 0.2876231
Validation loss decreased (0.250969 --> 0.250604).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.3459360599517822
Epoch: 55, Steps: 61 | Train Loss: 0.0993884 Vali Loss: 0.2505800 Test Loss: 0.2874528
Validation loss decreased (0.250604 --> 0.250580).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.2716352939605713
Epoch: 56, Steps: 61 | Train Loss: 0.0988989 Vali Loss: 0.2505741 Test Loss: 0.2872951
Validation loss decreased (0.250580 --> 0.250574).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.366114616394043
Epoch: 57, Steps: 61 | Train Loss: 0.0985167 Vali Loss: 0.2503882 Test Loss: 0.2871894
Validation loss decreased (0.250574 --> 0.250388).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.3992817401885986
Epoch: 58, Steps: 61 | Train Loss: 0.0981877 Vali Loss: 0.2506195 Test Loss: 0.2870402
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.375511884689331
Epoch: 59, Steps: 61 | Train Loss: 0.0977097 Vali Loss: 0.2503940 Test Loss: 0.2869257
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.3601887226104736
Epoch: 60, Steps: 61 | Train Loss: 0.0973842 Vali Loss: 0.2506234 Test Loss: 0.2868109
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.3265008926391602
Epoch: 61, Steps: 61 | Train Loss: 0.0972927 Vali Loss: 0.2495808 Test Loss: 0.2866826
Validation loss decreased (0.250388 --> 0.249581).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.3480920791625977
Epoch: 62, Steps: 61 | Train Loss: 0.0969138 Vali Loss: 0.2494186 Test Loss: 0.2865833
Validation loss decreased (0.249581 --> 0.249419).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.364929437637329
Epoch: 63, Steps: 61 | Train Loss: 0.0967313 Vali Loss: 0.2499118 Test Loss: 0.2864909
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.255540370941162
Epoch: 64, Steps: 61 | Train Loss: 0.0964106 Vali Loss: 0.2492719 Test Loss: 0.2863849
Validation loss decreased (0.249419 --> 0.249272).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.3346779346466064
Epoch: 65, Steps: 61 | Train Loss: 0.0961936 Vali Loss: 0.2488150 Test Loss: 0.2862914
Validation loss decreased (0.249272 --> 0.248815).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.314202070236206
Epoch: 66, Steps: 61 | Train Loss: 0.0958826 Vali Loss: 0.2493457 Test Loss: 0.2862152
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.2971210479736328
Epoch: 67, Steps: 61 | Train Loss: 0.0956591 Vali Loss: 0.2481486 Test Loss: 0.2861300
Validation loss decreased (0.248815 --> 0.248149).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.2968122959136963
Epoch: 68, Steps: 61 | Train Loss: 0.0953712 Vali Loss: 0.2483813 Test Loss: 0.2860508
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.2787275314331055
Epoch: 69, Steps: 61 | Train Loss: 0.0951858 Vali Loss: 0.2482001 Test Loss: 0.2859752
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.3604907989501953
Epoch: 70, Steps: 61 | Train Loss: 0.0950661 Vali Loss: 0.2488840 Test Loss: 0.2859145
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.4934568405151367
Epoch: 71, Steps: 61 | Train Loss: 0.0947842 Vali Loss: 0.2484265 Test Loss: 0.2858419
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.2975959777832031
Epoch: 72, Steps: 61 | Train Loss: 0.0946221 Vali Loss: 0.2485557 Test Loss: 0.2857693
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.324411392211914
Epoch: 73, Steps: 61 | Train Loss: 0.0946027 Vali Loss: 0.2482266 Test Loss: 0.2857120
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.3531773090362549
Epoch: 74, Steps: 61 | Train Loss: 0.0943606 Vali Loss: 0.2473442 Test Loss: 0.2856642
Validation loss decreased (0.248149 --> 0.247344).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.3747437000274658
Epoch: 75, Steps: 61 | Train Loss: 0.0941611 Vali Loss: 0.2479159 Test Loss: 0.2855938
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.304706335067749
Epoch: 76, Steps: 61 | Train Loss: 0.0940662 Vali Loss: 0.2489663 Test Loss: 0.2855546
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.284538745880127
Epoch: 77, Steps: 61 | Train Loss: 0.0938501 Vali Loss: 0.2476184 Test Loss: 0.2854993
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.232224941253662
Epoch: 78, Steps: 61 | Train Loss: 0.0937874 Vali Loss: 0.2489228 Test Loss: 0.2854569
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.084078073501587
Epoch: 79, Steps: 61 | Train Loss: 0.0936637 Vali Loss: 0.2466229 Test Loss: 0.2854085
Validation loss decreased (0.247344 --> 0.246623).  Saving model ...
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.31577730178833
Epoch: 80, Steps: 61 | Train Loss: 0.0934764 Vali Loss: 0.2477550 Test Loss: 0.2853626
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.3616654872894287
Epoch: 81, Steps: 61 | Train Loss: 0.0934193 Vali Loss: 0.2476090 Test Loss: 0.2853236
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.3972153663635254
Epoch: 82, Steps: 61 | Train Loss: 0.0933390 Vali Loss: 0.2476210 Test Loss: 0.2852840
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.378770351409912
Epoch: 83, Steps: 61 | Train Loss: 0.0933214 Vali Loss: 0.2476883 Test Loss: 0.2852453
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.2544398307800293
Epoch: 84, Steps: 61 | Train Loss: 0.0931532 Vali Loss: 0.2480929 Test Loss: 0.2852137
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.2651340961456299
Epoch: 85, Steps: 61 | Train Loss: 0.0931202 Vali Loss: 0.2473703 Test Loss: 0.2851824
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.3971827030181885
Epoch: 86, Steps: 61 | Train Loss: 0.0929347 Vali Loss: 0.2473793 Test Loss: 0.2851509
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.408958911895752
Epoch: 87, Steps: 61 | Train Loss: 0.0928369 Vali Loss: 0.2468217 Test Loss: 0.2851152
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.2691972255706787
Epoch: 88, Steps: 61 | Train Loss: 0.0927644 Vali Loss: 0.2478525 Test Loss: 0.2850885
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.2403671741485596
Epoch: 89, Steps: 61 | Train Loss: 0.0927627 Vali Loss: 0.2470472 Test Loss: 0.2850606
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.3188714981079102
Epoch: 90, Steps: 61 | Train Loss: 0.0927133 Vali Loss: 0.2473601 Test Loss: 0.2850330
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.2783451080322266
Epoch: 91, Steps: 61 | Train Loss: 0.0925581 Vali Loss: 0.2468928 Test Loss: 0.2850101
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.2328567504882812
Epoch: 92, Steps: 61 | Train Loss: 0.0925325 Vali Loss: 0.2471124 Test Loss: 0.2849853
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.3340935707092285
Epoch: 93, Steps: 61 | Train Loss: 0.0924793 Vali Loss: 0.2470899 Test Loss: 0.2849631
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.2987287044525146
Epoch: 94, Steps: 61 | Train Loss: 0.0924121 Vali Loss: 0.2470948 Test Loss: 0.2849452
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.3447341918945312
Epoch: 95, Steps: 61 | Train Loss: 0.0923237 Vali Loss: 0.2470322 Test Loss: 0.2849218
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.3098154067993164
Epoch: 96, Steps: 61 | Train Loss: 0.0922934 Vali Loss: 0.2464613 Test Loss: 0.2849035
Validation loss decreased (0.246623 --> 0.246461).  Saving model ...
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.3051750659942627
Epoch: 97, Steps: 61 | Train Loss: 0.0921461 Vali Loss: 0.2466217 Test Loss: 0.2848866
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.3229026794433594
Epoch: 98, Steps: 61 | Train Loss: 0.0921506 Vali Loss: 0.2466245 Test Loss: 0.2848714
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.2632133960723877
Epoch: 99, Steps: 61 | Train Loss: 0.0921709 Vali Loss: 0.2460163 Test Loss: 0.2848524
Validation loss decreased (0.246461 --> 0.246016).  Saving model ...
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.3285737037658691
Epoch: 100, Steps: 61 | Train Loss: 0.0920514 Vali Loss: 0.2467338 Test Loss: 0.2848374
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1160680107021042e-06
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=196, out_features=222, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  38986752.0
params:  43734.0
Trainable parameters:  43734
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.202855110168457
Epoch: 1, Steps: 61 | Train Loss: 0.4236306 Vali Loss: 0.2222133 Test Loss: 0.2741274
Validation loss decreased (inf --> 0.222213).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.3501965999603271
Epoch: 2, Steps: 61 | Train Loss: 0.4104711 Vali Loss: 0.2198473 Test Loss: 0.2734458
Validation loss decreased (0.222213 --> 0.219847).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.2527062892913818
Epoch: 3, Steps: 61 | Train Loss: 0.4071583 Vali Loss: 0.2166074 Test Loss: 0.2733493
Validation loss decreased (0.219847 --> 0.216607).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.3082807064056396
Epoch: 4, Steps: 61 | Train Loss: 0.4051342 Vali Loss: 0.2158477 Test Loss: 0.2731533
Validation loss decreased (0.216607 --> 0.215848).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.3084685802459717
Epoch: 5, Steps: 61 | Train Loss: 0.4022653 Vali Loss: 0.2144654 Test Loss: 0.2725747
Validation loss decreased (0.215848 --> 0.214465).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.3351054191589355
Epoch: 6, Steps: 61 | Train Loss: 0.4033565 Vali Loss: 0.2144859 Test Loss: 0.2724244
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.404421091079712
Epoch: 7, Steps: 61 | Train Loss: 0.4026095 Vali Loss: 0.2150305 Test Loss: 0.2722732
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.301058292388916
Epoch: 8, Steps: 61 | Train Loss: 0.4014720 Vali Loss: 0.2145254 Test Loss: 0.2720917
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.3877832889556885
Epoch: 9, Steps: 61 | Train Loss: 0.4016653 Vali Loss: 0.2133424 Test Loss: 0.2720870
Validation loss decreased (0.214465 --> 0.213342).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.3455817699432373
Epoch: 10, Steps: 61 | Train Loss: 0.4011391 Vali Loss: 0.2140169 Test Loss: 0.2720889
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.325160264968872
Epoch: 11, Steps: 61 | Train Loss: 0.4008970 Vali Loss: 0.2141135 Test Loss: 0.2720917
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.3002638816833496
Epoch: 12, Steps: 61 | Train Loss: 0.3997201 Vali Loss: 0.2142516 Test Loss: 0.2719162
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.3447248935699463
Epoch: 13, Steps: 61 | Train Loss: 0.4001775 Vali Loss: 0.2131414 Test Loss: 0.2719272
Validation loss decreased (0.213342 --> 0.213141).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.2230947017669678
Epoch: 14, Steps: 61 | Train Loss: 0.4001369 Vali Loss: 0.2124329 Test Loss: 0.2719319
Validation loss decreased (0.213141 --> 0.212433).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.361907720565796
Epoch: 15, Steps: 61 | Train Loss: 0.3998682 Vali Loss: 0.2127000 Test Loss: 0.2718987
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.2275373935699463
Epoch: 16, Steps: 61 | Train Loss: 0.3983382 Vali Loss: 0.2119037 Test Loss: 0.2715844
Validation loss decreased (0.212433 --> 0.211904).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.3643264770507812
Epoch: 17, Steps: 61 | Train Loss: 0.3994339 Vali Loss: 0.2116295 Test Loss: 0.2717567
Validation loss decreased (0.211904 --> 0.211629).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.3375792503356934
Epoch: 18, Steps: 61 | Train Loss: 0.3982239 Vali Loss: 0.2126124 Test Loss: 0.2716006
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.4025099277496338
Epoch: 19, Steps: 61 | Train Loss: 0.3981414 Vali Loss: 0.2122784 Test Loss: 0.2716041
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.2813618183135986
Epoch: 20, Steps: 61 | Train Loss: 0.3987662 Vali Loss: 0.2117551 Test Loss: 0.2717337
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.4054548740386963
Epoch: 21, Steps: 61 | Train Loss: 0.3991639 Vali Loss: 0.2120719 Test Loss: 0.2715677
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.5095655918121338
Epoch: 22, Steps: 61 | Train Loss: 0.3987743 Vali Loss: 0.2120262 Test Loss: 0.2715222
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.3738398551940918
Epoch: 23, Steps: 61 | Train Loss: 0.3977738 Vali Loss: 0.2122648 Test Loss: 0.2715204
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.4748256206512451
Epoch: 24, Steps: 61 | Train Loss: 0.3981923 Vali Loss: 0.2113409 Test Loss: 0.2715814
Validation loss decreased (0.211629 --> 0.211341).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.5845861434936523
Epoch: 25, Steps: 61 | Train Loss: 0.3985627 Vali Loss: 0.2122315 Test Loss: 0.2715354
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.3948571681976318
Epoch: 26, Steps: 61 | Train Loss: 0.3981653 Vali Loss: 0.2119470 Test Loss: 0.2714466
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.3824868202209473
Epoch: 27, Steps: 61 | Train Loss: 0.3982745 Vali Loss: 0.2109079 Test Loss: 0.2715007
Validation loss decreased (0.211341 --> 0.210908).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.3226604461669922
Epoch: 28, Steps: 61 | Train Loss: 0.3963120 Vali Loss: 0.2122636 Test Loss: 0.2714829
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.2893142700195312
Epoch: 29, Steps: 61 | Train Loss: 0.3981849 Vali Loss: 0.2112629 Test Loss: 0.2714446
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.37681245803833
Epoch: 30, Steps: 61 | Train Loss: 0.3981278 Vali Loss: 0.2125307 Test Loss: 0.2713297
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.447371244430542
Epoch: 31, Steps: 61 | Train Loss: 0.3977907 Vali Loss: 0.2112924 Test Loss: 0.2714147
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.4197111129760742
Epoch: 32, Steps: 61 | Train Loss: 0.3980911 Vali Loss: 0.2120220 Test Loss: 0.2713744
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.4234015941619873
Epoch: 33, Steps: 61 | Train Loss: 0.3981015 Vali Loss: 0.2120590 Test Loss: 0.2714347
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.4310789108276367
Epoch: 34, Steps: 61 | Train Loss: 0.3979118 Vali Loss: 0.2116362 Test Loss: 0.2713411
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.3601679801940918
Epoch: 35, Steps: 61 | Train Loss: 0.3977084 Vali Loss: 0.2114861 Test Loss: 0.2713779
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.7370002269744873
Epoch: 36, Steps: 61 | Train Loss: 0.3979641 Vali Loss: 0.2123312 Test Loss: 0.2713108
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.5289051532745361
Epoch: 37, Steps: 61 | Train Loss: 0.3964499 Vali Loss: 0.2113092 Test Loss: 0.2713569
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.3416991233825684
Epoch: 38, Steps: 61 | Train Loss: 0.3972166 Vali Loss: 0.2118463 Test Loss: 0.2713901
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.2835144996643066
Epoch: 39, Steps: 61 | Train Loss: 0.3974919 Vali Loss: 0.2111832 Test Loss: 0.2713605
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.3521716594696045
Epoch: 40, Steps: 61 | Train Loss: 0.3977384 Vali Loss: 0.2111988 Test Loss: 0.2713546
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.3072257041931152
Epoch: 41, Steps: 61 | Train Loss: 0.3970857 Vali Loss: 0.2111760 Test Loss: 0.2713635
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.288315773010254
Epoch: 42, Steps: 61 | Train Loss: 0.3969623 Vali Loss: 0.2124652 Test Loss: 0.2713507
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.3398401737213135
Epoch: 43, Steps: 61 | Train Loss: 0.3966749 Vali Loss: 0.2117016 Test Loss: 0.2713202
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.3761489391326904
Epoch: 44, Steps: 61 | Train Loss: 0.3974250 Vali Loss: 0.2115359 Test Loss: 0.2713123
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.3403513431549072
Epoch: 45, Steps: 61 | Train Loss: 0.3974390 Vali Loss: 0.2113027 Test Loss: 0.2713158
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.2926607131958008
Epoch: 46, Steps: 61 | Train Loss: 0.3969559 Vali Loss: 0.2108548 Test Loss: 0.2713296
Validation loss decreased (0.210908 --> 0.210855).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.4510126113891602
Epoch: 47, Steps: 61 | Train Loss: 0.3968346 Vali Loss: 0.2114102 Test Loss: 0.2712684
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.4851222038269043
Epoch: 48, Steps: 61 | Train Loss: 0.3961967 Vali Loss: 0.2114592 Test Loss: 0.2713055
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.4050135612487793
Epoch: 49, Steps: 61 | Train Loss: 0.3973456 Vali Loss: 0.2109607 Test Loss: 0.2712680
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.2575018405914307
Epoch: 50, Steps: 61 | Train Loss: 0.3960467 Vali Loss: 0.2114233 Test Loss: 0.2713118
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.4702153205871582
Epoch: 51, Steps: 61 | Train Loss: 0.3973260 Vali Loss: 0.2116055 Test Loss: 0.2712939
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.1343162059783936
Epoch: 52, Steps: 61 | Train Loss: 0.3969967 Vali Loss: 0.2121927 Test Loss: 0.2713058
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.3054256439208984
Epoch: 53, Steps: 61 | Train Loss: 0.3973785 Vali Loss: 0.2117609 Test Loss: 0.2712868
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.2947912216186523
Epoch: 54, Steps: 61 | Train Loss: 0.3973459 Vali Loss: 0.2119537 Test Loss: 0.2712841
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.8437561988830566
Epoch: 55, Steps: 61 | Train Loss: 0.3972434 Vali Loss: 0.2114284 Test Loss: 0.2712792
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.3884224891662598
Epoch: 56, Steps: 61 | Train Loss: 0.3973076 Vali Loss: 0.2110476 Test Loss: 0.2712723
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.3551974296569824
Epoch: 57, Steps: 61 | Train Loss: 0.3968722 Vali Loss: 0.2102288 Test Loss: 0.2712708
Validation loss decreased (0.210855 --> 0.210229).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.327188491821289
Epoch: 58, Steps: 61 | Train Loss: 0.3962371 Vali Loss: 0.2103358 Test Loss: 0.2712271
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.2740955352783203
Epoch: 59, Steps: 61 | Train Loss: 0.3948924 Vali Loss: 0.2115544 Test Loss: 0.2712691
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.334625005722046
Epoch: 60, Steps: 61 | Train Loss: 0.3956543 Vali Loss: 0.2108335 Test Loss: 0.2712704
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.36722731590271
Epoch: 61, Steps: 61 | Train Loss: 0.3963869 Vali Loss: 0.2103022 Test Loss: 0.2712793
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.347937822341919
Epoch: 62, Steps: 61 | Train Loss: 0.3953422 Vali Loss: 0.2111519 Test Loss: 0.2712631
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.3805732727050781
Epoch: 63, Steps: 61 | Train Loss: 0.3972899 Vali Loss: 0.2112461 Test Loss: 0.2712685
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.3446385860443115
Epoch: 64, Steps: 61 | Train Loss: 0.3967054 Vali Loss: 0.2108194 Test Loss: 0.2712795
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.3452658653259277
Epoch: 65, Steps: 61 | Train Loss: 0.3959884 Vali Loss: 0.2113514 Test Loss: 0.2712535
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.4380018711090088
Epoch: 66, Steps: 61 | Train Loss: 0.3955447 Vali Loss: 0.2112786 Test Loss: 0.2712640
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.3252863883972168
Epoch: 67, Steps: 61 | Train Loss: 0.3971206 Vali Loss: 0.2119361 Test Loss: 0.2712662
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.4353697299957275
Epoch: 68, Steps: 61 | Train Loss: 0.3970042 Vali Loss: 0.2114585 Test Loss: 0.2712519
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.3686113357543945
Epoch: 69, Steps: 61 | Train Loss: 0.3969944 Vali Loss: 0.2115931 Test Loss: 0.2712555
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.2513384819030762
Epoch: 70, Steps: 61 | Train Loss: 0.3968438 Vali Loss: 0.2109002 Test Loss: 0.2712731
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.318847417831421
Epoch: 71, Steps: 61 | Train Loss: 0.3970943 Vali Loss: 0.2114580 Test Loss: 0.2712508
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.3336217403411865
Epoch: 72, Steps: 61 | Train Loss: 0.3969259 Vali Loss: 0.2116033 Test Loss: 0.2712675
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.3624494075775146
Epoch: 73, Steps: 61 | Train Loss: 0.3957415 Vali Loss: 0.2108310 Test Loss: 0.2712573
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.3133141994476318
Epoch: 74, Steps: 61 | Train Loss: 0.3971047 Vali Loss: 0.2116564 Test Loss: 0.2712531
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.3022346496582031
Epoch: 75, Steps: 61 | Train Loss: 0.3959598 Vali Loss: 0.2115095 Test Loss: 0.2712514
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.4087800979614258
Epoch: 76, Steps: 61 | Train Loss: 0.3964802 Vali Loss: 0.2115447 Test Loss: 0.2712559
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.3634824752807617
Epoch: 77, Steps: 61 | Train Loss: 0.3971030 Vali Loss: 0.2119084 Test Loss: 0.2712633
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.27099788188934326, mae:0.3359937071800232, rse:0.4195311963558197, corr:[0.2740357  0.2760181  0.27476558 0.27498257 0.274331   0.27296016
 0.27244228 0.27210644 0.2711154  0.26980093 0.26887825 0.26759812
 0.26583034 0.26439562 0.2637378  0.26346895 0.2629626  0.26253134
 0.26196477 0.26081446 0.2594496  0.258477   0.25755122 0.25574824
 0.25346822 0.25165373 0.2502566  0.24870865 0.2474122  0.24649933
 0.24531327 0.24372143 0.24224073 0.2411701  0.23974371 0.2383159
 0.23751192 0.2367079  0.23546007 0.23433968 0.23388483 0.23338088
 0.23266177 0.2319914  0.23117197 0.22979134 0.2286064  0.22756606
 0.2257767  0.22347243 0.22197986 0.22084476 0.21979457 0.21835878
 0.21655466 0.21491809 0.21293989 0.21093798 0.20959257 0.20855682
 0.20771438 0.20738427 0.20759115 0.20761274 0.20692104 0.2068274
 0.20648363 0.20535272 0.2047929  0.2047724  0.20384264 0.20265077
 0.20231737 0.20208497 0.20093022 0.19909374 0.19849534 0.1981871
 0.19773409 0.19716075 0.19739825 0.1971262  0.1963893  0.19638014
 0.19608031 0.19586442 0.19650558 0.19695187 0.19534236 0.1948735
 0.1956232  0.1943713  0.19354017 0.19496733 0.1934405  0.19070148]
