Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=58, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_360_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_360_192_FITS_ETTh2_ftM_sl360_ll48_pl192_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8089
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=58, out_features=88, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4573184.0
params:  5192.0
Trainable parameters:  5192
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.637592077255249
Epoch: 1, Steps: 63 | Train Loss: 0.5709379 Vali Loss: 0.4221521 Test Loss: 0.4731610
Validation loss decreased (inf --> 0.422152).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.5204505920410156
Epoch: 2, Steps: 63 | Train Loss: 0.4651468 Vali Loss: 0.3840257 Test Loss: 0.4382856
Validation loss decreased (0.422152 --> 0.384026).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.0919220447540283
Epoch: 3, Steps: 63 | Train Loss: 0.4018308 Vali Loss: 0.3610032 Test Loss: 0.4184434
Validation loss decreased (0.384026 --> 0.361003).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.3440163135528564
Epoch: 4, Steps: 63 | Train Loss: 0.3621762 Vali Loss: 0.3466690 Test Loss: 0.4072120
Validation loss decreased (0.361003 --> 0.346669).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.2631330490112305
Epoch: 5, Steps: 63 | Train Loss: 0.3338022 Vali Loss: 0.3369766 Test Loss: 0.4001443
Validation loss decreased (0.346669 --> 0.336977).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.3651375770568848
Epoch: 6, Steps: 63 | Train Loss: 0.3150469 Vali Loss: 0.3301457 Test Loss: 0.3954444
Validation loss decreased (0.336977 --> 0.330146).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.7983615398406982
Epoch: 7, Steps: 63 | Train Loss: 0.3001100 Vali Loss: 0.3249154 Test Loss: 0.3922048
Validation loss decreased (0.330146 --> 0.324915).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.6391546726226807
Epoch: 8, Steps: 63 | Train Loss: 0.2879110 Vali Loss: 0.3207963 Test Loss: 0.3897444
Validation loss decreased (0.324915 --> 0.320796).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.0965769290924072
Epoch: 9, Steps: 63 | Train Loss: 0.2787405 Vali Loss: 0.3176405 Test Loss: 0.3876918
Validation loss decreased (0.320796 --> 0.317641).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.417299270629883
Epoch: 10, Steps: 63 | Train Loss: 0.2704851 Vali Loss: 0.3147561 Test Loss: 0.3859431
Validation loss decreased (0.317641 --> 0.314756).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.823387861251831
Epoch: 11, Steps: 63 | Train Loss: 0.2629946 Vali Loss: 0.3124073 Test Loss: 0.3842604
Validation loss decreased (0.314756 --> 0.312407).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.1397194862365723
Epoch: 12, Steps: 63 | Train Loss: 0.2573949 Vali Loss: 0.3099544 Test Loss: 0.3828982
Validation loss decreased (0.312407 --> 0.309954).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.7259597778320312
Epoch: 13, Steps: 63 | Train Loss: 0.2521926 Vali Loss: 0.3086506 Test Loss: 0.3816160
Validation loss decreased (0.309954 --> 0.308651).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.478017807006836
Epoch: 14, Steps: 63 | Train Loss: 0.2476807 Vali Loss: 0.3070493 Test Loss: 0.3803840
Validation loss decreased (0.308651 --> 0.307049).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.034398078918457
Epoch: 15, Steps: 63 | Train Loss: 0.2440334 Vali Loss: 0.3056903 Test Loss: 0.3793230
Validation loss decreased (0.307049 --> 0.305690).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.0671160221099854
Epoch: 16, Steps: 63 | Train Loss: 0.2402532 Vali Loss: 0.3043732 Test Loss: 0.3782901
Validation loss decreased (0.305690 --> 0.304373).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.5122921466827393
Epoch: 17, Steps: 63 | Train Loss: 0.2376394 Vali Loss: 0.3031912 Test Loss: 0.3773017
Validation loss decreased (0.304373 --> 0.303191).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.043480396270752
Epoch: 18, Steps: 63 | Train Loss: 0.2348930 Vali Loss: 0.3020463 Test Loss: 0.3764775
Validation loss decreased (0.303191 --> 0.302046).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.8529551029205322
Epoch: 19, Steps: 63 | Train Loss: 0.2318745 Vali Loss: 0.3011765 Test Loss: 0.3756255
Validation loss decreased (0.302046 --> 0.301177).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.6384775638580322
Epoch: 20, Steps: 63 | Train Loss: 0.2298989 Vali Loss: 0.3002501 Test Loss: 0.3748957
Validation loss decreased (0.301177 --> 0.300250).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.632568359375
Epoch: 21, Steps: 63 | Train Loss: 0.2283003 Vali Loss: 0.2995382 Test Loss: 0.3741220
Validation loss decreased (0.300250 --> 0.299538).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.542567014694214
Epoch: 22, Steps: 63 | Train Loss: 0.2262177 Vali Loss: 0.2988701 Test Loss: 0.3734436
Validation loss decreased (0.299538 --> 0.298870).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.299920082092285
Epoch: 23, Steps: 63 | Train Loss: 0.2244304 Vali Loss: 0.2981862 Test Loss: 0.3728703
Validation loss decreased (0.298870 --> 0.298186).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.4414987564086914
Epoch: 24, Steps: 63 | Train Loss: 0.2231278 Vali Loss: 0.2973661 Test Loss: 0.3723407
Validation loss decreased (0.298186 --> 0.297366).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.6698458194732666
Epoch: 25, Steps: 63 | Train Loss: 0.2219877 Vali Loss: 0.2969818 Test Loss: 0.3717735
Validation loss decreased (0.297366 --> 0.296982).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.6002342700958252
Epoch: 26, Steps: 63 | Train Loss: 0.2207632 Vali Loss: 0.2963171 Test Loss: 0.3712253
Validation loss decreased (0.296982 --> 0.296317).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.63519287109375
Epoch: 27, Steps: 63 | Train Loss: 0.2198291 Vali Loss: 0.2959178 Test Loss: 0.3707614
Validation loss decreased (0.296317 --> 0.295918).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.8715713024139404
Epoch: 28, Steps: 63 | Train Loss: 0.2183316 Vali Loss: 0.2954892 Test Loss: 0.3703588
Validation loss decreased (0.295918 --> 0.295489).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.6028993129730225
Epoch: 29, Steps: 63 | Train Loss: 0.2178270 Vali Loss: 0.2951373 Test Loss: 0.3699232
Validation loss decreased (0.295489 --> 0.295137).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.5692129135131836
Epoch: 30, Steps: 63 | Train Loss: 0.2169635 Vali Loss: 0.2947193 Test Loss: 0.3695315
Validation loss decreased (0.295137 --> 0.294719).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 3.3615171909332275
Epoch: 31, Steps: 63 | Train Loss: 0.2161723 Vali Loss: 0.2942907 Test Loss: 0.3691584
Validation loss decreased (0.294719 --> 0.294291).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 3.5893654823303223
Epoch: 32, Steps: 63 | Train Loss: 0.2148933 Vali Loss: 0.2940164 Test Loss: 0.3688163
Validation loss decreased (0.294291 --> 0.294016).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.684511184692383
Epoch: 33, Steps: 63 | Train Loss: 0.2147594 Vali Loss: 0.2934982 Test Loss: 0.3685486
Validation loss decreased (0.294016 --> 0.293498).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.852097272872925
Epoch: 34, Steps: 63 | Train Loss: 0.2142220 Vali Loss: 0.2933725 Test Loss: 0.3681981
Validation loss decreased (0.293498 --> 0.293372).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 3.654956817626953
Epoch: 35, Steps: 63 | Train Loss: 0.2137343 Vali Loss: 0.2931901 Test Loss: 0.3679461
Validation loss decreased (0.293372 --> 0.293190).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.8691704273223877
Epoch: 36, Steps: 63 | Train Loss: 0.2131415 Vali Loss: 0.2928188 Test Loss: 0.3676269
Validation loss decreased (0.293190 --> 0.292819).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 3.912041187286377
Epoch: 37, Steps: 63 | Train Loss: 0.2125323 Vali Loss: 0.2926046 Test Loss: 0.3673653
Validation loss decreased (0.292819 --> 0.292605).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 3.45686411857605
Epoch: 38, Steps: 63 | Train Loss: 0.2122637 Vali Loss: 0.2924332 Test Loss: 0.3671746
Validation loss decreased (0.292605 --> 0.292433).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 3.163789749145508
Epoch: 39, Steps: 63 | Train Loss: 0.2116749 Vali Loss: 0.2921856 Test Loss: 0.3669304
Validation loss decreased (0.292433 --> 0.292186).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.538536787033081
Epoch: 40, Steps: 63 | Train Loss: 0.2108508 Vali Loss: 0.2920043 Test Loss: 0.3666903
Validation loss decreased (0.292186 --> 0.292004).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.419384717941284
Epoch: 41, Steps: 63 | Train Loss: 0.2109852 Vali Loss: 0.2919189 Test Loss: 0.3664825
Validation loss decreased (0.292004 --> 0.291919).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.573765993118286
Epoch: 42, Steps: 63 | Train Loss: 0.2103805 Vali Loss: 0.2917448 Test Loss: 0.3662998
Validation loss decreased (0.291919 --> 0.291745).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.6848981380462646
Epoch: 43, Steps: 63 | Train Loss: 0.2098028 Vali Loss: 0.2915670 Test Loss: 0.3661200
Validation loss decreased (0.291745 --> 0.291567).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.302509069442749
Epoch: 44, Steps: 63 | Train Loss: 0.2101132 Vali Loss: 0.2913036 Test Loss: 0.3659658
Validation loss decreased (0.291567 --> 0.291304).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 3.6191861629486084
Epoch: 45, Steps: 63 | Train Loss: 0.2097745 Vali Loss: 0.2912583 Test Loss: 0.3657983
Validation loss decreased (0.291304 --> 0.291258).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 3.430990219116211
Epoch: 46, Steps: 63 | Train Loss: 0.2095672 Vali Loss: 0.2911124 Test Loss: 0.3656433
Validation loss decreased (0.291258 --> 0.291112).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 3.0436172485351562
Epoch: 47, Steps: 63 | Train Loss: 0.2092976 Vali Loss: 0.2909920 Test Loss: 0.3654873
Validation loss decreased (0.291112 --> 0.290992).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 3.518355131149292
Epoch: 48, Steps: 63 | Train Loss: 0.2088239 Vali Loss: 0.2908832 Test Loss: 0.3653559
Validation loss decreased (0.290992 --> 0.290883).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.633077383041382
Epoch: 49, Steps: 63 | Train Loss: 0.2087225 Vali Loss: 0.2907321 Test Loss: 0.3652582
Validation loss decreased (0.290883 --> 0.290732).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.4788475036621094
Epoch: 50, Steps: 63 | Train Loss: 0.2083871 Vali Loss: 0.2906560 Test Loss: 0.3650817
Validation loss decreased (0.290732 --> 0.290656).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.2275400161743164
Epoch: 51, Steps: 63 | Train Loss: 0.2085183 Vali Loss: 0.2905557 Test Loss: 0.3649844
Validation loss decreased (0.290656 --> 0.290556).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 3.009880542755127
Epoch: 52, Steps: 63 | Train Loss: 0.2081238 Vali Loss: 0.2904721 Test Loss: 0.3648564
Validation loss decreased (0.290556 --> 0.290472).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.8033692836761475
Epoch: 53, Steps: 63 | Train Loss: 0.2081818 Vali Loss: 0.2903375 Test Loss: 0.3647704
Validation loss decreased (0.290472 --> 0.290337).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.71771502494812
Epoch: 54, Steps: 63 | Train Loss: 0.2080594 Vali Loss: 0.2902231 Test Loss: 0.3646477
Validation loss decreased (0.290337 --> 0.290223).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.4111578464508057
Epoch: 55, Steps: 63 | Train Loss: 0.2076542 Vali Loss: 0.2901594 Test Loss: 0.3645559
Validation loss decreased (0.290223 --> 0.290159).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.1328155994415283
Epoch: 56, Steps: 63 | Train Loss: 0.2076322 Vali Loss: 0.2900904 Test Loss: 0.3644582
Validation loss decreased (0.290159 --> 0.290090).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.3078930377960205
Epoch: 57, Steps: 63 | Train Loss: 0.2072267 Vali Loss: 0.2900556 Test Loss: 0.3643861
Validation loss decreased (0.290090 --> 0.290056).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.5206501483917236
Epoch: 58, Steps: 63 | Train Loss: 0.2069067 Vali Loss: 0.2899691 Test Loss: 0.3642971
Validation loss decreased (0.290056 --> 0.289969).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 3.3365707397460938
Epoch: 59, Steps: 63 | Train Loss: 0.2071591 Vali Loss: 0.2899421 Test Loss: 0.3642074
Validation loss decreased (0.289969 --> 0.289942).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 3.608644723892212
Epoch: 60, Steps: 63 | Train Loss: 0.2071467 Vali Loss: 0.2895572 Test Loss: 0.3641641
Validation loss decreased (0.289942 --> 0.289557).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.6850037574768066
Epoch: 61, Steps: 63 | Train Loss: 0.2068715 Vali Loss: 0.2895945 Test Loss: 0.3640833
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 3.6338422298431396
Epoch: 62, Steps: 63 | Train Loss: 0.2068007 Vali Loss: 0.2897505 Test Loss: 0.3640099
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 3.7471675872802734
Epoch: 63, Steps: 63 | Train Loss: 0.2068728 Vali Loss: 0.2896917 Test Loss: 0.3639481
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 3.881525993347168
Epoch: 64, Steps: 63 | Train Loss: 0.2067371 Vali Loss: 0.2896531 Test Loss: 0.3638766
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 3.2026195526123047
Epoch: 65, Steps: 63 | Train Loss: 0.2062919 Vali Loss: 0.2895838 Test Loss: 0.3638200
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 3.821108818054199
Epoch: 66, Steps: 63 | Train Loss: 0.2063507 Vali Loss: 0.2895627 Test Loss: 0.3637762
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.6593310832977295
Epoch: 67, Steps: 63 | Train Loss: 0.2064744 Vali Loss: 0.2895189 Test Loss: 0.3637169
Validation loss decreased (0.289557 --> 0.289519).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.898615837097168
Epoch: 68, Steps: 63 | Train Loss: 0.2063926 Vali Loss: 0.2894490 Test Loss: 0.3636733
Validation loss decreased (0.289519 --> 0.289449).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.2813501358032227
Epoch: 69, Steps: 63 | Train Loss: 0.2061050 Vali Loss: 0.2894353 Test Loss: 0.3636263
Validation loss decreased (0.289449 --> 0.289435).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.5284337997436523
Epoch: 70, Steps: 63 | Train Loss: 0.2062265 Vali Loss: 0.2893259 Test Loss: 0.3635716
Validation loss decreased (0.289435 --> 0.289326).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.8911569118499756
Epoch: 71, Steps: 63 | Train Loss: 0.2058474 Vali Loss: 0.2893530 Test Loss: 0.3635267
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.7237329483032227
Epoch: 72, Steps: 63 | Train Loss: 0.2058395 Vali Loss: 0.2892696 Test Loss: 0.3634863
Validation loss decreased (0.289326 --> 0.289270).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 3.5943214893341064
Epoch: 73, Steps: 63 | Train Loss: 0.2057802 Vali Loss: 0.2893153 Test Loss: 0.3634546
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.5579349994659424
Epoch: 74, Steps: 63 | Train Loss: 0.2059160 Vali Loss: 0.2891852 Test Loss: 0.3634076
Validation loss decreased (0.289270 --> 0.289185).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.495978593826294
Epoch: 75, Steps: 63 | Train Loss: 0.2058857 Vali Loss: 0.2892569 Test Loss: 0.3633820
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.903059720993042
Epoch: 76, Steps: 63 | Train Loss: 0.2060299 Vali Loss: 0.2892237 Test Loss: 0.3633387
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.5220086574554443
Epoch: 77, Steps: 63 | Train Loss: 0.2057244 Vali Loss: 0.2888266 Test Loss: 0.3633139
Validation loss decreased (0.289185 --> 0.288827).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 3.050133466720581
Epoch: 78, Steps: 63 | Train Loss: 0.2057062 Vali Loss: 0.2891605 Test Loss: 0.3632801
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.8394386768341064
Epoch: 79, Steps: 63 | Train Loss: 0.2056511 Vali Loss: 0.2890494 Test Loss: 0.3632446
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 3.1234123706817627
Epoch: 80, Steps: 63 | Train Loss: 0.2057299 Vali Loss: 0.2890871 Test Loss: 0.3632265
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.5676887035369873
Epoch: 81, Steps: 63 | Train Loss: 0.2056385 Vali Loss: 0.2891059 Test Loss: 0.3631983
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 2.707249879837036
Epoch: 82, Steps: 63 | Train Loss: 0.2054090 Vali Loss: 0.2891215 Test Loss: 0.3631693
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 3.5317602157592773
Epoch: 83, Steps: 63 | Train Loss: 0.2054901 Vali Loss: 0.2890037 Test Loss: 0.3631490
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 3.202446937561035
Epoch: 84, Steps: 63 | Train Loss: 0.2055569 Vali Loss: 0.2890203 Test Loss: 0.3631255
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 3.8287675380706787
Epoch: 85, Steps: 63 | Train Loss: 0.2053847 Vali Loss: 0.2890359 Test Loss: 0.3631034
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 3.783019781112671
Epoch: 86, Steps: 63 | Train Loss: 0.2052644 Vali Loss: 0.2890479 Test Loss: 0.3630820
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 3.381978750228882
Epoch: 87, Steps: 63 | Train Loss: 0.2052713 Vali Loss: 0.2886095 Test Loss: 0.3630637
Validation loss decreased (0.288827 --> 0.288610).  Saving model ...
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 3.6704118251800537
Epoch: 88, Steps: 63 | Train Loss: 0.2054438 Vali Loss: 0.2889966 Test Loss: 0.3630410
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.8119285106658936
Epoch: 89, Steps: 63 | Train Loss: 0.2054455 Vali Loss: 0.2887098 Test Loss: 0.3630273
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 2.5857796669006348
Epoch: 90, Steps: 63 | Train Loss: 0.2054801 Vali Loss: 0.2889708 Test Loss: 0.3630073
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.5702033042907715
Epoch: 91, Steps: 63 | Train Loss: 0.2054576 Vali Loss: 0.2888601 Test Loss: 0.3629904
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 2.8139021396636963
Epoch: 92, Steps: 63 | Train Loss: 0.2054114 Vali Loss: 0.2889596 Test Loss: 0.3629773
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 2.554875135421753
Epoch: 93, Steps: 63 | Train Loss: 0.2050917 Vali Loss: 0.2889619 Test Loss: 0.3629638
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 2.7444393634796143
Epoch: 94, Steps: 63 | Train Loss: 0.2053537 Vali Loss: 0.2889444 Test Loss: 0.3629446
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 2.862729549407959
Epoch: 95, Steps: 63 | Train Loss: 0.2048704 Vali Loss: 0.2889393 Test Loss: 0.3629334
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 3.4639830589294434
Epoch: 96, Steps: 63 | Train Loss: 0.2044404 Vali Loss: 0.2888816 Test Loss: 0.3629187
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 4.158995866775513
Epoch: 97, Steps: 63 | Train Loss: 0.2048857 Vali Loss: 0.2888563 Test Loss: 0.3629103
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 3.6336326599121094
Epoch: 98, Steps: 63 | Train Loss: 0.2049671 Vali Loss: 0.2889013 Test Loss: 0.3628998
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 2.8521459102630615
Epoch: 99, Steps: 63 | Train Loss: 0.2045634 Vali Loss: 0.2889052 Test Loss: 0.3628872
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 3.329096555709839
Epoch: 100, Steps: 63 | Train Loss: 0.2052801 Vali Loss: 0.2888149 Test Loss: 0.3628768
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8089
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=58, out_features=88, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4573184.0
params:  5192.0
Trainable parameters:  5192
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.957385301589966
Epoch: 1, Steps: 63 | Train Loss: 0.5164979 Vali Loss: 0.2851467 Test Loss: 0.3578940
Validation loss decreased (inf --> 0.285147).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.536177396774292
Epoch: 2, Steps: 63 | Train Loss: 0.5117348 Vali Loss: 0.2838286 Test Loss: 0.3563187
Validation loss decreased (0.285147 --> 0.283829).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.85622501373291
Epoch: 3, Steps: 63 | Train Loss: 0.5106368 Vali Loss: 0.2832253 Test Loss: 0.3557797
Validation loss decreased (0.283829 --> 0.283225).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.4093801975250244
Epoch: 4, Steps: 63 | Train Loss: 0.5099359 Vali Loss: 0.2823501 Test Loss: 0.3556147
Validation loss decreased (0.283225 --> 0.282350).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.2439374923706055
Epoch: 5, Steps: 63 | Train Loss: 0.5081829 Vali Loss: 0.2823516 Test Loss: 0.3556108
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.945786952972412
Epoch: 6, Steps: 63 | Train Loss: 0.5087358 Vali Loss: 0.2815174 Test Loss: 0.3557694
Validation loss decreased (0.282350 --> 0.281517).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.644024133682251
Epoch: 7, Steps: 63 | Train Loss: 0.5082861 Vali Loss: 0.2815336 Test Loss: 0.3555422
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.4337356090545654
Epoch: 8, Steps: 63 | Train Loss: 0.5079072 Vali Loss: 0.2813094 Test Loss: 0.3554282
Validation loss decreased (0.281517 --> 0.281309).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.966564655303955
Epoch: 9, Steps: 63 | Train Loss: 0.5079329 Vali Loss: 0.2809439 Test Loss: 0.3556204
Validation loss decreased (0.281309 --> 0.280944).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.969024658203125
Epoch: 10, Steps: 63 | Train Loss: 0.5076864 Vali Loss: 0.2804814 Test Loss: 0.3554415
Validation loss decreased (0.280944 --> 0.280481).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.243577241897583
Epoch: 11, Steps: 63 | Train Loss: 0.5078543 Vali Loss: 0.2806530 Test Loss: 0.3553614
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.647104501724243
Epoch: 12, Steps: 63 | Train Loss: 0.5060275 Vali Loss: 0.2804398 Test Loss: 0.3552501
Validation loss decreased (0.280481 --> 0.280440).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.3762319087982178
Epoch: 13, Steps: 63 | Train Loss: 0.5065561 Vali Loss: 0.2804621 Test Loss: 0.3552162
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.8499951362609863
Epoch: 14, Steps: 63 | Train Loss: 0.5069570 Vali Loss: 0.2803427 Test Loss: 0.3552262
Validation loss decreased (0.280440 --> 0.280343).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.4269793033599854
Epoch: 15, Steps: 63 | Train Loss: 0.5069859 Vali Loss: 0.2801090 Test Loss: 0.3551129
Validation loss decreased (0.280343 --> 0.280109).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.3189666271209717
Epoch: 16, Steps: 63 | Train Loss: 0.5068114 Vali Loss: 0.2801156 Test Loss: 0.3550811
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.45241641998291
Epoch: 17, Steps: 63 | Train Loss: 0.5052629 Vali Loss: 0.2799853 Test Loss: 0.3551753
Validation loss decreased (0.280109 --> 0.279985).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.280836820602417
Epoch: 18, Steps: 63 | Train Loss: 0.5063420 Vali Loss: 0.2798592 Test Loss: 0.3549862
Validation loss decreased (0.279985 --> 0.279859).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.6420867443084717
Epoch: 19, Steps: 63 | Train Loss: 0.5067493 Vali Loss: 0.2797717 Test Loss: 0.3551465
Validation loss decreased (0.279859 --> 0.279772).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.338982343673706
Epoch: 20, Steps: 63 | Train Loss: 0.5057289 Vali Loss: 0.2797219 Test Loss: 0.3551533
Validation loss decreased (0.279772 --> 0.279722).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.9296391010284424
Epoch: 21, Steps: 63 | Train Loss: 0.5053623 Vali Loss: 0.2796367 Test Loss: 0.3551843
Validation loss decreased (0.279722 --> 0.279637).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.8072168827056885
Epoch: 22, Steps: 63 | Train Loss: 0.5059952 Vali Loss: 0.2794353 Test Loss: 0.3552149
Validation loss decreased (0.279637 --> 0.279435).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.1581249237060547
Epoch: 23, Steps: 63 | Train Loss: 0.5051841 Vali Loss: 0.2795095 Test Loss: 0.3551474
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.515925884246826
Epoch: 24, Steps: 63 | Train Loss: 0.5055372 Vali Loss: 0.2793291 Test Loss: 0.3551278
Validation loss decreased (0.279435 --> 0.279329).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.164607524871826
Epoch: 25, Steps: 63 | Train Loss: 0.5050866 Vali Loss: 0.2794878 Test Loss: 0.3550524
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.2667524814605713
Epoch: 26, Steps: 63 | Train Loss: 0.5063166 Vali Loss: 0.2793990 Test Loss: 0.3551131
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 3.429074287414551
Epoch: 27, Steps: 63 | Train Loss: 0.5044725 Vali Loss: 0.2791514 Test Loss: 0.3550565
Validation loss decreased (0.279329 --> 0.279151).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.260977268218994
Epoch: 28, Steps: 63 | Train Loss: 0.5052617 Vali Loss: 0.2793005 Test Loss: 0.3550845
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 4.077296257019043
Epoch: 29, Steps: 63 | Train Loss: 0.5056709 Vali Loss: 0.2792644 Test Loss: 0.3550967
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 3.336824893951416
Epoch: 30, Steps: 63 | Train Loss: 0.5044741 Vali Loss: 0.2792376 Test Loss: 0.3550846
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 3.883359670639038
Epoch: 31, Steps: 63 | Train Loss: 0.5048512 Vali Loss: 0.2792884 Test Loss: 0.3549966
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.717306137084961
Epoch: 32, Steps: 63 | Train Loss: 0.5040764 Vali Loss: 0.2792383 Test Loss: 0.3550322
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 3.4193594455718994
Epoch: 33, Steps: 63 | Train Loss: 0.5056419 Vali Loss: 0.2791619 Test Loss: 0.3549681
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.310309886932373
Epoch: 34, Steps: 63 | Train Loss: 0.5052079 Vali Loss: 0.2791918 Test Loss: 0.3549578
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.9149482250213623
Epoch: 35, Steps: 63 | Train Loss: 0.5048487 Vali Loss: 0.2792273 Test Loss: 0.3550131
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.0130703449249268
Epoch: 36, Steps: 63 | Train Loss: 0.5043990 Vali Loss: 0.2791047 Test Loss: 0.3550052
Validation loss decreased (0.279151 --> 0.279105).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.414876937866211
Epoch: 37, Steps: 63 | Train Loss: 0.5048425 Vali Loss: 0.2791560 Test Loss: 0.3550146
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.4623067378997803
Epoch: 38, Steps: 63 | Train Loss: 0.5060208 Vali Loss: 0.2791612 Test Loss: 0.3549610
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.534304141998291
Epoch: 39, Steps: 63 | Train Loss: 0.5057192 Vali Loss: 0.2789598 Test Loss: 0.3549528
Validation loss decreased (0.279105 --> 0.278960).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.296095848083496
Epoch: 40, Steps: 63 | Train Loss: 0.5052104 Vali Loss: 0.2791828 Test Loss: 0.3549036
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.4326119422912598
Epoch: 41, Steps: 63 | Train Loss: 0.5055816 Vali Loss: 0.2791177 Test Loss: 0.3549332
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.2645719051361084
Epoch: 42, Steps: 63 | Train Loss: 0.5051723 Vali Loss: 0.2791107 Test Loss: 0.3549514
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 3.023390769958496
Epoch: 43, Steps: 63 | Train Loss: 0.5057414 Vali Loss: 0.2791505 Test Loss: 0.3548965
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.490070343017578
Epoch: 44, Steps: 63 | Train Loss: 0.5053720 Vali Loss: 0.2790312 Test Loss: 0.3549229
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 3.3914084434509277
Epoch: 45, Steps: 63 | Train Loss: 0.5050260 Vali Loss: 0.2790414 Test Loss: 0.3549145
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.8974287509918213
Epoch: 46, Steps: 63 | Train Loss: 0.5056584 Vali Loss: 0.2790517 Test Loss: 0.3549373
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.22902512550354
Epoch: 47, Steps: 63 | Train Loss: 0.5046955 Vali Loss: 0.2789201 Test Loss: 0.3549346
Validation loss decreased (0.278960 --> 0.278920).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 3.6275088787078857
Epoch: 48, Steps: 63 | Train Loss: 0.5056490 Vali Loss: 0.2790829 Test Loss: 0.3549225
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.812446355819702
Epoch: 49, Steps: 63 | Train Loss: 0.5051784 Vali Loss: 0.2790292 Test Loss: 0.3549221
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 3.4898481369018555
Epoch: 50, Steps: 63 | Train Loss: 0.5049768 Vali Loss: 0.2790329 Test Loss: 0.3549293
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 3.7426340579986572
Epoch: 51, Steps: 63 | Train Loss: 0.5052844 Vali Loss: 0.2789990 Test Loss: 0.3549290
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.8420698642730713
Epoch: 52, Steps: 63 | Train Loss: 0.5045661 Vali Loss: 0.2789387 Test Loss: 0.3549065
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 3.6737165451049805
Epoch: 53, Steps: 63 | Train Loss: 0.5050740 Vali Loss: 0.2790135 Test Loss: 0.3549149
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.723284959793091
Epoch: 54, Steps: 63 | Train Loss: 0.5047484 Vali Loss: 0.2789033 Test Loss: 0.3549327
Validation loss decreased (0.278920 --> 0.278903).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.216780424118042
Epoch: 55, Steps: 63 | Train Loss: 0.5056358 Vali Loss: 0.2788965 Test Loss: 0.3549093
Validation loss decreased (0.278903 --> 0.278896).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.8215959072113037
Epoch: 56, Steps: 63 | Train Loss: 0.5049388 Vali Loss: 0.2789305 Test Loss: 0.3549377
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.746410369873047
Epoch: 57, Steps: 63 | Train Loss: 0.5043141 Vali Loss: 0.2789702 Test Loss: 0.3549352
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.4392411708831787
Epoch: 58, Steps: 63 | Train Loss: 0.5040845 Vali Loss: 0.2788944 Test Loss: 0.3549193
Validation loss decreased (0.278896 --> 0.278894).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.5674185752868652
Epoch: 59, Steps: 63 | Train Loss: 0.5056193 Vali Loss: 0.2789509 Test Loss: 0.3549463
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.6242101192474365
Epoch: 60, Steps: 63 | Train Loss: 0.5054467 Vali Loss: 0.2788981 Test Loss: 0.3549302
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.618518352508545
Epoch: 61, Steps: 63 | Train Loss: 0.5050377 Vali Loss: 0.2785482 Test Loss: 0.3549307
Validation loss decreased (0.278894 --> 0.278548).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.993173599243164
Epoch: 62, Steps: 63 | Train Loss: 0.5055350 Vali Loss: 0.2789206 Test Loss: 0.3549151
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 3.605039596557617
Epoch: 63, Steps: 63 | Train Loss: 0.5052169 Vali Loss: 0.2788608 Test Loss: 0.3549348
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.5785958766937256
Epoch: 64, Steps: 63 | Train Loss: 0.5045782 Vali Loss: 0.2789363 Test Loss: 0.3549159
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.7934274673461914
Epoch: 65, Steps: 63 | Train Loss: 0.5055850 Vali Loss: 0.2788809 Test Loss: 0.3549015
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.8700273036956787
Epoch: 66, Steps: 63 | Train Loss: 0.5051994 Vali Loss: 0.2789087 Test Loss: 0.3549115
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.0197529792785645
Epoch: 67, Steps: 63 | Train Loss: 0.5047636 Vali Loss: 0.2789353 Test Loss: 0.3549106
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 3.3202900886535645
Epoch: 68, Steps: 63 | Train Loss: 0.5050176 Vali Loss: 0.2788907 Test Loss: 0.3548954
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 3.5637128353118896
Epoch: 69, Steps: 63 | Train Loss: 0.5032451 Vali Loss: 0.2788983 Test Loss: 0.3549048
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.6626174449920654
Epoch: 70, Steps: 63 | Train Loss: 0.5034379 Vali Loss: 0.2789164 Test Loss: 0.3549211
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.9902312755584717
Epoch: 71, Steps: 63 | Train Loss: 0.5057720 Vali Loss: 0.2788617 Test Loss: 0.3549002
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.1875977516174316
Epoch: 72, Steps: 63 | Train Loss: 0.5049350 Vali Loss: 0.2788914 Test Loss: 0.3549223
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.0647594928741455
Epoch: 73, Steps: 63 | Train Loss: 0.5055323 Vali Loss: 0.2788623 Test Loss: 0.3549161
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.1365373134613037
Epoch: 74, Steps: 63 | Train Loss: 0.5039526 Vali Loss: 0.2788877 Test Loss: 0.3549113
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.4182724952697754
Epoch: 75, Steps: 63 | Train Loss: 0.5045120 Vali Loss: 0.2788867 Test Loss: 0.3549150
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.5322182178497314
Epoch: 76, Steps: 63 | Train Loss: 0.5043523 Vali Loss: 0.2789000 Test Loss: 0.3549116
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.2968943119049072
Epoch: 77, Steps: 63 | Train Loss: 0.5053909 Vali Loss: 0.2788952 Test Loss: 0.3549133
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.786000967025757
Epoch: 78, Steps: 63 | Train Loss: 0.5050413 Vali Loss: 0.2788906 Test Loss: 0.3549115
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.702476978302002
Epoch: 79, Steps: 63 | Train Loss: 0.5045268 Vali Loss: 0.2788362 Test Loss: 0.3549016
EarlyStopping counter: 18 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.4478843212127686
Epoch: 80, Steps: 63 | Train Loss: 0.5052481 Vali Loss: 0.2788695 Test Loss: 0.3549074
EarlyStopping counter: 19 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 3.0008652210235596
Epoch: 81, Steps: 63 | Train Loss: 0.5045114 Vali Loss: 0.2788735 Test Loss: 0.3549083
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_360_192_FITS_ETTh2_ftM_sl360_ll48_pl192_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.33573561906814575, mae:0.37616124749183655, rse:0.4646645784378052, corr:[0.26676702 0.26927468 0.2684305  0.26609588 0.264395   0.2636635
 0.26343024 0.26261002 0.26131085 0.25959742 0.25795323 0.2563711
 0.25521392 0.25451842 0.25404406 0.25372264 0.25317606 0.2525031
 0.25159693 0.2505848  0.24952734 0.24818423 0.24650802 0.24426696
 0.24188842 0.23978823 0.23827346 0.23694026 0.2355051  0.23396282
 0.23250225 0.2310348  0.22956823 0.2281726  0.22684519 0.22547975
 0.22405519 0.22285919 0.2222137  0.22172622 0.22117199 0.22044818
 0.21945927 0.21835798 0.2173898  0.21632648 0.21494104 0.21304397
 0.21088235 0.20899521 0.20765169 0.20650288 0.20510922 0.2033302
 0.20119493 0.19896719 0.19727579 0.19578587 0.19465616 0.19386907
 0.19350582 0.19322194 0.19309492 0.19289659 0.19239932 0.1918336
 0.19111703 0.19031473 0.1896068  0.18897861 0.18833402 0.18759859
 0.18658252 0.18553334 0.18458454 0.18371098 0.18312897 0.18264
 0.18193133 0.18098363 0.18051921 0.18015583 0.1799544  0.17969966
 0.17951253 0.17927001 0.179053   0.17880079 0.17829835 0.17777558
 0.17720133 0.17663398 0.17654201 0.17658679 0.17650533 0.17600317
 0.17507192 0.17377271 0.17262584 0.17170867 0.171043   0.17050594
 0.1700874  0.1693813  0.16885382 0.1686565  0.16859464 0.16883823
 0.16863005 0.16807546 0.16717792 0.16663557 0.16617116 0.16592143
 0.16574602 0.16520473 0.16452608 0.1634451  0.1621265  0.16067688
 0.15940864 0.15797673 0.15672974 0.15580878 0.154903   0.15404189
 0.1533683  0.15274093 0.1519958  0.15107422 0.15035352 0.14983712
 0.14963783 0.14940153 0.1489381  0.14836678 0.14776863 0.14739648
 0.14695069 0.14679646 0.1468073  0.14634295 0.14520931 0.14376888
 0.14221218 0.14061446 0.13909982 0.13793173 0.13722132 0.13661213
 0.13635199 0.13576429 0.1352477  0.1348552  0.134428   0.13398843
 0.13370912 0.1339068  0.1338608  0.13395368 0.13381766 0.13353576
 0.1333052  0.13314995 0.13321209 0.13313691 0.13285577 0.13182367
 0.13056053 0.12932447 0.12816879 0.12719432 0.12635794 0.12523963
 0.12370002 0.1218833  0.12023348 0.11905915 0.11844435 0.11773033
 0.11697141 0.11612722 0.1153166  0.11500459 0.11465415 0.11363429
 0.11231947 0.11080033 0.11022364 0.11173804 0.11492734 0.11609662]
