Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=30, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_90_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_90_192_FITS_ETTh2_ftM_sl90_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8359
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=30, out_features=94, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2526720.0
params:  2914.0
Trainable parameters:  2914
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.196821451187134
Epoch: 1, Steps: 65 | Train Loss: 0.7412998 Vali Loss: 0.3594460 Test Loss: 0.5060881
Validation loss decreased (inf --> 0.359446).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.0152485370635986
Epoch: 2, Steps: 65 | Train Loss: 0.6503417 Vali Loss: 0.3256061 Test Loss: 0.4593173
Validation loss decreased (0.359446 --> 0.325606).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.211554527282715
Epoch: 3, Steps: 65 | Train Loss: 0.6086098 Vali Loss: 0.3085048 Test Loss: 0.4357516
Validation loss decreased (0.325606 --> 0.308505).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.898719072341919
Epoch: 4, Steps: 65 | Train Loss: 0.5841075 Vali Loss: 0.2989165 Test Loss: 0.4227046
Validation loss decreased (0.308505 --> 0.298916).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 4.225611448287964
Epoch: 5, Steps: 65 | Train Loss: 0.5738938 Vali Loss: 0.2932204 Test Loss: 0.4152242
Validation loss decreased (0.298916 --> 0.293220).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.305889368057251
Epoch: 6, Steps: 65 | Train Loss: 0.5675319 Vali Loss: 0.2896338 Test Loss: 0.4106878
Validation loss decreased (0.293220 --> 0.289634).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.3420088291168213
Epoch: 7, Steps: 65 | Train Loss: 0.5616382 Vali Loss: 0.2871682 Test Loss: 0.4075155
Validation loss decreased (0.289634 --> 0.287168).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 4.228775501251221
Epoch: 8, Steps: 65 | Train Loss: 0.5572875 Vali Loss: 0.2854660 Test Loss: 0.4055233
Validation loss decreased (0.287168 --> 0.285466).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 4.3185553550720215
Epoch: 9, Steps: 65 | Train Loss: 0.5557579 Vali Loss: 0.2840973 Test Loss: 0.4039457
Validation loss decreased (0.285466 --> 0.284097).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 4.853429079055786
Epoch: 10, Steps: 65 | Train Loss: 0.5526558 Vali Loss: 0.2831562 Test Loss: 0.4028777
Validation loss decreased (0.284097 --> 0.283156).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.5714187622070312
Epoch: 11, Steps: 65 | Train Loss: 0.5529993 Vali Loss: 0.2823453 Test Loss: 0.4020478
Validation loss decreased (0.283156 --> 0.282345).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.486382484436035
Epoch: 12, Steps: 65 | Train Loss: 0.5516488 Vali Loss: 0.2816728 Test Loss: 0.4013158
Validation loss decreased (0.282345 --> 0.281673).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.409640073776245
Epoch: 13, Steps: 65 | Train Loss: 0.5505819 Vali Loss: 0.2810888 Test Loss: 0.4007761
Validation loss decreased (0.281673 --> 0.281089).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.8925914764404297
Epoch: 14, Steps: 65 | Train Loss: 0.5500769 Vali Loss: 0.2806075 Test Loss: 0.4002709
Validation loss decreased (0.281089 --> 0.280607).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.114978551864624
Epoch: 15, Steps: 65 | Train Loss: 0.5479505 Vali Loss: 0.2802117 Test Loss: 0.3999383
Validation loss decreased (0.280607 --> 0.280212).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.290888547897339
Epoch: 16, Steps: 65 | Train Loss: 0.5474182 Vali Loss: 0.2796761 Test Loss: 0.3996100
Validation loss decreased (0.280212 --> 0.279676).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 4.172861576080322
Epoch: 17, Steps: 65 | Train Loss: 0.5486026 Vali Loss: 0.2794437 Test Loss: 0.3993078
Validation loss decreased (0.279676 --> 0.279444).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 5.209685802459717
Epoch: 18, Steps: 65 | Train Loss: 0.5459564 Vali Loss: 0.2790638 Test Loss: 0.3990414
Validation loss decreased (0.279444 --> 0.279064).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 6.224344253540039
Epoch: 19, Steps: 65 | Train Loss: 0.5460039 Vali Loss: 0.2789058 Test Loss: 0.3988217
Validation loss decreased (0.279064 --> 0.278906).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.565577030181885
Epoch: 20, Steps: 65 | Train Loss: 0.5461111 Vali Loss: 0.2787129 Test Loss: 0.3986536
Validation loss decreased (0.278906 --> 0.278713).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 4.375318765640259
Epoch: 21, Steps: 65 | Train Loss: 0.5460571 Vali Loss: 0.2785203 Test Loss: 0.3984898
Validation loss decreased (0.278713 --> 0.278520).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.2949576377868652
Epoch: 22, Steps: 65 | Train Loss: 0.5455543 Vali Loss: 0.2783092 Test Loss: 0.3983505
Validation loss decreased (0.278520 --> 0.278309).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.6309399604797363
Epoch: 23, Steps: 65 | Train Loss: 0.5432849 Vali Loss: 0.2780471 Test Loss: 0.3981972
Validation loss decreased (0.278309 --> 0.278047).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 4.7051966190338135
Epoch: 24, Steps: 65 | Train Loss: 0.5444073 Vali Loss: 0.2779647 Test Loss: 0.3981004
Validation loss decreased (0.278047 --> 0.277965).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.9243879318237305
Epoch: 25, Steps: 65 | Train Loss: 0.5435157 Vali Loss: 0.2777757 Test Loss: 0.3979625
Validation loss decreased (0.277965 --> 0.277776).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.842071056365967
Epoch: 26, Steps: 65 | Train Loss: 0.5439667 Vali Loss: 0.2774996 Test Loss: 0.3978681
Validation loss decreased (0.277776 --> 0.277500).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 3.25913405418396
Epoch: 27, Steps: 65 | Train Loss: 0.5430026 Vali Loss: 0.2775176 Test Loss: 0.3977978
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.2386558055877686
Epoch: 28, Steps: 65 | Train Loss: 0.5404798 Vali Loss: 0.2774071 Test Loss: 0.3977052
Validation loss decreased (0.277500 --> 0.277407).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 3.5495617389678955
Epoch: 29, Steps: 65 | Train Loss: 0.5433380 Vali Loss: 0.2772563 Test Loss: 0.3976336
Validation loss decreased (0.277407 --> 0.277256).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 3.153207778930664
Epoch: 30, Steps: 65 | Train Loss: 0.5420232 Vali Loss: 0.2771993 Test Loss: 0.3975668
Validation loss decreased (0.277256 --> 0.277199).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 4.383091926574707
Epoch: 31, Steps: 65 | Train Loss: 0.5437542 Vali Loss: 0.2771265 Test Loss: 0.3975119
Validation loss decreased (0.277199 --> 0.277126).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 3.1122448444366455
Epoch: 32, Steps: 65 | Train Loss: 0.5428902 Vali Loss: 0.2770168 Test Loss: 0.3974612
Validation loss decreased (0.277126 --> 0.277017).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 4.570136547088623
Epoch: 33, Steps: 65 | Train Loss: 0.5426599 Vali Loss: 0.2769278 Test Loss: 0.3974116
Validation loss decreased (0.277017 --> 0.276928).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 4.750128746032715
Epoch: 34, Steps: 65 | Train Loss: 0.5432591 Vali Loss: 0.2769016 Test Loss: 0.3973690
Validation loss decreased (0.276928 --> 0.276902).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 4.555680751800537
Epoch: 35, Steps: 65 | Train Loss: 0.5428825 Vali Loss: 0.2767812 Test Loss: 0.3973429
Validation loss decreased (0.276902 --> 0.276781).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.411064863204956
Epoch: 36, Steps: 65 | Train Loss: 0.5430692 Vali Loss: 0.2767017 Test Loss: 0.3972831
Validation loss decreased (0.276781 --> 0.276702).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.9701006412506104
Epoch: 37, Steps: 65 | Train Loss: 0.5410847 Vali Loss: 0.2766181 Test Loss: 0.3972588
Validation loss decreased (0.276702 --> 0.276618).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 3.900242328643799
Epoch: 38, Steps: 65 | Train Loss: 0.5421647 Vali Loss: 0.2766192 Test Loss: 0.3972423
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.6414012908935547
Epoch: 39, Steps: 65 | Train Loss: 0.5411934 Vali Loss: 0.2765304 Test Loss: 0.3972195
Validation loss decreased (0.276618 --> 0.276530).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 3.132620096206665
Epoch: 40, Steps: 65 | Train Loss: 0.5421934 Vali Loss: 0.2765616 Test Loss: 0.3972056
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.3060107231140137
Epoch: 41, Steps: 65 | Train Loss: 0.5415324 Vali Loss: 0.2764365 Test Loss: 0.3971727
Validation loss decreased (0.276530 --> 0.276437).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 3.026967763900757
Epoch: 42, Steps: 65 | Train Loss: 0.5418191 Vali Loss: 0.2764260 Test Loss: 0.3971521
Validation loss decreased (0.276437 --> 0.276426).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 3.1254122257232666
Epoch: 43, Steps: 65 | Train Loss: 0.5416591 Vali Loss: 0.2763970 Test Loss: 0.3971176
Validation loss decreased (0.276426 --> 0.276397).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.968263626098633
Epoch: 44, Steps: 65 | Train Loss: 0.5386464 Vali Loss: 0.2763020 Test Loss: 0.3971029
Validation loss decreased (0.276397 --> 0.276302).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 4.247583866119385
Epoch: 45, Steps: 65 | Train Loss: 0.5418635 Vali Loss: 0.2762076 Test Loss: 0.3970858
Validation loss decreased (0.276302 --> 0.276208).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.9539034366607666
Epoch: 46, Steps: 65 | Train Loss: 0.5395106 Vali Loss: 0.2759226 Test Loss: 0.3970785
Validation loss decreased (0.276208 --> 0.275923).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.9487640857696533
Epoch: 47, Steps: 65 | Train Loss: 0.5423092 Vali Loss: 0.2761091 Test Loss: 0.3970561
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 4.11972451210022
Epoch: 48, Steps: 65 | Train Loss: 0.5401020 Vali Loss: 0.2762080 Test Loss: 0.3970425
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.9502532482147217
Epoch: 49, Steps: 65 | Train Loss: 0.5407092 Vali Loss: 0.2761713 Test Loss: 0.3970368
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 3.1202526092529297
Epoch: 50, Steps: 65 | Train Loss: 0.5409803 Vali Loss: 0.2760673 Test Loss: 0.3970303
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.6293840408325195
Epoch: 51, Steps: 65 | Train Loss: 0.5397668 Vali Loss: 0.2761574 Test Loss: 0.3970125
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 4.540588140487671
Epoch: 52, Steps: 65 | Train Loss: 0.5404287 Vali Loss: 0.2761023 Test Loss: 0.3970095
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 3.542876720428467
Epoch: 53, Steps: 65 | Train Loss: 0.5413839 Vali Loss: 0.2761283 Test Loss: 0.3969941
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 4.3226165771484375
Epoch: 54, Steps: 65 | Train Loss: 0.5404686 Vali Loss: 0.2757263 Test Loss: 0.3969886
Validation loss decreased (0.275923 --> 0.275726).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.9324264526367188
Epoch: 55, Steps: 65 | Train Loss: 0.5409065 Vali Loss: 0.2759251 Test Loss: 0.3969798
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.9983372688293457
Epoch: 56, Steps: 65 | Train Loss: 0.5393382 Vali Loss: 0.2759703 Test Loss: 0.3969717
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 3.5717804431915283
Epoch: 57, Steps: 65 | Train Loss: 0.5409829 Vali Loss: 0.2760231 Test Loss: 0.3969558
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 4.0946033000946045
Epoch: 58, Steps: 65 | Train Loss: 0.5415623 Vali Loss: 0.2759960 Test Loss: 0.3969546
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 4.342916011810303
Epoch: 59, Steps: 65 | Train Loss: 0.5396141 Vali Loss: 0.2758886 Test Loss: 0.3969536
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 3.3680615425109863
Epoch: 60, Steps: 65 | Train Loss: 0.5404551 Vali Loss: 0.2759182 Test Loss: 0.3969449
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 4.3329572677612305
Epoch: 61, Steps: 65 | Train Loss: 0.5402209 Vali Loss: 0.2758884 Test Loss: 0.3969319
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 3.7346549034118652
Epoch: 62, Steps: 65 | Train Loss: 0.5390490 Vali Loss: 0.2759649 Test Loss: 0.3969248
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 4.126155853271484
Epoch: 63, Steps: 65 | Train Loss: 0.5408474 Vali Loss: 0.2756955 Test Loss: 0.3969297
Validation loss decreased (0.275726 --> 0.275695).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.258165121078491
Epoch: 64, Steps: 65 | Train Loss: 0.5413516 Vali Loss: 0.2757955 Test Loss: 0.3969180
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.3920226097106934
Epoch: 65, Steps: 65 | Train Loss: 0.5403107 Vali Loss: 0.2755453 Test Loss: 0.3969186
Validation loss decreased (0.275695 --> 0.275545).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.338376045227051
Epoch: 66, Steps: 65 | Train Loss: 0.5402081 Vali Loss: 0.2758625 Test Loss: 0.3969148
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.820115804672241
Epoch: 67, Steps: 65 | Train Loss: 0.5399342 Vali Loss: 0.2758533 Test Loss: 0.3969089
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 3.0673460960388184
Epoch: 68, Steps: 65 | Train Loss: 0.5386776 Vali Loss: 0.2758205 Test Loss: 0.3969087
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 3.01263689994812
Epoch: 69, Steps: 65 | Train Loss: 0.5394372 Vali Loss: 0.2755163 Test Loss: 0.3969023
Validation loss decreased (0.275545 --> 0.275516).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.489744186401367
Epoch: 70, Steps: 65 | Train Loss: 0.5411261 Vali Loss: 0.2757840 Test Loss: 0.3969003
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 3.6487345695495605
Epoch: 71, Steps: 65 | Train Loss: 0.5380885 Vali Loss: 0.2758569 Test Loss: 0.3968951
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 3.1131246089935303
Epoch: 72, Steps: 65 | Train Loss: 0.5400023 Vali Loss: 0.2757918 Test Loss: 0.3968912
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 3.3518669605255127
Epoch: 73, Steps: 65 | Train Loss: 0.5402018 Vali Loss: 0.2757695 Test Loss: 0.3968926
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 3.755516529083252
Epoch: 74, Steps: 65 | Train Loss: 0.5411364 Vali Loss: 0.2755065 Test Loss: 0.3968919
Validation loss decreased (0.275516 --> 0.275507).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 3.0802948474884033
Epoch: 75, Steps: 65 | Train Loss: 0.5404209 Vali Loss: 0.2758476 Test Loss: 0.3968866
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.9673962593078613
Epoch: 76, Steps: 65 | Train Loss: 0.5408010 Vali Loss: 0.2758448 Test Loss: 0.3968841
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 4.15710973739624
Epoch: 77, Steps: 65 | Train Loss: 0.5402850 Vali Loss: 0.2758134 Test Loss: 0.3968815
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.7295467853546143
Epoch: 78, Steps: 65 | Train Loss: 0.5410330 Vali Loss: 0.2757731 Test Loss: 0.3968810
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 3.569441556930542
Epoch: 79, Steps: 65 | Train Loss: 0.5397843 Vali Loss: 0.2757841 Test Loss: 0.3968788
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 4.508527994155884
Epoch: 80, Steps: 65 | Train Loss: 0.5401324 Vali Loss: 0.2757768 Test Loss: 0.3968764
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.6495776176452637
Epoch: 81, Steps: 65 | Train Loss: 0.5400774 Vali Loss: 0.2757495 Test Loss: 0.3968720
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 2.9495699405670166
Epoch: 82, Steps: 65 | Train Loss: 0.5403422 Vali Loss: 0.2758041 Test Loss: 0.3968736
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.8281466960906982
Epoch: 83, Steps: 65 | Train Loss: 0.5401887 Vali Loss: 0.2757109 Test Loss: 0.3968700
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.7849321365356445
Epoch: 84, Steps: 65 | Train Loss: 0.5407253 Vali Loss: 0.2757211 Test Loss: 0.3968677
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.6107823848724365
Epoch: 85, Steps: 65 | Train Loss: 0.5406746 Vali Loss: 0.2757266 Test Loss: 0.3968680
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 3.8217709064483643
Epoch: 86, Steps: 65 | Train Loss: 0.5397764 Vali Loss: 0.2754584 Test Loss: 0.3968653
Validation loss decreased (0.275507 --> 0.275458).  Saving model ...
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 5.191484689712524
Epoch: 87, Steps: 65 | Train Loss: 0.5391190 Vali Loss: 0.2757056 Test Loss: 0.3968641
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 4.73401403427124
Epoch: 88, Steps: 65 | Train Loss: 0.5398297 Vali Loss: 0.2757429 Test Loss: 0.3968636
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 3.6449403762817383
Epoch: 89, Steps: 65 | Train Loss: 0.5400080 Vali Loss: 0.2757465 Test Loss: 0.3968628
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 3.6058976650238037
Epoch: 90, Steps: 65 | Train Loss: 0.5394480 Vali Loss: 0.2755955 Test Loss: 0.3968599
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 3.011364459991455
Epoch: 91, Steps: 65 | Train Loss: 0.5395741 Vali Loss: 0.2757298 Test Loss: 0.3968607
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 3.858996629714966
Epoch: 92, Steps: 65 | Train Loss: 0.5401798 Vali Loss: 0.2757210 Test Loss: 0.3968587
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 4.348598003387451
Epoch: 93, Steps: 65 | Train Loss: 0.5393315 Vali Loss: 0.2757418 Test Loss: 0.3968576
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 4.323357343673706
Epoch: 94, Steps: 65 | Train Loss: 0.5397063 Vali Loss: 0.2757670 Test Loss: 0.3968563
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.8111064434051514
Epoch: 95, Steps: 65 | Train Loss: 0.5391633 Vali Loss: 0.2756042 Test Loss: 0.3968559
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 3.247620105743408
Epoch: 96, Steps: 65 | Train Loss: 0.5387679 Vali Loss: 0.2757416 Test Loss: 0.3968548
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 4.047030687332153
Epoch: 97, Steps: 65 | Train Loss: 0.5398156 Vali Loss: 0.2757055 Test Loss: 0.3968540
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 2.987989902496338
Epoch: 98, Steps: 65 | Train Loss: 0.5402911 Vali Loss: 0.2757181 Test Loss: 0.3968534
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 3.1517043113708496
Epoch: 99, Steps: 65 | Train Loss: 0.5409302 Vali Loss: 0.2753784 Test Loss: 0.3968527
Validation loss decreased (0.275458 --> 0.275378).  Saving model ...
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 2.90513014793396
Epoch: 100, Steps: 65 | Train Loss: 0.5396131 Vali Loss: 0.2757303 Test Loss: 0.3968523
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1160680107021042e-06
>>>>>>>testing : ETTh2_90_192_FITS_ETTh2_ftM_sl90_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.37852907180786133, mae:0.39133119583129883, rse:0.49339014291763306, corr:[0.26753956 0.27029493 0.2674567  0.26864743 0.26568726 0.26518345
 0.264781   0.26296628 0.26278013 0.26172152 0.26012754 0.2590456
 0.25711048 0.25566316 0.25506848 0.25397435 0.25330302 0.25305834
 0.25188553 0.25071356 0.24982181 0.24853542 0.24738261 0.24535242
 0.24200563 0.23943172 0.23716964 0.23531672 0.23376413 0.2321887
 0.23117985 0.23013258 0.22856094 0.2272209  0.22653468 0.22500819
 0.22347468 0.22251749 0.22126529 0.22051147 0.22013076 0.21935129
 0.21890137 0.2182358  0.21689057 0.21593674 0.21504362 0.21240555
 0.20882113 0.20618168 0.20332447 0.20121998 0.19954239 0.19743276
 0.19584924 0.19386457 0.19261312 0.19164915 0.19071253 0.18928142
 0.18861541 0.18825163 0.1875911  0.18780462 0.18758911 0.18653177
 0.18610045 0.18540658 0.18440492 0.18389511 0.18298452 0.18112
 0.17869878 0.17707425 0.17535798 0.17424402 0.1731184  0.17235936
 0.17250915 0.17173128 0.17121623 0.17114128 0.17092896 0.17037728
 0.17012817 0.16983812 0.16945109 0.16980073 0.16945699 0.16862255
 0.16850117 0.1677725  0.16693744 0.16690622 0.16631442 0.1645411
 0.16238773 0.16034135 0.15803972 0.15671639 0.15545127 0.1541821
 0.15419742 0.15365851 0.15341656 0.15351686 0.15343611 0.15301064
 0.15290016 0.15251417 0.15150711 0.15158755 0.15130576 0.15023749
 0.15024965 0.14981973 0.14859891 0.14801548 0.14681709 0.14420281
 0.14173122 0.1398282  0.13766551 0.13658288 0.13533929 0.13399532
 0.13360891 0.13323689 0.13293679 0.13272774 0.13254704 0.1319497
 0.13165395 0.13110648 0.1303296  0.13030833 0.12993652 0.12900867
 0.12876698 0.12827587 0.12744175 0.12731028 0.12625824 0.12368507
 0.12081548 0.11841647 0.11596541 0.11468306 0.11333459 0.11210542
 0.11202771 0.11138488 0.11120549 0.11135091 0.11146988 0.11106218
 0.11098978 0.11077034 0.11021441 0.11076216 0.11057576 0.10956414
 0.1097024  0.10935266 0.10867073 0.10903355 0.10867349 0.10648514
 0.10388846 0.101932   0.100077   0.09941855 0.09828793 0.09726096
 0.09749158 0.09710319 0.09728988 0.09746836 0.09769999 0.09747066
 0.09736524 0.09692041 0.09639836 0.09703723 0.09621218 0.09511732
 0.09516416 0.09414118 0.0946823  0.09617739 0.09612013 0.10073181]
