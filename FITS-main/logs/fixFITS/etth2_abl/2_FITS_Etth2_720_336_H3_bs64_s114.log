Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=103, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_336_FITS_ETTh2_ftM_sl720_ll48_pl336_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=103, out_features=151, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  13935488.0
params:  15704.0
Trainable parameters:  15704
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.4590532779693604
Epoch: 1, Steps: 59 | Train Loss: 0.6812528 Vali Loss: 0.6049603 Test Loss: 0.4454117
Validation loss decreased (inf --> 0.604960).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.697430372238159
Epoch: 2, Steps: 59 | Train Loss: 0.5443184 Vali Loss: 0.5448975 Test Loss: 0.4137534
Validation loss decreased (0.604960 --> 0.544897).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.849470376968384
Epoch: 3, Steps: 59 | Train Loss: 0.4700831 Vali Loss: 0.5086665 Test Loss: 0.3984112
Validation loss decreased (0.544897 --> 0.508666).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.908432722091675
Epoch: 4, Steps: 59 | Train Loss: 0.4265310 Vali Loss: 0.4862252 Test Loss: 0.3906553
Validation loss decreased (0.508666 --> 0.486225).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.756014108657837
Epoch: 5, Steps: 59 | Train Loss: 0.3950651 Vali Loss: 0.4701976 Test Loss: 0.3865241
Validation loss decreased (0.486225 --> 0.470198).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.7812113761901855
Epoch: 6, Steps: 59 | Train Loss: 0.3731979 Vali Loss: 0.4592887 Test Loss: 0.3840913
Validation loss decreased (0.470198 --> 0.459289).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.6047863960266113
Epoch: 7, Steps: 59 | Train Loss: 0.3548052 Vali Loss: 0.4523934 Test Loss: 0.3823627
Validation loss decreased (0.459289 --> 0.452393).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.2415809631347656
Epoch: 8, Steps: 59 | Train Loss: 0.3410239 Vali Loss: 0.4421096 Test Loss: 0.3807823
Validation loss decreased (0.452393 --> 0.442110).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.614556312561035
Epoch: 9, Steps: 59 | Train Loss: 0.3286761 Vali Loss: 0.4375018 Test Loss: 0.3796950
Validation loss decreased (0.442110 --> 0.437502).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.0046608448028564
Epoch: 10, Steps: 59 | Train Loss: 0.3190760 Vali Loss: 0.4344389 Test Loss: 0.3786139
Validation loss decreased (0.437502 --> 0.434439).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.454561710357666
Epoch: 11, Steps: 59 | Train Loss: 0.3100566 Vali Loss: 0.4301081 Test Loss: 0.3775007
Validation loss decreased (0.434439 --> 0.430108).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.7558600902557373
Epoch: 12, Steps: 59 | Train Loss: 0.3026102 Vali Loss: 0.4289809 Test Loss: 0.3766305
Validation loss decreased (0.430108 --> 0.428981).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.3349177837371826
Epoch: 13, Steps: 59 | Train Loss: 0.2954580 Vali Loss: 0.4266204 Test Loss: 0.3757275
Validation loss decreased (0.428981 --> 0.426620).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.641773223876953
Epoch: 14, Steps: 59 | Train Loss: 0.2902709 Vali Loss: 0.4216953 Test Loss: 0.3749815
Validation loss decreased (0.426620 --> 0.421695).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.7104547023773193
Epoch: 15, Steps: 59 | Train Loss: 0.2849396 Vali Loss: 0.4229659 Test Loss: 0.3742213
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.3837738037109375
Epoch: 16, Steps: 59 | Train Loss: 0.2800950 Vali Loss: 0.4187182 Test Loss: 0.3735545
Validation loss decreased (0.421695 --> 0.418718).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.783874750137329
Epoch: 17, Steps: 59 | Train Loss: 0.2761393 Vali Loss: 0.4176780 Test Loss: 0.3728927
Validation loss decreased (0.418718 --> 0.417678).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.50099515914917
Epoch: 18, Steps: 59 | Train Loss: 0.2720814 Vali Loss: 0.4161507 Test Loss: 0.3723207
Validation loss decreased (0.417678 --> 0.416151).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.036755084991455
Epoch: 19, Steps: 59 | Train Loss: 0.2684462 Vali Loss: 0.4141614 Test Loss: 0.3716912
Validation loss decreased (0.416151 --> 0.414161).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.4486687183380127
Epoch: 20, Steps: 59 | Train Loss: 0.2659030 Vali Loss: 0.4131912 Test Loss: 0.3711722
Validation loss decreased (0.414161 --> 0.413191).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.4992127418518066
Epoch: 21, Steps: 59 | Train Loss: 0.2629984 Vali Loss: 0.4105934 Test Loss: 0.3706665
Validation loss decreased (0.413191 --> 0.410593).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.7594215869903564
Epoch: 22, Steps: 59 | Train Loss: 0.2602959 Vali Loss: 0.4112540 Test Loss: 0.3702996
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.8472824096679688
Epoch: 23, Steps: 59 | Train Loss: 0.2583934 Vali Loss: 0.4087074 Test Loss: 0.3699581
Validation loss decreased (0.410593 --> 0.408707).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.0814931392669678
Epoch: 24, Steps: 59 | Train Loss: 0.2565241 Vali Loss: 0.4097195 Test Loss: 0.3694421
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.893322467803955
Epoch: 25, Steps: 59 | Train Loss: 0.2544778 Vali Loss: 0.4087734 Test Loss: 0.3692421
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.3524868488311768
Epoch: 26, Steps: 59 | Train Loss: 0.2527555 Vali Loss: 0.4086276 Test Loss: 0.3688951
Validation loss decreased (0.408707 --> 0.408628).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.7141947746276855
Epoch: 27, Steps: 59 | Train Loss: 0.2509004 Vali Loss: 0.4045883 Test Loss: 0.3686407
Validation loss decreased (0.408628 --> 0.404588).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.0250308513641357
Epoch: 28, Steps: 59 | Train Loss: 0.2496841 Vali Loss: 0.4074887 Test Loss: 0.3684641
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.9539241790771484
Epoch: 29, Steps: 59 | Train Loss: 0.2488852 Vali Loss: 0.4074511 Test Loss: 0.3682225
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 3.019200086593628
Epoch: 30, Steps: 59 | Train Loss: 0.2477108 Vali Loss: 0.4066940 Test Loss: 0.3679393
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.9481239318847656
Epoch: 31, Steps: 59 | Train Loss: 0.2461252 Vali Loss: 0.4045128 Test Loss: 0.3678305
Validation loss decreased (0.404588 --> 0.404513).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.9885988235473633
Epoch: 32, Steps: 59 | Train Loss: 0.2452785 Vali Loss: 0.4046202 Test Loss: 0.3675854
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 3.5678982734680176
Epoch: 33, Steps: 59 | Train Loss: 0.2441570 Vali Loss: 0.4052484 Test Loss: 0.3674360
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.1703827381134033
Epoch: 34, Steps: 59 | Train Loss: 0.2435825 Vali Loss: 0.4007188 Test Loss: 0.3673134
Validation loss decreased (0.404513 --> 0.400719).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.9408068656921387
Epoch: 35, Steps: 59 | Train Loss: 0.2424545 Vali Loss: 0.4039937 Test Loss: 0.3671815
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.4762496948242188
Epoch: 36, Steps: 59 | Train Loss: 0.2415088 Vali Loss: 0.4056353 Test Loss: 0.3670638
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.717785596847534
Epoch: 37, Steps: 59 | Train Loss: 0.2409348 Vali Loss: 0.4051872 Test Loss: 0.3669258
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.586925506591797
Epoch: 38, Steps: 59 | Train Loss: 0.2404697 Vali Loss: 0.4016386 Test Loss: 0.3668367
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 3.1188533306121826
Epoch: 39, Steps: 59 | Train Loss: 0.2399914 Vali Loss: 0.4012503 Test Loss: 0.3667564
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.326707363128662
Epoch: 40, Steps: 59 | Train Loss: 0.2391376 Vali Loss: 0.4029505 Test Loss: 0.3666561
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.5487759113311768
Epoch: 41, Steps: 59 | Train Loss: 0.2392232 Vali Loss: 0.3990681 Test Loss: 0.3665609
Validation loss decreased (0.400719 --> 0.399068).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 3.375251054763794
Epoch: 42, Steps: 59 | Train Loss: 0.2385036 Vali Loss: 0.4020652 Test Loss: 0.3665036
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 3.007166862487793
Epoch: 43, Steps: 59 | Train Loss: 0.2380759 Vali Loss: 0.3994142 Test Loss: 0.3664297
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.2071428298950195
Epoch: 44, Steps: 59 | Train Loss: 0.2374854 Vali Loss: 0.4001488 Test Loss: 0.3663667
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 3.1550533771514893
Epoch: 45, Steps: 59 | Train Loss: 0.2371428 Vali Loss: 0.4005668 Test Loss: 0.3663165
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.8229222297668457
Epoch: 46, Steps: 59 | Train Loss: 0.2359894 Vali Loss: 0.4017533 Test Loss: 0.3662661
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 3.313483953475952
Epoch: 47, Steps: 59 | Train Loss: 0.2364419 Vali Loss: 0.3984000 Test Loss: 0.3662166
Validation loss decreased (0.399068 --> 0.398400).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 3.148566961288452
Epoch: 48, Steps: 59 | Train Loss: 0.2359725 Vali Loss: 0.3986447 Test Loss: 0.3661710
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 3.110887050628662
Epoch: 49, Steps: 59 | Train Loss: 0.2358081 Vali Loss: 0.3979344 Test Loss: 0.3661165
Validation loss decreased (0.398400 --> 0.397934).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.769493818283081
Epoch: 50, Steps: 59 | Train Loss: 0.2352304 Vali Loss: 0.3991118 Test Loss: 0.3661074
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.9208948612213135
Epoch: 51, Steps: 59 | Train Loss: 0.2350091 Vali Loss: 0.3955826 Test Loss: 0.3660523
Validation loss decreased (0.397934 --> 0.395583).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.151495933532715
Epoch: 52, Steps: 59 | Train Loss: 0.2350991 Vali Loss: 0.3982781 Test Loss: 0.3660400
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.845799446105957
Epoch: 53, Steps: 59 | Train Loss: 0.2347691 Vali Loss: 0.3986037 Test Loss: 0.3659997
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.7317862510681152
Epoch: 54, Steps: 59 | Train Loss: 0.2344449 Vali Loss: 0.3979583 Test Loss: 0.3659875
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.9968059062957764
Epoch: 55, Steps: 59 | Train Loss: 0.2338966 Vali Loss: 0.3979339 Test Loss: 0.3659452
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 3.0265893936157227
Epoch: 56, Steps: 59 | Train Loss: 0.2340528 Vali Loss: 0.3977925 Test Loss: 0.3659286
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 3.033566951751709
Epoch: 57, Steps: 59 | Train Loss: 0.2334330 Vali Loss: 0.3969271 Test Loss: 0.3659174
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.452406644821167
Epoch: 58, Steps: 59 | Train Loss: 0.2337684 Vali Loss: 0.3976670 Test Loss: 0.3658943
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.404618978500366
Epoch: 59, Steps: 59 | Train Loss: 0.2330498 Vali Loss: 0.3964915 Test Loss: 0.3658822
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.878793239593506
Epoch: 60, Steps: 59 | Train Loss: 0.2328449 Vali Loss: 0.3958906 Test Loss: 0.3658587
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.509080171585083
Epoch: 61, Steps: 59 | Train Loss: 0.2328996 Vali Loss: 0.4001537 Test Loss: 0.3658428
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.451045274734497
Epoch: 62, Steps: 59 | Train Loss: 0.2326978 Vali Loss: 0.3969300 Test Loss: 0.3658401
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.3116981983184814
Epoch: 63, Steps: 59 | Train Loss: 0.2326522 Vali Loss: 0.3942927 Test Loss: 0.3658111
Validation loss decreased (0.395583 --> 0.394293).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.862319231033325
Epoch: 64, Steps: 59 | Train Loss: 0.2327912 Vali Loss: 0.3961949 Test Loss: 0.3658038
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.814279317855835
Epoch: 65, Steps: 59 | Train Loss: 0.2325000 Vali Loss: 0.3999304 Test Loss: 0.3658053
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.7314085960388184
Epoch: 66, Steps: 59 | Train Loss: 0.2324631 Vali Loss: 0.3968953 Test Loss: 0.3657803
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.2868685722351074
Epoch: 67, Steps: 59 | Train Loss: 0.2320178 Vali Loss: 0.3954234 Test Loss: 0.3657853
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.6617801189422607
Epoch: 68, Steps: 59 | Train Loss: 0.2325830 Vali Loss: 0.3980365 Test Loss: 0.3657848
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.7005503177642822
Epoch: 69, Steps: 59 | Train Loss: 0.2315420 Vali Loss: 0.3977625 Test Loss: 0.3657727
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 4.176016807556152
Epoch: 70, Steps: 59 | Train Loss: 0.2318604 Vali Loss: 0.3978998 Test Loss: 0.3657638
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.885549783706665
Epoch: 71, Steps: 59 | Train Loss: 0.2315856 Vali Loss: 0.3958159 Test Loss: 0.3657567
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.6196253299713135
Epoch: 72, Steps: 59 | Train Loss: 0.2316307 Vali Loss: 0.3974057 Test Loss: 0.3657468
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.6774659156799316
Epoch: 73, Steps: 59 | Train Loss: 0.2320491 Vali Loss: 0.3979177 Test Loss: 0.3657507
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.9817028045654297
Epoch: 74, Steps: 59 | Train Loss: 0.2315883 Vali Loss: 0.3978708 Test Loss: 0.3657543
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.627133846282959
Epoch: 75, Steps: 59 | Train Loss: 0.2314177 Vali Loss: 0.3960446 Test Loss: 0.3657402
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.6114699840545654
Epoch: 76, Steps: 59 | Train Loss: 0.2313642 Vali Loss: 0.3981539 Test Loss: 0.3657401
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.8252382278442383
Epoch: 77, Steps: 59 | Train Loss: 0.2313257 Vali Loss: 0.3978037 Test Loss: 0.3657349
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.4872195720672607
Epoch: 78, Steps: 59 | Train Loss: 0.2315342 Vali Loss: 0.3982715 Test Loss: 0.3657268
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.7993528842926025
Epoch: 79, Steps: 59 | Train Loss: 0.2316042 Vali Loss: 0.3973029 Test Loss: 0.3657239
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 3.099522113800049
Epoch: 80, Steps: 59 | Train Loss: 0.2315239 Vali Loss: 0.3978325 Test Loss: 0.3657248
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.270019769668579
Epoch: 81, Steps: 59 | Train Loss: 0.2314910 Vali Loss: 0.3985247 Test Loss: 0.3657219
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 3.493182897567749
Epoch: 82, Steps: 59 | Train Loss: 0.2308732 Vali Loss: 0.3953822 Test Loss: 0.3657197
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.6163156032562256
Epoch: 83, Steps: 59 | Train Loss: 0.2307479 Vali Loss: 0.3957407 Test Loss: 0.3657205
EarlyStopping counter: 20 out of 20
Early stopping
train 7585
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=103, out_features=151, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  13935488.0
params:  15704.0
Trainable parameters:  15704
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.4657392501831055
Epoch: 1, Steps: 59 | Train Loss: 0.6284527 Vali Loss: 0.3881614 Test Loss: 0.3635346
Validation loss decreased (inf --> 0.388161).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.2218472957611084
Epoch: 2, Steps: 59 | Train Loss: 0.6200781 Vali Loss: 0.3857994 Test Loss: 0.3625413
Validation loss decreased (0.388161 --> 0.385799).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.4579901695251465
Epoch: 3, Steps: 59 | Train Loss: 0.6175982 Vali Loss: 0.3816843 Test Loss: 0.3618448
Validation loss decreased (0.385799 --> 0.381684).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.3628456592559814
Epoch: 4, Steps: 59 | Train Loss: 0.6180232 Vali Loss: 0.3826168 Test Loss: 0.3617571
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.9356396198272705
Epoch: 5, Steps: 59 | Train Loss: 0.6160657 Vali Loss: 0.3818583 Test Loss: 0.3614805
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.978632926940918
Epoch: 6, Steps: 59 | Train Loss: 0.6168816 Vali Loss: 0.3817670 Test Loss: 0.3610025
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.7011923789978027
Epoch: 7, Steps: 59 | Train Loss: 0.6161234 Vali Loss: 0.3786547 Test Loss: 0.3608938
Validation loss decreased (0.381684 --> 0.378655).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.7190475463867188
Epoch: 8, Steps: 59 | Train Loss: 0.6160948 Vali Loss: 0.3786883 Test Loss: 0.3607064
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.6535282135009766
Epoch: 9, Steps: 59 | Train Loss: 0.6160197 Vali Loss: 0.3801590 Test Loss: 0.3610033
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.8429110050201416
Epoch: 10, Steps: 59 | Train Loss: 0.6146258 Vali Loss: 0.3799471 Test Loss: 0.3608088
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.935728073120117
Epoch: 11, Steps: 59 | Train Loss: 0.6158361 Vali Loss: 0.3799659 Test Loss: 0.3608801
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.045300006866455
Epoch: 12, Steps: 59 | Train Loss: 0.6146384 Vali Loss: 0.3793725 Test Loss: 0.3607344
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.4967992305755615
Epoch: 13, Steps: 59 | Train Loss: 0.6135187 Vali Loss: 0.3785476 Test Loss: 0.3608202
Validation loss decreased (0.378655 --> 0.378548).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.416306734085083
Epoch: 14, Steps: 59 | Train Loss: 0.6132712 Vali Loss: 0.3796816 Test Loss: 0.3605785
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.384838342666626
Epoch: 15, Steps: 59 | Train Loss: 0.6136826 Vali Loss: 0.3780831 Test Loss: 0.3605262
Validation loss decreased (0.378548 --> 0.378083).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.2929422855377197
Epoch: 16, Steps: 59 | Train Loss: 0.6133221 Vali Loss: 0.3769009 Test Loss: 0.3605184
Validation loss decreased (0.378083 --> 0.376901).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.3268747329711914
Epoch: 17, Steps: 59 | Train Loss: 0.6136107 Vali Loss: 0.3760172 Test Loss: 0.3604947
Validation loss decreased (0.376901 --> 0.376017).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.9942238330841064
Epoch: 18, Steps: 59 | Train Loss: 0.6133282 Vali Loss: 0.3795149 Test Loss: 0.3603787
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.893580675125122
Epoch: 19, Steps: 59 | Train Loss: 0.6121574 Vali Loss: 0.3774615 Test Loss: 0.3603401
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.0475473403930664
Epoch: 20, Steps: 59 | Train Loss: 0.6127655 Vali Loss: 0.3777617 Test Loss: 0.3603474
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.4598188400268555
Epoch: 21, Steps: 59 | Train Loss: 0.6130856 Vali Loss: 0.3771656 Test Loss: 0.3605246
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.7903289794921875
Epoch: 22, Steps: 59 | Train Loss: 0.6130433 Vali Loss: 0.3762937 Test Loss: 0.3604438
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.3353488445281982
Epoch: 23, Steps: 59 | Train Loss: 0.6129280 Vali Loss: 0.3768806 Test Loss: 0.3604663
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.8157131671905518
Epoch: 24, Steps: 59 | Train Loss: 0.6137427 Vali Loss: 0.3771256 Test Loss: 0.3604286
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.925497055053711
Epoch: 25, Steps: 59 | Train Loss: 0.6123302 Vali Loss: 0.3776358 Test Loss: 0.3603401
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.1685874462127686
Epoch: 26, Steps: 59 | Train Loss: 0.6126099 Vali Loss: 0.3795501 Test Loss: 0.3604846
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 3.381174325942993
Epoch: 27, Steps: 59 | Train Loss: 0.6127765 Vali Loss: 0.3776303 Test Loss: 0.3604581
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.4779422283172607
Epoch: 28, Steps: 59 | Train Loss: 0.6137768 Vali Loss: 0.3775533 Test Loss: 0.3603588
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 3.2321982383728027
Epoch: 29, Steps: 59 | Train Loss: 0.6121333 Vali Loss: 0.3771582 Test Loss: 0.3604021
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.4968364238739014
Epoch: 30, Steps: 59 | Train Loss: 0.6126202 Vali Loss: 0.3776571 Test Loss: 0.3602609
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.191298484802246
Epoch: 31, Steps: 59 | Train Loss: 0.6134601 Vali Loss: 0.3764713 Test Loss: 0.3603457
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.9424750804901123
Epoch: 32, Steps: 59 | Train Loss: 0.6113571 Vali Loss: 0.3771663 Test Loss: 0.3602967
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 3.34982967376709
Epoch: 33, Steps: 59 | Train Loss: 0.6123744 Vali Loss: 0.3780650 Test Loss: 0.3603954
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.301483631134033
Epoch: 34, Steps: 59 | Train Loss: 0.6129000 Vali Loss: 0.3780992 Test Loss: 0.3602846
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 3.0068349838256836
Epoch: 35, Steps: 59 | Train Loss: 0.6129882 Vali Loss: 0.3771151 Test Loss: 0.3602375
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 3.5427258014678955
Epoch: 36, Steps: 59 | Train Loss: 0.6133892 Vali Loss: 0.3757115 Test Loss: 0.3602967
Validation loss decreased (0.376017 --> 0.375712).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.6670174598693848
Epoch: 37, Steps: 59 | Train Loss: 0.6118328 Vali Loss: 0.3809966 Test Loss: 0.3603036
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.756899833679199
Epoch: 38, Steps: 59 | Train Loss: 0.6130881 Vali Loss: 0.3778327 Test Loss: 0.3602853
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.784560441970825
Epoch: 39, Steps: 59 | Train Loss: 0.6121799 Vali Loss: 0.3778446 Test Loss: 0.3602993
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.4653077125549316
Epoch: 40, Steps: 59 | Train Loss: 0.6129846 Vali Loss: 0.3767235 Test Loss: 0.3603040
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.382918119430542
Epoch: 41, Steps: 59 | Train Loss: 0.6128745 Vali Loss: 0.3776390 Test Loss: 0.3602823
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 3.5390539169311523
Epoch: 42, Steps: 59 | Train Loss: 0.6131369 Vali Loss: 0.3758558 Test Loss: 0.3602774
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 3.290754795074463
Epoch: 43, Steps: 59 | Train Loss: 0.6136782 Vali Loss: 0.3758754 Test Loss: 0.3602307
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.3017261028289795
Epoch: 44, Steps: 59 | Train Loss: 0.6127716 Vali Loss: 0.3773367 Test Loss: 0.3602330
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 3.0489487648010254
Epoch: 45, Steps: 59 | Train Loss: 0.6126386 Vali Loss: 0.3779096 Test Loss: 0.3602517
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.674187183380127
Epoch: 46, Steps: 59 | Train Loss: 0.6121508 Vali Loss: 0.3759846 Test Loss: 0.3602088
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.658785104751587
Epoch: 47, Steps: 59 | Train Loss: 0.6120789 Vali Loss: 0.3778552 Test Loss: 0.3602392
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.2472920417785645
Epoch: 48, Steps: 59 | Train Loss: 0.6123649 Vali Loss: 0.3762496 Test Loss: 0.3602493
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.948876142501831
Epoch: 49, Steps: 59 | Train Loss: 0.6113096 Vali Loss: 0.3770525 Test Loss: 0.3602419
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.6122560501098633
Epoch: 50, Steps: 59 | Train Loss: 0.6126871 Vali Loss: 0.3798325 Test Loss: 0.3602489
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.882495164871216
Epoch: 51, Steps: 59 | Train Loss: 0.6123304 Vali Loss: 0.3781877 Test Loss: 0.3602431
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.498600482940674
Epoch: 52, Steps: 59 | Train Loss: 0.6132282 Vali Loss: 0.3759478 Test Loss: 0.3602444
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 3.190371036529541
Epoch: 53, Steps: 59 | Train Loss: 0.6121630 Vali Loss: 0.3755010 Test Loss: 0.3602721
Validation loss decreased (0.375712 --> 0.375501).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.6014575958251953
Epoch: 54, Steps: 59 | Train Loss: 0.6129684 Vali Loss: 0.3777436 Test Loss: 0.3602448
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 3.0278379917144775
Epoch: 55, Steps: 59 | Train Loss: 0.6121683 Vali Loss: 0.3727963 Test Loss: 0.3602458
Validation loss decreased (0.375501 --> 0.372796).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.7401769161224365
Epoch: 56, Steps: 59 | Train Loss: 0.6126691 Vali Loss: 0.3760112 Test Loss: 0.3602550
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.4055886268615723
Epoch: 57, Steps: 59 | Train Loss: 0.6127470 Vali Loss: 0.3792560 Test Loss: 0.3602382
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.844243288040161
Epoch: 58, Steps: 59 | Train Loss: 0.6121186 Vali Loss: 0.3783362 Test Loss: 0.3602335
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.7759339809417725
Epoch: 59, Steps: 59 | Train Loss: 0.6124606 Vali Loss: 0.3775629 Test Loss: 0.3602517
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.8184049129486084
Epoch: 60, Steps: 59 | Train Loss: 0.6125143 Vali Loss: 0.3756860 Test Loss: 0.3602602
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.5774824619293213
Epoch: 61, Steps: 59 | Train Loss: 0.6131258 Vali Loss: 0.3774197 Test Loss: 0.3602461
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.621250629425049
Epoch: 62, Steps: 59 | Train Loss: 0.6122654 Vali Loss: 0.3762578 Test Loss: 0.3602476
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.7931907176971436
Epoch: 63, Steps: 59 | Train Loss: 0.6117582 Vali Loss: 0.3782377 Test Loss: 0.3602421
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.998523712158203
Epoch: 64, Steps: 59 | Train Loss: 0.6117949 Vali Loss: 0.3746167 Test Loss: 0.3602560
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.559117555618286
Epoch: 65, Steps: 59 | Train Loss: 0.6125333 Vali Loss: 0.3768655 Test Loss: 0.3602451
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.6914639472961426
Epoch: 66, Steps: 59 | Train Loss: 0.6127533 Vali Loss: 0.3780224 Test Loss: 0.3602248
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.4440648555755615
Epoch: 67, Steps: 59 | Train Loss: 0.6126282 Vali Loss: 0.3786970 Test Loss: 0.3602419
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 3.6080942153930664
Epoch: 68, Steps: 59 | Train Loss: 0.6122096 Vali Loss: 0.3783687 Test Loss: 0.3602425
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.3047900199890137
Epoch: 69, Steps: 59 | Train Loss: 0.6106272 Vali Loss: 0.3780455 Test Loss: 0.3602378
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.1076395511627197
Epoch: 70, Steps: 59 | Train Loss: 0.6107005 Vali Loss: 0.3751713 Test Loss: 0.3602359
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 3.0513031482696533
Epoch: 71, Steps: 59 | Train Loss: 0.6117075 Vali Loss: 0.3748984 Test Loss: 0.3602345
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.7830653190612793
Epoch: 72, Steps: 59 | Train Loss: 0.6116800 Vali Loss: 0.3782955 Test Loss: 0.3602273
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 3.1266462802886963
Epoch: 73, Steps: 59 | Train Loss: 0.6117007 Vali Loss: 0.3772929 Test Loss: 0.3602294
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 3.4874227046966553
Epoch: 74, Steps: 59 | Train Loss: 0.6123844 Vali Loss: 0.3782378 Test Loss: 0.3602286
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.9184257984161377
Epoch: 75, Steps: 59 | Train Loss: 0.6121418 Vali Loss: 0.3749141 Test Loss: 0.3602275
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_720_336_FITS_ETTh2_ftM_sl720_ll48_pl336_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.3559722900390625, mae:0.396344929933548, rse:0.4770321249961853, corr:[0.26109102 0.2637613  0.2636097  0.26201874 0.26076683 0.2604481
 0.26063415 0.26026845 0.25914407 0.25738204 0.25573704 0.25442314
 0.25369596 0.25318417 0.25254896 0.25165257 0.2505339  0.24948551
 0.2486738  0.24805208 0.24735369 0.24623275 0.24463944 0.24284026
 0.2412137  0.24009003 0.23936553 0.23863412 0.23763289 0.23641554
 0.2351885  0.23409541 0.23316918 0.23247175 0.2317415  0.23083055
 0.22976443 0.22884344 0.22820829 0.2276918  0.22715816 0.22642538
 0.22545993 0.22441606 0.22339155 0.22232787 0.22110397 0.21950056
 0.21763992 0.2159368  0.21448797 0.21299234 0.21155715 0.21002528
 0.20803645 0.20591992 0.20404743 0.20248228 0.20130362 0.20050561
 0.20002954 0.19968942 0.19941953 0.19925268 0.19872732 0.19820574
 0.19759038 0.19702932 0.1964549  0.19602105 0.19539712 0.19459324
 0.19356039 0.19243914 0.19143312 0.1904135  0.18964267 0.189043
 0.18853436 0.18784952 0.18741336 0.18711747 0.18676549 0.18638131
 0.1860828  0.1858137  0.18542449 0.18491074 0.18426494 0.18379827
 0.18366653 0.1835751  0.18369417 0.1837655  0.18358615 0.1831398
 0.18246047 0.18165013 0.18099895 0.18038711 0.17982362 0.17925578
 0.17895721 0.17868188 0.17858686 0.17844526 0.17830344 0.17807922
 0.17746396 0.17673051 0.1760165  0.1756543  0.17534062 0.17513002
 0.1747787  0.17418438 0.17348674 0.17243557 0.17129251 0.17001173
 0.16875234 0.16755491 0.16659233 0.16590108 0.16520269 0.16451177
 0.16371714 0.16291158 0.16211668 0.16130911 0.16061908 0.15995689
 0.15945935 0.15897892 0.15852046 0.15805624 0.1574499  0.15685217
 0.15632294 0.15587208 0.15550582 0.15496291 0.15410693 0.15287921
 0.15130223 0.14977488 0.1484723  0.14742653 0.14651795 0.14575538
 0.14508195 0.14424048 0.14350425 0.14283966 0.14217444 0.14143622
 0.14094315 0.14077042 0.1407568  0.14069843 0.14020348 0.13962196
 0.13914269 0.13889684 0.13883089 0.13863206 0.13816999 0.13724901
 0.13614534 0.13496695 0.13391164 0.13289914 0.13195188 0.13077246
 0.1296166  0.12831435 0.1271433  0.12627663 0.12556688 0.12510023
 0.1247766  0.12452225 0.1242746  0.12404772 0.12348977 0.12300309
 0.12280489 0.12282064 0.12309884 0.12337686 0.12375332 0.12376756
 0.12346707 0.12303536 0.12245199 0.12195721 0.12147904 0.1209596
 0.12053316 0.12016229 0.11997197 0.1197985  0.11953647 0.11907568
 0.11860991 0.11850134 0.11861619 0.11895675 0.11922607 0.11941713
 0.1194522  0.11957803 0.11984604 0.12003333 0.11996233 0.11931089
 0.11825841 0.11712686 0.11619551 0.11582221 0.11572238 0.11604437
 0.11616424 0.11624824 0.11605857 0.11568815 0.11529586 0.11486575
 0.11442738 0.11413545 0.11390136 0.1140495  0.1143477  0.1149087
 0.11552408 0.11615013 0.11658861 0.11682695 0.11686871 0.11668938
 0.11627403 0.11571398 0.11522192 0.115179   0.11522162 0.11503988
 0.11493584 0.11487745 0.1150299  0.11528531 0.11556598 0.11592938
 0.1162153  0.11682869 0.11758515 0.11888312 0.1200193  0.12106194
 0.12151355 0.12163869 0.12183373 0.12196341 0.12269761 0.1235866
 0.12440612 0.12457089 0.12438585 0.12416729 0.12389323 0.1237867
 0.12388401 0.12410693 0.12440269 0.1241384  0.12387427 0.12340639
 0.1231958  0.12328269 0.12363721 0.12408876 0.12435311 0.12420271
 0.12366293 0.12322665 0.12302029 0.12304654 0.12333712 0.12363356
 0.12356874 0.12302703 0.1220931  0.12120744 0.12042981 0.11954187
 0.11883921 0.11831982 0.11805109 0.11760664 0.11729426 0.11695277
 0.11640211 0.11627413 0.11657955 0.11741915 0.11778847 0.1182047
 0.11816567 0.11815974 0.11816894 0.11836922 0.11865469 0.11868263
 0.11855827 0.1178873  0.11708983 0.11602143 0.11499812 0.11433534
 0.11431335 0.11472689 0.11461151 0.11430873 0.11403341 0.11430155
 0.1146802  0.11517469 0.1159714  0.11652644 0.11627939 0.11536422
 0.11453432 0.11463916 0.11561035 0.11602788 0.11495485 0.110875  ]
