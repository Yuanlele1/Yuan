Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=30, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_90_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_90_96_FITS_ETTh2_ftM_sl90_ll48_pl96_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8455
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=30, out_features=62, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1666560.0
params:  1922.0
Trainable parameters:  1922
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.9373908042907715
Epoch: 1, Steps: 66 | Train Loss: 0.4535036 Vali Loss: 0.2974858 Test Loss: 0.3980207
Validation loss decreased (inf --> 0.297486).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.4493634700775146
Epoch: 2, Steps: 66 | Train Loss: 0.3814670 Vali Loss: 0.2749709 Test Loss: 0.3655951
Validation loss decreased (0.297486 --> 0.274971).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.0251100063323975
Epoch: 3, Steps: 66 | Train Loss: 0.3394977 Vali Loss: 0.2616208 Test Loss: 0.3459766
Validation loss decreased (0.274971 --> 0.261621).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.9779303073883057
Epoch: 4, Steps: 66 | Train Loss: 0.3127245 Vali Loss: 0.2527046 Test Loss: 0.3331381
Validation loss decreased (0.261621 --> 0.252705).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.542057752609253
Epoch: 5, Steps: 66 | Train Loss: 0.2948361 Vali Loss: 0.2453550 Test Loss: 0.3244488
Validation loss decreased (0.252705 --> 0.245355).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.401735782623291
Epoch: 6, Steps: 66 | Train Loss: 0.2820540 Vali Loss: 0.2406410 Test Loss: 0.3184207
Validation loss decreased (0.245355 --> 0.240641).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.5524239540100098
Epoch: 7, Steps: 66 | Train Loss: 0.2727627 Vali Loss: 0.2371448 Test Loss: 0.3139824
Validation loss decreased (0.240641 --> 0.237145).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.300668954849243
Epoch: 8, Steps: 66 | Train Loss: 0.2655189 Vali Loss: 0.2334906 Test Loss: 0.3107391
Validation loss decreased (0.237145 --> 0.233491).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.336000442504883
Epoch: 9, Steps: 66 | Train Loss: 0.2601928 Vali Loss: 0.2307205 Test Loss: 0.3081592
Validation loss decreased (0.233491 --> 0.230720).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.901998519897461
Epoch: 10, Steps: 66 | Train Loss: 0.2559662 Vali Loss: 0.2296623 Test Loss: 0.3061664
Validation loss decreased (0.230720 --> 0.229662).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.034428834915161
Epoch: 11, Steps: 66 | Train Loss: 0.2524931 Vali Loss: 0.2276833 Test Loss: 0.3045021
Validation loss decreased (0.229662 --> 0.227683).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.8522114753723145
Epoch: 12, Steps: 66 | Train Loss: 0.2489476 Vali Loss: 0.2275123 Test Loss: 0.3031712
Validation loss decreased (0.227683 --> 0.227512).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.9138636589050293
Epoch: 13, Steps: 66 | Train Loss: 0.2470882 Vali Loss: 0.2261354 Test Loss: 0.3020113
Validation loss decreased (0.227512 --> 0.226135).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.057847261428833
Epoch: 14, Steps: 66 | Train Loss: 0.2451590 Vali Loss: 0.2255554 Test Loss: 0.3010482
Validation loss decreased (0.226135 --> 0.225555).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.278934955596924
Epoch: 15, Steps: 66 | Train Loss: 0.2433003 Vali Loss: 0.2246111 Test Loss: 0.3001907
Validation loss decreased (0.225555 --> 0.224611).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.566849708557129
Epoch: 16, Steps: 66 | Train Loss: 0.2418514 Vali Loss: 0.2235787 Test Loss: 0.2994521
Validation loss decreased (0.224611 --> 0.223579).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.5688905715942383
Epoch: 17, Steps: 66 | Train Loss: 0.2405525 Vali Loss: 0.2222259 Test Loss: 0.2988055
Validation loss decreased (0.223579 --> 0.222226).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.333543062210083
Epoch: 18, Steps: 66 | Train Loss: 0.2388360 Vali Loss: 0.2218046 Test Loss: 0.2982304
Validation loss decreased (0.222226 --> 0.221805).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.7654507160186768
Epoch: 19, Steps: 66 | Train Loss: 0.2383521 Vali Loss: 0.2222513 Test Loss: 0.2977332
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.882601499557495
Epoch: 20, Steps: 66 | Train Loss: 0.2373402 Vali Loss: 0.2211743 Test Loss: 0.2972827
Validation loss decreased (0.221805 --> 0.221174).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.2213382720947266
Epoch: 21, Steps: 66 | Train Loss: 0.2367038 Vali Loss: 0.2205892 Test Loss: 0.2968590
Validation loss decreased (0.221174 --> 0.220589).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.8004026412963867
Epoch: 22, Steps: 66 | Train Loss: 0.2358601 Vali Loss: 0.2206917 Test Loss: 0.2965139
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.6675944328308105
Epoch: 23, Steps: 66 | Train Loss: 0.2351521 Vali Loss: 0.2203652 Test Loss: 0.2961712
Validation loss decreased (0.220589 --> 0.220365).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.8340086936950684
Epoch: 24, Steps: 66 | Train Loss: 0.2346973 Vali Loss: 0.2197990 Test Loss: 0.2958813
Validation loss decreased (0.220365 --> 0.219799).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 3.5511178970336914
Epoch: 25, Steps: 66 | Train Loss: 0.2342133 Vali Loss: 0.2194887 Test Loss: 0.2956088
Validation loss decreased (0.219799 --> 0.219489).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.240577459335327
Epoch: 26, Steps: 66 | Train Loss: 0.2331070 Vali Loss: 0.2188587 Test Loss: 0.2953703
Validation loss decreased (0.219489 --> 0.218859).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 3.3327438831329346
Epoch: 27, Steps: 66 | Train Loss: 0.2330097 Vali Loss: 0.2179409 Test Loss: 0.2951517
Validation loss decreased (0.218859 --> 0.217941).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.465679883956909
Epoch: 28, Steps: 66 | Train Loss: 0.2329429 Vali Loss: 0.2178739 Test Loss: 0.2949423
Validation loss decreased (0.217941 --> 0.217874).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.0665743350982666
Epoch: 29, Steps: 66 | Train Loss: 0.2323999 Vali Loss: 0.2184708 Test Loss: 0.2947570
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 3.7348108291625977
Epoch: 30, Steps: 66 | Train Loss: 0.2321554 Vali Loss: 0.2179719 Test Loss: 0.2945938
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.5179829597473145
Epoch: 31, Steps: 66 | Train Loss: 0.2318110 Vali Loss: 0.2179365 Test Loss: 0.2944402
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 5.708071947097778
Epoch: 32, Steps: 66 | Train Loss: 0.2315801 Vali Loss: 0.2180261 Test Loss: 0.2942949
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.9190762042999268
Epoch: 33, Steps: 66 | Train Loss: 0.2313587 Vali Loss: 0.2179926 Test Loss: 0.2941787
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.028956174850464
Epoch: 34, Steps: 66 | Train Loss: 0.2310951 Vali Loss: 0.2178600 Test Loss: 0.2940477
Validation loss decreased (0.217874 --> 0.217860).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 3.558645725250244
Epoch: 35, Steps: 66 | Train Loss: 0.2308352 Vali Loss: 0.2173830 Test Loss: 0.2939497
Validation loss decreased (0.217860 --> 0.217383).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 3.363198757171631
Epoch: 36, Steps: 66 | Train Loss: 0.2306865 Vali Loss: 0.2173860 Test Loss: 0.2938432
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.6343307495117188
Epoch: 37, Steps: 66 | Train Loss: 0.2304774 Vali Loss: 0.2159468 Test Loss: 0.2937464
Validation loss decreased (0.217383 --> 0.215947).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.519252300262451
Epoch: 38, Steps: 66 | Train Loss: 0.2303096 Vali Loss: 0.2172983 Test Loss: 0.2936582
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.2803828716278076
Epoch: 39, Steps: 66 | Train Loss: 0.2301433 Vali Loss: 0.2169594 Test Loss: 0.2935803
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.7861251831054688
Epoch: 40, Steps: 66 | Train Loss: 0.2299570 Vali Loss: 0.2168657 Test Loss: 0.2935199
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.0977964401245117
Epoch: 41, Steps: 66 | Train Loss: 0.2296668 Vali Loss: 0.2170692 Test Loss: 0.2934407
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.1677424907684326
Epoch: 42, Steps: 66 | Train Loss: 0.2297259 Vali Loss: 0.2168688 Test Loss: 0.2933702
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.9923431873321533
Epoch: 43, Steps: 66 | Train Loss: 0.2295581 Vali Loss: 0.2164799 Test Loss: 0.2933066
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.611194133758545
Epoch: 44, Steps: 66 | Train Loss: 0.2293776 Vali Loss: 0.2165093 Test Loss: 0.2932629
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.8783953189849854
Epoch: 45, Steps: 66 | Train Loss: 0.2293078 Vali Loss: 0.2165293 Test Loss: 0.2932082
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.8803870677948
Epoch: 46, Steps: 66 | Train Loss: 0.2292838 Vali Loss: 0.2158979 Test Loss: 0.2931583
Validation loss decreased (0.215947 --> 0.215898).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.8630497455596924
Epoch: 47, Steps: 66 | Train Loss: 0.2290464 Vali Loss: 0.2162052 Test Loss: 0.2931156
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 3.1395230293273926
Epoch: 48, Steps: 66 | Train Loss: 0.2289402 Vali Loss: 0.2150503 Test Loss: 0.2930737
Validation loss decreased (0.215898 --> 0.215050).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 3.1882598400115967
Epoch: 49, Steps: 66 | Train Loss: 0.2289416 Vali Loss: 0.2157309 Test Loss: 0.2930287
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 3.1352312564849854
Epoch: 50, Steps: 66 | Train Loss: 0.2289235 Vali Loss: 0.2162412 Test Loss: 0.2929949
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 3.1791365146636963
Epoch: 51, Steps: 66 | Train Loss: 0.2288339 Vali Loss: 0.2152554 Test Loss: 0.2929535
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.8603174686431885
Epoch: 52, Steps: 66 | Train Loss: 0.2287007 Vali Loss: 0.2146205 Test Loss: 0.2929248
Validation loss decreased (0.215050 --> 0.214620).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 3.2701988220214844
Epoch: 53, Steps: 66 | Train Loss: 0.2277772 Vali Loss: 0.2157812 Test Loss: 0.2929023
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.8494248390197754
Epoch: 54, Steps: 66 | Train Loss: 0.2285640 Vali Loss: 0.2155948 Test Loss: 0.2928729
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.3597307205200195
Epoch: 55, Steps: 66 | Train Loss: 0.2284149 Vali Loss: 0.2154204 Test Loss: 0.2928480
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.7941651344299316
Epoch: 56, Steps: 66 | Train Loss: 0.2283795 Vali Loss: 0.2151571 Test Loss: 0.2928249
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.9076683521270752
Epoch: 57, Steps: 66 | Train Loss: 0.2284696 Vali Loss: 0.2152504 Test Loss: 0.2927976
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.153118848800659
Epoch: 58, Steps: 66 | Train Loss: 0.2278315 Vali Loss: 0.2155423 Test Loss: 0.2927790
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.3231141567230225
Epoch: 59, Steps: 66 | Train Loss: 0.2283423 Vali Loss: 0.2149231 Test Loss: 0.2927576
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 3.0261456966400146
Epoch: 60, Steps: 66 | Train Loss: 0.2282907 Vali Loss: 0.2160274 Test Loss: 0.2927375
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 3.348630905151367
Epoch: 61, Steps: 66 | Train Loss: 0.2273990 Vali Loss: 0.2157607 Test Loss: 0.2927167
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 4.333081007003784
Epoch: 62, Steps: 66 | Train Loss: 0.2281737 Vali Loss: 0.2156920 Test Loss: 0.2926987
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 4.389059543609619
Epoch: 63, Steps: 66 | Train Loss: 0.2274879 Vali Loss: 0.2158304 Test Loss: 0.2926860
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 3.1204800605773926
Epoch: 64, Steps: 66 | Train Loss: 0.2279957 Vali Loss: 0.2143643 Test Loss: 0.2926704
Validation loss decreased (0.214620 --> 0.214364).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 3.7630579471588135
Epoch: 65, Steps: 66 | Train Loss: 0.2281592 Vali Loss: 0.2153342 Test Loss: 0.2926562
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 3.434844493865967
Epoch: 66, Steps: 66 | Train Loss: 0.2280724 Vali Loss: 0.2163872 Test Loss: 0.2926390
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.5751914978027344
Epoch: 67, Steps: 66 | Train Loss: 0.2281051 Vali Loss: 0.2156217 Test Loss: 0.2926286
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.323556900024414
Epoch: 68, Steps: 66 | Train Loss: 0.2280722 Vali Loss: 0.2153697 Test Loss: 0.2926170
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 3.6660242080688477
Epoch: 69, Steps: 66 | Train Loss: 0.2280039 Vali Loss: 0.2152758 Test Loss: 0.2926053
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.7405500411987305
Epoch: 70, Steps: 66 | Train Loss: 0.2280246 Vali Loss: 0.2154431 Test Loss: 0.2925982
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 5.246837854385376
Epoch: 71, Steps: 66 | Train Loss: 0.2279186 Vali Loss: 0.2158289 Test Loss: 0.2925866
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.517413854598999
Epoch: 72, Steps: 66 | Train Loss: 0.2279293 Vali Loss: 0.2151091 Test Loss: 0.2925767
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.49330735206604
Epoch: 73, Steps: 66 | Train Loss: 0.2278055 Vali Loss: 0.2158692 Test Loss: 0.2925674
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 4.293730735778809
Epoch: 74, Steps: 66 | Train Loss: 0.2278800 Vali Loss: 0.2151773 Test Loss: 0.2925583
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 3.5594968795776367
Epoch: 75, Steps: 66 | Train Loss: 0.2278693 Vali Loss: 0.2158231 Test Loss: 0.2925501
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 3.9608402252197266
Epoch: 76, Steps: 66 | Train Loss: 0.2276903 Vali Loss: 0.2152311 Test Loss: 0.2925439
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.6880593299865723
Epoch: 77, Steps: 66 | Train Loss: 0.2278062 Vali Loss: 0.2157960 Test Loss: 0.2925364
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 3.8989651203155518
Epoch: 78, Steps: 66 | Train Loss: 0.2276801 Vali Loss: 0.2154769 Test Loss: 0.2925288
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 3.0399081707000732
Epoch: 79, Steps: 66 | Train Loss: 0.2276966 Vali Loss: 0.2156135 Test Loss: 0.2925241
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.3658876419067383
Epoch: 80, Steps: 66 | Train Loss: 0.2278250 Vali Loss: 0.2150748 Test Loss: 0.2925186
EarlyStopping counter: 16 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.3542943000793457
Epoch: 81, Steps: 66 | Train Loss: 0.2277336 Vali Loss: 0.2151731 Test Loss: 0.2925116
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 2.873647451400757
Epoch: 82, Steps: 66 | Train Loss: 0.2277475 Vali Loss: 0.2151850 Test Loss: 0.2925046
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.925565481185913
Epoch: 83, Steps: 66 | Train Loss: 0.2277628 Vali Loss: 0.2161165 Test Loss: 0.2925005
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.22285532951355
Epoch: 84, Steps: 66 | Train Loss: 0.2277369 Vali Loss: 0.2151355 Test Loss: 0.2924956
EarlyStopping counter: 20 out of 20
Early stopping
train 8455
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=30, out_features=62, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1666560.0
params:  1922.0
Trainable parameters:  1922
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.7181599140167236
Epoch: 1, Steps: 66 | Train Loss: 0.4249533 Vali Loss: 0.2145313 Test Loss: 0.2914459
Validation loss decreased (inf --> 0.214531).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.960160732269287
Epoch: 2, Steps: 66 | Train Loss: 0.4238671 Vali Loss: 0.2134089 Test Loss: 0.2910792
Validation loss decreased (0.214531 --> 0.213409).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.062023401260376
Epoch: 3, Steps: 66 | Train Loss: 0.4227295 Vali Loss: 0.2126535 Test Loss: 0.2907400
Validation loss decreased (0.213409 --> 0.212654).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.7771620750427246
Epoch: 4, Steps: 66 | Train Loss: 0.4219038 Vali Loss: 0.2135191 Test Loss: 0.2906312
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.620587110519409
Epoch: 5, Steps: 66 | Train Loss: 0.4214469 Vali Loss: 0.2132914 Test Loss: 0.2905246
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.9989724159240723
Epoch: 6, Steps: 66 | Train Loss: 0.4209377 Vali Loss: 0.2130607 Test Loss: 0.2903538
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.049590826034546
Epoch: 7, Steps: 66 | Train Loss: 0.4201722 Vali Loss: 0.2125519 Test Loss: 0.2902917
Validation loss decreased (0.212654 --> 0.212552).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.272634267807007
Epoch: 8, Steps: 66 | Train Loss: 0.4201829 Vali Loss: 0.2113309 Test Loss: 0.2902297
Validation loss decreased (0.212552 --> 0.211331).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.3165605068206787
Epoch: 9, Steps: 66 | Train Loss: 0.4199470 Vali Loss: 0.2118500 Test Loss: 0.2901912
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.4689199924468994
Epoch: 10, Steps: 66 | Train Loss: 0.4197535 Vali Loss: 0.2119238 Test Loss: 0.2901152
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.9725778102874756
Epoch: 11, Steps: 66 | Train Loss: 0.4191761 Vali Loss: 0.2113813 Test Loss: 0.2900625
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.0013716220855713
Epoch: 12, Steps: 66 | Train Loss: 0.4192482 Vali Loss: 0.2118428 Test Loss: 0.2900541
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.4197745323181152
Epoch: 13, Steps: 66 | Train Loss: 0.4190886 Vali Loss: 0.2108321 Test Loss: 0.2900408
Validation loss decreased (0.211331 --> 0.210832).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.523081064224243
Epoch: 14, Steps: 66 | Train Loss: 0.4189458 Vali Loss: 0.2120904 Test Loss: 0.2900064
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.094553232192993
Epoch: 15, Steps: 66 | Train Loss: 0.4188110 Vali Loss: 0.2111063 Test Loss: 0.2900117
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.440176010131836
Epoch: 16, Steps: 66 | Train Loss: 0.4187223 Vali Loss: 0.2119296 Test Loss: 0.2899600
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.8206822872161865
Epoch: 17, Steps: 66 | Train Loss: 0.4176345 Vali Loss: 0.2119598 Test Loss: 0.2899477
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.0312371253967285
Epoch: 18, Steps: 66 | Train Loss: 0.4186103 Vali Loss: 0.2116269 Test Loss: 0.2899692
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.557048797607422
Epoch: 19, Steps: 66 | Train Loss: 0.4185214 Vali Loss: 0.2116131 Test Loss: 0.2899185
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.8543119430541992
Epoch: 20, Steps: 66 | Train Loss: 0.4182840 Vali Loss: 0.2113587 Test Loss: 0.2898919
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.8480794429779053
Epoch: 21, Steps: 66 | Train Loss: 0.4184573 Vali Loss: 0.2107606 Test Loss: 0.2898986
Validation loss decreased (0.210832 --> 0.210761).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.7431771755218506
Epoch: 22, Steps: 66 | Train Loss: 0.4170254 Vali Loss: 0.2113409 Test Loss: 0.2898681
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.9354002475738525
Epoch: 23, Steps: 66 | Train Loss: 0.4180416 Vali Loss: 0.2113390 Test Loss: 0.2898590
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.8773727416992188
Epoch: 24, Steps: 66 | Train Loss: 0.4177934 Vali Loss: 0.2111818 Test Loss: 0.2898510
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 3.189115047454834
Epoch: 25, Steps: 66 | Train Loss: 0.4180817 Vali Loss: 0.2120622 Test Loss: 0.2898340
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.6198201179504395
Epoch: 26, Steps: 66 | Train Loss: 0.4179998 Vali Loss: 0.2120808 Test Loss: 0.2898632
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 5.020526170730591
Epoch: 27, Steps: 66 | Train Loss: 0.4180514 Vali Loss: 0.2114433 Test Loss: 0.2898866
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.135127544403076
Epoch: 28, Steps: 66 | Train Loss: 0.4181562 Vali Loss: 0.2110790 Test Loss: 0.2898529
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 3.5470919609069824
Epoch: 29, Steps: 66 | Train Loss: 0.4180323 Vali Loss: 0.2113043 Test Loss: 0.2898514
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.699921131134033
Epoch: 30, Steps: 66 | Train Loss: 0.4177655 Vali Loss: 0.2113436 Test Loss: 0.2898307
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 5.0000810623168945
Epoch: 31, Steps: 66 | Train Loss: 0.4178396 Vali Loss: 0.2113365 Test Loss: 0.2898422
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.9798481464385986
Epoch: 32, Steps: 66 | Train Loss: 0.4179247 Vali Loss: 0.2119831 Test Loss: 0.2898503
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.223555564880371
Epoch: 33, Steps: 66 | Train Loss: 0.4178971 Vali Loss: 0.2104863 Test Loss: 0.2898192
Validation loss decreased (0.210761 --> 0.210486).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.133927583694458
Epoch: 34, Steps: 66 | Train Loss: 0.4179153 Vali Loss: 0.2102851 Test Loss: 0.2898202
Validation loss decreased (0.210486 --> 0.210285).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.9286437034606934
Epoch: 35, Steps: 66 | Train Loss: 0.4178764 Vali Loss: 0.2108641 Test Loss: 0.2898161
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.9755587577819824
Epoch: 36, Steps: 66 | Train Loss: 0.4178985 Vali Loss: 0.2102375 Test Loss: 0.2898226
Validation loss decreased (0.210285 --> 0.210237).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.665677785873413
Epoch: 37, Steps: 66 | Train Loss: 0.4177713 Vali Loss: 0.2107320 Test Loss: 0.2898266
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.2472832202911377
Epoch: 38, Steps: 66 | Train Loss: 0.4177418 Vali Loss: 0.2112397 Test Loss: 0.2898152
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.6134536266326904
Epoch: 39, Steps: 66 | Train Loss: 0.4176030 Vali Loss: 0.2110595 Test Loss: 0.2898146
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.1287577152252197
Epoch: 40, Steps: 66 | Train Loss: 0.4172895 Vali Loss: 0.2109359 Test Loss: 0.2898103
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.4278409481048584
Epoch: 41, Steps: 66 | Train Loss: 0.4177661 Vali Loss: 0.2100505 Test Loss: 0.2898017
Validation loss decreased (0.210237 --> 0.210051).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.6070823669433594
Epoch: 42, Steps: 66 | Train Loss: 0.4172632 Vali Loss: 0.2116042 Test Loss: 0.2897881
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.8607351779937744
Epoch: 43, Steps: 66 | Train Loss: 0.4175806 Vali Loss: 0.2095412 Test Loss: 0.2898021
Validation loss decreased (0.210051 --> 0.209541).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.8726811408996582
Epoch: 44, Steps: 66 | Train Loss: 0.4176544 Vali Loss: 0.2097488 Test Loss: 0.2897839
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.8342018127441406
Epoch: 45, Steps: 66 | Train Loss: 0.4175927 Vali Loss: 0.2114795 Test Loss: 0.2897957
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.339906930923462
Epoch: 46, Steps: 66 | Train Loss: 0.4177345 Vali Loss: 0.2104909 Test Loss: 0.2897895
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.4723548889160156
Epoch: 47, Steps: 66 | Train Loss: 0.4171712 Vali Loss: 0.2113884 Test Loss: 0.2897843
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.4426629543304443
Epoch: 48, Steps: 66 | Train Loss: 0.4176824 Vali Loss: 0.2120862 Test Loss: 0.2897819
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.406160354614258
Epoch: 49, Steps: 66 | Train Loss: 0.4175942 Vali Loss: 0.2102615 Test Loss: 0.2897819
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 3.252903938293457
Epoch: 50, Steps: 66 | Train Loss: 0.4166896 Vali Loss: 0.2113979 Test Loss: 0.2897793
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 3.2162764072418213
Epoch: 51, Steps: 66 | Train Loss: 0.4176207 Vali Loss: 0.2108873 Test Loss: 0.2897821
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.423292875289917
Epoch: 52, Steps: 66 | Train Loss: 0.4170759 Vali Loss: 0.2108168 Test Loss: 0.2897792
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 3.6180758476257324
Epoch: 53, Steps: 66 | Train Loss: 0.4175955 Vali Loss: 0.2113588 Test Loss: 0.2897858
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 3.1175692081451416
Epoch: 54, Steps: 66 | Train Loss: 0.4170169 Vali Loss: 0.2115144 Test Loss: 0.2897706
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 3.9953370094299316
Epoch: 55, Steps: 66 | Train Loss: 0.4176610 Vali Loss: 0.2117843 Test Loss: 0.2897748
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.9885032176971436
Epoch: 56, Steps: 66 | Train Loss: 0.4175736 Vali Loss: 0.2104126 Test Loss: 0.2897776
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 3.09025239944458
Epoch: 57, Steps: 66 | Train Loss: 0.4176423 Vali Loss: 0.2107964 Test Loss: 0.2897715
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.188291549682617
Epoch: 58, Steps: 66 | Train Loss: 0.4170782 Vali Loss: 0.2112529 Test Loss: 0.2897722
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.2751996517181396
Epoch: 59, Steps: 66 | Train Loss: 0.4173800 Vali Loss: 0.2116385 Test Loss: 0.2897620
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.8930270671844482
Epoch: 60, Steps: 66 | Train Loss: 0.4175728 Vali Loss: 0.2106268 Test Loss: 0.2897771
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.1738462448120117
Epoch: 61, Steps: 66 | Train Loss: 0.4175858 Vali Loss: 0.2111336 Test Loss: 0.2897726
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.0949854850769043
Epoch: 62, Steps: 66 | Train Loss: 0.4174952 Vali Loss: 0.2112806 Test Loss: 0.2897729
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 5.250179767608643
Epoch: 63, Steps: 66 | Train Loss: 0.4174337 Vali Loss: 0.2113159 Test Loss: 0.2897659
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_90_96_FITS_ETTh2_ftM_sl90_ll48_pl96_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.29036903381347656, mae:0.3388461172580719, rse:0.4342666268348694, corr:[0.2763299  0.27764475 0.27527854 0.27576146 0.27388903 0.27275133
 0.27252537 0.27113628 0.27040094 0.26958415 0.26836833 0.26693335
 0.26509467 0.26362827 0.26266894 0.26196682 0.2614327  0.26114973
 0.26052904 0.25946584 0.25855494 0.25761306 0.2566255  0.25482374
 0.2517258  0.24912687 0.24671796 0.24523732 0.2439736  0.24245884
 0.24157116 0.24032657 0.2386449  0.23710226 0.23616986 0.23470576
 0.23305161 0.23183273 0.2305977  0.22969821 0.22907531 0.22852688
 0.22844344 0.22774129 0.22673628 0.22607717 0.22547778 0.22351535
 0.2200422  0.21742079 0.21474558 0.21288759 0.21149278 0.20972294
 0.2082784  0.20588686 0.20435548 0.2029685  0.20173067 0.20022863
 0.19927041 0.1988714  0.19848336 0.1987932  0.19851881 0.1978104
 0.19772172 0.19685972 0.19621746 0.1963504  0.19561055 0.19392411
 0.19165817 0.19015217 0.18840154 0.1876176  0.18657929 0.1858782
 0.1863341  0.18495627 0.18413325 0.18419978 0.18382047 0.18316105
 0.1827332  0.18214417 0.18219519 0.18307525 0.181779   0.1812358
 0.18190132 0.17949568 0.17943369 0.18065736 0.17799404 0.1815402 ]
