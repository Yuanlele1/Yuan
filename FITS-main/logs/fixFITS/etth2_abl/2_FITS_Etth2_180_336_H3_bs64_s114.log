Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=34, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_180_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_180_336_FITS_ETTh2_ftM_sl180_ll48_pl336_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8125
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=34, out_features=97, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2955008.0
params:  3395.0
Trainable parameters:  3395
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.7923054695129395
Epoch: 1, Steps: 63 | Train Loss: 0.7275247 Vali Loss: 0.4884491 Test Loss: 0.5205351
Validation loss decreased (inf --> 0.488449).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.627946138381958
Epoch: 2, Steps: 63 | Train Loss: 0.6147802 Vali Loss: 0.4474084 Test Loss: 0.4785285
Validation loss decreased (0.488449 --> 0.447408).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.9112930297851562
Epoch: 3, Steps: 63 | Train Loss: 0.5515849 Vali Loss: 0.4266184 Test Loss: 0.4539044
Validation loss decreased (0.447408 --> 0.426618).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.8092684745788574
Epoch: 4, Steps: 63 | Train Loss: 0.5125915 Vali Loss: 0.4132529 Test Loss: 0.4386986
Validation loss decreased (0.426618 --> 0.413253).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.213742256164551
Epoch: 5, Steps: 63 | Train Loss: 0.4864065 Vali Loss: 0.4051214 Test Loss: 0.4285063
Validation loss decreased (0.413253 --> 0.405121).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.1037657260894775
Epoch: 6, Steps: 63 | Train Loss: 0.4711678 Vali Loss: 0.3951306 Test Loss: 0.4213943
Validation loss decreased (0.405121 --> 0.395131).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.8346021175384521
Epoch: 7, Steps: 63 | Train Loss: 0.4589888 Vali Loss: 0.3922869 Test Loss: 0.4166066
Validation loss decreased (0.395131 --> 0.392287).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.311204433441162
Epoch: 8, Steps: 63 | Train Loss: 0.4499801 Vali Loss: 0.3887971 Test Loss: 0.4130067
Validation loss decreased (0.392287 --> 0.388797).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.138277292251587
Epoch: 9, Steps: 63 | Train Loss: 0.4449354 Vali Loss: 0.3855965 Test Loss: 0.4102732
Validation loss decreased (0.388797 --> 0.385597).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.2516231536865234
Epoch: 10, Steps: 63 | Train Loss: 0.4407128 Vali Loss: 0.3850410 Test Loss: 0.4083576
Validation loss decreased (0.385597 --> 0.385041).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.712752103805542
Epoch: 11, Steps: 63 | Train Loss: 0.4367058 Vali Loss: 0.3794245 Test Loss: 0.4066699
Validation loss decreased (0.385041 --> 0.379425).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.8808610439300537
Epoch: 12, Steps: 63 | Train Loss: 0.4338807 Vali Loss: 0.3810191 Test Loss: 0.4053959
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.913221836090088
Epoch: 13, Steps: 63 | Train Loss: 0.4306649 Vali Loss: 0.3804285 Test Loss: 0.4042918
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.8093509674072266
Epoch: 14, Steps: 63 | Train Loss: 0.4288870 Vali Loss: 0.3773906 Test Loss: 0.4033759
Validation loss decreased (0.379425 --> 0.377391).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.1866867542266846
Epoch: 15, Steps: 63 | Train Loss: 0.4283558 Vali Loss: 0.3757754 Test Loss: 0.4026548
Validation loss decreased (0.377391 --> 0.375775).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.0167524814605713
Epoch: 16, Steps: 63 | Train Loss: 0.4248713 Vali Loss: 0.3784095 Test Loss: 0.4020405
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.6419439315795898
Epoch: 17, Steps: 63 | Train Loss: 0.4245457 Vali Loss: 0.3749089 Test Loss: 0.4014498
Validation loss decreased (0.375775 --> 0.374909).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.7199864387512207
Epoch: 18, Steps: 63 | Train Loss: 0.4233700 Vali Loss: 0.3723861 Test Loss: 0.4009777
Validation loss decreased (0.374909 --> 0.372386).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.9661283493041992
Epoch: 19, Steps: 63 | Train Loss: 0.4243554 Vali Loss: 0.3760396 Test Loss: 0.4005125
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.2218828201293945
Epoch: 20, Steps: 63 | Train Loss: 0.4229441 Vali Loss: 0.3748498 Test Loss: 0.4000882
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.087991952896118
Epoch: 21, Steps: 63 | Train Loss: 0.4222629 Vali Loss: 0.3734651 Test Loss: 0.3997868
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.5819730758666992
Epoch: 22, Steps: 63 | Train Loss: 0.4219712 Vali Loss: 0.3714909 Test Loss: 0.3994285
Validation loss decreased (0.372386 --> 0.371491).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.2398056983947754
Epoch: 23, Steps: 63 | Train Loss: 0.4215692 Vali Loss: 0.3727340 Test Loss: 0.3990984
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.118957996368408
Epoch: 24, Steps: 63 | Train Loss: 0.4205312 Vali Loss: 0.3717010 Test Loss: 0.3988558
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.022449016571045
Epoch: 25, Steps: 63 | Train Loss: 0.4199275 Vali Loss: 0.3692478 Test Loss: 0.3986017
Validation loss decreased (0.371491 --> 0.369248).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.9199810028076172
Epoch: 26, Steps: 63 | Train Loss: 0.4203654 Vali Loss: 0.3711317 Test Loss: 0.3984229
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.6086151599884033
Epoch: 27, Steps: 63 | Train Loss: 0.4197218 Vali Loss: 0.3702029 Test Loss: 0.3982189
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.6458187103271484
Epoch: 28, Steps: 63 | Train Loss: 0.4187738 Vali Loss: 0.3729173 Test Loss: 0.3980305
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.4421651363372803
Epoch: 29, Steps: 63 | Train Loss: 0.4199656 Vali Loss: 0.3715186 Test Loss: 0.3978187
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.1200804710388184
Epoch: 30, Steps: 63 | Train Loss: 0.4186188 Vali Loss: 0.3698832 Test Loss: 0.3976631
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.063478469848633
Epoch: 31, Steps: 63 | Train Loss: 0.4179028 Vali Loss: 0.3714641 Test Loss: 0.3975483
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.1023874282836914
Epoch: 32, Steps: 63 | Train Loss: 0.4181171 Vali Loss: 0.3722330 Test Loss: 0.3973895
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.163477659225464
Epoch: 33, Steps: 63 | Train Loss: 0.4172792 Vali Loss: 0.3693371 Test Loss: 0.3973004
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.487544536590576
Epoch: 34, Steps: 63 | Train Loss: 0.4183303 Vali Loss: 0.3711692 Test Loss: 0.3971493
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.75968337059021
Epoch: 35, Steps: 63 | Train Loss: 0.4177410 Vali Loss: 0.3674152 Test Loss: 0.3970724
Validation loss decreased (0.369248 --> 0.367415).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.18166184425354
Epoch: 36, Steps: 63 | Train Loss: 0.4171146 Vali Loss: 0.3705487 Test Loss: 0.3969565
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.9813876152038574
Epoch: 37, Steps: 63 | Train Loss: 0.4169025 Vali Loss: 0.3677454 Test Loss: 0.3968514
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.129516124725342
Epoch: 38, Steps: 63 | Train Loss: 0.4171503 Vali Loss: 0.3700432 Test Loss: 0.3967736
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.2988076210021973
Epoch: 39, Steps: 63 | Train Loss: 0.4169750 Vali Loss: 0.3697455 Test Loss: 0.3966912
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.9352459907531738
Epoch: 40, Steps: 63 | Train Loss: 0.4163632 Vali Loss: 0.3688729 Test Loss: 0.3966315
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.9020755290985107
Epoch: 41, Steps: 63 | Train Loss: 0.4164267 Vali Loss: 0.3664002 Test Loss: 0.3965773
Validation loss decreased (0.367415 --> 0.366400).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.023571491241455
Epoch: 42, Steps: 63 | Train Loss: 0.4166065 Vali Loss: 0.3652023 Test Loss: 0.3964875
Validation loss decreased (0.366400 --> 0.365202).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.081019401550293
Epoch: 43, Steps: 63 | Train Loss: 0.4159011 Vali Loss: 0.3686171 Test Loss: 0.3964362
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.858449935913086
Epoch: 44, Steps: 63 | Train Loss: 0.4174658 Vali Loss: 0.3665540 Test Loss: 0.3963403
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.8592617511749268
Epoch: 45, Steps: 63 | Train Loss: 0.4175558 Vali Loss: 0.3677199 Test Loss: 0.3963284
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.6148126125335693
Epoch: 46, Steps: 63 | Train Loss: 0.4169854 Vali Loss: 0.3684723 Test Loss: 0.3962683
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.5132219791412354
Epoch: 47, Steps: 63 | Train Loss: 0.4165335 Vali Loss: 0.3660274 Test Loss: 0.3962228
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.3376612663269043
Epoch: 48, Steps: 63 | Train Loss: 0.4173505 Vali Loss: 0.3681493 Test Loss: 0.3961700
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.9424965381622314
Epoch: 49, Steps: 63 | Train Loss: 0.4152324 Vali Loss: 0.3675871 Test Loss: 0.3961436
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.9256985187530518
Epoch: 50, Steps: 63 | Train Loss: 0.4162301 Vali Loss: 0.3697301 Test Loss: 0.3961078
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.887399673461914
Epoch: 51, Steps: 63 | Train Loss: 0.4163902 Vali Loss: 0.3676722 Test Loss: 0.3960482
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.6292228698730469
Epoch: 52, Steps: 63 | Train Loss: 0.4157076 Vali Loss: 0.3674080 Test Loss: 0.3960126
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.9127461910247803
Epoch: 53, Steps: 63 | Train Loss: 0.4171431 Vali Loss: 0.3708162 Test Loss: 0.3959734
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.9674320220947266
Epoch: 54, Steps: 63 | Train Loss: 0.4156986 Vali Loss: 0.3691057 Test Loss: 0.3959600
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.320725679397583
Epoch: 55, Steps: 63 | Train Loss: 0.4162471 Vali Loss: 0.3672545 Test Loss: 0.3959178
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.6650166511535645
Epoch: 56, Steps: 63 | Train Loss: 0.4155540 Vali Loss: 0.3691260 Test Loss: 0.3959003
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.8005104064941406
Epoch: 57, Steps: 63 | Train Loss: 0.4166972 Vali Loss: 0.3693466 Test Loss: 0.3958713
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.187237501144409
Epoch: 58, Steps: 63 | Train Loss: 0.4169023 Vali Loss: 0.3664449 Test Loss: 0.3958530
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.1905417442321777
Epoch: 59, Steps: 63 | Train Loss: 0.4163163 Vali Loss: 0.3701170 Test Loss: 0.3958377
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.1600680351257324
Epoch: 60, Steps: 63 | Train Loss: 0.4161500 Vali Loss: 0.3687882 Test Loss: 0.3957981
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 4.895727634429932
Epoch: 61, Steps: 63 | Train Loss: 0.4157247 Vali Loss: 0.3675943 Test Loss: 0.3957663
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.4594812393188477
Epoch: 62, Steps: 63 | Train Loss: 0.4158134 Vali Loss: 0.3696717 Test Loss: 0.3957492
EarlyStopping counter: 20 out of 20
Early stopping
train 8125
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=34, out_features=97, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2955008.0
params:  3395.0
Trainable parameters:  3395
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.9172873497009277
Epoch: 1, Steps: 63 | Train Loss: 0.6255483 Vali Loss: 0.3690244 Test Loss: 0.3950007
Validation loss decreased (inf --> 0.369024).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.9397683143615723
Epoch: 2, Steps: 63 | Train Loss: 0.6217207 Vali Loss: 0.3687026 Test Loss: 0.3945965
Validation loss decreased (0.369024 --> 0.368703).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.0898945331573486
Epoch: 3, Steps: 63 | Train Loss: 0.6227766 Vali Loss: 0.3647831 Test Loss: 0.3939029
Validation loss decreased (0.368703 --> 0.364783).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.7560606002807617
Epoch: 4, Steps: 63 | Train Loss: 0.6198014 Vali Loss: 0.3664277 Test Loss: 0.3935525
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.8548905849456787
Epoch: 5, Steps: 63 | Train Loss: 0.6209809 Vali Loss: 0.3635736 Test Loss: 0.3933791
Validation loss decreased (0.364783 --> 0.363574).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.0102035999298096
Epoch: 6, Steps: 63 | Train Loss: 0.6204340 Vali Loss: 0.3678037 Test Loss: 0.3932431
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.8443918228149414
Epoch: 7, Steps: 63 | Train Loss: 0.6177332 Vali Loss: 0.3641386 Test Loss: 0.3931763
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.0001251697540283
Epoch: 8, Steps: 63 | Train Loss: 0.6190042 Vali Loss: 0.3652213 Test Loss: 0.3930393
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.371929168701172
Epoch: 9, Steps: 63 | Train Loss: 0.6186375 Vali Loss: 0.3645957 Test Loss: 0.3929543
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.7439570426940918
Epoch: 10, Steps: 63 | Train Loss: 0.6177746 Vali Loss: 0.3646364 Test Loss: 0.3928719
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.0382184982299805
Epoch: 11, Steps: 63 | Train Loss: 0.6167461 Vali Loss: 0.3657219 Test Loss: 0.3928975
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.9672634601593018
Epoch: 12, Steps: 63 | Train Loss: 0.6188372 Vali Loss: 0.3650252 Test Loss: 0.3927341
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.890007495880127
Epoch: 13, Steps: 63 | Train Loss: 0.6186807 Vali Loss: 0.3646861 Test Loss: 0.3927703
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.7373003959655762
Epoch: 14, Steps: 63 | Train Loss: 0.6187020 Vali Loss: 0.3635541 Test Loss: 0.3926403
Validation loss decreased (0.363574 --> 0.363554).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.9743876457214355
Epoch: 15, Steps: 63 | Train Loss: 0.6187009 Vali Loss: 0.3620060 Test Loss: 0.3926910
Validation loss decreased (0.363554 --> 0.362006).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.969346761703491
Epoch: 16, Steps: 63 | Train Loss: 0.6170827 Vali Loss: 0.3628887 Test Loss: 0.3926627
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.7709360122680664
Epoch: 17, Steps: 63 | Train Loss: 0.6187052 Vali Loss: 0.3620767 Test Loss: 0.3926304
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.8446588516235352
Epoch: 18, Steps: 63 | Train Loss: 0.6181730 Vali Loss: 0.3631059 Test Loss: 0.3925768
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.1374740600585938
Epoch: 19, Steps: 63 | Train Loss: 0.6179135 Vali Loss: 0.3639368 Test Loss: 0.3925402
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.702193021774292
Epoch: 20, Steps: 63 | Train Loss: 0.6189513 Vali Loss: 0.3633668 Test Loss: 0.3925250
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.7806670665740967
Epoch: 21, Steps: 63 | Train Loss: 0.6176191 Vali Loss: 0.3653567 Test Loss: 0.3924778
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.8103454113006592
Epoch: 22, Steps: 63 | Train Loss: 0.6173285 Vali Loss: 0.3648132 Test Loss: 0.3924685
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.0133161544799805
Epoch: 23, Steps: 63 | Train Loss: 0.6176102 Vali Loss: 0.3633783 Test Loss: 0.3924710
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.000826597213745
Epoch: 24, Steps: 63 | Train Loss: 0.6188688 Vali Loss: 0.3615064 Test Loss: 0.3924859
Validation loss decreased (0.362006 --> 0.361506).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.8356900215148926
Epoch: 25, Steps: 63 | Train Loss: 0.6169166 Vali Loss: 0.3614365 Test Loss: 0.3924743
Validation loss decreased (0.361506 --> 0.361436).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.8760449886322021
Epoch: 26, Steps: 63 | Train Loss: 0.6179247 Vali Loss: 0.3654951 Test Loss: 0.3924254
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.8506031036376953
Epoch: 27, Steps: 63 | Train Loss: 0.6193551 Vali Loss: 0.3640429 Test Loss: 0.3924560
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.997004747390747
Epoch: 28, Steps: 63 | Train Loss: 0.6194357 Vali Loss: 0.3659741 Test Loss: 0.3923846
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 4.950714111328125
Epoch: 29, Steps: 63 | Train Loss: 0.6167009 Vali Loss: 0.3636146 Test Loss: 0.3923810
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 3.362156867980957
Epoch: 30, Steps: 63 | Train Loss: 0.6171930 Vali Loss: 0.3618064 Test Loss: 0.3923518
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 4.525408983230591
Epoch: 31, Steps: 63 | Train Loss: 0.6162196 Vali Loss: 0.3643036 Test Loss: 0.3923535
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 5.552984714508057
Epoch: 32, Steps: 63 | Train Loss: 0.6171040 Vali Loss: 0.3635879 Test Loss: 0.3923306
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 3.553828001022339
Epoch: 33, Steps: 63 | Train Loss: 0.6164794 Vali Loss: 0.3620648 Test Loss: 0.3923378
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.8270299434661865
Epoch: 34, Steps: 63 | Train Loss: 0.6183115 Vali Loss: 0.3612583 Test Loss: 0.3923354
Validation loss decreased (0.361436 --> 0.361258).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.254585027694702
Epoch: 35, Steps: 63 | Train Loss: 0.6185382 Vali Loss: 0.3630445 Test Loss: 0.3923114
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 3.691760540008545
Epoch: 36, Steps: 63 | Train Loss: 0.6181002 Vali Loss: 0.3623072 Test Loss: 0.3923289
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 3.216684341430664
Epoch: 37, Steps: 63 | Train Loss: 0.6170076 Vali Loss: 0.3645580 Test Loss: 0.3923240
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.2267532348632812
Epoch: 38, Steps: 63 | Train Loss: 0.6165261 Vali Loss: 0.3626662 Test Loss: 0.3923450
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.144132614135742
Epoch: 39, Steps: 63 | Train Loss: 0.6171109 Vali Loss: 0.3657751 Test Loss: 0.3923773
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.600755214691162
Epoch: 40, Steps: 63 | Train Loss: 0.6175551 Vali Loss: 0.3654903 Test Loss: 0.3923094
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.135526657104492
Epoch: 41, Steps: 63 | Train Loss: 0.6180869 Vali Loss: 0.3643557 Test Loss: 0.3923092
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.2152159214019775
Epoch: 42, Steps: 63 | Train Loss: 0.6157238 Vali Loss: 0.3635968 Test Loss: 0.3923345
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.3036699295043945
Epoch: 43, Steps: 63 | Train Loss: 0.6159908 Vali Loss: 0.3656245 Test Loss: 0.3923365
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.0686728954315186
Epoch: 44, Steps: 63 | Train Loss: 0.6183013 Vali Loss: 0.3652521 Test Loss: 0.3923057
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.3116912841796875
Epoch: 45, Steps: 63 | Train Loss: 0.6170968 Vali Loss: 0.3639140 Test Loss: 0.3923086
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.8050532341003418
Epoch: 46, Steps: 63 | Train Loss: 0.6132597 Vali Loss: 0.3636377 Test Loss: 0.3922938
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.0479812622070312
Epoch: 47, Steps: 63 | Train Loss: 0.6160997 Vali Loss: 0.3617349 Test Loss: 0.3923062
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.0646159648895264
Epoch: 48, Steps: 63 | Train Loss: 0.6183330 Vali Loss: 0.3630354 Test Loss: 0.3923104
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.9401752948760986
Epoch: 49, Steps: 63 | Train Loss: 0.6179556 Vali Loss: 0.3629471 Test Loss: 0.3922855
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.7817912101745605
Epoch: 50, Steps: 63 | Train Loss: 0.6166028 Vali Loss: 0.3631915 Test Loss: 0.3922735
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.7590489387512207
Epoch: 51, Steps: 63 | Train Loss: 0.6156756 Vali Loss: 0.3642974 Test Loss: 0.3923034
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.915320873260498
Epoch: 52, Steps: 63 | Train Loss: 0.6180638 Vali Loss: 0.3602076 Test Loss: 0.3922767
Validation loss decreased (0.361258 --> 0.360208).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.123204231262207
Epoch: 53, Steps: 63 | Train Loss: 0.6174345 Vali Loss: 0.3653631 Test Loss: 0.3922836
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.9406390190124512
Epoch: 54, Steps: 63 | Train Loss: 0.6168585 Vali Loss: 0.3642219 Test Loss: 0.3922888
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.7842650413513184
Epoch: 55, Steps: 63 | Train Loss: 0.6166782 Vali Loss: 0.3649813 Test Loss: 0.3922729
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.731879472732544
Epoch: 56, Steps: 63 | Train Loss: 0.6176425 Vali Loss: 0.3629660 Test Loss: 0.3922814
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.2906997203826904
Epoch: 57, Steps: 63 | Train Loss: 0.6172747 Vali Loss: 0.3627873 Test Loss: 0.3922793
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.003251791000366
Epoch: 58, Steps: 63 | Train Loss: 0.6167293 Vali Loss: 0.3655260 Test Loss: 0.3922670
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.7382047176361084
Epoch: 59, Steps: 63 | Train Loss: 0.6161643 Vali Loss: 0.3638912 Test Loss: 0.3922658
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.2398266792297363
Epoch: 60, Steps: 63 | Train Loss: 0.6157126 Vali Loss: 0.3634109 Test Loss: 0.3922621
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.328314781188965
Epoch: 61, Steps: 63 | Train Loss: 0.6151093 Vali Loss: 0.3593363 Test Loss: 0.3922583
Validation loss decreased (0.360208 --> 0.359336).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.0004642009735107
Epoch: 62, Steps: 63 | Train Loss: 0.6159970 Vali Loss: 0.3644325 Test Loss: 0.3922588
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.438042640686035
Epoch: 63, Steps: 63 | Train Loss: 0.6161941 Vali Loss: 0.3642475 Test Loss: 0.3922586
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.46064829826355
Epoch: 64, Steps: 63 | Train Loss: 0.6163983 Vali Loss: 0.3654565 Test Loss: 0.3922448
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.227438449859619
Epoch: 65, Steps: 63 | Train Loss: 0.6182821 Vali Loss: 0.3661316 Test Loss: 0.3922464
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 9.397175073623657
Epoch: 66, Steps: 63 | Train Loss: 0.6172315 Vali Loss: 0.3639323 Test Loss: 0.3922533
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 11.217652082443237
Epoch: 67, Steps: 63 | Train Loss: 0.6154481 Vali Loss: 0.3629218 Test Loss: 0.3922465
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 7.980247259140015
Epoch: 68, Steps: 63 | Train Loss: 0.6161051 Vali Loss: 0.3625137 Test Loss: 0.3922541
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 5.4226744174957275
Epoch: 69, Steps: 63 | Train Loss: 0.6181465 Vali Loss: 0.3649433 Test Loss: 0.3922510
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 10.320422410964966
Epoch: 70, Steps: 63 | Train Loss: 0.6151143 Vali Loss: 0.3621598 Test Loss: 0.3922482
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 8.66187047958374
Epoch: 71, Steps: 63 | Train Loss: 0.6165432 Vali Loss: 0.3645536 Test Loss: 0.3922386
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 6.575289249420166
Epoch: 72, Steps: 63 | Train Loss: 0.6178102 Vali Loss: 0.3650979 Test Loss: 0.3922440
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 8.483937501907349
Epoch: 73, Steps: 63 | Train Loss: 0.6159194 Vali Loss: 0.3644612 Test Loss: 0.3922420
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 5.433588743209839
Epoch: 74, Steps: 63 | Train Loss: 0.6164849 Vali Loss: 0.3637055 Test Loss: 0.3922386
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.9385943412780762
Epoch: 75, Steps: 63 | Train Loss: 0.6165004 Vali Loss: 0.3626851 Test Loss: 0.3922379
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.8147828578948975
Epoch: 76, Steps: 63 | Train Loss: 0.6167573 Vali Loss: 0.3630318 Test Loss: 0.3922393
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.1629557609558105
Epoch: 77, Steps: 63 | Train Loss: 0.6140677 Vali Loss: 0.3635552 Test Loss: 0.3922395
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.8240561485290527
Epoch: 78, Steps: 63 | Train Loss: 0.6174184 Vali Loss: 0.3623874 Test Loss: 0.3922410
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.0977301597595215
Epoch: 79, Steps: 63 | Train Loss: 0.6176993 Vali Loss: 0.3634129 Test Loss: 0.3922395
EarlyStopping counter: 18 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.062908887863159
Epoch: 80, Steps: 63 | Train Loss: 0.6176578 Vali Loss: 0.3638323 Test Loss: 0.3922337
EarlyStopping counter: 19 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.9438140392303467
Epoch: 81, Steps: 63 | Train Loss: 0.6172152 Vali Loss: 0.3636850 Test Loss: 0.3922355
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_180_336_FITS_ETTh2_ftM_sl180_ll48_pl336_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.38761380314826965, mae:0.4119720458984375, rse:0.4977819621562958, corr:[0.26289967 0.26588744 0.264601   0.26282352 0.26194656 0.26128402
 0.26013437 0.25850827 0.25746652 0.25654262 0.2555687  0.25391874
 0.25249022 0.2512681  0.2505319  0.24994247 0.24925485 0.24827681
 0.24720362 0.24629146 0.24552144 0.24466838 0.24340971 0.2417008
 0.23939946 0.23738745 0.23568562 0.23441698 0.23308231 0.23167416
 0.23010264 0.22846332 0.22689526 0.2256307  0.22471605 0.22372866
 0.22255401 0.22111969 0.2201062  0.21923539 0.2185832  0.21776432
 0.21677524 0.21567231 0.21469623 0.21356553 0.21185681 0.20957322
 0.20668161 0.20419809 0.20204286 0.20015301 0.19816391 0.19624017
 0.19414179 0.1919479  0.19024903 0.18888457 0.18805242 0.18718246
 0.18648355 0.1855454  0.18509503 0.18472421 0.18428244 0.18360205
 0.1826418  0.18167987 0.1810986  0.18084602 0.17994751 0.17848416
 0.17635402 0.17467304 0.17344728 0.17244451 0.17135504 0.17049718
 0.16985737 0.16931629 0.16920757 0.16900249 0.16876921 0.16854827
 0.16873264 0.16872863 0.16865835 0.168178   0.16762291 0.1670617
 0.1668159  0.1665699  0.16657254 0.1666129  0.1662992  0.16582651
 0.16473895 0.1635986  0.16236815 0.16148832 0.16075388 0.1602038
 0.15991172 0.15961851 0.159617   0.15961519 0.15995784 0.16017085
 0.16029398 0.1597465  0.15905373 0.15845294 0.1580361  0.15765083
 0.15723029 0.15660962 0.15602556 0.15541689 0.154412   0.15290411
 0.15078622 0.1488756  0.14732268 0.14634387 0.14525124 0.14402914
 0.14290383 0.14201705 0.14135046 0.14070588 0.14019507 0.1396748
 0.13942504 0.13900803 0.13862441 0.13811798 0.13758026 0.13681784
 0.13607672 0.13555175 0.1354306  0.13521825 0.13418517 0.13247451
 0.12996499 0.12806632 0.12632686 0.12503974 0.12394917 0.1230955
 0.12251446 0.12184436 0.12147645 0.12140724 0.12171934 0.1218707
 0.12240101 0.12243231 0.12229614 0.1221519  0.12215967 0.12185735
 0.12124532 0.12083342 0.12081196 0.12100603 0.12070361 0.11957686
 0.11751595 0.11606392 0.11482722 0.11397123 0.11301833 0.11178778
 0.11086699 0.11020193 0.11011485 0.1099048  0.10997146 0.10999364
 0.11027067 0.11029764 0.11020342 0.11004118 0.1098031  0.10936744
 0.10916892 0.10917193 0.10950564 0.11001626 0.1101667  0.10988822
 0.10907107 0.10873999 0.10840105 0.10833539 0.10798592 0.10762218
 0.10758087 0.10779475 0.10824354 0.10836272 0.10874054 0.10878455
 0.10892613 0.10869254 0.10844491 0.10826129 0.10823189 0.10837187
 0.1084355  0.10853945 0.10879593 0.1090652  0.10916075 0.10879602
 0.1077257  0.1065301  0.10556187 0.10525423 0.10491069 0.10486992
 0.10477272 0.10506133 0.10547128 0.10584467 0.10613745 0.10598967
 0.10581313 0.10538721 0.10531113 0.1054563  0.10572278 0.10586517
 0.10600179 0.10638951 0.10703135 0.10762496 0.10758511 0.10705701
 0.10589948 0.10523722 0.10463744 0.10431024 0.10367436 0.10301422
 0.10267317 0.10312814 0.1039714  0.10447806 0.10517821 0.10575714
 0.10667836 0.10736746 0.10774904 0.10806449 0.10843837 0.10892235
 0.10906557 0.10917868 0.10968213 0.11035849 0.11091618 0.11109032
 0.1106448  0.11014655 0.10963523 0.10967147 0.10959633 0.10982973
 0.11006287 0.11025308 0.11068833 0.11109623 0.11179376 0.11211557
 0.1126314  0.11269295 0.11290722 0.11293826 0.11306182 0.11322752
 0.11349156 0.11366073 0.11386175 0.11420868 0.11435738 0.11472185
 0.11446208 0.11425544 0.11371014 0.11341989 0.11273818 0.1122099
 0.11204112 0.1120582  0.1129158  0.11351945 0.11431464 0.1149848
 0.11596639 0.11628253 0.11665419 0.11722895 0.11775871 0.11811346
 0.11809801 0.11826407 0.11874901 0.11935627 0.11966743 0.11942187
 0.11829867 0.11742906 0.11659295 0.1161995  0.11540223 0.11480519
 0.11409983 0.11417241 0.11480713 0.11528969 0.11604337 0.11675046
 0.11798434 0.11785699 0.11730308 0.1167335  0.11671548 0.11642506
 0.11548829 0.1137034  0.11236447 0.11297027 0.11427817 0.11310126]
