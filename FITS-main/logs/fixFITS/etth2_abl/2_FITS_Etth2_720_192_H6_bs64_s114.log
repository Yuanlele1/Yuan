Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=196, out_features=248, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  43552768.0
params:  48856.0
Trainable parameters:  48856
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 6.998632431030273
Epoch: 1, Steps: 60 | Train Loss: 0.5838889 Vali Loss: 0.4684516 Test Loss: 0.4426567
Validation loss decreased (inf --> 0.468452).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 7.411068916320801
Epoch: 2, Steps: 60 | Train Loss: 0.4525189 Vali Loss: 0.4096630 Test Loss: 0.4072169
Validation loss decreased (0.468452 --> 0.409663).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 7.236618757247925
Epoch: 3, Steps: 60 | Train Loss: 0.3882278 Vali Loss: 0.3844860 Test Loss: 0.3943003
Validation loss decreased (0.409663 --> 0.384486).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 7.354460954666138
Epoch: 4, Steps: 60 | Train Loss: 0.3515529 Vali Loss: 0.3721849 Test Loss: 0.3889666
Validation loss decreased (0.384486 --> 0.372185).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 6.851703882217407
Epoch: 5, Steps: 60 | Train Loss: 0.3250415 Vali Loss: 0.3648631 Test Loss: 0.3864702
Validation loss decreased (0.372185 --> 0.364863).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 7.032273769378662
Epoch: 6, Steps: 60 | Train Loss: 0.3036579 Vali Loss: 0.3598995 Test Loss: 0.3846235
Validation loss decreased (0.364863 --> 0.359899).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 7.124632835388184
Epoch: 7, Steps: 60 | Train Loss: 0.2870255 Vali Loss: 0.3558949 Test Loss: 0.3835575
Validation loss decreased (0.359899 --> 0.355895).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 7.474597215652466
Epoch: 8, Steps: 60 | Train Loss: 0.2723687 Vali Loss: 0.3524753 Test Loss: 0.3824368
Validation loss decreased (0.355895 --> 0.352475).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 7.546165704727173
Epoch: 9, Steps: 60 | Train Loss: 0.2600146 Vali Loss: 0.3492812 Test Loss: 0.3811371
Validation loss decreased (0.352475 --> 0.349281).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 7.126690626144409
Epoch: 10, Steps: 60 | Train Loss: 0.2491488 Vali Loss: 0.3464760 Test Loss: 0.3801704
Validation loss decreased (0.349281 --> 0.346476).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 7.24133038520813
Epoch: 11, Steps: 60 | Train Loss: 0.2394910 Vali Loss: 0.3438695 Test Loss: 0.3793511
Validation loss decreased (0.346476 --> 0.343870).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 7.285667896270752
Epoch: 12, Steps: 60 | Train Loss: 0.2309881 Vali Loss: 0.3418820 Test Loss: 0.3783929
Validation loss decreased (0.343870 --> 0.341882).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 7.480910539627075
Epoch: 13, Steps: 60 | Train Loss: 0.2236629 Vali Loss: 0.3395342 Test Loss: 0.3773000
Validation loss decreased (0.341882 --> 0.339534).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 7.242356061935425
Epoch: 14, Steps: 60 | Train Loss: 0.2167430 Vali Loss: 0.3372633 Test Loss: 0.3764043
Validation loss decreased (0.339534 --> 0.337263).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 7.4802234172821045
Epoch: 15, Steps: 60 | Train Loss: 0.2105969 Vali Loss: 0.3354909 Test Loss: 0.3754791
Validation loss decreased (0.337263 --> 0.335491).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 7.137644529342651
Epoch: 16, Steps: 60 | Train Loss: 0.2051959 Vali Loss: 0.3337315 Test Loss: 0.3745161
Validation loss decreased (0.335491 --> 0.333732).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 7.470692873001099
Epoch: 17, Steps: 60 | Train Loss: 0.2002376 Vali Loss: 0.3320148 Test Loss: 0.3737533
Validation loss decreased (0.333732 --> 0.332015).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 7.071268081665039
Epoch: 18, Steps: 60 | Train Loss: 0.1956052 Vali Loss: 0.3300182 Test Loss: 0.3728829
Validation loss decreased (0.332015 --> 0.330018).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 7.312369108200073
Epoch: 19, Steps: 60 | Train Loss: 0.1918861 Vali Loss: 0.3288620 Test Loss: 0.3723159
Validation loss decreased (0.330018 --> 0.328862).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 7.180224180221558
Epoch: 20, Steps: 60 | Train Loss: 0.1878119 Vali Loss: 0.3274131 Test Loss: 0.3715492
Validation loss decreased (0.328862 --> 0.327413).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 7.242460489273071
Epoch: 21, Steps: 60 | Train Loss: 0.1850495 Vali Loss: 0.3261875 Test Loss: 0.3709660
Validation loss decreased (0.327413 --> 0.326187).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 7.264928817749023
Epoch: 22, Steps: 60 | Train Loss: 0.1817537 Vali Loss: 0.3250787 Test Loss: 0.3704019
Validation loss decreased (0.326187 --> 0.325079).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 7.189935922622681
Epoch: 23, Steps: 60 | Train Loss: 0.1791024 Vali Loss: 0.3239585 Test Loss: 0.3697902
Validation loss decreased (0.325079 --> 0.323958).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 7.260265111923218
Epoch: 24, Steps: 60 | Train Loss: 0.1763831 Vali Loss: 0.3227678 Test Loss: 0.3692757
Validation loss decreased (0.323958 --> 0.322768).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 7.275831937789917
Epoch: 25, Steps: 60 | Train Loss: 0.1742588 Vali Loss: 0.3219352 Test Loss: 0.3687202
Validation loss decreased (0.322768 --> 0.321935).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 7.434050798416138
Epoch: 26, Steps: 60 | Train Loss: 0.1721736 Vali Loss: 0.3210953 Test Loss: 0.3683213
Validation loss decreased (0.321935 --> 0.321095).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 7.215518474578857
Epoch: 27, Steps: 60 | Train Loss: 0.1705516 Vali Loss: 0.3202151 Test Loss: 0.3678637
Validation loss decreased (0.321095 --> 0.320215).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 7.363758563995361
Epoch: 28, Steps: 60 | Train Loss: 0.1684013 Vali Loss: 0.3193637 Test Loss: 0.3674276
Validation loss decreased (0.320215 --> 0.319364).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 7.245531320571899
Epoch: 29, Steps: 60 | Train Loss: 0.1665358 Vali Loss: 0.3186564 Test Loss: 0.3670894
Validation loss decreased (0.319364 --> 0.318656).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 7.286331415176392
Epoch: 30, Steps: 60 | Train Loss: 0.1652768 Vali Loss: 0.3178686 Test Loss: 0.3667572
Validation loss decreased (0.318656 --> 0.317869).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 7.4780542850494385
Epoch: 31, Steps: 60 | Train Loss: 0.1638155 Vali Loss: 0.3173062 Test Loss: 0.3663865
Validation loss decreased (0.317869 --> 0.317306).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 7.403000831604004
Epoch: 32, Steps: 60 | Train Loss: 0.1623201 Vali Loss: 0.3164678 Test Loss: 0.3661174
Validation loss decreased (0.317306 --> 0.316468).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 7.312590837478638
Epoch: 33, Steps: 60 | Train Loss: 0.1612939 Vali Loss: 0.3158830 Test Loss: 0.3658557
Validation loss decreased (0.316468 --> 0.315883).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 7.1305365562438965
Epoch: 34, Steps: 60 | Train Loss: 0.1600295 Vali Loss: 0.3153984 Test Loss: 0.3656247
Validation loss decreased (0.315883 --> 0.315398).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 7.516689777374268
Epoch: 35, Steps: 60 | Train Loss: 0.1588434 Vali Loss: 0.3147995 Test Loss: 0.3653789
Validation loss decreased (0.315398 --> 0.314799).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 7.457862138748169
Epoch: 36, Steps: 60 | Train Loss: 0.1579274 Vali Loss: 0.3144093 Test Loss: 0.3650977
Validation loss decreased (0.314799 --> 0.314409).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 7.2340123653411865
Epoch: 37, Steps: 60 | Train Loss: 0.1566186 Vali Loss: 0.3137273 Test Loss: 0.3648661
Validation loss decreased (0.314409 --> 0.313727).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 7.3447265625
Epoch: 38, Steps: 60 | Train Loss: 0.1560770 Vali Loss: 0.3132231 Test Loss: 0.3646600
Validation loss decreased (0.313727 --> 0.313223).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 7.420285224914551
Epoch: 39, Steps: 60 | Train Loss: 0.1551114 Vali Loss: 0.3129492 Test Loss: 0.3644828
Validation loss decreased (0.313223 --> 0.312949).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 7.073111057281494
Epoch: 40, Steps: 60 | Train Loss: 0.1540901 Vali Loss: 0.3125510 Test Loss: 0.3643683
Validation loss decreased (0.312949 --> 0.312551).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 6.980634689331055
Epoch: 41, Steps: 60 | Train Loss: 0.1533772 Vali Loss: 0.3121587 Test Loss: 0.3641534
Validation loss decreased (0.312551 --> 0.312159).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 7.0873377323150635
Epoch: 42, Steps: 60 | Train Loss: 0.1526665 Vali Loss: 0.3117666 Test Loss: 0.3640163
Validation loss decreased (0.312159 --> 0.311767).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 7.079284429550171
Epoch: 43, Steps: 60 | Train Loss: 0.1524230 Vali Loss: 0.3113437 Test Loss: 0.3638620
Validation loss decreased (0.311767 --> 0.311344).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 7.160425901412964
Epoch: 44, Steps: 60 | Train Loss: 0.1518058 Vali Loss: 0.3111560 Test Loss: 0.3636912
Validation loss decreased (0.311344 --> 0.311156).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 7.025717496871948
Epoch: 45, Steps: 60 | Train Loss: 0.1509870 Vali Loss: 0.3106922 Test Loss: 0.3635961
Validation loss decreased (0.311156 --> 0.310692).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 7.084932565689087
Epoch: 46, Steps: 60 | Train Loss: 0.1501713 Vali Loss: 0.3104884 Test Loss: 0.3634708
Validation loss decreased (0.310692 --> 0.310488).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 6.949635982513428
Epoch: 47, Steps: 60 | Train Loss: 0.1498900 Vali Loss: 0.3102417 Test Loss: 0.3633300
Validation loss decreased (0.310488 --> 0.310242).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 6.841063022613525
Epoch: 48, Steps: 60 | Train Loss: 0.1493850 Vali Loss: 0.3099611 Test Loss: 0.3632607
Validation loss decreased (0.310242 --> 0.309961).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 7.066314458847046
Epoch: 49, Steps: 60 | Train Loss: 0.1487185 Vali Loss: 0.3096339 Test Loss: 0.3631511
Validation loss decreased (0.309961 --> 0.309634).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 7.200971841812134
Epoch: 50, Steps: 60 | Train Loss: 0.1485477 Vali Loss: 0.3094948 Test Loss: 0.3630559
Validation loss decreased (0.309634 --> 0.309495).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 7.143747329711914
Epoch: 51, Steps: 60 | Train Loss: 0.1484348 Vali Loss: 0.3092510 Test Loss: 0.3629542
Validation loss decreased (0.309495 --> 0.309251).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 6.952115058898926
Epoch: 52, Steps: 60 | Train Loss: 0.1478361 Vali Loss: 0.3086675 Test Loss: 0.3628508
Validation loss decreased (0.309251 --> 0.308668).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 7.085799932479858
Epoch: 53, Steps: 60 | Train Loss: 0.1474810 Vali Loss: 0.3088249 Test Loss: 0.3627908
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 6.869440078735352
Epoch: 54, Steps: 60 | Train Loss: 0.1472761 Vali Loss: 0.3086072 Test Loss: 0.3627179
Validation loss decreased (0.308668 --> 0.308607).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 7.056105375289917
Epoch: 55, Steps: 60 | Train Loss: 0.1469712 Vali Loss: 0.3084600 Test Loss: 0.3626460
Validation loss decreased (0.308607 --> 0.308460).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 7.040728807449341
Epoch: 56, Steps: 60 | Train Loss: 0.1465206 Vali Loss: 0.3082705 Test Loss: 0.3625565
Validation loss decreased (0.308460 --> 0.308271).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 7.005855560302734
Epoch: 57, Steps: 60 | Train Loss: 0.1460782 Vali Loss: 0.3080787 Test Loss: 0.3625195
Validation loss decreased (0.308271 --> 0.308079).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 7.097328186035156
Epoch: 58, Steps: 60 | Train Loss: 0.1460790 Vali Loss: 0.3079638 Test Loss: 0.3624493
Validation loss decreased (0.308079 --> 0.307964).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 6.944058656692505
Epoch: 59, Steps: 60 | Train Loss: 0.1459063 Vali Loss: 0.3077367 Test Loss: 0.3623896
Validation loss decreased (0.307964 --> 0.307737).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 5.921205520629883
Epoch: 60, Steps: 60 | Train Loss: 0.1454740 Vali Loss: 0.3074070 Test Loss: 0.3623295
Validation loss decreased (0.307737 --> 0.307407).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 6.147403001785278
Epoch: 61, Steps: 60 | Train Loss: 0.1453556 Vali Loss: 0.3074739 Test Loss: 0.3622985
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 7.102815628051758
Epoch: 62, Steps: 60 | Train Loss: 0.1452221 Vali Loss: 0.3073463 Test Loss: 0.3622537
Validation loss decreased (0.307407 --> 0.307346).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 6.903491020202637
Epoch: 63, Steps: 60 | Train Loss: 0.1447584 Vali Loss: 0.3072487 Test Loss: 0.3622043
Validation loss decreased (0.307346 --> 0.307249).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 6.854207992553711
Epoch: 64, Steps: 60 | Train Loss: 0.1446091 Vali Loss: 0.3071698 Test Loss: 0.3621591
Validation loss decreased (0.307249 --> 0.307170).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 4.821715831756592
Epoch: 65, Steps: 60 | Train Loss: 0.1445095 Vali Loss: 0.3070261 Test Loss: 0.3621204
Validation loss decreased (0.307170 --> 0.307026).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 7.061835050582886
Epoch: 66, Steps: 60 | Train Loss: 0.1441158 Vali Loss: 0.3069341 Test Loss: 0.3620847
Validation loss decreased (0.307026 --> 0.306934).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 7.142799377441406
Epoch: 67, Steps: 60 | Train Loss: 0.1441910 Vali Loss: 0.3068326 Test Loss: 0.3620470
Validation loss decreased (0.306934 --> 0.306833).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 6.829822540283203
Epoch: 68, Steps: 60 | Train Loss: 0.1436897 Vali Loss: 0.3066486 Test Loss: 0.3620254
Validation loss decreased (0.306833 --> 0.306649).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 6.677631616592407
Epoch: 69, Steps: 60 | Train Loss: 0.1437396 Vali Loss: 0.3065976 Test Loss: 0.3619868
Validation loss decreased (0.306649 --> 0.306598).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 7.0035529136657715
Epoch: 70, Steps: 60 | Train Loss: 0.1436216 Vali Loss: 0.3064986 Test Loss: 0.3619589
Validation loss decreased (0.306598 --> 0.306499).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 7.0072736740112305
Epoch: 71, Steps: 60 | Train Loss: 0.1434436 Vali Loss: 0.3064187 Test Loss: 0.3619382
Validation loss decreased (0.306499 --> 0.306419).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 6.836350202560425
Epoch: 72, Steps: 60 | Train Loss: 0.1436467 Vali Loss: 0.3063720 Test Loss: 0.3618995
Validation loss decreased (0.306419 --> 0.306372).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 6.967651844024658
Epoch: 73, Steps: 60 | Train Loss: 0.1430430 Vali Loss: 0.3061697 Test Loss: 0.3618728
Validation loss decreased (0.306372 --> 0.306170).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 7.139422655105591
Epoch: 74, Steps: 60 | Train Loss: 0.1427692 Vali Loss: 0.3061706 Test Loss: 0.3618616
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 7.059341907501221
Epoch: 75, Steps: 60 | Train Loss: 0.1428686 Vali Loss: 0.3061414 Test Loss: 0.3618305
Validation loss decreased (0.306170 --> 0.306141).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 6.670393705368042
Epoch: 76, Steps: 60 | Train Loss: 0.1428541 Vali Loss: 0.3059993 Test Loss: 0.3618051
Validation loss decreased (0.306141 --> 0.305999).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 7.143748760223389
Epoch: 77, Steps: 60 | Train Loss: 0.1426557 Vali Loss: 0.3059880 Test Loss: 0.3617989
Validation loss decreased (0.305999 --> 0.305988).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 6.811858892440796
Epoch: 78, Steps: 60 | Train Loss: 0.1423291 Vali Loss: 0.3059124 Test Loss: 0.3617836
Validation loss decreased (0.305988 --> 0.305912).  Saving model ...
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 6.977651357650757
Epoch: 79, Steps: 60 | Train Loss: 0.1428274 Vali Loss: 0.3057853 Test Loss: 0.3617443
Validation loss decreased (0.305912 --> 0.305785).  Saving model ...
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 6.921296119689941
Epoch: 80, Steps: 60 | Train Loss: 0.1426153 Vali Loss: 0.3058441 Test Loss: 0.3617378
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 6.558026313781738
Epoch: 81, Steps: 60 | Train Loss: 0.1423203 Vali Loss: 0.3057631 Test Loss: 0.3617191
Validation loss decreased (0.305785 --> 0.305763).  Saving model ...
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 6.8478827476501465
Epoch: 82, Steps: 60 | Train Loss: 0.1425603 Vali Loss: 0.3057607 Test Loss: 0.3617054
Validation loss decreased (0.305763 --> 0.305761).  Saving model ...
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 7.001520872116089
Epoch: 83, Steps: 60 | Train Loss: 0.1419185 Vali Loss: 0.3056820 Test Loss: 0.3616897
Validation loss decreased (0.305761 --> 0.305682).  Saving model ...
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 6.517019987106323
Epoch: 84, Steps: 60 | Train Loss: 0.1421636 Vali Loss: 0.3056428 Test Loss: 0.3616821
Validation loss decreased (0.305682 --> 0.305643).  Saving model ...
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 6.859355449676514
Epoch: 85, Steps: 60 | Train Loss: 0.1420898 Vali Loss: 0.3055720 Test Loss: 0.3616658
Validation loss decreased (0.305643 --> 0.305572).  Saving model ...
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 6.921810150146484
Epoch: 86, Steps: 60 | Train Loss: 0.1420352 Vali Loss: 0.3055640 Test Loss: 0.3616481
Validation loss decreased (0.305572 --> 0.305564).  Saving model ...
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 6.571552515029907
Epoch: 87, Steps: 60 | Train Loss: 0.1419585 Vali Loss: 0.3055395 Test Loss: 0.3616460
Validation loss decreased (0.305564 --> 0.305539).  Saving model ...
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 7.017210006713867
Epoch: 88, Steps: 60 | Train Loss: 0.1418028 Vali Loss: 0.3055103 Test Loss: 0.3616327
Validation loss decreased (0.305539 --> 0.305510).  Saving model ...
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 7.0746824741363525
Epoch: 89, Steps: 60 | Train Loss: 0.1417365 Vali Loss: 0.3054123 Test Loss: 0.3616242
Validation loss decreased (0.305510 --> 0.305412).  Saving model ...
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 6.8970561027526855
Epoch: 90, Steps: 60 | Train Loss: 0.1418580 Vali Loss: 0.3051361 Test Loss: 0.3616133
Validation loss decreased (0.305412 --> 0.305136).  Saving model ...
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 6.896242618560791
Epoch: 91, Steps: 60 | Train Loss: 0.1415549 Vali Loss: 0.3053432 Test Loss: 0.3616052
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 7.038695335388184
Epoch: 92, Steps: 60 | Train Loss: 0.1419764 Vali Loss: 0.3053775 Test Loss: 0.3615932
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 7.1531288623809814
Epoch: 93, Steps: 60 | Train Loss: 0.1418332 Vali Loss: 0.3053258 Test Loss: 0.3615877
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 6.7463414669036865
Epoch: 94, Steps: 60 | Train Loss: 0.1419328 Vali Loss: 0.3052996 Test Loss: 0.3615776
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 6.9427170753479
Epoch: 95, Steps: 60 | Train Loss: 0.1415981 Vali Loss: 0.3052739 Test Loss: 0.3615721
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 7.013536214828491
Epoch: 96, Steps: 60 | Train Loss: 0.1418674 Vali Loss: 0.3052319 Test Loss: 0.3615620
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 6.841972589492798
Epoch: 97, Steps: 60 | Train Loss: 0.1412607 Vali Loss: 0.3051913 Test Loss: 0.3615567
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 6.882173299789429
Epoch: 98, Steps: 60 | Train Loss: 0.1412405 Vali Loss: 0.3051566 Test Loss: 0.3615512
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 6.732271671295166
Epoch: 99, Steps: 60 | Train Loss: 0.1415399 Vali Loss: 0.3052339 Test Loss: 0.3615437
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 6.758933782577515
Epoch: 100, Steps: 60 | Train Loss: 0.1415350 Vali Loss: 0.3051999 Test Loss: 0.3615366
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.1160680107021042e-06
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=196, out_features=248, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  43552768.0
params:  48856.0
Trainable parameters:  48856
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 6.835758447647095
Epoch: 1, Steps: 60 | Train Loss: 0.5277428 Vali Loss: 0.2908827 Test Loss: 0.3547848
Validation loss decreased (inf --> 0.290883).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 6.8392493724823
Epoch: 2, Steps: 60 | Train Loss: 0.5181673 Vali Loss: 0.2866681 Test Loss: 0.3538012
Validation loss decreased (0.290883 --> 0.286668).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 6.8352251052856445
Epoch: 3, Steps: 60 | Train Loss: 0.5127490 Vali Loss: 0.2853155 Test Loss: 0.3533991
Validation loss decreased (0.286668 --> 0.285315).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 7.158676624298096
Epoch: 4, Steps: 60 | Train Loss: 0.5123596 Vali Loss: 0.2839608 Test Loss: 0.3532134
Validation loss decreased (0.285315 --> 0.283961).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 6.91501522064209
Epoch: 5, Steps: 60 | Train Loss: 0.5107529 Vali Loss: 0.2834891 Test Loss: 0.3530354
Validation loss decreased (0.283961 --> 0.283489).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 6.678555488586426
Epoch: 6, Steps: 60 | Train Loss: 0.5103790 Vali Loss: 0.2826161 Test Loss: 0.3531199
Validation loss decreased (0.283489 --> 0.282616).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 6.872208595275879
Epoch: 7, Steps: 60 | Train Loss: 0.5106626 Vali Loss: 0.2818749 Test Loss: 0.3528979
Validation loss decreased (0.282616 --> 0.281875).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 6.9257142543792725
Epoch: 8, Steps: 60 | Train Loss: 0.5100501 Vali Loss: 0.2819726 Test Loss: 0.3522950
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 7.122876405715942
Epoch: 9, Steps: 60 | Train Loss: 0.5103244 Vali Loss: 0.2815394 Test Loss: 0.3524124
Validation loss decreased (0.281875 --> 0.281539).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 6.980880975723267
Epoch: 10, Steps: 60 | Train Loss: 0.5083293 Vali Loss: 0.2814178 Test Loss: 0.3522508
Validation loss decreased (0.281539 --> 0.281418).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 6.8886730670928955
Epoch: 11, Steps: 60 | Train Loss: 0.5077459 Vali Loss: 0.2807488 Test Loss: 0.3521681
Validation loss decreased (0.281418 --> 0.280749).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 7.1492087841033936
Epoch: 12, Steps: 60 | Train Loss: 0.5074290 Vali Loss: 0.2808109 Test Loss: 0.3519471
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 6.927933931350708
Epoch: 13, Steps: 60 | Train Loss: 0.5081227 Vali Loss: 0.2805089 Test Loss: 0.3521812
Validation loss decreased (0.280749 --> 0.280509).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 6.9258363246917725
Epoch: 14, Steps: 60 | Train Loss: 0.5080304 Vali Loss: 0.2807321 Test Loss: 0.3521104
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 6.763307094573975
Epoch: 15, Steps: 60 | Train Loss: 0.5081968 Vali Loss: 0.2806519 Test Loss: 0.3517569
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 6.8200623989105225
Epoch: 16, Steps: 60 | Train Loss: 0.5080380 Vali Loss: 0.2809003 Test Loss: 0.3518316
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 6.86259913444519
Epoch: 17, Steps: 60 | Train Loss: 0.5081915 Vali Loss: 0.2806677 Test Loss: 0.3516689
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 6.977372407913208
Epoch: 18, Steps: 60 | Train Loss: 0.5072875 Vali Loss: 0.2802809 Test Loss: 0.3517912
Validation loss decreased (0.280509 --> 0.280281).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 7.026801109313965
Epoch: 19, Steps: 60 | Train Loss: 0.5062846 Vali Loss: 0.2799479 Test Loss: 0.3515553
Validation loss decreased (0.280281 --> 0.279948).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 6.981627702713013
Epoch: 20, Steps: 60 | Train Loss: 0.5060882 Vali Loss: 0.2799861 Test Loss: 0.3516728
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 6.897324800491333
Epoch: 21, Steps: 60 | Train Loss: 0.5042060 Vali Loss: 0.2801676 Test Loss: 0.3516287
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 6.899428844451904
Epoch: 22, Steps: 60 | Train Loss: 0.5074844 Vali Loss: 0.2802177 Test Loss: 0.3516025
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 6.880255460739136
Epoch: 23, Steps: 60 | Train Loss: 0.5071736 Vali Loss: 0.2798440 Test Loss: 0.3517885
Validation loss decreased (0.279948 --> 0.279844).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 7.054872512817383
Epoch: 24, Steps: 60 | Train Loss: 0.5066624 Vali Loss: 0.2798256 Test Loss: 0.3516891
Validation loss decreased (0.279844 --> 0.279826).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 6.9608893394470215
Epoch: 25, Steps: 60 | Train Loss: 0.5064937 Vali Loss: 0.2797163 Test Loss: 0.3515581
Validation loss decreased (0.279826 --> 0.279716).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 6.8686442375183105
Epoch: 26, Steps: 60 | Train Loss: 0.5044612 Vali Loss: 0.2795730 Test Loss: 0.3516103
Validation loss decreased (0.279716 --> 0.279573).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 6.731417417526245
Epoch: 27, Steps: 60 | Train Loss: 0.5060865 Vali Loss: 0.2796856 Test Loss: 0.3515376
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 6.894651651382446
Epoch: 28, Steps: 60 | Train Loss: 0.5056005 Vali Loss: 0.2795032 Test Loss: 0.3515605
Validation loss decreased (0.279573 --> 0.279503).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 6.590015411376953
Epoch: 29, Steps: 60 | Train Loss: 0.5068079 Vali Loss: 0.2794437 Test Loss: 0.3514174
Validation loss decreased (0.279503 --> 0.279444).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 6.19533109664917
Epoch: 30, Steps: 60 | Train Loss: 0.5060770 Vali Loss: 0.2795869 Test Loss: 0.3515304
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 6.769249677658081
Epoch: 31, Steps: 60 | Train Loss: 0.5045735 Vali Loss: 0.2793332 Test Loss: 0.3515041
Validation loss decreased (0.279444 --> 0.279333).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 7.895176410675049
Epoch: 32, Steps: 60 | Train Loss: 0.5067776 Vali Loss: 0.2796308 Test Loss: 0.3514202
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 8.0309157371521
Epoch: 33, Steps: 60 | Train Loss: 0.5053555 Vali Loss: 0.2795604 Test Loss: 0.3514413
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 7.930443286895752
Epoch: 34, Steps: 60 | Train Loss: 0.5063387 Vali Loss: 0.2795089 Test Loss: 0.3514197
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 7.536819696426392
Epoch: 35, Steps: 60 | Train Loss: 0.5034738 Vali Loss: 0.2794377 Test Loss: 0.3513974
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 7.872398376464844
Epoch: 36, Steps: 60 | Train Loss: 0.5056504 Vali Loss: 0.2793301 Test Loss: 0.3513783
Validation loss decreased (0.279333 --> 0.279330).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 7.760810852050781
Epoch: 37, Steps: 60 | Train Loss: 0.5059392 Vali Loss: 0.2793925 Test Loss: 0.3513655
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 7.6811933517456055
Epoch: 38, Steps: 60 | Train Loss: 0.5067933 Vali Loss: 0.2793165 Test Loss: 0.3514164
Validation loss decreased (0.279330 --> 0.279316).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 7.5607500076293945
Epoch: 39, Steps: 60 | Train Loss: 0.5058372 Vali Loss: 0.2794560 Test Loss: 0.3513430
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 7.466384172439575
Epoch: 40, Steps: 60 | Train Loss: 0.5061056 Vali Loss: 0.2792227 Test Loss: 0.3513774
Validation loss decreased (0.279316 --> 0.279223).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 7.727043151855469
Epoch: 41, Steps: 60 | Train Loss: 0.5041570 Vali Loss: 0.2792903 Test Loss: 0.3513694
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 7.700276613235474
Epoch: 42, Steps: 60 | Train Loss: 0.5064110 Vali Loss: 0.2793535 Test Loss: 0.3513562
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 7.521888732910156
Epoch: 43, Steps: 60 | Train Loss: 0.5049417 Vali Loss: 0.2789389 Test Loss: 0.3513316
Validation loss decreased (0.279223 --> 0.278939).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 7.6118528842926025
Epoch: 44, Steps: 60 | Train Loss: 0.5058077 Vali Loss: 0.2792927 Test Loss: 0.3512651
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 7.474008083343506
Epoch: 45, Steps: 60 | Train Loss: 0.5056639 Vali Loss: 0.2793462 Test Loss: 0.3513418
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 7.512929916381836
Epoch: 46, Steps: 60 | Train Loss: 0.5043742 Vali Loss: 0.2791310 Test Loss: 0.3513697
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 8.068376064300537
Epoch: 47, Steps: 60 | Train Loss: 0.5038375 Vali Loss: 0.2793444 Test Loss: 0.3512964
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 7.308513402938843
Epoch: 48, Steps: 60 | Train Loss: 0.5061202 Vali Loss: 0.2792800 Test Loss: 0.3513256
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 7.537687540054321
Epoch: 49, Steps: 60 | Train Loss: 0.5054922 Vali Loss: 0.2791894 Test Loss: 0.3513240
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 6.760612726211548
Epoch: 50, Steps: 60 | Train Loss: 0.5060425 Vali Loss: 0.2792540 Test Loss: 0.3513073
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 7.886016130447388
Epoch: 51, Steps: 60 | Train Loss: 0.5055461 Vali Loss: 0.2791249 Test Loss: 0.3513283
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 8.030748844146729
Epoch: 52, Steps: 60 | Train Loss: 0.5050969 Vali Loss: 0.2792118 Test Loss: 0.3512960
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 7.75499701499939
Epoch: 53, Steps: 60 | Train Loss: 0.5049656 Vali Loss: 0.2792088 Test Loss: 0.3513023
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 7.720547676086426
Epoch: 54, Steps: 60 | Train Loss: 0.5039155 Vali Loss: 0.2789349 Test Loss: 0.3512992
Validation loss decreased (0.278939 --> 0.278935).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 7.963705539703369
Epoch: 55, Steps: 60 | Train Loss: 0.5060575 Vali Loss: 0.2788108 Test Loss: 0.3513028
Validation loss decreased (0.278935 --> 0.278811).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 7.830874681472778
Epoch: 56, Steps: 60 | Train Loss: 0.5058369 Vali Loss: 0.2792068 Test Loss: 0.3512919
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 8.108239889144897
Epoch: 57, Steps: 60 | Train Loss: 0.5055334 Vali Loss: 0.2792152 Test Loss: 0.3512971
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 7.691949367523193
Epoch: 58, Steps: 60 | Train Loss: 0.5066826 Vali Loss: 0.2792032 Test Loss: 0.3513016
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 8.024978876113892
Epoch: 59, Steps: 60 | Train Loss: 0.5048861 Vali Loss: 0.2792460 Test Loss: 0.3512806
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 7.786379814147949
Epoch: 60, Steps: 60 | Train Loss: 0.5042656 Vali Loss: 0.2791408 Test Loss: 0.3512938
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 7.659607648849487
Epoch: 61, Steps: 60 | Train Loss: 0.5059376 Vali Loss: 0.2791239 Test Loss: 0.3512863
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 7.968653678894043
Epoch: 62, Steps: 60 | Train Loss: 0.5036709 Vali Loss: 0.2791819 Test Loss: 0.3512889
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 7.9450812339782715
Epoch: 63, Steps: 60 | Train Loss: 0.5038792 Vali Loss: 0.2792183 Test Loss: 0.3512677
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 7.824698209762573
Epoch: 64, Steps: 60 | Train Loss: 0.5061847 Vali Loss: 0.2792154 Test Loss: 0.3512778
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 7.939972400665283
Epoch: 65, Steps: 60 | Train Loss: 0.5046000 Vali Loss: 0.2791722 Test Loss: 0.3512705
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 7.625344753265381
Epoch: 66, Steps: 60 | Train Loss: 0.5059362 Vali Loss: 0.2791315 Test Loss: 0.3512693
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 6.288580894470215
Epoch: 67, Steps: 60 | Train Loss: 0.5037179 Vali Loss: 0.2790790 Test Loss: 0.3512855
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 7.662166357040405
Epoch: 68, Steps: 60 | Train Loss: 0.5058506 Vali Loss: 0.2789311 Test Loss: 0.3512734
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 8.057147741317749
Epoch: 69, Steps: 60 | Train Loss: 0.5032340 Vali Loss: 0.2791449 Test Loss: 0.3512615
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 7.736220598220825
Epoch: 70, Steps: 60 | Train Loss: 0.5065723 Vali Loss: 0.2791394 Test Loss: 0.3512751
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 7.580664157867432
Epoch: 71, Steps: 60 | Train Loss: 0.5057031 Vali Loss: 0.2791300 Test Loss: 0.3512804
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 7.811522960662842
Epoch: 72, Steps: 60 | Train Loss: 0.5057763 Vali Loss: 0.2791625 Test Loss: 0.3512677
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 7.8083295822143555
Epoch: 73, Steps: 60 | Train Loss: 0.5062460 Vali Loss: 0.2791256 Test Loss: 0.3512599
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 7.8556578159332275
Epoch: 74, Steps: 60 | Train Loss: 0.5055312 Vali Loss: 0.2790908 Test Loss: 0.3512659
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 7.826636552810669
Epoch: 75, Steps: 60 | Train Loss: 0.5052391 Vali Loss: 0.2791603 Test Loss: 0.3512594
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.33166661858558655, mae:0.37433573603630066, rse:0.4618402421474457, corr:[0.26602122 0.26807544 0.26703975 0.26754317 0.26686856 0.2657002
 0.26551518 0.26521993 0.2642202  0.2630799  0.26215756 0.26075047
 0.2591396  0.25792813 0.25725937 0.2569431  0.25662816 0.2562302
 0.25541487 0.25422078 0.25295058 0.25187823 0.25075647 0.24904895
 0.24690126 0.24497011 0.2434969  0.24196611 0.24047914 0.23931642
 0.23831971 0.23687999 0.23537068 0.234256   0.23309991 0.2317743
 0.23069471 0.22994153 0.22900623 0.22800963 0.22749236 0.22708334
 0.22625087 0.22521941 0.22432956 0.22323434 0.22188808 0.22038828
 0.21873666 0.21685359 0.2150964  0.21366748 0.2124589  0.21057613
 0.20822084 0.20664266 0.20517853 0.20312327 0.20146482 0.20048492
 0.19975373 0.1991286  0.19916718 0.1993137  0.19861828 0.19807157
 0.19773519 0.1970253  0.19618422 0.19565347 0.19503255 0.19390841
 0.19267105 0.19200426 0.19126084 0.18960889 0.1884119  0.18819675
 0.18792078 0.18684879 0.18650614 0.18642755 0.18570827 0.18490192
 0.18480936 0.18509455 0.18471044 0.18411602 0.18370165 0.18336639
 0.1826619  0.18201467 0.18216516 0.18192156 0.18123385 0.18097204
 0.18080066 0.17986637 0.17860362 0.17775743 0.17694286 0.17554569
 0.17462179 0.17424989 0.17386265 0.1729428  0.1724164  0.17274143
 0.17221493 0.17114797 0.17039382 0.1702229  0.16952528 0.16899194
 0.16873387 0.16813871 0.16728418 0.16629457 0.16531277 0.16356117
 0.16178451 0.1606084  0.15992266 0.15877515 0.15736853 0.15635927
 0.15559117 0.15458822 0.15399827 0.15339383 0.15230256 0.1510809
 0.15072842 0.15042363 0.14956318 0.14915812 0.1492013  0.1486945
 0.14763181 0.1472239  0.14740567 0.1467628  0.14567694 0.14477651
 0.14335212 0.14148055 0.14007166 0.13916017 0.13788022 0.13674377
 0.13675901 0.1362342  0.13518134 0.13466644 0.13477884 0.13400863
 0.13305692 0.13336569 0.13424481 0.13410339 0.1331321  0.13364173
 0.13415241 0.13312097 0.1326017  0.1334295  0.13366546 0.13225006
 0.13151579 0.13098863 0.12960817 0.12815908 0.12839602 0.1276063
 0.12534621 0.12387262 0.12377536 0.1227999  0.12076253 0.12115933
 0.12166607 0.1203351  0.12069183 0.12316886 0.12236292 0.12045644
 0.12193377 0.12251994 0.120561   0.1220578  0.12427405 0.11469924]
