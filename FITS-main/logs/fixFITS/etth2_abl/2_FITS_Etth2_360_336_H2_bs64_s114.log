Args in experiment:
Namespace(H_order=2, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=42, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_360_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_360_336_FITS_ETTh2_ftM_sl360_ll48_pl336_H2_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7945
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=42, out_features=81, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3048192.0
params:  3483.0
Trainable parameters:  3483
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.646315097808838
Epoch: 1, Steps: 62 | Train Loss: 0.6960285 Vali Loss: 0.5091831 Test Loss: 0.4633085
Validation loss decreased (inf --> 0.509183).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.731665849685669
Epoch: 2, Steps: 62 | Train Loss: 0.5848205 Vali Loss: 0.4713113 Test Loss: 0.4319607
Validation loss decreased (0.509183 --> 0.471311).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.3490285873413086
Epoch: 3, Steps: 62 | Train Loss: 0.5185966 Vali Loss: 0.4482450 Test Loss: 0.4142193
Validation loss decreased (0.471311 --> 0.448245).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.5464012622833252
Epoch: 4, Steps: 62 | Train Loss: 0.4755232 Vali Loss: 0.4336554 Test Loss: 0.4040400
Validation loss decreased (0.448245 --> 0.433655).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.8846702575683594
Epoch: 5, Steps: 62 | Train Loss: 0.4467800 Vali Loss: 0.4283921 Test Loss: 0.3979531
Validation loss decreased (0.433655 --> 0.428392).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.0021581649780273
Epoch: 6, Steps: 62 | Train Loss: 0.4270126 Vali Loss: 0.4220437 Test Loss: 0.3940139
Validation loss decreased (0.428392 --> 0.422044).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.022636651992798
Epoch: 7, Steps: 62 | Train Loss: 0.4116994 Vali Loss: 0.4144083 Test Loss: 0.3912424
Validation loss decreased (0.422044 --> 0.414408).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.0102720260620117
Epoch: 8, Steps: 62 | Train Loss: 0.4005076 Vali Loss: 0.4140978 Test Loss: 0.3895232
Validation loss decreased (0.414408 --> 0.414098).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.075326919555664
Epoch: 9, Steps: 62 | Train Loss: 0.3911000 Vali Loss: 0.4109347 Test Loss: 0.3879935
Validation loss decreased (0.414098 --> 0.410935).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.2207119464874268
Epoch: 10, Steps: 62 | Train Loss: 0.3839605 Vali Loss: 0.4088473 Test Loss: 0.3866990
Validation loss decreased (0.410935 --> 0.408847).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.2871367931365967
Epoch: 11, Steps: 62 | Train Loss: 0.3776479 Vali Loss: 0.4049488 Test Loss: 0.3857282
Validation loss decreased (0.408847 --> 0.404949).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.9207077026367188
Epoch: 12, Steps: 62 | Train Loss: 0.3720257 Vali Loss: 0.4027805 Test Loss: 0.3846734
Validation loss decreased (0.404949 --> 0.402780).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.5451362133026123
Epoch: 13, Steps: 62 | Train Loss: 0.3676992 Vali Loss: 0.4022891 Test Loss: 0.3837770
Validation loss decreased (0.402780 --> 0.402289).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.9851343631744385
Epoch: 14, Steps: 62 | Train Loss: 0.3635809 Vali Loss: 0.4016756 Test Loss: 0.3829004
Validation loss decreased (0.402289 --> 0.401676).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.088346242904663
Epoch: 15, Steps: 62 | Train Loss: 0.3593947 Vali Loss: 0.4010858 Test Loss: 0.3822075
Validation loss decreased (0.401676 --> 0.401086).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.9627532958984375
Epoch: 16, Steps: 62 | Train Loss: 0.3569780 Vali Loss: 0.4010240 Test Loss: 0.3814086
Validation loss decreased (0.401086 --> 0.401024).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.0425333976745605
Epoch: 17, Steps: 62 | Train Loss: 0.3541127 Vali Loss: 0.3972981 Test Loss: 0.3806828
Validation loss decreased (0.401024 --> 0.397298).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.755547285079956
Epoch: 18, Steps: 62 | Train Loss: 0.3515968 Vali Loss: 0.3980056 Test Loss: 0.3801560
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.8625519275665283
Epoch: 19, Steps: 62 | Train Loss: 0.3495756 Vali Loss: 0.3912877 Test Loss: 0.3794955
Validation loss decreased (0.397298 --> 0.391288).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.7314410209655762
Epoch: 20, Steps: 62 | Train Loss: 0.3473058 Vali Loss: 0.3949451 Test Loss: 0.3789184
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.902172565460205
Epoch: 21, Steps: 62 | Train Loss: 0.3457433 Vali Loss: 0.3937353 Test Loss: 0.3784430
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.1048460006713867
Epoch: 22, Steps: 62 | Train Loss: 0.3441796 Vali Loss: 0.3930808 Test Loss: 0.3779351
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.00542950630188
Epoch: 23, Steps: 62 | Train Loss: 0.3427301 Vali Loss: 0.3924665 Test Loss: 0.3774793
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.8089098930358887
Epoch: 24, Steps: 62 | Train Loss: 0.3406711 Vali Loss: 0.3958854 Test Loss: 0.3769745
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.9741556644439697
Epoch: 25, Steps: 62 | Train Loss: 0.3400023 Vali Loss: 0.3919623 Test Loss: 0.3766180
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.8347325325012207
Epoch: 26, Steps: 62 | Train Loss: 0.3386432 Vali Loss: 0.3922873 Test Loss: 0.3762105
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.7413077354431152
Epoch: 27, Steps: 62 | Train Loss: 0.3378116 Vali Loss: 0.3882066 Test Loss: 0.3759362
Validation loss decreased (0.391288 --> 0.388207).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.248520612716675
Epoch: 28, Steps: 62 | Train Loss: 0.3367986 Vali Loss: 0.3936737 Test Loss: 0.3756522
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.148345470428467
Epoch: 29, Steps: 62 | Train Loss: 0.3361006 Vali Loss: 0.3915374 Test Loss: 0.3752961
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.9023730754852295
Epoch: 30, Steps: 62 | Train Loss: 0.3352293 Vali Loss: 0.3919728 Test Loss: 0.3749481
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.8026506900787354
Epoch: 31, Steps: 62 | Train Loss: 0.3342574 Vali Loss: 0.3899809 Test Loss: 0.3746854
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.024603843688965
Epoch: 32, Steps: 62 | Train Loss: 0.3336188 Vali Loss: 0.3902595 Test Loss: 0.3745295
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.848543643951416
Epoch: 33, Steps: 62 | Train Loss: 0.3330770 Vali Loss: 0.3857974 Test Loss: 0.3742246
Validation loss decreased (0.388207 --> 0.385797).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.2273690700531006
Epoch: 34, Steps: 62 | Train Loss: 0.3325270 Vali Loss: 0.3885193 Test Loss: 0.3740329
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.991542100906372
Epoch: 35, Steps: 62 | Train Loss: 0.3320933 Vali Loss: 0.3891629 Test Loss: 0.3738457
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.5346224308013916
Epoch: 36, Steps: 62 | Train Loss: 0.3311563 Vali Loss: 0.3883126 Test Loss: 0.3736124
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.672990083694458
Epoch: 37, Steps: 62 | Train Loss: 0.3309565 Vali Loss: 0.3858036 Test Loss: 0.3735053
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.126443386077881
Epoch: 38, Steps: 62 | Train Loss: 0.3305479 Vali Loss: 0.3876959 Test Loss: 0.3732592
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.665177822113037
Epoch: 39, Steps: 62 | Train Loss: 0.3300390 Vali Loss: 0.3863809 Test Loss: 0.3730991
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.760730504989624
Epoch: 40, Steps: 62 | Train Loss: 0.3297825 Vali Loss: 0.3891512 Test Loss: 0.3729550
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.9437034130096436
Epoch: 41, Steps: 62 | Train Loss: 0.3295462 Vali Loss: 0.3860821 Test Loss: 0.3728055
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.9868214130401611
Epoch: 42, Steps: 62 | Train Loss: 0.3290982 Vali Loss: 0.3870539 Test Loss: 0.3726917
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.9379510879516602
Epoch: 43, Steps: 62 | Train Loss: 0.3285439 Vali Loss: 0.3872463 Test Loss: 0.3725963
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.9057204723358154
Epoch: 44, Steps: 62 | Train Loss: 0.3284814 Vali Loss: 0.3867865 Test Loss: 0.3724599
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.0023202896118164
Epoch: 45, Steps: 62 | Train Loss: 0.3281894 Vali Loss: 0.3868326 Test Loss: 0.3723049
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.6664927005767822
Epoch: 46, Steps: 62 | Train Loss: 0.3275725 Vali Loss: 0.3887538 Test Loss: 0.3722490
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.4621491432189941
Epoch: 47, Steps: 62 | Train Loss: 0.3274220 Vali Loss: 0.3854204 Test Loss: 0.3721091
Validation loss decreased (0.385797 --> 0.385420).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.0327653884887695
Epoch: 48, Steps: 62 | Train Loss: 0.3274982 Vali Loss: 0.3873918 Test Loss: 0.3720403
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.9777679443359375
Epoch: 49, Steps: 62 | Train Loss: 0.3269765 Vali Loss: 0.3844800 Test Loss: 0.3719315
Validation loss decreased (0.385420 --> 0.384480).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.9877541065216064
Epoch: 50, Steps: 62 | Train Loss: 0.3265947 Vali Loss: 0.3867099 Test Loss: 0.3718646
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.270148992538452
Epoch: 51, Steps: 62 | Train Loss: 0.3268917 Vali Loss: 0.3876285 Test Loss: 0.3717672
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.8525097370147705
Epoch: 52, Steps: 62 | Train Loss: 0.3267642 Vali Loss: 0.3837242 Test Loss: 0.3717255
Validation loss decreased (0.384480 --> 0.383724).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.195399761199951
Epoch: 53, Steps: 62 | Train Loss: 0.3263624 Vali Loss: 0.3835082 Test Loss: 0.3716170
Validation loss decreased (0.383724 --> 0.383508).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.093118190765381
Epoch: 54, Steps: 62 | Train Loss: 0.3263992 Vali Loss: 0.3868993 Test Loss: 0.3715484
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.0779459476470947
Epoch: 55, Steps: 62 | Train Loss: 0.3260063 Vali Loss: 0.3860942 Test Loss: 0.3715117
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.691683292388916
Epoch: 56, Steps: 62 | Train Loss: 0.3257257 Vali Loss: 0.3864138 Test Loss: 0.3714532
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.0865511894226074
Epoch: 57, Steps: 62 | Train Loss: 0.3258629 Vali Loss: 0.3848482 Test Loss: 0.3713940
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.2549359798431396
Epoch: 58, Steps: 62 | Train Loss: 0.3256131 Vali Loss: 0.3831309 Test Loss: 0.3713330
Validation loss decreased (0.383508 --> 0.383131).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.18524169921875
Epoch: 59, Steps: 62 | Train Loss: 0.3256699 Vali Loss: 0.3853413 Test Loss: 0.3712981
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.5970494747161865
Epoch: 60, Steps: 62 | Train Loss: 0.3254956 Vali Loss: 0.3835598 Test Loss: 0.3712328
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.043912172317505
Epoch: 61, Steps: 62 | Train Loss: 0.3254661 Vali Loss: 0.3856919 Test Loss: 0.3711987
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.0675671100616455
Epoch: 62, Steps: 62 | Train Loss: 0.3254312 Vali Loss: 0.3855399 Test Loss: 0.3711496
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.1280484199523926
Epoch: 63, Steps: 62 | Train Loss: 0.3251270 Vali Loss: 0.3859262 Test Loss: 0.3711163
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.306079864501953
Epoch: 64, Steps: 62 | Train Loss: 0.3249024 Vali Loss: 0.3828618 Test Loss: 0.3710712
Validation loss decreased (0.383131 --> 0.382862).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.247836112976074
Epoch: 65, Steps: 62 | Train Loss: 0.3248002 Vali Loss: 0.3866639 Test Loss: 0.3710288
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.681138038635254
Epoch: 66, Steps: 62 | Train Loss: 0.3250251 Vali Loss: 0.3839845 Test Loss: 0.3709878
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.5965421199798584
Epoch: 67, Steps: 62 | Train Loss: 0.3248646 Vali Loss: 0.3840753 Test Loss: 0.3709723
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.916546106338501
Epoch: 68, Steps: 62 | Train Loss: 0.3246307 Vali Loss: 0.3844692 Test Loss: 0.3709260
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.2722272872924805
Epoch: 69, Steps: 62 | Train Loss: 0.3247621 Vali Loss: 0.3874371 Test Loss: 0.3708971
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.7344701290130615
Epoch: 70, Steps: 62 | Train Loss: 0.3247216 Vali Loss: 0.3851504 Test Loss: 0.3708683
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.8499023914337158
Epoch: 71, Steps: 62 | Train Loss: 0.3242933 Vali Loss: 0.3848654 Test Loss: 0.3708460
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.9973046779632568
Epoch: 72, Steps: 62 | Train Loss: 0.3241798 Vali Loss: 0.3834835 Test Loss: 0.3708137
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.5835373401641846
Epoch: 73, Steps: 62 | Train Loss: 0.3243066 Vali Loss: 0.3844830 Test Loss: 0.3708018
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.7922112941741943
Epoch: 74, Steps: 62 | Train Loss: 0.3243201 Vali Loss: 0.3869562 Test Loss: 0.3707649
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.574737787246704
Epoch: 75, Steps: 62 | Train Loss: 0.3243100 Vali Loss: 0.3842895 Test Loss: 0.3707530
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.6798324584960938
Epoch: 76, Steps: 62 | Train Loss: 0.3240700 Vali Loss: 0.3846816 Test Loss: 0.3707173
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.8868577480316162
Epoch: 77, Steps: 62 | Train Loss: 0.3237886 Vali Loss: 0.3848601 Test Loss: 0.3707061
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.2504005432128906
Epoch: 78, Steps: 62 | Train Loss: 0.3242542 Vali Loss: 0.3836550 Test Loss: 0.3706792
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.425020217895508
Epoch: 79, Steps: 62 | Train Loss: 0.3240292 Vali Loss: 0.3851506 Test Loss: 0.3706633
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.8762850761413574
Epoch: 80, Steps: 62 | Train Loss: 0.3240584 Vali Loss: 0.3849527 Test Loss: 0.3706547
EarlyStopping counter: 16 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.7411036491394043
Epoch: 81, Steps: 62 | Train Loss: 0.3240656 Vali Loss: 0.3872671 Test Loss: 0.3706334
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.957916021347046
Epoch: 82, Steps: 62 | Train Loss: 0.3240580 Vali Loss: 0.3867842 Test Loss: 0.3706160
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.1513731479644775
Epoch: 83, Steps: 62 | Train Loss: 0.3240775 Vali Loss: 0.3847259 Test Loss: 0.3706026
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.3323190212249756
Epoch: 84, Steps: 62 | Train Loss: 0.3240543 Vali Loss: 0.3841915 Test Loss: 0.3705906
EarlyStopping counter: 20 out of 20
Early stopping
train 7945
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=42, out_features=81, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3048192.0
params:  3483.0
Trainable parameters:  3483
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.1615793704986572
Epoch: 1, Steps: 62 | Train Loss: 0.6190640 Vali Loss: 0.3814824 Test Loss: 0.3670714
Validation loss decreased (inf --> 0.381482).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.1217963695526123
Epoch: 2, Steps: 62 | Train Loss: 0.6147229 Vali Loss: 0.3814439 Test Loss: 0.3651949
Validation loss decreased (0.381482 --> 0.381444).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.7868359088897705
Epoch: 3, Steps: 62 | Train Loss: 0.6136790 Vali Loss: 0.3789613 Test Loss: 0.3647177
Validation loss decreased (0.381444 --> 0.378961).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.11250901222229
Epoch: 4, Steps: 62 | Train Loss: 0.6128254 Vali Loss: 0.3774691 Test Loss: 0.3643160
Validation loss decreased (0.378961 --> 0.377469).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.273350238800049
Epoch: 5, Steps: 62 | Train Loss: 0.6122915 Vali Loss: 0.3759876 Test Loss: 0.3642673
Validation loss decreased (0.377469 --> 0.375988).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.143209934234619
Epoch: 6, Steps: 62 | Train Loss: 0.6114759 Vali Loss: 0.3803312 Test Loss: 0.3642963
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.670048236846924
Epoch: 7, Steps: 62 | Train Loss: 0.6115870 Vali Loss: 0.3757048 Test Loss: 0.3641758
Validation loss decreased (0.375988 --> 0.375705).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.9437065124511719
Epoch: 8, Steps: 62 | Train Loss: 0.6106609 Vali Loss: 0.3765815 Test Loss: 0.3641728
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.7087900638580322
Epoch: 9, Steps: 62 | Train Loss: 0.6109638 Vali Loss: 0.3779604 Test Loss: 0.3640395
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.8129651546478271
Epoch: 10, Steps: 62 | Train Loss: 0.6108898 Vali Loss: 0.3772885 Test Loss: 0.3639684
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.653642177581787
Epoch: 11, Steps: 62 | Train Loss: 0.6095062 Vali Loss: 0.3768635 Test Loss: 0.3640438
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.6487581729888916
Epoch: 12, Steps: 62 | Train Loss: 0.6097357 Vali Loss: 0.3754887 Test Loss: 0.3640613
Validation loss decreased (0.375705 --> 0.375489).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.893129587173462
Epoch: 13, Steps: 62 | Train Loss: 0.6101626 Vali Loss: 0.3763926 Test Loss: 0.3642280
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.703490972518921
Epoch: 14, Steps: 62 | Train Loss: 0.6102930 Vali Loss: 0.3756968 Test Loss: 0.3640903
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.3456060886383057
Epoch: 15, Steps: 62 | Train Loss: 0.6099165 Vali Loss: 0.3773153 Test Loss: 0.3640602
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.7512764930725098
Epoch: 16, Steps: 62 | Train Loss: 0.6099903 Vali Loss: 0.3735206 Test Loss: 0.3642066
Validation loss decreased (0.375489 --> 0.373521).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.1373026371002197
Epoch: 17, Steps: 62 | Train Loss: 0.6091719 Vali Loss: 0.3757607 Test Loss: 0.3640789
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.8298473358154297
Epoch: 18, Steps: 62 | Train Loss: 0.6096039 Vali Loss: 0.3737957 Test Loss: 0.3640559
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.118572473526001
Epoch: 19, Steps: 62 | Train Loss: 0.6092797 Vali Loss: 0.3735137 Test Loss: 0.3640710
Validation loss decreased (0.373521 --> 0.373514).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.2633817195892334
Epoch: 20, Steps: 62 | Train Loss: 0.6088035 Vali Loss: 0.3753986 Test Loss: 0.3639432
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.0424654483795166
Epoch: 21, Steps: 62 | Train Loss: 0.6095490 Vali Loss: 0.3767299 Test Loss: 0.3640379
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.8259458541870117
Epoch: 22, Steps: 62 | Train Loss: 0.6096060 Vali Loss: 0.3755262 Test Loss: 0.3639315
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.347682476043701
Epoch: 23, Steps: 62 | Train Loss: 0.6092969 Vali Loss: 0.3747418 Test Loss: 0.3640494
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.8150100708007812
Epoch: 24, Steps: 62 | Train Loss: 0.6095146 Vali Loss: 0.3747667 Test Loss: 0.3640798
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.8132884502410889
Epoch: 25, Steps: 62 | Train Loss: 0.6091619 Vali Loss: 0.3736567 Test Loss: 0.3640173
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.009014368057251
Epoch: 26, Steps: 62 | Train Loss: 0.6090389 Vali Loss: 0.3749332 Test Loss: 0.3640174
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.9305651187896729
Epoch: 27, Steps: 62 | Train Loss: 0.6083568 Vali Loss: 0.3752267 Test Loss: 0.3640676
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.078955888748169
Epoch: 28, Steps: 62 | Train Loss: 0.6090480 Vali Loss: 0.3734243 Test Loss: 0.3639845
Validation loss decreased (0.373514 --> 0.373424).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.9417500495910645
Epoch: 29, Steps: 62 | Train Loss: 0.6089487 Vali Loss: 0.3753148 Test Loss: 0.3639898
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.935154914855957
Epoch: 30, Steps: 62 | Train Loss: 0.6086776 Vali Loss: 0.3732954 Test Loss: 0.3640510
Validation loss decreased (0.373424 --> 0.373295).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.8884341716766357
Epoch: 31, Steps: 62 | Train Loss: 0.6088791 Vali Loss: 0.3769921 Test Loss: 0.3640566
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.192230463027954
Epoch: 32, Steps: 62 | Train Loss: 0.6086724 Vali Loss: 0.3744098 Test Loss: 0.3639606
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.811258316040039
Epoch: 33, Steps: 62 | Train Loss: 0.6077576 Vali Loss: 0.3735272 Test Loss: 0.3640522
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.4090278148651123
Epoch: 34, Steps: 62 | Train Loss: 0.6079048 Vali Loss: 0.3742003 Test Loss: 0.3640145
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.9250538349151611
Epoch: 35, Steps: 62 | Train Loss: 0.6085927 Vali Loss: 0.3734153 Test Loss: 0.3639954
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.4615914821624756
Epoch: 36, Steps: 62 | Train Loss: 0.6089802 Vali Loss: 0.3713367 Test Loss: 0.3640541
Validation loss decreased (0.373295 --> 0.371337).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.7849032878875732
Epoch: 37, Steps: 62 | Train Loss: 0.6085507 Vali Loss: 0.3726165 Test Loss: 0.3639874
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.4512453079223633
Epoch: 38, Steps: 62 | Train Loss: 0.6089803 Vali Loss: 0.3750881 Test Loss: 0.3639840
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 5.547935247421265
Epoch: 39, Steps: 62 | Train Loss: 0.6089007 Vali Loss: 0.3748074 Test Loss: 0.3640273
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 5.315481424331665
Epoch: 40, Steps: 62 | Train Loss: 0.6077464 Vali Loss: 0.3750434 Test Loss: 0.3639973
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 6.580219030380249
Epoch: 41, Steps: 62 | Train Loss: 0.6082197 Vali Loss: 0.3722646 Test Loss: 0.3640084
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 6.872227907180786
Epoch: 42, Steps: 62 | Train Loss: 0.6087758 Vali Loss: 0.3747856 Test Loss: 0.3639908
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 5.970895051956177
Epoch: 43, Steps: 62 | Train Loss: 0.6090076 Vali Loss: 0.3747483 Test Loss: 0.3640108
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 6.172456502914429
Epoch: 44, Steps: 62 | Train Loss: 0.6085810 Vali Loss: 0.3736605 Test Loss: 0.3640041
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 5.421119928359985
Epoch: 45, Steps: 62 | Train Loss: 0.6081588 Vali Loss: 0.3745908 Test Loss: 0.3639734
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 5.7781078815460205
Epoch: 46, Steps: 62 | Train Loss: 0.6075482 Vali Loss: 0.3763943 Test Loss: 0.3640488
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 5.259591579437256
Epoch: 47, Steps: 62 | Train Loss: 0.6080991 Vali Loss: 0.3751914 Test Loss: 0.3640142
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 6.049450635910034
Epoch: 48, Steps: 62 | Train Loss: 0.6078738 Vali Loss: 0.3731875 Test Loss: 0.3640206
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 4.5827460289001465
Epoch: 49, Steps: 62 | Train Loss: 0.6088592 Vali Loss: 0.3765671 Test Loss: 0.3640147
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 5.135245323181152
Epoch: 50, Steps: 62 | Train Loss: 0.6085117 Vali Loss: 0.3741322 Test Loss: 0.3640108
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 4.47816801071167
Epoch: 51, Steps: 62 | Train Loss: 0.6084849 Vali Loss: 0.3732728 Test Loss: 0.3640227
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.9017343521118164
Epoch: 52, Steps: 62 | Train Loss: 0.6080543 Vali Loss: 0.3759986 Test Loss: 0.3640136
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.4556243419647217
Epoch: 53, Steps: 62 | Train Loss: 0.6079734 Vali Loss: 0.3741363 Test Loss: 0.3639827
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.0415053367614746
Epoch: 54, Steps: 62 | Train Loss: 0.6074320 Vali Loss: 0.3736964 Test Loss: 0.3640319
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.041764259338379
Epoch: 55, Steps: 62 | Train Loss: 0.6084383 Vali Loss: 0.3760044 Test Loss: 0.3640140
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.0081686973571777
Epoch: 56, Steps: 62 | Train Loss: 0.6083559 Vali Loss: 0.3732640 Test Loss: 0.3640200
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_360_336_FITS_ETTh2_ftM_sl360_ll48_pl336_H2_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.3596647381782532, mae:0.3972597122192383, rse:0.47949984669685364, corr:[0.26248014 0.26436624 0.26466307 0.26320502 0.2610519  0.25932512
 0.25841123 0.25781268 0.25732344 0.25633594 0.2549312  0.25316375
 0.25167498 0.2504953  0.24969976 0.2492197  0.24861309 0.2478341
 0.24678694 0.2455333  0.24427007 0.24295405 0.24161784 0.24023435
 0.23878601 0.23738149 0.2361022  0.23477876 0.23340648 0.23211324
 0.23098877 0.23003167 0.22903262 0.22801502 0.22693515 0.22584529
 0.22470646 0.22357273 0.22262925 0.22180064 0.22101381 0.22013564
 0.21902752 0.21768492 0.21618795 0.21464054 0.21306162 0.2113673
 0.20961353 0.20798069 0.20645155 0.20490696 0.20322432 0.20138226
 0.19943151 0.19747645 0.19587326 0.19446583 0.19343281 0.19285004
 0.19265626 0.19256555 0.19245332 0.1921742  0.19158153 0.19089918
 0.1900208  0.18912582 0.18817264 0.18738253 0.18670374 0.18607055
 0.18540363 0.18466058 0.18382625 0.1829059  0.18212745 0.18146144
 0.18087444 0.18030007 0.17998715 0.1796783  0.17939712 0.17904468
 0.17880899 0.1785588  0.17835674 0.17813405 0.17781696 0.17752385
 0.17727008 0.17692617 0.17677684 0.17664674 0.1764715  0.17619401
 0.17587464 0.17533107 0.17472562 0.17396313 0.17316914 0.17253122
 0.1723004  0.17216381 0.17228895 0.1724415  0.17250215 0.17243688
 0.17194134 0.1711643  0.17029187 0.16977435 0.1694158  0.1692792
 0.16917373 0.16876261 0.16813843 0.16698644 0.16558337 0.16411291
 0.16288288 0.16184598 0.16113925 0.16078426 0.16038173 0.15986243
 0.15906188 0.15821648 0.15741573 0.1566978  0.15625674 0.1560156
 0.15585555 0.15551443 0.15495443 0.15429905 0.1536604  0.15326446
 0.15290517 0.15272714 0.15260462 0.1521143  0.15108545 0.1497161
 0.1482325  0.14681329 0.14551516 0.1445639  0.14396901 0.14351545
 0.14319758 0.1427755  0.14237723 0.14202677 0.14168142 0.14130452
 0.14099164 0.14086802 0.14061663 0.14037538 0.14009915 0.13977128
 0.13952217 0.1393528  0.1392568  0.1390127  0.13862108 0.13785654
 0.13696645 0.13600083 0.13489273 0.13383031 0.13283186 0.13185723
 0.13100252 0.13016762 0.12951039 0.12887532 0.12835482 0.12777987
 0.12739949 0.12715231 0.12693626 0.12683877 0.12670282 0.1265066
 0.12646987 0.12658374 0.12679167 0.12717447 0.12752901 0.1275332
 0.12729685 0.12670547 0.12591234 0.12517011 0.1245358  0.12405744
 0.12389708 0.12391296 0.12393358 0.1238208  0.12366692 0.12326406
 0.12288371 0.12263234 0.12253066 0.12278792 0.12309083 0.12339813
 0.12359205 0.12378404 0.12393167 0.12370567 0.12331497 0.12256261
 0.12182557 0.12098584 0.1202984  0.11993515 0.11954169 0.11929769
 0.1189284  0.11866216 0.1183277  0.11779821 0.11737747 0.11692975
 0.11651015 0.11603953 0.11555166 0.11537717 0.11546306 0.11587956
 0.11640345 0.11717902 0.11781234 0.11793754 0.11754327 0.11671084
 0.11552985 0.11440087 0.11366706 0.11328803 0.11330525 0.11308275
 0.11259898 0.11197294 0.11127037 0.11045381 0.11002766 0.11019613
 0.11090451 0.11199542 0.11285411 0.11365429 0.11418207 0.11474546
 0.1151714  0.11578254 0.11684998 0.11780678 0.11866213 0.1189205
 0.118704   0.11801839 0.11728129 0.11684755 0.1166703  0.11685811
 0.11712188 0.11744146 0.11750703 0.11719045 0.1171548  0.11697708
 0.11708265 0.1174579  0.11785065 0.11811902 0.11818597 0.11811993
 0.11780263 0.11760183 0.11753137 0.1176779  0.11811187 0.11878754
 0.11873896 0.11774135 0.11629923 0.11506231 0.11390799 0.11318484
 0.11277255 0.11253794 0.11250845 0.11202258 0.11137242 0.11073363
 0.110169   0.1099098  0.10991673 0.11043169 0.11072271 0.11122552
 0.1113532  0.11145068 0.11165922 0.11153768 0.11180525 0.11200627
 0.11196798 0.11129957 0.11017394 0.10888458 0.10750583 0.10653886
 0.10614488 0.10647473 0.10691275 0.1072321  0.10755157 0.10764889
 0.10737948 0.10687281 0.10688513 0.10771521 0.10892781 0.10999455
 0.11047729 0.1107309  0.11121079 0.11237127 0.1156835  0.11998197]
