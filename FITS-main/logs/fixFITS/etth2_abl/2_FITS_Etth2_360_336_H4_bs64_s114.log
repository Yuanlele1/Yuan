Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=74, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_360_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_360_336_FITS_ETTh2_ftM_sl360_ll48_pl336_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7945
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=74, out_features=143, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  9481472.0
params:  10725.0
Trainable parameters:  10725
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.124377727508545
Epoch: 1, Steps: 62 | Train Loss: 0.6795094 Vali Loss: 0.5109024 Test Loss: 0.4517536
Validation loss decreased (inf --> 0.510902).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.246595859527588
Epoch: 2, Steps: 62 | Train Loss: 0.5551037 Vali Loss: 0.4665806 Test Loss: 0.4192733
Validation loss decreased (0.510902 --> 0.466581).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.7860665321350098
Epoch: 3, Steps: 62 | Train Loss: 0.4884895 Vali Loss: 0.4458820 Test Loss: 0.4044397
Validation loss decreased (0.466581 --> 0.445882).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 5.066474437713623
Epoch: 4, Steps: 62 | Train Loss: 0.4506289 Vali Loss: 0.4319648 Test Loss: 0.3975442
Validation loss decreased (0.445882 --> 0.431965).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.7000768184661865
Epoch: 5, Steps: 62 | Train Loss: 0.4262158 Vali Loss: 0.4221879 Test Loss: 0.3941498
Validation loss decreased (0.431965 --> 0.422188).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.9944136142730713
Epoch: 6, Steps: 62 | Train Loss: 0.4096501 Vali Loss: 0.4166794 Test Loss: 0.3918993
Validation loss decreased (0.422188 --> 0.416679).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.394648790359497
Epoch: 7, Steps: 62 | Train Loss: 0.3969971 Vali Loss: 0.4140347 Test Loss: 0.3905192
Validation loss decreased (0.416679 --> 0.414035).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.616234064102173
Epoch: 8, Steps: 62 | Train Loss: 0.3870759 Vali Loss: 0.4111468 Test Loss: 0.3892866
Validation loss decreased (0.414035 --> 0.411147).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 4.901499271392822
Epoch: 9, Steps: 62 | Train Loss: 0.3789032 Vali Loss: 0.4091687 Test Loss: 0.3881415
Validation loss decreased (0.411147 --> 0.409169).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.416034460067749
Epoch: 10, Steps: 62 | Train Loss: 0.3717055 Vali Loss: 0.4061159 Test Loss: 0.3871075
Validation loss decreased (0.409169 --> 0.406116).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.8403000831604004
Epoch: 11, Steps: 62 | Train Loss: 0.3659404 Vali Loss: 0.4032070 Test Loss: 0.3861311
Validation loss decreased (0.406116 --> 0.403207).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.3428847789764404
Epoch: 12, Steps: 62 | Train Loss: 0.3610878 Vali Loss: 0.4010769 Test Loss: 0.3849739
Validation loss decreased (0.403207 --> 0.401077).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.2875568866729736
Epoch: 13, Steps: 62 | Train Loss: 0.3563617 Vali Loss: 0.3997062 Test Loss: 0.3839902
Validation loss decreased (0.401077 --> 0.399706).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.177299737930298
Epoch: 14, Steps: 62 | Train Loss: 0.3528552 Vali Loss: 0.4008943 Test Loss: 0.3832925
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.331559181213379
Epoch: 15, Steps: 62 | Train Loss: 0.3490523 Vali Loss: 0.3982346 Test Loss: 0.3822307
Validation loss decreased (0.399706 --> 0.398235).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.35430908203125
Epoch: 16, Steps: 62 | Train Loss: 0.3464022 Vali Loss: 0.3957693 Test Loss: 0.3814620
Validation loss decreased (0.398235 --> 0.395769).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.5300211906433105
Epoch: 17, Steps: 62 | Train Loss: 0.3434093 Vali Loss: 0.3928379 Test Loss: 0.3808086
Validation loss decreased (0.395769 --> 0.392838).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.132901191711426
Epoch: 18, Steps: 62 | Train Loss: 0.3413099 Vali Loss: 0.3943931 Test Loss: 0.3799726
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.927086591720581
Epoch: 19, Steps: 62 | Train Loss: 0.3387211 Vali Loss: 0.3925856 Test Loss: 0.3793839
Validation loss decreased (0.392838 --> 0.392586).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.3004353046417236
Epoch: 20, Steps: 62 | Train Loss: 0.3369291 Vali Loss: 0.3916660 Test Loss: 0.3786166
Validation loss decreased (0.392586 --> 0.391666).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.2314908504486084
Epoch: 21, Steps: 62 | Train Loss: 0.3354601 Vali Loss: 0.3907259 Test Loss: 0.3780663
Validation loss decreased (0.391666 --> 0.390726).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.8647873401641846
Epoch: 22, Steps: 62 | Train Loss: 0.3338922 Vali Loss: 0.3921698 Test Loss: 0.3775119
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.530006170272827
Epoch: 23, Steps: 62 | Train Loss: 0.3324052 Vali Loss: 0.3912524 Test Loss: 0.3769942
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.0158650875091553
Epoch: 24, Steps: 62 | Train Loss: 0.3312195 Vali Loss: 0.3896898 Test Loss: 0.3765559
Validation loss decreased (0.390726 --> 0.389690).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.022132158279419
Epoch: 25, Steps: 62 | Train Loss: 0.3299265 Vali Loss: 0.3886744 Test Loss: 0.3760799
Validation loss decreased (0.389690 --> 0.388674).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.2724435329437256
Epoch: 26, Steps: 62 | Train Loss: 0.3286618 Vali Loss: 0.3896273 Test Loss: 0.3757038
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.82509183883667
Epoch: 27, Steps: 62 | Train Loss: 0.3278628 Vali Loss: 0.3893910 Test Loss: 0.3753584
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.4846298694610596
Epoch: 28, Steps: 62 | Train Loss: 0.3270896 Vali Loss: 0.3874827 Test Loss: 0.3750179
Validation loss decreased (0.388674 --> 0.387483).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 4.5364367961883545
Epoch: 29, Steps: 62 | Train Loss: 0.3263333 Vali Loss: 0.3865457 Test Loss: 0.3746382
Validation loss decreased (0.387483 --> 0.386546).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.9232795238494873
Epoch: 30, Steps: 62 | Train Loss: 0.3252792 Vali Loss: 0.3882386 Test Loss: 0.3743654
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 3.1401991844177246
Epoch: 31, Steps: 62 | Train Loss: 0.3249447 Vali Loss: 0.3858194 Test Loss: 0.3740250
Validation loss decreased (0.386546 --> 0.385819).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 3.0029447078704834
Epoch: 32, Steps: 62 | Train Loss: 0.3241670 Vali Loss: 0.3874531 Test Loss: 0.3738102
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 3.1611568927764893
Epoch: 33, Steps: 62 | Train Loss: 0.3232055 Vali Loss: 0.3851276 Test Loss: 0.3735411
Validation loss decreased (0.385819 --> 0.385128).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.7026238441467285
Epoch: 34, Steps: 62 | Train Loss: 0.3230496 Vali Loss: 0.3866656 Test Loss: 0.3732435
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 4.131419897079468
Epoch: 35, Steps: 62 | Train Loss: 0.3220207 Vali Loss: 0.3828252 Test Loss: 0.3730944
Validation loss decreased (0.385128 --> 0.382825).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.845900535583496
Epoch: 36, Steps: 62 | Train Loss: 0.3220679 Vali Loss: 0.3848482 Test Loss: 0.3729471
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.7596428394317627
Epoch: 37, Steps: 62 | Train Loss: 0.3216541 Vali Loss: 0.3847567 Test Loss: 0.3726966
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.4867489337921143
Epoch: 38, Steps: 62 | Train Loss: 0.3212294 Vali Loss: 0.3859230 Test Loss: 0.3725212
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 3.8084936141967773
Epoch: 39, Steps: 62 | Train Loss: 0.3209249 Vali Loss: 0.3853223 Test Loss: 0.3723251
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 3.0547099113464355
Epoch: 40, Steps: 62 | Train Loss: 0.3202426 Vali Loss: 0.3866240 Test Loss: 0.3722076
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.4242420196533203
Epoch: 41, Steps: 62 | Train Loss: 0.3200238 Vali Loss: 0.3809366 Test Loss: 0.3720472
Validation loss decreased (0.382825 --> 0.380937).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.485056161880493
Epoch: 42, Steps: 62 | Train Loss: 0.3199886 Vali Loss: 0.3831071 Test Loss: 0.3718856
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 3.508568525314331
Epoch: 43, Steps: 62 | Train Loss: 0.3195512 Vali Loss: 0.3840491 Test Loss: 0.3717716
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 4.106059789657593
Epoch: 44, Steps: 62 | Train Loss: 0.3189467 Vali Loss: 0.3850934 Test Loss: 0.3716307
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.461784601211548
Epoch: 45, Steps: 62 | Train Loss: 0.3188576 Vali Loss: 0.3841761 Test Loss: 0.3715283
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.2349753379821777
Epoch: 46, Steps: 62 | Train Loss: 0.3185990 Vali Loss: 0.3848988 Test Loss: 0.3714369
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.9799575805664062
Epoch: 47, Steps: 62 | Train Loss: 0.3184328 Vali Loss: 0.3842756 Test Loss: 0.3713191
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 4.375221014022827
Epoch: 48, Steps: 62 | Train Loss: 0.3183385 Vali Loss: 0.3848472 Test Loss: 0.3712404
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 3.894184112548828
Epoch: 49, Steps: 62 | Train Loss: 0.3181609 Vali Loss: 0.3835073 Test Loss: 0.3711286
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 4.286209344863892
Epoch: 50, Steps: 62 | Train Loss: 0.3181227 Vali Loss: 0.3830893 Test Loss: 0.3710504
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 3.1495165824890137
Epoch: 51, Steps: 62 | Train Loss: 0.3179152 Vali Loss: 0.3811469 Test Loss: 0.3709750
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 4.02259635925293
Epoch: 52, Steps: 62 | Train Loss: 0.3176231 Vali Loss: 0.3825835 Test Loss: 0.3708944
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 3.5102310180664062
Epoch: 53, Steps: 62 | Train Loss: 0.3172591 Vali Loss: 0.3820795 Test Loss: 0.3708443
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 4.294924259185791
Epoch: 54, Steps: 62 | Train Loss: 0.3173269 Vali Loss: 0.3819301 Test Loss: 0.3707721
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 3.83707594871521
Epoch: 55, Steps: 62 | Train Loss: 0.3167580 Vali Loss: 0.3830723 Test Loss: 0.3707052
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.4098880290985107
Epoch: 56, Steps: 62 | Train Loss: 0.3167832 Vali Loss: 0.3839209 Test Loss: 0.3706279
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.2952823638916016
Epoch: 57, Steps: 62 | Train Loss: 0.3170209 Vali Loss: 0.3808533 Test Loss: 0.3705840
Validation loss decreased (0.380937 --> 0.380853).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.5259408950805664
Epoch: 58, Steps: 62 | Train Loss: 0.3168287 Vali Loss: 0.3839247 Test Loss: 0.3705186
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.2675137519836426
Epoch: 59, Steps: 62 | Train Loss: 0.3167692 Vali Loss: 0.3831707 Test Loss: 0.3704606
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 3.3282904624938965
Epoch: 60, Steps: 62 | Train Loss: 0.3165483 Vali Loss: 0.3841344 Test Loss: 0.3704267
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 3.1080586910247803
Epoch: 61, Steps: 62 | Train Loss: 0.3163345 Vali Loss: 0.3831480 Test Loss: 0.3703638
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.3629379272460938
Epoch: 62, Steps: 62 | Train Loss: 0.3164641 Vali Loss: 0.3835215 Test Loss: 0.3703144
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 3.612407922744751
Epoch: 63, Steps: 62 | Train Loss: 0.3163752 Vali Loss: 0.3805210 Test Loss: 0.3702824
Validation loss decreased (0.380853 --> 0.380521).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 3.114229202270508
Epoch: 64, Steps: 62 | Train Loss: 0.3163330 Vali Loss: 0.3832368 Test Loss: 0.3702446
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.678980588912964
Epoch: 65, Steps: 62 | Train Loss: 0.3160082 Vali Loss: 0.3815747 Test Loss: 0.3702075
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.8492789268493652
Epoch: 66, Steps: 62 | Train Loss: 0.3162037 Vali Loss: 0.3810015 Test Loss: 0.3701780
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.048213005065918
Epoch: 67, Steps: 62 | Train Loss: 0.3160518 Vali Loss: 0.3834707 Test Loss: 0.3701375
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 3.4052634239196777
Epoch: 68, Steps: 62 | Train Loss: 0.3161158 Vali Loss: 0.3833917 Test Loss: 0.3701036
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.715165853500366
Epoch: 69, Steps: 62 | Train Loss: 0.3159836 Vali Loss: 0.3818354 Test Loss: 0.3700778
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 3.2592403888702393
Epoch: 70, Steps: 62 | Train Loss: 0.3153147 Vali Loss: 0.3808438 Test Loss: 0.3700554
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.8992669582366943
Epoch: 71, Steps: 62 | Train Loss: 0.3157474 Vali Loss: 0.3815143 Test Loss: 0.3700182
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.624579906463623
Epoch: 72, Steps: 62 | Train Loss: 0.3152037 Vali Loss: 0.3815974 Test Loss: 0.3699939
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.8259787559509277
Epoch: 73, Steps: 62 | Train Loss: 0.3152128 Vali Loss: 0.3819799 Test Loss: 0.3699751
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.4409310817718506
Epoch: 74, Steps: 62 | Train Loss: 0.3153266 Vali Loss: 0.3813417 Test Loss: 0.3699504
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.212869644165039
Epoch: 75, Steps: 62 | Train Loss: 0.3156179 Vali Loss: 0.3826466 Test Loss: 0.3699190
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.251669406890869
Epoch: 76, Steps: 62 | Train Loss: 0.3156521 Vali Loss: 0.3831737 Test Loss: 0.3699053
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.530076026916504
Epoch: 77, Steps: 62 | Train Loss: 0.3152988 Vali Loss: 0.3822147 Test Loss: 0.3698824
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.5883729457855225
Epoch: 78, Steps: 62 | Train Loss: 0.3154862 Vali Loss: 0.3826045 Test Loss: 0.3698669
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 3.622584581375122
Epoch: 79, Steps: 62 | Train Loss: 0.3154959 Vali Loss: 0.3829125 Test Loss: 0.3698500
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.19875168800354
Epoch: 80, Steps: 62 | Train Loss: 0.3154608 Vali Loss: 0.3832299 Test Loss: 0.3698373
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 3.126779079437256
Epoch: 81, Steps: 62 | Train Loss: 0.3151585 Vali Loss: 0.3821863 Test Loss: 0.3698191
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 4.040544271469116
Epoch: 82, Steps: 62 | Train Loss: 0.3150554 Vali Loss: 0.3837560 Test Loss: 0.3698005
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 4.4970057010650635
Epoch: 83, Steps: 62 | Train Loss: 0.3149962 Vali Loss: 0.3846795 Test Loss: 0.3697876
EarlyStopping counter: 20 out of 20
Early stopping
train 7945
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=74, out_features=143, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  9481472.0
params:  10725.0
Trainable parameters:  10725
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.244683265686035
Epoch: 1, Steps: 62 | Train Loss: 0.6155155 Vali Loss: 0.3781642 Test Loss: 0.3662465
Validation loss decreased (inf --> 0.378164).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.254380226135254
Epoch: 2, Steps: 62 | Train Loss: 0.6121400 Vali Loss: 0.3762531 Test Loss: 0.3640675
Validation loss decreased (0.378164 --> 0.376253).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.6443612575531006
Epoch: 3, Steps: 62 | Train Loss: 0.6095732 Vali Loss: 0.3760427 Test Loss: 0.3634982
Validation loss decreased (0.376253 --> 0.376043).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.705634117126465
Epoch: 4, Steps: 62 | Train Loss: 0.6085871 Vali Loss: 0.3768675 Test Loss: 0.3631007
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.4655563831329346
Epoch: 5, Steps: 62 | Train Loss: 0.6088679 Vali Loss: 0.3759148 Test Loss: 0.3626424
Validation loss decreased (0.376043 --> 0.375915).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.2460477352142334
Epoch: 6, Steps: 62 | Train Loss: 0.6082521 Vali Loss: 0.3753636 Test Loss: 0.3630008
Validation loss decreased (0.375915 --> 0.375364).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.446546792984009
Epoch: 7, Steps: 62 | Train Loss: 0.6079467 Vali Loss: 0.3742593 Test Loss: 0.3627318
Validation loss decreased (0.375364 --> 0.374259).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.5951759815216064
Epoch: 8, Steps: 62 | Train Loss: 0.6075836 Vali Loss: 0.3736357 Test Loss: 0.3626086
Validation loss decreased (0.374259 --> 0.373636).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.6229429244995117
Epoch: 9, Steps: 62 | Train Loss: 0.6073866 Vali Loss: 0.3731709 Test Loss: 0.3626521
Validation loss decreased (0.373636 --> 0.373171).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.5006422996520996
Epoch: 10, Steps: 62 | Train Loss: 0.6069567 Vali Loss: 0.3753897 Test Loss: 0.3626315
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 5.535366773605347
Epoch: 11, Steps: 62 | Train Loss: 0.6069500 Vali Loss: 0.3715277 Test Loss: 0.3628460
Validation loss decreased (0.373171 --> 0.371528).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.102238655090332
Epoch: 12, Steps: 62 | Train Loss: 0.6068960 Vali Loss: 0.3703696 Test Loss: 0.3626753
Validation loss decreased (0.371528 --> 0.370370).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.8998560905456543
Epoch: 13, Steps: 62 | Train Loss: 0.6067878 Vali Loss: 0.3723751 Test Loss: 0.3625781
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 4.407238006591797
Epoch: 14, Steps: 62 | Train Loss: 0.6059628 Vali Loss: 0.3733889 Test Loss: 0.3625845
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.5934298038482666
Epoch: 15, Steps: 62 | Train Loss: 0.6056523 Vali Loss: 0.3722294 Test Loss: 0.3626146
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.4338059425354004
Epoch: 16, Steps: 62 | Train Loss: 0.6054086 Vali Loss: 0.3724225 Test Loss: 0.3625458
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.900136709213257
Epoch: 17, Steps: 62 | Train Loss: 0.6061662 Vali Loss: 0.3713718 Test Loss: 0.3625764
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.2613565921783447
Epoch: 18, Steps: 62 | Train Loss: 0.6059778 Vali Loss: 0.3717334 Test Loss: 0.3624924
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.6780781745910645
Epoch: 19, Steps: 62 | Train Loss: 0.6055423 Vali Loss: 0.3729797 Test Loss: 0.3626368
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.151566743850708
Epoch: 20, Steps: 62 | Train Loss: 0.6056506 Vali Loss: 0.3721682 Test Loss: 0.3625361
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.2830328941345215
Epoch: 21, Steps: 62 | Train Loss: 0.6054799 Vali Loss: 0.3730727 Test Loss: 0.3625590
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.817356824874878
Epoch: 22, Steps: 62 | Train Loss: 0.6057132 Vali Loss: 0.3732351 Test Loss: 0.3624995
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.2831997871398926
Epoch: 23, Steps: 62 | Train Loss: 0.6056547 Vali Loss: 0.3720111 Test Loss: 0.3624652
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.234056234359741
Epoch: 24, Steps: 62 | Train Loss: 0.6056432 Vali Loss: 0.3741656 Test Loss: 0.3624514
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.961548328399658
Epoch: 25, Steps: 62 | Train Loss: 0.6057122 Vali Loss: 0.3714134 Test Loss: 0.3625545
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.3901255130767822
Epoch: 26, Steps: 62 | Train Loss: 0.6054202 Vali Loss: 0.3709914 Test Loss: 0.3625155
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 3.6604065895080566
Epoch: 27, Steps: 62 | Train Loss: 0.6052226 Vali Loss: 0.3696874 Test Loss: 0.3625142
Validation loss decreased (0.370370 --> 0.369687).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.4160683155059814
Epoch: 28, Steps: 62 | Train Loss: 0.6049724 Vali Loss: 0.3711813 Test Loss: 0.3624952
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.936150074005127
Epoch: 29, Steps: 62 | Train Loss: 0.6054436 Vali Loss: 0.3699390 Test Loss: 0.3625144
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 4.191983222961426
Epoch: 30, Steps: 62 | Train Loss: 0.6053413 Vali Loss: 0.3737365 Test Loss: 0.3625250
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.5232598781585693
Epoch: 31, Steps: 62 | Train Loss: 0.6048054 Vali Loss: 0.3713381 Test Loss: 0.3625608
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.9022254943847656
Epoch: 32, Steps: 62 | Train Loss: 0.6051791 Vali Loss: 0.3722397 Test Loss: 0.3624690
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 3.130176305770874
Epoch: 33, Steps: 62 | Train Loss: 0.6044002 Vali Loss: 0.3699339 Test Loss: 0.3625333
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.843740224838257
Epoch: 34, Steps: 62 | Train Loss: 0.6052052 Vali Loss: 0.3722266 Test Loss: 0.3625140
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 3.0841994285583496
Epoch: 35, Steps: 62 | Train Loss: 0.6054112 Vali Loss: 0.3720335 Test Loss: 0.3625391
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 3.3650903701782227
Epoch: 36, Steps: 62 | Train Loss: 0.6052699 Vali Loss: 0.3709998 Test Loss: 0.3624976
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.594782829284668
Epoch: 37, Steps: 62 | Train Loss: 0.6042427 Vali Loss: 0.3717277 Test Loss: 0.3625032
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.668464183807373
Epoch: 38, Steps: 62 | Train Loss: 0.6048719 Vali Loss: 0.3691224 Test Loss: 0.3625100
Validation loss decreased (0.369687 --> 0.369122).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 3.4630963802337646
Epoch: 39, Steps: 62 | Train Loss: 0.6051343 Vali Loss: 0.3703771 Test Loss: 0.3624909
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 4.24351167678833
Epoch: 40, Steps: 62 | Train Loss: 0.6049006 Vali Loss: 0.3708138 Test Loss: 0.3625374
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 4.353842258453369
Epoch: 41, Steps: 62 | Train Loss: 0.6050256 Vali Loss: 0.3708257 Test Loss: 0.3625256
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 3.739269971847534
Epoch: 42, Steps: 62 | Train Loss: 0.6050759 Vali Loss: 0.3704950 Test Loss: 0.3625073
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 3.2843830585479736
Epoch: 43, Steps: 62 | Train Loss: 0.6045477 Vali Loss: 0.3706855 Test Loss: 0.3625433
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.9275074005126953
Epoch: 44, Steps: 62 | Train Loss: 0.6051344 Vali Loss: 0.3705118 Test Loss: 0.3625022
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.4293501377105713
Epoch: 45, Steps: 62 | Train Loss: 0.6051105 Vali Loss: 0.3724957 Test Loss: 0.3625354
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.9334118366241455
Epoch: 46, Steps: 62 | Train Loss: 0.6051468 Vali Loss: 0.3712475 Test Loss: 0.3625126
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.977917432785034
Epoch: 47, Steps: 62 | Train Loss: 0.6044141 Vali Loss: 0.3705820 Test Loss: 0.3625106
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 3.89859676361084
Epoch: 48, Steps: 62 | Train Loss: 0.6047487 Vali Loss: 0.3706671 Test Loss: 0.3624963
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.974226951599121
Epoch: 49, Steps: 62 | Train Loss: 0.6051167 Vali Loss: 0.3715154 Test Loss: 0.3624750
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.2329392433166504
Epoch: 50, Steps: 62 | Train Loss: 0.6047234 Vali Loss: 0.3691166 Test Loss: 0.3625033
Validation loss decreased (0.369122 --> 0.369117).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 4.981170415878296
Epoch: 51, Steps: 62 | Train Loss: 0.6048114 Vali Loss: 0.3707105 Test Loss: 0.3624829
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.6153008937835693
Epoch: 52, Steps: 62 | Train Loss: 0.6046556 Vali Loss: 0.3719079 Test Loss: 0.3624916
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 3.731642484664917
Epoch: 53, Steps: 62 | Train Loss: 0.6048409 Vali Loss: 0.3707199 Test Loss: 0.3624904
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 3.1380937099456787
Epoch: 54, Steps: 62 | Train Loss: 0.6048632 Vali Loss: 0.3712674 Test Loss: 0.3625046
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.276761054992676
Epoch: 55, Steps: 62 | Train Loss: 0.6050540 Vali Loss: 0.3732161 Test Loss: 0.3624879
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 3.525266408920288
Epoch: 56, Steps: 62 | Train Loss: 0.6048064 Vali Loss: 0.3684907 Test Loss: 0.3624935
Validation loss decreased (0.369117 --> 0.368491).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.4455559253692627
Epoch: 57, Steps: 62 | Train Loss: 0.6046049 Vali Loss: 0.3689114 Test Loss: 0.3625114
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.8418338298797607
Epoch: 58, Steps: 62 | Train Loss: 0.6036851 Vali Loss: 0.3717293 Test Loss: 0.3625042
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.459256649017334
Epoch: 59, Steps: 62 | Train Loss: 0.6049830 Vali Loss: 0.3722970 Test Loss: 0.3624904
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.813767910003662
Epoch: 60, Steps: 62 | Train Loss: 0.6048275 Vali Loss: 0.3706076 Test Loss: 0.3624859
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.731506824493408
Epoch: 61, Steps: 62 | Train Loss: 0.6049699 Vali Loss: 0.3700533 Test Loss: 0.3624980
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.4306607246398926
Epoch: 62, Steps: 62 | Train Loss: 0.6045259 Vali Loss: 0.3723094 Test Loss: 0.3624846
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.8628811836242676
Epoch: 63, Steps: 62 | Train Loss: 0.6048583 Vali Loss: 0.3710632 Test Loss: 0.3624870
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.3150525093078613
Epoch: 64, Steps: 62 | Train Loss: 0.6037198 Vali Loss: 0.3715348 Test Loss: 0.3624976
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.3317627906799316
Epoch: 65, Steps: 62 | Train Loss: 0.6045407 Vali Loss: 0.3695781 Test Loss: 0.3625015
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.61409854888916
Epoch: 66, Steps: 62 | Train Loss: 0.6048209 Vali Loss: 0.3713730 Test Loss: 0.3624964
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.6693499088287354
Epoch: 67, Steps: 62 | Train Loss: 0.6044276 Vali Loss: 0.3718172 Test Loss: 0.3624966
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.910048484802246
Epoch: 68, Steps: 62 | Train Loss: 0.6043958 Vali Loss: 0.3714905 Test Loss: 0.3624914
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.8080461025238037
Epoch: 69, Steps: 62 | Train Loss: 0.6048701 Vali Loss: 0.3725651 Test Loss: 0.3624975
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 3.1046552658081055
Epoch: 70, Steps: 62 | Train Loss: 0.6047246 Vali Loss: 0.3692692 Test Loss: 0.3625038
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.395677089691162
Epoch: 71, Steps: 62 | Train Loss: 0.6049291 Vali Loss: 0.3691440 Test Loss: 0.3625031
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 4.264788866043091
Epoch: 72, Steps: 62 | Train Loss: 0.6048748 Vali Loss: 0.3710795 Test Loss: 0.3625074
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.438528537750244
Epoch: 73, Steps: 62 | Train Loss: 0.6042676 Vali Loss: 0.3706290 Test Loss: 0.3624980
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 3.150721549987793
Epoch: 74, Steps: 62 | Train Loss: 0.6048423 Vali Loss: 0.3688946 Test Loss: 0.3625035
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.263516426086426
Epoch: 75, Steps: 62 | Train Loss: 0.6044898 Vali Loss: 0.3711275 Test Loss: 0.3624968
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.9485185146331787
Epoch: 76, Steps: 62 | Train Loss: 0.6048658 Vali Loss: 0.3728265 Test Loss: 0.3625067
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_360_336_FITS_ETTh2_ftM_sl360_ll48_pl336_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.35809582471847534, mae:0.3963037431240082, rse:0.4784528613090515, corr:[0.26314974 0.2667558  0.2642751  0.262498   0.26226923 0.26176035
 0.2602579  0.25871912 0.25806862 0.2573029  0.25586107 0.2539368
 0.25260833 0.25178957 0.25109288 0.2503565  0.24955095 0.24887988
 0.2480067  0.24684854 0.24576508 0.24485244 0.24378018 0.2421211
 0.24002664 0.23827359 0.23717535 0.23631425 0.23536855 0.23428665
 0.23316774 0.23202455 0.23066847 0.22934957 0.22832043 0.22760576
 0.22670831 0.22547835 0.22431691 0.22346693 0.22293308 0.22227651
 0.22116892 0.21989563 0.21884152 0.21785365 0.21640262 0.21424347
 0.21201113 0.21042617 0.20931071 0.20803434 0.20636697 0.20446786
 0.20261548 0.20078233 0.19916108 0.1975002  0.1962988  0.19572306
 0.19547088 0.19506216 0.19468172 0.19441147 0.19407985 0.19363703
 0.19278307 0.19198316 0.19144031 0.19116712 0.19060361 0.18959674
 0.18850397 0.18776065 0.18722638 0.18643136 0.1855422  0.18473785
 0.1841749  0.1836285  0.18320523 0.18253179 0.18208185 0.1819606
 0.18206182 0.18182994 0.18140864 0.18103676 0.18075016 0.18042636
 0.17983636 0.17916517 0.17918868 0.17960903 0.17980944 0.17928392
 0.17840715 0.17759264 0.17721574 0.1767043  0.1759338  0.17526035
 0.1751834  0.17513424 0.17507537 0.17475091 0.17450994 0.17479116
 0.17492063 0.17458105 0.1736494  0.17296709 0.17261069 0.17255251
 0.17228448 0.17151076 0.17087364 0.17024402 0.16953252 0.16831863
 0.1668206  0.16548689 0.1648568  0.16458797 0.16391052 0.16294126
 0.16205496 0.16159058 0.1611741  0.16041361 0.1596524  0.15923056
 0.15914872 0.15886813 0.15816732 0.15747024 0.15714988 0.15718542
 0.1568148  0.15625292 0.15586455 0.15559098 0.15511434 0.15400054
 0.15219072 0.15040974 0.14933205 0.14907728 0.148825   0.14795995
 0.14705335 0.1464642  0.14638871 0.14620522 0.14546691 0.14469412
 0.14445363 0.14473179 0.14466034 0.14433935 0.14393    0.14366783
 0.14351018 0.14320482 0.1429158  0.14281186 0.14282615 0.14219569
 0.1410025  0.13958679 0.1385315  0.13809846 0.13760774 0.13640723
 0.13489503 0.1337115  0.1333055  0.13300711 0.13239753 0.13144758
 0.13092504 0.13087003 0.13079436 0.13052756 0.13005537 0.12978761
 0.1300271  0.13029276 0.13036923 0.13068938 0.13121893 0.13136671
 0.13087891 0.12984245 0.12909722 0.12912714 0.1293511  0.12903455
 0.12832077 0.1276779  0.1275088  0.12763609 0.12765342 0.1271272
 0.12665094 0.12657577 0.12660322 0.12664914 0.12646444 0.126476
 0.12685111 0.12733969 0.12753904 0.127237   0.12709089 0.12684044
 0.12633    0.12505239 0.12373362 0.12316688 0.12306938 0.12313843
 0.12270095 0.12231991 0.12222914 0.12226157 0.12213508 0.12129835
 0.12014837 0.11934721 0.1191775  0.11952775 0.11966413 0.11969389
 0.11985961 0.12050804 0.1210032  0.12091615 0.1206335  0.12041859
 0.11997065 0.11913441 0.11816972 0.11739699 0.1171613  0.11670186
 0.11607893 0.11561281 0.11546582 0.11537297 0.11543921 0.1154161
 0.11517426 0.11538609 0.11604675 0.11732931 0.1182768  0.11872194
 0.11888671 0.11936273 0.12028753 0.12083327 0.12124336 0.12142649
 0.12172461 0.12172677 0.12141306 0.12102284 0.12076487 0.12094079
 0.12109049 0.12113702 0.1209534  0.12081383 0.12144402 0.12158688
 0.12136123 0.12107754 0.12094612 0.12120036 0.12160727 0.12184445
 0.1215803  0.12146351 0.12138461 0.12142624 0.12159631 0.12207887
 0.12192091 0.12113212 0.12021405 0.11953741 0.11873285 0.1180735
 0.11735201 0.1164615  0.11591194 0.11540451 0.11538205 0.11536819
 0.11475758 0.11392771 0.11366092 0.11459952 0.11512202 0.11526164
 0.11462694 0.11464284 0.11562947 0.11604797 0.11602399 0.11539579
 0.11499406 0.11460386 0.11391944 0.1128056  0.11154374 0.11117196
 0.11138621 0.11138429 0.11052932 0.11001343 0.11091474 0.112055
 0.11182755 0.11079793 0.11114763 0.11321823 0.11443504 0.1137673
 0.11294298 0.1147206  0.11762797 0.11798915 0.11800532 0.12203776]
