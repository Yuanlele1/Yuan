Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=103, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=103, out_features=116, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  10705408.0
params:  12064.0
Trainable parameters:  12064
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.424482822418213
Epoch: 1, Steps: 61 | Train Loss: 0.5778696 Vali Loss: 0.4123785 Test Loss: 0.3924971
Validation loss decreased (inf --> 0.412378).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.393195152282715
Epoch: 2, Steps: 61 | Train Loss: 0.4590370 Vali Loss: 0.3586250 Test Loss: 0.3555524
Validation loss decreased (0.412378 --> 0.358625).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.1152355670928955
Epoch: 3, Steps: 61 | Train Loss: 0.3918584 Vali Loss: 0.3367134 Test Loss: 0.3394001
Validation loss decreased (0.358625 --> 0.336713).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.0229105949401855
Epoch: 4, Steps: 61 | Train Loss: 0.3493322 Vali Loss: 0.3247772 Test Loss: 0.3322528
Validation loss decreased (0.336713 --> 0.324777).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.688297748565674
Epoch: 5, Steps: 61 | Train Loss: 0.3189625 Vali Loss: 0.3208547 Test Loss: 0.3287099
Validation loss decreased (0.324777 --> 0.320855).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.0925893783569336
Epoch: 6, Steps: 61 | Train Loss: 0.2961559 Vali Loss: 0.3176033 Test Loss: 0.3263696
Validation loss decreased (0.320855 --> 0.317603).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.475820302963257
Epoch: 7, Steps: 61 | Train Loss: 0.2774320 Vali Loss: 0.3153532 Test Loss: 0.3245713
Validation loss decreased (0.317603 --> 0.315353).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.1990225315093994
Epoch: 8, Steps: 61 | Train Loss: 0.2622529 Vali Loss: 0.3114688 Test Loss: 0.3228504
Validation loss decreased (0.315353 --> 0.311469).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.2410728931427
Epoch: 9, Steps: 61 | Train Loss: 0.2487211 Vali Loss: 0.3087444 Test Loss: 0.3211839
Validation loss decreased (0.311469 --> 0.308744).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.265129327774048
Epoch: 10, Steps: 61 | Train Loss: 0.2370547 Vali Loss: 0.3063132 Test Loss: 0.3198294
Validation loss decreased (0.308744 --> 0.306313).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.2986841201782227
Epoch: 11, Steps: 61 | Train Loss: 0.2269739 Vali Loss: 0.3039359 Test Loss: 0.3180574
Validation loss decreased (0.306313 --> 0.303936).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.3251726627349854
Epoch: 12, Steps: 61 | Train Loss: 0.2177872 Vali Loss: 0.3013970 Test Loss: 0.3163335
Validation loss decreased (0.303936 --> 0.301397).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.3459970951080322
Epoch: 13, Steps: 61 | Train Loss: 0.2093526 Vali Loss: 0.2989725 Test Loss: 0.3148276
Validation loss decreased (0.301397 --> 0.298973).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.5333781242370605
Epoch: 14, Steps: 61 | Train Loss: 0.2020842 Vali Loss: 0.2964780 Test Loss: 0.3132083
Validation loss decreased (0.298973 --> 0.296478).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.8849849700927734
Epoch: 15, Steps: 61 | Train Loss: 0.1956144 Vali Loss: 0.2937708 Test Loss: 0.3118064
Validation loss decreased (0.296478 --> 0.293771).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.718104839324951
Epoch: 16, Steps: 61 | Train Loss: 0.1892767 Vali Loss: 0.2915193 Test Loss: 0.3103571
Validation loss decreased (0.293771 --> 0.291519).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.5567476749420166
Epoch: 17, Steps: 61 | Train Loss: 0.1840077 Vali Loss: 0.2891549 Test Loss: 0.3089507
Validation loss decreased (0.291519 --> 0.289155).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.365598440170288
Epoch: 18, Steps: 61 | Train Loss: 0.1788071 Vali Loss: 0.2876822 Test Loss: 0.3077058
Validation loss decreased (0.289155 --> 0.287682).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.1851940155029297
Epoch: 19, Steps: 61 | Train Loss: 0.1742521 Vali Loss: 0.2861837 Test Loss: 0.3065614
Validation loss decreased (0.287682 --> 0.286184).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.4405863285064697
Epoch: 20, Steps: 61 | Train Loss: 0.1701791 Vali Loss: 0.2845769 Test Loss: 0.3053358
Validation loss decreased (0.286184 --> 0.284577).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.270580291748047
Epoch: 21, Steps: 61 | Train Loss: 0.1659924 Vali Loss: 0.2833120 Test Loss: 0.3042293
Validation loss decreased (0.284577 --> 0.283312).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.339763879776001
Epoch: 22, Steps: 61 | Train Loss: 0.1626878 Vali Loss: 0.2798896 Test Loss: 0.3031909
Validation loss decreased (0.283312 --> 0.279890).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.216655731201172
Epoch: 23, Steps: 61 | Train Loss: 0.1593981 Vali Loss: 0.2793398 Test Loss: 0.3022322
Validation loss decreased (0.279890 --> 0.279340).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.1695139408111572
Epoch: 24, Steps: 61 | Train Loss: 0.1563525 Vali Loss: 0.2784704 Test Loss: 0.3013948
Validation loss decreased (0.279340 --> 0.278470).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.1566805839538574
Epoch: 25, Steps: 61 | Train Loss: 0.1534782 Vali Loss: 0.2767628 Test Loss: 0.3005543
Validation loss decreased (0.278470 --> 0.276763).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.7499935626983643
Epoch: 26, Steps: 61 | Train Loss: 0.1509698 Vali Loss: 0.2756460 Test Loss: 0.2997549
Validation loss decreased (0.276763 --> 0.275646).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.2912099361419678
Epoch: 27, Steps: 61 | Train Loss: 0.1484696 Vali Loss: 0.2748476 Test Loss: 0.2990012
Validation loss decreased (0.275646 --> 0.274848).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.419931173324585
Epoch: 28, Steps: 61 | Train Loss: 0.1462086 Vali Loss: 0.2742144 Test Loss: 0.2982895
Validation loss decreased (0.274848 --> 0.274214).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.8899712562561035
Epoch: 29, Steps: 61 | Train Loss: 0.1439259 Vali Loss: 0.2732124 Test Loss: 0.2976466
Validation loss decreased (0.274214 --> 0.273212).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.610992670059204
Epoch: 30, Steps: 61 | Train Loss: 0.1420462 Vali Loss: 0.2715905 Test Loss: 0.2970350
Validation loss decreased (0.273212 --> 0.271591).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.261712074279785
Epoch: 31, Steps: 61 | Train Loss: 0.1401929 Vali Loss: 0.2706003 Test Loss: 0.2964438
Validation loss decreased (0.271591 --> 0.270600).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.0317351818084717
Epoch: 32, Steps: 61 | Train Loss: 0.1386979 Vali Loss: 0.2701035 Test Loss: 0.2959137
Validation loss decreased (0.270600 --> 0.270104).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 3.482255458831787
Epoch: 33, Steps: 61 | Train Loss: 0.1369969 Vali Loss: 0.2701509 Test Loss: 0.2953149
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.087965726852417
Epoch: 34, Steps: 61 | Train Loss: 0.1354889 Vali Loss: 0.2688644 Test Loss: 0.2949037
Validation loss decreased (0.270104 --> 0.268864).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.6889560222625732
Epoch: 35, Steps: 61 | Train Loss: 0.1340449 Vali Loss: 0.2671514 Test Loss: 0.2944217
Validation loss decreased (0.268864 --> 0.267151).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.430978298187256
Epoch: 36, Steps: 61 | Train Loss: 0.1329067 Vali Loss: 0.2666083 Test Loss: 0.2939942
Validation loss decreased (0.267151 --> 0.266608).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.4360060691833496
Epoch: 37, Steps: 61 | Train Loss: 0.1315858 Vali Loss: 0.2666685 Test Loss: 0.2935735
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.8006865978240967
Epoch: 38, Steps: 61 | Train Loss: 0.1304406 Vali Loss: 0.2649771 Test Loss: 0.2931878
Validation loss decreased (0.266608 --> 0.264977).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.2335400581359863
Epoch: 39, Steps: 61 | Train Loss: 0.1292629 Vali Loss: 0.2650639 Test Loss: 0.2928421
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.9389710426330566
Epoch: 40, Steps: 61 | Train Loss: 0.1283611 Vali Loss: 0.2643815 Test Loss: 0.2924799
Validation loss decreased (0.264977 --> 0.264382).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.094667673110962
Epoch: 41, Steps: 61 | Train Loss: 0.1273395 Vali Loss: 0.2648213 Test Loss: 0.2921919
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.9354395866394043
Epoch: 42, Steps: 61 | Train Loss: 0.1264507 Vali Loss: 0.2634258 Test Loss: 0.2918271
Validation loss decreased (0.264382 --> 0.263426).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.2223057746887207
Epoch: 43, Steps: 61 | Train Loss: 0.1255420 Vali Loss: 0.2633835 Test Loss: 0.2915708
Validation loss decreased (0.263426 --> 0.263384).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.307176351547241
Epoch: 44, Steps: 61 | Train Loss: 0.1248001 Vali Loss: 0.2633195 Test Loss: 0.2912703
Validation loss decreased (0.263384 --> 0.263319).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.268845558166504
Epoch: 45, Steps: 61 | Train Loss: 0.1239879 Vali Loss: 0.2621470 Test Loss: 0.2910480
Validation loss decreased (0.263319 --> 0.262147).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.3109097480773926
Epoch: 46, Steps: 61 | Train Loss: 0.1233586 Vali Loss: 0.2618595 Test Loss: 0.2907877
Validation loss decreased (0.262147 --> 0.261860).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.0952775478363037
Epoch: 47, Steps: 61 | Train Loss: 0.1226457 Vali Loss: 0.2621701 Test Loss: 0.2905592
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.0349369049072266
Epoch: 48, Steps: 61 | Train Loss: 0.1219559 Vali Loss: 0.2610663 Test Loss: 0.2903561
Validation loss decreased (0.261860 --> 0.261066).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.44805645942688
Epoch: 49, Steps: 61 | Train Loss: 0.1213681 Vali Loss: 0.2609715 Test Loss: 0.2901374
Validation loss decreased (0.261066 --> 0.260972).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.0779190063476562
Epoch: 50, Steps: 61 | Train Loss: 0.1207997 Vali Loss: 0.2605056 Test Loss: 0.2899463
Validation loss decreased (0.260972 --> 0.260506).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.0809366703033447
Epoch: 51, Steps: 61 | Train Loss: 0.1202738 Vali Loss: 0.2602727 Test Loss: 0.2897822
Validation loss decreased (0.260506 --> 0.260273).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.9641287326812744
Epoch: 52, Steps: 61 | Train Loss: 0.1198236 Vali Loss: 0.2601456 Test Loss: 0.2896050
Validation loss decreased (0.260273 --> 0.260146).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.90708589553833
Epoch: 53, Steps: 61 | Train Loss: 0.1191946 Vali Loss: 0.2597348 Test Loss: 0.2894253
Validation loss decreased (0.260146 --> 0.259735).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.8956921100616455
Epoch: 54, Steps: 61 | Train Loss: 0.1187609 Vali Loss: 0.2598379 Test Loss: 0.2892767
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.13651180267334
Epoch: 55, Steps: 61 | Train Loss: 0.1182935 Vali Loss: 0.2585217 Test Loss: 0.2891228
Validation loss decreased (0.259735 --> 0.258522).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.04011607170105
Epoch: 56, Steps: 61 | Train Loss: 0.1178439 Vali Loss: 0.2594331 Test Loss: 0.2889771
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.7611966133117676
Epoch: 57, Steps: 61 | Train Loss: 0.1176359 Vali Loss: 0.2587432 Test Loss: 0.2888607
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.497135877609253
Epoch: 58, Steps: 61 | Train Loss: 0.1172715 Vali Loss: 0.2588461 Test Loss: 0.2887399
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.437927722930908
Epoch: 59, Steps: 61 | Train Loss: 0.1168267 Vali Loss: 0.2597239 Test Loss: 0.2885882
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.0537350177764893
Epoch: 60, Steps: 61 | Train Loss: 0.1164948 Vali Loss: 0.2586946 Test Loss: 0.2884852
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.124655246734619
Epoch: 61, Steps: 61 | Train Loss: 0.1161627 Vali Loss: 0.2567584 Test Loss: 0.2883663
Validation loss decreased (0.258522 --> 0.256758).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.524989366531372
Epoch: 62, Steps: 61 | Train Loss: 0.1157930 Vali Loss: 0.2577623 Test Loss: 0.2882708
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.3379034996032715
Epoch: 63, Steps: 61 | Train Loss: 0.1156074 Vali Loss: 0.2584617 Test Loss: 0.2881608
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.2065935134887695
Epoch: 64, Steps: 61 | Train Loss: 0.1153517 Vali Loss: 0.2581771 Test Loss: 0.2880768
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 3.9140267372131348
Epoch: 65, Steps: 61 | Train Loss: 0.1151927 Vali Loss: 0.2579778 Test Loss: 0.2879849
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.1366286277770996
Epoch: 66, Steps: 61 | Train Loss: 0.1146617 Vali Loss: 0.2578124 Test Loss: 0.2879032
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.0484979152679443
Epoch: 67, Steps: 61 | Train Loss: 0.1144916 Vali Loss: 0.2577971 Test Loss: 0.2878035
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.6234750747680664
Epoch: 68, Steps: 61 | Train Loss: 0.1144353 Vali Loss: 0.2561505 Test Loss: 0.2877401
Validation loss decreased (0.256758 --> 0.256151).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.412583827972412
Epoch: 69, Steps: 61 | Train Loss: 0.1141688 Vali Loss: 0.2566808 Test Loss: 0.2876680
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.9794650077819824
Epoch: 70, Steps: 61 | Train Loss: 0.1137531 Vali Loss: 0.2562846 Test Loss: 0.2875880
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.2065787315368652
Epoch: 71, Steps: 61 | Train Loss: 0.1138145 Vali Loss: 0.2569407 Test Loss: 0.2875320
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.4478447437286377
Epoch: 72, Steps: 61 | Train Loss: 0.1134778 Vali Loss: 0.2562340 Test Loss: 0.2874577
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.716068983078003
Epoch: 73, Steps: 61 | Train Loss: 0.1134064 Vali Loss: 0.2570160 Test Loss: 0.2874081
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 3.011918544769287
Epoch: 74, Steps: 61 | Train Loss: 0.1132046 Vali Loss: 0.2564287 Test Loss: 0.2873470
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.685713529586792
Epoch: 75, Steps: 61 | Train Loss: 0.1131632 Vali Loss: 0.2563015 Test Loss: 0.2872914
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.24857234954834
Epoch: 76, Steps: 61 | Train Loss: 0.1129842 Vali Loss: 0.2558867 Test Loss: 0.2872419
Validation loss decreased (0.256151 --> 0.255887).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.333890438079834
Epoch: 77, Steps: 61 | Train Loss: 0.1128574 Vali Loss: 0.2564033 Test Loss: 0.2871881
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.1076295375823975
Epoch: 78, Steps: 61 | Train Loss: 0.1127070 Vali Loss: 0.2567287 Test Loss: 0.2871475
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.01300311088562
Epoch: 79, Steps: 61 | Train Loss: 0.1126830 Vali Loss: 0.2566644 Test Loss: 0.2871004
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.1147313117980957
Epoch: 80, Steps: 61 | Train Loss: 0.1124462 Vali Loss: 0.2567314 Test Loss: 0.2870595
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.5230770111083984
Epoch: 81, Steps: 61 | Train Loss: 0.1123863 Vali Loss: 0.2555985 Test Loss: 0.2870143
Validation loss decreased (0.255887 --> 0.255599).  Saving model ...
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 3.910113573074341
Epoch: 82, Steps: 61 | Train Loss: 0.1122916 Vali Loss: 0.2562647 Test Loss: 0.2869842
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.648169994354248
Epoch: 83, Steps: 61 | Train Loss: 0.1121271 Vali Loss: 0.2550651 Test Loss: 0.2869405
Validation loss decreased (0.255599 --> 0.255065).  Saving model ...
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.388922929763794
Epoch: 84, Steps: 61 | Train Loss: 0.1120605 Vali Loss: 0.2557140 Test Loss: 0.2869073
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.4945292472839355
Epoch: 85, Steps: 61 | Train Loss: 0.1119546 Vali Loss: 0.2557808 Test Loss: 0.2868778
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 2.6015396118164062
Epoch: 86, Steps: 61 | Train Loss: 0.1118506 Vali Loss: 0.2554011 Test Loss: 0.2868409
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 2.1519851684570312
Epoch: 87, Steps: 61 | Train Loss: 0.1117811 Vali Loss: 0.2548644 Test Loss: 0.2868100
Validation loss decreased (0.255065 --> 0.254864).  Saving model ...
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 2.206416606903076
Epoch: 88, Steps: 61 | Train Loss: 0.1117137 Vali Loss: 0.2546245 Test Loss: 0.2867893
Validation loss decreased (0.254864 --> 0.254624).  Saving model ...
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.040276050567627
Epoch: 89, Steps: 61 | Train Loss: 0.1116201 Vali Loss: 0.2558956 Test Loss: 0.2867575
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.995718002319336
Epoch: 90, Steps: 61 | Train Loss: 0.1113859 Vali Loss: 0.2558037 Test Loss: 0.2867344
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.103618860244751
Epoch: 91, Steps: 61 | Train Loss: 0.1115294 Vali Loss: 0.2547924 Test Loss: 0.2867094
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 2.560694694519043
Epoch: 92, Steps: 61 | Train Loss: 0.1112718 Vali Loss: 0.2554630 Test Loss: 0.2866894
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 2.109287738800049
Epoch: 93, Steps: 61 | Train Loss: 0.1113870 Vali Loss: 0.2555038 Test Loss: 0.2866667
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.8831112384796143
Epoch: 94, Steps: 61 | Train Loss: 0.1112752 Vali Loss: 0.2550218 Test Loss: 0.2866426
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 2.1742701530456543
Epoch: 95, Steps: 61 | Train Loss: 0.1112304 Vali Loss: 0.2545831 Test Loss: 0.2866243
Validation loss decreased (0.254624 --> 0.254583).  Saving model ...
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 2.0526387691497803
Epoch: 96, Steps: 61 | Train Loss: 0.1110650 Vali Loss: 0.2546402 Test Loss: 0.2866060
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 2.0341603755950928
Epoch: 97, Steps: 61 | Train Loss: 0.1110026 Vali Loss: 0.2546047 Test Loss: 0.2865899
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 2.1613922119140625
Epoch: 98, Steps: 61 | Train Loss: 0.1109942 Vali Loss: 0.2554280 Test Loss: 0.2865672
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 2.1653313636779785
Epoch: 99, Steps: 61 | Train Loss: 0.1110524 Vali Loss: 0.2543847 Test Loss: 0.2865528
Validation loss decreased (0.254583 --> 0.254385).  Saving model ...
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 2.225128173828125
Epoch: 100, Steps: 61 | Train Loss: 0.1108553 Vali Loss: 0.2545813 Test Loss: 0.2865364
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1160680107021042e-06
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=103, out_features=116, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  10705408.0
params:  12064.0
Trainable parameters:  12064
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.8968734741210938
Epoch: 1, Steps: 61 | Train Loss: 0.4314371 Vali Loss: 0.2314112 Test Loss: 0.2750709
Validation loss decreased (inf --> 0.231411).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.157268524169922
Epoch: 2, Steps: 61 | Train Loss: 0.4179083 Vali Loss: 0.2249340 Test Loss: 0.2750250
Validation loss decreased (0.231411 --> 0.224934).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.356137752532959
Epoch: 3, Steps: 61 | Train Loss: 0.4120738 Vali Loss: 0.2211612 Test Loss: 0.2750715
Validation loss decreased (0.224934 --> 0.221161).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.5071308612823486
Epoch: 4, Steps: 61 | Train Loss: 0.4107105 Vali Loss: 0.2188170 Test Loss: 0.2749486
Validation loss decreased (0.221161 --> 0.218817).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.125631093978882
Epoch: 5, Steps: 61 | Train Loss: 0.4089958 Vali Loss: 0.2201141 Test Loss: 0.2751026
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.5463931560516357
Epoch: 6, Steps: 61 | Train Loss: 0.4078770 Vali Loss: 0.2190742 Test Loss: 0.2750624
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.2684667110443115
Epoch: 7, Steps: 61 | Train Loss: 0.4080100 Vali Loss: 0.2165923 Test Loss: 0.2749248
Validation loss decreased (0.218817 --> 0.216592).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.1608407497406006
Epoch: 8, Steps: 61 | Train Loss: 0.4061335 Vali Loss: 0.2180901 Test Loss: 0.2748871
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.304657220840454
Epoch: 9, Steps: 61 | Train Loss: 0.4067720 Vali Loss: 0.2175647 Test Loss: 0.2749184
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.058821201324463
Epoch: 10, Steps: 61 | Train Loss: 0.4065643 Vali Loss: 0.2167442 Test Loss: 0.2745778
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.6374521255493164
Epoch: 11, Steps: 61 | Train Loss: 0.4061514 Vali Loss: 0.2165978 Test Loss: 0.2744958
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.2924177646636963
Epoch: 12, Steps: 61 | Train Loss: 0.4042055 Vali Loss: 0.2163469 Test Loss: 0.2745193
Validation loss decreased (0.216592 --> 0.216347).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.0847556591033936
Epoch: 13, Steps: 61 | Train Loss: 0.4055676 Vali Loss: 0.2161712 Test Loss: 0.2743519
Validation loss decreased (0.216347 --> 0.216171).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.024693727493286
Epoch: 14, Steps: 61 | Train Loss: 0.4050900 Vali Loss: 0.2156812 Test Loss: 0.2743903
Validation loss decreased (0.216171 --> 0.215681).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.159654140472412
Epoch: 15, Steps: 61 | Train Loss: 0.4053445 Vali Loss: 0.2157757 Test Loss: 0.2745513
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.6621971130371094
Epoch: 16, Steps: 61 | Train Loss: 0.4051089 Vali Loss: 0.2151233 Test Loss: 0.2743159
Validation loss decreased (0.215681 --> 0.215123).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.5003225803375244
Epoch: 17, Steps: 61 | Train Loss: 0.4045941 Vali Loss: 0.2154751 Test Loss: 0.2743812
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.3623111248016357
Epoch: 18, Steps: 61 | Train Loss: 0.4047564 Vali Loss: 0.2164979 Test Loss: 0.2742638
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.9296190738677979
Epoch: 19, Steps: 61 | Train Loss: 0.4043039 Vali Loss: 0.2151781 Test Loss: 0.2741100
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.2676258087158203
Epoch: 20, Steps: 61 | Train Loss: 0.4042664 Vali Loss: 0.2149158 Test Loss: 0.2742729
Validation loss decreased (0.215123 --> 0.214916).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.203204393386841
Epoch: 21, Steps: 61 | Train Loss: 0.4044278 Vali Loss: 0.2152542 Test Loss: 0.2740519
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.096601963043213
Epoch: 22, Steps: 61 | Train Loss: 0.4038526 Vali Loss: 0.2155024 Test Loss: 0.2742154
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.21514892578125
Epoch: 23, Steps: 61 | Train Loss: 0.4036606 Vali Loss: 0.2149750 Test Loss: 0.2740970
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.9964613914489746
Epoch: 24, Steps: 61 | Train Loss: 0.4035888 Vali Loss: 0.2145313 Test Loss: 0.2741230
Validation loss decreased (0.214916 --> 0.214531).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.071772813796997
Epoch: 25, Steps: 61 | Train Loss: 0.4037844 Vali Loss: 0.2146583 Test Loss: 0.2740663
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.2398080825805664
Epoch: 26, Steps: 61 | Train Loss: 0.4038605 Vali Loss: 0.2149274 Test Loss: 0.2739460
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.8942534923553467
Epoch: 27, Steps: 61 | Train Loss: 0.4037358 Vali Loss: 0.2142524 Test Loss: 0.2739562
Validation loss decreased (0.214531 --> 0.214252).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.001798629760742
Epoch: 28, Steps: 61 | Train Loss: 0.4033065 Vali Loss: 0.2154881 Test Loss: 0.2739199
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.0485103130340576
Epoch: 29, Steps: 61 | Train Loss: 0.4035760 Vali Loss: 0.2147633 Test Loss: 0.2740294
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.878082275390625
Epoch: 30, Steps: 61 | Train Loss: 0.4032465 Vali Loss: 0.2150249 Test Loss: 0.2739084
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.0448687076568604
Epoch: 31, Steps: 61 | Train Loss: 0.4033695 Vali Loss: 0.2141334 Test Loss: 0.2739616
Validation loss decreased (0.214252 --> 0.214133).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.296820878982544
Epoch: 32, Steps: 61 | Train Loss: 0.4015726 Vali Loss: 0.2150182 Test Loss: 0.2739131
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.2757279872894287
Epoch: 33, Steps: 61 | Train Loss: 0.4032622 Vali Loss: 0.2140587 Test Loss: 0.2739984
Validation loss decreased (0.214133 --> 0.214059).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.1166610717773438
Epoch: 34, Steps: 61 | Train Loss: 0.4029564 Vali Loss: 0.2139959 Test Loss: 0.2738371
Validation loss decreased (0.214059 --> 0.213996).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.188209295272827
Epoch: 35, Steps: 61 | Train Loss: 0.4030706 Vali Loss: 0.2137456 Test Loss: 0.2739232
Validation loss decreased (0.213996 --> 0.213746).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.398369550704956
Epoch: 36, Steps: 61 | Train Loss: 0.4012095 Vali Loss: 0.2154005 Test Loss: 0.2738510
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.2392356395721436
Epoch: 37, Steps: 61 | Train Loss: 0.4022586 Vali Loss: 0.2146491 Test Loss: 0.2738416
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 3.2672791481018066
Epoch: 38, Steps: 61 | Train Loss: 0.4030366 Vali Loss: 0.2143187 Test Loss: 0.2739140
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.043828010559082
Epoch: 39, Steps: 61 | Train Loss: 0.4031217 Vali Loss: 0.2137091 Test Loss: 0.2739300
Validation loss decreased (0.213746 --> 0.213709).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.3700451850891113
Epoch: 40, Steps: 61 | Train Loss: 0.4029102 Vali Loss: 0.2145724 Test Loss: 0.2738361
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.171868324279785
Epoch: 41, Steps: 61 | Train Loss: 0.4026117 Vali Loss: 0.2143406 Test Loss: 0.2738815
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.9396040439605713
Epoch: 42, Steps: 61 | Train Loss: 0.4028863 Vali Loss: 0.2143380 Test Loss: 0.2738255
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.3217577934265137
Epoch: 43, Steps: 61 | Train Loss: 0.4010515 Vali Loss: 0.2150679 Test Loss: 0.2738417
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.668950080871582
Epoch: 44, Steps: 61 | Train Loss: 0.4029761 Vali Loss: 0.2134321 Test Loss: 0.2738547
Validation loss decreased (0.213709 --> 0.213432).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.829591989517212
Epoch: 45, Steps: 61 | Train Loss: 0.4023861 Vali Loss: 0.2150035 Test Loss: 0.2738079
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.0387167930603027
Epoch: 46, Steps: 61 | Train Loss: 0.4024931 Vali Loss: 0.2145730 Test Loss: 0.2738422
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.9645860195159912
Epoch: 47, Steps: 61 | Train Loss: 0.4027300 Vali Loss: 0.2137505 Test Loss: 0.2738241
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.423247814178467
Epoch: 48, Steps: 61 | Train Loss: 0.4026897 Vali Loss: 0.2146564 Test Loss: 0.2738385
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.100306272506714
Epoch: 49, Steps: 61 | Train Loss: 0.4011004 Vali Loss: 0.2140322 Test Loss: 0.2737741
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.9704790115356445
Epoch: 50, Steps: 61 | Train Loss: 0.4025128 Vali Loss: 0.2148168 Test Loss: 0.2738181
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.7311606407165527
Epoch: 51, Steps: 61 | Train Loss: 0.4026495 Vali Loss: 0.2135977 Test Loss: 0.2738294
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.2851104736328125
Epoch: 52, Steps: 61 | Train Loss: 0.4027645 Vali Loss: 0.2139906 Test Loss: 0.2738204
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.3203251361846924
Epoch: 53, Steps: 61 | Train Loss: 0.4025803 Vali Loss: 0.2137818 Test Loss: 0.2738138
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.4092812538146973
Epoch: 54, Steps: 61 | Train Loss: 0.4027009 Vali Loss: 0.2146675 Test Loss: 0.2738214
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.8530519008636475
Epoch: 55, Steps: 61 | Train Loss: 0.4026344 Vali Loss: 0.2141062 Test Loss: 0.2738040
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.8698134422302246
Epoch: 56, Steps: 61 | Train Loss: 0.4026397 Vali Loss: 0.2142052 Test Loss: 0.2738393
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.099466562271118
Epoch: 57, Steps: 61 | Train Loss: 0.4027808 Vali Loss: 0.2142093 Test Loss: 0.2737848
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.979538917541504
Epoch: 58, Steps: 61 | Train Loss: 0.4023655 Vali Loss: 0.2145074 Test Loss: 0.2738072
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.2702014446258545
Epoch: 59, Steps: 61 | Train Loss: 0.4018903 Vali Loss: 0.2141882 Test Loss: 0.2738147
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.4598631858825684
Epoch: 60, Steps: 61 | Train Loss: 0.4026686 Vali Loss: 0.2153915 Test Loss: 0.2738071
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.49121356010437
Epoch: 61, Steps: 61 | Train Loss: 0.4023813 Vali Loss: 0.2141848 Test Loss: 0.2737936
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.497246742248535
Epoch: 62, Steps: 61 | Train Loss: 0.4019633 Vali Loss: 0.2140388 Test Loss: 0.2738107
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 3.2951202392578125
Epoch: 63, Steps: 61 | Train Loss: 0.4024143 Vali Loss: 0.2143298 Test Loss: 0.2737660
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 3.3436293601989746
Epoch: 64, Steps: 61 | Train Loss: 0.4024872 Vali Loss: 0.2141582 Test Loss: 0.2738000
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.27356675267219543, mae:0.33791521191596985, rse:0.42151492834091187, corr:[0.2736148  0.2748542  0.2747485  0.27371296 0.27257872 0.2719035
 0.27158853 0.27103975 0.27014455 0.26877567 0.26724568 0.26562974
 0.26433384 0.26359406 0.26308444 0.2626504  0.26199433 0.26118487
 0.2602299  0.2592825  0.25835723 0.2571878  0.25565827 0.25364542
 0.2515093  0.24963374 0.24831156 0.24734752 0.24640672 0.24524169
 0.24377915 0.24205545 0.24024288 0.23886889 0.237904   0.23694688
 0.23585394 0.23472933 0.2339223  0.23320511 0.23261517 0.23199828
 0.2312044  0.230132   0.22903888 0.22788112 0.22667378 0.225129
 0.22314236 0.2211545  0.21977869 0.2185333  0.21743996 0.21616769
 0.21415207 0.21185754 0.20976228 0.20805971 0.20683485 0.2061286
 0.20581594 0.20544836 0.20515381 0.20509844 0.20460711 0.20410694
 0.2034827  0.20282455 0.20228699 0.20196533 0.2015334  0.20096177
 0.20005782 0.19880685 0.19759059 0.19618982 0.1954413  0.19536817
 0.19556029 0.19500904 0.19440565 0.19389173 0.19330549 0.19306867
 0.19319357 0.19356339 0.1934572  0.19288507 0.19179195 0.19142675
 0.19178039 0.19187877 0.1914826  0.1903711  0.18963638 0.19134168]
