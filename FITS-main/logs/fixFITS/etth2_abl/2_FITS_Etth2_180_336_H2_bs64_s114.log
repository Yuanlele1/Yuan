Args in experiment:
Namespace(H_order=2, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_180_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_180_336_FITS_ETTh2_ftM_sl180_ll48_pl336_H2_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8125
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=26, out_features=74, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1723904.0
params:  1998.0
Trainable parameters:  1998
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.9926235675811768
Epoch: 1, Steps: 63 | Train Loss: 0.7295258 Vali Loss: 0.4986883 Test Loss: 0.5328168
Validation loss decreased (inf --> 0.498688).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.3655083179473877
Epoch: 2, Steps: 63 | Train Loss: 0.6234372 Vali Loss: 0.4609193 Test Loss: 0.4892114
Validation loss decreased (0.498688 --> 0.460919).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.566277027130127
Epoch: 3, Steps: 63 | Train Loss: 0.5604124 Vali Loss: 0.4355709 Test Loss: 0.4623171
Validation loss decreased (0.460919 --> 0.435571).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.019519567489624
Epoch: 4, Steps: 63 | Train Loss: 0.5190758 Vali Loss: 0.4202980 Test Loss: 0.4450069
Validation loss decreased (0.435571 --> 0.420298).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.064631223678589
Epoch: 5, Steps: 63 | Train Loss: 0.4925184 Vali Loss: 0.4106616 Test Loss: 0.4334245
Validation loss decreased (0.420298 --> 0.410662).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.058628797531128
Epoch: 6, Steps: 63 | Train Loss: 0.4765023 Vali Loss: 0.4026566 Test Loss: 0.4253464
Validation loss decreased (0.410662 --> 0.402657).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.763197183609009
Epoch: 7, Steps: 63 | Train Loss: 0.4638783 Vali Loss: 0.3950963 Test Loss: 0.4197700
Validation loss decreased (0.402657 --> 0.395096).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.8538408279418945
Epoch: 8, Steps: 63 | Train Loss: 0.4543657 Vali Loss: 0.3927945 Test Loss: 0.4157527
Validation loss decreased (0.395096 --> 0.392795).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.7259833812713623
Epoch: 9, Steps: 63 | Train Loss: 0.4467940 Vali Loss: 0.3893813 Test Loss: 0.4127235
Validation loss decreased (0.392795 --> 0.389381).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.1998629570007324
Epoch: 10, Steps: 63 | Train Loss: 0.4430188 Vali Loss: 0.3861387 Test Loss: 0.4103036
Validation loss decreased (0.389381 --> 0.386139).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.202681303024292
Epoch: 11, Steps: 63 | Train Loss: 0.4392780 Vali Loss: 0.3849282 Test Loss: 0.4085131
Validation loss decreased (0.386139 --> 0.384928).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.7499191761016846
Epoch: 12, Steps: 63 | Train Loss: 0.4355379 Vali Loss: 0.3828004 Test Loss: 0.4071416
Validation loss decreased (0.384928 --> 0.382800).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.9803752899169922
Epoch: 13, Steps: 63 | Train Loss: 0.4316475 Vali Loss: 0.3816590 Test Loss: 0.4060236
Validation loss decreased (0.382800 --> 0.381659).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.3926758766174316
Epoch: 14, Steps: 63 | Train Loss: 0.4302919 Vali Loss: 0.3790535 Test Loss: 0.4049845
Validation loss decreased (0.381659 --> 0.379054).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.488278388977051
Epoch: 15, Steps: 63 | Train Loss: 0.4290739 Vali Loss: 0.3819100 Test Loss: 0.4042236
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.8395769596099854
Epoch: 16, Steps: 63 | Train Loss: 0.4300521 Vali Loss: 0.3800797 Test Loss: 0.4035180
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.330965042114258
Epoch: 17, Steps: 63 | Train Loss: 0.4280421 Vali Loss: 0.3789565 Test Loss: 0.4029344
Validation loss decreased (0.379054 --> 0.378956).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.206120014190674
Epoch: 18, Steps: 63 | Train Loss: 0.4274920 Vali Loss: 0.3761363 Test Loss: 0.4025041
Validation loss decreased (0.378956 --> 0.376136).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.233506441116333
Epoch: 19, Steps: 63 | Train Loss: 0.4273619 Vali Loss: 0.3773721 Test Loss: 0.4019852
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.8904647827148438
Epoch: 20, Steps: 63 | Train Loss: 0.4245981 Vali Loss: 0.3769149 Test Loss: 0.4016110
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.24709153175354
Epoch: 21, Steps: 63 | Train Loss: 0.4258936 Vali Loss: 0.3720017 Test Loss: 0.4012393
Validation loss decreased (0.376136 --> 0.372002).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.888465404510498
Epoch: 22, Steps: 63 | Train Loss: 0.4249197 Vali Loss: 0.3748340 Test Loss: 0.4010126
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.0010986328125
Epoch: 23, Steps: 63 | Train Loss: 0.4244308 Vali Loss: 0.3726088 Test Loss: 0.4006908
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.696279764175415
Epoch: 24, Steps: 63 | Train Loss: 0.4242298 Vali Loss: 0.3731069 Test Loss: 0.4004514
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.7841529846191406
Epoch: 25, Steps: 63 | Train Loss: 0.4238850 Vali Loss: 0.3736964 Test Loss: 0.4002127
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.7899842262268066
Epoch: 26, Steps: 63 | Train Loss: 0.4236339 Vali Loss: 0.3734136 Test Loss: 0.4000139
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.4787018299102783
Epoch: 27, Steps: 63 | Train Loss: 0.4223576 Vali Loss: 0.3758018 Test Loss: 0.3997496
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.2915024757385254
Epoch: 28, Steps: 63 | Train Loss: 0.4234289 Vali Loss: 0.3761618 Test Loss: 0.3996748
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.5284972190856934
Epoch: 29, Steps: 63 | Train Loss: 0.4216214 Vali Loss: 0.3730399 Test Loss: 0.3995001
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.2116169929504395
Epoch: 30, Steps: 63 | Train Loss: 0.4225862 Vali Loss: 0.3717697 Test Loss: 0.3993692
Validation loss decreased (0.372002 --> 0.371770).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.8668692111968994
Epoch: 31, Steps: 63 | Train Loss: 0.4224250 Vali Loss: 0.3688020 Test Loss: 0.3992130
Validation loss decreased (0.371770 --> 0.368802).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.4962103366851807
Epoch: 32, Steps: 63 | Train Loss: 0.4218556 Vali Loss: 0.3718388 Test Loss: 0.3990552
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.6176371574401855
Epoch: 33, Steps: 63 | Train Loss: 0.4216073 Vali Loss: 0.3718967 Test Loss: 0.3989653
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.2967004776000977
Epoch: 34, Steps: 63 | Train Loss: 0.4213322 Vali Loss: 0.3730771 Test Loss: 0.3988243
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.1271395683288574
Epoch: 35, Steps: 63 | Train Loss: 0.4209405 Vali Loss: 0.3732286 Test Loss: 0.3987381
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 3.6092214584350586
Epoch: 36, Steps: 63 | Train Loss: 0.4213980 Vali Loss: 0.3699276 Test Loss: 0.3986414
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.6971302032470703
Epoch: 37, Steps: 63 | Train Loss: 0.4213412 Vali Loss: 0.3738871 Test Loss: 0.3985254
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 3.2829439640045166
Epoch: 38, Steps: 63 | Train Loss: 0.4204062 Vali Loss: 0.3703640 Test Loss: 0.3984526
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.7837841510772705
Epoch: 39, Steps: 63 | Train Loss: 0.4197356 Vali Loss: 0.3715081 Test Loss: 0.3983873
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.451571464538574
Epoch: 40, Steps: 63 | Train Loss: 0.4215018 Vali Loss: 0.3707985 Test Loss: 0.3983248
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.9646477699279785
Epoch: 41, Steps: 63 | Train Loss: 0.4218734 Vali Loss: 0.3713544 Test Loss: 0.3982610
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.4482481479644775
Epoch: 42, Steps: 63 | Train Loss: 0.4199355 Vali Loss: 0.3721152 Test Loss: 0.3981860
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.4954051971435547
Epoch: 43, Steps: 63 | Train Loss: 0.4211343 Vali Loss: 0.3728569 Test Loss: 0.3981221
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.668987512588501
Epoch: 44, Steps: 63 | Train Loss: 0.4211353 Vali Loss: 0.3721096 Test Loss: 0.3980718
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 3.180558919906616
Epoch: 45, Steps: 63 | Train Loss: 0.4205170 Vali Loss: 0.3700525 Test Loss: 0.3979940
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.7498457431793213
Epoch: 46, Steps: 63 | Train Loss: 0.4213110 Vali Loss: 0.3722112 Test Loss: 0.3979643
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.280635118484497
Epoch: 47, Steps: 63 | Train Loss: 0.4201038 Vali Loss: 0.3687190 Test Loss: 0.3978995
Validation loss decreased (0.368802 --> 0.368719).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 3.2746808528900146
Epoch: 48, Steps: 63 | Train Loss: 0.4207457 Vali Loss: 0.3701693 Test Loss: 0.3978777
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.2082812786102295
Epoch: 49, Steps: 63 | Train Loss: 0.4199940 Vali Loss: 0.3708489 Test Loss: 0.3978198
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.068715810775757
Epoch: 50, Steps: 63 | Train Loss: 0.4201416 Vali Loss: 0.3717798 Test Loss: 0.3978007
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.389761447906494
Epoch: 51, Steps: 63 | Train Loss: 0.4189471 Vali Loss: 0.3719296 Test Loss: 0.3977641
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.200462818145752
Epoch: 52, Steps: 63 | Train Loss: 0.4189488 Vali Loss: 0.3706192 Test Loss: 0.3977187
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.1947057247161865
Epoch: 53, Steps: 63 | Train Loss: 0.4200398 Vali Loss: 0.3715806 Test Loss: 0.3976867
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.4237899780273438
Epoch: 54, Steps: 63 | Train Loss: 0.4200838 Vali Loss: 0.3706198 Test Loss: 0.3976431
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 3.069774627685547
Epoch: 55, Steps: 63 | Train Loss: 0.4193055 Vali Loss: 0.3674638 Test Loss: 0.3976223
Validation loss decreased (0.368719 --> 0.367464).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 3.4132866859436035
Epoch: 56, Steps: 63 | Train Loss: 0.4204150 Vali Loss: 0.3718860 Test Loss: 0.3975978
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.182192087173462
Epoch: 57, Steps: 63 | Train Loss: 0.4198129 Vali Loss: 0.3721540 Test Loss: 0.3975701
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.920091152191162
Epoch: 58, Steps: 63 | Train Loss: 0.4201603 Vali Loss: 0.3699766 Test Loss: 0.3975247
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 3.033984422683716
Epoch: 59, Steps: 63 | Train Loss: 0.4200023 Vali Loss: 0.3691643 Test Loss: 0.3975143
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.0964925289154053
Epoch: 60, Steps: 63 | Train Loss: 0.4183763 Vali Loss: 0.3712468 Test Loss: 0.3974848
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.1511549949645996
Epoch: 61, Steps: 63 | Train Loss: 0.4195680 Vali Loss: 0.3691701 Test Loss: 0.3974524
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.209064483642578
Epoch: 62, Steps: 63 | Train Loss: 0.4197028 Vali Loss: 0.3700617 Test Loss: 0.3974414
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.361529588699341
Epoch: 63, Steps: 63 | Train Loss: 0.4193429 Vali Loss: 0.3692452 Test Loss: 0.3974195
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.706394672393799
Epoch: 64, Steps: 63 | Train Loss: 0.4210414 Vali Loss: 0.3696252 Test Loss: 0.3974053
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.2079052925109863
Epoch: 65, Steps: 63 | Train Loss: 0.4201731 Vali Loss: 0.3658735 Test Loss: 0.3973863
Validation loss decreased (0.367464 --> 0.365873).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.245636224746704
Epoch: 66, Steps: 63 | Train Loss: 0.4207571 Vali Loss: 0.3674482 Test Loss: 0.3973684
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.9597063064575195
Epoch: 67, Steps: 63 | Train Loss: 0.4192889 Vali Loss: 0.3687080 Test Loss: 0.3973463
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.306833505630493
Epoch: 68, Steps: 63 | Train Loss: 0.4192204 Vali Loss: 0.3710817 Test Loss: 0.3973417
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.277061700820923
Epoch: 69, Steps: 63 | Train Loss: 0.4185098 Vali Loss: 0.3714395 Test Loss: 0.3973218
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.3077287673950195
Epoch: 70, Steps: 63 | Train Loss: 0.4190885 Vali Loss: 0.3709824 Test Loss: 0.3973129
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.6143994331359863
Epoch: 71, Steps: 63 | Train Loss: 0.4198603 Vali Loss: 0.3708673 Test Loss: 0.3972948
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.9348714351654053
Epoch: 72, Steps: 63 | Train Loss: 0.4185579 Vali Loss: 0.3692337 Test Loss: 0.3972762
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.4293737411499023
Epoch: 73, Steps: 63 | Train Loss: 0.4198845 Vali Loss: 0.3698456 Test Loss: 0.3972646
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.869269847869873
Epoch: 74, Steps: 63 | Train Loss: 0.4194524 Vali Loss: 0.3677746 Test Loss: 0.3972549
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.4258170127868652
Epoch: 75, Steps: 63 | Train Loss: 0.4199116 Vali Loss: 0.3719680 Test Loss: 0.3972415
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.641716957092285
Epoch: 76, Steps: 63 | Train Loss: 0.4186311 Vali Loss: 0.3705321 Test Loss: 0.3972335
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 3.5627448558807373
Epoch: 77, Steps: 63 | Train Loss: 0.4193679 Vali Loss: 0.3691370 Test Loss: 0.3972192
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.518054246902466
Epoch: 78, Steps: 63 | Train Loss: 0.4189549 Vali Loss: 0.3713142 Test Loss: 0.3972095
EarlyStopping counter: 13 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.4356484413146973
Epoch: 79, Steps: 63 | Train Loss: 0.4194854 Vali Loss: 0.3684843 Test Loss: 0.3972057
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.686589241027832
Epoch: 80, Steps: 63 | Train Loss: 0.4196906 Vali Loss: 0.3702686 Test Loss: 0.3971952
EarlyStopping counter: 15 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.415065050125122
Epoch: 81, Steps: 63 | Train Loss: 0.4190891 Vali Loss: 0.3705770 Test Loss: 0.3971888
EarlyStopping counter: 16 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 2.072979688644409
Epoch: 82, Steps: 63 | Train Loss: 0.4181488 Vali Loss: 0.3680098 Test Loss: 0.3971783
EarlyStopping counter: 17 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.1247148513793945
Epoch: 83, Steps: 63 | Train Loss: 0.4198399 Vali Loss: 0.3697938 Test Loss: 0.3971724
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.975721597671509
Epoch: 84, Steps: 63 | Train Loss: 0.4189843 Vali Loss: 0.3715116 Test Loss: 0.3971654
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.6771576404571533
Epoch: 85, Steps: 63 | Train Loss: 0.4186108 Vali Loss: 0.3696627 Test Loss: 0.3971554
EarlyStopping counter: 20 out of 20
Early stopping
train 8125
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=26, out_features=74, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1723904.0
params:  1998.0
Trainable parameters:  1998
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.6940624713897705
Epoch: 1, Steps: 63 | Train Loss: 0.6243920 Vali Loss: 0.3690330 Test Loss: 0.3960445
Validation loss decreased (inf --> 0.369033).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.767878532409668
Epoch: 2, Steps: 63 | Train Loss: 0.6222330 Vali Loss: 0.3685445 Test Loss: 0.3952667
Validation loss decreased (0.369033 --> 0.368545).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.9420413970947266
Epoch: 3, Steps: 63 | Train Loss: 0.6205095 Vali Loss: 0.3673796 Test Loss: 0.3948213
Validation loss decreased (0.368545 --> 0.367380).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.299802541732788
Epoch: 4, Steps: 63 | Train Loss: 0.6208883 Vali Loss: 0.3686509 Test Loss: 0.3944684
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.7593345642089844
Epoch: 5, Steps: 63 | Train Loss: 0.6233176 Vali Loss: 0.3681478 Test Loss: 0.3942965
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.8300130367279053
Epoch: 6, Steps: 63 | Train Loss: 0.6211172 Vali Loss: 0.3675697 Test Loss: 0.3941149
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.040050983428955
Epoch: 7, Steps: 63 | Train Loss: 0.6193387 Vali Loss: 0.3666762 Test Loss: 0.3940665
Validation loss decreased (0.367380 --> 0.366676).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.9166395664215088
Epoch: 8, Steps: 63 | Train Loss: 0.6187224 Vali Loss: 0.3678850 Test Loss: 0.3940648
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.1484453678131104
Epoch: 9, Steps: 63 | Train Loss: 0.6194229 Vali Loss: 0.3665686 Test Loss: 0.3938689
Validation loss decreased (0.366676 --> 0.366569).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.7759716510772705
Epoch: 10, Steps: 63 | Train Loss: 0.6207092 Vali Loss: 0.3673511 Test Loss: 0.3937386
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.125032663345337
Epoch: 11, Steps: 63 | Train Loss: 0.6193559 Vali Loss: 0.3675613 Test Loss: 0.3938537
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.89805269241333
Epoch: 12, Steps: 63 | Train Loss: 0.6182986 Vali Loss: 0.3652520 Test Loss: 0.3936043
Validation loss decreased (0.366569 --> 0.365252).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.4279568195343018
Epoch: 13, Steps: 63 | Train Loss: 0.6178098 Vali Loss: 0.3650025 Test Loss: 0.3936752
Validation loss decreased (0.365252 --> 0.365003).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.314556121826172
Epoch: 14, Steps: 63 | Train Loss: 0.6197016 Vali Loss: 0.3693373 Test Loss: 0.3935935
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.1606528759002686
Epoch: 15, Steps: 63 | Train Loss: 0.6194116 Vali Loss: 0.3656528 Test Loss: 0.3935741
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.9491374492645264
Epoch: 16, Steps: 63 | Train Loss: 0.6189389 Vali Loss: 0.3634505 Test Loss: 0.3935609
Validation loss decreased (0.365003 --> 0.363451).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.079078197479248
Epoch: 17, Steps: 63 | Train Loss: 0.6199383 Vali Loss: 0.3665945 Test Loss: 0.3935661
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.547849655151367
Epoch: 18, Steps: 63 | Train Loss: 0.6194692 Vali Loss: 0.3671569 Test Loss: 0.3935115
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 3.4136359691619873
Epoch: 19, Steps: 63 | Train Loss: 0.6173052 Vali Loss: 0.3620141 Test Loss: 0.3935488
Validation loss decreased (0.363451 --> 0.362014).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.547661542892456
Epoch: 20, Steps: 63 | Train Loss: 0.6196021 Vali Loss: 0.3665694 Test Loss: 0.3935090
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.77008056640625
Epoch: 21, Steps: 63 | Train Loss: 0.6190518 Vali Loss: 0.3664489 Test Loss: 0.3934935
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.5470190048217773
Epoch: 22, Steps: 63 | Train Loss: 0.6176761 Vali Loss: 0.3635949 Test Loss: 0.3934011
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.029167413711548
Epoch: 23, Steps: 63 | Train Loss: 0.6180106 Vali Loss: 0.3664100 Test Loss: 0.3933765
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.0507707595825195
Epoch: 24, Steps: 63 | Train Loss: 0.6192682 Vali Loss: 0.3666232 Test Loss: 0.3933787
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.4639086723327637
Epoch: 25, Steps: 63 | Train Loss: 0.6164993 Vali Loss: 0.3656201 Test Loss: 0.3933924
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.4856419563293457
Epoch: 26, Steps: 63 | Train Loss: 0.6188134 Vali Loss: 0.3643412 Test Loss: 0.3933554
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.110280752182007
Epoch: 27, Steps: 63 | Train Loss: 0.6185695 Vali Loss: 0.3651667 Test Loss: 0.3933483
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.0837478637695312
Epoch: 28, Steps: 63 | Train Loss: 0.6176221 Vali Loss: 0.3663518 Test Loss: 0.3933631
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.1101107597351074
Epoch: 29, Steps: 63 | Train Loss: 0.6172586 Vali Loss: 0.3651098 Test Loss: 0.3933438
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.5417754650115967
Epoch: 30, Steps: 63 | Train Loss: 0.6181339 Vali Loss: 0.3644198 Test Loss: 0.3933068
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.1801552772521973
Epoch: 31, Steps: 63 | Train Loss: 0.6164707 Vali Loss: 0.3650933 Test Loss: 0.3933305
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.1576502323150635
Epoch: 32, Steps: 63 | Train Loss: 0.6186897 Vali Loss: 0.3665836 Test Loss: 0.3933344
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.1769654750823975
Epoch: 33, Steps: 63 | Train Loss: 0.6185756 Vali Loss: 0.3662302 Test Loss: 0.3932962
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.358140468597412
Epoch: 34, Steps: 63 | Train Loss: 0.6188916 Vali Loss: 0.3634481 Test Loss: 0.3933236
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.4091291427612305
Epoch: 35, Steps: 63 | Train Loss: 0.6187665 Vali Loss: 0.3644045 Test Loss: 0.3933277
EarlyStopping counter: 16 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.5429041385650635
Epoch: 36, Steps: 63 | Train Loss: 0.6178377 Vali Loss: 0.3658430 Test Loss: 0.3933041
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.1740188598632812
Epoch: 37, Steps: 63 | Train Loss: 0.6178097 Vali Loss: 0.3676946 Test Loss: 0.3933113
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.8304643630981445
Epoch: 38, Steps: 63 | Train Loss: 0.6196561 Vali Loss: 0.3646989 Test Loss: 0.3932845
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.154757261276245
Epoch: 39, Steps: 63 | Train Loss: 0.6191164 Vali Loss: 0.3647368 Test Loss: 0.3933322
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_180_336_FITS_ETTh2_ftM_sl180_ll48_pl336_H2_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.38890540599823, mae:0.41278329491615295, rse:0.49861058592796326, corr:[0.26393452 0.26594967 0.2654022  0.2633122  0.26131177 0.26019314
 0.25969565 0.25897583 0.257865   0.25606397 0.25431794 0.2527794
 0.25198287 0.25130197 0.25063485 0.24970533 0.24860916 0.247483
 0.24657257 0.2458855  0.24519856 0.2442219  0.24274759 0.24091238
 0.23868315 0.23674692 0.2350183  0.23358586 0.2321403  0.23077899
 0.22939709 0.22790468 0.22626556 0.22472641 0.22351016 0.22245556
 0.2214639  0.22025244 0.2191845  0.2180362  0.21713205 0.21633407
 0.21561056 0.21470901 0.21355452 0.21195455 0.20978281 0.20731594
 0.20454971 0.20226023 0.20023271 0.19831239 0.19613002 0.19396333
 0.19181024 0.189815   0.18836488 0.18717112 0.18635191 0.18552126
 0.18489762 0.18412119 0.18361685 0.18301392 0.18239798 0.18186116
 0.18125479 0.18051188 0.17965795 0.17891397 0.17785044 0.1766736
 0.17500336 0.17333616 0.17168088 0.17026699 0.16923529 0.16875596
 0.16842788 0.1678666  0.1674209  0.166961   0.16667517 0.16650152
 0.16667382 0.16669647 0.16667621 0.1662535  0.16569082 0.1650884
 0.16483206 0.1647674  0.16497919 0.1651084  0.1646457  0.16384676
 0.16250148 0.1612803  0.16022398 0.15960273 0.15899575 0.1583628
 0.15787719 0.15747842 0.15749048 0.15755437 0.15788046 0.15801999
 0.15810016 0.15765706 0.15708765 0.15647982 0.15597595 0.15561645
 0.15535398 0.15488543 0.15410696 0.15299357 0.15157835 0.15011542
 0.14845979 0.14691047 0.14533843 0.14409347 0.14289922 0.14183003
 0.14090991 0.14006308 0.13924077 0.13842297 0.1378731  0.13746513
 0.1373043  0.13689603 0.13636474 0.13563772 0.13498738 0.1343963
 0.13400605 0.13374156 0.13354798 0.13306834 0.1318383  0.13012594
 0.12778826 0.12585984 0.12405256 0.12274093 0.12178995 0.12115171
 0.12069428 0.12005556 0.1195692  0.11930923 0.1194374  0.11950123
 0.12000457 0.12026835 0.12026156 0.11989313 0.11951029 0.11910777
 0.11884346 0.11885805 0.11893747 0.11884231 0.11823768 0.1171615
 0.11547148 0.11415423 0.11272715 0.11151284 0.11037503 0.10925581
 0.10847647 0.10782431 0.10761098 0.10734586 0.10753152 0.10779028
 0.10829055 0.10850761 0.10842391 0.10807952 0.10765859 0.10726341
 0.10725588 0.10749079 0.10790132 0.10832389 0.10836373 0.1080848
 0.10740105 0.10702369 0.1065333  0.10627256 0.10587046 0.10554186
 0.10552541 0.10576209 0.1062741  0.10651685 0.10685334 0.10670242
 0.10662307 0.10639387 0.10633198 0.10627932 0.10617445 0.10617012
 0.10625289 0.10658589 0.10703541 0.10727724 0.10714256 0.10659597
 0.10556307 0.10442538 0.1034212  0.10302496 0.10278328 0.1030446
 0.10332497 0.10376452 0.10403681 0.10413362 0.10431699 0.10435309
 0.10444949 0.10413264 0.10379713 0.10350004 0.10347228 0.10369109
 0.10414971 0.10482527 0.10548081 0.10593198 0.10585504 0.10551359
 0.10458108 0.10384462 0.10292071 0.10224193 0.10153287 0.10103264
 0.10088997 0.10145734 0.10248486 0.10328925 0.10415375 0.10459048
 0.10513545 0.10563878 0.10613221 0.10663188 0.10710822 0.10766181
 0.10791261 0.1081067  0.10849507 0.1088273  0.10905465 0.10915746
 0.10894379 0.10868645 0.10821566 0.10805939 0.10787423 0.10820559
 0.10872998 0.10916714 0.1095625  0.1096907  0.11006124 0.11030287
 0.11096335 0.11126836 0.11156682 0.11149864 0.11142112 0.11147868
 0.11182805 0.1122409  0.11267602 0.11307196 0.11306351 0.11317546
 0.11275183 0.11241043 0.11181892 0.1115313  0.11096792 0.11055212
 0.11037402 0.11035866 0.11123673 0.11200716 0.11291841 0.11344723
 0.11408187 0.11433546 0.11487543 0.11569569 0.1163945  0.11687635
 0.11697883 0.11705522 0.11715811 0.11730298 0.11746336 0.11755294
 0.11699217 0.11631053 0.11515857 0.11418924 0.11324731 0.11302602
 0.1129642  0.11331556 0.1136129  0.11340769 0.11357102 0.11429772
 0.11633405 0.11751963 0.11779986 0.11683249 0.11525458 0.11343534
 0.11238863 0.11225936 0.1128753  0.11334687 0.11182363 0.1080355 ]
