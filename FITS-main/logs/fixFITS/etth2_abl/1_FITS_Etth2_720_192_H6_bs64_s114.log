Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=196, out_features=248, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  43552768.0
params:  48856.0
Trainable parameters:  48856
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.3876750469207764
Epoch: 1, Steps: 60 | Train Loss: 0.7046047 Vali Loss: 0.3803487 Test Loss: 0.3885183
Validation loss decreased (inf --> 0.380349).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.0069773197174072
Epoch: 2, Steps: 60 | Train Loss: 0.5845649 Vali Loss: 0.3359129 Test Loss: 0.3699719
Validation loss decreased (0.380349 --> 0.335913).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.1137804985046387
Epoch: 3, Steps: 60 | Train Loss: 0.5553983 Vali Loss: 0.3199016 Test Loss: 0.3637135
Validation loss decreased (0.335913 --> 0.319902).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.9918360710144043
Epoch: 4, Steps: 60 | Train Loss: 0.5456589 Vali Loss: 0.3123785 Test Loss: 0.3605548
Validation loss decreased (0.319902 --> 0.312378).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.2444517612457275
Epoch: 5, Steps: 60 | Train Loss: 0.5385112 Vali Loss: 0.3070332 Test Loss: 0.3591176
Validation loss decreased (0.312378 --> 0.307033).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.0254898071289062
Epoch: 6, Steps: 60 | Train Loss: 0.5328273 Vali Loss: 0.3037241 Test Loss: 0.3577549
Validation loss decreased (0.307033 --> 0.303724).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.2725493907928467
Epoch: 7, Steps: 60 | Train Loss: 0.5293492 Vali Loss: 0.3001906 Test Loss: 0.3572856
Validation loss decreased (0.303724 --> 0.300191).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.127915382385254
Epoch: 8, Steps: 60 | Train Loss: 0.5267319 Vali Loss: 0.2982672 Test Loss: 0.3566965
Validation loss decreased (0.300191 --> 0.298267).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.0542664527893066
Epoch: 9, Steps: 60 | Train Loss: 0.5251167 Vali Loss: 0.2965156 Test Loss: 0.3559532
Validation loss decreased (0.298267 --> 0.296516).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.8180713653564453
Epoch: 10, Steps: 60 | Train Loss: 0.5229321 Vali Loss: 0.2948030 Test Loss: 0.3557777
Validation loss decreased (0.296516 --> 0.294803).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.6380228996276855
Epoch: 11, Steps: 60 | Train Loss: 0.5213029 Vali Loss: 0.2934270 Test Loss: 0.3554658
Validation loss decreased (0.294803 --> 0.293427).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.339799404144287
Epoch: 12, Steps: 60 | Train Loss: 0.5197486 Vali Loss: 0.2925670 Test Loss: 0.3551612
Validation loss decreased (0.293427 --> 0.292567).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.9918787479400635
Epoch: 13, Steps: 60 | Train Loss: 0.5190500 Vali Loss: 0.2917311 Test Loss: 0.3548971
Validation loss decreased (0.292567 --> 0.291731).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.1621227264404297
Epoch: 14, Steps: 60 | Train Loss: 0.5174379 Vali Loss: 0.2906874 Test Loss: 0.3546338
Validation loss decreased (0.291731 --> 0.290687).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.9268200397491455
Epoch: 15, Steps: 60 | Train Loss: 0.5168257 Vali Loss: 0.2901335 Test Loss: 0.3544956
Validation loss decreased (0.290687 --> 0.290134).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.413829803466797
Epoch: 16, Steps: 60 | Train Loss: 0.5162364 Vali Loss: 0.2896960 Test Loss: 0.3542217
Validation loss decreased (0.290134 --> 0.289696).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.2743237018585205
Epoch: 17, Steps: 60 | Train Loss: 0.5150001 Vali Loss: 0.2889844 Test Loss: 0.3541382
Validation loss decreased (0.289696 --> 0.288984).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.1888961791992188
Epoch: 18, Steps: 60 | Train Loss: 0.5134033 Vali Loss: 0.2881272 Test Loss: 0.3540320
Validation loss decreased (0.288984 --> 0.288127).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.402696371078491
Epoch: 19, Steps: 60 | Train Loss: 0.5141880 Vali Loss: 0.2878633 Test Loss: 0.3539807
Validation loss decreased (0.288127 --> 0.287863).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.115575075149536
Epoch: 20, Steps: 60 | Train Loss: 0.5123298 Vali Loss: 0.2874660 Test Loss: 0.3538296
Validation loss decreased (0.287863 --> 0.287466).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.5716636180877686
Epoch: 21, Steps: 60 | Train Loss: 0.5144803 Vali Loss: 0.2870782 Test Loss: 0.3538219
Validation loss decreased (0.287466 --> 0.287078).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.9916634559631348
Epoch: 22, Steps: 60 | Train Loss: 0.5131408 Vali Loss: 0.2869038 Test Loss: 0.3537357
Validation loss decreased (0.287078 --> 0.286904).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.5437028408050537
Epoch: 23, Steps: 60 | Train Loss: 0.5132591 Vali Loss: 0.2865734 Test Loss: 0.3535964
Validation loss decreased (0.286904 --> 0.286573).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.2589223384857178
Epoch: 24, Steps: 60 | Train Loss: 0.5122915 Vali Loss: 0.2861682 Test Loss: 0.3535380
Validation loss decreased (0.286573 --> 0.286168).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.9186062812805176
Epoch: 25, Steps: 60 | Train Loss: 0.5128024 Vali Loss: 0.2861933 Test Loss: 0.3533628
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.1193602085113525
Epoch: 26, Steps: 60 | Train Loss: 0.5126660 Vali Loss: 0.2859366 Test Loss: 0.3533970
Validation loss decreased (0.286168 --> 0.285937).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.5787975788116455
Epoch: 27, Steps: 60 | Train Loss: 0.5137726 Vali Loss: 0.2858593 Test Loss: 0.3532011
Validation loss decreased (0.285937 --> 0.285859).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.034210205078125
Epoch: 28, Steps: 60 | Train Loss: 0.5125845 Vali Loss: 0.2856110 Test Loss: 0.3531832
Validation loss decreased (0.285859 --> 0.285611).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.8519082069396973
Epoch: 29, Steps: 60 | Train Loss: 0.5116049 Vali Loss: 0.2854542 Test Loss: 0.3531253
Validation loss decreased (0.285611 --> 0.285454).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.2409255504608154
Epoch: 30, Steps: 60 | Train Loss: 0.5130094 Vali Loss: 0.2851643 Test Loss: 0.3530922
Validation loss decreased (0.285454 --> 0.285164).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.160113573074341
Epoch: 31, Steps: 60 | Train Loss: 0.5123642 Vali Loss: 0.2852931 Test Loss: 0.3530093
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.0565125942230225
Epoch: 32, Steps: 60 | Train Loss: 0.5115640 Vali Loss: 0.2847915 Test Loss: 0.3530254
Validation loss decreased (0.285164 --> 0.284791).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.709106206893921
Epoch: 33, Steps: 60 | Train Loss: 0.5124440 Vali Loss: 0.2847666 Test Loss: 0.3529996
Validation loss decreased (0.284791 --> 0.284767).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.5706336498260498
Epoch: 34, Steps: 60 | Train Loss: 0.5119791 Vali Loss: 0.2846685 Test Loss: 0.3529857
Validation loss decreased (0.284767 --> 0.284669).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.4780604839324951
Epoch: 35, Steps: 60 | Train Loss: 0.5115426 Vali Loss: 0.2844920 Test Loss: 0.3529722
Validation loss decreased (0.284669 --> 0.284492).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.421107292175293
Epoch: 36, Steps: 60 | Train Loss: 0.5118884 Vali Loss: 0.2845202 Test Loss: 0.3529009
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.511382818222046
Epoch: 37, Steps: 60 | Train Loss: 0.5098862 Vali Loss: 0.2842081 Test Loss: 0.3528501
Validation loss decreased (0.284492 --> 0.284208).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.3925111293792725
Epoch: 38, Steps: 60 | Train Loss: 0.5113515 Vali Loss: 0.2840588 Test Loss: 0.3528085
Validation loss decreased (0.284208 --> 0.284059).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.41359543800354
Epoch: 39, Steps: 60 | Train Loss: 0.5106672 Vali Loss: 0.2841600 Test Loss: 0.3527960
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.65293288230896
Epoch: 40, Steps: 60 | Train Loss: 0.5093739 Vali Loss: 0.2840522 Test Loss: 0.3528317
Validation loss decreased (0.284059 --> 0.284052).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.538668155670166
Epoch: 41, Steps: 60 | Train Loss: 0.5095660 Vali Loss: 0.2839926 Test Loss: 0.3527563
Validation loss decreased (0.284052 --> 0.283993).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.4399540424346924
Epoch: 42, Steps: 60 | Train Loss: 0.5093518 Vali Loss: 0.2838881 Test Loss: 0.3527563
Validation loss decreased (0.283993 --> 0.283888).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.4569337368011475
Epoch: 43, Steps: 60 | Train Loss: 0.5109124 Vali Loss: 0.2837201 Test Loss: 0.3527599
Validation loss decreased (0.283888 --> 0.283720).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.3473153114318848
Epoch: 44, Steps: 60 | Train Loss: 0.5108064 Vali Loss: 0.2838144 Test Loss: 0.3526937
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.5219032764434814
Epoch: 45, Steps: 60 | Train Loss: 0.5097149 Vali Loss: 0.2835883 Test Loss: 0.3527427
Validation loss decreased (0.283720 --> 0.283588).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.3824262619018555
Epoch: 46, Steps: 60 | Train Loss: 0.5084719 Vali Loss: 0.2836398 Test Loss: 0.3527257
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.4388129711151123
Epoch: 47, Steps: 60 | Train Loss: 0.5094214 Vali Loss: 0.2836362 Test Loss: 0.3526962
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.4618024826049805
Epoch: 48, Steps: 60 | Train Loss: 0.5091734 Vali Loss: 0.2835511 Test Loss: 0.3526871
Validation loss decreased (0.283588 --> 0.283551).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.5444953441619873
Epoch: 49, Steps: 60 | Train Loss: 0.5083465 Vali Loss: 0.2834151 Test Loss: 0.3526941
Validation loss decreased (0.283551 --> 0.283415).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.3664755821228027
Epoch: 50, Steps: 60 | Train Loss: 0.5092843 Vali Loss: 0.2834935 Test Loss: 0.3526719
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.3612101078033447
Epoch: 51, Steps: 60 | Train Loss: 0.5104133 Vali Loss: 0.2834226 Test Loss: 0.3526521
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.4308960437774658
Epoch: 52, Steps: 60 | Train Loss: 0.5094959 Vali Loss: 0.2830110 Test Loss: 0.3526136
Validation loss decreased (0.283415 --> 0.283011).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.5477559566497803
Epoch: 53, Steps: 60 | Train Loss: 0.5095349 Vali Loss: 0.2833617 Test Loss: 0.3526199
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.465418815612793
Epoch: 54, Steps: 60 | Train Loss: 0.5100846 Vali Loss: 0.2833140 Test Loss: 0.3526139
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.360487699508667
Epoch: 55, Steps: 60 | Train Loss: 0.5100594 Vali Loss: 0.2833143 Test Loss: 0.3526075
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.4061532020568848
Epoch: 56, Steps: 60 | Train Loss: 0.5092843 Vali Loss: 0.2832795 Test Loss: 0.3525805
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.3771307468414307
Epoch: 57, Steps: 60 | Train Loss: 0.5086557 Vali Loss: 0.2832060 Test Loss: 0.3525992
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.2948853969573975
Epoch: 58, Steps: 60 | Train Loss: 0.5098716 Vali Loss: 0.2832100 Test Loss: 0.3525843
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.237973928451538
Epoch: 59, Steps: 60 | Train Loss: 0.5100218 Vali Loss: 0.2831358 Test Loss: 0.3525633
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.3411178588867188
Epoch: 60, Steps: 60 | Train Loss: 0.5092730 Vali Loss: 0.2828792 Test Loss: 0.3525590
Validation loss decreased (0.283011 --> 0.282879).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.4727673530578613
Epoch: 61, Steps: 60 | Train Loss: 0.5097641 Vali Loss: 0.2830712 Test Loss: 0.3525738
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.3656330108642578
Epoch: 62, Steps: 60 | Train Loss: 0.5102280 Vali Loss: 0.2830600 Test Loss: 0.3525633
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.4443585872650146
Epoch: 63, Steps: 60 | Train Loss: 0.5092362 Vali Loss: 0.2830626 Test Loss: 0.3525450
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.4987154006958008
Epoch: 64, Steps: 60 | Train Loss: 0.5090825 Vali Loss: 0.2830864 Test Loss: 0.3525412
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.4374079704284668
Epoch: 65, Steps: 60 | Train Loss: 0.5094771 Vali Loss: 0.2830356 Test Loss: 0.3525421
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.5763733386993408
Epoch: 66, Steps: 60 | Train Loss: 0.5085554 Vali Loss: 0.2830384 Test Loss: 0.3525365
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.383127212524414
Epoch: 67, Steps: 60 | Train Loss: 0.5095288 Vali Loss: 0.2830171 Test Loss: 0.3525251
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.4917597770690918
Epoch: 68, Steps: 60 | Train Loss: 0.5082035 Vali Loss: 0.2829019 Test Loss: 0.3525357
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.4054102897644043
Epoch: 69, Steps: 60 | Train Loss: 0.5090323 Vali Loss: 0.2829304 Test Loss: 0.3525329
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.4778318405151367
Epoch: 70, Steps: 60 | Train Loss: 0.5090097 Vali Loss: 0.2829004 Test Loss: 0.3525254
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.0790917873382568
Epoch: 71, Steps: 60 | Train Loss: 0.5088333 Vali Loss: 0.2828954 Test Loss: 0.3525324
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.3963098526000977
Epoch: 72, Steps: 60 | Train Loss: 0.5104060 Vali Loss: 0.2829085 Test Loss: 0.3525133
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.329749584197998
Epoch: 73, Steps: 60 | Train Loss: 0.5079664 Vali Loss: 0.2827929 Test Loss: 0.3525161
Validation loss decreased (0.282879 --> 0.282793).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.1062448024749756
Epoch: 74, Steps: 60 | Train Loss: 0.5073397 Vali Loss: 0.2828470 Test Loss: 0.3525272
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.2471778392791748
Epoch: 75, Steps: 60 | Train Loss: 0.5084675 Vali Loss: 0.2828715 Test Loss: 0.3525161
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.3417837619781494
Epoch: 76, Steps: 60 | Train Loss: 0.5087496 Vali Loss: 0.2827916 Test Loss: 0.3525074
Validation loss decreased (0.282793 --> 0.282792).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.2444617748260498
Epoch: 77, Steps: 60 | Train Loss: 0.5084630 Vali Loss: 0.2828141 Test Loss: 0.3525126
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.0679147243499756
Epoch: 78, Steps: 60 | Train Loss: 0.5071404 Vali Loss: 0.2827945 Test Loss: 0.3525181
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.0025568008422852
Epoch: 79, Steps: 60 | Train Loss: 0.5100323 Vali Loss: 0.2827237 Test Loss: 0.3524967
Validation loss decreased (0.282792 --> 0.282724).  Saving model ...
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.2468979358673096
Epoch: 80, Steps: 60 | Train Loss: 0.5094364 Vali Loss: 0.2828108 Test Loss: 0.3525028
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.1871232986450195
Epoch: 81, Steps: 60 | Train Loss: 0.5084141 Vali Loss: 0.2827867 Test Loss: 0.3525004
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.2059874534606934
Epoch: 82, Steps: 60 | Train Loss: 0.5099369 Vali Loss: 0.2828286 Test Loss: 0.3524937
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.1641137599945068
Epoch: 83, Steps: 60 | Train Loss: 0.5072556 Vali Loss: 0.2827821 Test Loss: 0.3524934
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.297997236251831
Epoch: 84, Steps: 60 | Train Loss: 0.5088062 Vali Loss: 0.2827732 Test Loss: 0.3524944
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.2704219818115234
Epoch: 85, Steps: 60 | Train Loss: 0.5087282 Vali Loss: 0.2827486 Test Loss: 0.3524882
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.0564990043640137
Epoch: 86, Steps: 60 | Train Loss: 0.5086861 Vali Loss: 0.2827721 Test Loss: 0.3524876
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.2548696994781494
Epoch: 87, Steps: 60 | Train Loss: 0.5086671 Vali Loss: 0.2827885 Test Loss: 0.3524913
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.0926494598388672
Epoch: 88, Steps: 60 | Train Loss: 0.5082294 Vali Loss: 0.2827796 Test Loss: 0.3524850
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.291367530822754
Epoch: 89, Steps: 60 | Train Loss: 0.5082504 Vali Loss: 0.2827232 Test Loss: 0.3524871
Validation loss decreased (0.282724 --> 0.282723).  Saving model ...
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.1630737781524658
Epoch: 90, Steps: 60 | Train Loss: 0.5090708 Vali Loss: 0.2824525 Test Loss: 0.3524824
Validation loss decreased (0.282723 --> 0.282452).  Saving model ...
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.343940258026123
Epoch: 91, Steps: 60 | Train Loss: 0.5077453 Vali Loss: 0.2827025 Test Loss: 0.3524804
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.220872402191162
Epoch: 92, Steps: 60 | Train Loss: 0.5099235 Vali Loss: 0.2827562 Test Loss: 0.3524762
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.007889986038208
Epoch: 93, Steps: 60 | Train Loss: 0.5095284 Vali Loss: 0.2827182 Test Loss: 0.3524790
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.3671817779541016
Epoch: 94, Steps: 60 | Train Loss: 0.5102174 Vali Loss: 0.2827472 Test Loss: 0.3524759
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.1522822380065918
Epoch: 95, Steps: 60 | Train Loss: 0.5088883 Vali Loss: 0.2827336 Test Loss: 0.3524759
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 0.919363260269165
Epoch: 96, Steps: 60 | Train Loss: 0.5101333 Vali Loss: 0.2826899 Test Loss: 0.3524730
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 0.928837776184082
Epoch: 97, Steps: 60 | Train Loss: 0.5076598 Vali Loss: 0.2826663 Test Loss: 0.3524725
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.3507204055786133
Epoch: 98, Steps: 60 | Train Loss: 0.5075212 Vali Loss: 0.2826590 Test Loss: 0.3524721
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.0268185138702393
Epoch: 99, Steps: 60 | Train Loss: 0.5090765 Vali Loss: 0.2827427 Test Loss: 0.3524700
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 0.9679083824157715
Epoch: 100, Steps: 60 | Train Loss: 0.5094469 Vali Loss: 0.2827363 Test Loss: 0.3524659
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.1160680107021042e-06
>>>>>>>testing : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.3314214050769806, mae:0.3745322823524475, rse:0.4616694152355194, corr:[0.2629019  0.2672022  0.2656077  0.26698628 0.2667825  0.26543638
 0.26545444 0.26544407 0.26417714 0.26293793 0.26206508 0.26084355
 0.25942078 0.25820735 0.25753784 0.25717476 0.2567465  0.2561689
 0.25532842 0.25411397 0.2527425  0.2516961  0.25059944 0.24882968
 0.24666774 0.24505901 0.24376865 0.24196438 0.24018079 0.23914883
 0.2382503  0.23654617 0.23515134 0.23438399 0.23320316 0.2315781
 0.23070489 0.23032784 0.22912173 0.22776714 0.22745687 0.22726274
 0.22618382 0.22507603 0.22449507 0.22353342 0.22186443 0.2203127
 0.21897693 0.21711822 0.21509255 0.21382232 0.21275602 0.21067403
 0.20834774 0.20702192 0.2055252  0.20336843 0.202064   0.20147195
 0.20054159 0.19966473 0.19984798 0.20005411 0.19924334 0.19868387
 0.19854465 0.1978645  0.19684495 0.19638814 0.19598514 0.19478132
 0.19341882 0.19282839 0.19203492 0.19027562 0.18923391 0.18919784
 0.18864578 0.18735324 0.18708862 0.18714091 0.1864247  0.1857492
 0.18585749 0.18593715 0.18528195 0.18484041 0.18471105 0.18425909
 0.18350893 0.18319915 0.18329366 0.18272838 0.18219164 0.18223776
 0.18177982 0.1803985  0.1793469  0.17889531 0.17792307 0.17639118
 0.17574522 0.17546232 0.17465872 0.17369369 0.17358646 0.17375033
 0.17282197 0.1718724  0.17145826 0.17103198 0.17013584 0.16989446
 0.16983576 0.16903552 0.16806766 0.1673225  0.16639061 0.16467921
 0.16320118 0.1621079  0.1608902  0.15947346 0.15851478 0.15771586
 0.15653926 0.15542856 0.15505    0.15433285 0.15306243 0.1521163
 0.1518569  0.15113817 0.15019026 0.1500874  0.1500511  0.14921981
 0.14824705 0.1478686  0.1475212  0.14682439 0.14634591 0.14537933
 0.14314392 0.14112271 0.14021258 0.1390736  0.1372806  0.13646969
 0.13670737 0.13552321 0.13408211 0.13403782 0.13420022 0.13290466
 0.13205504 0.13267939 0.13305186 0.13259389 0.13233708 0.13289824
 0.13245326 0.13140555 0.13165015 0.13204528 0.13141166 0.13047995
 0.12996195 0.12812327 0.12621073 0.12591355 0.12598287 0.12363115
 0.12157747 0.12126081 0.12014769 0.11807093 0.11738319 0.11828195
 0.11714268 0.11600542 0.11787957 0.11899313 0.1169991  0.11734566
 0.11865934 0.11621131 0.11722232 0.12200315 0.12022687 0.12489565]
