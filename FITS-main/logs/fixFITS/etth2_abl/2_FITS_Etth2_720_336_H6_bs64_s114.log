Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_336_FITS_ETTh2_ftM_sl720_ll48_pl336_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=196, out_features=287, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  50401792.0
params:  56539.0
Trainable parameters:  56539
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 6.718878746032715
Epoch: 1, Steps: 59 | Train Loss: 0.6630233 Vali Loss: 0.5847979 Test Loss: 0.4425953
Validation loss decreased (inf --> 0.584798).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 6.527704477310181
Epoch: 2, Steps: 59 | Train Loss: 0.5180689 Vali Loss: 0.5195724 Test Loss: 0.4115012
Validation loss decreased (0.584798 --> 0.519572).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 6.640411376953125
Epoch: 3, Steps: 59 | Train Loss: 0.4497764 Vali Loss: 0.4871767 Test Loss: 0.3998267
Validation loss decreased (0.519572 --> 0.487177).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 6.465103626251221
Epoch: 4, Steps: 59 | Train Loss: 0.4111115 Vali Loss: 0.4679656 Test Loss: 0.3949058
Validation loss decreased (0.487177 --> 0.467966).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 6.623455762863159
Epoch: 5, Steps: 59 | Train Loss: 0.3846817 Vali Loss: 0.4581062 Test Loss: 0.3918915
Validation loss decreased (0.467966 --> 0.458106).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 6.4953453540802
Epoch: 6, Steps: 59 | Train Loss: 0.3635848 Vali Loss: 0.4486586 Test Loss: 0.3901159
Validation loss decreased (0.458106 --> 0.448659).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 6.485471487045288
Epoch: 7, Steps: 59 | Train Loss: 0.3480898 Vali Loss: 0.4437888 Test Loss: 0.3887329
Validation loss decreased (0.448659 --> 0.443789).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 6.786773204803467
Epoch: 8, Steps: 59 | Train Loss: 0.3334635 Vali Loss: 0.4397244 Test Loss: 0.3870352
Validation loss decreased (0.443789 --> 0.439724).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 6.74173378944397
Epoch: 9, Steps: 59 | Train Loss: 0.3218113 Vali Loss: 0.4357772 Test Loss: 0.3857048
Validation loss decreased (0.439724 --> 0.435777).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 6.365748643875122
Epoch: 10, Steps: 59 | Train Loss: 0.3112876 Vali Loss: 0.4302780 Test Loss: 0.3844132
Validation loss decreased (0.435777 --> 0.430278).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 6.493877172470093
Epoch: 11, Steps: 59 | Train Loss: 0.3028645 Vali Loss: 0.4294816 Test Loss: 0.3831335
Validation loss decreased (0.430278 --> 0.429482).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 6.820866823196411
Epoch: 12, Steps: 59 | Train Loss: 0.2956591 Vali Loss: 0.4241609 Test Loss: 0.3818590
Validation loss decreased (0.429482 --> 0.424161).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 6.5515265464782715
Epoch: 13, Steps: 59 | Train Loss: 0.2887579 Vali Loss: 0.4203328 Test Loss: 0.3807758
Validation loss decreased (0.424161 --> 0.420333).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 6.633545160293579
Epoch: 14, Steps: 59 | Train Loss: 0.2829203 Vali Loss: 0.4199522 Test Loss: 0.3797051
Validation loss decreased (0.420333 --> 0.419952).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 6.6079840660095215
Epoch: 15, Steps: 59 | Train Loss: 0.2775624 Vali Loss: 0.4182093 Test Loss: 0.3786706
Validation loss decreased (0.419952 --> 0.418209).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 6.524733781814575
Epoch: 16, Steps: 59 | Train Loss: 0.2722326 Vali Loss: 0.4181631 Test Loss: 0.3776936
Validation loss decreased (0.418209 --> 0.418163).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 6.749176263809204
Epoch: 17, Steps: 59 | Train Loss: 0.2684316 Vali Loss: 0.4167546 Test Loss: 0.3768391
Validation loss decreased (0.418163 --> 0.416755).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 6.642591714859009
Epoch: 18, Steps: 59 | Train Loss: 0.2646309 Vali Loss: 0.4143831 Test Loss: 0.3760588
Validation loss decreased (0.416755 --> 0.414383).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 6.431715965270996
Epoch: 19, Steps: 59 | Train Loss: 0.2609341 Vali Loss: 0.4138068 Test Loss: 0.3753558
Validation loss decreased (0.414383 --> 0.413807).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 6.632291078567505
Epoch: 20, Steps: 59 | Train Loss: 0.2574995 Vali Loss: 0.4140448 Test Loss: 0.3746875
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 6.441983461380005
Epoch: 21, Steps: 59 | Train Loss: 0.2546947 Vali Loss: 0.4094878 Test Loss: 0.3741482
Validation loss decreased (0.413807 --> 0.409488).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 6.327891111373901
Epoch: 22, Steps: 59 | Train Loss: 0.2525251 Vali Loss: 0.4098978 Test Loss: 0.3735797
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 6.378330945968628
Epoch: 23, Steps: 59 | Train Loss: 0.2502755 Vali Loss: 0.4092538 Test Loss: 0.3730384
Validation loss decreased (0.409488 --> 0.409254).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 6.501539945602417
Epoch: 24, Steps: 59 | Train Loss: 0.2482429 Vali Loss: 0.4099390 Test Loss: 0.3725942
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 6.339341163635254
Epoch: 25, Steps: 59 | Train Loss: 0.2463724 Vali Loss: 0.4068376 Test Loss: 0.3721645
Validation loss decreased (0.409254 --> 0.406838).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 6.298635721206665
Epoch: 26, Steps: 59 | Train Loss: 0.2444003 Vali Loss: 0.4052339 Test Loss: 0.3717243
Validation loss decreased (0.406838 --> 0.405234).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 6.455349445343018
Epoch: 27, Steps: 59 | Train Loss: 0.2433263 Vali Loss: 0.4080616 Test Loss: 0.3713459
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 6.454172372817993
Epoch: 28, Steps: 59 | Train Loss: 0.2413873 Vali Loss: 0.4054693 Test Loss: 0.3710404
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 6.199965000152588
Epoch: 29, Steps: 59 | Train Loss: 0.2403932 Vali Loss: 0.4042337 Test Loss: 0.3706993
Validation loss decreased (0.405234 --> 0.404234).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 6.214150667190552
Epoch: 30, Steps: 59 | Train Loss: 0.2391647 Vali Loss: 0.4001610 Test Loss: 0.3703969
Validation loss decreased (0.404234 --> 0.400161).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 6.206793785095215
Epoch: 31, Steps: 59 | Train Loss: 0.2375366 Vali Loss: 0.4069434 Test Loss: 0.3701582
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 6.467691659927368
Epoch: 32, Steps: 59 | Train Loss: 0.2369472 Vali Loss: 0.4020453 Test Loss: 0.3699124
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 6.636582136154175
Epoch: 33, Steps: 59 | Train Loss: 0.2359327 Vali Loss: 0.4022850 Test Loss: 0.3696504
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 6.009580373764038
Epoch: 34, Steps: 59 | Train Loss: 0.2349738 Vali Loss: 0.4005086 Test Loss: 0.3694468
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 6.376500844955444
Epoch: 35, Steps: 59 | Train Loss: 0.2343498 Vali Loss: 0.4017409 Test Loss: 0.3692325
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 6.033942222595215
Epoch: 36, Steps: 59 | Train Loss: 0.2329441 Vali Loss: 0.4023113 Test Loss: 0.3690980
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 6.107219457626343
Epoch: 37, Steps: 59 | Train Loss: 0.2322691 Vali Loss: 0.3993905 Test Loss: 0.3689334
Validation loss decreased (0.400161 --> 0.399391).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 6.174121618270874
Epoch: 38, Steps: 59 | Train Loss: 0.2321898 Vali Loss: 0.4034002 Test Loss: 0.3687618
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 6.166436195373535
Epoch: 39, Steps: 59 | Train Loss: 0.2311181 Vali Loss: 0.3992462 Test Loss: 0.3686283
Validation loss decreased (0.399391 --> 0.399246).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 6.165674209594727
Epoch: 40, Steps: 59 | Train Loss: 0.2309623 Vali Loss: 0.4011872 Test Loss: 0.3684927
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 6.586522340774536
Epoch: 41, Steps: 59 | Train Loss: 0.2304468 Vali Loss: 0.3980074 Test Loss: 0.3683703
Validation loss decreased (0.399246 --> 0.398007).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 6.2906882762908936
Epoch: 42, Steps: 59 | Train Loss: 0.2294758 Vali Loss: 0.3979669 Test Loss: 0.3682220
Validation loss decreased (0.398007 --> 0.397967).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 5.919131755828857
Epoch: 43, Steps: 59 | Train Loss: 0.2291848 Vali Loss: 0.3978670 Test Loss: 0.3681265
Validation loss decreased (0.397967 --> 0.397867).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 6.13212513923645
Epoch: 44, Steps: 59 | Train Loss: 0.2287905 Vali Loss: 0.3988313 Test Loss: 0.3680816
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 6.1693360805511475
Epoch: 45, Steps: 59 | Train Loss: 0.2282474 Vali Loss: 0.3998889 Test Loss: 0.3679557
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 6.209638833999634
Epoch: 46, Steps: 59 | Train Loss: 0.2277784 Vali Loss: 0.3976950 Test Loss: 0.3678947
Validation loss decreased (0.397867 --> 0.397695).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 6.198310136795044
Epoch: 47, Steps: 59 | Train Loss: 0.2279577 Vali Loss: 0.3987372 Test Loss: 0.3677981
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 6.083029747009277
Epoch: 48, Steps: 59 | Train Loss: 0.2275434 Vali Loss: 0.3993875 Test Loss: 0.3677276
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 6.030184507369995
Epoch: 49, Steps: 59 | Train Loss: 0.2272543 Vali Loss: 0.3987676 Test Loss: 0.3676526
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 6.178457260131836
Epoch: 50, Steps: 59 | Train Loss: 0.2269823 Vali Loss: 0.3976804 Test Loss: 0.3676004
Validation loss decreased (0.397695 --> 0.397680).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 6.4094297885894775
Epoch: 51, Steps: 59 | Train Loss: 0.2255760 Vali Loss: 0.3988663 Test Loss: 0.3675626
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 6.344653129577637
Epoch: 52, Steps: 59 | Train Loss: 0.2263246 Vali Loss: 0.3957438 Test Loss: 0.3674760
Validation loss decreased (0.397680 --> 0.395744).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 6.3464195728302
Epoch: 53, Steps: 59 | Train Loss: 0.2262410 Vali Loss: 0.3951344 Test Loss: 0.3674546
Validation loss decreased (0.395744 --> 0.395134).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 6.413649797439575
Epoch: 54, Steps: 59 | Train Loss: 0.2251122 Vali Loss: 0.3968291 Test Loss: 0.3674146
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 6.386451244354248
Epoch: 55, Steps: 59 | Train Loss: 0.2255946 Vali Loss: 0.3975056 Test Loss: 0.3673594
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 6.416828155517578
Epoch: 56, Steps: 59 | Train Loss: 0.2250286 Vali Loss: 0.3986036 Test Loss: 0.3673089
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 6.321342706680298
Epoch: 57, Steps: 59 | Train Loss: 0.2248358 Vali Loss: 0.3968844 Test Loss: 0.3672821
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 6.326312065124512
Epoch: 58, Steps: 59 | Train Loss: 0.2248711 Vali Loss: 0.3965407 Test Loss: 0.3672102
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 6.281519412994385
Epoch: 59, Steps: 59 | Train Loss: 0.2249064 Vali Loss: 0.3989422 Test Loss: 0.3672062
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 6.271275281906128
Epoch: 60, Steps: 59 | Train Loss: 0.2244105 Vali Loss: 0.3949474 Test Loss: 0.3671580
Validation loss decreased (0.395134 --> 0.394947).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 6.228407382965088
Epoch: 61, Steps: 59 | Train Loss: 0.2243560 Vali Loss: 0.3973115 Test Loss: 0.3671256
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 6.298686981201172
Epoch: 62, Steps: 59 | Train Loss: 0.2242751 Vali Loss: 0.3966340 Test Loss: 0.3671062
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 6.499131441116333
Epoch: 63, Steps: 59 | Train Loss: 0.2239799 Vali Loss: 0.3960548 Test Loss: 0.3670776
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 6.535341739654541
Epoch: 64, Steps: 59 | Train Loss: 0.2239079 Vali Loss: 0.3947683 Test Loss: 0.3670479
Validation loss decreased (0.394947 --> 0.394768).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 6.506944894790649
Epoch: 65, Steps: 59 | Train Loss: 0.2240466 Vali Loss: 0.3979032 Test Loss: 0.3670327
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 6.425395488739014
Epoch: 66, Steps: 59 | Train Loss: 0.2235735 Vali Loss: 0.3962796 Test Loss: 0.3670019
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 6.5066258907318115
Epoch: 67, Steps: 59 | Train Loss: 0.2229356 Vali Loss: 0.3981149 Test Loss: 0.3669893
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 6.318506717681885
Epoch: 68, Steps: 59 | Train Loss: 0.2229593 Vali Loss: 0.3943160 Test Loss: 0.3669648
Validation loss decreased (0.394768 --> 0.394316).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 6.471806287765503
Epoch: 69, Steps: 59 | Train Loss: 0.2232553 Vali Loss: 0.3925976 Test Loss: 0.3669586
Validation loss decreased (0.394316 --> 0.392598).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 6.455555200576782
Epoch: 70, Steps: 59 | Train Loss: 0.2229635 Vali Loss: 0.3951048 Test Loss: 0.3669499
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 6.456647634506226
Epoch: 71, Steps: 59 | Train Loss: 0.2234657 Vali Loss: 0.3958481 Test Loss: 0.3669280
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 6.559877157211304
Epoch: 72, Steps: 59 | Train Loss: 0.2229126 Vali Loss: 0.3951767 Test Loss: 0.3669104
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 6.542684078216553
Epoch: 73, Steps: 59 | Train Loss: 0.2229791 Vali Loss: 0.3968205 Test Loss: 0.3668942
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 6.415339231491089
Epoch: 74, Steps: 59 | Train Loss: 0.2231077 Vali Loss: 0.3966785 Test Loss: 0.3668860
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 6.137369155883789
Epoch: 75, Steps: 59 | Train Loss: 0.2227489 Vali Loss: 0.3943346 Test Loss: 0.3668681
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 6.538914680480957
Epoch: 76, Steps: 59 | Train Loss: 0.2227117 Vali Loss: 0.3967395 Test Loss: 0.3668700
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 6.819030284881592
Epoch: 77, Steps: 59 | Train Loss: 0.2224425 Vali Loss: 0.3947933 Test Loss: 0.3668588
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 7.907491445541382
Epoch: 78, Steps: 59 | Train Loss: 0.2229544 Vali Loss: 0.3935226 Test Loss: 0.3668537
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 8.352292537689209
Epoch: 79, Steps: 59 | Train Loss: 0.2218199 Vali Loss: 0.3952539 Test Loss: 0.3668389
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 7.901593446731567
Epoch: 80, Steps: 59 | Train Loss: 0.2224009 Vali Loss: 0.3943492 Test Loss: 0.3668304
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 7.213168382644653
Epoch: 81, Steps: 59 | Train Loss: 0.2218639 Vali Loss: 0.3942096 Test Loss: 0.3668192
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 7.546514511108398
Epoch: 82, Steps: 59 | Train Loss: 0.2224828 Vali Loss: 0.3954479 Test Loss: 0.3668181
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 6.996680736541748
Epoch: 83, Steps: 59 | Train Loss: 0.2223377 Vali Loss: 0.3950742 Test Loss: 0.3668094
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 6.9981303215026855
Epoch: 84, Steps: 59 | Train Loss: 0.2224458 Vali Loss: 0.3936497 Test Loss: 0.3668062
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 7.075630187988281
Epoch: 85, Steps: 59 | Train Loss: 0.2222786 Vali Loss: 0.3956008 Test Loss: 0.3667943
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 6.865301132202148
Epoch: 86, Steps: 59 | Train Loss: 0.2222912 Vali Loss: 0.3943700 Test Loss: 0.3667926
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 6.474495887756348
Epoch: 87, Steps: 59 | Train Loss: 0.2222468 Vali Loss: 0.3960672 Test Loss: 0.3667805
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 7.103315591812134
Epoch: 88, Steps: 59 | Train Loss: 0.2222584 Vali Loss: 0.3917273 Test Loss: 0.3667779
Validation loss decreased (0.392598 --> 0.391727).  Saving model ...
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 6.886148691177368
Epoch: 89, Steps: 59 | Train Loss: 0.2223315 Vali Loss: 0.3958423 Test Loss: 0.3667721
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 8.25615119934082
Epoch: 90, Steps: 59 | Train Loss: 0.2221445 Vali Loss: 0.3954425 Test Loss: 0.3667696
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 7.458346128463745
Epoch: 91, Steps: 59 | Train Loss: 0.2215504 Vali Loss: 0.3935317 Test Loss: 0.3667628
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 6.982924699783325
Epoch: 92, Steps: 59 | Train Loss: 0.2220600 Vali Loss: 0.3947477 Test Loss: 0.3667627
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 7.064838886260986
Epoch: 93, Steps: 59 | Train Loss: 0.2221046 Vali Loss: 0.3922275 Test Loss: 0.3667563
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 7.0880749225616455
Epoch: 94, Steps: 59 | Train Loss: 0.2217518 Vali Loss: 0.3920502 Test Loss: 0.3667524
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 6.988677024841309
Epoch: 95, Steps: 59 | Train Loss: 0.2214295 Vali Loss: 0.3963740 Test Loss: 0.3667485
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 7.21940279006958
Epoch: 96, Steps: 59 | Train Loss: 0.2219930 Vali Loss: 0.3949713 Test Loss: 0.3667493
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 7.334410905838013
Epoch: 97, Steps: 59 | Train Loss: 0.2218450 Vali Loss: 0.3946399 Test Loss: 0.3667463
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 7.08137321472168
Epoch: 98, Steps: 59 | Train Loss: 0.2219604 Vali Loss: 0.3910778 Test Loss: 0.3667437
Validation loss decreased (0.391727 --> 0.391078).  Saving model ...
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 7.176819086074829
Epoch: 99, Steps: 59 | Train Loss: 0.2214442 Vali Loss: 0.3944081 Test Loss: 0.3667396
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 5.576529502868652
Epoch: 100, Steps: 59 | Train Loss: 0.2212559 Vali Loss: 0.3945288 Test Loss: 0.3667385
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1160680107021042e-06
train 7585
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=196, out_features=287, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  50401792.0
params:  56539.0
Trainable parameters:  56539
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 4.6467578411102295
Epoch: 1, Steps: 59 | Train Loss: 0.6253999 Vali Loss: 0.3837486 Test Loss: 0.3627455
Validation loss decreased (inf --> 0.383749).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 6.348566770553589
Epoch: 2, Steps: 59 | Train Loss: 0.6180652 Vali Loss: 0.3807277 Test Loss: 0.3613372
Validation loss decreased (0.383749 --> 0.380728).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 6.385995388031006
Epoch: 3, Steps: 59 | Train Loss: 0.6146214 Vali Loss: 0.3803923 Test Loss: 0.3603419
Validation loss decreased (0.380728 --> 0.380392).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 6.230915546417236
Epoch: 4, Steps: 59 | Train Loss: 0.6134763 Vali Loss: 0.3804193 Test Loss: 0.3598621
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 6.03756308555603
Epoch: 5, Steps: 59 | Train Loss: 0.6111283 Vali Loss: 0.3777131 Test Loss: 0.3595200
Validation loss decreased (0.380392 --> 0.377713).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 6.240038871765137
Epoch: 6, Steps: 59 | Train Loss: 0.6120662 Vali Loss: 0.3770868 Test Loss: 0.3593540
Validation loss decreased (0.377713 --> 0.377087).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 6.233649492263794
Epoch: 7, Steps: 59 | Train Loss: 0.6116960 Vali Loss: 0.3771990 Test Loss: 0.3593610
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 6.085299968719482
Epoch: 8, Steps: 59 | Train Loss: 0.6100883 Vali Loss: 0.3765608 Test Loss: 0.3592020
Validation loss decreased (0.377087 --> 0.376561).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 6.049022197723389
Epoch: 9, Steps: 59 | Train Loss: 0.6120895 Vali Loss: 0.3765692 Test Loss: 0.3591913
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 6.186773061752319
Epoch: 10, Steps: 59 | Train Loss: 0.6110361 Vali Loss: 0.3768685 Test Loss: 0.3589414
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 5.979985952377319
Epoch: 11, Steps: 59 | Train Loss: 0.6106775 Vali Loss: 0.3761933 Test Loss: 0.3591224
Validation loss decreased (0.376561 --> 0.376193).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 5.795625686645508
Epoch: 12, Steps: 59 | Train Loss: 0.6105570 Vali Loss: 0.3761059 Test Loss: 0.3587887
Validation loss decreased (0.376193 --> 0.376106).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 6.205984115600586
Epoch: 13, Steps: 59 | Train Loss: 0.6097551 Vali Loss: 0.3763915 Test Loss: 0.3589020
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 6.150930881500244
Epoch: 14, Steps: 59 | Train Loss: 0.6098544 Vali Loss: 0.3746425 Test Loss: 0.3588084
Validation loss decreased (0.376106 --> 0.374642).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 5.854871511459351
Epoch: 15, Steps: 59 | Train Loss: 0.6096189 Vali Loss: 0.3764390 Test Loss: 0.3586262
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 6.1624579429626465
Epoch: 16, Steps: 59 | Train Loss: 0.6103440 Vali Loss: 0.3773150 Test Loss: 0.3587287
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 5.876432180404663
Epoch: 17, Steps: 59 | Train Loss: 0.6099830 Vali Loss: 0.3771458 Test Loss: 0.3586789
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.266920566558838
Epoch: 18, Steps: 59 | Train Loss: 0.6108832 Vali Loss: 0.3743022 Test Loss: 0.3586659
Validation loss decreased (0.374642 --> 0.374302).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.884420394897461
Epoch: 19, Steps: 59 | Train Loss: 0.6104235 Vali Loss: 0.3757144 Test Loss: 0.3586611
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.9472713470458984
Epoch: 20, Steps: 59 | Train Loss: 0.6097104 Vali Loss: 0.3754089 Test Loss: 0.3586324
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.423358917236328
Epoch: 21, Steps: 59 | Train Loss: 0.6094929 Vali Loss: 0.3741308 Test Loss: 0.3585823
Validation loss decreased (0.374302 --> 0.374131).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 4.184152841567993
Epoch: 22, Steps: 59 | Train Loss: 0.6094488 Vali Loss: 0.3759412 Test Loss: 0.3585980
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.8122501373291016
Epoch: 23, Steps: 59 | Train Loss: 0.6072661 Vali Loss: 0.3749702 Test Loss: 0.3586548
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 4.277316331863403
Epoch: 24, Steps: 59 | Train Loss: 0.6084076 Vali Loss: 0.3777983 Test Loss: 0.3584406
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.996786594390869
Epoch: 25, Steps: 59 | Train Loss: 0.6090916 Vali Loss: 0.3752280 Test Loss: 0.3584981
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.481402635574341
Epoch: 26, Steps: 59 | Train Loss: 0.6096687 Vali Loss: 0.3733872 Test Loss: 0.3585713
Validation loss decreased (0.374131 --> 0.373387).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 3.675915002822876
Epoch: 27, Steps: 59 | Train Loss: 0.6092962 Vali Loss: 0.3745223 Test Loss: 0.3585102
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.0989339351654053
Epoch: 28, Steps: 59 | Train Loss: 0.6093924 Vali Loss: 0.3773130 Test Loss: 0.3584902
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 3.7612104415893555
Epoch: 29, Steps: 59 | Train Loss: 0.6068551 Vali Loss: 0.3732811 Test Loss: 0.3585335
Validation loss decreased (0.373387 --> 0.373281).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 3.2992732524871826
Epoch: 30, Steps: 59 | Train Loss: 0.6095167 Vali Loss: 0.3737905 Test Loss: 0.3585816
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 3.2732813358306885
Epoch: 31, Steps: 59 | Train Loss: 0.6094328 Vali Loss: 0.3741757 Test Loss: 0.3585505
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 3.8184468746185303
Epoch: 32, Steps: 59 | Train Loss: 0.6070189 Vali Loss: 0.3740838 Test Loss: 0.3584829
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 3.6415319442749023
Epoch: 33, Steps: 59 | Train Loss: 0.6084643 Vali Loss: 0.3762600 Test Loss: 0.3584416
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.2708563804626465
Epoch: 34, Steps: 59 | Train Loss: 0.6095922 Vali Loss: 0.3750869 Test Loss: 0.3584689
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 3.9567580223083496
Epoch: 35, Steps: 59 | Train Loss: 0.6087036 Vali Loss: 0.3753577 Test Loss: 0.3585318
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 4.082889556884766
Epoch: 36, Steps: 59 | Train Loss: 0.6073314 Vali Loss: 0.3753546 Test Loss: 0.3584839
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 3.7944719791412354
Epoch: 37, Steps: 59 | Train Loss: 0.6085735 Vali Loss: 0.3729662 Test Loss: 0.3585199
Validation loss decreased (0.373281 --> 0.372966).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 4.3961873054504395
Epoch: 38, Steps: 59 | Train Loss: 0.6089367 Vali Loss: 0.3721531 Test Loss: 0.3584686
Validation loss decreased (0.372966 --> 0.372153).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 3.2663960456848145
Epoch: 39, Steps: 59 | Train Loss: 0.6087217 Vali Loss: 0.3737189 Test Loss: 0.3585043
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 3.7311151027679443
Epoch: 40, Steps: 59 | Train Loss: 0.6087642 Vali Loss: 0.3750344 Test Loss: 0.3584538
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 3.61099910736084
Epoch: 41, Steps: 59 | Train Loss: 0.6073360 Vali Loss: 0.3760205 Test Loss: 0.3584551
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 4.269270181655884
Epoch: 42, Steps: 59 | Train Loss: 0.6081027 Vali Loss: 0.3741564 Test Loss: 0.3584603
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 3.949857473373413
Epoch: 43, Steps: 59 | Train Loss: 0.6092673 Vali Loss: 0.3719945 Test Loss: 0.3584920
Validation loss decreased (0.372153 --> 0.371995).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.5188889503479004
Epoch: 44, Steps: 59 | Train Loss: 0.6080692 Vali Loss: 0.3763193 Test Loss: 0.3584877
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 3.6668927669525146
Epoch: 45, Steps: 59 | Train Loss: 0.6077202 Vali Loss: 0.3743753 Test Loss: 0.3584929
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 3.434180498123169
Epoch: 46, Steps: 59 | Train Loss: 0.6091226 Vali Loss: 0.3774525 Test Loss: 0.3584937
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 3.119988441467285
Epoch: 47, Steps: 59 | Train Loss: 0.6086598 Vali Loss: 0.3735909 Test Loss: 0.3584529
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 3.8718130588531494
Epoch: 48, Steps: 59 | Train Loss: 0.6070493 Vali Loss: 0.3763408 Test Loss: 0.3584534
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 3.2539706230163574
Epoch: 49, Steps: 59 | Train Loss: 0.6086697 Vali Loss: 0.3733202 Test Loss: 0.3584331
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 3.369997978210449
Epoch: 50, Steps: 59 | Train Loss: 0.6072550 Vali Loss: 0.3746720 Test Loss: 0.3584970
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 3.478010654449463
Epoch: 51, Steps: 59 | Train Loss: 0.6082107 Vali Loss: 0.3720626 Test Loss: 0.3584653
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 3.4605188369750977
Epoch: 52, Steps: 59 | Train Loss: 0.6083459 Vali Loss: 0.3769802 Test Loss: 0.3584577
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 3.3494482040405273
Epoch: 53, Steps: 59 | Train Loss: 0.6076991 Vali Loss: 0.3755155 Test Loss: 0.3584673
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 4.088822841644287
Epoch: 54, Steps: 59 | Train Loss: 0.6083339 Vali Loss: 0.3722657 Test Loss: 0.3584577
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 3.2330639362335205
Epoch: 55, Steps: 59 | Train Loss: 0.6083341 Vali Loss: 0.3760776 Test Loss: 0.3584581
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 3.64933705329895
Epoch: 56, Steps: 59 | Train Loss: 0.6071921 Vali Loss: 0.3774854 Test Loss: 0.3584667
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 3.230928659439087
Epoch: 57, Steps: 59 | Train Loss: 0.6078157 Vali Loss: 0.3748568 Test Loss: 0.3584636
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 3.6965348720550537
Epoch: 58, Steps: 59 | Train Loss: 0.6082703 Vali Loss: 0.3760144 Test Loss: 0.3584502
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 3.185098648071289
Epoch: 59, Steps: 59 | Train Loss: 0.6091478 Vali Loss: 0.3736629 Test Loss: 0.3584414
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 3.2039859294891357
Epoch: 60, Steps: 59 | Train Loss: 0.6056110 Vali Loss: 0.3727895 Test Loss: 0.3584530
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 3.889754295349121
Epoch: 61, Steps: 59 | Train Loss: 0.6078648 Vali Loss: 0.3745761 Test Loss: 0.3584575
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 3.8047170639038086
Epoch: 62, Steps: 59 | Train Loss: 0.6076394 Vali Loss: 0.3734967 Test Loss: 0.3584514
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 3.460099935531616
Epoch: 63, Steps: 59 | Train Loss: 0.6081896 Vali Loss: 0.3749928 Test Loss: 0.3584365
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_720_336_FITS_ETTh2_ftM_sl720_ll48_pl336_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.3542053699493408, mae:0.39531785249710083, rse:0.4758467674255371, corr:[0.26231423 0.26467738 0.26335794 0.26400644 0.26299962 0.2615927
 0.26157603 0.26115334 0.25978896 0.2586499  0.25786734 0.2564578
 0.2550905  0.25399962 0.25307778 0.25245228 0.2521271  0.25155067
 0.25044468 0.24936724 0.24850862 0.24760829 0.24646084 0.24517034
 0.24353017 0.24184142 0.24062143 0.23979203 0.23887059 0.23784253
 0.23712267 0.23641253 0.23532589 0.23416753 0.23320262 0.23239729
 0.23159398 0.23089722 0.23001286 0.22910598 0.22857137 0.22821243
 0.22755718 0.2266339  0.22570857 0.22474782 0.22347432 0.22185333
 0.2203635  0.21897131 0.21734451 0.21571833 0.2143882  0.21270755
 0.21068014 0.209109   0.20749688 0.20546794 0.20388399 0.20303707
 0.20240131 0.20200439 0.2022417  0.20244803 0.20158556 0.20085703
 0.20061815 0.20031542 0.19962054 0.19907033 0.19855203 0.19770333
 0.19658016 0.1958623  0.1952046  0.19370252 0.19238412 0.19208853
 0.19211465 0.19137563 0.19075368 0.1903829  0.18982111 0.18910082
 0.18882322 0.18906924 0.18898265 0.18829675 0.187535   0.18723007
 0.18699162 0.18657333 0.18662871 0.18667802 0.186458   0.18625075
 0.18612893 0.18554254 0.18459894 0.18383236 0.18345006 0.18281858
 0.18228826 0.18197735 0.18183549 0.18127859 0.18099092 0.18125124
 0.18102428 0.18028456 0.1795159  0.17913134 0.17850609 0.17815466
 0.17814031 0.17779917 0.17683329 0.17567737 0.1751643  0.17437582
 0.1729469  0.17160982 0.17085163 0.16992678 0.16877148 0.16822076
 0.16786215 0.1668543  0.16578043 0.16529039 0.16479978 0.16368781
 0.16295566 0.16281252 0.16249551 0.16179004 0.16128689 0.16107792
 0.16039816 0.15973923 0.15991816 0.15990803 0.15870729 0.15689436
 0.15537558 0.15419607 0.15285176 0.15177062 0.15109879 0.15035349
 0.14937826 0.14842172 0.14787349 0.14717606 0.14651138 0.14611377
 0.14557348 0.1448295  0.14464302 0.14493328 0.14454402 0.14404564
 0.14368302 0.14307581 0.14244501 0.14265734 0.14329751 0.14244448
 0.14044558 0.13903068 0.13869998 0.13785842 0.13647246 0.13529733
 0.13455904 0.13299355 0.13162136 0.13147946 0.13118392 0.13007605
 0.12900738 0.12887076 0.12879205 0.12820692 0.12757705 0.12787522
 0.12801264 0.12742898 0.12722933 0.1276351  0.12836349 0.12849572
 0.12821501 0.12780508 0.12724803 0.12690628 0.12645584 0.12579697
 0.12546235 0.12524462 0.12474419 0.12400222 0.1239026  0.12412635
 0.12358201 0.12309235 0.12336379 0.12398139 0.12374522 0.12343671
 0.12387639 0.12440246 0.12434028 0.12426255 0.12448737 0.12391583
 0.12277519 0.12220271 0.12186269 0.12101327 0.1199964  0.12019438
 0.12032367 0.12002631 0.11976201 0.12002724 0.1199012  0.11922307
 0.11896179 0.11905695 0.11839485 0.11820687 0.11902104 0.11979997
 0.11945488 0.11951826 0.12081842 0.12170458 0.12115049 0.12065177
 0.12094022 0.12067103 0.11977971 0.11975862 0.12004515 0.11947257
 0.11901587 0.11934353 0.11993171 0.11984836 0.11976668 0.12030983
 0.12039427 0.1205885  0.12127601 0.1228993  0.12405853 0.12529892
 0.12621567 0.12624727 0.125822   0.12601705 0.12728526 0.12777391
 0.12803431 0.12873092 0.12929331 0.12872542 0.12808119 0.12842658
 0.12832364 0.12747668 0.12770592 0.1285443  0.12883568 0.12788324
 0.12760787 0.12801585 0.1278624  0.1277059  0.12834296 0.12866035
 0.12792143 0.12745355 0.12738204 0.1269637  0.12668858 0.12743346
 0.12812635 0.12731439 0.12585805 0.12548247 0.12544948 0.12439173
 0.1233805  0.12293012 0.12245378 0.12175545 0.12176894 0.12157018
 0.12044533 0.12025377 0.12107236 0.12171752 0.12127677 0.12199855
 0.12248961 0.12214    0.12175684 0.12258378 0.12320933 0.1224575
 0.12185676 0.12133718 0.1203493  0.11920173 0.11922085 0.11902291
 0.11759558 0.11724599 0.11818429 0.11852166 0.11744245 0.1182431
 0.11959726 0.11890962 0.11819503 0.11983129 0.1206516  0.11850617
 0.1176874  0.11945435 0.1185715  0.11600004 0.11831883 0.11395615]
