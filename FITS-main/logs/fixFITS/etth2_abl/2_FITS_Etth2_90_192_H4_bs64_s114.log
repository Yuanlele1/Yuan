Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_90_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_90_192_FITS_ETTh2_ftM_sl90_ll48_pl192_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8359
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=26, out_features=81, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1886976.0
params:  2187.0
Trainable parameters:  2187
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.9539175033569336
Epoch: 1, Steps: 65 | Train Loss: 0.6280443 Vali Loss: 0.3841298 Test Loss: 0.5403380
Validation loss decreased (inf --> 0.384130).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.170496702194214
Epoch: 2, Steps: 65 | Train Loss: 0.5422753 Vali Loss: 0.3523983 Test Loss: 0.4958245
Validation loss decreased (0.384130 --> 0.352398).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.3738865852355957
Epoch: 3, Steps: 65 | Train Loss: 0.4916813 Vali Loss: 0.3323343 Test Loss: 0.4684601
Validation loss decreased (0.352398 --> 0.332334).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.059270143508911
Epoch: 4, Steps: 65 | Train Loss: 0.4594213 Vali Loss: 0.3197553 Test Loss: 0.4507936
Validation loss decreased (0.332334 --> 0.319755).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.9880766868591309
Epoch: 5, Steps: 65 | Train Loss: 0.4366541 Vali Loss: 0.3110543 Test Loss: 0.4389832
Validation loss decreased (0.319755 --> 0.311054).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.002902030944824
Epoch: 6, Steps: 65 | Train Loss: 0.4243207 Vali Loss: 0.3048465 Test Loss: 0.4307246
Validation loss decreased (0.311054 --> 0.304847).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.6007916927337646
Epoch: 7, Steps: 65 | Train Loss: 0.4144541 Vali Loss: 0.3003621 Test Loss: 0.4248416
Validation loss decreased (0.304847 --> 0.300362).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.8738455772399902
Epoch: 8, Steps: 65 | Train Loss: 0.4080371 Vali Loss: 0.2969335 Test Loss: 0.4204593
Validation loss decreased (0.300362 --> 0.296934).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.6205253601074219
Epoch: 9, Steps: 65 | Train Loss: 0.4028264 Vali Loss: 0.2943276 Test Loss: 0.4171925
Validation loss decreased (0.296934 --> 0.294328).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.8613948822021484
Epoch: 10, Steps: 65 | Train Loss: 0.3985126 Vali Loss: 0.2922459 Test Loss: 0.4146172
Validation loss decreased (0.294328 --> 0.292246).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.5340211391448975
Epoch: 11, Steps: 65 | Train Loss: 0.3945397 Vali Loss: 0.2905530 Test Loss: 0.4124824
Validation loss decreased (0.292246 --> 0.290553).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.1782124042510986
Epoch: 12, Steps: 65 | Train Loss: 0.3927036 Vali Loss: 0.2891607 Test Loss: 0.4108302
Validation loss decreased (0.290553 --> 0.289161).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.7474994659423828
Epoch: 13, Steps: 65 | Train Loss: 0.3906808 Vali Loss: 0.2877411 Test Loss: 0.4094942
Validation loss decreased (0.289161 --> 0.287741).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.2752134799957275
Epoch: 14, Steps: 65 | Train Loss: 0.3888846 Vali Loss: 0.2870779 Test Loss: 0.4083335
Validation loss decreased (0.287741 --> 0.287078).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.9194324016571045
Epoch: 15, Steps: 65 | Train Loss: 0.3880220 Vali Loss: 0.2862435 Test Loss: 0.4073459
Validation loss decreased (0.287078 --> 0.286243).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.0907950401306152
Epoch: 16, Steps: 65 | Train Loss: 0.3859654 Vali Loss: 0.2855102 Test Loss: 0.4065183
Validation loss decreased (0.286243 --> 0.285510).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.8546898365020752
Epoch: 17, Steps: 65 | Train Loss: 0.3857497 Vali Loss: 0.2848908 Test Loss: 0.4057780
Validation loss decreased (0.285510 --> 0.284891).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.9043464660644531
Epoch: 18, Steps: 65 | Train Loss: 0.3843324 Vali Loss: 0.2842078 Test Loss: 0.4051833
Validation loss decreased (0.284891 --> 0.284208).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.6572682857513428
Epoch: 19, Steps: 65 | Train Loss: 0.3847826 Vali Loss: 0.2838003 Test Loss: 0.4046081
Validation loss decreased (0.284208 --> 0.283800).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.941892385482788
Epoch: 20, Steps: 65 | Train Loss: 0.3823665 Vali Loss: 0.2833433 Test Loss: 0.4040766
Validation loss decreased (0.283800 --> 0.283343).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.111478567123413
Epoch: 21, Steps: 65 | Train Loss: 0.3824520 Vali Loss: 0.2829676 Test Loss: 0.4036338
Validation loss decreased (0.283343 --> 0.282968).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.18746280670166
Epoch: 22, Steps: 65 | Train Loss: 0.3828294 Vali Loss: 0.2821923 Test Loss: 0.4032883
Validation loss decreased (0.282968 --> 0.282192).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.7271275520324707
Epoch: 23, Steps: 65 | Train Loss: 0.3818831 Vali Loss: 0.2823004 Test Loss: 0.4029167
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.735013484954834
Epoch: 24, Steps: 65 | Train Loss: 0.3809683 Vali Loss: 0.2819161 Test Loss: 0.4026255
Validation loss decreased (0.282192 --> 0.281916).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.3858814239501953
Epoch: 25, Steps: 65 | Train Loss: 0.3817141 Vali Loss: 0.2817142 Test Loss: 0.4023280
Validation loss decreased (0.281916 --> 0.281714).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.661745309829712
Epoch: 26, Steps: 65 | Train Loss: 0.3812385 Vali Loss: 0.2814236 Test Loss: 0.4020439
Validation loss decreased (0.281714 --> 0.281424).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.175588846206665
Epoch: 27, Steps: 65 | Train Loss: 0.3802981 Vali Loss: 0.2811837 Test Loss: 0.4018023
Validation loss decreased (0.281424 --> 0.281184).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.2580325603485107
Epoch: 28, Steps: 65 | Train Loss: 0.3803113 Vali Loss: 0.2810113 Test Loss: 0.4016257
Validation loss decreased (0.281184 --> 0.281011).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.3267822265625
Epoch: 29, Steps: 65 | Train Loss: 0.3796305 Vali Loss: 0.2807544 Test Loss: 0.4014178
Validation loss decreased (0.281011 --> 0.280754).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.283801555633545
Epoch: 30, Steps: 65 | Train Loss: 0.3801652 Vali Loss: 0.2805977 Test Loss: 0.4012515
Validation loss decreased (0.280754 --> 0.280598).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.1252784729003906
Epoch: 31, Steps: 65 | Train Loss: 0.3796603 Vali Loss: 0.2804748 Test Loss: 0.4010694
Validation loss decreased (0.280598 --> 0.280475).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 3.6884896755218506
Epoch: 32, Steps: 65 | Train Loss: 0.3794624 Vali Loss: 0.2803237 Test Loss: 0.4009372
Validation loss decreased (0.280475 --> 0.280324).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.013195753097534
Epoch: 33, Steps: 65 | Train Loss: 0.3787113 Vali Loss: 0.2801859 Test Loss: 0.4007877
Validation loss decreased (0.280324 --> 0.280186).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.6505517959594727
Epoch: 34, Steps: 65 | Train Loss: 0.3793568 Vali Loss: 0.2800144 Test Loss: 0.4006626
Validation loss decreased (0.280186 --> 0.280014).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.8308868408203125
Epoch: 35, Steps: 65 | Train Loss: 0.3789624 Vali Loss: 0.2798566 Test Loss: 0.4005626
Validation loss decreased (0.280014 --> 0.279857).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.371159553527832
Epoch: 36, Steps: 65 | Train Loss: 0.3785169 Vali Loss: 0.2797576 Test Loss: 0.4004415
Validation loss decreased (0.279857 --> 0.279758).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.277259588241577
Epoch: 37, Steps: 65 | Train Loss: 0.3782598 Vali Loss: 0.2796757 Test Loss: 0.4003438
Validation loss decreased (0.279758 --> 0.279676).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.348320722579956
Epoch: 38, Steps: 65 | Train Loss: 0.3784568 Vali Loss: 0.2795774 Test Loss: 0.4002156
Validation loss decreased (0.279676 --> 0.279577).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.9304471015930176
Epoch: 39, Steps: 65 | Train Loss: 0.3778700 Vali Loss: 0.2794803 Test Loss: 0.4001414
Validation loss decreased (0.279577 --> 0.279480).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.0018510818481445
Epoch: 40, Steps: 65 | Train Loss: 0.3775233 Vali Loss: 0.2793195 Test Loss: 0.4000694
Validation loss decreased (0.279480 --> 0.279320).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.5651743412017822
Epoch: 41, Steps: 65 | Train Loss: 0.3782057 Vali Loss: 0.2793079 Test Loss: 0.3999887
Validation loss decreased (0.279320 --> 0.279308).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.4898812770843506
Epoch: 42, Steps: 65 | Train Loss: 0.3783283 Vali Loss: 0.2791970 Test Loss: 0.3999221
Validation loss decreased (0.279308 --> 0.279197).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.0119259357452393
Epoch: 43, Steps: 65 | Train Loss: 0.3780091 Vali Loss: 0.2791330 Test Loss: 0.3998560
Validation loss decreased (0.279197 --> 0.279133).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 4.008226156234741
Epoch: 44, Steps: 65 | Train Loss: 0.3775624 Vali Loss: 0.2786851 Test Loss: 0.3997777
Validation loss decreased (0.279133 --> 0.278685).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.8225889205932617
Epoch: 45, Steps: 65 | Train Loss: 0.3746791 Vali Loss: 0.2790026 Test Loss: 0.3997118
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.2122344970703125
Epoch: 46, Steps: 65 | Train Loss: 0.3772544 Vali Loss: 0.2789501 Test Loss: 0.3996577
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.894470453262329
Epoch: 47, Steps: 65 | Train Loss: 0.3770000 Vali Loss: 0.2788840 Test Loss: 0.3996148
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.970076084136963
Epoch: 48, Steps: 65 | Train Loss: 0.3773981 Vali Loss: 0.2787634 Test Loss: 0.3995616
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.3219590187072754
Epoch: 49, Steps: 65 | Train Loss: 0.3764444 Vali Loss: 0.2787792 Test Loss: 0.3995071
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.9303505420684814
Epoch: 50, Steps: 65 | Train Loss: 0.3773318 Vali Loss: 0.2787224 Test Loss: 0.3994715
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.078153133392334
Epoch: 51, Steps: 65 | Train Loss: 0.3773189 Vali Loss: 0.2783527 Test Loss: 0.3994368
Validation loss decreased (0.278685 --> 0.278353).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.7003955841064453
Epoch: 52, Steps: 65 | Train Loss: 0.3770485 Vali Loss: 0.2786068 Test Loss: 0.3994035
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.9067926406860352
Epoch: 53, Steps: 65 | Train Loss: 0.3761930 Vali Loss: 0.2785074 Test Loss: 0.3993602
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.913679838180542
Epoch: 54, Steps: 65 | Train Loss: 0.3766663 Vali Loss: 0.2785205 Test Loss: 0.3993343
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.2477803230285645
Epoch: 55, Steps: 65 | Train Loss: 0.3755797 Vali Loss: 0.2784246 Test Loss: 0.3992961
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.7775721549987793
Epoch: 56, Steps: 65 | Train Loss: 0.3763996 Vali Loss: 0.2780413 Test Loss: 0.3992682
Validation loss decreased (0.278353 --> 0.278041).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.91703200340271
Epoch: 57, Steps: 65 | Train Loss: 0.3762551 Vali Loss: 0.2784317 Test Loss: 0.3992362
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.561725616455078
Epoch: 58, Steps: 65 | Train Loss: 0.3766470 Vali Loss: 0.2784092 Test Loss: 0.3992172
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.405596971511841
Epoch: 59, Steps: 65 | Train Loss: 0.3769977 Vali Loss: 0.2783009 Test Loss: 0.3991860
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.0896449089050293
Epoch: 60, Steps: 65 | Train Loss: 0.3767404 Vali Loss: 0.2781990 Test Loss: 0.3991729
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 3.238712787628174
Epoch: 61, Steps: 65 | Train Loss: 0.3769777 Vali Loss: 0.2782992 Test Loss: 0.3991429
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.1033935546875
Epoch: 62, Steps: 65 | Train Loss: 0.3760977 Vali Loss: 0.2779673 Test Loss: 0.3991227
Validation loss decreased (0.278041 --> 0.277967).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.8402645587921143
Epoch: 63, Steps: 65 | Train Loss: 0.3764487 Vali Loss: 0.2782208 Test Loss: 0.3991015
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.408799886703491
Epoch: 64, Steps: 65 | Train Loss: 0.3762860 Vali Loss: 0.2781574 Test Loss: 0.3990804
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 3.2617645263671875
Epoch: 65, Steps: 65 | Train Loss: 0.3763585 Vali Loss: 0.2782023 Test Loss: 0.3990613
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.441746473312378
Epoch: 66, Steps: 65 | Train Loss: 0.3768677 Vali Loss: 0.2782010 Test Loss: 0.3990481
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.1263785362243652
Epoch: 67, Steps: 65 | Train Loss: 0.3749170 Vali Loss: 0.2781801 Test Loss: 0.3990326
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.908937931060791
Epoch: 68, Steps: 65 | Train Loss: 0.3765986 Vali Loss: 0.2781424 Test Loss: 0.3990142
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.1004414558410645
Epoch: 69, Steps: 65 | Train Loss: 0.3760919 Vali Loss: 0.2781392 Test Loss: 0.3989992
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.093127965927124
Epoch: 70, Steps: 65 | Train Loss: 0.3763771 Vali Loss: 0.2781054 Test Loss: 0.3989868
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.7370109558105469
Epoch: 71, Steps: 65 | Train Loss: 0.3767934 Vali Loss: 0.2780266 Test Loss: 0.3989749
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.619920253753662
Epoch: 72, Steps: 65 | Train Loss: 0.3751463 Vali Loss: 0.2780549 Test Loss: 0.3989594
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.0372583866119385
Epoch: 73, Steps: 65 | Train Loss: 0.3756812 Vali Loss: 0.2780568 Test Loss: 0.3989483
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 3.498643159866333
Epoch: 74, Steps: 65 | Train Loss: 0.3757993 Vali Loss: 0.2779244 Test Loss: 0.3989384
Validation loss decreased (0.277967 --> 0.277924).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.454836845397949
Epoch: 75, Steps: 65 | Train Loss: 0.3765976 Vali Loss: 0.2780464 Test Loss: 0.3989274
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.0074350833892822
Epoch: 76, Steps: 65 | Train Loss: 0.3762310 Vali Loss: 0.2780160 Test Loss: 0.3989165
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.0081255435943604
Epoch: 77, Steps: 65 | Train Loss: 0.3762904 Vali Loss: 0.2779369 Test Loss: 0.3989059
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.1019861698150635
Epoch: 78, Steps: 65 | Train Loss: 0.3744340 Vali Loss: 0.2779067 Test Loss: 0.3988959
Validation loss decreased (0.277924 --> 0.277907).  Saving model ...
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.7685866355895996
Epoch: 79, Steps: 65 | Train Loss: 0.3754365 Vali Loss: 0.2779970 Test Loss: 0.3988873
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.15983510017395
Epoch: 80, Steps: 65 | Train Loss: 0.3762750 Vali Loss: 0.2779844 Test Loss: 0.3988788
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.8259634971618652
Epoch: 81, Steps: 65 | Train Loss: 0.3749116 Vali Loss: 0.2779358 Test Loss: 0.3988682
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.9987926483154297
Epoch: 82, Steps: 65 | Train Loss: 0.3766116 Vali Loss: 0.2778484 Test Loss: 0.3988628
Validation loss decreased (0.277907 --> 0.277848).  Saving model ...
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.9462981224060059
Epoch: 83, Steps: 65 | Train Loss: 0.3758482 Vali Loss: 0.2779579 Test Loss: 0.3988543
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.8428754806518555
Epoch: 84, Steps: 65 | Train Loss: 0.3762379 Vali Loss: 0.2778730 Test Loss: 0.3988482
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.3727941513061523
Epoch: 85, Steps: 65 | Train Loss: 0.3763942 Vali Loss: 0.2779370 Test Loss: 0.3988418
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.9723353385925293
Epoch: 86, Steps: 65 | Train Loss: 0.3763110 Vali Loss: 0.2778820 Test Loss: 0.3988353
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.7781190872192383
Epoch: 87, Steps: 65 | Train Loss: 0.3763513 Vali Loss: 0.2778888 Test Loss: 0.3988322
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 2.1579976081848145
Epoch: 88, Steps: 65 | Train Loss: 0.3750275 Vali Loss: 0.2778677 Test Loss: 0.3988248
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.46665620803833
Epoch: 89, Steps: 65 | Train Loss: 0.3753554 Vali Loss: 0.2778345 Test Loss: 0.3988211
Validation loss decreased (0.277848 --> 0.277834).  Saving model ...
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.9172167778015137
Epoch: 90, Steps: 65 | Train Loss: 0.3745643 Vali Loss: 0.2775085 Test Loss: 0.3988145
Validation loss decreased (0.277834 --> 0.277508).  Saving model ...
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.3870043754577637
Epoch: 91, Steps: 65 | Train Loss: 0.3754831 Vali Loss: 0.2778973 Test Loss: 0.3988111
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.7780578136444092
Epoch: 92, Steps: 65 | Train Loss: 0.3759127 Vali Loss: 0.2778762 Test Loss: 0.3988064
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 3.453726291656494
Epoch: 93, Steps: 65 | Train Loss: 0.3760385 Vali Loss: 0.2778441 Test Loss: 0.3988024
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 2.020242691040039
Epoch: 94, Steps: 65 | Train Loss: 0.3761889 Vali Loss: 0.2778859 Test Loss: 0.3987983
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 2.04148530960083
Epoch: 95, Steps: 65 | Train Loss: 0.3754752 Vali Loss: 0.2778103 Test Loss: 0.3987933
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 2.7518913745880127
Epoch: 96, Steps: 65 | Train Loss: 0.3758881 Vali Loss: 0.2778618 Test Loss: 0.3987897
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.892761468887329
Epoch: 97, Steps: 65 | Train Loss: 0.3764550 Vali Loss: 0.2778647 Test Loss: 0.3987862
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 2.536036252975464
Epoch: 98, Steps: 65 | Train Loss: 0.3751472 Vali Loss: 0.2778533 Test Loss: 0.3987829
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 2.0483791828155518
Epoch: 99, Steps: 65 | Train Loss: 0.3763265 Vali Loss: 0.2777342 Test Loss: 0.3987794
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.7461433410644531
Epoch: 100, Steps: 65 | Train Loss: 0.3758352 Vali Loss: 0.2778221 Test Loss: 0.3987767
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8359
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=26, out_features=81, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1886976.0
params:  2187.0
Trainable parameters:  2187
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.7023274898529053
Epoch: 1, Steps: 65 | Train Loss: 0.5421412 Vali Loss: 0.2765912 Test Loss: 0.3975522
Validation loss decreased (inf --> 0.276591).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.414517402648926
Epoch: 2, Steps: 65 | Train Loss: 0.5408951 Vali Loss: 0.2759327 Test Loss: 0.3969816
Validation loss decreased (0.276591 --> 0.275933).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.3757026195526123
Epoch: 3, Steps: 65 | Train Loss: 0.5403448 Vali Loss: 0.2754816 Test Loss: 0.3966987
Validation loss decreased (0.275933 --> 0.275482).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.4599835872650146
Epoch: 4, Steps: 65 | Train Loss: 0.5394445 Vali Loss: 0.2751302 Test Loss: 0.3965126
Validation loss decreased (0.275482 --> 0.275130).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.9486377239227295
Epoch: 5, Steps: 65 | Train Loss: 0.5379646 Vali Loss: 0.2748873 Test Loss: 0.3965066
Validation loss decreased (0.275130 --> 0.274887).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.6993300914764404
Epoch: 6, Steps: 65 | Train Loss: 0.5380978 Vali Loss: 0.2745496 Test Loss: 0.3963673
Validation loss decreased (0.274887 --> 0.274550).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.8637628555297852
Epoch: 7, Steps: 65 | Train Loss: 0.5373217 Vali Loss: 0.2744649 Test Loss: 0.3964067
Validation loss decreased (0.274550 --> 0.274465).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.6538970470428467
Epoch: 8, Steps: 65 | Train Loss: 0.5381003 Vali Loss: 0.2744142 Test Loss: 0.3964417
Validation loss decreased (0.274465 --> 0.274414).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.7789208889007568
Epoch: 9, Steps: 65 | Train Loss: 0.5376872 Vali Loss: 0.2741449 Test Loss: 0.3963247
Validation loss decreased (0.274414 --> 0.274145).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.8322720527648926
Epoch: 10, Steps: 65 | Train Loss: 0.5370325 Vali Loss: 0.2741326 Test Loss: 0.3963754
Validation loss decreased (0.274145 --> 0.274133).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.083610773086548
Epoch: 11, Steps: 65 | Train Loss: 0.5359718 Vali Loss: 0.2740019 Test Loss: 0.3964208
Validation loss decreased (0.274133 --> 0.274002).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.3865966796875
Epoch: 12, Steps: 65 | Train Loss: 0.5351978 Vali Loss: 0.2739271 Test Loss: 0.3963864
Validation loss decreased (0.274002 --> 0.273927).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.9746525287628174
Epoch: 13, Steps: 65 | Train Loss: 0.5372625 Vali Loss: 0.2738555 Test Loss: 0.3964626
Validation loss decreased (0.273927 --> 0.273856).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.0536375045776367
Epoch: 14, Steps: 65 | Train Loss: 0.5367845 Vali Loss: 0.2737774 Test Loss: 0.3965121
Validation loss decreased (0.273856 --> 0.273777).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.136387348175049
Epoch: 15, Steps: 65 | Train Loss: 0.5364284 Vali Loss: 0.2736521 Test Loss: 0.3964666
Validation loss decreased (0.273777 --> 0.273652).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.853421926498413
Epoch: 16, Steps: 65 | Train Loss: 0.5353553 Vali Loss: 0.2736733 Test Loss: 0.3964755
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.730236768722534
Epoch: 17, Steps: 65 | Train Loss: 0.5361932 Vali Loss: 0.2736173 Test Loss: 0.3965417
Validation loss decreased (0.273652 --> 0.273617).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.158447027206421
Epoch: 18, Steps: 65 | Train Loss: 0.5355442 Vali Loss: 0.2734675 Test Loss: 0.3965475
Validation loss decreased (0.273617 --> 0.273467).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.7646551132202148
Epoch: 19, Steps: 65 | Train Loss: 0.5366474 Vali Loss: 0.2734514 Test Loss: 0.3965230
Validation loss decreased (0.273467 --> 0.273451).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.2122459411621094
Epoch: 20, Steps: 65 | Train Loss: 0.5358540 Vali Loss: 0.2731872 Test Loss: 0.3966585
Validation loss decreased (0.273451 --> 0.273187).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.0670111179351807
Epoch: 21, Steps: 65 | Train Loss: 0.5360551 Vali Loss: 0.2734571 Test Loss: 0.3966360
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.9508674144744873
Epoch: 22, Steps: 65 | Train Loss: 0.5350644 Vali Loss: 0.2734317 Test Loss: 0.3966298
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.9198040962219238
Epoch: 23, Steps: 65 | Train Loss: 0.5354518 Vali Loss: 0.2733457 Test Loss: 0.3966335
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.750540018081665
Epoch: 24, Steps: 65 | Train Loss: 0.5349462 Vali Loss: 0.2733829 Test Loss: 0.3966925
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.7113080024719238
Epoch: 25, Steps: 65 | Train Loss: 0.5353053 Vali Loss: 0.2733251 Test Loss: 0.3966632
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.5967018604278564
Epoch: 26, Steps: 65 | Train Loss: 0.5348006 Vali Loss: 0.2733026 Test Loss: 0.3967104
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.729515790939331
Epoch: 27, Steps: 65 | Train Loss: 0.5345499 Vali Loss: 0.2732627 Test Loss: 0.3967078
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.3545970916748047
Epoch: 28, Steps: 65 | Train Loss: 0.5357678 Vali Loss: 0.2732739 Test Loss: 0.3967406
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.7563676834106445
Epoch: 29, Steps: 65 | Train Loss: 0.5350896 Vali Loss: 0.2732675 Test Loss: 0.3967296
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.7959387302398682
Epoch: 30, Steps: 65 | Train Loss: 0.5351553 Vali Loss: 0.2732006 Test Loss: 0.3967552
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.8949675559997559
Epoch: 31, Steps: 65 | Train Loss: 0.5353016 Vali Loss: 0.2732553 Test Loss: 0.3967814
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 3.3517959117889404
Epoch: 32, Steps: 65 | Train Loss: 0.5354313 Vali Loss: 0.2731852 Test Loss: 0.3967726
Validation loss decreased (0.273187 --> 0.273185).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.255282163619995
Epoch: 33, Steps: 65 | Train Loss: 0.5360852 Vali Loss: 0.2731943 Test Loss: 0.3967719
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.8658149242401123
Epoch: 34, Steps: 65 | Train Loss: 0.5348914 Vali Loss: 0.2731253 Test Loss: 0.3967970
Validation loss decreased (0.273185 --> 0.273125).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.6512932777404785
Epoch: 35, Steps: 65 | Train Loss: 0.5362936 Vali Loss: 0.2731554 Test Loss: 0.3968179
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.041968584060669
Epoch: 36, Steps: 65 | Train Loss: 0.5348026 Vali Loss: 0.2731591 Test Loss: 0.3968168
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.291667938232422
Epoch: 37, Steps: 65 | Train Loss: 0.5333464 Vali Loss: 0.2731316 Test Loss: 0.3968118
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.9723072052001953
Epoch: 38, Steps: 65 | Train Loss: 0.5344121 Vali Loss: 0.2731354 Test Loss: 0.3968474
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.3274359703063965
Epoch: 39, Steps: 65 | Train Loss: 0.5355296 Vali Loss: 0.2731074 Test Loss: 0.3968318
Validation loss decreased (0.273125 --> 0.273107).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.8908076286315918
Epoch: 40, Steps: 65 | Train Loss: 0.5344571 Vali Loss: 0.2730910 Test Loss: 0.3968566
Validation loss decreased (0.273107 --> 0.273091).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.1423749923706055
Epoch: 41, Steps: 65 | Train Loss: 0.5340794 Vali Loss: 0.2731227 Test Loss: 0.3968601
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.270451068878174
Epoch: 42, Steps: 65 | Train Loss: 0.5347597 Vali Loss: 0.2731134 Test Loss: 0.3968678
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.158996105194092
Epoch: 43, Steps: 65 | Train Loss: 0.5347432 Vali Loss: 0.2730787 Test Loss: 0.3968741
Validation loss decreased (0.273091 --> 0.273079).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.410965919494629
Epoch: 44, Steps: 65 | Train Loss: 0.5348732 Vali Loss: 0.2729213 Test Loss: 0.3968778
Validation loss decreased (0.273079 --> 0.272921).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.669050931930542
Epoch: 45, Steps: 65 | Train Loss: 0.5337647 Vali Loss: 0.2730854 Test Loss: 0.3968719
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.6089248657226562
Epoch: 46, Steps: 65 | Train Loss: 0.5354035 Vali Loss: 0.2729899 Test Loss: 0.3968798
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.9544498920440674
Epoch: 47, Steps: 65 | Train Loss: 0.5355884 Vali Loss: 0.2730564 Test Loss: 0.3968957
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.7669117450714111
Epoch: 48, Steps: 65 | Train Loss: 0.5354298 Vali Loss: 0.2727234 Test Loss: 0.3968939
Validation loss decreased (0.272921 --> 0.272723).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.694868564605713
Epoch: 49, Steps: 65 | Train Loss: 0.5352259 Vali Loss: 0.2727884 Test Loss: 0.3968993
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.055068254470825
Epoch: 50, Steps: 65 | Train Loss: 0.5351380 Vali Loss: 0.2729960 Test Loss: 0.3969051
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.619487762451172
Epoch: 51, Steps: 65 | Train Loss: 0.5343522 Vali Loss: 0.2726738 Test Loss: 0.3969109
Validation loss decreased (0.272723 --> 0.272674).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.232264280319214
Epoch: 52, Steps: 65 | Train Loss: 0.5346305 Vali Loss: 0.2730063 Test Loss: 0.3969040
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.7205994129180908
Epoch: 53, Steps: 65 | Train Loss: 0.5343469 Vali Loss: 0.2730060 Test Loss: 0.3969090
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.887869119644165
Epoch: 54, Steps: 65 | Train Loss: 0.5350398 Vali Loss: 0.2727100 Test Loss: 0.3969090
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.899709701538086
Epoch: 55, Steps: 65 | Train Loss: 0.5351189 Vali Loss: 0.2730325 Test Loss: 0.3969239
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.9549460411071777
Epoch: 56, Steps: 65 | Train Loss: 0.5339790 Vali Loss: 0.2729851 Test Loss: 0.3969273
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.6314945220947266
Epoch: 57, Steps: 65 | Train Loss: 0.5343689 Vali Loss: 0.2730230 Test Loss: 0.3969326
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.1771140098571777
Epoch: 58, Steps: 65 | Train Loss: 0.5333943 Vali Loss: 0.2729693 Test Loss: 0.3969237
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.8397576808929443
Epoch: 59, Steps: 65 | Train Loss: 0.5346698 Vali Loss: 0.2729925 Test Loss: 0.3969335
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.9245705604553223
Epoch: 60, Steps: 65 | Train Loss: 0.5346854 Vali Loss: 0.2729958 Test Loss: 0.3969421
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.6324739456176758
Epoch: 61, Steps: 65 | Train Loss: 0.5356642 Vali Loss: 0.2729844 Test Loss: 0.3969356
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.8521509170532227
Epoch: 62, Steps: 65 | Train Loss: 0.5345109 Vali Loss: 0.2729417 Test Loss: 0.3969402
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.3761634826660156
Epoch: 63, Steps: 65 | Train Loss: 0.5348434 Vali Loss: 0.2726822 Test Loss: 0.3969482
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.068857192993164
Epoch: 64, Steps: 65 | Train Loss: 0.5348735 Vali Loss: 0.2730201 Test Loss: 0.3969496
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.6796443462371826
Epoch: 65, Steps: 65 | Train Loss: 0.5342657 Vali Loss: 0.2729930 Test Loss: 0.3969491
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.0755577087402344
Epoch: 66, Steps: 65 | Train Loss: 0.5321508 Vali Loss: 0.2729918 Test Loss: 0.3969492
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.8797709941864014
Epoch: 67, Steps: 65 | Train Loss: 0.5352389 Vali Loss: 0.2728489 Test Loss: 0.3969515
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 3.236084461212158
Epoch: 68, Steps: 65 | Train Loss: 0.5344031 Vali Loss: 0.2729495 Test Loss: 0.3969536
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.8670601844787598
Epoch: 69, Steps: 65 | Train Loss: 0.5348132 Vali Loss: 0.2729787 Test Loss: 0.3969581
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.839799404144287
Epoch: 70, Steps: 65 | Train Loss: 0.5357079 Vali Loss: 0.2729240 Test Loss: 0.3969558
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.34232759475708
Epoch: 71, Steps: 65 | Train Loss: 0.5353080 Vali Loss: 0.2729199 Test Loss: 0.3969564
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_90_192_FITS_ETTh2_ftM_sl90_ll48_pl192_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.376472145318985, mae:0.3903772532939911, rse:0.4920477867126465, corr:[0.26807347 0.27014893 0.26757273 0.26776922 0.2668182  0.26507643
 0.2649022  0.2642334  0.2629875  0.26208636 0.2613513  0.25951675
 0.257494   0.2563532  0.2554401  0.25467816 0.2542685  0.25391906
 0.25319743 0.25214532 0.25112012 0.25004166 0.24890028 0.24696992
 0.243703   0.24099633 0.23871419 0.23699658 0.23543325 0.2340369
 0.23310344 0.23151153 0.22998007 0.2285065  0.22746246 0.22611463
 0.22434722 0.2229451  0.22191037 0.22101389 0.2202539  0.21987747
 0.21973938 0.21873319 0.21752371 0.21669179 0.21575424 0.21354268
 0.20992832 0.20730233 0.20474762 0.2023743  0.2006108  0.19886057
 0.19697946 0.19436212 0.1930513  0.19160032 0.19044714 0.18916845
 0.18792006 0.18740077 0.18725921 0.18721896 0.1868152  0.18627644
 0.18593661 0.18516864 0.18451688 0.18411794 0.1834387  0.18195298
 0.17919174 0.17774425 0.17648369 0.17501564 0.17386058 0.1736876
 0.17372206 0.1723753  0.17186405 0.17164531 0.17135273 0.17081569
 0.17018367 0.1699796  0.16990812 0.16996044 0.1696528  0.16915011
 0.1688067  0.16822422 0.1678721  0.16752742 0.16717397 0.16620152
 0.16374694 0.16177647 0.16006553 0.1585711  0.15725075 0.15639567
 0.15650098 0.15564656 0.15544999 0.155382   0.15522566 0.15482278
 0.1542457  0.15388602 0.15301919 0.15253676 0.15240966 0.15198523
 0.15157859 0.15102962 0.1506006  0.14962374 0.14805773 0.14618236
 0.14339788 0.14112215 0.13941999 0.13850045 0.13713185 0.13601987
 0.13586466 0.13516521 0.13463426 0.13422203 0.13406347 0.13325806
 0.1323597  0.13197125 0.1315489  0.131028   0.13069855 0.13046117
 0.12993689 0.12921166 0.1290136  0.12864053 0.12728053 0.12524937
 0.12207022 0.11948814 0.11734159 0.11594062 0.11458289 0.11341459
 0.11338381 0.11263875 0.11218222 0.11178283 0.11186479 0.11145006
 0.11069662 0.11057851 0.1104716  0.11039141 0.11023554 0.11015607
 0.11001905 0.10943799 0.10960937 0.10980766 0.10931768 0.10790093
 0.10520971 0.10333387 0.10176581 0.10099664 0.10023575 0.0993158
 0.09928101 0.09876173 0.09863683 0.09822557 0.09819671 0.09766021
 0.09707635 0.09700143 0.09660958 0.09668867 0.09662872 0.09639642
 0.09618986 0.09598757 0.09657011 0.09663215 0.09676246 0.0998882 ]
