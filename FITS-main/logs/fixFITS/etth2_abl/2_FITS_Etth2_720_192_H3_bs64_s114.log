Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=103, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=103, out_features=130, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  11997440.0
params:  13520.0
Trainable parameters:  13520
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.975757360458374
Epoch: 1, Steps: 60 | Train Loss: 0.6220552 Vali Loss: 0.4976963 Test Loss: 0.4534178
Validation loss decreased (inf --> 0.497696).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.3144285678863525
Epoch: 2, Steps: 60 | Train Loss: 0.4961624 Vali Loss: 0.4384253 Test Loss: 0.4184113
Validation loss decreased (0.497696 --> 0.438425).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.231806993484497
Epoch: 3, Steps: 60 | Train Loss: 0.4266002 Vali Loss: 0.4081994 Test Loss: 0.4019731
Validation loss decreased (0.438425 --> 0.408199).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.037360191345215
Epoch: 4, Steps: 60 | Train Loss: 0.3833404 Vali Loss: 0.3917168 Test Loss: 0.3938709
Validation loss decreased (0.408199 --> 0.391717).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.657305955886841
Epoch: 5, Steps: 60 | Train Loss: 0.3531474 Vali Loss: 0.3813632 Test Loss: 0.3896143
Validation loss decreased (0.391717 --> 0.381363).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.026721715927124
Epoch: 6, Steps: 60 | Train Loss: 0.3302227 Vali Loss: 0.3743642 Test Loss: 0.3871757
Validation loss decreased (0.381363 --> 0.374364).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.786316394805908
Epoch: 7, Steps: 60 | Train Loss: 0.3108927 Vali Loss: 0.3688678 Test Loss: 0.3853441
Validation loss decreased (0.374364 --> 0.368868).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.9162793159484863
Epoch: 8, Steps: 60 | Train Loss: 0.2954847 Vali Loss: 0.3644230 Test Loss: 0.3840375
Validation loss decreased (0.368868 --> 0.364423).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.9177100658416748
Epoch: 9, Steps: 60 | Train Loss: 0.2822041 Vali Loss: 0.3607455 Test Loss: 0.3828902
Validation loss decreased (0.364423 --> 0.360745).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.0649688243865967
Epoch: 10, Steps: 60 | Train Loss: 0.2712618 Vali Loss: 0.3576467 Test Loss: 0.3818315
Validation loss decreased (0.360745 --> 0.357647).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.7124991416931152
Epoch: 11, Steps: 60 | Train Loss: 0.2609029 Vali Loss: 0.3547431 Test Loss: 0.3807464
Validation loss decreased (0.357647 --> 0.354743).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.412881374359131
Epoch: 12, Steps: 60 | Train Loss: 0.2522099 Vali Loss: 0.3518750 Test Loss: 0.3798560
Validation loss decreased (0.354743 --> 0.351875).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.0780506134033203
Epoch: 13, Steps: 60 | Train Loss: 0.2443257 Vali Loss: 0.3497900 Test Loss: 0.3788307
Validation loss decreased (0.351875 --> 0.349790).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.0802810192108154
Epoch: 14, Steps: 60 | Train Loss: 0.2373421 Vali Loss: 0.3475554 Test Loss: 0.3780496
Validation loss decreased (0.349790 --> 0.347555).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.1776678562164307
Epoch: 15, Steps: 60 | Train Loss: 0.2313023 Vali Loss: 0.3453450 Test Loss: 0.3771412
Validation loss decreased (0.347555 --> 0.345345).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.789942741394043
Epoch: 16, Steps: 60 | Train Loss: 0.2256168 Vali Loss: 0.3433945 Test Loss: 0.3762857
Validation loss decreased (0.345345 --> 0.343394).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.757075548171997
Epoch: 17, Steps: 60 | Train Loss: 0.2207574 Vali Loss: 0.3418439 Test Loss: 0.3755852
Validation loss decreased (0.343394 --> 0.341844).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.458070993423462
Epoch: 18, Steps: 60 | Train Loss: 0.2158194 Vali Loss: 0.3401863 Test Loss: 0.3748039
Validation loss decreased (0.341844 --> 0.340186).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 3.7374000549316406
Epoch: 19, Steps: 60 | Train Loss: 0.2119900 Vali Loss: 0.3387473 Test Loss: 0.3742250
Validation loss decreased (0.340186 --> 0.338747).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.0050535202026367
Epoch: 20, Steps: 60 | Train Loss: 0.2083687 Vali Loss: 0.3372522 Test Loss: 0.3734677
Validation loss decreased (0.338747 --> 0.337252).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.1625254154205322
Epoch: 21, Steps: 60 | Train Loss: 0.2047203 Vali Loss: 0.3359978 Test Loss: 0.3729543
Validation loss decreased (0.337252 --> 0.335998).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.7298524379730225
Epoch: 22, Steps: 60 | Train Loss: 0.2014645 Vali Loss: 0.3346224 Test Loss: 0.3722907
Validation loss decreased (0.335998 --> 0.334622).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.0807764530181885
Epoch: 23, Steps: 60 | Train Loss: 0.1986289 Vali Loss: 0.3334338 Test Loss: 0.3717525
Validation loss decreased (0.334622 --> 0.333434).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.1209545135498047
Epoch: 24, Steps: 60 | Train Loss: 0.1958887 Vali Loss: 0.3324133 Test Loss: 0.3713003
Validation loss decreased (0.333434 --> 0.332413).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.511434555053711
Epoch: 25, Steps: 60 | Train Loss: 0.1934264 Vali Loss: 0.3314213 Test Loss: 0.3707630
Validation loss decreased (0.332413 --> 0.331421).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.5898146629333496
Epoch: 26, Steps: 60 | Train Loss: 0.1911843 Vali Loss: 0.3303460 Test Loss: 0.3703834
Validation loss decreased (0.331421 --> 0.330346).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 3.105616569519043
Epoch: 27, Steps: 60 | Train Loss: 0.1891021 Vali Loss: 0.3295485 Test Loss: 0.3698647
Validation loss decreased (0.330346 --> 0.329548).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.526826858520508
Epoch: 28, Steps: 60 | Train Loss: 0.1872173 Vali Loss: 0.3286138 Test Loss: 0.3695143
Validation loss decreased (0.329548 --> 0.328614).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.866325616836548
Epoch: 29, Steps: 60 | Train Loss: 0.1851739 Vali Loss: 0.3277385 Test Loss: 0.3691360
Validation loss decreased (0.328614 --> 0.327739).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.34513258934021
Epoch: 30, Steps: 60 | Train Loss: 0.1834156 Vali Loss: 0.3269918 Test Loss: 0.3688069
Validation loss decreased (0.327739 --> 0.326992).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.6326467990875244
Epoch: 31, Steps: 60 | Train Loss: 0.1822298 Vali Loss: 0.3263986 Test Loss: 0.3684683
Validation loss decreased (0.326992 --> 0.326399).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.484528064727783
Epoch: 32, Steps: 60 | Train Loss: 0.1807923 Vali Loss: 0.3255841 Test Loss: 0.3682119
Validation loss decreased (0.326399 --> 0.325584).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 3.0924575328826904
Epoch: 33, Steps: 60 | Train Loss: 0.1796146 Vali Loss: 0.3250569 Test Loss: 0.3679589
Validation loss decreased (0.325584 --> 0.325057).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.47445011138916
Epoch: 34, Steps: 60 | Train Loss: 0.1781268 Vali Loss: 0.3245577 Test Loss: 0.3676403
Validation loss decreased (0.325057 --> 0.324558).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.173548936843872
Epoch: 35, Steps: 60 | Train Loss: 0.1773113 Vali Loss: 0.3238529 Test Loss: 0.3674361
Validation loss decreased (0.324558 --> 0.323853).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 3.431706190109253
Epoch: 36, Steps: 60 | Train Loss: 0.1757955 Vali Loss: 0.3234441 Test Loss: 0.3671550
Validation loss decreased (0.323853 --> 0.323444).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.3554904460906982
Epoch: 37, Steps: 60 | Train Loss: 0.1753043 Vali Loss: 0.3228150 Test Loss: 0.3669803
Validation loss decreased (0.323444 --> 0.322815).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.9628546237945557
Epoch: 38, Steps: 60 | Train Loss: 0.1742388 Vali Loss: 0.3223372 Test Loss: 0.3667587
Validation loss decreased (0.322815 --> 0.322337).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.521294116973877
Epoch: 39, Steps: 60 | Train Loss: 0.1729201 Vali Loss: 0.3218763 Test Loss: 0.3665819
Validation loss decreased (0.322337 --> 0.321876).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.856353282928467
Epoch: 40, Steps: 60 | Train Loss: 0.1726246 Vali Loss: 0.3213027 Test Loss: 0.3663994
Validation loss decreased (0.321876 --> 0.321303).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.830881357192993
Epoch: 41, Steps: 60 | Train Loss: 0.1715252 Vali Loss: 0.3210533 Test Loss: 0.3662145
Validation loss decreased (0.321303 --> 0.321053).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.664095401763916
Epoch: 42, Steps: 60 | Train Loss: 0.1706377 Vali Loss: 0.3203930 Test Loss: 0.3660427
Validation loss decreased (0.321053 --> 0.320393).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.2324225902557373
Epoch: 43, Steps: 60 | Train Loss: 0.1701474 Vali Loss: 0.3202952 Test Loss: 0.3659259
Validation loss decreased (0.320393 --> 0.320295).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.5606207847595215
Epoch: 44, Steps: 60 | Train Loss: 0.1693897 Vali Loss: 0.3197969 Test Loss: 0.3657556
Validation loss decreased (0.320295 --> 0.319797).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.799274206161499
Epoch: 45, Steps: 60 | Train Loss: 0.1685094 Vali Loss: 0.3196048 Test Loss: 0.3656301
Validation loss decreased (0.319797 --> 0.319605).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.074084758758545
Epoch: 46, Steps: 60 | Train Loss: 0.1676758 Vali Loss: 0.3192914 Test Loss: 0.3655382
Validation loss decreased (0.319605 --> 0.319291).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.936837673187256
Epoch: 47, Steps: 60 | Train Loss: 0.1675956 Vali Loss: 0.3189383 Test Loss: 0.3654072
Validation loss decreased (0.319291 --> 0.318938).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.393582582473755
Epoch: 48, Steps: 60 | Train Loss: 0.1673364 Vali Loss: 0.3187472 Test Loss: 0.3652571
Validation loss decreased (0.318938 --> 0.318747).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.8889005184173584
Epoch: 49, Steps: 60 | Train Loss: 0.1666442 Vali Loss: 0.3184614 Test Loss: 0.3651440
Validation loss decreased (0.318747 --> 0.318461).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.756953239440918
Epoch: 50, Steps: 60 | Train Loss: 0.1658636 Vali Loss: 0.3178893 Test Loss: 0.3650500
Validation loss decreased (0.318461 --> 0.317889).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.5870628356933594
Epoch: 51, Steps: 60 | Train Loss: 0.1657877 Vali Loss: 0.3180352 Test Loss: 0.3649753
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 3.901358127593994
Epoch: 52, Steps: 60 | Train Loss: 0.1651553 Vali Loss: 0.3177592 Test Loss: 0.3648795
Validation loss decreased (0.317889 --> 0.317759).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.818876028060913
Epoch: 53, Steps: 60 | Train Loss: 0.1649465 Vali Loss: 0.3175212 Test Loss: 0.3647712
Validation loss decreased (0.317759 --> 0.317521).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 3.0090203285217285
Epoch: 54, Steps: 60 | Train Loss: 0.1646891 Vali Loss: 0.3172908 Test Loss: 0.3647287
Validation loss decreased (0.317521 --> 0.317291).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 3.04630184173584
Epoch: 55, Steps: 60 | Train Loss: 0.1644250 Vali Loss: 0.3170551 Test Loss: 0.3646382
Validation loss decreased (0.317291 --> 0.317055).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.538386583328247
Epoch: 56, Steps: 60 | Train Loss: 0.1638641 Vali Loss: 0.3169678 Test Loss: 0.3645503
Validation loss decreased (0.317055 --> 0.316968).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 3.0778186321258545
Epoch: 57, Steps: 60 | Train Loss: 0.1636525 Vali Loss: 0.3167571 Test Loss: 0.3644999
Validation loss decreased (0.316968 --> 0.316757).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.599658727645874
Epoch: 58, Steps: 60 | Train Loss: 0.1633176 Vali Loss: 0.3165736 Test Loss: 0.3644414
Validation loss decreased (0.316757 --> 0.316574).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.97037672996521
Epoch: 59, Steps: 60 | Train Loss: 0.1633527 Vali Loss: 0.3163790 Test Loss: 0.3643865
Validation loss decreased (0.316574 --> 0.316379).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 3.238292694091797
Epoch: 60, Steps: 60 | Train Loss: 0.1628313 Vali Loss: 0.3162110 Test Loss: 0.3643159
Validation loss decreased (0.316379 --> 0.316211).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.8923752307891846
Epoch: 61, Steps: 60 | Train Loss: 0.1623720 Vali Loss: 0.3161251 Test Loss: 0.3642671
Validation loss decreased (0.316211 --> 0.316125).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.653167247772217
Epoch: 62, Steps: 60 | Train Loss: 0.1622472 Vali Loss: 0.3159984 Test Loss: 0.3642159
Validation loss decreased (0.316125 --> 0.315998).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.814948320388794
Epoch: 63, Steps: 60 | Train Loss: 0.1622398 Vali Loss: 0.3158838 Test Loss: 0.3641801
Validation loss decreased (0.315998 --> 0.315884).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.3782224655151367
Epoch: 64, Steps: 60 | Train Loss: 0.1618555 Vali Loss: 0.3154448 Test Loss: 0.3641258
Validation loss decreased (0.315884 --> 0.315445).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.950972557067871
Epoch: 65, Steps: 60 | Train Loss: 0.1614914 Vali Loss: 0.3155607 Test Loss: 0.3640897
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.971818685531616
Epoch: 66, Steps: 60 | Train Loss: 0.1616342 Vali Loss: 0.3155133 Test Loss: 0.3640491
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 3.0966389179229736
Epoch: 67, Steps: 60 | Train Loss: 0.1611773 Vali Loss: 0.3154017 Test Loss: 0.3640064
Validation loss decreased (0.315445 --> 0.315402).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 3.323956251144409
Epoch: 68, Steps: 60 | Train Loss: 0.1607256 Vali Loss: 0.3152468 Test Loss: 0.3639737
Validation loss decreased (0.315402 --> 0.315247).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.7007977962493896
Epoch: 69, Steps: 60 | Train Loss: 0.1606280 Vali Loss: 0.3151250 Test Loss: 0.3639493
Validation loss decreased (0.315247 --> 0.315125).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.6683404445648193
Epoch: 70, Steps: 60 | Train Loss: 0.1606964 Vali Loss: 0.3149997 Test Loss: 0.3639066
Validation loss decreased (0.315125 --> 0.315000).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.669099807739258
Epoch: 71, Steps: 60 | Train Loss: 0.1607902 Vali Loss: 0.3150519 Test Loss: 0.3638659
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 3.1009857654571533
Epoch: 72, Steps: 60 | Train Loss: 0.1601370 Vali Loss: 0.3149042 Test Loss: 0.3638530
Validation loss decreased (0.315000 --> 0.314904).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.9957268238067627
Epoch: 73, Steps: 60 | Train Loss: 0.1604217 Vali Loss: 0.3147114 Test Loss: 0.3638363
Validation loss decreased (0.314904 --> 0.314711).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.089907169342041
Epoch: 74, Steps: 60 | Train Loss: 0.1601561 Vali Loss: 0.3147542 Test Loss: 0.3638072
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.5343708992004395
Epoch: 75, Steps: 60 | Train Loss: 0.1600628 Vali Loss: 0.3146418 Test Loss: 0.3637852
Validation loss decreased (0.314711 --> 0.314642).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.522646188735962
Epoch: 76, Steps: 60 | Train Loss: 0.1601496 Vali Loss: 0.3145639 Test Loss: 0.3637560
Validation loss decreased (0.314642 --> 0.314564).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.5441830158233643
Epoch: 77, Steps: 60 | Train Loss: 0.1594910 Vali Loss: 0.3145404 Test Loss: 0.3637351
Validation loss decreased (0.314564 --> 0.314540).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 3.188223123550415
Epoch: 78, Steps: 60 | Train Loss: 0.1598615 Vali Loss: 0.3145113 Test Loss: 0.3637133
Validation loss decreased (0.314540 --> 0.314511).  Saving model ...
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.168818473815918
Epoch: 79, Steps: 60 | Train Loss: 0.1598268 Vali Loss: 0.3144391 Test Loss: 0.3636937
Validation loss decreased (0.314511 --> 0.314439).  Saving model ...
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.723602771759033
Epoch: 80, Steps: 60 | Train Loss: 0.1598301 Vali Loss: 0.3143845 Test Loss: 0.3636656
Validation loss decreased (0.314439 --> 0.314384).  Saving model ...
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.6632235050201416
Epoch: 81, Steps: 60 | Train Loss: 0.1597274 Vali Loss: 0.3142098 Test Loss: 0.3636534
Validation loss decreased (0.314384 --> 0.314210).  Saving model ...
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 3.0815634727478027
Epoch: 82, Steps: 60 | Train Loss: 0.1597160 Vali Loss: 0.3142712 Test Loss: 0.3636407
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.3755643367767334
Epoch: 83, Steps: 60 | Train Loss: 0.1595618 Vali Loss: 0.3140572 Test Loss: 0.3636295
Validation loss decreased (0.314210 --> 0.314057).  Saving model ...
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.972416877746582
Epoch: 84, Steps: 60 | Train Loss: 0.1592814 Vali Loss: 0.3142067 Test Loss: 0.3636096
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.651575803756714
Epoch: 85, Steps: 60 | Train Loss: 0.1590180 Vali Loss: 0.3141438 Test Loss: 0.3636021
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 2.8886098861694336
Epoch: 86, Steps: 60 | Train Loss: 0.1586025 Vali Loss: 0.3140687 Test Loss: 0.3635860
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 2.747641086578369
Epoch: 87, Steps: 60 | Train Loss: 0.1590127 Vali Loss: 0.3140493 Test Loss: 0.3635779
Validation loss decreased (0.314057 --> 0.314049).  Saving model ...
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 3.330131769180298
Epoch: 88, Steps: 60 | Train Loss: 0.1591142 Vali Loss: 0.3139678 Test Loss: 0.3635682
Validation loss decreased (0.314049 --> 0.313968).  Saving model ...
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.448390483856201
Epoch: 89, Steps: 60 | Train Loss: 0.1589302 Vali Loss: 0.3139537 Test Loss: 0.3635525
Validation loss decreased (0.313968 --> 0.313954).  Saving model ...
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 3.1266207695007324
Epoch: 90, Steps: 60 | Train Loss: 0.1587445 Vali Loss: 0.3139111 Test Loss: 0.3635419
Validation loss decreased (0.313954 --> 0.313911).  Saving model ...
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.5932199954986572
Epoch: 91, Steps: 60 | Train Loss: 0.1589781 Vali Loss: 0.3138303 Test Loss: 0.3635338
Validation loss decreased (0.313911 --> 0.313830).  Saving model ...
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 2.6181206703186035
Epoch: 92, Steps: 60 | Train Loss: 0.1585945 Vali Loss: 0.3139148 Test Loss: 0.3635236
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 2.284719467163086
Epoch: 93, Steps: 60 | Train Loss: 0.1584728 Vali Loss: 0.3138750 Test Loss: 0.3635193
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 2.722076177597046
Epoch: 94, Steps: 60 | Train Loss: 0.1586400 Vali Loss: 0.3138562 Test Loss: 0.3635064
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 2.1480162143707275
Epoch: 95, Steps: 60 | Train Loss: 0.1586564 Vali Loss: 0.3137587 Test Loss: 0.3634960
Validation loss decreased (0.313830 --> 0.313759).  Saving model ...
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 2.4362552165985107
Epoch: 96, Steps: 60 | Train Loss: 0.1584391 Vali Loss: 0.3138101 Test Loss: 0.3634889
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 2.440412998199463
Epoch: 97, Steps: 60 | Train Loss: 0.1587381 Vali Loss: 0.3137904 Test Loss: 0.3634834
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 2.0898330211639404
Epoch: 98, Steps: 60 | Train Loss: 0.1584087 Vali Loss: 0.3137135 Test Loss: 0.3634771
Validation loss decreased (0.313759 --> 0.313713).  Saving model ...
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 2.753136157989502
Epoch: 99, Steps: 60 | Train Loss: 0.1585109 Vali Loss: 0.3136863 Test Loss: 0.3634683
Validation loss decreased (0.313713 --> 0.313686).  Saving model ...
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 2.4342358112335205
Epoch: 100, Steps: 60 | Train Loss: 0.1585879 Vali Loss: 0.3136472 Test Loss: 0.3634642
Validation loss decreased (0.313686 --> 0.313647).  Saving model ...
Updating learning rate to 3.1160680107021042e-06
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=103, out_features=130, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  11997440.0
params:  13520.0
Trainable parameters:  13520
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.0332841873168945
Epoch: 1, Steps: 60 | Train Loss: 0.5321792 Vali Loss: 0.2963667 Test Loss: 0.3564044
Validation loss decreased (inf --> 0.296367).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.827024221420288
Epoch: 2, Steps: 60 | Train Loss: 0.5221256 Vali Loss: 0.2915389 Test Loss: 0.3549443
Validation loss decreased (0.296367 --> 0.291539).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.0199759006500244
Epoch: 3, Steps: 60 | Train Loss: 0.5190755 Vali Loss: 0.2884650 Test Loss: 0.3550423
Validation loss decreased (0.291539 --> 0.288465).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.1655454635620117
Epoch: 4, Steps: 60 | Train Loss: 0.5185546 Vali Loss: 0.2875679 Test Loss: 0.3549100
Validation loss decreased (0.288465 --> 0.287568).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.3785195350646973
Epoch: 5, Steps: 60 | Train Loss: 0.5167044 Vali Loss: 0.2864891 Test Loss: 0.3546962
Validation loss decreased (0.287568 --> 0.286489).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.33097767829895
Epoch: 6, Steps: 60 | Train Loss: 0.5162130 Vali Loss: 0.2856657 Test Loss: 0.3546446
Validation loss decreased (0.286489 --> 0.285666).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.3399288654327393
Epoch: 7, Steps: 60 | Train Loss: 0.5157384 Vali Loss: 0.2854024 Test Loss: 0.3544635
Validation loss decreased (0.285666 --> 0.285402).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.015146017074585
Epoch: 8, Steps: 60 | Train Loss: 0.5152288 Vali Loss: 0.2848604 Test Loss: 0.3540514
Validation loss decreased (0.285402 --> 0.284860).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.3424630165100098
Epoch: 9, Steps: 60 | Train Loss: 0.5155753 Vali Loss: 0.2839316 Test Loss: 0.3539926
Validation loss decreased (0.284860 --> 0.283932).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.6205379962921143
Epoch: 10, Steps: 60 | Train Loss: 0.5143852 Vali Loss: 0.2843047 Test Loss: 0.3540207
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.3839569091796875
Epoch: 11, Steps: 60 | Train Loss: 0.5118132 Vali Loss: 0.2844812 Test Loss: 0.3537640
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.118260145187378
Epoch: 12, Steps: 60 | Train Loss: 0.5137364 Vali Loss: 0.2837102 Test Loss: 0.3536164
Validation loss decreased (0.283932 --> 0.283710).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.4373559951782227
Epoch: 13, Steps: 60 | Train Loss: 0.5137752 Vali Loss: 0.2836249 Test Loss: 0.3536805
Validation loss decreased (0.283710 --> 0.283625).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.1016855239868164
Epoch: 14, Steps: 60 | Train Loss: 0.5118521 Vali Loss: 0.2833011 Test Loss: 0.3536871
Validation loss decreased (0.283625 --> 0.283301).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.701685905456543
Epoch: 15, Steps: 60 | Train Loss: 0.5109225 Vali Loss: 0.2829786 Test Loss: 0.3535539
Validation loss decreased (0.283301 --> 0.282979).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.2848727703094482
Epoch: 16, Steps: 60 | Train Loss: 0.5117550 Vali Loss: 0.2827224 Test Loss: 0.3535888
Validation loss decreased (0.282979 --> 0.282722).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.4528980255126953
Epoch: 17, Steps: 60 | Train Loss: 0.5130086 Vali Loss: 0.2829558 Test Loss: 0.3534764
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.6125941276550293
Epoch: 18, Steps: 60 | Train Loss: 0.5123570 Vali Loss: 0.2827698 Test Loss: 0.3534991
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.373974323272705
Epoch: 19, Steps: 60 | Train Loss: 0.5125270 Vali Loss: 0.2830691 Test Loss: 0.3533641
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.120328426361084
Epoch: 20, Steps: 60 | Train Loss: 0.5117105 Vali Loss: 0.2828901 Test Loss: 0.3532722
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.328838586807251
Epoch: 21, Steps: 60 | Train Loss: 0.5128795 Vali Loss: 0.2827206 Test Loss: 0.3532901
Validation loss decreased (0.282722 --> 0.282721).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.9937150478363037
Epoch: 22, Steps: 60 | Train Loss: 0.5128189 Vali Loss: 0.2826401 Test Loss: 0.3533562
Validation loss decreased (0.282721 --> 0.282640).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.9732298851013184
Epoch: 23, Steps: 60 | Train Loss: 0.5110308 Vali Loss: 0.2825100 Test Loss: 0.3533429
Validation loss decreased (0.282640 --> 0.282510).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.9723455905914307
Epoch: 24, Steps: 60 | Train Loss: 0.5117994 Vali Loss: 0.2823653 Test Loss: 0.3532671
Validation loss decreased (0.282510 --> 0.282365).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.5501835346221924
Epoch: 25, Steps: 60 | Train Loss: 0.5111620 Vali Loss: 0.2825017 Test Loss: 0.3531608
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.494802713394165
Epoch: 26, Steps: 60 | Train Loss: 0.5108015 Vali Loss: 0.2821967 Test Loss: 0.3532189
Validation loss decreased (0.282365 --> 0.282197).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.6948800086975098
Epoch: 27, Steps: 60 | Train Loss: 0.5116587 Vali Loss: 0.2820343 Test Loss: 0.3531195
Validation loss decreased (0.282197 --> 0.282034).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.3763697147369385
Epoch: 28, Steps: 60 | Train Loss: 0.5115408 Vali Loss: 0.2823513 Test Loss: 0.3531655
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.6179769039154053
Epoch: 29, Steps: 60 | Train Loss: 0.5114024 Vali Loss: 0.2820080 Test Loss: 0.3531102
Validation loss decreased (0.282034 --> 0.282008).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.3370461463928223
Epoch: 30, Steps: 60 | Train Loss: 0.5106309 Vali Loss: 0.2822571 Test Loss: 0.3530533
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.5755062103271484
Epoch: 31, Steps: 60 | Train Loss: 0.5106854 Vali Loss: 0.2822461 Test Loss: 0.3531872
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.702965021133423
Epoch: 32, Steps: 60 | Train Loss: 0.5107068 Vali Loss: 0.2820958 Test Loss: 0.3531362
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 3.513015031814575
Epoch: 33, Steps: 60 | Train Loss: 0.5106934 Vali Loss: 0.2819507 Test Loss: 0.3531386
Validation loss decreased (0.282008 --> 0.281951).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.502575397491455
Epoch: 34, Steps: 60 | Train Loss: 0.5094234 Vali Loss: 0.2821403 Test Loss: 0.3531346
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 3.4198524951934814
Epoch: 35, Steps: 60 | Train Loss: 0.5095568 Vali Loss: 0.2819647 Test Loss: 0.3530873
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.839092969894409
Epoch: 36, Steps: 60 | Train Loss: 0.5105229 Vali Loss: 0.2821977 Test Loss: 0.3530528
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 3.1620290279388428
Epoch: 37, Steps: 60 | Train Loss: 0.5107354 Vali Loss: 0.2821254 Test Loss: 0.3530459
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.4025051593780518
Epoch: 38, Steps: 60 | Train Loss: 0.5118128 Vali Loss: 0.2820615 Test Loss: 0.3530804
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.736666202545166
Epoch: 39, Steps: 60 | Train Loss: 0.5106353 Vali Loss: 0.2818963 Test Loss: 0.3530934
Validation loss decreased (0.281951 --> 0.281896).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.302865505218506
Epoch: 40, Steps: 60 | Train Loss: 0.5100108 Vali Loss: 0.2820334 Test Loss: 0.3530115
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.658902883529663
Epoch: 41, Steps: 60 | Train Loss: 0.5115634 Vali Loss: 0.2820522 Test Loss: 0.3529983
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.6628458499908447
Epoch: 42, Steps: 60 | Train Loss: 0.5099565 Vali Loss: 0.2820383 Test Loss: 0.3530019
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.5915563106536865
Epoch: 43, Steps: 60 | Train Loss: 0.5112024 Vali Loss: 0.2818509 Test Loss: 0.3529703
Validation loss decreased (0.281896 --> 0.281851).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.454923152923584
Epoch: 44, Steps: 60 | Train Loss: 0.5098325 Vali Loss: 0.2815705 Test Loss: 0.3529973
Validation loss decreased (0.281851 --> 0.281570).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.9344749450683594
Epoch: 45, Steps: 60 | Train Loss: 0.5092830 Vali Loss: 0.2818367 Test Loss: 0.3529848
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.163861036300659
Epoch: 46, Steps: 60 | Train Loss: 0.5116193 Vali Loss: 0.2819472 Test Loss: 0.3529829
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 3.2467572689056396
Epoch: 47, Steps: 60 | Train Loss: 0.5109991 Vali Loss: 0.2818413 Test Loss: 0.3530151
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.925389289855957
Epoch: 48, Steps: 60 | Train Loss: 0.5100428 Vali Loss: 0.2818156 Test Loss: 0.3529904
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.073486566543579
Epoch: 49, Steps: 60 | Train Loss: 0.5080320 Vali Loss: 0.2818136 Test Loss: 0.3529934
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.7259037494659424
Epoch: 50, Steps: 60 | Train Loss: 0.5100360 Vali Loss: 0.2818747 Test Loss: 0.3529868
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.8360319137573242
Epoch: 51, Steps: 60 | Train Loss: 0.5088108 Vali Loss: 0.2818126 Test Loss: 0.3529793
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 3.069690227508545
Epoch: 52, Steps: 60 | Train Loss: 0.5102651 Vali Loss: 0.2818638 Test Loss: 0.3529940
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.687452554702759
Epoch: 53, Steps: 60 | Train Loss: 0.5103398 Vali Loss: 0.2818639 Test Loss: 0.3529668
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 3.038907051086426
Epoch: 54, Steps: 60 | Train Loss: 0.5104580 Vali Loss: 0.2817079 Test Loss: 0.3529532
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.82016658782959
Epoch: 55, Steps: 60 | Train Loss: 0.5103301 Vali Loss: 0.2818225 Test Loss: 0.3529845
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.9749889373779297
Epoch: 56, Steps: 60 | Train Loss: 0.5103954 Vali Loss: 0.2818483 Test Loss: 0.3529603
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 3.1467998027801514
Epoch: 57, Steps: 60 | Train Loss: 0.5100358 Vali Loss: 0.2818474 Test Loss: 0.3529758
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 3.126938581466675
Epoch: 58, Steps: 60 | Train Loss: 0.5106441 Vali Loss: 0.2818003 Test Loss: 0.3529662
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.0357227325439453
Epoch: 59, Steps: 60 | Train Loss: 0.5085180 Vali Loss: 0.2817563 Test Loss: 0.3529969
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.491665840148926
Epoch: 60, Steps: 60 | Train Loss: 0.5108315 Vali Loss: 0.2817112 Test Loss: 0.3529853
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.3625690937042236
Epoch: 61, Steps: 60 | Train Loss: 0.5107256 Vali Loss: 0.2817951 Test Loss: 0.3529595
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 3.197667360305786
Epoch: 62, Steps: 60 | Train Loss: 0.5108430 Vali Loss: 0.2817898 Test Loss: 0.3529513
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 3.142810821533203
Epoch: 63, Steps: 60 | Train Loss: 0.5103776 Vali Loss: 0.2817964 Test Loss: 0.3529554
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 3.0158417224884033
Epoch: 64, Steps: 60 | Train Loss: 0.5100134 Vali Loss: 0.2817174 Test Loss: 0.3529532
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.3337581157684326, mae:0.3756585717201233, rse:0.463294118642807, corr:[0.26528537 0.2671559  0.26725945 0.26618794 0.26514456 0.2647333
 0.26474258 0.26440546 0.263511   0.26199645 0.26036352 0.2588316
 0.25775194 0.25721738 0.25684547 0.25639752 0.25563568 0.25470704
 0.25369984 0.2527698  0.25184056 0.2506201  0.24900682 0.2469399
 0.24482593 0.24296442 0.2416225  0.24058011 0.23952778 0.23823291
 0.23673889 0.23498559 0.23328257 0.23195268 0.23103078 0.23014034
 0.2291337  0.22813144 0.22735658 0.22662896 0.22595136 0.22519667
 0.22424139 0.22312002 0.22196914 0.22074297 0.21943773 0.21783571
 0.21598062 0.21421292 0.21275707 0.21121366 0.20962463 0.20790239
 0.20572832 0.20354299 0.2017072  0.20014104 0.19889955 0.19792204
 0.19732934 0.19681749 0.19650827 0.19638579 0.19592708 0.19537035
 0.19464311 0.193878   0.1932619  0.19281967 0.19226152 0.19150102
 0.19038202 0.189055   0.18776171 0.18646489 0.18566059 0.18527804
 0.18498413 0.18424363 0.18359259 0.18294887 0.18236224 0.18199718
 0.18191883 0.18203017 0.18188776 0.18137847 0.18046385 0.1796998
 0.17933664 0.17913546 0.17923403 0.17918758 0.17874387 0.1779182
 0.17682493 0.17577444 0.17495866 0.17420647 0.17332196 0.17214252
 0.1710722  0.17018281 0.16986237 0.16993162 0.170037   0.17004253
 0.16931865 0.1681815  0.16694875 0.16624933 0.16581878 0.1656773
 0.16542871 0.16479482 0.16395666 0.16273943 0.16143052 0.15992936
 0.15850243 0.15702353 0.15577565 0.15474813 0.1536771  0.15261136
 0.15177642 0.15092461 0.15005384 0.14910917 0.14834996 0.14761566
 0.14706141 0.1465497  0.14599428 0.1454812  0.1449195  0.14445463
 0.14412367 0.14383428 0.14351621 0.14285377 0.14182073 0.14042455
 0.13870977 0.13719891 0.13606328 0.13515314 0.13423239 0.13320887
 0.13232042 0.13122164 0.1305441  0.13027191 0.13008527 0.12953655
 0.12908906 0.12897682 0.12921163 0.12978278 0.12994094 0.12986316
 0.12961365 0.12927975 0.12902184 0.12876359 0.1286789  0.12832212
 0.1276937  0.12654649 0.12533644 0.12403122 0.12313527 0.12226082
 0.1214534  0.12008096 0.11827024 0.11677361 0.11561991 0.11563158
 0.11645856 0.11740968 0.11791243 0.11760722 0.11636247 0.11573592
 0.11665502 0.11807548 0.11889497 0.1175997  0.11577969 0.11734153]
