Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=34, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_180_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_180_96_FITS_ETTh2_ftM_sl180_ll48_pl96_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8365
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=34, out_features=52, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1584128.0
params:  1820.0
Trainable parameters:  1820
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.4827594757080078
Epoch: 1, Steps: 65 | Train Loss: 0.4687687 Vali Loss: 0.3115143 Test Loss: 0.4221886
Validation loss decreased (inf --> 0.311514).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.994098424911499
Epoch: 2, Steps: 65 | Train Loss: 0.3820302 Vali Loss: 0.2811306 Test Loss: 0.3815174
Validation loss decreased (0.311514 --> 0.281131).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.79378342628479
Epoch: 3, Steps: 65 | Train Loss: 0.3303266 Vali Loss: 0.2612770 Test Loss: 0.3573502
Validation loss decreased (0.281131 --> 0.261277).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.5545241832733154
Epoch: 4, Steps: 65 | Train Loss: 0.2955442 Vali Loss: 0.2515671 Test Loss: 0.3421636
Validation loss decreased (0.261277 --> 0.251567).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.6226751804351807
Epoch: 5, Steps: 65 | Train Loss: 0.2707637 Vali Loss: 0.2460374 Test Loss: 0.3322048
Validation loss decreased (0.251567 --> 0.246037).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.5473265647888184
Epoch: 6, Steps: 65 | Train Loss: 0.2520219 Vali Loss: 0.2406839 Test Loss: 0.3253731
Validation loss decreased (0.246037 --> 0.240684).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.9420945644378662
Epoch: 7, Steps: 65 | Train Loss: 0.2389862 Vali Loss: 0.2367765 Test Loss: 0.3204790
Validation loss decreased (0.240684 --> 0.236776).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.2420878410339355
Epoch: 8, Steps: 65 | Train Loss: 0.2288702 Vali Loss: 0.2336581 Test Loss: 0.3167520
Validation loss decreased (0.236776 --> 0.233658).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.7588067054748535
Epoch: 9, Steps: 65 | Train Loss: 0.2201876 Vali Loss: 0.2320383 Test Loss: 0.3137988
Validation loss decreased (0.233658 --> 0.232038).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.816112995147705
Epoch: 10, Steps: 65 | Train Loss: 0.2131881 Vali Loss: 0.2287235 Test Loss: 0.3115137
Validation loss decreased (0.232038 --> 0.228723).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.7684993743896484
Epoch: 11, Steps: 65 | Train Loss: 0.2078528 Vali Loss: 0.2291476 Test Loss: 0.3095919
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.8876731395721436
Epoch: 12, Steps: 65 | Train Loss: 0.2035024 Vali Loss: 0.2273450 Test Loss: 0.3079661
Validation loss decreased (0.228723 --> 0.227345).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.8976428508758545
Epoch: 13, Steps: 65 | Train Loss: 0.1994358 Vali Loss: 0.2257680 Test Loss: 0.3065462
Validation loss decreased (0.227345 --> 0.225768).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.6603336334228516
Epoch: 14, Steps: 65 | Train Loss: 0.1957285 Vali Loss: 0.2250068 Test Loss: 0.3053101
Validation loss decreased (0.225768 --> 0.225007).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.3723032474517822
Epoch: 15, Steps: 65 | Train Loss: 0.1925864 Vali Loss: 0.2247117 Test Loss: 0.3041975
Validation loss decreased (0.225007 --> 0.224712).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.641658067703247
Epoch: 16, Steps: 65 | Train Loss: 0.1903309 Vali Loss: 0.2232909 Test Loss: 0.3032594
Validation loss decreased (0.224712 --> 0.223291).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.68977952003479
Epoch: 17, Steps: 65 | Train Loss: 0.1879523 Vali Loss: 0.2222267 Test Loss: 0.3024714
Validation loss decreased (0.223291 --> 0.222227).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.4051852226257324
Epoch: 18, Steps: 65 | Train Loss: 0.1856209 Vali Loss: 0.2222755 Test Loss: 0.3017067
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.677215814590454
Epoch: 19, Steps: 65 | Train Loss: 0.1841881 Vali Loss: 0.2215652 Test Loss: 0.3010093
Validation loss decreased (0.222227 --> 0.221565).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.8696675300598145
Epoch: 20, Steps: 65 | Train Loss: 0.1825495 Vali Loss: 0.2201080 Test Loss: 0.3003849
Validation loss decreased (0.221565 --> 0.220108).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.9731194972991943
Epoch: 21, Steps: 65 | Train Loss: 0.1812326 Vali Loss: 0.2201947 Test Loss: 0.2998196
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.0389323234558105
Epoch: 22, Steps: 65 | Train Loss: 0.1798001 Vali Loss: 0.2205723 Test Loss: 0.2993197
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.5429456233978271
Epoch: 23, Steps: 65 | Train Loss: 0.1783918 Vali Loss: 0.2185688 Test Loss: 0.2988076
Validation loss decreased (0.220108 --> 0.218569).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.3751251697540283
Epoch: 24, Steps: 65 | Train Loss: 0.1766822 Vali Loss: 0.2184162 Test Loss: 0.2984054
Validation loss decreased (0.218569 --> 0.218416).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.5000348091125488
Epoch: 25, Steps: 65 | Train Loss: 0.1769581 Vali Loss: 0.2187938 Test Loss: 0.2979993
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.593280553817749
Epoch: 26, Steps: 65 | Train Loss: 0.1756920 Vali Loss: 0.2179619 Test Loss: 0.2976724
Validation loss decreased (0.218416 --> 0.217962).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.1770520210266113
Epoch: 27, Steps: 65 | Train Loss: 0.1752038 Vali Loss: 0.2195568 Test Loss: 0.2973103
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.9719626903533936
Epoch: 28, Steps: 65 | Train Loss: 0.1739983 Vali Loss: 0.2181030 Test Loss: 0.2970090
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.7011892795562744
Epoch: 29, Steps: 65 | Train Loss: 0.1737093 Vali Loss: 0.2182552 Test Loss: 0.2967463
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.299318552017212
Epoch: 30, Steps: 65 | Train Loss: 0.1732553 Vali Loss: 0.2168177 Test Loss: 0.2964754
Validation loss decreased (0.217962 --> 0.216818).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.5835952758789062
Epoch: 31, Steps: 65 | Train Loss: 0.1726119 Vali Loss: 0.2154609 Test Loss: 0.2962403
Validation loss decreased (0.216818 --> 0.215461).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.9435324668884277
Epoch: 32, Steps: 65 | Train Loss: 0.1720042 Vali Loss: 0.2185780 Test Loss: 0.2960459
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.615769863128662
Epoch: 33, Steps: 65 | Train Loss: 0.1713935 Vali Loss: 0.2181960 Test Loss: 0.2958332
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.6128416061401367
Epoch: 34, Steps: 65 | Train Loss: 0.1711636 Vali Loss: 0.2170841 Test Loss: 0.2956512
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.141404390335083
Epoch: 35, Steps: 65 | Train Loss: 0.1709467 Vali Loss: 0.2155653 Test Loss: 0.2954680
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.2461981773376465
Epoch: 36, Steps: 65 | Train Loss: 0.1700495 Vali Loss: 0.2164298 Test Loss: 0.2953366
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.5924465656280518
Epoch: 37, Steps: 65 | Train Loss: 0.1702623 Vali Loss: 0.2159217 Test Loss: 0.2951704
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.72432541847229
Epoch: 38, Steps: 65 | Train Loss: 0.1697644 Vali Loss: 0.2154689 Test Loss: 0.2950303
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.485301971435547
Epoch: 39, Steps: 65 | Train Loss: 0.1693579 Vali Loss: 0.2152379 Test Loss: 0.2949063
Validation loss decreased (0.215461 --> 0.215238).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.6805577278137207
Epoch: 40, Steps: 65 | Train Loss: 0.1692675 Vali Loss: 0.2157470 Test Loss: 0.2947834
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.1710572242736816
Epoch: 41, Steps: 65 | Train Loss: 0.1690420 Vali Loss: 0.2162303 Test Loss: 0.2946828
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.262777805328369
Epoch: 42, Steps: 65 | Train Loss: 0.1687531 Vali Loss: 0.2155214 Test Loss: 0.2945500
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.9184558391571045
Epoch: 43, Steps: 65 | Train Loss: 0.1687507 Vali Loss: 0.2152140 Test Loss: 0.2944856
Validation loss decreased (0.215238 --> 0.215214).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.301297903060913
Epoch: 44, Steps: 65 | Train Loss: 0.1678843 Vali Loss: 0.2151038 Test Loss: 0.2943883
Validation loss decreased (0.215214 --> 0.215104).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.1483137607574463
Epoch: 45, Steps: 65 | Train Loss: 0.1682774 Vali Loss: 0.2156216 Test Loss: 0.2942939
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.0433061122894287
Epoch: 46, Steps: 65 | Train Loss: 0.1674341 Vali Loss: 0.2162210 Test Loss: 0.2942093
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.9151017665863037
Epoch: 47, Steps: 65 | Train Loss: 0.1679896 Vali Loss: 0.2145204 Test Loss: 0.2941385
Validation loss decreased (0.215104 --> 0.214520).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.4340934753417969
Epoch: 48, Steps: 65 | Train Loss: 0.1676893 Vali Loss: 0.2147873 Test Loss: 0.2940683
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.6299936771392822
Epoch: 49, Steps: 65 | Train Loss: 0.1675072 Vali Loss: 0.2148484 Test Loss: 0.2940011
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.6616573333740234
Epoch: 50, Steps: 65 | Train Loss: 0.1675583 Vali Loss: 0.2152062 Test Loss: 0.2939462
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.6133298873901367
Epoch: 51, Steps: 65 | Train Loss: 0.1672876 Vali Loss: 0.2146576 Test Loss: 0.2938833
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.3831639289855957
Epoch: 52, Steps: 65 | Train Loss: 0.1671743 Vali Loss: 0.2152134 Test Loss: 0.2938216
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.8597157001495361
Epoch: 53, Steps: 65 | Train Loss: 0.1671811 Vali Loss: 0.2143022 Test Loss: 0.2937738
Validation loss decreased (0.214520 --> 0.214302).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.6656062602996826
Epoch: 54, Steps: 65 | Train Loss: 0.1664825 Vali Loss: 0.2135091 Test Loss: 0.2937209
Validation loss decreased (0.214302 --> 0.213509).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.501504898071289
Epoch: 55, Steps: 65 | Train Loss: 0.1663713 Vali Loss: 0.2155102 Test Loss: 0.2936794
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.7119712829589844
Epoch: 56, Steps: 65 | Train Loss: 0.1668271 Vali Loss: 0.2146960 Test Loss: 0.2936296
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.741950273513794
Epoch: 57, Steps: 65 | Train Loss: 0.1666357 Vali Loss: 0.2144461 Test Loss: 0.2935916
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.7619810104370117
Epoch: 58, Steps: 65 | Train Loss: 0.1660212 Vali Loss: 0.2139722 Test Loss: 0.2935508
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.8888709545135498
Epoch: 59, Steps: 65 | Train Loss: 0.1665160 Vali Loss: 0.2147503 Test Loss: 0.2935111
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.550570011138916
Epoch: 60, Steps: 65 | Train Loss: 0.1658415 Vali Loss: 0.2146138 Test Loss: 0.2934819
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.8755388259887695
Epoch: 61, Steps: 65 | Train Loss: 0.1664562 Vali Loss: 0.2149678 Test Loss: 0.2934429
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.8245933055877686
Epoch: 62, Steps: 65 | Train Loss: 0.1657317 Vali Loss: 0.2141747 Test Loss: 0.2934096
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.5121054649353027
Epoch: 63, Steps: 65 | Train Loss: 0.1653943 Vali Loss: 0.2139239 Test Loss: 0.2933851
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.9706873893737793
Epoch: 64, Steps: 65 | Train Loss: 0.1660683 Vali Loss: 0.2144192 Test Loss: 0.2933616
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.6794772148132324
Epoch: 65, Steps: 65 | Train Loss: 0.1658800 Vali Loss: 0.2140779 Test Loss: 0.2933359
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.8632583618164062
Epoch: 66, Steps: 65 | Train Loss: 0.1657210 Vali Loss: 0.2140862 Test Loss: 0.2933074
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.9835526943206787
Epoch: 67, Steps: 65 | Train Loss: 0.1659028 Vali Loss: 0.2135455 Test Loss: 0.2932865
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.4971940517425537
Epoch: 68, Steps: 65 | Train Loss: 0.1658729 Vali Loss: 0.2130007 Test Loss: 0.2932639
Validation loss decreased (0.213509 --> 0.213001).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.8357958793640137
Epoch: 69, Steps: 65 | Train Loss: 0.1651645 Vali Loss: 0.2133950 Test Loss: 0.2932406
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.8572096824645996
Epoch: 70, Steps: 65 | Train Loss: 0.1657900 Vali Loss: 0.2142810 Test Loss: 0.2932241
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.413517713546753
Epoch: 71, Steps: 65 | Train Loss: 0.1655863 Vali Loss: 0.2144728 Test Loss: 0.2932060
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.5439505577087402
Epoch: 72, Steps: 65 | Train Loss: 0.1653605 Vali Loss: 0.2135548 Test Loss: 0.2931882
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.890380620956421
Epoch: 73, Steps: 65 | Train Loss: 0.1651326 Vali Loss: 0.2145332 Test Loss: 0.2931733
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.3336920738220215
Epoch: 74, Steps: 65 | Train Loss: 0.1652062 Vali Loss: 0.2140231 Test Loss: 0.2931587
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.788424015045166
Epoch: 75, Steps: 65 | Train Loss: 0.1653768 Vali Loss: 0.2135809 Test Loss: 0.2931404
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.0495171546936035
Epoch: 76, Steps: 65 | Train Loss: 0.1653572 Vali Loss: 0.2138898 Test Loss: 0.2931300
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.4581985473632812
Epoch: 77, Steps: 65 | Train Loss: 0.1649197 Vali Loss: 0.2140289 Test Loss: 0.2931136
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.9131770133972168
Epoch: 78, Steps: 65 | Train Loss: 0.1652190 Vali Loss: 0.2142059 Test Loss: 0.2930969
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.5735430717468262
Epoch: 79, Steps: 65 | Train Loss: 0.1654268 Vali Loss: 0.2131718 Test Loss: 0.2930897
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.588965654373169
Epoch: 80, Steps: 65 | Train Loss: 0.1653202 Vali Loss: 0.2132090 Test Loss: 0.2930766
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.5958056449890137
Epoch: 81, Steps: 65 | Train Loss: 0.1649279 Vali Loss: 0.2140248 Test Loss: 0.2930642
EarlyStopping counter: 13 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.5135679244995117
Epoch: 82, Steps: 65 | Train Loss: 0.1652819 Vali Loss: 0.2131714 Test Loss: 0.2930528
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.5451874732971191
Epoch: 83, Steps: 65 | Train Loss: 0.1652913 Vali Loss: 0.2143478 Test Loss: 0.2930419
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.3494377136230469
Epoch: 84, Steps: 65 | Train Loss: 0.1645512 Vali Loss: 0.2132916 Test Loss: 0.2930316
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.4154956340789795
Epoch: 85, Steps: 65 | Train Loss: 0.1644534 Vali Loss: 0.2133760 Test Loss: 0.2930258
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.5413615703582764
Epoch: 86, Steps: 65 | Train Loss: 0.1650105 Vali Loss: 0.2135879 Test Loss: 0.2930184
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.8822674751281738
Epoch: 87, Steps: 65 | Train Loss: 0.1647152 Vali Loss: 0.2132029 Test Loss: 0.2930088
EarlyStopping counter: 19 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.7063438892364502
Epoch: 88, Steps: 65 | Train Loss: 0.1651854 Vali Loss: 0.2130344 Test Loss: 0.2930004
EarlyStopping counter: 20 out of 20
Early stopping
train 8365
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=34, out_features=52, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1584128.0
params:  1820.0
Trainable parameters:  1820
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.929663896560669
Epoch: 1, Steps: 65 | Train Loss: 0.4132949 Vali Loss: 0.2104262 Test Loss: 0.2903168
Validation loss decreased (inf --> 0.210426).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.071779727935791
Epoch: 2, Steps: 65 | Train Loss: 0.4108249 Vali Loss: 0.2100799 Test Loss: 0.2894389
Validation loss decreased (0.210426 --> 0.210080).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.7175912857055664
Epoch: 3, Steps: 65 | Train Loss: 0.4093542 Vali Loss: 0.2087306 Test Loss: 0.2889607
Validation loss decreased (0.210080 --> 0.208731).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.6574714183807373
Epoch: 4, Steps: 65 | Train Loss: 0.4070703 Vali Loss: 0.2088142 Test Loss: 0.2884012
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.4574904441833496
Epoch: 5, Steps: 65 | Train Loss: 0.4076297 Vali Loss: 0.2090032 Test Loss: 0.2883667
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.586242437362671
Epoch: 6, Steps: 65 | Train Loss: 0.4076559 Vali Loss: 0.2083062 Test Loss: 0.2880992
Validation loss decreased (0.208731 --> 0.208306).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.4955594539642334
Epoch: 7, Steps: 65 | Train Loss: 0.4043489 Vali Loss: 0.2069188 Test Loss: 0.2878577
Validation loss decreased (0.208306 --> 0.206919).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.7222871780395508
Epoch: 8, Steps: 65 | Train Loss: 0.4070205 Vali Loss: 0.2066313 Test Loss: 0.2876877
Validation loss decreased (0.206919 --> 0.206631).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.6327240467071533
Epoch: 9, Steps: 65 | Train Loss: 0.4062654 Vali Loss: 0.2073347 Test Loss: 0.2874581
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.6640136241912842
Epoch: 10, Steps: 65 | Train Loss: 0.4066288 Vali Loss: 0.2057468 Test Loss: 0.2874147
Validation loss decreased (0.206631 --> 0.205747).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.6481003761291504
Epoch: 11, Steps: 65 | Train Loss: 0.4063953 Vali Loss: 0.2078556 Test Loss: 0.2873283
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.5878291130065918
Epoch: 12, Steps: 65 | Train Loss: 0.4047200 Vali Loss: 0.2074226 Test Loss: 0.2872055
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.9893798828125
Epoch: 13, Steps: 65 | Train Loss: 0.4052772 Vali Loss: 0.2079775 Test Loss: 0.2872656
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.9351649284362793
Epoch: 14, Steps: 65 | Train Loss: 0.4047144 Vali Loss: 0.2069049 Test Loss: 0.2871657
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.152527093887329
Epoch: 15, Steps: 65 | Train Loss: 0.4054396 Vali Loss: 0.2066666 Test Loss: 0.2871620
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.811361312866211
Epoch: 16, Steps: 65 | Train Loss: 0.4041841 Vali Loss: 0.2069345 Test Loss: 0.2871647
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.7120707035064697
Epoch: 17, Steps: 65 | Train Loss: 0.4036548 Vali Loss: 0.2071661 Test Loss: 0.2870294
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.51069974899292
Epoch: 18, Steps: 65 | Train Loss: 0.4042611 Vali Loss: 0.2072038 Test Loss: 0.2869174
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.5575659275054932
Epoch: 19, Steps: 65 | Train Loss: 0.4031863 Vali Loss: 0.2069140 Test Loss: 0.2869350
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.32379150390625
Epoch: 20, Steps: 65 | Train Loss: 0.4032451 Vali Loss: 0.2072821 Test Loss: 0.2869182
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.6755666732788086
Epoch: 21, Steps: 65 | Train Loss: 0.4046768 Vali Loss: 0.2078168 Test Loss: 0.2868499
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.7571451663970947
Epoch: 22, Steps: 65 | Train Loss: 0.4042012 Vali Loss: 0.2083822 Test Loss: 0.2868891
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.7240424156188965
Epoch: 23, Steps: 65 | Train Loss: 0.4045942 Vali Loss: 0.2066666 Test Loss: 0.2867967
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.512681245803833
Epoch: 24, Steps: 65 | Train Loss: 0.4045093 Vali Loss: 0.2061652 Test Loss: 0.2868308
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.6898624897003174
Epoch: 25, Steps: 65 | Train Loss: 0.4037258 Vali Loss: 0.2073772 Test Loss: 0.2867836
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.9618961811065674
Epoch: 26, Steps: 65 | Train Loss: 0.4046173 Vali Loss: 0.2069202 Test Loss: 0.2867921
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.9321095943450928
Epoch: 27, Steps: 65 | Train Loss: 0.4030234 Vali Loss: 0.2069996 Test Loss: 0.2867403
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.6157770156860352
Epoch: 28, Steps: 65 | Train Loss: 0.4027969 Vali Loss: 0.2072904 Test Loss: 0.2867174
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.0129427909851074
Epoch: 29, Steps: 65 | Train Loss: 0.4046851 Vali Loss: 0.2068078 Test Loss: 0.2867173
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.6175918579101562
Epoch: 30, Steps: 65 | Train Loss: 0.4038924 Vali Loss: 0.2064690 Test Loss: 0.2866862
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_180_96_FITS_ETTh2_ftM_sl180_ll48_pl96_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.2871714234352112, mae:0.34054258465766907, rse:0.43186888098716736, corr:[0.2766361  0.27842835 0.27762982 0.27570695 0.2743041  0.27337423
 0.27244067 0.27131256 0.2703104  0.26910827 0.26766062 0.2658097
 0.26432055 0.2631615  0.2622769  0.2614872  0.26087904 0.26034847
 0.25956172 0.25849593 0.25722516 0.25587466 0.25445133 0.25259185
 0.24992006 0.24718674 0.24484003 0.24350965 0.24259222 0.24144998
 0.239573   0.2371639  0.23494579 0.23347598 0.23245512 0.23106723
 0.22928606 0.2274741  0.22670941 0.22628152 0.22582838 0.22489986
 0.22382694 0.22297738 0.22259443 0.22190137 0.22023228 0.21776526
 0.2146429  0.21210659 0.20999937 0.20826824 0.20668313 0.20545144
 0.20397419 0.20199464 0.19993241 0.19801418 0.19694467 0.19639035
 0.1961972  0.19529924 0.19472986 0.1944832  0.19459896 0.1943869
 0.1934049  0.19197041 0.19142665 0.19187708 0.19171956 0.19030386
 0.1873146  0.18487318 0.18393911 0.1839296  0.18334487 0.18217409
 0.1807634  0.18006413 0.18083592 0.1816151  0.18167573 0.18111353
 0.18125686 0.18188246 0.18274191 0.18254758 0.18176639 0.18136373
 0.18193553 0.18200092 0.18144071 0.18099591 0.18132274 0.18181698]
