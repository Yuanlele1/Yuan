Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=103, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=103, out_features=130, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  11997440.0
params:  13520.0
Trainable parameters:  13520
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.700064182281494
Epoch: 1, Steps: 60 | Train Loss: 0.7395552 Vali Loss: 0.4032527 Test Loss: 0.3944706
Validation loss decreased (inf --> 0.403253).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.5614898204803467
Epoch: 2, Steps: 60 | Train Loss: 0.6041244 Vali Loss: 0.3503552 Test Loss: 0.3717638
Validation loss decreased (0.403253 --> 0.350355).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.736459493637085
Epoch: 3, Steps: 60 | Train Loss: 0.5704803 Vali Loss: 0.3303297 Test Loss: 0.3652197
Validation loss decreased (0.350355 --> 0.330330).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.3231213092803955
Epoch: 4, Steps: 60 | Train Loss: 0.5566657 Vali Loss: 0.3205085 Test Loss: 0.3622902
Validation loss decreased (0.330330 --> 0.320509).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.7210395336151123
Epoch: 5, Steps: 60 | Train Loss: 0.5489020 Vali Loss: 0.3141220 Test Loss: 0.3609830
Validation loss decreased (0.320509 --> 0.314122).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.732180595397949
Epoch: 6, Steps: 60 | Train Loss: 0.5434439 Vali Loss: 0.3097409 Test Loss: 0.3600093
Validation loss decreased (0.314122 --> 0.309741).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.5582804679870605
Epoch: 7, Steps: 60 | Train Loss: 0.5362913 Vali Loss: 0.3061872 Test Loss: 0.3593389
Validation loss decreased (0.309741 --> 0.306187).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.79217267036438
Epoch: 8, Steps: 60 | Train Loss: 0.5332957 Vali Loss: 0.3036182 Test Loss: 0.3587885
Validation loss decreased (0.306187 --> 0.303618).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.29386830329895
Epoch: 9, Steps: 60 | Train Loss: 0.5324627 Vali Loss: 0.3016348 Test Loss: 0.3582723
Validation loss decreased (0.303618 --> 0.301635).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.9725542068481445
Epoch: 10, Steps: 60 | Train Loss: 0.5309926 Vali Loss: 0.3000281 Test Loss: 0.3578293
Validation loss decreased (0.301635 --> 0.300028).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.4228670597076416
Epoch: 11, Steps: 60 | Train Loss: 0.5277908 Vali Loss: 0.2983343 Test Loss: 0.3573475
Validation loss decreased (0.300028 --> 0.298334).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.9957141876220703
Epoch: 12, Steps: 60 | Train Loss: 0.5264632 Vali Loss: 0.2967947 Test Loss: 0.3571906
Validation loss decreased (0.298334 --> 0.296795).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.6726746559143066
Epoch: 13, Steps: 60 | Train Loss: 0.5257496 Vali Loss: 0.2962093 Test Loss: 0.3568213
Validation loss decreased (0.296795 --> 0.296209).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.5779898166656494
Epoch: 14, Steps: 60 | Train Loss: 0.5229072 Vali Loss: 0.2950026 Test Loss: 0.3565200
Validation loss decreased (0.296209 --> 0.295003).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.6789400577545166
Epoch: 15, Steps: 60 | Train Loss: 0.5230522 Vali Loss: 0.2943472 Test Loss: 0.3563446
Validation loss decreased (0.295003 --> 0.294347).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.359541654586792
Epoch: 16, Steps: 60 | Train Loss: 0.5222421 Vali Loss: 0.2934613 Test Loss: 0.3561798
Validation loss decreased (0.294347 --> 0.293461).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.8952736854553223
Epoch: 17, Steps: 60 | Train Loss: 0.5221335 Vali Loss: 0.2930049 Test Loss: 0.3561068
Validation loss decreased (0.293461 --> 0.293005).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.193516492843628
Epoch: 18, Steps: 60 | Train Loss: 0.5204933 Vali Loss: 0.2924381 Test Loss: 0.3557708
Validation loss decreased (0.293005 --> 0.292438).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.9087986946105957
Epoch: 19, Steps: 60 | Train Loss: 0.5206163 Vali Loss: 0.2919371 Test Loss: 0.3558784
Validation loss decreased (0.292438 --> 0.291937).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.967768907546997
Epoch: 20, Steps: 60 | Train Loss: 0.5210328 Vali Loss: 0.2914239 Test Loss: 0.3556602
Validation loss decreased (0.291937 --> 0.291424).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.4399595260620117
Epoch: 21, Steps: 60 | Train Loss: 0.5202176 Vali Loss: 0.2910883 Test Loss: 0.3555924
Validation loss decreased (0.291424 --> 0.291088).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.2928309440612793
Epoch: 22, Steps: 60 | Train Loss: 0.5196813 Vali Loss: 0.2906044 Test Loss: 0.3554530
Validation loss decreased (0.291088 --> 0.290604).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.94588303565979
Epoch: 23, Steps: 60 | Train Loss: 0.5186674 Vali Loss: 0.2902809 Test Loss: 0.3553418
Validation loss decreased (0.290604 --> 0.290281).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.52435302734375
Epoch: 24, Steps: 60 | Train Loss: 0.5189664 Vali Loss: 0.2900401 Test Loss: 0.3553305
Validation loss decreased (0.290281 --> 0.290040).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 3.053156852722168
Epoch: 25, Steps: 60 | Train Loss: 0.5185388 Vali Loss: 0.2897812 Test Loss: 0.3551352
Validation loss decreased (0.290040 --> 0.289781).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.997131824493408
Epoch: 26, Steps: 60 | Train Loss: 0.5176595 Vali Loss: 0.2893439 Test Loss: 0.3551888
Validation loss decreased (0.289781 --> 0.289344).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.9561216831207275
Epoch: 27, Steps: 60 | Train Loss: 0.5176540 Vali Loss: 0.2893632 Test Loss: 0.3550341
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.5618646144866943
Epoch: 28, Steps: 60 | Train Loss: 0.5177181 Vali Loss: 0.2890138 Test Loss: 0.3549465
Validation loss decreased (0.289344 --> 0.289014).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 3.421537399291992
Epoch: 29, Steps: 60 | Train Loss: 0.5167631 Vali Loss: 0.2887767 Test Loss: 0.3549538
Validation loss decreased (0.289014 --> 0.288777).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.7258546352386475
Epoch: 30, Steps: 60 | Train Loss: 0.5154969 Vali Loss: 0.2886156 Test Loss: 0.3549347
Validation loss decreased (0.288777 --> 0.288616).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 3.2273201942443848
Epoch: 31, Steps: 60 | Train Loss: 0.5170458 Vali Loss: 0.2885523 Test Loss: 0.3547916
Validation loss decreased (0.288616 --> 0.288552).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.678280830383301
Epoch: 32, Steps: 60 | Train Loss: 0.5163389 Vali Loss: 0.2882280 Test Loss: 0.3548417
Validation loss decreased (0.288552 --> 0.288228).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.5873239040374756
Epoch: 33, Steps: 60 | Train Loss: 0.5175603 Vali Loss: 0.2881417 Test Loss: 0.3547938
Validation loss decreased (0.288228 --> 0.288142).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.452110767364502
Epoch: 34, Steps: 60 | Train Loss: 0.5156198 Vali Loss: 0.2881386 Test Loss: 0.3547137
Validation loss decreased (0.288142 --> 0.288139).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 3.5632851123809814
Epoch: 35, Steps: 60 | Train Loss: 0.5176014 Vali Loss: 0.2879083 Test Loss: 0.3547362
Validation loss decreased (0.288139 --> 0.287908).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.137087821960449
Epoch: 36, Steps: 60 | Train Loss: 0.5152483 Vali Loss: 0.2879140 Test Loss: 0.3546605
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 3.1831183433532715
Epoch: 37, Steps: 60 | Train Loss: 0.5174434 Vali Loss: 0.2876773 Test Loss: 0.3546569
Validation loss decreased (0.287908 --> 0.287677).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.235081434249878
Epoch: 38, Steps: 60 | Train Loss: 0.5170672 Vali Loss: 0.2875712 Test Loss: 0.3546185
Validation loss decreased (0.287677 --> 0.287571).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 3.317998170852661
Epoch: 39, Steps: 60 | Train Loss: 0.5149160 Vali Loss: 0.2874217 Test Loss: 0.3546329
Validation loss decreased (0.287571 --> 0.287422).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.814913511276245
Epoch: 40, Steps: 60 | Train Loss: 0.5172692 Vali Loss: 0.2871803 Test Loss: 0.3545899
Validation loss decreased (0.287422 --> 0.287180).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 3.2092034816741943
Epoch: 41, Steps: 60 | Train Loss: 0.5161985 Vali Loss: 0.2872932 Test Loss: 0.3545609
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.5005240440368652
Epoch: 42, Steps: 60 | Train Loss: 0.5146971 Vali Loss: 0.2869096 Test Loss: 0.3545452
Validation loss decreased (0.287180 --> 0.286910).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 3.024254560470581
Epoch: 43, Steps: 60 | Train Loss: 0.5159045 Vali Loss: 0.2870981 Test Loss: 0.3545164
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.568410634994507
Epoch: 44, Steps: 60 | Train Loss: 0.5154027 Vali Loss: 0.2869162 Test Loss: 0.3545181
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.0264649391174316
Epoch: 45, Steps: 60 | Train Loss: 0.5147876 Vali Loss: 0.2869310 Test Loss: 0.3544910
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.821120262145996
Epoch: 46, Steps: 60 | Train Loss: 0.5129485 Vali Loss: 0.2868761 Test Loss: 0.3545077
Validation loss decreased (0.286910 --> 0.286876).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.7657952308654785
Epoch: 47, Steps: 60 | Train Loss: 0.5146587 Vali Loss: 0.2867654 Test Loss: 0.3544782
Validation loss decreased (0.286876 --> 0.286765).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.6780858039855957
Epoch: 48, Steps: 60 | Train Loss: 0.5159723 Vali Loss: 0.2868499 Test Loss: 0.3544368
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.462982416152954
Epoch: 49, Steps: 60 | Train Loss: 0.5151087 Vali Loss: 0.2867641 Test Loss: 0.3544213
Validation loss decreased (0.286765 --> 0.286764).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.3202598094940186
Epoch: 50, Steps: 60 | Train Loss: 0.5137122 Vali Loss: 0.2863639 Test Loss: 0.3544127
Validation loss decreased (0.286764 --> 0.286364).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.6686952114105225
Epoch: 51, Steps: 60 | Train Loss: 0.5149905 Vali Loss: 0.2867192 Test Loss: 0.3544141
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.3259341716766357
Epoch: 52, Steps: 60 | Train Loss: 0.5137434 Vali Loss: 0.2866326 Test Loss: 0.3544044
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.872664451599121
Epoch: 53, Steps: 60 | Train Loss: 0.5149377 Vali Loss: 0.2865741 Test Loss: 0.3543801
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.611752986907959
Epoch: 54, Steps: 60 | Train Loss: 0.5150328 Vali Loss: 0.2865208 Test Loss: 0.3544003
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.4926979541778564
Epoch: 55, Steps: 60 | Train Loss: 0.5156658 Vali Loss: 0.2864318 Test Loss: 0.3543469
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 3.109067678451538
Epoch: 56, Steps: 60 | Train Loss: 0.5142600 Vali Loss: 0.2865138 Test Loss: 0.3543402
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.643517255783081
Epoch: 57, Steps: 60 | Train Loss: 0.5148331 Vali Loss: 0.2864640 Test Loss: 0.3543360
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.2123751640319824
Epoch: 58, Steps: 60 | Train Loss: 0.5148082 Vali Loss: 0.2863665 Test Loss: 0.3543390
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 3.3192315101623535
Epoch: 59, Steps: 60 | Train Loss: 0.5160610 Vali Loss: 0.2863214 Test Loss: 0.3543239
Validation loss decreased (0.286364 --> 0.286321).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 3.02705979347229
Epoch: 60, Steps: 60 | Train Loss: 0.5149783 Vali Loss: 0.2862846 Test Loss: 0.3543058
Validation loss decreased (0.286321 --> 0.286285).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.9661948680877686
Epoch: 61, Steps: 60 | Train Loss: 0.5138524 Vali Loss: 0.2863153 Test Loss: 0.3543033
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.3085498809814453
Epoch: 62, Steps: 60 | Train Loss: 0.5142411 Vali Loss: 0.2863245 Test Loss: 0.3543047
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.7771730422973633
Epoch: 63, Steps: 60 | Train Loss: 0.5155282 Vali Loss: 0.2862738 Test Loss: 0.3542909
Validation loss decreased (0.286285 --> 0.286274).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.5124998092651367
Epoch: 64, Steps: 60 | Train Loss: 0.5145748 Vali Loss: 0.2859364 Test Loss: 0.3542949
Validation loss decreased (0.286274 --> 0.285936).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.726651668548584
Epoch: 65, Steps: 60 | Train Loss: 0.5137354 Vali Loss: 0.2861642 Test Loss: 0.3542910
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.942903995513916
Epoch: 66, Steps: 60 | Train Loss: 0.5153380 Vali Loss: 0.2862052 Test Loss: 0.3542752
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.76465106010437
Epoch: 67, Steps: 60 | Train Loss: 0.5143782 Vali Loss: 0.2862075 Test Loss: 0.3542764
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.412506103515625
Epoch: 68, Steps: 60 | Train Loss: 0.5126208 Vali Loss: 0.2861130 Test Loss: 0.3542866
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.814197063446045
Epoch: 69, Steps: 60 | Train Loss: 0.5133480 Vali Loss: 0.2860704 Test Loss: 0.3542824
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.7994606494903564
Epoch: 70, Steps: 60 | Train Loss: 0.5138545 Vali Loss: 0.2860384 Test Loss: 0.3542639
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 3.320347309112549
Epoch: 71, Steps: 60 | Train Loss: 0.5152484 Vali Loss: 0.2861596 Test Loss: 0.3542482
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.8336164951324463
Epoch: 72, Steps: 60 | Train Loss: 0.5131113 Vali Loss: 0.2860735 Test Loss: 0.3542598
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.664916515350342
Epoch: 73, Steps: 60 | Train Loss: 0.5149145 Vali Loss: 0.2859543 Test Loss: 0.3542746
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.589555263519287
Epoch: 74, Steps: 60 | Train Loss: 0.5141608 Vali Loss: 0.2860519 Test Loss: 0.3542625
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.2609241008758545
Epoch: 75, Steps: 60 | Train Loss: 0.5144866 Vali Loss: 0.2859882 Test Loss: 0.3542588
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.7761282920837402
Epoch: 76, Steps: 60 | Train Loss: 0.5152160 Vali Loss: 0.2859804 Test Loss: 0.3542552
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.725554943084717
Epoch: 77, Steps: 60 | Train Loss: 0.5126468 Vali Loss: 0.2860116 Test Loss: 0.3542494
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.656816005706787
Epoch: 78, Steps: 60 | Train Loss: 0.5149736 Vali Loss: 0.2860277 Test Loss: 0.3542441
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.885798931121826
Epoch: 79, Steps: 60 | Train Loss: 0.5151557 Vali Loss: 0.2860179 Test Loss: 0.3542426
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 3.0482232570648193
Epoch: 80, Steps: 60 | Train Loss: 0.5155285 Vali Loss: 0.2859964 Test Loss: 0.3542344
EarlyStopping counter: 16 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 3.1355113983154297
Epoch: 81, Steps: 60 | Train Loss: 0.5155434 Vali Loss: 0.2858855 Test Loss: 0.3542339
Validation loss decreased (0.285936 --> 0.285885).  Saving model ...
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 2.3953311443328857
Epoch: 82, Steps: 60 | Train Loss: 0.5157631 Vali Loss: 0.2859643 Test Loss: 0.3542280
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.637709140777588
Epoch: 83, Steps: 60 | Train Loss: 0.5155931 Vali Loss: 0.2858024 Test Loss: 0.3542311
Validation loss decreased (0.285885 --> 0.285802).  Saving model ...
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.1005308628082275
Epoch: 84, Steps: 60 | Train Loss: 0.5146569 Vali Loss: 0.2859723 Test Loss: 0.3542301
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.9386258125305176
Epoch: 85, Steps: 60 | Train Loss: 0.5139818 Vali Loss: 0.2859631 Test Loss: 0.3542294
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 2.9878861904144287
Epoch: 86, Steps: 60 | Train Loss: 0.5121444 Vali Loss: 0.2859147 Test Loss: 0.3542224
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 2.515266180038452
Epoch: 87, Steps: 60 | Train Loss: 0.5141649 Vali Loss: 0.2859237 Test Loss: 0.3542304
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 3.177743673324585
Epoch: 88, Steps: 60 | Train Loss: 0.5150732 Vali Loss: 0.2858858 Test Loss: 0.3542274
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 3.156378746032715
Epoch: 89, Steps: 60 | Train Loss: 0.5142509 Vali Loss: 0.2858948 Test Loss: 0.3542241
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 2.401805877685547
Epoch: 90, Steps: 60 | Train Loss: 0.5137640 Vali Loss: 0.2858954 Test Loss: 0.3542194
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.577845811843872
Epoch: 91, Steps: 60 | Train Loss: 0.5150379 Vali Loss: 0.2858529 Test Loss: 0.3542216
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 2.4234869480133057
Epoch: 92, Steps: 60 | Train Loss: 0.5137018 Vali Loss: 0.2859437 Test Loss: 0.3542168
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 2.7739787101745605
Epoch: 93, Steps: 60 | Train Loss: 0.5133824 Vali Loss: 0.2859242 Test Loss: 0.3542215
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 2.342081069946289
Epoch: 94, Steps: 60 | Train Loss: 0.5144226 Vali Loss: 0.2859294 Test Loss: 0.3542159
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 2.7129969596862793
Epoch: 95, Steps: 60 | Train Loss: 0.5147317 Vali Loss: 0.2858815 Test Loss: 0.3542125
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 2.6291868686676025
Epoch: 96, Steps: 60 | Train Loss: 0.5139907 Vali Loss: 0.2859264 Test Loss: 0.3542114
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 2.2893800735473633
Epoch: 97, Steps: 60 | Train Loss: 0.5153086 Vali Loss: 0.2859225 Test Loss: 0.3542100
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 2.5117602348327637
Epoch: 98, Steps: 60 | Train Loss: 0.5140784 Vali Loss: 0.2858764 Test Loss: 0.3542095
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 2.754361152648926
Epoch: 99, Steps: 60 | Train Loss: 0.5145157 Vali Loss: 0.2858640 Test Loss: 0.3542075
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 2.620211124420166
Epoch: 100, Steps: 60 | Train Loss: 0.5152871 Vali Loss: 0.2858416 Test Loss: 0.3542072
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.1160680107021042e-06
>>>>>>>testing : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.33357298374176025, mae:0.37584179639816284, rse:0.4631655812263489, corr:[0.26204237 0.26607233 0.266882   0.26540706 0.2643706  0.2643294
 0.26461717 0.26438278 0.26324093 0.26144907 0.2598024  0.25857085
 0.25778    0.25726795 0.25673053 0.25598204 0.25503993 0.25410894
 0.25324902 0.25242737 0.25144383 0.25006926 0.2482854  0.24629103
 0.24446695 0.24290572 0.2416367  0.2404541  0.23914075 0.2376204
 0.23608854 0.23447613 0.2330528  0.23186013 0.23093908 0.23005837
 0.2291548  0.2283249  0.22761601 0.22684856 0.226006   0.22506471
 0.22403064 0.22303163 0.22208078 0.22105403 0.2197904  0.21812384
 0.2162164  0.21443759 0.21294922 0.211469   0.20994663 0.2082348
 0.20610656 0.20400508 0.20225967 0.20081557 0.19972143 0.19886088
 0.19831285 0.19782257 0.19746245 0.19718851 0.19666916 0.19613172
 0.19553518 0.19497022 0.19447948 0.19398071 0.19322008 0.19220318
 0.1909491  0.18968445 0.18859327 0.18758602 0.1869009  0.18636042
 0.18574777 0.1848491  0.18417755 0.18368368 0.18336508 0.1831535
 0.18297774 0.18276866 0.18233973 0.18176715 0.1811205  0.18074015
 0.18061453 0.18042722 0.18027462 0.17994747 0.17941183 0.17873843
 0.17793518 0.17708465 0.17621888 0.17525987 0.17422414 0.1731492
 0.1723786  0.17184104 0.17160827 0.17139831 0.1710168  0.17053722
 0.16968332 0.16876581 0.16794157 0.16748103 0.1670544  0.16671321
 0.1663142  0.16576917 0.16516678 0.16419035 0.16288269 0.16114965
 0.15938866 0.15776525 0.15666917 0.15602326 0.15536316 0.15445273
 0.15338156 0.15213166 0.15098421 0.15009116 0.14963223 0.14919652
 0.14866945 0.14788061 0.146966   0.14625414 0.14580846 0.14563423
 0.1454475  0.14494368 0.14406316 0.14284611 0.14157863 0.14037432
 0.13908097 0.13773447 0.13620697 0.13446186 0.13276039 0.13149808
 0.13105164 0.13080357 0.13070758 0.13031524 0.12946914 0.12823881
 0.12755919 0.12778214 0.12854321 0.12921774 0.12887163 0.12792951
 0.127043   0.12676677 0.12720022 0.12765971 0.12757427 0.12632544
 0.12437423 0.12234549 0.12128282 0.12103515 0.12117774 0.12038139
 0.11847138 0.11552736 0.11277516 0.11165575 0.11184907 0.11290196
 0.11340844 0.1128189  0.11178887 0.11135893 0.11169588 0.11295568
 0.11399499 0.11320433 0.11147016 0.11075673 0.11583092 0.12684523]
