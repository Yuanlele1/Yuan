Args in experiment:
Namespace(H_order=2, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=72, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H2_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=72, out_features=81, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  5225472.0
params:  5913.0
Trainable parameters:  5913
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 4.005352258682251
Epoch: 1, Steps: 61 | Train Loss: 0.6229777 Vali Loss: 0.2950290 Test Loss: 0.3313136
Validation loss decreased (inf --> 0.295029).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.0144379138946533
Epoch: 2, Steps: 61 | Train Loss: 0.4908717 Vali Loss: 0.2602404 Test Loss: 0.2992254
Validation loss decreased (0.295029 --> 0.260240).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.5521292686462402
Epoch: 3, Steps: 61 | Train Loss: 0.4595850 Vali Loss: 0.2481380 Test Loss: 0.2895770
Validation loss decreased (0.260240 --> 0.248138).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.6828291416168213
Epoch: 4, Steps: 61 | Train Loss: 0.4465439 Vali Loss: 0.2425487 Test Loss: 0.2861570
Validation loss decreased (0.248138 --> 0.242549).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.3406622409820557
Epoch: 5, Steps: 61 | Train Loss: 0.4390534 Vali Loss: 0.2365222 Test Loss: 0.2841791
Validation loss decreased (0.242549 --> 0.236522).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.3583741188049316
Epoch: 6, Steps: 61 | Train Loss: 0.4336371 Vali Loss: 0.2337652 Test Loss: 0.2828822
Validation loss decreased (0.236522 --> 0.233765).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.216059446334839
Epoch: 7, Steps: 61 | Train Loss: 0.4284992 Vali Loss: 0.2320850 Test Loss: 0.2816564
Validation loss decreased (0.233765 --> 0.232085).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.3598642349243164
Epoch: 8, Steps: 61 | Train Loss: 0.4268541 Vali Loss: 0.2300097 Test Loss: 0.2806948
Validation loss decreased (0.232085 --> 0.230010).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.314350128173828
Epoch: 9, Steps: 61 | Train Loss: 0.4231001 Vali Loss: 0.2271348 Test Loss: 0.2802272
Validation loss decreased (0.230010 --> 0.227135).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.834912061691284
Epoch: 10, Steps: 61 | Train Loss: 0.4223157 Vali Loss: 0.2284611 Test Loss: 0.2795563
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.5532333850860596
Epoch: 11, Steps: 61 | Train Loss: 0.4205641 Vali Loss: 0.2259812 Test Loss: 0.2791603
Validation loss decreased (0.227135 --> 0.225981).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.824214220046997
Epoch: 12, Steps: 61 | Train Loss: 0.4193858 Vali Loss: 0.2255466 Test Loss: 0.2785507
Validation loss decreased (0.225981 --> 0.225547).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.152974843978882
Epoch: 13, Steps: 61 | Train Loss: 0.4185751 Vali Loss: 0.2243358 Test Loss: 0.2784193
Validation loss decreased (0.225547 --> 0.224336).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.0349040031433105
Epoch: 14, Steps: 61 | Train Loss: 0.4175118 Vali Loss: 0.2233862 Test Loss: 0.2781418
Validation loss decreased (0.224336 --> 0.223386).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.524770736694336
Epoch: 15, Steps: 61 | Train Loss: 0.4157009 Vali Loss: 0.2233960 Test Loss: 0.2779122
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.9983251094818115
Epoch: 16, Steps: 61 | Train Loss: 0.4161871 Vali Loss: 0.2222334 Test Loss: 0.2776848
Validation loss decreased (0.223386 --> 0.222233).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.613964080810547
Epoch: 17, Steps: 61 | Train Loss: 0.4151681 Vali Loss: 0.2225137 Test Loss: 0.2775542
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.3297908306121826
Epoch: 18, Steps: 61 | Train Loss: 0.4151662 Vali Loss: 0.2220320 Test Loss: 0.2774062
Validation loss decreased (0.222233 --> 0.222032).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.633579969406128
Epoch: 19, Steps: 61 | Train Loss: 0.4139186 Vali Loss: 0.2211564 Test Loss: 0.2772211
Validation loss decreased (0.222032 --> 0.221156).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.4166245460510254
Epoch: 20, Steps: 61 | Train Loss: 0.4143578 Vali Loss: 0.2217321 Test Loss: 0.2771997
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.2414374351501465
Epoch: 21, Steps: 61 | Train Loss: 0.4131304 Vali Loss: 0.2203307 Test Loss: 0.2769134
Validation loss decreased (0.221156 --> 0.220331).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.6116771697998047
Epoch: 22, Steps: 61 | Train Loss: 0.4124504 Vali Loss: 0.2206846 Test Loss: 0.2768159
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.7385830879211426
Epoch: 23, Steps: 61 | Train Loss: 0.4134685 Vali Loss: 0.2207723 Test Loss: 0.2768489
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.6120245456695557
Epoch: 24, Steps: 61 | Train Loss: 0.4124045 Vali Loss: 0.2204790 Test Loss: 0.2767706
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.5874276161193848
Epoch: 25, Steps: 61 | Train Loss: 0.4129359 Vali Loss: 0.2209935 Test Loss: 0.2767589
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.3225841522216797
Epoch: 26, Steps: 61 | Train Loss: 0.4127591 Vali Loss: 0.2203263 Test Loss: 0.2766155
Validation loss decreased (0.220331 --> 0.220326).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.5660030841827393
Epoch: 27, Steps: 61 | Train Loss: 0.4119307 Vali Loss: 0.2204071 Test Loss: 0.2766355
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.5572545528411865
Epoch: 28, Steps: 61 | Train Loss: 0.4115834 Vali Loss: 0.2194896 Test Loss: 0.2765577
Validation loss decreased (0.220326 --> 0.219490).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.380840301513672
Epoch: 29, Steps: 61 | Train Loss: 0.4121991 Vali Loss: 0.2196012 Test Loss: 0.2765128
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.715553045272827
Epoch: 30, Steps: 61 | Train Loss: 0.4114823 Vali Loss: 0.2202751 Test Loss: 0.2764906
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 3.4012246131896973
Epoch: 31, Steps: 61 | Train Loss: 0.4115786 Vali Loss: 0.2200559 Test Loss: 0.2763936
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.1053264141082764
Epoch: 32, Steps: 61 | Train Loss: 0.4112255 Vali Loss: 0.2191729 Test Loss: 0.2763942
Validation loss decreased (0.219490 --> 0.219173).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.3953139781951904
Epoch: 33, Steps: 61 | Train Loss: 0.4103548 Vali Loss: 0.2197871 Test Loss: 0.2763281
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.7088608741760254
Epoch: 34, Steps: 61 | Train Loss: 0.4113985 Vali Loss: 0.2189461 Test Loss: 0.2762886
Validation loss decreased (0.219173 --> 0.218946).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.4137353897094727
Epoch: 35, Steps: 61 | Train Loss: 0.4114242 Vali Loss: 0.2197765 Test Loss: 0.2762409
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.7246532440185547
Epoch: 36, Steps: 61 | Train Loss: 0.4109091 Vali Loss: 0.2194026 Test Loss: 0.2762935
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.6263492107391357
Epoch: 37, Steps: 61 | Train Loss: 0.4110949 Vali Loss: 0.2193510 Test Loss: 0.2761922
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.4423108100891113
Epoch: 38, Steps: 61 | Train Loss: 0.4105888 Vali Loss: 0.2197205 Test Loss: 0.2761894
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.6828534603118896
Epoch: 39, Steps: 61 | Train Loss: 0.4109155 Vali Loss: 0.2195495 Test Loss: 0.2762504
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.9813947677612305
Epoch: 40, Steps: 61 | Train Loss: 0.4105672 Vali Loss: 0.2187925 Test Loss: 0.2761505
Validation loss decreased (0.218946 --> 0.218792).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.7340590953826904
Epoch: 41, Steps: 61 | Train Loss: 0.4106311 Vali Loss: 0.2187864 Test Loss: 0.2761321
Validation loss decreased (0.218792 --> 0.218786).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 3.9578070640563965
Epoch: 42, Steps: 61 | Train Loss: 0.4104408 Vali Loss: 0.2195822 Test Loss: 0.2761860
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.3403587341308594
Epoch: 43, Steps: 61 | Train Loss: 0.4107893 Vali Loss: 0.2181900 Test Loss: 0.2761046
Validation loss decreased (0.218786 --> 0.218190).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 4.133386135101318
Epoch: 44, Steps: 61 | Train Loss: 0.4094865 Vali Loss: 0.2200334 Test Loss: 0.2761530
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 3.111403703689575
Epoch: 45, Steps: 61 | Train Loss: 0.4104278 Vali Loss: 0.2195135 Test Loss: 0.2761001
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.5302767753601074
Epoch: 46, Steps: 61 | Train Loss: 0.4106167 Vali Loss: 0.2185357 Test Loss: 0.2760726
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.8609988689422607
Epoch: 47, Steps: 61 | Train Loss: 0.4090177 Vali Loss: 0.2190602 Test Loss: 0.2760930
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 3.493793487548828
Epoch: 48, Steps: 61 | Train Loss: 0.4101637 Vali Loss: 0.2191380 Test Loss: 0.2760777
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 3.408139228820801
Epoch: 49, Steps: 61 | Train Loss: 0.4102818 Vali Loss: 0.2183683 Test Loss: 0.2760780
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.978816509246826
Epoch: 50, Steps: 61 | Train Loss: 0.4104875 Vali Loss: 0.2199414 Test Loss: 0.2760701
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.495049476623535
Epoch: 51, Steps: 61 | Train Loss: 0.4099510 Vali Loss: 0.2186270 Test Loss: 0.2760574
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.4887547492980957
Epoch: 52, Steps: 61 | Train Loss: 0.4098797 Vali Loss: 0.2178894 Test Loss: 0.2760202
Validation loss decreased (0.218190 --> 0.217889).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 3.045795440673828
Epoch: 53, Steps: 61 | Train Loss: 0.4096511 Vali Loss: 0.2195076 Test Loss: 0.2759993
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.6384220123291016
Epoch: 54, Steps: 61 | Train Loss: 0.4091015 Vali Loss: 0.2189596 Test Loss: 0.2760155
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.8562183380126953
Epoch: 55, Steps: 61 | Train Loss: 0.4101318 Vali Loss: 0.2190044 Test Loss: 0.2760178
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.527294397354126
Epoch: 56, Steps: 61 | Train Loss: 0.4097192 Vali Loss: 0.2187329 Test Loss: 0.2760272
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 3.217395067214966
Epoch: 57, Steps: 61 | Train Loss: 0.4101184 Vali Loss: 0.2194037 Test Loss: 0.2760074
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.84757661819458
Epoch: 58, Steps: 61 | Train Loss: 0.4104441 Vali Loss: 0.2190056 Test Loss: 0.2759699
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.4931509494781494
Epoch: 59, Steps: 61 | Train Loss: 0.4099747 Vali Loss: 0.2183740 Test Loss: 0.2759861
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 4.086409568786621
Epoch: 60, Steps: 61 | Train Loss: 0.4099756 Vali Loss: 0.2191987 Test Loss: 0.2759572
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.7144951820373535
Epoch: 61, Steps: 61 | Train Loss: 0.4088154 Vali Loss: 0.2184917 Test Loss: 0.2759718
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.6438441276550293
Epoch: 62, Steps: 61 | Train Loss: 0.4095793 Vali Loss: 0.2183995 Test Loss: 0.2759604
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.401491403579712
Epoch: 63, Steps: 61 | Train Loss: 0.4099483 Vali Loss: 0.2187934 Test Loss: 0.2759738
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.4944169521331787
Epoch: 64, Steps: 61 | Train Loss: 0.4095981 Vali Loss: 0.2192998 Test Loss: 0.2759457
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 4.150245904922485
Epoch: 65, Steps: 61 | Train Loss: 0.4096807 Vali Loss: 0.2195904 Test Loss: 0.2759530
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.685262680053711
Epoch: 66, Steps: 61 | Train Loss: 0.4102079 Vali Loss: 0.2194218 Test Loss: 0.2759596
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.3498435020446777
Epoch: 67, Steps: 61 | Train Loss: 0.4099968 Vali Loss: 0.2192533 Test Loss: 0.2759281
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.6382455825805664
Epoch: 68, Steps: 61 | Train Loss: 0.4099709 Vali Loss: 0.2180751 Test Loss: 0.2759362
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.428276538848877
Epoch: 69, Steps: 61 | Train Loss: 0.4098047 Vali Loss: 0.2185480 Test Loss: 0.2759286
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.3420979976654053
Epoch: 70, Steps: 61 | Train Loss: 0.4096509 Vali Loss: 0.2189173 Test Loss: 0.2759224
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.8059186935424805
Epoch: 71, Steps: 61 | Train Loss: 0.4099557 Vali Loss: 0.2182614 Test Loss: 0.2759213
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.145246982574463
Epoch: 72, Steps: 61 | Train Loss: 0.4100368 Vali Loss: 0.2183062 Test Loss: 0.2759160
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H2_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.275599867105484, mae:0.3395659625530243, rse:0.42307835817337036, corr:[0.27036184 0.27249363 0.27413258 0.27456403 0.27366275 0.27234742
 0.27115473 0.27004397 0.2689536  0.2677579  0.2666136  0.26551947
 0.26462772 0.26395217 0.2632802  0.26257706 0.2616514  0.26054296
 0.25929153 0.25802875 0.25680023 0.25549573 0.2540633  0.25242653
 0.25072342 0.24905547 0.2475118  0.24606618 0.24470615 0.24340291
 0.24214159 0.24085604 0.23947954 0.23815417 0.23687015 0.23553021
 0.2342099  0.23306894 0.23241742 0.23204783 0.23179968 0.23140575
 0.23066005 0.22940485 0.22783116 0.22608815 0.2244196  0.22288775
 0.22146188 0.22022678 0.21925662 0.21808608 0.21663234 0.2147944
 0.21227829 0.20967776 0.20750052 0.20603992 0.20535192 0.20535158
 0.20566499 0.20565748 0.20523837 0.20455267 0.20340198 0.20238294
 0.20169817 0.20141147 0.20141694 0.20147726 0.20121276 0.20057052
 0.19952059 0.19814974 0.19674928 0.1952823  0.1943291  0.19393508
 0.19391033 0.19365403 0.19351253 0.19336253 0.1928107  0.1921433
 0.19157775 0.1915103  0.19173394 0.19199224 0.19163303 0.19101347
 0.19015424 0.1890942  0.18871862 0.18932737 0.19056198 0.19109632]
