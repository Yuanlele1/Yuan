Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=50, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_180_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_180_336_FITS_ETTh2_ftM_sl180_ll48_pl336_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8125
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=50, out_features=143, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6406400.0
params:  7293.0
Trainable parameters:  7293
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 4.181008338928223
Epoch: 1, Steps: 63 | Train Loss: 0.7265696 Vali Loss: 0.4799331 Test Loss: 0.5105870
Validation loss decreased (inf --> 0.479933).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.7632532119750977
Epoch: 2, Steps: 63 | Train Loss: 0.6070646 Vali Loss: 0.4414558 Test Loss: 0.4678516
Validation loss decreased (0.479933 --> 0.441456).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.52668833732605
Epoch: 3, Steps: 63 | Train Loss: 0.5411282 Vali Loss: 0.4230423 Test Loss: 0.4444790
Validation loss decreased (0.441456 --> 0.423042).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 4.774920225143433
Epoch: 4, Steps: 63 | Train Loss: 0.5023212 Vali Loss: 0.4098555 Test Loss: 0.4303636
Validation loss decreased (0.423042 --> 0.409856).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.6247472763061523
Epoch: 5, Steps: 63 | Train Loss: 0.4786744 Vali Loss: 0.3979902 Test Loss: 0.4218789
Validation loss decreased (0.409856 --> 0.397990).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.5558817386627197
Epoch: 6, Steps: 63 | Train Loss: 0.4627452 Vali Loss: 0.3927784 Test Loss: 0.4163480
Validation loss decreased (0.397990 --> 0.392778).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.4890921115875244
Epoch: 7, Steps: 63 | Train Loss: 0.4537034 Vali Loss: 0.3915581 Test Loss: 0.4124996
Validation loss decreased (0.392778 --> 0.391558).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.36251163482666
Epoch: 8, Steps: 63 | Train Loss: 0.4456820 Vali Loss: 0.3851106 Test Loss: 0.4099240
Validation loss decreased (0.391558 --> 0.385111).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.3335366249084473
Epoch: 9, Steps: 63 | Train Loss: 0.4403311 Vali Loss: 0.3822849 Test Loss: 0.4079185
Validation loss decreased (0.385111 --> 0.382285).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.968411922454834
Epoch: 10, Steps: 63 | Train Loss: 0.4358826 Vali Loss: 0.3831372 Test Loss: 0.4064168
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.159695863723755
Epoch: 11, Steps: 63 | Train Loss: 0.4335210 Vali Loss: 0.3791762 Test Loss: 0.4052104
Validation loss decreased (0.382285 --> 0.379176).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.0190250873565674
Epoch: 12, Steps: 63 | Train Loss: 0.4287587 Vali Loss: 0.3808388 Test Loss: 0.4043305
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.2025797367095947
Epoch: 13, Steps: 63 | Train Loss: 0.4280879 Vali Loss: 0.3765936 Test Loss: 0.4032926
Validation loss decreased (0.379176 --> 0.376594).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.4047625064849854
Epoch: 14, Steps: 63 | Train Loss: 0.4259611 Vali Loss: 0.3766679 Test Loss: 0.4025009
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.717658042907715
Epoch: 15, Steps: 63 | Train Loss: 0.4246361 Vali Loss: 0.3734233 Test Loss: 0.4018373
Validation loss decreased (0.376594 --> 0.373423).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.444808006286621
Epoch: 16, Steps: 63 | Train Loss: 0.4243509 Vali Loss: 0.3747570 Test Loss: 0.4013535
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.051668167114258
Epoch: 17, Steps: 63 | Train Loss: 0.4224425 Vali Loss: 0.3741827 Test Loss: 0.4007600
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.6057417392730713
Epoch: 18, Steps: 63 | Train Loss: 0.4209391 Vali Loss: 0.3755876 Test Loss: 0.4003195
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 3.58013916015625
Epoch: 19, Steps: 63 | Train Loss: 0.4199723 Vali Loss: 0.3719911 Test Loss: 0.3999661
Validation loss decreased (0.373423 --> 0.371991).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.37510085105896
Epoch: 20, Steps: 63 | Train Loss: 0.4204526 Vali Loss: 0.3730111 Test Loss: 0.3996359
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.399214744567871
Epoch: 21, Steps: 63 | Train Loss: 0.4168786 Vali Loss: 0.3711663 Test Loss: 0.3992575
Validation loss decreased (0.371991 --> 0.371166).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.1237246990203857
Epoch: 22, Steps: 63 | Train Loss: 0.4189617 Vali Loss: 0.3728873 Test Loss: 0.3989460
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.7302422523498535
Epoch: 23, Steps: 63 | Train Loss: 0.4173767 Vali Loss: 0.3717771 Test Loss: 0.3986750
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.776487112045288
Epoch: 24, Steps: 63 | Train Loss: 0.4178166 Vali Loss: 0.3723243 Test Loss: 0.3983846
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.316486358642578
Epoch: 25, Steps: 63 | Train Loss: 0.4175197 Vali Loss: 0.3708583 Test Loss: 0.3981485
Validation loss decreased (0.371166 --> 0.370858).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.784032106399536
Epoch: 26, Steps: 63 | Train Loss: 0.4156272 Vali Loss: 0.3713859 Test Loss: 0.3980033
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 3.2435550689697266
Epoch: 27, Steps: 63 | Train Loss: 0.4152608 Vali Loss: 0.3693773 Test Loss: 0.3977658
Validation loss decreased (0.370858 --> 0.369377).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.0253329277038574
Epoch: 28, Steps: 63 | Train Loss: 0.4162479 Vali Loss: 0.3706497 Test Loss: 0.3976210
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 3.1371877193450928
Epoch: 29, Steps: 63 | Train Loss: 0.4155674 Vali Loss: 0.3707940 Test Loss: 0.3974591
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 4.058996677398682
Epoch: 30, Steps: 63 | Train Loss: 0.4164004 Vali Loss: 0.3701401 Test Loss: 0.3972615
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 3.3486087322235107
Epoch: 31, Steps: 63 | Train Loss: 0.4151750 Vali Loss: 0.3713825 Test Loss: 0.3971484
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 3.102783203125
Epoch: 32, Steps: 63 | Train Loss: 0.4150455 Vali Loss: 0.3712218 Test Loss: 0.3970103
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 3.497891664505005
Epoch: 33, Steps: 63 | Train Loss: 0.4142344 Vali Loss: 0.3711155 Test Loss: 0.3968758
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.430532217025757
Epoch: 34, Steps: 63 | Train Loss: 0.4137804 Vali Loss: 0.3717332 Test Loss: 0.3968363
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.5411524772644043
Epoch: 35, Steps: 63 | Train Loss: 0.4131660 Vali Loss: 0.3686392 Test Loss: 0.3966687
Validation loss decreased (0.369377 --> 0.368639).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 3.8966472148895264
Epoch: 36, Steps: 63 | Train Loss: 0.4144181 Vali Loss: 0.3679243 Test Loss: 0.3965860
Validation loss decreased (0.368639 --> 0.367924).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.870499849319458
Epoch: 37, Steps: 63 | Train Loss: 0.4139474 Vali Loss: 0.3697947 Test Loss: 0.3964784
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.536301851272583
Epoch: 38, Steps: 63 | Train Loss: 0.4143621 Vali Loss: 0.3694598 Test Loss: 0.3963680
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 4.106461048126221
Epoch: 39, Steps: 63 | Train Loss: 0.4142745 Vali Loss: 0.3711730 Test Loss: 0.3963017
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 3.8440279960632324
Epoch: 40, Steps: 63 | Train Loss: 0.4135477 Vali Loss: 0.3698303 Test Loss: 0.3962472
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 4.2109105587005615
Epoch: 41, Steps: 63 | Train Loss: 0.4144598 Vali Loss: 0.3706413 Test Loss: 0.3961752
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.860591173171997
Epoch: 42, Steps: 63 | Train Loss: 0.4134419 Vali Loss: 0.3676414 Test Loss: 0.3961177
Validation loss decreased (0.367924 --> 0.367641).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 4.443731784820557
Epoch: 43, Steps: 63 | Train Loss: 0.4125276 Vali Loss: 0.3687944 Test Loss: 0.3960475
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.217207431793213
Epoch: 44, Steps: 63 | Train Loss: 0.4133109 Vali Loss: 0.3698437 Test Loss: 0.3960041
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 3.9425127506256104
Epoch: 45, Steps: 63 | Train Loss: 0.4124816 Vali Loss: 0.3659246 Test Loss: 0.3959339
Validation loss decreased (0.367641 --> 0.365925).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.205322027206421
Epoch: 46, Steps: 63 | Train Loss: 0.4109986 Vali Loss: 0.3701991 Test Loss: 0.3958968
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.411797523498535
Epoch: 47, Steps: 63 | Train Loss: 0.4139060 Vali Loss: 0.3679696 Test Loss: 0.3958235
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.399725914001465
Epoch: 48, Steps: 63 | Train Loss: 0.4124810 Vali Loss: 0.3644291 Test Loss: 0.3957718
Validation loss decreased (0.365925 --> 0.364429).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.5166852474212646
Epoch: 49, Steps: 63 | Train Loss: 0.4134068 Vali Loss: 0.3680272 Test Loss: 0.3957087
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.9561281204223633
Epoch: 50, Steps: 63 | Train Loss: 0.4127115 Vali Loss: 0.3672225 Test Loss: 0.3956735
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.3686461448669434
Epoch: 51, Steps: 63 | Train Loss: 0.4106073 Vali Loss: 0.3693564 Test Loss: 0.3956586
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.980586528778076
Epoch: 52, Steps: 63 | Train Loss: 0.4131796 Vali Loss: 0.3702011 Test Loss: 0.3956175
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 4.14886736869812
Epoch: 53, Steps: 63 | Train Loss: 0.4133026 Vali Loss: 0.3666135 Test Loss: 0.3955972
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.919785976409912
Epoch: 54, Steps: 63 | Train Loss: 0.4122579 Vali Loss: 0.3663820 Test Loss: 0.3955424
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.7525439262390137
Epoch: 55, Steps: 63 | Train Loss: 0.4123180 Vali Loss: 0.3690954 Test Loss: 0.3955305
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.8774197101593018
Epoch: 56, Steps: 63 | Train Loss: 0.4130945 Vali Loss: 0.3670005 Test Loss: 0.3954926
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.362133741378784
Epoch: 57, Steps: 63 | Train Loss: 0.4134787 Vali Loss: 0.3687949 Test Loss: 0.3954650
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.6309714317321777
Epoch: 58, Steps: 63 | Train Loss: 0.4124293 Vali Loss: 0.3694307 Test Loss: 0.3954403
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.24702525138855
Epoch: 59, Steps: 63 | Train Loss: 0.4124282 Vali Loss: 0.3681582 Test Loss: 0.3954043
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.830007791519165
Epoch: 60, Steps: 63 | Train Loss: 0.4125326 Vali Loss: 0.3677420 Test Loss: 0.3953947
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 3.253539562225342
Epoch: 61, Steps: 63 | Train Loss: 0.4109526 Vali Loss: 0.3683075 Test Loss: 0.3953660
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.3597145080566406
Epoch: 62, Steps: 63 | Train Loss: 0.4126873 Vali Loss: 0.3678675 Test Loss: 0.3953447
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.9223005771636963
Epoch: 63, Steps: 63 | Train Loss: 0.4119594 Vali Loss: 0.3689737 Test Loss: 0.3953204
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.8396589756011963
Epoch: 64, Steps: 63 | Train Loss: 0.4129304 Vali Loss: 0.3675091 Test Loss: 0.3952987
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 3.0242722034454346
Epoch: 65, Steps: 63 | Train Loss: 0.4113608 Vali Loss: 0.3654700 Test Loss: 0.3952907
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 3.211529493331909
Epoch: 66, Steps: 63 | Train Loss: 0.4116894 Vali Loss: 0.3685417 Test Loss: 0.3952700
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.8993914127349854
Epoch: 67, Steps: 63 | Train Loss: 0.4129533 Vali Loss: 0.3673386 Test Loss: 0.3952526
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 4.26394510269165
Epoch: 68, Steps: 63 | Train Loss: 0.4105411 Vali Loss: 0.3684763 Test Loss: 0.3952470
EarlyStopping counter: 20 out of 20
Early stopping
train 8125
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=50, out_features=143, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6406400.0
params:  7293.0
Trainable parameters:  7293
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.7838215827941895
Epoch: 1, Steps: 63 | Train Loss: 0.6234301 Vali Loss: 0.3673142 Test Loss: 0.3941415
Validation loss decreased (inf --> 0.367314).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.2906994819641113
Epoch: 2, Steps: 63 | Train Loss: 0.6210786 Vali Loss: 0.3660997 Test Loss: 0.3937577
Validation loss decreased (0.367314 --> 0.366100).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 4.576547622680664
Epoch: 3, Steps: 63 | Train Loss: 0.6195832 Vali Loss: 0.3681560 Test Loss: 0.3934266
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.6097517013549805
Epoch: 4, Steps: 63 | Train Loss: 0.6186799 Vali Loss: 0.3652063 Test Loss: 0.3929659
Validation loss decreased (0.366100 --> 0.365206).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.2075178623199463
Epoch: 5, Steps: 63 | Train Loss: 0.6191355 Vali Loss: 0.3672764 Test Loss: 0.3929401
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.963574171066284
Epoch: 6, Steps: 63 | Train Loss: 0.6186840 Vali Loss: 0.3653730 Test Loss: 0.3927812
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.7248029708862305
Epoch: 7, Steps: 63 | Train Loss: 0.6155526 Vali Loss: 0.3639827 Test Loss: 0.3924158
Validation loss decreased (0.365206 --> 0.363983).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.2449934482574463
Epoch: 8, Steps: 63 | Train Loss: 0.6181060 Vali Loss: 0.3661914 Test Loss: 0.3923506
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.087519407272339
Epoch: 9, Steps: 63 | Train Loss: 0.6177644 Vali Loss: 0.3629473 Test Loss: 0.3923315
Validation loss decreased (0.363983 --> 0.362947).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 4.476142406463623
Epoch: 10, Steps: 63 | Train Loss: 0.6171941 Vali Loss: 0.3628793 Test Loss: 0.3922312
Validation loss decreased (0.362947 --> 0.362879).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.7476227283477783
Epoch: 11, Steps: 63 | Train Loss: 0.6179683 Vali Loss: 0.3633821 Test Loss: 0.3921946
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.5848445892333984
Epoch: 12, Steps: 63 | Train Loss: 0.6166418 Vali Loss: 0.3640073 Test Loss: 0.3921307
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.821152448654175
Epoch: 13, Steps: 63 | Train Loss: 0.6183331 Vali Loss: 0.3628954 Test Loss: 0.3921331
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.4523561000823975
Epoch: 14, Steps: 63 | Train Loss: 0.6158910 Vali Loss: 0.3640153 Test Loss: 0.3921127
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.0620064735412598
Epoch: 15, Steps: 63 | Train Loss: 0.6153250 Vali Loss: 0.3626669 Test Loss: 0.3920527
Validation loss decreased (0.362879 --> 0.362667).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.5160605907440186
Epoch: 16, Steps: 63 | Train Loss: 0.6177986 Vali Loss: 0.3649186 Test Loss: 0.3920161
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.2449989318847656
Epoch: 17, Steps: 63 | Train Loss: 0.6161330 Vali Loss: 0.3645788 Test Loss: 0.3920286
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.8663532733917236
Epoch: 18, Steps: 63 | Train Loss: 0.6156228 Vali Loss: 0.3611582 Test Loss: 0.3920372
Validation loss decreased (0.362667 --> 0.361158).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 3.8420445919036865
Epoch: 19, Steps: 63 | Train Loss: 0.6156460 Vali Loss: 0.3644562 Test Loss: 0.3920587
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.3406195640563965
Epoch: 20, Steps: 63 | Train Loss: 0.6166716 Vali Loss: 0.3634786 Test Loss: 0.3920049
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.8331680297851562
Epoch: 21, Steps: 63 | Train Loss: 0.6168006 Vali Loss: 0.3633759 Test Loss: 0.3919752
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.5792617797851562
Epoch: 22, Steps: 63 | Train Loss: 0.6152383 Vali Loss: 0.3627567 Test Loss: 0.3919937
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.587836742401123
Epoch: 23, Steps: 63 | Train Loss: 0.6151246 Vali Loss: 0.3646874 Test Loss: 0.3919454
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.1821088790893555
Epoch: 24, Steps: 63 | Train Loss: 0.6163966 Vali Loss: 0.3639376 Test Loss: 0.3919082
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.7080647945404053
Epoch: 25, Steps: 63 | Train Loss: 0.6171043 Vali Loss: 0.3655218 Test Loss: 0.3919198
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.3966004848480225
Epoch: 26, Steps: 63 | Train Loss: 0.6165871 Vali Loss: 0.3635388 Test Loss: 0.3918793
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.716413736343384
Epoch: 27, Steps: 63 | Train Loss: 0.6162363 Vali Loss: 0.3629521 Test Loss: 0.3918528
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.8965673446655273
Epoch: 28, Steps: 63 | Train Loss: 0.6170294 Vali Loss: 0.3639532 Test Loss: 0.3919004
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.9747560024261475
Epoch: 29, Steps: 63 | Train Loss: 0.6151608 Vali Loss: 0.3652004 Test Loss: 0.3918788
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.1692349910736084
Epoch: 30, Steps: 63 | Train Loss: 0.6144242 Vali Loss: 0.3635699 Test Loss: 0.3918699
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.9305734634399414
Epoch: 31, Steps: 63 | Train Loss: 0.6154165 Vali Loss: 0.3632977 Test Loss: 0.3918473
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.8446438312530518
Epoch: 32, Steps: 63 | Train Loss: 0.6161988 Vali Loss: 0.3646724 Test Loss: 0.3918144
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 3.30448579788208
Epoch: 33, Steps: 63 | Train Loss: 0.6145030 Vali Loss: 0.3663021 Test Loss: 0.3918403
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.8046209812164307
Epoch: 34, Steps: 63 | Train Loss: 0.6142151 Vali Loss: 0.3618933 Test Loss: 0.3918051
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.3479630947113037
Epoch: 35, Steps: 63 | Train Loss: 0.6153861 Vali Loss: 0.3625190 Test Loss: 0.3917893
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.877201557159424
Epoch: 36, Steps: 63 | Train Loss: 0.6128032 Vali Loss: 0.3646363 Test Loss: 0.3917763
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.0626935958862305
Epoch: 37, Steps: 63 | Train Loss: 0.6162789 Vali Loss: 0.3610997 Test Loss: 0.3918219
Validation loss decreased (0.361158 --> 0.361100).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.0597033500671387
Epoch: 38, Steps: 63 | Train Loss: 0.6156703 Vali Loss: 0.3605684 Test Loss: 0.3917833
Validation loss decreased (0.361100 --> 0.360568).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 3.4490959644317627
Epoch: 39, Steps: 63 | Train Loss: 0.6156243 Vali Loss: 0.3641250 Test Loss: 0.3918032
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 3.506403923034668
Epoch: 40, Steps: 63 | Train Loss: 0.6169322 Vali Loss: 0.3629434 Test Loss: 0.3917817
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 3.575394630432129
Epoch: 41, Steps: 63 | Train Loss: 0.6160886 Vali Loss: 0.3640903 Test Loss: 0.3917904
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.4035449028015137
Epoch: 42, Steps: 63 | Train Loss: 0.6155928 Vali Loss: 0.3623339 Test Loss: 0.3917967
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 3.382854461669922
Epoch: 43, Steps: 63 | Train Loss: 0.6155844 Vali Loss: 0.3626929 Test Loss: 0.3917967
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.903709650039673
Epoch: 44, Steps: 63 | Train Loss: 0.6155614 Vali Loss: 0.3617867 Test Loss: 0.3917944
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.913072347640991
Epoch: 45, Steps: 63 | Train Loss: 0.6150607 Vali Loss: 0.3611315 Test Loss: 0.3917677
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.7854983806610107
Epoch: 46, Steps: 63 | Train Loss: 0.6159721 Vali Loss: 0.3635014 Test Loss: 0.3917687
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 3.061248779296875
Epoch: 47, Steps: 63 | Train Loss: 0.6147534 Vali Loss: 0.3633442 Test Loss: 0.3917667
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.348310708999634
Epoch: 48, Steps: 63 | Train Loss: 0.6163375 Vali Loss: 0.3642219 Test Loss: 0.3917740
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 3.947753429412842
Epoch: 49, Steps: 63 | Train Loss: 0.6146851 Vali Loss: 0.3625399 Test Loss: 0.3917758
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 3.772364616394043
Epoch: 50, Steps: 63 | Train Loss: 0.6145576 Vali Loss: 0.3616137 Test Loss: 0.3917772
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 4.312828540802002
Epoch: 51, Steps: 63 | Train Loss: 0.6162932 Vali Loss: 0.3628084 Test Loss: 0.3917791
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 3.037719964981079
Epoch: 52, Steps: 63 | Train Loss: 0.6170942 Vali Loss: 0.3631524 Test Loss: 0.3917663
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 4.9862306118011475
Epoch: 53, Steps: 63 | Train Loss: 0.6143866 Vali Loss: 0.3632084 Test Loss: 0.3917700
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 4.260812044143677
Epoch: 54, Steps: 63 | Train Loss: 0.6154363 Vali Loss: 0.3593965 Test Loss: 0.3917647
Validation loss decreased (0.360568 --> 0.359397).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 3.9010603427886963
Epoch: 55, Steps: 63 | Train Loss: 0.6150006 Vali Loss: 0.3638598 Test Loss: 0.3917656
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 3.897030830383301
Epoch: 56, Steps: 63 | Train Loss: 0.6152985 Vali Loss: 0.3627679 Test Loss: 0.3917537
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 3.1320550441741943
Epoch: 57, Steps: 63 | Train Loss: 0.6143876 Vali Loss: 0.3622006 Test Loss: 0.3917656
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.8952357769012451
Epoch: 58, Steps: 63 | Train Loss: 0.6155468 Vali Loss: 0.3659512 Test Loss: 0.3917519
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.664364814758301
Epoch: 59, Steps: 63 | Train Loss: 0.6161850 Vali Loss: 0.3637962 Test Loss: 0.3917584
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.6398062705993652
Epoch: 60, Steps: 63 | Train Loss: 0.6143229 Vali Loss: 0.3652872 Test Loss: 0.3917546
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.6991171836853027
Epoch: 61, Steps: 63 | Train Loss: 0.6168132 Vali Loss: 0.3630914 Test Loss: 0.3917448
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.989915370941162
Epoch: 62, Steps: 63 | Train Loss: 0.6144724 Vali Loss: 0.3638023 Test Loss: 0.3917451
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.910158634185791
Epoch: 63, Steps: 63 | Train Loss: 0.6142290 Vali Loss: 0.3636609 Test Loss: 0.3917466
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 3.5327048301696777
Epoch: 64, Steps: 63 | Train Loss: 0.6150909 Vali Loss: 0.3641207 Test Loss: 0.3917568
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 4.352689743041992
Epoch: 65, Steps: 63 | Train Loss: 0.6147568 Vali Loss: 0.3644636 Test Loss: 0.3917458
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.7027275562286377
Epoch: 66, Steps: 63 | Train Loss: 0.6141191 Vali Loss: 0.3624636 Test Loss: 0.3917374
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 3.8003323078155518
Epoch: 67, Steps: 63 | Train Loss: 0.6159259 Vali Loss: 0.3620013 Test Loss: 0.3917404
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 3.480668067932129
Epoch: 68, Steps: 63 | Train Loss: 0.6141590 Vali Loss: 0.3636909 Test Loss: 0.3917396
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 3.0897557735443115
Epoch: 69, Steps: 63 | Train Loss: 0.6146562 Vali Loss: 0.3624383 Test Loss: 0.3917438
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.8831422328948975
Epoch: 70, Steps: 63 | Train Loss: 0.6156582 Vali Loss: 0.3631405 Test Loss: 0.3917384
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.7270636558532715
Epoch: 71, Steps: 63 | Train Loss: 0.6152334 Vali Loss: 0.3648124 Test Loss: 0.3917371
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.845055103302002
Epoch: 72, Steps: 63 | Train Loss: 0.6142516 Vali Loss: 0.3632630 Test Loss: 0.3917357
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.2977497577667236
Epoch: 73, Steps: 63 | Train Loss: 0.6156605 Vali Loss: 0.3627389 Test Loss: 0.3917292
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 3.156331777572632
Epoch: 74, Steps: 63 | Train Loss: 0.6134249 Vali Loss: 0.3633158 Test Loss: 0.3917367
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_180_336_FITS_ETTh2_ftM_sl180_ll48_pl336_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.387114554643631, mae:0.4116263687610626, rse:0.4974612593650818, corr:[0.2633862  0.26590756 0.2641267  0.26440266 0.26321438 0.26112473
 0.2603567  0.25953695 0.25818148 0.2568845  0.25608015 0.25457424
 0.25309792 0.25181973 0.25103235 0.25039214 0.24980576 0.24897978
 0.24800536 0.24700078 0.24598648 0.24515367 0.2442406  0.24268812
 0.24015039 0.23813176 0.23669073 0.23542216 0.23377012 0.23229593
 0.23086667 0.22922407 0.22764505 0.22647506 0.22538622 0.2241625
 0.2231882  0.22211172 0.22103411 0.21982105 0.21904573 0.21833402
 0.21754777 0.21650192 0.2153359  0.2140519  0.21262008 0.21063371
 0.2077246  0.20529832 0.20337644 0.20146501 0.19920166 0.19729267
 0.1953461  0.193091   0.19131406 0.18996738 0.1890389  0.18789932
 0.18716678 0.18651482 0.18637088 0.18589309 0.18531162 0.18467318
 0.18374696 0.18271734 0.1821366  0.18181092 0.18086007 0.17954454
 0.17750992 0.17591567 0.17469013 0.17349526 0.17212857 0.17139064
 0.17098987 0.17031035 0.16987406 0.1696458  0.16976802 0.16967957
 0.16957888 0.16933733 0.16948019 0.16918267 0.16853866 0.16794835
 0.16779381 0.16736695 0.16719736 0.16744533 0.16744377 0.16685387
 0.16550413 0.16452253 0.16344836 0.16253313 0.161767   0.16123977
 0.1607671  0.16037509 0.1606657  0.1607475  0.1607459  0.16074516
 0.1611269  0.1607538  0.16005312 0.15945387 0.15909173 0.1586036
 0.15809631 0.15756859 0.15710126 0.15646026 0.15547861 0.15404917
 0.15185462 0.14997518 0.14867216 0.1477089  0.14624646 0.1448842
 0.14405264 0.1432066  0.14229089 0.14164285 0.14135046 0.14082521
 0.14040683 0.13997373 0.1398233  0.13942553 0.13874291 0.13795869
 0.1374807  0.13696483 0.13655213 0.13627824 0.13554817 0.13402091
 0.13129492 0.12938242 0.1276381  0.12621495 0.12493344 0.12412526
 0.12370279 0.12304506 0.12263357 0.12258863 0.12297776 0.12316956
 0.12370753 0.12358612 0.12354194 0.12363865 0.12354357 0.12293299
 0.1224758  0.12237645 0.12213182 0.12206464 0.12202796 0.12103645
 0.11858955 0.11720027 0.11641228 0.11551934 0.11409646 0.11284038
 0.11225845 0.11152948 0.11126045 0.11111563 0.11132867 0.11132361
 0.11159388 0.1116355  0.11158925 0.11149023 0.11129011 0.11084422
 0.1106482  0.11054182 0.11075214 0.11122876 0.11146009 0.1112966
 0.11046831 0.11010236 0.10957733 0.10945127 0.10926346 0.10912529
 0.10905973 0.10909136 0.10947032 0.10960548 0.11015674 0.11028971
 0.11036179 0.11003198 0.10989074 0.10976861 0.10953774 0.10952643
 0.10974839 0.1098889  0.10993611 0.11020437 0.1105689  0.11011773
 0.10876099 0.10774536 0.107049   0.10658615 0.10598515 0.10603156
 0.10599416 0.10625956 0.10678397 0.10724764 0.10730087 0.10700205
 0.10708687 0.10676202 0.10650912 0.1065988  0.10698588 0.10710487
 0.10722239 0.10764951 0.10812116 0.1084635  0.10865992 0.10863148
 0.10751222 0.10644961 0.1055261  0.10526632 0.10485579 0.10440448
 0.10405072 0.10430603 0.10502917 0.10556754 0.10632939 0.10688566
 0.10785834 0.10846174 0.10868393 0.10903642 0.10959829 0.11008826
 0.1101651  0.11039929 0.11103563 0.11163901 0.11210984 0.11233485
 0.11198656 0.11151426 0.11091857 0.11096155 0.11082169 0.11092141
 0.11103769 0.11132425 0.1118372  0.11216173 0.11296778 0.11343922
 0.11389215 0.1137745  0.11412086 0.11422292 0.1141732  0.11431815
 0.11475926 0.11475268 0.11453851 0.11501709 0.11564517 0.11612853
 0.11563052 0.11539487 0.11482011 0.11438093 0.1137865  0.11356931
 0.1131606  0.1127596  0.11377008 0.11451737 0.11522086 0.11599711
 0.11717309 0.1171219  0.11730582 0.11820831 0.11877073 0.11879439
 0.11903816 0.11979189 0.11997558 0.11987642 0.12041542 0.12071744
 0.11934741 0.11818028 0.1175494  0.11734369 0.11621796 0.11549657
 0.11477765 0.11490007 0.11575666 0.1163201  0.11659504 0.11709207
 0.11915372 0.11908427 0.11792238 0.11778941 0.11861535 0.11726333
 0.11532353 0.11533538 0.11517801 0.11312403 0.11390821 0.11604906]
