Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=50, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_180_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_180_192_FITS_ETTh2_ftM_sl180_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8269
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=50, out_features=103, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4614400.0
params:  5253.0
Trainable parameters:  5253
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.7508084774017334
Epoch: 1, Steps: 64 | Train Loss: 0.5760498 Vali Loss: 0.3769724 Test Loss: 0.5152649
Validation loss decreased (inf --> 0.376972).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.969724655151367
Epoch: 2, Steps: 64 | Train Loss: 0.4735777 Vali Loss: 0.3428082 Test Loss: 0.4714889
Validation loss decreased (0.376972 --> 0.342808).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.7866897583007812
Epoch: 3, Steps: 64 | Train Loss: 0.4152116 Vali Loss: 0.3236191 Test Loss: 0.4465466
Validation loss decreased (0.342808 --> 0.323619).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.3311522006988525
Epoch: 4, Steps: 64 | Train Loss: 0.3816194 Vali Loss: 0.3117276 Test Loss: 0.4312081
Validation loss decreased (0.323619 --> 0.311728).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.7160797119140625
Epoch: 5, Steps: 64 | Train Loss: 0.3582347 Vali Loss: 0.3038027 Test Loss: 0.4214672
Validation loss decreased (0.311728 --> 0.303803).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.165919780731201
Epoch: 6, Steps: 64 | Train Loss: 0.3424766 Vali Loss: 0.2986228 Test Loss: 0.4148729
Validation loss decreased (0.303803 --> 0.298623).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.3901355266571045
Epoch: 7, Steps: 64 | Train Loss: 0.3315073 Vali Loss: 0.2949573 Test Loss: 0.4103418
Validation loss decreased (0.298623 --> 0.294957).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.765091896057129
Epoch: 8, Steps: 64 | Train Loss: 0.3225564 Vali Loss: 0.2921934 Test Loss: 0.4067624
Validation loss decreased (0.294957 --> 0.292193).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.235884189605713
Epoch: 9, Steps: 64 | Train Loss: 0.3166036 Vali Loss: 0.2901457 Test Loss: 0.4042227
Validation loss decreased (0.292193 --> 0.290146).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.140038251876831
Epoch: 10, Steps: 64 | Train Loss: 0.3108937 Vali Loss: 0.2884314 Test Loss: 0.4019911
Validation loss decreased (0.290146 --> 0.288431).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.54669451713562
Epoch: 11, Steps: 64 | Train Loss: 0.3063518 Vali Loss: 0.2870631 Test Loss: 0.4002374
Validation loss decreased (0.288431 --> 0.287063).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.9779043197631836
Epoch: 12, Steps: 64 | Train Loss: 0.3025250 Vali Loss: 0.2858240 Test Loss: 0.3987647
Validation loss decreased (0.287063 --> 0.285824).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 4.018737316131592
Epoch: 13, Steps: 64 | Train Loss: 0.2992291 Vali Loss: 0.2848346 Test Loss: 0.3974438
Validation loss decreased (0.285824 --> 0.284835).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.388972520828247
Epoch: 14, Steps: 64 | Train Loss: 0.2969757 Vali Loss: 0.2840566 Test Loss: 0.3962932
Validation loss decreased (0.284835 --> 0.284057).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.977043390274048
Epoch: 15, Steps: 64 | Train Loss: 0.2961059 Vali Loss: 0.2832836 Test Loss: 0.3952695
Validation loss decreased (0.284057 --> 0.283284).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.243494749069214
Epoch: 16, Steps: 64 | Train Loss: 0.2934186 Vali Loss: 0.2823043 Test Loss: 0.3943247
Validation loss decreased (0.283284 --> 0.282304).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.984562397003174
Epoch: 17, Steps: 64 | Train Loss: 0.2915786 Vali Loss: 0.2820651 Test Loss: 0.3935204
Validation loss decreased (0.282304 --> 0.282065).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.4601972103118896
Epoch: 18, Steps: 64 | Train Loss: 0.2903765 Vali Loss: 0.2814840 Test Loss: 0.3928227
Validation loss decreased (0.282065 --> 0.281484).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 3.019089460372925
Epoch: 19, Steps: 64 | Train Loss: 0.2885405 Vali Loss: 0.2809635 Test Loss: 0.3921968
Validation loss decreased (0.281484 --> 0.280963).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.7146687507629395
Epoch: 20, Steps: 64 | Train Loss: 0.2872551 Vali Loss: 0.2804400 Test Loss: 0.3915849
Validation loss decreased (0.280963 --> 0.280440).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.8029837608337402
Epoch: 21, Steps: 64 | Train Loss: 0.2879076 Vali Loss: 0.2801221 Test Loss: 0.3910530
Validation loss decreased (0.280440 --> 0.280122).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.4864871501922607
Epoch: 22, Steps: 64 | Train Loss: 0.2863080 Vali Loss: 0.2798183 Test Loss: 0.3904953
Validation loss decreased (0.280122 --> 0.279818).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.786932945251465
Epoch: 23, Steps: 64 | Train Loss: 0.2855466 Vali Loss: 0.2795003 Test Loss: 0.3900230
Validation loss decreased (0.279818 --> 0.279500).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.083125114440918
Epoch: 24, Steps: 64 | Train Loss: 0.2844488 Vali Loss: 0.2791444 Test Loss: 0.3895807
Validation loss decreased (0.279500 --> 0.279144).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 3.3327949047088623
Epoch: 25, Steps: 64 | Train Loss: 0.2843401 Vali Loss: 0.2788782 Test Loss: 0.3891786
Validation loss decreased (0.279144 --> 0.278878).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.5572257041931152
Epoch: 26, Steps: 64 | Train Loss: 0.2824713 Vali Loss: 0.2786332 Test Loss: 0.3888020
Validation loss decreased (0.278878 --> 0.278633).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.244333267211914
Epoch: 27, Steps: 64 | Train Loss: 0.2831553 Vali Loss: 0.2783676 Test Loss: 0.3884847
Validation loss decreased (0.278633 --> 0.278368).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 4.016161203384399
Epoch: 28, Steps: 64 | Train Loss: 0.2830931 Vali Loss: 0.2781686 Test Loss: 0.3881975
Validation loss decreased (0.278368 --> 0.278169).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 3.470628023147583
Epoch: 29, Steps: 64 | Train Loss: 0.2823293 Vali Loss: 0.2779578 Test Loss: 0.3879167
Validation loss decreased (0.278169 --> 0.277958).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 6.333453893661499
Epoch: 30, Steps: 64 | Train Loss: 0.2819775 Vali Loss: 0.2777302 Test Loss: 0.3876024
Validation loss decreased (0.277958 --> 0.277730).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 3.1847493648529053
Epoch: 31, Steps: 64 | Train Loss: 0.2812637 Vali Loss: 0.2776698 Test Loss: 0.3873202
Validation loss decreased (0.277730 --> 0.277670).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 3.2555649280548096
Epoch: 32, Steps: 64 | Train Loss: 0.2808019 Vali Loss: 0.2774903 Test Loss: 0.3871110
Validation loss decreased (0.277670 --> 0.277490).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.7283854484558105
Epoch: 33, Steps: 64 | Train Loss: 0.2815921 Vali Loss: 0.2771073 Test Loss: 0.3868951
Validation loss decreased (0.277490 --> 0.277107).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.004584550857544
Epoch: 34, Steps: 64 | Train Loss: 0.2809062 Vali Loss: 0.2770090 Test Loss: 0.3867039
Validation loss decreased (0.277107 --> 0.277009).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.116447925567627
Epoch: 35, Steps: 64 | Train Loss: 0.2804773 Vali Loss: 0.2770185 Test Loss: 0.3865213
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.476004123687744
Epoch: 36, Steps: 64 | Train Loss: 0.2807155 Vali Loss: 0.2768337 Test Loss: 0.3863353
Validation loss decreased (0.277009 --> 0.276834).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.736464500427246
Epoch: 37, Steps: 64 | Train Loss: 0.2800947 Vali Loss: 0.2767664 Test Loss: 0.3861676
Validation loss decreased (0.276834 --> 0.276766).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 3.0377585887908936
Epoch: 38, Steps: 64 | Train Loss: 0.2793748 Vali Loss: 0.2765950 Test Loss: 0.3860317
Validation loss decreased (0.276766 --> 0.276595).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 3.1226460933685303
Epoch: 39, Steps: 64 | Train Loss: 0.2807248 Vali Loss: 0.2765784 Test Loss: 0.3858763
Validation loss decreased (0.276595 --> 0.276578).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.5454673767089844
Epoch: 40, Steps: 64 | Train Loss: 0.2794918 Vali Loss: 0.2764751 Test Loss: 0.3857272
Validation loss decreased (0.276578 --> 0.276475).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.7004945278167725
Epoch: 41, Steps: 64 | Train Loss: 0.2789535 Vali Loss: 0.2764480 Test Loss: 0.3855993
Validation loss decreased (0.276475 --> 0.276448).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 3.136931896209717
Epoch: 42, Steps: 64 | Train Loss: 0.2787185 Vali Loss: 0.2762379 Test Loss: 0.3854834
Validation loss decreased (0.276448 --> 0.276238).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.9042880535125732
Epoch: 43, Steps: 64 | Train Loss: 0.2786317 Vali Loss: 0.2762421 Test Loss: 0.3853734
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.4183433055877686
Epoch: 44, Steps: 64 | Train Loss: 0.2782349 Vali Loss: 0.2760817 Test Loss: 0.3852538
Validation loss decreased (0.276238 --> 0.276082).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 3.1623551845550537
Epoch: 45, Steps: 64 | Train Loss: 0.2791530 Vali Loss: 0.2761005 Test Loss: 0.3851607
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 4.317294597625732
Epoch: 46, Steps: 64 | Train Loss: 0.2793908 Vali Loss: 0.2760497 Test Loss: 0.3850722
Validation loss decreased (0.276082 --> 0.276050).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.844134569168091
Epoch: 47, Steps: 64 | Train Loss: 0.2780927 Vali Loss: 0.2759783 Test Loss: 0.3849828
Validation loss decreased (0.276050 --> 0.275978).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 3.526089906692505
Epoch: 48, Steps: 64 | Train Loss: 0.2790180 Vali Loss: 0.2758938 Test Loss: 0.3849007
Validation loss decreased (0.275978 --> 0.275894).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.9221293926239014
Epoch: 49, Steps: 64 | Train Loss: 0.2789561 Vali Loss: 0.2758844 Test Loss: 0.3848023
Validation loss decreased (0.275894 --> 0.275884).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 3.2651050090789795
Epoch: 50, Steps: 64 | Train Loss: 0.2777800 Vali Loss: 0.2758325 Test Loss: 0.3847369
Validation loss decreased (0.275884 --> 0.275833).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.2934646606445312
Epoch: 51, Steps: 64 | Train Loss: 0.2785635 Vali Loss: 0.2756850 Test Loss: 0.3846655
Validation loss decreased (0.275833 --> 0.275685).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 3.3998043537139893
Epoch: 52, Steps: 64 | Train Loss: 0.2784038 Vali Loss: 0.2757066 Test Loss: 0.3845920
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 3.8984549045562744
Epoch: 53, Steps: 64 | Train Loss: 0.2789499 Vali Loss: 0.2756917 Test Loss: 0.3845367
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 3.5932135581970215
Epoch: 54, Steps: 64 | Train Loss: 0.2769143 Vali Loss: 0.2756594 Test Loss: 0.3844814
Validation loss decreased (0.275685 --> 0.275659).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.1303937435150146
Epoch: 55, Steps: 64 | Train Loss: 0.2778567 Vali Loss: 0.2755798 Test Loss: 0.3844172
Validation loss decreased (0.275659 --> 0.275580).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.881303071975708
Epoch: 56, Steps: 64 | Train Loss: 0.2775997 Vali Loss: 0.2755560 Test Loss: 0.3843634
Validation loss decreased (0.275580 --> 0.275556).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.954371690750122
Epoch: 57, Steps: 64 | Train Loss: 0.2774583 Vali Loss: 0.2754472 Test Loss: 0.3843069
Validation loss decreased (0.275556 --> 0.275447).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.716653347015381
Epoch: 58, Steps: 64 | Train Loss: 0.2769262 Vali Loss: 0.2753619 Test Loss: 0.3842649
Validation loss decreased (0.275447 --> 0.275362).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.5754153728485107
Epoch: 59, Steps: 64 | Train Loss: 0.2778336 Vali Loss: 0.2754828 Test Loss: 0.3842219
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 3.0165936946868896
Epoch: 60, Steps: 64 | Train Loss: 0.2783335 Vali Loss: 0.2754365 Test Loss: 0.3841802
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 3.458061933517456
Epoch: 61, Steps: 64 | Train Loss: 0.2779265 Vali Loss: 0.2753879 Test Loss: 0.3841387
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 3.0146992206573486
Epoch: 62, Steps: 64 | Train Loss: 0.2767058 Vali Loss: 0.2753634 Test Loss: 0.3840922
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 3.5563101768493652
Epoch: 63, Steps: 64 | Train Loss: 0.2780478 Vali Loss: 0.2749517 Test Loss: 0.3840688
Validation loss decreased (0.275362 --> 0.274952).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.660687208175659
Epoch: 64, Steps: 64 | Train Loss: 0.2766862 Vali Loss: 0.2752920 Test Loss: 0.3840304
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 3.201141357421875
Epoch: 65, Steps: 64 | Train Loss: 0.2781978 Vali Loss: 0.2753128 Test Loss: 0.3839972
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 3.605647563934326
Epoch: 66, Steps: 64 | Train Loss: 0.2778644 Vali Loss: 0.2752857 Test Loss: 0.3839693
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 4.0480711460113525
Epoch: 67, Steps: 64 | Train Loss: 0.2774046 Vali Loss: 0.2752747 Test Loss: 0.3839410
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 6.084909439086914
Epoch: 68, Steps: 64 | Train Loss: 0.2771529 Vali Loss: 0.2752782 Test Loss: 0.3839106
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 3.434239625930786
Epoch: 69, Steps: 64 | Train Loss: 0.2767231 Vali Loss: 0.2752221 Test Loss: 0.3838783
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.474139928817749
Epoch: 70, Steps: 64 | Train Loss: 0.2771642 Vali Loss: 0.2752408 Test Loss: 0.3838620
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.2950384616851807
Epoch: 71, Steps: 64 | Train Loss: 0.2771263 Vali Loss: 0.2750495 Test Loss: 0.3838362
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.836951494216919
Epoch: 72, Steps: 64 | Train Loss: 0.2774782 Vali Loss: 0.2751094 Test Loss: 0.3838120
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 3.339952230453491
Epoch: 73, Steps: 64 | Train Loss: 0.2777801 Vali Loss: 0.2751547 Test Loss: 0.3837947
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 3.1837775707244873
Epoch: 74, Steps: 64 | Train Loss: 0.2775339 Vali Loss: 0.2751231 Test Loss: 0.3837715
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 3.50840163230896
Epoch: 75, Steps: 64 | Train Loss: 0.2766565 Vali Loss: 0.2751102 Test Loss: 0.3837527
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 4.286792516708374
Epoch: 76, Steps: 64 | Train Loss: 0.2769153 Vali Loss: 0.2751547 Test Loss: 0.3837326
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 3.523764133453369
Epoch: 77, Steps: 64 | Train Loss: 0.2772871 Vali Loss: 0.2751344 Test Loss: 0.3837166
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 4.462430000305176
Epoch: 78, Steps: 64 | Train Loss: 0.2755379 Vali Loss: 0.2751246 Test Loss: 0.3837005
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 3.1223995685577393
Epoch: 79, Steps: 64 | Train Loss: 0.2771959 Vali Loss: 0.2750717 Test Loss: 0.3836845
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.8208587169647217
Epoch: 80, Steps: 64 | Train Loss: 0.2773422 Vali Loss: 0.2750365 Test Loss: 0.3836667
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.738234758377075
Epoch: 81, Steps: 64 | Train Loss: 0.2760600 Vali Loss: 0.2750229 Test Loss: 0.3836563
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 2.5040884017944336
Epoch: 82, Steps: 64 | Train Loss: 0.2768651 Vali Loss: 0.2750541 Test Loss: 0.3836421
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 3.0657124519348145
Epoch: 83, Steps: 64 | Train Loss: 0.2771255 Vali Loss: 0.2750556 Test Loss: 0.3836290
EarlyStopping counter: 20 out of 20
Early stopping
train 8269
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=50, out_features=103, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4614400.0
params:  5253.0
Trainable parameters:  5253
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.934544086456299
Epoch: 1, Steps: 64 | Train Loss: 0.5157648 Vali Loss: 0.2738433 Test Loss: 0.3822133
Validation loss decreased (inf --> 0.273843).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.378706216812134
Epoch: 2, Steps: 64 | Train Loss: 0.5172926 Vali Loss: 0.2732722 Test Loss: 0.3810764
Validation loss decreased (0.273843 --> 0.273272).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.7413439750671387
Epoch: 3, Steps: 64 | Train Loss: 0.5158613 Vali Loss: 0.2724992 Test Loss: 0.3805794
Validation loss decreased (0.273272 --> 0.272499).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.25840163230896
Epoch: 4, Steps: 64 | Train Loss: 0.5146990 Vali Loss: 0.2721622 Test Loss: 0.3800607
Validation loss decreased (0.272499 --> 0.272162).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.32840895652771
Epoch: 5, Steps: 64 | Train Loss: 0.5128353 Vali Loss: 0.2719961 Test Loss: 0.3796448
Validation loss decreased (0.272162 --> 0.271996).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.779367208480835
Epoch: 6, Steps: 64 | Train Loss: 0.5133681 Vali Loss: 0.2717341 Test Loss: 0.3794498
Validation loss decreased (0.271996 --> 0.271734).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.2520554065704346
Epoch: 7, Steps: 64 | Train Loss: 0.5114758 Vali Loss: 0.2714636 Test Loss: 0.3791938
Validation loss decreased (0.271734 --> 0.271464).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.9887516498565674
Epoch: 8, Steps: 64 | Train Loss: 0.5117676 Vali Loss: 0.2713808 Test Loss: 0.3789991
Validation loss decreased (0.271464 --> 0.271381).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.3405306339263916
Epoch: 9, Steps: 64 | Train Loss: 0.5141341 Vali Loss: 0.2712180 Test Loss: 0.3787741
Validation loss decreased (0.271381 --> 0.271218).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.8917601108551025
Epoch: 10, Steps: 64 | Train Loss: 0.5135046 Vali Loss: 0.2712767 Test Loss: 0.3786815
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.9492037296295166
Epoch: 11, Steps: 64 | Train Loss: 0.5139100 Vali Loss: 0.2712728 Test Loss: 0.3784728
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.367267370223999
Epoch: 12, Steps: 64 | Train Loss: 0.5102222 Vali Loss: 0.2711528 Test Loss: 0.3783333
Validation loss decreased (0.271218 --> 0.271153).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.6266305446624756
Epoch: 13, Steps: 64 | Train Loss: 0.5111452 Vali Loss: 0.2709637 Test Loss: 0.3782885
Validation loss decreased (0.271153 --> 0.270964).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.0780348777770996
Epoch: 14, Steps: 64 | Train Loss: 0.5126052 Vali Loss: 0.2708490 Test Loss: 0.3781746
Validation loss decreased (0.270964 --> 0.270849).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.37911319732666
Epoch: 15, Steps: 64 | Train Loss: 0.5128017 Vali Loss: 0.2709293 Test Loss: 0.3779837
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.3554165363311768
Epoch: 16, Steps: 64 | Train Loss: 0.5123566 Vali Loss: 0.2708898 Test Loss: 0.3779356
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.699429512023926
Epoch: 17, Steps: 64 | Train Loss: 0.5120470 Vali Loss: 0.2707864 Test Loss: 0.3779226
Validation loss decreased (0.270849 --> 0.270786).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.3136467933654785
Epoch: 18, Steps: 64 | Train Loss: 0.5111587 Vali Loss: 0.2707739 Test Loss: 0.3778750
Validation loss decreased (0.270786 --> 0.270774).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.791154384613037
Epoch: 19, Steps: 64 | Train Loss: 0.5123775 Vali Loss: 0.2707615 Test Loss: 0.3777773
Validation loss decreased (0.270774 --> 0.270762).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.339538097381592
Epoch: 20, Steps: 64 | Train Loss: 0.5112427 Vali Loss: 0.2706940 Test Loss: 0.3777275
Validation loss decreased (0.270762 --> 0.270694).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.702181577682495
Epoch: 21, Steps: 64 | Train Loss: 0.5117342 Vali Loss: 0.2706932 Test Loss: 0.3776904
Validation loss decreased (0.270694 --> 0.270693).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 4.902174234390259
Epoch: 22, Steps: 64 | Train Loss: 0.5113420 Vali Loss: 0.2705723 Test Loss: 0.3776273
Validation loss decreased (0.270693 --> 0.270572).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 4.314537525177002
Epoch: 23, Steps: 64 | Train Loss: 0.5106833 Vali Loss: 0.2706287 Test Loss: 0.3775352
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.2493386268615723
Epoch: 24, Steps: 64 | Train Loss: 0.5104370 Vali Loss: 0.2705637 Test Loss: 0.3775506
Validation loss decreased (0.270572 --> 0.270564).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 4.100613594055176
Epoch: 25, Steps: 64 | Train Loss: 0.5112339 Vali Loss: 0.2704961 Test Loss: 0.3775211
Validation loss decreased (0.270564 --> 0.270496).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.553415298461914
Epoch: 26, Steps: 64 | Train Loss: 0.5115513 Vali Loss: 0.2705106 Test Loss: 0.3774515
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 4.052395820617676
Epoch: 27, Steps: 64 | Train Loss: 0.5128201 Vali Loss: 0.2704841 Test Loss: 0.3774711
Validation loss decreased (0.270496 --> 0.270484).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.362902879714966
Epoch: 28, Steps: 64 | Train Loss: 0.5103247 Vali Loss: 0.2704347 Test Loss: 0.3774457
Validation loss decreased (0.270484 --> 0.270435).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.593079090118408
Epoch: 29, Steps: 64 | Train Loss: 0.5104963 Vali Loss: 0.2704530 Test Loss: 0.3773637
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.7488577365875244
Epoch: 30, Steps: 64 | Train Loss: 0.5123348 Vali Loss: 0.2705010 Test Loss: 0.3773267
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 3.126708507537842
Epoch: 31, Steps: 64 | Train Loss: 0.5102997 Vali Loss: 0.2704186 Test Loss: 0.3773356
Validation loss decreased (0.270435 --> 0.270419).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.521235227584839
Epoch: 32, Steps: 64 | Train Loss: 0.5117338 Vali Loss: 0.2703907 Test Loss: 0.3773359
Validation loss decreased (0.270419 --> 0.270391).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 3.042574167251587
Epoch: 33, Steps: 64 | Train Loss: 0.5119043 Vali Loss: 0.2704175 Test Loss: 0.3773019
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.3167567253112793
Epoch: 34, Steps: 64 | Train Loss: 0.5122138 Vali Loss: 0.2703831 Test Loss: 0.3773029
Validation loss decreased (0.270391 --> 0.270383).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 3.64748215675354
Epoch: 35, Steps: 64 | Train Loss: 0.5116849 Vali Loss: 0.2703587 Test Loss: 0.3772421
Validation loss decreased (0.270383 --> 0.270359).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 4.003753423690796
Epoch: 36, Steps: 64 | Train Loss: 0.5112457 Vali Loss: 0.2703348 Test Loss: 0.3772341
Validation loss decreased (0.270359 --> 0.270335).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 3.717097759246826
Epoch: 37, Steps: 64 | Train Loss: 0.5120161 Vali Loss: 0.2704152 Test Loss: 0.3772117
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.7931668758392334
Epoch: 38, Steps: 64 | Train Loss: 0.5107968 Vali Loss: 0.2703695 Test Loss: 0.3771945
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.407134532928467
Epoch: 39, Steps: 64 | Train Loss: 0.5124098 Vali Loss: 0.2702915 Test Loss: 0.3771903
Validation loss decreased (0.270335 --> 0.270292).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.428480863571167
Epoch: 40, Steps: 64 | Train Loss: 0.5092081 Vali Loss: 0.2703737 Test Loss: 0.3771420
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.680903673171997
Epoch: 41, Steps: 64 | Train Loss: 0.5102385 Vali Loss: 0.2703205 Test Loss: 0.3771297
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.0193562507629395
Epoch: 42, Steps: 64 | Train Loss: 0.5121679 Vali Loss: 0.2702992 Test Loss: 0.3771209
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.4279263019561768
Epoch: 43, Steps: 64 | Train Loss: 0.5110827 Vali Loss: 0.2703590 Test Loss: 0.3771257
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.424161434173584
Epoch: 44, Steps: 64 | Train Loss: 0.5112273 Vali Loss: 0.2703574 Test Loss: 0.3771058
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.3044238090515137
Epoch: 45, Steps: 64 | Train Loss: 0.5102428 Vali Loss: 0.2703183 Test Loss: 0.3771096
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 3.0467371940612793
Epoch: 46, Steps: 64 | Train Loss: 0.5090994 Vali Loss: 0.2702644 Test Loss: 0.3770784
Validation loss decreased (0.270292 --> 0.270264).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.9532852172851562
Epoch: 47, Steps: 64 | Train Loss: 0.5122661 Vali Loss: 0.2703173 Test Loss: 0.3770753
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.818531036376953
Epoch: 48, Steps: 64 | Train Loss: 0.5108839 Vali Loss: 0.2702379 Test Loss: 0.3770530
Validation loss decreased (0.270264 --> 0.270238).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 3.6017565727233887
Epoch: 49, Steps: 64 | Train Loss: 0.5103346 Vali Loss: 0.2702878 Test Loss: 0.3770704
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.969252347946167
Epoch: 50, Steps: 64 | Train Loss: 0.5105758 Vali Loss: 0.2703326 Test Loss: 0.3770438
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 3.6292383670806885
Epoch: 51, Steps: 64 | Train Loss: 0.5109367 Vali Loss: 0.2702699 Test Loss: 0.3770281
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.8805878162384033
Epoch: 52, Steps: 64 | Train Loss: 0.5122442 Vali Loss: 0.2702329 Test Loss: 0.3770432
Validation loss decreased (0.270238 --> 0.270233).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.365358591079712
Epoch: 53, Steps: 64 | Train Loss: 0.5115090 Vali Loss: 0.2702681 Test Loss: 0.3770254
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.9786269664764404
Epoch: 54, Steps: 64 | Train Loss: 0.5110219 Vali Loss: 0.2702401 Test Loss: 0.3770174
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 3.0667359828948975
Epoch: 55, Steps: 64 | Train Loss: 0.5108185 Vali Loss: 0.2702180 Test Loss: 0.3770140
Validation loss decreased (0.270233 --> 0.270218).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.767592191696167
Epoch: 56, Steps: 64 | Train Loss: 0.5115252 Vali Loss: 0.2702328 Test Loss: 0.3770075
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.8757271766662598
Epoch: 57, Steps: 64 | Train Loss: 0.5090892 Vali Loss: 0.2702571 Test Loss: 0.3770100
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 3.728419780731201
Epoch: 58, Steps: 64 | Train Loss: 0.5110827 Vali Loss: 0.2702310 Test Loss: 0.3769984
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 4.391148090362549
Epoch: 59, Steps: 64 | Train Loss: 0.5097106 Vali Loss: 0.2702595 Test Loss: 0.3770044
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 4.992767333984375
Epoch: 60, Steps: 64 | Train Loss: 0.5117621 Vali Loss: 0.2702252 Test Loss: 0.3769917
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 4.54557466506958
Epoch: 61, Steps: 64 | Train Loss: 0.5097545 Vali Loss: 0.2700441 Test Loss: 0.3769747
Validation loss decreased (0.270218 --> 0.270044).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 3.6581003665924072
Epoch: 62, Steps: 64 | Train Loss: 0.5118062 Vali Loss: 0.2699931 Test Loss: 0.3769771
Validation loss decreased (0.270044 --> 0.269993).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 3.2865724563598633
Epoch: 63, Steps: 64 | Train Loss: 0.5108200 Vali Loss: 0.2702381 Test Loss: 0.3769755
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 3.7165467739105225
Epoch: 64, Steps: 64 | Train Loss: 0.5108243 Vali Loss: 0.2702657 Test Loss: 0.3769698
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.813279390335083
Epoch: 65, Steps: 64 | Train Loss: 0.5111120 Vali Loss: 0.2702856 Test Loss: 0.3769619
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.2697837352752686
Epoch: 66, Steps: 64 | Train Loss: 0.5096486 Vali Loss: 0.2702748 Test Loss: 0.3769686
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.2906317710876465
Epoch: 67, Steps: 64 | Train Loss: 0.5122078 Vali Loss: 0.2702681 Test Loss: 0.3769675
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.6469638347625732
Epoch: 68, Steps: 64 | Train Loss: 0.5087037 Vali Loss: 0.2702234 Test Loss: 0.3769590
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 3.0349628925323486
Epoch: 69, Steps: 64 | Train Loss: 0.5106012 Vali Loss: 0.2702111 Test Loss: 0.3769594
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.3753883838653564
Epoch: 70, Steps: 64 | Train Loss: 0.5102148 Vali Loss: 0.2702231 Test Loss: 0.3769586
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 3.9230220317840576
Epoch: 71, Steps: 64 | Train Loss: 0.5103980 Vali Loss: 0.2702150 Test Loss: 0.3769590
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.2464637756347656
Epoch: 72, Steps: 64 | Train Loss: 0.5108810 Vali Loss: 0.2702313 Test Loss: 0.3769505
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 3.801699638366699
Epoch: 73, Steps: 64 | Train Loss: 0.5123872 Vali Loss: 0.2698284 Test Loss: 0.3769506
Validation loss decreased (0.269993 --> 0.269828).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 3.4803566932678223
Epoch: 74, Steps: 64 | Train Loss: 0.5115614 Vali Loss: 0.2701885 Test Loss: 0.3769446
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 3.3922805786132812
Epoch: 75, Steps: 64 | Train Loss: 0.5106461 Vali Loss: 0.2701653 Test Loss: 0.3769418
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 3.6016697883605957
Epoch: 76, Steps: 64 | Train Loss: 0.5117438 Vali Loss: 0.2702563 Test Loss: 0.3769457
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.3548974990844727
Epoch: 77, Steps: 64 | Train Loss: 0.5096965 Vali Loss: 0.2701969 Test Loss: 0.3769436
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.9681439399719238
Epoch: 78, Steps: 64 | Train Loss: 0.5114608 Vali Loss: 0.2702350 Test Loss: 0.3769422
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.184664011001587
Epoch: 79, Steps: 64 | Train Loss: 0.5086725 Vali Loss: 0.2702437 Test Loss: 0.3769386
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.32407546043396
Epoch: 80, Steps: 64 | Train Loss: 0.5094703 Vali Loss: 0.2702163 Test Loss: 0.3769448
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.846097946166992
Epoch: 81, Steps: 64 | Train Loss: 0.5109321 Vali Loss: 0.2702254 Test Loss: 0.3769393
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 2.930816650390625
Epoch: 82, Steps: 64 | Train Loss: 0.5095152 Vali Loss: 0.2702521 Test Loss: 0.3769367
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.24949049949646
Epoch: 83, Steps: 64 | Train Loss: 0.5107356 Vali Loss: 0.2702065 Test Loss: 0.3769364
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.6284165382385254
Epoch: 84, Steps: 64 | Train Loss: 0.5093599 Vali Loss: 0.2701319 Test Loss: 0.3769319
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 3.5090386867523193
Epoch: 85, Steps: 64 | Train Loss: 0.5097702 Vali Loss: 0.2702489 Test Loss: 0.3769322
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 4.0361738204956055
Epoch: 86, Steps: 64 | Train Loss: 0.5108321 Vali Loss: 0.2701507 Test Loss: 0.3769321
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 3.7723097801208496
Epoch: 87, Steps: 64 | Train Loss: 0.5122012 Vali Loss: 0.2702215 Test Loss: 0.3769308
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 3.4262633323669434
Epoch: 88, Steps: 64 | Train Loss: 0.5116574 Vali Loss: 0.2701871 Test Loss: 0.3769286
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 3.036729335784912
Epoch: 89, Steps: 64 | Train Loss: 0.5102890 Vali Loss: 0.2702139 Test Loss: 0.3769278
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 3.262882947921753
Epoch: 90, Steps: 64 | Train Loss: 0.5125193 Vali Loss: 0.2698407 Test Loss: 0.3769279
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.3274457454681396
Epoch: 91, Steps: 64 | Train Loss: 0.5100591 Vali Loss: 0.2702000 Test Loss: 0.3769259
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 2.5244808197021484
Epoch: 92, Steps: 64 | Train Loss: 0.5112613 Vali Loss: 0.2698353 Test Loss: 0.3769261
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 2.717796802520752
Epoch: 93, Steps: 64 | Train Loss: 0.5083183 Vali Loss: 0.2702177 Test Loss: 0.3769237
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_180_192_FITS_ETTh2_ftM_sl180_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.3575326204299927, mae:0.38565564155578613, rse:0.4795111417770386, corr:[0.26714197 0.2697452  0.26799408 0.26811603 0.26739767 0.26560488
 0.264826   0.2642953  0.26323253 0.2618829  0.26098326 0.25958034
 0.25793093 0.25644276 0.2557593  0.25543293 0.25494632 0.25427034
 0.25350586 0.25237185 0.25094882 0.24993438 0.24901462 0.24695331
 0.24380048 0.24150342 0.23970428 0.23775172 0.23576339 0.2344119
 0.23284414 0.23063198 0.22878294 0.22746134 0.2260433  0.22440828
 0.22322454 0.22189422 0.22067712 0.21960294 0.2190772  0.2183748
 0.21750943 0.21647768 0.21531631 0.21401641 0.21277751 0.21100529
 0.20792407 0.20534238 0.20354854 0.20175794 0.19944112 0.19754863
 0.19562769 0.19317062 0.19121878 0.18996546 0.18910623 0.18770266
 0.18692201 0.18640016 0.1863286  0.18565969 0.1850984  0.18465744
 0.18378505 0.18264364 0.18218629 0.18187845 0.18076171 0.17949411
 0.17766505 0.17610668 0.17476948 0.17365319 0.17239872 0.17161424
 0.17111854 0.17053293 0.17019166 0.16984765 0.17001024 0.17005464
 0.16984527 0.16945766 0.16972822 0.16959639 0.16882412 0.1681311
 0.16807896 0.16764791 0.16722584 0.16730364 0.16730045 0.16661486
 0.16494781 0.1638989  0.16272816 0.16154517 0.1605806  0.15999672
 0.15931414 0.15860283 0.15874466 0.1588302  0.15878136 0.15872608
 0.15911286 0.15872754 0.15792638 0.1573248  0.15705584 0.15648304
 0.15593535 0.15547921 0.1549552  0.15424713 0.15323737 0.15184249
 0.14956978 0.14753202 0.14617187 0.1451391  0.14356442 0.14218597
 0.14146514 0.14058211 0.13959259 0.13903184 0.13884987 0.13821214
 0.1377544  0.13735032 0.13724302 0.13676786 0.13617349 0.1355494
 0.13512556 0.1346054  0.13426238 0.13416135 0.13344954 0.13197938
 0.12924853 0.1273763  0.12571381 0.12439885 0.12314852 0.1223282
 0.12209802 0.12163365 0.12119231 0.12101621 0.12158187 0.12195928
 0.12253141 0.12234504 0.12249398 0.1228212  0.12261304 0.12192934
 0.12184053 0.12200133 0.12146121 0.12120745 0.12149382 0.12081697
 0.11807866 0.11657715 0.11574883 0.11503945 0.11377312 0.1124483
 0.11166766 0.11079632 0.11037023 0.10984169 0.10980324 0.10979784
 0.11031858 0.10977142 0.10904248 0.10903256 0.10876007 0.1066582
 0.10533401 0.10550961 0.10570899 0.104531   0.10463674 0.10766844]
