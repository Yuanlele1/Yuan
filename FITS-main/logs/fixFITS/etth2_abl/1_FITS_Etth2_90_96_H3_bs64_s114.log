Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=22, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_90_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_90_96_FITS_ETTh2_ftM_sl90_ll48_pl96_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8455
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=22, out_features=45, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  887040.0
params:  1035.0
Trainable parameters:  1035
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.4685113430023193
Epoch: 1, Steps: 66 | Train Loss: 0.5962055 Vali Loss: 0.2888372 Test Loss: 0.3856392
Validation loss decreased (inf --> 0.288837).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.475919485092163
Epoch: 2, Steps: 66 | Train Loss: 0.5256775 Vali Loss: 0.2610156 Test Loss: 0.3488717
Validation loss decreased (0.288837 --> 0.261016).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.2595343589782715
Epoch: 3, Steps: 66 | Train Loss: 0.4922986 Vali Loss: 0.2466548 Test Loss: 0.3303593
Validation loss decreased (0.261016 --> 0.246655).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.3614704608917236
Epoch: 4, Steps: 66 | Train Loss: 0.4745321 Vali Loss: 0.2377764 Test Loss: 0.3201675
Validation loss decreased (0.246655 --> 0.237776).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.5508184432983398
Epoch: 5, Steps: 66 | Train Loss: 0.4629189 Vali Loss: 0.2334758 Test Loss: 0.3139513
Validation loss decreased (0.237776 --> 0.233476).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.8025405406951904
Epoch: 6, Steps: 66 | Train Loss: 0.4573500 Vali Loss: 0.2293689 Test Loss: 0.3097904
Validation loss decreased (0.233476 --> 0.229369).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.294198989868164
Epoch: 7, Steps: 66 | Train Loss: 0.4524455 Vali Loss: 0.2276214 Test Loss: 0.3068591
Validation loss decreased (0.229369 --> 0.227621).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.324963092803955
Epoch: 8, Steps: 66 | Train Loss: 0.4480868 Vali Loss: 0.2259004 Test Loss: 0.3046426
Validation loss decreased (0.227621 --> 0.225900).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.638796091079712
Epoch: 9, Steps: 66 | Train Loss: 0.4456509 Vali Loss: 0.2247321 Test Loss: 0.3029849
Validation loss decreased (0.225900 --> 0.224732).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.521599292755127
Epoch: 10, Steps: 66 | Train Loss: 0.4433052 Vali Loss: 0.2219067 Test Loss: 0.3016951
Validation loss decreased (0.224732 --> 0.221907).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.4783620834350586
Epoch: 11, Steps: 66 | Train Loss: 0.4406418 Vali Loss: 0.2221216 Test Loss: 0.3005825
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.4170951843261719
Epoch: 12, Steps: 66 | Train Loss: 0.4399586 Vali Loss: 0.2202103 Test Loss: 0.2997059
Validation loss decreased (0.221907 --> 0.220210).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.6284806728363037
Epoch: 13, Steps: 66 | Train Loss: 0.4383505 Vali Loss: 0.2199669 Test Loss: 0.2989375
Validation loss decreased (0.220210 --> 0.219967).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.4765844345092773
Epoch: 14, Steps: 66 | Train Loss: 0.4371763 Vali Loss: 0.2201537 Test Loss: 0.2983284
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.6096255779266357
Epoch: 15, Steps: 66 | Train Loss: 0.4362585 Vali Loss: 0.2196267 Test Loss: 0.2977260
Validation loss decreased (0.219967 --> 0.219627).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.7307674884796143
Epoch: 16, Steps: 66 | Train Loss: 0.4353905 Vali Loss: 0.2197925 Test Loss: 0.2972681
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.6451389789581299
Epoch: 17, Steps: 66 | Train Loss: 0.4344982 Vali Loss: 0.2184869 Test Loss: 0.2968653
Validation loss decreased (0.219627 --> 0.218487).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.5245370864868164
Epoch: 18, Steps: 66 | Train Loss: 0.4337813 Vali Loss: 0.2177787 Test Loss: 0.2964914
Validation loss decreased (0.218487 --> 0.217779).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.561565637588501
Epoch: 19, Steps: 66 | Train Loss: 0.4329447 Vali Loss: 0.2170568 Test Loss: 0.2961584
Validation loss decreased (0.217779 --> 0.217057).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.1720945835113525
Epoch: 20, Steps: 66 | Train Loss: 0.4324691 Vali Loss: 0.2173673 Test Loss: 0.2958806
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.869140625
Epoch: 21, Steps: 66 | Train Loss: 0.4320130 Vali Loss: 0.2174609 Test Loss: 0.2956301
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.32881236076355
Epoch: 22, Steps: 66 | Train Loss: 0.4312918 Vali Loss: 0.2173035 Test Loss: 0.2953748
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.6609580516815186
Epoch: 23, Steps: 66 | Train Loss: 0.4310787 Vali Loss: 0.2172641 Test Loss: 0.2951727
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.5213816165924072
Epoch: 24, Steps: 66 | Train Loss: 0.4293092 Vali Loss: 0.2158857 Test Loss: 0.2949873
Validation loss decreased (0.217057 --> 0.215886).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.5370657444000244
Epoch: 25, Steps: 66 | Train Loss: 0.4303586 Vali Loss: 0.2172316 Test Loss: 0.2948202
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.7977697849273682
Epoch: 26, Steps: 66 | Train Loss: 0.4300002 Vali Loss: 0.2153613 Test Loss: 0.2946659
Validation loss decreased (0.215886 --> 0.215361).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.8321113586425781
Epoch: 27, Steps: 66 | Train Loss: 0.4295275 Vali Loss: 0.2171049 Test Loss: 0.2945335
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.3862888813018799
Epoch: 28, Steps: 66 | Train Loss: 0.4292741 Vali Loss: 0.2151470 Test Loss: 0.2943802
Validation loss decreased (0.215361 --> 0.215147).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.5852508544921875
Epoch: 29, Steps: 66 | Train Loss: 0.4288675 Vali Loss: 0.2171750 Test Loss: 0.2942865
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.5903937816619873
Epoch: 30, Steps: 66 | Train Loss: 0.4288870 Vali Loss: 0.2159900 Test Loss: 0.2941808
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.6832084655761719
Epoch: 31, Steps: 66 | Train Loss: 0.4283419 Vali Loss: 0.2161034 Test Loss: 0.2940811
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.7861313819885254
Epoch: 32, Steps: 66 | Train Loss: 0.4283323 Vali Loss: 0.2158510 Test Loss: 0.2939783
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.4024343490600586
Epoch: 33, Steps: 66 | Train Loss: 0.4263714 Vali Loss: 0.2148898 Test Loss: 0.2939021
Validation loss decreased (0.215147 --> 0.214890).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.64052152633667
Epoch: 34, Steps: 66 | Train Loss: 0.4280691 Vali Loss: 0.2160699 Test Loss: 0.2938330
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.721787929534912
Epoch: 35, Steps: 66 | Train Loss: 0.4279519 Vali Loss: 0.2151125 Test Loss: 0.2937479
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.880077838897705
Epoch: 36, Steps: 66 | Train Loss: 0.4277086 Vali Loss: 0.2163378 Test Loss: 0.2936825
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.7650153636932373
Epoch: 37, Steps: 66 | Train Loss: 0.4271317 Vali Loss: 0.2152740 Test Loss: 0.2936220
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.6581509113311768
Epoch: 38, Steps: 66 | Train Loss: 0.4274854 Vali Loss: 0.2162938 Test Loss: 0.2935800
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.566279411315918
Epoch: 39, Steps: 66 | Train Loss: 0.4271599 Vali Loss: 0.2152853 Test Loss: 0.2935242
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.6283438205718994
Epoch: 40, Steps: 66 | Train Loss: 0.4272604 Vali Loss: 0.2152417 Test Loss: 0.2934688
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.379601240158081
Epoch: 41, Steps: 66 | Train Loss: 0.4259280 Vali Loss: 0.2157017 Test Loss: 0.2934217
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.5548124313354492
Epoch: 42, Steps: 66 | Train Loss: 0.4268995 Vali Loss: 0.2147992 Test Loss: 0.2933891
Validation loss decreased (0.214890 --> 0.214799).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.5947437286376953
Epoch: 43, Steps: 66 | Train Loss: 0.4268548 Vali Loss: 0.2157580 Test Loss: 0.2933417
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.8533380031585693
Epoch: 44, Steps: 66 | Train Loss: 0.4265960 Vali Loss: 0.2155713 Test Loss: 0.2933090
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.527989387512207
Epoch: 45, Steps: 66 | Train Loss: 0.4263056 Vali Loss: 0.2160896 Test Loss: 0.2932664
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.401454210281372
Epoch: 46, Steps: 66 | Train Loss: 0.4262920 Vali Loss: 0.2148690 Test Loss: 0.2932339
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.4329376220703125
Epoch: 47, Steps: 66 | Train Loss: 0.4265546 Vali Loss: 0.2140893 Test Loss: 0.2932014
Validation loss decreased (0.214799 --> 0.214089).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.6565144062042236
Epoch: 48, Steps: 66 | Train Loss: 0.4262734 Vali Loss: 0.2145811 Test Loss: 0.2931708
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.7179572582244873
Epoch: 49, Steps: 66 | Train Loss: 0.4263426 Vali Loss: 0.2148999 Test Loss: 0.2931403
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.813462734222412
Epoch: 50, Steps: 66 | Train Loss: 0.4253478 Vali Loss: 0.2138649 Test Loss: 0.2931188
Validation loss decreased (0.214089 --> 0.213865).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.436607837677002
Epoch: 51, Steps: 66 | Train Loss: 0.4261893 Vali Loss: 0.2141561 Test Loss: 0.2930942
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.857844591140747
Epoch: 52, Steps: 66 | Train Loss: 0.4262539 Vali Loss: 0.2136023 Test Loss: 0.2930703
Validation loss decreased (0.213865 --> 0.213602).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.9821057319641113
Epoch: 53, Steps: 66 | Train Loss: 0.4260010 Vali Loss: 0.2146056 Test Loss: 0.2930552
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.35024094581604
Epoch: 54, Steps: 66 | Train Loss: 0.4254788 Vali Loss: 0.2137163 Test Loss: 0.2930330
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.8838393688201904
Epoch: 55, Steps: 66 | Train Loss: 0.4257135 Vali Loss: 0.2140741 Test Loss: 0.2930120
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.783186435699463
Epoch: 56, Steps: 66 | Train Loss: 0.4259695 Vali Loss: 0.2144965 Test Loss: 0.2929944
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.5355801582336426
Epoch: 57, Steps: 66 | Train Loss: 0.4259267 Vali Loss: 0.2151596 Test Loss: 0.2929778
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.2987697124481201
Epoch: 58, Steps: 66 | Train Loss: 0.4259519 Vali Loss: 0.2148080 Test Loss: 0.2929608
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.5970494747161865
Epoch: 59, Steps: 66 | Train Loss: 0.4258989 Vali Loss: 0.2152544 Test Loss: 0.2929453
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.6264896392822266
Epoch: 60, Steps: 66 | Train Loss: 0.4258633 Vali Loss: 0.2146017 Test Loss: 0.2929284
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.4559810161590576
Epoch: 61, Steps: 66 | Train Loss: 0.4258354 Vali Loss: 0.2142784 Test Loss: 0.2929186
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.069662570953369
Epoch: 62, Steps: 66 | Train Loss: 0.4255676 Vali Loss: 0.2145842 Test Loss: 0.2929062
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.001251459121704
Epoch: 63, Steps: 66 | Train Loss: 0.4257631 Vali Loss: 0.2146376 Test Loss: 0.2928932
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.3157525062561035
Epoch: 64, Steps: 66 | Train Loss: 0.4257973 Vali Loss: 0.2147454 Test Loss: 0.2928847
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.4509329795837402
Epoch: 65, Steps: 66 | Train Loss: 0.4257472 Vali Loss: 0.2143625 Test Loss: 0.2928689
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.6325914859771729
Epoch: 66, Steps: 66 | Train Loss: 0.4255828 Vali Loss: 0.2154167 Test Loss: 0.2928636
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.681849718093872
Epoch: 67, Steps: 66 | Train Loss: 0.4254699 Vali Loss: 0.2149523 Test Loss: 0.2928505
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.6021151542663574
Epoch: 68, Steps: 66 | Train Loss: 0.4256979 Vali Loss: 0.2146608 Test Loss: 0.2928412
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.8347649574279785
Epoch: 69, Steps: 66 | Train Loss: 0.4244746 Vali Loss: 0.2139639 Test Loss: 0.2928350
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.086406707763672
Epoch: 70, Steps: 66 | Train Loss: 0.4256473 Vali Loss: 0.2134957 Test Loss: 0.2928279
Validation loss decreased (0.213602 --> 0.213496).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.7365729808807373
Epoch: 71, Steps: 66 | Train Loss: 0.4253181 Vali Loss: 0.2150127 Test Loss: 0.2928196
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.574568510055542
Epoch: 72, Steps: 66 | Train Loss: 0.4254633 Vali Loss: 0.2149337 Test Loss: 0.2928126
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.467588186264038
Epoch: 73, Steps: 66 | Train Loss: 0.4255863 Vali Loss: 0.2149835 Test Loss: 0.2928034
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.8642423152923584
Epoch: 74, Steps: 66 | Train Loss: 0.4252476 Vali Loss: 0.2148919 Test Loss: 0.2927992
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.8812859058380127
Epoch: 75, Steps: 66 | Train Loss: 0.4253306 Vali Loss: 0.2152896 Test Loss: 0.2927921
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.4558629989624023
Epoch: 76, Steps: 66 | Train Loss: 0.4251443 Vali Loss: 0.2144926 Test Loss: 0.2927870
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.5205118656158447
Epoch: 77, Steps: 66 | Train Loss: 0.4254283 Vali Loss: 0.2148740 Test Loss: 0.2927824
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.4214770793914795
Epoch: 78, Steps: 66 | Train Loss: 0.4255635 Vali Loss: 0.2144260 Test Loss: 0.2927758
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.5275547504425049
Epoch: 79, Steps: 66 | Train Loss: 0.4254568 Vali Loss: 0.2142907 Test Loss: 0.2927720
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.6293411254882812
Epoch: 80, Steps: 66 | Train Loss: 0.4250840 Vali Loss: 0.2144573 Test Loss: 0.2927671
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.376542329788208
Epoch: 81, Steps: 66 | Train Loss: 0.4254332 Vali Loss: 0.2152590 Test Loss: 0.2927618
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.661919355392456
Epoch: 82, Steps: 66 | Train Loss: 0.4254179 Vali Loss: 0.2148501 Test Loss: 0.2927591
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.6802101135253906
Epoch: 83, Steps: 66 | Train Loss: 0.4254509 Vali Loss: 0.2141221 Test Loss: 0.2927539
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.3899009227752686
Epoch: 84, Steps: 66 | Train Loss: 0.4253503 Vali Loss: 0.2144426 Test Loss: 0.2927502
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.4795136451721191
Epoch: 85, Steps: 66 | Train Loss: 0.4254447 Vali Loss: 0.2143906 Test Loss: 0.2927473
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.3799808025360107
Epoch: 86, Steps: 66 | Train Loss: 0.4253235 Vali Loss: 0.2141924 Test Loss: 0.2927442
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.6991760730743408
Epoch: 87, Steps: 66 | Train Loss: 0.4252357 Vali Loss: 0.2147713 Test Loss: 0.2927401
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.713097095489502
Epoch: 88, Steps: 66 | Train Loss: 0.4252908 Vali Loss: 0.2140667 Test Loss: 0.2927380
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.9300403594970703
Epoch: 89, Steps: 66 | Train Loss: 0.4242399 Vali Loss: 0.2147129 Test Loss: 0.2927344
EarlyStopping counter: 19 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.5016636848449707
Epoch: 90, Steps: 66 | Train Loss: 0.4251534 Vali Loss: 0.2133982 Test Loss: 0.2927310
Validation loss decreased (0.213496 --> 0.213398).  Saving model ...
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.5912234783172607
Epoch: 91, Steps: 66 | Train Loss: 0.4253287 Vali Loss: 0.2133036 Test Loss: 0.2927293
Validation loss decreased (0.213398 --> 0.213304).  Saving model ...
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.8395373821258545
Epoch: 92, Steps: 66 | Train Loss: 0.4253172 Vali Loss: 0.2135013 Test Loss: 0.2927267
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.7895948886871338
Epoch: 93, Steps: 66 | Train Loss: 0.4250936 Vali Loss: 0.2139964 Test Loss: 0.2927237
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.4377970695495605
Epoch: 94, Steps: 66 | Train Loss: 0.4242088 Vali Loss: 0.2147946 Test Loss: 0.2927219
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.632370948791504
Epoch: 95, Steps: 66 | Train Loss: 0.4251508 Vali Loss: 0.2137674 Test Loss: 0.2927200
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.863394021987915
Epoch: 96, Steps: 66 | Train Loss: 0.4253801 Vali Loss: 0.2137324 Test Loss: 0.2927175
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.9960570335388184
Epoch: 97, Steps: 66 | Train Loss: 0.4251068 Vali Loss: 0.2143997 Test Loss: 0.2927153
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.7337279319763184
Epoch: 98, Steps: 66 | Train Loss: 0.4250592 Vali Loss: 0.2145587 Test Loss: 0.2927136
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.6706788539886475
Epoch: 99, Steps: 66 | Train Loss: 0.4241701 Vali Loss: 0.2144413 Test Loss: 0.2927115
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.7225935459136963
Epoch: 100, Steps: 66 | Train Loss: 0.4251953 Vali Loss: 0.2138397 Test Loss: 0.2927105
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.1160680107021042e-06
>>>>>>>testing : ETTh2_90_96_FITS_ETTh2_ftM_sl90_ll48_pl96_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.29324230551719666, mae:0.34071972966194153, rse:0.43640992045402527, corr:[0.27369657 0.27850994 0.275278   0.27380502 0.27403632 0.27285343
 0.2709877  0.27020392 0.2698604  0.2687318  0.2671361  0.2656428
 0.26422635 0.26293835 0.26188275 0.26133516 0.26081774 0.26007903
 0.25911978 0.2580887  0.2570941  0.25604466 0.2546362  0.252497
 0.24943517 0.24695049 0.24496038 0.2433675  0.24185666 0.24047998
 0.2394958  0.23806056 0.23646776 0.2352413  0.2345113  0.23332657
 0.23162583 0.23040807 0.2297495  0.22903042 0.22820227 0.22768423
 0.22752498 0.22676413 0.22563553 0.22464125 0.22375558 0.22187407
 0.21830383 0.21531919 0.21331784 0.21167943 0.20968737 0.20767933
 0.2064569  0.20474344 0.20301881 0.20143346 0.20085432 0.20015757
 0.19878477 0.19815493 0.19854811 0.19889845 0.19819807 0.19720255
 0.19705003 0.19699512 0.19626154 0.1950352  0.19405442 0.19310342
 0.19060166 0.18831268 0.18701874 0.18667895 0.18579158 0.18457843
 0.18418318 0.18368411 0.18333825 0.18265553 0.18248676 0.18260598
 0.18179335 0.18087612 0.18118145 0.18222125 0.18129113 0.1791589
 0.17909561 0.17988388 0.17802665 0.17524229 0.17861755 0.17879719]
