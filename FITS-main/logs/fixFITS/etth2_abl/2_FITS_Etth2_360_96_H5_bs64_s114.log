Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_360_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_360_96_FITS_ETTh2_ftM_sl360_ll48_pl96_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8185
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=90, out_features=114, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  9192960.0
params:  10374.0
Trainable parameters:  10374
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.8497276306152344
Epoch: 1, Steps: 63 | Train Loss: 0.4975956 Vali Loss: 0.3508296 Test Loss: 0.4153589
Validation loss decreased (inf --> 0.350830).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.2894983291625977
Epoch: 2, Steps: 63 | Train Loss: 0.3939621 Vali Loss: 0.3123358 Test Loss: 0.3779916
Validation loss decreased (0.350830 --> 0.312336).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.5777642726898193
Epoch: 3, Steps: 63 | Train Loss: 0.3354929 Vali Loss: 0.2896564 Test Loss: 0.3591917
Validation loss decreased (0.312336 --> 0.289656).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.8747127056121826
Epoch: 4, Steps: 63 | Train Loss: 0.2976502 Vali Loss: 0.2784068 Test Loss: 0.3491811
Validation loss decreased (0.289656 --> 0.278407).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 4.670499801635742
Epoch: 5, Steps: 63 | Train Loss: 0.2709826 Vali Loss: 0.2697135 Test Loss: 0.3425201
Validation loss decreased (0.278407 --> 0.269713).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.910442352294922
Epoch: 6, Steps: 63 | Train Loss: 0.2508801 Vali Loss: 0.2645692 Test Loss: 0.3381713
Validation loss decreased (0.269713 --> 0.264569).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.724169969558716
Epoch: 7, Steps: 63 | Train Loss: 0.2352786 Vali Loss: 0.2609943 Test Loss: 0.3346361
Validation loss decreased (0.264569 --> 0.260994).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.925441265106201
Epoch: 8, Steps: 63 | Train Loss: 0.2232105 Vali Loss: 0.2586925 Test Loss: 0.3316563
Validation loss decreased (0.260994 --> 0.258692).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 4.650149822235107
Epoch: 9, Steps: 63 | Train Loss: 0.2122455 Vali Loss: 0.2551006 Test Loss: 0.3290094
Validation loss decreased (0.258692 --> 0.255101).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.695988893508911
Epoch: 10, Steps: 63 | Train Loss: 0.2029674 Vali Loss: 0.2518480 Test Loss: 0.3265858
Validation loss decreased (0.255101 --> 0.251848).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.0577785968780518
Epoch: 11, Steps: 63 | Train Loss: 0.1936849 Vali Loss: 0.2500589 Test Loss: 0.3243556
Validation loss decreased (0.251848 --> 0.250059).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.790729284286499
Epoch: 12, Steps: 63 | Train Loss: 0.1872490 Vali Loss: 0.2470886 Test Loss: 0.3220690
Validation loss decreased (0.250059 --> 0.247089).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.470694065093994
Epoch: 13, Steps: 63 | Train Loss: 0.1808634 Vali Loss: 0.2471172 Test Loss: 0.3201270
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.758845090866089
Epoch: 14, Steps: 63 | Train Loss: 0.1758724 Vali Loss: 0.2448989 Test Loss: 0.3183079
Validation loss decreased (0.247089 --> 0.244899).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.0372748374938965
Epoch: 15, Steps: 63 | Train Loss: 0.1708452 Vali Loss: 0.2441059 Test Loss: 0.3165466
Validation loss decreased (0.244899 --> 0.244106).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.6214022636413574
Epoch: 16, Steps: 63 | Train Loss: 0.1666208 Vali Loss: 0.2426760 Test Loss: 0.3149256
Validation loss decreased (0.244106 --> 0.242676).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.977583885192871
Epoch: 17, Steps: 63 | Train Loss: 0.1621890 Vali Loss: 0.2415503 Test Loss: 0.3134385
Validation loss decreased (0.242676 --> 0.241550).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 4.833019733428955
Epoch: 18, Steps: 63 | Train Loss: 0.1591810 Vali Loss: 0.2396945 Test Loss: 0.3119116
Validation loss decreased (0.241550 --> 0.239695).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 4.06141209602356
Epoch: 19, Steps: 63 | Train Loss: 0.1555655 Vali Loss: 0.2386672 Test Loss: 0.3106612
Validation loss decreased (0.239695 --> 0.238667).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.870798110961914
Epoch: 20, Steps: 63 | Train Loss: 0.1527485 Vali Loss: 0.2379604 Test Loss: 0.3093817
Validation loss decreased (0.238667 --> 0.237960).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.3466930389404297
Epoch: 21, Steps: 63 | Train Loss: 0.1502486 Vali Loss: 0.2368082 Test Loss: 0.3081578
Validation loss decreased (0.237960 --> 0.236808).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.293642282485962
Epoch: 22, Steps: 63 | Train Loss: 0.1473007 Vali Loss: 0.2366633 Test Loss: 0.3069469
Validation loss decreased (0.236808 --> 0.236663).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.421412229537964
Epoch: 23, Steps: 63 | Train Loss: 0.1450546 Vali Loss: 0.2362789 Test Loss: 0.3059985
Validation loss decreased (0.236663 --> 0.236279).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.3077621459960938
Epoch: 24, Steps: 63 | Train Loss: 0.1432819 Vali Loss: 0.2345547 Test Loss: 0.3049870
Validation loss decreased (0.236279 --> 0.234555).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 3.449406385421753
Epoch: 25, Steps: 63 | Train Loss: 0.1408733 Vali Loss: 0.2339994 Test Loss: 0.3040414
Validation loss decreased (0.234555 --> 0.233999).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.901054620742798
Epoch: 26, Steps: 63 | Train Loss: 0.1398826 Vali Loss: 0.2337367 Test Loss: 0.3031365
Validation loss decreased (0.233999 --> 0.233737).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.333498001098633
Epoch: 27, Steps: 63 | Train Loss: 0.1384627 Vali Loss: 0.2332505 Test Loss: 0.3023847
Validation loss decreased (0.233737 --> 0.233251).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 4.017183065414429
Epoch: 28, Steps: 63 | Train Loss: 0.1360888 Vali Loss: 0.2326079 Test Loss: 0.3015949
Validation loss decreased (0.233251 --> 0.232608).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 4.546310663223267
Epoch: 29, Steps: 63 | Train Loss: 0.1354575 Vali Loss: 0.2325663 Test Loss: 0.3009073
Validation loss decreased (0.232608 --> 0.232566).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.7895445823669434
Epoch: 30, Steps: 63 | Train Loss: 0.1341175 Vali Loss: 0.2318191 Test Loss: 0.3002443
Validation loss decreased (0.232566 --> 0.231819).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 3.031430721282959
Epoch: 31, Steps: 63 | Train Loss: 0.1333136 Vali Loss: 0.2319149 Test Loss: 0.2995534
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 4.589385509490967
Epoch: 32, Steps: 63 | Train Loss: 0.1316909 Vali Loss: 0.2315319 Test Loss: 0.2989877
Validation loss decreased (0.231819 --> 0.231532).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.921168327331543
Epoch: 33, Steps: 63 | Train Loss: 0.1313324 Vali Loss: 0.2298774 Test Loss: 0.2983588
Validation loss decreased (0.231532 --> 0.229877).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.697232723236084
Epoch: 34, Steps: 63 | Train Loss: 0.1301739 Vali Loss: 0.2298743 Test Loss: 0.2978758
Validation loss decreased (0.229877 --> 0.229874).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 3.038018226623535
Epoch: 35, Steps: 63 | Train Loss: 0.1290586 Vali Loss: 0.2292141 Test Loss: 0.2974279
Validation loss decreased (0.229874 --> 0.229214).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 3.0717196464538574
Epoch: 36, Steps: 63 | Train Loss: 0.1279321 Vali Loss: 0.2294553 Test Loss: 0.2968956
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.988020420074463
Epoch: 37, Steps: 63 | Train Loss: 0.1282073 Vali Loss: 0.2295877 Test Loss: 0.2964519
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.1365861892700195
Epoch: 38, Steps: 63 | Train Loss: 0.1269771 Vali Loss: 0.2290917 Test Loss: 0.2960840
Validation loss decreased (0.229214 --> 0.229092).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 3.1401259899139404
Epoch: 39, Steps: 63 | Train Loss: 0.1264415 Vali Loss: 0.2291943 Test Loss: 0.2956564
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 3.454322099685669
Epoch: 40, Steps: 63 | Train Loss: 0.1257418 Vali Loss: 0.2282077 Test Loss: 0.2953011
Validation loss decreased (0.229092 --> 0.228208).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.6585824489593506
Epoch: 41, Steps: 63 | Train Loss: 0.1248194 Vali Loss: 0.2278489 Test Loss: 0.2948899
Validation loss decreased (0.228208 --> 0.227849).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 3.1321775913238525
Epoch: 42, Steps: 63 | Train Loss: 0.1250527 Vali Loss: 0.2282588 Test Loss: 0.2945484
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 3.4559366703033447
Epoch: 43, Steps: 63 | Train Loss: 0.1240404 Vali Loss: 0.2286390 Test Loss: 0.2942413
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.9716882705688477
Epoch: 44, Steps: 63 | Train Loss: 0.1237499 Vali Loss: 0.2279678 Test Loss: 0.2939220
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 4.9432172775268555
Epoch: 45, Steps: 63 | Train Loss: 0.1233370 Vali Loss: 0.2279394 Test Loss: 0.2936417
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 3.631796360015869
Epoch: 46, Steps: 63 | Train Loss: 0.1225470 Vali Loss: 0.2282466 Test Loss: 0.2933692
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 3.311295509338379
Epoch: 47, Steps: 63 | Train Loss: 0.1222161 Vali Loss: 0.2281607 Test Loss: 0.2931343
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 3.483757495880127
Epoch: 48, Steps: 63 | Train Loss: 0.1214246 Vali Loss: 0.2266950 Test Loss: 0.2929034
Validation loss decreased (0.227849 --> 0.226695).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 4.3984785079956055
Epoch: 49, Steps: 63 | Train Loss: 0.1215901 Vali Loss: 0.2276669 Test Loss: 0.2926576
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 3.0348501205444336
Epoch: 50, Steps: 63 | Train Loss: 0.1215440 Vali Loss: 0.2270571 Test Loss: 0.2924420
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.510723114013672
Epoch: 51, Steps: 63 | Train Loss: 0.1208771 Vali Loss: 0.2272470 Test Loss: 0.2922150
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.7834699153900146
Epoch: 52, Steps: 63 | Train Loss: 0.1208669 Vali Loss: 0.2261530 Test Loss: 0.2920165
Validation loss decreased (0.226695 --> 0.226153).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 3.141777992248535
Epoch: 53, Steps: 63 | Train Loss: 0.1204429 Vali Loss: 0.2261443 Test Loss: 0.2918479
Validation loss decreased (0.226153 --> 0.226144).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 3.657104253768921
Epoch: 54, Steps: 63 | Train Loss: 0.1203282 Vali Loss: 0.2277058 Test Loss: 0.2916574
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 3.5213189125061035
Epoch: 55, Steps: 63 | Train Loss: 0.1198829 Vali Loss: 0.2257574 Test Loss: 0.2914846
Validation loss decreased (0.226144 --> 0.225757).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.9916701316833496
Epoch: 56, Steps: 63 | Train Loss: 0.1198909 Vali Loss: 0.2259730 Test Loss: 0.2913531
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 3.263854503631592
Epoch: 57, Steps: 63 | Train Loss: 0.1193859 Vali Loss: 0.2256088 Test Loss: 0.2911694
Validation loss decreased (0.225757 --> 0.225609).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 3.8789126873016357
Epoch: 58, Steps: 63 | Train Loss: 0.1188289 Vali Loss: 0.2256898 Test Loss: 0.2910208
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.613903045654297
Epoch: 59, Steps: 63 | Train Loss: 0.1182371 Vali Loss: 0.2265269 Test Loss: 0.2908768
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 3.2946937084198
Epoch: 60, Steps: 63 | Train Loss: 0.1183529 Vali Loss: 0.2270447 Test Loss: 0.2907543
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 3.583723306655884
Epoch: 61, Steps: 63 | Train Loss: 0.1179508 Vali Loss: 0.2261957 Test Loss: 0.2906314
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.3005974292755127
Epoch: 62, Steps: 63 | Train Loss: 0.1184231 Vali Loss: 0.2256289 Test Loss: 0.2904942
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.395174980163574
Epoch: 63, Steps: 63 | Train Loss: 0.1183398 Vali Loss: 0.2263055 Test Loss: 0.2903833
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.7073230743408203
Epoch: 64, Steps: 63 | Train Loss: 0.1182287 Vali Loss: 0.2254019 Test Loss: 0.2902861
Validation loss decreased (0.225609 --> 0.225402).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 3.262341260910034
Epoch: 65, Steps: 63 | Train Loss: 0.1182311 Vali Loss: 0.2246928 Test Loss: 0.2901688
Validation loss decreased (0.225402 --> 0.224693).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 3.8582661151885986
Epoch: 66, Steps: 63 | Train Loss: 0.1174835 Vali Loss: 0.2249938 Test Loss: 0.2900739
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.4642179012298584
Epoch: 67, Steps: 63 | Train Loss: 0.1175124 Vali Loss: 0.2265515 Test Loss: 0.2899879
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 4.1084983348846436
Epoch: 68, Steps: 63 | Train Loss: 0.1172240 Vali Loss: 0.2262069 Test Loss: 0.2898926
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 3.1049954891204834
Epoch: 69, Steps: 63 | Train Loss: 0.1176281 Vali Loss: 0.2252950 Test Loss: 0.2898147
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 3.167106866836548
Epoch: 70, Steps: 63 | Train Loss: 0.1175821 Vali Loss: 0.2251355 Test Loss: 0.2897230
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.6608755588531494
Epoch: 71, Steps: 63 | Train Loss: 0.1168594 Vali Loss: 0.2249961 Test Loss: 0.2896497
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 3.703458786010742
Epoch: 72, Steps: 63 | Train Loss: 0.1173430 Vali Loss: 0.2248227 Test Loss: 0.2895731
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 3.747506618499756
Epoch: 73, Steps: 63 | Train Loss: 0.1168650 Vali Loss: 0.2249285 Test Loss: 0.2895016
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 3.43489408493042
Epoch: 74, Steps: 63 | Train Loss: 0.1170187 Vali Loss: 0.2239050 Test Loss: 0.2894380
Validation loss decreased (0.224693 --> 0.223905).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.931271553039551
Epoch: 75, Steps: 63 | Train Loss: 0.1169185 Vali Loss: 0.2251218 Test Loss: 0.2893701
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.876741409301758
Epoch: 76, Steps: 63 | Train Loss: 0.1166960 Vali Loss: 0.2249435 Test Loss: 0.2893033
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 3.62686824798584
Epoch: 77, Steps: 63 | Train Loss: 0.1169050 Vali Loss: 0.2260113 Test Loss: 0.2892551
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 3.1564977169036865
Epoch: 78, Steps: 63 | Train Loss: 0.1165782 Vali Loss: 0.2245141 Test Loss: 0.2891849
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 3.6428489685058594
Epoch: 79, Steps: 63 | Train Loss: 0.1163802 Vali Loss: 0.2255268 Test Loss: 0.2891349
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.3187947273254395
Epoch: 80, Steps: 63 | Train Loss: 0.1165724 Vali Loss: 0.2257198 Test Loss: 0.2890934
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 4.353180885314941
Epoch: 81, Steps: 63 | Train Loss: 0.1164427 Vali Loss: 0.2235456 Test Loss: 0.2890410
Validation loss decreased (0.223905 --> 0.223546).  Saving model ...
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 3.4510066509246826
Epoch: 82, Steps: 63 | Train Loss: 0.1166626 Vali Loss: 0.2244382 Test Loss: 0.2889976
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 3.053473472595215
Epoch: 83, Steps: 63 | Train Loss: 0.1164333 Vali Loss: 0.2245815 Test Loss: 0.2889487
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 3.5114834308624268
Epoch: 84, Steps: 63 | Train Loss: 0.1162960 Vali Loss: 0.2255361 Test Loss: 0.2889049
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.3709378242492676
Epoch: 85, Steps: 63 | Train Loss: 0.1158811 Vali Loss: 0.2245197 Test Loss: 0.2888753
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 3.1462960243225098
Epoch: 86, Steps: 63 | Train Loss: 0.1162544 Vali Loss: 0.2250640 Test Loss: 0.2888403
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 2.7849621772766113
Epoch: 87, Steps: 63 | Train Loss: 0.1156513 Vali Loss: 0.2249581 Test Loss: 0.2888020
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 4.677617311477661
Epoch: 88, Steps: 63 | Train Loss: 0.1162497 Vali Loss: 0.2251853 Test Loss: 0.2887666
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 3.3400795459747314
Epoch: 89, Steps: 63 | Train Loss: 0.1157877 Vali Loss: 0.2247878 Test Loss: 0.2887356
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 4.617161989212036
Epoch: 90, Steps: 63 | Train Loss: 0.1159262 Vali Loss: 0.2246353 Test Loss: 0.2887012
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.7383365631103516
Epoch: 91, Steps: 63 | Train Loss: 0.1156138 Vali Loss: 0.2245611 Test Loss: 0.2886679
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.9955146312713623
Epoch: 92, Steps: 63 | Train Loss: 0.1157327 Vali Loss: 0.2250324 Test Loss: 0.2886448
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 3.468496322631836
Epoch: 93, Steps: 63 | Train Loss: 0.1159886 Vali Loss: 0.2254092 Test Loss: 0.2886133
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 2.7214505672454834
Epoch: 94, Steps: 63 | Train Loss: 0.1155881 Vali Loss: 0.2245825 Test Loss: 0.2885911
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 2.8069655895233154
Epoch: 95, Steps: 63 | Train Loss: 0.1152721 Vali Loss: 0.2252732 Test Loss: 0.2885641
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 2.6890125274658203
Epoch: 96, Steps: 63 | Train Loss: 0.1159096 Vali Loss: 0.2244475 Test Loss: 0.2885422
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 4.6879472732543945
Epoch: 97, Steps: 63 | Train Loss: 0.1159906 Vali Loss: 0.2240463 Test Loss: 0.2885208
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 3.233304023742676
Epoch: 98, Steps: 63 | Train Loss: 0.1152242 Vali Loss: 0.2235338 Test Loss: 0.2884976
Validation loss decreased (0.223546 --> 0.223534).  Saving model ...
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 4.373549461364746
Epoch: 99, Steps: 63 | Train Loss: 0.1147031 Vali Loss: 0.2250312 Test Loss: 0.2884811
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 4.7528486251831055
Epoch: 100, Steps: 63 | Train Loss: 0.1158359 Vali Loss: 0.2247720 Test Loss: 0.2884651
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8185
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=90, out_features=114, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  9192960.0
params:  10374.0
Trainable parameters:  10374
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 4.016223430633545
Epoch: 1, Steps: 63 | Train Loss: 0.4116210 Vali Loss: 0.2155694 Test Loss: 0.2798457
Validation loss decreased (inf --> 0.215569).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.7936761379241943
Epoch: 2, Steps: 63 | Train Loss: 0.4059037 Vali Loss: 0.2154055 Test Loss: 0.2776622
Validation loss decreased (0.215569 --> 0.215405).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 5.494235515594482
Epoch: 3, Steps: 63 | Train Loss: 0.4029833 Vali Loss: 0.2139160 Test Loss: 0.2769968
Validation loss decreased (0.215405 --> 0.213916).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.7525112628936768
Epoch: 4, Steps: 63 | Train Loss: 0.4048957 Vali Loss: 0.2120086 Test Loss: 0.2765409
Validation loss decreased (0.213916 --> 0.212009).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.6399166584014893
Epoch: 5, Steps: 63 | Train Loss: 0.4010495 Vali Loss: 0.2117250 Test Loss: 0.2762640
Validation loss decreased (0.212009 --> 0.211725).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.9116733074188232
Epoch: 6, Steps: 63 | Train Loss: 0.4029460 Vali Loss: 0.2115270 Test Loss: 0.2756981
Validation loss decreased (0.211725 --> 0.211527).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.5949926376342773
Epoch: 7, Steps: 63 | Train Loss: 0.4026604 Vali Loss: 0.2126060 Test Loss: 0.2755181
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.571007490158081
Epoch: 8, Steps: 63 | Train Loss: 0.4005807 Vali Loss: 0.2110727 Test Loss: 0.2754559
Validation loss decreased (0.211527 --> 0.211073).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.4775121212005615
Epoch: 9, Steps: 63 | Train Loss: 0.4004007 Vali Loss: 0.2118341 Test Loss: 0.2753201
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.1373982429504395
Epoch: 10, Steps: 63 | Train Loss: 0.4000039 Vali Loss: 0.2117527 Test Loss: 0.2752244
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 4.140057802200317
Epoch: 11, Steps: 63 | Train Loss: 0.3973451 Vali Loss: 0.2117558 Test Loss: 0.2751255
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.1465792655944824
Epoch: 12, Steps: 63 | Train Loss: 0.3993767 Vali Loss: 0.2109333 Test Loss: 0.2749131
Validation loss decreased (0.211073 --> 0.210933).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.6930603981018066
Epoch: 13, Steps: 63 | Train Loss: 0.3967938 Vali Loss: 0.2119552 Test Loss: 0.2750226
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.7426319122314453
Epoch: 14, Steps: 63 | Train Loss: 0.3972900 Vali Loss: 0.2111204 Test Loss: 0.2747626
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.01820969581604
Epoch: 15, Steps: 63 | Train Loss: 0.3996647 Vali Loss: 0.2107613 Test Loss: 0.2748486
Validation loss decreased (0.210933 --> 0.210761).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.1094729900360107
Epoch: 16, Steps: 63 | Train Loss: 0.3979712 Vali Loss: 0.2102797 Test Loss: 0.2749045
Validation loss decreased (0.210761 --> 0.210280).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.4101195335388184
Epoch: 17, Steps: 63 | Train Loss: 0.3991000 Vali Loss: 0.2109828 Test Loss: 0.2746223
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.5635228157043457
Epoch: 18, Steps: 63 | Train Loss: 0.3969598 Vali Loss: 0.2108548 Test Loss: 0.2747522
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.458397626876831
Epoch: 19, Steps: 63 | Train Loss: 0.3975541 Vali Loss: 0.2110385 Test Loss: 0.2746283
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.5805866718292236
Epoch: 20, Steps: 63 | Train Loss: 0.4001520 Vali Loss: 0.2101884 Test Loss: 0.2746117
Validation loss decreased (0.210280 --> 0.210188).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 4.125966310501099
Epoch: 21, Steps: 63 | Train Loss: 0.3984269 Vali Loss: 0.2106851 Test Loss: 0.2745481
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.177863597869873
Epoch: 22, Steps: 63 | Train Loss: 0.3972436 Vali Loss: 0.2113835 Test Loss: 0.2745393
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.432080030441284
Epoch: 23, Steps: 63 | Train Loss: 0.3986018 Vali Loss: 0.2108840 Test Loss: 0.2745601
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 4.198436737060547
Epoch: 24, Steps: 63 | Train Loss: 0.3967274 Vali Loss: 0.2097447 Test Loss: 0.2746615
Validation loss decreased (0.210188 --> 0.209745).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 5.070366859436035
Epoch: 25, Steps: 63 | Train Loss: 0.3978614 Vali Loss: 0.2108133 Test Loss: 0.2744264
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.544420003890991
Epoch: 26, Steps: 63 | Train Loss: 0.3974444 Vali Loss: 0.2098008 Test Loss: 0.2744467
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 4.174144268035889
Epoch: 27, Steps: 63 | Train Loss: 0.3986761 Vali Loss: 0.2100653 Test Loss: 0.2744955
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.942293405532837
Epoch: 28, Steps: 63 | Train Loss: 0.3983278 Vali Loss: 0.2108345 Test Loss: 0.2744763
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.7979934215545654
Epoch: 29, Steps: 63 | Train Loss: 0.3963173 Vali Loss: 0.2111974 Test Loss: 0.2744721
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.5209708213806152
Epoch: 30, Steps: 63 | Train Loss: 0.3969504 Vali Loss: 0.2099011 Test Loss: 0.2744474
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 3.0181524753570557
Epoch: 31, Steps: 63 | Train Loss: 0.3978935 Vali Loss: 0.2096493 Test Loss: 0.2743071
Validation loss decreased (0.209745 --> 0.209649).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 3.60074782371521
Epoch: 32, Steps: 63 | Train Loss: 0.3971855 Vali Loss: 0.2103615 Test Loss: 0.2743724
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 3.6771936416625977
Epoch: 33, Steps: 63 | Train Loss: 0.3993050 Vali Loss: 0.2093646 Test Loss: 0.2744001
Validation loss decreased (0.209649 --> 0.209365).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.709883689880371
Epoch: 34, Steps: 63 | Train Loss: 0.3969310 Vali Loss: 0.2095834 Test Loss: 0.2743834
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 5.192082643508911
Epoch: 35, Steps: 63 | Train Loss: 0.3958320 Vali Loss: 0.2104881 Test Loss: 0.2743171
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 4.463414669036865
Epoch: 36, Steps: 63 | Train Loss: 0.3965589 Vali Loss: 0.2096512 Test Loss: 0.2744008
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.2060320377349854
Epoch: 37, Steps: 63 | Train Loss: 0.3977646 Vali Loss: 0.2100388 Test Loss: 0.2743240
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 4.274127006530762
Epoch: 38, Steps: 63 | Train Loss: 0.3960114 Vali Loss: 0.2105446 Test Loss: 0.2743132
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 3.7265498638153076
Epoch: 39, Steps: 63 | Train Loss: 0.3959737 Vali Loss: 0.2093183 Test Loss: 0.2743158
Validation loss decreased (0.209365 --> 0.209318).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 3.323925018310547
Epoch: 40, Steps: 63 | Train Loss: 0.3970638 Vali Loss: 0.2097773 Test Loss: 0.2743343
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 3.390078067779541
Epoch: 41, Steps: 63 | Train Loss: 0.3958005 Vali Loss: 0.2100894 Test Loss: 0.2743123
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 3.6405909061431885
Epoch: 42, Steps: 63 | Train Loss: 0.3954862 Vali Loss: 0.2109036 Test Loss: 0.2743061
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 3.3689041137695312
Epoch: 43, Steps: 63 | Train Loss: 0.3969040 Vali Loss: 0.2095265 Test Loss: 0.2742254
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.009394645690918
Epoch: 44, Steps: 63 | Train Loss: 0.3961625 Vali Loss: 0.2105974 Test Loss: 0.2742599
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 3.4049136638641357
Epoch: 45, Steps: 63 | Train Loss: 0.3963231 Vali Loss: 0.2094353 Test Loss: 0.2742094
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 4.120383977890015
Epoch: 46, Steps: 63 | Train Loss: 0.3977709 Vali Loss: 0.2102049 Test Loss: 0.2742361
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 3.331578254699707
Epoch: 47, Steps: 63 | Train Loss: 0.3983240 Vali Loss: 0.2087171 Test Loss: 0.2742495
Validation loss decreased (0.209318 --> 0.208717).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 3.859022855758667
Epoch: 48, Steps: 63 | Train Loss: 0.3974408 Vali Loss: 0.2095226 Test Loss: 0.2742413
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.576237440109253
Epoch: 49, Steps: 63 | Train Loss: 0.3968247 Vali Loss: 0.2097045 Test Loss: 0.2742610
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 5.38070011138916
Epoch: 50, Steps: 63 | Train Loss: 0.3980210 Vali Loss: 0.2094813 Test Loss: 0.2742137
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.6213107109069824
Epoch: 51, Steps: 63 | Train Loss: 0.3979862 Vali Loss: 0.2100764 Test Loss: 0.2742325
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.8093600273132324
Epoch: 52, Steps: 63 | Train Loss: 0.3947659 Vali Loss: 0.2093807 Test Loss: 0.2742355
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.8183507919311523
Epoch: 53, Steps: 63 | Train Loss: 0.3961796 Vali Loss: 0.2094150 Test Loss: 0.2742108
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.691906452178955
Epoch: 54, Steps: 63 | Train Loss: 0.3974252 Vali Loss: 0.2108540 Test Loss: 0.2742358
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 3.2462401390075684
Epoch: 55, Steps: 63 | Train Loss: 0.3970963 Vali Loss: 0.2092998 Test Loss: 0.2742502
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 3.656886577606201
Epoch: 56, Steps: 63 | Train Loss: 0.3983368 Vali Loss: 0.2100283 Test Loss: 0.2742470
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 3.424647808074951
Epoch: 57, Steps: 63 | Train Loss: 0.3968898 Vali Loss: 0.2098602 Test Loss: 0.2742481
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 3.4544484615325928
Epoch: 58, Steps: 63 | Train Loss: 0.3967384 Vali Loss: 0.2096492 Test Loss: 0.2742113
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 5.217273950576782
Epoch: 59, Steps: 63 | Train Loss: 0.3973304 Vali Loss: 0.2096173 Test Loss: 0.2741967
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 3.096259117126465
Epoch: 60, Steps: 63 | Train Loss: 0.3984404 Vali Loss: 0.2095698 Test Loss: 0.2742340
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 4.439193487167358
Epoch: 61, Steps: 63 | Train Loss: 0.3962378 Vali Loss: 0.2097667 Test Loss: 0.2742000
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 4.023197889328003
Epoch: 62, Steps: 63 | Train Loss: 0.3975247 Vali Loss: 0.2094949 Test Loss: 0.2742053
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 3.3293027877807617
Epoch: 63, Steps: 63 | Train Loss: 0.3980491 Vali Loss: 0.2104881 Test Loss: 0.2742037
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.705353260040283
Epoch: 64, Steps: 63 | Train Loss: 0.3966197 Vali Loss: 0.2091268 Test Loss: 0.2741964
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 3.2875616550445557
Epoch: 65, Steps: 63 | Train Loss: 0.3950119 Vali Loss: 0.2108133 Test Loss: 0.2741943
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 3.5205180644989014
Epoch: 66, Steps: 63 | Train Loss: 0.3983684 Vali Loss: 0.2099606 Test Loss: 0.2742037
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.31769061088562
Epoch: 67, Steps: 63 | Train Loss: 0.3975873 Vali Loss: 0.2102095 Test Loss: 0.2741838
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_360_96_FITS_ETTh2_ftM_sl360_ll48_pl96_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.2740415036678314, mae:0.3367467224597931, rse:0.4218805432319641, corr:[0.27538422 0.27788958 0.2753403  0.27426618 0.2737157  0.27214554
 0.27075627 0.26988995 0.26908213 0.2675912  0.26607755 0.2645756
 0.26323786 0.26212063 0.26127854 0.2610375  0.26084414 0.2604875
 0.25967768 0.25866136 0.2576885  0.2565579  0.25518104 0.25328064
 0.25110874 0.2489567  0.24708632 0.24558698 0.24460201 0.24367887
 0.24240766 0.24083352 0.23921746 0.23781677 0.23644876 0.23530056
 0.23431501 0.23308031 0.2319917  0.23126848 0.2310613  0.230742
 0.2300523  0.22928485 0.22870637 0.22765946 0.22628087 0.22480959
 0.2232265  0.22130153 0.21949002 0.21835916 0.21769953 0.21651691
 0.2144405  0.21245618 0.21119982 0.20945221 0.20762594 0.2067447
 0.20669264 0.20648354 0.20636861 0.20643966 0.20645672 0.20603016
 0.20537615 0.20490934 0.20474538 0.2041847  0.20341137 0.20293169
 0.20231807 0.20122501 0.20019424 0.1995781  0.19910823 0.19812427
 0.19722952 0.19682376 0.19667415 0.19542101 0.19464108 0.19492967
 0.19484447 0.1936972  0.19354725 0.1944731  0.19349217 0.19120435
 0.19043756 0.19072127 0.18899944 0.18577082 0.18689463 0.1857014 ]
