Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=22, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_90_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_90_192_FITS_ETTh2_ftM_sl90_ll48_pl192_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8359
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=22, out_features=68, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1340416.0
params:  1564.0
Trainable parameters:  1564
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 5.899563312530518
Epoch: 1, Steps: 65 | Train Loss: 0.6508533 Vali Loss: 0.3929283 Test Loss: 0.5523475
Validation loss decreased (inf --> 0.392928).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 6.439881801605225
Epoch: 2, Steps: 65 | Train Loss: 0.5676255 Vali Loss: 0.3634338 Test Loss: 0.5108084
Validation loss decreased (0.392928 --> 0.363434).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 4.0582356452941895
Epoch: 3, Steps: 65 | Train Loss: 0.5151684 Vali Loss: 0.3443474 Test Loss: 0.4839056
Validation loss decreased (0.363434 --> 0.344347).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 6.2528181076049805
Epoch: 4, Steps: 65 | Train Loss: 0.4820286 Vali Loss: 0.3311598 Test Loss: 0.4654131
Validation loss decreased (0.344347 --> 0.331160).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 6.1899755001068115
Epoch: 5, Steps: 65 | Train Loss: 0.4594822 Vali Loss: 0.3218126 Test Loss: 0.4523979
Validation loss decreased (0.331160 --> 0.321813).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.938182830810547
Epoch: 6, Steps: 65 | Train Loss: 0.4436456 Vali Loss: 0.3148422 Test Loss: 0.4430140
Validation loss decreased (0.321813 --> 0.314842).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 5.6710686683654785
Epoch: 7, Steps: 65 | Train Loss: 0.4310961 Vali Loss: 0.3096659 Test Loss: 0.4360393
Validation loss decreased (0.314842 --> 0.309666).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.2959401607513428
Epoch: 8, Steps: 65 | Train Loss: 0.4233060 Vali Loss: 0.3054466 Test Loss: 0.4305571
Validation loss decreased (0.309666 --> 0.305447).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.0682249069213867
Epoch: 9, Steps: 65 | Train Loss: 0.4175054 Vali Loss: 0.3022860 Test Loss: 0.4264238
Validation loss decreased (0.305447 --> 0.302286).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 5.830934286117554
Epoch: 10, Steps: 65 | Train Loss: 0.4093690 Vali Loss: 0.2997244 Test Loss: 0.4230478
Validation loss decreased (0.302286 --> 0.299724).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 4.609644174575806
Epoch: 11, Steps: 65 | Train Loss: 0.4082050 Vali Loss: 0.2974126 Test Loss: 0.4203543
Validation loss decreased (0.299724 --> 0.297413).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 6.724318265914917
Epoch: 12, Steps: 65 | Train Loss: 0.4050472 Vali Loss: 0.2955106 Test Loss: 0.4180468
Validation loss decreased (0.297413 --> 0.295511).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 5.803387403488159
Epoch: 13, Steps: 65 | Train Loss: 0.4008777 Vali Loss: 0.2939624 Test Loss: 0.4162053
Validation loss decreased (0.295511 --> 0.293962).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 5.9590771198272705
Epoch: 14, Steps: 65 | Train Loss: 0.3998323 Vali Loss: 0.2927752 Test Loss: 0.4145772
Validation loss decreased (0.293962 --> 0.292775).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.7814769744873047
Epoch: 15, Steps: 65 | Train Loss: 0.3974394 Vali Loss: 0.2915696 Test Loss: 0.4132314
Validation loss decreased (0.292775 --> 0.291570).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.888143539428711
Epoch: 16, Steps: 65 | Train Loss: 0.3961742 Vali Loss: 0.2905674 Test Loss: 0.4119905
Validation loss decreased (0.291570 --> 0.290567).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.6393954753875732
Epoch: 17, Steps: 65 | Train Loss: 0.3944254 Vali Loss: 0.2896566 Test Loss: 0.4109251
Validation loss decreased (0.290567 --> 0.289657).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.6106412410736084
Epoch: 18, Steps: 65 | Train Loss: 0.3930911 Vali Loss: 0.2888930 Test Loss: 0.4100470
Validation loss decreased (0.289657 --> 0.288893).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.94816255569458
Epoch: 19, Steps: 65 | Train Loss: 0.3910983 Vali Loss: 0.2881882 Test Loss: 0.4092340
Validation loss decreased (0.288893 --> 0.288188).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.6638453006744385
Epoch: 20, Steps: 65 | Train Loss: 0.3903400 Vali Loss: 0.2874063 Test Loss: 0.4084918
Validation loss decreased (0.288188 --> 0.287406).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.532895565032959
Epoch: 21, Steps: 65 | Train Loss: 0.3897240 Vali Loss: 0.2868532 Test Loss: 0.4078811
Validation loss decreased (0.287406 --> 0.286853).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.54764723777771
Epoch: 22, Steps: 65 | Train Loss: 0.3896606 Vali Loss: 0.2864061 Test Loss: 0.4072772
Validation loss decreased (0.286853 --> 0.286406).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.5673274993896484
Epoch: 23, Steps: 65 | Train Loss: 0.3884983 Vali Loss: 0.2859205 Test Loss: 0.4067544
Validation loss decreased (0.286406 --> 0.285920).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.5394554138183594
Epoch: 24, Steps: 65 | Train Loss: 0.3876727 Vali Loss: 0.2854587 Test Loss: 0.4063396
Validation loss decreased (0.285920 --> 0.285459).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.7087621688842773
Epoch: 25, Steps: 65 | Train Loss: 0.3864303 Vali Loss: 0.2849587 Test Loss: 0.4058808
Validation loss decreased (0.285459 --> 0.284959).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.69984769821167
Epoch: 26, Steps: 65 | Train Loss: 0.3855896 Vali Loss: 0.2847519 Test Loss: 0.4054932
Validation loss decreased (0.284959 --> 0.284752).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.5891664028167725
Epoch: 27, Steps: 65 | Train Loss: 0.3862495 Vali Loss: 0.2843613 Test Loss: 0.4051191
Validation loss decreased (0.284752 --> 0.284361).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.017202854156494
Epoch: 28, Steps: 65 | Train Loss: 0.3857524 Vali Loss: 0.2841313 Test Loss: 0.4048138
Validation loss decreased (0.284361 --> 0.284131).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.9336671829223633
Epoch: 29, Steps: 65 | Train Loss: 0.3852836 Vali Loss: 0.2838271 Test Loss: 0.4045292
Validation loss decreased (0.284131 --> 0.283827).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.898397445678711
Epoch: 30, Steps: 65 | Train Loss: 0.3847490 Vali Loss: 0.2834494 Test Loss: 0.4042647
Validation loss decreased (0.283827 --> 0.283449).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.6346616744995117
Epoch: 31, Steps: 65 | Train Loss: 0.3849229 Vali Loss: 0.2833363 Test Loss: 0.4039964
Validation loss decreased (0.283449 --> 0.283336).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.7503867149353027
Epoch: 32, Steps: 65 | Train Loss: 0.3836698 Vali Loss: 0.2830997 Test Loss: 0.4037671
Validation loss decreased (0.283336 --> 0.283100).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.6850290298461914
Epoch: 33, Steps: 65 | Train Loss: 0.3836672 Vali Loss: 0.2828119 Test Loss: 0.4035761
Validation loss decreased (0.283100 --> 0.282812).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.5926530361175537
Epoch: 34, Steps: 65 | Train Loss: 0.3835891 Vali Loss: 0.2826870 Test Loss: 0.4033487
Validation loss decreased (0.282812 --> 0.282687).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.7164380550384521
Epoch: 35, Steps: 65 | Train Loss: 0.3841602 Vali Loss: 0.2824776 Test Loss: 0.4031717
Validation loss decreased (0.282687 --> 0.282478).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.8185396194458008
Epoch: 36, Steps: 65 | Train Loss: 0.3835001 Vali Loss: 0.2823434 Test Loss: 0.4030071
Validation loss decreased (0.282478 --> 0.282343).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.810673713684082
Epoch: 37, Steps: 65 | Train Loss: 0.3821493 Vali Loss: 0.2821784 Test Loss: 0.4028642
Validation loss decreased (0.282343 --> 0.282178).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.090085744857788
Epoch: 38, Steps: 65 | Train Loss: 0.3829767 Vali Loss: 0.2819187 Test Loss: 0.4027123
Validation loss decreased (0.282178 --> 0.281919).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.6948668956756592
Epoch: 39, Steps: 65 | Train Loss: 0.3831266 Vali Loss: 0.2818632 Test Loss: 0.4025659
Validation loss decreased (0.281919 --> 0.281863).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.8810317516326904
Epoch: 40, Steps: 65 | Train Loss: 0.3823574 Vali Loss: 0.2817174 Test Loss: 0.4024335
Validation loss decreased (0.281863 --> 0.281717).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.5017077922821045
Epoch: 41, Steps: 65 | Train Loss: 0.3819649 Vali Loss: 0.2815486 Test Loss: 0.4023317
Validation loss decreased (0.281717 --> 0.281549).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.473111629486084
Epoch: 42, Steps: 65 | Train Loss: 0.3815996 Vali Loss: 0.2814629 Test Loss: 0.4022014
Validation loss decreased (0.281549 --> 0.281463).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.4288344383239746
Epoch: 43, Steps: 65 | Train Loss: 0.3822381 Vali Loss: 0.2813623 Test Loss: 0.4021100
Validation loss decreased (0.281463 --> 0.281362).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.8031914234161377
Epoch: 44, Steps: 65 | Train Loss: 0.3815722 Vali Loss: 0.2812752 Test Loss: 0.4020152
Validation loss decreased (0.281362 --> 0.281275).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.6241838932037354
Epoch: 45, Steps: 65 | Train Loss: 0.3793220 Vali Loss: 0.2811807 Test Loss: 0.4019262
Validation loss decreased (0.281275 --> 0.281181).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.4494433403015137
Epoch: 46, Steps: 65 | Train Loss: 0.3810345 Vali Loss: 0.2811079 Test Loss: 0.4018364
Validation loss decreased (0.281181 --> 0.281108).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.392446517944336
Epoch: 47, Steps: 65 | Train Loss: 0.3809633 Vali Loss: 0.2809621 Test Loss: 0.4017573
Validation loss decreased (0.281108 --> 0.280962).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.9037461280822754
Epoch: 48, Steps: 65 | Train Loss: 0.3799877 Vali Loss: 0.2809079 Test Loss: 0.4016911
Validation loss decreased (0.280962 --> 0.280908).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.6320011615753174
Epoch: 49, Steps: 65 | Train Loss: 0.3816237 Vali Loss: 0.2808534 Test Loss: 0.4016142
Validation loss decreased (0.280908 --> 0.280853).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.797767162322998
Epoch: 50, Steps: 65 | Train Loss: 0.3809733 Vali Loss: 0.2807036 Test Loss: 0.4015457
Validation loss decreased (0.280853 --> 0.280704).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.6449792385101318
Epoch: 51, Steps: 65 | Train Loss: 0.3817986 Vali Loss: 0.2806888 Test Loss: 0.4014879
Validation loss decreased (0.280704 --> 0.280689).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.7581100463867188
Epoch: 52, Steps: 65 | Train Loss: 0.3805117 Vali Loss: 0.2806252 Test Loss: 0.4014255
Validation loss decreased (0.280689 --> 0.280625).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.793869972229004
Epoch: 53, Steps: 65 | Train Loss: 0.3805147 Vali Loss: 0.2805429 Test Loss: 0.4013627
Validation loss decreased (0.280625 --> 0.280543).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.91178560256958
Epoch: 54, Steps: 65 | Train Loss: 0.3808575 Vali Loss: 0.2804644 Test Loss: 0.4013174
Validation loss decreased (0.280543 --> 0.280464).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.6936404705047607
Epoch: 55, Steps: 65 | Train Loss: 0.3795125 Vali Loss: 0.2803939 Test Loss: 0.4012648
Validation loss decreased (0.280464 --> 0.280394).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.5487060546875
Epoch: 56, Steps: 65 | Train Loss: 0.3801618 Vali Loss: 0.2804217 Test Loss: 0.4012073
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.6025266647338867
Epoch: 57, Steps: 65 | Train Loss: 0.3803881 Vali Loss: 0.2803879 Test Loss: 0.4011720
Validation loss decreased (0.280394 --> 0.280388).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.5215132236480713
Epoch: 58, Steps: 65 | Train Loss: 0.3812188 Vali Loss: 0.2802116 Test Loss: 0.4011229
Validation loss decreased (0.280388 --> 0.280212).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.8638896942138672
Epoch: 59, Steps: 65 | Train Loss: 0.3799713 Vali Loss: 0.2802636 Test Loss: 0.4010872
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.4751920700073242
Epoch: 60, Steps: 65 | Train Loss: 0.3809096 Vali Loss: 0.2798944 Test Loss: 0.4010509
Validation loss decreased (0.280212 --> 0.279894).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.589888572692871
Epoch: 61, Steps: 65 | Train Loss: 0.3796010 Vali Loss: 0.2801864 Test Loss: 0.4010173
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.6818997859954834
Epoch: 62, Steps: 65 | Train Loss: 0.3804681 Vali Loss: 0.2798018 Test Loss: 0.4009795
Validation loss decreased (0.279894 --> 0.279802).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.9391841888427734
Epoch: 63, Steps: 65 | Train Loss: 0.3801523 Vali Loss: 0.2799650 Test Loss: 0.4009415
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.364422082901001
Epoch: 64, Steps: 65 | Train Loss: 0.3801277 Vali Loss: 0.2800587 Test Loss: 0.4009158
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.8370790481567383
Epoch: 65, Steps: 65 | Train Loss: 0.3804875 Vali Loss: 0.2800427 Test Loss: 0.4008874
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.6858980655670166
Epoch: 66, Steps: 65 | Train Loss: 0.3803338 Vali Loss: 0.2799761 Test Loss: 0.4008594
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.3692626953125
Epoch: 67, Steps: 65 | Train Loss: 0.3798725 Vali Loss: 0.2799824 Test Loss: 0.4008318
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.069782018661499
Epoch: 68, Steps: 65 | Train Loss: 0.3806602 Vali Loss: 0.2799761 Test Loss: 0.4008064
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.4414381980895996
Epoch: 69, Steps: 65 | Train Loss: 0.3797033 Vali Loss: 0.2799074 Test Loss: 0.4007864
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.3320600986480713
Epoch: 70, Steps: 65 | Train Loss: 0.3799988 Vali Loss: 0.2799157 Test Loss: 0.4007636
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.6541447639465332
Epoch: 71, Steps: 65 | Train Loss: 0.3804913 Vali Loss: 0.2797925 Test Loss: 0.4007414
Validation loss decreased (0.279802 --> 0.279792).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.9211468696594238
Epoch: 72, Steps: 65 | Train Loss: 0.3788065 Vali Loss: 0.2798473 Test Loss: 0.4007246
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.3540070056915283
Epoch: 73, Steps: 65 | Train Loss: 0.3777418 Vali Loss: 0.2798053 Test Loss: 0.4007043
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.4656784534454346
Epoch: 74, Steps: 65 | Train Loss: 0.3797294 Vali Loss: 0.2797550 Test Loss: 0.4006858
Validation loss decreased (0.279792 --> 0.279755).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.4740116596221924
Epoch: 75, Steps: 65 | Train Loss: 0.3801523 Vali Loss: 0.2797855 Test Loss: 0.4006677
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.4296705722808838
Epoch: 76, Steps: 65 | Train Loss: 0.3792934 Vali Loss: 0.2796577 Test Loss: 0.4006480
Validation loss decreased (0.279755 --> 0.279658).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.4605712890625
Epoch: 77, Steps: 65 | Train Loss: 0.3804471 Vali Loss: 0.2797628 Test Loss: 0.4006344
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.654120683670044
Epoch: 78, Steps: 65 | Train Loss: 0.3793185 Vali Loss: 0.2794831 Test Loss: 0.4006194
Validation loss decreased (0.279658 --> 0.279483).  Saving model ...
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.4965829849243164
Epoch: 79, Steps: 65 | Train Loss: 0.3790792 Vali Loss: 0.2796594 Test Loss: 0.4006082
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.6534042358398438
Epoch: 80, Steps: 65 | Train Loss: 0.3793326 Vali Loss: 0.2797253 Test Loss: 0.4005915
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.4332795143127441
Epoch: 81, Steps: 65 | Train Loss: 0.3802278 Vali Loss: 0.2797146 Test Loss: 0.4005826
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.6824619770050049
Epoch: 82, Steps: 65 | Train Loss: 0.3793885 Vali Loss: 0.2796625 Test Loss: 0.4005692
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.7627289295196533
Epoch: 83, Steps: 65 | Train Loss: 0.3799769 Vali Loss: 0.2795833 Test Loss: 0.4005560
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.1526901721954346
Epoch: 84, Steps: 65 | Train Loss: 0.3791640 Vali Loss: 0.2795143 Test Loss: 0.4005457
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.8621349334716797
Epoch: 85, Steps: 65 | Train Loss: 0.3803178 Vali Loss: 0.2796584 Test Loss: 0.4005369
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.6845991611480713
Epoch: 86, Steps: 65 | Train Loss: 0.3801434 Vali Loss: 0.2796005 Test Loss: 0.4005261
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.6575565338134766
Epoch: 87, Steps: 65 | Train Loss: 0.3801026 Vali Loss: 0.2795904 Test Loss: 0.4005171
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 2.1947362422943115
Epoch: 88, Steps: 65 | Train Loss: 0.3783848 Vali Loss: 0.2796030 Test Loss: 0.4005065
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.8419241905212402
Epoch: 89, Steps: 65 | Train Loss: 0.3787918 Vali Loss: 0.2792386 Test Loss: 0.4004983
Validation loss decreased (0.279483 --> 0.279239).  Saving model ...
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.4625961780548096
Epoch: 90, Steps: 65 | Train Loss: 0.3785183 Vali Loss: 0.2795622 Test Loss: 0.4004910
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.036111354827881
Epoch: 91, Steps: 65 | Train Loss: 0.3793598 Vali Loss: 0.2795541 Test Loss: 0.4004829
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.983367681503296
Epoch: 92, Steps: 65 | Train Loss: 0.3791388 Vali Loss: 0.2795876 Test Loss: 0.4004761
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 2.0831503868103027
Epoch: 93, Steps: 65 | Train Loss: 0.3785405 Vali Loss: 0.2792288 Test Loss: 0.4004683
Validation loss decreased (0.279239 --> 0.279229).  Saving model ...
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 2.0137221813201904
Epoch: 94, Steps: 65 | Train Loss: 0.3794651 Vali Loss: 0.2795202 Test Loss: 0.4004616
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 2.084517240524292
Epoch: 95, Steps: 65 | Train Loss: 0.3790452 Vali Loss: 0.2791652 Test Loss: 0.4004551
Validation loss decreased (0.279229 --> 0.279165).  Saving model ...
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.6879355907440186
Epoch: 96, Steps: 65 | Train Loss: 0.3799044 Vali Loss: 0.2795301 Test Loss: 0.4004494
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.6662719249725342
Epoch: 97, Steps: 65 | Train Loss: 0.3803337 Vali Loss: 0.2795306 Test Loss: 0.4004433
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.6196272373199463
Epoch: 98, Steps: 65 | Train Loss: 0.3789444 Vali Loss: 0.2793935 Test Loss: 0.4004389
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.6003806591033936
Epoch: 99, Steps: 65 | Train Loss: 0.3787829 Vali Loss: 0.2791674 Test Loss: 0.4004332
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.770838737487793
Epoch: 100, Steps: 65 | Train Loss: 0.3797634 Vali Loss: 0.2795243 Test Loss: 0.4004287
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8359
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=22, out_features=68, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1340416.0
params:  1564.0
Trainable parameters:  1564
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.672194004058838
Epoch: 1, Steps: 65 | Train Loss: 0.5440435 Vali Loss: 0.2774223 Test Loss: 0.3986716
Validation loss decreased (inf --> 0.277422).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.2763454914093018
Epoch: 2, Steps: 65 | Train Loss: 0.5417639 Vali Loss: 0.2768661 Test Loss: 0.3978385
Validation loss decreased (0.277422 --> 0.276866).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.4427146911621094
Epoch: 3, Steps: 65 | Train Loss: 0.5422247 Vali Loss: 0.2762161 Test Loss: 0.3973526
Validation loss decreased (0.276866 --> 0.276216).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.6424586772918701
Epoch: 4, Steps: 65 | Train Loss: 0.5412998 Vali Loss: 0.2756447 Test Loss: 0.3971158
Validation loss decreased (0.276216 --> 0.275645).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.6679162979125977
Epoch: 5, Steps: 65 | Train Loss: 0.5368367 Vali Loss: 0.2754083 Test Loss: 0.3969376
Validation loss decreased (0.275645 --> 0.275408).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.8871946334838867
Epoch: 6, Steps: 65 | Train Loss: 0.5398172 Vali Loss: 0.2751475 Test Loss: 0.3968385
Validation loss decreased (0.275408 --> 0.275147).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.7738616466522217
Epoch: 7, Steps: 65 | Train Loss: 0.5386972 Vali Loss: 0.2748753 Test Loss: 0.3967576
Validation loss decreased (0.275147 --> 0.274875).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.7681376934051514
Epoch: 8, Steps: 65 | Train Loss: 0.5391694 Vali Loss: 0.2747534 Test Loss: 0.3968475
Validation loss decreased (0.274875 --> 0.274753).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.527834415435791
Epoch: 9, Steps: 65 | Train Loss: 0.5381977 Vali Loss: 0.2745964 Test Loss: 0.3967259
Validation loss decreased (0.274753 --> 0.274596).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.5052947998046875
Epoch: 10, Steps: 65 | Train Loss: 0.5383770 Vali Loss: 0.2745287 Test Loss: 0.3967713
Validation loss decreased (0.274596 --> 0.274529).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.4451727867126465
Epoch: 11, Steps: 65 | Train Loss: 0.5376928 Vali Loss: 0.2743876 Test Loss: 0.3967472
Validation loss decreased (0.274529 --> 0.274388).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.414896011352539
Epoch: 12, Steps: 65 | Train Loss: 0.5363507 Vali Loss: 0.2742583 Test Loss: 0.3968039
Validation loss decreased (0.274388 --> 0.274258).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.036266326904297
Epoch: 13, Steps: 65 | Train Loss: 0.5383598 Vali Loss: 0.2741801 Test Loss: 0.3968060
Validation loss decreased (0.274258 --> 0.274180).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.8259921073913574
Epoch: 14, Steps: 65 | Train Loss: 0.5379789 Vali Loss: 0.2741595 Test Loss: 0.3968726
Validation loss decreased (0.274180 --> 0.274160).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.7342822551727295
Epoch: 15, Steps: 65 | Train Loss: 0.5374569 Vali Loss: 0.2739351 Test Loss: 0.3968291
Validation loss decreased (0.274160 --> 0.273935).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.7425000667572021
Epoch: 16, Steps: 65 | Train Loss: 0.5367864 Vali Loss: 0.2740398 Test Loss: 0.3969064
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.6133434772491455
Epoch: 17, Steps: 65 | Train Loss: 0.5359180 Vali Loss: 0.2739429 Test Loss: 0.3969010
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.6258964538574219
Epoch: 18, Steps: 65 | Train Loss: 0.5369321 Vali Loss: 0.2739164 Test Loss: 0.3968947
Validation loss decreased (0.273935 --> 0.273916).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.4178400039672852
Epoch: 19, Steps: 65 | Train Loss: 0.5363879 Vali Loss: 0.2738721 Test Loss: 0.3969534
Validation loss decreased (0.273916 --> 0.273872).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.909454345703125
Epoch: 20, Steps: 65 | Train Loss: 0.5376787 Vali Loss: 0.2738846 Test Loss: 0.3969687
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.547757625579834
Epoch: 21, Steps: 65 | Train Loss: 0.5373864 Vali Loss: 0.2737128 Test Loss: 0.3969907
Validation loss decreased (0.273872 --> 0.273713).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.6094160079956055
Epoch: 22, Steps: 65 | Train Loss: 0.5357246 Vali Loss: 0.2736681 Test Loss: 0.3969450
Validation loss decreased (0.273713 --> 0.273668).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.4745125770568848
Epoch: 23, Steps: 65 | Train Loss: 0.5367388 Vali Loss: 0.2736253 Test Loss: 0.3969813
Validation loss decreased (0.273668 --> 0.273625).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.9374351501464844
Epoch: 24, Steps: 65 | Train Loss: 0.5369997 Vali Loss: 0.2737240 Test Loss: 0.3970258
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.3382134437561035
Epoch: 25, Steps: 65 | Train Loss: 0.5373133 Vali Loss: 0.2736595 Test Loss: 0.3970369
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.435821294784546
Epoch: 26, Steps: 65 | Train Loss: 0.5365866 Vali Loss: 0.2736313 Test Loss: 0.3970541
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.3450591564178467
Epoch: 27, Steps: 65 | Train Loss: 0.5353753 Vali Loss: 0.2736635 Test Loss: 0.3970389
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.2982535362243652
Epoch: 28, Steps: 65 | Train Loss: 0.5372923 Vali Loss: 0.2736449 Test Loss: 0.3970552
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.564988851547241
Epoch: 29, Steps: 65 | Train Loss: 0.5355557 Vali Loss: 0.2735863 Test Loss: 0.3970958
Validation loss decreased (0.273625 --> 0.273586).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.567965030670166
Epoch: 30, Steps: 65 | Train Loss: 0.5373900 Vali Loss: 0.2735581 Test Loss: 0.3970826
Validation loss decreased (0.273586 --> 0.273558).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.001603126525879
Epoch: 31, Steps: 65 | Train Loss: 0.5352943 Vali Loss: 0.2735431 Test Loss: 0.3970839
Validation loss decreased (0.273558 --> 0.273543).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.0579898357391357
Epoch: 32, Steps: 65 | Train Loss: 0.5368105 Vali Loss: 0.2735475 Test Loss: 0.3971156
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.6071786880493164
Epoch: 33, Steps: 65 | Train Loss: 0.5363348 Vali Loss: 0.2735391 Test Loss: 0.3971063
Validation loss decreased (0.273543 --> 0.273539).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.8066813945770264
Epoch: 34, Steps: 65 | Train Loss: 0.5356827 Vali Loss: 0.2734184 Test Loss: 0.3971290
Validation loss decreased (0.273539 --> 0.273418).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.5205204486846924
Epoch: 35, Steps: 65 | Train Loss: 0.5359346 Vali Loss: 0.2734607 Test Loss: 0.3971273
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.4274704456329346
Epoch: 36, Steps: 65 | Train Loss: 0.5352350 Vali Loss: 0.2734865 Test Loss: 0.3971418
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.6567378044128418
Epoch: 37, Steps: 65 | Train Loss: 0.5359631 Vali Loss: 0.2735111 Test Loss: 0.3971446
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.7085635662078857
Epoch: 38, Steps: 65 | Train Loss: 0.5371488 Vali Loss: 0.2734978 Test Loss: 0.3971615
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.483633041381836
Epoch: 39, Steps: 65 | Train Loss: 0.5343082 Vali Loss: 0.2734447 Test Loss: 0.3971703
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.7906084060668945
Epoch: 40, Steps: 65 | Train Loss: 0.5347327 Vali Loss: 0.2734114 Test Loss: 0.3971733
Validation loss decreased (0.273418 --> 0.273411).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.161808490753174
Epoch: 41, Steps: 65 | Train Loss: 0.5351758 Vali Loss: 0.2734266 Test Loss: 0.3971779
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.3902831077575684
Epoch: 42, Steps: 65 | Train Loss: 0.5351771 Vali Loss: 0.2734331 Test Loss: 0.3971884
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.6656396389007568
Epoch: 43, Steps: 65 | Train Loss: 0.5364631 Vali Loss: 0.2733959 Test Loss: 0.3971880
Validation loss decreased (0.273411 --> 0.273396).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.7277772426605225
Epoch: 44, Steps: 65 | Train Loss: 0.5371467 Vali Loss: 0.2730647 Test Loss: 0.3972065
Validation loss decreased (0.273396 --> 0.273065).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.7087900638580322
Epoch: 45, Steps: 65 | Train Loss: 0.5364522 Vali Loss: 0.2732991 Test Loss: 0.3971907
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.3933849334716797
Epoch: 46, Steps: 65 | Train Loss: 0.5367490 Vali Loss: 0.2734206 Test Loss: 0.3972093
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.3536524772644043
Epoch: 47, Steps: 65 | Train Loss: 0.5355322 Vali Loss: 0.2734024 Test Loss: 0.3972156
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.4837284088134766
Epoch: 48, Steps: 65 | Train Loss: 0.5372617 Vali Loss: 0.2734160 Test Loss: 0.3972181
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.0266571044921875
Epoch: 49, Steps: 65 | Train Loss: 0.5359602 Vali Loss: 0.2732822 Test Loss: 0.3972298
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.4878966808319092
Epoch: 50, Steps: 65 | Train Loss: 0.5345399 Vali Loss: 0.2733749 Test Loss: 0.3972239
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.6707954406738281
Epoch: 51, Steps: 65 | Train Loss: 0.5354378 Vali Loss: 0.2733399 Test Loss: 0.3972318
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.975985050201416
Epoch: 52, Steps: 65 | Train Loss: 0.5364550 Vali Loss: 0.2733913 Test Loss: 0.3972300
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.4383983612060547
Epoch: 53, Steps: 65 | Train Loss: 0.5369468 Vali Loss: 0.2733508 Test Loss: 0.3972347
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.5310900211334229
Epoch: 54, Steps: 65 | Train Loss: 0.5348072 Vali Loss: 0.2733696 Test Loss: 0.3972443
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.9856514930725098
Epoch: 55, Steps: 65 | Train Loss: 0.5367348 Vali Loss: 0.2733676 Test Loss: 0.3972501
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.0249998569488525
Epoch: 56, Steps: 65 | Train Loss: 0.5364010 Vali Loss: 0.2732975 Test Loss: 0.3972535
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.8100199699401855
Epoch: 57, Steps: 65 | Train Loss: 0.5356588 Vali Loss: 0.2733585 Test Loss: 0.3972487
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.5063157081604004
Epoch: 58, Steps: 65 | Train Loss: 0.5368243 Vali Loss: 0.2733397 Test Loss: 0.3972561
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.5736379623413086
Epoch: 59, Steps: 65 | Train Loss: 0.5354314 Vali Loss: 0.2730295 Test Loss: 0.3972599
Validation loss decreased (0.273065 --> 0.273030).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.6502363681793213
Epoch: 60, Steps: 65 | Train Loss: 0.5361805 Vali Loss: 0.2733454 Test Loss: 0.3972620
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.6654503345489502
Epoch: 61, Steps: 65 | Train Loss: 0.5362784 Vali Loss: 0.2733621 Test Loss: 0.3972655
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.414041519165039
Epoch: 62, Steps: 65 | Train Loss: 0.5356073 Vali Loss: 0.2733585 Test Loss: 0.3972642
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.7458508014678955
Epoch: 63, Steps: 65 | Train Loss: 0.5355653 Vali Loss: 0.2730011 Test Loss: 0.3972730
Validation loss decreased (0.273030 --> 0.273001).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.4950852394104004
Epoch: 64, Steps: 65 | Train Loss: 0.5367896 Vali Loss: 0.2732735 Test Loss: 0.3972752
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.091306447982788
Epoch: 65, Steps: 65 | Train Loss: 0.5359854 Vali Loss: 0.2732327 Test Loss: 0.3972722
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.3870527744293213
Epoch: 66, Steps: 65 | Train Loss: 0.5356176 Vali Loss: 0.2733533 Test Loss: 0.3972775
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.5086450576782227
Epoch: 67, Steps: 65 | Train Loss: 0.5358099 Vali Loss: 0.2732524 Test Loss: 0.3972767
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.3781979084014893
Epoch: 68, Steps: 65 | Train Loss: 0.5364948 Vali Loss: 0.2733243 Test Loss: 0.3972761
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.7924683094024658
Epoch: 69, Steps: 65 | Train Loss: 0.5365710 Vali Loss: 0.2733101 Test Loss: 0.3972777
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.6736655235290527
Epoch: 70, Steps: 65 | Train Loss: 0.5353547 Vali Loss: 0.2733235 Test Loss: 0.3972820
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.62739896774292
Epoch: 71, Steps: 65 | Train Loss: 0.5362192 Vali Loss: 0.2733250 Test Loss: 0.3972871
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.7750918865203857
Epoch: 72, Steps: 65 | Train Loss: 0.5369772 Vali Loss: 0.2733427 Test Loss: 0.3972840
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.7754251956939697
Epoch: 73, Steps: 65 | Train Loss: 0.5352967 Vali Loss: 0.2733217 Test Loss: 0.3972867
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.8672552108764648
Epoch: 74, Steps: 65 | Train Loss: 0.5355091 Vali Loss: 0.2731764 Test Loss: 0.3972898
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.748497724533081
Epoch: 75, Steps: 65 | Train Loss: 0.5357562 Vali Loss: 0.2733246 Test Loss: 0.3972848
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.498307228088379
Epoch: 76, Steps: 65 | Train Loss: 0.5362404 Vali Loss: 0.2731848 Test Loss: 0.3972918
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.6417906284332275
Epoch: 77, Steps: 65 | Train Loss: 0.5369034 Vali Loss: 0.2733181 Test Loss: 0.3972936
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.666752815246582
Epoch: 78, Steps: 65 | Train Loss: 0.5360943 Vali Loss: 0.2732664 Test Loss: 0.3972916
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.7508289813995361
Epoch: 79, Steps: 65 | Train Loss: 0.5358446 Vali Loss: 0.2730096 Test Loss: 0.3972935
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.410179615020752
Epoch: 80, Steps: 65 | Train Loss: 0.5350434 Vali Loss: 0.2732519 Test Loss: 0.3972935
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.0914719104766846
Epoch: 81, Steps: 65 | Train Loss: 0.5349424 Vali Loss: 0.2732692 Test Loss: 0.3972943
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 2.1561713218688965
Epoch: 82, Steps: 65 | Train Loss: 0.5348404 Vali Loss: 0.2733288 Test Loss: 0.3972949
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.7365443706512451
Epoch: 83, Steps: 65 | Train Loss: 0.5361465 Vali Loss: 0.2730260 Test Loss: 0.3972964
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_90_192_FITS_ETTh2_ftM_sl90_ll48_pl192_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.37687405943870544, mae:0.39069077372550964, rse:0.49231037497520447, corr:[0.26731735 0.27017328 0.26786143 0.2667741  0.26649106 0.26552764
 0.264461   0.2635907  0.26312304 0.26213196 0.26077548 0.2591037
 0.25737476 0.2561108  0.255107   0.25445813 0.25399646 0.2536069
 0.252958   0.2518301  0.25072393 0.2497079  0.24846637 0.24634634
 0.24311818 0.24060825 0.238419   0.23658782 0.23502867 0.23370509
 0.23271528 0.23089379 0.22924957 0.22798334 0.2270711  0.22552185
 0.2236231  0.2224312  0.22148263 0.22042911 0.21969268 0.21947658
 0.2193051  0.21822141 0.21708742 0.21625976 0.21520895 0.21302593
 0.20936613 0.20654733 0.20419376 0.20203462 0.20000826 0.19810931
 0.19649999 0.19386265 0.19197191 0.19055173 0.18979709 0.18850033
 0.18703419 0.18669128 0.18677932 0.18654157 0.18598959 0.18562013
 0.18536304 0.18456495 0.18390554 0.1835082  0.18269269 0.1812591
 0.1787027  0.17712805 0.17575975 0.1744997  0.17343332 0.17299464
 0.1729716  0.17172201 0.17106825 0.1708597  0.17079557 0.17023312
 0.16938934 0.16924551 0.16937388 0.16935124 0.16895534 0.16856262
 0.16822638 0.16756013 0.16736773 0.16724016 0.16663982 0.16537246
 0.1630538  0.16127118 0.15947822 0.15787038 0.15664712 0.15587717
 0.15595284 0.15503302 0.1546429  0.15460238 0.15472381 0.1543727
 0.15345564 0.15302023 0.15252334 0.15200281 0.15155572 0.15131834
 0.15126503 0.15054545 0.14984903 0.14914316 0.14767347 0.14535998
 0.14247788 0.14061822 0.13896519 0.13771144 0.13635527 0.13543138
 0.13523148 0.13438973 0.13388197 0.13352779 0.13332605 0.13252677
 0.13162217 0.13125737 0.13099666 0.13048942 0.12993306 0.12968512
 0.12942092 0.12862791 0.12807615 0.12786323 0.12683551 0.12454317
 0.12101667 0.1186747  0.11683907 0.11524679 0.11381409 0.11278834
 0.11269775 0.11182249 0.11141091 0.11114789 0.11109731 0.11049776
 0.10978913 0.10978704 0.10985298 0.10980201 0.10952682 0.10939112
 0.10946246 0.10899534 0.10887122 0.10909388 0.1089913  0.10754786
 0.10445103 0.10257249 0.10131928 0.10043272 0.09957075 0.09884921
 0.09877837 0.09796073 0.0977422  0.09774318 0.0979415  0.09710564
 0.09610275 0.09620325 0.09644784 0.09649576 0.09580294 0.09556648
 0.09622023 0.09610026 0.09550238 0.09569305 0.09726388 0.09907164]
