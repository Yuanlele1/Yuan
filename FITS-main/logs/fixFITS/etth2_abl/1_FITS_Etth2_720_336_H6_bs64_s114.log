Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_336_FITS_ETTh2_ftM_sl720_ll48_pl336_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=196, out_features=287, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  50401792.0
params:  56539.0
Trainable parameters:  56539
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.9878077507019043
Epoch: 1, Steps: 59 | Train Loss: 0.8275458 Vali Loss: 0.5094085 Test Loss: 0.3947662
Validation loss decreased (inf --> 0.509408).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.2710232734680176
Epoch: 2, Steps: 59 | Train Loss: 0.6995164 Vali Loss: 0.4534453 Test Loss: 0.3752927
Validation loss decreased (0.509408 --> 0.453445).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.2340080738067627
Epoch: 3, Steps: 59 | Train Loss: 0.6679406 Vali Loss: 0.4299752 Test Loss: 0.3685392
Validation loss decreased (0.453445 --> 0.429975).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.9182567596435547
Epoch: 4, Steps: 59 | Train Loss: 0.6544390 Vali Loss: 0.4168161 Test Loss: 0.3652873
Validation loss decreased (0.429975 --> 0.416816).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.319873571395874
Epoch: 5, Steps: 59 | Train Loss: 0.6454352 Vali Loss: 0.4122109 Test Loss: 0.3629307
Validation loss decreased (0.416816 --> 0.412211).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.076465129852295
Epoch: 6, Steps: 59 | Train Loss: 0.6387241 Vali Loss: 0.4063334 Test Loss: 0.3617113
Validation loss decreased (0.412211 --> 0.406333).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.002460241317749
Epoch: 7, Steps: 59 | Train Loss: 0.6362970 Vali Loss: 0.4034076 Test Loss: 0.3610323
Validation loss decreased (0.406333 --> 0.403408).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.0679984092712402
Epoch: 8, Steps: 59 | Train Loss: 0.6311430 Vali Loss: 0.4017559 Test Loss: 0.3602428
Validation loss decreased (0.403408 --> 0.401756).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.2110135555267334
Epoch: 9, Steps: 59 | Train Loss: 0.6290678 Vali Loss: 0.3992435 Test Loss: 0.3597837
Validation loss decreased (0.401756 --> 0.399243).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.9501221179962158
Epoch: 10, Steps: 59 | Train Loss: 0.6252750 Vali Loss: 0.3955873 Test Loss: 0.3594921
Validation loss decreased (0.399243 --> 0.395587).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.180424213409424
Epoch: 11, Steps: 59 | Train Loss: 0.6253810 Vali Loss: 0.3962124 Test Loss: 0.3592274
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.7846417427062988
Epoch: 12, Steps: 59 | Train Loss: 0.6249428 Vali Loss: 0.3918113 Test Loss: 0.3589538
Validation loss decreased (0.395587 --> 0.391811).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.488373041152954
Epoch: 13, Steps: 59 | Train Loss: 0.6235676 Vali Loss: 0.3891387 Test Loss: 0.3590615
Validation loss decreased (0.391811 --> 0.389139).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.8494329452514648
Epoch: 14, Steps: 59 | Train Loss: 0.6229047 Vali Loss: 0.3900878 Test Loss: 0.3588305
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.399125576019287
Epoch: 15, Steps: 59 | Train Loss: 0.6221668 Vali Loss: 0.3892686 Test Loss: 0.3588248
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.016906499862671
Epoch: 16, Steps: 59 | Train Loss: 0.6197807 Vali Loss: 0.3900938 Test Loss: 0.3586052
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.0891802310943604
Epoch: 17, Steps: 59 | Train Loss: 0.6205434 Vali Loss: 0.3896236 Test Loss: 0.3586302
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.4048049449920654
Epoch: 18, Steps: 59 | Train Loss: 0.6197809 Vali Loss: 0.3880681 Test Loss: 0.3585287
Validation loss decreased (0.389139 --> 0.388068).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.0443661212921143
Epoch: 19, Steps: 59 | Train Loss: 0.6183327 Vali Loss: 0.3881854 Test Loss: 0.3585451
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.3460590839385986
Epoch: 20, Steps: 59 | Train Loss: 0.6167696 Vali Loss: 0.3892353 Test Loss: 0.3585518
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.9396955966949463
Epoch: 21, Steps: 59 | Train Loss: 0.6164086 Vali Loss: 0.3852351 Test Loss: 0.3585779
Validation loss decreased (0.388068 --> 0.385235).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.590240478515625
Epoch: 22, Steps: 59 | Train Loss: 0.6170582 Vali Loss: 0.3860608 Test Loss: 0.3585221
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.7644634246826172
Epoch: 23, Steps: 59 | Train Loss: 0.6168530 Vali Loss: 0.3861267 Test Loss: 0.3584111
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.7421691417694092
Epoch: 24, Steps: 59 | Train Loss: 0.6165656 Vali Loss: 0.3873576 Test Loss: 0.3584600
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.6109750270843506
Epoch: 25, Steps: 59 | Train Loss: 0.6163022 Vali Loss: 0.3845982 Test Loss: 0.3584073
Validation loss decreased (0.385235 --> 0.384598).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.6761884689331055
Epoch: 26, Steps: 59 | Train Loss: 0.6154485 Vali Loss: 0.3833666 Test Loss: 0.3583727
Validation loss decreased (0.384598 --> 0.383367).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.6688005924224854
Epoch: 27, Steps: 59 | Train Loss: 0.6165451 Vali Loss: 0.3867969 Test Loss: 0.3583592
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.4402775764465332
Epoch: 28, Steps: 59 | Train Loss: 0.6149411 Vali Loss: 0.3845730 Test Loss: 0.3583230
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.4593582153320312
Epoch: 29, Steps: 59 | Train Loss: 0.6157451 Vali Loss: 0.3837790 Test Loss: 0.3582790
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.5012736320495605
Epoch: 30, Steps: 59 | Train Loss: 0.6154772 Vali Loss: 0.3799607 Test Loss: 0.3582762
Validation loss decreased (0.383367 --> 0.379961).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.6449353694915771
Epoch: 31, Steps: 59 | Train Loss: 0.6137659 Vali Loss: 0.3872651 Test Loss: 0.3583186
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.7652201652526855
Epoch: 32, Steps: 59 | Train Loss: 0.6150386 Vali Loss: 0.3824737 Test Loss: 0.3582727
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.6690547466278076
Epoch: 33, Steps: 59 | Train Loss: 0.6146907 Vali Loss: 0.3832010 Test Loss: 0.3582356
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.700024127960205
Epoch: 34, Steps: 59 | Train Loss: 0.6144099 Vali Loss: 0.3815154 Test Loss: 0.3581817
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.4603760242462158
Epoch: 35, Steps: 59 | Train Loss: 0.6147605 Vali Loss: 0.3831825 Test Loss: 0.3581850
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.735874891281128
Epoch: 36, Steps: 59 | Train Loss: 0.6126875 Vali Loss: 0.3840229 Test Loss: 0.3582543
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.829115629196167
Epoch: 37, Steps: 59 | Train Loss: 0.6127797 Vali Loss: 0.3812055 Test Loss: 0.3582522
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.6955137252807617
Epoch: 38, Steps: 59 | Train Loss: 0.6144488 Vali Loss: 0.3854738 Test Loss: 0.3582208
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.8176157474517822
Epoch: 39, Steps: 59 | Train Loss: 0.6129583 Vali Loss: 0.3814605 Test Loss: 0.3582436
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.7347078323364258
Epoch: 40, Steps: 59 | Train Loss: 0.6141526 Vali Loss: 0.3836894 Test Loss: 0.3582239
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.597904920578003
Epoch: 41, Steps: 59 | Train Loss: 0.6140888 Vali Loss: 0.3807170 Test Loss: 0.3582554
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.75437593460083
Epoch: 42, Steps: 59 | Train Loss: 0.6125383 Vali Loss: 0.3808008 Test Loss: 0.3581702
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.6317229270935059
Epoch: 43, Steps: 59 | Train Loss: 0.6130971 Vali Loss: 0.3808164 Test Loss: 0.3581678
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.6804766654968262
Epoch: 44, Steps: 59 | Train Loss: 0.6131080 Vali Loss: 0.3819224 Test Loss: 0.3582474
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.4709665775299072
Epoch: 45, Steps: 59 | Train Loss: 0.6126841 Vali Loss: 0.3831930 Test Loss: 0.3582035
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.5970511436462402
Epoch: 46, Steps: 59 | Train Loss: 0.6124308 Vali Loss: 0.3810955 Test Loss: 0.3582132
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.7014265060424805
Epoch: 47, Steps: 59 | Train Loss: 0.6139864 Vali Loss: 0.3823020 Test Loss: 0.3582068
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.9418880939483643
Epoch: 48, Steps: 59 | Train Loss: 0.6136758 Vali Loss: 0.3830918 Test Loss: 0.3582030
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.795116901397705
Epoch: 49, Steps: 59 | Train Loss: 0.6137217 Vali Loss: 0.3825802 Test Loss: 0.3582069
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.596343755722046
Epoch: 50, Steps: 59 | Train Loss: 0.6138224 Vali Loss: 0.3816509 Test Loss: 0.3582279
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_720_336_FITS_ETTh2_ftM_sl720_ll48_pl336_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.3540552258491516, mae:0.3957543969154358, rse:0.47574588656425476, corr:[0.25879028 0.26348677 0.26072505 0.2627567  0.26256454 0.26039258
 0.26082045 0.26110002 0.2589894  0.25771302 0.2574988  0.2561544
 0.2544937  0.25385556 0.25346205 0.25236225 0.2516467  0.25145596
 0.25081128 0.24939317 0.24831584 0.2477622  0.24662717 0.24513067
 0.24370973 0.24250326 0.24119993 0.240191   0.23947957 0.23864502
 0.2376775  0.23675898 0.23605798 0.23515987 0.23417804 0.23336962
 0.23277646 0.23206303 0.23103298 0.23026235 0.22991583 0.22940065
 0.22845602 0.22741485 0.22649771 0.22577485 0.22457486 0.22272092
 0.22106309 0.21985449 0.2185702  0.21714091 0.21562181 0.21383274
 0.21209696 0.21072292 0.20922743 0.20761035 0.20640707 0.2054961
 0.20465006 0.2043443  0.20470339 0.20464887 0.20385763 0.2034024
 0.20307474 0.20244214 0.20172048 0.20137987 0.2010383  0.20040289
 0.19956712 0.19853586 0.1971835  0.19585161 0.19526653 0.19498107
 0.19441183 0.19388528 0.19369808 0.19305566 0.19219466 0.19194661
 0.19202296 0.19166444 0.19117695 0.19102895 0.19069333 0.1899367
 0.18946345 0.18949789 0.18947391 0.18915255 0.18918699 0.18930145
 0.18878886 0.1878742  0.18733221 0.18695095 0.18644224 0.1860119
 0.18586269 0.18534449 0.18460436 0.1840552  0.18404841 0.18391629
 0.18333967 0.18279092 0.18231037 0.18187667 0.1813252  0.18079542
 0.18012333 0.17961197 0.17936595 0.17863247 0.17737187 0.17604767
 0.1750944  0.1743626  0.17375599 0.17310627 0.1722196  0.17126451
 0.17062455 0.17026475 0.1694852  0.16824177 0.1673783  0.16684143
 0.16602284 0.16501684 0.16476831 0.16483124 0.16415986 0.16320251
 0.16267487 0.16228542 0.1616088  0.16105263 0.16060728 0.15925308
 0.15725486 0.15620378 0.15572508 0.15438433 0.15276596 0.15248984
 0.15269426 0.15154989 0.15000498 0.14933188 0.14901182 0.1481388
 0.14746305 0.14746015 0.14719558 0.14622279 0.14547713 0.14548723
 0.14499506 0.14408301 0.1440586  0.14454779 0.14411066 0.1426904
 0.1415879  0.14075801 0.13988164 0.13913575 0.13856165 0.1373334
 0.13584737 0.13449803 0.13357902 0.13276295 0.13191248 0.1313945
 0.13063908 0.12978072 0.12950717 0.12953295 0.12877314 0.12822245
 0.12854813 0.12891255 0.12872477 0.12867674 0.12937036 0.12920736
 0.1279462  0.12709142 0.12701446 0.12676702 0.12594786 0.12537162
 0.12497529 0.12384929 0.12272229 0.12260856 0.12337682 0.1239552
 0.12372103 0.1227851  0.12149992 0.12133917 0.122332   0.12294879
 0.12248231 0.12254106 0.12349579 0.12338194 0.12180305 0.12071937
 0.1208915  0.12042479 0.11889817 0.11829308 0.11859996 0.11838907
 0.11728341 0.11717239 0.11755423 0.11711747 0.11620372 0.11576381
 0.11552596 0.11519926 0.11505083 0.11543187 0.11548037 0.11557025
 0.11612526 0.116693   0.11675428 0.11691701 0.11714163 0.11652173
 0.11528786 0.11472765 0.11488868 0.11482944 0.11436868 0.11412629
 0.11389056 0.11316094 0.11325914 0.11424814 0.11454852 0.11418108
 0.11433319 0.1152928  0.11536545 0.11579393 0.11730229 0.11909258
 0.11931365 0.11919816 0.11982346 0.12000833 0.12007412 0.12082703
 0.12184533 0.1213972  0.12080862 0.12144972 0.12156156 0.1201153
 0.11932617 0.12070733 0.12182526 0.12074495 0.12042128 0.1210492
 0.12069517 0.11954933 0.1200033  0.12141114 0.12141129 0.12093408
 0.12177901 0.12234092 0.12094747 0.12021189 0.12154371 0.12204576
 0.12062731 0.11991824 0.12038931 0.11988243 0.11841261 0.11779576
 0.11773274 0.11667258 0.11602315 0.11654748 0.11653071 0.11518401
 0.11470812 0.11593071 0.11623544 0.11625478 0.11716523 0.11862531
 0.11799016 0.11735865 0.11779923 0.11790884 0.11741838 0.11775839
 0.11808083 0.11637717 0.1153148  0.11612197 0.11594869 0.11388185
 0.11361454 0.11557532 0.11528029 0.11433119 0.11567339 0.11766724
 0.11687208 0.1168621  0.11956795 0.12056512 0.11972915 0.12110484
 0.12213568 0.12010054 0.12141593 0.12535189 0.12347597 0.1217064 ]
