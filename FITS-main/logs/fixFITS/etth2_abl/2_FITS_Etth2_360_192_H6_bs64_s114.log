Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_360_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_360_192_FITS_ETTh2_ftM_sl360_ll48_pl192_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8089
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=106, out_features=162, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  15386112.0
params:  17334.0
Trainable parameters:  17334
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.5630102157592773
Epoch: 1, Steps: 63 | Train Loss: 0.5592259 Vali Loss: 0.4153657 Test Loss: 0.4699005
Validation loss decreased (inf --> 0.415366).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.3538928031921387
Epoch: 2, Steps: 63 | Train Loss: 0.4413285 Vali Loss: 0.3744875 Test Loss: 0.4326789
Validation loss decreased (0.415366 --> 0.374488).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.3390944004058838
Epoch: 3, Steps: 63 | Train Loss: 0.3814674 Vali Loss: 0.3533469 Test Loss: 0.4153381
Validation loss decreased (0.374488 --> 0.353347).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.49001145362854
Epoch: 4, Steps: 63 | Train Loss: 0.3455105 Vali Loss: 0.3408574 Test Loss: 0.4066656
Validation loss decreased (0.353347 --> 0.340857).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.8314456939697266
Epoch: 5, Steps: 63 | Train Loss: 0.3217116 Vali Loss: 0.3323440 Test Loss: 0.4015482
Validation loss decreased (0.340857 --> 0.332344).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.2216086387634277
Epoch: 6, Steps: 63 | Train Loss: 0.3044408 Vali Loss: 0.3267615 Test Loss: 0.3979543
Validation loss decreased (0.332344 --> 0.326762).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.3443167209625244
Epoch: 7, Steps: 63 | Train Loss: 0.2904644 Vali Loss: 0.3220832 Test Loss: 0.3952895
Validation loss decreased (0.326762 --> 0.322083).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.6921393871307373
Epoch: 8, Steps: 63 | Train Loss: 0.2791984 Vali Loss: 0.3183935 Test Loss: 0.3929648
Validation loss decreased (0.322083 --> 0.318394).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.724921464920044
Epoch: 9, Steps: 63 | Train Loss: 0.2703184 Vali Loss: 0.3155198 Test Loss: 0.3908439
Validation loss decreased (0.318394 --> 0.315520).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.854990005493164
Epoch: 10, Steps: 63 | Train Loss: 0.2617838 Vali Loss: 0.3129240 Test Loss: 0.3890457
Validation loss decreased (0.315520 --> 0.312924).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.0643277168273926
Epoch: 11, Steps: 63 | Train Loss: 0.2552702 Vali Loss: 0.3107004 Test Loss: 0.3873198
Validation loss decreased (0.312924 --> 0.310700).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.067795753479004
Epoch: 12, Steps: 63 | Train Loss: 0.2494256 Vali Loss: 0.3087128 Test Loss: 0.3856788
Validation loss decreased (0.310700 --> 0.308713).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.6804924011230469
Epoch: 13, Steps: 63 | Train Loss: 0.2446162 Vali Loss: 0.3070252 Test Loss: 0.3842210
Validation loss decreased (0.308713 --> 0.307025).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.2949445247650146
Epoch: 14, Steps: 63 | Train Loss: 0.2400767 Vali Loss: 0.3054783 Test Loss: 0.3828243
Validation loss decreased (0.307025 --> 0.305478).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.6622686386108398
Epoch: 15, Steps: 63 | Train Loss: 0.2359115 Vali Loss: 0.3039934 Test Loss: 0.3814960
Validation loss decreased (0.305478 --> 0.303993).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.2571873664855957
Epoch: 16, Steps: 63 | Train Loss: 0.2321511 Vali Loss: 0.3027903 Test Loss: 0.3805127
Validation loss decreased (0.303993 --> 0.302790).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.2951819896697998
Epoch: 17, Steps: 63 | Train Loss: 0.2292933 Vali Loss: 0.3016533 Test Loss: 0.3793553
Validation loss decreased (0.302790 --> 0.301653).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.6248376369476318
Epoch: 18, Steps: 63 | Train Loss: 0.2265727 Vali Loss: 0.3005807 Test Loss: 0.3782672
Validation loss decreased (0.301653 --> 0.300581).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.3938829898834229
Epoch: 19, Steps: 63 | Train Loss: 0.2241912 Vali Loss: 0.2997544 Test Loss: 0.3774053
Validation loss decreased (0.300581 --> 0.299754).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.656207799911499
Epoch: 20, Steps: 63 | Train Loss: 0.2213446 Vali Loss: 0.2988391 Test Loss: 0.3764796
Validation loss decreased (0.299754 --> 0.298839).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.455362319946289
Epoch: 21, Steps: 63 | Train Loss: 0.2200486 Vali Loss: 0.2979570 Test Loss: 0.3756956
Validation loss decreased (0.298839 --> 0.297957).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.505882978439331
Epoch: 22, Steps: 63 | Train Loss: 0.2182145 Vali Loss: 0.2973258 Test Loss: 0.3748877
Validation loss decreased (0.297957 --> 0.297326).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.3204686641693115
Epoch: 23, Steps: 63 | Train Loss: 0.2163909 Vali Loss: 0.2967022 Test Loss: 0.3741719
Validation loss decreased (0.297326 --> 0.296702).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.673032283782959
Epoch: 24, Steps: 63 | Train Loss: 0.2148451 Vali Loss: 0.2960527 Test Loss: 0.3735149
Validation loss decreased (0.296702 --> 0.296053).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.5317740440368652
Epoch: 25, Steps: 63 | Train Loss: 0.2137054 Vali Loss: 0.2954012 Test Loss: 0.3729052
Validation loss decreased (0.296053 --> 0.295401).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.9058449268341064
Epoch: 26, Steps: 63 | Train Loss: 0.2122269 Vali Loss: 0.2949702 Test Loss: 0.3723426
Validation loss decreased (0.295401 --> 0.294970).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.7694892883300781
Epoch: 27, Steps: 63 | Train Loss: 0.2112113 Vali Loss: 0.2944505 Test Loss: 0.3718322
Validation loss decreased (0.294970 --> 0.294450).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.3648030757904053
Epoch: 28, Steps: 63 | Train Loss: 0.2102566 Vali Loss: 0.2939385 Test Loss: 0.3713081
Validation loss decreased (0.294450 --> 0.293938).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.5415878295898438
Epoch: 29, Steps: 63 | Train Loss: 0.2093121 Vali Loss: 0.2935776 Test Loss: 0.3707931
Validation loss decreased (0.293938 --> 0.293578).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.8858838081359863
Epoch: 30, Steps: 63 | Train Loss: 0.2081449 Vali Loss: 0.2931084 Test Loss: 0.3703310
Validation loss decreased (0.293578 --> 0.293108).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.2606167793273926
Epoch: 31, Steps: 63 | Train Loss: 0.2076651 Vali Loss: 0.2927917 Test Loss: 0.3699212
Validation loss decreased (0.293108 --> 0.292792).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.2906310558319092
Epoch: 32, Steps: 63 | Train Loss: 0.2069823 Vali Loss: 0.2924852 Test Loss: 0.3695170
Validation loss decreased (0.292792 --> 0.292485).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.4150869846343994
Epoch: 33, Steps: 63 | Train Loss: 0.2062083 Vali Loss: 0.2921096 Test Loss: 0.3691205
Validation loss decreased (0.292485 --> 0.292110).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.519395351409912
Epoch: 34, Steps: 63 | Train Loss: 0.2055351 Vali Loss: 0.2918554 Test Loss: 0.3687124
Validation loss decreased (0.292110 --> 0.291855).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.7015810012817383
Epoch: 35, Steps: 63 | Train Loss: 0.2048600 Vali Loss: 0.2916316 Test Loss: 0.3684118
Validation loss decreased (0.291855 --> 0.291632).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.8831017017364502
Epoch: 36, Steps: 63 | Train Loss: 0.2043262 Vali Loss: 0.2912909 Test Loss: 0.3680993
Validation loss decreased (0.291632 --> 0.291291).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.4451968669891357
Epoch: 37, Steps: 63 | Train Loss: 0.2039873 Vali Loss: 0.2910521 Test Loss: 0.3678217
Validation loss decreased (0.291291 --> 0.291052).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.247962236404419
Epoch: 38, Steps: 63 | Train Loss: 0.2031861 Vali Loss: 0.2908234 Test Loss: 0.3675377
Validation loss decreased (0.291052 --> 0.290823).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.8419373035430908
Epoch: 39, Steps: 63 | Train Loss: 0.2027454 Vali Loss: 0.2906438 Test Loss: 0.3673052
Validation loss decreased (0.290823 --> 0.290644).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.6117877960205078
Epoch: 40, Steps: 63 | Train Loss: 0.2021324 Vali Loss: 0.2904663 Test Loss: 0.3670225
Validation loss decreased (0.290644 --> 0.290466).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.0302131175994873
Epoch: 41, Steps: 63 | Train Loss: 0.2016919 Vali Loss: 0.2902533 Test Loss: 0.3668089
Validation loss decreased (0.290466 --> 0.290253).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.071739912033081
Epoch: 42, Steps: 63 | Train Loss: 0.2018886 Vali Loss: 0.2900745 Test Loss: 0.3665625
Validation loss decreased (0.290253 --> 0.290074).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.5761613845825195
Epoch: 43, Steps: 63 | Train Loss: 0.2016972 Vali Loss: 0.2899698 Test Loss: 0.3663810
Validation loss decreased (0.290074 --> 0.289970).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.5887782573699951
Epoch: 44, Steps: 63 | Train Loss: 0.2010292 Vali Loss: 0.2898005 Test Loss: 0.3661425
Validation loss decreased (0.289970 --> 0.289800).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.5189433097839355
Epoch: 45, Steps: 63 | Train Loss: 0.2009357 Vali Loss: 0.2896153 Test Loss: 0.3659335
Validation loss decreased (0.289800 --> 0.289615).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.616241693496704
Epoch: 46, Steps: 63 | Train Loss: 0.2007156 Vali Loss: 0.2895275 Test Loss: 0.3657440
Validation loss decreased (0.289615 --> 0.289527).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.1917564868927002
Epoch: 47, Steps: 63 | Train Loss: 0.2003836 Vali Loss: 0.2893737 Test Loss: 0.3656301
Validation loss decreased (0.289527 --> 0.289374).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.6122910976409912
Epoch: 48, Steps: 63 | Train Loss: 0.1996971 Vali Loss: 0.2892601 Test Loss: 0.3654383
Validation loss decreased (0.289374 --> 0.289260).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.217599868774414
Epoch: 49, Steps: 63 | Train Loss: 0.1996580 Vali Loss: 0.2891666 Test Loss: 0.3652794
Validation loss decreased (0.289260 --> 0.289167).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.5978131294250488
Epoch: 50, Steps: 63 | Train Loss: 0.1992430 Vali Loss: 0.2889652 Test Loss: 0.3651738
Validation loss decreased (0.289167 --> 0.288965).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.3318207263946533
Epoch: 51, Steps: 63 | Train Loss: 0.1993947 Vali Loss: 0.2889430 Test Loss: 0.3650122
Validation loss decreased (0.288965 --> 0.288943).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.207796573638916
Epoch: 52, Steps: 63 | Train Loss: 0.1993351 Vali Loss: 0.2887864 Test Loss: 0.3648828
Validation loss decreased (0.288943 --> 0.288786).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.2471668720245361
Epoch: 53, Steps: 63 | Train Loss: 0.1984816 Vali Loss: 0.2886273 Test Loss: 0.3647496
Validation loss decreased (0.288786 --> 0.288627).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.3606135845184326
Epoch: 54, Steps: 63 | Train Loss: 0.1991066 Vali Loss: 0.2886795 Test Loss: 0.3646019
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.4147145748138428
Epoch: 55, Steps: 63 | Train Loss: 0.1983037 Vali Loss: 0.2884932 Test Loss: 0.3645020
Validation loss decreased (0.288627 --> 0.288493).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.789442777633667
Epoch: 56, Steps: 63 | Train Loss: 0.1986927 Vali Loss: 0.2884756 Test Loss: 0.3644075
Validation loss decreased (0.288493 --> 0.288476).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.321716070175171
Epoch: 57, Steps: 63 | Train Loss: 0.1985847 Vali Loss: 0.2884181 Test Loss: 0.3642983
Validation loss decreased (0.288476 --> 0.288418).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.5453433990478516
Epoch: 58, Steps: 63 | Train Loss: 0.1983698 Vali Loss: 0.2883255 Test Loss: 0.3641927
Validation loss decreased (0.288418 --> 0.288325).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.7294337749481201
Epoch: 59, Steps: 63 | Train Loss: 0.1983005 Vali Loss: 0.2882340 Test Loss: 0.3641150
Validation loss decreased (0.288325 --> 0.288234).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.477424144744873
Epoch: 60, Steps: 63 | Train Loss: 0.1981248 Vali Loss: 0.2882167 Test Loss: 0.3640320
Validation loss decreased (0.288234 --> 0.288217).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.1000590324401855
Epoch: 61, Steps: 63 | Train Loss: 0.1976624 Vali Loss: 0.2881213 Test Loss: 0.3639353
Validation loss decreased (0.288217 --> 0.288121).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.9745452404022217
Epoch: 62, Steps: 63 | Train Loss: 0.1978479 Vali Loss: 0.2881462 Test Loss: 0.3638495
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.9567713737487793
Epoch: 63, Steps: 63 | Train Loss: 0.1978463 Vali Loss: 0.2879562 Test Loss: 0.3637891
Validation loss decreased (0.288121 --> 0.287956).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.6006619930267334
Epoch: 64, Steps: 63 | Train Loss: 0.1978539 Vali Loss: 0.2880002 Test Loss: 0.3637069
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.4074609279632568
Epoch: 65, Steps: 63 | Train Loss: 0.1977185 Vali Loss: 0.2879742 Test Loss: 0.3636414
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.1619293689727783
Epoch: 66, Steps: 63 | Train Loss: 0.1974075 Vali Loss: 0.2879381 Test Loss: 0.3635834
Validation loss decreased (0.287956 --> 0.287938).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.678938627243042
Epoch: 67, Steps: 63 | Train Loss: 0.1973024 Vali Loss: 0.2879108 Test Loss: 0.3635076
Validation loss decreased (0.287938 --> 0.287911).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.9347853660583496
Epoch: 68, Steps: 63 | Train Loss: 0.1971416 Vali Loss: 0.2878574 Test Loss: 0.3634468
Validation loss decreased (0.287911 --> 0.287857).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.672081470489502
Epoch: 69, Steps: 63 | Train Loss: 0.1969688 Vali Loss: 0.2877780 Test Loss: 0.3633838
Validation loss decreased (0.287857 --> 0.287778).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.952500820159912
Epoch: 70, Steps: 63 | Train Loss: 0.1972735 Vali Loss: 0.2877925 Test Loss: 0.3633404
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.566688060760498
Epoch: 71, Steps: 63 | Train Loss: 0.1971177 Vali Loss: 0.2877435 Test Loss: 0.3632779
Validation loss decreased (0.287778 --> 0.287744).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.57527756690979
Epoch: 72, Steps: 63 | Train Loss: 0.1972169 Vali Loss: 0.2876537 Test Loss: 0.3632272
Validation loss decreased (0.287744 --> 0.287654).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.7328050136566162
Epoch: 73, Steps: 63 | Train Loss: 0.1969362 Vali Loss: 0.2877115 Test Loss: 0.3631892
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.359837532043457
Epoch: 74, Steps: 63 | Train Loss: 0.1969499 Vali Loss: 0.2876746 Test Loss: 0.3631388
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.4508891105651855
Epoch: 75, Steps: 63 | Train Loss: 0.1968868 Vali Loss: 0.2876557 Test Loss: 0.3630975
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.2418179512023926
Epoch: 76, Steps: 63 | Train Loss: 0.1965685 Vali Loss: 0.2876306 Test Loss: 0.3630576
Validation loss decreased (0.287654 --> 0.287631).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.500763177871704
Epoch: 77, Steps: 63 | Train Loss: 0.1966290 Vali Loss: 0.2875999 Test Loss: 0.3630137
Validation loss decreased (0.287631 --> 0.287600).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.845304012298584
Epoch: 78, Steps: 63 | Train Loss: 0.1967598 Vali Loss: 0.2874436 Test Loss: 0.3629851
Validation loss decreased (0.287600 --> 0.287444).  Saving model ...
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.6974687576293945
Epoch: 79, Steps: 63 | Train Loss: 0.1967786 Vali Loss: 0.2874691 Test Loss: 0.3629448
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.9710898399353027
Epoch: 80, Steps: 63 | Train Loss: 0.1966295 Vali Loss: 0.2875208 Test Loss: 0.3629157
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.08363676071167
Epoch: 81, Steps: 63 | Train Loss: 0.1965970 Vali Loss: 0.2875350 Test Loss: 0.3628840
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.6043713092803955
Epoch: 82, Steps: 63 | Train Loss: 0.1961982 Vali Loss: 0.2874556 Test Loss: 0.3628530
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.429138422012329
Epoch: 83, Steps: 63 | Train Loss: 0.1962120 Vali Loss: 0.2874201 Test Loss: 0.3628248
Validation loss decreased (0.287444 --> 0.287420).  Saving model ...
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.9070920944213867
Epoch: 84, Steps: 63 | Train Loss: 0.1963938 Vali Loss: 0.2874089 Test Loss: 0.3627927
Validation loss decreased (0.287420 --> 0.287409).  Saving model ...
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.9009127616882324
Epoch: 85, Steps: 63 | Train Loss: 0.1964104 Vali Loss: 0.2873985 Test Loss: 0.3627651
Validation loss decreased (0.287409 --> 0.287398).  Saving model ...
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 2.615917205810547
Epoch: 86, Steps: 63 | Train Loss: 0.1966245 Vali Loss: 0.2874312 Test Loss: 0.3627459
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.427504539489746
Epoch: 87, Steps: 63 | Train Loss: 0.1959718 Vali Loss: 0.2874362 Test Loss: 0.3627208
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 2.0277609825134277
Epoch: 88, Steps: 63 | Train Loss: 0.1961576 Vali Loss: 0.2873173 Test Loss: 0.3626998
Validation loss decreased (0.287398 --> 0.287317).  Saving model ...
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.6098759174346924
Epoch: 89, Steps: 63 | Train Loss: 0.1961704 Vali Loss: 0.2874083 Test Loss: 0.3626750
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.86173677444458
Epoch: 90, Steps: 63 | Train Loss: 0.1958902 Vali Loss: 0.2873963 Test Loss: 0.3626553
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.5194365978240967
Epoch: 91, Steps: 63 | Train Loss: 0.1963336 Vali Loss: 0.2873728 Test Loss: 0.3626349
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.65566086769104
Epoch: 92, Steps: 63 | Train Loss: 0.1962138 Vali Loss: 0.2872735 Test Loss: 0.3626160
Validation loss decreased (0.287317 --> 0.287273).  Saving model ...
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.4791786670684814
Epoch: 93, Steps: 63 | Train Loss: 0.1957324 Vali Loss: 0.2872787 Test Loss: 0.3625941
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.4613542556762695
Epoch: 94, Steps: 63 | Train Loss: 0.1960810 Vali Loss: 0.2873333 Test Loss: 0.3625835
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.5727589130401611
Epoch: 95, Steps: 63 | Train Loss: 0.1963472 Vali Loss: 0.2869973 Test Loss: 0.3625615
Validation loss decreased (0.287273 --> 0.286997).  Saving model ...
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.4694008827209473
Epoch: 96, Steps: 63 | Train Loss: 0.1963245 Vali Loss: 0.2873165 Test Loss: 0.3625438
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.43015718460083
Epoch: 97, Steps: 63 | Train Loss: 0.1961979 Vali Loss: 0.2872816 Test Loss: 0.3625291
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 2.1770453453063965
Epoch: 98, Steps: 63 | Train Loss: 0.1961146 Vali Loss: 0.2873122 Test Loss: 0.3625205
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.6774230003356934
Epoch: 99, Steps: 63 | Train Loss: 0.1962353 Vali Loss: 0.2873154 Test Loss: 0.3625090
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.8840408325195312
Epoch: 100, Steps: 63 | Train Loss: 0.1961091 Vali Loss: 0.2872400 Test Loss: 0.3624949
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8089
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=106, out_features=162, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  15386112.0
params:  17334.0
Trainable parameters:  17334
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.4794745445251465
Epoch: 1, Steps: 63 | Train Loss: 0.5137535 Vali Loss: 0.2831014 Test Loss: 0.3559784
Validation loss decreased (inf --> 0.283101).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.6418652534484863
Epoch: 2, Steps: 63 | Train Loss: 0.5082649 Vali Loss: 0.2810321 Test Loss: 0.3540733
Validation loss decreased (0.283101 --> 0.281032).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.6174733638763428
Epoch: 3, Steps: 63 | Train Loss: 0.5068015 Vali Loss: 0.2803206 Test Loss: 0.3531987
Validation loss decreased (0.281032 --> 0.280321).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.234510898590088
Epoch: 4, Steps: 63 | Train Loss: 0.5044863 Vali Loss: 0.2793546 Test Loss: 0.3531896
Validation loss decreased (0.280321 --> 0.279355).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.6909265518188477
Epoch: 5, Steps: 63 | Train Loss: 0.5045955 Vali Loss: 0.2790410 Test Loss: 0.3532970
Validation loss decreased (0.279355 --> 0.279041).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.7686727046966553
Epoch: 6, Steps: 63 | Train Loss: 0.5042181 Vali Loss: 0.2789427 Test Loss: 0.3530332
Validation loss decreased (0.279041 --> 0.278943).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.8324522972106934
Epoch: 7, Steps: 63 | Train Loss: 0.5040566 Vali Loss: 0.2785344 Test Loss: 0.3530325
Validation loss decreased (0.278943 --> 0.278534).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.6940393447875977
Epoch: 8, Steps: 63 | Train Loss: 0.5047694 Vali Loss: 0.2780993 Test Loss: 0.3530707
Validation loss decreased (0.278534 --> 0.278099).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.536679983139038
Epoch: 9, Steps: 63 | Train Loss: 0.5040257 Vali Loss: 0.2781238 Test Loss: 0.3529132
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.7098681926727295
Epoch: 10, Steps: 63 | Train Loss: 0.5022678 Vali Loss: 0.2778631 Test Loss: 0.3531257
Validation loss decreased (0.278099 --> 0.277863).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.7712774276733398
Epoch: 11, Steps: 63 | Train Loss: 0.5029943 Vali Loss: 0.2776264 Test Loss: 0.3531251
Validation loss decreased (0.277863 --> 0.277626).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.6907386779785156
Epoch: 12, Steps: 63 | Train Loss: 0.5032651 Vali Loss: 0.2775491 Test Loss: 0.3530966
Validation loss decreased (0.277626 --> 0.277549).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.753922462463379
Epoch: 13, Steps: 63 | Train Loss: 0.5023069 Vali Loss: 0.2774270 Test Loss: 0.3528838
Validation loss decreased (0.277549 --> 0.277427).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.369598627090454
Epoch: 14, Steps: 63 | Train Loss: 0.5032358 Vali Loss: 0.2769304 Test Loss: 0.3529870
Validation loss decreased (0.277427 --> 0.276930).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.9857373237609863
Epoch: 15, Steps: 63 | Train Loss: 0.5025427 Vali Loss: 0.2773201 Test Loss: 0.3528301
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.4916412830352783
Epoch: 16, Steps: 63 | Train Loss: 0.5023532 Vali Loss: 0.2772107 Test Loss: 0.3528254
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.6098575592041016
Epoch: 17, Steps: 63 | Train Loss: 0.5028510 Vali Loss: 0.2771215 Test Loss: 0.3528006
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.258603572845459
Epoch: 18, Steps: 63 | Train Loss: 0.5019590 Vali Loss: 0.2768038 Test Loss: 0.3527233
Validation loss decreased (0.276930 --> 0.276804).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.9277582168579102
Epoch: 19, Steps: 63 | Train Loss: 0.5022398 Vali Loss: 0.2772089 Test Loss: 0.3526471
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.4288573265075684
Epoch: 20, Steps: 63 | Train Loss: 0.5027711 Vali Loss: 0.2770076 Test Loss: 0.3527156
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.5526533126831055
Epoch: 21, Steps: 63 | Train Loss: 0.5027140 Vali Loss: 0.2768943 Test Loss: 0.3526565
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.4156649112701416
Epoch: 22, Steps: 63 | Train Loss: 0.5016769 Vali Loss: 0.2767945 Test Loss: 0.3526113
Validation loss decreased (0.276804 --> 0.276794).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.815126895904541
Epoch: 23, Steps: 63 | Train Loss: 0.5020841 Vali Loss: 0.2769582 Test Loss: 0.3526045
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.0264174938201904
Epoch: 24, Steps: 63 | Train Loss: 0.5013521 Vali Loss: 0.2767159 Test Loss: 0.3526223
Validation loss decreased (0.276794 --> 0.276716).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.5040955543518066
Epoch: 25, Steps: 63 | Train Loss: 0.5012845 Vali Loss: 0.2767640 Test Loss: 0.3527101
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.661238670349121
Epoch: 26, Steps: 63 | Train Loss: 0.5020012 Vali Loss: 0.2768493 Test Loss: 0.3525870
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.506575584411621
Epoch: 27, Steps: 63 | Train Loss: 0.5023807 Vali Loss: 0.2766413 Test Loss: 0.3525509
Validation loss decreased (0.276716 --> 0.276641).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.869469404220581
Epoch: 28, Steps: 63 | Train Loss: 0.5018832 Vali Loss: 0.2765510 Test Loss: 0.3527119
Validation loss decreased (0.276641 --> 0.276551).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.238917350769043
Epoch: 29, Steps: 63 | Train Loss: 0.5014932 Vali Loss: 0.2766437 Test Loss: 0.3526345
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.7564449310302734
Epoch: 30, Steps: 63 | Train Loss: 0.5015981 Vali Loss: 0.2766677 Test Loss: 0.3525572
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.723829746246338
Epoch: 31, Steps: 63 | Train Loss: 0.5011481 Vali Loss: 0.2764964 Test Loss: 0.3525985
Validation loss decreased (0.276551 --> 0.276496).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.204193592071533
Epoch: 32, Steps: 63 | Train Loss: 0.5017581 Vali Loss: 0.2765567 Test Loss: 0.3526510
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.880553960800171
Epoch: 33, Steps: 63 | Train Loss: 0.5013532 Vali Loss: 0.2765458 Test Loss: 0.3525505
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.4030096530914307
Epoch: 34, Steps: 63 | Train Loss: 0.5015490 Vali Loss: 0.2763327 Test Loss: 0.3525259
Validation loss decreased (0.276496 --> 0.276333).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.8099298477172852
Epoch: 35, Steps: 63 | Train Loss: 0.5013758 Vali Loss: 0.2764817 Test Loss: 0.3525932
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.666764259338379
Epoch: 36, Steps: 63 | Train Loss: 0.5017956 Vali Loss: 0.2764556 Test Loss: 0.3525931
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.8829066753387451
Epoch: 37, Steps: 63 | Train Loss: 0.5011710 Vali Loss: 0.2764815 Test Loss: 0.3526183
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.5734262466430664
Epoch: 38, Steps: 63 | Train Loss: 0.5012207 Vali Loss: 0.2764526 Test Loss: 0.3525638
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.5652408599853516
Epoch: 39, Steps: 63 | Train Loss: 0.5015163 Vali Loss: 0.2764120 Test Loss: 0.3525932
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.7580687999725342
Epoch: 40, Steps: 63 | Train Loss: 0.5007610 Vali Loss: 0.2763748 Test Loss: 0.3526303
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.354707956314087
Epoch: 41, Steps: 63 | Train Loss: 0.4990001 Vali Loss: 0.2763701 Test Loss: 0.3525940
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.5872383117675781
Epoch: 42, Steps: 63 | Train Loss: 0.5010236 Vali Loss: 0.2763003 Test Loss: 0.3526654
Validation loss decreased (0.276333 --> 0.276300).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.5005602836608887
Epoch: 43, Steps: 63 | Train Loss: 0.5015090 Vali Loss: 0.2763894 Test Loss: 0.3525709
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.5714848041534424
Epoch: 44, Steps: 63 | Train Loss: 0.5003814 Vali Loss: 0.2762639 Test Loss: 0.3526253
Validation loss decreased (0.276300 --> 0.276264).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.65451979637146
Epoch: 45, Steps: 63 | Train Loss: 0.5006180 Vali Loss: 0.2761572 Test Loss: 0.3525771
Validation loss decreased (0.276264 --> 0.276157).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.0681238174438477
Epoch: 46, Steps: 63 | Train Loss: 0.5015955 Vali Loss: 0.2762527 Test Loss: 0.3526009
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.0363481044769287
Epoch: 47, Steps: 63 | Train Loss: 0.5009199 Vali Loss: 0.2762731 Test Loss: 0.3525861
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.6661384105682373
Epoch: 48, Steps: 63 | Train Loss: 0.5015664 Vali Loss: 0.2762836 Test Loss: 0.3526048
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.9686098098754883
Epoch: 49, Steps: 63 | Train Loss: 0.5013469 Vali Loss: 0.2763073 Test Loss: 0.3525927
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.2810466289520264
Epoch: 50, Steps: 63 | Train Loss: 0.4983851 Vali Loss: 0.2762739 Test Loss: 0.3525587
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.7455360889434814
Epoch: 51, Steps: 63 | Train Loss: 0.5002414 Vali Loss: 0.2761628 Test Loss: 0.3525989
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.1719202995300293
Epoch: 52, Steps: 63 | Train Loss: 0.5004720 Vali Loss: 0.2762623 Test Loss: 0.3526068
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.887333869934082
Epoch: 53, Steps: 63 | Train Loss: 0.5001720 Vali Loss: 0.2762098 Test Loss: 0.3525792
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.086390256881714
Epoch: 54, Steps: 63 | Train Loss: 0.5011629 Vali Loss: 0.2762297 Test Loss: 0.3525924
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.8791053295135498
Epoch: 55, Steps: 63 | Train Loss: 0.5009747 Vali Loss: 0.2762701 Test Loss: 0.3525821
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.5279934406280518
Epoch: 56, Steps: 63 | Train Loss: 0.5015732 Vali Loss: 0.2761682 Test Loss: 0.3525904
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.8541193008422852
Epoch: 57, Steps: 63 | Train Loss: 0.5011785 Vali Loss: 0.2761940 Test Loss: 0.3525846
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.4163146018981934
Epoch: 58, Steps: 63 | Train Loss: 0.5002892 Vali Loss: 0.2762125 Test Loss: 0.3525999
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.6973485946655273
Epoch: 59, Steps: 63 | Train Loss: 0.5017059 Vali Loss: 0.2762500 Test Loss: 0.3525609
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.5269043445587158
Epoch: 60, Steps: 63 | Train Loss: 0.5011508 Vali Loss: 0.2762424 Test Loss: 0.3525757
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.3206260204315186
Epoch: 61, Steps: 63 | Train Loss: 0.5003441 Vali Loss: 0.2762447 Test Loss: 0.3525806
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.408993721008301
Epoch: 62, Steps: 63 | Train Loss: 0.5011721 Vali Loss: 0.2762154 Test Loss: 0.3525661
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.2050118446350098
Epoch: 63, Steps: 63 | Train Loss: 0.4999813 Vali Loss: 0.2762273 Test Loss: 0.3525581
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.227731704711914
Epoch: 64, Steps: 63 | Train Loss: 0.5012152 Vali Loss: 0.2761985 Test Loss: 0.3525735
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.4838848114013672
Epoch: 65, Steps: 63 | Train Loss: 0.5011538 Vali Loss: 0.2762315 Test Loss: 0.3525651
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_360_192_FITS_ETTh2_ftM_sl360_ll48_pl192_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.33384594321250916, mae:0.37498393654823303, rse:0.46335509419441223, corr:[0.26814222 0.27009296 0.26763275 0.2679376  0.26646438 0.26454
 0.26428658 0.26334187 0.26171574 0.26068786 0.2597483  0.25788522
 0.25626525 0.25548533 0.25485173 0.25434908 0.25416055 0.2538905
 0.25296178 0.25184584 0.2506854  0.24939363 0.24796186 0.24612005
 0.2437595  0.24134172 0.23955922 0.23827739 0.23696166 0.23552974
 0.23436603 0.23290393 0.23095912 0.22946605 0.22853872 0.22740766
 0.22581238 0.22482151 0.22428773 0.22334802 0.22262242 0.22236313
 0.22175016 0.220594   0.21947376 0.21842898 0.21721026 0.21558702
 0.21375686 0.21180454 0.20999837 0.20866036 0.2075584  0.20602761
 0.20386727 0.20175873 0.20023161 0.19862093 0.19731344 0.19632354
 0.19588181 0.19563691 0.19564769 0.19550402 0.19508931 0.19453497
 0.19385652 0.19320852 0.19264372 0.19194448 0.19117984 0.19034846
 0.18934987 0.18865734 0.18810908 0.18699066 0.18579294 0.18522583
 0.18485454 0.18396227 0.18339594 0.18316051 0.1831847  0.18273056
 0.18224956 0.18216917 0.18230045 0.18199071 0.18123217 0.18062088
 0.18009849 0.1796751  0.17963089 0.17940876 0.17924677 0.178888
 0.17805986 0.17695202 0.17616574 0.17513004 0.17399326 0.1732863
 0.17294352 0.17218278 0.17172568 0.17161526 0.17143176 0.17154148
 0.17128284 0.17091063 0.17015429 0.1697291  0.16922094 0.1688445
 0.16852862 0.16803388 0.16760008 0.16661556 0.1654918  0.16436183
 0.16303335 0.16127957 0.16019411 0.15943556 0.15820806 0.15714316
 0.15671757 0.15611006 0.15506914 0.15423547 0.15394744 0.15341514
 0.15282893 0.1524523  0.15211026 0.15167549 0.15122661 0.15102632
 0.15043558 0.14998884 0.14988406 0.14965609 0.14906934 0.14785473
 0.14608079 0.14437501 0.14314424 0.1422504  0.1414958  0.1407562
 0.14045769 0.1395936  0.13903207 0.13889463 0.1385306  0.13798645
 0.13752767 0.13774435 0.1377329  0.13794045 0.13767743 0.13744935
 0.13744047 0.13710621 0.13691805 0.13701954 0.13699658 0.13565958
 0.13421369 0.13312949 0.13210213 0.13121592 0.13039693 0.12901945
 0.12746061 0.1259923  0.12451634 0.12334295 0.12266259 0.12140874
 0.120317   0.12025787 0.11999337 0.11907877 0.11836629 0.11764251
 0.11583067 0.11462509 0.11623372 0.11584355 0.1153846  0.1238608 ]
