Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=165, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=165, out_features=187, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  27646080.0
params:  31042.0
Trainable parameters:  31042
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.9398612976074219
Epoch: 1, Steps: 61 | Train Loss: 0.5913543 Vali Loss: 0.2821825 Test Loss: 0.3014628
Validation loss decreased (inf --> 0.282182).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.9431097507476807
Epoch: 2, Steps: 61 | Train Loss: 0.4727132 Vali Loss: 0.2543749 Test Loss: 0.2856125
Validation loss decreased (0.282182 --> 0.254375).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.8135666847229004
Epoch: 3, Steps: 61 | Train Loss: 0.4489599 Vali Loss: 0.2442016 Test Loss: 0.2812668
Validation loss decreased (0.254375 --> 0.244202).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.8547613620758057
Epoch: 4, Steps: 61 | Train Loss: 0.4372198 Vali Loss: 0.2382888 Test Loss: 0.2792611
Validation loss decreased (0.244202 --> 0.238289).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.9074320793151855
Epoch: 5, Steps: 61 | Train Loss: 0.4288043 Vali Loss: 0.2325621 Test Loss: 0.2778274
Validation loss decreased (0.238289 --> 0.232562).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.9278318881988525
Epoch: 6, Steps: 61 | Train Loss: 0.4249574 Vali Loss: 0.2293847 Test Loss: 0.2770664
Validation loss decreased (0.232562 --> 0.229385).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.8016102313995361
Epoch: 7, Steps: 61 | Train Loss: 0.4217121 Vali Loss: 0.2281233 Test Loss: 0.2765731
Validation loss decreased (0.229385 --> 0.228123).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.875291109085083
Epoch: 8, Steps: 61 | Train Loss: 0.4190598 Vali Loss: 0.2260083 Test Loss: 0.2759010
Validation loss decreased (0.228123 --> 0.226008).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.8778095245361328
Epoch: 9, Steps: 61 | Train Loss: 0.4164141 Vali Loss: 0.2254997 Test Loss: 0.2754786
Validation loss decreased (0.226008 --> 0.225500).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.930617332458496
Epoch: 10, Steps: 61 | Train Loss: 0.4141693 Vali Loss: 0.2223397 Test Loss: 0.2751387
Validation loss decreased (0.225500 --> 0.222340).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.7809944152832031
Epoch: 11, Steps: 61 | Train Loss: 0.4132493 Vali Loss: 0.2213418 Test Loss: 0.2749100
Validation loss decreased (0.222340 --> 0.221342).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.001215696334839
Epoch: 12, Steps: 61 | Train Loss: 0.4114981 Vali Loss: 0.2201831 Test Loss: 0.2746305
Validation loss decreased (0.221342 --> 0.220183).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.8032777309417725
Epoch: 13, Steps: 61 | Train Loss: 0.4102891 Vali Loss: 0.2200432 Test Loss: 0.2742212
Validation loss decreased (0.220183 --> 0.220043).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.7513923645019531
Epoch: 14, Steps: 61 | Train Loss: 0.4101568 Vali Loss: 0.2194353 Test Loss: 0.2741161
Validation loss decreased (0.220043 --> 0.219435).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.9058759212493896
Epoch: 15, Steps: 61 | Train Loss: 0.4095822 Vali Loss: 0.2202876 Test Loss: 0.2738987
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.8944621086120605
Epoch: 16, Steps: 61 | Train Loss: 0.4089812 Vali Loss: 0.2193460 Test Loss: 0.2737840
Validation loss decreased (0.219435 --> 0.219346).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.766679048538208
Epoch: 17, Steps: 61 | Train Loss: 0.4070116 Vali Loss: 0.2187085 Test Loss: 0.2735897
Validation loss decreased (0.219346 --> 0.218708).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.8775396347045898
Epoch: 18, Steps: 61 | Train Loss: 0.4077978 Vali Loss: 0.2183474 Test Loss: 0.2734727
Validation loss decreased (0.218708 --> 0.218347).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.837566614151001
Epoch: 19, Steps: 61 | Train Loss: 0.4070104 Vali Loss: 0.2170435 Test Loss: 0.2734448
Validation loss decreased (0.218347 --> 0.217043).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.7215542793273926
Epoch: 20, Steps: 61 | Train Loss: 0.4071698 Vali Loss: 0.2181560 Test Loss: 0.2734605
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.7192986011505127
Epoch: 21, Steps: 61 | Train Loss: 0.4067772 Vali Loss: 0.2172196 Test Loss: 0.2732127
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.8482096195220947
Epoch: 22, Steps: 61 | Train Loss: 0.4061873 Vali Loss: 0.2171874 Test Loss: 0.2731952
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.8645362854003906
Epoch: 23, Steps: 61 | Train Loss: 0.4060160 Vali Loss: 0.2169721 Test Loss: 0.2731722
Validation loss decreased (0.217043 --> 0.216972).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.745302677154541
Epoch: 24, Steps: 61 | Train Loss: 0.4050999 Vali Loss: 0.2152467 Test Loss: 0.2731153
Validation loss decreased (0.216972 --> 0.215247).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.9278149604797363
Epoch: 25, Steps: 61 | Train Loss: 0.4040382 Vali Loss: 0.2164933 Test Loss: 0.2730600
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.8897931575775146
Epoch: 26, Steps: 61 | Train Loss: 0.4043513 Vali Loss: 0.2166971 Test Loss: 0.2730122
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.9079174995422363
Epoch: 27, Steps: 61 | Train Loss: 0.4040413 Vali Loss: 0.2169934 Test Loss: 0.2730832
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.9656972885131836
Epoch: 28, Steps: 61 | Train Loss: 0.4046525 Vali Loss: 0.2166767 Test Loss: 0.2729776
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.8511254787445068
Epoch: 29, Steps: 61 | Train Loss: 0.4045183 Vali Loss: 0.2156451 Test Loss: 0.2728683
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.411508321762085
Epoch: 30, Steps: 61 | Train Loss: 0.4036205 Vali Loss: 0.2159497 Test Loss: 0.2727970
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.484072208404541
Epoch: 31, Steps: 61 | Train Loss: 0.4041633 Vali Loss: 0.2155269 Test Loss: 0.2729230
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.4938251972198486
Epoch: 32, Steps: 61 | Train Loss: 0.4042654 Vali Loss: 0.2150927 Test Loss: 0.2728463
Validation loss decreased (0.215247 --> 0.215093).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.3620414733886719
Epoch: 33, Steps: 61 | Train Loss: 0.4038952 Vali Loss: 0.2156287 Test Loss: 0.2727630
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.3241517543792725
Epoch: 34, Steps: 61 | Train Loss: 0.4019161 Vali Loss: 0.2146925 Test Loss: 0.2727596
Validation loss decreased (0.215093 --> 0.214692).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.446362018585205
Epoch: 35, Steps: 61 | Train Loss: 0.4039299 Vali Loss: 0.2157179 Test Loss: 0.2727843
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.5273754596710205
Epoch: 36, Steps: 61 | Train Loss: 0.4033267 Vali Loss: 0.2157850 Test Loss: 0.2727291
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.4427664279937744
Epoch: 37, Steps: 61 | Train Loss: 0.4035728 Vali Loss: 0.2152971 Test Loss: 0.2727263
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.6943883895874023
Epoch: 38, Steps: 61 | Train Loss: 0.4033064 Vali Loss: 0.2156359 Test Loss: 0.2727489
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.588366985321045
Epoch: 39, Steps: 61 | Train Loss: 0.4033062 Vali Loss: 0.2157504 Test Loss: 0.2726607
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.9172191619873047
Epoch: 40, Steps: 61 | Train Loss: 0.4028087 Vali Loss: 0.2152992 Test Loss: 0.2726578
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.4713950157165527
Epoch: 41, Steps: 61 | Train Loss: 0.4035929 Vali Loss: 0.2151038 Test Loss: 0.2726326
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.8291866779327393
Epoch: 42, Steps: 61 | Train Loss: 0.4033329 Vali Loss: 0.2142914 Test Loss: 0.2726562
Validation loss decreased (0.214692 --> 0.214291).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.9657161235809326
Epoch: 43, Steps: 61 | Train Loss: 0.4034083 Vali Loss: 0.2139473 Test Loss: 0.2726392
Validation loss decreased (0.214291 --> 0.213947).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.9220449924468994
Epoch: 44, Steps: 61 | Train Loss: 0.4028344 Vali Loss: 0.2144649 Test Loss: 0.2726074
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.6310529708862305
Epoch: 45, Steps: 61 | Train Loss: 0.4030657 Vali Loss: 0.2142907 Test Loss: 0.2726131
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.5985023975372314
Epoch: 46, Steps: 61 | Train Loss: 0.4015459 Vali Loss: 0.2147178 Test Loss: 0.2725867
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.556786298751831
Epoch: 47, Steps: 61 | Train Loss: 0.4027051 Vali Loss: 0.2156565 Test Loss: 0.2725904
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.597287893295288
Epoch: 48, Steps: 61 | Train Loss: 0.4018320 Vali Loss: 0.2146946 Test Loss: 0.2725674
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.624049425125122
Epoch: 49, Steps: 61 | Train Loss: 0.4029155 Vali Loss: 0.2145780 Test Loss: 0.2725828
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.785062313079834
Epoch: 50, Steps: 61 | Train Loss: 0.4020260 Vali Loss: 0.2153968 Test Loss: 0.2725777
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.6856658458709717
Epoch: 51, Steps: 61 | Train Loss: 0.4025836 Vali Loss: 0.2143427 Test Loss: 0.2725561
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.5604796409606934
Epoch: 52, Steps: 61 | Train Loss: 0.4023107 Vali Loss: 0.2144919 Test Loss: 0.2726029
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.5785331726074219
Epoch: 53, Steps: 61 | Train Loss: 0.4027399 Vali Loss: 0.2150455 Test Loss: 0.2725989
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.524770975112915
Epoch: 54, Steps: 61 | Train Loss: 0.4024951 Vali Loss: 0.2153235 Test Loss: 0.2725675
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.8095262050628662
Epoch: 55, Steps: 61 | Train Loss: 0.4026161 Vali Loss: 0.2152680 Test Loss: 0.2725779
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.9638779163360596
Epoch: 56, Steps: 61 | Train Loss: 0.4023926 Vali Loss: 0.2140518 Test Loss: 0.2725464
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.6833195686340332
Epoch: 57, Steps: 61 | Train Loss: 0.4017719 Vali Loss: 0.2141636 Test Loss: 0.2725888
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.474543571472168
Epoch: 58, Steps: 61 | Train Loss: 0.4021248 Vali Loss: 0.2134744 Test Loss: 0.2725550
Validation loss decreased (0.213947 --> 0.213474).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.8055760860443115
Epoch: 59, Steps: 61 | Train Loss: 0.4025912 Vali Loss: 0.2146062 Test Loss: 0.2725386
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.630636215209961
Epoch: 60, Steps: 61 | Train Loss: 0.4012509 Vali Loss: 0.2135845 Test Loss: 0.2725249
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.8009312152862549
Epoch: 61, Steps: 61 | Train Loss: 0.4025381 Vali Loss: 0.2142982 Test Loss: 0.2725371
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.8806273937225342
Epoch: 62, Steps: 61 | Train Loss: 0.4026258 Vali Loss: 0.2155153 Test Loss: 0.2725450
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.8933610916137695
Epoch: 63, Steps: 61 | Train Loss: 0.4025796 Vali Loss: 0.2141274 Test Loss: 0.2725443
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.8518939018249512
Epoch: 64, Steps: 61 | Train Loss: 0.4017425 Vali Loss: 0.2153769 Test Loss: 0.2725329
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.001699209213257
Epoch: 65, Steps: 61 | Train Loss: 0.4024945 Vali Loss: 0.2141026 Test Loss: 0.2725239
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.5451812744140625
Epoch: 66, Steps: 61 | Train Loss: 0.4023760 Vali Loss: 0.2145921 Test Loss: 0.2725295
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.8382022380828857
Epoch: 67, Steps: 61 | Train Loss: 0.4009735 Vali Loss: 0.2139040 Test Loss: 0.2725373
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.8477904796600342
Epoch: 68, Steps: 61 | Train Loss: 0.4025382 Vali Loss: 0.2137561 Test Loss: 0.2725239
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.7923264503479004
Epoch: 69, Steps: 61 | Train Loss: 0.4024106 Vali Loss: 0.2142812 Test Loss: 0.2725239
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.854017972946167
Epoch: 70, Steps: 61 | Train Loss: 0.4022429 Vali Loss: 0.2152184 Test Loss: 0.2725084
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.9371857643127441
Epoch: 71, Steps: 61 | Train Loss: 0.4024700 Vali Loss: 0.2145318 Test Loss: 0.2725268
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.7652826309204102
Epoch: 72, Steps: 61 | Train Loss: 0.4008689 Vali Loss: 0.2143687 Test Loss: 0.2725165
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.5036530494689941
Epoch: 73, Steps: 61 | Train Loss: 0.4006593 Vali Loss: 0.2133049 Test Loss: 0.2725072
Validation loss decreased (0.213474 --> 0.213305).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.6237092018127441
Epoch: 74, Steps: 61 | Train Loss: 0.4019274 Vali Loss: 0.2139624 Test Loss: 0.2725191
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.754699945449829
Epoch: 75, Steps: 61 | Train Loss: 0.4017395 Vali Loss: 0.2144127 Test Loss: 0.2725126
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.931396484375
Epoch: 76, Steps: 61 | Train Loss: 0.4021539 Vali Loss: 0.2150824 Test Loss: 0.2725226
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.529494047164917
Epoch: 77, Steps: 61 | Train Loss: 0.4021396 Vali Loss: 0.2135462 Test Loss: 0.2725127
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.6750283241271973
Epoch: 78, Steps: 61 | Train Loss: 0.4010671 Vali Loss: 0.2140333 Test Loss: 0.2725100
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.7951834201812744
Epoch: 79, Steps: 61 | Train Loss: 0.4018870 Vali Loss: 0.2149856 Test Loss: 0.2725098
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.690377950668335
Epoch: 80, Steps: 61 | Train Loss: 0.4020184 Vali Loss: 0.2139108 Test Loss: 0.2725045
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.7070434093475342
Epoch: 81, Steps: 61 | Train Loss: 0.4017293 Vali Loss: 0.2136977 Test Loss: 0.2725115
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.700484037399292
Epoch: 82, Steps: 61 | Train Loss: 0.4015079 Vali Loss: 0.2148429 Test Loss: 0.2725047
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.824812412261963
Epoch: 83, Steps: 61 | Train Loss: 0.4008474 Vali Loss: 0.2143540 Test Loss: 0.2725056
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.596459150314331
Epoch: 84, Steps: 61 | Train Loss: 0.4020946 Vali Loss: 0.2147636 Test Loss: 0.2724976
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.668788194656372
Epoch: 85, Steps: 61 | Train Loss: 0.4018351 Vali Loss: 0.2136171 Test Loss: 0.2724982
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.719597339630127
Epoch: 86, Steps: 61 | Train Loss: 0.4016964 Vali Loss: 0.2146784 Test Loss: 0.2724925
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.5850634574890137
Epoch: 87, Steps: 61 | Train Loss: 0.4023006 Vali Loss: 0.2132603 Test Loss: 0.2725029
Validation loss decreased (0.213305 --> 0.213260).  Saving model ...
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.6403045654296875
Epoch: 88, Steps: 61 | Train Loss: 0.4021961 Vali Loss: 0.2141184 Test Loss: 0.2724979
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.693647861480713
Epoch: 89, Steps: 61 | Train Loss: 0.4020855 Vali Loss: 0.2144687 Test Loss: 0.2724940
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.7208664417266846
Epoch: 90, Steps: 61 | Train Loss: 0.4007461 Vali Loss: 0.2138855 Test Loss: 0.2725013
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.7045795917510986
Epoch: 91, Steps: 61 | Train Loss: 0.4020413 Vali Loss: 0.2141223 Test Loss: 0.2724918
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.297206163406372
Epoch: 92, Steps: 61 | Train Loss: 0.4021816 Vali Loss: 0.2143263 Test Loss: 0.2724967
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.7893199920654297
Epoch: 93, Steps: 61 | Train Loss: 0.4022369 Vali Loss: 0.2139676 Test Loss: 0.2724908
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.6709790229797363
Epoch: 94, Steps: 61 | Train Loss: 0.4018152 Vali Loss: 0.2142681 Test Loss: 0.2724966
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.6586365699768066
Epoch: 95, Steps: 61 | Train Loss: 0.4015384 Vali Loss: 0.2150386 Test Loss: 0.2724938
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.7675797939300537
Epoch: 96, Steps: 61 | Train Loss: 0.4019410 Vali Loss: 0.2139713 Test Loss: 0.2724862
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.4838042259216309
Epoch: 97, Steps: 61 | Train Loss: 0.4016473 Vali Loss: 0.2145591 Test Loss: 0.2724879
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.6872541904449463
Epoch: 98, Steps: 61 | Train Loss: 0.4008273 Vali Loss: 0.2144653 Test Loss: 0.2724867
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.770181655883789
Epoch: 99, Steps: 61 | Train Loss: 0.4009756 Vali Loss: 0.2151920 Test Loss: 0.2724892
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.6801624298095703
Epoch: 100, Steps: 61 | Train Loss: 0.4013122 Vali Loss: 0.2147388 Test Loss: 0.2724875
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.1160680107021042e-06
>>>>>>>testing : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.2720852494239807, mae:0.3371132016181946, rse:0.42037200927734375, corr:[0.2706327  0.2755579  0.27385375 0.27355638 0.27402225 0.27325106
 0.27208474 0.2714896  0.2711035  0.2698965  0.2682619  0.26668566
 0.26560402 0.26478994 0.26387683 0.2631914  0.26291943 0.26261532
 0.2615735  0.26016688 0.25910252 0.25832865 0.25700754 0.2549207
 0.25283572 0.25139543 0.25013247 0.24852604 0.24693663 0.24587467
 0.2449178  0.24342632 0.24161585 0.2403367  0.23949094 0.23843738
 0.23702134 0.23581597 0.23517407 0.23446842 0.23351644 0.23274715
 0.2323434  0.23169933 0.23066644 0.22952102 0.22855633 0.22717056
 0.22511844 0.22299501 0.22164546 0.22057544 0.21944165 0.21785365
 0.21595928 0.21448484 0.21285889 0.2107033  0.20884721 0.20811047
 0.20793687 0.20730954 0.2068361  0.20716889 0.2070573  0.20645314
 0.20565541 0.20527017 0.2050506  0.20435974 0.203212   0.20260498
 0.20227136 0.20120785 0.19969752 0.19832972 0.197982   0.1974174
 0.19643445 0.1954999  0.19600824 0.1961725  0.1948141  0.19380632
 0.19436143 0.19504146 0.19432539 0.19369592 0.19374463 0.193529
 0.19199306 0.19113599 0.19264163 0.19185871 0.18867315 0.19342451]
