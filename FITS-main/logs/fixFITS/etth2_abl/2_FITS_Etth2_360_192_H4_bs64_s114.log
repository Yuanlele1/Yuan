Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=74, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_360_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_360_192_FITS_ETTh2_ftM_sl360_ll48_pl192_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8089
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=74, out_features=113, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  7492352.0
params:  8475.0
Trainable parameters:  8475
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 4.216120481491089
Epoch: 1, Steps: 63 | Train Loss: 0.5749126 Vali Loss: 0.4240864 Test Loss: 0.4741036
Validation loss decreased (inf --> 0.424086).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.179450035095215
Epoch: 2, Steps: 63 | Train Loss: 0.4669157 Vali Loss: 0.3860735 Test Loss: 0.4396058
Validation loss decreased (0.424086 --> 0.386073).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 4.89342737197876
Epoch: 3, Steps: 63 | Train Loss: 0.4073504 Vali Loss: 0.3646488 Test Loss: 0.4218762
Validation loss decreased (0.386073 --> 0.364649).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.4010424613952637
Epoch: 4, Steps: 63 | Train Loss: 0.3704736 Vali Loss: 0.3516158 Test Loss: 0.4121249
Validation loss decreased (0.364649 --> 0.351616).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.234558582305908
Epoch: 5, Steps: 63 | Train Loss: 0.3445028 Vali Loss: 0.3429319 Test Loss: 0.4061417
Validation loss decreased (0.351616 --> 0.342932).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.8542704582214355
Epoch: 6, Steps: 63 | Train Loss: 0.3261305 Vali Loss: 0.3368457 Test Loss: 0.4022079
Validation loss decreased (0.342932 --> 0.336846).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.1436901092529297
Epoch: 7, Steps: 63 | Train Loss: 0.3117264 Vali Loss: 0.3320979 Test Loss: 0.3991319
Validation loss decreased (0.336846 --> 0.332098).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.985348701477051
Epoch: 8, Steps: 63 | Train Loss: 0.2999385 Vali Loss: 0.3284498 Test Loss: 0.3966123
Validation loss decreased (0.332098 --> 0.328450).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.9341251850128174
Epoch: 9, Steps: 63 | Train Loss: 0.2897663 Vali Loss: 0.3251018 Test Loss: 0.3942864
Validation loss decreased (0.328450 --> 0.325102).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.5428388118743896
Epoch: 10, Steps: 63 | Train Loss: 0.2807563 Vali Loss: 0.3223772 Test Loss: 0.3924083
Validation loss decreased (0.325102 --> 0.322377).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.3066539764404297
Epoch: 11, Steps: 63 | Train Loss: 0.2739452 Vali Loss: 0.3197831 Test Loss: 0.3906048
Validation loss decreased (0.322377 --> 0.319783).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.7814464569091797
Epoch: 12, Steps: 63 | Train Loss: 0.2670878 Vali Loss: 0.3176760 Test Loss: 0.3890067
Validation loss decreased (0.319783 --> 0.317676).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 4.58758282661438
Epoch: 13, Steps: 63 | Train Loss: 0.2614623 Vali Loss: 0.3157369 Test Loss: 0.3874370
Validation loss decreased (0.317676 --> 0.315737).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.5509088039398193
Epoch: 14, Steps: 63 | Train Loss: 0.2567837 Vali Loss: 0.3140219 Test Loss: 0.3861211
Validation loss decreased (0.315737 --> 0.314022).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 4.88763689994812
Epoch: 15, Steps: 63 | Train Loss: 0.2521625 Vali Loss: 0.3121773 Test Loss: 0.3849030
Validation loss decreased (0.314022 --> 0.312177).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.2300937175750732
Epoch: 16, Steps: 63 | Train Loss: 0.2484140 Vali Loss: 0.3110089 Test Loss: 0.3836140
Validation loss decreased (0.312177 --> 0.311009).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.195005178451538
Epoch: 17, Steps: 63 | Train Loss: 0.2450529 Vali Loss: 0.3096291 Test Loss: 0.3826137
Validation loss decreased (0.311009 --> 0.309629).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.276156425476074
Epoch: 18, Steps: 63 | Train Loss: 0.2418764 Vali Loss: 0.3084032 Test Loss: 0.3815740
Validation loss decreased (0.309629 --> 0.308403).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.5517539978027344
Epoch: 19, Steps: 63 | Train Loss: 0.2390072 Vali Loss: 0.3073662 Test Loss: 0.3805887
Validation loss decreased (0.308403 --> 0.307366).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.666521072387695
Epoch: 20, Steps: 63 | Train Loss: 0.2367024 Vali Loss: 0.3061937 Test Loss: 0.3796877
Validation loss decreased (0.307366 --> 0.306194).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.74051833152771
Epoch: 21, Steps: 63 | Train Loss: 0.2342012 Vali Loss: 0.3052479 Test Loss: 0.3788583
Validation loss decreased (0.306194 --> 0.305248).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 4.105831861495972
Epoch: 22, Steps: 63 | Train Loss: 0.2317184 Vali Loss: 0.3044473 Test Loss: 0.3781338
Validation loss decreased (0.305248 --> 0.304447).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.338135004043579
Epoch: 23, Steps: 63 | Train Loss: 0.2298697 Vali Loss: 0.3036665 Test Loss: 0.3773016
Validation loss decreased (0.304447 --> 0.303667).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 4.356175422668457
Epoch: 24, Steps: 63 | Train Loss: 0.2281495 Vali Loss: 0.3027909 Test Loss: 0.3767111
Validation loss decreased (0.303667 --> 0.302791).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 6.419560432434082
Epoch: 25, Steps: 63 | Train Loss: 0.2266673 Vali Loss: 0.3021188 Test Loss: 0.3760943
Validation loss decreased (0.302791 --> 0.302119).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.8276572227478027
Epoch: 26, Steps: 63 | Train Loss: 0.2255349 Vali Loss: 0.3014960 Test Loss: 0.3754462
Validation loss decreased (0.302119 --> 0.301496).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 4.957225322723389
Epoch: 27, Steps: 63 | Train Loss: 0.2245124 Vali Loss: 0.3007693 Test Loss: 0.3748960
Validation loss decreased (0.301496 --> 0.300769).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.554633378982544
Epoch: 28, Steps: 63 | Train Loss: 0.2227619 Vali Loss: 0.3002979 Test Loss: 0.3743506
Validation loss decreased (0.300769 --> 0.300298).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 4.937127113342285
Epoch: 29, Steps: 63 | Train Loss: 0.2220924 Vali Loss: 0.2997930 Test Loss: 0.3739114
Validation loss decreased (0.300298 --> 0.299793).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 3.1631019115448
Epoch: 30, Steps: 63 | Train Loss: 0.2206329 Vali Loss: 0.2993124 Test Loss: 0.3734240
Validation loss decreased (0.299793 --> 0.299312).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 3.1801247596740723
Epoch: 31, Steps: 63 | Train Loss: 0.2200577 Vali Loss: 0.2988541 Test Loss: 0.3730314
Validation loss decreased (0.299312 --> 0.298854).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.590311288833618
Epoch: 32, Steps: 63 | Train Loss: 0.2191430 Vali Loss: 0.2984519 Test Loss: 0.3726322
Validation loss decreased (0.298854 --> 0.298452).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 5.640335321426392
Epoch: 33, Steps: 63 | Train Loss: 0.2186995 Vali Loss: 0.2980596 Test Loss: 0.3721923
Validation loss decreased (0.298452 --> 0.298060).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.4468674659729004
Epoch: 34, Steps: 63 | Train Loss: 0.2178842 Vali Loss: 0.2977632 Test Loss: 0.3718492
Validation loss decreased (0.298060 --> 0.297763).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.513732671737671
Epoch: 35, Steps: 63 | Train Loss: 0.2170353 Vali Loss: 0.2973402 Test Loss: 0.3715397
Validation loss decreased (0.297763 --> 0.297340).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.122997760772705
Epoch: 36, Steps: 63 | Train Loss: 0.2160369 Vali Loss: 0.2970085 Test Loss: 0.3712491
Validation loss decreased (0.297340 --> 0.297009).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 4.999548673629761
Epoch: 37, Steps: 63 | Train Loss: 0.2159181 Vali Loss: 0.2967165 Test Loss: 0.3709615
Validation loss decreased (0.297009 --> 0.296717).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 5.879747629165649
Epoch: 38, Steps: 63 | Train Loss: 0.2151977 Vali Loss: 0.2964273 Test Loss: 0.3706355
Validation loss decreased (0.296717 --> 0.296427).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 4.56519079208374
Epoch: 39, Steps: 63 | Train Loss: 0.2147022 Vali Loss: 0.2961121 Test Loss: 0.3703885
Validation loss decreased (0.296427 --> 0.296112).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 3.3377156257629395
Epoch: 40, Steps: 63 | Train Loss: 0.2144520 Vali Loss: 0.2957407 Test Loss: 0.3701206
Validation loss decreased (0.296112 --> 0.295741).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 3.882657766342163
Epoch: 41, Steps: 63 | Train Loss: 0.2136798 Vali Loss: 0.2955975 Test Loss: 0.3698863
Validation loss decreased (0.295741 --> 0.295597).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 3.330158233642578
Epoch: 42, Steps: 63 | Train Loss: 0.2134588 Vali Loss: 0.2954223 Test Loss: 0.3696772
Validation loss decreased (0.295597 --> 0.295422).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 3.9100043773651123
Epoch: 43, Steps: 63 | Train Loss: 0.2131835 Vali Loss: 0.2952030 Test Loss: 0.3694222
Validation loss decreased (0.295422 --> 0.295203).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.525207281112671
Epoch: 44, Steps: 63 | Train Loss: 0.2123675 Vali Loss: 0.2950730 Test Loss: 0.3691940
Validation loss decreased (0.295203 --> 0.295073).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.990841865539551
Epoch: 45, Steps: 63 | Train Loss: 0.2121399 Vali Loss: 0.2948340 Test Loss: 0.3690526
Validation loss decreased (0.295073 --> 0.294834).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 3.1031370162963867
Epoch: 46, Steps: 63 | Train Loss: 0.2117674 Vali Loss: 0.2946616 Test Loss: 0.3688913
Validation loss decreased (0.294834 --> 0.294662).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.486325740814209
Epoch: 47, Steps: 63 | Train Loss: 0.2113830 Vali Loss: 0.2944598 Test Loss: 0.3686904
Validation loss decreased (0.294662 --> 0.294460).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 3.573753595352173
Epoch: 48, Steps: 63 | Train Loss: 0.2112782 Vali Loss: 0.2941403 Test Loss: 0.3685561
Validation loss decreased (0.294460 --> 0.294140).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 4.030545949935913
Epoch: 49, Steps: 63 | Train Loss: 0.2106698 Vali Loss: 0.2941044 Test Loss: 0.3683669
Validation loss decreased (0.294140 --> 0.294104).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 4.521719217300415
Epoch: 50, Steps: 63 | Train Loss: 0.2108291 Vali Loss: 0.2936701 Test Loss: 0.3682439
Validation loss decreased (0.294104 --> 0.293670).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 3.3315024375915527
Epoch: 51, Steps: 63 | Train Loss: 0.2103922 Vali Loss: 0.2938379 Test Loss: 0.3680866
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 4.430181264877319
Epoch: 52, Steps: 63 | Train Loss: 0.2102809 Vali Loss: 0.2937278 Test Loss: 0.3679582
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 4.782759428024292
Epoch: 53, Steps: 63 | Train Loss: 0.2097265 Vali Loss: 0.2936551 Test Loss: 0.3678116
Validation loss decreased (0.293670 --> 0.293655).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 3.6851298809051514
Epoch: 54, Steps: 63 | Train Loss: 0.2100884 Vali Loss: 0.2933989 Test Loss: 0.3677235
Validation loss decreased (0.293655 --> 0.293399).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.5993409156799316
Epoch: 55, Steps: 63 | Train Loss: 0.2098765 Vali Loss: 0.2933991 Test Loss: 0.3675857
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.847181797027588
Epoch: 56, Steps: 63 | Train Loss: 0.2096997 Vali Loss: 0.2932982 Test Loss: 0.3674961
Validation loss decreased (0.293399 --> 0.293298).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 4.587164640426636
Epoch: 57, Steps: 63 | Train Loss: 0.2093818 Vali Loss: 0.2931919 Test Loss: 0.3674022
Validation loss decreased (0.293298 --> 0.293192).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 3.2217066287994385
Epoch: 58, Steps: 63 | Train Loss: 0.2094069 Vali Loss: 0.2930923 Test Loss: 0.3673042
Validation loss decreased (0.293192 --> 0.293092).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.6125006675720215
Epoch: 59, Steps: 63 | Train Loss: 0.2089817 Vali Loss: 0.2929507 Test Loss: 0.3672066
Validation loss decreased (0.293092 --> 0.292951).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 5.603445053100586
Epoch: 60, Steps: 63 | Train Loss: 0.2090671 Vali Loss: 0.2929385 Test Loss: 0.3670973
Validation loss decreased (0.292951 --> 0.292939).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 4.6198790073394775
Epoch: 61, Steps: 63 | Train Loss: 0.2087250 Vali Loss: 0.2928680 Test Loss: 0.3670352
Validation loss decreased (0.292939 --> 0.292868).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 3.7416138648986816
Epoch: 62, Steps: 63 | Train Loss: 0.2084819 Vali Loss: 0.2927766 Test Loss: 0.3669645
Validation loss decreased (0.292868 --> 0.292777).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 4.4314165115356445
Epoch: 63, Steps: 63 | Train Loss: 0.2079844 Vali Loss: 0.2926700 Test Loss: 0.3668807
Validation loss decreased (0.292777 --> 0.292670).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.8990652561187744
Epoch: 64, Steps: 63 | Train Loss: 0.2084098 Vali Loss: 0.2926307 Test Loss: 0.3668092
Validation loss decreased (0.292670 --> 0.292631).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 4.855902194976807
Epoch: 65, Steps: 63 | Train Loss: 0.2083929 Vali Loss: 0.2925655 Test Loss: 0.3667506
Validation loss decreased (0.292631 --> 0.292565).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 3.5151758193969727
Epoch: 66, Steps: 63 | Train Loss: 0.2082676 Vali Loss: 0.2925309 Test Loss: 0.3666733
Validation loss decreased (0.292565 --> 0.292531).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.801043748855591
Epoch: 67, Steps: 63 | Train Loss: 0.2079496 Vali Loss: 0.2923926 Test Loss: 0.3666137
Validation loss decreased (0.292531 --> 0.292393).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 3.0469253063201904
Epoch: 68, Steps: 63 | Train Loss: 0.2081668 Vali Loss: 0.2924062 Test Loss: 0.3665600
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.9922659397125244
Epoch: 69, Steps: 63 | Train Loss: 0.2077064 Vali Loss: 0.2923734 Test Loss: 0.3664918
Validation loss decreased (0.292393 --> 0.292373).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 3.490617036819458
Epoch: 70, Steps: 63 | Train Loss: 0.2077318 Vali Loss: 0.2923134 Test Loss: 0.3664531
Validation loss decreased (0.292373 --> 0.292313).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 3.7704811096191406
Epoch: 71, Steps: 63 | Train Loss: 0.2071969 Vali Loss: 0.2921617 Test Loss: 0.3663874
Validation loss decreased (0.292313 --> 0.292162).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 5.5760557651519775
Epoch: 72, Steps: 63 | Train Loss: 0.2073530 Vali Loss: 0.2922155 Test Loss: 0.3663523
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.1103968620300293
Epoch: 73, Steps: 63 | Train Loss: 0.2076297 Vali Loss: 0.2921530 Test Loss: 0.3663023
Validation loss decreased (0.292162 --> 0.292153).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 3.299790382385254
Epoch: 74, Steps: 63 | Train Loss: 0.2076636 Vali Loss: 0.2921618 Test Loss: 0.3662457
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 3.385108709335327
Epoch: 75, Steps: 63 | Train Loss: 0.2073218 Vali Loss: 0.2920085 Test Loss: 0.3662097
Validation loss decreased (0.292153 --> 0.292009).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 3.094611644744873
Epoch: 76, Steps: 63 | Train Loss: 0.2074420 Vali Loss: 0.2920757 Test Loss: 0.3661660
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 4.638202428817749
Epoch: 77, Steps: 63 | Train Loss: 0.2072599 Vali Loss: 0.2919374 Test Loss: 0.3661399
Validation loss decreased (0.292009 --> 0.291937).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.606121778488159
Epoch: 78, Steps: 63 | Train Loss: 0.2067378 Vali Loss: 0.2919654 Test Loss: 0.3661001
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.8242433071136475
Epoch: 79, Steps: 63 | Train Loss: 0.2071896 Vali Loss: 0.2919178 Test Loss: 0.3660660
Validation loss decreased (0.291937 --> 0.291918).  Saving model ...
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 3.3536620140075684
Epoch: 80, Steps: 63 | Train Loss: 0.2069114 Vali Loss: 0.2919474 Test Loss: 0.3660357
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.8709352016448975
Epoch: 81, Steps: 63 | Train Loss: 0.2072590 Vali Loss: 0.2918616 Test Loss: 0.3659993
Validation loss decreased (0.291918 --> 0.291862).  Saving model ...
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 2.5784947872161865
Epoch: 82, Steps: 63 | Train Loss: 0.2071311 Vali Loss: 0.2919048 Test Loss: 0.3659713
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 3.028303861618042
Epoch: 83, Steps: 63 | Train Loss: 0.2071848 Vali Loss: 0.2918635 Test Loss: 0.3659436
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 5.450746297836304
Epoch: 84, Steps: 63 | Train Loss: 0.2070145 Vali Loss: 0.2918546 Test Loss: 0.3659155
Validation loss decreased (0.291862 --> 0.291855).  Saving model ...
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 3.9457244873046875
Epoch: 85, Steps: 63 | Train Loss: 0.2071491 Vali Loss: 0.2917795 Test Loss: 0.3658940
Validation loss decreased (0.291855 --> 0.291779).  Saving model ...
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 3.120192766189575
Epoch: 86, Steps: 63 | Train Loss: 0.2068700 Vali Loss: 0.2917739 Test Loss: 0.3658713
Validation loss decreased (0.291779 --> 0.291774).  Saving model ...
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 3.440002679824829
Epoch: 87, Steps: 63 | Train Loss: 0.2065787 Vali Loss: 0.2917756 Test Loss: 0.3658471
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 3.7976460456848145
Epoch: 88, Steps: 63 | Train Loss: 0.2070637 Vali Loss: 0.2917769 Test Loss: 0.3658197
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 3.890449047088623
Epoch: 89, Steps: 63 | Train Loss: 0.2068024 Vali Loss: 0.2916942 Test Loss: 0.3658057
Validation loss decreased (0.291774 --> 0.291694).  Saving model ...
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 4.6066672801971436
Epoch: 90, Steps: 63 | Train Loss: 0.2067684 Vali Loss: 0.2917016 Test Loss: 0.3657856
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.644850730895996
Epoch: 91, Steps: 63 | Train Loss: 0.2067726 Vali Loss: 0.2917350 Test Loss: 0.3657655
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 3.4289863109588623
Epoch: 92, Steps: 63 | Train Loss: 0.2067625 Vali Loss: 0.2915916 Test Loss: 0.3657520
Validation loss decreased (0.291694 --> 0.291592).  Saving model ...
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 4.184568405151367
Epoch: 93, Steps: 63 | Train Loss: 0.2067320 Vali Loss: 0.2916427 Test Loss: 0.3657296
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 3.399765729904175
Epoch: 94, Steps: 63 | Train Loss: 0.2066503 Vali Loss: 0.2916189 Test Loss: 0.3657140
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 3.525815010070801
Epoch: 95, Steps: 63 | Train Loss: 0.2065318 Vali Loss: 0.2916424 Test Loss: 0.3657029
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 5.820364475250244
Epoch: 96, Steps: 63 | Train Loss: 0.2066950 Vali Loss: 0.2916324 Test Loss: 0.3656821
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 3.732827663421631
Epoch: 97, Steps: 63 | Train Loss: 0.2067799 Vali Loss: 0.2915783 Test Loss: 0.3656723
Validation loss decreased (0.291592 --> 0.291578).  Saving model ...
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 5.128107786178589
Epoch: 98, Steps: 63 | Train Loss: 0.2067067 Vali Loss: 0.2916079 Test Loss: 0.3656571
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 4.788832426071167
Epoch: 99, Steps: 63 | Train Loss: 0.2063574 Vali Loss: 0.2915757 Test Loss: 0.3656419
Validation loss decreased (0.291578 --> 0.291576).  Saving model ...
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 3.9394819736480713
Epoch: 100, Steps: 63 | Train Loss: 0.2063200 Vali Loss: 0.2915358 Test Loss: 0.3656320
Validation loss decreased (0.291576 --> 0.291536).  Saving model ...
Updating learning rate to 3.1160680107021042e-06
train 8089
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=74, out_features=113, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  7492352.0
params:  8475.0
Trainable parameters:  8475
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 4.477520942687988
Epoch: 1, Steps: 63 | Train Loss: 0.5187104 Vali Loss: 0.2852851 Test Loss: 0.3580790
Validation loss decreased (inf --> 0.285285).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.934321641921997
Epoch: 2, Steps: 63 | Train Loss: 0.5118949 Vali Loss: 0.2826302 Test Loss: 0.3557973
Validation loss decreased (0.285285 --> 0.282630).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.5117859840393066
Epoch: 3, Steps: 63 | Train Loss: 0.5091491 Vali Loss: 0.2813310 Test Loss: 0.3552255
Validation loss decreased (0.282630 --> 0.281331).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.599822998046875
Epoch: 4, Steps: 63 | Train Loss: 0.5083850 Vali Loss: 0.2803926 Test Loss: 0.3549684
Validation loss decreased (0.281331 --> 0.280393).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.4723339080810547
Epoch: 5, Steps: 63 | Train Loss: 0.5077907 Vali Loss: 0.2800554 Test Loss: 0.3547553
Validation loss decreased (0.280393 --> 0.280055).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.204007148742676
Epoch: 6, Steps: 63 | Train Loss: 0.5061931 Vali Loss: 0.2799989 Test Loss: 0.3543817
Validation loss decreased (0.280055 --> 0.279999).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.80584454536438
Epoch: 7, Steps: 63 | Train Loss: 0.5068388 Vali Loss: 0.2795627 Test Loss: 0.3545532
Validation loss decreased (0.279999 --> 0.279563).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.9683468341827393
Epoch: 8, Steps: 63 | Train Loss: 0.5064765 Vali Loss: 0.2792895 Test Loss: 0.3544452
Validation loss decreased (0.279563 --> 0.279290).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.4481852054595947
Epoch: 9, Steps: 63 | Train Loss: 0.5055172 Vali Loss: 0.2792063 Test Loss: 0.3544837
Validation loss decreased (0.279290 --> 0.279206).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.882643699645996
Epoch: 10, Steps: 63 | Train Loss: 0.5054321 Vali Loss: 0.2787580 Test Loss: 0.3545971
Validation loss decreased (0.279206 --> 0.278758).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 4.403304576873779
Epoch: 11, Steps: 63 | Train Loss: 0.5052213 Vali Loss: 0.2786977 Test Loss: 0.3544127
Validation loss decreased (0.278758 --> 0.278698).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 4.612104177474976
Epoch: 12, Steps: 63 | Train Loss: 0.5049569 Vali Loss: 0.2783817 Test Loss: 0.3546798
Validation loss decreased (0.278698 --> 0.278382).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 4.23989725112915
Epoch: 13, Steps: 63 | Train Loss: 0.5042556 Vali Loss: 0.2783546 Test Loss: 0.3543864
Validation loss decreased (0.278382 --> 0.278355).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.550288438796997
Epoch: 14, Steps: 63 | Train Loss: 0.5054717 Vali Loss: 0.2784749 Test Loss: 0.3542573
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.583333730697632
Epoch: 15, Steps: 63 | Train Loss: 0.5044965 Vali Loss: 0.2782081 Test Loss: 0.3542501
Validation loss decreased (0.278355 --> 0.278208).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.385338068008423
Epoch: 16, Steps: 63 | Train Loss: 0.5045787 Vali Loss: 0.2782727 Test Loss: 0.3542102
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.5868337154388428
Epoch: 17, Steps: 63 | Train Loss: 0.5048852 Vali Loss: 0.2783218 Test Loss: 0.3540794
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.3750627040863037
Epoch: 18, Steps: 63 | Train Loss: 0.5046266 Vali Loss: 0.2782077 Test Loss: 0.3541555
Validation loss decreased (0.278208 --> 0.278208).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 3.212881088256836
Epoch: 19, Steps: 63 | Train Loss: 0.5041859 Vali Loss: 0.2779683 Test Loss: 0.3541081
Validation loss decreased (0.278208 --> 0.277968).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.4727163314819336
Epoch: 20, Steps: 63 | Train Loss: 0.5048521 Vali Loss: 0.2778229 Test Loss: 0.3542946
Validation loss decreased (0.277968 --> 0.277823).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.7154810428619385
Epoch: 21, Steps: 63 | Train Loss: 0.5040501 Vali Loss: 0.2777151 Test Loss: 0.3542448
Validation loss decreased (0.277823 --> 0.277715).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.6687278747558594
Epoch: 22, Steps: 63 | Train Loss: 0.5046589 Vali Loss: 0.2777482 Test Loss: 0.3542869
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.430511713027954
Epoch: 23, Steps: 63 | Train Loss: 0.5048956 Vali Loss: 0.2776692 Test Loss: 0.3541887
Validation loss decreased (0.277715 --> 0.277669).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.910226345062256
Epoch: 24, Steps: 63 | Train Loss: 0.5042309 Vali Loss: 0.2774736 Test Loss: 0.3543296
Validation loss decreased (0.277669 --> 0.277474).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 3.15852689743042
Epoch: 25, Steps: 63 | Train Loss: 0.5036538 Vali Loss: 0.2774428 Test Loss: 0.3541329
Validation loss decreased (0.277474 --> 0.277443).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.1546308994293213
Epoch: 26, Steps: 63 | Train Loss: 0.5027932 Vali Loss: 0.2776283 Test Loss: 0.3540761
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.5547678470611572
Epoch: 27, Steps: 63 | Train Loss: 0.5038112 Vali Loss: 0.2774982 Test Loss: 0.3541392
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.057711362838745
Epoch: 28, Steps: 63 | Train Loss: 0.5036419 Vali Loss: 0.2774855 Test Loss: 0.3540983
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.7705295085906982
Epoch: 29, Steps: 63 | Train Loss: 0.5041738 Vali Loss: 0.2774248 Test Loss: 0.3541510
Validation loss decreased (0.277443 --> 0.277425).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.646543502807617
Epoch: 30, Steps: 63 | Train Loss: 0.5034915 Vali Loss: 0.2774596 Test Loss: 0.3540493
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.659430742263794
Epoch: 31, Steps: 63 | Train Loss: 0.5038322 Vali Loss: 0.2774569 Test Loss: 0.3540093
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 4.087731838226318
Epoch: 32, Steps: 63 | Train Loss: 0.5034538 Vali Loss: 0.2774156 Test Loss: 0.3540699
Validation loss decreased (0.277425 --> 0.277416).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.7493743896484375
Epoch: 33, Steps: 63 | Train Loss: 0.5029350 Vali Loss: 0.2772882 Test Loss: 0.3540739
Validation loss decreased (0.277416 --> 0.277288).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.0669913291931152
Epoch: 34, Steps: 63 | Train Loss: 0.5042290 Vali Loss: 0.2773309 Test Loss: 0.3541002
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.3230903148651123
Epoch: 35, Steps: 63 | Train Loss: 0.5045152 Vali Loss: 0.2773683 Test Loss: 0.3540353
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.759042978286743
Epoch: 36, Steps: 63 | Train Loss: 0.5039383 Vali Loss: 0.2773938 Test Loss: 0.3540051
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.9607176780700684
Epoch: 37, Steps: 63 | Train Loss: 0.5041145 Vali Loss: 0.2773285 Test Loss: 0.3540535
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.2561399936676025
Epoch: 38, Steps: 63 | Train Loss: 0.5033187 Vali Loss: 0.2772915 Test Loss: 0.3540566
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.0867412090301514
Epoch: 39, Steps: 63 | Train Loss: 0.5036173 Vali Loss: 0.2773041 Test Loss: 0.3540237
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.893723726272583
Epoch: 40, Steps: 63 | Train Loss: 0.5032426 Vali Loss: 0.2772364 Test Loss: 0.3540564
Validation loss decreased (0.277288 --> 0.277236).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 3.307055950164795
Epoch: 41, Steps: 63 | Train Loss: 0.5043238 Vali Loss: 0.2772319 Test Loss: 0.3540495
Validation loss decreased (0.277236 --> 0.277232).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.324535608291626
Epoch: 42, Steps: 63 | Train Loss: 0.5035700 Vali Loss: 0.2771773 Test Loss: 0.3540630
Validation loss decreased (0.277232 --> 0.277177).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 3.23750638961792
Epoch: 43, Steps: 63 | Train Loss: 0.5035965 Vali Loss: 0.2771985 Test Loss: 0.3540538
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.571418523788452
Epoch: 44, Steps: 63 | Train Loss: 0.5040075 Vali Loss: 0.2771918 Test Loss: 0.3540311
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.267638683319092
Epoch: 45, Steps: 63 | Train Loss: 0.5030459 Vali Loss: 0.2771957 Test Loss: 0.3540696
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.7428972721099854
Epoch: 46, Steps: 63 | Train Loss: 0.5033239 Vali Loss: 0.2771613 Test Loss: 0.3540436
Validation loss decreased (0.277177 --> 0.277161).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 4.229925155639648
Epoch: 47, Steps: 63 | Train Loss: 0.5034284 Vali Loss: 0.2771453 Test Loss: 0.3540260
Validation loss decreased (0.277161 --> 0.277145).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 3.3629322052001953
Epoch: 48, Steps: 63 | Train Loss: 0.5030556 Vali Loss: 0.2771306 Test Loss: 0.3540411
Validation loss decreased (0.277145 --> 0.277131).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.218406915664673
Epoch: 49, Steps: 63 | Train Loss: 0.5033481 Vali Loss: 0.2771019 Test Loss: 0.3540368
Validation loss decreased (0.277131 --> 0.277102).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 3.386187791824341
Epoch: 50, Steps: 63 | Train Loss: 0.5028741 Vali Loss: 0.2771157 Test Loss: 0.3540451
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 3.3039581775665283
Epoch: 51, Steps: 63 | Train Loss: 0.5034263 Vali Loss: 0.2771346 Test Loss: 0.3540268
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 3.4156723022460938
Epoch: 52, Steps: 63 | Train Loss: 0.5040973 Vali Loss: 0.2771047 Test Loss: 0.3540226
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.479017972946167
Epoch: 53, Steps: 63 | Train Loss: 0.5029544 Vali Loss: 0.2770788 Test Loss: 0.3540514
Validation loss decreased (0.277102 --> 0.277079).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.824410915374756
Epoch: 54, Steps: 63 | Train Loss: 0.5028836 Vali Loss: 0.2770576 Test Loss: 0.3540277
Validation loss decreased (0.277079 --> 0.277058).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.9455933570861816
Epoch: 55, Steps: 63 | Train Loss: 0.5033685 Vali Loss: 0.2770172 Test Loss: 0.3540142
Validation loss decreased (0.277058 --> 0.277017).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.8351235389709473
Epoch: 56, Steps: 63 | Train Loss: 0.5026853 Vali Loss: 0.2771267 Test Loss: 0.3539958
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.232208490371704
Epoch: 57, Steps: 63 | Train Loss: 0.5035863 Vali Loss: 0.2770839 Test Loss: 0.3540078
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.2233803272247314
Epoch: 58, Steps: 63 | Train Loss: 0.5026349 Vali Loss: 0.2770854 Test Loss: 0.3540197
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.715480327606201
Epoch: 59, Steps: 63 | Train Loss: 0.5025030 Vali Loss: 0.2770369 Test Loss: 0.3540083
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 3.6032028198242188
Epoch: 60, Steps: 63 | Train Loss: 0.5035668 Vali Loss: 0.2770431 Test Loss: 0.3540420
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.8858771324157715
Epoch: 61, Steps: 63 | Train Loss: 0.5023250 Vali Loss: 0.2766871 Test Loss: 0.3540218
Validation loss decreased (0.277017 --> 0.276687).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 4.412793874740601
Epoch: 62, Steps: 63 | Train Loss: 0.5038947 Vali Loss: 0.2768019 Test Loss: 0.3539987
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.879077196121216
Epoch: 63, Steps: 63 | Train Loss: 0.5023760 Vali Loss: 0.2769831 Test Loss: 0.3540102
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 3.4215879440307617
Epoch: 64, Steps: 63 | Train Loss: 0.5030162 Vali Loss: 0.2770301 Test Loss: 0.3540024
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 4.538988351821899
Epoch: 65, Steps: 63 | Train Loss: 0.5022140 Vali Loss: 0.2769525 Test Loss: 0.3540295
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.292553424835205
Epoch: 66, Steps: 63 | Train Loss: 0.5028450 Vali Loss: 0.2770131 Test Loss: 0.3540164
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.9293630123138428
Epoch: 67, Steps: 63 | Train Loss: 0.5028125 Vali Loss: 0.2770141 Test Loss: 0.3539991
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 3.138113498687744
Epoch: 68, Steps: 63 | Train Loss: 0.5034479 Vali Loss: 0.2770452 Test Loss: 0.3540143
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 3.3065478801727295
Epoch: 69, Steps: 63 | Train Loss: 0.5032399 Vali Loss: 0.2767085 Test Loss: 0.3540040
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.608067035675049
Epoch: 70, Steps: 63 | Train Loss: 0.5032245 Vali Loss: 0.2769435 Test Loss: 0.3540086
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.2006304264068604
Epoch: 71, Steps: 63 | Train Loss: 0.5037968 Vali Loss: 0.2769795 Test Loss: 0.3539956
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.7544825077056885
Epoch: 72, Steps: 63 | Train Loss: 0.5036941 Vali Loss: 0.2770352 Test Loss: 0.3540106
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 5.655261516571045
Epoch: 73, Steps: 63 | Train Loss: 0.5037431 Vali Loss: 0.2770044 Test Loss: 0.3540043
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.827810764312744
Epoch: 74, Steps: 63 | Train Loss: 0.5028281 Vali Loss: 0.2770240 Test Loss: 0.3539981
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 3.3658525943756104
Epoch: 75, Steps: 63 | Train Loss: 0.5036669 Vali Loss: 0.2766835 Test Loss: 0.3539950
Validation loss decreased (0.276687 --> 0.276684).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.970294713973999
Epoch: 76, Steps: 63 | Train Loss: 0.5027915 Vali Loss: 0.2770153 Test Loss: 0.3540013
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 4.43618369102478
Epoch: 77, Steps: 63 | Train Loss: 0.5025255 Vali Loss: 0.2770046 Test Loss: 0.3540094
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.6609854698181152
Epoch: 78, Steps: 63 | Train Loss: 0.5029356 Vali Loss: 0.2769266 Test Loss: 0.3540037
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.5840678215026855
Epoch: 79, Steps: 63 | Train Loss: 0.5031758 Vali Loss: 0.2769596 Test Loss: 0.3540038
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.4337265491485596
Epoch: 80, Steps: 63 | Train Loss: 0.5036032 Vali Loss: 0.2770295 Test Loss: 0.3539969
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 3.3483948707580566
Epoch: 81, Steps: 63 | Train Loss: 0.5033411 Vali Loss: 0.2769852 Test Loss: 0.3540035
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 2.3976964950561523
Epoch: 82, Steps: 63 | Train Loss: 0.5032601 Vali Loss: 0.2769618 Test Loss: 0.3539978
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 3.421160936355591
Epoch: 83, Steps: 63 | Train Loss: 0.5040817 Vali Loss: 0.2769741 Test Loss: 0.3539905
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.353376865386963
Epoch: 84, Steps: 63 | Train Loss: 0.5038008 Vali Loss: 0.2770390 Test Loss: 0.3539886
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 3.4932491779327393
Epoch: 85, Steps: 63 | Train Loss: 0.5025192 Vali Loss: 0.2770093 Test Loss: 0.3539867
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 2.720993995666504
Epoch: 86, Steps: 63 | Train Loss: 0.5022413 Vali Loss: 0.2769829 Test Loss: 0.3539891
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 2.550558090209961
Epoch: 87, Steps: 63 | Train Loss: 0.5024720 Vali Loss: 0.2770145 Test Loss: 0.3539920
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 2.2910168170928955
Epoch: 88, Steps: 63 | Train Loss: 0.5034716 Vali Loss: 0.2767583 Test Loss: 0.3539926
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.1873323917388916
Epoch: 89, Steps: 63 | Train Loss: 0.5025427 Vali Loss: 0.2769988 Test Loss: 0.3539906
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 2.33852481842041
Epoch: 90, Steps: 63 | Train Loss: 0.5036786 Vali Loss: 0.2769782 Test Loss: 0.3539925
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.940147638320923
Epoch: 91, Steps: 63 | Train Loss: 0.5028235 Vali Loss: 0.2769570 Test Loss: 0.3539899
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 3.6335911750793457
Epoch: 92, Steps: 63 | Train Loss: 0.5032188 Vali Loss: 0.2770233 Test Loss: 0.3539900
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 3.822004556655884
Epoch: 93, Steps: 63 | Train Loss: 0.5029609 Vali Loss: 0.2769896 Test Loss: 0.3539897
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 2.8306288719177246
Epoch: 94, Steps: 63 | Train Loss: 0.5033061 Vali Loss: 0.2770003 Test Loss: 0.3539896
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 3.493133306503296
Epoch: 95, Steps: 63 | Train Loss: 0.5019548 Vali Loss: 0.2769919 Test Loss: 0.3539907
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_360_192_FITS_ETTh2_ftM_sl360_ll48_pl192_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.3345314860343933, mae:0.37535715103149414, rse:0.4638305604457855, corr:[0.26716736 0.27034876 0.26805043 0.26604432 0.26555264 0.26518536
 0.26397002 0.26239553 0.26150036 0.26063597 0.25930887 0.2574006
 0.25581437 0.25492355 0.2544824  0.25424606 0.2537986  0.25329608
 0.25246    0.25134978 0.2501973  0.24896373 0.24750875 0.24539185
 0.24298222 0.24075982 0.2390571  0.23759599 0.23629312 0.23508011
 0.23385446 0.23229125 0.23049173 0.22887325 0.22773716 0.22683501
 0.22558467 0.22411622 0.22315456 0.22267377 0.22238523 0.22186321
 0.22088699 0.21970682 0.2187739  0.2178554  0.21653928 0.21457553
 0.2123949  0.2106489  0.20940164 0.20815068 0.2066044  0.2047763
 0.20276882 0.20076077 0.1991168  0.19747366 0.19623722 0.19548233
 0.19518192 0.19483812 0.19463962 0.1944469  0.19409744 0.19363637
 0.19288425 0.19201812 0.19138967 0.19091293 0.19026063 0.18932754
 0.18817931 0.18728055 0.18659715 0.1857633  0.18497434 0.1842653
 0.183555   0.18281358 0.18251613 0.18203844 0.18161277 0.1812875
 0.18124355 0.18114164 0.18095556 0.18065953 0.18016873 0.17971489
 0.17912216 0.17844309 0.17830798 0.1783731  0.17831564 0.17774585
 0.17677914 0.17561153 0.17470135 0.17382744 0.1729536  0.1721902
 0.17176053 0.17119429 0.17080805 0.17054594 0.17029697 0.17048271
 0.17032209 0.16984926 0.1689795  0.16844648 0.1680145  0.16782537
 0.16764629 0.16698442 0.16629884 0.16540278 0.16433308 0.16292949
 0.16145551 0.15984085 0.15873902 0.15809897 0.157219   0.15605238
 0.15509099 0.15449548 0.15402643 0.15329109 0.15251458 0.15183651
 0.15156674 0.151329   0.1508111  0.1502193  0.1497617  0.14961982
 0.14918374 0.1487887  0.14854264 0.14813429 0.14743687 0.14639615
 0.14477569 0.14277086 0.14109583 0.14029327 0.14001046 0.1392865
 0.13855611 0.13767076 0.13739583 0.13741551 0.13694523 0.1361548
 0.13573822 0.13619821 0.13639444 0.13644989 0.13611048 0.13582575
 0.13582177 0.13569252 0.13544838 0.13508713 0.13497236 0.13427962
 0.13308264 0.1314896  0.13005099 0.12929901 0.12889813 0.12773094
 0.12563288 0.1235546  0.12246539 0.1219987  0.12119392 0.11954483
 0.11844502 0.11851812 0.11875062 0.11817095 0.11655692 0.11508702
 0.11500946 0.11459875 0.11302558 0.1126534  0.1162452  0.12012652]
