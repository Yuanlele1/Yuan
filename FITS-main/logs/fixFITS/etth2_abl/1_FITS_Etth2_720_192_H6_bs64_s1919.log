Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=1919, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=196, out_features=248, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  43552768.0
params:  48856.0
Trainable parameters:  48856
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.1856703758239746
Epoch: 1, Steps: 60 | Train Loss: 0.6999248 Vali Loss: 0.3700026 Test Loss: 0.3876553
Validation loss decreased (inf --> 0.370003).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.5493731498718262
Epoch: 2, Steps: 60 | Train Loss: 0.5790910 Vali Loss: 0.3303196 Test Loss: 0.3685252
Validation loss decreased (0.370003 --> 0.330320).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.6175353527069092
Epoch: 3, Steps: 60 | Train Loss: 0.5545688 Vali Loss: 0.3162002 Test Loss: 0.3627788
Validation loss decreased (0.330320 --> 0.316200).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.6116552352905273
Epoch: 4, Steps: 60 | Train Loss: 0.5428266 Vali Loss: 0.3086987 Test Loss: 0.3599088
Validation loss decreased (0.316200 --> 0.308699).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.4400439262390137
Epoch: 5, Steps: 60 | Train Loss: 0.5366088 Vali Loss: 0.3040485 Test Loss: 0.3583093
Validation loss decreased (0.308699 --> 0.304049).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.443512201309204
Epoch: 6, Steps: 60 | Train Loss: 0.5304182 Vali Loss: 0.3008006 Test Loss: 0.3572488
Validation loss decreased (0.304049 --> 0.300801).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.97894287109375
Epoch: 7, Steps: 60 | Train Loss: 0.5267379 Vali Loss: 0.2982193 Test Loss: 0.3565545
Validation loss decreased (0.300801 --> 0.298219).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.361757516860962
Epoch: 8, Steps: 60 | Train Loss: 0.5245942 Vali Loss: 0.2959133 Test Loss: 0.3561090
Validation loss decreased (0.298219 --> 0.295913).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.4876666069030762
Epoch: 9, Steps: 60 | Train Loss: 0.5207452 Vali Loss: 0.2942838 Test Loss: 0.3554863
Validation loss decreased (0.295913 --> 0.294284).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.4361498355865479
Epoch: 10, Steps: 60 | Train Loss: 0.5222794 Vali Loss: 0.2927630 Test Loss: 0.3551679
Validation loss decreased (0.294284 --> 0.292763).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.8422572612762451
Epoch: 11, Steps: 60 | Train Loss: 0.5192995 Vali Loss: 0.2919700 Test Loss: 0.3550086
Validation loss decreased (0.292763 --> 0.291970).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.4948015213012695
Epoch: 12, Steps: 60 | Train Loss: 0.5187301 Vali Loss: 0.2912959 Test Loss: 0.3545020
Validation loss decreased (0.291970 --> 0.291296).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.014112710952759
Epoch: 13, Steps: 60 | Train Loss: 0.5174323 Vali Loss: 0.2901665 Test Loss: 0.3543319
Validation loss decreased (0.291296 --> 0.290167).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.6035010814666748
Epoch: 14, Steps: 60 | Train Loss: 0.5180918 Vali Loss: 0.2896247 Test Loss: 0.3540039
Validation loss decreased (0.290167 --> 0.289625).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.816284418106079
Epoch: 15, Steps: 60 | Train Loss: 0.5155942 Vali Loss: 0.2890240 Test Loss: 0.3539691
Validation loss decreased (0.289625 --> 0.289024).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.710172414779663
Epoch: 16, Steps: 60 | Train Loss: 0.5152955 Vali Loss: 0.2880976 Test Loss: 0.3538925
Validation loss decreased (0.289024 --> 0.288098).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.428879976272583
Epoch: 17, Steps: 60 | Train Loss: 0.5136892 Vali Loss: 0.2879140 Test Loss: 0.3535956
Validation loss decreased (0.288098 --> 0.287914).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.879676342010498
Epoch: 18, Steps: 60 | Train Loss: 0.5147148 Vali Loss: 0.2873040 Test Loss: 0.3535391
Validation loss decreased (0.287914 --> 0.287304).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.559145212173462
Epoch: 19, Steps: 60 | Train Loss: 0.5138477 Vali Loss: 0.2869739 Test Loss: 0.3533082
Validation loss decreased (0.287304 --> 0.286974).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.033184766769409
Epoch: 20, Steps: 60 | Train Loss: 0.5128171 Vali Loss: 0.2867317 Test Loss: 0.3532968
Validation loss decreased (0.286974 --> 0.286732).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.8537826538085938
Epoch: 21, Steps: 60 | Train Loss: 0.5136702 Vali Loss: 0.2862447 Test Loss: 0.3532464
Validation loss decreased (0.286732 --> 0.286245).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.7814013957977295
Epoch: 22, Steps: 60 | Train Loss: 0.5137783 Vali Loss: 0.2863044 Test Loss: 0.3530639
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.5373311042785645
Epoch: 23, Steps: 60 | Train Loss: 0.5123590 Vali Loss: 0.2859638 Test Loss: 0.3530244
Validation loss decreased (0.286245 --> 0.285964).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.3096978664398193
Epoch: 24, Steps: 60 | Train Loss: 0.5101853 Vali Loss: 0.2853913 Test Loss: 0.3529949
Validation loss decreased (0.285964 --> 0.285391).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.542736530303955
Epoch: 25, Steps: 60 | Train Loss: 0.5120823 Vali Loss: 0.2854898 Test Loss: 0.3528697
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.3973467350006104
Epoch: 26, Steps: 60 | Train Loss: 0.5127249 Vali Loss: 0.2851943 Test Loss: 0.3528818
Validation loss decreased (0.285391 --> 0.285194).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.7182621955871582
Epoch: 27, Steps: 60 | Train Loss: 0.5115288 Vali Loss: 0.2848910 Test Loss: 0.3528085
Validation loss decreased (0.285194 --> 0.284891).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.5874087810516357
Epoch: 28, Steps: 60 | Train Loss: 0.5120529 Vali Loss: 0.2848715 Test Loss: 0.3526491
Validation loss decreased (0.284891 --> 0.284871).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.5242433547973633
Epoch: 29, Steps: 60 | Train Loss: 0.5116996 Vali Loss: 0.2847011 Test Loss: 0.3526290
Validation loss decreased (0.284871 --> 0.284701).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.4669435024261475
Epoch: 30, Steps: 60 | Train Loss: 0.5095463 Vali Loss: 0.2845575 Test Loss: 0.3526797
Validation loss decreased (0.284701 --> 0.284557).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.387021780014038
Epoch: 31, Steps: 60 | Train Loss: 0.5115402 Vali Loss: 0.2843301 Test Loss: 0.3525673
Validation loss decreased (0.284557 --> 0.284330).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.3881289958953857
Epoch: 32, Steps: 60 | Train Loss: 0.5100277 Vali Loss: 0.2842710 Test Loss: 0.3525134
Validation loss decreased (0.284330 --> 0.284271).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.4439606666564941
Epoch: 33, Steps: 60 | Train Loss: 0.5120462 Vali Loss: 0.2842060 Test Loss: 0.3524818
Validation loss decreased (0.284271 --> 0.284206).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.4365944862365723
Epoch: 34, Steps: 60 | Train Loss: 0.5111448 Vali Loss: 0.2840114 Test Loss: 0.3525002
Validation loss decreased (0.284206 --> 0.284011).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.4717235565185547
Epoch: 35, Steps: 60 | Train Loss: 0.5102903 Vali Loss: 0.2838869 Test Loss: 0.3525008
Validation loss decreased (0.284011 --> 0.283887).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.3397033214569092
Epoch: 36, Steps: 60 | Train Loss: 0.5112874 Vali Loss: 0.2839295 Test Loss: 0.3524602
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.7769834995269775
Epoch: 37, Steps: 60 | Train Loss: 0.5087529 Vali Loss: 0.2837876 Test Loss: 0.3523876
Validation loss decreased (0.283887 --> 0.283788).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.4993023872375488
Epoch: 38, Steps: 60 | Train Loss: 0.5106012 Vali Loss: 0.2836198 Test Loss: 0.3524186
Validation loss decreased (0.283788 --> 0.283620).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.4838428497314453
Epoch: 39, Steps: 60 | Train Loss: 0.5114926 Vali Loss: 0.2835978 Test Loss: 0.3523541
Validation loss decreased (0.283620 --> 0.283598).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.4290502071380615
Epoch: 40, Steps: 60 | Train Loss: 0.5103153 Vali Loss: 0.2834673 Test Loss: 0.3523840
Validation loss decreased (0.283598 --> 0.283467).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.5000743865966797
Epoch: 41, Steps: 60 | Train Loss: 0.5101107 Vali Loss: 0.2831342 Test Loss: 0.3522854
Validation loss decreased (0.283467 --> 0.283134).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.6164770126342773
Epoch: 42, Steps: 60 | Train Loss: 0.5090374 Vali Loss: 0.2834229 Test Loss: 0.3523661
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.3834450244903564
Epoch: 43, Steps: 60 | Train Loss: 0.5086717 Vali Loss: 0.2832621 Test Loss: 0.3523490
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.4535260200500488
Epoch: 44, Steps: 60 | Train Loss: 0.5107194 Vali Loss: 0.2832645 Test Loss: 0.3523204
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.4246752262115479
Epoch: 45, Steps: 60 | Train Loss: 0.5088680 Vali Loss: 0.2831499 Test Loss: 0.3522823
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.5091578960418701
Epoch: 46, Steps: 60 | Train Loss: 0.5090071 Vali Loss: 0.2832425 Test Loss: 0.3522300
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.5973775386810303
Epoch: 47, Steps: 60 | Train Loss: 0.5082759 Vali Loss: 0.2830627 Test Loss: 0.3522779
Validation loss decreased (0.283134 --> 0.283063).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.4715673923492432
Epoch: 48, Steps: 60 | Train Loss: 0.5079512 Vali Loss: 0.2830691 Test Loss: 0.3521968
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.4089529514312744
Epoch: 49, Steps: 60 | Train Loss: 0.5076015 Vali Loss: 0.2829782 Test Loss: 0.3522440
Validation loss decreased (0.283063 --> 0.282978).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.4162554740905762
Epoch: 50, Steps: 60 | Train Loss: 0.5083298 Vali Loss: 0.2829786 Test Loss: 0.3522130
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.550595760345459
Epoch: 51, Steps: 60 | Train Loss: 0.5102890 Vali Loss: 0.2829257 Test Loss: 0.3521838
Validation loss decreased (0.282978 --> 0.282926).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.39851713180542
Epoch: 52, Steps: 60 | Train Loss: 0.5079696 Vali Loss: 0.2829487 Test Loss: 0.3521743
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.5156242847442627
Epoch: 53, Steps: 60 | Train Loss: 0.5086521 Vali Loss: 0.2829218 Test Loss: 0.3521813
Validation loss decreased (0.282926 --> 0.282922).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.3909122943878174
Epoch: 54, Steps: 60 | Train Loss: 0.5097936 Vali Loss: 0.2826020 Test Loss: 0.3521624
Validation loss decreased (0.282922 --> 0.282602).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.4649944305419922
Epoch: 55, Steps: 60 | Train Loss: 0.5096440 Vali Loss: 0.2828041 Test Loss: 0.3521832
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.4708285331726074
Epoch: 56, Steps: 60 | Train Loss: 0.5098139 Vali Loss: 0.2824573 Test Loss: 0.3521561
Validation loss decreased (0.282602 --> 0.282457).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.8035967350006104
Epoch: 57, Steps: 60 | Train Loss: 0.5093819 Vali Loss: 0.2827388 Test Loss: 0.3521599
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.5997772216796875
Epoch: 58, Steps: 60 | Train Loss: 0.5081565 Vali Loss: 0.2827442 Test Loss: 0.3521180
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.326890230178833
Epoch: 59, Steps: 60 | Train Loss: 0.5090305 Vali Loss: 0.2828080 Test Loss: 0.3521143
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.6015770435333252
Epoch: 60, Steps: 60 | Train Loss: 0.5088608 Vali Loss: 0.2826605 Test Loss: 0.3521220
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.4381868839263916
Epoch: 61, Steps: 60 | Train Loss: 0.5095096 Vali Loss: 0.2826931 Test Loss: 0.3521045
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.4926648139953613
Epoch: 62, Steps: 60 | Train Loss: 0.5080370 Vali Loss: 0.2826710 Test Loss: 0.3520913
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.4370059967041016
Epoch: 63, Steps: 60 | Train Loss: 0.5101004 Vali Loss: 0.2827078 Test Loss: 0.3520935
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.419039011001587
Epoch: 64, Steps: 60 | Train Loss: 0.5091668 Vali Loss: 0.2826754 Test Loss: 0.3520720
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.4056344032287598
Epoch: 65, Steps: 60 | Train Loss: 0.5098726 Vali Loss: 0.2826802 Test Loss: 0.3520861
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.4979190826416016
Epoch: 66, Steps: 60 | Train Loss: 0.5086359 Vali Loss: 0.2826419 Test Loss: 0.3520700
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.4460721015930176
Epoch: 67, Steps: 60 | Train Loss: 0.5092100 Vali Loss: 0.2826176 Test Loss: 0.3520667
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.5090796947479248
Epoch: 68, Steps: 60 | Train Loss: 0.5089887 Vali Loss: 0.2826607 Test Loss: 0.3520702
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.5057384967803955
Epoch: 69, Steps: 60 | Train Loss: 0.5076473 Vali Loss: 0.2822681 Test Loss: 0.3520648
Validation loss decreased (0.282457 --> 0.282268).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.3017284870147705
Epoch: 70, Steps: 60 | Train Loss: 0.5101290 Vali Loss: 0.2823566 Test Loss: 0.3520570
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.381866216659546
Epoch: 71, Steps: 60 | Train Loss: 0.5081860 Vali Loss: 0.2825545 Test Loss: 0.3520564
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.4119274616241455
Epoch: 72, Steps: 60 | Train Loss: 0.5088061 Vali Loss: 0.2825717 Test Loss: 0.3520569
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.3348619937896729
Epoch: 73, Steps: 60 | Train Loss: 0.5081691 Vali Loss: 0.2825891 Test Loss: 0.3520461
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.3966436386108398
Epoch: 74, Steps: 60 | Train Loss: 0.5075018 Vali Loss: 0.2822555 Test Loss: 0.3520574
Validation loss decreased (0.282268 --> 0.282256).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.8095896244049072
Epoch: 75, Steps: 60 | Train Loss: 0.5094609 Vali Loss: 0.2825416 Test Loss: 0.3520564
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.3940577507019043
Epoch: 76, Steps: 60 | Train Loss: 0.5087807 Vali Loss: 0.2825425 Test Loss: 0.3520518
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.4270617961883545
Epoch: 77, Steps: 60 | Train Loss: 0.5084701 Vali Loss: 0.2821263 Test Loss: 0.3520490
Validation loss decreased (0.282256 --> 0.282126).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.5842537879943848
Epoch: 78, Steps: 60 | Train Loss: 0.5089807 Vali Loss: 0.2825197 Test Loss: 0.3520534
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.390425205230713
Epoch: 79, Steps: 60 | Train Loss: 0.5070152 Vali Loss: 0.2825087 Test Loss: 0.3520520
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.351654291152954
Epoch: 80, Steps: 60 | Train Loss: 0.5097950 Vali Loss: 0.2825295 Test Loss: 0.3520338
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.4026494026184082
Epoch: 81, Steps: 60 | Train Loss: 0.5073587 Vali Loss: 0.2824455 Test Loss: 0.3520340
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.3932390213012695
Epoch: 82, Steps: 60 | Train Loss: 0.5092247 Vali Loss: 0.2824585 Test Loss: 0.3520337
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.393979549407959
Epoch: 83, Steps: 60 | Train Loss: 0.5088664 Vali Loss: 0.2824576 Test Loss: 0.3520366
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.9015252590179443
Epoch: 84, Steps: 60 | Train Loss: 0.5099388 Vali Loss: 0.2824519 Test Loss: 0.3520266
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.5079314708709717
Epoch: 85, Steps: 60 | Train Loss: 0.5086849 Vali Loss: 0.2824561 Test Loss: 0.3520389
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.4883666038513184
Epoch: 86, Steps: 60 | Train Loss: 0.5095107 Vali Loss: 0.2824518 Test Loss: 0.3520330
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.4862251281738281
Epoch: 87, Steps: 60 | Train Loss: 0.5089432 Vali Loss: 0.2824639 Test Loss: 0.3520318
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.4675920009613037
Epoch: 88, Steps: 60 | Train Loss: 0.5084581 Vali Loss: 0.2824395 Test Loss: 0.3520305
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.4938561916351318
Epoch: 89, Steps: 60 | Train Loss: 0.5085372 Vali Loss: 0.2823627 Test Loss: 0.3520283
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.436131477355957
Epoch: 90, Steps: 60 | Train Loss: 0.5077697 Vali Loss: 0.2823852 Test Loss: 0.3520323
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.274491786956787
Epoch: 91, Steps: 60 | Train Loss: 0.5094298 Vali Loss: 0.2823837 Test Loss: 0.3520306
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.4386699199676514
Epoch: 92, Steps: 60 | Train Loss: 0.5089798 Vali Loss: 0.2824390 Test Loss: 0.3520299
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.4601905345916748
Epoch: 93, Steps: 60 | Train Loss: 0.5081665 Vali Loss: 0.2824575 Test Loss: 0.3520259
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 2.4002866744995117
Epoch: 94, Steps: 60 | Train Loss: 0.5082660 Vali Loss: 0.2824154 Test Loss: 0.3520270
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.4938371181488037
Epoch: 95, Steps: 60 | Train Loss: 0.5083401 Vali Loss: 0.2823303 Test Loss: 0.3520249
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.509934425354004
Epoch: 96, Steps: 60 | Train Loss: 0.5094287 Vali Loss: 0.2824300 Test Loss: 0.3520244
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.4895007610321045
Epoch: 97, Steps: 60 | Train Loss: 0.5084469 Vali Loss: 0.2824435 Test Loss: 0.3520243
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.33146730065345764, mae:0.3745116889476776, rse:0.4617013931274414, corr:[0.26291254 0.2673993  0.2657275  0.26702696 0.26688907 0.26553097
 0.26546326 0.26542705 0.26417676 0.26292616 0.2620837  0.26092362
 0.25945473 0.2581708  0.25758612 0.25731814 0.25681686 0.25614288
 0.25533983 0.25412998 0.2526738  0.25162736 0.25059202 0.24876596
 0.2464986  0.24489397 0.24365738 0.24188246 0.24015093 0.23912778
 0.23812717 0.23637432 0.23511977 0.23444769 0.23319851 0.2315481
 0.23075135 0.23037046 0.22913912 0.22789553 0.22763826 0.22728576
 0.2260765  0.22503549 0.22451918 0.22351612 0.2218453  0.22031188
 0.21889779 0.21699163 0.21503839 0.21373521 0.21253522 0.21049869
 0.20832479 0.20694517 0.20532492 0.2032601  0.20206425 0.20135906
 0.20035654 0.1996213  0.19985278 0.19988309 0.1989783  0.19847009
 0.1982928  0.19754194 0.19660033 0.1961773  0.19560578 0.19430879
 0.19306414 0.19250719 0.19159804 0.18985234 0.18891928 0.18882447
 0.18816341 0.18693744 0.1867528  0.18674786 0.18603869 0.18547729
 0.18554671 0.18550038 0.18494421 0.18469316 0.1844916  0.18383558
 0.18310773 0.18293391 0.18304218 0.18244852 0.18190849 0.1818773
 0.18136074 0.18011673 0.17920089 0.17864084 0.1775526  0.17611663
 0.17556123 0.17524153 0.1745141  0.17369433 0.17348295 0.17344388
 0.17257823 0.17180131 0.17131868 0.17076999 0.16991912 0.16965371
 0.16938014 0.16851749 0.16775371 0.16707973 0.16596869 0.16416076
 0.1627441  0.16165502 0.16041905 0.15909185 0.15819678 0.15734696
 0.15619881 0.15524134 0.15494134 0.15421407 0.15296313 0.1520152
 0.15168771 0.15097165 0.15010042 0.14995776 0.14978209 0.14892651
 0.14807035 0.14776616 0.14740728 0.1466435  0.14606439 0.14505418
 0.14289175 0.140958   0.14009489 0.1390641  0.13733965 0.13639428
 0.13653864 0.1355781  0.13433585 0.13411807 0.13409758 0.1329687
 0.13226685 0.13281474 0.13323069 0.13289563 0.13242792 0.13268973
 0.13236402 0.13148925 0.13152064 0.1317772  0.13139282 0.13056062
 0.12990388 0.1282726  0.12676032 0.12637274 0.12619464 0.12407301
 0.12228037 0.12181467 0.12068726 0.11880293 0.11791208 0.11857129
 0.1177894  0.11697546 0.11860463 0.11970387 0.11798616 0.11821952
 0.11970112 0.11793084 0.11848532 0.12260264 0.12173484 0.12350733]
