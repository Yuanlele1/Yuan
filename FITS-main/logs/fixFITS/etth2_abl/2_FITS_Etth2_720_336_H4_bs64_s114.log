Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=134, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_336_FITS_ETTh2_ftM_sl720_ll48_pl336_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=134, out_features=196, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  23532544.0
params:  26460.0
Trainable parameters:  26460
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.024963617324829
Epoch: 1, Steps: 59 | Train Loss: 0.6637788 Vali Loss: 0.5869524 Test Loss: 0.4391463
Validation loss decreased (inf --> 0.586952).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.8946523666381836
Epoch: 2, Steps: 59 | Train Loss: 0.5251640 Vali Loss: 0.5251566 Test Loss: 0.4057986
Validation loss decreased (0.586952 --> 0.525157).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.0638515949249268
Epoch: 3, Steps: 59 | Train Loss: 0.4539626 Vali Loss: 0.4905111 Test Loss: 0.3916437
Validation loss decreased (0.525157 --> 0.490511).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.07126522064209
Epoch: 4, Steps: 59 | Train Loss: 0.4129450 Vali Loss: 0.4713795 Test Loss: 0.3854727
Validation loss decreased (0.490511 --> 0.471379).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.8931655883789062
Epoch: 5, Steps: 59 | Train Loss: 0.3844891 Vali Loss: 0.4595993 Test Loss: 0.3821992
Validation loss decreased (0.471379 --> 0.459599).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.9793119430541992
Epoch: 6, Steps: 59 | Train Loss: 0.3636749 Vali Loss: 0.4493845 Test Loss: 0.3804262
Validation loss decreased (0.459599 --> 0.449385).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.0554847717285156
Epoch: 7, Steps: 59 | Train Loss: 0.3475990 Vali Loss: 0.4429332 Test Loss: 0.3790834
Validation loss decreased (0.449385 --> 0.442933).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.089139223098755
Epoch: 8, Steps: 59 | Train Loss: 0.3342542 Vali Loss: 0.4374870 Test Loss: 0.3780191
Validation loss decreased (0.442933 --> 0.437487).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.8508672714233398
Epoch: 9, Steps: 59 | Train Loss: 0.3231051 Vali Loss: 0.4345393 Test Loss: 0.3769992
Validation loss decreased (0.437487 --> 0.434539).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.9898452758789062
Epoch: 10, Steps: 59 | Train Loss: 0.3127735 Vali Loss: 0.4299534 Test Loss: 0.3760161
Validation loss decreased (0.434539 --> 0.429953).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.9091172218322754
Epoch: 11, Steps: 59 | Train Loss: 0.3038509 Vali Loss: 0.4268083 Test Loss: 0.3752873
Validation loss decreased (0.429953 --> 0.426808).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.9101667404174805
Epoch: 12, Steps: 59 | Train Loss: 0.2969737 Vali Loss: 0.4216305 Test Loss: 0.3745143
Validation loss decreased (0.426808 --> 0.421630).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.907146692276001
Epoch: 13, Steps: 59 | Train Loss: 0.2909015 Vali Loss: 0.4211981 Test Loss: 0.3737658
Validation loss decreased (0.421630 --> 0.421198).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.9778683185577393
Epoch: 14, Steps: 59 | Train Loss: 0.2849495 Vali Loss: 0.4198799 Test Loss: 0.3730928
Validation loss decreased (0.421198 --> 0.419880).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.070848226547241
Epoch: 15, Steps: 59 | Train Loss: 0.2795457 Vali Loss: 0.4169032 Test Loss: 0.3724313
Validation loss decreased (0.419880 --> 0.416903).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.9060063362121582
Epoch: 16, Steps: 59 | Train Loss: 0.2751740 Vali Loss: 0.4156577 Test Loss: 0.3719710
Validation loss decreased (0.416903 --> 0.415658).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.991084337234497
Epoch: 17, Steps: 59 | Train Loss: 0.2712921 Vali Loss: 0.4152257 Test Loss: 0.3712588
Validation loss decreased (0.415658 --> 0.415226).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.980726718902588
Epoch: 18, Steps: 59 | Train Loss: 0.2675843 Vali Loss: 0.4147332 Test Loss: 0.3707502
Validation loss decreased (0.415226 --> 0.414733).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.8776288032531738
Epoch: 19, Steps: 59 | Train Loss: 0.2642106 Vali Loss: 0.4119645 Test Loss: 0.3703779
Validation loss decreased (0.414733 --> 0.411965).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.0247323513031006
Epoch: 20, Steps: 59 | Train Loss: 0.2610483 Vali Loss: 0.4126431 Test Loss: 0.3699647
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.9919071197509766
Epoch: 21, Steps: 59 | Train Loss: 0.2586616 Vali Loss: 0.4113908 Test Loss: 0.3695756
Validation loss decreased (0.411965 --> 0.411391).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.9222133159637451
Epoch: 22, Steps: 59 | Train Loss: 0.2563003 Vali Loss: 0.4105268 Test Loss: 0.3691471
Validation loss decreased (0.411391 --> 0.410527).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.8761794567108154
Epoch: 23, Steps: 59 | Train Loss: 0.2537887 Vali Loss: 0.4075521 Test Loss: 0.3688536
Validation loss decreased (0.410527 --> 0.407552).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.8863768577575684
Epoch: 24, Steps: 59 | Train Loss: 0.2520669 Vali Loss: 0.4079719 Test Loss: 0.3686209
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.0119409561157227
Epoch: 25, Steps: 59 | Train Loss: 0.2503067 Vali Loss: 0.4080715 Test Loss: 0.3683110
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.973503589630127
Epoch: 26, Steps: 59 | Train Loss: 0.2483017 Vali Loss: 0.4055978 Test Loss: 0.3680734
Validation loss decreased (0.407552 --> 0.405598).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.0040440559387207
Epoch: 27, Steps: 59 | Train Loss: 0.2474731 Vali Loss: 0.4043216 Test Loss: 0.3678738
Validation loss decreased (0.405598 --> 0.404322).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.0438950061798096
Epoch: 28, Steps: 59 | Train Loss: 0.2452317 Vali Loss: 0.4051478 Test Loss: 0.3676968
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.9731476306915283
Epoch: 29, Steps: 59 | Train Loss: 0.2442631 Vali Loss: 0.4034386 Test Loss: 0.3674721
Validation loss decreased (0.404322 --> 0.403439).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.9070520401000977
Epoch: 30, Steps: 59 | Train Loss: 0.2434877 Vali Loss: 0.4048409 Test Loss: 0.3673744
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.8599669933319092
Epoch: 31, Steps: 59 | Train Loss: 0.2423219 Vali Loss: 0.4012490 Test Loss: 0.3671788
Validation loss decreased (0.403439 --> 0.401249).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.0102994441986084
Epoch: 32, Steps: 59 | Train Loss: 0.2414420 Vali Loss: 0.4032336 Test Loss: 0.3670383
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.9682364463806152
Epoch: 33, Steps: 59 | Train Loss: 0.2401940 Vali Loss: 0.4011878 Test Loss: 0.3669108
Validation loss decreased (0.401249 --> 0.401188).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.067901372909546
Epoch: 34, Steps: 59 | Train Loss: 0.2391250 Vali Loss: 0.4005425 Test Loss: 0.3667728
Validation loss decreased (0.401188 --> 0.400542).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.038841724395752
Epoch: 35, Steps: 59 | Train Loss: 0.2381572 Vali Loss: 0.4004667 Test Loss: 0.3667018
Validation loss decreased (0.400542 --> 0.400467).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.0543129444122314
Epoch: 36, Steps: 59 | Train Loss: 0.2371176 Vali Loss: 0.4010232 Test Loss: 0.3666263
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.073758363723755
Epoch: 37, Steps: 59 | Train Loss: 0.2367596 Vali Loss: 0.4002416 Test Loss: 0.3665248
Validation loss decreased (0.400467 --> 0.400242).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.1025257110595703
Epoch: 38, Steps: 59 | Train Loss: 0.2366258 Vali Loss: 0.3991085 Test Loss: 0.3663962
Validation loss decreased (0.400242 --> 0.399108).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.9911572933197021
Epoch: 39, Steps: 59 | Train Loss: 0.2356809 Vali Loss: 0.4003443 Test Loss: 0.3663132
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.041100025177002
Epoch: 40, Steps: 59 | Train Loss: 0.2350930 Vali Loss: 0.3976765 Test Loss: 0.3662863
Validation loss decreased (0.399108 --> 0.397677).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.1063451766967773
Epoch: 41, Steps: 59 | Train Loss: 0.2345676 Vali Loss: 0.3975629 Test Loss: 0.3662546
Validation loss decreased (0.397677 --> 0.397563).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.061722755432129
Epoch: 42, Steps: 59 | Train Loss: 0.2344151 Vali Loss: 0.3979576 Test Loss: 0.3661603
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.0134196281433105
Epoch: 43, Steps: 59 | Train Loss: 0.2341923 Vali Loss: 0.3995857 Test Loss: 0.3661377
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.9771020412445068
Epoch: 44, Steps: 59 | Train Loss: 0.2331018 Vali Loss: 0.3965112 Test Loss: 0.3660949
Validation loss decreased (0.397563 --> 0.396511).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.0691704750061035
Epoch: 45, Steps: 59 | Train Loss: 0.2333687 Vali Loss: 0.3954593 Test Loss: 0.3660146
Validation loss decreased (0.396511 --> 0.395459).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.0024585723876953
Epoch: 46, Steps: 59 | Train Loss: 0.2328587 Vali Loss: 0.4015066 Test Loss: 0.3659759
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.080207347869873
Epoch: 47, Steps: 59 | Train Loss: 0.2323359 Vali Loss: 0.3984979 Test Loss: 0.3659723
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.0272607803344727
Epoch: 48, Steps: 59 | Train Loss: 0.2320316 Vali Loss: 0.3969662 Test Loss: 0.3659105
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.895461082458496
Epoch: 49, Steps: 59 | Train Loss: 0.2315420 Vali Loss: 0.3984875 Test Loss: 0.3658655
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.030327796936035
Epoch: 50, Steps: 59 | Train Loss: 0.2308234 Vali Loss: 0.3976897 Test Loss: 0.3658490
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.0619795322418213
Epoch: 51, Steps: 59 | Train Loss: 0.2313085 Vali Loss: 0.3988164 Test Loss: 0.3658450
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.973020315170288
Epoch: 52, Steps: 59 | Train Loss: 0.2311797 Vali Loss: 0.3963487 Test Loss: 0.3658016
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.076998472213745
Epoch: 53, Steps: 59 | Train Loss: 0.2306297 Vali Loss: 0.3974219 Test Loss: 0.3657959
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.074582815170288
Epoch: 54, Steps: 59 | Train Loss: 0.2300194 Vali Loss: 0.3970626 Test Loss: 0.3657589
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.004791259765625
Epoch: 55, Steps: 59 | Train Loss: 0.2300103 Vali Loss: 0.3933083 Test Loss: 0.3657350
Validation loss decreased (0.395459 --> 0.393308).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.0069029331207275
Epoch: 56, Steps: 59 | Train Loss: 0.2300058 Vali Loss: 0.3959259 Test Loss: 0.3657278
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.845649242401123
Epoch: 57, Steps: 59 | Train Loss: 0.2294616 Vali Loss: 0.3960291 Test Loss: 0.3657239
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.958153247833252
Epoch: 58, Steps: 59 | Train Loss: 0.2296835 Vali Loss: 0.3959697 Test Loss: 0.3656925
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.9270570278167725
Epoch: 59, Steps: 59 | Train Loss: 0.2294588 Vali Loss: 0.3961678 Test Loss: 0.3656815
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.9483487606048584
Epoch: 60, Steps: 59 | Train Loss: 0.2292010 Vali Loss: 0.3964933 Test Loss: 0.3656881
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.9051613807678223
Epoch: 61, Steps: 59 | Train Loss: 0.2288820 Vali Loss: 0.3955160 Test Loss: 0.3656636
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.008920192718506
Epoch: 62, Steps: 59 | Train Loss: 0.2285644 Vali Loss: 0.3966318 Test Loss: 0.3656543
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.9611477851867676
Epoch: 63, Steps: 59 | Train Loss: 0.2284656 Vali Loss: 0.3953829 Test Loss: 0.3656389
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.9723682403564453
Epoch: 64, Steps: 59 | Train Loss: 0.2287672 Vali Loss: 0.3953433 Test Loss: 0.3656309
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.0420191287994385
Epoch: 65, Steps: 59 | Train Loss: 0.2281198 Vali Loss: 0.3944516 Test Loss: 0.3656252
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.119079351425171
Epoch: 66, Steps: 59 | Train Loss: 0.2287046 Vali Loss: 0.3936800 Test Loss: 0.3656166
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.054097890853882
Epoch: 67, Steps: 59 | Train Loss: 0.2281270 Vali Loss: 0.3936832 Test Loss: 0.3656210
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.0377910137176514
Epoch: 68, Steps: 59 | Train Loss: 0.2278630 Vali Loss: 0.3933809 Test Loss: 0.3656115
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.0309245586395264
Epoch: 69, Steps: 59 | Train Loss: 0.2279775 Vali Loss: 0.3951690 Test Loss: 0.3656069
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.9244961738586426
Epoch: 70, Steps: 59 | Train Loss: 0.2278124 Vali Loss: 0.3949328 Test Loss: 0.3656088
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.9540574550628662
Epoch: 71, Steps: 59 | Train Loss: 0.2279592 Vali Loss: 0.3955207 Test Loss: 0.3656018
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.888273000717163
Epoch: 72, Steps: 59 | Train Loss: 0.2280942 Vali Loss: 0.3956445 Test Loss: 0.3656077
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.0778415203094482
Epoch: 73, Steps: 59 | Train Loss: 0.2277964 Vali Loss: 0.3947534 Test Loss: 0.3655914
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.058669328689575
Epoch: 74, Steps: 59 | Train Loss: 0.2272835 Vali Loss: 0.3962151 Test Loss: 0.3655930
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.1193764209747314
Epoch: 75, Steps: 59 | Train Loss: 0.2270455 Vali Loss: 0.3954055 Test Loss: 0.3655928
EarlyStopping counter: 20 out of 20
Early stopping
train 7585
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=134, out_features=196, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  23532544.0
params:  26460.0
Trainable parameters:  26460
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.9652814865112305
Epoch: 1, Steps: 59 | Train Loss: 0.6253966 Vali Loss: 0.3847864 Test Loss: 0.3630461
Validation loss decreased (inf --> 0.384786).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.9562532901763916
Epoch: 2, Steps: 59 | Train Loss: 0.6193951 Vali Loss: 0.3815401 Test Loss: 0.3611759
Validation loss decreased (0.384786 --> 0.381540).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.908578872680664
Epoch: 3, Steps: 59 | Train Loss: 0.6163004 Vali Loss: 0.3838589 Test Loss: 0.3605272
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.9824635982513428
Epoch: 4, Steps: 59 | Train Loss: 0.6149410 Vali Loss: 0.3801449 Test Loss: 0.3602232
Validation loss decreased (0.381540 --> 0.380145).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.0118162631988525
Epoch: 5, Steps: 59 | Train Loss: 0.6151521 Vali Loss: 0.3807082 Test Loss: 0.3602322
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.9962232112884521
Epoch: 6, Steps: 59 | Train Loss: 0.6147854 Vali Loss: 0.3799172 Test Loss: 0.3599373
Validation loss decreased (0.380145 --> 0.379917).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.0518648624420166
Epoch: 7, Steps: 59 | Train Loss: 0.6139560 Vali Loss: 0.3778102 Test Loss: 0.3597527
Validation loss decreased (0.379917 --> 0.377810).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.9419522285461426
Epoch: 8, Steps: 59 | Train Loss: 0.6143323 Vali Loss: 0.3769844 Test Loss: 0.3595869
Validation loss decreased (0.377810 --> 0.376984).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.0642716884613037
Epoch: 9, Steps: 59 | Train Loss: 0.6132842 Vali Loss: 0.3779378 Test Loss: 0.3597293
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.0752460956573486
Epoch: 10, Steps: 59 | Train Loss: 0.6130906 Vali Loss: 0.3779941 Test Loss: 0.3595383
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.016322374343872
Epoch: 11, Steps: 59 | Train Loss: 0.6131016 Vali Loss: 0.3785465 Test Loss: 0.3594089
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.0461339950561523
Epoch: 12, Steps: 59 | Train Loss: 0.6128759 Vali Loss: 0.3774239 Test Loss: 0.3595525
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.9367334842681885
Epoch: 13, Steps: 59 | Train Loss: 0.6132994 Vali Loss: 0.3767714 Test Loss: 0.3592383
Validation loss decreased (0.376984 --> 0.376771).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.99906587600708
Epoch: 14, Steps: 59 | Train Loss: 0.6117858 Vali Loss: 0.3780182 Test Loss: 0.3592936
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.1402313709259033
Epoch: 15, Steps: 59 | Train Loss: 0.6122843 Vali Loss: 0.3787373 Test Loss: 0.3594694
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.9228601455688477
Epoch: 16, Steps: 59 | Train Loss: 0.6121557 Vali Loss: 0.3758147 Test Loss: 0.3595169
Validation loss decreased (0.376771 --> 0.375815).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.0983097553253174
Epoch: 17, Steps: 59 | Train Loss: 0.6118079 Vali Loss: 0.3755599 Test Loss: 0.3593544
Validation loss decreased (0.375815 --> 0.375560).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.9476776123046875
Epoch: 18, Steps: 59 | Train Loss: 0.6117604 Vali Loss: 0.3781844 Test Loss: 0.3592402
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.8568329811096191
Epoch: 19, Steps: 59 | Train Loss: 0.6117157 Vali Loss: 0.3744188 Test Loss: 0.3593550
Validation loss decreased (0.375560 --> 0.374419).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.0263617038726807
Epoch: 20, Steps: 59 | Train Loss: 0.6106673 Vali Loss: 0.3763762 Test Loss: 0.3593433
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.9588234424591064
Epoch: 21, Steps: 59 | Train Loss: 0.6121565 Vali Loss: 0.3760537 Test Loss: 0.3592262
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.949657917022705
Epoch: 22, Steps: 59 | Train Loss: 0.6104020 Vali Loss: 0.3768362 Test Loss: 0.3593029
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.9313552379608154
Epoch: 23, Steps: 59 | Train Loss: 0.6116819 Vali Loss: 0.3759667 Test Loss: 0.3591539
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.9832019805908203
Epoch: 24, Steps: 59 | Train Loss: 0.6109862 Vali Loss: 0.3756612 Test Loss: 0.3592432
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.913480281829834
Epoch: 25, Steps: 59 | Train Loss: 0.6113480 Vali Loss: 0.3743928 Test Loss: 0.3592942
Validation loss decreased (0.374419 --> 0.374393).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.883631944656372
Epoch: 26, Steps: 59 | Train Loss: 0.6110211 Vali Loss: 0.3770753 Test Loss: 0.3591813
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.9162213802337646
Epoch: 27, Steps: 59 | Train Loss: 0.6104565 Vali Loss: 0.3755296 Test Loss: 0.3591268
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.9683668613433838
Epoch: 28, Steps: 59 | Train Loss: 0.6115458 Vali Loss: 0.3750840 Test Loss: 0.3591678
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.9797842502593994
Epoch: 29, Steps: 59 | Train Loss: 0.6118834 Vali Loss: 0.3755475 Test Loss: 0.3592266
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.8611230850219727
Epoch: 30, Steps: 59 | Train Loss: 0.6110143 Vali Loss: 0.3749595 Test Loss: 0.3592072
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.100086212158203
Epoch: 31, Steps: 59 | Train Loss: 0.6101087 Vali Loss: 0.3766959 Test Loss: 0.3592119
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.114718437194824
Epoch: 32, Steps: 59 | Train Loss: 0.6101697 Vali Loss: 0.3772642 Test Loss: 0.3591653
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.9537417888641357
Epoch: 33, Steps: 59 | Train Loss: 0.6095352 Vali Loss: 0.3744612 Test Loss: 0.3590748
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.9252080917358398
Epoch: 34, Steps: 59 | Train Loss: 0.6109129 Vali Loss: 0.3730039 Test Loss: 0.3591626
Validation loss decreased (0.374393 --> 0.373004).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.9835073947906494
Epoch: 35, Steps: 59 | Train Loss: 0.6107996 Vali Loss: 0.3775071 Test Loss: 0.3591075
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.8890376091003418
Epoch: 36, Steps: 59 | Train Loss: 0.6119066 Vali Loss: 0.3761804 Test Loss: 0.3591745
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.903442144393921
Epoch: 37, Steps: 59 | Train Loss: 0.6093400 Vali Loss: 0.3746938 Test Loss: 0.3591419
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.9941766262054443
Epoch: 38, Steps: 59 | Train Loss: 0.6110659 Vali Loss: 0.3779175 Test Loss: 0.3591523
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.143639087677002
Epoch: 39, Steps: 59 | Train Loss: 0.6115840 Vali Loss: 0.3758718 Test Loss: 0.3591543
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.9482250213623047
Epoch: 40, Steps: 59 | Train Loss: 0.6104163 Vali Loss: 0.3737040 Test Loss: 0.3591575
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.9304025173187256
Epoch: 41, Steps: 59 | Train Loss: 0.6104137 Vali Loss: 0.3759848 Test Loss: 0.3591510
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.067434072494507
Epoch: 42, Steps: 59 | Train Loss: 0.6095716 Vali Loss: 0.3773580 Test Loss: 0.3591130
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.0669500827789307
Epoch: 43, Steps: 59 | Train Loss: 0.6100872 Vali Loss: 0.3758548 Test Loss: 0.3591501
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.9005990028381348
Epoch: 44, Steps: 59 | Train Loss: 0.6110236 Vali Loss: 0.3738073 Test Loss: 0.3591677
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.9048395156860352
Epoch: 45, Steps: 59 | Train Loss: 0.6097108 Vali Loss: 0.3749782 Test Loss: 0.3591475
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.9254438877105713
Epoch: 46, Steps: 59 | Train Loss: 0.6102278 Vali Loss: 0.3758866 Test Loss: 0.3591417
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.8966667652130127
Epoch: 47, Steps: 59 | Train Loss: 0.6110284 Vali Loss: 0.3770407 Test Loss: 0.3591417
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.983461856842041
Epoch: 48, Steps: 59 | Train Loss: 0.6118160 Vali Loss: 0.3763896 Test Loss: 0.3591439
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.022359609603882
Epoch: 49, Steps: 59 | Train Loss: 0.6092903 Vali Loss: 0.3756873 Test Loss: 0.3591705
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.876455545425415
Epoch: 50, Steps: 59 | Train Loss: 0.6105753 Vali Loss: 0.3764078 Test Loss: 0.3591351
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.002558708190918
Epoch: 51, Steps: 59 | Train Loss: 0.6106094 Vali Loss: 0.3765919 Test Loss: 0.3591414
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.0352389812469482
Epoch: 52, Steps: 59 | Train Loss: 0.6103422 Vali Loss: 0.3767511 Test Loss: 0.3591621
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.953460931777954
Epoch: 53, Steps: 59 | Train Loss: 0.6102544 Vali Loss: 0.3761646 Test Loss: 0.3591391
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.880284309387207
Epoch: 54, Steps: 59 | Train Loss: 0.6094204 Vali Loss: 0.3758400 Test Loss: 0.3591194
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_720_336_FITS_ETTh2_ftM_sl720_ll48_pl336_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.3548802137374878, mae:0.3957980275154114, rse:0.47629982233047485, corr:[0.26178786 0.26502576 0.2637001  0.2623395  0.26207897 0.2621403
 0.26145142 0.26011103 0.2592124  0.25849473 0.2575402  0.2559262
 0.25442407 0.25338054 0.2527522  0.25227028 0.25153598 0.25057787
 0.24963892 0.2488559  0.24807371 0.24703164 0.24561583 0.2440495
 0.24258284 0.24137841 0.24025401 0.2391541  0.2382207  0.23742767
 0.23655933 0.235469   0.23427483 0.2333401  0.23267491 0.23199594
 0.23104657 0.23008804 0.22937374 0.22884874 0.22832698 0.22759493
 0.22664979 0.22579242 0.22510944 0.22428441 0.22294042 0.22101988
 0.21907419 0.21761724 0.21647099 0.21508534 0.21349317 0.2117219
 0.20972548 0.20790958 0.20631091 0.2047417  0.20339352 0.20245153
 0.20192346 0.20147985 0.20109145 0.20092052 0.20060216 0.20047824
 0.20018804 0.19964267 0.19884281 0.19815296 0.1974477  0.19672778
 0.19577435 0.19461842 0.19350713 0.19247696 0.19184892 0.19141147
 0.19092794 0.19008863 0.18947369 0.18902652 0.18865861 0.18841521
 0.18832712 0.18821765 0.18783931 0.18719909 0.18637441 0.1857264
 0.18548806 0.18540287 0.18563038 0.18579203 0.18561482 0.18511063
 0.18451874 0.18403034 0.18372782 0.1832009  0.18246761 0.18164775
 0.1812144  0.18087193 0.18066204 0.18033901 0.18010713 0.18003787
 0.17975408 0.17934246 0.17861305 0.17790134 0.17721584 0.17697057
 0.17692538 0.17665769 0.17599918 0.17473325 0.1734102  0.17216775
 0.17112213 0.17012142 0.1692074  0.16841154 0.16759165 0.16684656
 0.16600779 0.16511586 0.16430977 0.16363719 0.1631389  0.16251199
 0.161834   0.16114041 0.16071258 0.1605715  0.16029088 0.15966818
 0.15873429 0.15790384 0.1575939  0.15750831 0.15711798 0.15595314
 0.15406214 0.1522318  0.15085992 0.14989838 0.14899766 0.14813872
 0.14744928 0.14683212 0.14649758 0.1460584  0.14526491 0.14429314
 0.14373864 0.14370665 0.14382486 0.14365123 0.14283107 0.14200269
 0.1415085  0.14134863 0.14129096 0.14107509 0.14076409 0.14018485
 0.13946424 0.13835984 0.13697667 0.13556802 0.13460937 0.13382737
 0.1331241  0.13185436 0.13036461 0.12925085 0.12856966 0.12833235
 0.12803093 0.12742865 0.12674809 0.1264026  0.12609845 0.12603743
 0.12605093 0.12596758 0.12606412 0.1262943  0.12675588 0.12674072
 0.12624115 0.12567736 0.12524621 0.12514605 0.12494804 0.12432954
 0.12353414 0.12281831 0.12253626 0.12244041 0.12226816 0.12194811
 0.12167601 0.12185494 0.12200816 0.12196571 0.12162038 0.12140986
 0.12154704 0.12211508 0.12277677 0.12303215 0.12287201 0.12226839
 0.12142049 0.12034456 0.11904775 0.11810257 0.11771485 0.11827473
 0.11881195 0.11902953 0.11856873 0.11795045 0.11774898 0.11787443
 0.11782086 0.11744326 0.11682297 0.11680579 0.11730593 0.11809584
 0.11854806 0.1186727  0.11877051 0.11915814 0.1195815  0.11949737
 0.11877797 0.11791135 0.11758168 0.1180559  0.11833022 0.11776122
 0.11713388 0.11707794 0.11787406 0.11872283 0.1188723  0.11851563
 0.11817362 0.11888649 0.12020075 0.12183289 0.12264477 0.12319542
 0.12367352 0.12437655 0.12497644 0.12483472 0.12481683 0.12519106
 0.12619805 0.12696837 0.1271936  0.12689912 0.12641926 0.12646185
 0.12694733 0.12725523 0.12712903 0.12633513 0.12619236 0.12644371
 0.12672655 0.12641715 0.1256723  0.12535197 0.12591998 0.12683845
 0.12710714 0.12663245 0.12578827 0.12536184 0.12572274 0.12610142
 0.12564893 0.12452048 0.1235307  0.1234161  0.12355659 0.12283766
 0.12151832 0.1203782  0.12016512 0.12037499 0.12040231 0.11968184
 0.11846954 0.11832114 0.11932181 0.12071989 0.12076536 0.12037867
 0.11993141 0.12043592 0.12128484 0.12164101 0.12113839 0.12028016
 0.12012717 0.1201341  0.11996679 0.1189548  0.11762586 0.11683103
 0.11682982 0.11699113 0.11632241 0.11600547 0.11663457 0.11805114
 0.11826906 0.11719149 0.11653139 0.11745457 0.11914204 0.11948952
 0.11756795 0.11527159 0.11541723 0.11780822 0.11886122 0.11247651]
