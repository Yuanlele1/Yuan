Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=42, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_90_j336_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_90_j336_H8_FITS_custom_ftM_sl90_ll48_pl336_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17987
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=42, out_features=198, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  341687808.0
params:  8514.0
Trainable parameters:  8514
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.9578362
	speed: 0.1306s/iter; left time: 1815.9218s
Epoch: 1 cost time: 17.8869149684906
Epoch: 1, Steps: 140 | Train Loss: 1.2183416 Vali Loss: 0.6265368 Test Loss: 0.7189111
Validation loss decreased (inf --> 0.626537).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5080042
	speed: 0.3226s/iter; left time: 4439.1173s
Epoch: 2 cost time: 18.146677017211914
Epoch: 2, Steps: 140 | Train Loss: 0.5680804 Vali Loss: 0.3813569 Test Loss: 0.4370066
Validation loss decreased (0.626537 --> 0.381357).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3411391
	speed: 0.3101s/iter; left time: 4223.6250s
Epoch: 3 cost time: 17.592967748641968
Epoch: 3, Steps: 140 | Train Loss: 0.3848227 Vali Loss: 0.2887715 Test Loss: 0.3292574
Validation loss decreased (0.381357 --> 0.288771).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2996991
	speed: 0.3153s/iter; left time: 4250.8048s
Epoch: 4 cost time: 18.367661476135254
Epoch: 4, Steps: 140 | Train Loss: 0.3117867 Vali Loss: 0.2503373 Test Loss: 0.2837226
Validation loss decreased (0.288771 --> 0.250337).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2721354
	speed: 0.3190s/iter; left time: 4255.4133s
Epoch: 5 cost time: 17.922417163848877
Epoch: 5, Steps: 140 | Train Loss: 0.2798193 Vali Loss: 0.2321368 Test Loss: 0.2623500
Validation loss decreased (0.250337 --> 0.232137).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2583791
	speed: 0.3169s/iter; left time: 4183.2956s
Epoch: 6 cost time: 18.34974980354309
Epoch: 6, Steps: 140 | Train Loss: 0.2638279 Vali Loss: 0.2218712 Test Loss: 0.2508345
Validation loss decreased (0.232137 --> 0.221871).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2440798
	speed: 0.3145s/iter; left time: 4107.5396s
Epoch: 7 cost time: 17.433587789535522
Epoch: 7, Steps: 140 | Train Loss: 0.2545915 Vali Loss: 0.2161069 Test Loss: 0.2437425
Validation loss decreased (0.221871 --> 0.216107).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2415663
	speed: 0.2970s/iter; left time: 3838.1025s
Epoch: 8 cost time: 16.882286548614502
Epoch: 8, Steps: 140 | Train Loss: 0.2485870 Vali Loss: 0.2115478 Test Loss: 0.2389432
Validation loss decreased (0.216107 --> 0.211548).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2632538
	speed: 0.3102s/iter; left time: 3964.4405s
Epoch: 9 cost time: 17.69918990135193
Epoch: 9, Steps: 140 | Train Loss: 0.2443269 Vali Loss: 0.2086359 Test Loss: 0.2354646
Validation loss decreased (0.211548 --> 0.208636).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2458571
	speed: 0.3019s/iter; left time: 3816.4711s
Epoch: 10 cost time: 17.346669912338257
Epoch: 10, Steps: 140 | Train Loss: 0.2412571 Vali Loss: 0.2065739 Test Loss: 0.2328831
Validation loss decreased (0.208636 --> 0.206574).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2477353
	speed: 0.3152s/iter; left time: 3940.3683s
Epoch: 11 cost time: 17.679891109466553
Epoch: 11, Steps: 140 | Train Loss: 0.2388136 Vali Loss: 0.2043624 Test Loss: 0.2308506
Validation loss decreased (0.206574 --> 0.204362).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2358264
	speed: 0.3074s/iter; left time: 3799.7197s
Epoch: 12 cost time: 17.176841259002686
Epoch: 12, Steps: 140 | Train Loss: 0.2369020 Vali Loss: 0.2030026 Test Loss: 0.2292751
Validation loss decreased (0.204362 --> 0.203003).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2259629
	speed: 0.3130s/iter; left time: 3824.7798s
Epoch: 13 cost time: 17.35106873512268
Epoch: 13, Steps: 140 | Train Loss: 0.2353832 Vali Loss: 0.2018248 Test Loss: 0.2280262
Validation loss decreased (0.203003 --> 0.201825).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2221431
	speed: 0.3056s/iter; left time: 3691.8805s
Epoch: 14 cost time: 17.124022245407104
Epoch: 14, Steps: 140 | Train Loss: 0.2341857 Vali Loss: 0.2014004 Test Loss: 0.2270158
Validation loss decreased (0.201825 --> 0.201400).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2295111
	speed: 0.3136s/iter; left time: 3745.1727s
Epoch: 15 cost time: 17.44623875617981
Epoch: 15, Steps: 140 | Train Loss: 0.2332392 Vali Loss: 0.1999688 Test Loss: 0.2261484
Validation loss decreased (0.201400 --> 0.199969).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2238683
	speed: 0.3033s/iter; left time: 3579.4145s
Epoch: 16 cost time: 16.8486270904541
Epoch: 16, Steps: 140 | Train Loss: 0.2324799 Vali Loss: 0.1993957 Test Loss: 0.2254485
Validation loss decreased (0.199969 --> 0.199396).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2319017
	speed: 0.3034s/iter; left time: 3537.6090s
Epoch: 17 cost time: 16.889314889907837
Epoch: 17, Steps: 140 | Train Loss: 0.2315860 Vali Loss: 0.1987375 Test Loss: 0.2248486
Validation loss decreased (0.199396 --> 0.198738).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2212416
	speed: 0.3002s/iter; left time: 3458.1462s
Epoch: 18 cost time: 16.92967653274536
Epoch: 18, Steps: 140 | Train Loss: 0.2311024 Vali Loss: 0.1983378 Test Loss: 0.2243317
Validation loss decreased (0.198738 --> 0.198338).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2239290
	speed: 0.3059s/iter; left time: 3481.2581s
Epoch: 19 cost time: 17.458643913269043
Epoch: 19, Steps: 140 | Train Loss: 0.2305801 Vali Loss: 0.1979401 Test Loss: 0.2238829
Validation loss decreased (0.198338 --> 0.197940).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2344593
	speed: 0.3142s/iter; left time: 3531.6285s
Epoch: 20 cost time: 17.646544456481934
Epoch: 20, Steps: 140 | Train Loss: 0.2301761 Vali Loss: 0.1976184 Test Loss: 0.2234928
Validation loss decreased (0.197940 --> 0.197618).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2326201
	speed: 0.3100s/iter; left time: 3440.8470s
Epoch: 21 cost time: 17.497127532958984
Epoch: 21, Steps: 140 | Train Loss: 0.2297468 Vali Loss: 0.1973599 Test Loss: 0.2231442
Validation loss decreased (0.197618 --> 0.197360).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2255175
	speed: 0.3025s/iter; left time: 3315.8822s
Epoch: 22 cost time: 17.002182722091675
Epoch: 22, Steps: 140 | Train Loss: 0.2293422 Vali Loss: 0.1968594 Test Loss: 0.2228284
Validation loss decreased (0.197360 --> 0.196859).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2387958
	speed: 0.3017s/iter; left time: 3264.8157s
Epoch: 23 cost time: 17.522687435150146
Epoch: 23, Steps: 140 | Train Loss: 0.2291075 Vali Loss: 0.1968672 Test Loss: 0.2225483
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2291536
	speed: 0.3090s/iter; left time: 3300.8424s
Epoch: 24 cost time: 17.87440061569214
Epoch: 24, Steps: 140 | Train Loss: 0.2287702 Vali Loss: 0.1967777 Test Loss: 0.2222980
Validation loss decreased (0.196859 --> 0.196778).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2138569
	speed: 0.3113s/iter; left time: 3281.0601s
Epoch: 25 cost time: 17.340413331985474
Epoch: 25, Steps: 140 | Train Loss: 0.2284967 Vali Loss: 0.1962696 Test Loss: 0.2220691
Validation loss decreased (0.196778 --> 0.196270).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2282472
	speed: 0.3135s/iter; left time: 3260.5745s
Epoch: 26 cost time: 18.017523765563965
Epoch: 26, Steps: 140 | Train Loss: 0.2282572 Vali Loss: 0.1961936 Test Loss: 0.2218406
Validation loss decreased (0.196270 --> 0.196194).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2291185
	speed: 0.3103s/iter; left time: 3183.7120s
Epoch: 27 cost time: 17.358651399612427
Epoch: 27, Steps: 140 | Train Loss: 0.2279796 Vali Loss: 0.1961682 Test Loss: 0.2216486
Validation loss decreased (0.196194 --> 0.196168).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2319409
	speed: 0.3078s/iter; left time: 3115.4835s
Epoch: 28 cost time: 17.171720027923584
Epoch: 28, Steps: 140 | Train Loss: 0.2278423 Vali Loss: 0.1960272 Test Loss: 0.2214722
Validation loss decreased (0.196168 --> 0.196027).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2406537
	speed: 0.3201s/iter; left time: 3194.7913s
Epoch: 29 cost time: 17.885547399520874
Epoch: 29, Steps: 140 | Train Loss: 0.2275961 Vali Loss: 0.1956180 Test Loss: 0.2213078
Validation loss decreased (0.196027 --> 0.195618).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2219948
	speed: 0.3045s/iter; left time: 2996.2573s
Epoch: 30 cost time: 17.579344034194946
Epoch: 30, Steps: 140 | Train Loss: 0.2274983 Vali Loss: 0.1953114 Test Loss: 0.2211598
Validation loss decreased (0.195618 --> 0.195311).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2408296
	speed: 0.3127s/iter; left time: 3033.7719s
Epoch: 31 cost time: 17.644503116607666
Epoch: 31, Steps: 140 | Train Loss: 0.2273237 Vali Loss: 0.1952976 Test Loss: 0.2210162
Validation loss decreased (0.195311 --> 0.195298).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2222084
	speed: 0.3069s/iter; left time: 2934.7070s
Epoch: 32 cost time: 17.13659381866455
Epoch: 32, Steps: 140 | Train Loss: 0.2271645 Vali Loss: 0.1954579 Test Loss: 0.2208863
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2241152
	speed: 0.3124s/iter; left time: 2943.4489s
Epoch: 33 cost time: 18.039351224899292
Epoch: 33, Steps: 140 | Train Loss: 0.2270139 Vali Loss: 0.1953808 Test Loss: 0.2207641
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2164596
	speed: 0.3280s/iter; left time: 3044.2704s
Epoch: 34 cost time: 17.722962856292725
Epoch: 34, Steps: 140 | Train Loss: 0.2268984 Vali Loss: 0.1951095 Test Loss: 0.2206523
Validation loss decreased (0.195298 --> 0.195109).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2302068
	speed: 0.3084s/iter; left time: 2819.2374s
Epoch: 35 cost time: 17.22326683998108
Epoch: 35, Steps: 140 | Train Loss: 0.2267601 Vali Loss: 0.1948772 Test Loss: 0.2205456
Validation loss decreased (0.195109 --> 0.194877).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2209813
	speed: 0.3111s/iter; left time: 2800.0839s
Epoch: 36 cost time: 17.05613946914673
Epoch: 36, Steps: 140 | Train Loss: 0.2267021 Vali Loss: 0.1950688 Test Loss: 0.2204532
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2336800
	speed: 0.3091s/iter; left time: 2738.9616s
Epoch: 37 cost time: 17.371355772018433
Epoch: 37, Steps: 140 | Train Loss: 0.2265775 Vali Loss: 0.1945022 Test Loss: 0.2203659
Validation loss decreased (0.194877 --> 0.194502).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2162935
	speed: 0.3100s/iter; left time: 2703.8374s
Epoch: 38 cost time: 17.444314002990723
Epoch: 38, Steps: 140 | Train Loss: 0.2264204 Vali Loss: 0.1945891 Test Loss: 0.2202808
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2389825
	speed: 0.3108s/iter; left time: 2666.9823s
Epoch: 39 cost time: 17.28415608406067
Epoch: 39, Steps: 140 | Train Loss: 0.2264539 Vali Loss: 0.1948742 Test Loss: 0.2202141
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2324433
	speed: 0.3130s/iter; left time: 2642.3980s
Epoch: 40 cost time: 17.448134422302246
Epoch: 40, Steps: 140 | Train Loss: 0.2263331 Vali Loss: 0.1947070 Test Loss: 0.2201458
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2325149
	speed: 0.3132s/iter; left time: 2599.7552s
Epoch: 41 cost time: 17.672654390335083
Epoch: 41, Steps: 140 | Train Loss: 0.2262726 Vali Loss: 0.1947494 Test Loss: 0.2200811
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2238955
	speed: 0.3056s/iter; left time: 2494.4005s
Epoch: 42 cost time: 17.380954027175903
Epoch: 42, Steps: 140 | Train Loss: 0.2262102 Vali Loss: 0.1943557 Test Loss: 0.2200266
Validation loss decreased (0.194502 --> 0.194356).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2162303
	speed: 0.3127s/iter; left time: 2508.0358s
Epoch: 43 cost time: 17.701169967651367
Epoch: 43, Steps: 140 | Train Loss: 0.2261398 Vali Loss: 0.1944164 Test Loss: 0.2199689
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2184970
	speed: 0.3127s/iter; left time: 2464.2214s
Epoch: 44 cost time: 17.62055277824402
Epoch: 44, Steps: 140 | Train Loss: 0.2261283 Vali Loss: 0.1946683 Test Loss: 0.2199137
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2180830
	speed: 0.3132s/iter; left time: 2424.5697s
Epoch: 45 cost time: 18.39327907562256
Epoch: 45, Steps: 140 | Train Loss: 0.2259988 Vali Loss: 0.1946657 Test Loss: 0.2198693
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2308937
	speed: 0.3202s/iter; left time: 2434.0441s
Epoch: 46 cost time: 17.65314269065857
Epoch: 46, Steps: 140 | Train Loss: 0.2260092 Vali Loss: 0.1948997 Test Loss: 0.2198312
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2212527
	speed: 0.3127s/iter; left time: 2333.1359s
Epoch: 47 cost time: 17.804646015167236
Epoch: 47, Steps: 140 | Train Loss: 0.2259717 Vali Loss: 0.1939942 Test Loss: 0.2197886
Validation loss decreased (0.194356 --> 0.193994).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2287214
	speed: 0.3127s/iter; left time: 2289.5867s
Epoch: 48 cost time: 17.0679874420166
Epoch: 48, Steps: 140 | Train Loss: 0.2259845 Vali Loss: 0.1941115 Test Loss: 0.2197526
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2169830
	speed: 0.3091s/iter; left time: 2219.7033s
Epoch: 49 cost time: 17.69704532623291
Epoch: 49, Steps: 140 | Train Loss: 0.2257947 Vali Loss: 0.1943492 Test Loss: 0.2197243
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2173373
	speed: 0.3041s/iter; left time: 2140.8470s
Epoch: 50 cost time: 17.24698305130005
Epoch: 50, Steps: 140 | Train Loss: 0.2258570 Vali Loss: 0.1939416 Test Loss: 0.2196941
Validation loss decreased (0.193994 --> 0.193942).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2381390
	speed: 0.3007s/iter; left time: 2075.2944s
Epoch: 51 cost time: 17.322332620620728
Epoch: 51, Steps: 140 | Train Loss: 0.2258102 Vali Loss: 0.1941522 Test Loss: 0.2196624
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2181690
	speed: 0.3121s/iter; left time: 2110.3580s
Epoch: 52 cost time: 17.752323389053345
Epoch: 52, Steps: 140 | Train Loss: 0.2257760 Vali Loss: 0.1938295 Test Loss: 0.2196369
Validation loss decreased (0.193942 --> 0.193830).  Saving model ...
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2233885
	speed: 0.3095s/iter; left time: 2049.2481s
Epoch: 53 cost time: 17.258176565170288
Epoch: 53, Steps: 140 | Train Loss: 0.2257479 Vali Loss: 0.1938009 Test Loss: 0.2196153
Validation loss decreased (0.193830 --> 0.193801).  Saving model ...
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2310310
	speed: 0.3131s/iter; left time: 2029.0679s
Epoch: 54 cost time: 17.3226900100708
Epoch: 54, Steps: 140 | Train Loss: 0.2257429 Vali Loss: 0.1940510 Test Loss: 0.2195922
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2322461
	speed: 0.3092s/iter; left time: 1960.4617s
Epoch: 55 cost time: 17.547497272491455
Epoch: 55, Steps: 140 | Train Loss: 0.2256631 Vali Loss: 0.1940460 Test Loss: 0.2195724
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2166988
	speed: 0.3096s/iter; left time: 1919.6335s
Epoch: 56 cost time: 17.476459741592407
Epoch: 56, Steps: 140 | Train Loss: 0.2256317 Vali Loss: 0.1938036 Test Loss: 0.2195553
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2194456
	speed: 0.3041s/iter; left time: 1843.3015s
Epoch: 57 cost time: 16.963638305664062
Epoch: 57, Steps: 140 | Train Loss: 0.2256668 Vali Loss: 0.1938670 Test Loss: 0.2195387
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2302856
	speed: 0.3019s/iter; left time: 1787.6974s
Epoch: 58 cost time: 17.092153310775757
Epoch: 58, Steps: 140 | Train Loss: 0.2256456 Vali Loss: 0.1938880 Test Loss: 0.2195255
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2273316
	speed: 0.3114s/iter; left time: 1800.2456s
Epoch: 59 cost time: 17.577178478240967
Epoch: 59, Steps: 140 | Train Loss: 0.2256986 Vali Loss: 0.1943724 Test Loss: 0.2195101
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.2245249
	speed: 0.3127s/iter; left time: 1763.7169s
Epoch: 60 cost time: 17.511032104492188
Epoch: 60, Steps: 140 | Train Loss: 0.2256197 Vali Loss: 0.1940452 Test Loss: 0.2194957
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.2203267
	speed: 0.3167s/iter; left time: 1742.2508s
Epoch: 61 cost time: 17.825351238250732
Epoch: 61, Steps: 140 | Train Loss: 0.2256698 Vali Loss: 0.1942615 Test Loss: 0.2194815
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.2351722
	speed: 0.3089s/iter; left time: 1655.7820s
Epoch: 62 cost time: 17.309237957000732
Epoch: 62, Steps: 140 | Train Loss: 0.2256372 Vali Loss: 0.1938407 Test Loss: 0.2194737
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.2142031
	speed: 0.3035s/iter; left time: 1584.5995s
Epoch: 63 cost time: 17.055763721466064
Epoch: 63, Steps: 140 | Train Loss: 0.2255763 Vali Loss: 0.1940600 Test Loss: 0.2194638
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.2308531
	speed: 0.3167s/iter; left time: 1609.1226s
Epoch: 64 cost time: 17.640010356903076
Epoch: 64, Steps: 140 | Train Loss: 0.2255765 Vali Loss: 0.1939972 Test Loss: 0.2194542
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.2150942
	speed: 0.3090s/iter; left time: 1526.7955s
Epoch: 65 cost time: 18.054015159606934
Epoch: 65, Steps: 140 | Train Loss: 0.2255954 Vali Loss: 0.1942600 Test Loss: 0.2194444
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.2234947
	speed: 0.3190s/iter; left time: 1531.4657s
Epoch: 66 cost time: 17.30135726928711
Epoch: 66, Steps: 140 | Train Loss: 0.2256334 Vali Loss: 0.1940296 Test Loss: 0.2194410
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.2214629
	speed: 0.3019s/iter; left time: 1407.0751s
Epoch: 67 cost time: 17.282538175582886
Epoch: 67, Steps: 140 | Train Loss: 0.2255552 Vali Loss: 0.1939753 Test Loss: 0.2194325
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.2217358
	speed: 0.2903s/iter; left time: 1312.3829s
Epoch: 68 cost time: 16.000677824020386
Epoch: 68, Steps: 140 | Train Loss: 0.2255241 Vali Loss: 0.1937426 Test Loss: 0.2194247
Validation loss decreased (0.193801 --> 0.193743).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.2304169
	speed: 0.2756s/iter; left time: 1207.5562s
Epoch: 69 cost time: 15.306492328643799
Epoch: 69, Steps: 140 | Train Loss: 0.2255876 Vali Loss: 0.1938954 Test Loss: 0.2194186
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.2148048
	speed: 0.3048s/iter; left time: 1292.6355s
Epoch: 70 cost time: 17.810813426971436
Epoch: 70, Steps: 140 | Train Loss: 0.2255208 Vali Loss: 0.1940203 Test Loss: 0.2194153
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.2256825
	speed: 0.3043s/iter; left time: 1247.7654s
Epoch: 71 cost time: 16.917189836502075
Epoch: 71, Steps: 140 | Train Loss: 0.2255232 Vali Loss: 0.1937895 Test Loss: 0.2194120
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.2265537
	speed: 0.3100s/iter; left time: 1227.7485s
Epoch: 72 cost time: 16.94114089012146
Epoch: 72, Steps: 140 | Train Loss: 0.2256092 Vali Loss: 0.1937310 Test Loss: 0.2194058
Validation loss decreased (0.193743 --> 0.193731).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.2292684
	speed: 0.3052s/iter; left time: 1166.0112s
Epoch: 73 cost time: 17.737330198287964
Epoch: 73, Steps: 140 | Train Loss: 0.2255233 Vali Loss: 0.1937928 Test Loss: 0.2194016
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.2189150
	speed: 0.3021s/iter; left time: 1112.1000s
Epoch: 74 cost time: 16.60451316833496
Epoch: 74, Steps: 140 | Train Loss: 0.2255034 Vali Loss: 0.1938100 Test Loss: 0.2193984
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.2293691
	speed: 0.3107s/iter; left time: 1100.1636s
Epoch: 75 cost time: 17.87511157989502
Epoch: 75, Steps: 140 | Train Loss: 0.2255183 Vali Loss: 0.1937946 Test Loss: 0.2193932
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.2274379
	speed: 0.3047s/iter; left time: 1036.3604s
Epoch: 76 cost time: 17.120452404022217
Epoch: 76, Steps: 140 | Train Loss: 0.2255087 Vali Loss: 0.1937174 Test Loss: 0.2193910
Validation loss decreased (0.193731 --> 0.193717).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.2232267
	speed: 0.3086s/iter; left time: 1006.2165s
Epoch: 77 cost time: 17.240740060806274
Epoch: 77, Steps: 140 | Train Loss: 0.2255202 Vali Loss: 0.1938858 Test Loss: 0.2193888
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.2252229
	speed: 0.3046s/iter; left time: 950.7569s
Epoch: 78 cost time: 18.076195001602173
Epoch: 78, Steps: 140 | Train Loss: 0.2255022 Vali Loss: 0.1937772 Test Loss: 0.2193851
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.2321334
	speed: 0.3061s/iter; left time: 912.3353s
Epoch: 79 cost time: 17.072410821914673
Epoch: 79, Steps: 140 | Train Loss: 0.2254385 Vali Loss: 0.1939044 Test Loss: 0.2193838
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.2151233
	speed: 0.3221s/iter; left time: 914.9553s
Epoch: 80 cost time: 17.81203031539917
Epoch: 80, Steps: 140 | Train Loss: 0.2254340 Vali Loss: 0.1939064 Test Loss: 0.2193810
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.2092022
	speed: 0.3007s/iter; left time: 812.0924s
Epoch: 81 cost time: 17.108749866485596
Epoch: 81, Steps: 140 | Train Loss: 0.2255313 Vali Loss: 0.1935272 Test Loss: 0.2193793
Validation loss decreased (0.193717 --> 0.193527).  Saving model ...
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.2149644
	speed: 0.3060s/iter; left time: 783.7127s
Epoch: 82 cost time: 17.341981410980225
Epoch: 82, Steps: 140 | Train Loss: 0.2254805 Vali Loss: 0.1938519 Test Loss: 0.2193774
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.2079453
	speed: 0.3053s/iter; left time: 739.0317s
Epoch: 83 cost time: 17.29537034034729
Epoch: 83, Steps: 140 | Train Loss: 0.2255228 Vali Loss: 0.1939450 Test Loss: 0.2193758
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.2119319
	speed: 0.3098s/iter; left time: 706.5514s
Epoch: 84 cost time: 17.080259799957275
Epoch: 84, Steps: 140 | Train Loss: 0.2254655 Vali Loss: 0.1941528 Test Loss: 0.2193734
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.2227146
	speed: 0.3073s/iter; left time: 657.9930s
Epoch: 85 cost time: 17.815969467163086
Epoch: 85, Steps: 140 | Train Loss: 0.2255611 Vali Loss: 0.1939138 Test Loss: 0.2193718
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.2285468
	speed: 0.3011s/iter; left time: 602.4184s
Epoch: 86 cost time: 16.949314832687378
Epoch: 86, Steps: 140 | Train Loss: 0.2254666 Vali Loss: 0.1937138 Test Loss: 0.2193716
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.2250429
	speed: 0.3092s/iter; left time: 575.5003s
Epoch: 87 cost time: 17.12878680229187
Epoch: 87, Steps: 140 | Train Loss: 0.2254117 Vali Loss: 0.1937489 Test Loss: 0.2193694
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.2149646
	speed: 0.3075s/iter; left time: 529.2823s
Epoch: 88 cost time: 17.7503662109375
Epoch: 88, Steps: 140 | Train Loss: 0.2255573 Vali Loss: 0.1936541 Test Loss: 0.2193688
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.2386389
	speed: 0.3171s/iter; left time: 501.3288s
Epoch: 89 cost time: 16.916337966918945
Epoch: 89, Steps: 140 | Train Loss: 0.2255402 Vali Loss: 0.1934022 Test Loss: 0.2193677
Validation loss decreased (0.193527 --> 0.193402).  Saving model ...
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.2221889
	speed: 0.3002s/iter; left time: 432.5334s
Epoch: 90 cost time: 17.369683742523193
Epoch: 90, Steps: 140 | Train Loss: 0.2254102 Vali Loss: 0.1938138 Test Loss: 0.2193661
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.204402478767869e-06
	iters: 100, epoch: 91 | loss: 0.2150751
	speed: 0.3030s/iter; left time: 394.1984s
Epoch: 91 cost time: 17.01196265220642
Epoch: 91, Steps: 140 | Train Loss: 0.2254768 Vali Loss: 0.1941490 Test Loss: 0.2193648
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.944182354829475e-06
	iters: 100, epoch: 92 | loss: 0.2281351
	speed: 0.3087s/iter; left time: 358.3922s
Epoch: 92 cost time: 17.067869663238525
Epoch: 92, Steps: 140 | Train Loss: 0.2255139 Vali Loss: 0.1935695 Test Loss: 0.2193642
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.696973237088e-06
	iters: 100, epoch: 93 | loss: 0.2255145
	speed: 0.3035s/iter; left time: 309.8669s
Epoch: 93 cost time: 17.77377486228943
Epoch: 93, Steps: 140 | Train Loss: 0.2254817 Vali Loss: 0.1937920 Test Loss: 0.2193636
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.462124575233601e-06
	iters: 100, epoch: 94 | loss: 0.2280560
	speed: 0.3124s/iter; left time: 275.1847s
Epoch: 94 cost time: 17.05073857307434
Epoch: 94, Steps: 140 | Train Loss: 0.2255123 Vali Loss: 0.1937966 Test Loss: 0.2193632
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.239018346471921e-06
	iters: 100, epoch: 95 | loss: 0.2302859
	speed: 0.3103s/iter; left time: 229.8983s
Epoch: 95 cost time: 17.555328845977783
Epoch: 95, Steps: 140 | Train Loss: 0.2254078 Vali Loss: 0.1936770 Test Loss: 0.2193625
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.027067429148324e-06
	iters: 100, epoch: 96 | loss: 0.2109158
	speed: 0.2981s/iter; left time: 179.1585s
Epoch: 96 cost time: 17.090778827667236
Epoch: 96, Steps: 140 | Train Loss: 0.2254584 Vali Loss: 0.1941391 Test Loss: 0.2193610
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.825714057690908e-06
	iters: 100, epoch: 97 | loss: 0.2285905
	speed: 0.3054s/iter; left time: 140.7895s
Epoch: 97 cost time: 17.050955533981323
Epoch: 97, Steps: 140 | Train Loss: 0.2255027 Vali Loss: 0.1935970 Test Loss: 0.2193605
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.6344283548063623e-06
	iters: 100, epoch: 98 | loss: 0.2312231
	speed: 0.3091s/iter; left time: 99.2302s
Epoch: 98 cost time: 17.723369598388672
Epoch: 98, Steps: 140 | Train Loss: 0.2254992 Vali Loss: 0.1939736 Test Loss: 0.2193601
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.452706937066044e-06
	iters: 100, epoch: 99 | loss: 0.2194571
	speed: 0.3053s/iter; left time: 55.2654s
Epoch: 99 cost time: 16.722486972808838
Epoch: 99, Steps: 140 | Train Loss: 0.2254657 Vali Loss: 0.1938010 Test Loss: 0.2193594
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.2800715902127414e-06
	iters: 100, epoch: 100 | loss: 0.2218702
	speed: 0.3048s/iter; left time: 12.4985s
Epoch: 100 cost time: 17.36120891571045
Epoch: 100, Steps: 140 | Train Loss: 0.2255061 Vali Loss: 0.1935576 Test Loss: 0.2193592
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.1160680107021042e-06
>>>>>>>testing : Electricity_90_j336_H8_FITS_custom_ftM_sl90_ll48_pl336_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4925
mse:0.21791018545627594, mae:0.29702869057655334, rse:0.46460089087486267, corr:[0.4549313  0.45478043 0.4527591  0.451896   0.45077604 0.4502857
 0.45023403 0.44952202 0.4487499  0.4476557  0.44718096 0.4465206
 0.44635287 0.44567505 0.4455662  0.4450324  0.44502667 0.44520816
 0.44523638 0.44527462 0.44516242 0.44521105 0.44513804 0.44405577
 0.44208857 0.44033396 0.43934453 0.4383113  0.43777815 0.43803835
 0.43876007 0.43909132 0.43850467 0.4381713  0.4377988  0.437521
 0.4374176  0.43718895 0.43709245 0.4367867  0.436803   0.43679258
 0.43697852 0.4370285  0.43712652 0.4373463  0.43734944 0.43709934
 0.43601283 0.43555048 0.43556798 0.4357732  0.436692   0.43821383
 0.44035897 0.44179812 0.44169325 0.44171634 0.44145903 0.4413315
 0.4411185  0.4409685  0.4410149  0.4410696  0.4412329  0.44138896
 0.44179198 0.44184202 0.44230285 0.44265816 0.44320986 0.4434541
 0.44354168 0.44402316 0.44466358 0.4458287  0.4477618  0.4502459
 0.45361072 0.45594823 0.45597035 0.45573848 0.45530203 0.45496863
 0.4546385  0.45446548 0.45449558 0.4545972  0.4548453  0.45508167
 0.4553789  0.45549524 0.45565212 0.4557941  0.45595568 0.45603237
 0.45575634 0.45574287 0.45561647 0.4556075  0.4556151  0.45572448
 0.45617118 0.45620945 0.45585567 0.45544112 0.45513925 0.45487452
 0.4547265  0.4546354  0.4546899  0.45476836 0.45493782 0.45512253
 0.45529288 0.45535544 0.45535254 0.45546368 0.4555769  0.45564947
 0.45551834 0.45547867 0.4554154  0.45540667 0.45538253 0.45540047
 0.4555948  0.45546192 0.45520982 0.45488706 0.45468876 0.45440164
 0.45438167 0.4543174  0.4544541  0.45454463 0.45478186 0.45504367
 0.45524967 0.45534396 0.4553143  0.45541185 0.45544964 0.45529333
 0.45494834 0.45473337 0.45465353 0.45460007 0.4546645  0.45473033
 0.45497718 0.45491636 0.45458174 0.45420513 0.453916   0.4536177
 0.45361218 0.45361695 0.4538276  0.45396972 0.45431894 0.45465857
 0.45495284 0.45499715 0.45482638 0.45437706 0.45384467 0.451458
 0.44845885 0.44609758 0.4443788  0.44290766 0.44194567 0.44137546
 0.44116646 0.44110265 0.44029033 0.43993998 0.43952382 0.43933603
 0.43919158 0.43897933 0.43890136 0.43860137 0.43851417 0.4384413
 0.43835056 0.4381765  0.43796253 0.43761843 0.43722165 0.43554318
 0.43329936 0.43173224 0.43063942 0.4297456  0.4294885  0.42980167
 0.4307521  0.43137076 0.43100998 0.43091542 0.43071407 0.43068004
 0.43065086 0.43064684 0.4306062  0.43040866 0.43039295 0.43031597
 0.4304124  0.430304   0.43033716 0.43034637 0.43033662 0.42973235
 0.42874804 0.4283427  0.4282784  0.42861235 0.4295691  0.4311318
 0.43343    0.43512267 0.43521595 0.4353864  0.43528664 0.43525785
 0.4351329  0.4350872  0.43512794 0.43519238 0.43531334 0.43543592
 0.43573347 0.43578586 0.43615696 0.4363955  0.4369876  0.43705806
 0.43721426 0.43774298 0.43843764 0.43964386 0.44153506 0.44403875
 0.4474599  0.45000982 0.45021918 0.45013046 0.4498744  0.44965062
 0.4494358  0.4493339  0.44936678 0.44945303 0.44960532 0.44977903
 0.449988   0.45006254 0.45019653 0.4502904  0.45048523 0.45043826
 0.45020136 0.45013094 0.45000488 0.45003775 0.4500385  0.45026076
 0.45072496 0.45089674 0.45061743 0.4502635  0.45008504 0.4498097
 0.44974723 0.44962317 0.449676   0.44969115 0.4497697  0.44991112
 0.45000172 0.44999844 0.4499372  0.45001617 0.45014808 0.45011637
 0.45000765 0.44987848 0.44988754 0.44982806 0.44984412 0.4499652
 0.45015964 0.45019844 0.44994056 0.4497543  0.44961536 0.4494087
 0.44945908 0.44938514 0.4495392  0.44949272 0.44966072 0.44977316
 0.44986877 0.4498526  0.44973525 0.44984588 0.44978502 0.44958368
 0.44918606 0.44892523 0.4489223  0.4487373  0.44897047 0.44902563
 0.44941604 0.44960734 0.4493645  0.44939026 0.44914308 0.44925743
 0.4491365  0.4493158  0.44919163 0.4492225  0.4492599  0.44924825
 0.44927683 0.44886065 0.44884178 0.4484075  0.44833982 0.44856513]
