Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_90_j192_H4', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_90_j192_H4_FITS_custom_ftM_sl90_ll48_pl192_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18131
val 2441
test 5069
Model(
  (freq_upsampler): Linear(in_features=26, out_features=81, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  86531328.0
params:  2187.0
Trainable parameters:  2187
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.7609595
	speed: 0.1194s/iter; left time: 1672.1582s
Epoch: 1 cost time: 17.057312726974487
Epoch: 1, Steps: 141 | Train Loss: 1.0090307 Vali Loss: 0.5125023 Test Loss: 0.5801635
Validation loss decreased (inf --> 0.512502).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3914282
	speed: 0.2685s/iter; left time: 3721.4121s
Epoch: 2 cost time: 15.136656045913696
Epoch: 2, Steps: 141 | Train Loss: 0.4507768 Vali Loss: 0.3065007 Test Loss: 0.3489012
Validation loss decreased (0.512502 --> 0.306501).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2917296
	speed: 0.2678s/iter; left time: 3673.4168s
Epoch: 3 cost time: 15.721239805221558
Epoch: 3, Steps: 141 | Train Loss: 0.3093768 Vali Loss: 0.2439288 Test Loss: 0.2775203
Validation loss decreased (0.306501 --> 0.243929).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2620551
	speed: 0.2499s/iter; left time: 3392.8496s
Epoch: 4 cost time: 13.524529218673706
Epoch: 4, Steps: 141 | Train Loss: 0.2635107 Vali Loss: 0.2214900 Test Loss: 0.2519937
Validation loss decreased (0.243929 --> 0.221490).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2396010
	speed: 0.2117s/iter; left time: 2845.0990s
Epoch: 5 cost time: 11.31780743598938
Epoch: 5, Steps: 141 | Train Loss: 0.2456092 Vali Loss: 0.2114280 Test Loss: 0.2405736
Validation loss decreased (0.221490 --> 0.211428).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2433329
	speed: 0.1810s/iter; left time: 2406.7199s
Epoch: 6 cost time: 11.1130690574646
Epoch: 6, Steps: 141 | Train Loss: 0.2366865 Vali Loss: 0.2054646 Test Loss: 0.2340942
Validation loss decreased (0.211428 --> 0.205465).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2333571
	speed: 0.2118s/iter; left time: 2786.4071s
Epoch: 7 cost time: 15.650598049163818
Epoch: 7, Steps: 141 | Train Loss: 0.2311680 Vali Loss: 0.2016203 Test Loss: 0.2298396
Validation loss decreased (0.205465 --> 0.201620).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2313504
	speed: 0.2594s/iter; left time: 3375.5992s
Epoch: 8 cost time: 14.743961811065674
Epoch: 8, Steps: 141 | Train Loss: 0.2273921 Vali Loss: 0.1987139 Test Loss: 0.2267615
Validation loss decreased (0.201620 --> 0.198714).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2275993
	speed: 0.2589s/iter; left time: 3333.2906s
Epoch: 9 cost time: 16.12588906288147
Epoch: 9, Steps: 141 | Train Loss: 0.2246376 Vali Loss: 0.1964962 Test Loss: 0.2244308
Validation loss decreased (0.198714 --> 0.196496).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2171578
	speed: 0.2533s/iter; left time: 3224.7082s
Epoch: 10 cost time: 14.668124914169312
Epoch: 10, Steps: 141 | Train Loss: 0.2224851 Vali Loss: 0.1947719 Test Loss: 0.2226001
Validation loss decreased (0.196496 --> 0.194772).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2180635
	speed: 0.2612s/iter; left time: 3289.1337s
Epoch: 11 cost time: 15.358734607696533
Epoch: 11, Steps: 141 | Train Loss: 0.2207195 Vali Loss: 0.1933393 Test Loss: 0.2211288
Validation loss decreased (0.194772 --> 0.193339).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2260789
	speed: 0.2455s/iter; left time: 3056.2898s
Epoch: 12 cost time: 14.568455934524536
Epoch: 12, Steps: 141 | Train Loss: 0.2192131 Vali Loss: 0.1922645 Test Loss: 0.2199084
Validation loss decreased (0.193339 --> 0.192264).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2243268
	speed: 0.2636s/iter; left time: 3245.0659s
Epoch: 13 cost time: 14.954026222229004
Epoch: 13, Steps: 141 | Train Loss: 0.2180875 Vali Loss: 0.1913227 Test Loss: 0.2188843
Validation loss decreased (0.192264 --> 0.191323).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2086255
	speed: 0.2478s/iter; left time: 3015.7170s
Epoch: 14 cost time: 14.768804788589478
Epoch: 14, Steps: 141 | Train Loss: 0.2171105 Vali Loss: 0.1904203 Test Loss: 0.2180115
Validation loss decreased (0.191323 --> 0.190420).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2172572
	speed: 0.2690s/iter; left time: 3235.6698s
Epoch: 15 cost time: 15.113202333450317
Epoch: 15, Steps: 141 | Train Loss: 0.2162319 Vali Loss: 0.1897663 Test Loss: 0.2172653
Validation loss decreased (0.190420 --> 0.189766).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2094268
	speed: 0.2356s/iter; left time: 2800.0747s
Epoch: 16 cost time: 14.449618339538574
Epoch: 16, Steps: 141 | Train Loss: 0.2154956 Vali Loss: 0.1891760 Test Loss: 0.2166084
Validation loss decreased (0.189766 --> 0.189176).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2229154
	speed: 0.2589s/iter; left time: 3040.5135s
Epoch: 17 cost time: 14.587148427963257
Epoch: 17, Steps: 141 | Train Loss: 0.2149044 Vali Loss: 0.1886038 Test Loss: 0.2160360
Validation loss decreased (0.189176 --> 0.188604).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2151626
	speed: 0.2520s/iter; left time: 2924.7314s
Epoch: 18 cost time: 14.965123414993286
Epoch: 18, Steps: 141 | Train Loss: 0.2142397 Vali Loss: 0.1882146 Test Loss: 0.2155263
Validation loss decreased (0.188604 --> 0.188215).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2221800
	speed: 0.2606s/iter; left time: 2986.7079s
Epoch: 19 cost time: 15.115440368652344
Epoch: 19, Steps: 141 | Train Loss: 0.2137567 Vali Loss: 0.1877283 Test Loss: 0.2150751
Validation loss decreased (0.188215 --> 0.187728).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2110935
	speed: 0.2550s/iter; left time: 2887.0314s
Epoch: 20 cost time: 15.790802001953125
Epoch: 20, Steps: 141 | Train Loss: 0.2133153 Vali Loss: 0.1873355 Test Loss: 0.2146774
Validation loss decreased (0.187728 --> 0.187336).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2185962
	speed: 0.2601s/iter; left time: 2908.1777s
Epoch: 21 cost time: 14.7925443649292
Epoch: 21, Steps: 141 | Train Loss: 0.2128471 Vali Loss: 0.1869882 Test Loss: 0.2143294
Validation loss decreased (0.187336 --> 0.186988).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2099394
	speed: 0.2455s/iter; left time: 2709.9107s
Epoch: 22 cost time: 15.508414506912231
Epoch: 22, Steps: 141 | Train Loss: 0.2125607 Vali Loss: 0.1867341 Test Loss: 0.2140096
Validation loss decreased (0.186988 --> 0.186734).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2062752
	speed: 0.2539s/iter; left time: 2767.3214s
Epoch: 23 cost time: 14.51091456413269
Epoch: 23, Steps: 141 | Train Loss: 0.2122181 Vali Loss: 0.1864175 Test Loss: 0.2137222
Validation loss decreased (0.186734 --> 0.186417).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2262094
	speed: 0.2541s/iter; left time: 2733.1176s
Epoch: 24 cost time: 14.989973306655884
Epoch: 24, Steps: 141 | Train Loss: 0.2119416 Vali Loss: 0.1861940 Test Loss: 0.2134737
Validation loss decreased (0.186417 --> 0.186194).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2152741
	speed: 0.2525s/iter; left time: 2680.8525s
Epoch: 25 cost time: 14.499470472335815
Epoch: 25, Steps: 141 | Train Loss: 0.2116720 Vali Loss: 0.1859341 Test Loss: 0.2132436
Validation loss decreased (0.186194 --> 0.185934).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2082833
	speed: 0.2531s/iter; left time: 2651.0900s
Epoch: 26 cost time: 15.247423887252808
Epoch: 26, Steps: 141 | Train Loss: 0.2114450 Vali Loss: 0.1857716 Test Loss: 0.2130351
Validation loss decreased (0.185934 --> 0.185772).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2122148
	speed: 0.2516s/iter; left time: 2600.4383s
Epoch: 27 cost time: 14.221228837966919
Epoch: 27, Steps: 141 | Train Loss: 0.2112139 Vali Loss: 0.1855736 Test Loss: 0.2128538
Validation loss decreased (0.185772 --> 0.185574).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2136137
	speed: 0.2517s/iter; left time: 2565.3539s
Epoch: 28 cost time: 15.025149822235107
Epoch: 28, Steps: 141 | Train Loss: 0.2111009 Vali Loss: 0.1855773 Test Loss: 0.2126853
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2191923
	speed: 0.2472s/iter; left time: 2485.2187s
Epoch: 29 cost time: 13.841989755630493
Epoch: 29, Steps: 141 | Train Loss: 0.2109088 Vali Loss: 0.1852828 Test Loss: 0.2125372
Validation loss decreased (0.185574 --> 0.185283).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2140856
	speed: 0.2500s/iter; left time: 2478.2021s
Epoch: 30 cost time: 14.847818613052368
Epoch: 30, Steps: 141 | Train Loss: 0.2107192 Vali Loss: 0.1853084 Test Loss: 0.2124029
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2124293
	speed: 0.2505s/iter; left time: 2447.3938s
Epoch: 31 cost time: 14.454969644546509
Epoch: 31, Steps: 141 | Train Loss: 0.2106345 Vali Loss: 0.1850932 Test Loss: 0.2122815
Validation loss decreased (0.185283 --> 0.185093).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2107843
	speed: 0.2543s/iter; left time: 2449.2785s
Epoch: 32 cost time: 14.913492441177368
Epoch: 32, Steps: 141 | Train Loss: 0.2105085 Vali Loss: 0.1850530 Test Loss: 0.2121737
Validation loss decreased (0.185093 --> 0.185053).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2013353
	speed: 0.2497s/iter; left time: 2369.5595s
Epoch: 33 cost time: 13.629208087921143
Epoch: 33, Steps: 141 | Train Loss: 0.2103070 Vali Loss: 0.1849707 Test Loss: 0.2120753
Validation loss decreased (0.185053 --> 0.184971).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2106403
	speed: 0.2542s/iter; left time: 2376.1187s
Epoch: 34 cost time: 14.44260835647583
Epoch: 34, Steps: 141 | Train Loss: 0.2101710 Vali Loss: 0.1848912 Test Loss: 0.2119861
Validation loss decreased (0.184971 --> 0.184891).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2023238
	speed: 0.2402s/iter; left time: 2211.4918s
Epoch: 35 cost time: 14.024985551834106
Epoch: 35, Steps: 141 | Train Loss: 0.2101972 Vali Loss: 0.1847517 Test Loss: 0.2119097
Validation loss decreased (0.184891 --> 0.184752).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2104575
	speed: 0.2554s/iter; left time: 2315.1917s
Epoch: 36 cost time: 14.656106233596802
Epoch: 36, Steps: 141 | Train Loss: 0.2101029 Vali Loss: 0.1846857 Test Loss: 0.2118405
Validation loss decreased (0.184752 --> 0.184686).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2233808
	speed: 0.2466s/iter; left time: 2200.4692s
Epoch: 37 cost time: 14.035916328430176
Epoch: 37, Steps: 141 | Train Loss: 0.2100126 Vali Loss: 0.1847060 Test Loss: 0.2117723
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2027204
	speed: 0.2576s/iter; left time: 2262.8081s
Epoch: 38 cost time: 15.277829885482788
Epoch: 38, Steps: 141 | Train Loss: 0.2099404 Vali Loss: 0.1846450 Test Loss: 0.2117180
Validation loss decreased (0.184686 --> 0.184645).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2099070
	speed: 0.2423s/iter; left time: 2094.3816s
Epoch: 39 cost time: 14.350497722625732
Epoch: 39, Steps: 141 | Train Loss: 0.2098397 Vali Loss: 0.1845904 Test Loss: 0.2116662
Validation loss decreased (0.184645 --> 0.184590).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2087874
	speed: 0.2595s/iter; left time: 2206.4271s
Epoch: 40 cost time: 14.484309673309326
Epoch: 40, Steps: 141 | Train Loss: 0.2098658 Vali Loss: 0.1845168 Test Loss: 0.2116210
Validation loss decreased (0.184590 --> 0.184517).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2015736
	speed: 0.2323s/iter; left time: 1942.5780s
Epoch: 41 cost time: 14.069724559783936
Epoch: 41, Steps: 141 | Train Loss: 0.2098541 Vali Loss: 0.1844630 Test Loss: 0.2115813
Validation loss decreased (0.184517 --> 0.184463).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2040183
	speed: 0.2522s/iter; left time: 2073.3495s
Epoch: 42 cost time: 14.152034997940063
Epoch: 42, Steps: 141 | Train Loss: 0.2097525 Vali Loss: 0.1844987 Test Loss: 0.2115467
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2058735
	speed: 0.2438s/iter; left time: 1969.2663s
Epoch: 43 cost time: 14.190480470657349
Epoch: 43, Steps: 141 | Train Loss: 0.2097298 Vali Loss: 0.1843951 Test Loss: 0.2115102
Validation loss decreased (0.184463 --> 0.184395).  Saving model ...
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2121743
	speed: 0.2542s/iter; left time: 2017.5757s
Epoch: 44 cost time: 14.483124732971191
Epoch: 44, Steps: 141 | Train Loss: 0.2096581 Vali Loss: 0.1844746 Test Loss: 0.2114826
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2186757
	speed: 0.2380s/iter; left time: 1855.9168s
Epoch: 45 cost time: 14.179596900939941
Epoch: 45, Steps: 141 | Train Loss: 0.2096774 Vali Loss: 0.1843228 Test Loss: 0.2114542
Validation loss decreased (0.184395 --> 0.184323).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2112465
	speed: 0.2494s/iter; left time: 1909.6510s
Epoch: 46 cost time: 13.673527956008911
Epoch: 46, Steps: 141 | Train Loss: 0.2096150 Vali Loss: 0.1843372 Test Loss: 0.2114319
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2096551
	speed: 0.2353s/iter; left time: 1768.3314s
Epoch: 47 cost time: 14.261372566223145
Epoch: 47, Steps: 141 | Train Loss: 0.2095348 Vali Loss: 0.1843465 Test Loss: 0.2114112
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2036848
	speed: 0.2543s/iter; left time: 1874.8793s
Epoch: 48 cost time: 14.202208757400513
Epoch: 48, Steps: 141 | Train Loss: 0.2095411 Vali Loss: 0.1843567 Test Loss: 0.2113920
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2115939
	speed: 0.2328s/iter; left time: 1683.7221s
Epoch: 49 cost time: 14.134761810302734
Epoch: 49, Steps: 141 | Train Loss: 0.2095600 Vali Loss: 0.1843136 Test Loss: 0.2113738
Validation loss decreased (0.184323 --> 0.184314).  Saving model ...
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2090158
	speed: 0.2468s/iter; left time: 1750.4809s
Epoch: 50 cost time: 13.674349069595337
Epoch: 50, Steps: 141 | Train Loss: 0.2095587 Vali Loss: 0.1842302 Test Loss: 0.2113585
Validation loss decreased (0.184314 --> 0.184230).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1995789
	speed: 0.2358s/iter; left time: 1639.3538s
Epoch: 51 cost time: 14.529277801513672
Epoch: 51, Steps: 141 | Train Loss: 0.2095757 Vali Loss: 0.1842546 Test Loss: 0.2113446
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2096591
	speed: 0.2395s/iter; left time: 1631.0349s
Epoch: 52 cost time: 13.561595678329468
Epoch: 52, Steps: 141 | Train Loss: 0.2095147 Vali Loss: 0.1843211 Test Loss: 0.2113351
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2053342
	speed: 0.2249s/iter; left time: 1499.8386s
Epoch: 53 cost time: 14.17318606376648
Epoch: 53, Steps: 141 | Train Loss: 0.2094920 Vali Loss: 0.1842325 Test Loss: 0.2113244
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2076355
	speed: 0.2430s/iter; left time: 1586.4004s
Epoch: 54 cost time: 13.63037657737732
Epoch: 54, Steps: 141 | Train Loss: 0.2094580 Vali Loss: 0.1842575 Test Loss: 0.2113126
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2065776
	speed: 0.2362s/iter; left time: 1508.4572s
Epoch: 55 cost time: 14.525741338729858
Epoch: 55, Steps: 141 | Train Loss: 0.2094727 Vali Loss: 0.1842657 Test Loss: 0.2113054
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2132820
	speed: 0.2409s/iter; left time: 1504.8413s
Epoch: 56 cost time: 13.645581007003784
Epoch: 56, Steps: 141 | Train Loss: 0.2095016 Vali Loss: 0.1841584 Test Loss: 0.2112961
Validation loss decreased (0.184230 --> 0.184158).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2236764
	speed: 0.2365s/iter; left time: 1443.7708s
Epoch: 57 cost time: 14.806561470031738
Epoch: 57, Steps: 141 | Train Loss: 0.2094750 Vali Loss: 0.1842637 Test Loss: 0.2112891
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2046032
	speed: 0.2371s/iter; left time: 1414.1618s
Epoch: 58 cost time: 13.23430871963501
Epoch: 58, Steps: 141 | Train Loss: 0.2093970 Vali Loss: 0.1842209 Test Loss: 0.2112824
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2075355
	speed: 0.2268s/iter; left time: 1320.8714s
Epoch: 59 cost time: 14.346697092056274
Epoch: 59, Steps: 141 | Train Loss: 0.2094426 Vali Loss: 0.1841642 Test Loss: 0.2112764
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.2054501
	speed: 0.2503s/iter; left time: 1422.1982s
Epoch: 60 cost time: 14.17059850692749
Epoch: 60, Steps: 141 | Train Loss: 0.2094283 Vali Loss: 0.1841967 Test Loss: 0.2112728
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.2137669
	speed: 0.2371s/iter; left time: 1313.7607s
Epoch: 61 cost time: 14.799422979354858
Epoch: 61, Steps: 141 | Train Loss: 0.2094529 Vali Loss: 0.1841941 Test Loss: 0.2112679
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.2059492
	speed: 0.2394s/iter; left time: 1292.8183s
Epoch: 62 cost time: 13.505707502365112
Epoch: 62, Steps: 141 | Train Loss: 0.2093901 Vali Loss: 0.1842311 Test Loss: 0.2112620
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.2093571
	speed: 0.2346s/iter; left time: 1233.8379s
Epoch: 63 cost time: 14.512067794799805
Epoch: 63, Steps: 141 | Train Loss: 0.2094765 Vali Loss: 0.1842235 Test Loss: 0.2112588
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.2125903
	speed: 0.2417s/iter; left time: 1237.0019s
Epoch: 64 cost time: 13.472852945327759
Epoch: 64, Steps: 141 | Train Loss: 0.2093963 Vali Loss: 0.1841816 Test Loss: 0.2112547
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.2081970
	speed: 0.2351s/iter; left time: 1170.1408s
Epoch: 65 cost time: 13.974756717681885
Epoch: 65, Steps: 141 | Train Loss: 0.2094555 Vali Loss: 0.1842470 Test Loss: 0.2112515
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.2121466
	speed: 0.2455s/iter; left time: 1187.4407s
Epoch: 66 cost time: 14.233883142471313
Epoch: 66, Steps: 141 | Train Loss: 0.2094126 Vali Loss: 0.1842090 Test Loss: 0.2112489
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.2045444
	speed: 0.2426s/iter; left time: 1139.0688s
Epoch: 67 cost time: 14.302508354187012
Epoch: 67, Steps: 141 | Train Loss: 0.2094400 Vali Loss: 0.1842348 Test Loss: 0.2112458
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.2061833
	speed: 0.2421s/iter; left time: 1102.4872s
Epoch: 68 cost time: 13.855777263641357
Epoch: 68, Steps: 141 | Train Loss: 0.2094618 Vali Loss: 0.1842469 Test Loss: 0.2112439
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.2139872
	speed: 0.2405s/iter; left time: 1061.3889s
Epoch: 69 cost time: 14.453284978866577
Epoch: 69, Steps: 141 | Train Loss: 0.2094302 Vali Loss: 0.1841803 Test Loss: 0.2112422
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.2017450
	speed: 0.2380s/iter; left time: 1016.6684s
Epoch: 70 cost time: 12.913123846054077
Epoch: 70, Steps: 141 | Train Loss: 0.2093840 Vali Loss: 0.1842225 Test Loss: 0.2112397
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.1982496
	speed: 0.2364s/iter; left time: 976.6918s
Epoch: 71 cost time: 14.436324834823608
Epoch: 71, Steps: 141 | Train Loss: 0.2094386 Vali Loss: 0.1841222 Test Loss: 0.2112381
Validation loss decreased (0.184158 --> 0.184122).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.2119577
	speed: 0.2495s/iter; left time: 995.6906s
Epoch: 72 cost time: 13.764893531799316
Epoch: 72, Steps: 141 | Train Loss: 0.2094054 Vali Loss: 0.1841844 Test Loss: 0.2112362
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.2142458
	speed: 0.2382s/iter; left time: 916.8647s
Epoch: 73 cost time: 14.179576396942139
Epoch: 73, Steps: 141 | Train Loss: 0.2094345 Vali Loss: 0.1841893 Test Loss: 0.2112338
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.2178895
	speed: 0.2394s/iter; left time: 887.8274s
Epoch: 74 cost time: 13.343790292739868
Epoch: 74, Steps: 141 | Train Loss: 0.2093749 Vali Loss: 0.1841640 Test Loss: 0.2112324
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.1996902
	speed: 0.2390s/iter; left time: 852.4907s
Epoch: 75 cost time: 14.263129949569702
Epoch: 75, Steps: 141 | Train Loss: 0.2093522 Vali Loss: 0.1841755 Test Loss: 0.2112316
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.2160373
	speed: 0.2354s/iter; left time: 806.5670s
Epoch: 76 cost time: 13.041884183883667
Epoch: 76, Steps: 141 | Train Loss: 0.2093686 Vali Loss: 0.1841514 Test Loss: 0.2112304
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.2111655
	speed: 0.2336s/iter; left time: 767.2443s
Epoch: 77 cost time: 14.127204656600952
Epoch: 77, Steps: 141 | Train Loss: 0.2093975 Vali Loss: 0.1842211 Test Loss: 0.2112293
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.2167750
	speed: 0.2339s/iter; left time: 735.3374s
Epoch: 78 cost time: 13.027666568756104
Epoch: 78, Steps: 141 | Train Loss: 0.2093916 Vali Loss: 0.1842519 Test Loss: 0.2112279
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.2200150
	speed: 0.2327s/iter; left time: 698.8855s
Epoch: 79 cost time: 13.919749021530151
Epoch: 79, Steps: 141 | Train Loss: 0.2093073 Vali Loss: 0.1841463 Test Loss: 0.2112266
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.2131617
	speed: 0.2331s/iter; left time: 667.1850s
Epoch: 80 cost time: 13.564021110534668
Epoch: 80, Steps: 141 | Train Loss: 0.2093314 Vali Loss: 0.1842096 Test Loss: 0.2112257
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.2092694
	speed: 0.2411s/iter; left time: 656.1468s
Epoch: 81 cost time: 14.314364910125732
Epoch: 81, Steps: 141 | Train Loss: 0.2093620 Vali Loss: 0.1842177 Test Loss: 0.2112250
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.2135415
	speed: 0.2386s/iter; left time: 615.4760s
Epoch: 82 cost time: 13.611016035079956
Epoch: 82, Steps: 141 | Train Loss: 0.2093784 Vali Loss: 0.1841357 Test Loss: 0.2112240
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.2177477
	speed: 0.2437s/iter; left time: 594.3868s
Epoch: 83 cost time: 14.139963865280151
Epoch: 83, Steps: 141 | Train Loss: 0.2093595 Vali Loss: 0.1841484 Test Loss: 0.2112233
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.2228212
	speed: 0.2385s/iter; left time: 548.1387s
Epoch: 84 cost time: 13.013187170028687
Epoch: 84, Steps: 141 | Train Loss: 0.2093829 Vali Loss: 0.1842052 Test Loss: 0.2112228
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.2102681
	speed: 0.2466s/iter; left time: 531.9103s
Epoch: 85 cost time: 14.231033086776733
Epoch: 85, Steps: 141 | Train Loss: 0.2093932 Vali Loss: 0.1841466 Test Loss: 0.2112223
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.2022441
	speed: 0.2289s/iter; left time: 461.4613s
Epoch: 86 cost time: 13.120038509368896
Epoch: 86, Steps: 141 | Train Loss: 0.2093780 Vali Loss: 0.1840814 Test Loss: 0.2112214
Validation loss decreased (0.184122 --> 0.184081).  Saving model ...
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.2073832
	speed: 0.2462s/iter; left time: 461.6425s
Epoch: 87 cost time: 14.033313512802124
Epoch: 87, Steps: 141 | Train Loss: 0.2094019 Vali Loss: 0.1842378 Test Loss: 0.2112208
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.2135372
	speed: 0.2303s/iter; left time: 399.3923s
Epoch: 88 cost time: 13.593794822692871
Epoch: 88, Steps: 141 | Train Loss: 0.2093015 Vali Loss: 0.1842046 Test Loss: 0.2112203
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.2068778
	speed: 0.2479s/iter; left time: 394.9082s
Epoch: 89 cost time: 14.799349308013916
Epoch: 89, Steps: 141 | Train Loss: 0.2093781 Vali Loss: 0.1841780 Test Loss: 0.2112197
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.2093715
	speed: 0.2377s/iter; left time: 345.1026s
Epoch: 90 cost time: 13.850757360458374
Epoch: 90, Steps: 141 | Train Loss: 0.2094095 Vali Loss: 0.1841581 Test Loss: 0.2112193
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.204402478767869e-06
	iters: 100, epoch: 91 | loss: 0.2183041
	speed: 0.2474s/iter; left time: 324.3802s
Epoch: 91 cost time: 14.245081901550293
Epoch: 91, Steps: 141 | Train Loss: 0.2093697 Vali Loss: 0.1841764 Test Loss: 0.2112190
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.944182354829475e-06
	iters: 100, epoch: 92 | loss: 0.2165942
	speed: 0.2279s/iter; left time: 266.6889s
Epoch: 92 cost time: 13.494935035705566
Epoch: 92, Steps: 141 | Train Loss: 0.2093907 Vali Loss: 0.1841833 Test Loss: 0.2112183
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.696973237088e-06
	iters: 100, epoch: 93 | loss: 0.1946469
	speed: 0.2457s/iter; left time: 252.8038s
Epoch: 93 cost time: 14.225363969802856
Epoch: 93, Steps: 141 | Train Loss: 0.2093870 Vali Loss: 0.1841381 Test Loss: 0.2112180
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.462124575233601e-06
	iters: 100, epoch: 94 | loss: 0.2101687
	speed: 0.2380s/iter; left time: 211.3167s
Epoch: 94 cost time: 13.904762744903564
Epoch: 94, Steps: 141 | Train Loss: 0.2094230 Vali Loss: 0.1842679 Test Loss: 0.2112175
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.239018346471921e-06
	iters: 100, epoch: 95 | loss: 0.2036695
	speed: 0.2380s/iter; left time: 177.7631s
Epoch: 95 cost time: 13.897647619247437
Epoch: 95, Steps: 141 | Train Loss: 0.2093569 Vali Loss: 0.1841331 Test Loss: 0.2112172
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.027067429148324e-06
	iters: 100, epoch: 96 | loss: 0.2069472
	speed: 0.2306s/iter; left time: 139.7542s
Epoch: 96 cost time: 13.580450296401978
Epoch: 96, Steps: 141 | Train Loss: 0.2093632 Vali Loss: 0.1841212 Test Loss: 0.2112169
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.825714057690908e-06
	iters: 100, epoch: 97 | loss: 0.2067319
	speed: 0.2433s/iter; left time: 113.1159s
Epoch: 97 cost time: 14.058083057403564
Epoch: 97, Steps: 141 | Train Loss: 0.2092878 Vali Loss: 0.1841615 Test Loss: 0.2112166
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.6344283548063623e-06
	iters: 100, epoch: 98 | loss: 0.2180565
	speed: 0.2332s/iter; left time: 75.5469s
Epoch: 98 cost time: 13.779559135437012
Epoch: 98, Steps: 141 | Train Loss: 0.2093653 Vali Loss: 0.1841073 Test Loss: 0.2112161
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.452706937066044e-06
	iters: 100, epoch: 99 | loss: 0.2140741
	speed: 0.2432s/iter; left time: 44.5063s
Epoch: 99 cost time: 13.955085277557373
Epoch: 99, Steps: 141 | Train Loss: 0.2093619 Vali Loss: 0.1842006 Test Loss: 0.2112159
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.2800715902127414e-06
	iters: 100, epoch: 100 | loss: 0.2011815
	speed: 0.2299s/iter; left time: 9.6550s
Epoch: 100 cost time: 13.809974193572998
Epoch: 100, Steps: 141 | Train Loss: 0.2093808 Vali Loss: 0.1841422 Test Loss: 0.2112158
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.1160680107021042e-06
>>>>>>>testing : Electricity_90_j192_H4_FITS_custom_ftM_sl90_ll48_pl192_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5069
mse:0.20888268947601318, mae:0.2915295660495758, rse:0.4544159770011902, corr:[0.45919433 0.45719248 0.45684665 0.45599714 0.45467082 0.45386833
 0.4542794  0.45295605 0.45156878 0.450984   0.45022556 0.449315
 0.44919127 0.44909036 0.4484954  0.44822192 0.44855267 0.44880816
 0.4487469  0.44860852 0.4486466  0.4487076  0.44840938 0.44715908
 0.44472918 0.4435715  0.4425489  0.441295   0.44069222 0.4408782
 0.44187865 0.44183218 0.4415537  0.44122034 0.440762   0.44029582
 0.44028085 0.4402733  0.43980095 0.43947622 0.43963486 0.43965137
 0.43938726 0.4394201  0.43966696 0.4397724  0.43964624 0.43924433
 0.4380428  0.43776977 0.43782297 0.43796313 0.43868247 0.44018123
 0.44250536 0.4439587  0.4445433  0.44441733 0.44424084 0.44402784
 0.44386244 0.44383615 0.44376245 0.4437463  0.44404837 0.4443437
 0.4444012  0.4445534  0.44492108 0.4452627  0.4455791  0.44594035
 0.4459696  0.44661394 0.44740447 0.4484822  0.45016173 0.45272517
 0.4560685  0.45860866 0.45960957 0.45917255 0.45869038 0.4583929
 0.45802996 0.45781347 0.45777056 0.45779288 0.4580812  0.45838565
 0.45847133 0.45850992 0.45853046 0.45859367 0.45873538 0.4587327
 0.45835313 0.45835063 0.4584284  0.4583612  0.45826566 0.45848402
 0.4590097  0.45902783 0.45889094 0.4585468  0.45812735 0.45790094
 0.4577527  0.45765144 0.45766482 0.4576578  0.45780918 0.4580502
 0.45814514 0.45826137 0.45838583 0.45846626 0.45862997 0.45875236
 0.45845228 0.45843247 0.45851478 0.45850486 0.45836198 0.45841533
 0.4588038  0.45866126 0.4584544  0.4582986  0.4579483  0.45771763
 0.45767865 0.45765734 0.4577403  0.45781144 0.45794922 0.45827252
 0.45844656 0.4584212  0.45842493 0.45845878 0.458473   0.45837077
 0.45791152 0.45777443 0.4577952  0.45781025 0.4577173  0.45777038
 0.4582709  0.45829153 0.45802578 0.4578055  0.45749462 0.4572164
 0.4571794  0.45723307 0.45739836 0.45759276 0.45778838 0.4582376
 0.45851153 0.45823103 0.45792505 0.4576378  0.45651954 0.4540853
 0.45108372 0.44905514 0.44751358 0.44613242 0.44514757 0.44449145
 0.44460386 0.4444877  0.44425943 0.44400162 0.44375315 0.4434281
 0.44330937 0.44312492 0.4425699  0.44202626 0.4419108  0.44192785
 0.44146377 0.4408281  0.44080862 0.44082642 0.44057003 0.4411876 ]
