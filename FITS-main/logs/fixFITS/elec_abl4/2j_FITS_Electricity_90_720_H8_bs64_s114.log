Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=42, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_90_j720_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_90_j720_H8_FITS_custom_ftM_sl90_ll48_pl720_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17603
val 1913
test 4541
Model(
  (freq_upsampler): Linear(in_features=42, out_features=378, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  652313088.0
params:  16254.0
Trainable parameters:  16254
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 1.0988041
	speed: 0.1863s/iter; left time: 2534.4125s
Epoch: 1 cost time: 25.1012442111969
Epoch: 1, Steps: 137 | Train Loss: 1.5800477 Vali Loss: 0.7779698 Test Loss: 0.8591877
Validation loss decreased (inf --> 0.777970).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5918243
	speed: 0.4597s/iter; left time: 6188.8842s
Epoch: 2 cost time: 25.797927618026733
Epoch: 2, Steps: 137 | Train Loss: 0.6707483 Vali Loss: 0.4829353 Test Loss: 0.5439079
Validation loss decreased (0.777970 --> 0.482935).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4237214
	speed: 0.4527s/iter; left time: 6033.4592s
Epoch: 3 cost time: 23.450591802597046
Epoch: 3, Steps: 137 | Train Loss: 0.4689757 Vali Loss: 0.3766538 Test Loss: 0.4279099
Validation loss decreased (0.482935 --> 0.376654).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3621487
	speed: 0.4225s/iter; left time: 5572.5702s
Epoch: 4 cost time: 24.432404041290283
Epoch: 4, Steps: 137 | Train Loss: 0.3829650 Vali Loss: 0.3244366 Test Loss: 0.3693693
Validation loss decreased (0.376654 --> 0.324437).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3317102
	speed: 0.4568s/iter; left time: 5962.8865s
Epoch: 5 cost time: 25.470349311828613
Epoch: 5, Steps: 137 | Train Loss: 0.3369353 Vali Loss: 0.2949773 Test Loss: 0.3357804
Validation loss decreased (0.324437 --> 0.294977).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2961281
	speed: 0.4583s/iter; left time: 5919.8310s
Epoch: 6 cost time: 25.798155784606934
Epoch: 6, Steps: 137 | Train Loss: 0.3098743 Vali Loss: 0.2771635 Test Loss: 0.3152946
Validation loss decreased (0.294977 --> 0.277163).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2887042
	speed: 0.4839s/iter; left time: 6183.8481s
Epoch: 7 cost time: 25.479597091674805
Epoch: 7, Steps: 137 | Train Loss: 0.2929088 Vali Loss: 0.2654480 Test Loss: 0.3020218
Validation loss decreased (0.277163 --> 0.265448).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2686124
	speed: 0.4542s/iter; left time: 5741.9149s
Epoch: 8 cost time: 25.28395652770996
Epoch: 8, Steps: 137 | Train Loss: 0.2817571 Vali Loss: 0.2576768 Test Loss: 0.2929988
Validation loss decreased (0.265448 --> 0.257677).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2799725
	speed: 0.4677s/iter; left time: 5848.3481s
Epoch: 9 cost time: 25.290238857269287
Epoch: 9, Steps: 137 | Train Loss: 0.2742062 Vali Loss: 0.2521439 Test Loss: 0.2866912
Validation loss decreased (0.257677 --> 0.252144).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2817520
	speed: 0.4621s/iter; left time: 5715.3524s
Epoch: 10 cost time: 25.143887758255005
Epoch: 10, Steps: 137 | Train Loss: 0.2687569 Vali Loss: 0.2482504 Test Loss: 0.2820723
Validation loss decreased (0.252144 --> 0.248250).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2669952
	speed: 0.4549s/iter; left time: 5564.2705s
Epoch: 11 cost time: 25.0658175945282
Epoch: 11, Steps: 137 | Train Loss: 0.2647307 Vali Loss: 0.2451375 Test Loss: 0.2786534
Validation loss decreased (0.248250 --> 0.245138).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2492193
	speed: 0.4642s/iter; left time: 5614.0521s
Epoch: 12 cost time: 25.171141624450684
Epoch: 12, Steps: 137 | Train Loss: 0.2616735 Vali Loss: 0.2427042 Test Loss: 0.2760076
Validation loss decreased (0.245138 --> 0.242704).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2476567
	speed: 0.4668s/iter; left time: 5581.6604s
Epoch: 13 cost time: 25.20284914970398
Epoch: 13, Steps: 137 | Train Loss: 0.2592178 Vali Loss: 0.2408893 Test Loss: 0.2739489
Validation loss decreased (0.242704 --> 0.240889).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2523248
	speed: 0.4592s/iter; left time: 5427.6066s
Epoch: 14 cost time: 25.30225443840027
Epoch: 14, Steps: 137 | Train Loss: 0.2574268 Vali Loss: 0.2396338 Test Loss: 0.2722768
Validation loss decreased (0.240889 --> 0.239634).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2533951
	speed: 0.4622s/iter; left time: 5399.3613s
Epoch: 15 cost time: 25.75018835067749
Epoch: 15, Steps: 137 | Train Loss: 0.2558765 Vali Loss: 0.2386849 Test Loss: 0.2709299
Validation loss decreased (0.239634 --> 0.238685).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2706136
	speed: 0.4586s/iter; left time: 5294.6171s
Epoch: 16 cost time: 26.072263717651367
Epoch: 16, Steps: 137 | Train Loss: 0.2546460 Vali Loss: 0.2374605 Test Loss: 0.2698304
Validation loss decreased (0.238685 --> 0.237461).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2550184
	speed: 0.4674s/iter; left time: 5332.7774s
Epoch: 17 cost time: 26.14970588684082
Epoch: 17, Steps: 137 | Train Loss: 0.2535995 Vali Loss: 0.2369200 Test Loss: 0.2689152
Validation loss decreased (0.237461 --> 0.236920).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2599316
	speed: 0.4635s/iter; left time: 5224.4369s
Epoch: 18 cost time: 25.812639474868774
Epoch: 18, Steps: 137 | Train Loss: 0.2526879 Vali Loss: 0.2359898 Test Loss: 0.2680886
Validation loss decreased (0.236920 --> 0.235990).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2530760
	speed: 0.4607s/iter; left time: 5130.2437s
Epoch: 19 cost time: 25.904298305511475
Epoch: 19, Steps: 137 | Train Loss: 0.2519562 Vali Loss: 0.2349801 Test Loss: 0.2674279
Validation loss decreased (0.235990 --> 0.234980).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2452667
	speed: 0.4679s/iter; left time: 5145.4668s
Epoch: 20 cost time: 25.860957860946655
Epoch: 20, Steps: 137 | Train Loss: 0.2513568 Vali Loss: 0.2354030 Test Loss: 0.2668832
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2442810
	speed: 0.4477s/iter; left time: 4862.0757s
Epoch: 21 cost time: 25.915400743484497
Epoch: 21, Steps: 137 | Train Loss: 0.2508218 Vali Loss: 0.2343776 Test Loss: 0.2663839
Validation loss decreased (0.234980 --> 0.234378).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2464295
	speed: 0.4643s/iter; left time: 4978.7629s
Epoch: 22 cost time: 26.364069938659668
Epoch: 22, Steps: 137 | Train Loss: 0.2502164 Vali Loss: 0.2337301 Test Loss: 0.2659510
Validation loss decreased (0.234378 --> 0.233730).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2434171
	speed: 0.4635s/iter; left time: 4907.4388s
Epoch: 23 cost time: 26.236138582229614
Epoch: 23, Steps: 137 | Train Loss: 0.2498548 Vali Loss: 0.2338611 Test Loss: 0.2655725
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2515634
	speed: 0.4625s/iter; left time: 4832.9849s
Epoch: 24 cost time: 25.638559818267822
Epoch: 24, Steps: 137 | Train Loss: 0.2494894 Vali Loss: 0.2336619 Test Loss: 0.2652574
Validation loss decreased (0.233730 --> 0.233662).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2440876
	speed: 0.4624s/iter; left time: 4768.9294s
Epoch: 25 cost time: 25.75472331047058
Epoch: 25, Steps: 137 | Train Loss: 0.2491811 Vali Loss: 0.2333467 Test Loss: 0.2649396
Validation loss decreased (0.233662 --> 0.233347).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2588938
	speed: 0.4594s/iter; left time: 4675.3610s
Epoch: 26 cost time: 25.9027419090271
Epoch: 26, Steps: 137 | Train Loss: 0.2488377 Vali Loss: 0.2335746 Test Loss: 0.2646820
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2482800
	speed: 0.4614s/iter; left time: 4632.3005s
Epoch: 27 cost time: 25.582281351089478
Epoch: 27, Steps: 137 | Train Loss: 0.2486283 Vali Loss: 0.2332128 Test Loss: 0.2644500
Validation loss decreased (0.233347 --> 0.233213).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2406779
	speed: 0.4649s/iter; left time: 4603.6266s
Epoch: 28 cost time: 25.655081510543823
Epoch: 28, Steps: 137 | Train Loss: 0.2483315 Vali Loss: 0.2318008 Test Loss: 0.2642502
Validation loss decreased (0.233213 --> 0.231801).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2587143
	speed: 0.4593s/iter; left time: 4485.2089s
Epoch: 29 cost time: 26.209667682647705
Epoch: 29, Steps: 137 | Train Loss: 0.2481607 Vali Loss: 0.2324796 Test Loss: 0.2640492
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2523926
	speed: 0.4625s/iter; left time: 4452.9206s
Epoch: 30 cost time: 25.073487997055054
Epoch: 30, Steps: 137 | Train Loss: 0.2479652 Vali Loss: 0.2324214 Test Loss: 0.2638768
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2379090
	speed: 0.4664s/iter; left time: 4426.2731s
Epoch: 31 cost time: 25.352954864501953
Epoch: 31, Steps: 137 | Train Loss: 0.2478132 Vali Loss: 0.2320454 Test Loss: 0.2637226
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2454144
	speed: 0.4613s/iter; left time: 4315.0658s
Epoch: 32 cost time: 25.017038345336914
Epoch: 32, Steps: 137 | Train Loss: 0.2476682 Vali Loss: 0.2321923 Test Loss: 0.2635801
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2448986
	speed: 0.4603s/iter; left time: 4242.1324s
Epoch: 33 cost time: 25.27344059944153
Epoch: 33, Steps: 137 | Train Loss: 0.2475146 Vali Loss: 0.2319452 Test Loss: 0.2634370
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2499474
	speed: 0.4642s/iter; left time: 4215.3181s
Epoch: 34 cost time: 25.233190536499023
Epoch: 34, Steps: 137 | Train Loss: 0.2473543 Vali Loss: 0.2323075 Test Loss: 0.2633268
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2514688
	speed: 0.4660s/iter; left time: 4167.6135s
Epoch: 35 cost time: 25.3937406539917
Epoch: 35, Steps: 137 | Train Loss: 0.2472525 Vali Loss: 0.2320195 Test Loss: 0.2632299
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2460585
	speed: 0.4626s/iter; left time: 4073.4617s
Epoch: 36 cost time: 25.948707580566406
Epoch: 36, Steps: 137 | Train Loss: 0.2471172 Vali Loss: 0.2316425 Test Loss: 0.2631134
Validation loss decreased (0.231801 --> 0.231642).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2429809
	speed: 0.4663s/iter; left time: 4041.9337s
Epoch: 37 cost time: 25.60369300842285
Epoch: 37, Steps: 137 | Train Loss: 0.2470653 Vali Loss: 0.2315520 Test Loss: 0.2630284
Validation loss decreased (0.231642 --> 0.231552).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2473545
	speed: 0.4608s/iter; left time: 3931.6798s
Epoch: 38 cost time: 25.617426872253418
Epoch: 38, Steps: 137 | Train Loss: 0.2468764 Vali Loss: 0.2319299 Test Loss: 0.2629473
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2465915
	speed: 0.4665s/iter; left time: 3916.1249s
Epoch: 39 cost time: 26.1777925491333
Epoch: 39, Steps: 137 | Train Loss: 0.2468550 Vali Loss: 0.2314410 Test Loss: 0.2628404
Validation loss decreased (0.231552 --> 0.231441).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2539243
	speed: 0.4809s/iter; left time: 3971.6048s
Epoch: 40 cost time: 26.492181062698364
Epoch: 40, Steps: 137 | Train Loss: 0.2467279 Vali Loss: 0.2315546 Test Loss: 0.2627691
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2441656
	speed: 0.4697s/iter; left time: 3814.6077s
Epoch: 41 cost time: 26.2196946144104
Epoch: 41, Steps: 137 | Train Loss: 0.2466451 Vali Loss: 0.2311169 Test Loss: 0.2626987
Validation loss decreased (0.231441 --> 0.231117).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2448041
	speed: 0.4673s/iter; left time: 3731.1953s
Epoch: 42 cost time: 26.339728116989136
Epoch: 42, Steps: 137 | Train Loss: 0.2465640 Vali Loss: 0.2308937 Test Loss: 0.2626368
Validation loss decreased (0.231117 --> 0.230894).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2497098
	speed: 0.4725s/iter; left time: 3707.6352s
Epoch: 43 cost time: 26.843262672424316
Epoch: 43, Steps: 137 | Train Loss: 0.2465620 Vali Loss: 0.2313036 Test Loss: 0.2625772
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2368044
	speed: 0.4681s/iter; left time: 3608.8092s
Epoch: 44 cost time: 25.649303674697876
Epoch: 44, Steps: 137 | Train Loss: 0.2464074 Vali Loss: 0.2310505 Test Loss: 0.2625206
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2553841
	speed: 0.4544s/iter; left time: 3440.8454s
Epoch: 45 cost time: 25.748971462249756
Epoch: 45, Steps: 137 | Train Loss: 0.2464029 Vali Loss: 0.2310469 Test Loss: 0.2624470
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2337499
	speed: 0.4591s/iter; left time: 3413.5194s
Epoch: 46 cost time: 26.021045207977295
Epoch: 46, Steps: 137 | Train Loss: 0.2463293 Vali Loss: 0.2310088 Test Loss: 0.2623996
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2497950
	speed: 0.4597s/iter; left time: 3355.4929s
Epoch: 47 cost time: 25.635245323181152
Epoch: 47, Steps: 137 | Train Loss: 0.2462518 Vali Loss: 0.2307361 Test Loss: 0.2623526
Validation loss decreased (0.230894 --> 0.230736).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2467033
	speed: 0.4641s/iter; left time: 3323.6536s
Epoch: 48 cost time: 25.86310625076294
Epoch: 48, Steps: 137 | Train Loss: 0.2462473 Vali Loss: 0.2308228 Test Loss: 0.2623074
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2440082
	speed: 0.4607s/iter; left time: 3236.2042s
Epoch: 49 cost time: 25.809459924697876
Epoch: 49, Steps: 137 | Train Loss: 0.2461900 Vali Loss: 0.2305426 Test Loss: 0.2622661
Validation loss decreased (0.230736 --> 0.230543).  Saving model ...
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2485440
	speed: 0.4532s/iter; left time: 3121.7957s
Epoch: 50 cost time: 25.11637854576111
Epoch: 50, Steps: 137 | Train Loss: 0.2460568 Vali Loss: 0.2306699 Test Loss: 0.2622212
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2481392
	speed: 0.4564s/iter; left time: 3081.3789s
Epoch: 51 cost time: 25.23210310935974
Epoch: 51, Steps: 137 | Train Loss: 0.2461325 Vali Loss: 0.2311206 Test Loss: 0.2621740
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2401665
	speed: 0.4674s/iter; left time: 3091.1666s
Epoch: 52 cost time: 25.338191270828247
Epoch: 52, Steps: 137 | Train Loss: 0.2460291 Vali Loss: 0.2307805 Test Loss: 0.2621418
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2438069
	speed: 0.4630s/iter; left time: 2999.1137s
Epoch: 53 cost time: 25.101414918899536
Epoch: 53, Steps: 137 | Train Loss: 0.2459792 Vali Loss: 0.2311219 Test Loss: 0.2621190
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2588759
	speed: 0.4611s/iter; left time: 2923.5022s
Epoch: 54 cost time: 25.31109857559204
Epoch: 54, Steps: 137 | Train Loss: 0.2459511 Vali Loss: 0.2312179 Test Loss: 0.2620843
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2450537
	speed: 0.4707s/iter; left time: 2919.6032s
Epoch: 55 cost time: 25.404563903808594
Epoch: 55, Steps: 137 | Train Loss: 0.2460203 Vali Loss: 0.2303431 Test Loss: 0.2620470
Validation loss decreased (0.230543 --> 0.230343).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2477482
	speed: 0.4588s/iter; left time: 2783.3841s
Epoch: 56 cost time: 25.38747763633728
Epoch: 56, Steps: 137 | Train Loss: 0.2458755 Vali Loss: 0.2306427 Test Loss: 0.2620160
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2582455
	speed: 0.4588s/iter; left time: 2719.9874s
Epoch: 57 cost time: 25.51346731185913
Epoch: 57, Steps: 137 | Train Loss: 0.2458930 Vali Loss: 0.2309893 Test Loss: 0.2619936
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2398186
	speed: 0.4603s/iter; left time: 2666.1004s
Epoch: 58 cost time: 25.94059133529663
Epoch: 58, Steps: 137 | Train Loss: 0.2458777 Vali Loss: 0.2306537 Test Loss: 0.2619730
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2435527
	speed: 0.4690s/iter; left time: 2652.0728s
Epoch: 59 cost time: 25.846638917922974
Epoch: 59, Steps: 137 | Train Loss: 0.2458190 Vali Loss: 0.2305954 Test Loss: 0.2619340
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.2377635
	speed: 0.4540s/iter; left time: 2504.9772s
Epoch: 60 cost time: 25.68115997314453
Epoch: 60, Steps: 137 | Train Loss: 0.2458195 Vali Loss: 0.2304156 Test Loss: 0.2619196
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.2519167
	speed: 0.4552s/iter; left time: 2449.6252s
Epoch: 61 cost time: 26.086718320846558
Epoch: 61, Steps: 137 | Train Loss: 0.2457480 Vali Loss: 0.2306171 Test Loss: 0.2619015
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.2504877
	speed: 0.4613s/iter; left time: 2419.3047s
Epoch: 62 cost time: 26.33772897720337
Epoch: 62, Steps: 137 | Train Loss: 0.2457442 Vali Loss: 0.2301978 Test Loss: 0.2618757
Validation loss decreased (0.230343 --> 0.230198).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.2431836
	speed: 0.4575s/iter; left time: 2336.2456s
Epoch: 63 cost time: 26.320537567138672
Epoch: 63, Steps: 137 | Train Loss: 0.2457423 Vali Loss: 0.2305123 Test Loss: 0.2618533
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.2319481
	speed: 0.4578s/iter; left time: 2275.1170s
Epoch: 64 cost time: 26.00407099723816
Epoch: 64, Steps: 137 | Train Loss: 0.2457159 Vali Loss: 0.2299799 Test Loss: 0.2618324
Validation loss decreased (0.230198 --> 0.229980).  Saving model ...
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.2467688
	speed: 0.4501s/iter; left time: 2175.4006s
Epoch: 65 cost time: 25.650481939315796
Epoch: 65, Steps: 137 | Train Loss: 0.2457221 Vali Loss: 0.2303769 Test Loss: 0.2618222
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.2525730
	speed: 0.4564s/iter; left time: 2143.3111s
Epoch: 66 cost time: 25.59336256980896
Epoch: 66, Steps: 137 | Train Loss: 0.2456873 Vali Loss: 0.2307360 Test Loss: 0.2618024
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.2386033
	speed: 0.4652s/iter; left time: 2120.8030s
Epoch: 67 cost time: 26.080193042755127
Epoch: 67, Steps: 137 | Train Loss: 0.2456510 Vali Loss: 0.2301043 Test Loss: 0.2617886
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.2554297
	speed: 0.4706s/iter; left time: 2080.9055s
Epoch: 68 cost time: 26.320053100585938
Epoch: 68, Steps: 137 | Train Loss: 0.2456321 Vali Loss: 0.2306065 Test Loss: 0.2617728
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.2496564
	speed: 0.4825s/iter; left time: 2067.3686s
Epoch: 69 cost time: 26.91160488128662
Epoch: 69, Steps: 137 | Train Loss: 0.2455256 Vali Loss: 0.2303334 Test Loss: 0.2617570
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.2535129
	speed: 0.5081s/iter; left time: 2107.5172s
Epoch: 70 cost time: 26.54181480407715
Epoch: 70, Steps: 137 | Train Loss: 0.2456077 Vali Loss: 0.2307417 Test Loss: 0.2617425
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.2443355
	speed: 0.4823s/iter; left time: 1934.6019s
Epoch: 71 cost time: 26.03955912590027
Epoch: 71, Steps: 137 | Train Loss: 0.2456008 Vali Loss: 0.2302608 Test Loss: 0.2617315
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.2416686
	speed: 0.4675s/iter; left time: 1810.9625s
Epoch: 72 cost time: 25.561654090881348
Epoch: 72, Steps: 137 | Train Loss: 0.2455833 Vali Loss: 0.2305159 Test Loss: 0.2617254
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.2434340
	speed: 0.4703s/iter; left time: 1757.5316s
Epoch: 73 cost time: 26.050926446914673
Epoch: 73, Steps: 137 | Train Loss: 0.2455481 Vali Loss: 0.2304418 Test Loss: 0.2617081
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.2472124
	speed: 0.4747s/iter; left time: 1709.0597s
Epoch: 74 cost time: 25.917479276657104
Epoch: 74, Steps: 137 | Train Loss: 0.2456078 Vali Loss: 0.2299262 Test Loss: 0.2617034
Validation loss decreased (0.229980 --> 0.229926).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.2552734
	speed: 0.4789s/iter; left time: 1658.5998s
Epoch: 75 cost time: 26.809037685394287
Epoch: 75, Steps: 137 | Train Loss: 0.2455339 Vali Loss: 0.2300628 Test Loss: 0.2616878
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.2404885
	speed: 0.4847s/iter; left time: 1612.2332s
Epoch: 76 cost time: 27.063650608062744
Epoch: 76, Steps: 137 | Train Loss: 0.2454610 Vali Loss: 0.2303402 Test Loss: 0.2616822
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.2504515
	speed: 0.4623s/iter; left time: 1474.2012s
Epoch: 77 cost time: 25.713529109954834
Epoch: 77, Steps: 137 | Train Loss: 0.2454744 Vali Loss: 0.2300824 Test Loss: 0.2616751
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.2500744
	speed: 0.4602s/iter; left time: 1404.5474s
Epoch: 78 cost time: 26.04326844215393
Epoch: 78, Steps: 137 | Train Loss: 0.2454928 Vali Loss: 0.2305407 Test Loss: 0.2616662
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.2405242
	speed: 0.4795s/iter; left time: 1397.8324s
Epoch: 79 cost time: 25.918071269989014
Epoch: 79, Steps: 137 | Train Loss: 0.2454680 Vali Loss: 0.2299854 Test Loss: 0.2616602
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.2381138
	speed: 0.4948s/iter; left time: 1374.4783s
Epoch: 80 cost time: 27.87666344642639
Epoch: 80, Steps: 137 | Train Loss: 0.2454165 Vali Loss: 0.2304849 Test Loss: 0.2616516
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.2302475
	speed: 0.4720s/iter; left time: 1246.5985s
Epoch: 81 cost time: 25.650219440460205
Epoch: 81, Steps: 137 | Train Loss: 0.2455315 Vali Loss: 0.2302241 Test Loss: 0.2616461
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.2446179
	speed: 0.4675s/iter; left time: 1170.6514s
Epoch: 82 cost time: 26.09147810935974
Epoch: 82, Steps: 137 | Train Loss: 0.2453795 Vali Loss: 0.2303151 Test Loss: 0.2616382
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.2471451
	speed: 0.4591s/iter; left time: 1086.6662s
Epoch: 83 cost time: 26.439783096313477
Epoch: 83, Steps: 137 | Train Loss: 0.2454190 Vali Loss: 0.2301382 Test Loss: 0.2616319
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.2497557
	speed: 0.4548s/iter; left time: 1014.2869s
Epoch: 84 cost time: 25.71558976173401
Epoch: 84, Steps: 137 | Train Loss: 0.2454681 Vali Loss: 0.2301109 Test Loss: 0.2616273
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.2559555
	speed: 0.4668s/iter; left time: 976.9526s
Epoch: 85 cost time: 26.180823802947998
Epoch: 85, Steps: 137 | Train Loss: 0.2454551 Vali Loss: 0.2302261 Test Loss: 0.2616213
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.2280657
	speed: 0.4658s/iter; left time: 911.1306s
Epoch: 86 cost time: 26.09872007369995
Epoch: 86, Steps: 137 | Train Loss: 0.2454950 Vali Loss: 0.2307518 Test Loss: 0.2616180
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.2554990
	speed: 0.4658s/iter; left time: 847.3248s
Epoch: 87 cost time: 26.80703902244568
Epoch: 87, Steps: 137 | Train Loss: 0.2454457 Vali Loss: 0.2305000 Test Loss: 0.2616148
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.2529206
	speed: 0.4774s/iter; left time: 803.0687s
Epoch: 88 cost time: 26.53811740875244
Epoch: 88, Steps: 137 | Train Loss: 0.2454586 Vali Loss: 0.2302326 Test Loss: 0.2616101
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.2489443
	speed: 0.4597s/iter; left time: 710.3123s
Epoch: 89 cost time: 25.774298429489136
Epoch: 89, Steps: 137 | Train Loss: 0.2454290 Vali Loss: 0.2304388 Test Loss: 0.2616060
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.2420934
	speed: 0.4672s/iter; left time: 657.7965s
Epoch: 90 cost time: 26.1040358543396
Epoch: 90, Steps: 137 | Train Loss: 0.2454221 Vali Loss: 0.2303364 Test Loss: 0.2616018
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.204402478767869e-06
	iters: 100, epoch: 91 | loss: 0.2323044
	speed: 0.4675s/iter; left time: 594.1750s
Epoch: 91 cost time: 26.095222234725952
Epoch: 91, Steps: 137 | Train Loss: 0.2453829 Vali Loss: 0.2304050 Test Loss: 0.2615976
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.944182354829475e-06
	iters: 100, epoch: 92 | loss: 0.2414066
	speed: 0.4759s/iter; left time: 539.7235s
Epoch: 92 cost time: 25.555189609527588
Epoch: 92, Steps: 137 | Train Loss: 0.2454554 Vali Loss: 0.2303046 Test Loss: 0.2615958
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.696973237088e-06
	iters: 100, epoch: 93 | loss: 0.2502507
	speed: 0.4634s/iter; left time: 461.9779s
Epoch: 93 cost time: 25.245452880859375
Epoch: 93, Steps: 137 | Train Loss: 0.2453771 Vali Loss: 0.2303123 Test Loss: 0.2615924
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.462124575233601e-06
	iters: 100, epoch: 94 | loss: 0.2407293
	speed: 0.4606s/iter; left time: 396.0912s
Epoch: 94 cost time: 24.947810888290405
Epoch: 94, Steps: 137 | Train Loss: 0.2453769 Vali Loss: 0.2303255 Test Loss: 0.2615900
EarlyStopping counter: 20 out of 20
Early stopping
train 17603
val 1913
test 4541
Model(
  (freq_upsampler): Linear(in_features=42, out_features=378, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  652313088.0
params:  16254.0
Trainable parameters:  16254
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2867216
	speed: 0.1837s/iter; left time: 2498.0211s
Epoch: 1 cost time: 25.312276124954224
Epoch: 1, Steps: 137 | Train Loss: 0.2789984 Vali Loss: 0.2318750 Test Loss: 0.2628855
Validation loss decreased (inf --> 0.231875).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2795089
	speed: 0.4785s/iter; left time: 6442.6318s
Epoch: 2 cost time: 25.633765697479248
Epoch: 2, Steps: 137 | Train Loss: 0.2760753 Vali Loss: 0.2303340 Test Loss: 0.2616907
Validation loss decreased (0.231875 --> 0.230334).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2853282
	speed: 0.4585s/iter; left time: 6110.3270s
Epoch: 3 cost time: 25.559285879135132
Epoch: 3, Steps: 137 | Train Loss: 0.2753320 Vali Loss: 0.2305014 Test Loss: 0.2612662
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2695168
	speed: 0.4823s/iter; left time: 6361.3165s
Epoch: 4 cost time: 25.80602502822876
Epoch: 4, Steps: 137 | Train Loss: 0.2750624 Vali Loss: 0.2298726 Test Loss: 0.2611654
Validation loss decreased (0.230334 --> 0.229873).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2651868
	speed: 0.4804s/iter; left time: 6270.6536s
Epoch: 5 cost time: 25.75993800163269
Epoch: 5, Steps: 137 | Train Loss: 0.2748920 Vali Loss: 0.2297416 Test Loss: 0.2611338
Validation loss decreased (0.229873 --> 0.229742).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2744886
	speed: 0.4630s/iter; left time: 5979.8996s
Epoch: 6 cost time: 25.61116933822632
Epoch: 6, Steps: 137 | Train Loss: 0.2747885 Vali Loss: 0.2298950 Test Loss: 0.2610347
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2751725
	speed: 0.4542s/iter; left time: 5804.6726s
Epoch: 7 cost time: 25.69152331352234
Epoch: 7, Steps: 137 | Train Loss: 0.2747295 Vali Loss: 0.2295514 Test Loss: 0.2610550
Validation loss decreased (0.229742 --> 0.229551).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2710352
	speed: 0.4721s/iter; left time: 5968.7640s
Epoch: 8 cost time: 25.543219566345215
Epoch: 8, Steps: 137 | Train Loss: 0.2746931 Vali Loss: 0.2294531 Test Loss: 0.2609865
Validation loss decreased (0.229551 --> 0.229453).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2634054
	speed: 0.4680s/iter; left time: 5851.8350s
Epoch: 9 cost time: 25.969625234603882
Epoch: 9, Steps: 137 | Train Loss: 0.2746905 Vali Loss: 0.2298574 Test Loss: 0.2610081
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2664540
	speed: 0.4765s/iter; left time: 5893.6372s
Epoch: 10 cost time: 27.145702123641968
Epoch: 10, Steps: 137 | Train Loss: 0.2746817 Vali Loss: 0.2296534 Test Loss: 0.2610041
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2735801
	speed: 0.4774s/iter; left time: 5838.8634s
Epoch: 11 cost time: 26.41105031967163
Epoch: 11, Steps: 137 | Train Loss: 0.2746306 Vali Loss: 0.2296970 Test Loss: 0.2609187
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2709149
	speed: 0.5048s/iter; left time: 6105.2495s
Epoch: 12 cost time: 28.393749713897705
Epoch: 12, Steps: 137 | Train Loss: 0.2746896 Vali Loss: 0.2294078 Test Loss: 0.2608970
Validation loss decreased (0.229453 --> 0.229408).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2816702
	speed: 0.4614s/iter; left time: 5516.8664s
Epoch: 13 cost time: 26.50814437866211
Epoch: 13, Steps: 137 | Train Loss: 0.2745277 Vali Loss: 0.2294392 Test Loss: 0.2609227
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2727650
	speed: 0.4784s/iter; left time: 5654.3177s
Epoch: 14 cost time: 26.081516981124878
Epoch: 14, Steps: 137 | Train Loss: 0.2745687 Vali Loss: 0.2296039 Test Loss: 0.2609736
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2786953
	speed: 0.4800s/iter; left time: 5608.0294s
Epoch: 15 cost time: 26.84925389289856
Epoch: 15, Steps: 137 | Train Loss: 0.2745923 Vali Loss: 0.2292516 Test Loss: 0.2609898
Validation loss decreased (0.229408 --> 0.229252).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2782031
	speed: 0.4935s/iter; left time: 5697.8744s
Epoch: 16 cost time: 28.98409628868103
Epoch: 16, Steps: 137 | Train Loss: 0.2745875 Vali Loss: 0.2293067 Test Loss: 0.2609576
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2660999
	speed: 0.4954s/iter; left time: 5651.4491s
Epoch: 17 cost time: 26.322762966156006
Epoch: 17, Steps: 137 | Train Loss: 0.2746263 Vali Loss: 0.2293334 Test Loss: 0.2609009
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2639194
	speed: 0.4992s/iter; left time: 5626.6402s
Epoch: 18 cost time: 25.90604567527771
Epoch: 18, Steps: 137 | Train Loss: 0.2746054 Vali Loss: 0.2291307 Test Loss: 0.2609576
Validation loss decreased (0.229252 --> 0.229131).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2883011
	speed: 0.4796s/iter; left time: 5339.8452s
Epoch: 19 cost time: 27.177181243896484
Epoch: 19, Steps: 137 | Train Loss: 0.2746220 Vali Loss: 0.2297476 Test Loss: 0.2609321
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2725924
	speed: 0.4721s/iter; left time: 5191.6670s
Epoch: 20 cost time: 25.459327459335327
Epoch: 20, Steps: 137 | Train Loss: 0.2746555 Vali Loss: 0.2296333 Test Loss: 0.2609704
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2663878
	speed: 0.4692s/iter; left time: 5095.7416s
Epoch: 21 cost time: 25.786561012268066
Epoch: 21, Steps: 137 | Train Loss: 0.2746766 Vali Loss: 0.2298328 Test Loss: 0.2609014
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2821518
	speed: 0.4961s/iter; left time: 5320.5266s
Epoch: 22 cost time: 28.581349849700928
Epoch: 22, Steps: 137 | Train Loss: 0.2746053 Vali Loss: 0.2286641 Test Loss: 0.2609617
Validation loss decreased (0.229131 --> 0.228664).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2832056
	speed: 0.4862s/iter; left time: 5147.2413s
Epoch: 23 cost time: 25.260919094085693
Epoch: 23, Steps: 137 | Train Loss: 0.2744269 Vali Loss: 0.2291999 Test Loss: 0.2609356
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2767074
	speed: 0.5009s/iter; left time: 5234.1147s
Epoch: 24 cost time: 26.093640327453613
Epoch: 24, Steps: 137 | Train Loss: 0.2745376 Vali Loss: 0.2293600 Test Loss: 0.2609205
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2824040
	speed: 0.4677s/iter; left time: 4823.6796s
Epoch: 25 cost time: 26.574719667434692
Epoch: 25, Steps: 137 | Train Loss: 0.2745716 Vali Loss: 0.2296117 Test Loss: 0.2609438
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2801455
	speed: 0.5036s/iter; left time: 5124.4518s
Epoch: 26 cost time: 26.48466920852661
Epoch: 26, Steps: 137 | Train Loss: 0.2744268 Vali Loss: 0.2294866 Test Loss: 0.2608955
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2795141
	speed: 0.5215s/iter; left time: 5235.6424s
Epoch: 27 cost time: 26.842737913131714
Epoch: 27, Steps: 137 | Train Loss: 0.2744982 Vali Loss: 0.2291812 Test Loss: 0.2609260
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2710581
	speed: 0.4953s/iter; left time: 4904.6573s
Epoch: 28 cost time: 28.327590703964233
Epoch: 28, Steps: 137 | Train Loss: 0.2745174 Vali Loss: 0.2291445 Test Loss: 0.2609262
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2767206
	speed: 0.4815s/iter; left time: 4701.6967s
Epoch: 29 cost time: 26.509318351745605
Epoch: 29, Steps: 137 | Train Loss: 0.2744939 Vali Loss: 0.2291617 Test Loss: 0.2609035
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2734155
	speed: 0.5435s/iter; left time: 5233.2504s
Epoch: 30 cost time: 28.173368453979492
Epoch: 30, Steps: 137 | Train Loss: 0.2745341 Vali Loss: 0.2292691 Test Loss: 0.2609206
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2658285
	speed: 0.4746s/iter; left time: 4504.8169s
Epoch: 31 cost time: 26.51684832572937
Epoch: 31, Steps: 137 | Train Loss: 0.2744931 Vali Loss: 0.2292495 Test Loss: 0.2608943
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2727361
	speed: 0.4849s/iter; left time: 4536.0161s
Epoch: 32 cost time: 25.507022619247437
Epoch: 32, Steps: 137 | Train Loss: 0.2745306 Vali Loss: 0.2295277 Test Loss: 0.2609550
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2748403
	speed: 0.4864s/iter; left time: 4482.8142s
Epoch: 33 cost time: 28.70477795600891
Epoch: 33, Steps: 137 | Train Loss: 0.2745156 Vali Loss: 0.2295352 Test Loss: 0.2609390
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2785431
	speed: 0.4723s/iter; left time: 4288.4638s
Epoch: 34 cost time: 27.065476894378662
Epoch: 34, Steps: 137 | Train Loss: 0.2744885 Vali Loss: 0.2294677 Test Loss: 0.2609133
EarlyStopping counter: 12 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2705679
	speed: 0.4907s/iter; left time: 4388.4645s
Epoch: 35 cost time: 26.13518786430359
Epoch: 35, Steps: 137 | Train Loss: 0.2745466 Vali Loss: 0.2295860 Test Loss: 0.2608953
EarlyStopping counter: 13 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2658865
	speed: 0.4847s/iter; left time: 4268.2000s
Epoch: 36 cost time: 26.67707347869873
Epoch: 36, Steps: 137 | Train Loss: 0.2745238 Vali Loss: 0.2292560 Test Loss: 0.2609249
EarlyStopping counter: 14 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2771427
	speed: 0.4719s/iter; left time: 4091.3130s
Epoch: 37 cost time: 26.300200700759888
Epoch: 37, Steps: 137 | Train Loss: 0.2745206 Vali Loss: 0.2294072 Test Loss: 0.2609287
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2698771
	speed: 0.4581s/iter; left time: 3908.2132s
Epoch: 38 cost time: 25.92898154258728
Epoch: 38, Steps: 137 | Train Loss: 0.2744664 Vali Loss: 0.2290601 Test Loss: 0.2608975
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2713162
	speed: 0.4645s/iter; left time: 3899.3169s
Epoch: 39 cost time: 26.260143280029297
Epoch: 39, Steps: 137 | Train Loss: 0.2745329 Vali Loss: 0.2290677 Test Loss: 0.2609196
EarlyStopping counter: 17 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2748457
	speed: 0.4953s/iter; left time: 4090.2549s
Epoch: 40 cost time: 29.1589515209198
Epoch: 40, Steps: 137 | Train Loss: 0.2744336 Vali Loss: 0.2289340 Test Loss: 0.2609071
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2667125
	speed: 0.4897s/iter; left time: 3977.0681s
Epoch: 41 cost time: 26.564607858657837
Epoch: 41, Steps: 137 | Train Loss: 0.2744949 Vali Loss: 0.2293409 Test Loss: 0.2608962
EarlyStopping counter: 19 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2607030
	speed: 0.4828s/iter; left time: 3854.7914s
Epoch: 42 cost time: 25.113078594207764
Epoch: 42, Steps: 137 | Train Loss: 0.2745345 Vali Loss: 0.2293988 Test Loss: 0.2609208
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_90_j720_H8_FITS_custom_ftM_sl90_ll48_pl720_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
mse:0.262908011674881, mae:0.33399367332458496, rse:0.5114807486534119, corr:[0.4376709  0.43563646 0.43361637 0.43185347 0.4305565  0.43002924
 0.42981914 0.42998362 0.42943043 0.42941487 0.4290145  0.42872828
 0.4284527  0.4279944  0.42791465 0.42777836 0.43215936 0.43231776
 0.43243125 0.4323687  0.4321065  0.43176958 0.43143508 0.42968875
 0.42741516 0.42572898 0.4242795  0.42315963 0.4228434  0.42323294
 0.42427912 0.42515624 0.42510355 0.4253159  0.42512858 0.42494324
 0.42471793 0.4243539  0.4241444  0.42392856 0.4241002  0.42433783
 0.4245742  0.42457724 0.42466018 0.42462447 0.4245633  0.42384863
 0.42268693 0.4220243  0.42162162 0.4214577  0.42229244 0.42389578
 0.42630786 0.42818654 0.4285926  0.4289949  0.4289514  0.4287242
 0.4284948  0.42821407 0.42815456 0.42820188 0.4284422  0.4287986
 0.42923015 0.42936888 0.42971596 0.4298841  0.43027118 0.4301994
 0.43006042 0.43039834 0.4307729  0.43176842 0.4335812  0.43616396
 0.43993014 0.44267404 0.44314513 0.44319502 0.44287682 0.44247574
 0.4421213  0.44169733 0.44165206 0.4418246  0.44218472 0.44245264
 0.4427733  0.44286475 0.44292015 0.4429444  0.44305626 0.4430549
 0.44269705 0.4425014  0.44224733 0.4420448  0.4420243  0.44237372
 0.4429969  0.44332743 0.4432623  0.44304535 0.44270205 0.44229987
 0.44198585 0.4416125  0.4415492  0.44166744 0.4419293  0.44225487
 0.4424493  0.44244918 0.44249618 0.44255808 0.4426263  0.4426324
 0.44240004 0.4422762  0.44202983 0.44178623 0.44175264 0.4419527
 0.4423521  0.4424998  0.4424094  0.44217864 0.44188017 0.44149962
 0.4411976  0.4409278  0.4409312  0.4411122  0.44144624 0.44187102
 0.44224742 0.44239324 0.44257608 0.44276717 0.44277954 0.44258076
 0.44211692 0.44191965 0.44159538 0.44130096 0.441417   0.44166568
 0.44222558 0.44233558 0.44211355 0.44192982 0.44141933 0.44095427
 0.44068366 0.4404946  0.44067824 0.44095045 0.441409   0.44187889
 0.44229087 0.44244066 0.44230804 0.4417679  0.44116962 0.43874577
 0.43531784 0.43276203 0.43058974 0.42888397 0.4280257  0.42768484
 0.4279382  0.42814562 0.4277245  0.42753085 0.42712164 0.4268109
 0.42651823 0.42613932 0.42612642 0.42606625 0.42619652 0.42638212
 0.42643818 0.42620033 0.42590153 0.4254211  0.42495176 0.4231155
 0.42063367 0.41869003 0.4172365  0.41629967 0.41611364 0.41689104
 0.41821292 0.4191364  0.4191618  0.4191231  0.41896182 0.4186869
 0.41842788 0.41816917 0.41806874 0.41799155 0.41809648 0.4182619
 0.41844735 0.4184701  0.4183834  0.41820738 0.41823962 0.41739294
 0.41615835 0.4153712  0.41497558 0.4151888  0.41613352 0.4181411
 0.42065987 0.4225734  0.423054   0.4231907  0.42304984 0.42279
 0.4226619  0.42229357 0.4222098  0.42233166 0.42253458 0.4228734
 0.42329156 0.42344496 0.42371738 0.42387694 0.42431986 0.42414397
 0.4239635  0.42429066 0.4247374  0.42582887 0.42775774 0.43065906
 0.43427026 0.43709862 0.43752363 0.43744987 0.43717045 0.4367763
 0.4363853  0.43607828 0.4360942  0.43623888 0.43662333 0.4369778
 0.4372706  0.43740755 0.4374908  0.43761697 0.43773955 0.43769786
 0.43732846 0.43714067 0.4368402  0.43668905 0.43685734 0.43726146
 0.43788722 0.43829155 0.4380525  0.4376594  0.43719032 0.43675762
 0.43638903 0.43600476 0.43603224 0.43619666 0.4364994  0.4368468
 0.43707275 0.43708494 0.43707207 0.4371778  0.43727985 0.4373387
 0.4370254  0.4369129  0.4366951  0.43648055 0.43654695 0.43678972
 0.4373472  0.43748114 0.4372578  0.43698913 0.4365033  0.43609568
 0.43583515 0.43556076 0.4357318  0.43590945 0.43620458 0.43661383
 0.4369855  0.4372191  0.4373825  0.43745634 0.43752155 0.43728822
 0.4367782  0.43650472 0.4361957  0.43609786 0.43623888 0.43655986
 0.43720397 0.43727615 0.43708074 0.43664148 0.4361671  0.43570095
 0.43539894 0.4353572  0.4354592  0.4357419  0.4362556  0.43666652
 0.4371013  0.43705055 0.4367449  0.43609443 0.43531907 0.4326044
 0.4289819  0.42640585 0.42439055 0.42293867 0.42202598 0.42195964
 0.42244312 0.4225696  0.4220384  0.4217337  0.4212568  0.42067584
 0.42023334 0.41997394 0.41990787 0.41984797 0.41995585 0.42011973
 0.4202385  0.41994312 0.41965827 0.41901374 0.4184117  0.41636497
 0.41358423 0.41161272 0.4102549  0.40930426 0.4091857  0.41010177
 0.41160598 0.41259673 0.4125195  0.41238964 0.41218624 0.41184247
 0.41152322 0.4111929  0.41111243 0.41108435 0.41114417 0.41134807
 0.41151133 0.4114897  0.41141513 0.4112461  0.41109604 0.41015694
 0.40886623 0.40815577 0.408031   0.40841597 0.40980026 0.41205767
 0.41473868 0.4168485  0.41713455 0.4173249  0.41711864 0.4167935
 0.41662133 0.41631624 0.41632983 0.41640094 0.41660362 0.4170274
 0.4172753  0.4173877  0.41772097 0.41783592 0.41818443 0.41800323
 0.41785216 0.41818625 0.41879076 0.4201904  0.42246988 0.4256114
 0.42955658 0.4324858  0.4329079  0.43284392 0.43241176 0.431939
 0.43152636 0.4312885  0.4313551  0.43149143 0.43189424 0.43225014
 0.43260577 0.43273643 0.43287322 0.4330844  0.43316582 0.43305954
 0.43262762 0.4324142  0.4322079  0.43213707 0.43235743 0.432881
 0.43361598 0.43381152 0.43349403 0.43312538 0.43260974 0.4321223
 0.4317818  0.43156543 0.43163347 0.43182826 0.43220684 0.43254083
 0.4327622  0.43280226 0.43286955 0.432957   0.43303195 0.4330943
 0.43282798 0.43265402 0.4324359  0.4323829  0.4325597  0.43289298
 0.43342516 0.43346313 0.43325037 0.4327606  0.43230185 0.43183646
 0.43162727 0.43153277 0.43164608 0.43186396 0.43224528 0.4326473
 0.43295744 0.43313155 0.43336642 0.43345222 0.4335237  0.43327156
 0.432773   0.43259674 0.43242973 0.43245795 0.43271393 0.43302557
 0.43358916 0.43369254 0.43344206 0.4328526  0.43237883 0.43192554
 0.43169206 0.43159497 0.4318099  0.432174   0.43254843 0.43304724
 0.43333614 0.43327966 0.4330821  0.43240568 0.43162447 0.4288324
 0.42531547 0.42275706 0.42088827 0.41961786 0.4188789  0.41879612
 0.4190851  0.41926447 0.41872332 0.41828024 0.41777351 0.41722515
 0.416893   0.41659018 0.41656986 0.41658202 0.41649982 0.4168614
 0.41685003 0.4165056  0.41623625 0.41561848 0.41493896 0.4128807
 0.41016418 0.40825653 0.40693712 0.4063049  0.40623325 0.40711197
 0.40850356 0.40920135 0.4089543  0.4086844  0.40825865 0.40799555
 0.4077292  0.4075453  0.4073962  0.40723202 0.40736502 0.4075513
 0.40758622 0.40753588 0.40742064 0.40724987 0.40709934 0.40620205
 0.40492338 0.4043431  0.40418914 0.40463167 0.40598932 0.40812793
 0.41091564 0.41274855 0.4128698  0.41289717 0.41252276 0.41217512
 0.41184756 0.41167223 0.41172877 0.4117026  0.411921   0.41211277
 0.41229704 0.4123833  0.41260096 0.41278642 0.4131542  0.4130207
 0.4129084  0.41325802 0.41413015 0.41553417 0.4178327  0.4208869
 0.42458138 0.4272335  0.42749706 0.42714489 0.4266802  0.42620638
 0.4258839  0.4256566  0.42578733 0.42610687 0.4265425  0.42691362
 0.42712396 0.42712817 0.42731947 0.42742088 0.42754558 0.42738974
 0.426976   0.42686465 0.4266321  0.42670676 0.42695105 0.42742312
 0.42806652 0.42817554 0.42783928 0.4271159  0.4267027  0.42618644
 0.42582706 0.42566693 0.42575008 0.42602652 0.42632806 0.42669502
 0.42690665 0.42684847 0.42694256 0.42692366 0.42700428 0.42700446
 0.4267403  0.4267536  0.42663154 0.42656177 0.42676345 0.42708826
 0.42751852 0.4275303  0.4272328  0.42667234 0.42625922 0.42579216
 0.4255895  0.42552185 0.4256436  0.4258799  0.4261553  0.42660645
 0.4268382  0.42700362 0.42705455 0.4272145  0.42718983 0.42699677
 0.42666262 0.42642608 0.42635718 0.42641798 0.42676112 0.42717433
 0.4276365  0.42769396 0.42725018 0.426676   0.42606452 0.4255904
 0.4253701  0.42528918 0.42545676 0.42571506 0.42600757 0.42641544
 0.42640978 0.4263949  0.4260529  0.42552814 0.4245491  0.42195782
 0.41845545 0.41604677 0.41425467 0.4129927  0.4125935  0.41246432
 0.41278747 0.41298983 0.4123508  0.4118743  0.41109142 0.41061148
 0.41020843 0.40980542 0.40976673 0.40947813 0.40961498 0.40965086
 0.40942255 0.40905973 0.40875328 0.40837622 0.40749362 0.4059868
 0.4031688  0.4018706  0.40053874 0.4002009  0.4003725  0.40126446
 0.40282333 0.40330264 0.4032344  0.40272677 0.40185618 0.4015863
 0.40073264 0.40040946 0.3997923  0.39868343 0.39906257 0.3973501
 0.39841816 0.39612728 0.3975393  0.39566725 0.3966813  0.39080855]
