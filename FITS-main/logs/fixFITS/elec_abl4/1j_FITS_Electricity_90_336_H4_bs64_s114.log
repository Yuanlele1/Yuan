Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_90_j336_H4', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_90_j336_H4_FITS_custom_ftM_sl90_ll48_pl336_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17987
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=26, out_features=123, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  131399424.0
params:  3321.0
Trainable parameters:  3321
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.8782322
	speed: 0.1503s/iter; left time: 2089.6615s
Epoch: 1 cost time: 20.502183437347412
Epoch: 1, Steps: 140 | Train Loss: 1.1816773 Vali Loss: 0.6005591 Test Loss: 0.6822847
Validation loss decreased (inf --> 0.600559).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4821807
	speed: 0.3691s/iter; left time: 5079.3345s
Epoch: 2 cost time: 21.414089918136597
Epoch: 2, Steps: 140 | Train Loss: 0.5385630 Vali Loss: 0.3658726 Test Loss: 0.4148011
Validation loss decreased (0.600559 --> 0.365873).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3447949
	speed: 0.3722s/iter; left time: 5069.4338s
Epoch: 3 cost time: 19.84934163093567
Epoch: 3, Steps: 140 | Train Loss: 0.3702142 Vali Loss: 0.2834848 Test Loss: 0.3201778
Validation loss decreased (0.365873 --> 0.283485).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3014988
	speed: 0.3889s/iter; left time: 5242.1674s
Epoch: 4 cost time: 21.031577110290527
Epoch: 4, Steps: 140 | Train Loss: 0.3060166 Vali Loss: 0.2495109 Test Loss: 0.2808832
Validation loss decreased (0.283485 --> 0.249511).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2753094
	speed: 0.3804s/iter; left time: 5075.4061s
Epoch: 5 cost time: 21.354291439056396
Epoch: 5, Steps: 140 | Train Loss: 0.2781094 Vali Loss: 0.2331881 Test Loss: 0.2625581
Validation loss decreased (0.249511 --> 0.233188).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2536550
	speed: 0.3761s/iter; left time: 4964.8697s
Epoch: 6 cost time: 21.31277871131897
Epoch: 6, Steps: 140 | Train Loss: 0.2642787 Vali Loss: 0.2245190 Test Loss: 0.2527259
Validation loss decreased (0.233188 --> 0.224519).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2571536
	speed: 0.3734s/iter; left time: 4876.6420s
Epoch: 7 cost time: 21.003177165985107
Epoch: 7, Steps: 140 | Train Loss: 0.2562544 Vali Loss: 0.2191012 Test Loss: 0.2466368
Validation loss decreased (0.224519 --> 0.219101).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2602613
	speed: 0.3896s/iter; left time: 5033.8498s
Epoch: 8 cost time: 20.825127840042114
Epoch: 8, Steps: 140 | Train Loss: 0.2510920 Vali Loss: 0.2151751 Test Loss: 0.2425246
Validation loss decreased (0.219101 --> 0.215175).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2493331
	speed: 0.3809s/iter; left time: 4867.8483s
Epoch: 9 cost time: 21.2299964427948
Epoch: 9, Steps: 140 | Train Loss: 0.2474314 Vali Loss: 0.2125444 Test Loss: 0.2395536
Validation loss decreased (0.215175 --> 0.212544).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2565127
	speed: 0.3753s/iter; left time: 4744.5121s
Epoch: 10 cost time: 21.19806742668152
Epoch: 10, Steps: 140 | Train Loss: 0.2447613 Vali Loss: 0.2106074 Test Loss: 0.2373285
Validation loss decreased (0.212544 --> 0.210607).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2362108
	speed: 0.3778s/iter; left time: 4723.3928s
Epoch: 11 cost time: 20.802878618240356
Epoch: 11, Steps: 140 | Train Loss: 0.2426350 Vali Loss: 0.2089541 Test Loss: 0.2355956
Validation loss decreased (0.210607 --> 0.208954).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2461475
	speed: 0.3847s/iter; left time: 4755.2024s
Epoch: 12 cost time: 20.992136240005493
Epoch: 12, Steps: 140 | Train Loss: 0.2410790 Vali Loss: 0.2074104 Test Loss: 0.2342331
Validation loss decreased (0.208954 --> 0.207410).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2447419
	speed: 0.3865s/iter; left time: 4723.1349s
Epoch: 13 cost time: 21.682093381881714
Epoch: 13, Steps: 140 | Train Loss: 0.2397623 Vali Loss: 0.2065078 Test Loss: 0.2331391
Validation loss decreased (0.207410 --> 0.206508).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2386826
	speed: 0.3878s/iter; left time: 4684.8931s
Epoch: 14 cost time: 21.669378995895386
Epoch: 14, Steps: 140 | Train Loss: 0.2387686 Vali Loss: 0.2053865 Test Loss: 0.2322270
Validation loss decreased (0.206508 --> 0.205386).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2330969
	speed: 0.3880s/iter; left time: 4633.5430s
Epoch: 15 cost time: 21.458173274993896
Epoch: 15, Steps: 140 | Train Loss: 0.2378594 Vali Loss: 0.2050233 Test Loss: 0.2314611
Validation loss decreased (0.205386 --> 0.205023).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2318165
	speed: 0.3860s/iter; left time: 4555.3555s
Epoch: 16 cost time: 20.95286536216736
Epoch: 16, Steps: 140 | Train Loss: 0.2372336 Vali Loss: 0.2043061 Test Loss: 0.2308400
Validation loss decreased (0.205023 --> 0.204306).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2500851
	speed: 0.3789s/iter; left time: 4418.5244s
Epoch: 17 cost time: 20.95936679840088
Epoch: 17, Steps: 140 | Train Loss: 0.2365434 Vali Loss: 0.2036351 Test Loss: 0.2302851
Validation loss decreased (0.204306 --> 0.203635).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2435375
	speed: 0.3767s/iter; left time: 4340.0046s
Epoch: 18 cost time: 21.309104681015015
Epoch: 18, Steps: 140 | Train Loss: 0.2359551 Vali Loss: 0.2034940 Test Loss: 0.2298103
Validation loss decreased (0.203635 --> 0.203494).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2416000
	speed: 0.3830s/iter; left time: 4358.8620s
Epoch: 19 cost time: 20.541308403015137
Epoch: 19, Steps: 140 | Train Loss: 0.2355355 Vali Loss: 0.2027301 Test Loss: 0.2293831
Validation loss decreased (0.203494 --> 0.202730).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2287323
	speed: 0.3757s/iter; left time: 4223.4930s
Epoch: 20 cost time: 20.019601106643677
Epoch: 20, Steps: 140 | Train Loss: 0.2350846 Vali Loss: 0.2025017 Test Loss: 0.2290169
Validation loss decreased (0.202730 --> 0.202502).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2249640
	speed: 0.3648s/iter; left time: 4049.3541s
Epoch: 21 cost time: 19.920276641845703
Epoch: 21, Steps: 140 | Train Loss: 0.2347957 Vali Loss: 0.2020678 Test Loss: 0.2286832
Validation loss decreased (0.202502 --> 0.202068).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2415590
	speed: 0.3648s/iter; left time: 3998.7928s
Epoch: 22 cost time: 20.819196939468384
Epoch: 22, Steps: 140 | Train Loss: 0.2343775 Vali Loss: 0.2018047 Test Loss: 0.2283773
Validation loss decreased (0.202068 --> 0.201805).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2311217
	speed: 0.3668s/iter; left time: 3969.2839s
Epoch: 23 cost time: 20.052218914031982
Epoch: 23, Steps: 140 | Train Loss: 0.2340418 Vali Loss: 0.2017186 Test Loss: 0.2281156
Validation loss decreased (0.201805 --> 0.201719).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2416634
	speed: 0.3769s/iter; left time: 4026.0518s
Epoch: 24 cost time: 20.120922565460205
Epoch: 24, Steps: 140 | Train Loss: 0.2337882 Vali Loss: 0.2015995 Test Loss: 0.2278530
Validation loss decreased (0.201719 --> 0.201600).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2292975
	speed: 0.3738s/iter; left time: 3940.2894s
Epoch: 25 cost time: 21.15037178993225
Epoch: 25, Steps: 140 | Train Loss: 0.2335711 Vali Loss: 0.2011760 Test Loss: 0.2276336
Validation loss decreased (0.201600 --> 0.201176).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2386934
	speed: 0.3728s/iter; left time: 3877.5305s
Epoch: 26 cost time: 21.29267954826355
Epoch: 26, Steps: 140 | Train Loss: 0.2332720 Vali Loss: 0.2011929 Test Loss: 0.2274252
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2251411
	speed: 0.3700s/iter; left time: 3796.9849s
Epoch: 27 cost time: 20.411174535751343
Epoch: 27, Steps: 140 | Train Loss: 0.2331481 Vali Loss: 0.2010317 Test Loss: 0.2272431
Validation loss decreased (0.201176 --> 0.201032).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2279854
	speed: 0.3755s/iter; left time: 3800.4110s
Epoch: 28 cost time: 20.02762722969055
Epoch: 28, Steps: 140 | Train Loss: 0.2329247 Vali Loss: 0.2011013 Test Loss: 0.2270683
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2269085
	speed: 0.3695s/iter; left time: 3687.9119s
Epoch: 29 cost time: 20.04144835472107
Epoch: 29, Steps: 140 | Train Loss: 0.2327420 Vali Loss: 0.2004896 Test Loss: 0.2269020
Validation loss decreased (0.201032 --> 0.200490).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2235340
	speed: 0.3757s/iter; left time: 3697.2730s
Epoch: 30 cost time: 21.706339359283447
Epoch: 30, Steps: 140 | Train Loss: 0.2326003 Vali Loss: 0.2006905 Test Loss: 0.2267635
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2237894
	speed: 0.3721s/iter; left time: 3610.1195s
Epoch: 31 cost time: 19.90474033355713
Epoch: 31, Steps: 140 | Train Loss: 0.2324244 Vali Loss: 0.2005309 Test Loss: 0.2266321
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2283782
	speed: 0.3697s/iter; left time: 3535.0564s
Epoch: 32 cost time: 20.095859050750732
Epoch: 32, Steps: 140 | Train Loss: 0.2322758 Vali Loss: 0.2006932 Test Loss: 0.2265096
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2303675
	speed: 0.3602s/iter; left time: 3393.1913s
Epoch: 33 cost time: 19.833542823791504
Epoch: 33, Steps: 140 | Train Loss: 0.2322277 Vali Loss: 0.2001277 Test Loss: 0.2263946
Validation loss decreased (0.200490 --> 0.200128).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2248257
	speed: 0.3608s/iter; left time: 3348.3930s
Epoch: 34 cost time: 21.39226222038269
Epoch: 34, Steps: 140 | Train Loss: 0.2319639 Vali Loss: 0.2003908 Test Loss: 0.2262889
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2353754
	speed: 0.3776s/iter; left time: 3452.0712s
Epoch: 35 cost time: 20.295536756515503
Epoch: 35, Steps: 140 | Train Loss: 0.2319666 Vali Loss: 0.2001928 Test Loss: 0.2261926
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2314854
	speed: 0.3686s/iter; left time: 3317.6972s
Epoch: 36 cost time: 19.290262937545776
Epoch: 36, Steps: 140 | Train Loss: 0.2318337 Vali Loss: 0.1998695 Test Loss: 0.2261101
Validation loss decreased (0.200128 --> 0.199869).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2377266
	speed: 0.3643s/iter; left time: 3227.8307s
Epoch: 37 cost time: 20.031198978424072
Epoch: 37, Steps: 140 | Train Loss: 0.2316418 Vali Loss: 0.1999272 Test Loss: 0.2260249
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2211959
	speed: 0.3614s/iter; left time: 3151.8271s
Epoch: 38 cost time: 20.445488691329956
Epoch: 38, Steps: 140 | Train Loss: 0.2317178 Vali Loss: 0.1997002 Test Loss: 0.2259491
Validation loss decreased (0.199869 --> 0.199700).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2272580
	speed: 0.3540s/iter; left time: 3037.6786s
Epoch: 39 cost time: 19.53279709815979
Epoch: 39, Steps: 140 | Train Loss: 0.2316133 Vali Loss: 0.1995876 Test Loss: 0.2258923
Validation loss decreased (0.199700 --> 0.199588).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2194621
	speed: 0.3641s/iter; left time: 3073.1862s
Epoch: 40 cost time: 19.704766511917114
Epoch: 40, Steps: 140 | Train Loss: 0.2315563 Vali Loss: 0.1997378 Test Loss: 0.2258270
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2381567
	speed: 0.3658s/iter; left time: 3036.6134s
Epoch: 41 cost time: 19.913716554641724
Epoch: 41, Steps: 140 | Train Loss: 0.2313974 Vali Loss: 0.1998659 Test Loss: 0.2257667
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2432927
	speed: 0.3673s/iter; left time: 2997.7989s
Epoch: 42 cost time: 21.190454721450806
Epoch: 42, Steps: 140 | Train Loss: 0.2314263 Vali Loss: 0.1994746 Test Loss: 0.2257206
Validation loss decreased (0.199588 --> 0.199475).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2265436
	speed: 0.3660s/iter; left time: 2935.3718s
Epoch: 43 cost time: 19.939884185791016
Epoch: 43, Steps: 140 | Train Loss: 0.2313786 Vali Loss: 0.1994012 Test Loss: 0.2256733
Validation loss decreased (0.199475 --> 0.199401).  Saving model ...
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2389893
	speed: 0.3643s/iter; left time: 2870.9125s
Epoch: 44 cost time: 19.312723636627197
Epoch: 44, Steps: 140 | Train Loss: 0.2312859 Vali Loss: 0.1993374 Test Loss: 0.2256289
Validation loss decreased (0.199401 --> 0.199337).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2263380
	speed: 0.3688s/iter; left time: 2855.0034s
Epoch: 45 cost time: 20.43529200553894
Epoch: 45, Steps: 140 | Train Loss: 0.2312375 Vali Loss: 0.1996372 Test Loss: 0.2255905
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2177408
	speed: 0.3678s/iter; left time: 2795.7805s
Epoch: 46 cost time: 21.06416344642639
Epoch: 46, Steps: 140 | Train Loss: 0.2312068 Vali Loss: 0.1994878 Test Loss: 0.2255566
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2300621
	speed: 0.3546s/iter; left time: 2645.9013s
Epoch: 47 cost time: 19.6011323928833
Epoch: 47, Steps: 140 | Train Loss: 0.2311917 Vali Loss: 0.1996261 Test Loss: 0.2255192
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2229849
	speed: 0.3677s/iter; left time: 2691.7073s
Epoch: 48 cost time: 19.949703454971313
Epoch: 48, Steps: 140 | Train Loss: 0.2311644 Vali Loss: 0.1992297 Test Loss: 0.2254911
Validation loss decreased (0.199337 --> 0.199230).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2393801
	speed: 0.3658s/iter; left time: 2627.1178s
Epoch: 49 cost time: 19.910637617111206
Epoch: 49, Steps: 140 | Train Loss: 0.2310774 Vali Loss: 0.1993821 Test Loss: 0.2254620
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2295983
	speed: 0.3664s/iter; left time: 2579.6903s
Epoch: 50 cost time: 20.861098289489746
Epoch: 50, Steps: 140 | Train Loss: 0.2310393 Vali Loss: 0.1995767 Test Loss: 0.2254359
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2306773
	speed: 0.3673s/iter; left time: 2534.6927s
Epoch: 51 cost time: 20.89306402206421
Epoch: 51, Steps: 140 | Train Loss: 0.2311067 Vali Loss: 0.1994491 Test Loss: 0.2254143
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2396297
	speed: 0.3756s/iter; left time: 2539.3929s
Epoch: 52 cost time: 19.8162043094635
Epoch: 52, Steps: 140 | Train Loss: 0.2310653 Vali Loss: 0.1993988 Test Loss: 0.2253934
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2251526
	speed: 0.3714s/iter; left time: 2459.2425s
Epoch: 53 cost time: 20.28737449645996
Epoch: 53, Steps: 140 | Train Loss: 0.2310666 Vali Loss: 0.1994263 Test Loss: 0.2253800
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2322823
	speed: 0.3636s/iter; left time: 2356.3610s
Epoch: 54 cost time: 19.568827629089355
Epoch: 54, Steps: 140 | Train Loss: 0.2310283 Vali Loss: 0.1993184 Test Loss: 0.2253611
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2187192
	speed: 0.3554s/iter; left time: 2253.6336s
Epoch: 55 cost time: 19.99707269668579
Epoch: 55, Steps: 140 | Train Loss: 0.2310046 Vali Loss: 0.1990289 Test Loss: 0.2253441
Validation loss decreased (0.199230 --> 0.199029).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2314913
	speed: 0.3645s/iter; left time: 2260.3868s
Epoch: 56 cost time: 19.518619775772095
Epoch: 56, Steps: 140 | Train Loss: 0.2309514 Vali Loss: 0.1992755 Test Loss: 0.2253290
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2277249
	speed: 0.3694s/iter; left time: 2238.6432s
Epoch: 57 cost time: 20.333186149597168
Epoch: 57, Steps: 140 | Train Loss: 0.2308946 Vali Loss: 0.1991526 Test Loss: 0.2253177
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2257335
	speed: 0.3375s/iter; left time: 1998.2057s
Epoch: 58 cost time: 17.354961156845093
Epoch: 58, Steps: 140 | Train Loss: 0.2309062 Vali Loss: 0.1992661 Test Loss: 0.2253048
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2401729
	speed: 0.2928s/iter; left time: 1692.8954s
Epoch: 59 cost time: 16.300076007843018
Epoch: 59, Steps: 140 | Train Loss: 0.2309437 Vali Loss: 0.1991205 Test Loss: 0.2252926
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.2276525
	speed: 0.3107s/iter; left time: 1752.4997s
Epoch: 60 cost time: 19.684277772903442
Epoch: 60, Steps: 140 | Train Loss: 0.2309074 Vali Loss: 0.1988124 Test Loss: 0.2252861
Validation loss decreased (0.199029 --> 0.198812).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.2310569
	speed: 0.3641s/iter; left time: 2003.1139s
Epoch: 61 cost time: 20.206861972808838
Epoch: 61, Steps: 140 | Train Loss: 0.2309266 Vali Loss: 0.1992740 Test Loss: 0.2252722
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.2265861
	speed: 0.3602s/iter; left time: 1930.9284s
Epoch: 62 cost time: 20.057722091674805
Epoch: 62, Steps: 140 | Train Loss: 0.2308632 Vali Loss: 0.1989944 Test Loss: 0.2252649
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.2266200
	speed: 0.3678s/iter; left time: 1920.3713s
Epoch: 63 cost time: 19.85954523086548
Epoch: 63, Steps: 140 | Train Loss: 0.2309235 Vali Loss: 0.1992709 Test Loss: 0.2252594
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.2301116
	speed: 0.3540s/iter; left time: 1798.8322s
Epoch: 64 cost time: 20.140904426574707
Epoch: 64, Steps: 140 | Train Loss: 0.2308702 Vali Loss: 0.1993092 Test Loss: 0.2252513
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.2299992
	speed: 0.3688s/iter; left time: 1822.1666s
Epoch: 65 cost time: 20.44740581512451
Epoch: 65, Steps: 140 | Train Loss: 0.2308054 Vali Loss: 0.1995061 Test Loss: 0.2252471
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.2352369
	speed: 0.3716s/iter; left time: 1784.1292s
Epoch: 66 cost time: 21.11715054512024
Epoch: 66, Steps: 140 | Train Loss: 0.2308076 Vali Loss: 0.1990581 Test Loss: 0.2252403
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.2277060
	speed: 0.3822s/iter; left time: 1781.5243s
Epoch: 67 cost time: 20.65348982810974
Epoch: 67, Steps: 140 | Train Loss: 0.2309491 Vali Loss: 0.1990322 Test Loss: 0.2252341
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.2304845
	speed: 0.3582s/iter; left time: 1619.5704s
Epoch: 68 cost time: 20.14519500732422
Epoch: 68, Steps: 140 | Train Loss: 0.2308279 Vali Loss: 0.1988541 Test Loss: 0.2252276
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.2269425
	speed: 0.3723s/iter; left time: 1631.0387s
Epoch: 69 cost time: 20.085153818130493
Epoch: 69, Steps: 140 | Train Loss: 0.2308261 Vali Loss: 0.1990143 Test Loss: 0.2252254
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.2291359
	speed: 0.3583s/iter; left time: 1519.4606s
Epoch: 70 cost time: 20.194500207901
Epoch: 70, Steps: 140 | Train Loss: 0.2309011 Vali Loss: 0.1990830 Test Loss: 0.2252212
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.2348873
	speed: 0.3664s/iter; left time: 1502.6263s
Epoch: 71 cost time: 19.55554986000061
Epoch: 71, Steps: 140 | Train Loss: 0.2308605 Vali Loss: 0.1987136 Test Loss: 0.2252170
Validation loss decreased (0.198812 --> 0.198714).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.2387822
	speed: 0.3439s/iter; left time: 1362.0769s
Epoch: 72 cost time: 19.76262331008911
Epoch: 72, Steps: 140 | Train Loss: 0.2308054 Vali Loss: 0.1992811 Test Loss: 0.2252130
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.2267168
	speed: 0.3752s/iter; left time: 1433.5010s
Epoch: 73 cost time: 20.273990631103516
Epoch: 73, Steps: 140 | Train Loss: 0.2307943 Vali Loss: 0.1993236 Test Loss: 0.2252111
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.2299978
	speed: 0.3647s/iter; left time: 1342.5918s
Epoch: 74 cost time: 20.50309443473816
Epoch: 74, Steps: 140 | Train Loss: 0.2308557 Vali Loss: 0.1989021 Test Loss: 0.2252079
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.2461021
	speed: 0.3866s/iter; left time: 1368.8016s
Epoch: 75 cost time: 20.42164921760559
Epoch: 75, Steps: 140 | Train Loss: 0.2308780 Vali Loss: 0.1988824 Test Loss: 0.2252057
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.2195220
	speed: 0.3603s/iter; left time: 1225.2447s
Epoch: 76 cost time: 20.074448108673096
Epoch: 76, Steps: 140 | Train Loss: 0.2307773 Vali Loss: 0.1988277 Test Loss: 0.2252024
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.2365075
	speed: 0.3798s/iter; left time: 1238.6835s
Epoch: 77 cost time: 20.349562644958496
Epoch: 77, Steps: 140 | Train Loss: 0.2308273 Vali Loss: 0.1991642 Test Loss: 0.2251999
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.2303568
	speed: 0.3505s/iter; left time: 1094.0324s
Epoch: 78 cost time: 19.525519609451294
Epoch: 78, Steps: 140 | Train Loss: 0.2307450 Vali Loss: 0.1989206 Test Loss: 0.2251974
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.2361271
	speed: 0.3651s/iter; left time: 1088.5044s
Epoch: 79 cost time: 19.83125400543213
Epoch: 79, Steps: 140 | Train Loss: 0.2308040 Vali Loss: 0.1990820 Test Loss: 0.2251964
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.2156841
	speed: 0.3485s/iter; left time: 990.2140s
Epoch: 80 cost time: 19.591086864471436
Epoch: 80, Steps: 140 | Train Loss: 0.2307493 Vali Loss: 0.1986689 Test Loss: 0.2251933
Validation loss decreased (0.198714 --> 0.198669).  Saving model ...
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.2343997
	speed: 0.3688s/iter; left time: 996.1764s
Epoch: 81 cost time: 20.419567108154297
Epoch: 81, Steps: 140 | Train Loss: 0.2308471 Vali Loss: 0.1991115 Test Loss: 0.2251929
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.2281872
	speed: 0.3582s/iter; left time: 917.2440s
Epoch: 82 cost time: 19.625793933868408
Epoch: 82, Steps: 140 | Train Loss: 0.2307342 Vali Loss: 0.1990754 Test Loss: 0.2251910
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.2370031
	speed: 0.3787s/iter; left time: 916.8828s
Epoch: 83 cost time: 20.37244200706482
Epoch: 83, Steps: 140 | Train Loss: 0.2308177 Vali Loss: 0.1994399 Test Loss: 0.2251890
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.2356264
	speed: 0.3519s/iter; left time: 802.7958s
Epoch: 84 cost time: 19.983662128448486
Epoch: 84, Steps: 140 | Train Loss: 0.2307988 Vali Loss: 0.1992138 Test Loss: 0.2251878
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.2245448
	speed: 0.3807s/iter; left time: 815.0476s
Epoch: 85 cost time: 20.52101993560791
Epoch: 85, Steps: 140 | Train Loss: 0.2308425 Vali Loss: 0.1993466 Test Loss: 0.2251865
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.2347711
	speed: 0.3615s/iter; left time: 723.2694s
Epoch: 86 cost time: 19.69018054008484
Epoch: 86, Steps: 140 | Train Loss: 0.2307851 Vali Loss: 0.1992718 Test Loss: 0.2251855
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.2255757
	speed: 0.3845s/iter; left time: 715.6033s
Epoch: 87 cost time: 20.88634991645813
Epoch: 87, Steps: 140 | Train Loss: 0.2308272 Vali Loss: 0.1989441 Test Loss: 0.2251849
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.2402799
	speed: 0.3553s/iter; left time: 611.3991s
Epoch: 88 cost time: 19.94252634048462
Epoch: 88, Steps: 140 | Train Loss: 0.2308362 Vali Loss: 0.1991871 Test Loss: 0.2251841
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.2334109
	speed: 0.3813s/iter; left time: 602.8253s
Epoch: 89 cost time: 20.781135082244873
Epoch: 89, Steps: 140 | Train Loss: 0.2308149 Vali Loss: 0.1990773 Test Loss: 0.2251831
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.2456820
	speed: 0.3492s/iter; left time: 503.2331s
Epoch: 90 cost time: 19.040873289108276
Epoch: 90, Steps: 140 | Train Loss: 0.2307208 Vali Loss: 0.1988954 Test Loss: 0.2251820
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.204402478767869e-06
	iters: 100, epoch: 91 | loss: 0.2270379
	speed: 0.3703s/iter; left time: 481.6999s
Epoch: 91 cost time: 19.671865701675415
Epoch: 91, Steps: 140 | Train Loss: 0.2308042 Vali Loss: 0.1990621 Test Loss: 0.2251814
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.944182354829475e-06
	iters: 100, epoch: 92 | loss: 0.2273735
	speed: 0.3516s/iter; left time: 408.1822s
Epoch: 92 cost time: 19.06280016899109
Epoch: 92, Steps: 140 | Train Loss: 0.2307109 Vali Loss: 0.1990849 Test Loss: 0.2251801
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.696973237088e-06
	iters: 100, epoch: 93 | loss: 0.2323997
	speed: 0.3741s/iter; left time: 381.9644s
Epoch: 93 cost time: 20.388872385025024
Epoch: 93, Steps: 140 | Train Loss: 0.2308227 Vali Loss: 0.1990140 Test Loss: 0.2251793
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.462124575233601e-06
	iters: 100, epoch: 94 | loss: 0.2317725
	speed: 0.3534s/iter; left time: 311.3892s
Epoch: 94 cost time: 18.9186110496521
Epoch: 94, Steps: 140 | Train Loss: 0.2308072 Vali Loss: 0.1989959 Test Loss: 0.2251788
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.239018346471921e-06
	iters: 100, epoch: 95 | loss: 0.2359641
	speed: 0.3662s/iter; left time: 271.3219s
Epoch: 95 cost time: 19.871199131011963
Epoch: 95, Steps: 140 | Train Loss: 0.2308387 Vali Loss: 0.1990061 Test Loss: 0.2251780
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.027067429148324e-06
	iters: 100, epoch: 96 | loss: 0.2284445
	speed: 0.3468s/iter; left time: 208.4239s
Epoch: 96 cost time: 18.599777698516846
Epoch: 96, Steps: 140 | Train Loss: 0.2308129 Vali Loss: 0.1992584 Test Loss: 0.2251778
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.825714057690908e-06
	iters: 100, epoch: 97 | loss: 0.2241877
	speed: 0.3718s/iter; left time: 171.4116s
Epoch: 97 cost time: 20.952642917633057
Epoch: 97, Steps: 140 | Train Loss: 0.2308260 Vali Loss: 0.1989417 Test Loss: 0.2251766
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.6344283548063623e-06
	iters: 100, epoch: 98 | loss: 0.2259550
	speed: 0.3579s/iter; left time: 114.8867s
Epoch: 98 cost time: 18.87761092185974
Epoch: 98, Steps: 140 | Train Loss: 0.2308696 Vali Loss: 0.1994577 Test Loss: 0.2251764
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.452706937066044e-06
	iters: 100, epoch: 99 | loss: 0.2351614
	speed: 0.3663s/iter; left time: 66.2938s
Epoch: 99 cost time: 19.794517755508423
Epoch: 99, Steps: 140 | Train Loss: 0.2307766 Vali Loss: 0.1990259 Test Loss: 0.2251760
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.2800715902127414e-06
	iters: 100, epoch: 100 | loss: 0.2166247
	speed: 0.3445s/iter; left time: 14.1235s
Epoch: 100 cost time: 18.49949550628662
Epoch: 100, Steps: 140 | Train Loss: 0.2308557 Vali Loss: 0.1991284 Test Loss: 0.2251755
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_90_j336_H4_FITS_custom_ftM_sl90_ll48_pl336_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4925
mse:0.22375229001045227, mae:0.30599749088287354, rse:0.4707876145839691, corr:[0.45508936 0.45238793 0.45186538 0.4514065  0.45003927 0.44888034
 0.44959262 0.44870764 0.44718215 0.44634005 0.4457621  0.4451503
 0.44486776 0.44443533 0.44400436 0.44396317 0.444013   0.4441368
 0.444371   0.44436213 0.44426897 0.44425544 0.44399568 0.44281614
 0.440369   0.43911815 0.43813932 0.43703082 0.43639618 0.43650505
 0.4376945  0.43772003 0.43729183 0.43699104 0.43672663 0.4363143
 0.43624496 0.43617526 0.4358479  0.435707   0.4358026  0.43586364
 0.43594527 0.43608454 0.43620592 0.43628463 0.43626785 0.4359176
 0.43462047 0.43427658 0.43435946 0.43452984 0.43525994 0.436722
 0.43902865 0.4404389  0.4408671  0.44068235 0.4405235  0.44023275
 0.43999988 0.4399143  0.439859   0.43999088 0.44023928 0.44042304
 0.44062316 0.4408804  0.44121623 0.44155318 0.44194248 0.442333
 0.44230437 0.4429131  0.44365507 0.44472134 0.44647804 0.44898456
 0.4522829  0.4547863  0.45564654 0.45506412 0.45458433 0.45421886
 0.45380026 0.45356727 0.4534869  0.4535914  0.45390573 0.45412004
 0.4543366  0.45462146 0.45475322 0.45483527 0.45504633 0.4551268
 0.45472512 0.45472145 0.4547975  0.45469463 0.45463356 0.45482814
 0.45530987 0.45530868 0.45507362 0.45459667 0.45423365 0.45397475
 0.45373362 0.4536598  0.45368427 0.45374545 0.45400104 0.45419216
 0.45428634 0.4544435  0.45448473 0.4544606  0.45463243 0.4548411
 0.45451263 0.45447338 0.4545839  0.45454141 0.45439947 0.454419
 0.45472467 0.4545549  0.45428786 0.45394522 0.45362064 0.4534463
 0.45333308 0.45333362 0.4534503  0.45356676 0.4538588  0.45417368
 0.45430323 0.45443407 0.45450485 0.45445994 0.4544588  0.45445722
 0.45397303 0.453763   0.45379284 0.45378712 0.45368472 0.4537147
 0.45405325 0.45396453 0.45367676 0.45325476 0.45285824 0.4526722
 0.4526115  0.45267424 0.4529047  0.4531011  0.45344386 0.45395842
 0.45418632 0.45410976 0.45406717 0.45374846 0.45250887 0.45016468
 0.44717205 0.44493273 0.44332767 0.44190004 0.44076687 0.44009262
 0.440103   0.43974105 0.43940315 0.43895224 0.4384688  0.4382624
 0.43819898 0.43799838 0.4378091  0.4375466  0.43748286 0.4375276
 0.43731257 0.43709728 0.43701375 0.4366936  0.43577248 0.43415397
 0.43186137 0.43035042 0.42934778 0.42859313 0.4281265  0.42835358
 0.42950952 0.42995796 0.43010387 0.4299344  0.4295958  0.42951182
 0.42964315 0.4295486  0.4293742  0.42923126 0.42924976 0.4293208
 0.4291886  0.42914894 0.42932007 0.42931014 0.428967   0.42848563
 0.4274565  0.42695177 0.42695257 0.4274059  0.42815012 0.42959753
 0.43205008 0.433737   0.4344896  0.43454146 0.43429077 0.4341455
 0.43416938 0.43405852 0.43395507 0.43403357 0.43426013 0.43447447
 0.4345282  0.43469462 0.43512022 0.4354049  0.43558192 0.43595192
 0.43608534 0.43656978 0.43733737 0.43865177 0.44032505 0.44274375
 0.44622046 0.4488685  0.44984975 0.44960704 0.44914845 0.44880643
 0.44863638 0.4484479  0.44830492 0.44839886 0.44862875 0.4488227
 0.44898582 0.44917086 0.4493294  0.44943962 0.44956478 0.44956377
 0.4492553  0.44920677 0.44916713 0.44918856 0.4492572  0.44941515
 0.44993046 0.4500389  0.44988024 0.44963992 0.44923308 0.448834
 0.44879562 0.44876897 0.4486136  0.4486361  0.44883418 0.44898486
 0.44905055 0.44905397 0.4490756  0.4491114  0.44921958 0.4492739
 0.4490348  0.44907844 0.44904757 0.4490125  0.44910824 0.44916323
 0.4494382  0.44932547 0.44910014 0.44900888 0.4487173  0.44832748
 0.44841564 0.4485865  0.44845068 0.44848934 0.44877827 0.44897738
 0.4489948  0.44894087 0.44897556 0.44902283 0.4489807  0.4487518
 0.44833526 0.4483144  0.4481539  0.448046   0.44824675 0.4482841
 0.44853538 0.4486592  0.44857556 0.4484514  0.44823322 0.44793755
 0.4482121  0.44844118 0.44808266 0.44821012 0.44872597 0.44863012
 0.44828677 0.44825056 0.44829288 0.4475783  0.44696966 0.44644752]
