Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=34, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_90_j192_H6', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_90_j192_H6_FITS_custom_ftM_sl90_ll48_pl192_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18131
val 2441
test 5069
Model(
  (freq_upsampler): Linear(in_features=34, out_features=106, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  148081152.0
params:  3710.0
Trainable parameters:  3710
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6389279
	speed: 0.0967s/iter; left time: 1354.4770s
Epoch: 1 cost time: 13.281027793884277
Epoch: 1, Steps: 141 | Train Loss: 0.8648188 Vali Loss: 0.4410599 Test Loss: 0.5036424
Validation loss decreased (inf --> 0.441060).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3648059
	speed: 0.1990s/iter; left time: 2758.4748s
Epoch: 2 cost time: 12.039442777633667
Epoch: 2, Steps: 141 | Train Loss: 0.3954278 Vali Loss: 0.2767953 Test Loss: 0.3163527
Validation loss decreased (0.441060 --> 0.276795).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2704892
	speed: 0.1971s/iter; left time: 2704.5969s
Epoch: 3 cost time: 12.047978639602661
Epoch: 3, Steps: 141 | Train Loss: 0.2848333 Vali Loss: 0.2284499 Test Loss: 0.2606434
Validation loss decreased (0.276795 --> 0.228450).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2452611
	speed: 0.1985s/iter; left time: 2695.7285s
Epoch: 4 cost time: 12.062241315841675
Epoch: 4, Steps: 141 | Train Loss: 0.2489742 Vali Loss: 0.2100056 Test Loss: 0.2397482
Validation loss decreased (0.228450 --> 0.210006).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2319431
	speed: 0.2005s/iter; left time: 2693.6137s
Epoch: 5 cost time: 12.022286891937256
Epoch: 5, Steps: 141 | Train Loss: 0.2338772 Vali Loss: 0.2007581 Test Loss: 0.2294950
Validation loss decreased (0.210006 --> 0.200758).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2205299
	speed: 0.1958s/iter; left time: 2603.3197s
Epoch: 6 cost time: 11.92094898223877
Epoch: 6, Steps: 141 | Train Loss: 0.2257357 Vali Loss: 0.1953052 Test Loss: 0.2234701
Validation loss decreased (0.200758 --> 0.195305).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2301052
	speed: 0.1996s/iter; left time: 2625.0830s
Epoch: 7 cost time: 12.38465142250061
Epoch: 7, Steps: 141 | Train Loss: 0.2206164 Vali Loss: 0.1917701 Test Loss: 0.2195798
Validation loss decreased (0.195305 --> 0.191770).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2195241
	speed: 0.2001s/iter; left time: 2604.5385s
Epoch: 8 cost time: 12.49850845336914
Epoch: 8, Steps: 141 | Train Loss: 0.2172742 Vali Loss: 0.1893345 Test Loss: 0.2169353
Validation loss decreased (0.191770 --> 0.189335).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2143654
	speed: 0.1978s/iter; left time: 2546.2585s
Epoch: 9 cost time: 12.236352443695068
Epoch: 9, Steps: 141 | Train Loss: 0.2149645 Vali Loss: 0.1875550 Test Loss: 0.2150712
Validation loss decreased (0.189335 --> 0.187555).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2178401
	speed: 0.1996s/iter; left time: 2541.5510s
Epoch: 10 cost time: 12.39147138595581
Epoch: 10, Steps: 141 | Train Loss: 0.2132552 Vali Loss: 0.1863041 Test Loss: 0.2136799
Validation loss decreased (0.187555 --> 0.186304).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2120853
	speed: 0.1990s/iter; left time: 2505.5455s
Epoch: 11 cost time: 12.522878170013428
Epoch: 11, Steps: 141 | Train Loss: 0.2119168 Vali Loss: 0.1854147 Test Loss: 0.2126460
Validation loss decreased (0.186304 --> 0.185415).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2143193
	speed: 0.2044s/iter; left time: 2545.1815s
Epoch: 12 cost time: 12.504318237304688
Epoch: 12, Steps: 141 | Train Loss: 0.2110543 Vali Loss: 0.1847472 Test Loss: 0.2118280
Validation loss decreased (0.185415 --> 0.184747).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2173650
	speed: 0.2011s/iter; left time: 2474.7308s
Epoch: 13 cost time: 12.186744689941406
Epoch: 13, Steps: 141 | Train Loss: 0.2102123 Vali Loss: 0.1839895 Test Loss: 0.2111787
Validation loss decreased (0.184747 --> 0.183989).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2091050
	speed: 0.1932s/iter; left time: 2350.4140s
Epoch: 14 cost time: 11.504597425460815
Epoch: 14, Steps: 141 | Train Loss: 0.2096449 Vali Loss: 0.1835608 Test Loss: 0.2106510
Validation loss decreased (0.183989 --> 0.183561).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1970976
	speed: 0.1974s/iter; left time: 2374.0909s
Epoch: 15 cost time: 12.016668558120728
Epoch: 15, Steps: 141 | Train Loss: 0.2091493 Vali Loss: 0.1832538 Test Loss: 0.2102147
Validation loss decreased (0.183561 --> 0.183254).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2048340
	speed: 0.2137s/iter; left time: 2539.6683s
Epoch: 16 cost time: 12.854759931564331
Epoch: 16, Steps: 141 | Train Loss: 0.2087207 Vali Loss: 0.1828801 Test Loss: 0.2098386
Validation loss decreased (0.183254 --> 0.182880).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2048386
	speed: 0.2116s/iter; left time: 2484.9424s
Epoch: 17 cost time: 13.150719404220581
Epoch: 17, Steps: 141 | Train Loss: 0.2084029 Vali Loss: 0.1825738 Test Loss: 0.2095278
Validation loss decreased (0.182880 --> 0.182574).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2129224
	speed: 0.2159s/iter; left time: 2505.6285s
Epoch: 18 cost time: 13.517091989517212
Epoch: 18, Steps: 141 | Train Loss: 0.2080090 Vali Loss: 0.1823318 Test Loss: 0.2092665
Validation loss decreased (0.182574 --> 0.182332).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2022152
	speed: 0.2143s/iter; left time: 2456.7392s
Epoch: 19 cost time: 13.110050439834595
Epoch: 19, Steps: 141 | Train Loss: 0.2077410 Vali Loss: 0.1821620 Test Loss: 0.2090207
Validation loss decreased (0.182332 --> 0.182162).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2134050
	speed: 0.2130s/iter; left time: 2411.0872s
Epoch: 20 cost time: 13.07387924194336
Epoch: 20, Steps: 141 | Train Loss: 0.2075199 Vali Loss: 0.1819851 Test Loss: 0.2088115
Validation loss decreased (0.182162 --> 0.181985).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2144041
	speed: 0.2170s/iter; left time: 2426.1589s
Epoch: 21 cost time: 13.487646579742432
Epoch: 21, Steps: 141 | Train Loss: 0.2073322 Vali Loss: 0.1817651 Test Loss: 0.2086249
Validation loss decreased (0.181985 --> 0.181765).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2112920
	speed: 0.2148s/iter; left time: 2370.9073s
Epoch: 22 cost time: 13.1801016330719
Epoch: 22, Steps: 141 | Train Loss: 0.2071155 Vali Loss: 0.1817241 Test Loss: 0.2084640
Validation loss decreased (0.181765 --> 0.181724).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1982529
	speed: 0.2182s/iter; left time: 2378.5963s
Epoch: 23 cost time: 13.329214096069336
Epoch: 23, Steps: 141 | Train Loss: 0.2069435 Vali Loss: 0.1815818 Test Loss: 0.2083140
Validation loss decreased (0.181724 --> 0.181582).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2177931
	speed: 0.2125s/iter; left time: 2286.2408s
Epoch: 24 cost time: 13.01650881767273
Epoch: 24, Steps: 141 | Train Loss: 0.2068480 Vali Loss: 0.1814254 Test Loss: 0.2081898
Validation loss decreased (0.181582 --> 0.181425).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2142995
	speed: 0.2121s/iter; left time: 2251.7041s
Epoch: 25 cost time: 13.023496389389038
Epoch: 25, Steps: 141 | Train Loss: 0.2067362 Vali Loss: 0.1812835 Test Loss: 0.2080754
Validation loss decreased (0.181425 --> 0.181284).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2158374
	speed: 0.2168s/iter; left time: 2271.2733s
Epoch: 26 cost time: 13.101969480514526
Epoch: 26, Steps: 141 | Train Loss: 0.2066332 Vali Loss: 0.1811688 Test Loss: 0.2079742
Validation loss decreased (0.181284 --> 0.181169).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2087242
	speed: 0.2170s/iter; left time: 2243.0116s
Epoch: 27 cost time: 13.198321104049683
Epoch: 27, Steps: 141 | Train Loss: 0.2064692 Vali Loss: 0.1811312 Test Loss: 0.2078832
Validation loss decreased (0.181169 --> 0.181131).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2070698
	speed: 0.2120s/iter; left time: 2160.8484s
Epoch: 28 cost time: 13.333821773529053
Epoch: 28, Steps: 141 | Train Loss: 0.2064408 Vali Loss: 0.1811102 Test Loss: 0.2078101
Validation loss decreased (0.181131 --> 0.181110).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2008046
	speed: 0.2142s/iter; left time: 2153.3838s
Epoch: 29 cost time: 13.225369215011597
Epoch: 29, Steps: 141 | Train Loss: 0.2063446 Vali Loss: 0.1809882 Test Loss: 0.2077313
Validation loss decreased (0.181110 --> 0.180988).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2164937
	speed: 0.2168s/iter; left time: 2148.8488s
Epoch: 30 cost time: 13.257665395736694
Epoch: 30, Steps: 141 | Train Loss: 0.2062296 Vali Loss: 0.1809250 Test Loss: 0.2076646
Validation loss decreased (0.180988 --> 0.180925).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2034353
	speed: 0.2173s/iter; left time: 2123.4723s
Epoch: 31 cost time: 13.226785898208618
Epoch: 31, Steps: 141 | Train Loss: 0.2061401 Vali Loss: 0.1808570 Test Loss: 0.2076027
Validation loss decreased (0.180925 --> 0.180857).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2208643
	speed: 0.2126s/iter; left time: 2047.3683s
Epoch: 32 cost time: 13.034216403961182
Epoch: 32, Steps: 141 | Train Loss: 0.2060984 Vali Loss: 0.1807538 Test Loss: 0.2075493
Validation loss decreased (0.180857 --> 0.180754).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2156072
	speed: 0.2109s/iter; left time: 2001.1453s
Epoch: 33 cost time: 13.090961456298828
Epoch: 33, Steps: 141 | Train Loss: 0.2060530 Vali Loss: 0.1807708 Test Loss: 0.2075030
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2038413
	speed: 0.2127s/iter; left time: 1988.2001s
Epoch: 34 cost time: 13.0309157371521
Epoch: 34, Steps: 141 | Train Loss: 0.2060413 Vali Loss: 0.1807922 Test Loss: 0.2074618
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1956951
	speed: 0.2086s/iter; left time: 1920.3883s
Epoch: 35 cost time: 13.03642201423645
Epoch: 35, Steps: 141 | Train Loss: 0.2060268 Vali Loss: 0.1807811 Test Loss: 0.2074252
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2139785
	speed: 0.2165s/iter; left time: 1963.0263s
Epoch: 36 cost time: 13.122369766235352
Epoch: 36, Steps: 141 | Train Loss: 0.2059209 Vali Loss: 0.1805491 Test Loss: 0.2073910
Validation loss decreased (0.180754 --> 0.180549).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2077256
	speed: 0.2120s/iter; left time: 1892.2333s
Epoch: 37 cost time: 12.96156930923462
Epoch: 37, Steps: 141 | Train Loss: 0.2059151 Vali Loss: 0.1806725 Test Loss: 0.2073671
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2073427
	speed: 0.2169s/iter; left time: 1905.2216s
Epoch: 38 cost time: 13.629869937896729
Epoch: 38, Steps: 141 | Train Loss: 0.2058808 Vali Loss: 0.1805961 Test Loss: 0.2073348
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1974018
	speed: 0.2182s/iter; left time: 1886.3080s
Epoch: 39 cost time: 13.154423236846924
Epoch: 39, Steps: 141 | Train Loss: 0.2058154 Vali Loss: 0.1805456 Test Loss: 0.2073194
Validation loss decreased (0.180549 --> 0.180546).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2087882
	speed: 0.2144s/iter; left time: 1822.5391s
Epoch: 40 cost time: 13.10880446434021
Epoch: 40, Steps: 141 | Train Loss: 0.2058031 Vali Loss: 0.1804953 Test Loss: 0.2072927
Validation loss decreased (0.180546 --> 0.180495).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1879317
	speed: 0.2160s/iter; left time: 1805.5941s
Epoch: 41 cost time: 13.473463296890259
Epoch: 41, Steps: 141 | Train Loss: 0.2057698 Vali Loss: 0.1805965 Test Loss: 0.2072804
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2150099
	speed: 0.2142s/iter; left time: 1760.3413s
Epoch: 42 cost time: 13.09679889678955
Epoch: 42, Steps: 141 | Train Loss: 0.2058077 Vali Loss: 0.1805589 Test Loss: 0.2072591
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2069370
	speed: 0.2116s/iter; left time: 1709.2058s
Epoch: 43 cost time: 13.0176260471344
Epoch: 43, Steps: 141 | Train Loss: 0.2057997 Vali Loss: 0.1805291 Test Loss: 0.2072458
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2157231
	speed: 0.2158s/iter; left time: 1713.0329s
Epoch: 44 cost time: 13.283673286437988
Epoch: 44, Steps: 141 | Train Loss: 0.2057726 Vali Loss: 0.1805052 Test Loss: 0.2072330
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2012103
	speed: 0.2161s/iter; left time: 1684.8441s
Epoch: 45 cost time: 12.989912509918213
Epoch: 45, Steps: 141 | Train Loss: 0.2057845 Vali Loss: 0.1805955 Test Loss: 0.2072203
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2200820
	speed: 0.2122s/iter; left time: 1624.2999s
Epoch: 46 cost time: 12.852920055389404
Epoch: 46, Steps: 141 | Train Loss: 0.2058052 Vali Loss: 0.1805021 Test Loss: 0.2072101
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2134563
	speed: 0.2159s/iter; left time: 1622.2237s
Epoch: 47 cost time: 13.18411636352539
Epoch: 47, Steps: 141 | Train Loss: 0.2056460 Vali Loss: 0.1804914 Test Loss: 0.2072026
Validation loss decreased (0.180495 --> 0.180491).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2058746
	speed: 0.2136s/iter; left time: 1575.0975s
Epoch: 48 cost time: 13.45289421081543
Epoch: 48, Steps: 141 | Train Loss: 0.2056783 Vali Loss: 0.1804908 Test Loss: 0.2071924
Validation loss decreased (0.180491 --> 0.180491).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2120907
	speed: 0.2134s/iter; left time: 1543.5540s
Epoch: 49 cost time: 13.261043787002563
Epoch: 49, Steps: 141 | Train Loss: 0.2056987 Vali Loss: 0.1805204 Test Loss: 0.2071852
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1947686
	speed: 0.2126s/iter; left time: 1507.4401s
Epoch: 50 cost time: 13.124492168426514
Epoch: 50, Steps: 141 | Train Loss: 0.2057089 Vali Loss: 0.1805482 Test Loss: 0.2071794
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2148059
	speed: 0.2167s/iter; left time: 1506.0013s
Epoch: 51 cost time: 13.230144739151001
Epoch: 51, Steps: 141 | Train Loss: 0.2056112 Vali Loss: 0.1804131 Test Loss: 0.2071732
Validation loss decreased (0.180491 --> 0.180413).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2127889
	speed: 0.2169s/iter; left time: 1477.1460s
Epoch: 52 cost time: 13.451064348220825
Epoch: 52, Steps: 141 | Train Loss: 0.2055713 Vali Loss: 0.1804533 Test Loss: 0.2071671
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2123775
	speed: 0.2161s/iter; left time: 1440.8509s
Epoch: 53 cost time: 13.022363901138306
Epoch: 53, Steps: 141 | Train Loss: 0.2056759 Vali Loss: 0.1804907 Test Loss: 0.2071638
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1978994
	speed: 0.2145s/iter; left time: 1400.1985s
Epoch: 54 cost time: 13.133837461471558
Epoch: 54, Steps: 141 | Train Loss: 0.2055987 Vali Loss: 0.1804419 Test Loss: 0.2071587
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2068613
	speed: 0.2204s/iter; left time: 1407.8087s
Epoch: 55 cost time: 13.097862482070923
Epoch: 55, Steps: 141 | Train Loss: 0.2055885 Vali Loss: 0.1805359 Test Loss: 0.2071549
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2076669
	speed: 0.2176s/iter; left time: 1358.8700s
Epoch: 56 cost time: 13.458044528961182
Epoch: 56, Steps: 141 | Train Loss: 0.2056071 Vali Loss: 0.1804959 Test Loss: 0.2071519
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2084039
	speed: 0.2150s/iter; left time: 1312.6267s
Epoch: 57 cost time: 13.476255416870117
Epoch: 57, Steps: 141 | Train Loss: 0.2056906 Vali Loss: 0.1804880 Test Loss: 0.2071477
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2181761
	speed: 0.2203s/iter; left time: 1313.6306s
Epoch: 58 cost time: 13.274993181228638
Epoch: 58, Steps: 141 | Train Loss: 0.2055813 Vali Loss: 0.1804921 Test Loss: 0.2071448
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2029901
	speed: 0.2191s/iter; left time: 1275.8856s
Epoch: 59 cost time: 13.296800374984741
Epoch: 59, Steps: 141 | Train Loss: 0.2055693 Vali Loss: 0.1803294 Test Loss: 0.2071423
Validation loss decreased (0.180413 --> 0.180329).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1995886
	speed: 0.2159s/iter; left time: 1226.5594s
Epoch: 60 cost time: 13.325876951217651
Epoch: 60, Steps: 141 | Train Loss: 0.2056557 Vali Loss: 0.1804358 Test Loss: 0.2071398
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.2022908
	speed: 0.2131s/iter; left time: 1180.8888s
Epoch: 61 cost time: 13.257987022399902
Epoch: 61, Steps: 141 | Train Loss: 0.2056760 Vali Loss: 0.1804547 Test Loss: 0.2071396
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.2026243
	speed: 0.2163s/iter; left time: 1167.9630s
Epoch: 62 cost time: 13.539700269699097
Epoch: 62, Steps: 141 | Train Loss: 0.2055610 Vali Loss: 0.1804123 Test Loss: 0.2071367
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.2038568
	speed: 0.2172s/iter; left time: 1142.2106s
Epoch: 63 cost time: 13.634826421737671
Epoch: 63, Steps: 141 | Train Loss: 0.2056185 Vali Loss: 0.1804010 Test Loss: 0.2071350
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.2034908
	speed: 0.2202s/iter; left time: 1127.2288s
Epoch: 64 cost time: 13.278680086135864
Epoch: 64, Steps: 141 | Train Loss: 0.2055664 Vali Loss: 0.1804631 Test Loss: 0.2071338
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.2140447
	speed: 0.2183s/iter; left time: 1086.5976s
Epoch: 65 cost time: 13.246703863143921
Epoch: 65, Steps: 141 | Train Loss: 0.2056352 Vali Loss: 0.1803562 Test Loss: 0.2071321
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.2032470
	speed: 0.2188s/iter; left time: 1058.0855s
Epoch: 66 cost time: 13.283536911010742
Epoch: 66, Steps: 141 | Train Loss: 0.2055939 Vali Loss: 0.1805095 Test Loss: 0.2071303
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.2124613
	speed: 0.2139s/iter; left time: 1004.3992s
Epoch: 67 cost time: 13.104666709899902
Epoch: 67, Steps: 141 | Train Loss: 0.2056061 Vali Loss: 0.1804997 Test Loss: 0.2071291
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.2075168
	speed: 0.2128s/iter; left time: 969.2522s
Epoch: 68 cost time: 12.999443292617798
Epoch: 68, Steps: 141 | Train Loss: 0.2057084 Vali Loss: 0.1804834 Test Loss: 0.2071284
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.2048596
	speed: 0.2129s/iter; left time: 939.5731s
Epoch: 69 cost time: 12.867633581161499
Epoch: 69, Steps: 141 | Train Loss: 0.2056472 Vali Loss: 0.1804851 Test Loss: 0.2071282
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.2060424
	speed: 0.2105s/iter; left time: 899.3250s
Epoch: 70 cost time: 13.36571216583252
Epoch: 70, Steps: 141 | Train Loss: 0.2056094 Vali Loss: 0.1804871 Test Loss: 0.2071263
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.2100718
	speed: 0.2201s/iter; left time: 909.2790s
Epoch: 71 cost time: 13.231731176376343
Epoch: 71, Steps: 141 | Train Loss: 0.2056386 Vali Loss: 0.1803928 Test Loss: 0.2071254
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.2043274
	speed: 0.2191s/iter; left time: 874.3643s
Epoch: 72 cost time: 13.345718383789062
Epoch: 72, Steps: 141 | Train Loss: 0.2056071 Vali Loss: 0.1804069 Test Loss: 0.2071251
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.2100953
	speed: 0.2155s/iter; left time: 829.5783s
Epoch: 73 cost time: 13.2536461353302
Epoch: 73, Steps: 141 | Train Loss: 0.2056167 Vali Loss: 0.1804744 Test Loss: 0.2071249
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.2085848
	speed: 0.2141s/iter; left time: 793.8064s
Epoch: 74 cost time: 13.456764221191406
Epoch: 74, Steps: 141 | Train Loss: 0.2056531 Vali Loss: 0.1805380 Test Loss: 0.2071235
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.2121029
	speed: 0.2143s/iter; left time: 764.5086s
Epoch: 75 cost time: 13.119431495666504
Epoch: 75, Steps: 141 | Train Loss: 0.2056095 Vali Loss: 0.1803651 Test Loss: 0.2071227
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.2017917
	speed: 0.2163s/iter; left time: 741.0265s
Epoch: 76 cost time: 12.873609066009521
Epoch: 76, Steps: 141 | Train Loss: 0.2055567 Vali Loss: 0.1804390 Test Loss: 0.2071220
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.2012786
	speed: 0.2147s/iter; left time: 705.4013s
Epoch: 77 cost time: 13.230444192886353
Epoch: 77, Steps: 141 | Train Loss: 0.2055546 Vali Loss: 0.1804142 Test Loss: 0.2071223
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.2133075
	speed: 0.2115s/iter; left time: 665.0612s
Epoch: 78 cost time: 12.928422451019287
Epoch: 78, Steps: 141 | Train Loss: 0.2056343 Vali Loss: 0.1804304 Test Loss: 0.2071212
EarlyStopping counter: 19 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.2040984
	speed: 0.2109s/iter; left time: 633.2286s
Epoch: 79 cost time: 12.833147525787354
Epoch: 79, Steps: 141 | Train Loss: 0.2056454 Vali Loss: 0.1804200 Test Loss: 0.2071209
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_90_j192_H6_FITS_custom_ftM_sl90_ll48_pl192_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5069
mse:0.20479393005371094, mae:0.285179078578949, rse:0.4499465227127075, corr:[0.45936075 0.45846733 0.45757776 0.45618474 0.4555103  0.45483282
 0.45449394 0.45376432 0.45274624 0.45173702 0.45095742 0.4504517
 0.45019    0.44950232 0.44950262 0.44898927 0.44904846 0.449314
 0.44928268 0.44932276 0.4491349  0.44922638 0.44910488 0.4479359
 0.4458623  0.4445414  0.44321218 0.44218037 0.44180578 0.44174513
 0.44257674 0.44280154 0.44228622 0.4419536  0.44145647 0.441095
 0.44109946 0.44062102 0.4405984  0.44025892 0.44013315 0.44016096
 0.4401022  0.44019935 0.44023746 0.44046187 0.44039965 0.44004253
 0.43910155 0.4387344  0.43859136 0.4387728  0.43974558 0.4411229
 0.44332498 0.44486868 0.4449552  0.44497123 0.44482997 0.44459036
 0.44460794 0.44427115 0.44449165 0.44454345 0.44465107 0.44494602
 0.44519404 0.44532248 0.44556555 0.44609305 0.44639403 0.44671732
 0.44690165 0.44745216 0.44807673 0.44916493 0.45107877 0.45359573
 0.45683482 0.45941222 0.45981053 0.45958057 0.45920646 0.45882198
 0.4586696  0.4582821  0.45853192 0.45853522 0.45872718 0.4590975
 0.4592076  0.45924067 0.45921943 0.45929813 0.4593899  0.45937166
 0.45917013 0.4591766  0.45902675 0.45900962 0.45908618 0.45916075
 0.45956796 0.45972237 0.45938423 0.45911938 0.45879528 0.45854437
 0.45856318 0.45826313 0.4584664  0.45848152 0.45854408 0.45880145
 0.45890033 0.45899844 0.4590829  0.4592279  0.45930362 0.45937634
 0.4592361  0.45923737 0.45910126 0.45909572 0.45912892 0.4591058
 0.4593352  0.459326   0.45902294 0.458875   0.45862898 0.45839658
 0.45848003 0.45826116 0.45853126 0.4585926  0.4586961  0.45903346
 0.4590997  0.4591108  0.45912302 0.45917356 0.45909446 0.45892355
 0.4586247  0.45847893 0.45834434 0.4583524  0.45840344 0.4585115
 0.45880878 0.45891625 0.45864776 0.4584228  0.45815918 0.4579136
 0.45800486 0.4578204  0.4581482  0.45825034 0.4584559  0.4588945
 0.45892268 0.45886257 0.45847064 0.45812163 0.45724013 0.4547571
 0.4520501  0.44975057 0.44812065 0.44690365 0.4457313  0.44535536
 0.44532216 0.44522843 0.44514796 0.44463924 0.4445783  0.44444215
 0.4441458  0.4437589  0.44350374 0.44265842 0.44252598 0.44243124
 0.44165727 0.44170558 0.44118473 0.4413788  0.44161478 0.4417538 ]
