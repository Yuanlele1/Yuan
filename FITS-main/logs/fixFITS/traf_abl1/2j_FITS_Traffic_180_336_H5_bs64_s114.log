Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=50, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_180_j336_H5', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=10, pred_len=336, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_180_j336_H5_FITS_custom_ftM_sl180_ll48_pl336_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11765
val 1421
test 3173
Model(
  (freq_upsampler): Linear(in_features=50, out_features=143, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  788902400.0
params:  7293.0
Trainable parameters:  7293
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 73.65429902076721
Epoch: 1, Steps: 91 | Train Loss: 1.3143137 Vali Loss: 1.3020742 Test Loss: 1.5684360
Validation loss decreased (inf --> 1.302074).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 70.77766752243042
Epoch: 2, Steps: 91 | Train Loss: 0.8270549 Vali Loss: 0.9874045 Test Loss: 1.1957988
Validation loss decreased (1.302074 --> 0.987404).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 72.28813672065735
Epoch: 3, Steps: 91 | Train Loss: 0.6249784 Vali Loss: 0.8210841 Test Loss: 1.0006427
Validation loss decreased (0.987404 --> 0.821084).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 72.52846479415894
Epoch: 4, Steps: 91 | Train Loss: 0.5159483 Vali Loss: 0.7219539 Test Loss: 0.8855709
Validation loss decreased (0.821084 --> 0.721954).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 71.52774024009705
Epoch: 5, Steps: 91 | Train Loss: 0.4505189 Vali Loss: 0.6601219 Test Loss: 0.8123615
Validation loss decreased (0.721954 --> 0.660122).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 68.94530487060547
Epoch: 6, Steps: 91 | Train Loss: 0.4081207 Vali Loss: 0.6173339 Test Loss: 0.7621298
Validation loss decreased (0.660122 --> 0.617334).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 73.41509413719177
Epoch: 7, Steps: 91 | Train Loss: 0.3782471 Vali Loss: 0.5863101 Test Loss: 0.7252992
Validation loss decreased (0.617334 --> 0.586310).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 72.2792158126831
Epoch: 8, Steps: 91 | Train Loss: 0.3558222 Vali Loss: 0.5623317 Test Loss: 0.6965863
Validation loss decreased (0.586310 --> 0.562332).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 69.28487968444824
Epoch: 9, Steps: 91 | Train Loss: 0.3381394 Vali Loss: 0.5437548 Test Loss: 0.6733739
Validation loss decreased (0.562332 --> 0.543755).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 72.09822654724121
Epoch: 10, Steps: 91 | Train Loss: 0.3238940 Vali Loss: 0.5277181 Test Loss: 0.6538966
Validation loss decreased (0.543755 --> 0.527718).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 72.86919379234314
Epoch: 11, Steps: 91 | Train Loss: 0.3117907 Vali Loss: 0.5142746 Test Loss: 0.6373849
Validation loss decreased (0.527718 --> 0.514275).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 71.48787355422974
Epoch: 12, Steps: 91 | Train Loss: 0.3015482 Vali Loss: 0.5029369 Test Loss: 0.6230544
Validation loss decreased (0.514275 --> 0.502937).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 68.94690418243408
Epoch: 13, Steps: 91 | Train Loss: 0.2927786 Vali Loss: 0.4927297 Test Loss: 0.6106723
Validation loss decreased (0.502937 --> 0.492730).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 75.44591164588928
Epoch: 14, Steps: 91 | Train Loss: 0.2850277 Vali Loss: 0.4840545 Test Loss: 0.5997961
Validation loss decreased (0.492730 --> 0.484054).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 71.74788904190063
Epoch: 15, Steps: 91 | Train Loss: 0.2782598 Vali Loss: 0.4769964 Test Loss: 0.5904047
Validation loss decreased (0.484054 --> 0.476996).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 73.40975618362427
Epoch: 16, Steps: 91 | Train Loss: 0.2723369 Vali Loss: 0.4696503 Test Loss: 0.5817569
Validation loss decreased (0.476996 --> 0.469650).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 76.68270921707153
Epoch: 17, Steps: 91 | Train Loss: 0.2669947 Vali Loss: 0.4640835 Test Loss: 0.5741944
Validation loss decreased (0.469650 --> 0.464083).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 72.5857503414154
Epoch: 18, Steps: 91 | Train Loss: 0.2622681 Vali Loss: 0.4581913 Test Loss: 0.5675635
Validation loss decreased (0.464083 --> 0.458191).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 69.64609384536743
Epoch: 19, Steps: 91 | Train Loss: 0.2580282 Vali Loss: 0.4534206 Test Loss: 0.5614662
Validation loss decreased (0.458191 --> 0.453421).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 71.81020545959473
Epoch: 20, Steps: 91 | Train Loss: 0.2541919 Vali Loss: 0.4494077 Test Loss: 0.5560179
Validation loss decreased (0.453421 --> 0.449408).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 72.96849822998047
Epoch: 21, Steps: 91 | Train Loss: 0.2507299 Vali Loss: 0.4455307 Test Loss: 0.5510228
Validation loss decreased (0.449408 --> 0.445531).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 71.45167994499207
Epoch: 22, Steps: 91 | Train Loss: 0.2476329 Vali Loss: 0.4417334 Test Loss: 0.5466149
Validation loss decreased (0.445531 --> 0.441733).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 74.20354342460632
Epoch: 23, Steps: 91 | Train Loss: 0.2447905 Vali Loss: 0.4382470 Test Loss: 0.5425137
Validation loss decreased (0.441733 --> 0.438247).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 77.06948733329773
Epoch: 24, Steps: 91 | Train Loss: 0.2422480 Vali Loss: 0.4355097 Test Loss: 0.5388402
Validation loss decreased (0.438247 --> 0.435510).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 71.51978969573975
Epoch: 25, Steps: 91 | Train Loss: 0.2398428 Vali Loss: 0.4327398 Test Loss: 0.5355254
Validation loss decreased (0.435510 --> 0.432740).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 72.37240695953369
Epoch: 26, Steps: 91 | Train Loss: 0.2377760 Vali Loss: 0.4302741 Test Loss: 0.5324322
Validation loss decreased (0.432740 --> 0.430274).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 77.81852722167969
Epoch: 27, Steps: 91 | Train Loss: 0.2357135 Vali Loss: 0.4278391 Test Loss: 0.5295473
Validation loss decreased (0.430274 --> 0.427839).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 70.34648203849792
Epoch: 28, Steps: 91 | Train Loss: 0.2339546 Vali Loss: 0.4259918 Test Loss: 0.5268579
Validation loss decreased (0.427839 --> 0.425992).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 68.68380880355835
Epoch: 29, Steps: 91 | Train Loss: 0.2322349 Vali Loss: 0.4241979 Test Loss: 0.5244655
Validation loss decreased (0.425992 --> 0.424198).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 74.26161408424377
Epoch: 30, Steps: 91 | Train Loss: 0.2307610 Vali Loss: 0.4223687 Test Loss: 0.5223203
Validation loss decreased (0.424198 --> 0.422369).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 71.39664483070374
Epoch: 31, Steps: 91 | Train Loss: 0.2293390 Vali Loss: 0.4203131 Test Loss: 0.5202307
Validation loss decreased (0.422369 --> 0.420313).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 73.25111627578735
Epoch: 32, Steps: 91 | Train Loss: 0.2280065 Vali Loss: 0.4190087 Test Loss: 0.5183761
Validation loss decreased (0.420313 --> 0.419009).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 78.13496947288513
Epoch: 33, Steps: 91 | Train Loss: 0.2268832 Vali Loss: 0.4177532 Test Loss: 0.5166122
Validation loss decreased (0.419009 --> 0.417753).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 73.34372234344482
Epoch: 34, Steps: 91 | Train Loss: 0.2257042 Vali Loss: 0.4165095 Test Loss: 0.5150225
Validation loss decreased (0.417753 --> 0.416510).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 75.03578925132751
Epoch: 35, Steps: 91 | Train Loss: 0.2246796 Vali Loss: 0.4151426 Test Loss: 0.5135610
Validation loss decreased (0.416510 --> 0.415143).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 72.11020565032959
Epoch: 36, Steps: 91 | Train Loss: 0.2237681 Vali Loss: 0.4139310 Test Loss: 0.5121431
Validation loss decreased (0.415143 --> 0.413931).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 69.60977721214294
Epoch: 37, Steps: 91 | Train Loss: 0.2227978 Vali Loss: 0.4128544 Test Loss: 0.5108587
Validation loss decreased (0.413931 --> 0.412854).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 72.7365083694458
Epoch: 38, Steps: 91 | Train Loss: 0.2220099 Vali Loss: 0.4119350 Test Loss: 0.5095886
Validation loss decreased (0.412854 --> 0.411935).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 76.18381142616272
Epoch: 39, Steps: 91 | Train Loss: 0.2211980 Vali Loss: 0.4108682 Test Loss: 0.5084509
Validation loss decreased (0.411935 --> 0.410868).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 75.77120733261108
Epoch: 40, Steps: 91 | Train Loss: 0.2204389 Vali Loss: 0.4099333 Test Loss: 0.5074121
Validation loss decreased (0.410868 --> 0.409933).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 75.13656902313232
Epoch: 41, Steps: 91 | Train Loss: 0.2198016 Vali Loss: 0.4093509 Test Loss: 0.5063926
Validation loss decreased (0.409933 --> 0.409351).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 78.02582383155823
Epoch: 42, Steps: 91 | Train Loss: 0.2191628 Vali Loss: 0.4083887 Test Loss: 0.5055088
Validation loss decreased (0.409351 --> 0.408389).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 75.98779726028442
Epoch: 43, Steps: 91 | Train Loss: 0.2184926 Vali Loss: 0.4078299 Test Loss: 0.5046521
Validation loss decreased (0.408389 --> 0.407830).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 68.84393525123596
Epoch: 44, Steps: 91 | Train Loss: 0.2179679 Vali Loss: 0.4071478 Test Loss: 0.5038077
Validation loss decreased (0.407830 --> 0.407148).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 69.96558332443237
Epoch: 45, Steps: 91 | Train Loss: 0.2174047 Vali Loss: 0.4062248 Test Loss: 0.5030724
Validation loss decreased (0.407148 --> 0.406225).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 69.30203652381897
Epoch: 46, Steps: 91 | Train Loss: 0.2169301 Vali Loss: 0.4055171 Test Loss: 0.5023446
Validation loss decreased (0.406225 --> 0.405517).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 69.21430277824402
Epoch: 47, Steps: 91 | Train Loss: 0.2164898 Vali Loss: 0.4054576 Test Loss: 0.5017034
Validation loss decreased (0.405517 --> 0.405458).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 76.37374305725098
Epoch: 48, Steps: 91 | Train Loss: 0.2160410 Vali Loss: 0.4047567 Test Loss: 0.5010622
Validation loss decreased (0.405458 --> 0.404757).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 73.55797052383423
Epoch: 49, Steps: 91 | Train Loss: 0.2156574 Vali Loss: 0.4043669 Test Loss: 0.5004962
Validation loss decreased (0.404757 --> 0.404367).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 74.7617244720459
Epoch: 50, Steps: 91 | Train Loss: 0.2152527 Vali Loss: 0.4039596 Test Loss: 0.4999004
Validation loss decreased (0.404367 --> 0.403960).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 76.27492547035217
Epoch: 51, Steps: 91 | Train Loss: 0.2148442 Vali Loss: 0.4034766 Test Loss: 0.4993911
Validation loss decreased (0.403960 --> 0.403477).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 74.11125469207764
Epoch: 52, Steps: 91 | Train Loss: 0.2145364 Vali Loss: 0.4028322 Test Loss: 0.4989251
Validation loss decreased (0.403477 --> 0.402832).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 70.42326045036316
Epoch: 53, Steps: 91 | Train Loss: 0.2142584 Vali Loss: 0.4028441 Test Loss: 0.4984421
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 71.16799902915955
Epoch: 54, Steps: 91 | Train Loss: 0.2139300 Vali Loss: 0.4024282 Test Loss: 0.4980133
Validation loss decreased (0.402832 --> 0.402428).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 73.9129593372345
Epoch: 55, Steps: 91 | Train Loss: 0.2136665 Vali Loss: 0.4020763 Test Loss: 0.4976276
Validation loss decreased (0.402428 --> 0.402076).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 66.28841781616211
Epoch: 56, Steps: 91 | Train Loss: 0.2133132 Vali Loss: 0.4017910 Test Loss: 0.4972509
Validation loss decreased (0.402076 --> 0.401791).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 74.3021469116211
Epoch: 57, Steps: 91 | Train Loss: 0.2130951 Vali Loss: 0.4012547 Test Loss: 0.4968677
Validation loss decreased (0.401791 --> 0.401255).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 73.63466548919678
Epoch: 58, Steps: 91 | Train Loss: 0.2128717 Vali Loss: 0.4010306 Test Loss: 0.4965264
Validation loss decreased (0.401255 --> 0.401031).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 69.58185386657715
Epoch: 59, Steps: 91 | Train Loss: 0.2126591 Vali Loss: 0.4005472 Test Loss: 0.4961986
Validation loss decreased (0.401031 --> 0.400547).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 72.5689525604248
Epoch: 60, Steps: 91 | Train Loss: 0.2124405 Vali Loss: 0.4006126 Test Loss: 0.4958797
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 75.26594519615173
Epoch: 61, Steps: 91 | Train Loss: 0.2122242 Vali Loss: 0.4003660 Test Loss: 0.4955986
Validation loss decreased (0.400547 --> 0.400366).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 69.98794102668762
Epoch: 62, Steps: 91 | Train Loss: 0.2119969 Vali Loss: 0.4001919 Test Loss: 0.4953279
Validation loss decreased (0.400366 --> 0.400192).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 74.36877155303955
Epoch: 63, Steps: 91 | Train Loss: 0.2118296 Vali Loss: 0.3998796 Test Loss: 0.4950729
Validation loss decreased (0.400192 --> 0.399880).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 75.69521999359131
Epoch: 64, Steps: 91 | Train Loss: 0.2117051 Vali Loss: 0.3995356 Test Loss: 0.4948213
Validation loss decreased (0.399880 --> 0.399536).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 71.3380663394928
Epoch: 65, Steps: 91 | Train Loss: 0.2115595 Vali Loss: 0.3997530 Test Loss: 0.4945778
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 72.87987399101257
Epoch: 66, Steps: 91 | Train Loss: 0.2114029 Vali Loss: 0.3990874 Test Loss: 0.4943621
Validation loss decreased (0.399536 --> 0.399087).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 75.70502495765686
Epoch: 67, Steps: 91 | Train Loss: 0.2111783 Vali Loss: 0.3988690 Test Loss: 0.4941493
Validation loss decreased (0.399087 --> 0.398869).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 72.64598941802979
Epoch: 68, Steps: 91 | Train Loss: 0.2110751 Vali Loss: 0.3988810 Test Loss: 0.4939615
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 72.3357207775116
Epoch: 69, Steps: 91 | Train Loss: 0.2109575 Vali Loss: 0.3989274 Test Loss: 0.4937724
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 70.55500268936157
Epoch: 70, Steps: 91 | Train Loss: 0.2107534 Vali Loss: 0.3986346 Test Loss: 0.4936149
Validation loss decreased (0.398869 --> 0.398635).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 64.92593693733215
Epoch: 71, Steps: 91 | Train Loss: 0.2107223 Vali Loss: 0.3987777 Test Loss: 0.4934396
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 66.66845870018005
Epoch: 72, Steps: 91 | Train Loss: 0.2106263 Vali Loss: 0.3982536 Test Loss: 0.4932803
Validation loss decreased (0.398635 --> 0.398254).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 71.65266442298889
Epoch: 73, Steps: 91 | Train Loss: 0.2104669 Vali Loss: 0.3983774 Test Loss: 0.4931321
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 63.59954619407654
Epoch: 74, Steps: 91 | Train Loss: 0.2104265 Vali Loss: 0.3984532 Test Loss: 0.4929923
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 52.66402864456177
Epoch: 75, Steps: 91 | Train Loss: 0.2102730 Vali Loss: 0.3978123 Test Loss: 0.4928522
Validation loss decreased (0.398254 --> 0.397812).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 56.419339179992676
Epoch: 76, Steps: 91 | Train Loss: 0.2101944 Vali Loss: 0.3978331 Test Loss: 0.4927219
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 52.245259046554565
Epoch: 77, Steps: 91 | Train Loss: 0.2100492 Vali Loss: 0.3979221 Test Loss: 0.4926013
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 53.7657516002655
Epoch: 78, Steps: 91 | Train Loss: 0.2100949 Vali Loss: 0.3974926 Test Loss: 0.4924890
Validation loss decreased (0.397812 --> 0.397493).  Saving model ...
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 56.12382102012634
Epoch: 79, Steps: 91 | Train Loss: 0.2099026 Vali Loss: 0.3975753 Test Loss: 0.4923740
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 52.360201597213745
Epoch: 80, Steps: 91 | Train Loss: 0.2098511 Vali Loss: 0.3971977 Test Loss: 0.4922749
Validation loss decreased (0.397493 --> 0.397198).  Saving model ...
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 53.75768041610718
Epoch: 81, Steps: 91 | Train Loss: 0.2098465 Vali Loss: 0.3974307 Test Loss: 0.4921817
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 56.479247093200684
Epoch: 82, Steps: 91 | Train Loss: 0.2097428 Vali Loss: 0.3973745 Test Loss: 0.4920845
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 53.04746961593628
Epoch: 83, Steps: 91 | Train Loss: 0.2097552 Vali Loss: 0.3972395 Test Loss: 0.4920049
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 50.147186279296875
Epoch: 84, Steps: 91 | Train Loss: 0.2095466 Vali Loss: 0.3968077 Test Loss: 0.4919116
Validation loss decreased (0.397198 --> 0.396808).  Saving model ...
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 54.54807710647583
Epoch: 85, Steps: 91 | Train Loss: 0.2095329 Vali Loss: 0.3968115 Test Loss: 0.4918372
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 52.484742164611816
Epoch: 86, Steps: 91 | Train Loss: 0.2094930 Vali Loss: 0.3970507 Test Loss: 0.4917570
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 54.82925844192505
Epoch: 87, Steps: 91 | Train Loss: 0.2094582 Vali Loss: 0.3968888 Test Loss: 0.4916902
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 57.49073934555054
Epoch: 88, Steps: 91 | Train Loss: 0.2093362 Vali Loss: 0.3969762 Test Loss: 0.4916184
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 53.98543882369995
Epoch: 89, Steps: 91 | Train Loss: 0.2093782 Vali Loss: 0.3967665 Test Loss: 0.4915518
Validation loss decreased (0.396808 --> 0.396766).  Saving model ...
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 53.9467933177948
Epoch: 90, Steps: 91 | Train Loss: 0.2092890 Vali Loss: 0.3968825 Test Loss: 0.4914912
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 55.48668360710144
Epoch: 91, Steps: 91 | Train Loss: 0.2092157 Vali Loss: 0.3966352 Test Loss: 0.4914356
Validation loss decreased (0.396766 --> 0.396635).  Saving model ...
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 57.05708932876587
Epoch: 92, Steps: 91 | Train Loss: 0.2092391 Vali Loss: 0.3966332 Test Loss: 0.4913769
Validation loss decreased (0.396635 --> 0.396633).  Saving model ...
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 54.08324122428894
Epoch: 93, Steps: 91 | Train Loss: 0.2091609 Vali Loss: 0.3964740 Test Loss: 0.4913227
Validation loss decreased (0.396633 --> 0.396474).  Saving model ...
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 58.989973306655884
Epoch: 94, Steps: 91 | Train Loss: 0.2091588 Vali Loss: 0.3968145 Test Loss: 0.4912765
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 56.612191915512085
Epoch: 95, Steps: 91 | Train Loss: 0.2091313 Vali Loss: 0.3964918 Test Loss: 0.4912251
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 53.505218505859375
Epoch: 96, Steps: 91 | Train Loss: 0.2090536 Vali Loss: 0.3966322 Test Loss: 0.4911838
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 51.60826659202576
Epoch: 97, Steps: 91 | Train Loss: 0.2090085 Vali Loss: 0.3963664 Test Loss: 0.4911437
Validation loss decreased (0.396474 --> 0.396366).  Saving model ...
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 42.907551288604736
Epoch: 98, Steps: 91 | Train Loss: 0.2090597 Vali Loss: 0.3963181 Test Loss: 0.4911037
Validation loss decreased (0.396366 --> 0.396318).  Saving model ...
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 54.73241901397705
Epoch: 99, Steps: 91 | Train Loss: 0.2089838 Vali Loss: 0.3960435 Test Loss: 0.4910590
Validation loss decreased (0.396318 --> 0.396043).  Saving model ...
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 57.01192021369934
Epoch: 100, Steps: 91 | Train Loss: 0.2089319 Vali Loss: 0.3963634 Test Loss: 0.4910245
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.1160680107021042e-06
train 11765
val 1421
test 3173
Model(
  (freq_upsampler): Linear(in_features=50, out_features=143, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  788902400.0
params:  7293.0
Trainable parameters:  7293
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 52.955511808395386
Epoch: 1, Steps: 91 | Train Loss: 0.2957611 Vali Loss: 0.3891089 Test Loss: 0.4836142
Validation loss decreased (inf --> 0.389109).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 48.92706918716431
Epoch: 2, Steps: 91 | Train Loss: 0.2933150 Vali Loss: 0.3888007 Test Loss: 0.4829510
Validation loss decreased (0.389109 --> 0.388801).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 51.40338182449341
Epoch: 3, Steps: 91 | Train Loss: 0.2929141 Vali Loss: 0.3881392 Test Loss: 0.4831263
Validation loss decreased (0.388801 --> 0.388139).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 54.53635907173157
Epoch: 4, Steps: 91 | Train Loss: 0.2929143 Vali Loss: 0.3882537 Test Loss: 0.4829725
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 49.15331244468689
Epoch: 5, Steps: 91 | Train Loss: 0.2926616 Vali Loss: 0.3880498 Test Loss: 0.4826368
Validation loss decreased (0.388139 --> 0.388050).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 51.2219877243042
Epoch: 6, Steps: 91 | Train Loss: 0.2927296 Vali Loss: 0.3883515 Test Loss: 0.4828492
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 51.779497146606445
Epoch: 7, Steps: 91 | Train Loss: 0.2927160 Vali Loss: 0.3881132 Test Loss: 0.4829194
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 52.383148431777954
Epoch: 8, Steps: 91 | Train Loss: 0.2927513 Vali Loss: 0.3879175 Test Loss: 0.4826854
Validation loss decreased (0.388050 --> 0.387918).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 50.822686195373535
Epoch: 9, Steps: 91 | Train Loss: 0.2926944 Vali Loss: 0.3879854 Test Loss: 0.4827144
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 52.68488383293152
Epoch: 10, Steps: 91 | Train Loss: 0.2926885 Vali Loss: 0.3879788 Test Loss: 0.4828276
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 52.10603094100952
Epoch: 11, Steps: 91 | Train Loss: 0.2926665 Vali Loss: 0.3882395 Test Loss: 0.4827909
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 48.6743597984314
Epoch: 12, Steps: 91 | Train Loss: 0.2927239 Vali Loss: 0.3884852 Test Loss: 0.4826866
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 48.0723078250885
Epoch: 13, Steps: 91 | Train Loss: 0.2926705 Vali Loss: 0.3878707 Test Loss: 0.4827054
Validation loss decreased (0.387918 --> 0.387871).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 46.55044388771057
Epoch: 14, Steps: 91 | Train Loss: 0.2926404 Vali Loss: 0.3879609 Test Loss: 0.4826957
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 49.454636335372925
Epoch: 15, Steps: 91 | Train Loss: 0.2926275 Vali Loss: 0.3879333 Test Loss: 0.4825827
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 47.739052534103394
Epoch: 16, Steps: 91 | Train Loss: 0.2925632 Vali Loss: 0.3883084 Test Loss: 0.4827581
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 56.947240591049194
Epoch: 17, Steps: 91 | Train Loss: 0.2925913 Vali Loss: 0.3879399 Test Loss: 0.4827207
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 51.405688524246216
Epoch: 18, Steps: 91 | Train Loss: 0.2926017 Vali Loss: 0.3880634 Test Loss: 0.4826605
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 65.27859783172607
Epoch: 19, Steps: 91 | Train Loss: 0.2925615 Vali Loss: 0.3879775 Test Loss: 0.4826036
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 56.54865550994873
Epoch: 20, Steps: 91 | Train Loss: 0.2925597 Vali Loss: 0.3880880 Test Loss: 0.4826594
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 52.92456412315369
Epoch: 21, Steps: 91 | Train Loss: 0.2926756 Vali Loss: 0.3878496 Test Loss: 0.4825319
Validation loss decreased (0.387871 --> 0.387850).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 55.78918504714966
Epoch: 22, Steps: 91 | Train Loss: 0.2925256 Vali Loss: 0.3878963 Test Loss: 0.4826520
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 51.3111617565155
Epoch: 23, Steps: 91 | Train Loss: 0.2925899 Vali Loss: 0.3878916 Test Loss: 0.4825824
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 52.59732913970947
Epoch: 24, Steps: 91 | Train Loss: 0.2926389 Vali Loss: 0.3880744 Test Loss: 0.4825053
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 55.49924635887146
Epoch: 25, Steps: 91 | Train Loss: 0.2925729 Vali Loss: 0.3881286 Test Loss: 0.4826223
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 49.19783663749695
Epoch: 26, Steps: 91 | Train Loss: 0.2925731 Vali Loss: 0.3880789 Test Loss: 0.4825777
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 54.05401921272278
Epoch: 27, Steps: 91 | Train Loss: 0.2925601 Vali Loss: 0.3877518 Test Loss: 0.4826021
Validation loss decreased (0.387850 --> 0.387752).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 52.64643359184265
Epoch: 28, Steps: 91 | Train Loss: 0.2925065 Vali Loss: 0.3881107 Test Loss: 0.4826066
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 50.39217209815979
Epoch: 29, Steps: 91 | Train Loss: 0.2924881 Vali Loss: 0.3878618 Test Loss: 0.4825214
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 54.12061095237732
Epoch: 30, Steps: 91 | Train Loss: 0.2925830 Vali Loss: 0.3878685 Test Loss: 0.4826468
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 54.77585005760193
Epoch: 31, Steps: 91 | Train Loss: 0.2925107 Vali Loss: 0.3880302 Test Loss: 0.4824958
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 49.724825859069824
Epoch: 32, Steps: 91 | Train Loss: 0.2924182 Vali Loss: 0.3878184 Test Loss: 0.4824847
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 52.700390338897705
Epoch: 33, Steps: 91 | Train Loss: 0.2925420 Vali Loss: 0.3879813 Test Loss: 0.4826385
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 55.33035588264465
Epoch: 34, Steps: 91 | Train Loss: 0.2924378 Vali Loss: 0.3878440 Test Loss: 0.4825255
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 50.450995683670044
Epoch: 35, Steps: 91 | Train Loss: 0.2925112 Vali Loss: 0.3876151 Test Loss: 0.4825227
Validation loss decreased (0.387752 --> 0.387615).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 54.67087244987488
Epoch: 36, Steps: 91 | Train Loss: 0.2924312 Vali Loss: 0.3881123 Test Loss: 0.4825049
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 54.35961866378784
Epoch: 37, Steps: 91 | Train Loss: 0.2923905 Vali Loss: 0.3879704 Test Loss: 0.4825607
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 50.32376408576965
Epoch: 38, Steps: 91 | Train Loss: 0.2924930 Vali Loss: 0.3882834 Test Loss: 0.4825556
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 52.75953650474548
Epoch: 39, Steps: 91 | Train Loss: 0.2924743 Vali Loss: 0.3879037 Test Loss: 0.4824992
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 54.27904677391052
Epoch: 40, Steps: 91 | Train Loss: 0.2925347 Vali Loss: 0.3880578 Test Loss: 0.4824768
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 51.70224070549011
Epoch: 41, Steps: 91 | Train Loss: 0.2925408 Vali Loss: 0.3882138 Test Loss: 0.4826314
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 53.47719621658325
Epoch: 42, Steps: 91 | Train Loss: 0.2923925 Vali Loss: 0.3878037 Test Loss: 0.4825370
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 46.44249176979065
Epoch: 43, Steps: 91 | Train Loss: 0.2924515 Vali Loss: 0.3880547 Test Loss: 0.4825336
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 47.39835071563721
Epoch: 44, Steps: 91 | Train Loss: 0.2924099 Vali Loss: 0.3879592 Test Loss: 0.4825520
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 49.85871386528015
Epoch: 45, Steps: 91 | Train Loss: 0.2924097 Vali Loss: 0.3879669 Test Loss: 0.4825412
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : Traffic_180_j336_H5_FITS_custom_ftM_sl180_ll48_pl336_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3173
mse:0.4805985391139984, mae:0.3139406442642212, rse:0.5697581171989441, corr:[0.27740386 0.28358737 0.28456467 0.28349775 0.28326315 0.28379476
 0.28342205 0.28313416 0.28328896 0.28336662 0.28335327 0.2830717
 0.2827843  0.28300744 0.28281647 0.28248826 0.28269666 0.2827523
 0.282465   0.28252256 0.2829905  0.28382728 0.28436565 0.28385496
 0.2832572  0.28264296 0.28257826 0.2823253  0.28219688 0.28271666
 0.2830015  0.28285617 0.2829339  0.2832264  0.28346497 0.28335646
 0.28276598 0.28220132 0.28206268 0.28216475 0.2821858  0.28236184
 0.2825609  0.28241113 0.28225788 0.28237894 0.282439   0.2822778
 0.2820575  0.2817289  0.28182665 0.28214857 0.2823517  0.28260273
 0.28274462 0.28259128 0.28249574 0.28262562 0.28260058 0.28231046
 0.28201604 0.28196898 0.2822356  0.28249297 0.28229246 0.28186688
 0.28187415 0.28196418 0.28199133 0.28214616 0.2821552  0.28189194
 0.28153414 0.2812993  0.2813703  0.2816407  0.2818328  0.2818311
 0.2817688  0.2817109  0.28167635 0.28172898 0.28177753 0.2816622
 0.2814093  0.28114754 0.2810404  0.281239   0.28150412 0.28148338
 0.2813475  0.2812197  0.28123474 0.28145787 0.28158677 0.2813965
 0.28109497 0.28104535 0.28120804 0.28124848 0.28121403 0.2811527
 0.28096062 0.28078917 0.2808288  0.28098285 0.2811322  0.28116113
 0.28100345 0.28089035 0.28085634 0.28091985 0.28101096 0.28104493
 0.28106555 0.28099814 0.28081864 0.28062984 0.2806303  0.28069717
 0.2808186  0.28089896 0.28105953 0.28104874 0.28082713 0.28071377
 0.28063238 0.280516   0.28053755 0.28060108 0.28075925 0.28121898
 0.28161204 0.2818121  0.2815527  0.2813675  0.2814424  0.28147143
 0.28147003 0.28141388 0.28138542 0.2818968  0.2825106  0.28248587
 0.28231797 0.28206682 0.2820297  0.28206623 0.28201357 0.2820598
 0.28193566 0.2816478  0.28159416 0.28165528 0.2819386  0.28292352
 0.28406674 0.28484473 0.28426537 0.28347418 0.2830654  0.28270748
 0.2829531  0.2835903  0.28410926 0.2853039  0.2864866  0.2860144
 0.28488892 0.2835704  0.28314254 0.28296667 0.2828884  0.28320605
 0.2832578  0.28317457 0.28344896 0.2836095  0.2835963  0.28371924
 0.28378668 0.28387022 0.28362384 0.28339022 0.28317866 0.282929
 0.28270206 0.28251743 0.28266674 0.2834543  0.28404665 0.28369805
 0.2830834  0.28245515 0.28244564 0.28261134 0.28253928 0.28262502
 0.28279224 0.28280994 0.2828731  0.28298903 0.28297624 0.28287065
 0.28258023 0.2821226  0.28169635 0.28171912 0.28188857 0.2818788
 0.28174454 0.2814886  0.2812846  0.28137827 0.28143167 0.2813063
 0.2813376  0.28140134 0.28150213 0.2815446  0.28155488 0.2816259
 0.2817607  0.28182486 0.28175756 0.2817297  0.28174108 0.2816316
 0.28147858 0.28140584 0.28126374 0.28102633 0.28089023 0.2808338
 0.28079522 0.2808262  0.2809459  0.28102463 0.2811715  0.2812029
 0.28096455 0.28070015 0.28079593 0.28105116 0.28124604 0.28129953
 0.2810682  0.2807483  0.28062114 0.280585   0.28056505 0.28059474
 0.28054124 0.28039455 0.28035298 0.28045285 0.28049973 0.28050324
 0.28044748 0.28035194 0.28039524 0.2805483  0.28055182 0.2804574
 0.2804615  0.28056136 0.28072387 0.2807993  0.28072044 0.28062296
 0.28049806 0.28031513 0.28022322 0.28024969 0.28024405 0.28012693
 0.27992138 0.2797788  0.27965736 0.2796588  0.2797717  0.2799145
 0.28010055 0.2801579  0.2800501  0.2799496  0.27988303 0.2798123
 0.279967   0.28017503 0.28027186 0.2801902  0.28003255 0.2798987
 0.27973834 0.27954116 0.27938893 0.2793816  0.2796477  0.28013346
 0.28049213 0.2808226  0.28068578 0.28040788 0.28044692 0.28055298
 0.2806196  0.28062847 0.28061885 0.28097165 0.28141573 0.2813132
 0.28124616 0.28114146 0.28113076 0.28103638 0.28085512 0.28073516
 0.28052834 0.28035954 0.280213   0.27996904 0.2802751  0.28145957
 0.28271714 0.2838326  0.2836046  0.28266478 0.2822956  0.28201845
 0.2817866  0.28233773 0.28282717 0.28297696 0.28354692 0.2827373 ]
