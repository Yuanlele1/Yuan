Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_360_j192_H5', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=10, pred_len=192, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_360_j192_H5_FITS_custom_ftM_sl360_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11729
val 1565
test 3317
Model(
  (freq_upsampler): Linear(in_features=90, out_features=138, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1370373120.0
params:  12558.0
Trainable parameters:  12558
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 79.61816954612732
Epoch: 1, Steps: 91 | Train Loss: 1.1544996 Vali Loss: 1.2545173 Test Loss: 1.4680072
Validation loss decreased (inf --> 1.254517).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 75.183522939682
Epoch: 2, Steps: 91 | Train Loss: 0.8705425 Vali Loss: 1.0625714 Test Loss: 1.2419637
Validation loss decreased (1.254517 --> 1.062571).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 73.82222843170166
Epoch: 3, Steps: 91 | Train Loss: 0.7462573 Vali Loss: 0.9722414 Test Loss: 1.1365212
Validation loss decreased (1.062571 --> 0.972241).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 76.06717848777771
Epoch: 4, Steps: 91 | Train Loss: 0.6708999 Vali Loss: 0.9094527 Test Loss: 1.0645131
Validation loss decreased (0.972241 --> 0.909453).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 77.73096680641174
Epoch: 5, Steps: 91 | Train Loss: 0.6135317 Vali Loss: 0.8578942 Test Loss: 1.0050086
Validation loss decreased (0.909453 --> 0.857894).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 79.58526468276978
Epoch: 6, Steps: 91 | Train Loss: 0.5657906 Vali Loss: 0.8155496 Test Loss: 0.9569227
Validation loss decreased (0.857894 --> 0.815550).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 76.01874566078186
Epoch: 7, Steps: 91 | Train Loss: 0.5247249 Vali Loss: 0.7760696 Test Loss: 0.9116466
Validation loss decreased (0.815550 --> 0.776070).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 75.45525240898132
Epoch: 8, Steps: 91 | Train Loss: 0.4891074 Vali Loss: 0.7404451 Test Loss: 0.8700284
Validation loss decreased (0.776070 --> 0.740445).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 76.48943853378296
Epoch: 9, Steps: 91 | Train Loss: 0.4577459 Vali Loss: 0.7118989 Test Loss: 0.8369132
Validation loss decreased (0.740445 --> 0.711899).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 74.03006291389465
Epoch: 10, Steps: 91 | Train Loss: 0.4301720 Vali Loss: 0.6839995 Test Loss: 0.8049363
Validation loss decreased (0.711899 --> 0.684000).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 76.94108700752258
Epoch: 11, Steps: 91 | Train Loss: 0.4057171 Vali Loss: 0.6580525 Test Loss: 0.7754041
Validation loss decreased (0.684000 --> 0.658053).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 75.84945869445801
Epoch: 12, Steps: 91 | Train Loss: 0.3839133 Vali Loss: 0.6363823 Test Loss: 0.7503101
Validation loss decreased (0.658053 --> 0.636382).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 76.10499405860901
Epoch: 13, Steps: 91 | Train Loss: 0.3644201 Vali Loss: 0.6186182 Test Loss: 0.7302635
Validation loss decreased (0.636382 --> 0.618618).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 75.31299781799316
Epoch: 14, Steps: 91 | Train Loss: 0.3468749 Vali Loss: 0.5994999 Test Loss: 0.7082314
Validation loss decreased (0.618618 --> 0.599500).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 74.21186685562134
Epoch: 15, Steps: 91 | Train Loss: 0.3311238 Vali Loss: 0.5823693 Test Loss: 0.6886326
Validation loss decreased (0.599500 --> 0.582369).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 78.44824290275574
Epoch: 16, Steps: 91 | Train Loss: 0.3169560 Vali Loss: 0.5676216 Test Loss: 0.6720477
Validation loss decreased (0.582369 --> 0.567622).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 76.68641567230225
Epoch: 17, Steps: 91 | Train Loss: 0.3040880 Vali Loss: 0.5534670 Test Loss: 0.6555398
Validation loss decreased (0.567622 --> 0.553467).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 79.74970769882202
Epoch: 18, Steps: 91 | Train Loss: 0.2923667 Vali Loss: 0.5418230 Test Loss: 0.6424283
Validation loss decreased (0.553467 --> 0.541823).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 76.99610090255737
Epoch: 19, Steps: 91 | Train Loss: 0.2817232 Vali Loss: 0.5314137 Test Loss: 0.6304549
Validation loss decreased (0.541823 --> 0.531414).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 74.84049892425537
Epoch: 20, Steps: 91 | Train Loss: 0.2720617 Vali Loss: 0.5204980 Test Loss: 0.6178968
Validation loss decreased (0.531414 --> 0.520498).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 75.72378897666931
Epoch: 21, Steps: 91 | Train Loss: 0.2632256 Vali Loss: 0.5110146 Test Loss: 0.6071034
Validation loss decreased (0.520498 --> 0.511015).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 77.01249074935913
Epoch: 22, Steps: 91 | Train Loss: 0.2550925 Vali Loss: 0.5023592 Test Loss: 0.5975451
Validation loss decreased (0.511015 --> 0.502359).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 74.6493787765503
Epoch: 23, Steps: 91 | Train Loss: 0.2476553 Vali Loss: 0.4938428 Test Loss: 0.5878266
Validation loss decreased (0.502359 --> 0.493843).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 80.58832335472107
Epoch: 24, Steps: 91 | Train Loss: 0.2408334 Vali Loss: 0.4864640 Test Loss: 0.5797719
Validation loss decreased (0.493843 --> 0.486464).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 74.58894777297974
Epoch: 25, Steps: 91 | Train Loss: 0.2344905 Vali Loss: 0.4790168 Test Loss: 0.5714931
Validation loss decreased (0.486464 --> 0.479017).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 77.34729599952698
Epoch: 26, Steps: 91 | Train Loss: 0.2287455 Vali Loss: 0.4733347 Test Loss: 0.5647638
Validation loss decreased (0.479017 --> 0.473335).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 72.4262638092041
Epoch: 27, Steps: 91 | Train Loss: 0.2233695 Vali Loss: 0.4673781 Test Loss: 0.5580615
Validation loss decreased (0.473335 --> 0.467378).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 77.75145888328552
Epoch: 28, Steps: 91 | Train Loss: 0.2183607 Vali Loss: 0.4620157 Test Loss: 0.5521065
Validation loss decreased (0.467378 --> 0.462016).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 78.22661662101746
Epoch: 29, Steps: 91 | Train Loss: 0.2137970 Vali Loss: 0.4566960 Test Loss: 0.5461425
Validation loss decreased (0.462016 --> 0.456696).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 78.43529653549194
Epoch: 30, Steps: 91 | Train Loss: 0.2095303 Vali Loss: 0.4522210 Test Loss: 0.5409719
Validation loss decreased (0.456696 --> 0.452221).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 78.57496404647827
Epoch: 31, Steps: 91 | Train Loss: 0.2055500 Vali Loss: 0.4481260 Test Loss: 0.5367811
Validation loss decreased (0.452221 --> 0.448126).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 72.64017939567566
Epoch: 32, Steps: 91 | Train Loss: 0.2019005 Vali Loss: 0.4440335 Test Loss: 0.5319686
Validation loss decreased (0.448126 --> 0.444033).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 76.52099871635437
Epoch: 33, Steps: 91 | Train Loss: 0.1984592 Vali Loss: 0.4395860 Test Loss: 0.5274925
Validation loss decreased (0.444033 --> 0.439586).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 78.73210644721985
Epoch: 34, Steps: 91 | Train Loss: 0.1953073 Vali Loss: 0.4365029 Test Loss: 0.5240031
Validation loss decreased (0.439586 --> 0.436503).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 75.66869306564331
Epoch: 35, Steps: 91 | Train Loss: 0.1923126 Vali Loss: 0.4334363 Test Loss: 0.5203381
Validation loss decreased (0.436503 --> 0.433436).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 79.71499705314636
Epoch: 36, Steps: 91 | Train Loss: 0.1895530 Vali Loss: 0.4310420 Test Loss: 0.5170811
Validation loss decreased (0.433436 --> 0.431042).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 74.032301902771
Epoch: 37, Steps: 91 | Train Loss: 0.1869745 Vali Loss: 0.4276322 Test Loss: 0.5136954
Validation loss decreased (0.431042 --> 0.427632).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 75.09277081489563
Epoch: 38, Steps: 91 | Train Loss: 0.1845413 Vali Loss: 0.4245822 Test Loss: 0.5108113
Validation loss decreased (0.427632 --> 0.424582).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 78.23189616203308
Epoch: 39, Steps: 91 | Train Loss: 0.1822645 Vali Loss: 0.4222279 Test Loss: 0.5077627
Validation loss decreased (0.424582 --> 0.422228).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 79.94282293319702
Epoch: 40, Steps: 91 | Train Loss: 0.1801250 Vali Loss: 0.4199698 Test Loss: 0.5051540
Validation loss decreased (0.422228 --> 0.419970).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 80.14022469520569
Epoch: 41, Steps: 91 | Train Loss: 0.1781234 Vali Loss: 0.4177562 Test Loss: 0.5031194
Validation loss decreased (0.419970 --> 0.417756).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 76.64779710769653
Epoch: 42, Steps: 91 | Train Loss: 0.1762459 Vali Loss: 0.4155055 Test Loss: 0.5005404
Validation loss decreased (0.417756 --> 0.415506).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 82.04024815559387
Epoch: 43, Steps: 91 | Train Loss: 0.1745192 Vali Loss: 0.4134669 Test Loss: 0.4984858
Validation loss decreased (0.415506 --> 0.413467).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 79.97278761863708
Epoch: 44, Steps: 91 | Train Loss: 0.1728687 Vali Loss: 0.4118971 Test Loss: 0.4965569
Validation loss decreased (0.413467 --> 0.411897).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 78.3812325000763
Epoch: 45, Steps: 91 | Train Loss: 0.1713020 Vali Loss: 0.4102311 Test Loss: 0.4944132
Validation loss decreased (0.411897 --> 0.410231).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 81.24803280830383
Epoch: 46, Steps: 91 | Train Loss: 0.1698164 Vali Loss: 0.4087537 Test Loss: 0.4929662
Validation loss decreased (0.410231 --> 0.408754).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 73.55191469192505
Epoch: 47, Steps: 91 | Train Loss: 0.1684339 Vali Loss: 0.4067882 Test Loss: 0.4911530
Validation loss decreased (0.408754 --> 0.406788).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 79.23267936706543
Epoch: 48, Steps: 91 | Train Loss: 0.1671516 Vali Loss: 0.4059647 Test Loss: 0.4896803
Validation loss decreased (0.406788 --> 0.405965).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 72.5979630947113
Epoch: 49, Steps: 91 | Train Loss: 0.1659062 Vali Loss: 0.4041914 Test Loss: 0.4882352
Validation loss decreased (0.405965 --> 0.404191).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 76.01490664482117
Epoch: 50, Steps: 91 | Train Loss: 0.1647656 Vali Loss: 0.4027578 Test Loss: 0.4866208
Validation loss decreased (0.404191 --> 0.402758).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 77.91769194602966
Epoch: 51, Steps: 91 | Train Loss: 0.1636555 Vali Loss: 0.4020618 Test Loss: 0.4855399
Validation loss decreased (0.402758 --> 0.402062).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 71.96286821365356
Epoch: 52, Steps: 91 | Train Loss: 0.1626562 Vali Loss: 0.4006190 Test Loss: 0.4843790
Validation loss decreased (0.402062 --> 0.400619).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 75.76482915878296
Epoch: 53, Steps: 91 | Train Loss: 0.1616899 Vali Loss: 0.3993587 Test Loss: 0.4830652
Validation loss decreased (0.400619 --> 0.399359).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 68.31454586982727
Epoch: 54, Steps: 91 | Train Loss: 0.1607448 Vali Loss: 0.3987925 Test Loss: 0.4821013
Validation loss decreased (0.399359 --> 0.398793).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 74.13772416114807
Epoch: 55, Steps: 91 | Train Loss: 0.1599043 Vali Loss: 0.3977392 Test Loss: 0.4810474
Validation loss decreased (0.398793 --> 0.397739).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 73.20585060119629
Epoch: 56, Steps: 91 | Train Loss: 0.1590484 Vali Loss: 0.3963778 Test Loss: 0.4800582
Validation loss decreased (0.397739 --> 0.396378).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 71.77196907997131
Epoch: 57, Steps: 91 | Train Loss: 0.1582934 Vali Loss: 0.3960562 Test Loss: 0.4790919
Validation loss decreased (0.396378 --> 0.396056).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 79.47192645072937
Epoch: 58, Steps: 91 | Train Loss: 0.1575379 Vali Loss: 0.3949169 Test Loss: 0.4782230
Validation loss decreased (0.396056 --> 0.394917).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 73.32479357719421
Epoch: 59, Steps: 91 | Train Loss: 0.1568642 Vali Loss: 0.3947592 Test Loss: 0.4773900
Validation loss decreased (0.394917 --> 0.394759).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 72.90106391906738
Epoch: 60, Steps: 91 | Train Loss: 0.1562144 Vali Loss: 0.3936270 Test Loss: 0.4765701
Validation loss decreased (0.394759 --> 0.393627).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 75.66325759887695
Epoch: 61, Steps: 91 | Train Loss: 0.1555783 Vali Loss: 0.3927245 Test Loss: 0.4759074
Validation loss decreased (0.393627 --> 0.392724).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 71.56712245941162
Epoch: 62, Steps: 91 | Train Loss: 0.1549896 Vali Loss: 0.3922972 Test Loss: 0.4751731
Validation loss decreased (0.392724 --> 0.392297).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 77.25158619880676
Epoch: 63, Steps: 91 | Train Loss: 0.1544299 Vali Loss: 0.3916427 Test Loss: 0.4745148
Validation loss decreased (0.392297 --> 0.391643).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 75.31720685958862
Epoch: 64, Steps: 91 | Train Loss: 0.1538905 Vali Loss: 0.3912621 Test Loss: 0.4739196
Validation loss decreased (0.391643 --> 0.391262).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 73.05990815162659
Epoch: 65, Steps: 91 | Train Loss: 0.1534081 Vali Loss: 0.3903787 Test Loss: 0.4733360
Validation loss decreased (0.391262 --> 0.390379).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 73.22639751434326
Epoch: 66, Steps: 91 | Train Loss: 0.1529124 Vali Loss: 0.3903003 Test Loss: 0.4727520
Validation loss decreased (0.390379 --> 0.390300).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 72.4133472442627
Epoch: 67, Steps: 91 | Train Loss: 0.1524541 Vali Loss: 0.3896898 Test Loss: 0.4722080
Validation loss decreased (0.390300 --> 0.389690).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 81.66830539703369
Epoch: 68, Steps: 91 | Train Loss: 0.1520630 Vali Loss: 0.3886873 Test Loss: 0.4717021
Validation loss decreased (0.389690 --> 0.388687).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 74.11577892303467
Epoch: 69, Steps: 91 | Train Loss: 0.1516404 Vali Loss: 0.3893473 Test Loss: 0.4712076
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 75.22738718986511
Epoch: 70, Steps: 91 | Train Loss: 0.1512207 Vali Loss: 0.3881645 Test Loss: 0.4707489
Validation loss decreased (0.388687 --> 0.388164).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 72.19734311103821
Epoch: 71, Steps: 91 | Train Loss: 0.1508242 Vali Loss: 0.3880080 Test Loss: 0.4702845
Validation loss decreased (0.388164 --> 0.388008).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 71.25690817832947
Epoch: 72, Steps: 91 | Train Loss: 0.1505168 Vali Loss: 0.3872796 Test Loss: 0.4698783
Validation loss decreased (0.388008 --> 0.387280).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 78.6801393032074
Epoch: 73, Steps: 91 | Train Loss: 0.1501696 Vali Loss: 0.3868941 Test Loss: 0.4695134
Validation loss decreased (0.387280 --> 0.386894).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 75.37983989715576
Epoch: 74, Steps: 91 | Train Loss: 0.1498764 Vali Loss: 0.3866238 Test Loss: 0.4691311
Validation loss decreased (0.386894 --> 0.386624).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 78.27935338020325
Epoch: 75, Steps: 91 | Train Loss: 0.1495660 Vali Loss: 0.3856576 Test Loss: 0.4687935
Validation loss decreased (0.386624 --> 0.385658).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 75.66303825378418
Epoch: 76, Steps: 91 | Train Loss: 0.1493043 Vali Loss: 0.3856912 Test Loss: 0.4684185
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 70.55334305763245
Epoch: 77, Steps: 91 | Train Loss: 0.1489914 Vali Loss: 0.3855638 Test Loss: 0.4681166
Validation loss decreased (0.385658 --> 0.385564).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 75.39200186729431
Epoch: 78, Steps: 91 | Train Loss: 0.1487548 Vali Loss: 0.3852573 Test Loss: 0.4678154
Validation loss decreased (0.385564 --> 0.385257).  Saving model ...
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 73.63509035110474
Epoch: 79, Steps: 91 | Train Loss: 0.1485260 Vali Loss: 0.3849132 Test Loss: 0.4675483
Validation loss decreased (0.385257 --> 0.384913).  Saving model ...
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 76.59897804260254
Epoch: 80, Steps: 91 | Train Loss: 0.1482679 Vali Loss: 0.3844840 Test Loss: 0.4673046
Validation loss decreased (0.384913 --> 0.384484).  Saving model ...
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 75.7690818309784
Epoch: 81, Steps: 91 | Train Loss: 0.1480920 Vali Loss: 0.3845612 Test Loss: 0.4670168
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 73.22188544273376
Epoch: 82, Steps: 91 | Train Loss: 0.1478481 Vali Loss: 0.3845502 Test Loss: 0.4667735
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 76.0284743309021
Epoch: 83, Steps: 91 | Train Loss: 0.1476686 Vali Loss: 0.3842399 Test Loss: 0.4665745
Validation loss decreased (0.384484 --> 0.384240).  Saving model ...
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 73.14430689811707
Epoch: 84, Steps: 91 | Train Loss: 0.1474671 Vali Loss: 0.3837108 Test Loss: 0.4663561
Validation loss decreased (0.384240 --> 0.383711).  Saving model ...
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 75.7825984954834
Epoch: 85, Steps: 91 | Train Loss: 0.1472897 Vali Loss: 0.3841618 Test Loss: 0.4661501
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 76.93291544914246
Epoch: 86, Steps: 91 | Train Loss: 0.1471072 Vali Loss: 0.3835770 Test Loss: 0.4659670
Validation loss decreased (0.383711 --> 0.383577).  Saving model ...
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 72.89507055282593
Epoch: 87, Steps: 91 | Train Loss: 0.1469626 Vali Loss: 0.3830383 Test Loss: 0.4657566
Validation loss decreased (0.383577 --> 0.383038).  Saving model ...
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 70.19705748558044
Epoch: 88, Steps: 91 | Train Loss: 0.1468295 Vali Loss: 0.3828036 Test Loss: 0.4655745
Validation loss decreased (0.383038 --> 0.382804).  Saving model ...
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 76.42100048065186
Epoch: 89, Steps: 91 | Train Loss: 0.1466575 Vali Loss: 0.3830919 Test Loss: 0.4653927
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 75.61525702476501
Epoch: 90, Steps: 91 | Train Loss: 0.1465190 Vali Loss: 0.3826617 Test Loss: 0.4652470
Validation loss decreased (0.382804 --> 0.382662).  Saving model ...
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 79.23502993583679
Epoch: 91, Steps: 91 | Train Loss: 0.1463903 Vali Loss: 0.3823440 Test Loss: 0.4650832
Validation loss decreased (0.382662 --> 0.382344).  Saving model ...
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 76.10185980796814
Epoch: 92, Steps: 91 | Train Loss: 0.1462671 Vali Loss: 0.3820218 Test Loss: 0.4649466
Validation loss decreased (0.382344 --> 0.382022).  Saving model ...
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 76.76259303092957
Epoch: 93, Steps: 91 | Train Loss: 0.1461478 Vali Loss: 0.3824328 Test Loss: 0.4648130
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 73.01618552207947
Epoch: 94, Steps: 91 | Train Loss: 0.1460599 Vali Loss: 0.3829238 Test Loss: 0.4646777
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 73.47488045692444
Epoch: 95, Steps: 91 | Train Loss: 0.1459468 Vali Loss: 0.3824117 Test Loss: 0.4645626
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 78.91033792495728
Epoch: 96, Steps: 91 | Train Loss: 0.1458154 Vali Loss: 0.3821330 Test Loss: 0.4644318
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 77.06440830230713
Epoch: 97, Steps: 91 | Train Loss: 0.1457516 Vali Loss: 0.3820607 Test Loss: 0.4643264
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 78.73727798461914
Epoch: 98, Steps: 91 | Train Loss: 0.1456517 Vali Loss: 0.3821973 Test Loss: 0.4642294
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 75.4655921459198
Epoch: 99, Steps: 91 | Train Loss: 0.1455036 Vali Loss: 0.3819124 Test Loss: 0.4641284
Validation loss decreased (0.382022 --> 0.381912).  Saving model ...
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 76.06657290458679
Epoch: 100, Steps: 91 | Train Loss: 0.1454339 Vali Loss: 0.3819180 Test Loss: 0.4640218
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.1160680107021042e-06
train 11729
val 1565
test 3317
Model(
  (freq_upsampler): Linear(in_features=90, out_features=138, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1370373120.0
params:  12558.0
Trainable parameters:  12558
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 77.62712812423706
Epoch: 1, Steps: 91 | Train Loss: 0.2679782 Vali Loss: 0.3484194 Test Loss: 0.4326376
Validation loss decreased (inf --> 0.348419).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 78.51231336593628
Epoch: 2, Steps: 91 | Train Loss: 0.2592051 Vali Loss: 0.3474133 Test Loss: 0.4328995
Validation loss decreased (0.348419 --> 0.347413).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 78.20928263664246
Epoch: 3, Steps: 91 | Train Loss: 0.2587372 Vali Loss: 0.3469871 Test Loss: 0.4329036
Validation loss decreased (0.347413 --> 0.346987).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 80.06237816810608
Epoch: 4, Steps: 91 | Train Loss: 0.2587779 Vali Loss: 0.3468872 Test Loss: 0.4327204
Validation loss decreased (0.346987 --> 0.346887).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 73.00896620750427
Epoch: 5, Steps: 91 | Train Loss: 0.2587307 Vali Loss: 0.3471675 Test Loss: 0.4326283
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 75.77756857872009
Epoch: 6, Steps: 91 | Train Loss: 0.2586968 Vali Loss: 0.3470205 Test Loss: 0.4323800
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 74.45215845108032
Epoch: 7, Steps: 91 | Train Loss: 0.2585877 Vali Loss: 0.3468372 Test Loss: 0.4323952
Validation loss decreased (0.346887 --> 0.346837).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 76.91649174690247
Epoch: 8, Steps: 91 | Train Loss: 0.2584587 Vali Loss: 0.3471010 Test Loss: 0.4323723
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 79.43624019622803
Epoch: 9, Steps: 91 | Train Loss: 0.2586578 Vali Loss: 0.3467633 Test Loss: 0.4323998
Validation loss decreased (0.346837 --> 0.346763).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 73.74220585823059
Epoch: 10, Steps: 91 | Train Loss: 0.2585958 Vali Loss: 0.3466077 Test Loss: 0.4321363
Validation loss decreased (0.346763 --> 0.346608).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 75.37493681907654
Epoch: 11, Steps: 91 | Train Loss: 0.2585380 Vali Loss: 0.3470290 Test Loss: 0.4322012
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 73.61133742332458
Epoch: 12, Steps: 91 | Train Loss: 0.2585510 Vali Loss: 0.3466648 Test Loss: 0.4321602
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 62.54290556907654
Epoch: 13, Steps: 91 | Train Loss: 0.2584864 Vali Loss: 0.3466436 Test Loss: 0.4321708
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 63.8606116771698
Epoch: 14, Steps: 91 | Train Loss: 0.2584158 Vali Loss: 0.3464876 Test Loss: 0.4322511
Validation loss decreased (0.346608 --> 0.346488).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 61.688827991485596
Epoch: 15, Steps: 91 | Train Loss: 0.2584506 Vali Loss: 0.3467896 Test Loss: 0.4321764
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 63.36146330833435
Epoch: 16, Steps: 91 | Train Loss: 0.2584522 Vali Loss: 0.3467840 Test Loss: 0.4321077
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 61.67351055145264
Epoch: 17, Steps: 91 | Train Loss: 0.2584683 Vali Loss: 0.3464409 Test Loss: 0.4321210
Validation loss decreased (0.346488 --> 0.346441).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 60.577725410461426
Epoch: 18, Steps: 91 | Train Loss: 0.2584277 Vali Loss: 0.3466505 Test Loss: 0.4321554
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 64.52814435958862
Epoch: 19, Steps: 91 | Train Loss: 0.2584124 Vali Loss: 0.3469586 Test Loss: 0.4321305
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 60.18457818031311
Epoch: 20, Steps: 91 | Train Loss: 0.2584113 Vali Loss: 0.3466938 Test Loss: 0.4320884
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 62.45854878425598
Epoch: 21, Steps: 91 | Train Loss: 0.2583829 Vali Loss: 0.3464867 Test Loss: 0.4320830
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 59.9527850151062
Epoch: 22, Steps: 91 | Train Loss: 0.2583400 Vali Loss: 0.3464907 Test Loss: 0.4319874
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 60.96033215522766
Epoch: 23, Steps: 91 | Train Loss: 0.2582635 Vali Loss: 0.3460608 Test Loss: 0.4320898
Validation loss decreased (0.346441 --> 0.346061).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 62.31935524940491
Epoch: 24, Steps: 91 | Train Loss: 0.2583698 Vali Loss: 0.3463648 Test Loss: 0.4319743
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 58.84868574142456
Epoch: 25, Steps: 91 | Train Loss: 0.2583061 Vali Loss: 0.3466597 Test Loss: 0.4320281
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 62.25509595870972
Epoch: 26, Steps: 91 | Train Loss: 0.2582910 Vali Loss: 0.3462295 Test Loss: 0.4320827
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 63.91678333282471
Epoch: 27, Steps: 91 | Train Loss: 0.2582472 Vali Loss: 0.3465299 Test Loss: 0.4319550
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 61.2308464050293
Epoch: 28, Steps: 91 | Train Loss: 0.2582716 Vali Loss: 0.3465244 Test Loss: 0.4320994
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 65.02463150024414
Epoch: 29, Steps: 91 | Train Loss: 0.2583307 Vali Loss: 0.3464615 Test Loss: 0.4320365
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 58.05960536003113
Epoch: 30, Steps: 91 | Train Loss: 0.2583659 Vali Loss: 0.3464392 Test Loss: 0.4320157
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 61.78720307350159
Epoch: 31, Steps: 91 | Train Loss: 0.2582187 Vali Loss: 0.3465177 Test Loss: 0.4320714
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 61.86417198181152
Epoch: 32, Steps: 91 | Train Loss: 0.2583879 Vali Loss: 0.3465415 Test Loss: 0.4320235
EarlyStopping counter: 9 out of 10
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 61.49559760093689
Epoch: 33, Steps: 91 | Train Loss: 0.2583176 Vali Loss: 0.3467978 Test Loss: 0.4319655
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : Traffic_360_j192_H5_FITS_custom_ftM_sl360_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3317
mse:0.43109723925590515, mae:0.2966417968273163, rse:0.5418968796730042, corr:[0.28360146 0.29175577 0.29260314 0.29274032 0.2924392  0.2921699
 0.29223755 0.2923219  0.29212672 0.29183966 0.29174662 0.29170176
 0.29152176 0.29130316 0.2912905  0.2914385  0.29148632 0.29133815
 0.2911227  0.29103506 0.29105422 0.29101244 0.2910022  0.291512
 0.29225114 0.2922976  0.29218993 0.2921831  0.2922328  0.29227248
 0.292202   0.29202488 0.29187605 0.29181847 0.29174128 0.29150444
 0.2912753  0.2912267  0.29137936 0.29151303 0.29145464 0.29123926
 0.29101917 0.29094297 0.29102558 0.29108095 0.2909872  0.2909857
 0.2910932  0.29106283 0.2911786  0.2914221  0.29159653 0.291552
 0.2913135  0.29107654 0.29101682 0.29108357 0.2910577  0.29085553
 0.2906855  0.29065007 0.29064685 0.2905424  0.29043543 0.2904934
 0.2906387  0.29069048 0.29060945 0.290507   0.29041302 0.2903507
 0.2901432  0.28986102 0.28975156 0.28983483 0.28991023 0.28980643
 0.28958863 0.28946528 0.28954995 0.28971618 0.2897188  0.28949472
 0.28927577 0.28925893 0.28940228 0.28951314 0.28954893 0.2895911
 0.28964204 0.28960466 0.28948036 0.28935573 0.2892392  0.28906453
 0.28879422 0.2887308  0.28894928 0.2893042  0.2895157  0.2894605
 0.28929195 0.2892081  0.28924763 0.28929546 0.2892413  0.28911084
 0.28905535 0.2890985  0.28915024 0.28909653 0.28895754 0.28889573
 0.28892046 0.28890106 0.2887407  0.2884969  0.28842437 0.28848052
 0.28842965 0.28842053 0.2885922  0.28893673 0.28932935 0.2895318
 0.28945705 0.28922454 0.28903553 0.28895852 0.28891438 0.2888494
 0.28882495 0.2888982  0.289089   0.28930974 0.2894324  0.28934947
 0.28922814 0.28914022 0.28911018 0.28919518 0.28944606 0.28996754
 0.29038495 0.29059383 0.29064137 0.290512   0.29035208 0.29028726
 0.29030272 0.2903179  0.29030192 0.29030973 0.29036972 0.29043123
 0.29044536 0.2904381  0.29049608 0.2906009  0.29064614 0.29055384
 0.29040277 0.29037324 0.2905367  0.29075673 0.29096815 0.29146856
 0.29193166 0.29163638 0.2912543  0.2908599  0.29059783 0.29069626
 0.2909975  0.29105264 0.29068935 0.2902779  0.2902741  0.29060405
 0.290835   0.290737   0.2906135  0.2907227  0.29082343 0.2906291
 0.29026386 0.29021123 0.29034007 0.29002053 0.28953958 0.2903857 ]
