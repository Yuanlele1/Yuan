Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_360_j96_H5', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=10, pred_len=96, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_360_j96_H5_FITS_custom_ftM_sl360_ll48_pl96_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11825
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=90, out_features=114, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1132047360.0
params:  10374.0
Trainable parameters:  10374
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 69.5374825000763
Epoch: 1, Steps: 92 | Train Loss: 1.0107451 Vali Loss: 1.1017088 Test Loss: 1.2747399
Validation loss decreased (inf --> 1.101709).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 65.75821733474731
Epoch: 2, Steps: 92 | Train Loss: 0.7715405 Vali Loss: 0.9518278 Test Loss: 1.0942712
Validation loss decreased (1.101709 --> 0.951828).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 69.62578558921814
Epoch: 3, Steps: 92 | Train Loss: 0.6603979 Vali Loss: 0.8740128 Test Loss: 1.0049554
Validation loss decreased (0.951828 --> 0.874013).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 65.38343167304993
Epoch: 4, Steps: 92 | Train Loss: 0.5886794 Vali Loss: 0.8213980 Test Loss: 0.9433732
Validation loss decreased (0.874013 --> 0.821398).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 70.91561770439148
Epoch: 5, Steps: 92 | Train Loss: 0.5325028 Vali Loss: 0.7791054 Test Loss: 0.8957369
Validation loss decreased (0.821398 --> 0.779105).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 64.67639946937561
Epoch: 6, Steps: 92 | Train Loss: 0.4856284 Vali Loss: 0.7408859 Test Loss: 0.8538518
Validation loss decreased (0.779105 --> 0.740886).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 70.81483888626099
Epoch: 7, Steps: 92 | Train Loss: 0.4454017 Vali Loss: 0.7045228 Test Loss: 0.8123245
Validation loss decreased (0.740886 --> 0.704523).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 67.3768835067749
Epoch: 8, Steps: 92 | Train Loss: 0.4105973 Vali Loss: 0.6758121 Test Loss: 0.7804939
Validation loss decreased (0.704523 --> 0.675812).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 66.72622084617615
Epoch: 9, Steps: 92 | Train Loss: 0.3802070 Vali Loss: 0.6498344 Test Loss: 0.7510700
Validation loss decreased (0.675812 --> 0.649834).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 65.12085223197937
Epoch: 10, Steps: 92 | Train Loss: 0.3535663 Vali Loss: 0.6261579 Test Loss: 0.7243133
Validation loss decreased (0.649834 --> 0.626158).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 70.48100352287292
Epoch: 11, Steps: 92 | Train Loss: 0.3300858 Vali Loss: 0.6050361 Test Loss: 0.6999622
Validation loss decreased (0.626158 --> 0.605036).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 69.37957048416138
Epoch: 12, Steps: 92 | Train Loss: 0.3093127 Vali Loss: 0.5851610 Test Loss: 0.6786525
Validation loss decreased (0.605036 --> 0.585161).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 69.65926599502563
Epoch: 13, Steps: 92 | Train Loss: 0.2909012 Vali Loss: 0.5660964 Test Loss: 0.6577361
Validation loss decreased (0.585161 --> 0.566096).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 68.08921265602112
Epoch: 14, Steps: 92 | Train Loss: 0.2744684 Vali Loss: 0.5499567 Test Loss: 0.6394780
Validation loss decreased (0.566096 --> 0.549957).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 70.74924564361572
Epoch: 15, Steps: 92 | Train Loss: 0.2598147 Vali Loss: 0.5362259 Test Loss: 0.6241139
Validation loss decreased (0.549957 --> 0.536226).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 65.90345430374146
Epoch: 16, Steps: 92 | Train Loss: 0.2466789 Vali Loss: 0.5223259 Test Loss: 0.6089523
Validation loss decreased (0.536226 --> 0.522326).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 66.68538880348206
Epoch: 17, Steps: 92 | Train Loss: 0.2348704 Vali Loss: 0.5105469 Test Loss: 0.5958001
Validation loss decreased (0.522326 --> 0.510547).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 67.77485489845276
Epoch: 18, Steps: 92 | Train Loss: 0.2242562 Vali Loss: 0.4983946 Test Loss: 0.5830254
Validation loss decreased (0.510547 --> 0.498395).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 68.11804842948914
Epoch: 19, Steps: 92 | Train Loss: 0.2146245 Vali Loss: 0.4916386 Test Loss: 0.5734268
Validation loss decreased (0.498395 --> 0.491639).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 67.77621483802795
Epoch: 20, Steps: 92 | Train Loss: 0.2059537 Vali Loss: 0.4825791 Test Loss: 0.5634105
Validation loss decreased (0.491639 --> 0.482579).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 71.29475450515747
Epoch: 21, Steps: 92 | Train Loss: 0.1980793 Vali Loss: 0.4743986 Test Loss: 0.5542073
Validation loss decreased (0.482579 --> 0.474399).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 67.16230702400208
Epoch: 22, Steps: 92 | Train Loss: 0.1909185 Vali Loss: 0.4657802 Test Loss: 0.5464589
Validation loss decreased (0.474399 --> 0.465780).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 67.75111603736877
Epoch: 23, Steps: 92 | Train Loss: 0.1844023 Vali Loss: 0.4591288 Test Loss: 0.5382578
Validation loss decreased (0.465780 --> 0.459129).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 68.40430402755737
Epoch: 24, Steps: 92 | Train Loss: 0.1784542 Vali Loss: 0.4525777 Test Loss: 0.5311306
Validation loss decreased (0.459129 --> 0.452578).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 66.85324263572693
Epoch: 25, Steps: 92 | Train Loss: 0.1730229 Vali Loss: 0.4464509 Test Loss: 0.5252228
Validation loss decreased (0.452578 --> 0.446451).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 66.46469306945801
Epoch: 26, Steps: 92 | Train Loss: 0.1680358 Vali Loss: 0.4408410 Test Loss: 0.5190976
Validation loss decreased (0.446451 --> 0.440841).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 65.8861494064331
Epoch: 27, Steps: 92 | Train Loss: 0.1634783 Vali Loss: 0.4352374 Test Loss: 0.5142488
Validation loss decreased (0.440841 --> 0.435237).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 69.84150886535645
Epoch: 28, Steps: 92 | Train Loss: 0.1592572 Vali Loss: 0.4320582 Test Loss: 0.5089465
Validation loss decreased (0.435237 --> 0.432058).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 64.8681526184082
Epoch: 29, Steps: 92 | Train Loss: 0.1553900 Vali Loss: 0.4272534 Test Loss: 0.5042849
Validation loss decreased (0.432058 --> 0.427253).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 68.33723211288452
Epoch: 30, Steps: 92 | Train Loss: 0.1518502 Vali Loss: 0.4241060 Test Loss: 0.4999731
Validation loss decreased (0.427253 --> 0.424106).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 67.83791208267212
Epoch: 31, Steps: 92 | Train Loss: 0.1485560 Vali Loss: 0.4191398 Test Loss: 0.4960225
Validation loss decreased (0.424106 --> 0.419140).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 65.30174612998962
Epoch: 32, Steps: 92 | Train Loss: 0.1455209 Vali Loss: 0.4158601 Test Loss: 0.4920059
Validation loss decreased (0.419140 --> 0.415860).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 67.32565927505493
Epoch: 33, Steps: 92 | Train Loss: 0.1427086 Vali Loss: 0.4133041 Test Loss: 0.4892295
Validation loss decreased (0.415860 --> 0.413304).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 67.1356589794159
Epoch: 34, Steps: 92 | Train Loss: 0.1401195 Vali Loss: 0.4102925 Test Loss: 0.4860590
Validation loss decreased (0.413304 --> 0.410292).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 68.52893567085266
Epoch: 35, Steps: 92 | Train Loss: 0.1377061 Vali Loss: 0.4079510 Test Loss: 0.4830597
Validation loss decreased (0.410292 --> 0.407951).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 67.01356315612793
Epoch: 36, Steps: 92 | Train Loss: 0.1354543 Vali Loss: 0.4053352 Test Loss: 0.4804181
Validation loss decreased (0.407951 --> 0.405335).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 66.68638253211975
Epoch: 37, Steps: 92 | Train Loss: 0.1333748 Vali Loss: 0.4030565 Test Loss: 0.4778796
Validation loss decreased (0.405335 --> 0.403056).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 69.30515575408936
Epoch: 38, Steps: 92 | Train Loss: 0.1314425 Vali Loss: 0.4004857 Test Loss: 0.4759393
Validation loss decreased (0.403056 --> 0.400486).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 64.15717029571533
Epoch: 39, Steps: 92 | Train Loss: 0.1296156 Vali Loss: 0.3986319 Test Loss: 0.4733922
Validation loss decreased (0.400486 --> 0.398632).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 71.5162456035614
Epoch: 40, Steps: 92 | Train Loss: 0.1279703 Vali Loss: 0.3978287 Test Loss: 0.4715092
Validation loss decreased (0.398632 --> 0.397829).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 68.99764943122864
Epoch: 41, Steps: 92 | Train Loss: 0.1263627 Vali Loss: 0.3949748 Test Loss: 0.4693874
Validation loss decreased (0.397829 --> 0.394975).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 70.48523116111755
Epoch: 42, Steps: 92 | Train Loss: 0.1248739 Vali Loss: 0.3921397 Test Loss: 0.4679865
Validation loss decreased (0.394975 --> 0.392140).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 68.7720696926117
Epoch: 43, Steps: 92 | Train Loss: 0.1235253 Vali Loss: 0.3913540 Test Loss: 0.4661009
Validation loss decreased (0.392140 --> 0.391354).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 69.3415961265564
Epoch: 44, Steps: 92 | Train Loss: 0.1222290 Vali Loss: 0.3895551 Test Loss: 0.4646180
Validation loss decreased (0.391354 --> 0.389555).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 67.8221697807312
Epoch: 45, Steps: 92 | Train Loss: 0.1210244 Vali Loss: 0.3888227 Test Loss: 0.4632168
Validation loss decreased (0.389555 --> 0.388823).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 66.65325236320496
Epoch: 46, Steps: 92 | Train Loss: 0.1198785 Vali Loss: 0.3882935 Test Loss: 0.4619568
Validation loss decreased (0.388823 --> 0.388293).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 71.71013021469116
Epoch: 47, Steps: 92 | Train Loss: 0.1188072 Vali Loss: 0.3865670 Test Loss: 0.4607978
Validation loss decreased (0.388293 --> 0.386567).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 69.93231248855591
Epoch: 48, Steps: 92 | Train Loss: 0.1178227 Vali Loss: 0.3852468 Test Loss: 0.4593837
Validation loss decreased (0.386567 --> 0.385247).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 65.72653985023499
Epoch: 49, Steps: 92 | Train Loss: 0.1168825 Vali Loss: 0.3836037 Test Loss: 0.4582792
Validation loss decreased (0.385247 --> 0.383604).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 71.42130041122437
Epoch: 50, Steps: 92 | Train Loss: 0.1160208 Vali Loss: 0.3820749 Test Loss: 0.4574064
Validation loss decreased (0.383604 --> 0.382075).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 66.18197989463806
Epoch: 51, Steps: 92 | Train Loss: 0.1151887 Vali Loss: 0.3813659 Test Loss: 0.4565518
Validation loss decreased (0.382075 --> 0.381366).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 74.43351006507874
Epoch: 52, Steps: 92 | Train Loss: 0.1144232 Vali Loss: 0.3816631 Test Loss: 0.4556669
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 66.3485655784607
Epoch: 53, Steps: 92 | Train Loss: 0.1136707 Vali Loss: 0.3801028 Test Loss: 0.4547113
Validation loss decreased (0.381366 --> 0.380103).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 73.31099033355713
Epoch: 54, Steps: 92 | Train Loss: 0.1129866 Vali Loss: 0.3811596 Test Loss: 0.4539342
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 66.79751372337341
Epoch: 55, Steps: 92 | Train Loss: 0.1123390 Vali Loss: 0.3790803 Test Loss: 0.4529454
Validation loss decreased (0.380103 --> 0.379080).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 67.52566313743591
Epoch: 56, Steps: 92 | Train Loss: 0.1117013 Vali Loss: 0.3787168 Test Loss: 0.4523261
Validation loss decreased (0.379080 --> 0.378717).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 68.46716237068176
Epoch: 57, Steps: 92 | Train Loss: 0.1111239 Vali Loss: 0.3779630 Test Loss: 0.4517061
Validation loss decreased (0.378717 --> 0.377963).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 68.52374982833862
Epoch: 58, Steps: 92 | Train Loss: 0.1105695 Vali Loss: 0.3765534 Test Loss: 0.4510210
Validation loss decreased (0.377963 --> 0.376553).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 64.12095236778259
Epoch: 59, Steps: 92 | Train Loss: 0.1100552 Vali Loss: 0.3767344 Test Loss: 0.4504545
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 65.455557346344
Epoch: 60, Steps: 92 | Train Loss: 0.1095580 Vali Loss: 0.3749128 Test Loss: 0.4499691
Validation loss decreased (0.376553 --> 0.374913).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 64.69092464447021
Epoch: 61, Steps: 92 | Train Loss: 0.1090961 Vali Loss: 0.3754595 Test Loss: 0.4493156
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 64.53251051902771
Epoch: 62, Steps: 92 | Train Loss: 0.1086465 Vali Loss: 0.3748994 Test Loss: 0.4488796
Validation loss decreased (0.374913 --> 0.374899).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 63.213152170181274
Epoch: 63, Steps: 92 | Train Loss: 0.1082455 Vali Loss: 0.3745188 Test Loss: 0.4484163
Validation loss decreased (0.374899 --> 0.374519).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 63.62606358528137
Epoch: 64, Steps: 92 | Train Loss: 0.1078365 Vali Loss: 0.3740835 Test Loss: 0.4479611
Validation loss decreased (0.374519 --> 0.374084).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 63.45157551765442
Epoch: 65, Steps: 92 | Train Loss: 0.1074598 Vali Loss: 0.3727740 Test Loss: 0.4475724
Validation loss decreased (0.374084 --> 0.372774).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 66.2509024143219
Epoch: 66, Steps: 92 | Train Loss: 0.1071337 Vali Loss: 0.3736173 Test Loss: 0.4471521
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 66.05615139007568
Epoch: 67, Steps: 92 | Train Loss: 0.1068049 Vali Loss: 0.3721181 Test Loss: 0.4467202
Validation loss decreased (0.372774 --> 0.372118).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 68.3633463382721
Epoch: 68, Steps: 92 | Train Loss: 0.1064515 Vali Loss: 0.3727641 Test Loss: 0.4463640
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 61.54698467254639
Epoch: 69, Steps: 92 | Train Loss: 0.1061683 Vali Loss: 0.3723030 Test Loss: 0.4460168
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 66.06253099441528
Epoch: 70, Steps: 92 | Train Loss: 0.1058827 Vali Loss: 0.3712126 Test Loss: 0.4457669
Validation loss decreased (0.372118 --> 0.371213).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 65.27649903297424
Epoch: 71, Steps: 92 | Train Loss: 0.1056192 Vali Loss: 0.3716387 Test Loss: 0.4454329
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 67.3412549495697
Epoch: 72, Steps: 92 | Train Loss: 0.1053506 Vali Loss: 0.3715478 Test Loss: 0.4451288
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 63.52576231956482
Epoch: 73, Steps: 92 | Train Loss: 0.1050920 Vali Loss: 0.3707450 Test Loss: 0.4448661
Validation loss decreased (0.371213 --> 0.370745).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 66.97744870185852
Epoch: 74, Steps: 92 | Train Loss: 0.1048876 Vali Loss: 0.3701956 Test Loss: 0.4445657
Validation loss decreased (0.370745 --> 0.370196).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 62.81785035133362
Epoch: 75, Steps: 92 | Train Loss: 0.1046641 Vali Loss: 0.3698129 Test Loss: 0.4443376
Validation loss decreased (0.370196 --> 0.369813).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 66.60894632339478
Epoch: 76, Steps: 92 | Train Loss: 0.1044524 Vali Loss: 0.3708196 Test Loss: 0.4441034
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 65.028817653656
Epoch: 77, Steps: 92 | Train Loss: 0.1042508 Vali Loss: 0.3695991 Test Loss: 0.4438631
Validation loss decreased (0.369813 --> 0.369599).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 61.55350661277771
Epoch: 78, Steps: 92 | Train Loss: 0.1040823 Vali Loss: 0.3696667 Test Loss: 0.4436722
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 65.41665172576904
Epoch: 79, Steps: 92 | Train Loss: 0.1038880 Vali Loss: 0.3689022 Test Loss: 0.4434923
Validation loss decreased (0.369599 --> 0.368902).  Saving model ...
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 65.82932806015015
Epoch: 80, Steps: 92 | Train Loss: 0.1036939 Vali Loss: 0.3694954 Test Loss: 0.4433092
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 67.98272967338562
Epoch: 81, Steps: 92 | Train Loss: 0.1035795 Vali Loss: 0.3687434 Test Loss: 0.4431457
Validation loss decreased (0.368902 --> 0.368743).  Saving model ...
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 66.68455505371094
Epoch: 82, Steps: 92 | Train Loss: 0.1033938 Vali Loss: 0.3689792 Test Loss: 0.4429294
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 66.98298382759094
Epoch: 83, Steps: 92 | Train Loss: 0.1032493 Vali Loss: 0.3685670 Test Loss: 0.4427672
Validation loss decreased (0.368743 --> 0.368567).  Saving model ...
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 66.66035985946655
Epoch: 84, Steps: 92 | Train Loss: 0.1031371 Vali Loss: 0.3686384 Test Loss: 0.4426416
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 65.41890120506287
Epoch: 85, Steps: 92 | Train Loss: 0.1030182 Vali Loss: 0.3686125 Test Loss: 0.4424957
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 65.67074918746948
Epoch: 86, Steps: 92 | Train Loss: 0.1028885 Vali Loss: 0.3683344 Test Loss: 0.4423631
Validation loss decreased (0.368567 --> 0.368334).  Saving model ...
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 69.90798163414001
Epoch: 87, Steps: 92 | Train Loss: 0.1027598 Vali Loss: 0.3682815 Test Loss: 0.4422463
Validation loss decreased (0.368334 --> 0.368281).  Saving model ...
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 69.35715675354004
Epoch: 88, Steps: 92 | Train Loss: 0.1026369 Vali Loss: 0.3680792 Test Loss: 0.4421107
Validation loss decreased (0.368281 --> 0.368079).  Saving model ...
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 65.03270769119263
Epoch: 89, Steps: 92 | Train Loss: 0.1025468 Vali Loss: 0.3679954 Test Loss: 0.4420026
Validation loss decreased (0.368079 --> 0.367995).  Saving model ...
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 65.95188045501709
Epoch: 90, Steps: 92 | Train Loss: 0.1024412 Vali Loss: 0.3684019 Test Loss: 0.4418665
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 65.35042977333069
Epoch: 91, Steps: 92 | Train Loss: 0.1023595 Vali Loss: 0.3676798 Test Loss: 0.4417644
Validation loss decreased (0.367995 --> 0.367680).  Saving model ...
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 65.52649283409119
Epoch: 92, Steps: 92 | Train Loss: 0.1022402 Vali Loss: 0.3684324 Test Loss: 0.4416685
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 68.38693594932556
Epoch: 93, Steps: 92 | Train Loss: 0.1021813 Vali Loss: 0.3680412 Test Loss: 0.4415810
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 69.05514907836914
Epoch: 94, Steps: 92 | Train Loss: 0.1020940 Vali Loss: 0.3673404 Test Loss: 0.4414806
Validation loss decreased (0.367680 --> 0.367340).  Saving model ...
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 69.07050848007202
Epoch: 95, Steps: 92 | Train Loss: 0.1019914 Vali Loss: 0.3673495 Test Loss: 0.4413884
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 64.1391294002533
Epoch: 96, Steps: 92 | Train Loss: 0.1019258 Vali Loss: 0.3671212 Test Loss: 0.4413183
Validation loss decreased (0.367340 --> 0.367121).  Saving model ...
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 70.17759728431702
Epoch: 97, Steps: 92 | Train Loss: 0.1018613 Vali Loss: 0.3685105 Test Loss: 0.4412348
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 63.80156636238098
Epoch: 98, Steps: 92 | Train Loss: 0.1017963 Vali Loss: 0.3678141 Test Loss: 0.4411718
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 67.54679942131042
Epoch: 99, Steps: 92 | Train Loss: 0.1017475 Vali Loss: 0.3678513 Test Loss: 0.4410954
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 65.57024812698364
Epoch: 100, Steps: 92 | Train Loss: 0.1016834 Vali Loss: 0.3672839 Test Loss: 0.4410346
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.1160680107021042e-06
train 11825
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=90, out_features=114, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1132047360.0
params:  10374.0
Trainable parameters:  10374
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 68.91401982307434
Epoch: 1, Steps: 92 | Train Loss: 0.2579193 Vali Loss: 0.3464788 Test Loss: 0.4236085
Validation loss decreased (inf --> 0.346479).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 64.07148766517639
Epoch: 2, Steps: 92 | Train Loss: 0.2543402 Vali Loss: 0.3454171 Test Loss: 0.4226254
Validation loss decreased (0.346479 --> 0.345417).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 65.9544780254364
Epoch: 3, Steps: 92 | Train Loss: 0.2539318 Vali Loss: 0.3455291 Test Loss: 0.4221649
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00045125
Epoch: 4 cost time: 63.95331287384033
Epoch: 4, Steps: 92 | Train Loss: 0.2536669 Vali Loss: 0.3448430 Test Loss: 0.4216109
Validation loss decreased (0.345417 --> 0.344843).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 65.91576313972473
Epoch: 5, Steps: 92 | Train Loss: 0.2534767 Vali Loss: 0.3430057 Test Loss: 0.4218920
Validation loss decreased (0.344843 --> 0.343006).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 63.17033863067627
Epoch: 6, Steps: 92 | Train Loss: 0.2533769 Vali Loss: 0.3448451 Test Loss: 0.4216774
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 69.50706696510315
Epoch: 7, Steps: 92 | Train Loss: 0.2534265 Vali Loss: 0.3437733 Test Loss: 0.4218384
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 66.53925466537476
Epoch: 8, Steps: 92 | Train Loss: 0.2533164 Vali Loss: 0.3439105 Test Loss: 0.4214906
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 71.3592312335968
Epoch: 9, Steps: 92 | Train Loss: 0.2532720 Vali Loss: 0.3429501 Test Loss: 0.4213986
Validation loss decreased (0.343006 --> 0.342950).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 66.73918771743774
Epoch: 10, Steps: 92 | Train Loss: 0.2531760 Vali Loss: 0.3442880 Test Loss: 0.4216708
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 70.01148986816406
Epoch: 11, Steps: 92 | Train Loss: 0.2532344 Vali Loss: 0.3436879 Test Loss: 0.4213612
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 65.52032613754272
Epoch: 12, Steps: 92 | Train Loss: 0.2530946 Vali Loss: 0.3432426 Test Loss: 0.4215893
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 66.53851461410522
Epoch: 13, Steps: 92 | Train Loss: 0.2531619 Vali Loss: 0.3443781 Test Loss: 0.4216166
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 66.29367685317993
Epoch: 14, Steps: 92 | Train Loss: 0.2531330 Vali Loss: 0.3436854 Test Loss: 0.4211511
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 68.73319339752197
Epoch: 15, Steps: 92 | Train Loss: 0.2531099 Vali Loss: 0.3443070 Test Loss: 0.4211567
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 67.74887466430664
Epoch: 16, Steps: 92 | Train Loss: 0.2531492 Vali Loss: 0.3443144 Test Loss: 0.4214036
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 69.98811626434326
Epoch: 17, Steps: 92 | Train Loss: 0.2531258 Vali Loss: 0.3436527 Test Loss: 0.4212939
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 66.18624639511108
Epoch: 18, Steps: 92 | Train Loss: 0.2530776 Vali Loss: 0.3445010 Test Loss: 0.4211210
EarlyStopping counter: 9 out of 10
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 66.21034574508667
Epoch: 19, Steps: 92 | Train Loss: 0.2530536 Vali Loss: 0.3429069 Test Loss: 0.4210260
Validation loss decreased (0.342950 --> 0.342907).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 67.34720158576965
Epoch: 20, Steps: 92 | Train Loss: 0.2530227 Vali Loss: 0.3440163 Test Loss: 0.4212834
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 68.89533376693726
Epoch: 21, Steps: 92 | Train Loss: 0.2530264 Vali Loss: 0.3427618 Test Loss: 0.4212110
Validation loss decreased (0.342907 --> 0.342762).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 66.71753001213074
Epoch: 22, Steps: 92 | Train Loss: 0.2529342 Vali Loss: 0.3440574 Test Loss: 0.4211190
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 68.70073509216309
Epoch: 23, Steps: 92 | Train Loss: 0.2529304 Vali Loss: 0.3433974 Test Loss: 0.4211079
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 68.98395919799805
Epoch: 24, Steps: 92 | Train Loss: 0.2530059 Vali Loss: 0.3429116 Test Loss: 0.4212162
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 65.12531185150146
Epoch: 25, Steps: 92 | Train Loss: 0.2529485 Vali Loss: 0.3428903 Test Loss: 0.4211249
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 68.38524150848389
Epoch: 26, Steps: 92 | Train Loss: 0.2529039 Vali Loss: 0.3440032 Test Loss: 0.4209715
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 67.03719997406006
Epoch: 27, Steps: 92 | Train Loss: 0.2530223 Vali Loss: 0.3437582 Test Loss: 0.4210653
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 72.48628544807434
Epoch: 28, Steps: 92 | Train Loss: 0.2529393 Vali Loss: 0.3443004 Test Loss: 0.4211374
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 67.03719663619995
Epoch: 29, Steps: 92 | Train Loss: 0.2529781 Vali Loss: 0.3441540 Test Loss: 0.4209917
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 64.73973202705383
Epoch: 30, Steps: 92 | Train Loss: 0.2529534 Vali Loss: 0.3446302 Test Loss: 0.4210577
EarlyStopping counter: 9 out of 10
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 66.8332028388977
Epoch: 31, Steps: 92 | Train Loss: 0.2528573 Vali Loss: 0.3438997 Test Loss: 0.4209918
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : Traffic_360_j96_H5_FITS_custom_ftM_sl360_ll48_pl96_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3413
mse:0.41974833607673645, mae:0.2929718792438507, rse:0.5364730954170227, corr:[0.2863684  0.29516757 0.2956202  0.29544142 0.29518437 0.2949479
 0.29478103 0.29457718 0.29432717 0.29420334 0.29432717 0.29450288
 0.29455543 0.29447034 0.29438728 0.29438326 0.29441336 0.29442194
 0.2943436  0.29421827 0.2940605  0.2938258  0.29370818 0.29418352
 0.2948705  0.2947857  0.29442453 0.29416236 0.29408953 0.29417098
 0.29427937 0.29433602 0.29434198 0.29430652 0.29426602 0.29422778
 0.29427502 0.29434508 0.29439133 0.2944249  0.29450122 0.2945637
 0.2944986  0.29433066 0.29416174 0.29400027 0.2938545  0.29393628
 0.29412892 0.29408684 0.29402864 0.2940832  0.29418644 0.2941564
 0.2939195  0.29360557 0.29338664 0.29331785 0.2933747  0.2935073
 0.29371446 0.2938705  0.29392037 0.29392046 0.29394418 0.29393837
 0.29382187 0.2936944  0.2937162  0.293848   0.29388613 0.29384625
 0.29369602 0.293562   0.2935811  0.293672   0.29367596 0.2935631
 0.29347295 0.29349852 0.29353836 0.29347575 0.29339018 0.2934235
 0.29352167 0.2934507  0.29324847 0.29317182 0.29322374 0.2931011
 0.29275644 0.29249927 0.29237592 0.2921357  0.29210216 0.293121  ]
