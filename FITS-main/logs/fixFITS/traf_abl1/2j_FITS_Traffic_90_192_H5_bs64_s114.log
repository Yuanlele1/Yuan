Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=30, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_90_j192_H5', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=10, pred_len=192, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_90_j192_H5_FITS_custom_ftM_sl90_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11999
val 1565
test 3317
Model(
  (freq_upsampler): Linear(in_features=30, out_features=94, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  311147520.0
params:  2914.0
Trainable parameters:  2914
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 54.897908210754395
Epoch: 1, Steps: 93 | Train Loss: 1.4107534 Vali Loss: 1.4684149 Test Loss: 1.7346840
Validation loss decreased (inf --> 1.468415).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 47.98944687843323
Epoch: 2, Steps: 93 | Train Loss: 0.9096570 Vali Loss: 1.0986818 Test Loss: 1.3005795
Validation loss decreased (1.468415 --> 1.098682).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 51.221497535705566
Epoch: 3, Steps: 93 | Train Loss: 0.6790496 Vali Loss: 0.9095724 Test Loss: 1.0788448
Validation loss decreased (1.098682 --> 0.909572).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 50.14493274688721
Epoch: 4, Steps: 93 | Train Loss: 0.5545490 Vali Loss: 0.7991655 Test Loss: 0.9494601
Validation loss decreased (0.909572 --> 0.799166).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 52.13458609580994
Epoch: 5, Steps: 93 | Train Loss: 0.4793618 Vali Loss: 0.7303693 Test Loss: 0.8696055
Validation loss decreased (0.799166 --> 0.730369).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 51.54503417015076
Epoch: 6, Steps: 93 | Train Loss: 0.4307840 Vali Loss: 0.6848144 Test Loss: 0.8166332
Validation loss decreased (0.730369 --> 0.684814).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 50.42979717254639
Epoch: 7, Steps: 93 | Train Loss: 0.3975286 Vali Loss: 0.6517619 Test Loss: 0.7800132
Validation loss decreased (0.684814 --> 0.651762).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 49.54110360145569
Epoch: 8, Steps: 93 | Train Loss: 0.3741218 Vali Loss: 0.6296881 Test Loss: 0.7539288
Validation loss decreased (0.651762 --> 0.629688).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 51.207985401153564
Epoch: 9, Steps: 93 | Train Loss: 0.3570497 Vali Loss: 0.6116906 Test Loss: 0.7342520
Validation loss decreased (0.629688 --> 0.611691).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 50.193371534347534
Epoch: 10, Steps: 93 | Train Loss: 0.3442271 Vali Loss: 0.5982179 Test Loss: 0.7193313
Validation loss decreased (0.611691 --> 0.598218).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 50.79917335510254
Epoch: 11, Steps: 93 | Train Loss: 0.3341964 Vali Loss: 0.5886384 Test Loss: 0.7075838
Validation loss decreased (0.598218 --> 0.588638).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 50.23795533180237
Epoch: 12, Steps: 93 | Train Loss: 0.3263492 Vali Loss: 0.5799324 Test Loss: 0.6980018
Validation loss decreased (0.588638 --> 0.579932).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 53.429683446884155
Epoch: 13, Steps: 93 | Train Loss: 0.3200255 Vali Loss: 0.5730289 Test Loss: 0.6901744
Validation loss decreased (0.579932 --> 0.573029).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 50.63399147987366
Epoch: 14, Steps: 93 | Train Loss: 0.3147895 Vali Loss: 0.5670713 Test Loss: 0.6836008
Validation loss decreased (0.573029 --> 0.567071).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 51.06739354133606
Epoch: 15, Steps: 93 | Train Loss: 0.3104680 Vali Loss: 0.5626574 Test Loss: 0.6779156
Validation loss decreased (0.567071 --> 0.562657).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 52.07375907897949
Epoch: 16, Steps: 93 | Train Loss: 0.3067215 Vali Loss: 0.5579469 Test Loss: 0.6731068
Validation loss decreased (0.562657 --> 0.557947).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 52.74733233451843
Epoch: 17, Steps: 93 | Train Loss: 0.3037472 Vali Loss: 0.5544800 Test Loss: 0.6689930
Validation loss decreased (0.557947 --> 0.554480).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 51.82693362236023
Epoch: 18, Steps: 93 | Train Loss: 0.3010123 Vali Loss: 0.5517195 Test Loss: 0.6653858
Validation loss decreased (0.554480 --> 0.551719).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 49.273247957229614
Epoch: 19, Steps: 93 | Train Loss: 0.2987201 Vali Loss: 0.5477253 Test Loss: 0.6621959
Validation loss decreased (0.551719 --> 0.547725).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 52.79832601547241
Epoch: 20, Steps: 93 | Train Loss: 0.2966429 Vali Loss: 0.5456844 Test Loss: 0.6594439
Validation loss decreased (0.547725 --> 0.545684).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 53.165170192718506
Epoch: 21, Steps: 93 | Train Loss: 0.2948322 Vali Loss: 0.5431519 Test Loss: 0.6569464
Validation loss decreased (0.545684 --> 0.543152).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 53.64031744003296
Epoch: 22, Steps: 93 | Train Loss: 0.2932858 Vali Loss: 0.5414898 Test Loss: 0.6547531
Validation loss decreased (0.543152 --> 0.541490).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 50.72317099571228
Epoch: 23, Steps: 93 | Train Loss: 0.2918331 Vali Loss: 0.5395913 Test Loss: 0.6527217
Validation loss decreased (0.541490 --> 0.539591).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 52.12562537193298
Epoch: 24, Steps: 93 | Train Loss: 0.2906031 Vali Loss: 0.5380720 Test Loss: 0.6509554
Validation loss decreased (0.539591 --> 0.538072).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 51.29496359825134
Epoch: 25, Steps: 93 | Train Loss: 0.2895161 Vali Loss: 0.5360611 Test Loss: 0.6494102
Validation loss decreased (0.538072 --> 0.536061).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 54.06623578071594
Epoch: 26, Steps: 93 | Train Loss: 0.2884411 Vali Loss: 0.5353900 Test Loss: 0.6479413
Validation loss decreased (0.536061 --> 0.535390).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 52.094876289367676
Epoch: 27, Steps: 93 | Train Loss: 0.2876314 Vali Loss: 0.5334380 Test Loss: 0.6466340
Validation loss decreased (0.535390 --> 0.533438).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 50.29230713844299
Epoch: 28, Steps: 93 | Train Loss: 0.2867251 Vali Loss: 0.5331321 Test Loss: 0.6454452
Validation loss decreased (0.533438 --> 0.533132).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 49.59939742088318
Epoch: 29, Steps: 93 | Train Loss: 0.2859046 Vali Loss: 0.5318757 Test Loss: 0.6442934
Validation loss decreased (0.533132 --> 0.531876).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 54.63000249862671
Epoch: 30, Steps: 93 | Train Loss: 0.2851810 Vali Loss: 0.5313028 Test Loss: 0.6433728
Validation loss decreased (0.531876 --> 0.531303).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 51.046061754226685
Epoch: 31, Steps: 93 | Train Loss: 0.2845027 Vali Loss: 0.5294715 Test Loss: 0.6424570
Validation loss decreased (0.531303 --> 0.529471).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 55.65731859207153
Epoch: 32, Steps: 93 | Train Loss: 0.2839712 Vali Loss: 0.5296353 Test Loss: 0.6416209
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 51.40078139305115
Epoch: 33, Steps: 93 | Train Loss: 0.2834282 Vali Loss: 0.5291057 Test Loss: 0.6408328
Validation loss decreased (0.529471 --> 0.529106).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 54.40892219543457
Epoch: 34, Steps: 93 | Train Loss: 0.2828083 Vali Loss: 0.5278547 Test Loss: 0.6400912
Validation loss decreased (0.529106 --> 0.527855).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 51.49725317955017
Epoch: 35, Steps: 93 | Train Loss: 0.2824091 Vali Loss: 0.5274740 Test Loss: 0.6394139
Validation loss decreased (0.527855 --> 0.527474).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 52.62092733383179
Epoch: 36, Steps: 93 | Train Loss: 0.2819752 Vali Loss: 0.5268989 Test Loss: 0.6387968
Validation loss decreased (0.527474 --> 0.526899).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 52.67657685279846
Epoch: 37, Steps: 93 | Train Loss: 0.2815757 Vali Loss: 0.5265767 Test Loss: 0.6382296
Validation loss decreased (0.526899 --> 0.526577).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 50.66438627243042
Epoch: 38, Steps: 93 | Train Loss: 0.2811882 Vali Loss: 0.5262722 Test Loss: 0.6376983
Validation loss decreased (0.526577 --> 0.526272).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 49.41822052001953
Epoch: 39, Steps: 93 | Train Loss: 0.2807643 Vali Loss: 0.5253855 Test Loss: 0.6371718
Validation loss decreased (0.526272 --> 0.525385).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 51.20362138748169
Epoch: 40, Steps: 93 | Train Loss: 0.2804874 Vali Loss: 0.5251051 Test Loss: 0.6367131
Validation loss decreased (0.525385 --> 0.525105).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 50.24503421783447
Epoch: 41, Steps: 93 | Train Loss: 0.2802292 Vali Loss: 0.5244293 Test Loss: 0.6362739
Validation loss decreased (0.525105 --> 0.524429).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 54.162171602249146
Epoch: 42, Steps: 93 | Train Loss: 0.2799556 Vali Loss: 0.5248665 Test Loss: 0.6358613
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 49.1111261844635
Epoch: 43, Steps: 93 | Train Loss: 0.2796167 Vali Loss: 0.5233340 Test Loss: 0.6354384
Validation loss decreased (0.524429 --> 0.523334).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 50.54948806762695
Epoch: 44, Steps: 93 | Train Loss: 0.2792032 Vali Loss: 0.5232773 Test Loss: 0.6350772
Validation loss decreased (0.523334 --> 0.523277).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 48.68884754180908
Epoch: 45, Steps: 93 | Train Loss: 0.2790963 Vali Loss: 0.5233146 Test Loss: 0.6347477
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 50.428980350494385
Epoch: 46, Steps: 93 | Train Loss: 0.2787210 Vali Loss: 0.5224466 Test Loss: 0.6344172
Validation loss decreased (0.523277 --> 0.522447).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 50.47452163696289
Epoch: 47, Steps: 93 | Train Loss: 0.2786035 Vali Loss: 0.5223423 Test Loss: 0.6340752
Validation loss decreased (0.522447 --> 0.522342).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 51.03311729431152
Epoch: 48, Steps: 93 | Train Loss: 0.2783557 Vali Loss: 0.5218596 Test Loss: 0.6338046
Validation loss decreased (0.522342 --> 0.521860).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 47.769540786743164
Epoch: 49, Steps: 93 | Train Loss: 0.2782649 Vali Loss: 0.5221847 Test Loss: 0.6335245
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 52.10098338127136
Epoch: 50, Steps: 93 | Train Loss: 0.2780410 Vali Loss: 0.5213159 Test Loss: 0.6332770
Validation loss decreased (0.521860 --> 0.521316).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 46.929789781570435
Epoch: 51, Steps: 93 | Train Loss: 0.2779063 Vali Loss: 0.5218332 Test Loss: 0.6330112
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 45.80348062515259
Epoch: 52, Steps: 93 | Train Loss: 0.2777094 Vali Loss: 0.5211653 Test Loss: 0.6327767
Validation loss decreased (0.521316 --> 0.521165).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 43.31172204017639
Epoch: 53, Steps: 93 | Train Loss: 0.2774580 Vali Loss: 0.5214778 Test Loss: 0.6325362
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 47.88720655441284
Epoch: 54, Steps: 93 | Train Loss: 0.2773241 Vali Loss: 0.5202883 Test Loss: 0.6323470
Validation loss decreased (0.521165 --> 0.520288).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 45.026050090789795
Epoch: 55, Steps: 93 | Train Loss: 0.2771285 Vali Loss: 0.5209195 Test Loss: 0.6321468
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 47.2213716506958
Epoch: 56, Steps: 93 | Train Loss: 0.2770887 Vali Loss: 0.5207187 Test Loss: 0.6319513
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 44.317769050598145
Epoch: 57, Steps: 93 | Train Loss: 0.2769652 Vali Loss: 0.5199636 Test Loss: 0.6317733
Validation loss decreased (0.520288 --> 0.519964).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 44.70136022567749
Epoch: 58, Steps: 93 | Train Loss: 0.2768095 Vali Loss: 0.5199811 Test Loss: 0.6315941
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 45.706096172332764
Epoch: 59, Steps: 93 | Train Loss: 0.2767314 Vali Loss: 0.5196416 Test Loss: 0.6314550
Validation loss decreased (0.519964 --> 0.519642).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 46.08275079727173
Epoch: 60, Steps: 93 | Train Loss: 0.2765976 Vali Loss: 0.5201438 Test Loss: 0.6312901
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 48.00776696205139
Epoch: 61, Steps: 93 | Train Loss: 0.2764952 Vali Loss: 0.5194671 Test Loss: 0.6311331
Validation loss decreased (0.519642 --> 0.519467).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 51.77084469795227
Epoch: 62, Steps: 93 | Train Loss: 0.2763332 Vali Loss: 0.5196027 Test Loss: 0.6310238
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 49.721352338790894
Epoch: 63, Steps: 93 | Train Loss: 0.2762293 Vali Loss: 0.5192385 Test Loss: 0.6308784
Validation loss decreased (0.519467 --> 0.519239).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 50.36274838447571
Epoch: 64, Steps: 93 | Train Loss: 0.2761651 Vali Loss: 0.5193055 Test Loss: 0.6307442
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 49.31437039375305
Epoch: 65, Steps: 93 | Train Loss: 0.2761224 Vali Loss: 0.5187570 Test Loss: 0.6306188
Validation loss decreased (0.519239 --> 0.518757).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 52.5189642906189
Epoch: 66, Steps: 93 | Train Loss: 0.2760010 Vali Loss: 0.5191623 Test Loss: 0.6305184
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 49.44705152511597
Epoch: 67, Steps: 93 | Train Loss: 0.2759754 Vali Loss: 0.5197138 Test Loss: 0.6304067
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 52.218679904937744
Epoch: 68, Steps: 93 | Train Loss: 0.2758848 Vali Loss: 0.5192172 Test Loss: 0.6303042
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 48.039583921432495
Epoch: 69, Steps: 93 | Train Loss: 0.2757163 Vali Loss: 0.5187573 Test Loss: 0.6302034
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 54.73853325843811
Epoch: 70, Steps: 93 | Train Loss: 0.2757386 Vali Loss: 0.5191141 Test Loss: 0.6301011
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 49.429574728012085
Epoch: 71, Steps: 93 | Train Loss: 0.2756263 Vali Loss: 0.5188264 Test Loss: 0.6300215
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 53.33024215698242
Epoch: 72, Steps: 93 | Train Loss: 0.2754713 Vali Loss: 0.5183910 Test Loss: 0.6299356
Validation loss decreased (0.518757 --> 0.518391).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 49.776183128356934
Epoch: 73, Steps: 93 | Train Loss: 0.2755082 Vali Loss: 0.5186088 Test Loss: 0.6298612
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 49.920642614364624
Epoch: 74, Steps: 93 | Train Loss: 0.2754622 Vali Loss: 0.5186093 Test Loss: 0.6297850
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 50.89406180381775
Epoch: 75, Steps: 93 | Train Loss: 0.2754791 Vali Loss: 0.5187023 Test Loss: 0.6297144
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 53.84445357322693
Epoch: 76, Steps: 93 | Train Loss: 0.2753711 Vali Loss: 0.5184203 Test Loss: 0.6296492
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 49.14736866950989
Epoch: 77, Steps: 93 | Train Loss: 0.2753628 Vali Loss: 0.5183856 Test Loss: 0.6295766
Validation loss decreased (0.518391 --> 0.518386).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 48.39529514312744
Epoch: 78, Steps: 93 | Train Loss: 0.2753026 Vali Loss: 0.5180734 Test Loss: 0.6295226
Validation loss decreased (0.518386 --> 0.518073).  Saving model ...
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 49.09366583824158
Epoch: 79, Steps: 93 | Train Loss: 0.2752351 Vali Loss: 0.5182648 Test Loss: 0.6294607
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 51.31325888633728
Epoch: 80, Steps: 93 | Train Loss: 0.2751923 Vali Loss: 0.5176248 Test Loss: 0.6294066
Validation loss decreased (0.518073 --> 0.517625).  Saving model ...
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 47.42550444602966
Epoch: 81, Steps: 93 | Train Loss: 0.2751768 Vali Loss: 0.5176487 Test Loss: 0.6293565
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 50.18659782409668
Epoch: 82, Steps: 93 | Train Loss: 0.2750974 Vali Loss: 0.5173973 Test Loss: 0.6293088
Validation loss decreased (0.517625 --> 0.517397).  Saving model ...
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 47.335997343063354
Epoch: 83, Steps: 93 | Train Loss: 0.2750973 Vali Loss: 0.5182552 Test Loss: 0.6292549
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 49.55975556373596
Epoch: 84, Steps: 93 | Train Loss: 0.2750012 Vali Loss: 0.5176997 Test Loss: 0.6292129
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 47.01909804344177
Epoch: 85, Steps: 93 | Train Loss: 0.2750017 Vali Loss: 0.5183158 Test Loss: 0.6291679
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 48.506325483322144
Epoch: 86, Steps: 93 | Train Loss: 0.2749625 Vali Loss: 0.5179096 Test Loss: 0.6291273
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 39.13019871711731
Epoch: 87, Steps: 93 | Train Loss: 0.2749611 Vali Loss: 0.5174903 Test Loss: 0.6290873
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 38.96410822868347
Epoch: 88, Steps: 93 | Train Loss: 0.2748568 Vali Loss: 0.5180815 Test Loss: 0.6290484
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 37.90573191642761
Epoch: 89, Steps: 93 | Train Loss: 0.2749268 Vali Loss: 0.5177006 Test Loss: 0.6290203
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 37.778202056884766
Epoch: 90, Steps: 93 | Train Loss: 0.2748465 Vali Loss: 0.5180416 Test Loss: 0.6289803
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 36.321491718292236
Epoch: 91, Steps: 93 | Train Loss: 0.2748397 Vali Loss: 0.5173430 Test Loss: 0.6289543
Validation loss decreased (0.517397 --> 0.517343).  Saving model ...
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 37.71967673301697
Epoch: 92, Steps: 93 | Train Loss: 0.2747964 Vali Loss: 0.5173107 Test Loss: 0.6289262
Validation loss decreased (0.517343 --> 0.517311).  Saving model ...
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 38.22568964958191
Epoch: 93, Steps: 93 | Train Loss: 0.2747957 Vali Loss: 0.5175908 Test Loss: 0.6288955
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 37.435094356536865
Epoch: 94, Steps: 93 | Train Loss: 0.2747817 Vali Loss: 0.5184261 Test Loss: 0.6288659
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 37.799115896224976
Epoch: 95, Steps: 93 | Train Loss: 0.2747922 Vali Loss: 0.5175384 Test Loss: 0.6288432
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 37.19113063812256
Epoch: 96, Steps: 93 | Train Loss: 0.2746637 Vali Loss: 0.5171686 Test Loss: 0.6288223
Validation loss decreased (0.517311 --> 0.517169).  Saving model ...
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 38.41698217391968
Epoch: 97, Steps: 93 | Train Loss: 0.2746998 Vali Loss: 0.5178618 Test Loss: 0.6287940
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 38.464855432510376
Epoch: 98, Steps: 93 | Train Loss: 0.2747304 Vali Loss: 0.5175750 Test Loss: 0.6287760
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 38.71429896354675
Epoch: 99, Steps: 93 | Train Loss: 0.2746775 Vali Loss: 0.5178245 Test Loss: 0.6287552
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 37.935643434524536
Epoch: 100, Steps: 93 | Train Loss: 0.2746510 Vali Loss: 0.5170439 Test Loss: 0.6287348
Validation loss decreased (0.517169 --> 0.517044).  Saving model ...
Updating learning rate to 3.1160680107021042e-06
train 11999
val 1565
test 3317
Model(
  (freq_upsampler): Linear(in_features=30, out_features=94, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  311147520.0
params:  2914.0
Trainable parameters:  2914
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 39.545734882354736
Epoch: 1, Steps: 93 | Train Loss: 0.3872937 Vali Loss: 0.5123306 Test Loss: 0.6239106
Validation loss decreased (inf --> 0.512331).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 37.47709822654724
Epoch: 2, Steps: 93 | Train Loss: 0.3852388 Vali Loss: 0.5112270 Test Loss: 0.6233591
Validation loss decreased (0.512331 --> 0.511227).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 37.490473985672
Epoch: 3, Steps: 93 | Train Loss: 0.3847514 Vali Loss: 0.5113969 Test Loss: 0.6230989
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00045125
Epoch: 4 cost time: 37.340211153030396
Epoch: 4, Steps: 93 | Train Loss: 0.3848152 Vali Loss: 0.5106128 Test Loss: 0.6228091
Validation loss decreased (0.511227 --> 0.510613).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 38.83776378631592
Epoch: 5, Steps: 93 | Train Loss: 0.3846785 Vali Loss: 0.5109525 Test Loss: 0.6230085
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 36.03182864189148
Epoch: 6, Steps: 93 | Train Loss: 0.3846839 Vali Loss: 0.5110634 Test Loss: 0.6229880
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 38.24560809135437
Epoch: 7, Steps: 93 | Train Loss: 0.3845255 Vali Loss: 0.5107726 Test Loss: 0.6231233
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 36.82157373428345
Epoch: 8, Steps: 93 | Train Loss: 0.3845815 Vali Loss: 0.5108154 Test Loss: 0.6230571
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 38.9518084526062
Epoch: 9, Steps: 93 | Train Loss: 0.3845193 Vali Loss: 0.5112413 Test Loss: 0.6229404
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 35.6861093044281
Epoch: 10, Steps: 93 | Train Loss: 0.3845643 Vali Loss: 0.5107142 Test Loss: 0.6228988
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 38.310728549957275
Epoch: 11, Steps: 93 | Train Loss: 0.3845059 Vali Loss: 0.5106036 Test Loss: 0.6228963
Validation loss decreased (0.510613 --> 0.510604).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 36.3012011051178
Epoch: 12, Steps: 93 | Train Loss: 0.3844044 Vali Loss: 0.5110047 Test Loss: 0.6227521
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 39.37243151664734
Epoch: 13, Steps: 93 | Train Loss: 0.3845524 Vali Loss: 0.5099952 Test Loss: 0.6226287
Validation loss decreased (0.510604 --> 0.509995).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 36.27689862251282
Epoch: 14, Steps: 93 | Train Loss: 0.3844320 Vali Loss: 0.5114859 Test Loss: 0.6228966
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 37.63094425201416
Epoch: 15, Steps: 93 | Train Loss: 0.3845648 Vali Loss: 0.5100667 Test Loss: 0.6229019
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 36.52691102027893
Epoch: 16, Steps: 93 | Train Loss: 0.3844514 Vali Loss: 0.5102480 Test Loss: 0.6226910
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 44.97490215301514
Epoch: 17, Steps: 93 | Train Loss: 0.3844644 Vali Loss: 0.5111332 Test Loss: 0.6227070
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 42.73823165893555
Epoch: 18, Steps: 93 | Train Loss: 0.3844472 Vali Loss: 0.5102684 Test Loss: 0.6227211
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 43.829750299453735
Epoch: 19, Steps: 93 | Train Loss: 0.3843630 Vali Loss: 0.5110053 Test Loss: 0.6229602
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 40.22726774215698
Epoch: 20, Steps: 93 | Train Loss: 0.3844731 Vali Loss: 0.5104421 Test Loss: 0.6226410
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 42.844555377960205
Epoch: 21, Steps: 93 | Train Loss: 0.3843695 Vali Loss: 0.5099041 Test Loss: 0.6226272
Validation loss decreased (0.509995 --> 0.509904).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 42.08020043373108
Epoch: 22, Steps: 93 | Train Loss: 0.3844942 Vali Loss: 0.5106424 Test Loss: 0.6227298
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 41.755512714385986
Epoch: 23, Steps: 93 | Train Loss: 0.3842953 Vali Loss: 0.5112149 Test Loss: 0.6227661
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 40.89818358421326
Epoch: 24, Steps: 93 | Train Loss: 0.3843295 Vali Loss: 0.5105857 Test Loss: 0.6228139
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 43.21501278877258
Epoch: 25, Steps: 93 | Train Loss: 0.3844758 Vali Loss: 0.5108714 Test Loss: 0.6227086
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 42.34708309173584
Epoch: 26, Steps: 93 | Train Loss: 0.3842918 Vali Loss: 0.5106233 Test Loss: 0.6226081
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 41.747223138809204
Epoch: 27, Steps: 93 | Train Loss: 0.3842999 Vali Loss: 0.5107145 Test Loss: 0.6226355
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 41.517152309417725
Epoch: 28, Steps: 93 | Train Loss: 0.3844002 Vali Loss: 0.5113750 Test Loss: 0.6227992
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 42.21253967285156
Epoch: 29, Steps: 93 | Train Loss: 0.3843725 Vali Loss: 0.5108340 Test Loss: 0.6226105
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 41.23102521896362
Epoch: 30, Steps: 93 | Train Loss: 0.3844507 Vali Loss: 0.5108737 Test Loss: 0.6226248
EarlyStopping counter: 9 out of 10
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 41.21508026123047
Epoch: 31, Steps: 93 | Train Loss: 0.3843565 Vali Loss: 0.5102552 Test Loss: 0.6226613
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : Traffic_90_j192_H5_FITS_custom_ftM_sl90_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3317
mse:0.622450590133667, mae:0.37581712007522583, rse:0.651150643825531, corr:[0.2720467  0.28508717 0.2852786  0.28418368 0.28396264 0.28482842
 0.28667566 0.28674704 0.28642556 0.2864159  0.28575954 0.28568545
 0.28496855 0.28412795 0.2846071  0.28509063 0.28560525 0.2867963
 0.2884597  0.2901673  0.29077357 0.29171395 0.29177475 0.29116014
 0.29585215 0.29891086 0.29790872 0.29699522 0.29716852 0.29821092
 0.29936334 0.30117074 0.30153826 0.3012551  0.3015702  0.30158377
 0.30071962 0.29974896 0.29945567 0.2994754  0.2996505  0.29997435
 0.30059665 0.30112883 0.3010669  0.30160433 0.30119    0.2997615
 0.30014855 0.29898953 0.29741606 0.2968104  0.29562417 0.29147023
 0.2882688  0.28936604 0.28965405 0.28921145 0.28911734 0.28825885
 0.28695697 0.28590253 0.28519335 0.28502166 0.28516734 0.28542903
 0.2860918  0.2864445  0.2858356  0.2857157  0.28560448 0.28422967
 0.28260213 0.28132832 0.28069723 0.28148207 0.28323016 0.2836994
 0.28389156 0.28615266 0.28663376 0.2860865  0.2854601  0.284157
 0.28317675 0.28241888 0.2814434  0.28116322 0.28120553 0.28100806
 0.28130093 0.2817505  0.28192914 0.28249398 0.2829034  0.28257197
 0.28213397 0.28199518 0.28197482 0.2818166  0.28189775 0.28246164
 0.2834247  0.2847608  0.28491172 0.28428474 0.28384513 0.2830116
 0.2822457  0.28198642 0.28159398 0.28140286 0.28156683 0.2817343
 0.28225547 0.28269112 0.28276205 0.28338534 0.28399846 0.28391463
 0.28377914 0.2838723  0.28416014 0.28417656 0.2839538  0.2839372
 0.28389168 0.28364766 0.28311667 0.28246212 0.28211457 0.28174117
 0.28137448 0.28130108 0.2812846  0.28164005 0.28222054 0.28248405
 0.28310066 0.28368846 0.28384528 0.28482744 0.285086   0.2836444
 0.28259742 0.28221115 0.28232148 0.28253615 0.28263566 0.28301242
 0.2833405  0.2833553  0.28306168 0.2823411  0.28182656 0.28146246
 0.2811856  0.28165248 0.28224155 0.28266227 0.28336436 0.28392145
 0.285159   0.2866557  0.28700098 0.28775498 0.28764093 0.28508753
 0.28387368 0.28249443 0.28079805 0.27995348 0.28043786 0.28244302
 0.28485072 0.28668144 0.2876263  0.28798375 0.2884902  0.28871492
 0.28802845 0.2873689  0.28709173 0.28639728 0.28541195 0.28501186
 0.28502846 0.28465727 0.28491876 0.28570014 0.28430176 0.28586537]
