Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=50, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_180_j192_H5', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=10, pred_len=192, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_180_j192_H5_FITS_custom_ftM_sl180_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11909
val 1565
test 3317
Model(
  (freq_upsampler): Linear(in_features=50, out_features=103, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  568230400.0
params:  5253.0
Trainable parameters:  5253
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 60.60002112388611
Epoch: 1, Steps: 93 | Train Loss: 1.2383543 Vali Loss: 1.2421733 Test Loss: 1.4700854
Validation loss decreased (inf --> 1.242173).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 56.02630352973938
Epoch: 2, Steps: 93 | Train Loss: 0.8040672 Vali Loss: 0.9426703 Test Loss: 1.1285200
Validation loss decreased (1.242173 --> 0.942670).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 57.01853060722351
Epoch: 3, Steps: 93 | Train Loss: 0.6049890 Vali Loss: 0.7853076 Test Loss: 0.9500526
Validation loss decreased (0.942670 --> 0.785308).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 54.85610842704773
Epoch: 4, Steps: 93 | Train Loss: 0.4917390 Vali Loss: 0.6927855 Test Loss: 0.8454341
Validation loss decreased (0.785308 --> 0.692786).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 59.4180588722229
Epoch: 5, Steps: 93 | Train Loss: 0.4213011 Vali Loss: 0.6334617 Test Loss: 0.7785383
Validation loss decreased (0.692786 --> 0.633462).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 54.23447632789612
Epoch: 6, Steps: 93 | Train Loss: 0.3744897 Vali Loss: 0.5932534 Test Loss: 0.7324508
Validation loss decreased (0.633462 --> 0.593253).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 57.818851709365845
Epoch: 7, Steps: 93 | Train Loss: 0.3416315 Vali Loss: 0.5629436 Test Loss: 0.6974068
Validation loss decreased (0.593253 --> 0.562944).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 55.66046690940857
Epoch: 8, Steps: 93 | Train Loss: 0.3173318 Vali Loss: 0.5415513 Test Loss: 0.6718293
Validation loss decreased (0.562944 --> 0.541551).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 57.28118872642517
Epoch: 9, Steps: 93 | Train Loss: 0.2986025 Vali Loss: 0.5230939 Test Loss: 0.6503178
Validation loss decreased (0.541551 --> 0.523094).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 59.20670533180237
Epoch: 10, Steps: 93 | Train Loss: 0.2835845 Vali Loss: 0.5076629 Test Loss: 0.6323219
Validation loss decreased (0.523094 --> 0.507663).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 58.507649660110474
Epoch: 11, Steps: 93 | Train Loss: 0.2712547 Vali Loss: 0.4960699 Test Loss: 0.6168311
Validation loss decreased (0.507663 --> 0.496070).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 59.005191802978516
Epoch: 12, Steps: 93 | Train Loss: 0.2608661 Vali Loss: 0.4849927 Test Loss: 0.6041358
Validation loss decreased (0.496070 --> 0.484993).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 57.598363399505615
Epoch: 13, Steps: 93 | Train Loss: 0.2520188 Vali Loss: 0.4765960 Test Loss: 0.5927566
Validation loss decreased (0.484993 --> 0.476596).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 58.35335683822632
Epoch: 14, Steps: 93 | Train Loss: 0.2443615 Vali Loss: 0.4680538 Test Loss: 0.5826029
Validation loss decreased (0.476596 --> 0.468054).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 58.989856243133545
Epoch: 15, Steps: 93 | Train Loss: 0.2376697 Vali Loss: 0.4611675 Test Loss: 0.5735987
Validation loss decreased (0.468054 --> 0.461168).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 58.54989790916443
Epoch: 16, Steps: 93 | Train Loss: 0.2317722 Vali Loss: 0.4550681 Test Loss: 0.5657051
Validation loss decreased (0.461168 --> 0.455068).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 56.68901491165161
Epoch: 17, Steps: 93 | Train Loss: 0.2265454 Vali Loss: 0.4490725 Test Loss: 0.5584304
Validation loss decreased (0.455068 --> 0.449073).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 59.52225732803345
Epoch: 18, Steps: 93 | Train Loss: 0.2218830 Vali Loss: 0.4437404 Test Loss: 0.5522031
Validation loss decreased (0.449073 --> 0.443740).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 59.750741720199585
Epoch: 19, Steps: 93 | Train Loss: 0.2177216 Vali Loss: 0.4389649 Test Loss: 0.5464043
Validation loss decreased (0.443740 --> 0.438965).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 61.78073477745056
Epoch: 20, Steps: 93 | Train Loss: 0.2139814 Vali Loss: 0.4354829 Test Loss: 0.5411015
Validation loss decreased (0.438965 --> 0.435483).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 62.9542019367218
Epoch: 21, Steps: 93 | Train Loss: 0.2106005 Vali Loss: 0.4314954 Test Loss: 0.5365291
Validation loss decreased (0.435483 --> 0.431495).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 58.29943132400513
Epoch: 22, Steps: 93 | Train Loss: 0.2075379 Vali Loss: 0.4282764 Test Loss: 0.5321880
Validation loss decreased (0.431495 --> 0.428276).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 60.377485513687134
Epoch: 23, Steps: 93 | Train Loss: 0.2047580 Vali Loss: 0.4250130 Test Loss: 0.5282816
Validation loss decreased (0.428276 --> 0.425013).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 58.03193545341492
Epoch: 24, Steps: 93 | Train Loss: 0.2022356 Vali Loss: 0.4218228 Test Loss: 0.5246631
Validation loss decreased (0.425013 --> 0.421823).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 60.26876473426819
Epoch: 25, Steps: 93 | Train Loss: 0.1999043 Vali Loss: 0.4199942 Test Loss: 0.5214881
Validation loss decreased (0.421823 --> 0.419994).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 59.484949588775635
Epoch: 26, Steps: 93 | Train Loss: 0.1977949 Vali Loss: 0.4171080 Test Loss: 0.5185527
Validation loss decreased (0.419994 --> 0.417108).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 59.740275859832764
Epoch: 27, Steps: 93 | Train Loss: 0.1958600 Vali Loss: 0.4151258 Test Loss: 0.5157510
Validation loss decreased (0.417108 --> 0.415126).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 60.55035400390625
Epoch: 28, Steps: 93 | Train Loss: 0.1940639 Vali Loss: 0.4131047 Test Loss: 0.5132714
Validation loss decreased (0.415126 --> 0.413105).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 59.65284442901611
Epoch: 29, Steps: 93 | Train Loss: 0.1924242 Vali Loss: 0.4107280 Test Loss: 0.5109020
Validation loss decreased (0.413105 --> 0.410728).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 60.631505250930786
Epoch: 30, Steps: 93 | Train Loss: 0.1908989 Vali Loss: 0.4096087 Test Loss: 0.5087815
Validation loss decreased (0.410728 --> 0.409609).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 61.17456388473511
Epoch: 31, Steps: 93 | Train Loss: 0.1894967 Vali Loss: 0.4081260 Test Loss: 0.5067969
Validation loss decreased (0.409609 --> 0.408126).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 59.92188119888306
Epoch: 32, Steps: 93 | Train Loss: 0.1882005 Vali Loss: 0.4063766 Test Loss: 0.5050089
Validation loss decreased (0.408126 --> 0.406377).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 60.122851848602295
Epoch: 33, Steps: 93 | Train Loss: 0.1869974 Vali Loss: 0.4051197 Test Loss: 0.5033189
Validation loss decreased (0.406377 --> 0.405120).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 65.69342184066772
Epoch: 34, Steps: 93 | Train Loss: 0.1858802 Vali Loss: 0.4037132 Test Loss: 0.5016780
Validation loss decreased (0.405120 --> 0.403713).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 57.893035650253296
Epoch: 35, Steps: 93 | Train Loss: 0.1848266 Vali Loss: 0.4026009 Test Loss: 0.5002496
Validation loss decreased (0.403713 --> 0.402601).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 57.637306213378906
Epoch: 36, Steps: 93 | Train Loss: 0.1838538 Vali Loss: 0.4016982 Test Loss: 0.4988700
Validation loss decreased (0.402601 --> 0.401698).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 55.08420133590698
Epoch: 37, Steps: 93 | Train Loss: 0.1829449 Vali Loss: 0.4008393 Test Loss: 0.4976039
Validation loss decreased (0.401698 --> 0.400839).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 59.63392519950867
Epoch: 38, Steps: 93 | Train Loss: 0.1821204 Vali Loss: 0.4002421 Test Loss: 0.4964180
Validation loss decreased (0.400839 --> 0.400242).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 58.129963397979736
Epoch: 39, Steps: 93 | Train Loss: 0.1813230 Vali Loss: 0.3992698 Test Loss: 0.4953117
Validation loss decreased (0.400242 --> 0.399270).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 60.715190172195435
Epoch: 40, Steps: 93 | Train Loss: 0.1805865 Vali Loss: 0.3980416 Test Loss: 0.4942965
Validation loss decreased (0.399270 --> 0.398042).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 59.88301682472229
Epoch: 41, Steps: 93 | Train Loss: 0.1798901 Vali Loss: 0.3974634 Test Loss: 0.4932919
Validation loss decreased (0.398042 --> 0.397463).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 61.08071303367615
Epoch: 42, Steps: 93 | Train Loss: 0.1792547 Vali Loss: 0.3968689 Test Loss: 0.4924162
Validation loss decreased (0.397463 --> 0.396869).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 62.362788438797
Epoch: 43, Steps: 93 | Train Loss: 0.1786479 Vali Loss: 0.3957795 Test Loss: 0.4915565
Validation loss decreased (0.396869 --> 0.395779).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 61.30708193778992
Epoch: 44, Steps: 93 | Train Loss: 0.1780848 Vali Loss: 0.3956596 Test Loss: 0.4907596
Validation loss decreased (0.395779 --> 0.395660).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 61.18461489677429
Epoch: 45, Steps: 93 | Train Loss: 0.1775480 Vali Loss: 0.3952748 Test Loss: 0.4900392
Validation loss decreased (0.395660 --> 0.395275).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 58.575393199920654
Epoch: 46, Steps: 93 | Train Loss: 0.1770426 Vali Loss: 0.3943603 Test Loss: 0.4893304
Validation loss decreased (0.395275 --> 0.394360).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 60.713475465774536
Epoch: 47, Steps: 93 | Train Loss: 0.1765669 Vali Loss: 0.3938212 Test Loss: 0.4886673
Validation loss decreased (0.394360 --> 0.393821).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 57.405353307724
Epoch: 48, Steps: 93 | Train Loss: 0.1761263 Vali Loss: 0.3930793 Test Loss: 0.4880616
Validation loss decreased (0.393821 --> 0.393079).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 61.19241118431091
Epoch: 49, Steps: 93 | Train Loss: 0.1757196 Vali Loss: 0.3931626 Test Loss: 0.4874831
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 60.01547074317932
Epoch: 50, Steps: 93 | Train Loss: 0.1753200 Vali Loss: 0.3922681 Test Loss: 0.4869243
Validation loss decreased (0.393079 --> 0.392268).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 59.99990892410278
Epoch: 51, Steps: 93 | Train Loss: 0.1749512 Vali Loss: 0.3916860 Test Loss: 0.4864258
Validation loss decreased (0.392268 --> 0.391686).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 59.33590221405029
Epoch: 52, Steps: 93 | Train Loss: 0.1746047 Vali Loss: 0.3914255 Test Loss: 0.4859430
Validation loss decreased (0.391686 --> 0.391425).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 61.66907739639282
Epoch: 53, Steps: 93 | Train Loss: 0.1742727 Vali Loss: 0.3911055 Test Loss: 0.4854938
Validation loss decreased (0.391425 --> 0.391106).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 59.004085540771484
Epoch: 54, Steps: 93 | Train Loss: 0.1739546 Vali Loss: 0.3910315 Test Loss: 0.4850594
Validation loss decreased (0.391106 --> 0.391031).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 60.11121988296509
Epoch: 55, Steps: 93 | Train Loss: 0.1736734 Vali Loss: 0.3908533 Test Loss: 0.4846224
Validation loss decreased (0.391031 --> 0.390853).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 54.36077356338501
Epoch: 56, Steps: 93 | Train Loss: 0.1733871 Vali Loss: 0.3901215 Test Loss: 0.4842847
Validation loss decreased (0.390853 --> 0.390121).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 54.74673652648926
Epoch: 57, Steps: 93 | Train Loss: 0.1731347 Vali Loss: 0.3900525 Test Loss: 0.4839073
Validation loss decreased (0.390121 --> 0.390053).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 58.90509295463562
Epoch: 58, Steps: 93 | Train Loss: 0.1728866 Vali Loss: 0.3897590 Test Loss: 0.4835638
Validation loss decreased (0.390053 --> 0.389759).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 55.56547403335571
Epoch: 59, Steps: 93 | Train Loss: 0.1726420 Vali Loss: 0.3887937 Test Loss: 0.4832409
Validation loss decreased (0.389759 --> 0.388794).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 59.53082299232483
Epoch: 60, Steps: 93 | Train Loss: 0.1724205 Vali Loss: 0.3887498 Test Loss: 0.4829476
Validation loss decreased (0.388794 --> 0.388750).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 59.14226579666138
Epoch: 61, Steps: 93 | Train Loss: 0.1722102 Vali Loss: 0.3882976 Test Loss: 0.4826457
Validation loss decreased (0.388750 --> 0.388298).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 63.02658271789551
Epoch: 62, Steps: 93 | Train Loss: 0.1720142 Vali Loss: 0.3886491 Test Loss: 0.4823744
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 60.18215775489807
Epoch: 63, Steps: 93 | Train Loss: 0.1718274 Vali Loss: 0.3882834 Test Loss: 0.4821419
Validation loss decreased (0.388298 --> 0.388283).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 63.088292598724365
Epoch: 64, Steps: 93 | Train Loss: 0.1716491 Vali Loss: 0.3882897 Test Loss: 0.4818716
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 56.51219940185547
Epoch: 65, Steps: 93 | Train Loss: 0.1714787 Vali Loss: 0.3881581 Test Loss: 0.4816505
Validation loss decreased (0.388283 --> 0.388158).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 58.87399983406067
Epoch: 66, Steps: 93 | Train Loss: 0.1713156 Vali Loss: 0.3878618 Test Loss: 0.4814138
Validation loss decreased (0.388158 --> 0.387862).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 56.92901277542114
Epoch: 67, Steps: 93 | Train Loss: 0.1711638 Vali Loss: 0.3879286 Test Loss: 0.4812360
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 58.51417016983032
Epoch: 68, Steps: 93 | Train Loss: 0.1710287 Vali Loss: 0.3877797 Test Loss: 0.4810302
Validation loss decreased (0.387862 --> 0.387780).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 58.25818204879761
Epoch: 69, Steps: 93 | Train Loss: 0.1708824 Vali Loss: 0.3870527 Test Loss: 0.4808405
Validation loss decreased (0.387780 --> 0.387053).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 56.82410740852356
Epoch: 70, Steps: 93 | Train Loss: 0.1707419 Vali Loss: 0.3874265 Test Loss: 0.4806660
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 55.34805774688721
Epoch: 71, Steps: 93 | Train Loss: 0.1706287 Vali Loss: 0.3872151 Test Loss: 0.4805074
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 60.16240620613098
Epoch: 72, Steps: 93 | Train Loss: 0.1705105 Vali Loss: 0.3870960 Test Loss: 0.4803530
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 59.35257124900818
Epoch: 73, Steps: 93 | Train Loss: 0.1704029 Vali Loss: 0.3868595 Test Loss: 0.4802009
Validation loss decreased (0.387053 --> 0.386860).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 57.47064733505249
Epoch: 74, Steps: 93 | Train Loss: 0.1703045 Vali Loss: 0.3862523 Test Loss: 0.4800637
Validation loss decreased (0.386860 --> 0.386252).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 60.695258378982544
Epoch: 75, Steps: 93 | Train Loss: 0.1701955 Vali Loss: 0.3865062 Test Loss: 0.4799170
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 56.80850315093994
Epoch: 76, Steps: 93 | Train Loss: 0.1701128 Vali Loss: 0.3862071 Test Loss: 0.4797898
Validation loss decreased (0.386252 --> 0.386207).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 62.54094576835632
Epoch: 77, Steps: 93 | Train Loss: 0.1700102 Vali Loss: 0.3861454 Test Loss: 0.4796766
Validation loss decreased (0.386207 --> 0.386145).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 59.037962913513184
Epoch: 78, Steps: 93 | Train Loss: 0.1699375 Vali Loss: 0.3859446 Test Loss: 0.4795642
Validation loss decreased (0.386145 --> 0.385945).  Saving model ...
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 60.45854043960571
Epoch: 79, Steps: 93 | Train Loss: 0.1698407 Vali Loss: 0.3864576 Test Loss: 0.4794515
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 57.93216824531555
Epoch: 80, Steps: 93 | Train Loss: 0.1697731 Vali Loss: 0.3860511 Test Loss: 0.4793613
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 61.69821286201477
Epoch: 81, Steps: 93 | Train Loss: 0.1696955 Vali Loss: 0.3861368 Test Loss: 0.4792669
EarlyStopping counter: 3 out of 10
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 57.3438823223114
Epoch: 82, Steps: 93 | Train Loss: 0.1696329 Vali Loss: 0.3858375 Test Loss: 0.4791606
Validation loss decreased (0.385945 --> 0.385838).  Saving model ...
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 60.48308300971985
Epoch: 83, Steps: 93 | Train Loss: 0.1695574 Vali Loss: 0.3858698 Test Loss: 0.4790762
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 59.04350471496582
Epoch: 84, Steps: 93 | Train Loss: 0.1694947 Vali Loss: 0.3858645 Test Loss: 0.4789972
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 56.351845502853394
Epoch: 85, Steps: 93 | Train Loss: 0.1694441 Vali Loss: 0.3856661 Test Loss: 0.4789143
Validation loss decreased (0.385838 --> 0.385666).  Saving model ...
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 60.658788204193115
Epoch: 86, Steps: 93 | Train Loss: 0.1693831 Vali Loss: 0.3857217 Test Loss: 0.4788406
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 58.78609561920166
Epoch: 87, Steps: 93 | Train Loss: 0.1693301 Vali Loss: 0.3862070 Test Loss: 0.4787660
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 56.63512444496155
Epoch: 88, Steps: 93 | Train Loss: 0.1692844 Vali Loss: 0.3858534 Test Loss: 0.4787021
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 53.595298528671265
Epoch: 89, Steps: 93 | Train Loss: 0.1692339 Vali Loss: 0.3854434 Test Loss: 0.4786409
Validation loss decreased (0.385666 --> 0.385443).  Saving model ...
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 56.75131034851074
Epoch: 90, Steps: 93 | Train Loss: 0.1691849 Vali Loss: 0.3855880 Test Loss: 0.4785765
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 53.54720973968506
Epoch: 91, Steps: 93 | Train Loss: 0.1691398 Vali Loss: 0.3856200 Test Loss: 0.4785222
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 58.825862646102905
Epoch: 92, Steps: 93 | Train Loss: 0.1690897 Vali Loss: 0.3855124 Test Loss: 0.4784646
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 50.83726716041565
Epoch: 93, Steps: 93 | Train Loss: 0.1690535 Vali Loss: 0.3854305 Test Loss: 0.4784120
Validation loss decreased (0.385443 --> 0.385430).  Saving model ...
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 48.58513522148132
Epoch: 94, Steps: 93 | Train Loss: 0.1690310 Vali Loss: 0.3848098 Test Loss: 0.4783624
Validation loss decreased (0.385430 --> 0.384810).  Saving model ...
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 41.68251585960388
Epoch: 95, Steps: 93 | Train Loss: 0.1689837 Vali Loss: 0.3853554 Test Loss: 0.4783192
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 45.913217067718506
Epoch: 96, Steps: 93 | Train Loss: 0.1689385 Vali Loss: 0.3849230 Test Loss: 0.4782708
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 41.70657253265381
Epoch: 97, Steps: 93 | Train Loss: 0.1689230 Vali Loss: 0.3849188 Test Loss: 0.4782306
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 44.831268548965454
Epoch: 98, Steps: 93 | Train Loss: 0.1688888 Vali Loss: 0.3852986 Test Loss: 0.4781904
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 41.62950682640076
Epoch: 99, Steps: 93 | Train Loss: 0.1688587 Vali Loss: 0.3851206 Test Loss: 0.4781532
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 45.012441873550415
Epoch: 100, Steps: 93 | Train Loss: 0.1688298 Vali Loss: 0.3845541 Test Loss: 0.4781148
Validation loss decreased (0.384810 --> 0.384554).  Saving model ...
Updating learning rate to 3.1160680107021042e-06
train 11909
val 1565
test 3317
Model(
  (freq_upsampler): Linear(in_features=50, out_features=103, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  568230400.0
params:  5253.0
Trainable parameters:  5253
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 41.58048892021179
Epoch: 1, Steps: 93 | Train Loss: 0.2845694 Vali Loss: 0.3769708 Test Loss: 0.4694661
Validation loss decreased (inf --> 0.376971).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 45.0171263217926
Epoch: 2, Steps: 93 | Train Loss: 0.2820280 Vali Loss: 0.3764669 Test Loss: 0.4689575
Validation loss decreased (0.376971 --> 0.376467).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 39.98675799369812
Epoch: 3, Steps: 93 | Train Loss: 0.2816015 Vali Loss: 0.3762645 Test Loss: 0.4687088
Validation loss decreased (0.376467 --> 0.376264).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 43.234570264816284
Epoch: 4, Steps: 93 | Train Loss: 0.2814551 Vali Loss: 0.3759068 Test Loss: 0.4686098
Validation loss decreased (0.376264 --> 0.375907).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 43.30331563949585
Epoch: 5, Steps: 93 | Train Loss: 0.2813829 Vali Loss: 0.3760835 Test Loss: 0.4686509
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 42.536425828933716
Epoch: 6, Steps: 93 | Train Loss: 0.2813341 Vali Loss: 0.3758545 Test Loss: 0.4683388
Validation loss decreased (0.375907 --> 0.375854).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 41.59530019760132
Epoch: 7, Steps: 93 | Train Loss: 0.2812956 Vali Loss: 0.3756113 Test Loss: 0.4685288
Validation loss decreased (0.375854 --> 0.375611).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 40.860153675079346
Epoch: 8, Steps: 93 | Train Loss: 0.2812929 Vali Loss: 0.3765433 Test Loss: 0.4684888
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 44.04822134971619
Epoch: 9, Steps: 93 | Train Loss: 0.2812039 Vali Loss: 0.3760244 Test Loss: 0.4683419
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 42.65712809562683
Epoch: 10, Steps: 93 | Train Loss: 0.2812192 Vali Loss: 0.3756199 Test Loss: 0.4684972
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 45.8304386138916
Epoch: 11, Steps: 93 | Train Loss: 0.2812032 Vali Loss: 0.3757386 Test Loss: 0.4685158
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 41.75127577781677
Epoch: 12, Steps: 93 | Train Loss: 0.2811654 Vali Loss: 0.3754076 Test Loss: 0.4682986
Validation loss decreased (0.375611 --> 0.375408).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 45.636826038360596
Epoch: 13, Steps: 93 | Train Loss: 0.2811583 Vali Loss: 0.3754379 Test Loss: 0.4682937
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 42.603599071502686
Epoch: 14, Steps: 93 | Train Loss: 0.2811366 Vali Loss: 0.3754979 Test Loss: 0.4681494
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 46.61223220825195
Epoch: 15, Steps: 93 | Train Loss: 0.2811354 Vali Loss: 0.3758852 Test Loss: 0.4683678
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 42.85158133506775
Epoch: 16, Steps: 93 | Train Loss: 0.2811012 Vali Loss: 0.3754719 Test Loss: 0.4682513
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 45.05205202102661
Epoch: 17, Steps: 93 | Train Loss: 0.2810847 Vali Loss: 0.3759969 Test Loss: 0.4682994
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 42.56670594215393
Epoch: 18, Steps: 93 | Train Loss: 0.2810903 Vali Loss: 0.3754991 Test Loss: 0.4681434
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 48.94225192070007
Epoch: 19, Steps: 93 | Train Loss: 0.2810619 Vali Loss: 0.3758733 Test Loss: 0.4682428
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 44.20507049560547
Epoch: 20, Steps: 93 | Train Loss: 0.2810693 Vali Loss: 0.3760284 Test Loss: 0.4681969
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 46.09556555747986
Epoch: 21, Steps: 93 | Train Loss: 0.2810457 Vali Loss: 0.3759287 Test Loss: 0.4682975
EarlyStopping counter: 9 out of 10
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 43.87467932701111
Epoch: 22, Steps: 93 | Train Loss: 0.2810618 Vali Loss: 0.3756835 Test Loss: 0.4682043
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : Traffic_180_j192_H5_FITS_custom_ftM_sl180_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3317
mse:0.4674701988697052, mae:0.3086591958999634, rse:0.564294695854187, corr:[0.2835159  0.28904375 0.29000998 0.28879806 0.28828803 0.28935072
 0.28948775 0.28900743 0.28885412 0.28875506 0.2887964  0.2888267
 0.288696   0.28878286 0.2883861  0.2879551  0.28811714 0.2883473
 0.28827047 0.2881549  0.28826657 0.28901917 0.28978702 0.28950727
 0.28882796 0.2878107  0.28744206 0.28706956 0.28686842 0.28747347
 0.28797793 0.2880417  0.28827006 0.28849068 0.28835747 0.28794152
 0.28743747 0.28720278 0.2872745  0.28749406 0.28763115 0.28777352
 0.2877285  0.2873252  0.287062   0.28735816 0.2877791  0.28788614
 0.28764316 0.28698665 0.28680435 0.286971   0.28685704 0.28669238
 0.28669947 0.2866963  0.28674456 0.28685054 0.28674906 0.28648362
 0.28623253 0.28598922 0.2858283  0.2858119  0.2856694  0.28550625
 0.2855833  0.28565562 0.2857219  0.28623894 0.28678834 0.28679624
 0.2863539  0.2858095  0.28537336 0.2850721  0.28494018 0.28482878
 0.28475624 0.28491983 0.28517446 0.28521833 0.2850611  0.28491393
 0.28491175 0.28501487 0.2850517  0.2850157  0.28496554 0.28475732
 0.28443933 0.28437626 0.2847178  0.28523493 0.28554076 0.28547812
 0.2851038  0.28473365 0.28467917 0.28473344 0.28468102 0.28454465
 0.28436938 0.28426617 0.28425747 0.28415897 0.28407666 0.28432265
 0.2847749  0.28516153 0.28511393 0.2847129  0.28427833 0.28405783
 0.28414184 0.28432915 0.28435093 0.28424513 0.2841707  0.28411546
 0.28431016 0.28459692 0.28484818 0.28481963 0.28470665 0.28466693
 0.28429914 0.28368226 0.28342578 0.28357953 0.2840743  0.2849296
 0.28562388 0.2860468  0.28576857 0.28512534 0.28452605 0.28420174
 0.28440306 0.2848093  0.2851532  0.28582263 0.28636578 0.28616983
 0.28591037 0.28567013 0.2857149  0.28574744 0.28548658 0.28527594
 0.28509098 0.28490263 0.28491345 0.2850328  0.28555542 0.28680873
 0.2879445  0.28868523 0.28824082 0.2877093  0.2874517  0.28698272
 0.2869467  0.28737372 0.28791642 0.28922606 0.29027787 0.2896479
 0.28865895 0.28743327 0.2869149  0.28673163 0.2868593  0.28732866
 0.28741384 0.28734216 0.28757045 0.2877654  0.28791186 0.28814888
 0.28822947 0.2883391  0.2880828  0.2879608  0.28825638 0.28798112
 0.2869975  0.2866939  0.28708518 0.28704634 0.28654587 0.2865612 ]
