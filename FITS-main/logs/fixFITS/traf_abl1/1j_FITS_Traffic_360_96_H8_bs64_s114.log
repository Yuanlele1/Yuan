Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=138, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_360_j96_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=10, pred_len=96, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_360_j96_H8_FITS_custom_ftM_sl360_ll48_pl96_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11825
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=138, out_features=174, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2649388032.0
params:  24186.0
Trainable parameters:  24186
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 140.70474791526794
Epoch: 1, Steps: 92 | Train Loss: 0.6830913 Vali Loss: 0.5360463 Test Loss: 0.6274896
Validation loss decreased (inf --> 0.536046).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 132.57859921455383
Epoch: 2, Steps: 92 | Train Loss: 0.3401619 Vali Loss: 0.3820501 Test Loss: 0.4548975
Validation loss decreased (0.536046 --> 0.382050).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 141.22669291496277
Epoch: 3, Steps: 92 | Train Loss: 0.2679356 Vali Loss: 0.3479050 Test Loss: 0.4203620
Validation loss decreased (0.382050 --> 0.347905).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 132.21511960029602
Epoch: 4, Steps: 92 | Train Loss: 0.2528507 Vali Loss: 0.3406472 Test Loss: 0.4151273
Validation loss decreased (0.347905 --> 0.340647).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 134.42039394378662
Epoch: 5, Steps: 92 | Train Loss: 0.2498511 Vali Loss: 0.3397881 Test Loss: 0.4143992
Validation loss decreased (0.340647 --> 0.339788).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 126.63397336006165
Epoch: 6, Steps: 92 | Train Loss: 0.2489812 Vali Loss: 0.3392025 Test Loss: 0.4142894
Validation loss decreased (0.339788 --> 0.339202).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 137.93745851516724
Epoch: 7, Steps: 92 | Train Loss: 0.2486065 Vali Loss: 0.3383490 Test Loss: 0.4139550
Validation loss decreased (0.339202 --> 0.338349).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 125.67247200012207
Epoch: 8, Steps: 92 | Train Loss: 0.2483614 Vali Loss: 0.3392551 Test Loss: 0.4139104
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 125.51482725143433
Epoch: 9, Steps: 92 | Train Loss: 0.2481727 Vali Loss: 0.3377334 Test Loss: 0.4134462
Validation loss decreased (0.338349 --> 0.337733).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 131.5014145374298
Epoch: 10, Steps: 92 | Train Loss: 0.2479845 Vali Loss: 0.3379206 Test Loss: 0.4133938
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 131.85148787498474
Epoch: 11, Steps: 92 | Train Loss: 0.2478518 Vali Loss: 0.3370542 Test Loss: 0.4132253
Validation loss decreased (0.337733 --> 0.337054).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 128.5919725894928
Epoch: 12, Steps: 92 | Train Loss: 0.2477390 Vali Loss: 0.3380379 Test Loss: 0.4131279
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 123.06783151626587
Epoch: 13, Steps: 92 | Train Loss: 0.2476350 Vali Loss: 0.3387330 Test Loss: 0.4130035
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 129.36780381202698
Epoch: 14, Steps: 92 | Train Loss: 0.2475956 Vali Loss: 0.3381610 Test Loss: 0.4129536
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 111.89647388458252
Epoch: 15, Steps: 92 | Train Loss: 0.2475751 Vali Loss: 0.3376991 Test Loss: 0.4129079
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 118.21575403213501
Epoch: 16, Steps: 92 | Train Loss: 0.2475123 Vali Loss: 0.3368243 Test Loss: 0.4128365
Validation loss decreased (0.337054 --> 0.336824).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 115.49032926559448
Epoch: 17, Steps: 92 | Train Loss: 0.2474069 Vali Loss: 0.3376253 Test Loss: 0.4127882
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 111.84780955314636
Epoch: 18, Steps: 92 | Train Loss: 0.2474554 Vali Loss: 0.3383204 Test Loss: 0.4126943
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 112.01935362815857
Epoch: 19, Steps: 92 | Train Loss: 0.2474221 Vali Loss: 0.3382130 Test Loss: 0.4126751
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 119.85483574867249
Epoch: 20, Steps: 92 | Train Loss: 0.2473588 Vali Loss: 0.3368659 Test Loss: 0.4126509
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 111.07428121566772
Epoch: 21, Steps: 92 | Train Loss: 0.2473539 Vali Loss: 0.3367878 Test Loss: 0.4126889
Validation loss decreased (0.336824 --> 0.336788).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 115.92483949661255
Epoch: 22, Steps: 92 | Train Loss: 0.2473573 Vali Loss: 0.3378431 Test Loss: 0.4125843
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 113.26443076133728
Epoch: 23, Steps: 92 | Train Loss: 0.2472456 Vali Loss: 0.3372439 Test Loss: 0.4125795
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 106.70080184936523
Epoch: 24, Steps: 92 | Train Loss: 0.2472984 Vali Loss: 0.3370461 Test Loss: 0.4125529
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 97.33525681495667
Epoch: 25, Steps: 92 | Train Loss: 0.2473540 Vali Loss: 0.3375748 Test Loss: 0.4124667
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 99.2879467010498
Epoch: 26, Steps: 92 | Train Loss: 0.2471247 Vali Loss: 0.3361274 Test Loss: 0.4125708
Validation loss decreased (0.336788 --> 0.336127).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 96.76729774475098
Epoch: 27, Steps: 92 | Train Loss: 0.2472456 Vali Loss: 0.3374912 Test Loss: 0.4124787
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 102.99466180801392
Epoch: 28, Steps: 92 | Train Loss: 0.2471988 Vali Loss: 0.3381838 Test Loss: 0.4124410
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 102.84213018417358
Epoch: 29, Steps: 92 | Train Loss: 0.2472317 Vali Loss: 0.3374091 Test Loss: 0.4123676
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 103.56237149238586
Epoch: 30, Steps: 92 | Train Loss: 0.2471645 Vali Loss: 0.3380219 Test Loss: 0.4124011
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 101.44608807563782
Epoch: 31, Steps: 92 | Train Loss: 0.2471879 Vali Loss: 0.3373310 Test Loss: 0.4125098
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 86.1499125957489
Epoch: 32, Steps: 92 | Train Loss: 0.2471974 Vali Loss: 0.3372461 Test Loss: 0.4124094
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 90.08591079711914
Epoch: 33, Steps: 92 | Train Loss: 0.2470875 Vali Loss: 0.3355295 Test Loss: 0.4124503
Validation loss decreased (0.336127 --> 0.335529).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 85.79918503761292
Epoch: 34, Steps: 92 | Train Loss: 0.2471973 Vali Loss: 0.3373562 Test Loss: 0.4123656
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 88.73556995391846
Epoch: 35, Steps: 92 | Train Loss: 0.2471644 Vali Loss: 0.3363391 Test Loss: 0.4123094
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 86.71139335632324
Epoch: 36, Steps: 92 | Train Loss: 0.2471707 Vali Loss: 0.3367125 Test Loss: 0.4122876
EarlyStopping counter: 3 out of 10
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 90.08656454086304
Epoch: 37, Steps: 92 | Train Loss: 0.2471256 Vali Loss: 0.3373213 Test Loss: 0.4122998
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 89.11260294914246
Epoch: 38, Steps: 92 | Train Loss: 0.2471653 Vali Loss: 0.3364276 Test Loss: 0.4123192
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 86.19847798347473
Epoch: 39, Steps: 92 | Train Loss: 0.2471668 Vali Loss: 0.3370817 Test Loss: 0.4122857
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 94.25884246826172
Epoch: 40, Steps: 92 | Train Loss: 0.2470779 Vali Loss: 0.3372427 Test Loss: 0.4122636
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 87.83516025543213
Epoch: 41, Steps: 92 | Train Loss: 0.2470543 Vali Loss: 0.3376897 Test Loss: 0.4123150
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 84.76578712463379
Epoch: 42, Steps: 92 | Train Loss: 0.2469873 Vali Loss: 0.3367061 Test Loss: 0.4122988
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 82.30301976203918
Epoch: 43, Steps: 92 | Train Loss: 0.2469222 Vali Loss: 0.3363190 Test Loss: 0.4122929
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : Traffic_360_j96_H8_FITS_custom_ftM_sl360_ll48_pl96_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3413
mse:0.41085687279701233, mae:0.2809608578681946, rse:0.5307607054710388, corr:[0.27858946 0.2907528  0.2923558  0.29114142 0.29229563 0.29225346
 0.29185995 0.29260394 0.29201856 0.291797   0.29209706 0.2913204
 0.29131007 0.29130676 0.29058918 0.29085475 0.29107893 0.290856
 0.29121622 0.291334   0.2911673  0.29116562 0.29081076 0.29113942
 0.29257026 0.29264578 0.2924573  0.29250976 0.29218346 0.2919507
 0.29181167 0.29141635 0.2914402  0.2914627  0.2910116  0.29103878
 0.29112795 0.2908045  0.29098448 0.2911222  0.29103455 0.29139623
 0.2914516  0.29128757 0.29146728 0.29130197 0.2910424  0.29134008
 0.2918974  0.29208222 0.2919334  0.2913452  0.29127678 0.29146472
 0.29109433 0.29102015 0.29126766 0.2909226  0.29078048 0.29093447
 0.2907092  0.2908744  0.29111773 0.2907934  0.2910808  0.29146773
 0.29115033 0.29129505 0.29148647 0.29122892 0.29118606 0.29109246
 0.2909429  0.29099408 0.29071173 0.2906746  0.29102427 0.2906269
 0.29018724 0.2905154  0.2904774  0.29021132 0.29043904 0.29037744
 0.29046667 0.29080355 0.29039592 0.29058075 0.29094434 0.29010513
 0.290309   0.2901531  0.2886704  0.28927037 0.28862596 0.29085004]
