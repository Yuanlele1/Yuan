Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=50, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_180_j96_H5', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=10, pred_len=96, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_180_j96_H5_FITS_custom_ftM_sl180_ll48_pl96_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 12005
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=50, out_features=76, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  419276800.0
params:  3876.0
Trainable parameters:  3876
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 50.32536506652832
Epoch: 1, Steps: 93 | Train Loss: 0.9211191 Vali Loss: 0.9576600 Test Loss: 1.1388991
Validation loss decreased (inf --> 0.957660).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 46.770602226257324
Epoch: 2, Steps: 93 | Train Loss: 0.6022418 Vali Loss: 0.7463270 Test Loss: 0.8977066
Validation loss decreased (0.957660 --> 0.746327).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 46.39699649810791
Epoch: 3, Steps: 93 | Train Loss: 0.4619455 Vali Loss: 0.6461204 Test Loss: 0.7864029
Validation loss decreased (0.746327 --> 0.646120).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 48.68321394920349
Epoch: 4, Steps: 93 | Train Loss: 0.3860168 Vali Loss: 0.5954162 Test Loss: 0.7253986
Validation loss decreased (0.646120 --> 0.595416).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 46.335137128829956
Epoch: 5, Steps: 93 | Train Loss: 0.3390046 Vali Loss: 0.5614448 Test Loss: 0.6858201
Validation loss decreased (0.595416 --> 0.561445).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 49.035067558288574
Epoch: 6, Steps: 93 | Train Loss: 0.3061423 Vali Loss: 0.5372879 Test Loss: 0.6568484
Validation loss decreased (0.561445 --> 0.537288).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 45.87318158149719
Epoch: 7, Steps: 93 | Train Loss: 0.2812975 Vali Loss: 0.5186839 Test Loss: 0.6340412
Validation loss decreased (0.537288 --> 0.518684).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 48.446006774902344
Epoch: 8, Steps: 93 | Train Loss: 0.2616069 Vali Loss: 0.5024097 Test Loss: 0.6155610
Validation loss decreased (0.518684 --> 0.502410).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 47.77877116203308
Epoch: 9, Steps: 93 | Train Loss: 0.2453218 Vali Loss: 0.4902401 Test Loss: 0.5996320
Validation loss decreased (0.502410 --> 0.490240).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 46.94174337387085
Epoch: 10, Steps: 93 | Train Loss: 0.2317174 Vali Loss: 0.4793510 Test Loss: 0.5861537
Validation loss decreased (0.490240 --> 0.479351).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 49.33620262145996
Epoch: 11, Steps: 93 | Train Loss: 0.2201888 Vali Loss: 0.4691994 Test Loss: 0.5740039
Validation loss decreased (0.479351 --> 0.469199).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 45.804996728897095
Epoch: 12, Steps: 93 | Train Loss: 0.2102404 Vali Loss: 0.4627674 Test Loss: 0.5642968
Validation loss decreased (0.469199 --> 0.462767).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 48.790038108825684
Epoch: 13, Steps: 93 | Train Loss: 0.2017904 Vali Loss: 0.4546640 Test Loss: 0.5556682
Validation loss decreased (0.462767 --> 0.454664).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 47.433566093444824
Epoch: 14, Steps: 93 | Train Loss: 0.1943604 Vali Loss: 0.4483730 Test Loss: 0.5474995
Validation loss decreased (0.454664 --> 0.448373).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 48.692187547683716
Epoch: 15, Steps: 93 | Train Loss: 0.1878944 Vali Loss: 0.4418410 Test Loss: 0.5403460
Validation loss decreased (0.448373 --> 0.441841).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 48.668455839157104
Epoch: 16, Steps: 93 | Train Loss: 0.1822332 Vali Loss: 0.4396863 Test Loss: 0.5347413
Validation loss decreased (0.441841 --> 0.439686).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 49.821906089782715
Epoch: 17, Steps: 93 | Train Loss: 0.1772289 Vali Loss: 0.4342509 Test Loss: 0.5293854
Validation loss decreased (0.439686 --> 0.434251).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 45.45691442489624
Epoch: 18, Steps: 93 | Train Loss: 0.1728166 Vali Loss: 0.4288519 Test Loss: 0.5243826
Validation loss decreased (0.434251 --> 0.428852).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 47.41885757446289
Epoch: 19, Steps: 93 | Train Loss: 0.1689157 Vali Loss: 0.4262848 Test Loss: 0.5201739
Validation loss decreased (0.428852 --> 0.426285).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 49.57807111740112
Epoch: 20, Steps: 93 | Train Loss: 0.1653942 Vali Loss: 0.4231521 Test Loss: 0.5160925
Validation loss decreased (0.426285 --> 0.423152).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 44.161540031433105
Epoch: 21, Steps: 93 | Train Loss: 0.1622507 Vali Loss: 0.4202254 Test Loss: 0.5125141
Validation loss decreased (0.423152 --> 0.420225).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 49.62381386756897
Epoch: 22, Steps: 93 | Train Loss: 0.1594008 Vali Loss: 0.4184021 Test Loss: 0.5097293
Validation loss decreased (0.420225 --> 0.418402).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 47.53168869018555
Epoch: 23, Steps: 93 | Train Loss: 0.1569682 Vali Loss: 0.4172294 Test Loss: 0.5070328
Validation loss decreased (0.418402 --> 0.417229).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 51.04585886001587
Epoch: 24, Steps: 93 | Train Loss: 0.1546840 Vali Loss: 0.4139026 Test Loss: 0.5043493
Validation loss decreased (0.417229 --> 0.413903).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 49.89698147773743
Epoch: 25, Steps: 93 | Train Loss: 0.1526838 Vali Loss: 0.4123998 Test Loss: 0.5020354
Validation loss decreased (0.413903 --> 0.412400).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 52.77360916137695
Epoch: 26, Steps: 93 | Train Loss: 0.1507944 Vali Loss: 0.4095581 Test Loss: 0.5000774
Validation loss decreased (0.412400 --> 0.409558).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 49.32739734649658
Epoch: 27, Steps: 93 | Train Loss: 0.1491041 Vali Loss: 0.4103231 Test Loss: 0.4982033
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 48.18001389503479
Epoch: 28, Steps: 93 | Train Loss: 0.1475769 Vali Loss: 0.4073343 Test Loss: 0.4965801
Validation loss decreased (0.409558 --> 0.407334).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 51.18081831932068
Epoch: 29, Steps: 93 | Train Loss: 0.1461090 Vali Loss: 0.4051248 Test Loss: 0.4949996
Validation loss decreased (0.407334 --> 0.405125).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 49.03061819076538
Epoch: 30, Steps: 93 | Train Loss: 0.1448600 Vali Loss: 0.4048217 Test Loss: 0.4935074
Validation loss decreased (0.405125 --> 0.404822).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 50.350550413131714
Epoch: 31, Steps: 93 | Train Loss: 0.1436828 Vali Loss: 0.4045826 Test Loss: 0.4921326
Validation loss decreased (0.404822 --> 0.404583).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 46.51588416099548
Epoch: 32, Steps: 93 | Train Loss: 0.1426467 Vali Loss: 0.4035981 Test Loss: 0.4909773
Validation loss decreased (0.404583 --> 0.403598).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 53.66917705535889
Epoch: 33, Steps: 93 | Train Loss: 0.1416585 Vali Loss: 0.4023431 Test Loss: 0.4898940
Validation loss decreased (0.403598 --> 0.402343).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 48.667214155197144
Epoch: 34, Steps: 93 | Train Loss: 0.1407995 Vali Loss: 0.4012605 Test Loss: 0.4887788
Validation loss decreased (0.402343 --> 0.401260).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 51.23074388504028
Epoch: 35, Steps: 93 | Train Loss: 0.1399588 Vali Loss: 0.4003088 Test Loss: 0.4878820
Validation loss decreased (0.401260 --> 0.400309).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 51.97115635871887
Epoch: 36, Steps: 93 | Train Loss: 0.1391362 Vali Loss: 0.4000813 Test Loss: 0.4869756
Validation loss decreased (0.400309 --> 0.400081).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 47.820594787597656
Epoch: 37, Steps: 93 | Train Loss: 0.1384307 Vali Loss: 0.3993222 Test Loss: 0.4861571
Validation loss decreased (0.400081 --> 0.399322).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 50.78294587135315
Epoch: 38, Steps: 93 | Train Loss: 0.1377905 Vali Loss: 0.3987080 Test Loss: 0.4853627
Validation loss decreased (0.399322 --> 0.398708).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 51.36918115615845
Epoch: 39, Steps: 93 | Train Loss: 0.1371893 Vali Loss: 0.3979049 Test Loss: 0.4847326
Validation loss decreased (0.398708 --> 0.397905).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 50.52067852020264
Epoch: 40, Steps: 93 | Train Loss: 0.1365496 Vali Loss: 0.3977648 Test Loss: 0.4840662
Validation loss decreased (0.397905 --> 0.397765).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 50.5324227809906
Epoch: 41, Steps: 93 | Train Loss: 0.1361058 Vali Loss: 0.3978930 Test Loss: 0.4834907
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 53.127346992492676
Epoch: 42, Steps: 93 | Train Loss: 0.1355921 Vali Loss: 0.3966712 Test Loss: 0.4828940
Validation loss decreased (0.397765 --> 0.396671).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 48.85728597640991
Epoch: 43, Steps: 93 | Train Loss: 0.1351380 Vali Loss: 0.3970606 Test Loss: 0.4824671
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 47.84534573554993
Epoch: 44, Steps: 93 | Train Loss: 0.1346991 Vali Loss: 0.3944246 Test Loss: 0.4819370
Validation loss decreased (0.396671 --> 0.394425).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 49.74842166900635
Epoch: 45, Steps: 93 | Train Loss: 0.1342790 Vali Loss: 0.3945549 Test Loss: 0.4815010
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 45.3736674785614
Epoch: 46, Steps: 93 | Train Loss: 0.1339400 Vali Loss: 0.3958622 Test Loss: 0.4810075
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 49.769951581954956
Epoch: 47, Steps: 93 | Train Loss: 0.1336093 Vali Loss: 0.3946700 Test Loss: 0.4806365
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 46.46442937850952
Epoch: 48, Steps: 93 | Train Loss: 0.1332518 Vali Loss: 0.3953930 Test Loss: 0.4802759
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 48.62187647819519
Epoch: 49, Steps: 93 | Train Loss: 0.1329674 Vali Loss: 0.3952158 Test Loss: 0.4799049
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 49.16413736343384
Epoch: 50, Steps: 93 | Train Loss: 0.1326770 Vali Loss: 0.3957156 Test Loss: 0.4795985
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 46.90321660041809
Epoch: 51, Steps: 93 | Train Loss: 0.1323544 Vali Loss: 0.3935150 Test Loss: 0.4793137
Validation loss decreased (0.394425 --> 0.393515).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 52.402607917785645
Epoch: 52, Steps: 93 | Train Loss: 0.1321544 Vali Loss: 0.3939259 Test Loss: 0.4790038
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 49.563514709472656
Epoch: 53, Steps: 93 | Train Loss: 0.1319578 Vali Loss: 0.3928770 Test Loss: 0.4787329
Validation loss decreased (0.393515 --> 0.392877).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 51.27968215942383
Epoch: 54, Steps: 93 | Train Loss: 0.1317162 Vali Loss: 0.3942142 Test Loss: 0.4784874
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 49.907044649124146
Epoch: 55, Steps: 93 | Train Loss: 0.1314968 Vali Loss: 0.3927705 Test Loss: 0.4782660
Validation loss decreased (0.392877 --> 0.392770).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 47.69765281677246
Epoch: 56, Steps: 93 | Train Loss: 0.1312571 Vali Loss: 0.3932252 Test Loss: 0.4780432
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 48.524821281433105
Epoch: 57, Steps: 93 | Train Loss: 0.1310844 Vali Loss: 0.3924346 Test Loss: 0.4777686
Validation loss decreased (0.392770 --> 0.392435).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 46.275673627853394
Epoch: 58, Steps: 93 | Train Loss: 0.1309072 Vali Loss: 0.3920954 Test Loss: 0.4775735
Validation loss decreased (0.392435 --> 0.392095).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 49.439637184143066
Epoch: 59, Steps: 93 | Train Loss: 0.1307218 Vali Loss: 0.3927811 Test Loss: 0.4774051
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 48.42128896713257
Epoch: 60, Steps: 93 | Train Loss: 0.1305944 Vali Loss: 0.3929970 Test Loss: 0.4772195
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 49.71112322807312
Epoch: 61, Steps: 93 | Train Loss: 0.1304248 Vali Loss: 0.3931394 Test Loss: 0.4770424
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 46.877995014190674
Epoch: 62, Steps: 93 | Train Loss: 0.1303482 Vali Loss: 0.3914933 Test Loss: 0.4768696
Validation loss decreased (0.392095 --> 0.391493).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 50.335566997528076
Epoch: 63, Steps: 93 | Train Loss: 0.1300864 Vali Loss: 0.3914992 Test Loss: 0.4767070
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 50.256080627441406
Epoch: 64, Steps: 93 | Train Loss: 0.1300260 Vali Loss: 0.3932955 Test Loss: 0.4765707
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 49.10123920440674
Epoch: 65, Steps: 93 | Train Loss: 0.1299172 Vali Loss: 0.3921898 Test Loss: 0.4763993
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 53.26807713508606
Epoch: 66, Steps: 93 | Train Loss: 0.1297979 Vali Loss: 0.3912170 Test Loss: 0.4762916
Validation loss decreased (0.391493 --> 0.391217).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 46.45420837402344
Epoch: 67, Steps: 93 | Train Loss: 0.1297138 Vali Loss: 0.3918540 Test Loss: 0.4761625
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 50.57696533203125
Epoch: 68, Steps: 93 | Train Loss: 0.1295942 Vali Loss: 0.3926208 Test Loss: 0.4760250
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 49.33790874481201
Epoch: 69, Steps: 93 | Train Loss: 0.1294886 Vali Loss: 0.3910180 Test Loss: 0.4759190
Validation loss decreased (0.391217 --> 0.391018).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 44.31076145172119
Epoch: 70, Steps: 93 | Train Loss: 0.1294109 Vali Loss: 0.3916154 Test Loss: 0.4758152
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 47.01743531227112
Epoch: 71, Steps: 93 | Train Loss: 0.1293190 Vali Loss: 0.3910910 Test Loss: 0.4756985
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 43.40907073020935
Epoch: 72, Steps: 93 | Train Loss: 0.1292335 Vali Loss: 0.3914568 Test Loss: 0.4756120
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 46.839043855667114
Epoch: 73, Steps: 93 | Train Loss: 0.1291820 Vali Loss: 0.3924523 Test Loss: 0.4755122
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 47.14038109779358
Epoch: 74, Steps: 93 | Train Loss: 0.1291239 Vali Loss: 0.3909726 Test Loss: 0.4754271
Validation loss decreased (0.391018 --> 0.390973).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 46.481454610824585
Epoch: 75, Steps: 93 | Train Loss: 0.1290325 Vali Loss: 0.3909872 Test Loss: 0.4753283
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 50.12101435661316
Epoch: 76, Steps: 93 | Train Loss: 0.1289148 Vali Loss: 0.3909855 Test Loss: 0.4752499
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 48.32380175590515
Epoch: 77, Steps: 93 | Train Loss: 0.1288562 Vali Loss: 0.3918330 Test Loss: 0.4751838
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 53.1496901512146
Epoch: 78, Steps: 93 | Train Loss: 0.1288122 Vali Loss: 0.3910163 Test Loss: 0.4751098
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 51.711302280426025
Epoch: 79, Steps: 93 | Train Loss: 0.1288006 Vali Loss: 0.3905647 Test Loss: 0.4750313
Validation loss decreased (0.390973 --> 0.390565).  Saving model ...
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 50.48653817176819
Epoch: 80, Steps: 93 | Train Loss: 0.1287386 Vali Loss: 0.3902570 Test Loss: 0.4749939
Validation loss decreased (0.390565 --> 0.390257).  Saving model ...
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 47.821656703948975
Epoch: 81, Steps: 93 | Train Loss: 0.1286938 Vali Loss: 0.3892458 Test Loss: 0.4749142
Validation loss decreased (0.390257 --> 0.389246).  Saving model ...
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 47.16687226295471
Epoch: 82, Steps: 93 | Train Loss: 0.1286066 Vali Loss: 0.3908217 Test Loss: 0.4748687
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 49.03906202316284
Epoch: 83, Steps: 93 | Train Loss: 0.1285862 Vali Loss: 0.3903256 Test Loss: 0.4747972
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 48.27862882614136
Epoch: 84, Steps: 93 | Train Loss: 0.1285361 Vali Loss: 0.3895235 Test Loss: 0.4747487
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 49.520601749420166
Epoch: 85, Steps: 93 | Train Loss: 0.1284941 Vali Loss: 0.3912408 Test Loss: 0.4746999
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 45.84968400001526
Epoch: 86, Steps: 93 | Train Loss: 0.1284232 Vali Loss: 0.3902552 Test Loss: 0.4746610
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 48.77921915054321
Epoch: 87, Steps: 93 | Train Loss: 0.1284285 Vali Loss: 0.3893185 Test Loss: 0.4746038
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 47.38212251663208
Epoch: 88, Steps: 93 | Train Loss: 0.1283739 Vali Loss: 0.3897354 Test Loss: 0.4745619
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 47.277891397476196
Epoch: 89, Steps: 93 | Train Loss: 0.1283616 Vali Loss: 0.3912777 Test Loss: 0.4745187
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 50.25199365615845
Epoch: 90, Steps: 93 | Train Loss: 0.1282733 Vali Loss: 0.3904391 Test Loss: 0.4744854
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 45.05497860908508
Epoch: 91, Steps: 93 | Train Loss: 0.1283059 Vali Loss: 0.3899105 Test Loss: 0.4744368
EarlyStopping counter: 10 out of 10
Early stopping
train 12005
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=50, out_features=76, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  419276800.0
params:  3876.0
Trainable parameters:  3876
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 50.70971059799194
Epoch: 1, Steps: 93 | Train Loss: 0.2822747 Vali Loss: 0.3798079 Test Loss: 0.4600163
Validation loss decreased (inf --> 0.379808).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 47.450430393218994
Epoch: 2, Steps: 93 | Train Loss: 0.2783315 Vali Loss: 0.3766198 Test Loss: 0.4589218
Validation loss decreased (0.379808 --> 0.376620).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 49.89274978637695
Epoch: 3, Steps: 93 | Train Loss: 0.2775104 Vali Loss: 0.3758660 Test Loss: 0.4579727
Validation loss decreased (0.376620 --> 0.375866).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 49.927244663238525
Epoch: 4, Steps: 93 | Train Loss: 0.2773178 Vali Loss: 0.3757212 Test Loss: 0.4575977
Validation loss decreased (0.375866 --> 0.375721).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 46.026755571365356
Epoch: 5, Steps: 93 | Train Loss: 0.2771351 Vali Loss: 0.3767415 Test Loss: 0.4575941
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 50.20948076248169
Epoch: 6, Steps: 93 | Train Loss: 0.2769404 Vali Loss: 0.3757342 Test Loss: 0.4574627
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 50.46310305595398
Epoch: 7, Steps: 93 | Train Loss: 0.2768706 Vali Loss: 0.3755622 Test Loss: 0.4570349
Validation loss decreased (0.375721 --> 0.375562).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 48.69656753540039
Epoch: 8, Steps: 93 | Train Loss: 0.2768614 Vali Loss: 0.3750657 Test Loss: 0.4569469
Validation loss decreased (0.375562 --> 0.375066).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 50.35175967216492
Epoch: 9, Steps: 93 | Train Loss: 0.2767915 Vali Loss: 0.3759689 Test Loss: 0.4570307
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 47.08818221092224
Epoch: 10, Steps: 93 | Train Loss: 0.2767148 Vali Loss: 0.3761820 Test Loss: 0.4572073
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 48.965818881988525
Epoch: 11, Steps: 93 | Train Loss: 0.2767063 Vali Loss: 0.3762765 Test Loss: 0.4569632
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 47.79097938537598
Epoch: 12, Steps: 93 | Train Loss: 0.2766698 Vali Loss: 0.3755498 Test Loss: 0.4568033
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 48.71753215789795
Epoch: 13, Steps: 93 | Train Loss: 0.2766251 Vali Loss: 0.3757012 Test Loss: 0.4568308
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 47.04625368118286
Epoch: 14, Steps: 93 | Train Loss: 0.2765648 Vali Loss: 0.3770033 Test Loss: 0.4569286
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 50.712294816970825
Epoch: 15, Steps: 93 | Train Loss: 0.2767521 Vali Loss: 0.3756245 Test Loss: 0.4567996
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 44.51354503631592
Epoch: 16, Steps: 93 | Train Loss: 0.2765633 Vali Loss: 0.3747517 Test Loss: 0.4567471
Validation loss decreased (0.375066 --> 0.374752).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 48.877312660217285
Epoch: 17, Steps: 93 | Train Loss: 0.2765105 Vali Loss: 0.3760066 Test Loss: 0.4567201
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 48.9760582447052
Epoch: 18, Steps: 93 | Train Loss: 0.2766578 Vali Loss: 0.3756755 Test Loss: 0.4567153
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 45.94762206077576
Epoch: 19, Steps: 93 | Train Loss: 0.2765253 Vali Loss: 0.3764263 Test Loss: 0.4566860
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 46.770607471466064
Epoch: 20, Steps: 93 | Train Loss: 0.2765451 Vali Loss: 0.3760184 Test Loss: 0.4569159
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 46.6055371761322
Epoch: 21, Steps: 93 | Train Loss: 0.2765595 Vali Loss: 0.3756121 Test Loss: 0.4565394
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 45.33375811576843
Epoch: 22, Steps: 93 | Train Loss: 0.2763208 Vali Loss: 0.3759841 Test Loss: 0.4566835
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 45.71217155456543
Epoch: 23, Steps: 93 | Train Loss: 0.2763688 Vali Loss: 0.3759668 Test Loss: 0.4565447
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 42.77968764305115
Epoch: 24, Steps: 93 | Train Loss: 0.2765131 Vali Loss: 0.3751999 Test Loss: 0.4566855
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 48.061240673065186
Epoch: 25, Steps: 93 | Train Loss: 0.2764587 Vali Loss: 0.3753912 Test Loss: 0.4566081
EarlyStopping counter: 9 out of 10
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 41.90253162384033
Epoch: 26, Steps: 93 | Train Loss: 0.2765647 Vali Loss: 0.3766156 Test Loss: 0.4566631
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : Traffic_180_j96_H5_FITS_custom_ftM_sl180_ll48_pl96_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3413
mse:0.4565466344356537, mae:0.3047606647014618, rse:0.5594947338104248, corr:[0.28573138 0.2918221  0.29290062 0.29168612 0.2913125  0.2922453
 0.29220194 0.29195845 0.2922631  0.29247352 0.29238898 0.29178372
 0.29103175 0.2909678  0.29074168 0.29027176 0.29019335 0.29027194
 0.29024687 0.290412   0.29086208 0.29187685 0.29283214 0.2925583
 0.29178032 0.290878   0.29100293 0.29098013 0.29061946 0.29092306
 0.29130882 0.29128253 0.29114315 0.29084083 0.2906244  0.29068014
 0.29062197 0.29043952 0.29035565 0.29039803 0.2903248  0.29037502
 0.2904494  0.29033595 0.29040053 0.2907495  0.2908434  0.29059505
 0.29022893 0.28961492 0.28943253 0.28954232 0.28948623 0.2896383
 0.28999707 0.29009035 0.29002666 0.28999254 0.28994018 0.28997898
 0.28994122 0.28958175 0.28939286 0.28967592 0.28965044 0.2893385
 0.2895158  0.28994027 0.29027277 0.2906385  0.29044437 0.2895795
 0.2888731  0.28870076 0.2887413  0.28887463 0.2891197  0.2893655
 0.28962916 0.2897661  0.2898096  0.2899666  0.2897949  0.2891746
 0.28888625 0.28885204 0.28847933 0.28859776 0.28936586 0.289258
 0.2885859  0.28854975 0.28848734 0.28796104 0.28767034 0.2889142 ]
