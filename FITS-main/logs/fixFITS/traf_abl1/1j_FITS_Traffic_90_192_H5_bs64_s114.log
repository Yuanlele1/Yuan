Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=30, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_90_j192_H5', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=10, pred_len=192, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_90_j192_H5_FITS_custom_ftM_sl90_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11999
val 1565
test 3317
Model(
  (freq_upsampler): Linear(in_features=30, out_features=94, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  311147520.0
params:  2914.0
Trainable parameters:  2914
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 60.06596088409424
Epoch: 1, Steps: 93 | Train Loss: 1.3077523 Vali Loss: 1.1625718 Test Loss: 1.3754712
Validation loss decreased (inf --> 1.162572).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 54.6360387802124
Epoch: 2, Steps: 93 | Train Loss: 0.7608587 Vali Loss: 0.8135496 Test Loss: 0.9683211
Validation loss decreased (1.162572 --> 0.813550).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 56.139567852020264
Epoch: 3, Steps: 93 | Train Loss: 0.5703293 Vali Loss: 0.6723536 Test Loss: 0.8054504
Validation loss decreased (0.813550 --> 0.672354).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 58.56569862365723
Epoch: 4, Steps: 93 | Train Loss: 0.4887087 Vali Loss: 0.6085096 Test Loss: 0.7318677
Validation loss decreased (0.672354 --> 0.608510).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 57.84241271018982
Epoch: 5, Steps: 93 | Train Loss: 0.4499953 Vali Loss: 0.5761160 Test Loss: 0.6948048
Validation loss decreased (0.608510 --> 0.576116).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 54.91412878036499
Epoch: 6, Steps: 93 | Train Loss: 0.4295449 Vali Loss: 0.5582244 Test Loss: 0.6739154
Validation loss decreased (0.576116 --> 0.558224).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 53.504287004470825
Epoch: 7, Steps: 93 | Train Loss: 0.4174187 Vali Loss: 0.5457999 Test Loss: 0.6611094
Validation loss decreased (0.558224 --> 0.545800).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 56.59608483314514
Epoch: 8, Steps: 93 | Train Loss: 0.4098898 Vali Loss: 0.5388602 Test Loss: 0.6524763
Validation loss decreased (0.545800 --> 0.538860).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 57.84989356994629
Epoch: 9, Steps: 93 | Train Loss: 0.4046320 Vali Loss: 0.5331815 Test Loss: 0.6466199
Validation loss decreased (0.538860 --> 0.533181).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 60.88473391532898
Epoch: 10, Steps: 93 | Train Loss: 0.4010943 Vali Loss: 0.5290940 Test Loss: 0.6422427
Validation loss decreased (0.533181 --> 0.529094).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 56.29287910461426
Epoch: 11, Steps: 93 | Train Loss: 0.3981743 Vali Loss: 0.5265591 Test Loss: 0.6389340
Validation loss decreased (0.529094 --> 0.526559).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 61.98299169540405
Epoch: 12, Steps: 93 | Train Loss: 0.3960399 Vali Loss: 0.5244551 Test Loss: 0.6363844
Validation loss decreased (0.526559 --> 0.524455).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 59.99613380432129
Epoch: 13, Steps: 93 | Train Loss: 0.3943678 Vali Loss: 0.5226716 Test Loss: 0.6344303
Validation loss decreased (0.524455 --> 0.522672).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 59.66253924369812
Epoch: 14, Steps: 93 | Train Loss: 0.3929361 Vali Loss: 0.5207664 Test Loss: 0.6327146
Validation loss decreased (0.522672 --> 0.520766).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 57.28286814689636
Epoch: 15, Steps: 93 | Train Loss: 0.3918410 Vali Loss: 0.5198113 Test Loss: 0.6312462
Validation loss decreased (0.520766 --> 0.519811).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 59.34548330307007
Epoch: 16, Steps: 93 | Train Loss: 0.3907358 Vali Loss: 0.5185558 Test Loss: 0.6301214
Validation loss decreased (0.519811 --> 0.518556).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 58.027358293533325
Epoch: 17, Steps: 93 | Train Loss: 0.3902160 Vali Loss: 0.5178517 Test Loss: 0.6291613
Validation loss decreased (0.518556 --> 0.517852).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 58.924320459365845
Epoch: 18, Steps: 93 | Train Loss: 0.3894014 Vali Loss: 0.5173626 Test Loss: 0.6283538
Validation loss decreased (0.517852 --> 0.517363).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 55.2584331035614
Epoch: 19, Steps: 93 | Train Loss: 0.3888995 Vali Loss: 0.5155888 Test Loss: 0.6276227
Validation loss decreased (0.517363 --> 0.515589).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 60.55514168739319
Epoch: 20, Steps: 93 | Train Loss: 0.3883569 Vali Loss: 0.5153576 Test Loss: 0.6270761
Validation loss decreased (0.515589 --> 0.515358).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 55.14209461212158
Epoch: 21, Steps: 93 | Train Loss: 0.3878407 Vali Loss: 0.5146640 Test Loss: 0.6264902
Validation loss decreased (0.515358 --> 0.514664).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 59.73683953285217
Epoch: 22, Steps: 93 | Train Loss: 0.3875530 Vali Loss: 0.5145008 Test Loss: 0.6260747
Validation loss decreased (0.514664 --> 0.514501).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 55.44942784309387
Epoch: 23, Steps: 93 | Train Loss: 0.3871239 Vali Loss: 0.5139040 Test Loss: 0.6256343
Validation loss decreased (0.514501 --> 0.513904).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 61.39793562889099
Epoch: 24, Steps: 93 | Train Loss: 0.3868821 Vali Loss: 0.5135986 Test Loss: 0.6252905
Validation loss decreased (0.513904 --> 0.513599).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 54.036465644836426
Epoch: 25, Steps: 93 | Train Loss: 0.3867547 Vali Loss: 0.5126508 Test Loss: 0.6250066
Validation loss decreased (0.513599 --> 0.512651).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 59.047523498535156
Epoch: 26, Steps: 93 | Train Loss: 0.3864160 Vali Loss: 0.5132298 Test Loss: 0.6247678
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 55.818623781204224
Epoch: 27, Steps: 93 | Train Loss: 0.3864115 Vali Loss: 0.5122128 Test Loss: 0.6245252
Validation loss decreased (0.512651 --> 0.512213).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 60.35200214385986
Epoch: 28, Steps: 93 | Train Loss: 0.3861327 Vali Loss: 0.5127815 Test Loss: 0.6243607
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 57.34711265563965
Epoch: 29, Steps: 93 | Train Loss: 0.3858897 Vali Loss: 0.5123963 Test Loss: 0.6241214
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 48.006046533584595
Epoch: 30, Steps: 93 | Train Loss: 0.3857534 Vali Loss: 0.5124043 Test Loss: 0.6240445
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 44.659252882003784
Epoch: 31, Steps: 93 | Train Loss: 0.3855508 Vali Loss: 0.5113849 Test Loss: 0.6239499
Validation loss decreased (0.512213 --> 0.511385).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 47.63731002807617
Epoch: 32, Steps: 93 | Train Loss: 0.3855629 Vali Loss: 0.5121344 Test Loss: 0.6238049
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 44.75443983078003
Epoch: 33, Steps: 93 | Train Loss: 0.3854891 Vali Loss: 0.5122181 Test Loss: 0.6237142
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 46.282474994659424
Epoch: 34, Steps: 93 | Train Loss: 0.3852157 Vali Loss: 0.5113854 Test Loss: 0.6236073
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 45.61807322502136
Epoch: 35, Steps: 93 | Train Loss: 0.3852582 Vali Loss: 0.5116894 Test Loss: 0.6235120
EarlyStopping counter: 4 out of 10
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 47.6546311378479
Epoch: 36, Steps: 93 | Train Loss: 0.3852158 Vali Loss: 0.5116174 Test Loss: 0.6234856
EarlyStopping counter: 5 out of 10
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 47.4148006439209
Epoch: 37, Steps: 93 | Train Loss: 0.3851712 Vali Loss: 0.5116519 Test Loss: 0.6234289
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 43.49891781806946
Epoch: 38, Steps: 93 | Train Loss: 0.3851040 Vali Loss: 0.5118104 Test Loss: 0.6233803
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 47.16412329673767
Epoch: 39, Steps: 93 | Train Loss: 0.3849688 Vali Loss: 0.5114460 Test Loss: 0.6233476
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 46.30226278305054
Epoch: 40, Steps: 93 | Train Loss: 0.3849972 Vali Loss: 0.5115158 Test Loss: 0.6233054
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 47.52290725708008
Epoch: 41, Steps: 93 | Train Loss: 0.3850381 Vali Loss: 0.5112043 Test Loss: 0.6232687
Validation loss decreased (0.511385 --> 0.511204).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 43.66541051864624
Epoch: 42, Steps: 93 | Train Loss: 0.3850404 Vali Loss: 0.5120360 Test Loss: 0.6232576
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 46.09598445892334
Epoch: 43, Steps: 93 | Train Loss: 0.3849108 Vali Loss: 0.5108562 Test Loss: 0.6231937
Validation loss decreased (0.511204 --> 0.510856).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 45.382347106933594
Epoch: 44, Steps: 93 | Train Loss: 0.3846855 Vali Loss: 0.5111045 Test Loss: 0.6231803
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 46.94009041786194
Epoch: 45, Steps: 93 | Train Loss: 0.3848865 Vali Loss: 0.5114632 Test Loss: 0.6231845
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 42.72180676460266
Epoch: 46, Steps: 93 | Train Loss: 0.3846447 Vali Loss: 0.5108625 Test Loss: 0.6231566
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 49.04993939399719
Epoch: 47, Steps: 93 | Train Loss: 0.3847561 Vali Loss: 0.5109027 Test Loss: 0.6231030
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 47.06151819229126
Epoch: 48, Steps: 93 | Train Loss: 0.3846732 Vali Loss: 0.5106837 Test Loss: 0.6231210
Validation loss decreased (0.510856 --> 0.510684).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 43.51079177856445
Epoch: 49, Steps: 93 | Train Loss: 0.3848250 Vali Loss: 0.5113174 Test Loss: 0.6231042
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 42.067084074020386
Epoch: 50, Steps: 93 | Train Loss: 0.3847545 Vali Loss: 0.5106308 Test Loss: 0.6231181
Validation loss decreased (0.510684 --> 0.510631).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 45.91037058830261
Epoch: 51, Steps: 93 | Train Loss: 0.3848019 Vali Loss: 0.5114793 Test Loss: 0.6230812
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 39.823599338531494
Epoch: 52, Steps: 93 | Train Loss: 0.3847550 Vali Loss: 0.5109102 Test Loss: 0.6230808
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 42.598010301589966
Epoch: 53, Steps: 93 | Train Loss: 0.3846214 Vali Loss: 0.5114415 Test Loss: 0.6230534
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 39.4132924079895
Epoch: 54, Steps: 93 | Train Loss: 0.3846281 Vali Loss: 0.5104844 Test Loss: 0.6230621
Validation loss decreased (0.510631 --> 0.510484).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 44.16197228431702
Epoch: 55, Steps: 93 | Train Loss: 0.3845440 Vali Loss: 0.5113681 Test Loss: 0.6230696
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 40.747066259384155
Epoch: 56, Steps: 93 | Train Loss: 0.3846712 Vali Loss: 0.5112540 Test Loss: 0.6230488
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 38.65617227554321
Epoch: 57, Steps: 93 | Train Loss: 0.3846766 Vali Loss: 0.5106521 Test Loss: 0.6230595
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 39.957900285720825
Epoch: 58, Steps: 93 | Train Loss: 0.3846320 Vali Loss: 0.5108138 Test Loss: 0.6230458
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 44.71782994270325
Epoch: 59, Steps: 93 | Train Loss: 0.3846744 Vali Loss: 0.5107616 Test Loss: 0.6230533
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 47.51087164878845
Epoch: 60, Steps: 93 | Train Loss: 0.3846265 Vali Loss: 0.5113503 Test Loss: 0.6230544
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 44.32327723503113
Epoch: 61, Steps: 93 | Train Loss: 0.3846478 Vali Loss: 0.5107744 Test Loss: 0.6230335
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 46.530057191848755
Epoch: 62, Steps: 93 | Train Loss: 0.3845392 Vali Loss: 0.5110106 Test Loss: 0.6230650
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 47.166281938552856
Epoch: 63, Steps: 93 | Train Loss: 0.3845394 Vali Loss: 0.5107651 Test Loss: 0.6230540
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 45.643136739730835
Epoch: 64, Steps: 93 | Train Loss: 0.3845498 Vali Loss: 0.5109896 Test Loss: 0.6230382
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : Traffic_90_j192_H5_FITS_custom_ftM_sl90_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3317
mse:0.6228823661804199, mae:0.3764762580394745, rse:0.6513764262199402, corr:[0.27698836 0.2803719  0.28373876 0.282507   0.2820039  0.28559858
 0.2877743  0.28687713 0.28725216 0.2873937  0.28557995 0.28531688
 0.28505898 0.2835535  0.2836478  0.28480646 0.28519714 0.2860027
 0.28823823 0.29029807 0.29079282 0.29177892 0.29185948 0.2909874
 0.29549393 0.2995463  0.29932183 0.29798296 0.2980207  0.2993372
 0.2998078  0.30096716 0.3012621  0.30077022 0.30047837 0.30010384
 0.299266   0.29847497 0.2985208  0.29886618 0.2991347  0.29984847
 0.30107662 0.30176243 0.3015502  0.3017944  0.30107677 0.29950595
 0.29996437 0.29882127 0.29694796 0.2961908  0.2951417  0.29114342
 0.28779793 0.28869084 0.28895018 0.28846148 0.28803736 0.28688353
 0.28573877 0.285179   0.28481707 0.28459537 0.28470045 0.2851164
 0.28573322 0.28618702 0.28622398 0.28645727 0.2860836  0.2844958
 0.28287697 0.2815804  0.2808111  0.28130195 0.28264567 0.28281456
 0.28290308 0.2852635  0.28598273 0.2856308  0.2849609  0.2835154
 0.2826202  0.2821905  0.2814709  0.2810855  0.28092408 0.2808245
 0.28122926 0.28163058 0.28188288 0.28250748 0.28291437 0.282732
 0.28240764 0.2821448  0.28192118 0.28174892 0.28190815 0.28229934
 0.28295115 0.28419355 0.28434822 0.28365728 0.2832357  0.28267974
 0.28222707 0.28197375 0.28157043 0.28152397 0.28162113 0.28163406
 0.2822041  0.28274727 0.2828747  0.2834415  0.28397766 0.28397614
 0.28394118 0.2839371  0.28388274 0.28370515 0.28365222 0.2836824
 0.28338662 0.28317776 0.28291816 0.2822338  0.28182402 0.28170475
 0.28160876 0.28157246 0.28151497 0.28180072 0.28228566 0.28266504
 0.28357396 0.28424007 0.2842007  0.28501135 0.28520077 0.28359312
 0.2825713  0.28240025 0.2823204  0.28217962 0.28226438 0.28255895
 0.28260255 0.28273192 0.28285235 0.28225812 0.2816726  0.28152397
 0.28142303 0.28153414 0.2819137  0.2825195  0.28321227 0.2838086
 0.2852293  0.28661534 0.28678325 0.2875782  0.2874808  0.28470543
 0.28367755 0.28303608 0.28124315 0.27980718 0.28030536 0.2821854
 0.28431767 0.28657255 0.28773955 0.28757352 0.28774452 0.2883583
 0.28786907 0.28686306 0.2870809  0.28710285 0.28609592 0.2864728
 0.28682974 0.2858144  0.28622434 0.28593156 0.28258157 0.28448486]
