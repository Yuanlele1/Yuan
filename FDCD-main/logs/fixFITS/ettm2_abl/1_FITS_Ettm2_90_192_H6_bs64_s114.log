Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=16, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_90_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_90_192_FITS_ETTm2_ftM_sl90_ll48_pl192_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34279
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=16, out_features=50, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  716800.0
params:  850.0
Trainable parameters:  850
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3892304
	speed: 0.0186s/iter; left time: 494.6040s
	iters: 200, epoch: 1 | loss: 0.4650501
	speed: 0.0114s/iter; left time: 303.1049s
Epoch: 1 cost time: 3.774770498275757
Epoch: 1, Steps: 267 | Train Loss: 0.4170835 Vali Loss: 0.1893400 Test Loss: 0.2698659
Validation loss decreased (inf --> 0.189340).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2252386
	speed: 0.0603s/iter; left time: 1587.3600s
	iters: 200, epoch: 2 | loss: 0.3061022
	speed: 0.0106s/iter; left time: 277.0995s
Epoch: 2 cost time: 3.4122707843780518
Epoch: 2, Steps: 267 | Train Loss: 0.3575053 Vali Loss: 0.1768994 Test Loss: 0.2543756
Validation loss decreased (0.189340 --> 0.176899).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3111981
	speed: 0.0622s/iter; left time: 1620.3972s
	iters: 200, epoch: 3 | loss: 0.4494629
	speed: 0.0105s/iter; left time: 271.5636s
Epoch: 3 cost time: 3.4102976322174072
Epoch: 3, Steps: 267 | Train Loss: 0.3473187 Vali Loss: 0.1744579 Test Loss: 0.2512363
Validation loss decreased (0.176899 --> 0.174458).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4698950
	speed: 0.0619s/iter; left time: 1597.4926s
	iters: 200, epoch: 4 | loss: 0.3651130
	speed: 0.0114s/iter; left time: 292.3397s
Epoch: 4 cost time: 3.5555951595306396
Epoch: 4, Steps: 267 | Train Loss: 0.3427971 Vali Loss: 0.1735440 Test Loss: 0.2498634
Validation loss decreased (0.174458 --> 0.173544).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4192617
	speed: 0.0607s/iter; left time: 1548.7402s
	iters: 200, epoch: 5 | loss: 0.1979582
	speed: 0.0122s/iter; left time: 310.7721s
Epoch: 5 cost time: 3.5295863151550293
Epoch: 5, Steps: 267 | Train Loss: 0.3414370 Vali Loss: 0.1733740 Test Loss: 0.2491646
Validation loss decreased (0.173544 --> 0.173374).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3289653
	speed: 0.0578s/iter; left time: 1461.5440s
	iters: 200, epoch: 6 | loss: 0.3809637
	speed: 0.0105s/iter; left time: 264.5066s
Epoch: 6 cost time: 3.318282127380371
Epoch: 6, Steps: 267 | Train Loss: 0.3403215 Vali Loss: 0.1732408 Test Loss: 0.2489050
Validation loss decreased (0.173374 --> 0.173241).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3945542
	speed: 0.0675s/iter; left time: 1686.4358s
	iters: 200, epoch: 7 | loss: 0.4022863
	speed: 0.0110s/iter; left time: 274.5861s
Epoch: 7 cost time: 3.652745008468628
Epoch: 7, Steps: 267 | Train Loss: 0.3393242 Vali Loss: 0.1732571 Test Loss: 0.2486398
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3875211
	speed: 0.0617s/iter; left time: 1525.0722s
	iters: 200, epoch: 8 | loss: 0.3701036
	speed: 0.0102s/iter; left time: 250.7331s
Epoch: 8 cost time: 3.434573173522949
Epoch: 8, Steps: 267 | Train Loss: 0.3393117 Vali Loss: 0.1731299 Test Loss: 0.2485322
Validation loss decreased (0.173241 --> 0.173130).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3697023
	speed: 0.0673s/iter; left time: 1645.8101s
	iters: 200, epoch: 9 | loss: 0.3533568
	speed: 0.0124s/iter; left time: 302.6925s
Epoch: 9 cost time: 4.194321155548096
Epoch: 9, Steps: 267 | Train Loss: 0.3387896 Vali Loss: 0.1731522 Test Loss: 0.2483935
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3767042
	speed: 0.0633s/iter; left time: 1530.5868s
	iters: 200, epoch: 10 | loss: 0.4066463
	speed: 0.0110s/iter; left time: 264.9599s
Epoch: 10 cost time: 3.461557388305664
Epoch: 10, Steps: 267 | Train Loss: 0.3384838 Vali Loss: 0.1731414 Test Loss: 0.2483706
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2190495
	speed: 0.0628s/iter; left time: 1503.5834s
	iters: 200, epoch: 11 | loss: 0.4383233
	speed: 0.0112s/iter; left time: 265.7954s
Epoch: 11 cost time: 3.37717342376709
Epoch: 11, Steps: 267 | Train Loss: 0.3378297 Vali Loss: 0.1732758 Test Loss: 0.2483582
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2980013
	speed: 0.0612s/iter; left time: 1448.8138s
	iters: 200, epoch: 12 | loss: 0.2654090
	speed: 0.0107s/iter; left time: 251.3336s
Epoch: 12 cost time: 3.361673355102539
Epoch: 12, Steps: 267 | Train Loss: 0.3372937 Vali Loss: 0.1734131 Test Loss: 0.2482785
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3654160
	speed: 0.0686s/iter; left time: 1605.3681s
	iters: 200, epoch: 13 | loss: 0.3375334
	speed: 0.0104s/iter; left time: 242.7463s
Epoch: 13 cost time: 3.3443644046783447
Epoch: 13, Steps: 267 | Train Loss: 0.3375273 Vali Loss: 0.1732924 Test Loss: 0.2483177
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2469430
	speed: 0.0611s/iter; left time: 1413.1350s
	iters: 200, epoch: 14 | loss: 0.4982134
	speed: 0.0103s/iter; left time: 238.3147s
Epoch: 14 cost time: 3.3890371322631836
Epoch: 14, Steps: 267 | Train Loss: 0.3377845 Vali Loss: 0.1735501 Test Loss: 0.2483581
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4631433
	speed: 0.0596s/iter; left time: 1362.0962s
	iters: 200, epoch: 15 | loss: 0.2469422
	speed: 0.0104s/iter; left time: 236.4504s
Epoch: 15 cost time: 3.304123878479004
Epoch: 15, Steps: 267 | Train Loss: 0.3378400 Vali Loss: 0.1734600 Test Loss: 0.2483094
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4167249
	speed: 0.0598s/iter; left time: 1350.2498s
	iters: 200, epoch: 16 | loss: 0.3649814
	speed: 0.0108s/iter; left time: 242.5796s
Epoch: 16 cost time: 3.473198175430298
Epoch: 16, Steps: 267 | Train Loss: 0.3377484 Vali Loss: 0.1733067 Test Loss: 0.2483380
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3219323
	speed: 0.0622s/iter; left time: 1387.8695s
	iters: 200, epoch: 17 | loss: 0.3448301
	speed: 0.0106s/iter; left time: 236.0685s
Epoch: 17 cost time: 3.624134063720703
Epoch: 17, Steps: 267 | Train Loss: 0.3376204 Vali Loss: 0.1734520 Test Loss: 0.2483488
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3637463
	speed: 0.0609s/iter; left time: 1342.9484s
	iters: 200, epoch: 18 | loss: 0.2618474
	speed: 0.0104s/iter; left time: 229.1764s
Epoch: 18 cost time: 3.3792190551757812
Epoch: 18, Steps: 267 | Train Loss: 0.3373700 Vali Loss: 0.1735142 Test Loss: 0.2483371
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2765078
	speed: 0.0627s/iter; left time: 1366.2519s
	iters: 200, epoch: 19 | loss: 0.4598186
	speed: 0.0103s/iter; left time: 223.8085s
Epoch: 19 cost time: 3.35746169090271
Epoch: 19, Steps: 267 | Train Loss: 0.3370183 Vali Loss: 0.1735964 Test Loss: 0.2483309
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2547353
	speed: 0.0600s/iter; left time: 1290.6831s
	iters: 200, epoch: 20 | loss: 0.3855785
	speed: 0.0130s/iter; left time: 277.7621s
Epoch: 20 cost time: 3.7193052768707275
Epoch: 20, Steps: 267 | Train Loss: 0.3369511 Vali Loss: 0.1736171 Test Loss: 0.2483674
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.5611929
	speed: 0.0649s/iter; left time: 1380.1439s
	iters: 200, epoch: 21 | loss: 0.2772468
	speed: 0.0102s/iter; left time: 215.9517s
Epoch: 21 cost time: 3.45383882522583
Epoch: 21, Steps: 267 | Train Loss: 0.3375201 Vali Loss: 0.1736002 Test Loss: 0.2483792
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1915576
	speed: 0.0608s/iter; left time: 1277.4220s
	iters: 200, epoch: 22 | loss: 0.3797128
	speed: 0.0105s/iter; left time: 219.6595s
Epoch: 22 cost time: 3.3865840435028076
Epoch: 22, Steps: 267 | Train Loss: 0.3367237 Vali Loss: 0.1737198 Test Loss: 0.2483491
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2156386
	speed: 0.0627s/iter; left time: 1298.5609s
	iters: 200, epoch: 23 | loss: 0.2945715
	speed: 0.0102s/iter; left time: 211.1998s
Epoch: 23 cost time: 3.3929269313812256
Epoch: 23, Steps: 267 | Train Loss: 0.3363569 Vali Loss: 0.1735254 Test Loss: 0.2483527
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4005809
	speed: 0.0656s/iter; left time: 1342.5175s
	iters: 200, epoch: 24 | loss: 0.2793786
	speed: 0.0105s/iter; left time: 212.8191s
Epoch: 24 cost time: 4.934597015380859
Epoch: 24, Steps: 267 | Train Loss: 0.3369385 Vali Loss: 0.1736414 Test Loss: 0.2483631
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2962618
	speed: 0.0751s/iter; left time: 1515.5533s
	iters: 200, epoch: 25 | loss: 0.3722076
	speed: 0.0107s/iter; left time: 215.7634s
Epoch: 25 cost time: 3.8765830993652344
Epoch: 25, Steps: 267 | Train Loss: 0.3366251 Vali Loss: 0.1735752 Test Loss: 0.2483626
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4419706
	speed: 0.0682s/iter; left time: 1359.7545s
	iters: 200, epoch: 26 | loss: 0.2826785
	speed: 0.0118s/iter; left time: 234.0729s
Epoch: 26 cost time: 3.429075241088867
Epoch: 26, Steps: 267 | Train Loss: 0.3371518 Vali Loss: 0.1735692 Test Loss: 0.2483539
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3299761
	speed: 0.0635s/iter; left time: 1247.5804s
	iters: 200, epoch: 27 | loss: 0.2125015
	speed: 0.0291s/iter; left time: 570.1209s
Epoch: 27 cost time: 6.8218371868133545
Epoch: 27, Steps: 267 | Train Loss: 0.3372197 Vali Loss: 0.1734095 Test Loss: 0.2483636
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2449555
	speed: 0.0787s/iter; left time: 1526.8447s
	iters: 200, epoch: 28 | loss: 0.4216177
	speed: 0.0103s/iter; left time: 198.3888s
Epoch: 28 cost time: 3.6439945697784424
Epoch: 28, Steps: 267 | Train Loss: 0.3368443 Vali Loss: 0.1734921 Test Loss: 0.2483560
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_90_192_FITS_ETTm2_ftM_sl90_ll48_pl192_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.2493654191493988, mae:0.3072672486305237, rse:0.4042157232761383, corr:[0.5609592  0.56642675 0.5615443  0.55589753 0.5543777  0.5556043
 0.55567455 0.5536142  0.5511922  0.5503207  0.5510368  0.5515711
 0.55068487 0.5488106  0.5473635  0.5472372  0.54765886 0.5472784
 0.54576504 0.54382694 0.5426138  0.54249513 0.542684   0.54232764
 0.5413348  0.5402726  0.53979    0.5397899  0.53961545 0.53885716
 0.53765815 0.53661764 0.5361323  0.53605676 0.5358904  0.53533953
 0.53441834 0.5334777  0.5328004  0.5323382  0.53192717 0.53145254
 0.5309119  0.530455   0.5301259  0.5297582  0.52920693 0.5283788
 0.5274418  0.5266241  0.52595586 0.52536905 0.5247155  0.52394015
 0.52323663 0.52273303 0.522369   0.5220804  0.52177507 0.5214882
 0.5212661  0.52116734 0.5211882  0.52128357 0.5213036  0.521212
 0.5210466  0.5208778  0.5208241  0.520874   0.52095264 0.52101403
 0.5209992  0.52094907 0.5208614  0.52075255 0.52062947 0.52041394
 0.52011526 0.51979977 0.51955026 0.51936847 0.51920915 0.51898503
 0.518633   0.5182222  0.51783055 0.51754403 0.51730794 0.51699716
 0.5165551  0.5159705  0.51527977 0.5144865  0.51339906 0.5117829
 0.50967103 0.5074545  0.5055395  0.503994   0.50256443 0.5009953
 0.49928775 0.49766478 0.49636286 0.49536753 0.49442363 0.49329555
 0.49194518 0.49057737 0.48939994 0.4883366  0.4872436  0.48595893
 0.4845347  0.4832024  0.48214087 0.48128337 0.48042575 0.47935644
 0.47817552 0.47710288 0.47626987 0.47556385 0.4747828  0.4738161
 0.4727195  0.47166148 0.47068962 0.46980843 0.4689632  0.46803367
 0.46703038 0.46608883 0.4653322  0.4649467  0.46464363 0.46430168
 0.46379298 0.4632622  0.4629168  0.462728   0.4624776  0.46189424
 0.46093386 0.45989013 0.459011   0.45840868 0.45785496 0.45708716
 0.45611307 0.45536503 0.4549515  0.4546521  0.4542443  0.45366642
 0.45301744 0.45267123 0.4526257  0.45280647 0.45281526 0.45240486
 0.45183223 0.45130214 0.45123875 0.45142353 0.45147547 0.45121214
 0.45084766 0.45078236 0.45110142 0.451544   0.45178717 0.45168978
 0.4514629  0.45139003 0.45150942 0.4517443  0.45193264 0.45207664
 0.4521469  0.45207125 0.4519993  0.45186985 0.45184317 0.4520348
 0.45227683 0.45254222 0.45288157 0.4535786  0.45445028 0.45337242]
