Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_720_720_FITS_ETTm2_ftM_sl720_ll48_pl720_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=106, out_features=212, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  20134912.0
params:  22684.0
Trainable parameters:  22684
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4635371
	speed: 0.0291s/iter; left time: 748.1875s
	iters: 200, epoch: 1 | loss: 0.5438815
	speed: 0.0227s/iter; left time: 582.0114s
Epoch: 1 cost time: 6.491965055465698
Epoch: 1, Steps: 258 | Train Loss: 0.5751630 Vali Loss: 0.2786936 Test Loss: 0.3735374
Validation loss decreased (inf --> 0.278694).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5808871
	speed: 0.1041s/iter; left time: 2648.6980s
	iters: 200, epoch: 2 | loss: 0.4827980
	speed: 0.0240s/iter; left time: 609.3653s
Epoch: 2 cost time: 6.8762571811676025
Epoch: 2, Steps: 258 | Train Loss: 0.5173751 Vali Loss: 0.2690624 Test Loss: 0.3640226
Validation loss decreased (0.278694 --> 0.269062).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4503457
	speed: 0.1055s/iter; left time: 2656.8922s
	iters: 200, epoch: 3 | loss: 0.6386450
	speed: 0.0240s/iter; left time: 602.1966s
Epoch: 3 cost time: 7.0780158042907715
Epoch: 3, Steps: 258 | Train Loss: 0.5083155 Vali Loss: 0.2661079 Test Loss: 0.3599859
Validation loss decreased (0.269062 --> 0.266108).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3671085
	speed: 0.1054s/iter; left time: 2627.0288s
	iters: 200, epoch: 4 | loss: 0.5175946
	speed: 0.0248s/iter; left time: 615.3120s
Epoch: 4 cost time: 7.001124620437622
Epoch: 4, Steps: 258 | Train Loss: 0.5037142 Vali Loss: 0.2644572 Test Loss: 0.3581561
Validation loss decreased (0.266108 --> 0.264457).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4653016
	speed: 0.1032s/iter; left time: 2546.5680s
	iters: 200, epoch: 5 | loss: 0.5842043
	speed: 0.0250s/iter; left time: 614.9737s
Epoch: 5 cost time: 6.973991394042969
Epoch: 5, Steps: 258 | Train Loss: 0.5016872 Vali Loss: 0.2636735 Test Loss: 0.3564713
Validation loss decreased (0.264457 --> 0.263674).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.5358415
	speed: 0.1084s/iter; left time: 2644.9882s
	iters: 200, epoch: 6 | loss: 0.4483637
	speed: 0.0242s/iter; left time: 589.2744s
Epoch: 6 cost time: 7.015890598297119
Epoch: 6, Steps: 258 | Train Loss: 0.5003397 Vali Loss: 0.2630665 Test Loss: 0.3554808
Validation loss decreased (0.263674 --> 0.263067).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.6606080
	speed: 0.1054s/iter; left time: 2545.5363s
	iters: 200, epoch: 7 | loss: 0.5333021
	speed: 0.0241s/iter; left time: 580.8381s
Epoch: 7 cost time: 6.772517919540405
Epoch: 7, Steps: 258 | Train Loss: 0.4989310 Vali Loss: 0.2623230 Test Loss: 0.3550739
Validation loss decreased (0.263067 --> 0.262323).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.5174621
	speed: 0.1016s/iter; left time: 2427.1792s
	iters: 200, epoch: 8 | loss: 0.4871202
	speed: 0.0240s/iter; left time: 571.3229s
Epoch: 8 cost time: 6.916797876358032
Epoch: 8, Steps: 258 | Train Loss: 0.4982787 Vali Loss: 0.2620040 Test Loss: 0.3545384
Validation loss decreased (0.262323 --> 0.262004).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3968214
	speed: 0.1066s/iter; left time: 2519.2651s
	iters: 200, epoch: 9 | loss: 0.4264001
	speed: 0.0254s/iter; left time: 598.7516s
Epoch: 9 cost time: 7.130938291549683
Epoch: 9, Steps: 258 | Train Loss: 0.4973656 Vali Loss: 0.2616517 Test Loss: 0.3542859
Validation loss decreased (0.262004 --> 0.261652).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.5551780
	speed: 0.1069s/iter; left time: 2498.4814s
	iters: 200, epoch: 10 | loss: 0.4448959
	speed: 0.0251s/iter; left time: 583.9873s
Epoch: 10 cost time: 6.967203617095947
Epoch: 10, Steps: 258 | Train Loss: 0.4970279 Vali Loss: 0.2612039 Test Loss: 0.3540832
Validation loss decreased (0.261652 --> 0.261204).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4871192
	speed: 0.1100s/iter; left time: 2543.2052s
	iters: 200, epoch: 11 | loss: 0.3677740
	speed: 0.0253s/iter; left time: 582.6064s
Epoch: 11 cost time: 7.270817995071411
Epoch: 11, Steps: 258 | Train Loss: 0.4963107 Vali Loss: 0.2614178 Test Loss: 0.3536199
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.5803165
	speed: 0.1079s/iter; left time: 2467.3423s
	iters: 200, epoch: 12 | loss: 0.7413377
	speed: 0.0238s/iter; left time: 542.1618s
Epoch: 12 cost time: 7.370114088058472
Epoch: 12, Steps: 258 | Train Loss: 0.4961749 Vali Loss: 0.2613285 Test Loss: 0.3535037
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4242962
	speed: 0.1057s/iter; left time: 2389.9327s
	iters: 200, epoch: 13 | loss: 0.6042295
	speed: 0.0230s/iter; left time: 516.6249s
Epoch: 13 cost time: 6.63406777381897
Epoch: 13, Steps: 258 | Train Loss: 0.4961077 Vali Loss: 0.2611617 Test Loss: 0.3533415
Validation loss decreased (0.261204 --> 0.261162).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3726468
	speed: 0.1028s/iter; left time: 2296.7075s
	iters: 200, epoch: 14 | loss: 0.4603989
	speed: 0.0242s/iter; left time: 539.2473s
Epoch: 14 cost time: 6.738509654998779
Epoch: 14, Steps: 258 | Train Loss: 0.4952662 Vali Loss: 0.2607957 Test Loss: 0.3533469
Validation loss decreased (0.261162 --> 0.260796).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4448492
	speed: 0.0987s/iter; left time: 2179.2163s
	iters: 200, epoch: 15 | loss: 0.5199741
	speed: 0.0248s/iter; left time: 544.3906s
Epoch: 15 cost time: 6.71512508392334
Epoch: 15, Steps: 258 | Train Loss: 0.4955604 Vali Loss: 0.2609763 Test Loss: 0.3529965
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4589243
	speed: 0.0997s/iter; left time: 2177.5085s
	iters: 200, epoch: 16 | loss: 0.4382912
	speed: 0.0230s/iter; left time: 500.5014s
Epoch: 16 cost time: 6.665661334991455
Epoch: 16, Steps: 258 | Train Loss: 0.4946630 Vali Loss: 0.2604860 Test Loss: 0.3531143
Validation loss decreased (0.260796 --> 0.260486).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3460967
	speed: 0.1028s/iter; left time: 2218.7675s
	iters: 200, epoch: 17 | loss: 0.4637965
	speed: 0.0232s/iter; left time: 499.2395s
Epoch: 17 cost time: 6.912508010864258
Epoch: 17, Steps: 258 | Train Loss: 0.4948215 Vali Loss: 0.2608902 Test Loss: 0.3527269
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4853757
	speed: 0.1005s/iter; left time: 2142.2599s
	iters: 200, epoch: 18 | loss: 0.4285213
	speed: 0.0239s/iter; left time: 506.6031s
Epoch: 18 cost time: 6.73005747795105
Epoch: 18, Steps: 258 | Train Loss: 0.4947360 Vali Loss: 0.2606505 Test Loss: 0.3528437
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.5062560
	speed: 0.1005s/iter; left time: 2115.6526s
	iters: 200, epoch: 19 | loss: 0.5348747
	speed: 0.0243s/iter; left time: 509.1311s
Epoch: 19 cost time: 6.874007940292358
Epoch: 19, Steps: 258 | Train Loss: 0.4947706 Vali Loss: 0.2607088 Test Loss: 0.3528318
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.5893570
	speed: 0.1014s/iter; left time: 2109.4563s
	iters: 200, epoch: 20 | loss: 0.5077928
	speed: 0.0238s/iter; left time: 493.4736s
Epoch: 20 cost time: 6.761340141296387
Epoch: 20, Steps: 258 | Train Loss: 0.4942597 Vali Loss: 0.2605920 Test Loss: 0.3527220
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.7471894
	speed: 0.1036s/iter; left time: 2127.2493s
	iters: 200, epoch: 21 | loss: 0.4004019
	speed: 0.0235s/iter; left time: 479.7795s
Epoch: 21 cost time: 6.787940740585327
Epoch: 21, Steps: 258 | Train Loss: 0.4938924 Vali Loss: 0.2605014 Test Loss: 0.3527707
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.5495166
	speed: 0.1046s/iter; left time: 2120.9822s
	iters: 200, epoch: 22 | loss: 0.4676659
	speed: 0.0242s/iter; left time: 487.7391s
Epoch: 22 cost time: 7.011293649673462
Epoch: 22, Steps: 258 | Train Loss: 0.4938569 Vali Loss: 0.2604033 Test Loss: 0.3526936
Validation loss decreased (0.260486 --> 0.260403).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4461653
	speed: 0.1173s/iter; left time: 2348.3288s
	iters: 200, epoch: 23 | loss: 0.4801434
	speed: 0.0240s/iter; left time: 478.1505s
Epoch: 23 cost time: 8.43025827407837
Epoch: 23, Steps: 258 | Train Loss: 0.4943800 Vali Loss: 0.2607672 Test Loss: 0.3525335
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.5737054
	speed: 0.1018s/iter; left time: 2012.4886s
	iters: 200, epoch: 24 | loss: 0.4007513
	speed: 0.0232s/iter; left time: 455.8339s
Epoch: 24 cost time: 6.722811222076416
Epoch: 24, Steps: 258 | Train Loss: 0.4947132 Vali Loss: 0.2606388 Test Loss: 0.3525493
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.5253909
	speed: 0.1009s/iter; left time: 1968.7351s
	iters: 200, epoch: 25 | loss: 0.5306019
	speed: 0.0238s/iter; left time: 461.0815s
Epoch: 25 cost time: 6.776848554611206
Epoch: 25, Steps: 258 | Train Loss: 0.4943232 Vali Loss: 0.2603218 Test Loss: 0.3525105
Validation loss decreased (0.260403 --> 0.260322).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4136276
	speed: 0.1052s/iter; left time: 2025.5982s
	iters: 200, epoch: 26 | loss: 0.4735907
	speed: 0.0251s/iter; left time: 480.2290s
Epoch: 26 cost time: 7.192612409591675
Epoch: 26, Steps: 258 | Train Loss: 0.4939438 Vali Loss: 0.2602644 Test Loss: 0.3525183
Validation loss decreased (0.260322 --> 0.260264).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4479135
	speed: 0.1053s/iter; left time: 1999.8854s
	iters: 200, epoch: 27 | loss: 0.4378653
	speed: 0.0245s/iter; left time: 462.9779s
Epoch: 27 cost time: 6.895748615264893
Epoch: 27, Steps: 258 | Train Loss: 0.4940431 Vali Loss: 0.2604325 Test Loss: 0.3523723
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4043334
	speed: 0.1034s/iter; left time: 1937.0939s
	iters: 200, epoch: 28 | loss: 0.5851707
	speed: 0.0252s/iter; left time: 469.5824s
Epoch: 28 cost time: 7.088067054748535
Epoch: 28, Steps: 258 | Train Loss: 0.4936895 Vali Loss: 0.2603605 Test Loss: 0.3524232
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.5046986
	speed: 0.1079s/iter; left time: 1993.6686s
	iters: 200, epoch: 29 | loss: 0.6076528
	speed: 0.0230s/iter; left time: 422.8208s
Epoch: 29 cost time: 6.897515535354614
Epoch: 29, Steps: 258 | Train Loss: 0.4939805 Vali Loss: 0.2603929 Test Loss: 0.3523958
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3782081
	speed: 0.1047s/iter; left time: 1907.1460s
	iters: 200, epoch: 30 | loss: 0.4231329
	speed: 0.0252s/iter; left time: 455.7484s
Epoch: 30 cost time: 7.143864870071411
Epoch: 30, Steps: 258 | Train Loss: 0.4938889 Vali Loss: 0.2602970 Test Loss: 0.3524176
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4403376
	speed: 0.1067s/iter; left time: 1917.0396s
	iters: 200, epoch: 31 | loss: 0.5573503
	speed: 0.0252s/iter; left time: 450.1275s
Epoch: 31 cost time: 7.059640169143677
Epoch: 31, Steps: 258 | Train Loss: 0.4940175 Vali Loss: 0.2604808 Test Loss: 0.3523581
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.5595318
	speed: 0.1068s/iter; left time: 1891.4401s
	iters: 200, epoch: 32 | loss: 0.4773192
	speed: 0.0249s/iter; left time: 438.1666s
Epoch: 32 cost time: 7.108175992965698
Epoch: 32, Steps: 258 | Train Loss: 0.4935404 Vali Loss: 0.2602182 Test Loss: 0.3523573
Validation loss decreased (0.260264 --> 0.260218).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3740398
	speed: 0.1047s/iter; left time: 1826.5901s
	iters: 200, epoch: 33 | loss: 0.4785166
	speed: 0.0242s/iter; left time: 419.1189s
Epoch: 33 cost time: 6.861680269241333
Epoch: 33, Steps: 258 | Train Loss: 0.4942076 Vali Loss: 0.2600757 Test Loss: 0.3524116
Validation loss decreased (0.260218 --> 0.260076).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4595171
	speed: 0.1053s/iter; left time: 1810.2357s
	iters: 200, epoch: 34 | loss: 0.4123271
	speed: 0.0245s/iter; left time: 418.2502s
Epoch: 34 cost time: 7.036604404449463
Epoch: 34, Steps: 258 | Train Loss: 0.4940596 Vali Loss: 0.2601800 Test Loss: 0.3523725
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.5748545
	speed: 0.1060s/iter; left time: 1794.7559s
	iters: 200, epoch: 35 | loss: 0.5357475
	speed: 0.0243s/iter; left time: 408.9074s
Epoch: 35 cost time: 7.019956350326538
Epoch: 35, Steps: 258 | Train Loss: 0.4939330 Vali Loss: 0.2600706 Test Loss: 0.3523405
Validation loss decreased (0.260076 --> 0.260071).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3201295
	speed: 0.1030s/iter; left time: 1716.5168s
	iters: 200, epoch: 36 | loss: 0.5159423
	speed: 0.0232s/iter; left time: 384.3595s
Epoch: 36 cost time: 6.9049718379974365
Epoch: 36, Steps: 258 | Train Loss: 0.4936102 Vali Loss: 0.2602230 Test Loss: 0.3522887
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4352058
	speed: 0.1055s/iter; left time: 1731.3841s
	iters: 200, epoch: 37 | loss: 0.5432580
	speed: 0.0255s/iter; left time: 416.3353s
Epoch: 37 cost time: 7.3268444538116455
Epoch: 37, Steps: 258 | Train Loss: 0.4936062 Vali Loss: 0.2603261 Test Loss: 0.3522681
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.5635512
	speed: 0.1048s/iter; left time: 1692.3211s
	iters: 200, epoch: 38 | loss: 0.4558061
	speed: 0.0242s/iter; left time: 388.0929s
Epoch: 38 cost time: 6.70494818687439
Epoch: 38, Steps: 258 | Train Loss: 0.4930989 Vali Loss: 0.2600257 Test Loss: 0.3522963
Validation loss decreased (0.260071 --> 0.260026).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.6977551
	speed: 0.1041s/iter; left time: 1655.3705s
	iters: 200, epoch: 39 | loss: 0.5442048
	speed: 0.0256s/iter; left time: 404.3507s
Epoch: 39 cost time: 7.084413051605225
Epoch: 39, Steps: 258 | Train Loss: 0.4938513 Vali Loss: 0.2602454 Test Loss: 0.3522733
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.5434160
	speed: 0.1091s/iter; left time: 1706.1984s
	iters: 200, epoch: 40 | loss: 0.4730041
	speed: 0.0253s/iter; left time: 393.1868s
Epoch: 40 cost time: 7.302781820297241
Epoch: 40, Steps: 258 | Train Loss: 0.4934715 Vali Loss: 0.2604163 Test Loss: 0.3522851
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.4434378
	speed: 0.1061s/iter; left time: 1632.2471s
	iters: 200, epoch: 41 | loss: 0.4449812
	speed: 0.0294s/iter; left time: 449.0246s
Epoch: 41 cost time: 7.355722665786743
Epoch: 41, Steps: 258 | Train Loss: 0.4934481 Vali Loss: 0.2602811 Test Loss: 0.3522516
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.5098190
	speed: 0.1037s/iter; left time: 1568.9562s
	iters: 200, epoch: 42 | loss: 0.3614201
	speed: 0.0224s/iter; left time: 336.2930s
Epoch: 42 cost time: 6.8590216636657715
Epoch: 42, Steps: 258 | Train Loss: 0.4930351 Vali Loss: 0.2603959 Test Loss: 0.3522348
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.4407046
	speed: 0.0973s/iter; left time: 1446.0776s
	iters: 200, epoch: 43 | loss: 0.3823975
	speed: 0.0266s/iter; left time: 392.8024s
Epoch: 43 cost time: 6.809478998184204
Epoch: 43, Steps: 258 | Train Loss: 0.4930979 Vali Loss: 0.2602868 Test Loss: 0.3522521
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.6508496
	speed: 0.0990s/iter; left time: 1445.4383s
	iters: 200, epoch: 44 | loss: 0.4790086
	speed: 0.0233s/iter; left time: 337.5963s
Epoch: 44 cost time: 6.712250471115112
Epoch: 44, Steps: 258 | Train Loss: 0.4934611 Vali Loss: 0.2600169 Test Loss: 0.3522158
Validation loss decreased (0.260026 --> 0.260017).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.4555516
	speed: 0.1012s/iter; left time: 1452.3560s
	iters: 200, epoch: 45 | loss: 0.4477634
	speed: 0.0229s/iter; left time: 325.8063s
Epoch: 45 cost time: 6.550604581832886
Epoch: 45, Steps: 258 | Train Loss: 0.4934812 Vali Loss: 0.2601738 Test Loss: 0.3522312
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.5764695
	speed: 0.0993s/iter; left time: 1399.4949s
	iters: 200, epoch: 46 | loss: 0.4459070
	speed: 0.0241s/iter; left time: 337.0545s
Epoch: 46 cost time: 6.615839958190918
Epoch: 46, Steps: 258 | Train Loss: 0.4932264 Vali Loss: 0.2603180 Test Loss: 0.3522527
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.4319683
	speed: 0.0979s/iter; left time: 1354.7477s
	iters: 200, epoch: 47 | loss: 0.5117310
	speed: 0.0264s/iter; left time: 362.0303s
Epoch: 47 cost time: 6.934619188308716
Epoch: 47, Steps: 258 | Train Loss: 0.4937549 Vali Loss: 0.2603090 Test Loss: 0.3522431
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.5601863
	speed: 0.1079s/iter; left time: 1464.8125s
	iters: 200, epoch: 48 | loss: 0.5770953
	speed: 0.0308s/iter; left time: 415.1411s
Epoch: 48 cost time: 7.577598810195923
Epoch: 48, Steps: 258 | Train Loss: 0.4934526 Vali Loss: 0.2600654 Test Loss: 0.3522403
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.4889574
	speed: 0.1078s/iter; left time: 1435.5729s
	iters: 200, epoch: 49 | loss: 0.4809211
	speed: 0.0245s/iter; left time: 323.3219s
Epoch: 49 cost time: 7.261331081390381
Epoch: 49, Steps: 258 | Train Loss: 0.4930553 Vali Loss: 0.2601337 Test Loss: 0.3522317
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.4738456
	speed: 0.1007s/iter; left time: 1314.5807s
	iters: 200, epoch: 50 | loss: 0.3123695
	speed: 0.0244s/iter; left time: 315.9856s
Epoch: 50 cost time: 6.922767162322998
Epoch: 50, Steps: 258 | Train Loss: 0.4938434 Vali Loss: 0.2600793 Test Loss: 0.3522466
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.5610011
	speed: 0.1010s/iter; left time: 1292.5486s
	iters: 200, epoch: 51 | loss: 0.4975432
	speed: 0.0244s/iter; left time: 310.1827s
Epoch: 51 cost time: 6.789985179901123
Epoch: 51, Steps: 258 | Train Loss: 0.4934182 Vali Loss: 0.2602022 Test Loss: 0.3522472
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.5847053
	speed: 0.1062s/iter; left time: 1331.7043s
	iters: 200, epoch: 52 | loss: 0.5836002
	speed: 0.0236s/iter; left time: 293.4058s
Epoch: 52 cost time: 7.324676036834717
Epoch: 52, Steps: 258 | Train Loss: 0.4932736 Vali Loss: 0.2601916 Test Loss: 0.3522481
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.3152598
	speed: 0.1004s/iter; left time: 1233.8891s
	iters: 200, epoch: 53 | loss: 0.5495333
	speed: 0.0219s/iter; left time: 267.1555s
Epoch: 53 cost time: 6.475518226623535
Epoch: 53, Steps: 258 | Train Loss: 0.4935379 Vali Loss: 0.2599533 Test Loss: 0.3522272
Validation loss decreased (0.260017 --> 0.259953).  Saving model ...
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.5092835
	speed: 0.0956s/iter; left time: 1149.3539s
	iters: 200, epoch: 54 | loss: 0.4320965
	speed: 0.0237s/iter; left time: 282.6814s
Epoch: 54 cost time: 6.699866056442261
Epoch: 54, Steps: 258 | Train Loss: 0.4935079 Vali Loss: 0.2601501 Test Loss: 0.3522249
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.4444645
	speed: 0.1038s/iter; left time: 1222.1411s
	iters: 200, epoch: 55 | loss: 0.4615391
	speed: 0.0248s/iter; left time: 289.4218s
Epoch: 55 cost time: 7.126955509185791
Epoch: 55, Steps: 258 | Train Loss: 0.4938237 Vali Loss: 0.2601952 Test Loss: 0.3522212
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.5237482
	speed: 0.1046s/iter; left time: 1203.7747s
	iters: 200, epoch: 56 | loss: 0.6230847
	speed: 0.0243s/iter; left time: 277.2748s
Epoch: 56 cost time: 7.1910552978515625
Epoch: 56, Steps: 258 | Train Loss: 0.4937978 Vali Loss: 0.2602607 Test Loss: 0.3522121
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.5712742
	speed: 0.3077s/iter; left time: 3462.9247s
	iters: 200, epoch: 57 | loss: 0.3925439
	speed: 0.0903s/iter; left time: 1006.5837s
Epoch: 57 cost time: 23.721081256866455
Epoch: 57, Steps: 258 | Train Loss: 0.4933610 Vali Loss: 0.2600342 Test Loss: 0.3522324
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.5957778
	speed: 0.3619s/iter; left time: 3978.6137s
	iters: 200, epoch: 58 | loss: 0.2983715
	speed: 0.0803s/iter; left time: 874.6869s
Epoch: 58 cost time: 22.87106728553772
Epoch: 58, Steps: 258 | Train Loss: 0.4936636 Vali Loss: 0.2600363 Test Loss: 0.3522205
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.3910734
	speed: 0.3423s/iter; left time: 3675.7039s
	iters: 200, epoch: 59 | loss: 0.3274269
	speed: 0.0817s/iter; left time: 868.6776s
Epoch: 59 cost time: 22.04427719116211
Epoch: 59, Steps: 258 | Train Loss: 0.4937809 Vali Loss: 0.2598317 Test Loss: 0.3522219
Validation loss decreased (0.259953 --> 0.259832).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.3432208
	speed: 0.3532s/iter; left time: 3700.8053s
	iters: 200, epoch: 60 | loss: 0.4843218
	speed: 0.0765s/iter; left time: 794.2013s
Epoch: 60 cost time: 20.57710027694702
Epoch: 60, Steps: 258 | Train Loss: 0.4938367 Vali Loss: 0.2602859 Test Loss: 0.3522117
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.5365561
	speed: 0.3191s/iter; left time: 3261.0967s
	iters: 200, epoch: 61 | loss: 0.3317057
	speed: 0.0743s/iter; left time: 751.8210s
Epoch: 61 cost time: 21.202306270599365
Epoch: 61, Steps: 258 | Train Loss: 0.4934387 Vali Loss: 0.2602480 Test Loss: 0.3522080
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.4528150
	speed: 0.3187s/iter; left time: 3175.5384s
	iters: 200, epoch: 62 | loss: 0.4934101
	speed: 0.0772s/iter; left time: 761.5691s
Epoch: 62 cost time: 19.959513187408447
Epoch: 62, Steps: 258 | Train Loss: 0.4936500 Vali Loss: 0.2599380 Test Loss: 0.3522150
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.3718543
	speed: 0.3011s/iter; left time: 2922.4870s
	iters: 200, epoch: 63 | loss: 0.4378156
	speed: 0.0833s/iter; left time: 800.2385s
Epoch: 63 cost time: 21.50295925140381
Epoch: 63, Steps: 258 | Train Loss: 0.4934528 Vali Loss: 0.2601867 Test Loss: 0.3522125
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.4428023
	speed: 0.3106s/iter; left time: 2934.6280s
	iters: 200, epoch: 64 | loss: 0.5453742
	speed: 0.0761s/iter; left time: 711.4321s
Epoch: 64 cost time: 19.663312196731567
Epoch: 64, Steps: 258 | Train Loss: 0.4937798 Vali Loss: 0.2601113 Test Loss: 0.3522078
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.4914241
	speed: 0.2918s/iter; left time: 2681.5896s
	iters: 200, epoch: 65 | loss: 0.4767530
	speed: 0.0716s/iter; left time: 651.0785s
Epoch: 65 cost time: 20.449706077575684
Epoch: 65, Steps: 258 | Train Loss: 0.4932649 Vali Loss: 0.2598687 Test Loss: 0.3522064
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.4561132
	speed: 0.2980s/iter; left time: 2661.0927s
	iters: 200, epoch: 66 | loss: 0.4494072
	speed: 0.0749s/iter; left time: 661.3392s
Epoch: 66 cost time: 19.58271050453186
Epoch: 66, Steps: 258 | Train Loss: 0.4937050 Vali Loss: 0.2601673 Test Loss: 0.3522048
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.4527030
	speed: 0.3028s/iter; left time: 2626.4888s
	iters: 200, epoch: 67 | loss: 0.5504348
	speed: 0.0743s/iter; left time: 637.1859s
Epoch: 67 cost time: 21.510477542877197
Epoch: 67, Steps: 258 | Train Loss: 0.4931530 Vali Loss: 0.2602827 Test Loss: 0.3522034
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.4512123
	speed: 0.3136s/iter; left time: 2638.7516s
	iters: 200, epoch: 68 | loss: 0.6634870
	speed: 0.0727s/iter; left time: 604.1879s
Epoch: 68 cost time: 20.822240352630615
Epoch: 68, Steps: 258 | Train Loss: 0.4930306 Vali Loss: 0.2598776 Test Loss: 0.3522014
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.6840258
	speed: 0.3005s/iter; left time: 2450.8320s
	iters: 200, epoch: 69 | loss: 0.4452418
	speed: 0.0829s/iter; left time: 668.1300s
Epoch: 69 cost time: 20.701216220855713
Epoch: 69, Steps: 258 | Train Loss: 0.4935836 Vali Loss: 0.2602057 Test Loss: 0.3521995
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.6036054
	speed: 0.2907s/iter; left time: 2295.9199s
	iters: 200, epoch: 70 | loss: 0.4743387
	speed: 0.0790s/iter; left time: 616.4809s
Epoch: 70 cost time: 19.874152183532715
Epoch: 70, Steps: 258 | Train Loss: 0.4930987 Vali Loss: 0.2600901 Test Loss: 0.3522016
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.6229094
	speed: 0.2996s/iter; left time: 2289.0511s
	iters: 200, epoch: 71 | loss: 0.3740807
	speed: 0.0717s/iter; left time: 540.7213s
Epoch: 71 cost time: 18.592002391815186
Epoch: 71, Steps: 258 | Train Loss: 0.4932492 Vali Loss: 0.2597830 Test Loss: 0.3521990
Validation loss decreased (0.259832 --> 0.259783).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.3815875
	speed: 0.3024s/iter; left time: 2232.7523s
	iters: 200, epoch: 72 | loss: 0.3820493
	speed: 0.0639s/iter; left time: 465.6643s
Epoch: 72 cost time: 19.424015045166016
Epoch: 72, Steps: 258 | Train Loss: 0.4937311 Vali Loss: 0.2601734 Test Loss: 0.3521940
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.3560670
	speed: 0.3222s/iter; left time: 2295.6762s
	iters: 200, epoch: 73 | loss: 0.4958435
	speed: 0.0804s/iter; left time: 565.0925s
Epoch: 73 cost time: 19.943605184555054
Epoch: 73, Steps: 258 | Train Loss: 0.4931843 Vali Loss: 0.2600372 Test Loss: 0.3521938
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.3825782
	speed: 0.3137s/iter; left time: 2154.1096s
	iters: 200, epoch: 74 | loss: 0.5887608
	speed: 0.0743s/iter; left time: 502.6828s
Epoch: 74 cost time: 19.929709911346436
Epoch: 74, Steps: 258 | Train Loss: 0.4939679 Vali Loss: 0.2599604 Test Loss: 0.3521971
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.6249128
	speed: 0.2844s/iter; left time: 1879.8850s
	iters: 200, epoch: 75 | loss: 0.4642333
	speed: 0.0655s/iter; left time: 426.5662s
Epoch: 75 cost time: 18.027655124664307
Epoch: 75, Steps: 258 | Train Loss: 0.4936494 Vali Loss: 0.2602274 Test Loss: 0.3521939
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.5226247
	speed: 0.3107s/iter; left time: 1973.3874s
	iters: 200, epoch: 76 | loss: 0.4457387
	speed: 0.0695s/iter; left time: 434.2459s
Epoch: 76 cost time: 19.296676874160767
Epoch: 76, Steps: 258 | Train Loss: 0.4934252 Vali Loss: 0.2599435 Test Loss: 0.3521892
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.5543043
	speed: 0.2997s/iter; left time: 1826.3110s
	iters: 200, epoch: 77 | loss: 0.4615901
	speed: 0.0681s/iter; left time: 407.9495s
Epoch: 77 cost time: 18.163062572479248
Epoch: 77, Steps: 258 | Train Loss: 0.4937329 Vali Loss: 0.2602247 Test Loss: 0.3521930
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.7924381
	speed: 0.2980s/iter; left time: 1738.7546s
	iters: 200, epoch: 78 | loss: 0.4858924
	speed: 0.0758s/iter; left time: 434.5203s
Epoch: 78 cost time: 19.70927619934082
Epoch: 78, Steps: 258 | Train Loss: 0.4938487 Vali Loss: 0.2603745 Test Loss: 0.3521957
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.4501761
	speed: 0.2883s/iter; left time: 1607.8362s
	iters: 200, epoch: 79 | loss: 0.5863506
	speed: 0.0645s/iter; left time: 353.1415s
Epoch: 79 cost time: 18.12214469909668
Epoch: 79, Steps: 258 | Train Loss: 0.4934904 Vali Loss: 0.2602524 Test Loss: 0.3521947
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.3819337
	speed: 0.3001s/iter; left time: 1596.0729s
	iters: 200, epoch: 80 | loss: 0.5596362
	speed: 0.0709s/iter; left time: 370.1414s
Epoch: 80 cost time: 20.211943864822388
Epoch: 80, Steps: 258 | Train Loss: 0.4932719 Vali Loss: 0.2600833 Test Loss: 0.3521942
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.3993742
	speed: 0.2896s/iter; left time: 1465.9161s
	iters: 200, epoch: 81 | loss: 0.5821806
	speed: 0.0670s/iter; left time: 332.3104s
Epoch: 81 cost time: 18.566351652145386
Epoch: 81, Steps: 258 | Train Loss: 0.4931304 Vali Loss: 0.2599714 Test Loss: 0.3521959
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.4595512
	speed: 0.2860s/iter; left time: 1373.8180s
	iters: 200, epoch: 82 | loss: 0.4558775
	speed: 0.0654s/iter; left time: 307.7247s
Epoch: 82 cost time: 18.420962810516357
Epoch: 82, Steps: 258 | Train Loss: 0.4932046 Vali Loss: 0.2600773 Test Loss: 0.3521943
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.6459709
	speed: 0.2917s/iter; left time: 1325.5621s
	iters: 200, epoch: 83 | loss: 0.4409640
	speed: 0.0651s/iter; left time: 289.4491s
Epoch: 83 cost time: 17.55234122276306
Epoch: 83, Steps: 258 | Train Loss: 0.4929404 Vali Loss: 0.2599939 Test Loss: 0.3521943
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.5183834
	speed: 0.2780s/iter; left time: 1191.9705s
	iters: 200, epoch: 84 | loss: 0.5003499
	speed: 0.0742s/iter; left time: 310.7565s
Epoch: 84 cost time: 18.78359842300415
Epoch: 84, Steps: 258 | Train Loss: 0.4936284 Vali Loss: 0.2600347 Test Loss: 0.3521940
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.4264606
	speed: 0.2667s/iter; left time: 1074.4749s
	iters: 200, epoch: 85 | loss: 0.4659636
	speed: 0.0664s/iter; left time: 261.0672s
Epoch: 85 cost time: 18.605114936828613
Epoch: 85, Steps: 258 | Train Loss: 0.4937063 Vali Loss: 0.2598313 Test Loss: 0.3521937
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.3747597
	speed: 0.2852s/iter; left time: 1075.4391s
	iters: 200, epoch: 86 | loss: 0.4343259
	speed: 0.0713s/iter; left time: 261.8000s
Epoch: 86 cost time: 18.594656705856323
Epoch: 86, Steps: 258 | Train Loss: 0.4931917 Vali Loss: 0.2601584 Test Loss: 0.3521943
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.5629436
	speed: 0.2876s/iter; left time: 1010.3591s
	iters: 200, epoch: 87 | loss: 0.3856547
	speed: 0.0626s/iter; left time: 213.8015s
Epoch: 87 cost time: 17.957009315490723
Epoch: 87, Steps: 258 | Train Loss: 0.4934727 Vali Loss: 0.2600595 Test Loss: 0.3521915
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.5882420
	speed: 0.2619s/iter; left time: 852.4005s
	iters: 200, epoch: 88 | loss: 0.5125093
	speed: 0.0712s/iter; left time: 224.5503s
Epoch: 88 cost time: 18.75225591659546
Epoch: 88, Steps: 258 | Train Loss: 0.4931681 Vali Loss: 0.2603358 Test Loss: 0.3521898
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.4029568
	speed: 0.2717s/iter; left time: 814.3742s
	iters: 200, epoch: 89 | loss: 0.5114292
	speed: 0.0728s/iter; left time: 210.7797s
Epoch: 89 cost time: 18.51392936706543
Epoch: 89, Steps: 258 | Train Loss: 0.4937134 Vali Loss: 0.2599951 Test Loss: 0.3521879
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.5391282
	speed: 0.2766s/iter; left time: 757.5362s
	iters: 200, epoch: 90 | loss: 0.4648037
	speed: 0.0707s/iter; left time: 186.6128s
Epoch: 90 cost time: 18.151309728622437
Epoch: 90, Steps: 258 | Train Loss: 0.4930312 Vali Loss: 0.2601462 Test Loss: 0.3521886
EarlyStopping counter: 19 out of 20
Updating learning rate to 5.204402478767869e-06
	iters: 100, epoch: 91 | loss: 0.5588359
	speed: 0.2798s/iter; left time: 694.2470s
	iters: 200, epoch: 91 | loss: 0.4418741
	speed: 0.0614s/iter; left time: 146.1388s
Epoch: 91 cost time: 17.753257751464844
Epoch: 91, Steps: 258 | Train Loss: 0.4930639 Vali Loss: 0.2600256 Test Loss: 0.3521898
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_720_720_FITS_ETTm2_ftM_sl720_ll48_pl720_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.3488311767578125, mae:0.3778514266014099, rse:0.474735826253891, corr:[0.5440922  0.54384255 0.53807133 0.5355419  0.53644645 0.5379561
 0.53779316 0.53634983 0.5351352  0.5350234  0.53580767 0.5365036
 0.53640664 0.5356446  0.5349356  0.5346523  0.5347728  0.5348525
 0.53440726 0.5334431  0.5324192  0.5316973  0.5314323  0.531439
 0.53130454 0.5308419  0.5301749  0.5295662  0.52916676 0.5289569
 0.5287211  0.52834934 0.5278005  0.5271264  0.52650625 0.526061
 0.5256949  0.52526325 0.5246248  0.5238514  0.52311593 0.5225355
 0.52217865 0.5219216  0.5215716  0.52096015 0.5201254  0.5192315
 0.5183886  0.51765895 0.5170461  0.5164925  0.51585686 0.51510197
 0.5143175  0.51365316 0.51318276 0.5128712  0.51262856 0.5123438
 0.5120167  0.51172817 0.5115394  0.51142097 0.5112915  0.5111206
 0.510799   0.51042825 0.5100954  0.5098435  0.50963724 0.5093917
 0.50904906 0.508612   0.5080979  0.5075794  0.5070892  0.5065832
 0.5060312  0.5054016  0.5046596  0.5039199  0.50328684 0.50277746
 0.5023366  0.5018799  0.501323   0.50075036 0.50021684 0.49978846
 0.4994605  0.4990972  0.4985258  0.49767435 0.49653494 0.49518368
 0.4937574  0.49239948 0.49107388 0.489769   0.48852342 0.48737642
 0.4863515  0.48538664 0.48436797 0.4832354  0.48204523 0.48094368
 0.47999355 0.47922474 0.47855285 0.47780478 0.47692055 0.47587004
 0.4747508  0.47376433 0.47302246 0.47241026 0.47177368 0.47093776
 0.46997508 0.46899664 0.46819878 0.46759185 0.46703276 0.46632046
 0.46538606 0.46426764 0.4631283  0.46213976 0.4613851  0.46075907
 0.46011883 0.45935974 0.45852143 0.45772952 0.45709178 0.45664623
 0.4562475  0.45571476 0.4549479  0.45403966 0.45319727 0.45252162
 0.45201498 0.45147884 0.45083922 0.4500077  0.44908038 0.44821766
 0.44759533 0.44720733 0.44679043 0.4461451  0.4452736  0.44435808
 0.44361755 0.44315973 0.44288513 0.44265535 0.44224498 0.44163486
 0.44093055 0.44035572 0.44002157 0.43985638 0.4396521  0.4392863
 0.4387859  0.43829185 0.4378623  0.43755117 0.4372461  0.43682188
 0.4362078  0.43548223 0.4347867  0.4342293  0.43379116 0.4334081
 0.4328958  0.43220356 0.4314539  0.43078592 0.43028343 0.4299065
 0.42955783 0.4290467  0.42829043 0.42727545 0.4260946  0.42481267
 0.42348948 0.42225865 0.4209801  0.41963962 0.41835517 0.41716468
 0.4160736  0.41497028 0.41376168 0.41242898 0.41106477 0.40981326
 0.408751   0.40780792 0.4068229  0.40569857 0.4045575  0.40359935
 0.40280062 0.4020985  0.4013682  0.4004824  0.39941746 0.39818278
 0.3969209  0.39573082 0.39473316 0.3938106  0.39278615 0.3915998
 0.3903376  0.38919148 0.38833922 0.3876287  0.38687983 0.38599998
 0.38491672 0.3837985  0.38282165 0.38208583 0.38152742 0.38101238
 0.38038507 0.37968752 0.3790383  0.37856928 0.37833253 0.37816688
 0.37787792 0.3773017  0.3765384  0.3759538  0.3756538  0.37567636
 0.37581447 0.3758155  0.37550792 0.37495884 0.3745102  0.37436566
 0.3745069  0.37476096 0.37478167 0.37445605 0.3738515  0.3732733
 0.37292162 0.37280926 0.37273324 0.37251008 0.37203616 0.3714783
 0.37102404 0.37073943 0.37062684 0.37053093 0.3702723  0.36978686
 0.3692669  0.3688852  0.36865845 0.36854082 0.3683491  0.367961
 0.36745977 0.36689663 0.3663674  0.36600098 0.36569858 0.36541766
 0.3650838  0.3647513  0.36447635 0.36420897 0.36381245 0.3630183
 0.36182955 0.36051974 0.3592953  0.3583278  0.35769558 0.35725138
 0.35687885 0.35636622 0.35562015 0.3547498  0.3539883  0.353399
 0.3530168  0.35262713 0.35216898 0.35151726 0.35083172 0.35025132
 0.349885   0.34959292 0.34925863 0.34881976 0.3483163  0.34796944
 0.3477637  0.34770983 0.34762672 0.34735385 0.34691    0.34644535
 0.3460606  0.34586966 0.34584358 0.34581405 0.3456357  0.34534508
 0.34506077 0.344975   0.34513012 0.3453339  0.34546408 0.3453699
 0.34516662 0.3449482  0.3448688  0.34499484 0.34514362 0.34521002
 0.3450552  0.3446315  0.3441894  0.34399843 0.34407592 0.3442217
 0.3442536  0.3440758  0.3437428  0.34342226 0.34328464 0.34339094
 0.3435743  0.34365302 0.34350166 0.34316143 0.34282914 0.34263813
 0.3425851  0.34255683 0.34233767 0.341971   0.3414725  0.34108943
 0.3409356  0.34095043 0.34093818 0.3407366  0.3403146  0.33990836
 0.33965546 0.3396781  0.33982962 0.33990657 0.33979678 0.33949485
 0.33922726 0.33923763 0.3395459  0.33994678 0.34015676 0.34007883
 0.33982605 0.33959097 0.33948448 0.33942252 0.3393142  0.33887318
 0.33809683 0.33713248 0.3362313  0.33552524 0.33496615 0.3344967
 0.33390948 0.33313835 0.33226097 0.33146727 0.33090168 0.33052614
 0.3302154  0.32986063 0.32929718 0.32858032 0.32793683 0.3273981
 0.32694283 0.32646236 0.32591915 0.3253667  0.3248193  0.32442695
 0.32419914 0.32413223 0.32408312 0.32389286 0.3235845  0.3232067
 0.3229421  0.32287502 0.322911   0.3229336  0.3228229  0.32261023
 0.32244158 0.32241023 0.3224952  0.32264075 0.3227732  0.32284707
 0.32290626 0.3229774  0.3231313  0.3233363  0.3235267  0.3236214
 0.32357147 0.32334018 0.32307053 0.32290313 0.32287714 0.32284915
 0.3226214  0.32227027 0.32182187 0.32134983 0.32099035 0.32082692
 0.320692   0.32051358 0.32021144 0.3197859  0.31937432 0.31903046
 0.31879285 0.31859237 0.31837872 0.31806138 0.31770924 0.3174369
 0.31725195 0.31709448 0.31684968 0.31648496 0.3161328  0.3158014
 0.31557712 0.31544355 0.31531093 0.3150801  0.3147102  0.3142693
 0.31388345 0.3135903  0.31332    0.312968   0.3125361  0.31201705
 0.31150267 0.3109936  0.31051117 0.30990204 0.30906925 0.30795115
 0.3066137  0.3053168  0.30415583 0.3031788  0.30234143 0.30152264
 0.30060607 0.29965895 0.2987442  0.2980153  0.29742903 0.29686934
 0.2962363  0.2955686  0.29488322 0.29415044 0.293422   0.29269934
 0.2919867  0.29120287 0.29035968 0.289596   0.28892502 0.2884314
 0.28797004 0.28746462 0.28693458 0.28640765 0.28600588 0.2857022
 0.2854354  0.28511912 0.28468022 0.2841507  0.2836517  0.28327253
 0.28300035 0.2827319  0.2825238  0.2822642  0.2819235  0.28158084
 0.2813116  0.28118262 0.28111252 0.2810262  0.2808978  0.28069645
 0.28042755 0.28018144 0.2799877  0.2798435  0.27971956 0.2795404
 0.27926657 0.2789684  0.27882242 0.2788265  0.27889475 0.27890915
 0.27878648 0.27856174 0.2782857  0.27807724 0.2779204  0.27771246
 0.27740273 0.27705368 0.2767326  0.27651036 0.27634576 0.2762343
 0.27605465 0.27579647 0.27551186 0.27530435 0.2751126  0.27501276
 0.27491853 0.2748041  0.27456418 0.2742122  0.2738883  0.27371085
 0.27370158 0.27371368 0.27361277 0.2733065  0.27287838 0.27250853
 0.27230787 0.27223852 0.27205968 0.27156898 0.27066168 0.2692992
 0.26768434 0.26626518 0.2651799  0.26436335 0.26361755 0.26283634
 0.26201308 0.26118222 0.26038054 0.2595795  0.25872073 0.25785205
 0.25700378 0.25621405 0.255594   0.25508407 0.25458002 0.25404623
 0.25345418 0.25282082 0.25230896 0.25191113 0.25166702 0.25151438
 0.25134242 0.25116926 0.2509486  0.25068447 0.2504895  0.25035307
 0.2501136  0.24975869 0.24942026 0.24913496 0.2490565  0.24917753
 0.24944033 0.24950536 0.24932326 0.2490479  0.24884121 0.24882607
 0.24904205 0.24946685 0.2498805  0.25018242 0.25038648 0.25063583
 0.25098097 0.2513677  0.251672   0.25183764 0.2517907  0.2515677
 0.2512684  0.25109968 0.25117722 0.25121492 0.25125286 0.25115284
 0.25095895 0.2508308  0.25079188 0.25094804 0.25098118 0.2507462
 0.2501922  0.24963263 0.2492276  0.2489982  0.2490748  0.24908748
 0.24893843 0.24854505 0.24808547 0.24776845 0.247792   0.24790528
 0.24804129 0.24797612 0.24763016 0.24733306 0.2473086  0.24751195
 0.24773325 0.24791399 0.24783929 0.24759892 0.24753675 0.24779028
 0.24826288 0.24877553 0.24900594 0.24864027 0.24768573 0.24646343
 0.24528798 0.24430415 0.24343023 0.24249834 0.24156404 0.24067518
 0.23992684 0.2393522  0.23913877 0.23895173 0.23863558 0.23807886
 0.23740366 0.23682237 0.23642908 0.23611249 0.23581895 0.2352947
 0.23459773 0.23386917 0.23320825 0.23285723 0.23256902 0.23209497
 0.23142518 0.2306634  0.23014447 0.22982714 0.22956216 0.22903807
 0.22827178 0.22720666 0.22628908 0.22588713 0.2258968  0.22585832
 0.22521321 0.22403911 0.22287092 0.22253679 0.222837   0.22307895
 0.22232223 0.22055165 0.21917279 0.21983045 0.22172025 0.21999142]
