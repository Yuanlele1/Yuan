Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=38, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_180_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_180_336_FITS_ETTm2_ftM_sl180_ll48_pl336_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34045
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=38, out_features=108, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3677184.0
params:  4212.0
Trainable parameters:  4212
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3180746
	speed: 0.0282s/iter; left time: 744.9866s
	iters: 200, epoch: 1 | loss: 0.3286601
	speed: 0.0182s/iter; left time: 479.7311s
Epoch: 1 cost time: 5.307990550994873
Epoch: 1, Steps: 265 | Train Loss: 0.3940421 Vali Loss: 0.2406615 Test Loss: 0.3276330
Validation loss decreased (inf --> 0.240662).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3883599
	speed: 0.0571s/iter; left time: 1492.9016s
	iters: 200, epoch: 2 | loss: 0.2755789
	speed: 0.0156s/iter; left time: 406.8856s
Epoch: 2 cost time: 4.228469610214233
Epoch: 2, Steps: 265 | Train Loss: 0.3100233 Vali Loss: 0.2237141 Test Loss: 0.3065715
Validation loss decreased (0.240662 --> 0.223714).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2337133
	speed: 0.0559s/iter; left time: 1445.2720s
	iters: 200, epoch: 3 | loss: 0.4277984
	speed: 0.0145s/iter; left time: 372.6675s
Epoch: 3 cost time: 3.9592742919921875
Epoch: 3, Steps: 265 | Train Loss: 0.2923324 Vali Loss: 0.2177990 Test Loss: 0.2989004
Validation loss decreased (0.223714 --> 0.217799).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2448077
	speed: 0.0570s/iter; left time: 1460.7656s
	iters: 200, epoch: 4 | loss: 0.2963360
	speed: 0.0146s/iter; left time: 371.3100s
Epoch: 4 cost time: 3.908374309539795
Epoch: 4, Steps: 265 | Train Loss: 0.2854503 Vali Loss: 0.2142284 Test Loss: 0.2945219
Validation loss decreased (0.217799 --> 0.214228).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2769969
	speed: 0.0599s/iter; left time: 1519.1179s
	iters: 200, epoch: 5 | loss: 0.1878317
	speed: 0.0132s/iter; left time: 331.9290s
Epoch: 5 cost time: 3.8979411125183105
Epoch: 5, Steps: 265 | Train Loss: 0.2823202 Vali Loss: 0.2120147 Test Loss: 0.2918936
Validation loss decreased (0.214228 --> 0.212015).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3221290
	speed: 0.0659s/iter; left time: 1652.1536s
	iters: 200, epoch: 6 | loss: 0.3285903
	speed: 0.0122s/iter; left time: 303.8373s
Epoch: 6 cost time: 4.657325744628906
Epoch: 6, Steps: 265 | Train Loss: 0.2801507 Vali Loss: 0.2107409 Test Loss: 0.2902464
Validation loss decreased (0.212015 --> 0.210741).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2637537
	speed: 0.0639s/iter; left time: 1585.9322s
	iters: 200, epoch: 7 | loss: 0.4011273
	speed: 0.0184s/iter; left time: 455.9081s
Epoch: 7 cost time: 7.432248830795288
Epoch: 7, Steps: 265 | Train Loss: 0.2789315 Vali Loss: 0.2098667 Test Loss: 0.2890718
Validation loss decreased (0.210741 --> 0.209867).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3248271
	speed: 0.1205s/iter; left time: 2958.5864s
	iters: 200, epoch: 8 | loss: 0.4040304
	speed: 0.0178s/iter; left time: 435.8339s
Epoch: 8 cost time: 5.834771394729614
Epoch: 8, Steps: 265 | Train Loss: 0.2780890 Vali Loss: 0.2092445 Test Loss: 0.2882302
Validation loss decreased (0.209867 --> 0.209245).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1998245
	speed: 0.0835s/iter; left time: 2027.4977s
	iters: 200, epoch: 9 | loss: 0.2777322
	speed: 0.0258s/iter; left time: 624.5870s
Epoch: 9 cost time: 6.503856420516968
Epoch: 9, Steps: 265 | Train Loss: 0.2771094 Vali Loss: 0.2088189 Test Loss: 0.2878546
Validation loss decreased (0.209245 --> 0.208819).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2212738
	speed: 0.1488s/iter; left time: 3574.4175s
	iters: 200, epoch: 10 | loss: 0.3058807
	speed: 0.0725s/iter; left time: 1734.6151s
Epoch: 10 cost time: 13.543787240982056
Epoch: 10, Steps: 265 | Train Loss: 0.2769315 Vali Loss: 0.2087998 Test Loss: 0.2874771
Validation loss decreased (0.208819 --> 0.208800).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3211929
	speed: 0.1999s/iter; left time: 4748.0426s
	iters: 200, epoch: 11 | loss: 0.1741993
	speed: 0.0852s/iter; left time: 2015.2240s
Epoch: 11 cost time: 19.008574962615967
Epoch: 11, Steps: 265 | Train Loss: 0.2766953 Vali Loss: 0.2084247 Test Loss: 0.2871692
Validation loss decreased (0.208800 --> 0.208425).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4572330
	speed: 0.1931s/iter; left time: 4536.0373s
	iters: 200, epoch: 12 | loss: 0.3082393
	speed: 0.0343s/iter; left time: 801.6020s
Epoch: 12 cost time: 8.84803819656372
Epoch: 12, Steps: 265 | Train Loss: 0.2757929 Vali Loss: 0.2082875 Test Loss: 0.2869011
Validation loss decreased (0.208425 --> 0.208287).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2470406
	speed: 0.1408s/iter; left time: 3269.0803s
	iters: 200, epoch: 13 | loss: 0.4194347
	speed: 0.0193s/iter; left time: 445.7610s
Epoch: 13 cost time: 7.126383066177368
Epoch: 13, Steps: 265 | Train Loss: 0.2762831 Vali Loss: 0.2081547 Test Loss: 0.2867784
Validation loss decreased (0.208287 --> 0.208155).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2406690
	speed: 0.1666s/iter; left time: 3823.3254s
	iters: 200, epoch: 14 | loss: 0.3533678
	speed: 0.0447s/iter; left time: 1022.1122s
Epoch: 14 cost time: 11.773115158081055
Epoch: 14, Steps: 265 | Train Loss: 0.2757957 Vali Loss: 0.2079973 Test Loss: 0.2865732
Validation loss decreased (0.208155 --> 0.207997).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3077202
	speed: 0.1964s/iter; left time: 4457.1201s
	iters: 200, epoch: 15 | loss: 0.2050148
	speed: 0.0367s/iter; left time: 829.3609s
Epoch: 15 cost time: 12.47329068183899
Epoch: 15, Steps: 265 | Train Loss: 0.2758145 Vali Loss: 0.2079233 Test Loss: 0.2864915
Validation loss decreased (0.207997 --> 0.207923).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2609503
	speed: 0.1773s/iter; left time: 3976.6448s
	iters: 200, epoch: 16 | loss: 0.2715373
	speed: 0.0323s/iter; left time: 721.3008s
Epoch: 16 cost time: 8.371701717376709
Epoch: 16, Steps: 265 | Train Loss: 0.2758079 Vali Loss: 0.2079373 Test Loss: 0.2863946
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1968909
	speed: 0.1228s/iter; left time: 2720.6026s
	iters: 200, epoch: 17 | loss: 0.2300733
	speed: 0.0233s/iter; left time: 513.0921s
Epoch: 17 cost time: 7.419215202331543
Epoch: 17, Steps: 265 | Train Loss: 0.2758614 Vali Loss: 0.2080304 Test Loss: 0.2863033
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2289786
	speed: 0.1643s/iter; left time: 3596.5733s
	iters: 200, epoch: 18 | loss: 0.2050747
	speed: 0.0482s/iter; left time: 1050.9302s
Epoch: 18 cost time: 11.86822772026062
Epoch: 18, Steps: 265 | Train Loss: 0.2756485 Vali Loss: 0.2079334 Test Loss: 0.2861679
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1954521
	speed: 0.1834s/iter; left time: 3967.5738s
	iters: 200, epoch: 19 | loss: 0.2546928
	speed: 0.0345s/iter; left time: 743.3642s
Epoch: 19 cost time: 12.543519496917725
Epoch: 19, Steps: 265 | Train Loss: 0.2755326 Vali Loss: 0.2078101 Test Loss: 0.2861209
Validation loss decreased (0.207923 --> 0.207810).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3437472
	speed: 0.1726s/iter; left time: 3688.1682s
	iters: 200, epoch: 20 | loss: 0.2406173
	speed: 0.0392s/iter; left time: 833.9821s
Epoch: 20 cost time: 10.15193247795105
Epoch: 20, Steps: 265 | Train Loss: 0.2753145 Vali Loss: 0.2077408 Test Loss: 0.2860656
Validation loss decreased (0.207810 --> 0.207741).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3476860
	speed: 0.1250s/iter; left time: 2638.3604s
	iters: 200, epoch: 21 | loss: 0.3248657
	speed: 0.0292s/iter; left time: 613.1308s
Epoch: 21 cost time: 7.061824560165405
Epoch: 21, Steps: 265 | Train Loss: 0.2752158 Vali Loss: 0.2078215 Test Loss: 0.2859985
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1768298
	speed: 0.1765s/iter; left time: 3677.0586s
	iters: 200, epoch: 22 | loss: 0.2775998
	speed: 0.0596s/iter; left time: 1235.4402s
Epoch: 22 cost time: 14.084076881408691
Epoch: 22, Steps: 265 | Train Loss: 0.2753204 Vali Loss: 0.2079088 Test Loss: 0.2859953
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2662672
	speed: 0.2228s/iter; left time: 4583.4199s
	iters: 200, epoch: 23 | loss: 0.2996594
	speed: 0.0565s/iter; left time: 1156.9490s
Epoch: 23 cost time: 18.342899560928345
Epoch: 23, Steps: 265 | Train Loss: 0.2757927 Vali Loss: 0.2078168 Test Loss: 0.2859341
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2557986
	speed: 0.2351s/iter; left time: 4774.4809s
	iters: 200, epoch: 24 | loss: 0.3256637
	speed: 0.0211s/iter; left time: 426.8998s
Epoch: 24 cost time: 8.022329092025757
Epoch: 24, Steps: 265 | Train Loss: 0.2757761 Vali Loss: 0.2078190 Test Loss: 0.2859107
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2453530
	speed: 0.1351s/iter; left time: 2707.6570s
	iters: 200, epoch: 25 | loss: 0.2590732
	speed: 0.0283s/iter; left time: 564.1196s
Epoch: 25 cost time: 9.125990390777588
Epoch: 25, Steps: 265 | Train Loss: 0.2754884 Vali Loss: 0.2078055 Test Loss: 0.2858907
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2520825
	speed: 0.1791s/iter; left time: 3542.2539s
	iters: 200, epoch: 26 | loss: 0.2254366
	speed: 0.0393s/iter; left time: 772.7875s
Epoch: 26 cost time: 10.995426177978516
Epoch: 26, Steps: 265 | Train Loss: 0.2753165 Vali Loss: 0.2077205 Test Loss: 0.2858670
Validation loss decreased (0.207741 --> 0.207721).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2769292
	speed: 0.2030s/iter; left time: 3960.3308s
	iters: 200, epoch: 27 | loss: 0.1679920
	speed: 0.0273s/iter; left time: 530.3959s
Epoch: 27 cost time: 8.590133666992188
Epoch: 27, Steps: 265 | Train Loss: 0.2756663 Vali Loss: 0.2076162 Test Loss: 0.2858441
Validation loss decreased (0.207721 --> 0.207616).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3031931
	speed: 0.1369s/iter; left time: 2634.8710s
	iters: 200, epoch: 28 | loss: 0.3207944
	speed: 0.0411s/iter; left time: 786.3310s
Epoch: 28 cost time: 8.4305579662323
Epoch: 28, Steps: 265 | Train Loss: 0.2754888 Vali Loss: 0.2076479 Test Loss: 0.2858114
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2147498
	speed: 0.1235s/iter; left time: 2344.7487s
	iters: 200, epoch: 29 | loss: 0.4124289
	speed: 0.0371s/iter; left time: 701.2482s
Epoch: 29 cost time: 10.101394891738892
Epoch: 29, Steps: 265 | Train Loss: 0.2755036 Vali Loss: 0.2078438 Test Loss: 0.2858030
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2524588
	speed: 0.1841s/iter; left time: 3446.2128s
	iters: 200, epoch: 30 | loss: 0.3865752
	speed: 0.0283s/iter; left time: 527.6235s
Epoch: 30 cost time: 9.68197774887085
Epoch: 30, Steps: 265 | Train Loss: 0.2753399 Vali Loss: 0.2076483 Test Loss: 0.2857918
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3392010
	speed: 0.2136s/iter; left time: 3941.5737s
	iters: 200, epoch: 31 | loss: 0.2518264
	speed: 0.0598s/iter; left time: 1097.7168s
Epoch: 31 cost time: 14.49833369255066
Epoch: 31, Steps: 265 | Train Loss: 0.2751785 Vali Loss: 0.2077770 Test Loss: 0.2857840
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3021766
	speed: 0.1820s/iter; left time: 3309.8962s
	iters: 200, epoch: 32 | loss: 0.1931063
	speed: 0.0241s/iter; left time: 436.3384s
Epoch: 32 cost time: 6.711676120758057
Epoch: 32, Steps: 265 | Train Loss: 0.2755622 Vali Loss: 0.2077250 Test Loss: 0.2857654
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3767836
	speed: 0.1275s/iter; left time: 2285.2248s
	iters: 200, epoch: 33 | loss: 0.2926049
	speed: 0.0277s/iter; left time: 493.4526s
Epoch: 33 cost time: 7.761947870254517
Epoch: 33, Steps: 265 | Train Loss: 0.2754891 Vali Loss: 0.2079228 Test Loss: 0.2857445
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2615375
	speed: 0.2026s/iter; left time: 3577.8695s
	iters: 200, epoch: 34 | loss: 0.3648614
	speed: 0.0643s/iter; left time: 1128.6793s
Epoch: 34 cost time: 16.207828521728516
Epoch: 34, Steps: 265 | Train Loss: 0.2752747 Vali Loss: 0.2077383 Test Loss: 0.2857494
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2874205
	speed: 0.2042s/iter; left time: 3551.7902s
	iters: 200, epoch: 35 | loss: 0.1992513
	speed: 0.0404s/iter; left time: 697.9485s
Epoch: 35 cost time: 13.256102085113525
Epoch: 35, Steps: 265 | Train Loss: 0.2746465 Vali Loss: 0.2076665 Test Loss: 0.2857156
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2357473
	speed: 0.2305s/iter; left time: 3947.9660s
	iters: 200, epoch: 36 | loss: 0.3050901
	speed: 0.0288s/iter; left time: 489.5282s
Epoch: 36 cost time: 9.046876192092896
Epoch: 36, Steps: 265 | Train Loss: 0.2750740 Vali Loss: 0.2077732 Test Loss: 0.2856846
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3805986
	speed: 0.1566s/iter; left time: 2640.9593s
	iters: 200, epoch: 37 | loss: 0.2282087
	speed: 0.0261s/iter; left time: 437.5870s
Epoch: 37 cost time: 9.412355422973633
Epoch: 37, Steps: 265 | Train Loss: 0.2754862 Vali Loss: 0.2077415 Test Loss: 0.2857089
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2012490
	speed: 0.1677s/iter; left time: 2782.5382s
	iters: 200, epoch: 38 | loss: 0.3062837
	speed: 0.0271s/iter; left time: 447.7066s
Epoch: 38 cost time: 8.275523900985718
Epoch: 38, Steps: 265 | Train Loss: 0.2750681 Vali Loss: 0.2078148 Test Loss: 0.2856795
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2774784
	speed: 0.1777s/iter; left time: 2901.6487s
	iters: 200, epoch: 39 | loss: 0.2825682
	speed: 0.0337s/iter; left time: 547.0176s
Epoch: 39 cost time: 11.52424168586731
Epoch: 39, Steps: 265 | Train Loss: 0.2752630 Vali Loss: 0.2077514 Test Loss: 0.2856731
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2244136
	speed: 0.1490s/iter; left time: 2394.0415s
	iters: 200, epoch: 40 | loss: 0.2612452
	speed: 0.0195s/iter; left time: 311.7814s
Epoch: 40 cost time: 7.680918216705322
Epoch: 40, Steps: 265 | Train Loss: 0.2749573 Vali Loss: 0.2076467 Test Loss: 0.2856795
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3506172
	speed: 0.1530s/iter; left time: 2417.2222s
	iters: 200, epoch: 41 | loss: 0.3339407
	speed: 0.0264s/iter; left time: 414.2133s
Epoch: 41 cost time: 10.51418161392212
Epoch: 41, Steps: 265 | Train Loss: 0.2755217 Vali Loss: 0.2078150 Test Loss: 0.2856688
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2196534
	speed: 0.2008s/iter; left time: 3119.6039s
	iters: 200, epoch: 42 | loss: 0.3021581
	speed: 0.0234s/iter; left time: 360.7501s
Epoch: 42 cost time: 8.871448040008545
Epoch: 42, Steps: 265 | Train Loss: 0.2747829 Vali Loss: 0.2077143 Test Loss: 0.2856643
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2510883
	speed: 0.2022s/iter; left time: 3087.3073s
	iters: 200, epoch: 43 | loss: 0.3385592
	speed: 0.0512s/iter; left time: 776.8109s
Epoch: 43 cost time: 12.010960340499878
Epoch: 43, Steps: 265 | Train Loss: 0.2754919 Vali Loss: 0.2078260 Test Loss: 0.2856613
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2854912
	speed: 0.1914s/iter; left time: 2872.7237s
	iters: 200, epoch: 44 | loss: 0.2098414
	speed: 0.0247s/iter; left time: 367.8154s
Epoch: 44 cost time: 8.246009349822998
Epoch: 44, Steps: 265 | Train Loss: 0.2750565 Vali Loss: 0.2078510 Test Loss: 0.2856622
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2782719
	speed: 0.1350s/iter; left time: 1989.8991s
	iters: 200, epoch: 45 | loss: 0.2483077
	speed: 0.0283s/iter; left time: 414.6174s
Epoch: 45 cost time: 7.76005744934082
Epoch: 45, Steps: 265 | Train Loss: 0.2751166 Vali Loss: 0.2078396 Test Loss: 0.2856548
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2341658
	speed: 0.1499s/iter; left time: 2169.9371s
	iters: 200, epoch: 46 | loss: 0.1695415
	speed: 0.0537s/iter; left time: 771.7712s
Epoch: 46 cost time: 15.107998132705688
Epoch: 46, Steps: 265 | Train Loss: 0.2750727 Vali Loss: 0.2078347 Test Loss: 0.2856555
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2480075
	speed: 0.1724s/iter; left time: 2449.9214s
	iters: 200, epoch: 47 | loss: 0.2413572
	speed: 0.0282s/iter; left time: 397.4100s
Epoch: 47 cost time: 8.652531623840332
Epoch: 47, Steps: 265 | Train Loss: 0.2753755 Vali Loss: 0.2077222 Test Loss: 0.2856399
EarlyStopping counter: 20 out of 20
Early stopping
train 34045
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=38, out_features=108, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3677184.0
params:  4212.0
Trainable parameters:  4212
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3343275
	speed: 0.0451s/iter; left time: 1191.0236s
	iters: 200, epoch: 1 | loss: 0.4845695
	speed: 0.0643s/iter; left time: 1691.8536s
Epoch: 1 cost time: 16.271721839904785
Epoch: 1, Steps: 265 | Train Loss: 0.4176002 Vali Loss: 0.2074515 Test Loss: 0.2852614
Validation loss decreased (inf --> 0.207451).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5571217
	speed: 0.1920s/iter; left time: 5018.8565s
	iters: 200, epoch: 2 | loss: 0.4762614
	speed: 0.0387s/iter; left time: 1007.3258s
Epoch: 2 cost time: 10.987799644470215
Epoch: 2, Steps: 265 | Train Loss: 0.4171113 Vali Loss: 0.2071455 Test Loss: 0.2850634
Validation loss decreased (0.207451 --> 0.207146).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3260855
	speed: 0.1968s/iter; left time: 5092.6018s
	iters: 200, epoch: 3 | loss: 0.4494041
	speed: 0.0442s/iter; left time: 1139.0491s
Epoch: 3 cost time: 11.035184144973755
Epoch: 3, Steps: 265 | Train Loss: 0.4164293 Vali Loss: 0.2071045 Test Loss: 0.2847891
Validation loss decreased (0.207146 --> 0.207105).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4709000
	speed: 0.1907s/iter; left time: 4881.8847s
	iters: 200, epoch: 4 | loss: 0.3596209
	speed: 0.0424s/iter; left time: 1081.2789s
Epoch: 4 cost time: 12.904431819915771
Epoch: 4, Steps: 265 | Train Loss: 0.4161075 Vali Loss: 0.2070658 Test Loss: 0.2848022
Validation loss decreased (0.207105 --> 0.207066).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3963278
	speed: 0.1503s/iter; left time: 3807.7039s
	iters: 200, epoch: 5 | loss: 0.4133421
	speed: 0.0266s/iter; left time: 672.2799s
Epoch: 5 cost time: 7.550890207290649
Epoch: 5, Steps: 265 | Train Loss: 0.4165653 Vali Loss: 0.2069904 Test Loss: 0.2846452
Validation loss decreased (0.207066 --> 0.206990).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3540127
	speed: 0.1348s/iter; left time: 3380.8941s
	iters: 200, epoch: 6 | loss: 0.5242013
	speed: 0.0303s/iter; left time: 756.6295s
Epoch: 6 cost time: 9.333295583724976
Epoch: 6, Steps: 265 | Train Loss: 0.4156217 Vali Loss: 0.2073508 Test Loss: 0.2845843
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3160224
	speed: 0.2123s/iter; left time: 5268.5977s
	iters: 200, epoch: 7 | loss: 0.4684100
	speed: 0.0334s/iter; left time: 825.0517s
Epoch: 7 cost time: 11.483537197113037
Epoch: 7, Steps: 265 | Train Loss: 0.4152113 Vali Loss: 0.2069938 Test Loss: 0.2845068
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.6713479
	speed: 0.2258s/iter; left time: 5542.5159s
	iters: 200, epoch: 8 | loss: 0.4407156
	speed: 0.0405s/iter; left time: 990.9969s
Epoch: 8 cost time: 11.760144710540771
Epoch: 8, Steps: 265 | Train Loss: 0.4155197 Vali Loss: 0.2071355 Test Loss: 0.2844175
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4361798
	speed: 0.1243s/iter; left time: 3017.0067s
	iters: 200, epoch: 9 | loss: 0.3695417
	speed: 0.0212s/iter; left time: 513.0468s
Epoch: 9 cost time: 6.7881081104278564
Epoch: 9, Steps: 265 | Train Loss: 0.4160586 Vali Loss: 0.2067762 Test Loss: 0.2844535
Validation loss decreased (0.206990 --> 0.206776).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4753846
	speed: 0.1622s/iter; left time: 3895.3051s
	iters: 200, epoch: 10 | loss: 0.3141342
	speed: 0.0322s/iter; left time: 769.2615s
Epoch: 10 cost time: 8.962233781814575
Epoch: 10, Steps: 265 | Train Loss: 0.4161328 Vali Loss: 0.2070161 Test Loss: 0.2845204
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3265690
	speed: 0.1557s/iter; left time: 3699.1377s
	iters: 200, epoch: 11 | loss: 0.2956176
	speed: 0.0326s/iter; left time: 771.4420s
Epoch: 11 cost time: 9.982564687728882
Epoch: 11, Steps: 265 | Train Loss: 0.4155571 Vali Loss: 0.2071854 Test Loss: 0.2844240
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3595914
	speed: 0.1370s/iter; left time: 3217.2285s
	iters: 200, epoch: 12 | loss: 0.4538744
	speed: 0.0310s/iter; left time: 723.8235s
Epoch: 12 cost time: 7.748702526092529
Epoch: 12, Steps: 265 | Train Loss: 0.4158730 Vali Loss: 0.2071426 Test Loss: 0.2845283
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4621634
	speed: 0.1555s/iter; left time: 3611.2563s
	iters: 200, epoch: 13 | loss: 0.4389046
	speed: 0.0200s/iter; left time: 461.3980s
Epoch: 13 cost time: 7.404895544052124
Epoch: 13, Steps: 265 | Train Loss: 0.4153509 Vali Loss: 0.2070990 Test Loss: 0.2844982
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.5495390
	speed: 0.2559s/iter; left time: 5874.5115s
	iters: 200, epoch: 14 | loss: 0.3116478
	speed: 0.0512s/iter; left time: 1170.3486s
Epoch: 14 cost time: 13.359511613845825
Epoch: 14, Steps: 265 | Train Loss: 0.4158921 Vali Loss: 0.2071557 Test Loss: 0.2844097
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3675033
	speed: 0.1897s/iter; left time: 4303.7345s
	iters: 200, epoch: 15 | loss: 0.3729722
	speed: 0.0271s/iter; left time: 613.0693s
Epoch: 15 cost time: 8.917011260986328
Epoch: 15, Steps: 265 | Train Loss: 0.4153852 Vali Loss: 0.2070934 Test Loss: 0.2844259
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.5447971
	speed: 0.1246s/iter; left time: 2794.5704s
	iters: 200, epoch: 16 | loss: 0.3454742
	speed: 0.0320s/iter; left time: 713.5418s
Epoch: 16 cost time: 7.11846137046814
Epoch: 16, Steps: 265 | Train Loss: 0.4157739 Vali Loss: 0.2070954 Test Loss: 0.2844390
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4481705
	speed: 0.1384s/iter; left time: 3067.5977s
	iters: 200, epoch: 17 | loss: 0.3710303
	speed: 0.0547s/iter; left time: 1206.8624s
Epoch: 17 cost time: 11.305322408676147
Epoch: 17, Steps: 265 | Train Loss: 0.4148889 Vali Loss: 0.2070375 Test Loss: 0.2844516
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3562161
	speed: 0.1874s/iter; left time: 4103.4920s
	iters: 200, epoch: 18 | loss: 0.3401253
	speed: 0.0320s/iter; left time: 697.4065s
Epoch: 18 cost time: 10.093510866165161
Epoch: 18, Steps: 265 | Train Loss: 0.4155246 Vali Loss: 0.2069875 Test Loss: 0.2844105
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3553030
	speed: 0.2039s/iter; left time: 4409.8984s
	iters: 200, epoch: 19 | loss: 0.2828313
	speed: 0.0210s/iter; left time: 453.0213s
Epoch: 19 cost time: 8.149303197860718
Epoch: 19, Steps: 265 | Train Loss: 0.4148874 Vali Loss: 0.2071302 Test Loss: 0.2844479
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3261894
	speed: 0.1425s/iter; left time: 3044.8890s
	iters: 200, epoch: 20 | loss: 0.2944797
	speed: 0.0290s/iter; left time: 617.6876s
Epoch: 20 cost time: 8.779993772506714
Epoch: 20, Steps: 265 | Train Loss: 0.4155386 Vali Loss: 0.2071179 Test Loss: 0.2844105
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4323225
	speed: 0.2017s/iter; left time: 4255.3585s
	iters: 200, epoch: 21 | loss: 0.4150047
	speed: 0.0377s/iter; left time: 791.8943s
Epoch: 21 cost time: 12.142774820327759
Epoch: 21, Steps: 265 | Train Loss: 0.4152231 Vali Loss: 0.2073400 Test Loss: 0.2844344
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3972173
	speed: 0.1822s/iter; left time: 3795.8825s
	iters: 200, epoch: 22 | loss: 0.5349888
	speed: 0.0430s/iter; left time: 890.9135s
Epoch: 22 cost time: 12.12045669555664
Epoch: 22, Steps: 265 | Train Loss: 0.4158338 Vali Loss: 0.2071446 Test Loss: 0.2844197
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4897096
	speed: 0.1910s/iter; left time: 3929.9471s
	iters: 200, epoch: 23 | loss: 0.5320100
	speed: 0.0244s/iter; left time: 498.7353s
Epoch: 23 cost time: 10.429044723510742
Epoch: 23, Steps: 265 | Train Loss: 0.4157502 Vali Loss: 0.2072584 Test Loss: 0.2843820
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4921592
	speed: 0.1620s/iter; left time: 3289.6295s
	iters: 200, epoch: 24 | loss: 0.4132566
	speed: 0.0287s/iter; left time: 579.6881s
Epoch: 24 cost time: 8.141969919204712
Epoch: 24, Steps: 265 | Train Loss: 0.4151499 Vali Loss: 0.2073302 Test Loss: 0.2843514
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.5464129
	speed: 0.1907s/iter; left time: 3822.1638s
	iters: 200, epoch: 25 | loss: 0.2555951
	speed: 0.0455s/iter; left time: 906.6551s
Epoch: 25 cost time: 12.646504640579224
Epoch: 25, Steps: 265 | Train Loss: 0.4151973 Vali Loss: 0.2071983 Test Loss: 0.2843853
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.5665034
	speed: 0.2500s/iter; left time: 4943.8039s
	iters: 200, epoch: 26 | loss: 0.3484716
	speed: 0.0514s/iter; left time: 1010.7632s
Epoch: 26 cost time: 13.266493558883667
Epoch: 26, Steps: 265 | Train Loss: 0.4153128 Vali Loss: 0.2073075 Test Loss: 0.2843930
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3032824
	speed: 0.1669s/iter; left time: 3257.3271s
	iters: 200, epoch: 27 | loss: 0.4016908
	speed: 0.0346s/iter; left time: 671.1756s
Epoch: 27 cost time: 9.264967441558838
Epoch: 27, Steps: 265 | Train Loss: 0.4149302 Vali Loss: 0.2073411 Test Loss: 0.2844023
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.5806324
	speed: 0.1308s/iter; left time: 2516.6975s
	iters: 200, epoch: 28 | loss: 0.4189239
	speed: 0.0321s/iter; left time: 615.0193s
Epoch: 28 cost time: 7.874195337295532
Epoch: 28, Steps: 265 | Train Loss: 0.4142085 Vali Loss: 0.2071778 Test Loss: 0.2843814
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4645975
	speed: 0.1951s/iter; left time: 3702.7708s
	iters: 200, epoch: 29 | loss: 0.3558026
	speed: 0.0419s/iter; left time: 790.3548s
Epoch: 29 cost time: 11.25580906867981
Epoch: 29, Steps: 265 | Train Loss: 0.4149490 Vali Loss: 0.2072191 Test Loss: 0.2843974
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_180_336_FITS_ETTm2_ftM_sl180_ll48_pl336_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.28571057319641113, mae:0.33143341541290283, rse:0.43174153566360474, corr:[0.56344473 0.5632026  0.55752414 0.5556539  0.5561704  0.5551342
 0.5528748  0.5516939  0.5518143  0.55148566 0.55006653 0.5488916
 0.548924   0.54930353 0.54883885 0.5476389  0.54673356 0.5463882
 0.5458381  0.54467094 0.5435208  0.543106   0.5431292  0.5427798
 0.54184586 0.54103595 0.540931   0.541      0.5404729  0.5393921
 0.53852636 0.538281   0.5381855  0.5378036  0.5372043  0.5367251
 0.5362674  0.5355762  0.5345573  0.53362405 0.533161   0.53303283
 0.53282565 0.5323383  0.53178614 0.5314022  0.53096306 0.5301931
 0.5291447  0.52820396 0.5275668  0.5271194  0.52657354 0.5258962
 0.5253384  0.5249661  0.5244491  0.52376676 0.52313    0.52282226
 0.522707   0.52262    0.5224541  0.5221621  0.52192706 0.5217707
 0.52151734 0.5212186  0.5210647  0.5211395  0.52118397 0.5210495
 0.5207931  0.5205551  0.5204662  0.5203063  0.51996344 0.5194727
 0.51904196 0.51871246 0.51836467 0.5179189  0.51745874 0.5170426
 0.5166743  0.51629037 0.5158537  0.51545155 0.5150849  0.51472443
 0.5144002  0.5141073  0.51374775 0.51317924 0.5122311  0.5108025
 0.5090166  0.5071972  0.5053909  0.50366324 0.50216305 0.50095487
 0.4998724  0.49867237 0.49724078 0.49576667 0.49452403 0.49358782
 0.49274543 0.4916785  0.4905596  0.48948553 0.48854327 0.48762205
 0.4865211  0.48533836 0.48420286 0.48317724 0.48226187 0.48129028
 0.48029235 0.47931972 0.47840786 0.4775479  0.4767045  0.47584543
 0.47496668 0.47406134 0.47311485 0.47212207 0.47118887 0.47034457
 0.46961614 0.4688688  0.46818727 0.4676318  0.4671123  0.46664628
 0.46613428 0.46556026 0.46498904 0.4644535  0.4639092  0.46315348
 0.46216834 0.46111095 0.46012124 0.4593395  0.45871043 0.45801294
 0.45740458 0.45711067 0.45682505 0.45632774 0.45566988 0.45506975
 0.45466498 0.45439142 0.4539788  0.45346498 0.4530212  0.45270544
 0.4525252  0.45227945 0.45215574 0.45211914 0.45205688 0.4519214
 0.45176077 0.45181698 0.45210633 0.45241496 0.452532   0.4523118
 0.45206264 0.45197725 0.45203707 0.4519913  0.45176044 0.45152366
 0.4513682  0.45124143 0.45108634 0.45082223 0.45058495 0.4504423
 0.45040214 0.4503513  0.45008522 0.44948906 0.4485131  0.44715106
 0.44550955 0.44389862 0.44247586 0.44130394 0.44034937 0.4393766
 0.4382635  0.43707618 0.4358958  0.43482134 0.4337758  0.43296582
 0.4324682  0.43207905 0.43145224 0.43054655 0.4296155  0.42888165
 0.42830598 0.42775285 0.42715442 0.4265063  0.42584562 0.42509794
 0.4243096  0.4234544  0.42273006 0.42193276 0.42088827 0.41977435
 0.4187349  0.41792262 0.41729426 0.41653582 0.41577518 0.41510478
 0.41440487 0.41350517 0.41236964 0.4113627  0.41065332 0.4103124
 0.4100425  0.40978113 0.4096928  0.4096139  0.40943816 0.408904
 0.40808317 0.40729392 0.40677944 0.40659767 0.40641344 0.4060918
 0.40588936 0.40594    0.40614992 0.4062375  0.40625668 0.4063909
 0.40672916 0.40725687 0.40758982 0.40760735 0.4075175  0.40753904
 0.40755084 0.40736133 0.4070524  0.40697172 0.4071215  0.40715724
 0.40694803 0.40666565 0.40663317 0.4068817  0.407221   0.40739244
 0.40725031 0.40703616 0.4068096  0.40666983 0.40656036 0.40653202
 0.4066118  0.40668246 0.4066809  0.406574   0.40639544 0.40644434
 0.40667766 0.4068112  0.40672168 0.40641582 0.40583768 0.40484923
 0.40345833 0.4021841  0.4011924  0.40054697 0.3999814  0.39935264
 0.39879566 0.39825007 0.39769778 0.39710718 0.39663646 0.3962435
 0.3958604  0.39522666 0.39449748 0.39385864 0.39328656 0.39259765
 0.3917684  0.3908985  0.39013112 0.38947716 0.38872066 0.38777772
 0.38667277 0.38570637 0.3847725  0.3838103  0.38276398 0.38181728
 0.38088936 0.37982824 0.37871447 0.3778657  0.37733188 0.37661707
 0.37541464 0.37418774 0.373689   0.37365368 0.3730299  0.3718701
 0.3716162  0.3724753  0.37259594 0.37103373 0.3717752  0.3796822 ]
