Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=122, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=514, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_720_720_FITS_ETTm2_ftM_sl720_ll48_pl720_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=122, out_features=244, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  26672128.0
params:  30012.0
Trainable parameters:  30012
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4310155
	speed: 0.0274s/iter; left time: 704.0663s
	iters: 200, epoch: 1 | loss: 0.3738062
	speed: 0.0206s/iter; left time: 526.7776s
Epoch: 1 cost time: 6.335610628128052
Epoch: 1, Steps: 258 | Train Loss: 0.4261147 Vali Loss: 0.2958506 Test Loss: 0.3939469
Validation loss decreased (inf --> 0.295851).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3839698
	speed: 0.0862s/iter; left time: 2193.6293s
	iters: 200, epoch: 2 | loss: 0.3477039
	speed: 0.0188s/iter; left time: 476.6762s
Epoch: 2 cost time: 5.845773935317993
Epoch: 2, Steps: 258 | Train Loss: 0.3174438 Vali Loss: 0.2806251 Test Loss: 0.3767932
Validation loss decreased (0.295851 --> 0.280625).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3008782
	speed: 0.0828s/iter; left time: 2084.4768s
	iters: 200, epoch: 3 | loss: 0.3497421
	speed: 0.0246s/iter; left time: 617.7859s
Epoch: 3 cost time: 6.022285223007202
Epoch: 3, Steps: 258 | Train Loss: 0.2874811 Vali Loss: 0.2746222 Test Loss: 0.3688041
Validation loss decreased (0.280625 --> 0.274622).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3052049
	speed: 0.0810s/iter; left time: 2018.7286s
	iters: 200, epoch: 4 | loss: 0.3124606
	speed: 0.0254s/iter; left time: 631.5203s
Epoch: 4 cost time: 6.297269105911255
Epoch: 4, Steps: 258 | Train Loss: 0.2728850 Vali Loss: 0.2708604 Test Loss: 0.3638699
Validation loss decreased (0.274622 --> 0.270860).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1943063
	speed: 0.0900s/iter; left time: 2219.4912s
	iters: 200, epoch: 5 | loss: 0.2276053
	speed: 0.0189s/iter; left time: 464.9874s
Epoch: 5 cost time: 5.528124570846558
Epoch: 5, Steps: 258 | Train Loss: 0.2651905 Vali Loss: 0.2678128 Test Loss: 0.3605684
Validation loss decreased (0.270860 --> 0.267813).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2905908
	speed: 0.0830s/iter; left time: 2024.9773s
	iters: 200, epoch: 6 | loss: 0.2723895
	speed: 0.0195s/iter; left time: 474.0032s
Epoch: 6 cost time: 5.623193740844727
Epoch: 6, Steps: 258 | Train Loss: 0.2607137 Vali Loss: 0.2661063 Test Loss: 0.3583789
Validation loss decreased (0.267813 --> 0.266106).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3130937
	speed: 0.0821s/iter; left time: 1983.1160s
	iters: 200, epoch: 7 | loss: 0.2093203
	speed: 0.0190s/iter; left time: 458.0831s
Epoch: 7 cost time: 5.523473024368286
Epoch: 7, Steps: 258 | Train Loss: 0.2588045 Vali Loss: 0.2654459 Test Loss: 0.3570006
Validation loss decreased (0.266106 --> 0.265446).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2580636
	speed: 0.0847s/iter; left time: 2023.0351s
	iters: 200, epoch: 8 | loss: 0.2533777
	speed: 0.0200s/iter; left time: 476.9032s
Epoch: 8 cost time: 5.899392127990723
Epoch: 8, Steps: 258 | Train Loss: 0.2573634 Vali Loss: 0.2641984 Test Loss: 0.3562202
Validation loss decreased (0.265446 --> 0.264198).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2672046
	speed: 0.0877s/iter; left time: 2073.6718s
	iters: 200, epoch: 9 | loss: 0.2947806
	speed: 0.0191s/iter; left time: 450.6216s
Epoch: 9 cost time: 5.806098937988281
Epoch: 9, Steps: 258 | Train Loss: 0.2564683 Vali Loss: 0.2636204 Test Loss: 0.3557311
Validation loss decreased (0.264198 --> 0.263620).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2583407
	speed: 0.0761s/iter; left time: 1780.2773s
	iters: 200, epoch: 10 | loss: 0.3067783
	speed: 0.0188s/iter; left time: 438.5268s
Epoch: 10 cost time: 5.8679211139678955
Epoch: 10, Steps: 258 | Train Loss: 0.2556272 Vali Loss: 0.2637890 Test Loss: 0.3551202
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1950822
	speed: 0.0935s/iter; left time: 2161.5723s
	iters: 200, epoch: 11 | loss: 0.2788579
	speed: 0.0208s/iter; left time: 478.9386s
Epoch: 11 cost time: 5.758294582366943
Epoch: 11, Steps: 258 | Train Loss: 0.2557133 Vali Loss: 0.2632058 Test Loss: 0.3548626
Validation loss decreased (0.263620 --> 0.263206).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1946858
	speed: 0.0792s/iter; left time: 1811.4861s
	iters: 200, epoch: 12 | loss: 0.2252049
	speed: 0.0193s/iter; left time: 440.0462s
Epoch: 12 cost time: 5.7265472412109375
Epoch: 12, Steps: 258 | Train Loss: 0.2556580 Vali Loss: 0.2629769 Test Loss: 0.3547817
Validation loss decreased (0.263206 --> 0.262977).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2384177
	speed: 0.0920s/iter; left time: 2079.6541s
	iters: 200, epoch: 13 | loss: 0.2216767
	speed: 0.0221s/iter; left time: 496.2504s
Epoch: 13 cost time: 6.264631986618042
Epoch: 13, Steps: 258 | Train Loss: 0.2552744 Vali Loss: 0.2628508 Test Loss: 0.3546321
Validation loss decreased (0.262977 --> 0.262851).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1809450
	speed: 0.0899s/iter; left time: 2009.5966s
	iters: 200, epoch: 14 | loss: 0.2603408
	speed: 0.0211s/iter; left time: 470.4924s
Epoch: 14 cost time: 6.325927495956421
Epoch: 14, Steps: 258 | Train Loss: 0.2553817 Vali Loss: 0.2629314 Test Loss: 0.3543643
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3229501
	speed: 0.0941s/iter; left time: 2078.2033s
	iters: 200, epoch: 15 | loss: 0.2773716
	speed: 0.0222s/iter; left time: 488.1074s
Epoch: 15 cost time: 5.867889404296875
Epoch: 15, Steps: 258 | Train Loss: 0.2552444 Vali Loss: 0.2627116 Test Loss: 0.3544754
Validation loss decreased (0.262851 --> 0.262712).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2671053
	speed: 0.1057s/iter; left time: 2308.5648s
	iters: 200, epoch: 16 | loss: 0.1873392
	speed: 0.0205s/iter; left time: 446.2073s
Epoch: 16 cost time: 5.53410530090332
Epoch: 16, Steps: 258 | Train Loss: 0.2550322 Vali Loss: 0.2626783 Test Loss: 0.3542282
Validation loss decreased (0.262712 --> 0.262678).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3050095
	speed: 0.0827s/iter; left time: 1784.6021s
	iters: 200, epoch: 17 | loss: 0.3443939
	speed: 0.0200s/iter; left time: 429.3545s
Epoch: 17 cost time: 5.778058767318726
Epoch: 17, Steps: 258 | Train Loss: 0.2549303 Vali Loss: 0.2626897 Test Loss: 0.3543950
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3035676
	speed: 0.0813s/iter; left time: 1732.6217s
	iters: 200, epoch: 18 | loss: 0.2973597
	speed: 0.0240s/iter; left time: 508.9812s
Epoch: 18 cost time: 5.924637794494629
Epoch: 18, Steps: 258 | Train Loss: 0.2549936 Vali Loss: 0.2624825 Test Loss: 0.3542325
Validation loss decreased (0.262678 --> 0.262482).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2426808
	speed: 0.0801s/iter; left time: 1687.0195s
	iters: 200, epoch: 19 | loss: 0.2969854
	speed: 0.0200s/iter; left time: 418.8404s
Epoch: 19 cost time: 5.698135614395142
Epoch: 19, Steps: 258 | Train Loss: 0.2551434 Vali Loss: 0.2626578 Test Loss: 0.3542008
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2427024
	speed: 0.0805s/iter; left time: 1675.1942s
	iters: 200, epoch: 20 | loss: 0.2244903
	speed: 0.0192s/iter; left time: 397.8904s
Epoch: 20 cost time: 5.3635852336883545
Epoch: 20, Steps: 258 | Train Loss: 0.2552249 Vali Loss: 0.2628327 Test Loss: 0.3540364
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3128497
	speed: 0.0851s/iter; left time: 1748.2277s
	iters: 200, epoch: 21 | loss: 0.2637500
	speed: 0.0183s/iter; left time: 373.3627s
Epoch: 21 cost time: 5.270419597625732
Epoch: 21, Steps: 258 | Train Loss: 0.2549359 Vali Loss: 0.2626173 Test Loss: 0.3540318
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3016977
	speed: 0.0786s/iter; left time: 1595.2007s
	iters: 200, epoch: 22 | loss: 0.2919577
	speed: 0.0197s/iter; left time: 397.9324s
Epoch: 22 cost time: 5.516217231750488
Epoch: 22, Steps: 258 | Train Loss: 0.2550557 Vali Loss: 0.2627016 Test Loss: 0.3541724
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2496682
	speed: 0.0837s/iter; left time: 1676.4572s
	iters: 200, epoch: 23 | loss: 0.2337903
	speed: 0.0212s/iter; left time: 422.6756s
Epoch: 23 cost time: 5.705463171005249
Epoch: 23, Steps: 258 | Train Loss: 0.2551743 Vali Loss: 0.2628635 Test Loss: 0.3540147
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2777363
	speed: 0.0859s/iter; left time: 1697.9024s
	iters: 200, epoch: 24 | loss: 0.2930311
	speed: 0.0213s/iter; left time: 418.1515s
Epoch: 24 cost time: 6.4090282917022705
Epoch: 24, Steps: 258 | Train Loss: 0.2550062 Vali Loss: 0.2623834 Test Loss: 0.3540533
Validation loss decreased (0.262482 --> 0.262383).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2310752
	speed: 0.0846s/iter; left time: 1649.9679s
	iters: 200, epoch: 25 | loss: 0.2255502
	speed: 0.0188s/iter; left time: 365.4847s
Epoch: 25 cost time: 5.59822416305542
Epoch: 25, Steps: 258 | Train Loss: 0.2549558 Vali Loss: 0.2628196 Test Loss: 0.3540700
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2830423
	speed: 0.0764s/iter; left time: 1471.7316s
	iters: 200, epoch: 26 | loss: 0.3001420
	speed: 0.0178s/iter; left time: 341.6368s
Epoch: 26 cost time: 5.5554423332214355
Epoch: 26, Steps: 258 | Train Loss: 0.2547599 Vali Loss: 0.2626085 Test Loss: 0.3540421
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2338938
	speed: 0.0845s/iter; left time: 1605.6471s
	iters: 200, epoch: 27 | loss: 0.2442160
	speed: 0.0223s/iter; left time: 421.6119s
Epoch: 27 cost time: 5.777109146118164
Epoch: 27, Steps: 258 | Train Loss: 0.2549183 Vali Loss: 0.2624694 Test Loss: 0.3540720
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2693627
	speed: 0.1029s/iter; left time: 1927.1668s
	iters: 200, epoch: 28 | loss: 0.3466441
	speed: 0.0204s/iter; left time: 379.2627s
Epoch: 28 cost time: 5.646410703659058
Epoch: 28, Steps: 258 | Train Loss: 0.2549298 Vali Loss: 0.2626824 Test Loss: 0.3540787
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2448490
	speed: 0.0781s/iter; left time: 1443.8884s
	iters: 200, epoch: 29 | loss: 0.2124654
	speed: 0.0181s/iter; left time: 333.4435s
Epoch: 29 cost time: 5.182709455490112
Epoch: 29, Steps: 258 | Train Loss: 0.2548887 Vali Loss: 0.2625053 Test Loss: 0.3539906
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2034777
	speed: 0.0821s/iter; left time: 1496.0998s
	iters: 200, epoch: 30 | loss: 0.2495574
	speed: 0.0192s/iter; left time: 348.0774s
Epoch: 30 cost time: 5.443665504455566
Epoch: 30, Steps: 258 | Train Loss: 0.2549665 Vali Loss: 0.2626283 Test Loss: 0.3539771
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2249156
	speed: 0.0800s/iter; left time: 1436.9360s
	iters: 200, epoch: 31 | loss: 0.2558018
	speed: 0.0194s/iter; left time: 346.3342s
Epoch: 31 cost time: 5.4564666748046875
Epoch: 31, Steps: 258 | Train Loss: 0.2547902 Vali Loss: 0.2626338 Test Loss: 0.3539586
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2425130
	speed: 0.0777s/iter; left time: 1375.3762s
	iters: 200, epoch: 32 | loss: 0.3476372
	speed: 0.0256s/iter; left time: 451.4174s
Epoch: 32 cost time: 6.756415843963623
Epoch: 32, Steps: 258 | Train Loss: 0.2548604 Vali Loss: 0.2624419 Test Loss: 0.3539405
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2808647
	speed: 0.0864s/iter; left time: 1506.7630s
	iters: 200, epoch: 33 | loss: 0.2531645
	speed: 0.0209s/iter; left time: 363.0121s
Epoch: 33 cost time: 5.672540903091431
Epoch: 33, Steps: 258 | Train Loss: 0.2549038 Vali Loss: 0.2625709 Test Loss: 0.3539800
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2790628
	speed: 0.0762s/iter; left time: 1309.9294s
	iters: 200, epoch: 34 | loss: 0.2042906
	speed: 0.0184s/iter; left time: 314.4024s
Epoch: 34 cost time: 5.15712571144104
Epoch: 34, Steps: 258 | Train Loss: 0.2544950 Vali Loss: 0.2627449 Test Loss: 0.3539687
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2519666
	speed: 0.0786s/iter; left time: 1331.1159s
	iters: 200, epoch: 35 | loss: 0.2832583
	speed: 0.0217s/iter; left time: 365.3858s
Epoch: 35 cost time: 5.781401872634888
Epoch: 35, Steps: 258 | Train Loss: 0.2548765 Vali Loss: 0.2627402 Test Loss: 0.3539356
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2406064
	speed: 0.0775s/iter; left time: 1292.2660s
	iters: 200, epoch: 36 | loss: 0.2783360
	speed: 0.0185s/iter; left time: 306.0622s
Epoch: 36 cost time: 5.266344308853149
Epoch: 36, Steps: 258 | Train Loss: 0.2550106 Vali Loss: 0.2625213 Test Loss: 0.3539789
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3097753
	speed: 0.0754s/iter; left time: 1236.7306s
	iters: 200, epoch: 37 | loss: 0.2774273
	speed: 0.0180s/iter; left time: 292.8724s
Epoch: 37 cost time: 5.189313650131226
Epoch: 37, Steps: 258 | Train Loss: 0.2547729 Vali Loss: 0.2625996 Test Loss: 0.3539372
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2616658
	speed: 0.0749s/iter; left time: 1210.5949s
	iters: 200, epoch: 38 | loss: 0.3396502
	speed: 0.0193s/iter; left time: 309.8529s
Epoch: 38 cost time: 5.480405330657959
Epoch: 38, Steps: 258 | Train Loss: 0.2548990 Vali Loss: 0.2628509 Test Loss: 0.3539341
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2510582
	speed: 0.0835s/iter; left time: 1327.5306s
	iters: 200, epoch: 39 | loss: 0.3304212
	speed: 0.0225s/iter; left time: 354.7854s
Epoch: 39 cost time: 6.181728839874268
Epoch: 39, Steps: 258 | Train Loss: 0.2547086 Vali Loss: 0.2625825 Test Loss: 0.3539439
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2228720
	speed: 0.0852s/iter; left time: 1332.6326s
	iters: 200, epoch: 40 | loss: 0.3041359
	speed: 0.0229s/iter; left time: 355.2450s
Epoch: 40 cost time: 5.917703866958618
Epoch: 40, Steps: 258 | Train Loss: 0.2549505 Vali Loss: 0.2622642 Test Loss: 0.3539675
Validation loss decreased (0.262383 --> 0.262264).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2334038
	speed: 0.0888s/iter; left time: 1366.0778s
	iters: 200, epoch: 41 | loss: 0.2785639
	speed: 0.0257s/iter; left time: 393.3371s
Epoch: 41 cost time: 6.523204326629639
Epoch: 41, Steps: 258 | Train Loss: 0.2548981 Vali Loss: 0.2622807 Test Loss: 0.3539068
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2798015
	speed: 0.0788s/iter; left time: 1191.6306s
	iters: 200, epoch: 42 | loss: 0.2250287
	speed: 0.0195s/iter; left time: 292.7901s
Epoch: 42 cost time: 5.621917247772217
Epoch: 42, Steps: 258 | Train Loss: 0.2546489 Vali Loss: 0.2625176 Test Loss: 0.3539229
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2632087
	speed: 0.0876s/iter; left time: 1302.2929s
	iters: 200, epoch: 43 | loss: 0.2447680
	speed: 0.0195s/iter; left time: 287.4573s
Epoch: 43 cost time: 6.026543855667114
Epoch: 43, Steps: 258 | Train Loss: 0.2543981 Vali Loss: 0.2627483 Test Loss: 0.3539440
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2508643
	speed: 0.0938s/iter; left time: 1369.7822s
	iters: 200, epoch: 44 | loss: 0.2165507
	speed: 0.0195s/iter; left time: 283.2460s
Epoch: 44 cost time: 5.508804798126221
Epoch: 44, Steps: 258 | Train Loss: 0.2545815 Vali Loss: 0.2626966 Test Loss: 0.3539489
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2921136
	speed: 0.0778s/iter; left time: 1115.7205s
	iters: 200, epoch: 45 | loss: 0.2605917
	speed: 0.0215s/iter; left time: 306.1336s
Epoch: 45 cost time: 5.660179853439331
Epoch: 45, Steps: 258 | Train Loss: 0.2546343 Vali Loss: 0.2625632 Test Loss: 0.3539381
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2613783
	speed: 0.0860s/iter; left time: 1211.9254s
	iters: 200, epoch: 46 | loss: 0.2191245
	speed: 0.0191s/iter; left time: 267.4984s
Epoch: 46 cost time: 5.703750133514404
Epoch: 46, Steps: 258 | Train Loss: 0.2546198 Vali Loss: 0.2624312 Test Loss: 0.3539321
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2491691
	speed: 0.0864s/iter; left time: 1195.6683s
	iters: 200, epoch: 47 | loss: 0.2809080
	speed: 0.0219s/iter; left time: 300.4524s
Epoch: 47 cost time: 6.069006681442261
Epoch: 47, Steps: 258 | Train Loss: 0.2545269 Vali Loss: 0.2625894 Test Loss: 0.3539097
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2161222
	speed: 0.0808s/iter; left time: 1096.7692s
	iters: 200, epoch: 48 | loss: 0.2526859
	speed: 0.0241s/iter; left time: 324.1305s
Epoch: 48 cost time: 6.4099767208099365
Epoch: 48, Steps: 258 | Train Loss: 0.2547927 Vali Loss: 0.2626384 Test Loss: 0.3539217
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2262774
	speed: 0.0872s/iter; left time: 1161.4055s
	iters: 200, epoch: 49 | loss: 0.2845319
	speed: 0.0196s/iter; left time: 259.5647s
Epoch: 49 cost time: 5.521410226821899
Epoch: 49, Steps: 258 | Train Loss: 0.2547733 Vali Loss: 0.2627360 Test Loss: 0.3539077
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2182052
	speed: 0.0832s/iter; left time: 1086.9104s
	iters: 200, epoch: 50 | loss: 0.2502044
	speed: 0.0202s/iter; left time: 261.1667s
Epoch: 50 cost time: 6.519028902053833
Epoch: 50, Steps: 258 | Train Loss: 0.2546968 Vali Loss: 0.2623635 Test Loss: 0.3539103
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2603589
	speed: 0.0981s/iter; left time: 1255.7312s
	iters: 200, epoch: 51 | loss: 0.2456983
	speed: 0.0233s/iter; left time: 296.3301s
Epoch: 51 cost time: 6.656788349151611
Epoch: 51, Steps: 258 | Train Loss: 0.2549381 Vali Loss: 0.2627202 Test Loss: 0.3539348
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2436376
	speed: 0.0868s/iter; left time: 1088.7594s
	iters: 200, epoch: 52 | loss: 0.2836550
	speed: 0.0192s/iter; left time: 239.2835s
Epoch: 52 cost time: 5.554274559020996
Epoch: 52, Steps: 258 | Train Loss: 0.2548709 Vali Loss: 0.2626092 Test Loss: 0.3539025
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2959263
	speed: 0.0822s/iter; left time: 1009.5100s
	iters: 200, epoch: 53 | loss: 0.2341907
	speed: 0.0211s/iter; left time: 256.9842s
Epoch: 53 cost time: 5.310609579086304
Epoch: 53, Steps: 258 | Train Loss: 0.2547136 Vali Loss: 0.2624882 Test Loss: 0.3539070
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2315282
	speed: 0.0786s/iter; left time: 944.8060s
	iters: 200, epoch: 54 | loss: 0.3141778
	speed: 0.0207s/iter; left time: 246.3749s
Epoch: 54 cost time: 6.0464911460876465
Epoch: 54, Steps: 258 | Train Loss: 0.2545089 Vali Loss: 0.2626317 Test Loss: 0.3539077
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1797612
	speed: 0.0857s/iter; left time: 1008.0764s
	iters: 200, epoch: 55 | loss: 0.2925114
	speed: 0.0176s/iter; left time: 205.5367s
Epoch: 55 cost time: 5.16202712059021
Epoch: 55, Steps: 258 | Train Loss: 0.2545609 Vali Loss: 0.2625816 Test Loss: 0.3538926
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2308396
	speed: 0.0721s/iter; left time: 830.1383s
	iters: 200, epoch: 56 | loss: 0.2536868
	speed: 0.0172s/iter; left time: 196.5857s
Epoch: 56 cost time: 4.859898328781128
Epoch: 56, Steps: 258 | Train Loss: 0.2546602 Vali Loss: 0.2625918 Test Loss: 0.3539055
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2996422
	speed: 0.0753s/iter; left time: 847.5424s
	iters: 200, epoch: 57 | loss: 0.2665158
	speed: 0.0169s/iter; left time: 188.8682s
Epoch: 57 cost time: 4.787215709686279
Epoch: 57, Steps: 258 | Train Loss: 0.2547295 Vali Loss: 0.2626129 Test Loss: 0.3538949
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2463477
	speed: 0.0733s/iter; left time: 806.2263s
	iters: 200, epoch: 58 | loss: 0.2967703
	speed: 0.0179s/iter; left time: 195.1265s
Epoch: 58 cost time: 4.97913122177124
Epoch: 58, Steps: 258 | Train Loss: 0.2546738 Vali Loss: 0.2625753 Test Loss: 0.3538862
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2551172
	speed: 0.0776s/iter; left time: 833.2051s
	iters: 200, epoch: 59 | loss: 0.2108552
	speed: 0.0189s/iter; left time: 200.6017s
Epoch: 59 cost time: 4.993450164794922
Epoch: 59, Steps: 258 | Train Loss: 0.2547424 Vali Loss: 0.2625716 Test Loss: 0.3538835
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.2611874
	speed: 0.0760s/iter; left time: 795.9341s
	iters: 200, epoch: 60 | loss: 0.2135972
	speed: 0.0308s/iter; left time: 319.3837s
Epoch: 60 cost time: 6.329880237579346
Epoch: 60, Steps: 258 | Train Loss: 0.2546665 Vali Loss: 0.2625929 Test Loss: 0.3539012
EarlyStopping counter: 20 out of 20
Early stopping
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=122, out_features=244, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  26672128.0
params:  30012.0
Trainable parameters:  30012
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4976082
	speed: 0.0227s/iter; left time: 584.1164s
	iters: 200, epoch: 1 | loss: 0.3699209
	speed: 0.0165s/iter; left time: 422.8743s
Epoch: 1 cost time: 4.8675031661987305
Epoch: 1, Steps: 258 | Train Loss: 0.4969550 Vali Loss: 0.2615843 Test Loss: 0.3532667
Validation loss decreased (inf --> 0.261584).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5640043
	speed: 0.0986s/iter; left time: 2508.0684s
	iters: 200, epoch: 2 | loss: 0.4080610
	speed: 0.0253s/iter; left time: 640.0618s
Epoch: 2 cost time: 8.149892807006836
Epoch: 2, Steps: 258 | Train Loss: 0.4959790 Vali Loss: 0.2607945 Test Loss: 0.3532105
Validation loss decreased (0.261584 --> 0.260795).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3326791
	speed: 0.0735s/iter; left time: 1850.1142s
	iters: 200, epoch: 3 | loss: 0.5859842
	speed: 0.0164s/iter; left time: 411.2227s
Epoch: 3 cost time: 4.765614032745361
Epoch: 3, Steps: 258 | Train Loss: 0.4952767 Vali Loss: 0.2606384 Test Loss: 0.3530860
Validation loss decreased (0.260795 --> 0.260638).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4189359
	speed: 0.0772s/iter; left time: 1925.6044s
	iters: 200, epoch: 4 | loss: 0.5502768
	speed: 0.0246s/iter; left time: 611.7983s
Epoch: 4 cost time: 7.210683584213257
Epoch: 4, Steps: 258 | Train Loss: 0.4948012 Vali Loss: 0.2609572 Test Loss: 0.3526385
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4203011
	speed: 0.0883s/iter; left time: 2177.3278s
	iters: 200, epoch: 5 | loss: 0.5535226
	speed: 0.0174s/iter; left time: 427.7186s
Epoch: 5 cost time: 5.06015157699585
Epoch: 5, Steps: 258 | Train Loss: 0.4946521 Vali Loss: 0.2605722 Test Loss: 0.3523313
Validation loss decreased (0.260638 --> 0.260572).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.5121244
	speed: 0.0803s/iter; left time: 1960.6516s
	iters: 200, epoch: 6 | loss: 0.4773019
	speed: 0.0181s/iter; left time: 439.0134s
Epoch: 6 cost time: 5.264204263687134
Epoch: 6, Steps: 258 | Train Loss: 0.4941350 Vali Loss: 0.2600986 Test Loss: 0.3523265
Validation loss decreased (0.260572 --> 0.260099).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.5300553
	speed: 0.0731s/iter; left time: 1766.2524s
	iters: 200, epoch: 7 | loss: 0.3996916
	speed: 0.0165s/iter; left time: 397.5742s
Epoch: 7 cost time: 4.660072088241577
Epoch: 7, Steps: 258 | Train Loss: 0.4943617 Vali Loss: 0.2604373 Test Loss: 0.3521096
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4209632
	speed: 0.0819s/iter; left time: 1957.1110s
	iters: 200, epoch: 8 | loss: 0.4317164
	speed: 0.0167s/iter; left time: 397.9478s
Epoch: 8 cost time: 4.821124792098999
Epoch: 8, Steps: 258 | Train Loss: 0.4941445 Vali Loss: 0.2604014 Test Loss: 0.3524311
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.5430061
	speed: 0.0703s/iter; left time: 1662.5263s
	iters: 200, epoch: 9 | loss: 0.4187969
	speed: 0.0167s/iter; left time: 392.6187s
Epoch: 9 cost time: 4.785413026809692
Epoch: 9, Steps: 258 | Train Loss: 0.4938951 Vali Loss: 0.2603469 Test Loss: 0.3520824
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3554145
	speed: 0.0716s/iter; left time: 1673.0353s
	iters: 200, epoch: 10 | loss: 0.6031861
	speed: 0.0170s/iter; left time: 395.9889s
Epoch: 10 cost time: 4.781376838684082
Epoch: 10, Steps: 258 | Train Loss: 0.4938506 Vali Loss: 0.2602453 Test Loss: 0.3520726
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4789429
	speed: 0.0883s/iter; left time: 2041.8449s
	iters: 200, epoch: 11 | loss: 0.5735616
	speed: 0.0167s/iter; left time: 383.4927s
Epoch: 11 cost time: 6.790310382843018
Epoch: 11, Steps: 258 | Train Loss: 0.4941171 Vali Loss: 0.2601516 Test Loss: 0.3522093
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.6709443
	speed: 0.0726s/iter; left time: 1660.1304s
	iters: 200, epoch: 12 | loss: 0.5807416
	speed: 0.0163s/iter; left time: 369.9019s
Epoch: 12 cost time: 4.804113388061523
Epoch: 12, Steps: 258 | Train Loss: 0.4936428 Vali Loss: 0.2603101 Test Loss: 0.3521324
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4623675
	speed: 0.0712s/iter; left time: 1609.1578s
	iters: 200, epoch: 13 | loss: 0.5514898
	speed: 0.0162s/iter; left time: 364.5410s
Epoch: 13 cost time: 4.670570611953735
Epoch: 13, Steps: 258 | Train Loss: 0.4940753 Vali Loss: 0.2601821 Test Loss: 0.3522158
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3988849
	speed: 0.0727s/iter; left time: 1625.6816s
	iters: 200, epoch: 14 | loss: 0.3251455
	speed: 0.0173s/iter; left time: 384.4319s
Epoch: 14 cost time: 4.944336414337158
Epoch: 14, Steps: 258 | Train Loss: 0.4935678 Vali Loss: 0.2597826 Test Loss: 0.3522201
Validation loss decreased (0.260099 --> 0.259783).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.6057206
	speed: 0.0706s/iter; left time: 1558.4583s
	iters: 200, epoch: 15 | loss: 0.5090910
	speed: 0.0167s/iter; left time: 367.4607s
Epoch: 15 cost time: 4.728858947753906
Epoch: 15, Steps: 258 | Train Loss: 0.4933037 Vali Loss: 0.2603382 Test Loss: 0.3521074
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.5892527
	speed: 0.0721s/iter; left time: 1573.6999s
	iters: 200, epoch: 16 | loss: 0.4047326
	speed: 0.0174s/iter; left time: 377.7817s
Epoch: 16 cost time: 4.945387840270996
Epoch: 16, Steps: 258 | Train Loss: 0.4938206 Vali Loss: 0.2595310 Test Loss: 0.3522028
Validation loss decreased (0.259783 --> 0.259531).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4548028
	speed: 0.0738s/iter; left time: 1592.3421s
	iters: 200, epoch: 17 | loss: 0.6014223
	speed: 0.0174s/iter; left time: 374.6636s
Epoch: 17 cost time: 5.024093389511108
Epoch: 17, Steps: 258 | Train Loss: 0.4930181 Vali Loss: 0.2598670 Test Loss: 0.3520957
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3811699
	speed: 0.0931s/iter; left time: 1983.9294s
	iters: 200, epoch: 18 | loss: 0.5201380
	speed: 0.0187s/iter; left time: 396.1591s
Epoch: 18 cost time: 7.091737270355225
Epoch: 18, Steps: 258 | Train Loss: 0.4928626 Vali Loss: 0.2600218 Test Loss: 0.3520930
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3837002
	speed: 0.0703s/iter; left time: 1479.4594s
	iters: 200, epoch: 19 | loss: 0.6206863
	speed: 0.0161s/iter; left time: 337.3677s
Epoch: 19 cost time: 4.681890249252319
Epoch: 19, Steps: 258 | Train Loss: 0.4926040 Vali Loss: 0.2599890 Test Loss: 0.3520602
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4898207
	speed: 0.0949s/iter; left time: 1974.7219s
	iters: 200, epoch: 20 | loss: 0.6197878
	speed: 0.0173s/iter; left time: 359.0341s
Epoch: 20 cost time: 6.438081502914429
Epoch: 20, Steps: 258 | Train Loss: 0.4931413 Vali Loss: 0.2599315 Test Loss: 0.3519764
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.5144288
	speed: 0.0716s/iter; left time: 1471.1940s
	iters: 200, epoch: 21 | loss: 0.4896172
	speed: 0.0273s/iter; left time: 558.4845s
Epoch: 21 cost time: 5.917649507522583
Epoch: 21, Steps: 258 | Train Loss: 0.4935027 Vali Loss: 0.2599426 Test Loss: 0.3520602
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4660700
	speed: 0.0740s/iter; left time: 1501.2209s
	iters: 200, epoch: 22 | loss: 0.4915669
	speed: 0.0174s/iter; left time: 350.4908s
Epoch: 22 cost time: 5.075083494186401
Epoch: 22, Steps: 258 | Train Loss: 0.4933564 Vali Loss: 0.2599887 Test Loss: 0.3520173
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4200002
	speed: 0.0758s/iter; left time: 1517.6685s
	iters: 200, epoch: 23 | loss: 0.5070174
	speed: 0.0171s/iter; left time: 341.0923s
Epoch: 23 cost time: 4.858743667602539
Epoch: 23, Steps: 258 | Train Loss: 0.4934883 Vali Loss: 0.2597351 Test Loss: 0.3521453
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.5085968
	speed: 0.0774s/iter; left time: 1530.5402s
	iters: 200, epoch: 24 | loss: 0.4206325
	speed: 0.0171s/iter; left time: 335.3456s
Epoch: 24 cost time: 5.0308027267456055
Epoch: 24, Steps: 258 | Train Loss: 0.4933961 Vali Loss: 0.2599309 Test Loss: 0.3519487
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4313318
	speed: 0.0733s/iter; left time: 1430.3919s
	iters: 200, epoch: 25 | loss: 0.4036248
	speed: 0.0165s/iter; left time: 319.7103s
Epoch: 25 cost time: 4.781047821044922
Epoch: 25, Steps: 258 | Train Loss: 0.4929893 Vali Loss: 0.2599381 Test Loss: 0.3519243
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.5626751
	speed: 0.0708s/iter; left time: 1362.9681s
	iters: 200, epoch: 26 | loss: 0.4994898
	speed: 0.0252s/iter; left time: 481.7625s
Epoch: 26 cost time: 5.759972095489502
Epoch: 26, Steps: 258 | Train Loss: 0.4928460 Vali Loss: 0.2596596 Test Loss: 0.3521214
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.5466578
	speed: 0.0723s/iter; left time: 1372.4080s
	iters: 200, epoch: 27 | loss: 0.4834026
	speed: 0.0171s/iter; left time: 323.9648s
Epoch: 27 cost time: 4.873965501785278
Epoch: 27, Steps: 258 | Train Loss: 0.4925046 Vali Loss: 0.2597210 Test Loss: 0.3520357
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4992327
	speed: 0.0728s/iter; left time: 1363.5221s
	iters: 200, epoch: 28 | loss: 0.4480475
	speed: 0.0166s/iter; left time: 310.2451s
Epoch: 28 cost time: 4.806065559387207
Epoch: 28, Steps: 258 | Train Loss: 0.4929567 Vali Loss: 0.2598248 Test Loss: 0.3520447
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.5030663
	speed: 0.0701s/iter; left time: 1295.4895s
	iters: 200, epoch: 29 | loss: 0.4517396
	speed: 0.0182s/iter; left time: 334.6826s
Epoch: 29 cost time: 5.009487867355347
Epoch: 29, Steps: 258 | Train Loss: 0.4932960 Vali Loss: 0.2596646 Test Loss: 0.3520538
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3705320
	speed: 0.0753s/iter; left time: 1371.0349s
	iters: 200, epoch: 30 | loss: 0.3124050
	speed: 0.0165s/iter; left time: 299.1598s
Epoch: 30 cost time: 4.962884187698364
Epoch: 30, Steps: 258 | Train Loss: 0.4928038 Vali Loss: 0.2596348 Test Loss: 0.3520207
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3629012
	speed: 0.0704s/iter; left time: 1265.3050s
	iters: 200, epoch: 31 | loss: 0.5380489
	speed: 0.0165s/iter; left time: 294.8093s
Epoch: 31 cost time: 4.709903001785278
Epoch: 31, Steps: 258 | Train Loss: 0.4933383 Vali Loss: 0.2596547 Test Loss: 0.3519467
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4431271
	speed: 0.0701s/iter; left time: 1240.8819s
	iters: 200, epoch: 32 | loss: 0.4431604
	speed: 0.0169s/iter; left time: 296.9300s
Epoch: 32 cost time: 4.930328130722046
Epoch: 32, Steps: 258 | Train Loss: 0.4932748 Vali Loss: 0.2598533 Test Loss: 0.3519366
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.6386969
	speed: 0.0730s/iter; left time: 1274.0659s
	iters: 200, epoch: 33 | loss: 0.4523694
	speed: 0.0173s/iter; left time: 299.5455s
Epoch: 33 cost time: 4.98283576965332
Epoch: 33, Steps: 258 | Train Loss: 0.4925082 Vali Loss: 0.2598514 Test Loss: 0.3519625
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.5347144
	speed: 0.0712s/iter; left time: 1223.7677s
	iters: 200, epoch: 34 | loss: 0.3967980
	speed: 0.0171s/iter; left time: 292.5660s
Epoch: 34 cost time: 4.891739130020142
Epoch: 34, Steps: 258 | Train Loss: 0.4924294 Vali Loss: 0.2599582 Test Loss: 0.3519429
EarlyStopping counter: 18 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3732195
	speed: 0.0718s/iter; left time: 1214.8357s
	iters: 200, epoch: 35 | loss: 0.3455530
	speed: 0.0171s/iter; left time: 287.1747s
Epoch: 35 cost time: 4.827935457229614
Epoch: 35, Steps: 258 | Train Loss: 0.4933510 Vali Loss: 0.2597537 Test Loss: 0.3519838
EarlyStopping counter: 19 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4081708
	speed: 0.0866s/iter; left time: 1444.1751s
	iters: 200, epoch: 36 | loss: 0.4023203
	speed: 0.0244s/iter; left time: 404.8714s
Epoch: 36 cost time: 7.496055364608765
Epoch: 36, Steps: 258 | Train Loss: 0.4932838 Vali Loss: 0.2597745 Test Loss: 0.3519995
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_720_720_FITS_ETTm2_ftM_sl720_ll48_pl720_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.34886401891708374, mae:0.37787947058677673, rse:0.47475823760032654, corr:[0.54564476 0.5456929  0.54158306 0.5399446  0.5407088  0.54140085
 0.54056627 0.5391558  0.5384336  0.5385674  0.5387953  0.5384229
 0.53771603 0.5373294  0.5375219  0.53775877 0.5373469  0.53617126
 0.5348105  0.5339136  0.5336486  0.5335879  0.5332239  0.53245944
 0.53160346 0.5310347  0.5307852  0.53056365 0.5300809  0.5293851
 0.528739   0.52840364 0.52825505 0.5279404  0.52730614 0.52648896
 0.52569884 0.5250916  0.52459264 0.5240764  0.52346456 0.52278227
 0.52217865 0.52169275 0.52124834 0.5206833  0.51996064 0.5191656
 0.51838106 0.51765347 0.5169766  0.5163105  0.51557446 0.5148105
 0.5141443  0.5136408  0.5132009  0.5127074  0.51215917 0.5116279
 0.5112575  0.51111317 0.51109    0.5110006  0.5107922  0.5105704
 0.51033205 0.51011753 0.50983983 0.5094393  0.50897163 0.50858283
 0.5083459  0.5081688  0.5078407  0.50729084 0.50663084 0.50602376
 0.5055862  0.5052023  0.5046262  0.5038224  0.50293285 0.5021915
 0.50175506 0.5015494  0.5013037  0.50090945 0.5003654  0.49980792
 0.4993629  0.49897894 0.4984754  0.4977427  0.49673468 0.49549857
 0.49412572 0.4927083  0.49119952 0.48966014 0.4882493  0.48706058
 0.48605013 0.48502928 0.48381355 0.48239794 0.48098335 0.47982994
 0.47900543 0.47847039 0.47808206 0.47766307 0.477153   0.47646675
 0.47559956 0.47465092 0.47372743 0.47285497 0.4720617  0.47123417
 0.47035736 0.46937996 0.4684131  0.46755043 0.46685904 0.46626192
 0.46561846 0.46475777 0.46363482 0.46238917 0.4612987  0.46050802
 0.45996007 0.45945698 0.45890385 0.45832312 0.457773   0.45727038
 0.4566698  0.4558478  0.4548141  0.45382068 0.4531603  0.4528083
 0.45250618 0.45187753 0.45091003 0.44973204 0.44863313 0.4477308
 0.4469958  0.4462864  0.44546953 0.44467708 0.4441415  0.44387046
 0.4436082  0.44308704 0.4422416  0.4414185  0.44091803 0.44085932
 0.4409724  0.4409518  0.44060203 0.43997443 0.43928656 0.43881908
 0.43865755 0.43868682 0.43864033 0.43841732 0.43795475 0.4372642
 0.43638667 0.43545213 0.4346323  0.43403286 0.4335705  0.43308195
 0.43230644 0.43126985 0.4303326  0.42982012 0.4297706  0.42987323
 0.42974356 0.42915127 0.4282302  0.4272657  0.4264272  0.42553955
 0.42431712 0.4227426  0.42083964 0.4189966  0.41765893 0.4167969
 0.41608375 0.41512942 0.41385067 0.41243866 0.41116035 0.41010347
 0.4091087  0.4079525  0.40657672 0.40517056 0.40406358 0.40336162
 0.40272266 0.40189198 0.4008544  0.3997744  0.3988718  0.39814007
 0.39748722 0.39673907 0.3959085  0.3949212  0.3937514  0.392491
 0.3912993  0.3903717  0.38980103 0.38927984 0.38853276 0.38743082
 0.38595763 0.38441935 0.38313678 0.38225207 0.38163817 0.3811146
 0.38052315 0.37992835 0.3794022  0.3789514  0.37852967 0.37799016
 0.37731075 0.37652454 0.37582222 0.3754288  0.37515876 0.37498018
 0.37492454 0.3751072  0.375476   0.375779   0.37581462 0.3754069
 0.37469348 0.37411448 0.3738645  0.37390998 0.37387577 0.3735396
 0.37288523 0.3721831  0.3716793  0.37144035 0.37125254 0.3710421
 0.37087303 0.37086025 0.37107795 0.37125984 0.37098992 0.37009102
 0.36896795 0.3681774  0.36792836 0.368007   0.3678565  0.36715522
 0.36620045 0.36545935 0.36531413 0.36572406 0.36611265 0.36610606
 0.36565202 0.36510035 0.36476645 0.36456347 0.36410666 0.36299965
 0.36144453 0.3601047  0.35933194 0.3590479  0.35889    0.3584599
 0.35780087 0.3570203  0.35620326 0.3553406  0.3543827  0.35326678
 0.35229316 0.35164657 0.35145068 0.35129574 0.35089812 0.35017458
 0.34943083 0.34894124 0.34887362 0.34901652 0.34896946 0.34861428
 0.34795177 0.34739172 0.34713724 0.3471027  0.34704798 0.34681705
 0.34639102 0.3460523  0.34603623 0.34627908 0.34650278 0.34650564
 0.34623152 0.3458639  0.34560356 0.34547323 0.34552634 0.3456023
 0.34570315 0.34567523 0.34547675 0.34519538 0.34489018 0.34481174
 0.34497127 0.3451676  0.3452868  0.3452566  0.34503922 0.34474373
 0.34462827 0.34475413 0.34488338 0.34470293 0.34411028 0.34337208
 0.34285402 0.3428333  0.3432172  0.34366906 0.34393936 0.34394497
 0.34379658 0.3436316  0.3433463  0.3429389  0.34228733 0.34166175
 0.3413006  0.341243   0.34125847 0.3410528  0.34047797 0.33981192
 0.3393176  0.3392551  0.3395177  0.33987352 0.34016022 0.3402796
 0.34033224 0.3404389  0.340578   0.34065458 0.34062874 0.34063518
 0.34079653 0.34105656 0.34121573 0.34108555 0.3407737  0.34027788
 0.33970955 0.33902293 0.3381798  0.33722576 0.33635247 0.33583212
 0.3354961  0.3349794  0.33399338 0.33267677 0.33154002 0.33100435
 0.33104467 0.3312014  0.33082905 0.32976848 0.3285001  0.32758412
 0.3273262  0.32747912 0.3276085  0.32745963 0.3270062  0.32658398
 0.3263568  0.3263031  0.3261036  0.3255288  0.32478324 0.32419714
 0.3240888  0.32437176 0.32466358 0.32472393 0.32456008 0.324422
 0.32448843 0.32462808 0.32455105 0.3241839  0.32372627 0.32350063
 0.3236591  0.32398257 0.3242128  0.32421696 0.3241866  0.32441023
 0.3249344  0.32538825 0.32545328 0.32503456 0.32438713 0.32389045
 0.3237421  0.32400188 0.32424074 0.32405812 0.32345298 0.3227494
 0.3221206  0.32168514 0.32130063 0.32080936 0.3202798  0.3198194
 0.31957024 0.31946534 0.31935912 0.31908798 0.31875965 0.31857088
 0.31852338 0.3184396  0.3180818  0.3174395  0.31684586 0.31647143
 0.31644174 0.3165683  0.31648633 0.31597722 0.3151279  0.3143129
 0.31391788 0.3140161  0.3143286  0.31448168 0.31432337 0.31381956
 0.31310537 0.31227723 0.31151968 0.3108406  0.31022823 0.30954838
 0.3086436  0.3075447  0.3062398  0.30490437 0.30373764 0.3027655
 0.3018318  0.3008604  0.29980412 0.29884732 0.29805353 0.29737657
 0.29669833 0.2959823  0.2952119  0.29441804 0.29379416 0.29340315
 0.293134   0.29272097 0.29204795 0.29127166 0.2904956  0.2898914
 0.28929716 0.2886137  0.2878924  0.2872549  0.28692627 0.2868834
 0.28691876 0.28679615 0.286396   0.28583133 0.28531954 0.2849394
 0.28459513 0.2841422  0.28377172 0.28351894 0.28341073 0.28340623
 0.28332138 0.28305498 0.28256643 0.28204924 0.28176463 0.2817349
 0.28178078 0.2817142  0.28143162 0.28103793 0.28072253 0.2805498
 0.2804437  0.2803454  0.28032443 0.28034014 0.28030196 0.2800941
 0.27962658 0.27900055 0.2784186  0.2781635  0.27825582 0.27845255
 0.27852517 0.2783861  0.27805966 0.2776688  0.27725345 0.2768937
 0.27653694 0.276268   0.2761824  0.27630934 0.27638048 0.27630493
 0.27593228 0.27536228 0.27468157 0.27404866 0.27359354 0.27331612
 0.27318463 0.27313545 0.27318776 0.27328938 0.27334002 0.27323556
 0.27289578 0.27239278 0.2718208  0.27132556 0.2708808  0.27019772
 0.26909545 0.26781178 0.26653132 0.26540726 0.26445255 0.26363122
 0.2628471  0.26197758 0.26100022 0.25996217 0.2589333  0.25805432
 0.25732532 0.25668147 0.25616595 0.25571993 0.2552785  0.25480425
 0.25418654 0.2533501  0.25246403 0.25165257 0.25114024 0.25094876
 0.25090107 0.2508833  0.25069493 0.25031793 0.24996278 0.24971971
 0.24943735 0.24907789 0.24875668 0.24852268 0.24855815 0.24884836
 0.24925873 0.24934748 0.24904789 0.2485978  0.24825422 0.24816622
 0.24831708 0.24861023 0.24880843 0.24891965 0.2490971  0.24955492
 0.25025573 0.2509728  0.25144547 0.25154343 0.2512041  0.2505871
 0.24999136 0.24980892 0.2502112  0.25082272 0.25149086 0.2518465
 0.25178882 0.25145224 0.2508992  0.25036123 0.24969614 0.24902536
 0.24854442 0.24859422 0.2490328  0.2494304  0.24960549 0.24923113
 0.24863638 0.2481936  0.24816114 0.24838564 0.24859574 0.24836425
 0.247887   0.24740145 0.2471046  0.24718851 0.24750471 0.2477578
 0.24781162 0.24787578 0.24786922 0.24776414 0.24766073 0.24760784
 0.2476828  0.24799389 0.24835086 0.24832565 0.24766316 0.24647737
 0.24511953 0.24395135 0.24307214 0.24230167 0.24152456 0.24062733
 0.23968889 0.23884623 0.23841259 0.23813348 0.23787032 0.23748107
 0.23699722 0.23649706 0.23597865 0.23537977 0.23480998 0.23419246
 0.23360208 0.23297848 0.2321721  0.23138097 0.23062485 0.23001987
 0.22968942 0.22948442 0.22926028 0.2287312  0.22797443 0.22714834
 0.22649683 0.2258064  0.22513723 0.2247009  0.22469707 0.22509046
 0.22531445 0.2248591  0.22367626 0.22266276 0.2224855  0.22320272
 0.22355944 0.22236355 0.22023787 0.21964094 0.22173643 0.22170436]
