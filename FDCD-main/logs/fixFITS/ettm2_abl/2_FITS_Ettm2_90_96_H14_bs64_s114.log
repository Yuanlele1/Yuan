Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=24, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_90_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_90_96_FITS_ETTm2_ftM_sl90_ll48_pl96_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34375
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=24, out_features=49, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1053696.0
params:  1225.0
Trainable parameters:  1225
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2146071
	speed: 0.0460s/iter; left time: 1227.1424s
	iters: 200, epoch: 1 | loss: 0.1773090
	speed: 0.0270s/iter; left time: 718.2339s
Epoch: 1 cost time: 10.114585161209106
Epoch: 1, Steps: 268 | Train Loss: 0.2104356 Vali Loss: 0.1541816 Test Loss: 0.2163618
Validation loss decreased (inf --> 0.154182).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1491112
	speed: 0.1723s/iter; left time: 4553.8547s
	iters: 200, epoch: 2 | loss: 0.1212960
	speed: 0.0538s/iter; left time: 1417.1008s
Epoch: 2 cost time: 13.822747230529785
Epoch: 2, Steps: 268 | Train Loss: 0.1581982 Vali Loss: 0.1429341 Test Loss: 0.2008350
Validation loss decreased (0.154182 --> 0.142934).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1411093
	speed: 0.2081s/iter; left time: 5443.9224s
	iters: 200, epoch: 3 | loss: 0.1871715
	speed: 0.0448s/iter; left time: 1167.8340s
Epoch: 3 cost time: 12.82810091972351
Epoch: 3, Steps: 268 | Train Loss: 0.1429823 Vali Loss: 0.1381775 Test Loss: 0.1944336
Validation loss decreased (0.142934 --> 0.138178).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1143971
	speed: 0.1716s/iter; left time: 4443.3096s
	iters: 200, epoch: 4 | loss: 0.1384605
	speed: 0.0202s/iter; left time: 521.7688s
Epoch: 4 cost time: 6.984206199645996
Epoch: 4, Steps: 268 | Train Loss: 0.1364501 Vali Loss: 0.1350876 Test Loss: 0.1907450
Validation loss decreased (0.138178 --> 0.135088).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1224577
	speed: 0.1515s/iter; left time: 3882.9838s
	iters: 200, epoch: 5 | loss: 0.1225326
	speed: 0.0172s/iter; left time: 440.3125s
Epoch: 5 cost time: 6.157862186431885
Epoch: 5, Steps: 268 | Train Loss: 0.1330505 Vali Loss: 0.1330741 Test Loss: 0.1882792
Validation loss decreased (0.135088 --> 0.133074).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.0943141
	speed: 0.1181s/iter; left time: 2995.6247s
	iters: 200, epoch: 6 | loss: 0.1263470
	speed: 0.0176s/iter; left time: 444.8479s
Epoch: 6 cost time: 7.309177875518799
Epoch: 6, Steps: 268 | Train Loss: 0.1309397 Vali Loss: 0.1318919 Test Loss: 0.1867972
Validation loss decreased (0.133074 --> 0.131892).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1374402
	speed: 0.2150s/iter; left time: 5395.2209s
	iters: 200, epoch: 7 | loss: 0.1228893
	speed: 0.0364s/iter; left time: 908.5395s
Epoch: 7 cost time: 11.120818138122559
Epoch: 7, Steps: 268 | Train Loss: 0.1296550 Vali Loss: 0.1311649 Test Loss: 0.1859969
Validation loss decreased (0.131892 --> 0.131165).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1360685
	speed: 0.2154s/iter; left time: 5347.6859s
	iters: 200, epoch: 8 | loss: 0.1767233
	speed: 0.0265s/iter; left time: 656.1146s
Epoch: 8 cost time: 9.744337558746338
Epoch: 8, Steps: 268 | Train Loss: 0.1292059 Vali Loss: 0.1306579 Test Loss: 0.1854165
Validation loss decreased (0.131165 --> 0.130658).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1881591
	speed: 0.1477s/iter; left time: 3626.5934s
	iters: 200, epoch: 9 | loss: 0.0809700
	speed: 0.0358s/iter; left time: 876.3209s
Epoch: 9 cost time: 11.040500402450562
Epoch: 9, Steps: 268 | Train Loss: 0.1287123 Vali Loss: 0.1305251 Test Loss: 0.1852353
Validation loss decreased (0.130658 --> 0.130525).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1220806
	speed: 0.1500s/iter; left time: 3644.2064s
	iters: 200, epoch: 10 | loss: 0.1003467
	speed: 0.0214s/iter; left time: 516.5075s
Epoch: 10 cost time: 8.371771574020386
Epoch: 10, Steps: 268 | Train Loss: 0.1287294 Vali Loss: 0.1302312 Test Loss: 0.1850136
Validation loss decreased (0.130525 --> 0.130231).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2040512
	speed: 0.1226s/iter; left time: 2944.2354s
	iters: 200, epoch: 11 | loss: 0.0839835
	speed: 0.0399s/iter; left time: 954.1579s
Epoch: 11 cost time: 10.582529306411743
Epoch: 11, Steps: 268 | Train Loss: 0.1285288 Vali Loss: 0.1301799 Test Loss: 0.1849402
Validation loss decreased (0.130231 --> 0.130180).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1495599
	speed: 0.2033s/iter; left time: 4829.3677s
	iters: 200, epoch: 12 | loss: 0.1296741
	speed: 0.0339s/iter; left time: 800.6753s
Epoch: 12 cost time: 9.565307378768921
Epoch: 12, Steps: 268 | Train Loss: 0.1285546 Vali Loss: 0.1302405 Test Loss: 0.1849788
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1103678
	speed: 0.1436s/iter; left time: 3373.3781s
	iters: 200, epoch: 13 | loss: 0.0939184
	speed: 0.0318s/iter; left time: 743.3035s
Epoch: 13 cost time: 7.226649045944214
Epoch: 13, Steps: 268 | Train Loss: 0.1284416 Vali Loss: 0.1302247 Test Loss: 0.1849336
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.0948904
	speed: 0.1292s/iter; left time: 2999.5325s
	iters: 200, epoch: 14 | loss: 0.1106237
	speed: 0.0306s/iter; left time: 708.1653s
Epoch: 14 cost time: 9.387038469314575
Epoch: 14, Steps: 268 | Train Loss: 0.1283296 Vali Loss: 0.1301842 Test Loss: 0.1849717
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1534244
	speed: 0.1733s/iter; left time: 3977.5301s
	iters: 200, epoch: 15 | loss: 0.1142742
	speed: 0.0198s/iter; left time: 453.4806s
Epoch: 15 cost time: 8.908295631408691
Epoch: 15, Steps: 268 | Train Loss: 0.1284591 Vali Loss: 0.1300715 Test Loss: 0.1849042
Validation loss decreased (0.130180 --> 0.130071).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1179902
	speed: 0.1899s/iter; left time: 4308.1946s
	iters: 200, epoch: 16 | loss: 0.1320705
	speed: 0.0379s/iter; left time: 856.5967s
Epoch: 16 cost time: 11.213166952133179
Epoch: 16, Steps: 268 | Train Loss: 0.1284856 Vali Loss: 0.1302153 Test Loss: 0.1849457
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1109438
	speed: 0.1414s/iter; left time: 3169.0263s
	iters: 200, epoch: 17 | loss: 0.1481003
	speed: 0.0282s/iter; left time: 628.9902s
Epoch: 17 cost time: 7.702017784118652
Epoch: 17, Steps: 268 | Train Loss: 0.1284335 Vali Loss: 0.1302199 Test Loss: 0.1849480
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1747519
	speed: 0.1440s/iter; left time: 3188.2463s
	iters: 200, epoch: 18 | loss: 0.1663127
	speed: 0.0322s/iter; left time: 710.8152s
Epoch: 18 cost time: 8.290050029754639
Epoch: 18, Steps: 268 | Train Loss: 0.1283527 Vali Loss: 0.1301396 Test Loss: 0.1849359
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1464204
	speed: 0.1295s/iter; left time: 2833.9849s
	iters: 200, epoch: 19 | loss: 0.1010963
	speed: 0.0403s/iter; left time: 876.5445s
Epoch: 19 cost time: 10.36617374420166
Epoch: 19, Steps: 268 | Train Loss: 0.1283771 Vali Loss: 0.1303370 Test Loss: 0.1849789
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.0840833
	speed: 0.1902s/iter; left time: 4109.9972s
	iters: 200, epoch: 20 | loss: 0.1195136
	speed: 0.0223s/iter; left time: 478.7611s
Epoch: 20 cost time: 11.08215045928955
Epoch: 20, Steps: 268 | Train Loss: 0.1283680 Vali Loss: 0.1301207 Test Loss: 0.1849094
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1062691
	speed: 0.1494s/iter; left time: 3187.9072s
	iters: 200, epoch: 21 | loss: 0.1495344
	speed: 0.0486s/iter; left time: 1032.0161s
Epoch: 21 cost time: 11.86722993850708
Epoch: 21, Steps: 268 | Train Loss: 0.1284548 Vali Loss: 0.1304023 Test Loss: 0.1850232
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1211766
	speed: 0.1395s/iter; left time: 2939.7654s
	iters: 200, epoch: 22 | loss: 0.0835080
	speed: 0.0305s/iter; left time: 640.4300s
Epoch: 22 cost time: 9.474347352981567
Epoch: 22, Steps: 268 | Train Loss: 0.1283369 Vali Loss: 0.1303667 Test Loss: 0.1850150
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1357895
	speed: 0.1588s/iter; left time: 3302.9823s
	iters: 200, epoch: 23 | loss: 0.1012249
	speed: 0.0213s/iter; left time: 440.9075s
Epoch: 23 cost time: 7.703723907470703
Epoch: 23, Steps: 268 | Train Loss: 0.1283942 Vali Loss: 0.1303600 Test Loss: 0.1849605
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.0854537
	speed: 0.1360s/iter; left time: 2793.7830s
	iters: 200, epoch: 24 | loss: 0.1100283
	speed: 0.0227s/iter; left time: 464.5242s
Epoch: 24 cost time: 7.342087984085083
Epoch: 24, Steps: 268 | Train Loss: 0.1283806 Vali Loss: 0.1302383 Test Loss: 0.1849851
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1253461
	speed: 0.1310s/iter; left time: 2655.7596s
	iters: 200, epoch: 25 | loss: 0.0968111
	speed: 0.0378s/iter; left time: 763.1994s
Epoch: 25 cost time: 9.154495239257812
Epoch: 25, Steps: 268 | Train Loss: 0.1283713 Vali Loss: 0.1303419 Test Loss: 0.1850067
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1029488
	speed: 0.1608s/iter; left time: 3215.6677s
	iters: 200, epoch: 26 | loss: 0.1530216
	speed: 0.0439s/iter; left time: 873.0395s
Epoch: 26 cost time: 11.592825412750244
Epoch: 26, Steps: 268 | Train Loss: 0.1283970 Vali Loss: 0.1302186 Test Loss: 0.1849504
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1107938
	speed: 0.1865s/iter; left time: 3680.7045s
	iters: 200, epoch: 27 | loss: 0.1067904
	speed: 0.0302s/iter; left time: 592.4037s
Epoch: 27 cost time: 9.118708610534668
Epoch: 27, Steps: 268 | Train Loss: 0.1282963 Vali Loss: 0.1303408 Test Loss: 0.1849792
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1726392
	speed: 0.1556s/iter; left time: 3028.3981s
	iters: 200, epoch: 28 | loss: 0.1262835
	speed: 0.0348s/iter; left time: 673.5452s
Epoch: 28 cost time: 9.600549459457397
Epoch: 28, Steps: 268 | Train Loss: 0.1282918 Vali Loss: 0.1302869 Test Loss: 0.1849788
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1072414
	speed: 0.1402s/iter; left time: 2690.4922s
	iters: 200, epoch: 29 | loss: 0.0934929
	speed: 0.0392s/iter; left time: 748.1753s
Epoch: 29 cost time: 10.361009120941162
Epoch: 29, Steps: 268 | Train Loss: 0.1282701 Vali Loss: 0.1303217 Test Loss: 0.1849784
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1476899
	speed: 0.1302s/iter; left time: 2464.3215s
	iters: 200, epoch: 30 | loss: 0.0841354
	speed: 0.0298s/iter; left time: 560.2534s
Epoch: 30 cost time: 9.480641603469849
Epoch: 30, Steps: 268 | Train Loss: 0.1283193 Vali Loss: 0.1303021 Test Loss: 0.1849709
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1469560
	speed: 0.1666s/iter; left time: 3108.6029s
	iters: 200, epoch: 31 | loss: 0.1419396
	speed: 0.0451s/iter; left time: 837.4251s
Epoch: 31 cost time: 11.272647857666016
Epoch: 31, Steps: 268 | Train Loss: 0.1281274 Vali Loss: 0.1303481 Test Loss: 0.1849771
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1130654
	speed: 0.1990s/iter; left time: 3659.7207s
	iters: 200, epoch: 32 | loss: 0.1297417
	speed: 0.0347s/iter; left time: 634.8295s
Epoch: 32 cost time: 10.034542560577393
Epoch: 32, Steps: 268 | Train Loss: 0.1282700 Vali Loss: 0.1303699 Test Loss: 0.1849894
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1005278
	speed: 0.1611s/iter; left time: 2920.2815s
	iters: 200, epoch: 33 | loss: 0.1578838
	speed: 0.0391s/iter; left time: 705.3941s
Epoch: 33 cost time: 8.346012115478516
Epoch: 33, Steps: 268 | Train Loss: 0.1283729 Vali Loss: 0.1303668 Test Loss: 0.1849795
EarlyStopping counter: 18 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.0988296
	speed: 0.1149s/iter; left time: 2051.2705s
	iters: 200, epoch: 34 | loss: 0.0922436
	speed: 0.0278s/iter; left time: 494.0638s
Epoch: 34 cost time: 7.381089687347412
Epoch: 34, Steps: 268 | Train Loss: 0.1283613 Vali Loss: 0.1304290 Test Loss: 0.1849909
EarlyStopping counter: 19 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1069824
	speed: 0.1910s/iter; left time: 3359.9155s
	iters: 200, epoch: 35 | loss: 0.1420143
	speed: 0.0312s/iter; left time: 546.3932s
Epoch: 35 cost time: 14.001742839813232
Epoch: 35, Steps: 268 | Train Loss: 0.1283840 Vali Loss: 0.1303757 Test Loss: 0.1849699
EarlyStopping counter: 20 out of 20
Early stopping
train 34375
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=24, out_features=49, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1053696.0
params:  1225.0
Trainable parameters:  1225
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2777322
	speed: 0.0416s/iter; left time: 1112.0236s
	iters: 200, epoch: 1 | loss: 0.2049486
	speed: 0.0303s/iter; left time: 807.0426s
Epoch: 1 cost time: 11.129415273666382
Epoch: 1, Steps: 268 | Train Loss: 0.2415400 Vali Loss: 0.1297644 Test Loss: 0.1843778
Validation loss decreased (inf --> 0.129764).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2073717
	speed: 0.1895s/iter; left time: 5009.8865s
	iters: 200, epoch: 2 | loss: 0.2110878
	speed: 0.0309s/iter; left time: 814.1509s
Epoch: 2 cost time: 12.887198209762573
Epoch: 2, Steps: 268 | Train Loss: 0.2407655 Vali Loss: 0.1297400 Test Loss: 0.1841961
Validation loss decreased (0.129764 --> 0.129740).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2842593
	speed: 0.1475s/iter; left time: 3858.9991s
	iters: 200, epoch: 3 | loss: 0.2623907
	speed: 0.0338s/iter; left time: 880.5254s
Epoch: 3 cost time: 9.120163440704346
Epoch: 3, Steps: 268 | Train Loss: 0.2405574 Vali Loss: 0.1300370 Test Loss: 0.1843604
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2571800
	speed: 0.1452s/iter; left time: 3760.8445s
	iters: 200, epoch: 4 | loss: 0.1822544
	speed: 0.0305s/iter; left time: 787.6777s
Epoch: 4 cost time: 8.950469255447388
Epoch: 4, Steps: 268 | Train Loss: 0.2404666 Vali Loss: 0.1297436 Test Loss: 0.1842185
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2590201
	speed: 0.1365s/iter; left time: 3498.5537s
	iters: 200, epoch: 5 | loss: 0.1796459
	speed: 0.0340s/iter; left time: 867.7706s
Epoch: 5 cost time: 8.346184253692627
Epoch: 5, Steps: 268 | Train Loss: 0.2404682 Vali Loss: 0.1298944 Test Loss: 0.1842147
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1754467
	speed: 0.1843s/iter; left time: 4674.9016s
	iters: 200, epoch: 6 | loss: 0.3580289
	speed: 0.0252s/iter; left time: 637.7309s
Epoch: 6 cost time: 9.33591890335083
Epoch: 6, Steps: 268 | Train Loss: 0.2402205 Vali Loss: 0.1298357 Test Loss: 0.1841621
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2588721
	speed: 0.1666s/iter; left time: 4180.5207s
	iters: 200, epoch: 7 | loss: 0.2278733
	speed: 0.0265s/iter; left time: 663.2059s
Epoch: 7 cost time: 8.031145572662354
Epoch: 7, Steps: 268 | Train Loss: 0.2397892 Vali Loss: 0.1298110 Test Loss: 0.1841387
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2024298
	speed: 0.1239s/iter; left time: 3075.6942s
	iters: 200, epoch: 8 | loss: 0.2271162
	speed: 0.0209s/iter; left time: 516.2234s
Epoch: 8 cost time: 6.451373338699341
Epoch: 8, Steps: 268 | Train Loss: 0.2402193 Vali Loss: 0.1300065 Test Loss: 0.1842845
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2247052
	speed: 0.1090s/iter; left time: 2676.5240s
	iters: 200, epoch: 9 | loss: 0.2754335
	speed: 0.0206s/iter; left time: 504.2193s
Epoch: 9 cost time: 6.991866588592529
Epoch: 9, Steps: 268 | Train Loss: 0.2399327 Vali Loss: 0.1301144 Test Loss: 0.1842486
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2338595
	speed: 0.1712s/iter; left time: 4157.3677s
	iters: 200, epoch: 10 | loss: 0.2112950
	speed: 0.0621s/iter; left time: 1501.3156s
Epoch: 10 cost time: 13.448184490203857
Epoch: 10, Steps: 268 | Train Loss: 0.2403156 Vali Loss: 0.1299726 Test Loss: 0.1842348
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2174255
	speed: 0.1459s/iter; left time: 3505.3283s
	iters: 200, epoch: 11 | loss: 0.1835295
	speed: 0.0471s/iter; left time: 1125.5427s
Epoch: 11 cost time: 11.055608034133911
Epoch: 11, Steps: 268 | Train Loss: 0.2401904 Vali Loss: 0.1299520 Test Loss: 0.1841259
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1680023
	speed: 0.1558s/iter; left time: 3700.1118s
	iters: 200, epoch: 12 | loss: 0.2609529
	speed: 0.0286s/iter; left time: 677.0151s
Epoch: 12 cost time: 7.784954309463501
Epoch: 12, Steps: 268 | Train Loss: 0.2400811 Vali Loss: 0.1299653 Test Loss: 0.1841585
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1730606
	speed: 0.1481s/iter; left time: 3478.8235s
	iters: 200, epoch: 13 | loss: 0.2023445
	speed: 0.0563s/iter; left time: 1316.4325s
Epoch: 13 cost time: 14.461901664733887
Epoch: 13, Steps: 268 | Train Loss: 0.2401556 Vali Loss: 0.1300798 Test Loss: 0.1842129
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1576606
	speed: 0.2024s/iter; left time: 4699.3592s
	iters: 200, epoch: 14 | loss: 0.3380723
	speed: 0.0523s/iter; left time: 1208.9646s
Epoch: 14 cost time: 10.89258861541748
Epoch: 14, Steps: 268 | Train Loss: 0.2399870 Vali Loss: 0.1298702 Test Loss: 0.1841497
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2337251
	speed: 0.1796s/iter; left time: 4122.3902s
	iters: 200, epoch: 15 | loss: 0.2521780
	speed: 0.0353s/iter; left time: 806.0688s
Epoch: 15 cost time: 10.078153610229492
Epoch: 15, Steps: 268 | Train Loss: 0.2402063 Vali Loss: 0.1298993 Test Loss: 0.1841515
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1455594
	speed: 0.1413s/iter; left time: 3205.6694s
	iters: 200, epoch: 16 | loss: 0.2043150
	speed: 0.0172s/iter; left time: 388.4278s
Epoch: 16 cost time: 7.46096658706665
Epoch: 16, Steps: 268 | Train Loss: 0.2398266 Vali Loss: 0.1299701 Test Loss: 0.1841120
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2899281
	speed: 0.1643s/iter; left time: 3683.4856s
	iters: 200, epoch: 17 | loss: 0.1612823
	speed: 0.0203s/iter; left time: 452.0038s
Epoch: 17 cost time: 8.074498176574707
Epoch: 17, Steps: 268 | Train Loss: 0.2399804 Vali Loss: 0.1299263 Test Loss: 0.1841358
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2489133
	speed: 0.1832s/iter; left time: 4056.4455s
	iters: 200, epoch: 18 | loss: 0.2883485
	speed: 0.0466s/iter; left time: 1027.8271s
Epoch: 18 cost time: 12.103742361068726
Epoch: 18, Steps: 268 | Train Loss: 0.2400214 Vali Loss: 0.1299028 Test Loss: 0.1840724
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1977203
	speed: 0.1582s/iter; left time: 3461.6094s
	iters: 200, epoch: 19 | loss: 0.2460913
	speed: 0.0269s/iter; left time: 585.2253s
Epoch: 19 cost time: 10.37119746208191
Epoch: 19, Steps: 268 | Train Loss: 0.2398297 Vali Loss: 0.1299636 Test Loss: 0.1841744
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1982155
	speed: 0.1888s/iter; left time: 4080.4327s
	iters: 200, epoch: 20 | loss: 0.1679330
	speed: 0.0244s/iter; left time: 524.1426s
Epoch: 20 cost time: 10.525399208068848
Epoch: 20, Steps: 268 | Train Loss: 0.2399193 Vali Loss: 0.1298909 Test Loss: 0.1841095
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1975484
	speed: 0.1317s/iter; left time: 2810.2973s
	iters: 200, epoch: 21 | loss: 0.2497257
	speed: 0.0277s/iter; left time: 587.3542s
Epoch: 21 cost time: 8.014045715332031
Epoch: 21, Steps: 268 | Train Loss: 0.2400365 Vali Loss: 0.1299426 Test Loss: 0.1841243
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2409104
	speed: 0.1376s/iter; left time: 2900.5248s
	iters: 200, epoch: 22 | loss: 0.2866394
	speed: 0.0275s/iter; left time: 576.1635s
Epoch: 22 cost time: 9.203420162200928
Epoch: 22, Steps: 268 | Train Loss: 0.2399431 Vali Loss: 0.1298967 Test Loss: 0.1841455
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_90_96_FITS_ETTm2_ftM_sl90_ll48_pl96_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.1850477010011673, mae:0.2686539590358734, rse:0.3487691283226013, corr:[0.57422346 0.5724678  0.5661053  0.5643591  0.5641502  0.5619485
 0.56024283 0.5603056  0.5598374  0.55829847 0.5573278  0.5569057
 0.55586183 0.5547412  0.5544762  0.5540534  0.5526784  0.55142117
 0.5510068  0.5503451  0.54891044 0.5477683  0.5473347  0.5468053
 0.545844   0.5451345  0.54495203 0.5445685  0.5439121  0.5435516
 0.5431006  0.54219574 0.54121196 0.54074806 0.5403754  0.5396389
 0.5388167  0.5384182  0.5380477  0.53723615 0.5362809  0.53585523
 0.5357628  0.53555816 0.5351551  0.53452    0.53373647 0.53291816
 0.5322824  0.5316256  0.5306933  0.5298399  0.5293194  0.52881527
 0.52808756 0.52724046 0.5265655  0.5260796  0.5255053  0.5252082
 0.52524424 0.5252868  0.52504057 0.5247959  0.52474266 0.52471405
 0.52458596 0.524441   0.5244955  0.5245333  0.5244463  0.52453035
 0.5247971  0.5250059  0.5248741  0.5247303  0.5248569  0.5249127
 0.5247635  0.5246518  0.5247018  0.5246443  0.5244259  0.5242805
 0.52433586 0.52435595 0.524159   0.523927   0.5237588  0.52359504
 0.52350396 0.5236292  0.5236169  0.52345544 0.5230442  0.52151394]
