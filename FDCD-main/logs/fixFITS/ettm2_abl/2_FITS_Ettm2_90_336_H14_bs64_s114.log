Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=24, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_90_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_90_336_FITS_ETTm2_ftM_sl90_ll48_pl336_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=24, out_features=113, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2429952.0
params:  2825.0
Trainable parameters:  2825
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5222192
	speed: 0.0389s/iter; left time: 1031.3768s
	iters: 200, epoch: 1 | loss: 0.4027198
	speed: 0.0399s/iter; left time: 1052.1718s
Epoch: 1 cost time: 9.666604280471802
Epoch: 1, Steps: 266 | Train Loss: 0.4618244 Vali Loss: 0.2491038 Test Loss: 0.3456783
Validation loss decreased (inf --> 0.249104).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5240587
	speed: 0.1119s/iter; left time: 2936.5973s
	iters: 200, epoch: 2 | loss: 0.4039425
	speed: 0.0337s/iter; left time: 880.5496s
Epoch: 2 cost time: 7.892327547073364
Epoch: 2, Steps: 266 | Train Loss: 0.3762879 Vali Loss: 0.2263114 Test Loss: 0.3184950
Validation loss decreased (0.249104 --> 0.226311).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3806445
	speed: 0.1330s/iter; left time: 3453.8027s
	iters: 200, epoch: 3 | loss: 0.2510306
	speed: 0.0213s/iter; left time: 550.2242s
Epoch: 3 cost time: 8.274743795394897
Epoch: 3, Steps: 266 | Train Loss: 0.3597400 Vali Loss: 0.2209513 Test Loss: 0.3118692
Validation loss decreased (0.226311 --> 0.220951).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3525311
	speed: 0.1349s/iter; left time: 3466.8945s
	iters: 200, epoch: 4 | loss: 0.3588024
	speed: 0.0230s/iter; left time: 588.2000s
Epoch: 4 cost time: 6.257550239562988
Epoch: 4, Steps: 266 | Train Loss: 0.3548342 Vali Loss: 0.2188887 Test Loss: 0.3095276
Validation loss decreased (0.220951 --> 0.218889).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3196607
	speed: 0.1348s/iter; left time: 3429.1328s
	iters: 200, epoch: 5 | loss: 0.3338361
	speed: 0.0303s/iter; left time: 768.4775s
Epoch: 5 cost time: 8.982383012771606
Epoch: 5, Steps: 266 | Train Loss: 0.3529360 Vali Loss: 0.2184212 Test Loss: 0.3085165
Validation loss decreased (0.218889 --> 0.218421).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3662212
	speed: 0.1220s/iter; left time: 3071.2394s
	iters: 200, epoch: 6 | loss: 0.2165728
	speed: 0.0334s/iter; left time: 837.4747s
Epoch: 6 cost time: 7.237876892089844
Epoch: 6, Steps: 266 | Train Loss: 0.3519427 Vali Loss: 0.2181855 Test Loss: 0.3078989
Validation loss decreased (0.218421 --> 0.218185).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3151305
	speed: 0.1075s/iter; left time: 2677.6064s
	iters: 200, epoch: 7 | loss: 0.3802867
	speed: 0.0243s/iter; left time: 601.8091s
Epoch: 7 cost time: 6.20024299621582
Epoch: 7, Steps: 266 | Train Loss: 0.3516826 Vali Loss: 0.2180854 Test Loss: 0.3077210
Validation loss decreased (0.218185 --> 0.218085).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3045557
	speed: 0.1161s/iter; left time: 2861.3164s
	iters: 200, epoch: 8 | loss: 0.2755452
	speed: 0.0393s/iter; left time: 965.0609s
Epoch: 8 cost time: 9.943268299102783
Epoch: 8, Steps: 266 | Train Loss: 0.3505888 Vali Loss: 0.2180954 Test Loss: 0.3075819
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3118738
	speed: 0.1561s/iter; left time: 3804.6703s
	iters: 200, epoch: 9 | loss: 0.2889906
	speed: 0.0338s/iter; left time: 821.4448s
Epoch: 9 cost time: 7.787375211715698
Epoch: 9, Steps: 266 | Train Loss: 0.3505321 Vali Loss: 0.2183008 Test Loss: 0.3075498
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4310556
	speed: 0.1331s/iter; left time: 3209.1934s
	iters: 200, epoch: 10 | loss: 0.2861338
	speed: 0.0186s/iter; left time: 446.0557s
Epoch: 10 cost time: 7.034009695053101
Epoch: 10, Steps: 266 | Train Loss: 0.3506309 Vali Loss: 0.2182429 Test Loss: 0.3075406
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3659610
	speed: 0.1103s/iter; left time: 2629.7180s
	iters: 200, epoch: 11 | loss: 0.2528635
	speed: 0.0185s/iter; left time: 438.3179s
Epoch: 11 cost time: 6.27143669128418
Epoch: 11, Steps: 266 | Train Loss: 0.3505141 Vali Loss: 0.2182434 Test Loss: 0.3075643
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3987666
	speed: 0.1143s/iter; left time: 2695.1120s
	iters: 200, epoch: 12 | loss: 0.4017128
	speed: 0.0269s/iter; left time: 631.1309s
Epoch: 12 cost time: 6.5024261474609375
Epoch: 12, Steps: 266 | Train Loss: 0.3503116 Vali Loss: 0.2184954 Test Loss: 0.3075362
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3707425
	speed: 0.1419s/iter; left time: 3308.4072s
	iters: 200, epoch: 13 | loss: 0.2648343
	speed: 0.0289s/iter; left time: 671.7011s
Epoch: 13 cost time: 8.510568857192993
Epoch: 13, Steps: 266 | Train Loss: 0.3498409 Vali Loss: 0.2182514 Test Loss: 0.3075206
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3071231
	speed: 0.1325s/iter; left time: 3052.6733s
	iters: 200, epoch: 14 | loss: 0.4472071
	speed: 0.0402s/iter; left time: 922.5766s
Epoch: 14 cost time: 10.002355813980103
Epoch: 14, Steps: 266 | Train Loss: 0.3496914 Vali Loss: 0.2185383 Test Loss: 0.3075383
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3834555
	speed: 0.1274s/iter; left time: 2902.0180s
	iters: 200, epoch: 15 | loss: 0.3640985
	speed: 0.0330s/iter; left time: 747.7305s
Epoch: 15 cost time: 7.935954809188843
Epoch: 15, Steps: 266 | Train Loss: 0.3500549 Vali Loss: 0.2185773 Test Loss: 0.3075695
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2939945
	speed: 0.1205s/iter; left time: 2711.8422s
	iters: 200, epoch: 16 | loss: 0.3817143
	speed: 0.0247s/iter; left time: 552.7830s
Epoch: 16 cost time: 6.615591526031494
Epoch: 16, Steps: 266 | Train Loss: 0.3500119 Vali Loss: 0.2185709 Test Loss: 0.3075926
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3081627
	speed: 0.1134s/iter; left time: 2521.7202s
	iters: 200, epoch: 17 | loss: 0.4688881
	speed: 0.0201s/iter; left time: 445.4386s
Epoch: 17 cost time: 7.169359922409058
Epoch: 17, Steps: 266 | Train Loss: 0.3493554 Vali Loss: 0.2185280 Test Loss: 0.3076500
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3912066
	speed: 0.1224s/iter; left time: 2689.1792s
	iters: 200, epoch: 18 | loss: 0.3366600
	speed: 0.0221s/iter; left time: 483.5389s
Epoch: 18 cost time: 7.77580189704895
Epoch: 18, Steps: 266 | Train Loss: 0.3498007 Vali Loss: 0.2187766 Test Loss: 0.3076896
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1977872
	speed: 0.1142s/iter; left time: 2479.1657s
	iters: 200, epoch: 19 | loss: 0.2429128
	speed: 0.0238s/iter; left time: 513.3511s
Epoch: 19 cost time: 6.824119567871094
Epoch: 19, Steps: 266 | Train Loss: 0.3495347 Vali Loss: 0.2185926 Test Loss: 0.3076243
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3112867
	speed: 0.0997s/iter; left time: 2138.2373s
	iters: 200, epoch: 20 | loss: 0.4212553
	speed: 0.0228s/iter; left time: 486.2204s
Epoch: 20 cost time: 6.964047431945801
Epoch: 20, Steps: 266 | Train Loss: 0.3494818 Vali Loss: 0.2185979 Test Loss: 0.3076660
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2881016
	speed: 0.1064s/iter; left time: 2253.9391s
	iters: 200, epoch: 21 | loss: 0.2644759
	speed: 0.0293s/iter; left time: 617.2205s
Epoch: 21 cost time: 7.3681628704071045
Epoch: 21, Steps: 266 | Train Loss: 0.3494379 Vali Loss: 0.2188028 Test Loss: 0.3076759
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4061204
	speed: 0.1098s/iter; left time: 2297.0735s
	iters: 200, epoch: 22 | loss: 0.3113639
	speed: 0.0308s/iter; left time: 642.0345s
Epoch: 22 cost time: 8.242163181304932
Epoch: 22, Steps: 266 | Train Loss: 0.3496947 Vali Loss: 0.2189512 Test Loss: 0.3076650
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3021223
	speed: 0.1381s/iter; left time: 2851.7607s
	iters: 200, epoch: 23 | loss: 0.2886132
	speed: 0.0208s/iter; left time: 427.9087s
Epoch: 23 cost time: 8.340631484985352
Epoch: 23, Steps: 266 | Train Loss: 0.3496561 Vali Loss: 0.2190295 Test Loss: 0.3077441
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3182431
	speed: 0.1293s/iter; left time: 2635.3804s
	iters: 200, epoch: 24 | loss: 0.4040029
	speed: 0.0285s/iter; left time: 578.3599s
Epoch: 24 cost time: 7.917255640029907
Epoch: 24, Steps: 266 | Train Loss: 0.3496890 Vali Loss: 0.2191086 Test Loss: 0.3077225
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2590801
	speed: 0.0997s/iter; left time: 2006.5661s
	iters: 200, epoch: 25 | loss: 0.4345965
	speed: 0.0315s/iter; left time: 631.4264s
Epoch: 25 cost time: 7.125582218170166
Epoch: 25, Steps: 266 | Train Loss: 0.3496502 Vali Loss: 0.2189436 Test Loss: 0.3077857
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3960116
	speed: 0.1403s/iter; left time: 2785.5680s
	iters: 200, epoch: 26 | loss: 0.2639153
	speed: 0.0305s/iter; left time: 603.2019s
Epoch: 26 cost time: 7.888468980789185
Epoch: 26, Steps: 266 | Train Loss: 0.3493719 Vali Loss: 0.2189979 Test Loss: 0.3077505
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2426889
	speed: 0.1309s/iter; left time: 2563.0122s
	iters: 200, epoch: 27 | loss: 0.2359996
	speed: 0.0309s/iter; left time: 601.1230s
Epoch: 27 cost time: 8.478857517242432
Epoch: 27, Steps: 266 | Train Loss: 0.3497202 Vali Loss: 0.2190120 Test Loss: 0.3077669
EarlyStopping counter: 20 out of 20
Early stopping
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=24, out_features=113, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2429952.0
params:  2825.0
Trainable parameters:  2825
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2969602
	speed: 0.0340s/iter; left time: 900.3342s
	iters: 200, epoch: 1 | loss: 0.4408481
	speed: 0.0323s/iter; left time: 853.1070s
Epoch: 1 cost time: 8.88740587234497
Epoch: 1, Steps: 266 | Train Loss: 0.4424285 Vali Loss: 0.2177421 Test Loss: 0.3070044
Validation loss decreased (inf --> 0.217742).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3234111
	speed: 0.1321s/iter; left time: 3465.7971s
	iters: 200, epoch: 2 | loss: 0.5693196
	speed: 0.0309s/iter; left time: 806.5338s
Epoch: 2 cost time: 7.210191965103149
Epoch: 2, Steps: 266 | Train Loss: 0.4413991 Vali Loss: 0.2179454 Test Loss: 0.3069419
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4877175
	speed: 0.1220s/iter; left time: 3169.0311s
	iters: 200, epoch: 3 | loss: 0.3687899
	speed: 0.0190s/iter; left time: 491.6596s
Epoch: 3 cost time: 5.685016632080078
Epoch: 3, Steps: 266 | Train Loss: 0.4408757 Vali Loss: 0.2180498 Test Loss: 0.3070368
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4599542
	speed: 0.1197s/iter; left time: 3077.5414s
	iters: 200, epoch: 4 | loss: 0.4204579
	speed: 0.0280s/iter; left time: 715.7628s
Epoch: 4 cost time: 7.368750095367432
Epoch: 4, Steps: 266 | Train Loss: 0.4407515 Vali Loss: 0.2181080 Test Loss: 0.3070283
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2984331
	speed: 0.1043s/iter; left time: 2652.7711s
	iters: 200, epoch: 5 | loss: 0.3429612
	speed: 0.0222s/iter; left time: 562.2529s
Epoch: 5 cost time: 7.249004602432251
Epoch: 5, Steps: 266 | Train Loss: 0.4414730 Vali Loss: 0.2181753 Test Loss: 0.3070765
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4500429
	speed: 0.1374s/iter; left time: 3458.7416s
	iters: 200, epoch: 6 | loss: 0.3952625
	speed: 0.0296s/iter; left time: 743.2254s
Epoch: 6 cost time: 8.250014305114746
Epoch: 6, Steps: 266 | Train Loss: 0.4404826 Vali Loss: 0.2182138 Test Loss: 0.3071125
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.7225142
	speed: 0.1447s/iter; left time: 3602.8914s
	iters: 200, epoch: 7 | loss: 0.2683678
	speed: 0.0276s/iter; left time: 684.4585s
Epoch: 7 cost time: 8.581639051437378
Epoch: 7, Steps: 266 | Train Loss: 0.4409033 Vali Loss: 0.2183050 Test Loss: 0.3071828
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4477754
	speed: 0.1379s/iter; left time: 3398.9359s
	iters: 200, epoch: 8 | loss: 0.4894564
	speed: 0.0383s/iter; left time: 940.4996s
Epoch: 8 cost time: 9.245176315307617
Epoch: 8, Steps: 266 | Train Loss: 0.4404786 Vali Loss: 0.2182610 Test Loss: 0.3071493
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4246831
	speed: 0.1191s/iter; left time: 2901.7749s
	iters: 200, epoch: 9 | loss: 0.3079965
	speed: 0.0368s/iter; left time: 892.2930s
Epoch: 9 cost time: 8.737782955169678
Epoch: 9, Steps: 266 | Train Loss: 0.4409086 Vali Loss: 0.2184394 Test Loss: 0.3072314
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2842674
	speed: 0.1118s/iter; left time: 2695.1828s
	iters: 200, epoch: 10 | loss: 0.5834204
	speed: 0.0326s/iter; left time: 783.2488s
Epoch: 10 cost time: 8.987876892089844
Epoch: 10, Steps: 266 | Train Loss: 0.4409384 Vali Loss: 0.2185055 Test Loss: 0.3071524
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2953770
	speed: 0.1355s/iter; left time: 3229.6776s
	iters: 200, epoch: 11 | loss: 0.5168831
	speed: 0.0374s/iter; left time: 887.9955s
Epoch: 11 cost time: 7.828948259353638
Epoch: 11, Steps: 266 | Train Loss: 0.4409621 Vali Loss: 0.2185840 Test Loss: 0.3072532
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2552200
	speed: 0.1293s/iter; left time: 3048.8705s
	iters: 200, epoch: 12 | loss: 0.7111858
	speed: 0.0381s/iter; left time: 894.7116s
Epoch: 12 cost time: 9.207306385040283
Epoch: 12, Steps: 266 | Train Loss: 0.4404267 Vali Loss: 0.2186054 Test Loss: 0.3072318
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4150447
	speed: 0.1436s/iter; left time: 3346.1573s
	iters: 200, epoch: 13 | loss: 0.4419884
	speed: 0.0293s/iter; left time: 679.1421s
Epoch: 13 cost time: 8.659830093383789
Epoch: 13, Steps: 266 | Train Loss: 0.4397516 Vali Loss: 0.2184519 Test Loss: 0.3071482
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3889766
	speed: 0.1358s/iter; left time: 3128.4808s
	iters: 200, epoch: 14 | loss: 0.3252265
	speed: 0.0216s/iter; left time: 494.6980s
Epoch: 14 cost time: 7.172858238220215
Epoch: 14, Steps: 266 | Train Loss: 0.4403824 Vali Loss: 0.2185931 Test Loss: 0.3072796
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4516470
	speed: 0.1476s/iter; left time: 3361.5022s
	iters: 200, epoch: 15 | loss: 0.3324075
	speed: 0.0260s/iter; left time: 590.7132s
Epoch: 15 cost time: 7.934936761856079
Epoch: 15, Steps: 266 | Train Loss: 0.4407968 Vali Loss: 0.2187409 Test Loss: 0.3073263
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3568999
	speed: 0.1272s/iter; left time: 2864.1460s
	iters: 200, epoch: 16 | loss: 0.4078934
	speed: 0.0179s/iter; left time: 401.9583s
Epoch: 16 cost time: 6.907222509384155
Epoch: 16, Steps: 266 | Train Loss: 0.4406576 Vali Loss: 0.2185035 Test Loss: 0.3073130
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.5041844
	speed: 0.1229s/iter; left time: 2733.8544s
	iters: 200, epoch: 17 | loss: 0.3204073
	speed: 0.0200s/iter; left time: 441.8920s
Epoch: 17 cost time: 7.215651750564575
Epoch: 17, Steps: 266 | Train Loss: 0.4407453 Vali Loss: 0.2185699 Test Loss: 0.3073060
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.5407035
	speed: 0.1211s/iter; left time: 2662.6931s
	iters: 200, epoch: 18 | loss: 0.3403883
	speed: 0.0190s/iter; left time: 415.2832s
Epoch: 18 cost time: 6.848567008972168
Epoch: 18, Steps: 266 | Train Loss: 0.4402470 Vali Loss: 0.2187613 Test Loss: 0.3072877
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.5260723
	speed: 0.1149s/iter; left time: 2495.4560s
	iters: 200, epoch: 19 | loss: 0.3366652
	speed: 0.0275s/iter; left time: 593.5132s
Epoch: 19 cost time: 7.2329795360565186
Epoch: 19, Steps: 266 | Train Loss: 0.4403677 Vali Loss: 0.2185352 Test Loss: 0.3072707
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3659281
	speed: 0.1164s/iter; left time: 2495.4810s
	iters: 200, epoch: 20 | loss: 0.3795467
	speed: 0.0341s/iter; left time: 727.1064s
Epoch: 20 cost time: 8.547858476638794
Epoch: 20, Steps: 266 | Train Loss: 0.4405589 Vali Loss: 0.2187208 Test Loss: 0.3073068
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2706829
	speed: 0.1408s/iter; left time: 2982.3569s
	iters: 200, epoch: 21 | loss: 0.4975126
	speed: 0.0323s/iter; left time: 680.6618s
Epoch: 21 cost time: 9.441120862960815
Epoch: 21, Steps: 266 | Train Loss: 0.4401252 Vali Loss: 0.2188695 Test Loss: 0.3072935
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_90_336_FITS_ETTm2_ftM_sl90_ll48_pl336_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.30839285254478455, mae:0.3430652618408203, rse:0.44855204224586487, corr:[0.560596   0.56053406 0.55425483 0.55264634 0.5524921  0.5501169
 0.54842216 0.5489914  0.54878014 0.5467409  0.5451812  0.54505694
 0.54487747 0.5441674  0.54347926 0.5428075  0.5419094  0.54116154
 0.5404916  0.53936094 0.5380169  0.5372015  0.5366503  0.5357977
 0.53495884 0.5347694  0.53479606 0.53423643 0.5333803  0.5327766
 0.53209627 0.53108144 0.53019124 0.5298102  0.52946466 0.52882695
 0.5280972  0.5274954  0.5267789  0.5258895  0.52517545 0.52486485
 0.5246301  0.5242756  0.52392185 0.5235177  0.52293146 0.5221248
 0.5212645  0.520379   0.51947117 0.5187131  0.5180898  0.5174247
 0.5167843  0.5162481  0.51582426 0.51547605 0.515149   0.5149115
 0.5146837  0.5144259  0.51431465 0.5143997  0.51447827 0.5143996
 0.51421636 0.51405793 0.5140538  0.5140747  0.51405215 0.51409096
 0.51414186 0.51412714 0.51395875 0.5137816  0.51370084 0.51353884
 0.51320034 0.51285493 0.51266915 0.5124558  0.51212275 0.5118092
 0.51158726 0.5112626  0.5108008  0.5104546  0.51032007 0.5101418
 0.5097012  0.50916326 0.50878596 0.5083119  0.5071659  0.5053459
 0.50325227 0.50096774 0.49861765 0.49667475 0.49522087 0.49380714
 0.49235025 0.49127227 0.490442   0.48916125 0.4874825  0.48604912
 0.48501647 0.48397163 0.48265472 0.48128933 0.48011443 0.47887248
 0.47741047 0.4759617  0.4747058  0.47365764 0.47269768 0.47164333
 0.4705816  0.469539   0.46858487 0.4677409  0.46682033 0.46573946
 0.46476936 0.46398342 0.46303067 0.46184272 0.46072266 0.45987356
 0.45913744 0.4583374  0.45754385 0.4570149  0.4564298  0.4558219
 0.45536608 0.4550754  0.45470184 0.45410186 0.4535399  0.45308036
 0.4524436  0.4515545  0.45059288 0.44977978 0.44881812 0.44768402
 0.44681305 0.44662115 0.4465203  0.44601557 0.44546214 0.44509768
 0.4447166  0.44440955 0.4442599  0.44432372 0.44420356 0.44388255
 0.4437873  0.44377768 0.44386253 0.4440446  0.44436285 0.44460762
 0.4445535  0.44440764 0.44448486 0.44470528 0.44485942 0.44500372
 0.4451469  0.44500396 0.4445719  0.44448203 0.44487944 0.44506553
 0.44450632 0.44372672 0.44361272 0.4438021  0.4436812  0.44330448
 0.44308844 0.44296503 0.44249102 0.4415876  0.4403924  0.43873242
 0.43651205 0.43420562 0.43225795 0.43059    0.4290979  0.42791522
 0.42709503 0.42629275 0.42520088 0.42391    0.42260545 0.42127737
 0.42000774 0.41891643 0.41777012 0.41632834 0.41475585 0.41354606
 0.41259128 0.41154745 0.41020694 0.40879598 0.40756854 0.4065156
 0.40553248 0.40454918 0.4036137  0.40257698 0.40144762 0.40033194
 0.3991544  0.39789757 0.39698902 0.3961991  0.39538336 0.39442006
 0.39355582 0.39290935 0.3921467  0.39127964 0.39054242 0.39008725
 0.3895846  0.3889501  0.38860175 0.38862732 0.38852564 0.3879034
 0.38717285 0.3867753  0.38644436 0.3862226  0.38614807 0.38621607
 0.3863384  0.38625988 0.3861599  0.3862102  0.3864338  0.3866129
 0.3866519  0.38667682 0.38662624 0.3864763  0.38654438 0.38688174
 0.38718212 0.38734287 0.38756365 0.38803467 0.3885425  0.3888775
 0.38920292 0.38950443 0.38986963 0.39029178 0.39077404 0.3910907
 0.39101008 0.39085257 0.39094737 0.3912884  0.39172783 0.39222828
 0.39278316 0.3931634  0.39325553 0.3932494  0.39323342 0.3932013
 0.39321962 0.3934267  0.39363718 0.39341125 0.39262787 0.39164165
 0.39059994 0.38938788 0.38829395 0.38786823 0.38793606 0.38797486
 0.38798544 0.38821042 0.38838685 0.38801423 0.38723937 0.38667354
 0.3863511  0.38582125 0.3850726  0.3844871  0.38392782 0.38288853
 0.38158238 0.38068333 0.38018066 0.3794015  0.37830645 0.37757418
 0.37705326 0.37611693 0.37490028 0.37428066 0.37408385 0.37315604
 0.37160793 0.3707293  0.3704013  0.36946908 0.3682467  0.36790228
 0.3676556  0.36625907 0.36507025 0.36533144 0.36504707 0.3627597
 0.3617712  0.3634211  0.36253715 0.35868984 0.3608036  0.36528972]
