Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=122, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_720_720_FITS_ETTm2_ftM_sl720_ll48_pl720_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=122, out_features=244, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  26672128.0
params:  30012.0
Trainable parameters:  30012
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3730170
	speed: 0.0281s/iter; left time: 721.0720s
	iters: 200, epoch: 1 | loss: 0.4586482
	speed: 0.0216s/iter; left time: 552.6957s
Epoch: 1 cost time: 6.222139120101929
Epoch: 1, Steps: 258 | Train Loss: 0.4335389 Vali Loss: 0.2959006 Test Loss: 0.3944496
Validation loss decreased (inf --> 0.295901).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2645182
	speed: 0.0969s/iter; left time: 2465.1535s
	iters: 200, epoch: 2 | loss: 0.2988102
	speed: 0.0234s/iter; left time: 591.8267s
Epoch: 2 cost time: 6.5546886920928955
Epoch: 2, Steps: 258 | Train Loss: 0.3216932 Vali Loss: 0.2809815 Test Loss: 0.3765641
Validation loss decreased (0.295901 --> 0.280981).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3317439
	speed: 0.1044s/iter; left time: 2630.5253s
	iters: 200, epoch: 3 | loss: 0.2035412
	speed: 0.0224s/iter; left time: 561.8516s
Epoch: 3 cost time: 6.410931587219238
Epoch: 3, Steps: 258 | Train Loss: 0.2903330 Vali Loss: 0.2751558 Test Loss: 0.3683769
Validation loss decreased (0.280981 --> 0.275156).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2301612
	speed: 0.0968s/iter; left time: 2413.9637s
	iters: 200, epoch: 4 | loss: 0.3256615
	speed: 0.0230s/iter; left time: 570.8430s
Epoch: 4 cost time: 6.4719398021698
Epoch: 4, Steps: 258 | Train Loss: 0.2746679 Vali Loss: 0.2709505 Test Loss: 0.3635639
Validation loss decreased (0.275156 --> 0.270950).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2262934
	speed: 0.0976s/iter; left time: 2407.3111s
	iters: 200, epoch: 5 | loss: 0.3379228
	speed: 0.0222s/iter; left time: 546.6000s
Epoch: 5 cost time: 6.488955497741699
Epoch: 5, Steps: 258 | Train Loss: 0.2662879 Vali Loss: 0.2678682 Test Loss: 0.3602269
Validation loss decreased (0.270950 --> 0.267868).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2460114
	speed: 0.1068s/iter; left time: 2606.0675s
	iters: 200, epoch: 6 | loss: 0.2529966
	speed: 0.0243s/iter; left time: 591.1715s
Epoch: 6 cost time: 7.062175750732422
Epoch: 6, Steps: 258 | Train Loss: 0.2612914 Vali Loss: 0.2661007 Test Loss: 0.3581317
Validation loss decreased (0.267868 --> 0.266101).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2749721
	speed: 0.1033s/iter; left time: 2494.9902s
	iters: 200, epoch: 7 | loss: 0.2342370
	speed: 0.0238s/iter; left time: 572.4803s
Epoch: 7 cost time: 6.763496160507202
Epoch: 7, Steps: 258 | Train Loss: 0.2588457 Vali Loss: 0.2652811 Test Loss: 0.3567462
Validation loss decreased (0.266101 --> 0.265281).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3057777
	speed: 0.1036s/iter; left time: 2475.3346s
	iters: 200, epoch: 8 | loss: 0.2564284
	speed: 0.0238s/iter; left time: 565.8986s
Epoch: 8 cost time: 6.797564744949341
Epoch: 8, Steps: 258 | Train Loss: 0.2573758 Vali Loss: 0.2647232 Test Loss: 0.3558214
Validation loss decreased (0.265281 --> 0.264723).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2752057
	speed: 0.1007s/iter; left time: 2379.7754s
	iters: 200, epoch: 9 | loss: 0.2416268
	speed: 0.0241s/iter; left time: 566.0742s
Epoch: 9 cost time: 6.943126201629639
Epoch: 9, Steps: 258 | Train Loss: 0.2563807 Vali Loss: 0.2638050 Test Loss: 0.3555689
Validation loss decreased (0.264723 --> 0.263805).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3036138
	speed: 0.1047s/iter; left time: 2448.2510s
	iters: 200, epoch: 10 | loss: 0.3010431
	speed: 0.0228s/iter; left time: 529.7510s
Epoch: 10 cost time: 6.5490782260894775
Epoch: 10, Steps: 258 | Train Loss: 0.2560379 Vali Loss: 0.2635105 Test Loss: 0.3551272
Validation loss decreased (0.263805 --> 0.263510).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2263809
	speed: 0.1018s/iter; left time: 2353.3627s
	iters: 200, epoch: 11 | loss: 0.3149883
	speed: 0.0229s/iter; left time: 526.6690s
Epoch: 11 cost time: 6.672647953033447
Epoch: 11, Steps: 258 | Train Loss: 0.2552850 Vali Loss: 0.2632782 Test Loss: 0.3549829
Validation loss decreased (0.263510 --> 0.263278).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3233831
	speed: 0.1025s/iter; left time: 2344.5705s
	iters: 200, epoch: 12 | loss: 0.2491063
	speed: 0.0235s/iter; left time: 534.9027s
Epoch: 12 cost time: 6.866259336471558
Epoch: 12, Steps: 258 | Train Loss: 0.2556122 Vali Loss: 0.2629014 Test Loss: 0.3548568
Validation loss decreased (0.263278 --> 0.262901).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2305654
	speed: 0.1081s/iter; left time: 2444.0354s
	iters: 200, epoch: 13 | loss: 0.2618488
	speed: 0.0240s/iter; left time: 539.1411s
Epoch: 13 cost time: 6.99046516418457
Epoch: 13, Steps: 258 | Train Loss: 0.2554212 Vali Loss: 0.2632873 Test Loss: 0.3546778
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3281725
	speed: 0.0987s/iter; left time: 2206.6430s
	iters: 200, epoch: 14 | loss: 0.2461372
	speed: 0.0263s/iter; left time: 585.0378s
Epoch: 14 cost time: 6.840162754058838
Epoch: 14, Steps: 258 | Train Loss: 0.2554555 Vali Loss: 0.2627331 Test Loss: 0.3543943
Validation loss decreased (0.262901 --> 0.262733).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2086113
	speed: 0.1015s/iter; left time: 2242.3839s
	iters: 200, epoch: 15 | loss: 0.3251408
	speed: 0.0223s/iter; left time: 490.0485s
Epoch: 15 cost time: 6.669061899185181
Epoch: 15, Steps: 258 | Train Loss: 0.2553645 Vali Loss: 0.2630064 Test Loss: 0.3543761
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2769078
	speed: 0.1035s/iter; left time: 2259.6942s
	iters: 200, epoch: 16 | loss: 0.2346590
	speed: 0.0238s/iter; left time: 517.8400s
Epoch: 16 cost time: 7.1567254066467285
Epoch: 16, Steps: 258 | Train Loss: 0.2551161 Vali Loss: 0.2627674 Test Loss: 0.3544936
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2808945
	speed: 0.1005s/iter; left time: 2168.1468s
	iters: 200, epoch: 17 | loss: 0.2621742
	speed: 0.0244s/iter; left time: 524.8859s
Epoch: 17 cost time: 6.987268924713135
Epoch: 17, Steps: 258 | Train Loss: 0.2551890 Vali Loss: 0.2629700 Test Loss: 0.3543020
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3077177
	speed: 0.1102s/iter; left time: 2348.2242s
	iters: 200, epoch: 18 | loss: 0.1914924
	speed: 0.0233s/iter; left time: 495.0785s
Epoch: 18 cost time: 7.141260385513306
Epoch: 18, Steps: 258 | Train Loss: 0.2551875 Vali Loss: 0.2629132 Test Loss: 0.3543842
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1967464
	speed: 0.1055s/iter; left time: 2220.9641s
	iters: 200, epoch: 19 | loss: 0.2264027
	speed: 0.0240s/iter; left time: 503.4926s
Epoch: 19 cost time: 7.51114559173584
Epoch: 19, Steps: 258 | Train Loss: 0.2553266 Vali Loss: 0.2629569 Test Loss: 0.3542763
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3778933
	speed: 0.0973s/iter; left time: 2022.7212s
	iters: 200, epoch: 20 | loss: 0.3545079
	speed: 0.0234s/iter; left time: 484.2489s
Epoch: 20 cost time: 6.628700494766235
Epoch: 20, Steps: 258 | Train Loss: 0.2552536 Vali Loss: 0.2628753 Test Loss: 0.3542663
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1750938
	speed: 0.0951s/iter; left time: 1954.1748s
	iters: 200, epoch: 21 | loss: 0.3319864
	speed: 0.0256s/iter; left time: 523.7611s
Epoch: 21 cost time: 6.734808444976807
Epoch: 21, Steps: 258 | Train Loss: 0.2550458 Vali Loss: 0.2627436 Test Loss: 0.3541616
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2272507
	speed: 0.0952s/iter; left time: 1930.9070s
	iters: 200, epoch: 22 | loss: 0.1889953
	speed: 0.0230s/iter; left time: 464.6019s
Epoch: 22 cost time: 6.621398687362671
Epoch: 22, Steps: 258 | Train Loss: 0.2551463 Vali Loss: 0.2626503 Test Loss: 0.3541771
Validation loss decreased (0.262733 --> 0.262650).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2270437
	speed: 0.1035s/iter; left time: 2073.3863s
	iters: 200, epoch: 23 | loss: 0.2557366
	speed: 0.0283s/iter; left time: 564.7077s
Epoch: 23 cost time: 7.117921829223633
Epoch: 23, Steps: 258 | Train Loss: 0.2545890 Vali Loss: 0.2627389 Test Loss: 0.3541889
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2712555
	speed: 0.1011s/iter; left time: 1997.6122s
	iters: 200, epoch: 24 | loss: 0.2731301
	speed: 0.0233s/iter; left time: 458.5067s
Epoch: 24 cost time: 6.555971145629883
Epoch: 24, Steps: 258 | Train Loss: 0.2550338 Vali Loss: 0.2627220 Test Loss: 0.3540405
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2607703
	speed: 0.1018s/iter; left time: 1985.1874s
	iters: 200, epoch: 25 | loss: 0.3130479
	speed: 0.0227s/iter; left time: 440.6998s
Epoch: 25 cost time: 6.708129644393921
Epoch: 25, Steps: 258 | Train Loss: 0.2549897 Vali Loss: 0.2626355 Test Loss: 0.3540721
Validation loss decreased (0.262650 --> 0.262635).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2345853
	speed: 0.1079s/iter; left time: 2076.9114s
	iters: 200, epoch: 26 | loss: 0.2603885
	speed: 0.0302s/iter; left time: 579.0417s
Epoch: 26 cost time: 7.544851303100586
Epoch: 26, Steps: 258 | Train Loss: 0.2550605 Vali Loss: 0.2629153 Test Loss: 0.3541166
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2723959
	speed: 0.1026s/iter; left time: 1948.8984s
	iters: 200, epoch: 27 | loss: 0.2475450
	speed: 0.0238s/iter; left time: 448.9136s
Epoch: 27 cost time: 6.884687185287476
Epoch: 27, Steps: 258 | Train Loss: 0.2547600 Vali Loss: 0.2626250 Test Loss: 0.3540798
Validation loss decreased (0.262635 --> 0.262625).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2650009
	speed: 0.1015s/iter; left time: 1901.9312s
	iters: 200, epoch: 28 | loss: 0.2746411
	speed: 0.0237s/iter; left time: 441.7744s
Epoch: 28 cost time: 6.653475522994995
Epoch: 28, Steps: 258 | Train Loss: 0.2547635 Vali Loss: 0.2625614 Test Loss: 0.3540950
Validation loss decreased (0.262625 --> 0.262561).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2604269
	speed: 0.0997s/iter; left time: 1842.4380s
	iters: 200, epoch: 29 | loss: 0.2182880
	speed: 0.0218s/iter; left time: 401.1836s
Epoch: 29 cost time: 6.486895322799683
Epoch: 29, Steps: 258 | Train Loss: 0.2551291 Vali Loss: 0.2627055 Test Loss: 0.3540794
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3418440
	speed: 0.0964s/iter; left time: 1757.0943s
	iters: 200, epoch: 30 | loss: 0.2371670
	speed: 0.0232s/iter; left time: 420.5906s
Epoch: 30 cost time: 6.744316339492798
Epoch: 30, Steps: 258 | Train Loss: 0.2549215 Vali Loss: 0.2624373 Test Loss: 0.3540753
Validation loss decreased (0.262561 --> 0.262437).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2389862
	speed: 0.1013s/iter; left time: 1819.1145s
	iters: 200, epoch: 31 | loss: 0.2460848
	speed: 0.0352s/iter; left time: 628.0167s
Epoch: 31 cost time: 8.131478071212769
Epoch: 31, Steps: 258 | Train Loss: 0.2547407 Vali Loss: 0.2626192 Test Loss: 0.3540609
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2726147
	speed: 0.1033s/iter; left time: 1829.0091s
	iters: 200, epoch: 32 | loss: 0.2992474
	speed: 0.0249s/iter; left time: 437.6294s
Epoch: 32 cost time: 7.197525978088379
Epoch: 32, Steps: 258 | Train Loss: 0.2545325 Vali Loss: 0.2625550 Test Loss: 0.3539850
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2348296
	speed: 0.1057s/iter; left time: 1844.5444s
	iters: 200, epoch: 33 | loss: 0.2452717
	speed: 0.0235s/iter; left time: 408.0883s
Epoch: 33 cost time: 6.68714451789856
Epoch: 33, Steps: 258 | Train Loss: 0.2545014 Vali Loss: 0.2626550 Test Loss: 0.3539443
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2038175
	speed: 0.1010s/iter; left time: 1735.3262s
	iters: 200, epoch: 34 | loss: 0.2899559
	speed: 0.0241s/iter; left time: 412.0794s
Epoch: 34 cost time: 7.152949571609497
Epoch: 34, Steps: 258 | Train Loss: 0.2546986 Vali Loss: 0.2626388 Test Loss: 0.3540194
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2703233
	speed: 0.1035s/iter; left time: 1752.6192s
	iters: 200, epoch: 35 | loss: 0.2881625
	speed: 0.0251s/iter; left time: 422.5334s
Epoch: 35 cost time: 6.897984743118286
Epoch: 35, Steps: 258 | Train Loss: 0.2546156 Vali Loss: 0.2628685 Test Loss: 0.3540253
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2392981
	speed: 0.1042s/iter; left time: 1737.6009s
	iters: 200, epoch: 36 | loss: 0.2514489
	speed: 0.0248s/iter; left time: 411.4417s
Epoch: 36 cost time: 6.9488608837127686
Epoch: 36, Steps: 258 | Train Loss: 0.2548903 Vali Loss: 0.2625532 Test Loss: 0.3539513
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1850160
	speed: 0.1049s/iter; left time: 1722.2883s
	iters: 200, epoch: 37 | loss: 0.3152388
	speed: 0.0241s/iter; left time: 393.8709s
Epoch: 37 cost time: 6.924981117248535
Epoch: 37, Steps: 258 | Train Loss: 0.2548635 Vali Loss: 0.2623851 Test Loss: 0.3539684
Validation loss decreased (0.262437 --> 0.262385).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2491720
	speed: 0.1068s/iter; left time: 1725.2103s
	iters: 200, epoch: 38 | loss: 0.2666518
	speed: 0.0242s/iter; left time: 388.1218s
Epoch: 38 cost time: 6.82823371887207
Epoch: 38, Steps: 258 | Train Loss: 0.2549256 Vali Loss: 0.2626245 Test Loss: 0.3539756
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2615146
	speed: 0.1024s/iter; left time: 1628.0885s
	iters: 200, epoch: 39 | loss: 0.2404687
	speed: 0.0234s/iter; left time: 368.9552s
Epoch: 39 cost time: 6.811208248138428
Epoch: 39, Steps: 258 | Train Loss: 0.2547885 Vali Loss: 0.2621714 Test Loss: 0.3540209
Validation loss decreased (0.262385 --> 0.262171).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2299765
	speed: 0.0986s/iter; left time: 1542.5109s
	iters: 200, epoch: 40 | loss: 0.2610056
	speed: 0.0248s/iter; left time: 385.3007s
Epoch: 40 cost time: 7.00684928894043
Epoch: 40, Steps: 258 | Train Loss: 0.2547411 Vali Loss: 0.2625557 Test Loss: 0.3540512
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3185537
	speed: 0.0990s/iter; left time: 1523.0518s
	iters: 200, epoch: 41 | loss: 0.2292990
	speed: 0.0232s/iter; left time: 354.0784s
Epoch: 41 cost time: 6.59634804725647
Epoch: 41, Steps: 258 | Train Loss: 0.2546215 Vali Loss: 0.2622692 Test Loss: 0.3539748
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2354172
	speed: 0.1006s/iter; left time: 1521.4562s
	iters: 200, epoch: 42 | loss: 0.2319640
	speed: 0.0241s/iter; left time: 361.6937s
Epoch: 42 cost time: 6.954355478286743
Epoch: 42, Steps: 258 | Train Loss: 0.2550606 Vali Loss: 0.2626377 Test Loss: 0.3539849
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2130205
	speed: 0.1045s/iter; left time: 1553.5310s
	iters: 200, epoch: 43 | loss: 0.2974814
	speed: 0.0228s/iter; left time: 336.7682s
Epoch: 43 cost time: 6.508901119232178
Epoch: 43, Steps: 258 | Train Loss: 0.2547120 Vali Loss: 0.2625782 Test Loss: 0.3539801
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2764395
	speed: 0.1008s/iter; left time: 1472.5941s
	iters: 200, epoch: 44 | loss: 0.3301094
	speed: 0.0241s/iter; left time: 350.1678s
Epoch: 44 cost time: 6.92603325843811
Epoch: 44, Steps: 258 | Train Loss: 0.2547275 Vali Loss: 0.2624363 Test Loss: 0.3539648
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2612750
	speed: 0.1002s/iter; left time: 1437.6054s
	iters: 200, epoch: 45 | loss: 0.2683351
	speed: 0.0251s/iter; left time: 358.2644s
Epoch: 45 cost time: 6.95516037940979
Epoch: 45, Steps: 258 | Train Loss: 0.2545510 Vali Loss: 0.2625065 Test Loss: 0.3539605
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2927603
	speed: 0.1029s/iter; left time: 1450.6608s
	iters: 200, epoch: 46 | loss: 0.2193758
	speed: 0.0242s/iter; left time: 338.4219s
Epoch: 46 cost time: 6.879147529602051
Epoch: 46, Steps: 258 | Train Loss: 0.2548176 Vali Loss: 0.2625980 Test Loss: 0.3539415
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2319640
	speed: 0.1021s/iter; left time: 1412.6388s
	iters: 200, epoch: 47 | loss: 0.2120400
	speed: 0.0242s/iter; left time: 332.6762s
Epoch: 47 cost time: 6.934819459915161
Epoch: 47, Steps: 258 | Train Loss: 0.2547884 Vali Loss: 0.2626311 Test Loss: 0.3539629
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2261997
	speed: 0.1004s/iter; left time: 1362.5803s
	iters: 200, epoch: 48 | loss: 0.2667792
	speed: 0.0227s/iter; left time: 305.6223s
Epoch: 48 cost time: 6.565728425979614
Epoch: 48, Steps: 258 | Train Loss: 0.2544700 Vali Loss: 0.2623891 Test Loss: 0.3539243
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2474977
	speed: 0.1022s/iter; left time: 1361.6322s
	iters: 200, epoch: 49 | loss: 0.3331051
	speed: 0.0242s/iter; left time: 320.4283s
Epoch: 49 cost time: 7.204096794128418
Epoch: 49, Steps: 258 | Train Loss: 0.2549919 Vali Loss: 0.2626401 Test Loss: 0.3539250
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2621241
	speed: 0.1061s/iter; left time: 1385.7919s
	iters: 200, epoch: 50 | loss: 0.2234455
	speed: 0.0234s/iter; left time: 302.7288s
Epoch: 50 cost time: 6.957889795303345
Epoch: 50, Steps: 258 | Train Loss: 0.2549390 Vali Loss: 0.2627595 Test Loss: 0.3539030
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2037852
	speed: 0.1019s/iter; left time: 1304.0966s
	iters: 200, epoch: 51 | loss: 0.2695078
	speed: 0.0243s/iter; left time: 308.4125s
Epoch: 51 cost time: 6.900162696838379
Epoch: 51, Steps: 258 | Train Loss: 0.2550574 Vali Loss: 0.2627048 Test Loss: 0.3539251
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2939173
	speed: 0.1022s/iter; left time: 1282.1669s
	iters: 200, epoch: 52 | loss: 0.2674894
	speed: 0.0249s/iter; left time: 309.4753s
Epoch: 52 cost time: 6.9295220375061035
Epoch: 52, Steps: 258 | Train Loss: 0.2545062 Vali Loss: 0.2626298 Test Loss: 0.3538999
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2901650
	speed: 0.1040s/iter; left time: 1277.0834s
	iters: 200, epoch: 53 | loss: 0.2809394
	speed: 0.0223s/iter; left time: 272.0552s
Epoch: 53 cost time: 6.551020860671997
Epoch: 53, Steps: 258 | Train Loss: 0.2547129 Vali Loss: 0.2625772 Test Loss: 0.3538998
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2705759
	speed: 0.1026s/iter; left time: 1233.8913s
	iters: 200, epoch: 54 | loss: 0.2600464
	speed: 0.0231s/iter; left time: 274.9424s
Epoch: 54 cost time: 6.718711614608765
Epoch: 54, Steps: 258 | Train Loss: 0.2547650 Vali Loss: 0.2625928 Test Loss: 0.3539078
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2371642
	speed: 0.0993s/iter; left time: 1168.1697s
	iters: 200, epoch: 55 | loss: 0.2253528
	speed: 0.0239s/iter; left time: 278.6957s
Epoch: 55 cost time: 6.893249034881592
Epoch: 55, Steps: 258 | Train Loss: 0.2545991 Vali Loss: 0.2624653 Test Loss: 0.3539350
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2412609
	speed: 0.1013s/iter; left time: 1165.9889s
	iters: 200, epoch: 56 | loss: 0.2315403
	speed: 0.0243s/iter; left time: 277.2042s
Epoch: 56 cost time: 7.298740386962891
Epoch: 56, Steps: 258 | Train Loss: 0.2545945 Vali Loss: 0.2627271 Test Loss: 0.3539276
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2084697
	speed: 0.1102s/iter; left time: 1239.5205s
	iters: 200, epoch: 57 | loss: 0.2624503
	speed: 0.0249s/iter; left time: 277.4275s
Epoch: 57 cost time: 7.143458843231201
Epoch: 57, Steps: 258 | Train Loss: 0.2546864 Vali Loss: 0.2624724 Test Loss: 0.3539154
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1688114
	speed: 0.1009s/iter; left time: 1109.7548s
	iters: 200, epoch: 58 | loss: 0.3019341
	speed: 0.0236s/iter; left time: 257.6339s
Epoch: 58 cost time: 6.603276014328003
Epoch: 58, Steps: 258 | Train Loss: 0.2546785 Vali Loss: 0.2624515 Test Loss: 0.3539149
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2465771
	speed: 0.0992s/iter; left time: 1064.8485s
	iters: 200, epoch: 59 | loss: 0.2241833
	speed: 0.0281s/iter; left time: 298.4373s
Epoch: 59 cost time: 7.310925483703613
Epoch: 59, Steps: 258 | Train Loss: 0.2547389 Vali Loss: 0.2625907 Test Loss: 0.3539184
EarlyStopping counter: 20 out of 20
Early stopping
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=122, out_features=244, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  26672128.0
params:  30012.0
Trainable parameters:  30012
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4882557
	speed: 0.0295s/iter; left time: 757.6069s
	iters: 200, epoch: 1 | loss: 0.4071626
	speed: 0.0226s/iter; left time: 579.5475s
Epoch: 1 cost time: 6.55363655090332
Epoch: 1, Steps: 258 | Train Loss: 0.4962530 Vali Loss: 0.2619419 Test Loss: 0.3532993
Validation loss decreased (inf --> 0.261942).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4455466
	speed: 0.0995s/iter; left time: 2532.1137s
	iters: 200, epoch: 2 | loss: 0.4437015
	speed: 0.0258s/iter; left time: 652.9133s
Epoch: 2 cost time: 6.756246328353882
Epoch: 2, Steps: 258 | Train Loss: 0.4954195 Vali Loss: 0.2611147 Test Loss: 0.3528302
Validation loss decreased (0.261942 --> 0.261115).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4042980
	speed: 0.0978s/iter; left time: 2463.3118s
	iters: 200, epoch: 3 | loss: 0.4757081
	speed: 0.0224s/iter; left time: 561.5849s
Epoch: 3 cost time: 6.322279453277588
Epoch: 3, Steps: 258 | Train Loss: 0.4948466 Vali Loss: 0.2606593 Test Loss: 0.3524832
Validation loss decreased (0.261115 --> 0.260659).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4498033
	speed: 0.0962s/iter; left time: 2398.2009s
	iters: 200, epoch: 4 | loss: 0.3576551
	speed: 0.0227s/iter; left time: 562.6095s
Epoch: 4 cost time: 6.521533250808716
Epoch: 4, Steps: 258 | Train Loss: 0.4951225 Vali Loss: 0.2605778 Test Loss: 0.3525883
Validation loss decreased (0.260659 --> 0.260578).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4911513
	speed: 0.1072s/iter; left time: 2643.7135s
	iters: 200, epoch: 5 | loss: 0.4576809
	speed: 0.0236s/iter; left time: 580.2248s
Epoch: 5 cost time: 7.32754373550415
Epoch: 5, Steps: 258 | Train Loss: 0.4940583 Vali Loss: 0.2603669 Test Loss: 0.3527726
Validation loss decreased (0.260578 --> 0.260367).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.5523560
	speed: 0.0991s/iter; left time: 2420.0355s
	iters: 200, epoch: 6 | loss: 0.3942189
	speed: 0.0463s/iter; left time: 1126.0390s
Epoch: 6 cost time: 10.981093883514404
Epoch: 6, Steps: 258 | Train Loss: 0.4947517 Vali Loss: 0.2601610 Test Loss: 0.3524626
Validation loss decreased (0.260367 --> 0.260161).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4295380
	speed: 0.1256s/iter; left time: 3034.6490s
	iters: 200, epoch: 7 | loss: 0.4550710
	speed: 0.0290s/iter; left time: 698.3869s
Epoch: 7 cost time: 7.474949598312378
Epoch: 7, Steps: 258 | Train Loss: 0.4943614 Vali Loss: 0.2601185 Test Loss: 0.3523206
Validation loss decreased (0.260161 --> 0.260118).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.5573479
	speed: 0.1012s/iter; left time: 2417.7335s
	iters: 200, epoch: 8 | loss: 0.4911079
	speed: 0.0242s/iter; left time: 575.6947s
Epoch: 8 cost time: 6.613711595535278
Epoch: 8, Steps: 258 | Train Loss: 0.4939904 Vali Loss: 0.2605908 Test Loss: 0.3522525
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.6134115
	speed: 0.1034s/iter; left time: 2443.8542s
	iters: 200, epoch: 9 | loss: 0.5579721
	speed: 0.0233s/iter; left time: 547.3411s
Epoch: 9 cost time: 6.837723255157471
Epoch: 9, Steps: 258 | Train Loss: 0.4941037 Vali Loss: 0.2599271 Test Loss: 0.3523777
Validation loss decreased (0.260118 --> 0.259927).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4644394
	speed: 0.1010s/iter; left time: 2362.3972s
	iters: 200, epoch: 10 | loss: 0.6582924
	speed: 0.0243s/iter; left time: 565.8387s
Epoch: 10 cost time: 6.901350498199463
Epoch: 10, Steps: 258 | Train Loss: 0.4936003 Vali Loss: 0.2603485 Test Loss: 0.3520008
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.7674735
	speed: 0.1001s/iter; left time: 2314.7169s
	iters: 200, epoch: 11 | loss: 0.5882089
	speed: 0.0229s/iter; left time: 526.3105s
Epoch: 11 cost time: 6.627390146255493
Epoch: 11, Steps: 258 | Train Loss: 0.4934027 Vali Loss: 0.2598473 Test Loss: 0.3522656
Validation loss decreased (0.259927 --> 0.259847).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4088844
	speed: 0.0964s/iter; left time: 2204.3744s
	iters: 200, epoch: 12 | loss: 0.4726873
	speed: 0.0287s/iter; left time: 654.3086s
Epoch: 12 cost time: 7.245282888412476
Epoch: 12, Steps: 258 | Train Loss: 0.4931197 Vali Loss: 0.2602153 Test Loss: 0.3522626
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4979580
	speed: 0.1104s/iter; left time: 2495.3324s
	iters: 200, epoch: 13 | loss: 0.5195745
	speed: 0.0230s/iter; left time: 516.9331s
Epoch: 13 cost time: 7.73824405670166
Epoch: 13, Steps: 258 | Train Loss: 0.4937791 Vali Loss: 0.2594054 Test Loss: 0.3521255
Validation loss decreased (0.259847 --> 0.259405).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4572162
	speed: 0.1038s/iter; left time: 2318.9804s
	iters: 200, epoch: 14 | loss: 0.5111750
	speed: 0.0226s/iter; left time: 501.9658s
Epoch: 14 cost time: 6.758824348449707
Epoch: 14, Steps: 258 | Train Loss: 0.4936906 Vali Loss: 0.2597439 Test Loss: 0.3521729
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.5450297
	speed: 0.0994s/iter; left time: 2194.5652s
	iters: 200, epoch: 15 | loss: 0.3800641
	speed: 0.0240s/iter; left time: 527.2759s
Epoch: 15 cost time: 6.681608200073242
Epoch: 15, Steps: 258 | Train Loss: 0.4933783 Vali Loss: 0.2600625 Test Loss: 0.3522027
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4927064
	speed: 0.1012s/iter; left time: 2210.1380s
	iters: 200, epoch: 16 | loss: 0.4806298
	speed: 0.0242s/iter; left time: 525.1334s
Epoch: 16 cost time: 6.828306198120117
Epoch: 16, Steps: 258 | Train Loss: 0.4935200 Vali Loss: 0.2600031 Test Loss: 0.3522068
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.5095451
	speed: 0.1019s/iter; left time: 2197.2160s
	iters: 200, epoch: 17 | loss: 0.4427155
	speed: 0.0241s/iter; left time: 517.3469s
Epoch: 17 cost time: 6.907712459564209
Epoch: 17, Steps: 258 | Train Loss: 0.4931538 Vali Loss: 0.2598329 Test Loss: 0.3520786
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.5816038
	speed: 0.1023s/iter; left time: 2179.9219s
	iters: 200, epoch: 18 | loss: 0.5287190
	speed: 0.0235s/iter; left time: 498.7521s
Epoch: 18 cost time: 6.847872018814087
Epoch: 18, Steps: 258 | Train Loss: 0.4933314 Vali Loss: 0.2600550 Test Loss: 0.3521198
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.5606531
	speed: 0.0935s/iter; left time: 1967.8684s
	iters: 200, epoch: 19 | loss: 0.5342906
	speed: 0.0249s/iter; left time: 522.3000s
Epoch: 19 cost time: 6.775313377380371
Epoch: 19, Steps: 258 | Train Loss: 0.4935880 Vali Loss: 0.2597919 Test Loss: 0.3521580
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4860166
	speed: 0.0913s/iter; left time: 1898.2648s
	iters: 200, epoch: 20 | loss: 0.6128256
	speed: 0.0243s/iter; left time: 502.0906s
Epoch: 20 cost time: 6.629501104354858
Epoch: 20, Steps: 258 | Train Loss: 0.4931052 Vali Loss: 0.2599989 Test Loss: 0.3520255
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4469520
	speed: 0.0961s/iter; left time: 1973.2190s
	iters: 200, epoch: 21 | loss: 0.3691843
	speed: 0.0225s/iter; left time: 460.4472s
Epoch: 21 cost time: 6.537746429443359
Epoch: 21, Steps: 258 | Train Loss: 0.4933083 Vali Loss: 0.2602022 Test Loss: 0.3520939
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.6716958
	speed: 0.1010s/iter; left time: 2049.0545s
	iters: 200, epoch: 22 | loss: 0.4706631
	speed: 0.0218s/iter; left time: 440.5457s
Epoch: 22 cost time: 6.303181409835815
Epoch: 22, Steps: 258 | Train Loss: 0.4928302 Vali Loss: 0.2599605 Test Loss: 0.3520724
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4467937
	speed: 0.0982s/iter; left time: 1967.1583s
	iters: 200, epoch: 23 | loss: 0.5180539
	speed: 0.0228s/iter; left time: 454.8520s
Epoch: 23 cost time: 6.403093576431274
Epoch: 23, Steps: 258 | Train Loss: 0.4932756 Vali Loss: 0.2599291 Test Loss: 0.3520423
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4759621
	speed: 0.1020s/iter; left time: 2016.3940s
	iters: 200, epoch: 24 | loss: 0.4974333
	speed: 0.0232s/iter; left time: 456.8148s
Epoch: 24 cost time: 6.724472999572754
Epoch: 24, Steps: 258 | Train Loss: 0.4934598 Vali Loss: 0.2598992 Test Loss: 0.3520718
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4001998
	speed: 0.1011s/iter; left time: 1972.7816s
	iters: 200, epoch: 25 | loss: 0.4338084
	speed: 0.0237s/iter; left time: 459.9303s
Epoch: 25 cost time: 6.841462135314941
Epoch: 25, Steps: 258 | Train Loss: 0.4930500 Vali Loss: 0.2598073 Test Loss: 0.3520052
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4940892
	speed: 0.1017s/iter; left time: 1957.2646s
	iters: 200, epoch: 26 | loss: 0.4157888
	speed: 0.0231s/iter; left time: 441.8608s
Epoch: 26 cost time: 6.7736194133758545
Epoch: 26, Steps: 258 | Train Loss: 0.4926733 Vali Loss: 0.2597649 Test Loss: 0.3520443
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4559159
	speed: 0.1030s/iter; left time: 1955.3470s
	iters: 200, epoch: 27 | loss: 0.6373281
	speed: 0.0249s/iter; left time: 470.2145s
Epoch: 27 cost time: 7.03205943107605
Epoch: 27, Steps: 258 | Train Loss: 0.4930711 Vali Loss: 0.2599438 Test Loss: 0.3520251
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4796389
	speed: 0.1038s/iter; left time: 1944.2805s
	iters: 200, epoch: 28 | loss: 0.4783049
	speed: 0.0248s/iter; left time: 462.3342s
Epoch: 28 cost time: 7.037813186645508
Epoch: 28, Steps: 258 | Train Loss: 0.4928910 Vali Loss: 0.2599314 Test Loss: 0.3519319
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3843310
	speed: 0.1196s/iter; left time: 2210.1991s
	iters: 200, epoch: 29 | loss: 0.4152594
	speed: 0.0238s/iter; left time: 437.7808s
Epoch: 29 cost time: 8.85765814781189
Epoch: 29, Steps: 258 | Train Loss: 0.4931019 Vali Loss: 0.2598422 Test Loss: 0.3520253
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.5009057
	speed: 0.1024s/iter; left time: 1865.7528s
	iters: 200, epoch: 30 | loss: 0.5364874
	speed: 0.0292s/iter; left time: 529.3574s
Epoch: 30 cost time: 7.3456761837005615
Epoch: 30, Steps: 258 | Train Loss: 0.4930074 Vali Loss: 0.2601215 Test Loss: 0.3519647
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4811927
	speed: 0.1014s/iter; left time: 1822.0161s
	iters: 200, epoch: 31 | loss: 0.4482706
	speed: 0.0236s/iter; left time: 421.5732s
Epoch: 31 cost time: 6.7773120403289795
Epoch: 31, Steps: 258 | Train Loss: 0.4928605 Vali Loss: 0.2597648 Test Loss: 0.3521057
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.5198564
	speed: 0.1052s/iter; left time: 1863.0089s
	iters: 200, epoch: 32 | loss: 0.5184036
	speed: 0.0235s/iter; left time: 412.8922s
Epoch: 32 cost time: 7.391395568847656
Epoch: 32, Steps: 258 | Train Loss: 0.4932652 Vali Loss: 0.2598337 Test Loss: 0.3520365
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4720884
	speed: 0.1041s/iter; left time: 1815.2957s
	iters: 200, epoch: 33 | loss: 0.4005016
	speed: 0.0253s/iter; left time: 439.1553s
Epoch: 33 cost time: 7.143779993057251
Epoch: 33, Steps: 258 | Train Loss: 0.4934246 Vali Loss: 0.2600021 Test Loss: 0.3519613
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_720_720_FITS_ETTm2_ftM_sl720_ll48_pl720_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.3487663269042969, mae:0.37791234254837036, rse:0.4746917188167572, corr:[0.5446247  0.54549855 0.54170257 0.5399734  0.54058784 0.5412867
 0.54055977 0.5392337  0.5385925  0.53884506 0.53919804 0.5388566
 0.53800505 0.5373656  0.53736013 0.5376012  0.5374012  0.5365104
 0.5353359  0.53445035 0.53409153 0.5339453  0.5335636  0.53285646
 0.5321118  0.53164744 0.53144807 0.5311969  0.5306047  0.5297598
 0.52898526 0.5285404  0.5283024  0.52795225 0.52734387 0.52658314
 0.5258607  0.525307   0.524815   0.52423716 0.523526   0.52278405
 0.5222061  0.52181816 0.5214626  0.52090275 0.5200826  0.51915115
 0.51830727 0.517668   0.51719594 0.5166969  0.51593965 0.514957
 0.5140238  0.5134144  0.51315606 0.5130595  0.51290935 0.51258004
 0.51214474 0.5117452  0.51144844 0.5112205  0.5110303  0.5109051
 0.51075834 0.51058996 0.5103145  0.50989676 0.5094081  0.5089736
 0.5086787  0.5084944  0.5082441  0.5078079  0.5072068  0.50653267
 0.505899   0.5053002  0.5046622  0.504019   0.5034302  0.5029409
 0.5025363  0.5021109  0.501528   0.50085187 0.50018054 0.49964747
 0.49928892 0.49894953 0.49841914 0.49762598 0.49658954 0.49539405
 0.4941242  0.49284586 0.49152106 0.49020943 0.48900393 0.48790005
 0.48679984 0.48557216 0.48418972 0.48281956 0.4816839  0.48084655
 0.4801086  0.47930998 0.47841448 0.47749016 0.4766877  0.4759388
 0.47507867 0.47405082 0.4729665  0.47202373 0.4714207  0.47103778
 0.47061092 0.469777   0.46849784 0.46699664 0.4656928  0.4648494
 0.4643762  0.4638766  0.46303988 0.4618687  0.4606433  0.45959562
 0.4587445  0.45788416 0.45692515 0.45600545 0.45538324 0.45519534
 0.4551781  0.45490155 0.45411125 0.4529966  0.4520392  0.45154843
 0.45148784 0.45140642 0.45098868 0.45006555 0.44881836 0.44751638
 0.44640827 0.44553584 0.44474098 0.4439965  0.4434008  0.4430081
 0.44272158 0.4423939  0.44193998 0.44148576 0.4410281  0.44052935
 0.43985966 0.4390677  0.43841544 0.4382416  0.43857342 0.4390705
 0.4392544  0.43886694 0.43793985 0.4369491  0.43636787 0.4362918
 0.43631014 0.43596423 0.43514076 0.43414065 0.43338865 0.43311316
 0.43303066 0.4327642  0.43220663 0.4314875  0.4308437  0.43036124
 0.42993    0.4292922  0.42839283 0.4273923  0.4265238  0.42580023
 0.42503276 0.42407167 0.42267138 0.42100224 0.41947496 0.41826388
 0.41729563 0.4162973  0.4151049  0.41376254 0.41246653 0.41138184
 0.4104901  0.40962115 0.40860102 0.4073693  0.40604734 0.4047739
 0.40351036 0.40234637 0.40141696 0.40072763 0.40010896 0.39922443
 0.39795431 0.3964209  0.39503655 0.39390868 0.392844   0.3915865
 0.39008278 0.3886289  0.38767236 0.38721076 0.386924   0.38633758
 0.38509074 0.3834249  0.38189998 0.38099834 0.38067177 0.38049445
 0.3799872  0.37911892 0.3781773  0.37751594 0.37725016 0.3770918
 0.3767533  0.37616733 0.37568256 0.37574854 0.37619022 0.37658173
 0.3764106  0.37555394 0.3743273  0.37329894 0.3729746  0.37328482
 0.37383685 0.37429821 0.37439585 0.37419558 0.37381038 0.37343228
 0.3731289  0.37294018 0.37281138 0.37264836 0.37227222 0.37170854
 0.37108856 0.3705945  0.37044433 0.3705422  0.37055105 0.37020487
 0.3696657  0.36925426 0.3691214  0.3691794  0.36902347 0.368371
 0.36740357 0.36644873 0.36586925 0.36578178 0.3657837  0.36553204
 0.36490336 0.36421517 0.36383837 0.36377087 0.3636137  0.36280346
 0.36130255 0.3596426  0.35830173 0.3575307  0.3571879  0.35680023
 0.35612887 0.3550874  0.35384852 0.3527462  0.3520811  0.35181496
 0.35185584 0.35186115 0.3517033  0.3511704  0.35041326 0.34966055
 0.3491936  0.349004   0.34900272 0.34899548 0.3488243  0.3485843
 0.3482696  0.3480538  0.34787753 0.3476008  0.34718612 0.34672156
 0.34629142 0.3460868  0.34612554 0.34617656 0.3459894  0.34554684
 0.34502587 0.34475455 0.34487453 0.34516704 0.34542835 0.34540164
 0.34518772 0.3449331  0.344891   0.34518427 0.3456015  0.34599262
 0.34613052 0.34586987 0.34541655 0.3450304  0.34476963 0.34454867
 0.34433174 0.34409693 0.34382695 0.34354395 0.34330267 0.3431805
 0.3431365  0.3431415  0.34311408 0.34301943 0.342942   0.34295085
 0.3430744  0.34326893 0.34330076 0.3431585  0.34276012 0.34236148
 0.34213156 0.3420631  0.34195152 0.3415955  0.34095362 0.34033638
 0.33998787 0.34013465 0.34062445 0.34117275 0.34157017 0.3416949
 0.3416393  0.34150642 0.34125286 0.34081316 0.34028754 0.34001243
 0.3402346  0.34084064 0.341401   0.34145316 0.3409509  0.34002116
 0.33914867 0.33860102 0.3382573  0.33770835 0.33665374 0.33524555
 0.333759   0.33251208 0.33159992 0.33093798 0.3304197  0.3300178
 0.3298414  0.32995307 0.33012488 0.3301523  0.32995352 0.32940236
 0.32855517 0.32753602 0.32652637 0.32569838 0.3250872  0.3248317
 0.32489246 0.32518798 0.3254288  0.32536036 0.32501745 0.32450402
 0.3240918  0.32395273 0.32406527 0.32431144 0.324473   0.32442358
 0.32414165 0.3236483  0.32304102 0.32258758 0.3225317  0.32291958
 0.32356316 0.3240821  0.32426876 0.32413223 0.3239325  0.32393432
 0.32418633 0.32442912 0.32447883 0.3242975  0.32402858 0.32376793
 0.3234414  0.32307446 0.32249966 0.3216989  0.32095104 0.32060432
 0.32063392 0.32088923 0.32103962 0.32088464 0.32054377 0.32016212
 0.31986296 0.31956404 0.31913984 0.31849408 0.31785357 0.3175359
 0.31761166 0.31788743 0.31800547 0.31776673 0.31734842 0.316899
 0.31665745 0.3166534  0.3167158  0.31664607 0.31636277 0.3159874
 0.31567484 0.31541082 0.3150484  0.31449354 0.31385013 0.3132303
 0.31279835 0.31252933 0.31233835 0.31195864 0.31126192 0.31020424
 0.3088548  0.30746388 0.30607858 0.30474925 0.3035147  0.30239594
 0.3014159  0.30068383 0.30013642 0.29970396 0.2991401  0.298289
 0.29720274 0.29615888 0.29533198 0.29465097 0.2940135  0.29329112
 0.29248855 0.291671   0.29099354 0.29058707 0.2902477  0.2898201
 0.2890422  0.28796983 0.28692886 0.28619733 0.28593478 0.28593996
 0.28592607 0.28571895 0.2852931  0.28475794 0.28422374 0.28366086
 0.28298104 0.28217676 0.28159603 0.2813258  0.28132218 0.28146228
 0.28157035 0.28161955 0.28159684 0.28156936 0.28157648 0.28150475
 0.28125232 0.28089476 0.28057626 0.2804294  0.28041887 0.2802925
 0.27982432 0.27910116 0.27853236 0.27837604 0.27860373 0.2789175
 0.27896634 0.2786846  0.27825835 0.27804157 0.27809888 0.27815685
 0.27793473 0.27739334 0.27672166 0.2762184  0.2759782  0.27597412
 0.27595183 0.27580097 0.27555713 0.27538058 0.2752319  0.27518874
 0.27511194 0.27496126 0.27460715 0.2740572  0.27345827 0.2729867
 0.27281004 0.27297774 0.27343363 0.27390823 0.2741249  0.27395794
 0.2734319  0.27274704 0.27207166 0.27152395 0.27099764 0.27018118
 0.26896504 0.2676709  0.2665104  0.265586   0.26482007 0.26410633
 0.263354   0.26251084 0.26162106 0.2607524  0.25994882 0.25930068
 0.25874823 0.25815794 0.25749612 0.25667924 0.25573686 0.25486678
 0.25420544 0.25376686 0.25356564 0.2534041  0.2532311  0.2530076
 0.25272158 0.2525065  0.25232327 0.25213197 0.25199124 0.25185597
 0.25153685 0.25102082 0.25041422 0.24973483 0.24919769 0.24892412
 0.24900201 0.24915344 0.24931112 0.24950527 0.24971078 0.24988857
 0.25001603 0.25014883 0.25020644 0.2502427  0.2503496  0.25067577
 0.2512195  0.25190678 0.25265685 0.25341642 0.25398234 0.2541795
 0.25397348 0.25361556 0.25336933 0.25307682 0.2528042  0.25231627
 0.25157472 0.2507959  0.25016862 0.24999593 0.25004515 0.2501324
 0.2500772  0.25000018 0.24984212 0.24950527 0.24921565 0.24888009
 0.24874498 0.24885538 0.24912645 0.2492483  0.24905267 0.24839844
 0.24781492 0.24768615 0.24804494 0.248705   0.24913293 0.24885964
 0.24791828 0.24700017 0.24655373 0.24678251 0.24754862 0.24834424
 0.24873799 0.24870549 0.24833871 0.24765284 0.24670298 0.24559703
 0.24440625 0.24320203 0.24204448 0.2410087  0.24027777 0.23978315
 0.23931484 0.23865741 0.2380455  0.2374861  0.23719406 0.23712057
 0.23701882 0.23654908 0.23554792 0.23424703 0.23330124 0.23294094
 0.23307064 0.2331512  0.23263244 0.23168445 0.23066442 0.22999902
 0.2297548  0.2294591  0.22876531 0.22758849 0.2265277  0.22613795
 0.22655882 0.22699563 0.22685686 0.22607729 0.22511981 0.22450666
 0.22412392 0.22357418 0.2226058  0.22179706 0.22155198 0.22186
 0.22161159 0.21980225 0.2171484  0.21593165 0.21682066 0.21502292]
