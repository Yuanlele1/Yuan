Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=22, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_90_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_90_96_FITS_ETTm2_ftM_sl90_ll48_pl96_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34375
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=22, out_features=45, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  887040.0
params:  1035.0
Trainable parameters:  1035
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2941221
	speed: 0.0226s/iter; left time: 604.0614s
	iters: 200, epoch: 1 | loss: 0.2519380
	speed: 0.0151s/iter; left time: 401.1770s
Epoch: 1 cost time: 4.845067024230957
Epoch: 1, Steps: 268 | Train Loss: 0.2988644 Vali Loss: 0.1426383 Test Loss: 0.2032180
Validation loss decreased (inf --> 0.142638).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2093845
	speed: 0.1043s/iter; left time: 2757.9921s
	iters: 200, epoch: 2 | loss: 0.1714513
	speed: 0.0384s/iter; left time: 1012.0325s
Epoch: 2 cost time: 9.238528728485107
Epoch: 2, Steps: 268 | Train Loss: 0.2579878 Vali Loss: 0.1333344 Test Loss: 0.1911076
Validation loss decreased (0.142638 --> 0.133334).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2268881
	speed: 0.1097s/iter; left time: 2870.0495s
	iters: 200, epoch: 3 | loss: 0.2677878
	speed: 0.0262s/iter; left time: 684.0266s
Epoch: 3 cost time: 6.972975254058838
Epoch: 3, Steps: 268 | Train Loss: 0.2493078 Vali Loss: 0.1308280 Test Loss: 0.1873816
Validation loss decreased (0.133334 --> 0.130828).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4240105
	speed: 0.0960s/iter; left time: 2486.7711s
	iters: 200, epoch: 4 | loss: 0.2219127
	speed: 0.0218s/iter; left time: 561.6316s
Epoch: 4 cost time: 5.4228596687316895
Epoch: 4, Steps: 268 | Train Loss: 0.2460834 Vali Loss: 0.1299093 Test Loss: 0.1859412
Validation loss decreased (0.130828 --> 0.129909).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2019831
	speed: 0.1048s/iter; left time: 2685.0684s
	iters: 200, epoch: 5 | loss: 0.2055784
	speed: 0.0169s/iter; left time: 432.1230s
Epoch: 5 cost time: 5.7457780838012695
Epoch: 5, Steps: 268 | Train Loss: 0.2446358 Vali Loss: 0.1295469 Test Loss: 0.1851341
Validation loss decreased (0.129909 --> 0.129547).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2043264
	speed: 0.1023s/iter; left time: 2593.4527s
	iters: 200, epoch: 6 | loss: 0.1967472
	speed: 0.0158s/iter; left time: 398.9909s
Epoch: 6 cost time: 4.87777853012085
Epoch: 6, Steps: 268 | Train Loss: 0.2434684 Vali Loss: 0.1294951 Test Loss: 0.1849254
Validation loss decreased (0.129547 --> 0.129495).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2543913
	speed: 0.0912s/iter; left time: 2288.6816s
	iters: 200, epoch: 7 | loss: 0.1592243
	speed: 0.0158s/iter; left time: 394.6490s
Epoch: 7 cost time: 5.009286880493164
Epoch: 7, Steps: 268 | Train Loss: 0.2424641 Vali Loss: 0.1294383 Test Loss: 0.1846357
Validation loss decreased (0.129495 --> 0.129438).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2079850
	speed: 0.1230s/iter; left time: 3053.9617s
	iters: 200, epoch: 8 | loss: 0.2279389
	speed: 0.0221s/iter; left time: 545.5860s
Epoch: 8 cost time: 6.9640984535217285
Epoch: 8, Steps: 268 | Train Loss: 0.2419223 Vali Loss: 0.1295098 Test Loss: 0.1845264
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4005942
	speed: 0.0995s/iter; left time: 2444.1882s
	iters: 200, epoch: 9 | loss: 0.2595561
	speed: 0.0200s/iter; left time: 487.9902s
Epoch: 9 cost time: 5.261751890182495
Epoch: 9, Steps: 268 | Train Loss: 0.2417257 Vali Loss: 0.1296125 Test Loss: 0.1844914
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1595418
	speed: 0.1012s/iter; left time: 2458.1270s
	iters: 200, epoch: 10 | loss: 0.2857732
	speed: 0.0176s/iter; left time: 424.6486s
Epoch: 10 cost time: 6.234739065170288
Epoch: 10, Steps: 268 | Train Loss: 0.2416961 Vali Loss: 0.1297526 Test Loss: 0.1844977
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1824736
	speed: 0.0926s/iter; left time: 2224.6326s
	iters: 200, epoch: 11 | loss: 0.2143565
	speed: 0.0198s/iter; left time: 473.7179s
Epoch: 11 cost time: 5.206289052963257
Epoch: 11, Steps: 268 | Train Loss: 0.2413369 Vali Loss: 0.1297628 Test Loss: 0.1844391
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2244959
	speed: 0.0960s/iter; left time: 2281.1518s
	iters: 200, epoch: 12 | loss: 0.3275526
	speed: 0.0170s/iter; left time: 403.1866s
Epoch: 12 cost time: 5.205089092254639
Epoch: 12, Steps: 268 | Train Loss: 0.2413333 Vali Loss: 0.1297881 Test Loss: 0.1843994
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2655116
	speed: 0.0943s/iter; left time: 2214.7398s
	iters: 200, epoch: 13 | loss: 0.2770555
	speed: 0.0179s/iter; left time: 417.6991s
Epoch: 13 cost time: 5.100823163986206
Epoch: 13, Steps: 268 | Train Loss: 0.2412031 Vali Loss: 0.1297084 Test Loss: 0.1843442
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2063511
	speed: 0.0918s/iter; left time: 2130.1835s
	iters: 200, epoch: 14 | loss: 0.1698652
	speed: 0.0164s/iter; left time: 380.0211s
Epoch: 14 cost time: 6.070123195648193
Epoch: 14, Steps: 268 | Train Loss: 0.2407101 Vali Loss: 0.1296276 Test Loss: 0.1842764
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2820051
	speed: 0.1247s/iter; left time: 2861.1694s
	iters: 200, epoch: 15 | loss: 0.2314544
	speed: 0.0279s/iter; left time: 638.2030s
Epoch: 15 cost time: 8.768842697143555
Epoch: 15, Steps: 268 | Train Loss: 0.2407212 Vali Loss: 0.1295992 Test Loss: 0.1843099
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2042809
	speed: 0.1013s/iter; left time: 2297.1770s
	iters: 200, epoch: 16 | loss: 0.2243980
	speed: 0.0184s/iter; left time: 415.3239s
Epoch: 16 cost time: 6.323923349380493
Epoch: 16, Steps: 268 | Train Loss: 0.2407551 Vali Loss: 0.1295667 Test Loss: 0.1842575
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3264273
	speed: 0.0887s/iter; left time: 1988.5394s
	iters: 200, epoch: 17 | loss: 0.2538791
	speed: 0.0153s/iter; left time: 341.9335s
Epoch: 17 cost time: 4.789598703384399
Epoch: 17, Steps: 268 | Train Loss: 0.2406658 Vali Loss: 0.1298168 Test Loss: 0.1842965
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2127675
	speed: 0.0974s/iter; left time: 2157.8568s
	iters: 200, epoch: 18 | loss: 0.2087879
	speed: 0.0226s/iter; left time: 497.4594s
Epoch: 18 cost time: 6.6338279247283936
Epoch: 18, Steps: 268 | Train Loss: 0.2407078 Vali Loss: 0.1297259 Test Loss: 0.1842567
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2406662
	speed: 0.0926s/iter; left time: 2026.3526s
	iters: 200, epoch: 19 | loss: 0.2023046
	speed: 0.0182s/iter; left time: 396.9446s
Epoch: 19 cost time: 5.570185899734497
Epoch: 19, Steps: 268 | Train Loss: 0.2406318 Vali Loss: 0.1297276 Test Loss: 0.1841975
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2593262
	speed: 0.0870s/iter; left time: 1880.5439s
	iters: 200, epoch: 20 | loss: 0.2406263
	speed: 0.0177s/iter; left time: 381.3378s
Epoch: 20 cost time: 5.008789300918579
Epoch: 20, Steps: 268 | Train Loss: 0.2404670 Vali Loss: 0.1298012 Test Loss: 0.1842276
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2185689
	speed: 0.0847s/iter; left time: 1808.3957s
	iters: 200, epoch: 21 | loss: 0.1849371
	speed: 0.0170s/iter; left time: 360.1280s
Epoch: 21 cost time: 4.92737889289856
Epoch: 21, Steps: 268 | Train Loss: 0.2405453 Vali Loss: 0.1298743 Test Loss: 0.1842694
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2306361
	speed: 0.1026s/iter; left time: 2161.3630s
	iters: 200, epoch: 22 | loss: 0.3157819
	speed: 0.0212s/iter; left time: 444.2598s
Epoch: 22 cost time: 5.348952054977417
Epoch: 22, Steps: 268 | Train Loss: 0.2403755 Vali Loss: 0.1299144 Test Loss: 0.1842612
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2012579
	speed: 0.0903s/iter; left time: 1879.4752s
	iters: 200, epoch: 23 | loss: 0.2560657
	speed: 0.0191s/iter; left time: 395.3185s
Epoch: 23 cost time: 6.046844482421875
Epoch: 23, Steps: 268 | Train Loss: 0.2403637 Vali Loss: 0.1297672 Test Loss: 0.1842778
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2192968
	speed: 0.1051s/iter; left time: 2158.8389s
	iters: 200, epoch: 24 | loss: 0.2182473
	speed: 0.0159s/iter; left time: 324.7371s
Epoch: 24 cost time: 5.550178050994873
Epoch: 24, Steps: 268 | Train Loss: 0.2406317 Vali Loss: 0.1297838 Test Loss: 0.1842504
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1667162
	speed: 0.0922s/iter; left time: 1867.9982s
	iters: 200, epoch: 25 | loss: 0.2307295
	speed: 0.0165s/iter; left time: 333.1283s
Epoch: 25 cost time: 5.019493341445923
Epoch: 25, Steps: 268 | Train Loss: 0.2404277 Vali Loss: 0.1298637 Test Loss: 0.1842301
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2536054
	speed: 0.1052s/iter; left time: 2104.9967s
	iters: 200, epoch: 26 | loss: 0.2263790
	speed: 0.0220s/iter; left time: 438.1487s
Epoch: 26 cost time: 5.616732120513916
Epoch: 26, Steps: 268 | Train Loss: 0.2401404 Vali Loss: 0.1298725 Test Loss: 0.1842800
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2535059
	speed: 0.0974s/iter; left time: 1921.7421s
	iters: 200, epoch: 27 | loss: 0.3359036
	speed: 0.0230s/iter; left time: 451.8127s
Epoch: 27 cost time: 5.946088552474976
Epoch: 27, Steps: 268 | Train Loss: 0.2404717 Vali Loss: 0.1299033 Test Loss: 0.1842630
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_90_96_FITS_ETTm2_ftM_sl90_ll48_pl96_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.18548890948295593, mae:0.2690576910972595, rse:0.34918463230133057, corr:[0.5695192  0.5717376  0.56309515 0.5617661  0.5632611  0.5609286
 0.5580189  0.55833673 0.55893475 0.5572687  0.55557215 0.55595666
 0.5562907  0.5547135  0.55278206 0.55261785 0.5527813  0.55152583
 0.5498518  0.5493032  0.54903084 0.5477354  0.5462041  0.54590356
 0.54608434 0.54537255 0.54437894 0.5443285  0.54460686 0.5439429
 0.54252535 0.5417239  0.54170567 0.54138756 0.54043734 0.53967893
 0.53940666 0.5389537  0.5381046  0.537355   0.5369831  0.53664225
 0.5360009  0.53552336 0.535517   0.53532547 0.5345865  0.5335888
 0.53297096 0.53246975 0.53159195 0.5305047  0.52980924 0.5294349
 0.5289818  0.5281877  0.5274573  0.5271621  0.52693236 0.5264511
 0.5259499  0.52580464 0.5259181  0.5258945  0.5256147  0.525448
 0.5255047  0.5253912  0.52509046 0.5249117  0.5250903  0.5253691
 0.5253295  0.5251622  0.52513295 0.52524555 0.525151   0.52484274
 0.5247251  0.5248215  0.5246539  0.5241372  0.52389765 0.5240703
 0.5240331  0.52349997 0.52308637 0.52328473 0.5233068  0.5228192
 0.52269804 0.52326816 0.5231948  0.52220786 0.5223351  0.52128243]
