Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=42, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_360_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_360_720_FITS_ETTm2_ftM_sl360_ll48_pl720_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33481
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=42, out_features=126, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4741632.0
params:  5418.0
Trainable parameters:  5418
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6971924
	speed: 0.0243s/iter; left time: 632.3403s
	iters: 200, epoch: 1 | loss: 0.6503460
	speed: 0.0171s/iter; left time: 442.0285s
Epoch: 1 cost time: 5.116983890533447
Epoch: 1, Steps: 261 | Train Loss: 0.6282981 Vali Loss: 0.2897459 Test Loss: 0.3942697
Validation loss decreased (inf --> 0.289746).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4290119
	speed: 0.0755s/iter; left time: 1944.5798s
	iters: 200, epoch: 2 | loss: 0.5441640
	speed: 0.0155s/iter; left time: 398.5507s
Epoch: 2 cost time: 4.597196817398071
Epoch: 2, Steps: 261 | Train Loss: 0.5479094 Vali Loss: 0.2771626 Test Loss: 0.3798648
Validation loss decreased (0.289746 --> 0.277163).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5818531
	speed: 0.0757s/iter; left time: 1929.9592s
	iters: 200, epoch: 3 | loss: 0.4695353
	speed: 0.0155s/iter; left time: 393.2161s
Epoch: 3 cost time: 4.697699785232544
Epoch: 3, Steps: 261 | Train Loss: 0.5365744 Vali Loss: 0.2729958 Test Loss: 0.3756382
Validation loss decreased (0.277163 --> 0.272996).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3946940
	speed: 0.0746s/iter; left time: 1880.2192s
	iters: 200, epoch: 4 | loss: 0.5067637
	speed: 0.0159s/iter; left time: 398.4638s
Epoch: 4 cost time: 4.640925645828247
Epoch: 4, Steps: 261 | Train Loss: 0.5307624 Vali Loss: 0.2707175 Test Loss: 0.3733623
Validation loss decreased (0.272996 --> 0.270717).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.6205847
	speed: 0.0755s/iter; left time: 1883.4656s
	iters: 200, epoch: 5 | loss: 0.4836470
	speed: 0.0172s/iter; left time: 427.0523s
Epoch: 5 cost time: 4.971649885177612
Epoch: 5, Steps: 261 | Train Loss: 0.5274312 Vali Loss: 0.2691332 Test Loss: 0.3721536
Validation loss decreased (0.270717 --> 0.269133).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.5111393
	speed: 0.0820s/iter; left time: 2026.2266s
	iters: 200, epoch: 6 | loss: 0.4078132
	speed: 0.0168s/iter; left time: 412.6521s
Epoch: 6 cost time: 4.9954071044921875
Epoch: 6, Steps: 261 | Train Loss: 0.5244675 Vali Loss: 0.2680033 Test Loss: 0.3713223
Validation loss decreased (0.269133 --> 0.268003).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.8441132
	speed: 0.0922s/iter; left time: 2251.8932s
	iters: 200, epoch: 7 | loss: 0.6297962
	speed: 0.0152s/iter; left time: 369.7480s
Epoch: 7 cost time: 4.875894546508789
Epoch: 7, Steps: 261 | Train Loss: 0.5242796 Vali Loss: 0.2674176 Test Loss: 0.3707142
Validation loss decreased (0.268003 --> 0.267418).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.5882641
	speed: 0.0759s/iter; left time: 1835.9913s
	iters: 200, epoch: 8 | loss: 0.5992350
	speed: 0.0153s/iter; left time: 368.4171s
Epoch: 8 cost time: 4.467015027999878
Epoch: 8, Steps: 261 | Train Loss: 0.5225809 Vali Loss: 0.2667991 Test Loss: 0.3703581
Validation loss decreased (0.267418 --> 0.266799).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.5370292
	speed: 0.0750s/iter; left time: 1793.3062s
	iters: 200, epoch: 9 | loss: 0.5713406
	speed: 0.0152s/iter; left time: 361.9885s
Epoch: 9 cost time: 4.589857816696167
Epoch: 9, Steps: 261 | Train Loss: 0.5218433 Vali Loss: 0.2666454 Test Loss: 0.3700859
Validation loss decreased (0.266799 --> 0.266645).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4840309
	speed: 0.0753s/iter; left time: 1780.1503s
	iters: 200, epoch: 10 | loss: 0.5159999
	speed: 0.0156s/iter; left time: 366.4824s
Epoch: 10 cost time: 4.617400884628296
Epoch: 10, Steps: 261 | Train Loss: 0.5212445 Vali Loss: 0.2661187 Test Loss: 0.3698468
Validation loss decreased (0.266645 --> 0.266119).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3582660
	speed: 0.0782s/iter; left time: 1828.5363s
	iters: 200, epoch: 11 | loss: 0.5958272
	speed: 0.0169s/iter; left time: 394.2211s
Epoch: 11 cost time: 4.987846374511719
Epoch: 11, Steps: 261 | Train Loss: 0.5205680 Vali Loss: 0.2656852 Test Loss: 0.3695888
Validation loss decreased (0.266119 --> 0.265685).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.5354495
	speed: 0.0820s/iter; left time: 1897.8107s
	iters: 200, epoch: 12 | loss: 0.7248279
	speed: 0.0166s/iter; left time: 382.9388s
Epoch: 12 cost time: 4.857006549835205
Epoch: 12, Steps: 261 | Train Loss: 0.5204273 Vali Loss: 0.2656105 Test Loss: 0.3694911
Validation loss decreased (0.265685 --> 0.265611).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3532442
	speed: 0.0812s/iter; left time: 1857.4850s
	iters: 200, epoch: 13 | loss: 0.5233207
	speed: 0.0164s/iter; left time: 373.2345s
Epoch: 13 cost time: 4.937272310256958
Epoch: 13, Steps: 261 | Train Loss: 0.5198669 Vali Loss: 0.2653218 Test Loss: 0.3693409
Validation loss decreased (0.265611 --> 0.265322).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3964488
	speed: 0.0777s/iter; left time: 1757.4403s
	iters: 200, epoch: 14 | loss: 0.4290807
	speed: 0.0156s/iter; left time: 351.4598s
Epoch: 14 cost time: 4.6805665493011475
Epoch: 14, Steps: 261 | Train Loss: 0.5197301 Vali Loss: 0.2651432 Test Loss: 0.3692417
Validation loss decreased (0.265322 --> 0.265143).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4694978
	speed: 0.0795s/iter; left time: 1776.2803s
	iters: 200, epoch: 15 | loss: 0.5963923
	speed: 0.0160s/iter; left time: 355.8470s
Epoch: 15 cost time: 4.910252809524536
Epoch: 15, Steps: 261 | Train Loss: 0.5192927 Vali Loss: 0.2649226 Test Loss: 0.3692288
Validation loss decreased (0.265143 --> 0.264923).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.5894020
	speed: 0.0755s/iter; left time: 1666.9184s
	iters: 200, epoch: 16 | loss: 0.3761798
	speed: 0.0158s/iter; left time: 347.2638s
Epoch: 16 cost time: 4.685845136642456
Epoch: 16, Steps: 261 | Train Loss: 0.5190328 Vali Loss: 0.2648022 Test Loss: 0.3691353
Validation loss decreased (0.264923 --> 0.264802).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4883119
	speed: 0.0768s/iter; left time: 1676.6221s
	iters: 200, epoch: 17 | loss: 0.7764325
	speed: 0.0167s/iter; left time: 361.7561s
Epoch: 17 cost time: 4.861504077911377
Epoch: 17, Steps: 261 | Train Loss: 0.5185793 Vali Loss: 0.2650858 Test Loss: 0.3690253
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4570464
	speed: 0.0789s/iter; left time: 1700.4715s
	iters: 200, epoch: 18 | loss: 0.5302296
	speed: 0.0167s/iter; left time: 358.2459s
Epoch: 18 cost time: 4.920320510864258
Epoch: 18, Steps: 261 | Train Loss: 0.5181839 Vali Loss: 0.2646022 Test Loss: 0.3690044
Validation loss decreased (0.264802 --> 0.264602).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.7508848
	speed: 0.0793s/iter; left time: 1688.9579s
	iters: 200, epoch: 19 | loss: 0.4834984
	speed: 0.0164s/iter; left time: 348.7111s
Epoch: 19 cost time: 4.917611360549927
Epoch: 19, Steps: 261 | Train Loss: 0.5184335 Vali Loss: 0.2646339 Test Loss: 0.3690053
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.5237581
	speed: 0.0815s/iter; left time: 1715.6915s
	iters: 200, epoch: 20 | loss: 0.4488226
	speed: 0.0168s/iter; left time: 351.7616s
Epoch: 20 cost time: 5.060279130935669
Epoch: 20, Steps: 261 | Train Loss: 0.5182541 Vali Loss: 0.2645661 Test Loss: 0.3689680
Validation loss decreased (0.264602 --> 0.264566).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3621219
	speed: 0.0809s/iter; left time: 1680.5787s
	iters: 200, epoch: 21 | loss: 0.5261928
	speed: 0.0233s/iter; left time: 481.7457s
Epoch: 21 cost time: 7.033885955810547
Epoch: 21, Steps: 261 | Train Loss: 0.5183159 Vali Loss: 0.2647826 Test Loss: 0.3689557
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.5880055
	speed: 0.0888s/iter; left time: 1822.1794s
	iters: 200, epoch: 22 | loss: 0.5490178
	speed: 0.0154s/iter; left time: 314.3288s
Epoch: 22 cost time: 4.5368287563323975
Epoch: 22, Steps: 261 | Train Loss: 0.5183059 Vali Loss: 0.2644698 Test Loss: 0.3688878
Validation loss decreased (0.264566 --> 0.264470).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.5644977
	speed: 0.0750s/iter; left time: 1519.0591s
	iters: 200, epoch: 23 | loss: 0.5685912
	speed: 0.0152s/iter; left time: 305.7672s
Epoch: 23 cost time: 4.64107084274292
Epoch: 23, Steps: 261 | Train Loss: 0.5176583 Vali Loss: 0.2643266 Test Loss: 0.3689142
Validation loss decreased (0.264470 --> 0.264327).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.5404527
	speed: 0.0786s/iter; left time: 1571.4328s
	iters: 200, epoch: 24 | loss: 0.5078253
	speed: 0.0168s/iter; left time: 334.3918s
Epoch: 24 cost time: 5.0519022941589355
Epoch: 24, Steps: 261 | Train Loss: 0.5182503 Vali Loss: 0.2644332 Test Loss: 0.3688999
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.5573095
	speed: 0.0766s/iter; left time: 1511.0217s
	iters: 200, epoch: 25 | loss: 0.4487583
	speed: 0.0154s/iter; left time: 302.2577s
Epoch: 25 cost time: 4.645998001098633
Epoch: 25, Steps: 261 | Train Loss: 0.5184485 Vali Loss: 0.2646596 Test Loss: 0.3688918
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.5956335
	speed: 0.0756s/iter; left time: 1471.7118s
	iters: 200, epoch: 26 | loss: 0.5316637
	speed: 0.0152s/iter; left time: 295.2434s
Epoch: 26 cost time: 4.526626110076904
Epoch: 26, Steps: 261 | Train Loss: 0.5182328 Vali Loss: 0.2646789 Test Loss: 0.3688971
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3778785
	speed: 0.0757s/iter; left time: 1454.8723s
	iters: 200, epoch: 27 | loss: 0.4396239
	speed: 0.0162s/iter; left time: 310.3469s
Epoch: 27 cost time: 4.762655019760132
Epoch: 27, Steps: 261 | Train Loss: 0.5183468 Vali Loss: 0.2645638 Test Loss: 0.3688982
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4882397
	speed: 0.0758s/iter; left time: 1437.5003s
	iters: 200, epoch: 28 | loss: 0.3796268
	speed: 0.0154s/iter; left time: 289.6752s
Epoch: 28 cost time: 4.544978141784668
Epoch: 28, Steps: 261 | Train Loss: 0.5177631 Vali Loss: 0.2644880 Test Loss: 0.3688511
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.5074943
	speed: 0.0763s/iter; left time: 1426.8932s
	iters: 200, epoch: 29 | loss: 0.5734387
	speed: 0.0154s/iter; left time: 287.2080s
Epoch: 29 cost time: 4.656137704849243
Epoch: 29, Steps: 261 | Train Loss: 0.5182054 Vali Loss: 0.2644227 Test Loss: 0.3688362
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4729799
	speed: 0.0750s/iter; left time: 1382.1359s
	iters: 200, epoch: 30 | loss: 0.5469596
	speed: 0.0160s/iter; left time: 293.9901s
Epoch: 30 cost time: 4.750974178314209
Epoch: 30, Steps: 261 | Train Loss: 0.5179389 Vali Loss: 0.2644365 Test Loss: 0.3688240
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4149828
	speed: 0.0763s/iter; left time: 1386.9109s
	iters: 200, epoch: 31 | loss: 0.6096196
	speed: 0.0164s/iter; left time: 296.4033s
Epoch: 31 cost time: 4.781576156616211
Epoch: 31, Steps: 261 | Train Loss: 0.5179162 Vali Loss: 0.2642964 Test Loss: 0.3688228
Validation loss decreased (0.264327 --> 0.264296).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4293329
	speed: 0.0773s/iter; left time: 1383.5956s
	iters: 200, epoch: 32 | loss: 0.5868248
	speed: 0.0276s/iter; left time: 492.2383s
Epoch: 32 cost time: 7.6447529792785645
Epoch: 32, Steps: 261 | Train Loss: 0.5177639 Vali Loss: 0.2645593 Test Loss: 0.3688181
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3961816
	speed: 0.0918s/iter; left time: 1620.7807s
	iters: 200, epoch: 33 | loss: 0.4154395
	speed: 0.0151s/iter; left time: 264.8665s
Epoch: 33 cost time: 4.493337154388428
Epoch: 33, Steps: 261 | Train Loss: 0.5175218 Vali Loss: 0.2642378 Test Loss: 0.3688129
Validation loss decreased (0.264296 --> 0.264238).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.6368937
	speed: 0.0736s/iter; left time: 1279.6009s
	iters: 200, epoch: 34 | loss: 0.4652840
	speed: 0.0151s/iter; left time: 261.5297s
Epoch: 34 cost time: 4.616732597351074
Epoch: 34, Steps: 261 | Train Loss: 0.5177787 Vali Loss: 0.2641964 Test Loss: 0.3688180
Validation loss decreased (0.264238 --> 0.264196).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.5329563
	speed: 0.0737s/iter; left time: 1261.9145s
	iters: 200, epoch: 35 | loss: 0.5757843
	speed: 0.0150s/iter; left time: 255.5095s
Epoch: 35 cost time: 4.4802093505859375
Epoch: 35, Steps: 261 | Train Loss: 0.5178707 Vali Loss: 0.2643329 Test Loss: 0.3688188
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4234294
	speed: 0.0744s/iter; left time: 1255.6186s
	iters: 200, epoch: 36 | loss: 0.4964662
	speed: 0.0164s/iter; left time: 275.5281s
Epoch: 36 cost time: 4.852433443069458
Epoch: 36, Steps: 261 | Train Loss: 0.5176015 Vali Loss: 0.2644184 Test Loss: 0.3688179
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.6338803
	speed: 0.0760s/iter; left time: 1261.8562s
	iters: 200, epoch: 37 | loss: 0.5440853
	speed: 0.0157s/iter; left time: 259.8459s
Epoch: 37 cost time: 4.6384711265563965
Epoch: 37, Steps: 261 | Train Loss: 0.5168235 Vali Loss: 0.2642719 Test Loss: 0.3688118
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.5645080
	speed: 0.0764s/iter; left time: 1248.8503s
	iters: 200, epoch: 38 | loss: 0.4759465
	speed: 0.0159s/iter; left time: 257.8350s
Epoch: 38 cost time: 4.596651315689087
Epoch: 38, Steps: 261 | Train Loss: 0.5172677 Vali Loss: 0.2645326 Test Loss: 0.3688194
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.5077822
	speed: 0.0741s/iter; left time: 1192.4014s
	iters: 200, epoch: 39 | loss: 0.5840939
	speed: 0.0147s/iter; left time: 234.7924s
Epoch: 39 cost time: 4.406922340393066
Epoch: 39, Steps: 261 | Train Loss: 0.5172904 Vali Loss: 0.2643440 Test Loss: 0.3688200
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.4834498
	speed: 0.0745s/iter; left time: 1178.1281s
	iters: 200, epoch: 40 | loss: 0.4241229
	speed: 0.0151s/iter; left time: 236.7470s
Epoch: 40 cost time: 4.569334983825684
Epoch: 40, Steps: 261 | Train Loss: 0.5175818 Vali Loss: 0.2643250 Test Loss: 0.3688226
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.5874545
	speed: 0.0736s/iter; left time: 1145.0617s
	iters: 200, epoch: 41 | loss: 0.5275265
	speed: 0.0154s/iter; left time: 237.9156s
Epoch: 41 cost time: 4.586134672164917
Epoch: 41, Steps: 261 | Train Loss: 0.5177236 Vali Loss: 0.2644640 Test Loss: 0.3688086
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3674034
	speed: 0.0764s/iter; left time: 1169.1435s
	iters: 200, epoch: 42 | loss: 0.6368589
	speed: 0.0158s/iter; left time: 240.2075s
Epoch: 42 cost time: 4.744199514389038
Epoch: 42, Steps: 261 | Train Loss: 0.5175956 Vali Loss: 0.2642898 Test Loss: 0.3688096
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.6157363
	speed: 0.0782s/iter; left time: 1176.1692s
	iters: 200, epoch: 43 | loss: 0.6161082
	speed: 0.0300s/iter; left time: 448.5176s
Epoch: 43 cost time: 6.191638231277466
Epoch: 43, Steps: 261 | Train Loss: 0.5173213 Vali Loss: 0.2641079 Test Loss: 0.3688096
Validation loss decreased (0.264196 --> 0.264108).  Saving model ...
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.5418777
	speed: 0.0760s/iter; left time: 1123.3995s
	iters: 200, epoch: 44 | loss: 0.6171048
	speed: 0.0152s/iter; left time: 222.7726s
Epoch: 44 cost time: 4.571038007736206
Epoch: 44, Steps: 261 | Train Loss: 0.5178611 Vali Loss: 0.2642300 Test Loss: 0.3688066
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.4724430
	speed: 0.0755s/iter; left time: 1095.6329s
	iters: 200, epoch: 45 | loss: 0.5656520
	speed: 0.0152s/iter; left time: 218.5731s
Epoch: 45 cost time: 4.711233615875244
Epoch: 45, Steps: 261 | Train Loss: 0.5176599 Vali Loss: 0.2643020 Test Loss: 0.3688079
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.4355808
	speed: 0.0728s/iter; left time: 1037.7664s
	iters: 200, epoch: 46 | loss: 0.4319481
	speed: 0.0168s/iter; left time: 238.4950s
Epoch: 46 cost time: 4.677095174789429
Epoch: 46, Steps: 261 | Train Loss: 0.5173531 Vali Loss: 0.2642588 Test Loss: 0.3688065
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.3756604
	speed: 0.0763s/iter; left time: 1067.9890s
	iters: 200, epoch: 47 | loss: 0.5637940
	speed: 0.0160s/iter; left time: 222.1698s
Epoch: 47 cost time: 4.753498315811157
Epoch: 47, Steps: 261 | Train Loss: 0.5176236 Vali Loss: 0.2641636 Test Loss: 0.3688084
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.4627517
	speed: 0.0769s/iter; left time: 1055.9780s
	iters: 200, epoch: 48 | loss: 0.4686115
	speed: 0.0157s/iter; left time: 214.5809s
Epoch: 48 cost time: 4.700550079345703
Epoch: 48, Steps: 261 | Train Loss: 0.5174550 Vali Loss: 0.2643080 Test Loss: 0.3688076
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.5210035
	speed: 0.0770s/iter; left time: 1037.8594s
	iters: 200, epoch: 49 | loss: 0.5329365
	speed: 0.0167s/iter; left time: 223.9321s
Epoch: 49 cost time: 4.9493513107299805
Epoch: 49, Steps: 261 | Train Loss: 0.5174817 Vali Loss: 0.2643698 Test Loss: 0.3688008
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.5565444
	speed: 0.0806s/iter; left time: 1065.4498s
	iters: 200, epoch: 50 | loss: 0.6115487
	speed: 0.0152s/iter; left time: 198.9021s
Epoch: 50 cost time: 4.662687540054321
Epoch: 50, Steps: 261 | Train Loss: 0.5173592 Vali Loss: 0.2641075 Test Loss: 0.3687910
Validation loss decreased (0.264108 --> 0.264107).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.4884427
	speed: 0.0750s/iter; left time: 971.2001s
	iters: 200, epoch: 51 | loss: 0.4379205
	speed: 0.0154s/iter; left time: 197.5340s
Epoch: 51 cost time: 4.578863859176636
Epoch: 51, Steps: 261 | Train Loss: 0.5167341 Vali Loss: 0.2641189 Test Loss: 0.3687970
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.6820382
	speed: 0.0748s/iter; left time: 949.2147s
	iters: 200, epoch: 52 | loss: 0.6832978
	speed: 0.0153s/iter; left time: 192.5792s
Epoch: 52 cost time: 4.5386669635772705
Epoch: 52, Steps: 261 | Train Loss: 0.5167640 Vali Loss: 0.2645624 Test Loss: 0.3687956
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.6151946
	speed: 0.0753s/iter; left time: 935.7894s
	iters: 200, epoch: 53 | loss: 0.4595484
	speed: 0.0227s/iter; left time: 280.3718s
Epoch: 53 cost time: 5.361515283584595
Epoch: 53, Steps: 261 | Train Loss: 0.5174123 Vali Loss: 0.2643391 Test Loss: 0.3687904
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.4909840
	speed: 0.0754s/iter; left time: 917.9968s
	iters: 200, epoch: 54 | loss: 0.5019597
	speed: 0.0159s/iter; left time: 191.3045s
Epoch: 54 cost time: 4.668412446975708
Epoch: 54, Steps: 261 | Train Loss: 0.5177242 Vali Loss: 0.2640948 Test Loss: 0.3687924
Validation loss decreased (0.264107 --> 0.264095).  Saving model ...
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.3800573
	speed: 0.0739s/iter; left time: 879.6311s
	iters: 200, epoch: 55 | loss: 0.5137189
	speed: 0.0164s/iter; left time: 193.1869s
Epoch: 55 cost time: 4.782227516174316
Epoch: 55, Steps: 261 | Train Loss: 0.5175503 Vali Loss: 0.2641417 Test Loss: 0.3687931
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.6783859
	speed: 0.0809s/iter; left time: 941.7797s
	iters: 200, epoch: 56 | loss: 0.5125847
	speed: 0.0156s/iter; left time: 179.7419s
Epoch: 56 cost time: 4.708991289138794
Epoch: 56, Steps: 261 | Train Loss: 0.5175664 Vali Loss: 0.2641459 Test Loss: 0.3687968
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.4171287
	speed: 0.0757s/iter; left time: 861.7518s
	iters: 200, epoch: 57 | loss: 0.5184587
	speed: 0.0158s/iter; left time: 178.2010s
Epoch: 57 cost time: 4.802727937698364
Epoch: 57, Steps: 261 | Train Loss: 0.5177034 Vali Loss: 0.2641133 Test Loss: 0.3687945
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.4712604
	speed: 0.0798s/iter; left time: 887.7972s
	iters: 200, epoch: 58 | loss: 0.4409626
	speed: 0.0154s/iter; left time: 170.0403s
Epoch: 58 cost time: 4.70501971244812
Epoch: 58, Steps: 261 | Train Loss: 0.5175317 Vali Loss: 0.2641470 Test Loss: 0.3687904
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.3991124
	speed: 0.0771s/iter; left time: 837.9597s
	iters: 200, epoch: 59 | loss: 0.5742921
	speed: 0.0152s/iter; left time: 163.4072s
Epoch: 59 cost time: 4.767325401306152
Epoch: 59, Steps: 261 | Train Loss: 0.5174634 Vali Loss: 0.2638994 Test Loss: 0.3687899
Validation loss decreased (0.264095 --> 0.263899).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.5844113
	speed: 0.0755s/iter; left time: 799.9278s
	iters: 200, epoch: 60 | loss: 0.7122688
	speed: 0.0168s/iter; left time: 176.3614s
Epoch: 60 cost time: 4.932655096054077
Epoch: 60, Steps: 261 | Train Loss: 0.5172337 Vali Loss: 0.2643546 Test Loss: 0.3687907
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.6729158
	speed: 0.0777s/iter; left time: 803.9579s
	iters: 200, epoch: 61 | loss: 0.6502887
	speed: 0.0165s/iter; left time: 168.9019s
Epoch: 61 cost time: 4.877195358276367
Epoch: 61, Steps: 261 | Train Loss: 0.5173354 Vali Loss: 0.2641666 Test Loss: 0.3687927
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.5747268
	speed: 0.1007s/iter; left time: 1015.0225s
	iters: 200, epoch: 62 | loss: 0.6775072
	speed: 0.0159s/iter; left time: 158.5052s
Epoch: 62 cost time: 4.550112247467041
Epoch: 62, Steps: 261 | Train Loss: 0.5172761 Vali Loss: 0.2639809 Test Loss: 0.3687907
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.4797526
	speed: 0.0765s/iter; left time: 750.7975s
	iters: 200, epoch: 63 | loss: 0.4846156
	speed: 0.0156s/iter; left time: 151.2752s
Epoch: 63 cost time: 4.762397289276123
Epoch: 63, Steps: 261 | Train Loss: 0.5172617 Vali Loss: 0.2640874 Test Loss: 0.3687910
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.4155426
	speed: 0.0828s/iter; left time: 791.0271s
	iters: 200, epoch: 64 | loss: 0.5723351
	speed: 0.0167s/iter; left time: 157.5357s
Epoch: 64 cost time: 4.902174711227417
Epoch: 64, Steps: 261 | Train Loss: 0.5173745 Vali Loss: 0.2642134 Test Loss: 0.3687893
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.4778011
	speed: 0.0772s/iter; left time: 717.8732s
	iters: 200, epoch: 65 | loss: 0.6003590
	speed: 0.0157s/iter; left time: 144.5146s
Epoch: 65 cost time: 4.659525394439697
Epoch: 65, Steps: 261 | Train Loss: 0.5174730 Vali Loss: 0.2641270 Test Loss: 0.3687905
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.6771505
	speed: 0.0945s/iter; left time: 853.5197s
	iters: 200, epoch: 66 | loss: 0.4312581
	speed: 0.0152s/iter; left time: 136.0668s
Epoch: 66 cost time: 4.61272120475769
Epoch: 66, Steps: 261 | Train Loss: 0.5174470 Vali Loss: 0.2641721 Test Loss: 0.3687892
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.5567592
	speed: 0.0753s/iter; left time: 660.6470s
	iters: 200, epoch: 67 | loss: 0.5667561
	speed: 0.0153s/iter; left time: 132.9971s
Epoch: 67 cost time: 4.565001487731934
Epoch: 67, Steps: 261 | Train Loss: 0.5174443 Vali Loss: 0.2642835 Test Loss: 0.3687897
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.4383800
	speed: 0.0748s/iter; left time: 636.6435s
	iters: 200, epoch: 68 | loss: 0.4129970
	speed: 0.0161s/iter; left time: 135.6532s
Epoch: 68 cost time: 4.608332872390747
Epoch: 68, Steps: 261 | Train Loss: 0.5169890 Vali Loss: 0.2643504 Test Loss: 0.3687889
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.6883014
	speed: 0.0771s/iter; left time: 636.2944s
	iters: 200, epoch: 69 | loss: 0.5424406
	speed: 0.0156s/iter; left time: 127.0072s
Epoch: 69 cost time: 4.67942476272583
Epoch: 69, Steps: 261 | Train Loss: 0.5175975 Vali Loss: 0.2641366 Test Loss: 0.3687866
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.4089202
	speed: 0.0769s/iter; left time: 614.8327s
	iters: 200, epoch: 70 | loss: 0.4527982
	speed: 0.0156s/iter; left time: 122.8890s
Epoch: 70 cost time: 4.639756917953491
Epoch: 70, Steps: 261 | Train Loss: 0.5172223 Vali Loss: 0.2641802 Test Loss: 0.3687881
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.4075398
	speed: 0.0760s/iter; left time: 587.6942s
	iters: 200, epoch: 71 | loss: 0.5015944
	speed: 0.0154s/iter; left time: 117.2237s
Epoch: 71 cost time: 4.627740383148193
Epoch: 71, Steps: 261 | Train Loss: 0.5170084 Vali Loss: 0.2641894 Test Loss: 0.3687850
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.5332240
	speed: 0.0765s/iter; left time: 571.2205s
	iters: 200, epoch: 72 | loss: 0.3579438
	speed: 0.0162s/iter; left time: 119.5489s
Epoch: 72 cost time: 4.795068979263306
Epoch: 72, Steps: 261 | Train Loss: 0.5172060 Vali Loss: 0.2638637 Test Loss: 0.3687867
Validation loss decreased (0.263899 --> 0.263864).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.5323979
	speed: 0.0764s/iter; left time: 550.9008s
	iters: 200, epoch: 73 | loss: 0.4635493
	speed: 0.0158s/iter; left time: 112.0363s
Epoch: 73 cost time: 4.553739309310913
Epoch: 73, Steps: 261 | Train Loss: 0.5170616 Vali Loss: 0.2642040 Test Loss: 0.3687840
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.6480985
	speed: 0.0741s/iter; left time: 515.0459s
	iters: 200, epoch: 74 | loss: 0.4807921
	speed: 0.0156s/iter; left time: 106.7024s
Epoch: 74 cost time: 4.501136779785156
Epoch: 74, Steps: 261 | Train Loss: 0.5172476 Vali Loss: 0.2642424 Test Loss: 0.3687835
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.6274988
	speed: 0.0812s/iter; left time: 543.2234s
	iters: 200, epoch: 75 | loss: 0.4550982
	speed: 0.0163s/iter; left time: 107.3547s
Epoch: 75 cost time: 5.197608470916748
Epoch: 75, Steps: 261 | Train Loss: 0.5171286 Vali Loss: 0.2642518 Test Loss: 0.3687859
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.5950568
	speed: 0.0793s/iter; left time: 509.6286s
	iters: 200, epoch: 76 | loss: 0.4554668
	speed: 0.0159s/iter; left time: 100.7901s
Epoch: 76 cost time: 4.608700275421143
Epoch: 76, Steps: 261 | Train Loss: 0.5173032 Vali Loss: 0.2640501 Test Loss: 0.3687861
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.4855217
	speed: 0.0757s/iter; left time: 466.7810s
	iters: 200, epoch: 77 | loss: 0.5119433
	speed: 0.0153s/iter; left time: 92.8111s
Epoch: 77 cost time: 4.597499132156372
Epoch: 77, Steps: 261 | Train Loss: 0.5169442 Vali Loss: 0.2643233 Test Loss: 0.3687869
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.5012175
	speed: 0.0751s/iter; left time: 443.4342s
	iters: 200, epoch: 78 | loss: 0.5839815
	speed: 0.0154s/iter; left time: 89.5390s
Epoch: 78 cost time: 4.560086488723755
Epoch: 78, Steps: 261 | Train Loss: 0.5166136 Vali Loss: 0.2642705 Test Loss: 0.3687852
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.3034973
	speed: 0.0750s/iter; left time: 422.9827s
	iters: 200, epoch: 79 | loss: 0.5074397
	speed: 0.0153s/iter; left time: 85.0247s
Epoch: 79 cost time: 4.613515853881836
Epoch: 79, Steps: 261 | Train Loss: 0.5164147 Vali Loss: 0.2643264 Test Loss: 0.3687845
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.3623458
	speed: 0.0779s/iter; left time: 419.3754s
	iters: 200, epoch: 80 | loss: 0.5922399
	speed: 0.0167s/iter; left time: 88.0096s
Epoch: 80 cost time: 4.8079140186309814
Epoch: 80, Steps: 261 | Train Loss: 0.5177358 Vali Loss: 0.2641130 Test Loss: 0.3687852
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.4637732
	speed: 0.0720s/iter; left time: 368.5192s
	iters: 200, epoch: 81 | loss: 0.4191144
	speed: 0.0155s/iter; left time: 77.8407s
Epoch: 81 cost time: 4.489753007888794
Epoch: 81, Steps: 261 | Train Loss: 0.5171852 Vali Loss: 0.2638535 Test Loss: 0.3687846
Validation loss decreased (0.263864 --> 0.263854).  Saving model ...
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.5743339
	speed: 0.0763s/iter; left time: 370.7695s
	iters: 200, epoch: 82 | loss: 0.5163543
	speed: 0.0166s/iter; left time: 78.8357s
Epoch: 82 cost time: 4.882805585861206
Epoch: 82, Steps: 261 | Train Loss: 0.5173927 Vali Loss: 0.2642263 Test Loss: 0.3687840
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.6133813
	speed: 0.0755s/iter; left time: 347.0714s
	iters: 200, epoch: 83 | loss: 0.6270373
	speed: 0.0155s/iter; left time: 69.5890s
Epoch: 83 cost time: 4.581271171569824
Epoch: 83, Steps: 261 | Train Loss: 0.5174331 Vali Loss: 0.2641896 Test Loss: 0.3687858
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.3332856
	speed: 0.0762s/iter; left time: 330.5450s
	iters: 200, epoch: 84 | loss: 0.4585405
	speed: 0.0155s/iter; left time: 65.5717s
Epoch: 84 cost time: 4.696650981903076
Epoch: 84, Steps: 261 | Train Loss: 0.5169917 Vali Loss: 0.2642139 Test Loss: 0.3687848
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.4737578
	speed: 0.0768s/iter; left time: 313.2338s
	iters: 200, epoch: 85 | loss: 0.5707749
	speed: 0.0166s/iter; left time: 66.0984s
Epoch: 85 cost time: 4.872542381286621
Epoch: 85, Steps: 261 | Train Loss: 0.5169771 Vali Loss: 0.2642325 Test Loss: 0.3687850
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.5523268
	speed: 0.0880s/iter; left time: 335.7820s
	iters: 200, epoch: 86 | loss: 0.6173249
	speed: 0.0165s/iter; left time: 61.2900s
Epoch: 86 cost time: 4.822659015655518
Epoch: 86, Steps: 261 | Train Loss: 0.5174456 Vali Loss: 0.2641609 Test Loss: 0.3687846
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.6157221
	speed: 0.0806s/iter; left time: 286.6132s
	iters: 200, epoch: 87 | loss: 0.4694956
	speed: 0.0169s/iter; left time: 58.3714s
Epoch: 87 cost time: 5.002995252609253
Epoch: 87, Steps: 261 | Train Loss: 0.5171151 Vali Loss: 0.2641501 Test Loss: 0.3687845
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.6684068
	speed: 0.0854s/iter; left time: 281.1730s
	iters: 200, epoch: 88 | loss: 0.3355658
	speed: 0.0207s/iter; left time: 66.1794s
Epoch: 88 cost time: 5.440260887145996
Epoch: 88, Steps: 261 | Train Loss: 0.5170173 Vali Loss: 0.2643816 Test Loss: 0.3687835
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.4285705
	speed: 0.0804s/iter; left time: 243.9148s
	iters: 200, epoch: 89 | loss: 0.5183973
	speed: 0.0166s/iter; left time: 48.7684s
Epoch: 89 cost time: 4.899433851242065
Epoch: 89, Steps: 261 | Train Loss: 0.5172433 Vali Loss: 0.2640937 Test Loss: 0.3687842
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.3909277
	speed: 0.0763s/iter; left time: 211.5241s
	iters: 200, epoch: 90 | loss: 0.6718574
	speed: 0.0166s/iter; left time: 44.2588s
Epoch: 90 cost time: 4.829386472702026
Epoch: 90, Steps: 261 | Train Loss: 0.5174113 Vali Loss: 0.2640119 Test Loss: 0.3687845
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.204402478767869e-06
	iters: 100, epoch: 91 | loss: 0.4647915
	speed: 0.0901s/iter; left time: 226.1231s
	iters: 200, epoch: 91 | loss: 0.4540937
	speed: 0.0165s/iter; left time: 39.7903s
Epoch: 91 cost time: 4.921100616455078
Epoch: 91, Steps: 261 | Train Loss: 0.5170130 Vali Loss: 0.2641544 Test Loss: 0.3687842
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.944182354829475e-06
	iters: 100, epoch: 92 | loss: 0.5098961
	speed: 0.0787s/iter; left time: 177.1381s
	iters: 200, epoch: 92 | loss: 0.4183639
	speed: 0.0166s/iter; left time: 35.7278s
Epoch: 92 cost time: 4.917418479919434
Epoch: 92, Steps: 261 | Train Loss: 0.5170556 Vali Loss: 0.2640469 Test Loss: 0.3687843
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.696973237088e-06
	iters: 100, epoch: 93 | loss: 0.4639998
	speed: 0.0774s/iter; left time: 153.9805s
	iters: 200, epoch: 93 | loss: 0.5614388
	speed: 0.0164s/iter; left time: 30.9197s
Epoch: 93 cost time: 4.893465518951416
Epoch: 93, Steps: 261 | Train Loss: 0.5168293 Vali Loss: 0.2640660 Test Loss: 0.3687835
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.462124575233601e-06
	iters: 100, epoch: 94 | loss: 0.4310279
	speed: 0.0801s/iter; left time: 138.3368s
	iters: 200, epoch: 94 | loss: 0.4887624
	speed: 0.0166s/iter; left time: 27.0386s
Epoch: 94 cost time: 4.926319360733032
Epoch: 94, Steps: 261 | Train Loss: 0.5172942 Vali Loss: 0.2642372 Test Loss: 0.3687839
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.239018346471921e-06
	iters: 100, epoch: 95 | loss: 0.4793297
	speed: 0.0789s/iter; left time: 115.7329s
	iters: 200, epoch: 95 | loss: 0.4974630
	speed: 0.0163s/iter; left time: 22.2991s
Epoch: 95 cost time: 4.881463527679443
Epoch: 95, Steps: 261 | Train Loss: 0.5167870 Vali Loss: 0.2639645 Test Loss: 0.3687837
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.027067429148324e-06
	iters: 100, epoch: 96 | loss: 0.4104486
	speed: 0.0974s/iter; left time: 117.4341s
	iters: 200, epoch: 96 | loss: 0.4274716
	speed: 0.0354s/iter; left time: 39.1501s
Epoch: 96 cost time: 8.750624656677246
Epoch: 96, Steps: 261 | Train Loss: 0.5176802 Vali Loss: 0.2641043 Test Loss: 0.3687840
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.825714057690908e-06
	iters: 100, epoch: 97 | loss: 0.3443257
	speed: 0.0799s/iter; left time: 75.5408s
	iters: 200, epoch: 97 | loss: 0.5565645
	speed: 0.0168s/iter; left time: 14.2292s
Epoch: 97 cost time: 4.910176753997803
Epoch: 97, Steps: 261 | Train Loss: 0.5172946 Vali Loss: 0.2641622 Test Loss: 0.3687835
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.6344283548063623e-06
	iters: 100, epoch: 98 | loss: 0.4317635
	speed: 0.0741s/iter; left time: 50.6752s
	iters: 200, epoch: 98 | loss: 0.5004295
	speed: 0.0154s/iter; left time: 8.9968s
Epoch: 98 cost time: 4.508823394775391
Epoch: 98, Steps: 261 | Train Loss: 0.5172279 Vali Loss: 0.2640021 Test Loss: 0.3687836
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.452706937066044e-06
	iters: 100, epoch: 99 | loss: 0.5340200
	speed: 0.0789s/iter; left time: 33.3762s
	iters: 200, epoch: 99 | loss: 0.5537186
	speed: 0.0169s/iter; left time: 5.4597s
Epoch: 99 cost time: 4.883583068847656
Epoch: 99, Steps: 261 | Train Loss: 0.5167312 Vali Loss: 0.2641278 Test Loss: 0.3687840
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.2800715902127414e-06
	iters: 100, epoch: 100 | loss: 0.3962607
	speed: 0.0768s/iter; left time: 12.4349s
	iters: 200, epoch: 100 | loss: 0.5187845
	speed: 0.0151s/iter; left time: 0.9374s
Epoch: 100 cost time: 4.592580318450928
Epoch: 100, Steps: 261 | Train Loss: 0.5170211 Vali Loss: 0.2641685 Test Loss: 0.3687840
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.1160680107021042e-06
>>>>>>>testing : ETTm2_360_720_FITS_ETTm2_ftM_sl360_ll48_pl720_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.36607038974761963, mae:0.3822193741798401, rse:0.48632511496543884, corr:[0.5386076  0.54293376 0.5411993  0.5383965  0.53690135 0.53683513
 0.53761363 0.53818524 0.5379373  0.53705364 0.5360213  0.53536856
 0.535279   0.53559    0.5359786  0.53599936 0.535516   0.5346239
 0.53359264 0.532683   0.53210884 0.5319153  0.5319035  0.53190404
 0.5317091  0.53121847 0.5305535  0.52988863 0.52937335 0.5290179
 0.528785   0.52859247 0.5283073  0.5278533  0.52723783 0.52653956
 0.52584416 0.52523434 0.5247512  0.5243469  0.5239334  0.5234679
 0.5229105  0.5222507  0.52153045 0.5207612  0.52003473 0.5193709
 0.51869977 0.5179773  0.51715595 0.51632893 0.5154981  0.51467323
 0.5139209  0.5132976  0.5127887  0.5123812  0.51204884 0.5117343
 0.5114228  0.5111084  0.51082575 0.51056814 0.5103405  0.51016504
 0.5099862  0.50980157 0.5096235  0.509469   0.5093051  0.5091163
 0.5088924  0.5086358  0.5083193  0.5079083  0.50744605 0.50693774
 0.50643647 0.5059377  0.50547653 0.50500005 0.5044945  0.50390077
 0.5032668  0.5026569  0.5020757  0.50159323 0.501198   0.50083596
 0.5004349  0.49990776 0.4991449  0.49809927 0.4967855  0.495263
 0.4936381  0.49210486 0.49071315 0.48939902 0.48809695 0.48682624
 0.4855908  0.48435265 0.4830831  0.48187542 0.48079795 0.47987095
 0.47904742 0.47824028 0.47743744 0.4765984  0.4757493  0.47489524
 0.47407234 0.47331735 0.47262907 0.47196856 0.4713522  0.47071034
 0.47000566 0.46919838 0.46839362 0.4676369  0.46694213 0.4662857
 0.4656382  0.46492317 0.4640881  0.4631548  0.4622247  0.461374
 0.46064758 0.46004844 0.45951477 0.45899013 0.458361   0.45765474
 0.45687303 0.45608386 0.45534265 0.4546635  0.4540356  0.45335367
 0.45255852 0.45163426 0.4506596  0.44972178 0.448881   0.44815013
 0.44756213 0.44708744 0.44658786 0.44599545 0.4453181  0.44462383
 0.4439756  0.4434389  0.44299418 0.4426951  0.44243157 0.4421222
 0.44175494 0.44133282 0.4409595  0.44069248 0.44047236 0.4403375
 0.44019657 0.4400072  0.43971142 0.4392924  0.43875128 0.43818024
 0.43767112 0.43730125 0.43704093 0.43681008 0.43651244 0.43608162
 0.4354874  0.43477473 0.43411273 0.4335983  0.43328    0.4330962
 0.43292308 0.43257862 0.43192327 0.43084753 0.42942646 0.42770326
 0.42586708 0.42420068 0.42267218 0.4211783  0.4196959  0.41816962
 0.41663367 0.4151038  0.41362017 0.41223937 0.41098392 0.4098354
 0.40872982 0.4076403  0.406506   0.40537393 0.4042975  0.40337703
 0.40255696 0.4017518  0.4009332  0.40012294 0.39927307 0.39840278
 0.39749718 0.39636198 0.39514107 0.39395142 0.3928643  0.39190033
 0.39108756 0.3903391  0.38963902 0.38882017 0.38782206 0.38660684
 0.38530484 0.3840952  0.3830593  0.3822308  0.38159344 0.38113043
 0.3807185  0.38025755 0.37973955 0.37911278 0.378414   0.3777308
 0.37708813 0.37651816 0.3760454  0.37581554 0.37564784 0.37548766
 0.3753506  0.37518856 0.37498572 0.3747654  0.3745758  0.37449312
 0.37442574 0.37443233 0.3743949  0.374286   0.3740789  0.37378064
 0.37349722 0.37327018 0.37315205 0.37309623 0.37296167 0.37275505
 0.37252024 0.37229186 0.37208638 0.37183672 0.37158406 0.37137005
 0.3711608  0.37092155 0.3706475  0.37041017 0.37015048 0.36988088
 0.36953577 0.36911896 0.36870196 0.36837748 0.36815324 0.3680374
 0.36791727 0.3676998  0.36730385 0.36664814 0.36564872 0.36437982
 0.3630057  0.36179832 0.36077124 0.35986444 0.35906136 0.35835323
 0.3576893  0.35704455 0.35642448 0.35573757 0.35503864 0.35439342
 0.3538128  0.35324425 0.3527659  0.35238948 0.3520599  0.3517281
 0.3514548  0.35115406 0.350814   0.3505583  0.3504491  0.35050786
 0.35059118 0.35057107 0.35031107 0.3498392  0.34926078 0.34868595
 0.34823218 0.347927   0.34772006 0.34755605 0.3473568  0.34704852
 0.34659094 0.34611326 0.34572223 0.34545085 0.34529644 0.3452842
 0.34532833 0.3452982  0.3451147  0.3447041  0.3441079  0.3435206
 0.34300578 0.34262565 0.34239373 0.34230506 0.34224278 0.3421161
 0.34187472 0.34162784 0.34144372 0.34134623 0.34137383 0.34147865
 0.3416141  0.34169608 0.3416331  0.34145847 0.34126467 0.3410822
 0.34093192 0.34087104 0.34083414 0.3407698  0.34063005 0.3403539
 0.34000632 0.33968997 0.33939865 0.3391524  0.3388965  0.33867455
 0.3384293  0.33820942 0.33801818 0.3378541  0.33777174 0.33770064
 0.33763573 0.33758762 0.3375698  0.33755046 0.33751673 0.33748314
 0.33742422 0.33730155 0.33705047 0.33654258 0.3358182  0.334871
 0.33378512 0.33271775 0.33173287 0.33081388 0.32990104 0.32903874
 0.32819232 0.327328   0.3264976  0.32567453 0.32486743 0.32409886
 0.32341766 0.32287115 0.32233134 0.3217794  0.3211959  0.3205357
 0.3198792  0.31923527 0.31869608 0.3183276  0.31814712 0.3181525
 0.31822544 0.31818023 0.31794682 0.31757736 0.31715128 0.31679526
 0.3165811  0.31652454 0.31653988 0.31651148 0.3163359  0.31600496
 0.31558943 0.31524515 0.3150427  0.3150104  0.31513143 0.31532025
 0.3154371  0.31542265 0.31523982 0.3148913  0.31449193 0.31412226
 0.31380886 0.31355408 0.31329042 0.31303793 0.3127418  0.3123918
 0.31196526 0.31157774 0.31120205 0.31092525 0.310703   0.31052205
 0.31032073 0.31009775 0.30987418 0.30961716 0.30936396 0.30912945
 0.30900055 0.30895284 0.30889425 0.30877566 0.30855122 0.30823186
 0.30789316 0.30760092 0.30733258 0.30709293 0.30687597 0.3065864
 0.30624735 0.3058948  0.30559468 0.30533046 0.30502024 0.30467716
 0.3042468  0.30373693 0.30314246 0.30254668 0.30202702 0.3015587
 0.30106506 0.3004347  0.29960907 0.29854375 0.29725063 0.2957984
 0.2943841  0.29315007 0.29209408 0.2911615  0.29023892 0.2892691
 0.28825343 0.28725412 0.286345   0.2856146  0.28501934 0.28447172
 0.28392074 0.28333187 0.28268248 0.28196415 0.28123263 0.28051403
 0.2798808  0.27933392 0.2788505  0.27842876 0.27806666 0.27778134
 0.27752042 0.27714595 0.27670002 0.27624688 0.27591607 0.27567467
 0.27548155 0.275258   0.2749342  0.2744858  0.27394983 0.27336237
 0.27286404 0.27250028 0.2722914  0.27218425 0.27206525 0.27187228
 0.27153394 0.2711031  0.27061892 0.2701752  0.26986235 0.26964155
 0.26943117 0.26917    0.26877567 0.2682737  0.26775235 0.26733145
 0.26706177 0.26695627 0.26703185 0.2671491  0.26719254 0.26712826
 0.2669019  0.26661143 0.26634175 0.266186   0.2661221  0.26610154
 0.2660257  0.2658601  0.26558682 0.26524457 0.2648437  0.26453242
 0.26435497 0.2643175  0.2643419  0.26427996 0.26406324 0.26368886
 0.26323298 0.26285294 0.26265094 0.2626214  0.26262578 0.26253694
 0.26227707 0.2618009  0.26122335 0.26065227 0.2602882  0.26013932
 0.2600829  0.2598912  0.25932705 0.2582481  0.25669917 0.2548041
 0.25285473 0.25122166 0.24999043 0.24905257 0.24820575 0.2473206
 0.24624069 0.24505971 0.24385904 0.24275012 0.2418367  0.2411271
 0.24045257 0.23969686 0.23887494 0.23804158 0.2371919  0.2363804
 0.23569962 0.23516636 0.23474823 0.23437229 0.23405054 0.23375672
 0.23347072 0.2331433  0.232759   0.23235856 0.23199232 0.23166169
 0.23133042 0.2309668  0.23055217 0.23008434 0.22963192 0.2292063
 0.22887836 0.22858198 0.22829834 0.22803043 0.2277564  0.22752695
 0.22729084 0.22708662 0.22687408 0.22668552 0.22652364 0.22634134
 0.22608028 0.22567785 0.22523433 0.22490408 0.22475022 0.2246994
 0.22475572 0.22489999 0.22501653 0.22494733 0.2247372  0.22443065
 0.22430304 0.22434068 0.22447665 0.22466524 0.2247527  0.2246762
 0.22435102 0.22393405 0.22356065 0.22330979 0.22336826 0.22350094
 0.2236349  0.22365747 0.22347467 0.22313842 0.22275081 0.22242494
 0.22241464 0.22276294 0.22330679 0.22391933 0.22439337 0.22453806
 0.2244412  0.22430202 0.22432947 0.22458053 0.22510755 0.22572374
 0.22617091 0.2262595  0.22591268 0.2250435  0.22372662 0.22224914
 0.2208336  0.2196611  0.21866518 0.21768437 0.21665676 0.21569753
 0.21480106 0.21408862 0.21367624 0.21344487 0.21318333 0.21280251
 0.21232486 0.2117207  0.21113603 0.21067251 0.21048726 0.21037108
 0.21029644 0.210106   0.2097432  0.20942341 0.20923038 0.20921789
 0.2093876  0.20946401 0.2093135  0.2088782  0.20824167 0.20745084
 0.2067491  0.20613372 0.20564853 0.20526727 0.20475574 0.20413578
 0.20329489 0.20248574 0.20194475 0.20179217 0.20189281 0.20198485
 0.201767   0.20113629 0.20019588 0.19971251 0.20060319 0.20341876]
