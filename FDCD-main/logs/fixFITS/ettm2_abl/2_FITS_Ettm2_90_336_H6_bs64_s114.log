Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=16, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_90_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_90_336_FITS_ETTm2_ftM_sl90_ll48_pl336_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=16, out_features=75, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1075200.0
params:  1275.0
Trainable parameters:  1275
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5050159
	speed: 0.0218s/iter; left time: 578.2026s
	iters: 200, epoch: 1 | loss: 0.4241951
	speed: 0.0156s/iter; left time: 412.7491s
Epoch: 1 cost time: 5.555339336395264
Epoch: 1, Steps: 266 | Train Loss: 0.4732668 Vali Loss: 0.2580545 Test Loss: 0.3570398
Validation loss decreased (inf --> 0.258054).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3682016
	speed: 0.1198s/iter; left time: 3142.2527s
	iters: 200, epoch: 2 | loss: 0.2635119
	speed: 0.0270s/iter; left time: 705.3691s
Epoch: 2 cost time: 10.168895721435547
Epoch: 2, Steps: 266 | Train Loss: 0.3835047 Vali Loss: 0.2290238 Test Loss: 0.3213699
Validation loss decreased (0.258054 --> 0.229024).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3348836
	speed: 0.1181s/iter; left time: 3066.3343s
	iters: 200, epoch: 3 | loss: 0.2711845
	speed: 0.0225s/iter; left time: 580.9009s
Epoch: 3 cost time: 7.400632381439209
Epoch: 3, Steps: 266 | Train Loss: 0.3626899 Vali Loss: 0.2215855 Test Loss: 0.3122472
Validation loss decreased (0.229024 --> 0.221585).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4499693
	speed: 0.1030s/iter; left time: 2647.0013s
	iters: 200, epoch: 4 | loss: 0.4186541
	speed: 0.0178s/iter; left time: 455.8316s
Epoch: 4 cost time: 6.785566568374634
Epoch: 4, Steps: 266 | Train Loss: 0.3561675 Vali Loss: 0.2191131 Test Loss: 0.3094259
Validation loss decreased (0.221585 --> 0.219113).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4855506
	speed: 0.0992s/iter; left time: 2522.1577s
	iters: 200, epoch: 5 | loss: 0.2892574
	speed: 0.0188s/iter; left time: 475.2259s
Epoch: 5 cost time: 6.421795129776001
Epoch: 5, Steps: 266 | Train Loss: 0.3543899 Vali Loss: 0.2185667 Test Loss: 0.3085234
Validation loss decreased (0.219113 --> 0.218567).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.5102012
	speed: 0.0938s/iter; left time: 2360.7395s
	iters: 200, epoch: 6 | loss: 0.3455038
	speed: 0.0174s/iter; left time: 437.3956s
Epoch: 6 cost time: 5.104020357131958
Epoch: 6, Steps: 266 | Train Loss: 0.3537412 Vali Loss: 0.2183645 Test Loss: 0.3080461
Validation loss decreased (0.218567 --> 0.218365).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4368193
	speed: 0.0834s/iter; left time: 2076.9646s
	iters: 200, epoch: 7 | loss: 0.2650974
	speed: 0.0247s/iter; left time: 612.2120s
Epoch: 7 cost time: 6.18427300453186
Epoch: 7, Steps: 266 | Train Loss: 0.3522887 Vali Loss: 0.2181865 Test Loss: 0.3079855
Validation loss decreased (0.218365 --> 0.218187).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4389490
	speed: 0.1087s/iter; left time: 2678.7866s
	iters: 200, epoch: 8 | loss: 0.2827854
	speed: 0.0284s/iter; left time: 697.8295s
Epoch: 8 cost time: 7.691654682159424
Epoch: 8, Steps: 266 | Train Loss: 0.3523629 Vali Loss: 0.2184452 Test Loss: 0.3078884
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3272925
	speed: 0.0837s/iter; left time: 2039.0826s
	iters: 200, epoch: 9 | loss: 0.4137970
	speed: 0.0199s/iter; left time: 481.9109s
Epoch: 9 cost time: 5.455370187759399
Epoch: 9, Steps: 266 | Train Loss: 0.3519365 Vali Loss: 0.2184283 Test Loss: 0.3078817
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3342096
	speed: 0.0951s/iter; left time: 2292.8173s
	iters: 200, epoch: 10 | loss: 0.2164793
	speed: 0.0170s/iter; left time: 407.1556s
Epoch: 10 cost time: 7.019317388534546
Epoch: 10, Steps: 266 | Train Loss: 0.3516458 Vali Loss: 0.2185117 Test Loss: 0.3078825
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3187910
	speed: 0.1244s/iter; left time: 2966.9348s
	iters: 200, epoch: 11 | loss: 0.4002732
	speed: 0.0162s/iter; left time: 383.6090s
Epoch: 11 cost time: 5.6954874992370605
Epoch: 11, Steps: 266 | Train Loss: 0.3512549 Vali Loss: 0.2187345 Test Loss: 0.3079566
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3386384
	speed: 0.0812s/iter; left time: 1913.4728s
	iters: 200, epoch: 12 | loss: 0.3484395
	speed: 0.0245s/iter; left time: 574.5929s
Epoch: 12 cost time: 5.819239377975464
Epoch: 12, Steps: 266 | Train Loss: 0.3517838 Vali Loss: 0.2188237 Test Loss: 0.3080775
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4157493
	speed: 0.0841s/iter; left time: 1960.1323s
	iters: 200, epoch: 13 | loss: 0.4080699
	speed: 0.0173s/iter; left time: 401.6873s
Epoch: 13 cost time: 5.878166913986206
Epoch: 13, Steps: 266 | Train Loss: 0.3516233 Vali Loss: 0.2189357 Test Loss: 0.3079892
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3208368
	speed: 0.0920s/iter; left time: 2120.6947s
	iters: 200, epoch: 14 | loss: 0.2222363
	speed: 0.0171s/iter; left time: 391.4372s
Epoch: 14 cost time: 5.178632974624634
Epoch: 14, Steps: 266 | Train Loss: 0.3517286 Vali Loss: 0.2187117 Test Loss: 0.3080364
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3345439
	speed: 0.1062s/iter; left time: 2418.5068s
	iters: 200, epoch: 15 | loss: 0.1940466
	speed: 0.0228s/iter; left time: 516.3056s
Epoch: 15 cost time: 7.72901463508606
Epoch: 15, Steps: 266 | Train Loss: 0.3513298 Vali Loss: 0.2190978 Test Loss: 0.3080564
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2465455
	speed: 0.1347s/iter; left time: 3032.7116s
	iters: 200, epoch: 16 | loss: 0.3787122
	speed: 0.0387s/iter; left time: 868.0205s
Epoch: 16 cost time: 8.417394399642944
Epoch: 16, Steps: 266 | Train Loss: 0.3508708 Vali Loss: 0.2191227 Test Loss: 0.3081114
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2236677
	speed: 0.0858s/iter; left time: 1908.4146s
	iters: 200, epoch: 17 | loss: 0.3297394
	speed: 0.0172s/iter; left time: 380.3242s
Epoch: 17 cost time: 5.223773241043091
Epoch: 17, Steps: 266 | Train Loss: 0.3509922 Vali Loss: 0.2189820 Test Loss: 0.3081287
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4757966
	speed: 0.0905s/iter; left time: 1989.8430s
	iters: 200, epoch: 18 | loss: 0.4435526
	speed: 0.0186s/iter; left time: 407.2996s
Epoch: 18 cost time: 5.49796199798584
Epoch: 18, Steps: 266 | Train Loss: 0.3512734 Vali Loss: 0.2188502 Test Loss: 0.3081031
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3383678
	speed: 0.0997s/iter; left time: 2164.7423s
	iters: 200, epoch: 19 | loss: 0.3215565
	speed: 0.0263s/iter; left time: 568.3365s
Epoch: 19 cost time: 8.423279285430908
Epoch: 19, Steps: 266 | Train Loss: 0.3515535 Vali Loss: 0.2191448 Test Loss: 0.3081020
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2603957
	speed: 0.1104s/iter; left time: 2367.0777s
	iters: 200, epoch: 20 | loss: 0.4418777
	speed: 0.0302s/iter; left time: 645.2515s
Epoch: 20 cost time: 7.072287321090698
Epoch: 20, Steps: 266 | Train Loss: 0.3512422 Vali Loss: 0.2190789 Test Loss: 0.3081470
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2793763
	speed: 0.0928s/iter; left time: 1966.5916s
	iters: 200, epoch: 21 | loss: 0.3467073
	speed: 0.0184s/iter; left time: 388.5235s
Epoch: 21 cost time: 6.468157768249512
Epoch: 21, Steps: 266 | Train Loss: 0.3509524 Vali Loss: 0.2192796 Test Loss: 0.3081514
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2841891
	speed: 0.0925s/iter; left time: 1935.4461s
	iters: 200, epoch: 22 | loss: 0.3413332
	speed: 0.0170s/iter; left time: 353.1904s
Epoch: 22 cost time: 5.312033176422119
Epoch: 22, Steps: 266 | Train Loss: 0.3507356 Vali Loss: 0.2191546 Test Loss: 0.3081537
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2381582
	speed: 0.0839s/iter; left time: 1732.9983s
	iters: 200, epoch: 23 | loss: 0.4889116
	speed: 0.0163s/iter; left time: 335.8151s
Epoch: 23 cost time: 4.89259934425354
Epoch: 23, Steps: 266 | Train Loss: 0.3512287 Vali Loss: 0.2192878 Test Loss: 0.3081883
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3354178
	speed: 0.0948s/iter; left time: 1931.6289s
	iters: 200, epoch: 24 | loss: 0.3479869
	speed: 0.0158s/iter; left time: 319.8416s
Epoch: 24 cost time: 5.587295770645142
Epoch: 24, Steps: 266 | Train Loss: 0.3511396 Vali Loss: 0.2193384 Test Loss: 0.3082612
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4919211
	speed: 0.0934s/iter; left time: 1878.6953s
	iters: 200, epoch: 25 | loss: 0.4805685
	speed: 0.0185s/iter; left time: 370.7925s
Epoch: 25 cost time: 5.767617225646973
Epoch: 25, Steps: 266 | Train Loss: 0.3514264 Vali Loss: 0.2193317 Test Loss: 0.3082172
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2891084
	speed: 0.1045s/iter; left time: 2074.6571s
	iters: 200, epoch: 26 | loss: 0.2944006
	speed: 0.0204s/iter; left time: 403.6444s
Epoch: 26 cost time: 7.634936094284058
Epoch: 26, Steps: 266 | Train Loss: 0.3512981 Vali Loss: 0.2192702 Test Loss: 0.3082789
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3105090
	speed: 0.0873s/iter; left time: 1710.0193s
	iters: 200, epoch: 27 | loss: 0.2577516
	speed: 0.0187s/iter; left time: 363.9206s
Epoch: 27 cost time: 5.485270738601685
Epoch: 27, Steps: 266 | Train Loss: 0.3513181 Vali Loss: 0.2191952 Test Loss: 0.3082695
EarlyStopping counter: 20 out of 20
Early stopping
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=16, out_features=75, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1075200.0
params:  1275.0
Trainable parameters:  1275
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5302365
	speed: 0.0279s/iter; left time: 738.8268s
	iters: 200, epoch: 1 | loss: 0.4342431
	speed: 0.0171s/iter; left time: 451.4859s
Epoch: 1 cost time: 5.825899362564087
Epoch: 1, Steps: 266 | Train Loss: 0.4428171 Vali Loss: 0.2180776 Test Loss: 0.3074786
Validation loss decreased (inf --> 0.218078).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2751963
	speed: 0.1272s/iter; left time: 3338.2445s
	iters: 200, epoch: 2 | loss: 0.4220641
	speed: 0.0307s/iter; left time: 802.9077s
Epoch: 2 cost time: 8.380858898162842
Epoch: 2, Steps: 266 | Train Loss: 0.4424322 Vali Loss: 0.2183275 Test Loss: 0.3074836
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3874878
	speed: 0.0966s/iter; left time: 2507.7568s
	iters: 200, epoch: 3 | loss: 0.3872814
	speed: 0.0212s/iter; left time: 547.7179s
Epoch: 3 cost time: 5.94620156288147
Epoch: 3, Steps: 266 | Train Loss: 0.4422083 Vali Loss: 0.2183282 Test Loss: 0.3074123
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4339421
	speed: 0.0914s/iter; left time: 2348.9106s
	iters: 200, epoch: 4 | loss: 0.3279989
	speed: 0.0201s/iter; left time: 513.9339s
Epoch: 4 cost time: 6.482770919799805
Epoch: 4, Steps: 266 | Train Loss: 0.4418503 Vali Loss: 0.2183600 Test Loss: 0.3075054
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3999612
	speed: 0.0965s/iter; left time: 2455.1449s
	iters: 200, epoch: 5 | loss: 0.4882151
	speed: 0.0234s/iter; left time: 592.2672s
Epoch: 5 cost time: 8.377257347106934
Epoch: 5, Steps: 266 | Train Loss: 0.4418639 Vali Loss: 0.2186372 Test Loss: 0.3075305
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3676432
	speed: 0.1348s/iter; left time: 3392.5011s
	iters: 200, epoch: 6 | loss: 0.3976879
	speed: 0.0322s/iter; left time: 807.0891s
Epoch: 6 cost time: 9.73616647720337
Epoch: 6, Steps: 266 | Train Loss: 0.4417888 Vali Loss: 0.2186090 Test Loss: 0.3075585
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4739716
	speed: 0.1050s/iter; left time: 2614.4432s
	iters: 200, epoch: 7 | loss: 0.4505852
	speed: 0.0201s/iter; left time: 498.7401s
Epoch: 7 cost time: 5.7184672355651855
Epoch: 7, Steps: 266 | Train Loss: 0.4416994 Vali Loss: 0.2185051 Test Loss: 0.3075077
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4798990
	speed: 0.0844s/iter; left time: 2079.3641s
	iters: 200, epoch: 8 | loss: 0.5784968
	speed: 0.0193s/iter; left time: 474.0688s
Epoch: 8 cost time: 5.418738126754761
Epoch: 8, Steps: 266 | Train Loss: 0.4416264 Vali Loss: 0.2188391 Test Loss: 0.3075916
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4963842
	speed: 0.0859s/iter; left time: 2094.4807s
	iters: 200, epoch: 9 | loss: 0.4742346
	speed: 0.0154s/iter; left time: 374.5399s
Epoch: 9 cost time: 5.395963191986084
Epoch: 9, Steps: 266 | Train Loss: 0.4409785 Vali Loss: 0.2185974 Test Loss: 0.3075399
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3731664
	speed: 0.1246s/iter; left time: 3003.2294s
	iters: 200, epoch: 10 | loss: 0.4435668
	speed: 0.0283s/iter; left time: 678.6152s
Epoch: 10 cost time: 8.652698993682861
Epoch: 10, Steps: 266 | Train Loss: 0.4414219 Vali Loss: 0.2187584 Test Loss: 0.3076234
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3668154
	speed: 0.1120s/iter; left time: 2671.0322s
	iters: 200, epoch: 11 | loss: 0.3212393
	speed: 0.0259s/iter; left time: 613.9080s
Epoch: 11 cost time: 7.473081588745117
Epoch: 11, Steps: 266 | Train Loss: 0.4413527 Vali Loss: 0.2186391 Test Loss: 0.3075168
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3945874
	speed: 0.1003s/iter; left time: 2363.7026s
	iters: 200, epoch: 12 | loss: 0.4397511
	speed: 0.0148s/iter; left time: 346.3456s
Epoch: 12 cost time: 5.26519775390625
Epoch: 12, Steps: 266 | Train Loss: 0.4409626 Vali Loss: 0.2187297 Test Loss: 0.3076391
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4880919
	speed: 0.0879s/iter; left time: 2049.8376s
	iters: 200, epoch: 13 | loss: 0.5244672
	speed: 0.0190s/iter; left time: 441.7860s
Epoch: 13 cost time: 5.835275173187256
Epoch: 13, Steps: 266 | Train Loss: 0.4409356 Vali Loss: 0.2189777 Test Loss: 0.3076423
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4704067
	speed: 0.0872s/iter; left time: 2008.2868s
	iters: 200, epoch: 14 | loss: 0.3692103
	speed: 0.0161s/iter; left time: 369.4987s
Epoch: 14 cost time: 5.0233705043792725
Epoch: 14, Steps: 266 | Train Loss: 0.4413806 Vali Loss: 0.2188689 Test Loss: 0.3076624
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4318735
	speed: 0.0853s/iter; left time: 1943.5358s
	iters: 200, epoch: 15 | loss: 0.4907311
	speed: 0.0176s/iter; left time: 399.5495s
Epoch: 15 cost time: 5.673557281494141
Epoch: 15, Steps: 266 | Train Loss: 0.4405194 Vali Loss: 0.2189533 Test Loss: 0.3076715
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3332443
	speed: 0.0827s/iter; left time: 1862.1369s
	iters: 200, epoch: 16 | loss: 0.3645486
	speed: 0.0194s/iter; left time: 434.8055s
Epoch: 16 cost time: 5.709034204483032
Epoch: 16, Steps: 266 | Train Loss: 0.4412976 Vali Loss: 0.2189960 Test Loss: 0.3076802
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3934616
	speed: 0.1031s/iter; left time: 2293.5216s
	iters: 200, epoch: 17 | loss: 0.5716752
	speed: 0.0252s/iter; left time: 558.6626s
Epoch: 17 cost time: 7.519915580749512
Epoch: 17, Steps: 266 | Train Loss: 0.4405713 Vali Loss: 0.2190167 Test Loss: 0.3077026
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3313870
	speed: 0.1016s/iter; left time: 2233.7363s
	iters: 200, epoch: 18 | loss: 0.4802514
	speed: 0.0203s/iter; left time: 444.3727s
Epoch: 18 cost time: 7.31628680229187
Epoch: 18, Steps: 266 | Train Loss: 0.4408675 Vali Loss: 0.2189799 Test Loss: 0.3077373
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2903963
	speed: 0.1247s/iter; left time: 2708.0917s
	iters: 200, epoch: 19 | loss: 0.4818949
	speed: 0.0292s/iter; left time: 631.5550s
Epoch: 19 cost time: 9.32973575592041
Epoch: 19, Steps: 266 | Train Loss: 0.4412404 Vali Loss: 0.2190002 Test Loss: 0.3077701
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4269726
	speed: 0.1079s/iter; left time: 2314.7273s
	iters: 200, epoch: 20 | loss: 0.4609717
	speed: 0.0242s/iter; left time: 515.5545s
Epoch: 20 cost time: 5.929007053375244
Epoch: 20, Steps: 266 | Train Loss: 0.4405235 Vali Loss: 0.2189855 Test Loss: 0.3077549
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.5189369
	speed: 0.1061s/iter; left time: 2246.8565s
	iters: 200, epoch: 21 | loss: 0.3588374
	speed: 0.0174s/iter; left time: 367.3691s
Epoch: 21 cost time: 6.637654542922974
Epoch: 21, Steps: 266 | Train Loss: 0.4409229 Vali Loss: 0.2189135 Test Loss: 0.3077669
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_90_336_FITS_ETTm2_ftM_sl90_ll48_pl336_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.308862566947937, mae:0.34353703260421753, rse:0.4488934874534607, corr:[0.55700433 0.5587118  0.5557579  0.55206376 0.5501293  0.55001026
 0.54992867 0.5487785  0.54708254 0.5458166  0.54545754 0.54553485
 0.5452671  0.54441255 0.5433125  0.5424426  0.5417947  0.5409823
 0.5397803  0.53839326 0.53728384 0.5367153  0.5364445  0.5360538
 0.53534645 0.5344608  0.5337281  0.5332308  0.5327278  0.53200215
 0.53106034 0.53018105 0.52960414 0.52934307 0.5291062  0.5286459
 0.5278443  0.52686805 0.5259583  0.5252372  0.5247011  0.5243432
 0.5241131  0.52395815 0.52377796 0.52340823 0.5228141  0.5219552
 0.52095276 0.5200188  0.5192529  0.5186524  0.5180503  0.51733536
 0.5166464  0.5160931  0.51568764 0.51540214 0.5151473  0.5149139
 0.51469624 0.514537   0.5144743  0.51446813 0.5144059  0.5142636
 0.5140887  0.51392853 0.5138748  0.5139304  0.5140134  0.5140802
 0.5140734  0.5140341  0.51392853 0.5137891  0.5136564  0.51346606
 0.5132138  0.5129325  0.51268756 0.51249015 0.51230013 0.51205134
 0.5117179  0.5112977  0.51088375 0.510563   0.5103371  0.510137
 0.5098582  0.50936985 0.50863695 0.50765616 0.5063767  0.5047012
 0.50259507 0.50028825 0.4981428  0.4963637  0.4948567  0.4934212
 0.49187312 0.49023396 0.4888206  0.48773393 0.4867919  0.48571888
 0.4844041  0.48297846 0.48166102 0.48048797 0.47938088 0.47816187
 0.47675982 0.47536987 0.47419584 0.47321594 0.47228426 0.47118816
 0.46997976 0.46884608 0.46791372 0.4671193  0.46630403 0.46535316
 0.4642805  0.46319744 0.4621288  0.46115088 0.4602595  0.45937443
 0.4584714  0.45761865 0.4568499  0.45632324 0.45588183 0.45548284
 0.45505908 0.45462027 0.4542218  0.45383623 0.4533925  0.45279533
 0.4520045  0.45109558 0.45010066 0.44919932 0.44840243 0.4476997
 0.44709384 0.44673136 0.44647285 0.44610316 0.4456283  0.44511944
 0.4446576  0.4444042  0.44431415 0.4444199  0.44457355 0.444612
 0.44459847 0.44448063 0.44449365 0.44465736 0.4448899  0.44512632
 0.44531855 0.44544104 0.44548002 0.44542253 0.44529846 0.44517818
 0.44513568 0.44519156 0.44526708 0.44528666 0.4451583  0.44489253
 0.44455698 0.4442624  0.44414786 0.44411898 0.44405535 0.44379035
 0.4432371  0.44243896 0.44144875 0.44030938 0.43900645 0.4374532
 0.4356385  0.43372467 0.43185833 0.43016794 0.42871833 0.42742217
 0.42615047 0.42481238 0.42355675 0.42250463 0.42162254 0.42072392
 0.4196294  0.41833538 0.41689014 0.4154534  0.41414055 0.4129938
 0.41185367 0.41063976 0.40935433 0.40809155 0.40696186 0.40594664
 0.40497223 0.40391377 0.40282866 0.40167877 0.4005001  0.39937586
 0.39834893 0.3973103  0.39642298 0.395542   0.39472312 0.39394167
 0.39313805 0.3922483  0.39119256 0.39017308 0.3893378  0.38882315
 0.38852254 0.38822883 0.38781607 0.38725528 0.38672277 0.38635448
 0.3862141  0.38620007 0.38606098 0.38591456 0.38575184 0.3855618
 0.38556406 0.38578376 0.386077   0.3861849  0.3861274  0.38603976
 0.38603005 0.386188   0.38645867 0.38669    0.3868581  0.38701555
 0.38724208 0.38758522 0.38798562 0.38843405 0.38888597 0.38924927
 0.3895147  0.38961008 0.38964373 0.38962665 0.38967693 0.38989156
 0.39024577 0.3907269  0.39121768 0.39167246 0.39208987 0.39242122
 0.39266852 0.39283922 0.3930008  0.39327157 0.39362568 0.39400297
 0.39422655 0.39414394 0.39370635 0.3929848  0.39210287 0.39116907
 0.39027312 0.38951457 0.38893485 0.38856596 0.38827065 0.38795838
 0.38763326 0.3873106  0.38712004 0.38713133 0.38718772 0.38704014
 0.38655293 0.38576454 0.38483545 0.38397244 0.3832503  0.38256428
 0.3817472  0.38070822 0.37958667 0.37857872 0.37773764 0.37706488
 0.376388   0.37564462 0.3748237  0.3740094  0.37328056 0.37246698
 0.3713094  0.3698169  0.36834207 0.36737993 0.3670163  0.366831
 0.36612743 0.36469975 0.36312622 0.36208704 0.36183017 0.36169004
 0.3607659  0.35908392 0.35819897 0.3593787  0.36123377 0.35907573]
