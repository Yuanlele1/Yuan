Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_720_720_FITS_ETTm2_ftM_sl720_ll48_pl720_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=90, out_features=180, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  14515200.0
params:  16380.0
Trainable parameters:  16380
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3908640
	speed: 0.0270s/iter; left time: 693.8726s
	iters: 200, epoch: 1 | loss: 0.4259118
	speed: 0.0220s/iter; left time: 564.2737s
Epoch: 1 cost time: 6.149352788925171
Epoch: 1, Steps: 258 | Train Loss: 0.4300936 Vali Loss: 0.2975508 Test Loss: 0.3964931
Validation loss decreased (inf --> 0.297551).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3476790
	speed: 0.0923s/iter; left time: 2347.9760s
	iters: 200, epoch: 2 | loss: 0.4167973
	speed: 0.0209s/iter; left time: 530.3104s
Epoch: 2 cost time: 6.143920183181763
Epoch: 2, Steps: 258 | Train Loss: 0.3167438 Vali Loss: 0.2806151 Test Loss: 0.3769953
Validation loss decreased (0.297551 --> 0.280615).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3785537
	speed: 0.0937s/iter; left time: 2359.7317s
	iters: 200, epoch: 3 | loss: 0.2444618
	speed: 0.0208s/iter; left time: 522.6259s
Epoch: 3 cost time: 6.23393177986145
Epoch: 3, Steps: 258 | Train Loss: 0.2870529 Vali Loss: 0.2741272 Test Loss: 0.3690991
Validation loss decreased (0.280615 --> 0.274127).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3295376
	speed: 0.0939s/iter; left time: 2340.0678s
	iters: 200, epoch: 4 | loss: 0.1960724
	speed: 0.0202s/iter; left time: 501.8103s
Epoch: 4 cost time: 5.948457479476929
Epoch: 4, Steps: 258 | Train Loss: 0.2734500 Vali Loss: 0.2706562 Test Loss: 0.3641788
Validation loss decreased (0.274127 --> 0.270656).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2667653
	speed: 0.0911s/iter; left time: 2247.6437s
	iters: 200, epoch: 5 | loss: 0.2892694
	speed: 0.0216s/iter; left time: 531.3925s
Epoch: 5 cost time: 6.279844045639038
Epoch: 5, Steps: 258 | Train Loss: 0.2659258 Vali Loss: 0.2681783 Test Loss: 0.3608945
Validation loss decreased (0.270656 --> 0.268178).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2375931
	speed: 0.0917s/iter; left time: 2238.1518s
	iters: 200, epoch: 6 | loss: 0.1769053
	speed: 0.0210s/iter; left time: 510.5484s
Epoch: 6 cost time: 6.103362798690796
Epoch: 6, Steps: 258 | Train Loss: 0.2623042 Vali Loss: 0.2663728 Test Loss: 0.3589295
Validation loss decreased (0.268178 --> 0.266373).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2944026
	speed: 0.0884s/iter; left time: 2134.0214s
	iters: 200, epoch: 7 | loss: 0.2204926
	speed: 0.0214s/iter; left time: 514.1606s
Epoch: 7 cost time: 6.0838258266448975
Epoch: 7, Steps: 258 | Train Loss: 0.2604234 Vali Loss: 0.2653767 Test Loss: 0.3574087
Validation loss decreased (0.266373 --> 0.265377).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2297919
	speed: 0.0907s/iter; left time: 2166.3377s
	iters: 200, epoch: 8 | loss: 0.2678335
	speed: 0.0210s/iter; left time: 499.0719s
Epoch: 8 cost time: 6.024662494659424
Epoch: 8, Steps: 258 | Train Loss: 0.2591330 Vali Loss: 0.2651080 Test Loss: 0.3565494
Validation loss decreased (0.265377 --> 0.265108).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2889558
	speed: 0.0887s/iter; left time: 2097.6961s
	iters: 200, epoch: 9 | loss: 0.2314289
	speed: 0.0208s/iter; left time: 489.6433s
Epoch: 9 cost time: 5.996993541717529
Epoch: 9, Steps: 258 | Train Loss: 0.2584607 Vali Loss: 0.2645524 Test Loss: 0.3557974
Validation loss decreased (0.265108 --> 0.264552).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3162968
	speed: 0.0929s/iter; left time: 2172.8464s
	iters: 200, epoch: 10 | loss: 0.2156158
	speed: 0.0215s/iter; left time: 499.5170s
Epoch: 10 cost time: 6.172473669052124
Epoch: 10, Steps: 258 | Train Loss: 0.2582884 Vali Loss: 0.2644215 Test Loss: 0.3554032
Validation loss decreased (0.264552 --> 0.264422).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2554174
	speed: 0.0884s/iter; left time: 2045.0015s
	iters: 200, epoch: 11 | loss: 0.3480309
	speed: 0.0216s/iter; left time: 497.8325s
Epoch: 11 cost time: 6.047060489654541
Epoch: 11, Steps: 258 | Train Loss: 0.2579799 Vali Loss: 0.2638462 Test Loss: 0.3553220
Validation loss decreased (0.264422 --> 0.263846).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2840939
	speed: 0.0912s/iter; left time: 2084.4855s
	iters: 200, epoch: 12 | loss: 0.2710284
	speed: 0.0209s/iter; left time: 476.5339s
Epoch: 12 cost time: 6.072812557220459
Epoch: 12, Steps: 258 | Train Loss: 0.2575489 Vali Loss: 0.2636906 Test Loss: 0.3549408
Validation loss decreased (0.263846 --> 0.263691).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2200260
	speed: 0.0880s/iter; left time: 1990.0008s
	iters: 200, epoch: 13 | loss: 0.2311122
	speed: 0.0209s/iter; left time: 471.1718s
Epoch: 13 cost time: 6.0445942878723145
Epoch: 13, Steps: 258 | Train Loss: 0.2578008 Vali Loss: 0.2635354 Test Loss: 0.3549698
Validation loss decreased (0.263691 --> 0.263535).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3543167
	speed: 0.0918s/iter; left time: 2052.3702s
	iters: 200, epoch: 14 | loss: 0.1973803
	speed: 0.0211s/iter; left time: 468.6280s
Epoch: 14 cost time: 6.080263376235962
Epoch: 14, Steps: 258 | Train Loss: 0.2574735 Vali Loss: 0.2639680 Test Loss: 0.3548071
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1810275
	speed: 0.0908s/iter; left time: 2006.4373s
	iters: 200, epoch: 15 | loss: 0.2616073
	speed: 0.0208s/iter; left time: 457.1395s
Epoch: 15 cost time: 5.995193958282471
Epoch: 15, Steps: 258 | Train Loss: 0.2571458 Vali Loss: 0.2634616 Test Loss: 0.3547497
Validation loss decreased (0.263535 --> 0.263462).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2855759
	speed: 0.0893s/iter; left time: 1950.4570s
	iters: 200, epoch: 16 | loss: 0.2393759
	speed: 0.0210s/iter; left time: 456.5049s
Epoch: 16 cost time: 5.9671385288238525
Epoch: 16, Steps: 258 | Train Loss: 0.2571060 Vali Loss: 0.2637630 Test Loss: 0.3545107
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3189641
	speed: 0.0892s/iter; left time: 1924.4103s
	iters: 200, epoch: 17 | loss: 0.3121479
	speed: 0.0213s/iter; left time: 456.9154s
Epoch: 17 cost time: 6.0677056312561035
Epoch: 17, Steps: 258 | Train Loss: 0.2573404 Vali Loss: 0.2636309 Test Loss: 0.3546965
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2576507
	speed: 0.0893s/iter; left time: 1904.3055s
	iters: 200, epoch: 18 | loss: 0.2732523
	speed: 0.0218s/iter; left time: 461.5187s
Epoch: 18 cost time: 6.166688442230225
Epoch: 18, Steps: 258 | Train Loss: 0.2572420 Vali Loss: 0.2637156 Test Loss: 0.3546321
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2764682
	speed: 0.0905s/iter; left time: 1905.8047s
	iters: 200, epoch: 19 | loss: 0.2566192
	speed: 0.0209s/iter; left time: 437.2329s
Epoch: 19 cost time: 5.966299772262573
Epoch: 19, Steps: 258 | Train Loss: 0.2573515 Vali Loss: 0.2637389 Test Loss: 0.3545004
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3464079
	speed: 0.0937s/iter; left time: 1949.4929s
	iters: 200, epoch: 20 | loss: 0.2454174
	speed: 0.0222s/iter; left time: 459.0917s
Epoch: 20 cost time: 6.199922323226929
Epoch: 20, Steps: 258 | Train Loss: 0.2571620 Vali Loss: 0.2636663 Test Loss: 0.3545302
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3255647
	speed: 0.0929s/iter; left time: 1908.4155s
	iters: 200, epoch: 21 | loss: 0.2428949
	speed: 0.0212s/iter; left time: 433.3021s
Epoch: 21 cost time: 6.129415035247803
Epoch: 21, Steps: 258 | Train Loss: 0.2569262 Vali Loss: 0.2634091 Test Loss: 0.3544456
Validation loss decreased (0.263462 --> 0.263409).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1544955
	speed: 0.0934s/iter; left time: 1894.5562s
	iters: 200, epoch: 22 | loss: 0.2316560
	speed: 0.0205s/iter; left time: 414.6715s
Epoch: 22 cost time: 6.025019645690918
Epoch: 22, Steps: 258 | Train Loss: 0.2573484 Vali Loss: 0.2635769 Test Loss: 0.3544331
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1762040
	speed: 0.0891s/iter; left time: 1783.4893s
	iters: 200, epoch: 23 | loss: 0.2290196
	speed: 0.0204s/iter; left time: 406.3879s
Epoch: 23 cost time: 5.876276016235352
Epoch: 23, Steps: 258 | Train Loss: 0.2572365 Vali Loss: 0.2632300 Test Loss: 0.3542989
Validation loss decreased (0.263409 --> 0.263230).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2419267
	speed: 0.0942s/iter; left time: 1862.0117s
	iters: 200, epoch: 24 | loss: 0.2196986
	speed: 0.0205s/iter; left time: 403.3685s
Epoch: 24 cost time: 6.111798048019409
Epoch: 24, Steps: 258 | Train Loss: 0.2569695 Vali Loss: 0.2635461 Test Loss: 0.3542612
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2022975
	speed: 0.0909s/iter; left time: 1773.9171s
	iters: 200, epoch: 25 | loss: 0.2608934
	speed: 0.0213s/iter; left time: 413.7876s
Epoch: 25 cost time: 6.077542304992676
Epoch: 25, Steps: 258 | Train Loss: 0.2569864 Vali Loss: 0.2633808 Test Loss: 0.3543944
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2578617
	speed: 0.0925s/iter; left time: 1781.4535s
	iters: 200, epoch: 26 | loss: 0.2030406
	speed: 0.0224s/iter; left time: 428.2516s
Epoch: 26 cost time: 6.386584997177124
Epoch: 26, Steps: 258 | Train Loss: 0.2569669 Vali Loss: 0.2632646 Test Loss: 0.3542654
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2686784
	speed: 0.0932s/iter; left time: 1770.7447s
	iters: 200, epoch: 27 | loss: 0.2380974
	speed: 0.0212s/iter; left time: 400.0554s
Epoch: 27 cost time: 6.186456680297852
Epoch: 27, Steps: 258 | Train Loss: 0.2570748 Vali Loss: 0.2633463 Test Loss: 0.3542845
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2231572
	speed: 0.0925s/iter; left time: 1733.8830s
	iters: 200, epoch: 28 | loss: 0.2602571
	speed: 0.0216s/iter; left time: 403.0502s
Epoch: 28 cost time: 6.144486904144287
Epoch: 28, Steps: 258 | Train Loss: 0.2571782 Vali Loss: 0.2632442 Test Loss: 0.3543077
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2406564
	speed: 0.0897s/iter; left time: 1656.5335s
	iters: 200, epoch: 29 | loss: 0.2266822
	speed: 0.0203s/iter; left time: 373.1270s
Epoch: 29 cost time: 5.993291139602661
Epoch: 29, Steps: 258 | Train Loss: 0.2567756 Vali Loss: 0.2635982 Test Loss: 0.3542677
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1951688
	speed: 0.0895s/iter; left time: 1630.8018s
	iters: 200, epoch: 30 | loss: 0.2520180
	speed: 0.0209s/iter; left time: 378.1485s
Epoch: 30 cost time: 6.086139678955078
Epoch: 30, Steps: 258 | Train Loss: 0.2572079 Vali Loss: 0.2632452 Test Loss: 0.3542664
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2604520
	speed: 0.0898s/iter; left time: 1612.7443s
	iters: 200, epoch: 31 | loss: 0.3151579
	speed: 0.0211s/iter; left time: 376.5394s
Epoch: 31 cost time: 6.054365873336792
Epoch: 31, Steps: 258 | Train Loss: 0.2570446 Vali Loss: 0.2632301 Test Loss: 0.3542491
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2278441
	speed: 0.0887s/iter; left time: 1570.1297s
	iters: 200, epoch: 32 | loss: 0.3505077
	speed: 0.0209s/iter; left time: 367.5590s
Epoch: 32 cost time: 6.050628185272217
Epoch: 32, Steps: 258 | Train Loss: 0.2571538 Vali Loss: 0.2633155 Test Loss: 0.3543352
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2591427
	speed: 0.0953s/iter; left time: 1662.0877s
	iters: 200, epoch: 33 | loss: 0.3195304
	speed: 0.0209s/iter; left time: 361.7370s
Epoch: 33 cost time: 6.184703588485718
Epoch: 33, Steps: 258 | Train Loss: 0.2569525 Vali Loss: 0.2633187 Test Loss: 0.3542294
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2514821
	speed: 0.0949s/iter; left time: 1631.0437s
	iters: 200, epoch: 34 | loss: 0.2105069
	speed: 0.0214s/iter; left time: 366.2809s
Epoch: 34 cost time: 6.4970481395721436
Epoch: 34, Steps: 258 | Train Loss: 0.2567182 Vali Loss: 0.2635178 Test Loss: 0.3542196
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2739137
	speed: 0.0887s/iter; left time: 1502.1470s
	iters: 200, epoch: 35 | loss: 0.2092503
	speed: 0.0212s/iter; left time: 356.9324s
Epoch: 35 cost time: 6.077797889709473
Epoch: 35, Steps: 258 | Train Loss: 0.2571982 Vali Loss: 0.2636153 Test Loss: 0.3541847
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2250547
	speed: 0.0887s/iter; left time: 1478.8044s
	iters: 200, epoch: 36 | loss: 0.3337980
	speed: 0.0209s/iter; left time: 345.8503s
Epoch: 36 cost time: 6.010831117630005
Epoch: 36, Steps: 258 | Train Loss: 0.2568337 Vali Loss: 0.2633085 Test Loss: 0.3542280
EarlyStopping counter: 13 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2597542
	speed: 0.0908s/iter; left time: 1490.8288s
	iters: 200, epoch: 37 | loss: 0.2298985
	speed: 0.0214s/iter; left time: 348.5834s
Epoch: 37 cost time: 6.024035692214966
Epoch: 37, Steps: 258 | Train Loss: 0.2570480 Vali Loss: 0.2633653 Test Loss: 0.3542405
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2478458
	speed: 0.0882s/iter; left time: 1424.6887s
	iters: 200, epoch: 38 | loss: 0.2782733
	speed: 0.0209s/iter; left time: 336.0539s
Epoch: 38 cost time: 5.945261716842651
Epoch: 38, Steps: 258 | Train Loss: 0.2571008 Vali Loss: 0.2635291 Test Loss: 0.3542122
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2209949
	speed: 0.0929s/iter; left time: 1477.5974s
	iters: 200, epoch: 39 | loss: 0.2634401
	speed: 0.0208s/iter; left time: 329.2700s
Epoch: 39 cost time: 6.015587329864502
Epoch: 39, Steps: 258 | Train Loss: 0.2569804 Vali Loss: 0.2634181 Test Loss: 0.3542086
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2977058
	speed: 0.0874s/iter; left time: 1366.3754s
	iters: 200, epoch: 40 | loss: 0.2216686
	speed: 0.0212s/iter; left time: 329.0757s
Epoch: 40 cost time: 5.8797767162323
Epoch: 40, Steps: 258 | Train Loss: 0.2568411 Vali Loss: 0.2632990 Test Loss: 0.3541698
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2408115
	speed: 0.0879s/iter; left time: 1351.3479s
	iters: 200, epoch: 41 | loss: 0.2140004
	speed: 0.0205s/iter; left time: 313.8855s
Epoch: 41 cost time: 5.884212255477905
Epoch: 41, Steps: 258 | Train Loss: 0.2568284 Vali Loss: 0.2635461 Test Loss: 0.3541491
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2020885
	speed: 0.0888s/iter; left time: 1342.7602s
	iters: 200, epoch: 42 | loss: 0.2155178
	speed: 0.0202s/iter; left time: 304.1283s
Epoch: 42 cost time: 5.987354040145874
Epoch: 42, Steps: 258 | Train Loss: 0.2571265 Vali Loss: 0.2634504 Test Loss: 0.3541450
EarlyStopping counter: 19 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1736861
	speed: 0.0895s/iter; left time: 1330.8025s
	iters: 200, epoch: 43 | loss: 0.1876139
	speed: 0.0212s/iter; left time: 313.1309s
Epoch: 43 cost time: 6.171775579452515
Epoch: 43, Steps: 258 | Train Loss: 0.2569890 Vali Loss: 0.2634272 Test Loss: 0.3541633
EarlyStopping counter: 20 out of 20
Early stopping
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=90, out_features=180, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  14515200.0
params:  16380.0
Trainable parameters:  16380
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6179844
	speed: 0.0274s/iter; left time: 703.2744s
	iters: 200, epoch: 1 | loss: 0.4375049
	speed: 0.0207s/iter; left time: 530.5952s
Epoch: 1 cost time: 5.99327278137207
Epoch: 1, Steps: 258 | Train Loss: 0.4975829 Vali Loss: 0.2623267 Test Loss: 0.3534891
Validation loss decreased (inf --> 0.262327).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4138848
	speed: 0.0902s/iter; left time: 2294.6688s
	iters: 200, epoch: 2 | loss: 0.5575526
	speed: 0.0209s/iter; left time: 530.3160s
Epoch: 2 cost time: 6.12666916847229
Epoch: 2, Steps: 258 | Train Loss: 0.4964206 Vali Loss: 0.2616568 Test Loss: 0.3533921
Validation loss decreased (0.262327 --> 0.261657).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4078057
	speed: 0.0914s/iter; left time: 2302.5480s
	iters: 200, epoch: 3 | loss: 0.5551391
	speed: 0.0206s/iter; left time: 516.2287s
Epoch: 3 cost time: 6.086166620254517
Epoch: 3, Steps: 258 | Train Loss: 0.4962239 Vali Loss: 0.2612053 Test Loss: 0.3529874
Validation loss decreased (0.261657 --> 0.261205).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3953992
	speed: 0.0885s/iter; left time: 2206.8752s
	iters: 200, epoch: 4 | loss: 0.4384520
	speed: 0.0209s/iter; left time: 519.3605s
Epoch: 4 cost time: 5.970795631408691
Epoch: 4, Steps: 258 | Train Loss: 0.4953552 Vali Loss: 0.2614667 Test Loss: 0.3530826
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3165338
	speed: 0.0921s/iter; left time: 2272.0535s
	iters: 200, epoch: 5 | loss: 0.5058094
	speed: 0.0214s/iter; left time: 524.9823s
Epoch: 5 cost time: 6.138314247131348
Epoch: 5, Steps: 258 | Train Loss: 0.4955812 Vali Loss: 0.2610324 Test Loss: 0.3525589
Validation loss decreased (0.261205 --> 0.261032).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.5438643
	speed: 0.0884s/iter; left time: 2158.3565s
	iters: 200, epoch: 6 | loss: 0.4981046
	speed: 0.0206s/iter; left time: 499.8075s
Epoch: 6 cost time: 5.836462497711182
Epoch: 6, Steps: 258 | Train Loss: 0.4944822 Vali Loss: 0.2611331 Test Loss: 0.3525209
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3971609
	speed: 0.0894s/iter; left time: 2159.0722s
	iters: 200, epoch: 7 | loss: 0.4772488
	speed: 0.0211s/iter; left time: 507.5527s
Epoch: 7 cost time: 5.977861166000366
Epoch: 7, Steps: 258 | Train Loss: 0.4949065 Vali Loss: 0.2609464 Test Loss: 0.3526392
Validation loss decreased (0.261032 --> 0.260946).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.5252454
	speed: 0.0906s/iter; left time: 2165.0125s
	iters: 200, epoch: 8 | loss: 0.3735809
	speed: 0.0207s/iter; left time: 492.0149s
Epoch: 8 cost time: 5.966487407684326
Epoch: 8, Steps: 258 | Train Loss: 0.4949552 Vali Loss: 0.2604765 Test Loss: 0.3526566
Validation loss decreased (0.260946 --> 0.260476).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4701826
	speed: 0.0928s/iter; left time: 2193.2864s
	iters: 200, epoch: 9 | loss: 0.5584271
	speed: 0.0208s/iter; left time: 488.5621s
Epoch: 9 cost time: 6.012585163116455
Epoch: 9, Steps: 258 | Train Loss: 0.4947978 Vali Loss: 0.2609183 Test Loss: 0.3523971
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4906116
	speed: 0.0875s/iter; left time: 2046.2912s
	iters: 200, epoch: 10 | loss: 0.6100682
	speed: 0.0215s/iter; left time: 500.7825s
Epoch: 10 cost time: 5.985723495483398
Epoch: 10, Steps: 258 | Train Loss: 0.4949696 Vali Loss: 0.2610635 Test Loss: 0.3522965
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4269574
	speed: 0.0881s/iter; left time: 2036.1520s
	iters: 200, epoch: 11 | loss: 0.3799555
	speed: 0.0207s/iter; left time: 476.9718s
Epoch: 11 cost time: 6.023633718490601
Epoch: 11, Steps: 258 | Train Loss: 0.4943097 Vali Loss: 0.2606312 Test Loss: 0.3525169
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.5177922
	speed: 0.0894s/iter; left time: 2043.7196s
	iters: 200, epoch: 12 | loss: 0.6504759
	speed: 0.0210s/iter; left time: 476.9176s
Epoch: 12 cost time: 6.056847810745239
Epoch: 12, Steps: 258 | Train Loss: 0.4946024 Vali Loss: 0.2611103 Test Loss: 0.3524214
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.5123872
	speed: 0.0890s/iter; left time: 2012.6300s
	iters: 200, epoch: 13 | loss: 0.5561082
	speed: 0.0206s/iter; left time: 463.4818s
Epoch: 13 cost time: 5.8858115673065186
Epoch: 13, Steps: 258 | Train Loss: 0.4941577 Vali Loss: 0.2607625 Test Loss: 0.3523465
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4463317
	speed: 0.0882s/iter; left time: 1970.4044s
	iters: 200, epoch: 14 | loss: 0.6993106
	speed: 0.0208s/iter; left time: 463.7381s
Epoch: 14 cost time: 5.9555418491363525
Epoch: 14, Steps: 258 | Train Loss: 0.4937414 Vali Loss: 0.2610281 Test Loss: 0.3523706
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.5472036
	speed: 0.0896s/iter; left time: 1979.8719s
	iters: 200, epoch: 15 | loss: 0.4706160
	speed: 0.0206s/iter; left time: 453.3116s
Epoch: 15 cost time: 5.884351015090942
Epoch: 15, Steps: 258 | Train Loss: 0.4941747 Vali Loss: 0.2609661 Test Loss: 0.3522899
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.5520185
	speed: 0.0883s/iter; left time: 1926.6968s
	iters: 200, epoch: 16 | loss: 0.4385351
	speed: 0.0202s/iter; left time: 438.3044s
Epoch: 16 cost time: 5.746009588241577
Epoch: 16, Steps: 258 | Train Loss: 0.4945723 Vali Loss: 0.2610649 Test Loss: 0.3521132
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.5737342
	speed: 0.0913s/iter; left time: 1970.6554s
	iters: 200, epoch: 17 | loss: 0.5141876
	speed: 0.0210s/iter; left time: 451.2614s
Epoch: 17 cost time: 5.9951560497283936
Epoch: 17, Steps: 258 | Train Loss: 0.4940523 Vali Loss: 0.2607335 Test Loss: 0.3524020
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.5500861
	speed: 0.0895s/iter; left time: 1906.9170s
	iters: 200, epoch: 18 | loss: 0.4788631
	speed: 0.0209s/iter; left time: 443.8258s
Epoch: 18 cost time: 6.057298898696899
Epoch: 18, Steps: 258 | Train Loss: 0.4941215 Vali Loss: 0.2607110 Test Loss: 0.3523968
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4102802
	speed: 0.0882s/iter; left time: 1858.0111s
	iters: 200, epoch: 19 | loss: 0.5316678
	speed: 0.0216s/iter; left time: 453.1519s
Epoch: 19 cost time: 6.228163480758667
Epoch: 19, Steps: 258 | Train Loss: 0.4939929 Vali Loss: 0.2603624 Test Loss: 0.3522272
Validation loss decreased (0.260476 --> 0.260362).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.5049697
	speed: 0.0888s/iter; left time: 1847.0657s
	iters: 200, epoch: 20 | loss: 0.5830514
	speed: 0.0208s/iter; left time: 431.2836s
Epoch: 20 cost time: 5.994619846343994
Epoch: 20, Steps: 258 | Train Loss: 0.4943020 Vali Loss: 0.2608418 Test Loss: 0.3522608
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.6566250
	speed: 0.0903s/iter; left time: 1853.9995s
	iters: 200, epoch: 21 | loss: 0.4132935
	speed: 0.0211s/iter; left time: 432.2596s
Epoch: 21 cost time: 6.102855920791626
Epoch: 21, Steps: 258 | Train Loss: 0.4936241 Vali Loss: 0.2605707 Test Loss: 0.3522822
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.5425341
	speed: 0.0906s/iter; left time: 1837.7924s
	iters: 200, epoch: 22 | loss: 0.5002224
	speed: 0.0209s/iter; left time: 421.8362s
Epoch: 22 cost time: 6.177026748657227
Epoch: 22, Steps: 258 | Train Loss: 0.4939308 Vali Loss: 0.2608156 Test Loss: 0.3521294
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4145187
	speed: 0.0886s/iter; left time: 1773.7941s
	iters: 200, epoch: 23 | loss: 0.4347735
	speed: 0.0208s/iter; left time: 413.8517s
Epoch: 23 cost time: 6.049588203430176
Epoch: 23, Steps: 258 | Train Loss: 0.4940438 Vali Loss: 0.2604439 Test Loss: 0.3522345
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.5359710
	speed: 0.0887s/iter; left time: 1753.8088s
	iters: 200, epoch: 24 | loss: 0.6723084
	speed: 0.0212s/iter; left time: 416.7352s
Epoch: 24 cost time: 6.069077014923096
Epoch: 24, Steps: 258 | Train Loss: 0.4937881 Vali Loss: 0.2603646 Test Loss: 0.3522304
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4909380
	speed: 0.0938s/iter; left time: 1829.9597s
	iters: 200, epoch: 25 | loss: 0.6697096
	speed: 0.0216s/iter; left time: 419.5706s
Epoch: 25 cost time: 6.229344129562378
Epoch: 25, Steps: 258 | Train Loss: 0.4939748 Vali Loss: 0.2604610 Test Loss: 0.3522954
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.7892372
	speed: 0.0918s/iter; left time: 1767.5347s
	iters: 200, epoch: 26 | loss: 0.4952953
	speed: 0.0212s/iter; left time: 405.5773s
Epoch: 26 cost time: 6.227867841720581
Epoch: 26, Steps: 258 | Train Loss: 0.4941025 Vali Loss: 0.2605768 Test Loss: 0.3522769
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4217444
	speed: 0.0897s/iter; left time: 1703.5685s
	iters: 200, epoch: 27 | loss: 0.5469640
	speed: 0.0212s/iter; left time: 399.6805s
Epoch: 27 cost time: 6.0639660358428955
Epoch: 27, Steps: 258 | Train Loss: 0.4937714 Vali Loss: 0.2605159 Test Loss: 0.3522737
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4388184
	speed: 0.0918s/iter; left time: 1720.4993s
	iters: 200, epoch: 28 | loss: 0.5622829
	speed: 0.0213s/iter; left time: 396.0066s
Epoch: 28 cost time: 6.6476075649261475
Epoch: 28, Steps: 258 | Train Loss: 0.4933060 Vali Loss: 0.2605658 Test Loss: 0.3522524
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.5369485
	speed: 0.1015s/iter; left time: 1875.3252s
	iters: 200, epoch: 29 | loss: 0.5315556
	speed: 0.0197s/iter; left time: 362.2200s
Epoch: 29 cost time: 5.953420639038086
Epoch: 29, Steps: 258 | Train Loss: 0.4933985 Vali Loss: 0.2604817 Test Loss: 0.3523270
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.5203338
	speed: 0.0923s/iter; left time: 1681.1563s
	iters: 200, epoch: 30 | loss: 0.5816112
	speed: 0.0217s/iter; left time: 392.3027s
Epoch: 30 cost time: 6.312412977218628
Epoch: 30, Steps: 258 | Train Loss: 0.4936576 Vali Loss: 0.2606390 Test Loss: 0.3522271
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4593706
	speed: 0.0901s/iter; left time: 1618.2263s
	iters: 200, epoch: 31 | loss: 0.3542590
	speed: 0.0205s/iter; left time: 366.5654s
Epoch: 31 cost time: 6.060262680053711
Epoch: 31, Steps: 258 | Train Loss: 0.4940466 Vali Loss: 0.2607410 Test Loss: 0.3521835
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3676071
	speed: 0.0884s/iter; left time: 1564.7013s
	iters: 200, epoch: 32 | loss: 0.5027483
	speed: 0.0209s/iter; left time: 368.2014s
Epoch: 32 cost time: 5.86285400390625
Epoch: 32, Steps: 258 | Train Loss: 0.4932263 Vali Loss: 0.2605580 Test Loss: 0.3522575
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.5605849
	speed: 0.0870s/iter; left time: 1517.6313s
	iters: 200, epoch: 33 | loss: 0.4948735
	speed: 0.0210s/iter; left time: 363.9305s
Epoch: 33 cost time: 5.957919359207153
Epoch: 33, Steps: 258 | Train Loss: 0.4937512 Vali Loss: 0.2606144 Test Loss: 0.3522052
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4179578
	speed: 0.0895s/iter; left time: 1537.8308s
	iters: 200, epoch: 34 | loss: 0.4864541
	speed: 0.0196s/iter; left time: 334.3562s
Epoch: 34 cost time: 5.662396669387817
Epoch: 34, Steps: 258 | Train Loss: 0.4938635 Vali Loss: 0.2607307 Test Loss: 0.3522832
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.6517252
	speed: 0.0925s/iter; left time: 1566.1439s
	iters: 200, epoch: 35 | loss: 0.4489089
	speed: 0.0210s/iter; left time: 353.6163s
Epoch: 35 cost time: 6.217473268508911
Epoch: 35, Steps: 258 | Train Loss: 0.4938947 Vali Loss: 0.2605367 Test Loss: 0.3522008
EarlyStopping counter: 16 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3901671
	speed: 0.0883s/iter; left time: 1472.0279s
	iters: 200, epoch: 36 | loss: 0.4462311
	speed: 0.0202s/iter; left time: 335.0890s
Epoch: 36 cost time: 5.872328519821167
Epoch: 36, Steps: 258 | Train Loss: 0.4936466 Vali Loss: 0.2608003 Test Loss: 0.3521783
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.5409765
	speed: 0.0920s/iter; left time: 1510.4287s
	iters: 200, epoch: 37 | loss: 0.3803466
	speed: 0.0208s/iter; left time: 339.0396s
Epoch: 37 cost time: 6.079715251922607
Epoch: 37, Steps: 258 | Train Loss: 0.4927807 Vali Loss: 0.2606708 Test Loss: 0.3522452
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4160534
	speed: 0.0903s/iter; left time: 1458.5188s
	iters: 200, epoch: 38 | loss: 0.4606278
	speed: 0.0201s/iter; left time: 323.0562s
Epoch: 38 cost time: 5.9171061515808105
Epoch: 38, Steps: 258 | Train Loss: 0.4936927 Vali Loss: 0.2605619 Test Loss: 0.3522103
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3841697
	speed: 0.0911s/iter; left time: 1448.1779s
	iters: 200, epoch: 39 | loss: 0.4224512
	speed: 0.0206s/iter; left time: 325.3640s
Epoch: 39 cost time: 5.917364597320557
Epoch: 39, Steps: 258 | Train Loss: 0.4931890 Vali Loss: 0.2605037 Test Loss: 0.3522653
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_720_720_FITS_ETTm2_ftM_sl720_ll48_pl720_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.34888067841529846, mae:0.377949059009552, rse:0.47476956248283386, corr:[0.5428145  0.5447762  0.5428451  0.5404071  0.5391552  0.5391896
 0.53974485 0.5398883  0.539281   0.53828496 0.5374463  0.53706974
 0.5371643  0.53742254 0.5374851  0.5370277  0.5361512  0.53516465
 0.5343136  0.53370565 0.5333313  0.5329931  0.53254724 0.53196615
 0.5312956  0.53067327 0.53018945 0.52985513 0.5295775  0.5292492
 0.5287783  0.52823704 0.52766794 0.5270712  0.5265127  0.526027
 0.52554286 0.52501553 0.52438813 0.5237017  0.5230251  0.5223923
 0.5218627  0.52141404 0.52098274 0.5204446  0.51976013 0.518962
 0.5180517  0.51706827 0.51613164 0.5153708  0.5147694  0.51426077
 0.5137754  0.51328075 0.51276654 0.5122702  0.51187104 0.5115804
 0.5114022  0.51129436 0.5111871  0.5110025  0.51072377 0.510434
 0.51011366 0.50986236 0.5096792  0.5095001  0.50924325 0.508875
 0.5084323  0.50796586 0.50749445 0.5070479  0.506616   0.50615185
 0.50565255 0.50509006 0.50440276 0.5036471  0.5028783  0.50212586
 0.5014258  0.50079715 0.5001966  0.49968624 0.49925628 0.49890953
 0.4986319  0.4983258  0.49782377 0.4970193  0.49585283 0.49437228
 0.4927501  0.49123308 0.48988533 0.48870182 0.4876331  0.4865884
 0.48550993 0.48436946 0.4831851  0.4820291  0.48099643 0.48013815
 0.47936398 0.47858396 0.477737   0.47678924 0.47584412 0.47492588
 0.47404936 0.4732586  0.47257048 0.47191128 0.47126728 0.470565
 0.46986255 0.46914324 0.46844858 0.4677334  0.4669344  0.4660058
 0.464999   0.46396455 0.4629621  0.46202156 0.46115842 0.46031344
 0.45945483 0.45852447 0.45753345 0.4565057  0.4554916  0.45461726
 0.4539373  0.45343974 0.45301902 0.45256683 0.45201504 0.451276
 0.4503944  0.44942492 0.44858387 0.4479067  0.4473656  0.44682157
 0.44621634 0.44554943 0.44479853 0.4440463  0.4434143  0.4429754
 0.44269896 0.44246995 0.44213936 0.441706   0.4411349  0.44052538
 0.43997306 0.43959892 0.43942362 0.43938    0.43932807 0.4391935
 0.43897876 0.43873623 0.43842798 0.438091   0.43768728 0.4371957
 0.43657678 0.4358326  0.43499014 0.43410468 0.433211   0.4324246
 0.4317328  0.43112385 0.43062854 0.43021807 0.4298513  0.42950213
 0.4291938  0.42885795 0.42841578 0.4277279  0.42671144 0.42533213
 0.4236892  0.42207283 0.42048728 0.4189744  0.41764456 0.41649377
 0.4155191  0.41462463 0.41370043 0.41264865 0.4114151  0.4100326
 0.40859932 0.40723148 0.40602037 0.40502104 0.40430796 0.40386084
 0.4033917  0.40268004 0.40164968 0.40037265 0.39905587 0.39780453
 0.39668995 0.39564934 0.39467838 0.39366737 0.39252096 0.3912591
 0.38998023 0.38884556 0.3880035  0.38731468 0.38663822 0.3858851
 0.38491207 0.38377523 0.38258228 0.38149622 0.38062358 0.38002893
 0.37963012 0.37934825 0.37904575 0.37862483 0.37810016 0.37749544
 0.3768929  0.37629965 0.3757569  0.37541124 0.37514183 0.3749453
 0.37478748 0.37466976 0.37455755 0.37441534 0.37431282 0.37420505
 0.3740344  0.37382823 0.37351704 0.37316015 0.37278685 0.37250084
 0.37230358 0.37215605 0.37196296 0.37171343 0.37138996 0.37111926
 0.37096018 0.37087098 0.37082255 0.37071744 0.37041628 0.36983165
 0.3690864  0.36832345 0.36763537 0.36714134 0.36680847 0.36653674
 0.3662864  0.36590302 0.36535874 0.36483675 0.36442134 0.36421996
 0.3641573  0.36409888 0.3638577  0.36326197 0.36228782 0.36096618
 0.35959473 0.35856777 0.35796124 0.35765633 0.35747108 0.35715798
 0.35669056 0.35603908 0.3552509  0.35445204 0.35381168 0.35332766
 0.35304558 0.35280466 0.35258391 0.35221636 0.35174114 0.35119548
 0.35067654 0.35011494 0.34951428 0.34888652 0.34827206 0.347849
 0.3475796  0.3475265  0.34758487 0.3476229  0.3475763  0.3474349
 0.34714985 0.34680626 0.34651485 0.3463232  0.34622902 0.3462391
 0.34630245 0.3464245  0.34658307 0.34666568 0.3467235  0.34672356
 0.3467512  0.3467295  0.34661674 0.3464132  0.34603935 0.34560272
 0.34514153 0.34464228 0.3442437  0.3440868  0.34414235 0.34426063
 0.3443552  0.34435505 0.34422368 0.34397674 0.34368807 0.34347948
 0.3433763  0.34338614 0.34343013 0.34340584 0.343278   0.34302846
 0.34269688 0.34238246 0.34207678 0.3419044  0.3417456  0.34161922
 0.34148905 0.34132344 0.34108818 0.340764   0.3403122  0.33983296
 0.33933476 0.3389682  0.3387939  0.33887523 0.33922493 0.3397202
 0.34025002 0.3407337  0.34107172 0.3411861  0.34104893 0.34076014
 0.34044555 0.3401703  0.3399084  0.3395593  0.33920437 0.33877242
 0.33836445 0.3380162  0.3377204  0.33737728 0.3368653  0.336235
 0.33545637 0.33457646 0.33365113 0.3327555  0.33195865 0.33126992
 0.33070984 0.33031192 0.3299388  0.32951972 0.3290735  0.3284775
 0.3277054  0.32677975 0.32584736 0.32508525 0.3245092  0.32417193
 0.32398033 0.32390246 0.32383946 0.32370034 0.32354042 0.3233844
 0.3233564  0.32349628 0.3237019  0.3238685  0.32386714 0.32369944
 0.3234832  0.32333797 0.32332537 0.32349253 0.32380375 0.32415253
 0.32443058 0.32450238 0.32438412 0.32414883 0.32395628 0.32393882
 0.32413366 0.32439873 0.32464108 0.32476932 0.3247403  0.32449007
 0.32396328 0.3233636  0.32274687 0.32212055 0.3215439  0.32110173
 0.32070094 0.32038257 0.3201157  0.31984815 0.31960937 0.3193591
 0.3191144  0.3188614  0.31862488 0.31834427 0.31806657 0.31786212
 0.3177203  0.31759587 0.31738785 0.31701893 0.31656647 0.3160042
 0.3154732  0.31509334 0.31491143 0.3148817  0.31487107 0.3147552
 0.31447154 0.3140076  0.3134106  0.31278855 0.3123175  0.3120026
 0.31179783 0.31152087 0.31110504 0.31042695 0.30951568 0.30843058
 0.30724865 0.30612078 0.30499464 0.30384287 0.30267495 0.3015111
 0.3003784  0.29941067 0.29864207 0.29813868 0.29775852 0.29730952
 0.29666322 0.29586783 0.29498357 0.29402548 0.29310724 0.2922835
 0.29156438 0.29083285 0.2900384  0.28928906 0.28862748 0.2882198
 0.28799185 0.287852   0.28771845 0.28746256 0.2870875  0.2865719
 0.28598282 0.2854147  0.2849213  0.28453967 0.2842722  0.28404948
 0.2837651  0.28333402 0.28293902 0.28260067 0.28233337 0.28215116
 0.28199327 0.2818289  0.28156993 0.2812317  0.28092578 0.28072014
 0.2806367  0.28069285 0.28080034 0.28086117 0.28080815 0.28057143
 0.28011927 0.279549   0.27909395 0.27884388 0.2788173  0.27894637
 0.27909032 0.27914026 0.27899012 0.27868918 0.27828902 0.27784687
 0.2774542  0.27721104 0.2771167  0.27711895 0.27708805 0.2770091
 0.27680975 0.27652055 0.2761614  0.27578765 0.27530968 0.27488145
 0.27459377 0.27457735 0.2747505  0.27496687 0.2750871  0.27499735
 0.27467242 0.27416474 0.27366075 0.27332184 0.27324426 0.27340168
 0.27362034 0.27366692 0.2732778  0.2723775  0.27104944 0.26940522
 0.2676842  0.2662848  0.2652996  0.26464114 0.26406217 0.2633901
 0.26255924 0.2616124  0.2606628  0.25980365 0.25907275 0.25851867
 0.25808236 0.2576572  0.257243   0.25676543 0.256172   0.25548145
 0.254687   0.25378004 0.2529072  0.2521078  0.2515291  0.25120735
 0.2510513  0.25098214 0.2507935  0.25036424 0.24980669 0.24927521
 0.24884525 0.24864657 0.24875514 0.24898396 0.2492095  0.24927929
 0.24918026 0.24876541 0.24817586 0.24766488 0.24736385 0.24729344
 0.2474225  0.24773733 0.24811602 0.24851365 0.24891967 0.2493469
 0.24973127 0.2499911  0.25009003 0.25012562 0.25013903 0.25014475
 0.25011113 0.250091   0.25015157 0.25011307 0.25012887 0.25013167
 0.25010043 0.250049   0.24990879 0.24983175 0.24969539 0.24953508
 0.24930644 0.24914078 0.24898669 0.2487721  0.24871425 0.24869442
 0.24878965 0.24891122 0.2489804  0.24889211 0.24869524 0.24828477
 0.24790955 0.2476524  0.24753025 0.24765679 0.2479491  0.24818158
 0.24817757 0.24806826 0.24785177 0.2476777  0.24775189 0.24804266
 0.24838674 0.2486563  0.24865797 0.24818005 0.24721897 0.24598248
 0.24468504 0.24348283 0.24241124 0.24141635 0.2405455  0.23974974
 0.23901026 0.23831847 0.23788314 0.23754649 0.23723401 0.23680528
 0.23623842 0.23560838 0.23501165 0.23448674 0.23411743 0.23372208
 0.2332204  0.23254971 0.23171091 0.23103407 0.23059082 0.230374
 0.23030151 0.23013613 0.22976658 0.2290161  0.22800487 0.22693445
 0.2261688  0.22567566 0.22547075 0.22544461 0.22541839 0.22529095
 0.2249594  0.22453277 0.22403839 0.2235747  0.22288787 0.22204538
 0.22127454 0.22103779 0.22169246 0.2229305  0.22321254 0.21966945]
