Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=30, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_180_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_180_336_FITS_ETTm2_ftM_sl180_ll48_pl336_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34045
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=30, out_features=86, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2311680.0
params:  2666.0
Trainable parameters:  2666
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5096424
	speed: 0.0211s/iter; left time: 556.1058s
	iters: 200, epoch: 1 | loss: 0.3896767
	speed: 0.0150s/iter; left time: 394.4859s
Epoch: 1 cost time: 4.57196831703186
Epoch: 1, Steps: 265 | Train Loss: 0.5060457 Vali Loss: 0.2275225 Test Loss: 0.3113772
Validation loss decreased (inf --> 0.227522).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6429085
	speed: 0.0689s/iter; left time: 1801.5850s
	iters: 200, epoch: 2 | loss: 0.4414893
	speed: 0.0129s/iter; left time: 335.7086s
Epoch: 2 cost time: 3.885739326477051
Epoch: 2, Steps: 265 | Train Loss: 0.4424295 Vali Loss: 0.2158185 Test Loss: 0.2978670
Validation loss decreased (0.227522 --> 0.215819).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5258852
	speed: 0.0667s/iter; left time: 1725.3568s
	iters: 200, epoch: 3 | loss: 0.4267091
	speed: 0.0130s/iter; left time: 334.6210s
Epoch: 3 cost time: 3.9545037746429443
Epoch: 3, Steps: 265 | Train Loss: 0.4314920 Vali Loss: 0.2126676 Test Loss: 0.2938821
Validation loss decreased (0.215819 --> 0.212668).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.5001976
	speed: 0.0664s/iter; left time: 1701.2388s
	iters: 200, epoch: 4 | loss: 0.3653725
	speed: 0.0133s/iter; left time: 338.7560s
Epoch: 4 cost time: 4.059254169464111
Epoch: 4, Steps: 265 | Train Loss: 0.4284325 Vali Loss: 0.2109864 Test Loss: 0.2915809
Validation loss decreased (0.212668 --> 0.210986).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3998529
	speed: 0.0678s/iter; left time: 1717.2677s
	iters: 200, epoch: 5 | loss: 0.3629559
	speed: 0.0135s/iter; left time: 339.5128s
Epoch: 5 cost time: 4.018610000610352
Epoch: 5, Steps: 265 | Train Loss: 0.4255921 Vali Loss: 0.2100962 Test Loss: 0.2902129
Validation loss decreased (0.210986 --> 0.210096).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4501692
	speed: 0.0688s/iter; left time: 1725.9277s
	iters: 200, epoch: 6 | loss: 0.5182028
	speed: 0.0139s/iter; left time: 347.6944s
Epoch: 6 cost time: 4.075443506240845
Epoch: 6, Steps: 265 | Train Loss: 0.4238204 Vali Loss: 0.2091773 Test Loss: 0.2890934
Validation loss decreased (0.210096 --> 0.209177).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.5549455
	speed: 0.0740s/iter; left time: 1836.4366s
	iters: 200, epoch: 7 | loss: 0.5195667
	speed: 0.0147s/iter; left time: 362.6654s
Epoch: 7 cost time: 4.811028718948364
Epoch: 7, Steps: 265 | Train Loss: 0.4224765 Vali Loss: 0.2090017 Test Loss: 0.2883783
Validation loss decreased (0.209177 --> 0.209002).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3865144
	speed: 0.0727s/iter; left time: 1783.3892s
	iters: 200, epoch: 8 | loss: 0.3186852
	speed: 0.0152s/iter; left time: 371.0980s
Epoch: 8 cost time: 4.511350631713867
Epoch: 8, Steps: 265 | Train Loss: 0.4219490 Vali Loss: 0.2086961 Test Loss: 0.2877312
Validation loss decreased (0.209002 --> 0.208696).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4213365
	speed: 0.0713s/iter; left time: 1730.1457s
	iters: 200, epoch: 9 | loss: 0.3713243
	speed: 0.0133s/iter; left time: 322.6579s
Epoch: 9 cost time: 4.14049506187439
Epoch: 9, Steps: 265 | Train Loss: 0.4206469 Vali Loss: 0.2083499 Test Loss: 0.2872672
Validation loss decreased (0.208696 --> 0.208350).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3741364
	speed: 0.0676s/iter; left time: 1623.1314s
	iters: 200, epoch: 10 | loss: 0.3628170
	speed: 0.0128s/iter; left time: 306.2473s
Epoch: 10 cost time: 3.949882745742798
Epoch: 10, Steps: 265 | Train Loss: 0.4196739 Vali Loss: 0.2082613 Test Loss: 0.2868786
Validation loss decreased (0.208350 --> 0.208261).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4219911
	speed: 0.0678s/iter; left time: 1609.2251s
	iters: 200, epoch: 11 | loss: 0.4065590
	speed: 0.0142s/iter; left time: 335.9414s
Epoch: 11 cost time: 4.076916694641113
Epoch: 11, Steps: 265 | Train Loss: 0.4200045 Vali Loss: 0.2077541 Test Loss: 0.2865143
Validation loss decreased (0.208261 --> 0.207754).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3383704
	speed: 0.0678s/iter; left time: 1592.1142s
	iters: 200, epoch: 12 | loss: 0.3548297
	speed: 0.0134s/iter; left time: 312.6380s
Epoch: 12 cost time: 4.0210301876068115
Epoch: 12, Steps: 265 | Train Loss: 0.4184150 Vali Loss: 0.2078774 Test Loss: 0.2862842
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.6034966
	speed: 0.0672s/iter; left time: 1561.2442s
	iters: 200, epoch: 13 | loss: 0.4084199
	speed: 0.0134s/iter; left time: 310.9264s
Epoch: 13 cost time: 4.07707142829895
Epoch: 13, Steps: 265 | Train Loss: 0.4181441 Vali Loss: 0.2077013 Test Loss: 0.2861350
Validation loss decreased (0.207754 --> 0.207701).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3329947
	speed: 0.0708s/iter; left time: 1626.1485s
	iters: 200, epoch: 14 | loss: 0.5534902
	speed: 0.0132s/iter; left time: 302.7385s
Epoch: 14 cost time: 4.16435694694519
Epoch: 14, Steps: 265 | Train Loss: 0.4179595 Vali Loss: 0.2078098 Test Loss: 0.2859399
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.5140911
	speed: 0.0690s/iter; left time: 1564.8488s
	iters: 200, epoch: 15 | loss: 0.3279475
	speed: 0.0153s/iter; left time: 345.9666s
Epoch: 15 cost time: 4.490467071533203
Epoch: 15, Steps: 265 | Train Loss: 0.4178692 Vali Loss: 0.2075773 Test Loss: 0.2857874
Validation loss decreased (0.207701 --> 0.207577).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4405810
	speed: 0.0709s/iter; left time: 1590.1524s
	iters: 200, epoch: 16 | loss: 0.3091908
	speed: 0.0153s/iter; left time: 340.7161s
Epoch: 16 cost time: 4.411244869232178
Epoch: 16, Steps: 265 | Train Loss: 0.4182340 Vali Loss: 0.2075112 Test Loss: 0.2856922
Validation loss decreased (0.207577 --> 0.207511).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3324532
	speed: 0.0713s/iter; left time: 1579.9087s
	iters: 200, epoch: 17 | loss: 0.3422503
	speed: 0.0136s/iter; left time: 300.3692s
Epoch: 17 cost time: 4.169648885726929
Epoch: 17, Steps: 265 | Train Loss: 0.4182398 Vali Loss: 0.2074312 Test Loss: 0.2855771
Validation loss decreased (0.207511 --> 0.207431).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.5284134
	speed: 0.0658s/iter; left time: 1440.6258s
	iters: 200, epoch: 18 | loss: 0.3756147
	speed: 0.0131s/iter; left time: 285.3853s
Epoch: 18 cost time: 3.949643850326538
Epoch: 18, Steps: 265 | Train Loss: 0.4180146 Vali Loss: 0.2075346 Test Loss: 0.2855145
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4035962
	speed: 0.0649s/iter; left time: 1404.6663s
	iters: 200, epoch: 19 | loss: 0.5438557
	speed: 0.0131s/iter; left time: 282.2544s
Epoch: 19 cost time: 3.892090082168579
Epoch: 19, Steps: 265 | Train Loss: 0.4178206 Vali Loss: 0.2073276 Test Loss: 0.2854401
Validation loss decreased (0.207431 --> 0.207328).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4705577
	speed: 0.0672s/iter; left time: 1436.6364s
	iters: 200, epoch: 20 | loss: 0.5473311
	speed: 0.0133s/iter; left time: 282.0471s
Epoch: 20 cost time: 4.083406209945679
Epoch: 20, Steps: 265 | Train Loss: 0.4181214 Vali Loss: 0.2073131 Test Loss: 0.2853159
Validation loss decreased (0.207328 --> 0.207313).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3002690
	speed: 0.0728s/iter; left time: 1535.3990s
	iters: 200, epoch: 21 | loss: 0.4225435
	speed: 0.0151s/iter; left time: 316.1394s
Epoch: 21 cost time: 4.584945201873779
Epoch: 21, Steps: 265 | Train Loss: 0.4174224 Vali Loss: 0.2072679 Test Loss: 0.2852704
Validation loss decreased (0.207313 --> 0.207268).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3777305
	speed: 0.0790s/iter; left time: 1645.7325s
	iters: 200, epoch: 22 | loss: 0.3607374
	speed: 0.0424s/iter; left time: 878.2500s
Epoch: 22 cost time: 9.91695499420166
Epoch: 22, Steps: 265 | Train Loss: 0.4170608 Vali Loss: 0.2073506 Test Loss: 0.2851961
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2677956
	speed: 0.0868s/iter; left time: 1785.5890s
	iters: 200, epoch: 23 | loss: 0.4663783
	speed: 0.0136s/iter; left time: 278.2851s
Epoch: 23 cost time: 4.1124937534332275
Epoch: 23, Steps: 265 | Train Loss: 0.4177059 Vali Loss: 0.2071531 Test Loss: 0.2851696
Validation loss decreased (0.207268 --> 0.207153).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.5551695
	speed: 0.0682s/iter; left time: 1385.7794s
	iters: 200, epoch: 24 | loss: 0.2913356
	speed: 0.0124s/iter; left time: 251.3939s
Epoch: 24 cost time: 3.962918519973755
Epoch: 24, Steps: 265 | Train Loss: 0.4174664 Vali Loss: 0.2071486 Test Loss: 0.2851188
Validation loss decreased (0.207153 --> 0.207149).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2546430
	speed: 0.0679s/iter; left time: 1361.1177s
	iters: 200, epoch: 25 | loss: 0.3263195
	speed: 0.0132s/iter; left time: 263.0832s
Epoch: 25 cost time: 4.001822471618652
Epoch: 25, Steps: 265 | Train Loss: 0.4160141 Vali Loss: 0.2070899 Test Loss: 0.2850930
Validation loss decreased (0.207149 --> 0.207090).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4133304
	speed: 0.0681s/iter; left time: 1346.4838s
	iters: 200, epoch: 26 | loss: 0.5858884
	speed: 0.0137s/iter; left time: 269.1591s
Epoch: 26 cost time: 4.036460638046265
Epoch: 26, Steps: 265 | Train Loss: 0.4155986 Vali Loss: 0.2072443 Test Loss: 0.2850673
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3977197
	speed: 0.0690s/iter; left time: 1347.1455s
	iters: 200, epoch: 27 | loss: 0.2469967
	speed: 0.0132s/iter; left time: 255.3662s
Epoch: 27 cost time: 4.0526347160339355
Epoch: 27, Steps: 265 | Train Loss: 0.4167480 Vali Loss: 0.2070687 Test Loss: 0.2850335
Validation loss decreased (0.207090 --> 0.207069).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3491395
	speed: 0.0715s/iter; left time: 1375.5705s
	iters: 200, epoch: 28 | loss: 0.4050860
	speed: 0.0149s/iter; left time: 285.5925s
Epoch: 28 cost time: 4.496483564376831
Epoch: 28, Steps: 265 | Train Loss: 0.4166804 Vali Loss: 0.2072452 Test Loss: 0.2849989
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3877837
	speed: 0.0714s/iter; left time: 1355.0537s
	iters: 200, epoch: 29 | loss: 0.3696545
	speed: 0.0146s/iter; left time: 276.5693s
Epoch: 29 cost time: 4.3676533699035645
Epoch: 29, Steps: 265 | Train Loss: 0.4168602 Vali Loss: 0.2071581 Test Loss: 0.2849874
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4221834
	speed: 0.0734s/iter; left time: 1374.0858s
	iters: 200, epoch: 30 | loss: 0.5419991
	speed: 0.0153s/iter; left time: 284.5466s
Epoch: 30 cost time: 4.587810039520264
Epoch: 30, Steps: 265 | Train Loss: 0.4163441 Vali Loss: 0.2072938 Test Loss: 0.2849809
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3055947
	speed: 0.0696s/iter; left time: 1283.3378s
	iters: 200, epoch: 31 | loss: 0.4485817
	speed: 0.0127s/iter; left time: 232.6844s
Epoch: 31 cost time: 3.9227170944213867
Epoch: 31, Steps: 265 | Train Loss: 0.4166821 Vali Loss: 0.2071269 Test Loss: 0.2849533
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3001205
	speed: 0.0658s/iter; left time: 1196.3456s
	iters: 200, epoch: 32 | loss: 0.5316460
	speed: 0.0130s/iter; left time: 234.3308s
Epoch: 32 cost time: 3.866659164428711
Epoch: 32, Steps: 265 | Train Loss: 0.4169530 Vali Loss: 0.2072219 Test Loss: 0.2849565
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3072110
	speed: 0.0665s/iter; left time: 1191.1904s
	iters: 200, epoch: 33 | loss: 0.4208108
	speed: 0.0133s/iter; left time: 237.8812s
Epoch: 33 cost time: 3.9185469150543213
Epoch: 33, Steps: 265 | Train Loss: 0.4165502 Vali Loss: 0.2070114 Test Loss: 0.2849431
Validation loss decreased (0.207069 --> 0.207011).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4159707
	speed: 0.0695s/iter; left time: 1227.7060s
	iters: 200, epoch: 34 | loss: 0.2625884
	speed: 0.0144s/iter; left time: 252.8833s
Epoch: 34 cost time: 4.555501461029053
Epoch: 34, Steps: 265 | Train Loss: 0.4170054 Vali Loss: 0.2071635 Test Loss: 0.2849377
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4772820
	speed: 0.0693s/iter; left time: 1205.6478s
	iters: 200, epoch: 35 | loss: 0.4139782
	speed: 0.0151s/iter; left time: 260.4531s
Epoch: 35 cost time: 4.449072599411011
Epoch: 35, Steps: 265 | Train Loss: 0.4170484 Vali Loss: 0.2073939 Test Loss: 0.2849200
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3684627
	speed: 0.0673s/iter; left time: 1152.7365s
	iters: 200, epoch: 36 | loss: 0.4508043
	speed: 0.0140s/iter; left time: 238.7443s
Epoch: 36 cost time: 4.056986570358276
Epoch: 36, Steps: 265 | Train Loss: 0.4160048 Vali Loss: 0.2072712 Test Loss: 0.2848905
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3490896
	speed: 0.0682s/iter; left time: 1150.2390s
	iters: 200, epoch: 37 | loss: 0.3893084
	speed: 0.0132s/iter; left time: 220.5289s
Epoch: 37 cost time: 3.985983371734619
Epoch: 37, Steps: 265 | Train Loss: 0.4166720 Vali Loss: 0.2073138 Test Loss: 0.2848749
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4161182
	speed: 0.0675s/iter; left time: 1119.9413s
	iters: 200, epoch: 38 | loss: 0.5951336
	speed: 0.0130s/iter; left time: 214.7605s
Epoch: 38 cost time: 3.9421727657318115
Epoch: 38, Steps: 265 | Train Loss: 0.4169364 Vali Loss: 0.2072149 Test Loss: 0.2848618
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.5034590
	speed: 0.0680s/iter; left time: 1110.7615s
	iters: 200, epoch: 39 | loss: 0.3770522
	speed: 0.0132s/iter; left time: 213.6384s
Epoch: 39 cost time: 3.9901421070098877
Epoch: 39, Steps: 265 | Train Loss: 0.4164718 Vali Loss: 0.2071827 Test Loss: 0.2848503
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.3774856
	speed: 0.0658s/iter; left time: 1057.1783s
	iters: 200, epoch: 40 | loss: 0.6245095
	speed: 0.0133s/iter; left time: 213.1075s
Epoch: 40 cost time: 3.908447265625
Epoch: 40, Steps: 265 | Train Loss: 0.4161402 Vali Loss: 0.2072380 Test Loss: 0.2848547
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.4431488
	speed: 0.0670s/iter; left time: 1058.1095s
	iters: 200, epoch: 41 | loss: 0.4217823
	speed: 0.0128s/iter; left time: 200.5813s
Epoch: 41 cost time: 3.9626171588897705
Epoch: 41, Steps: 265 | Train Loss: 0.4157782 Vali Loss: 0.2073033 Test Loss: 0.2848437
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.4424692
	speed: 0.0663s/iter; left time: 1029.6538s
	iters: 200, epoch: 42 | loss: 0.3035579
	speed: 0.0126s/iter; left time: 193.8110s
Epoch: 42 cost time: 3.8921635150909424
Epoch: 42, Steps: 265 | Train Loss: 0.4166455 Vali Loss: 0.2069988 Test Loss: 0.2848434
Validation loss decreased (0.207011 --> 0.206999).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.4149565
	speed: 0.0693s/iter; left time: 1058.0433s
	iters: 200, epoch: 43 | loss: 0.4237339
	speed: 0.0134s/iter; left time: 203.4007s
Epoch: 43 cost time: 4.21876335144043
Epoch: 43, Steps: 265 | Train Loss: 0.4162744 Vali Loss: 0.2070785 Test Loss: 0.2848332
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.3913113
	speed: 0.0711s/iter; left time: 1066.6018s
	iters: 200, epoch: 44 | loss: 0.3300782
	speed: 0.0132s/iter; left time: 196.7619s
Epoch: 44 cost time: 4.066158056259155
Epoch: 44, Steps: 265 | Train Loss: 0.4165793 Vali Loss: 0.2070617 Test Loss: 0.2848333
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.4039028
	speed: 0.0696s/iter; left time: 1025.7526s
	iters: 200, epoch: 45 | loss: 0.6752359
	speed: 0.0138s/iter; left time: 202.0692s
Epoch: 45 cost time: 4.129189968109131
Epoch: 45, Steps: 265 | Train Loss: 0.4167764 Vali Loss: 0.2071294 Test Loss: 0.2848225
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.3042098
	speed: 0.0670s/iter; left time: 970.1649s
	iters: 200, epoch: 46 | loss: 0.2620167
	speed: 0.0127s/iter; left time: 182.6825s
Epoch: 46 cost time: 3.8336527347564697
Epoch: 46, Steps: 265 | Train Loss: 0.4163804 Vali Loss: 0.2072126 Test Loss: 0.2848100
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.4729701
	speed: 0.0642s/iter; left time: 912.5657s
	iters: 200, epoch: 47 | loss: 0.5013830
	speed: 0.0129s/iter; left time: 182.5956s
Epoch: 47 cost time: 3.93620228767395
Epoch: 47, Steps: 265 | Train Loss: 0.4158411 Vali Loss: 0.2072103 Test Loss: 0.2848155
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.3714754
	speed: 0.0659s/iter; left time: 918.3519s
	iters: 200, epoch: 48 | loss: 0.5314475
	speed: 0.0134s/iter; left time: 186.0473s
Epoch: 48 cost time: 3.9406960010528564
Epoch: 48, Steps: 265 | Train Loss: 0.4160026 Vali Loss: 0.2073588 Test Loss: 0.2848076
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.3281282
	speed: 0.0687s/iter; left time: 939.5280s
	iters: 200, epoch: 49 | loss: 0.4237401
	speed: 0.0130s/iter; left time: 176.0297s
Epoch: 49 cost time: 4.081460475921631
Epoch: 49, Steps: 265 | Train Loss: 0.4166030 Vali Loss: 0.2072856 Test Loss: 0.2848114
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.5384220
	speed: 0.0674s/iter; left time: 904.0260s
	iters: 200, epoch: 50 | loss: 0.6225470
	speed: 0.0131s/iter; left time: 174.7962s
Epoch: 50 cost time: 4.008517742156982
Epoch: 50, Steps: 265 | Train Loss: 0.4159840 Vali Loss: 0.2073577 Test Loss: 0.2848026
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.4017798
	speed: 0.0680s/iter; left time: 894.4402s
	iters: 200, epoch: 51 | loss: 0.2980651
	speed: 0.0142s/iter; left time: 185.9397s
Epoch: 51 cost time: 4.248490810394287
Epoch: 51, Steps: 265 | Train Loss: 0.4166845 Vali Loss: 0.2071659 Test Loss: 0.2848020
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.4580627
	speed: 0.0705s/iter; left time: 908.5825s
	iters: 200, epoch: 52 | loss: 0.5011302
	speed: 0.0149s/iter; left time: 190.7427s
Epoch: 52 cost time: 4.446284294128418
Epoch: 52, Steps: 265 | Train Loss: 0.4164910 Vali Loss: 0.2071944 Test Loss: 0.2847948
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.6137437
	speed: 0.0697s/iter; left time: 879.5712s
	iters: 200, epoch: 53 | loss: 0.4777727
	speed: 0.0196s/iter; left time: 244.8272s
Epoch: 53 cost time: 4.73659610748291
Epoch: 53, Steps: 265 | Train Loss: 0.4165260 Vali Loss: 0.2070279 Test Loss: 0.2847922
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.3258593
	speed: 0.0680s/iter; left time: 839.7514s
	iters: 200, epoch: 54 | loss: 0.3139999
	speed: 0.0132s/iter; left time: 162.2816s
Epoch: 54 cost time: 3.963148832321167
Epoch: 54, Steps: 265 | Train Loss: 0.4161609 Vali Loss: 0.2072639 Test Loss: 0.2847867
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.3996649
	speed: 0.0671s/iter; left time: 810.9953s
	iters: 200, epoch: 55 | loss: 0.3668772
	speed: 0.0136s/iter; left time: 162.5331s
Epoch: 55 cost time: 4.035680770874023
Epoch: 55, Steps: 265 | Train Loss: 0.4164662 Vali Loss: 0.2072533 Test Loss: 0.2847874
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.4281408
	speed: 0.0681s/iter; left time: 805.6653s
	iters: 200, epoch: 56 | loss: 0.4192698
	speed: 0.0131s/iter; left time: 153.6110s
Epoch: 56 cost time: 3.9719295501708984
Epoch: 56, Steps: 265 | Train Loss: 0.4167551 Vali Loss: 0.2071864 Test Loss: 0.2847859
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.4470093
	speed: 0.0675s/iter; left time: 779.9032s
	iters: 200, epoch: 57 | loss: 0.2797022
	speed: 0.0132s/iter; left time: 150.7843s
Epoch: 57 cost time: 4.086665630340576
Epoch: 57, Steps: 265 | Train Loss: 0.4164900 Vali Loss: 0.2073675 Test Loss: 0.2847814
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2364256
	speed: 0.0677s/iter; left time: 765.0622s
	iters: 200, epoch: 58 | loss: 0.3780033
	speed: 0.0137s/iter; left time: 153.8169s
Epoch: 58 cost time: 4.235682249069214
Epoch: 58, Steps: 265 | Train Loss: 0.4165623 Vali Loss: 0.2071705 Test Loss: 0.2847751
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2987751
	speed: 0.0748s/iter; left time: 825.4583s
	iters: 200, epoch: 59 | loss: 0.5226216
	speed: 0.0153s/iter; left time: 167.7091s
Epoch: 59 cost time: 4.539289712905884
Epoch: 59, Steps: 265 | Train Loss: 0.4164617 Vali Loss: 0.2073310 Test Loss: 0.2847786
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.3862804
	speed: 0.0755s/iter; left time: 812.5199s
	iters: 200, epoch: 60 | loss: 0.4299588
	speed: 0.0147s/iter; left time: 156.4765s
Epoch: 60 cost time: 4.656331539154053
Epoch: 60, Steps: 265 | Train Loss: 0.4154840 Vali Loss: 0.2072940 Test Loss: 0.2847729
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.5208414
	speed: 0.0735s/iter; left time: 771.8794s
	iters: 200, epoch: 61 | loss: 0.4180943
	speed: 0.0132s/iter; left time: 137.7103s
Epoch: 61 cost time: 4.2402403354644775
Epoch: 61, Steps: 265 | Train Loss: 0.4154821 Vali Loss: 0.2070622 Test Loss: 0.2847688
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.4153283
	speed: 0.0686s/iter; left time: 702.1378s
	iters: 200, epoch: 62 | loss: 0.2689727
	speed: 0.0127s/iter; left time: 128.4578s
Epoch: 62 cost time: 3.9196512699127197
Epoch: 62, Steps: 265 | Train Loss: 0.4164405 Vali Loss: 0.2072033 Test Loss: 0.2847702
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_180_336_FITS_ETTm2_ftM_sl180_ll48_pl336_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.286101758480072, mae:0.331600546836853, rse:0.43203699588775635, corr:[0.56042576 0.56158715 0.55671984 0.553873   0.55388874 0.55420524
 0.5532104  0.55130696 0.5499491  0.5496461  0.549765   0.5495457
 0.548774   0.5479025  0.5474688  0.54731953 0.54694617 0.54608023
 0.5449604  0.5440888  0.54369205 0.54350644 0.54314625 0.5425321
 0.54186994 0.5414273  0.5412792  0.54111195 0.5405927  0.53970104
 0.5387836  0.53818226 0.5378722  0.537626   0.53717965 0.5365201
 0.5357432  0.53508013 0.5345166  0.53394794 0.53333664 0.5327494
 0.53231806 0.5320594  0.5318186  0.53143656 0.5307663  0.5298353
 0.5288434  0.5280172  0.5274064  0.52695227 0.52642876 0.5257153
 0.5249723  0.52443475 0.5240575  0.52379173 0.5234873  0.52311796
 0.5227028  0.52243763 0.5223639  0.5222966  0.5221436  0.5219049
 0.52161163 0.5213833  0.52127236 0.5212627  0.52120507 0.5210538
 0.520851   0.5206153  0.52043664 0.5202429  0.51999074 0.51961446
 0.5191813  0.5187463  0.5183141  0.5178756  0.51744974 0.5170288
 0.51662683 0.5162355  0.51582867 0.51544374 0.51506835 0.51469743
 0.51435673 0.5139942  0.5134939  0.5127297  0.511622   0.5101421
 0.5083701  0.5065817  0.504866   0.5032633  0.50180244 0.5005049
 0.49931535 0.49813068 0.4968503  0.49550262 0.49421862 0.49311197
 0.49215022 0.49112096 0.4901131  0.4891008  0.48810974 0.4871027
 0.4860219  0.48495525 0.483934   0.4829185  0.48190865 0.48087272
 0.4798978  0.47903022 0.47824392 0.47742954 0.47653314 0.47557247
 0.4746064  0.4736872  0.4728147  0.47193614 0.4710329  0.4701025
 0.46923396 0.4684382  0.4678192  0.46732548 0.46679893 0.4662543
 0.46570164 0.46518558 0.4646893  0.4641421  0.46347687 0.46262133
 0.46164557 0.4606789  0.45981434 0.45912325 0.4585608  0.45794368
 0.4573098  0.45685026 0.45648465 0.45613578 0.45571253 0.45516458
 0.4545652  0.45406005 0.4536565  0.45336947 0.4531309  0.45284218
 0.4525654  0.4522878  0.45222697 0.45233127 0.45244205 0.45247597
 0.4524042  0.45235437 0.45240837 0.45257068 0.4527729  0.452797
 0.45265755 0.45241058 0.45221987 0.45213813 0.45211947 0.4520794
 0.45186615 0.45147452 0.45109224 0.4508203  0.450714   0.45062435
 0.45043918 0.4501101  0.44959387 0.4488662  0.4478748  0.44658816
 0.44507727 0.4435429  0.44204196 0.44065523 0.43949115 0.43844208
 0.4373519  0.43615758 0.4349094  0.43383944 0.43299913 0.43240288
 0.43184942 0.43118286 0.43037742 0.42957553 0.42890155 0.4283444
 0.42780402 0.42719546 0.4264959  0.4257504  0.42502588 0.42429537
 0.42357722 0.42275566 0.4219417  0.4210719  0.42007598 0.41906106
 0.41808218 0.41728005 0.41674662 0.41620138 0.4155451  0.41472012
 0.4137257  0.41273034 0.4118503  0.4111982  0.4106743  0.41025206
 0.4098186  0.4094357  0.4092058  0.40896732 0.40871143 0.4083141
 0.40776175 0.40710777 0.40649962 0.4061289  0.40594053 0.40581948
 0.40577623 0.40582684 0.40601352 0.4062382  0.4064664  0.4066241
 0.40665752 0.40677956 0.40699542 0.40719074 0.40724826 0.40719578
 0.40709677 0.4070165  0.40703174 0.4071921  0.4073443  0.4073101
 0.4071349  0.40699017 0.40703708 0.40721548 0.40740955 0.40747008
 0.4072533  0.4069456  0.40666896 0.4065911  0.40664208 0.4067075
 0.40668055 0.40654504 0.40643468 0.40639004 0.4062966  0.40626365
 0.40628842 0.40629148 0.40623584 0.40603435 0.4055292  0.4045747
 0.4032307  0.40198833 0.4009298  0.40015423 0.3995366  0.39896083
 0.39844412 0.3978487  0.39719185 0.39651188 0.39600158 0.39559725
 0.3951998  0.39460033 0.39392355 0.39318293 0.39236724 0.39158234
 0.39097202 0.3904648  0.3898275  0.38892707 0.38784152 0.38684848
 0.38607547 0.38560364 0.38508025 0.3842861  0.38309756 0.38183954
 0.38084015 0.38019034 0.3795357  0.37852505 0.37724483 0.3761378
 0.37557617 0.37530062 0.37469062 0.3734315  0.37205327 0.37158477
 0.3723836  0.3730649  0.37236232 0.37085685 0.37165686 0.3772635 ]
