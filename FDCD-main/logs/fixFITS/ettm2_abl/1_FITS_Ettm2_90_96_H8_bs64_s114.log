Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=18, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_90_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_90_96_FITS_ETTm2_ftM_sl90_ll48_pl96_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34375
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=18, out_features=37, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  596736.0
params:  703.0
Trainable parameters:  703
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3282056
	speed: 0.0182s/iter; left time: 484.9507s
	iters: 200, epoch: 1 | loss: 0.3610453
	speed: 0.0118s/iter; left time: 313.7131s
Epoch: 1 cost time: 3.9551594257354736
Epoch: 1, Steps: 268 | Train Loss: 0.3128118 Vali Loss: 0.1493714 Test Loss: 0.2119560
Validation loss decreased (inf --> 0.149371).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2237490
	speed: 0.0648s/iter; left time: 1713.0717s
	iters: 200, epoch: 2 | loss: 0.2754721
	speed: 0.0134s/iter; left time: 352.3524s
Epoch: 2 cost time: 3.7823703289031982
Epoch: 2, Steps: 268 | Train Loss: 0.2642889 Vali Loss: 0.1369844 Test Loss: 0.1959555
Validation loss decreased (0.149371 --> 0.136984).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1926782
	speed: 0.0728s/iter; left time: 1905.9839s
	iters: 200, epoch: 3 | loss: 0.2166173
	speed: 0.0143s/iter; left time: 372.5860s
Epoch: 3 cost time: 4.181757688522339
Epoch: 3, Steps: 268 | Train Loss: 0.2532676 Vali Loss: 0.1328202 Test Loss: 0.1902761
Validation loss decreased (0.136984 --> 0.132820).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1970717
	speed: 0.0602s/iter; left time: 1559.8025s
	iters: 200, epoch: 4 | loss: 0.2279642
	speed: 0.0112s/iter; left time: 288.9435s
Epoch: 4 cost time: 3.510000228881836
Epoch: 4, Steps: 268 | Train Loss: 0.2487408 Vali Loss: 0.1310119 Test Loss: 0.1876764
Validation loss decreased (0.132820 --> 0.131012).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3273776
	speed: 0.0581s/iter; left time: 1489.8426s
	iters: 200, epoch: 5 | loss: 0.1941670
	speed: 0.0112s/iter; left time: 286.4191s
Epoch: 5 cost time: 3.336301565170288
Epoch: 5, Steps: 268 | Train Loss: 0.2456270 Vali Loss: 0.1301876 Test Loss: 0.1863205
Validation loss decreased (0.131012 --> 0.130188).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2755413
	speed: 0.0674s/iter; left time: 1709.0503s
	iters: 200, epoch: 6 | loss: 0.2152615
	speed: 0.0103s/iter; left time: 259.2020s
Epoch: 6 cost time: 4.203048229217529
Epoch: 6, Steps: 268 | Train Loss: 0.2447745 Vali Loss: 0.1298547 Test Loss: 0.1856472
Validation loss decreased (0.130188 --> 0.129855).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3280549
	speed: 0.0625s/iter; left time: 1569.3590s
	iters: 200, epoch: 7 | loss: 0.3052292
	speed: 0.0167s/iter; left time: 418.2559s
Epoch: 7 cost time: 4.183151483535767
Epoch: 7, Steps: 268 | Train Loss: 0.2437352 Vali Loss: 0.1299128 Test Loss: 0.1853661
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1854819
	speed: 0.0624s/iter; left time: 1550.2131s
	iters: 200, epoch: 8 | loss: 0.1562361
	speed: 0.0111s/iter; left time: 275.1878s
Epoch: 8 cost time: 3.625049591064453
Epoch: 8, Steps: 268 | Train Loss: 0.2429946 Vali Loss: 0.1297518 Test Loss: 0.1849849
Validation loss decreased (0.129855 --> 0.129752).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1925747
	speed: 0.0575s/iter; left time: 1412.6718s
	iters: 200, epoch: 9 | loss: 0.2328233
	speed: 0.0101s/iter; left time: 246.3647s
Epoch: 9 cost time: 3.287649154663086
Epoch: 9, Steps: 268 | Train Loss: 0.2426314 Vali Loss: 0.1298658 Test Loss: 0.1850029
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2692657
	speed: 0.0690s/iter; left time: 1676.2503s
	iters: 200, epoch: 10 | loss: 0.2486447
	speed: 0.0191s/iter; left time: 461.6468s
Epoch: 10 cost time: 4.730107069015503
Epoch: 10, Steps: 268 | Train Loss: 0.2424616 Vali Loss: 0.1299150 Test Loss: 0.1849227
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2018751
	speed: 0.0661s/iter; left time: 1586.5874s
	iters: 200, epoch: 11 | loss: 0.1782345
	speed: 0.0149s/iter; left time: 355.3519s
Epoch: 11 cost time: 3.8546059131622314
Epoch: 11, Steps: 268 | Train Loss: 0.2421594 Vali Loss: 0.1296635 Test Loss: 0.1847510
Validation loss decreased (0.129752 --> 0.129663).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2207775
	speed: 0.0631s/iter; left time: 1498.8003s
	iters: 200, epoch: 12 | loss: 0.1455768
	speed: 0.0143s/iter; left time: 338.2705s
Epoch: 12 cost time: 4.1957972049713135
Epoch: 12, Steps: 268 | Train Loss: 0.2416504 Vali Loss: 0.1300936 Test Loss: 0.1849237
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2368799
	speed: 0.0715s/iter; left time: 1678.7555s
	iters: 200, epoch: 13 | loss: 0.2300895
	speed: 0.0106s/iter; left time: 246.7207s
Epoch: 13 cost time: 3.7926809787750244
Epoch: 13, Steps: 268 | Train Loss: 0.2415346 Vali Loss: 0.1301005 Test Loss: 0.1848393
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2512068
	speed: 0.0674s/iter; left time: 1564.3266s
	iters: 200, epoch: 14 | loss: 0.1817414
	speed: 0.0136s/iter; left time: 314.7148s
Epoch: 14 cost time: 3.6800849437713623
Epoch: 14, Steps: 268 | Train Loss: 0.2417626 Vali Loss: 0.1301045 Test Loss: 0.1847897
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1740322
	speed: 0.0600s/iter; left time: 1377.6155s
	iters: 200, epoch: 15 | loss: 0.2196553
	speed: 0.0105s/iter; left time: 239.1543s
Epoch: 15 cost time: 3.4489545822143555
Epoch: 15, Steps: 268 | Train Loss: 0.2413751 Vali Loss: 0.1300781 Test Loss: 0.1847912
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2706486
	speed: 0.0596s/iter; left time: 1351.7084s
	iters: 200, epoch: 16 | loss: 0.2560437
	speed: 0.0106s/iter; left time: 238.4590s
Epoch: 16 cost time: 3.5092601776123047
Epoch: 16, Steps: 268 | Train Loss: 0.2414568 Vali Loss: 0.1300305 Test Loss: 0.1848031
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3300237
	speed: 0.0616s/iter; left time: 1379.7067s
	iters: 200, epoch: 17 | loss: 0.2771827
	speed: 0.0106s/iter; left time: 235.5811s
Epoch: 17 cost time: 3.4672436714172363
Epoch: 17, Steps: 268 | Train Loss: 0.2411896 Vali Loss: 0.1300911 Test Loss: 0.1847806
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4549116
	speed: 0.0580s/iter; left time: 1285.4761s
	iters: 200, epoch: 18 | loss: 0.2067855
	speed: 0.0117s/iter; left time: 257.2124s
Epoch: 18 cost time: 3.4674346446990967
Epoch: 18, Steps: 268 | Train Loss: 0.2407787 Vali Loss: 0.1301862 Test Loss: 0.1847895
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1908499
	speed: 0.0627s/iter; left time: 1371.9040s
	iters: 200, epoch: 19 | loss: 0.3281454
	speed: 0.0113s/iter; left time: 246.5547s
Epoch: 19 cost time: 3.9043538570404053
Epoch: 19, Steps: 268 | Train Loss: 0.2410626 Vali Loss: 0.1301378 Test Loss: 0.1847594
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1806888
	speed: 0.0645s/iter; left time: 1393.1806s
	iters: 200, epoch: 20 | loss: 0.1718915
	speed: 0.0117s/iter; left time: 250.8266s
Epoch: 20 cost time: 3.6054880619049072
Epoch: 20, Steps: 268 | Train Loss: 0.2407411 Vali Loss: 0.1302389 Test Loss: 0.1847543
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1895660
	speed: 0.0847s/iter; left time: 1807.4934s
	iters: 200, epoch: 21 | loss: 0.2201245
	speed: 0.0111s/iter; left time: 236.2463s
Epoch: 21 cost time: 3.6061527729034424
Epoch: 21, Steps: 268 | Train Loss: 0.2409133 Vali Loss: 0.1301680 Test Loss: 0.1847175
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1629210
	speed: 0.0655s/iter; left time: 1379.7474s
	iters: 200, epoch: 22 | loss: 0.2304347
	speed: 0.0143s/iter; left time: 299.3790s
Epoch: 22 cost time: 4.168613433837891
Epoch: 22, Steps: 268 | Train Loss: 0.2411043 Vali Loss: 0.1300794 Test Loss: 0.1846567
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1976050
	speed: 0.0631s/iter; left time: 1312.3817s
	iters: 200, epoch: 23 | loss: 0.3165589
	speed: 0.0106s/iter; left time: 218.8134s
Epoch: 23 cost time: 3.4204792976379395
Epoch: 23, Steps: 268 | Train Loss: 0.2405635 Vali Loss: 0.1300649 Test Loss: 0.1847034
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3643827
	speed: 0.0612s/iter; left time: 1257.7764s
	iters: 200, epoch: 24 | loss: 0.3291777
	speed: 0.0119s/iter; left time: 243.1789s
Epoch: 24 cost time: 3.724468231201172
Epoch: 24, Steps: 268 | Train Loss: 0.2406725 Vali Loss: 0.1301609 Test Loss: 0.1847272
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1467093
	speed: 0.0719s/iter; left time: 1458.3286s
	iters: 200, epoch: 25 | loss: 0.2981754
	speed: 0.0112s/iter; left time: 224.9585s
Epoch: 25 cost time: 4.507380485534668
Epoch: 25, Steps: 268 | Train Loss: 0.2409260 Vali Loss: 0.1301565 Test Loss: 0.1847095
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2313427
	speed: 0.0632s/iter; left time: 1263.7034s
	iters: 200, epoch: 26 | loss: 0.2090304
	speed: 0.0108s/iter; left time: 215.7951s
Epoch: 26 cost time: 3.6294822692871094
Epoch: 26, Steps: 268 | Train Loss: 0.2410054 Vali Loss: 0.1301304 Test Loss: 0.1846466
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1845400
	speed: 0.0602s/iter; left time: 1188.8650s
	iters: 200, epoch: 27 | loss: 0.2430879
	speed: 0.0105s/iter; left time: 206.5193s
Epoch: 27 cost time: 3.49587082862854
Epoch: 27, Steps: 268 | Train Loss: 0.2408556 Vali Loss: 0.1301791 Test Loss: 0.1846886
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2795431
	speed: 0.0657s/iter; left time: 1278.1539s
	iters: 200, epoch: 28 | loss: 0.2076682
	speed: 0.0112s/iter; left time: 217.0964s
Epoch: 28 cost time: 3.5747029781341553
Epoch: 28, Steps: 268 | Train Loss: 0.2410028 Vali Loss: 0.1302625 Test Loss: 0.1847076
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1995064
	speed: 0.0614s/iter; left time: 1179.3499s
	iters: 200, epoch: 29 | loss: 0.3081865
	speed: 0.0102s/iter; left time: 195.7343s
Epoch: 29 cost time: 3.5572047233581543
Epoch: 29, Steps: 268 | Train Loss: 0.2409171 Vali Loss: 0.1302170 Test Loss: 0.1846648
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2527219
	speed: 0.0617s/iter; left time: 1168.6108s
	iters: 200, epoch: 30 | loss: 0.1973211
	speed: 0.0108s/iter; left time: 203.6833s
Epoch: 30 cost time: 3.5866763591766357
Epoch: 30, Steps: 268 | Train Loss: 0.2408826 Vali Loss: 0.1302379 Test Loss: 0.1846960
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2824378
	speed: 0.0621s/iter; left time: 1159.3595s
	iters: 200, epoch: 31 | loss: 0.2963171
	speed: 0.0123s/iter; left time: 228.1712s
Epoch: 31 cost time: 3.71281099319458
Epoch: 31, Steps: 268 | Train Loss: 0.2409494 Vali Loss: 0.1302290 Test Loss: 0.1847066
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_90_96_FITS_ETTm2_ftM_sl90_ll48_pl96_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.18560074269771576, mae:0.2691428065299988, rse:0.3492898941040039, corr:[0.5702228  0.5731211  0.5655344  0.56137246 0.5623236  0.5626898
 0.5602978  0.55764407 0.5572097  0.557892   0.5575101  0.55585164
 0.55448616 0.5544827  0.5547031  0.553775   0.5519284  0.55053496
 0.5502406  0.5499979  0.54885525 0.547172   0.5461629  0.54624885
 0.5464031  0.5457175  0.5444693  0.5436317  0.54355896 0.54353714
 0.54282457 0.54162854 0.54072046 0.5405559  0.5405683  0.5401285
 0.53907895 0.53802913 0.5374459  0.5370681  0.5364963  0.5357569
 0.53524727 0.5352298  0.5353121  0.53493905 0.53405917 0.53299266
 0.5322214  0.53169847 0.5310778  0.53023636 0.52936286 0.52869236
 0.52831167 0.5278881  0.5271026  0.5262831  0.5258086  0.5257952
 0.5258198  0.5254895  0.52504426 0.5249538  0.5251711  0.52537656
 0.5252448  0.52479297 0.5245053  0.52460897 0.5249794  0.5252585
 0.5252343  0.52514035 0.52512455 0.52523553 0.52530175 0.5251188
 0.5248247  0.52472264 0.5248442  0.5248599  0.52465725 0.5243188
 0.524138   0.52416277 0.5240802  0.52379227 0.52334696 0.5231461
 0.52327424 0.5234607  0.523144   0.52268434 0.5225637  0.5212212 ]
