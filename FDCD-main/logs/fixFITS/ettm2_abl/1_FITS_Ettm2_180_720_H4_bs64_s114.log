Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=18, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_180_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_180_720_FITS_ETTm2_ftM_sl180_ll48_pl720_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33661
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=18, out_features=90, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1451520.0
params:  1710.0
Trainable parameters:  1710
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5549621
	speed: 0.0850s/iter; left time: 2217.5347s
	iters: 200, epoch: 1 | loss: 0.6268737
	speed: 0.0711s/iter; left time: 1848.7815s
Epoch: 1 cost time: 20.35231876373291
Epoch: 1, Steps: 262 | Train Loss: 0.6982968 Vali Loss: 0.3134299 Test Loss: 0.4354420
Validation loss decreased (inf --> 0.313430).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.7802723
	speed: 0.2574s/iter; left time: 6649.9512s
	iters: 200, epoch: 2 | loss: 0.7053515
	speed: 0.0715s/iter; left time: 1839.9612s
Epoch: 2 cost time: 18.53537082672119
Epoch: 2, Steps: 262 | Train Loss: 0.5902875 Vali Loss: 0.2897090 Test Loss: 0.4039634
Validation loss decreased (0.313430 --> 0.289709).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4766074
	speed: 0.2719s/iter; left time: 6953.3269s
	iters: 200, epoch: 3 | loss: 0.5407329
	speed: 0.0738s/iter; left time: 1881.4159s
Epoch: 3 cost time: 20.882015705108643
Epoch: 3, Steps: 262 | Train Loss: 0.5720360 Vali Loss: 0.2838226 Test Loss: 0.3963147
Validation loss decreased (0.289709 --> 0.283823).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.5846666
	speed: 0.3063s/iter; left time: 7753.6348s
	iters: 200, epoch: 4 | loss: 0.4686513
	speed: 0.0651s/iter; left time: 1640.5856s
Epoch: 4 cost time: 18.47165846824646
Epoch: 4, Steps: 262 | Train Loss: 0.5660899 Vali Loss: 0.2812884 Test Loss: 0.3933243
Validation loss decreased (0.283823 --> 0.281288).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.6579444
	speed: 0.3193s/iter; left time: 7998.5311s
	iters: 200, epoch: 5 | loss: 0.5036881
	speed: 0.0683s/iter; left time: 1704.5944s
Epoch: 5 cost time: 19.69747519493103
Epoch: 5, Steps: 262 | Train Loss: 0.5626629 Vali Loss: 0.2800163 Test Loss: 0.3917053
Validation loss decreased (0.281288 --> 0.280016).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4500344
	speed: 0.3354s/iter; left time: 8316.1175s
	iters: 200, epoch: 6 | loss: 0.5727540
	speed: 0.0659s/iter; left time: 1627.6257s
Epoch: 6 cost time: 19.465811729431152
Epoch: 6, Steps: 262 | Train Loss: 0.5619207 Vali Loss: 0.2793902 Test Loss: 0.3906803
Validation loss decreased (0.280016 --> 0.279390).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.5449740
	speed: 0.3223s/iter; left time: 7905.9622s
	iters: 200, epoch: 7 | loss: 0.5180580
	speed: 0.0713s/iter; left time: 1741.2115s
Epoch: 7 cost time: 19.978080987930298
Epoch: 7, Steps: 262 | Train Loss: 0.5610181 Vali Loss: 0.2788060 Test Loss: 0.3900596
Validation loss decreased (0.279390 --> 0.278806).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.6837772
	speed: 0.3316s/iter; left time: 8046.0657s
	iters: 200, epoch: 8 | loss: 0.4370601
	speed: 0.0753s/iter; left time: 1818.6478s
Epoch: 8 cost time: 19.45652461051941
Epoch: 8, Steps: 262 | Train Loss: 0.5598244 Vali Loss: 0.2786179 Test Loss: 0.3895781
Validation loss decreased (0.278806 --> 0.278618).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.5120324
	speed: 0.3141s/iter; left time: 7540.8264s
	iters: 200, epoch: 9 | loss: 0.6472352
	speed: 0.0756s/iter; left time: 1807.4045s
Epoch: 9 cost time: 19.2496235370636
Epoch: 9, Steps: 262 | Train Loss: 0.5598976 Vali Loss: 0.2787300 Test Loss: 0.3892176
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.5549175
	speed: 0.3000s/iter; left time: 7122.0988s
	iters: 200, epoch: 10 | loss: 0.5700783
	speed: 0.0749s/iter; left time: 1770.2218s
Epoch: 10 cost time: 20.27991032600403
Epoch: 10, Steps: 262 | Train Loss: 0.5581771 Vali Loss: 0.2781270 Test Loss: 0.3889644
Validation loss decreased (0.278618 --> 0.278127).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.8403654
	speed: 0.3355s/iter; left time: 7877.4459s
	iters: 200, epoch: 11 | loss: 0.6171652
	speed: 0.0748s/iter; left time: 1749.3950s
Epoch: 11 cost time: 20.21127223968506
Epoch: 11, Steps: 262 | Train Loss: 0.5590943 Vali Loss: 0.2778555 Test Loss: 0.3887246
Validation loss decreased (0.278127 --> 0.277855).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4680769
	speed: 0.3107s/iter; left time: 7214.9315s
	iters: 200, epoch: 12 | loss: 0.6483734
	speed: 0.0670s/iter; left time: 1548.3326s
Epoch: 12 cost time: 18.949077367782593
Epoch: 12, Steps: 262 | Train Loss: 0.5578948 Vali Loss: 0.2780352 Test Loss: 0.3885398
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3752595
	speed: 0.3048s/iter; left time: 6997.7907s
	iters: 200, epoch: 13 | loss: 0.5532318
	speed: 0.0607s/iter; left time: 1386.4967s
Epoch: 13 cost time: 17.050649166107178
Epoch: 13, Steps: 262 | Train Loss: 0.5568842 Vali Loss: 0.2779153 Test Loss: 0.3883449
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4951313
	speed: 0.2945s/iter; left time: 6683.0221s
	iters: 200, epoch: 14 | loss: 0.6479338
	speed: 0.0697s/iter; left time: 1574.7001s
Epoch: 14 cost time: 18.406007289886475
Epoch: 14, Steps: 262 | Train Loss: 0.5573500 Vali Loss: 0.2780881 Test Loss: 0.3882701
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4912564
	speed: 0.3164s/iter; left time: 7097.7570s
	iters: 200, epoch: 15 | loss: 0.5438184
	speed: 0.0653s/iter; left time: 1459.2236s
Epoch: 15 cost time: 18.87424349784851
Epoch: 15, Steps: 262 | Train Loss: 0.5570058 Vali Loss: 0.2781319 Test Loss: 0.3881492
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.7800626
	speed: 0.2934s/iter; left time: 6505.0546s
	iters: 200, epoch: 16 | loss: 0.6631081
	speed: 0.0653s/iter; left time: 1441.4252s
Epoch: 16 cost time: 17.704896450042725
Epoch: 16, Steps: 262 | Train Loss: 0.5571337 Vali Loss: 0.2779180 Test Loss: 0.3880396
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.5388230
	speed: 0.2560s/iter; left time: 5607.9248s
	iters: 200, epoch: 17 | loss: 0.4010401
	speed: 0.0681s/iter; left time: 1484.4607s
Epoch: 17 cost time: 16.70886254310608
Epoch: 17, Steps: 262 | Train Loss: 0.5572305 Vali Loss: 0.2777029 Test Loss: 0.3879555
Validation loss decreased (0.277855 --> 0.277703).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.8313270
	speed: 0.2457s/iter; left time: 5318.8821s
	iters: 200, epoch: 18 | loss: 0.6264552
	speed: 0.0708s/iter; left time: 1524.5337s
Epoch: 18 cost time: 19.173773765563965
Epoch: 18, Steps: 262 | Train Loss: 0.5566336 Vali Loss: 0.2776646 Test Loss: 0.3879155
Validation loss decreased (0.277703 --> 0.277665).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.5484854
	speed: 0.2934s/iter; left time: 6275.1179s
	iters: 200, epoch: 19 | loss: 0.5575162
	speed: 0.0744s/iter; left time: 1583.2646s
Epoch: 19 cost time: 19.06938672065735
Epoch: 19, Steps: 262 | Train Loss: 0.5571167 Vali Loss: 0.2779284 Test Loss: 0.3878749
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.5550453
	speed: 0.2896s/iter; left time: 6117.7717s
	iters: 200, epoch: 20 | loss: 0.4118019
	speed: 0.0814s/iter; left time: 1711.5400s
Epoch: 20 cost time: 19.3979651927948
Epoch: 20, Steps: 262 | Train Loss: 0.5564377 Vali Loss: 0.2774119 Test Loss: 0.3877781
Validation loss decreased (0.277665 --> 0.277412).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4824563
	speed: 0.2603s/iter; left time: 5430.8061s
	iters: 200, epoch: 21 | loss: 0.5559071
	speed: 0.0783s/iter; left time: 1626.2615s
Epoch: 21 cost time: 19.057594537734985
Epoch: 21, Steps: 262 | Train Loss: 0.5565238 Vali Loss: 0.2775504 Test Loss: 0.3877557
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.6910546
	speed: 0.2437s/iter; left time: 5018.9921s
	iters: 200, epoch: 22 | loss: 0.6620731
	speed: 0.0579s/iter; left time: 1187.8802s
Epoch: 22 cost time: 14.933901309967041
Epoch: 22, Steps: 262 | Train Loss: 0.5566962 Vali Loss: 0.2774137 Test Loss: 0.3877204
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.5669234
	speed: 0.1982s/iter; left time: 4030.6830s
	iters: 200, epoch: 23 | loss: 0.6364037
	speed: 0.0376s/iter; left time: 761.5615s
Epoch: 23 cost time: 11.256797075271606
Epoch: 23, Steps: 262 | Train Loss: 0.5557937 Vali Loss: 0.2775953 Test Loss: 0.3876929
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.5280774
	speed: 0.1997s/iter; left time: 4008.3287s
	iters: 200, epoch: 24 | loss: 0.5946731
	speed: 0.0520s/iter; left time: 1038.6843s
Epoch: 24 cost time: 12.426945209503174
Epoch: 24, Steps: 262 | Train Loss: 0.5566677 Vali Loss: 0.2774484 Test Loss: 0.3876338
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.6558845
	speed: 0.1522s/iter; left time: 3016.0593s
	iters: 200, epoch: 25 | loss: 0.5991096
	speed: 0.0338s/iter; left time: 665.7396s
Epoch: 25 cost time: 9.301359176635742
Epoch: 25, Steps: 262 | Train Loss: 0.5571196 Vali Loss: 0.2774903 Test Loss: 0.3876095
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.7335706
	speed: 0.1366s/iter; left time: 2669.8592s
	iters: 200, epoch: 26 | loss: 0.4271547
	speed: 0.0351s/iter; left time: 682.2605s
Epoch: 26 cost time: 8.991332769393921
Epoch: 26, Steps: 262 | Train Loss: 0.5562653 Vali Loss: 0.2777108 Test Loss: 0.3875994
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3975614
	speed: 0.1726s/iter; left time: 3329.4473s
	iters: 200, epoch: 27 | loss: 0.5972114
	speed: 0.0305s/iter; left time: 585.5912s
Epoch: 27 cost time: 10.384616374969482
Epoch: 27, Steps: 262 | Train Loss: 0.5563029 Vali Loss: 0.2773998 Test Loss: 0.3875585
Validation loss decreased (0.277412 --> 0.277400).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.5280582
	speed: 0.1245s/iter; left time: 2369.0683s
	iters: 200, epoch: 28 | loss: 0.4883294
	speed: 0.0354s/iter; left time: 670.4460s
Epoch: 28 cost time: 10.806123495101929
Epoch: 28, Steps: 262 | Train Loss: 0.5560897 Vali Loss: 0.2773886 Test Loss: 0.3875138
Validation loss decreased (0.277400 --> 0.277389).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4094499
	speed: 0.1320s/iter; left time: 2477.1936s
	iters: 200, epoch: 29 | loss: 0.6512197
	speed: 0.0280s/iter; left time: 522.0932s
Epoch: 29 cost time: 8.188110589981079
Epoch: 29, Steps: 262 | Train Loss: 0.5564980 Vali Loss: 0.2776883 Test Loss: 0.3875127
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4665374
	speed: 0.1180s/iter; left time: 2182.5978s
	iters: 200, epoch: 30 | loss: 0.5061544
	speed: 0.0309s/iter; left time: 567.9073s
Epoch: 30 cost time: 9.003292798995972
Epoch: 30, Steps: 262 | Train Loss: 0.5558780 Vali Loss: 0.2775684 Test Loss: 0.3874944
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.6119174
	speed: 0.1749s/iter; left time: 3190.4238s
	iters: 200, epoch: 31 | loss: 0.4626159
	speed: 0.0581s/iter; left time: 1054.2856s
Epoch: 31 cost time: 15.569187879562378
Epoch: 31, Steps: 262 | Train Loss: 0.5557338 Vali Loss: 0.2775752 Test Loss: 0.3874810
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.6679577
	speed: 0.1724s/iter; left time: 3099.8491s
	iters: 200, epoch: 32 | loss: 0.5326302
	speed: 0.0455s/iter; left time: 812.9922s
Epoch: 32 cost time: 14.035709619522095
Epoch: 32, Steps: 262 | Train Loss: 0.5560247 Vali Loss: 0.2775537 Test Loss: 0.3874733
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.5681641
	speed: 0.1356s/iter; left time: 2402.2640s
	iters: 200, epoch: 33 | loss: 0.3971922
	speed: 0.0307s/iter; left time: 541.6283s
Epoch: 33 cost time: 7.932999849319458
Epoch: 33, Steps: 262 | Train Loss: 0.5565731 Vali Loss: 0.2776173 Test Loss: 0.3874478
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.5594884
	speed: 0.1753s/iter; left time: 3059.3422s
	iters: 200, epoch: 34 | loss: 0.6104725
	speed: 0.0318s/iter; left time: 551.1055s
Epoch: 34 cost time: 10.687288284301758
Epoch: 34, Steps: 262 | Train Loss: 0.5560939 Vali Loss: 0.2776946 Test Loss: 0.3874329
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.6608866
	speed: 0.1268s/iter; left time: 2179.9544s
	iters: 200, epoch: 35 | loss: 0.5471066
	speed: 0.0247s/iter; left time: 421.5600s
Epoch: 35 cost time: 7.892257928848267
Epoch: 35, Steps: 262 | Train Loss: 0.5560352 Vali Loss: 0.2776117 Test Loss: 0.3874279
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4656099
	speed: 0.1173s/iter; left time: 1985.6382s
	iters: 200, epoch: 36 | loss: 0.4746110
	speed: 0.0277s/iter; left time: 465.4711s
Epoch: 36 cost time: 8.07486629486084
Epoch: 36, Steps: 262 | Train Loss: 0.5550417 Vali Loss: 0.2776421 Test Loss: 0.3874200
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.5572289
	speed: 0.1423s/iter; left time: 2372.3646s
	iters: 200, epoch: 37 | loss: 0.4989921
	speed: 0.0633s/iter; left time: 1048.8829s
Epoch: 37 cost time: 14.189757347106934
Epoch: 37, Steps: 262 | Train Loss: 0.5559101 Vali Loss: 0.2774972 Test Loss: 0.3874069
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.5420878
	speed: 0.1968s/iter; left time: 3228.6034s
	iters: 200, epoch: 38 | loss: 0.4703586
	speed: 0.0694s/iter; left time: 1131.5467s
Epoch: 38 cost time: 18.253692626953125
Epoch: 38, Steps: 262 | Train Loss: 0.5560694 Vali Loss: 0.2773736 Test Loss: 0.3873942
Validation loss decreased (0.277389 --> 0.277374).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.6470168
	speed: 0.2613s/iter; left time: 4219.3415s
	iters: 200, epoch: 39 | loss: 0.7574347
	speed: 0.0496s/iter; left time: 796.1615s
Epoch: 39 cost time: 15.542840242385864
Epoch: 39, Steps: 262 | Train Loss: 0.5550564 Vali Loss: 0.2771992 Test Loss: 0.3873809
Validation loss decreased (0.277374 --> 0.277199).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.8015316
	speed: 0.1696s/iter; left time: 2693.6000s
	iters: 200, epoch: 40 | loss: 0.5682988
	speed: 0.0330s/iter; left time: 520.2881s
Epoch: 40 cost time: 9.236637592315674
Epoch: 40, Steps: 262 | Train Loss: 0.5558323 Vali Loss: 0.2773946 Test Loss: 0.3873852
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.4630843
	speed: 0.1508s/iter; left time: 2356.2063s
	iters: 200, epoch: 41 | loss: 0.4651759
	speed: 0.0401s/iter; left time: 622.6816s
Epoch: 41 cost time: 12.456846952438354
Epoch: 41, Steps: 262 | Train Loss: 0.5559006 Vali Loss: 0.2774081 Test Loss: 0.3873773
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.5654746
	speed: 0.1419s/iter; left time: 2178.6916s
	iters: 200, epoch: 42 | loss: 0.6857831
	speed: 0.0430s/iter; left time: 655.7599s
Epoch: 42 cost time: 9.766435146331787
Epoch: 42, Steps: 262 | Train Loss: 0.5557772 Vali Loss: 0.2773532 Test Loss: 0.3873724
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.5503922
	speed: 0.1481s/iter; left time: 2235.9415s
	iters: 200, epoch: 43 | loss: 0.4299622
	speed: 0.0370s/iter; left time: 554.5847s
Epoch: 43 cost time: 10.608294010162354
Epoch: 43, Steps: 262 | Train Loss: 0.5563737 Vali Loss: 0.2775059 Test Loss: 0.3873729
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.4291979
	speed: 0.1196s/iter; left time: 1774.0278s
	iters: 200, epoch: 44 | loss: 0.5839689
	speed: 0.0313s/iter; left time: 460.6420s
Epoch: 44 cost time: 8.695427894592285
Epoch: 44, Steps: 262 | Train Loss: 0.5555866 Vali Loss: 0.2776022 Test Loss: 0.3873645
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.5520777
	speed: 0.1450s/iter; left time: 2112.7884s
	iters: 200, epoch: 45 | loss: 0.6118639
	speed: 0.0616s/iter; left time: 892.1732s
Epoch: 45 cost time: 13.516787767410278
Epoch: 45, Steps: 262 | Train Loss: 0.5561193 Vali Loss: 0.2773900 Test Loss: 0.3873694
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.5019043
	speed: 0.1312s/iter; left time: 1876.9922s
	iters: 200, epoch: 46 | loss: 0.5947841
	speed: 0.0396s/iter; left time: 562.5029s
Epoch: 46 cost time: 9.479919195175171
Epoch: 46, Steps: 262 | Train Loss: 0.5554789 Vali Loss: 0.2774357 Test Loss: 0.3873558
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.4891122
	speed: 0.1428s/iter; left time: 2005.8543s
	iters: 200, epoch: 47 | loss: 0.4762510
	speed: 0.0357s/iter; left time: 498.5731s
Epoch: 47 cost time: 10.014002799987793
Epoch: 47, Steps: 262 | Train Loss: 0.5550672 Vali Loss: 0.2772657 Test Loss: 0.3873539
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.4432122
	speed: 0.1257s/iter; left time: 1733.5005s
	iters: 200, epoch: 48 | loss: 0.6313132
	speed: 0.0331s/iter; left time: 452.9110s
Epoch: 48 cost time: 8.549392938613892
Epoch: 48, Steps: 262 | Train Loss: 0.5562464 Vali Loss: 0.2776127 Test Loss: 0.3873495
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.4722239
	speed: 0.1127s/iter; left time: 1523.8292s
	iters: 200, epoch: 49 | loss: 0.5185325
	speed: 0.0370s/iter; left time: 496.9396s
Epoch: 49 cost time: 9.424529790878296
Epoch: 49, Steps: 262 | Train Loss: 0.5555220 Vali Loss: 0.2773628 Test Loss: 0.3873455
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.5578806
	speed: 0.1680s/iter; left time: 2227.5949s
	iters: 200, epoch: 50 | loss: 0.6665763
	speed: 0.0282s/iter; left time: 371.6180s
Epoch: 50 cost time: 8.440787553787231
Epoch: 50, Steps: 262 | Train Loss: 0.5551100 Vali Loss: 0.2776555 Test Loss: 0.3873432
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.4226001
	speed: 0.1516s/iter; left time: 1971.1665s
	iters: 200, epoch: 51 | loss: 0.4799826
	speed: 0.0586s/iter; left time: 756.1676s
Epoch: 51 cost time: 13.657353162765503
Epoch: 51, Steps: 262 | Train Loss: 0.5556520 Vali Loss: 0.2772413 Test Loss: 0.3873416
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.5776784
	speed: 0.1568s/iter; left time: 1997.9285s
	iters: 200, epoch: 52 | loss: 0.4578002
	speed: 0.0431s/iter; left time: 544.5583s
Epoch: 52 cost time: 11.082895994186401
Epoch: 52, Steps: 262 | Train Loss: 0.5548894 Vali Loss: 0.2774442 Test Loss: 0.3873311
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.6970065
	speed: 0.1598s/iter; left time: 1993.4249s
	iters: 200, epoch: 53 | loss: 0.6035184
	speed: 0.0380s/iter; left time: 470.5932s
Epoch: 53 cost time: 13.103484869003296
Epoch: 53, Steps: 262 | Train Loss: 0.5559288 Vali Loss: 0.2775355 Test Loss: 0.3873340
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.6380494
	speed: 0.2342s/iter; left time: 2861.3383s
	iters: 200, epoch: 54 | loss: 0.5950837
	speed: 0.0719s/iter; left time: 871.3884s
Epoch: 54 cost time: 17.133986234664917
Epoch: 54, Steps: 262 | Train Loss: 0.5559602 Vali Loss: 0.2774009 Test Loss: 0.3873331
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.7217432
	speed: 0.1876s/iter; left time: 2241.8285s
	iters: 200, epoch: 55 | loss: 0.6646805
	speed: 0.0319s/iter; left time: 378.4929s
Epoch: 55 cost time: 9.24232006072998
Epoch: 55, Steps: 262 | Train Loss: 0.5563387 Vali Loss: 0.2773577 Test Loss: 0.3873285
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.6494453
	speed: 0.1144s/iter; left time: 1337.8333s
	iters: 200, epoch: 56 | loss: 0.5989395
	speed: 0.0282s/iter; left time: 326.4728s
Epoch: 56 cost time: 8.035208463668823
Epoch: 56, Steps: 262 | Train Loss: 0.5551259 Vali Loss: 0.2776592 Test Loss: 0.3873257
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.6290921
	speed: 0.1141s/iter; left time: 1304.5142s
	iters: 200, epoch: 57 | loss: 0.6813001
	speed: 0.0265s/iter; left time: 300.0613s
Epoch: 57 cost time: 7.435060977935791
Epoch: 57, Steps: 262 | Train Loss: 0.5556696 Vali Loss: 0.2774440 Test Loss: 0.3873229
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.6413252
	speed: 0.1602s/iter; left time: 1789.4505s
	iters: 200, epoch: 58 | loss: 0.6561211
	speed: 0.0257s/iter; left time: 284.1382s
Epoch: 58 cost time: 9.592274188995361
Epoch: 58, Steps: 262 | Train Loss: 0.5562302 Vali Loss: 0.2774466 Test Loss: 0.3873235
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.6038955
	speed: 0.1155s/iter; left time: 1259.2674s
	iters: 200, epoch: 59 | loss: 0.5361642
	speed: 0.0297s/iter; left time: 320.4200s
Epoch: 59 cost time: 9.02243161201477
Epoch: 59, Steps: 262 | Train Loss: 0.5551204 Vali Loss: 0.2771335 Test Loss: 0.3873216
Validation loss decreased (0.277199 --> 0.277134).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.3740274
	speed: 0.1678s/iter; left time: 1785.4688s
	iters: 200, epoch: 60 | loss: 0.3930620
	speed: 0.0525s/iter; left time: 554.0268s
Epoch: 60 cost time: 15.863428115844727
Epoch: 60, Steps: 262 | Train Loss: 0.5556182 Vali Loss: 0.2776151 Test Loss: 0.3873197
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.5857225
	speed: 0.3414s/iter; left time: 3544.5860s
	iters: 200, epoch: 61 | loss: 0.6997605
	speed: 0.0803s/iter; left time: 825.4392s
Epoch: 61 cost time: 21.723451375961304
Epoch: 61, Steps: 262 | Train Loss: 0.5563943 Vali Loss: 0.2774560 Test Loss: 0.3873191
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.4370115
	speed: 0.3473s/iter; left time: 3514.6698s
	iters: 200, epoch: 62 | loss: 0.3775395
	speed: 0.0813s/iter; left time: 814.3147s
Epoch: 62 cost time: 21.14657735824585
Epoch: 62, Steps: 262 | Train Loss: 0.5552193 Vali Loss: 0.2774355 Test Loss: 0.3873183
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.4627758
	speed: 0.3355s/iter; left time: 3307.4143s
	iters: 200, epoch: 63 | loss: 0.5289984
	speed: 0.0731s/iter; left time: 713.0963s
Epoch: 63 cost time: 20.608131170272827
Epoch: 63, Steps: 262 | Train Loss: 0.5559919 Vali Loss: 0.2774275 Test Loss: 0.3873138
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.3816295
	speed: 0.3425s/iter; left time: 3286.7377s
	iters: 200, epoch: 64 | loss: 0.5231799
	speed: 0.0659s/iter; left time: 626.1257s
Epoch: 64 cost time: 19.712331533432007
Epoch: 64, Steps: 262 | Train Loss: 0.5552889 Vali Loss: 0.2774820 Test Loss: 0.3873153
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.7389395
	speed: 0.3324s/iter; left time: 3102.7522s
	iters: 200, epoch: 65 | loss: 0.6100689
	speed: 0.0760s/iter; left time: 701.5686s
Epoch: 65 cost time: 21.25924277305603
Epoch: 65, Steps: 262 | Train Loss: 0.5563953 Vali Loss: 0.2774868 Test Loss: 0.3873135
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.4784121
	speed: 0.2870s/iter; left time: 2603.1729s
	iters: 200, epoch: 66 | loss: 0.5625101
	speed: 0.0675s/iter; left time: 605.7705s
Epoch: 66 cost time: 17.333815813064575
Epoch: 66, Steps: 262 | Train Loss: 0.5560266 Vali Loss: 0.2775183 Test Loss: 0.3873115
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.6566575
	speed: 0.3112s/iter; left time: 2741.4363s
	iters: 200, epoch: 67 | loss: 0.4059006
	speed: 0.0677s/iter; left time: 589.5345s
Epoch: 67 cost time: 19.293695211410522
Epoch: 67, Steps: 262 | Train Loss: 0.5558583 Vali Loss: 0.2772273 Test Loss: 0.3873093
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.5694290
	speed: 0.3069s/iter; left time: 2623.2141s
	iters: 200, epoch: 68 | loss: 0.4438818
	speed: 0.0716s/iter; left time: 604.7706s
Epoch: 68 cost time: 19.20783805847168
Epoch: 68, Steps: 262 | Train Loss: 0.5553349 Vali Loss: 0.2774239 Test Loss: 0.3873097
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.5055841
	speed: 0.3127s/iter; left time: 2590.8837s
	iters: 200, epoch: 69 | loss: 0.6703560
	speed: 0.0713s/iter; left time: 583.6494s
Epoch: 69 cost time: 19.044869899749756
Epoch: 69, Steps: 262 | Train Loss: 0.5558503 Vali Loss: 0.2773750 Test Loss: 0.3873093
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.6557002
	speed: 0.2937s/iter; left time: 2355.9567s
	iters: 200, epoch: 70 | loss: 0.5021629
	speed: 0.0730s/iter; left time: 578.7586s
Epoch: 70 cost time: 19.898926973342896
Epoch: 70, Steps: 262 | Train Loss: 0.5558925 Vali Loss: 0.2775287 Test Loss: 0.3873089
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.4152219
	speed: 0.2934s/iter; left time: 2277.0750s
	iters: 200, epoch: 71 | loss: 0.5081691
	speed: 0.0608s/iter; left time: 465.5761s
Epoch: 71 cost time: 16.67770791053772
Epoch: 71, Steps: 262 | Train Loss: 0.5556993 Vali Loss: 0.2775229 Test Loss: 0.3873079
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.5122874
	speed: 0.2319s/iter; left time: 1739.1558s
	iters: 200, epoch: 72 | loss: 0.5869504
	speed: 0.0688s/iter; left time: 509.0938s
Epoch: 72 cost time: 18.292625427246094
Epoch: 72, Steps: 262 | Train Loss: 0.5554977 Vali Loss: 0.2774361 Test Loss: 0.3873060
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.6056013
	speed: 0.2548s/iter; left time: 1844.1223s
	iters: 200, epoch: 73 | loss: 0.4150956
	speed: 0.0670s/iter; left time: 477.9500s
Epoch: 73 cost time: 17.814935445785522
Epoch: 73, Steps: 262 | Train Loss: 0.5558566 Vali Loss: 0.2775671 Test Loss: 0.3873063
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.7965924
	speed: 0.3248s/iter; left time: 2265.1541s
	iters: 200, epoch: 74 | loss: 0.4732584
	speed: 0.0766s/iter; left time: 526.7224s
Epoch: 74 cost time: 20.585720777511597
Epoch: 74, Steps: 262 | Train Loss: 0.5559950 Vali Loss: 0.2774183 Test Loss: 0.3873056
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.6050678
	speed: 0.3010s/iter; left time: 2020.6001s
	iters: 200, epoch: 75 | loss: 0.4164379
	speed: 0.0572s/iter; left time: 378.0782s
Epoch: 75 cost time: 15.491838216781616
Epoch: 75, Steps: 262 | Train Loss: 0.5555953 Vali Loss: 0.2774356 Test Loss: 0.3873055
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.4425783
	speed: 0.2116s/iter; left time: 1365.0835s
	iters: 200, epoch: 76 | loss: 0.4298421
	speed: 0.0574s/iter; left time: 364.5577s
Epoch: 76 cost time: 13.754812479019165
Epoch: 76, Steps: 262 | Train Loss: 0.5557394 Vali Loss: 0.2774152 Test Loss: 0.3873042
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.5475267
	speed: 0.2604s/iter; left time: 1611.4305s
	iters: 200, epoch: 77 | loss: 0.5115486
	speed: 0.0640s/iter; left time: 389.5169s
Epoch: 77 cost time: 17.44939422607422
Epoch: 77, Steps: 262 | Train Loss: 0.5564485 Vali Loss: 0.2773458 Test Loss: 0.3873045
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.5461376
	speed: 0.2919s/iter; left time: 1730.3508s
	iters: 200, epoch: 78 | loss: 0.5905808
	speed: 0.0715s/iter; left time: 416.9168s
Epoch: 78 cost time: 20.111552953720093
Epoch: 78, Steps: 262 | Train Loss: 0.5553600 Vali Loss: 0.2772676 Test Loss: 0.3873020
EarlyStopping counter: 19 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.5742409
	speed: 0.3305s/iter; left time: 1872.3872s
	iters: 200, epoch: 79 | loss: 0.5132893
	speed: 0.0774s/iter; left time: 430.5611s
Epoch: 79 cost time: 20.98016619682312
Epoch: 79, Steps: 262 | Train Loss: 0.5557193 Vali Loss: 0.2773248 Test Loss: 0.3873015
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_180_720_FITS_ETTm2_ftM_sl180_ll48_pl720_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.3846858739852905, mae:0.3881467878818512, rse:0.4985371530056, corr:[0.54279286 0.54453343 0.5436807  0.5412653  0.5386857  0.5366871
 0.5355685  0.5350876  0.53490514 0.5347348  0.5343259  0.533654
 0.53276134 0.5317174  0.53076607 0.5299465  0.529223   0.52856755
 0.5279083  0.52721226 0.5264889  0.52576196 0.52507645 0.52450395
 0.5240325  0.5235984  0.5231687  0.5227009  0.5221749  0.52157456
 0.5209583  0.52040803 0.51992947 0.5194951  0.51904184 0.51855755
 0.5179878  0.51740783 0.5168008  0.5161974  0.51564264 0.51514155
 0.51468235 0.5142185  0.5136783  0.5130573  0.51235425 0.5115982
 0.5107909  0.5099292  0.5090307  0.50817555 0.50736994 0.50661266
 0.5059619  0.5054828  0.5051399  0.5049481  0.50482243 0.5047049
 0.50450444 0.50423455 0.50393337 0.5035711  0.5032257  0.50298214
 0.50282407 0.50277954 0.50280035 0.5028351  0.5027982  0.50265294
 0.50244296 0.5021357  0.5018118  0.5014748  0.5011763  0.5008908
 0.50063777 0.5003607  0.50000834 0.49955082 0.4990346  0.49847087
 0.4979008  0.49738556 0.49694607 0.4966413  0.49641472 0.4961917
 0.49590185 0.49545264 0.49474233 0.49368292 0.49224585 0.49047542
 0.4885196  0.48667532 0.48502836 0.48354402 0.48215953 0.4808187
 0.47947788 0.47813204 0.476771   0.4754538  0.47425678 0.4731974
 0.4721831  0.47099224 0.46969414 0.46829164 0.46691287 0.46565023
 0.46450254 0.46351528 0.46264732 0.46180472 0.4609298  0.4599232
 0.4588117  0.45768732 0.45662746 0.45566258 0.4547722  0.4539049
 0.4530141  0.45207325 0.45110056 0.45009294 0.44910315 0.44813904
 0.44724032 0.44638976 0.44569185 0.44517708 0.44478172 0.4444504
 0.4440647  0.44354838 0.44284523 0.4419627  0.44097635 0.4399468
 0.43894714 0.4380578  0.43727115 0.43659654 0.43601763 0.4354356
 0.4348142  0.43423066 0.43364635 0.4331079  0.43265754 0.43225658
 0.43190983 0.4315912  0.4312014  0.43072864 0.4302257  0.42974448
 0.42939913 0.42915183 0.42911655 0.4292238  0.42937937 0.42953217
 0.42962512 0.42965636 0.42961556 0.42953616 0.4294758  0.42940387
 0.4293382  0.42925236 0.4291581  0.42900705 0.4288078  0.42857674
 0.4282802  0.42793483 0.42765316 0.4274346  0.42728356 0.42709666
 0.42682737 0.42638126 0.4257029  0.42472988 0.42343393 0.42185628
 0.42014945 0.41855395 0.4170541  0.415602   0.4142401  0.41292244
 0.41163117 0.41038626 0.40920347 0.40822124 0.40738258 0.40668124
 0.40599757 0.40522134 0.40429267 0.40326557 0.40227267 0.40142334
 0.4007235  0.40013325 0.39957213 0.3989511  0.39821228 0.39729288
 0.39624077 0.3950278  0.3938566  0.39280295 0.39186755 0.39108703
 0.39036754 0.38966432 0.38897437 0.3881226  0.38708475 0.38592222
 0.38470227 0.38356242 0.38262206 0.38196024 0.38154274 0.38130188
 0.38105807 0.38071105 0.3802489  0.37959296 0.37886924 0.37813964
 0.37750357 0.3769891  0.37660408 0.37641442 0.37633002 0.37627745
 0.3762149  0.37613472 0.37610042 0.37614757 0.37633854 0.3766662
 0.37701347 0.37735188 0.3775589  0.3775435  0.37731937 0.37703407
 0.37680167 0.37666187 0.37664515 0.37677088 0.37694675 0.37705174
 0.37706274 0.37699392 0.37686622 0.37671    0.37657902 0.3765055
 0.37644225 0.37637472 0.37625384 0.376121   0.3759854  0.37586844
 0.3757363  0.3755711  0.3754233  0.37535208 0.37529758 0.3753089
 0.37531596 0.37518317 0.3748179  0.3741578  0.37320495 0.37201056
 0.37070486 0.36960596 0.36870664 0.36801562 0.3674077  0.36676994
 0.3661309  0.3654249  0.36469463 0.3640142  0.36350337 0.3631366
 0.36282906 0.3623258  0.3616464  0.3608175  0.35991478 0.35901508
 0.35824433 0.357614   0.35703486 0.3564677  0.35585284 0.35518974
 0.35443035 0.3536237  0.352762   0.35191256 0.35104886 0.3502113
 0.34942207 0.34868225 0.34797907 0.34727427 0.34655052 0.34578472
 0.34502468 0.34432808 0.34376156 0.3433553  0.34306908 0.3428679
 0.3427116  0.3424805  0.3421342  0.34160548 0.34091976 0.340212
 0.33952144 0.33889046 0.3383306  0.33793545 0.33764774 0.33742866
 0.33726338 0.33717385 0.33715624 0.33724198 0.33737645 0.3375625
 0.33769888 0.3377238  0.33759105 0.3373149  0.33697817 0.336683
 0.33650032 0.33648428 0.3365859  0.33678424 0.33699897 0.33716467
 0.33726108 0.33727902 0.33722347 0.33714762 0.3370827  0.3371279
 0.33724892 0.33743352 0.3376288  0.33777308 0.33793497 0.33802843
 0.33806038 0.33809337 0.338146   0.33822536 0.33830783 0.33836424
 0.33836827 0.3382246  0.33785152 0.3371487  0.33617562 0.33497557
 0.333678   0.3324345  0.3313404  0.33040804 0.32951546 0.3286687
 0.3277983  0.32685828 0.3258974  0.3250087  0.32420594 0.3235062
 0.32285315 0.32210866 0.32122448 0.3202689  0.31933674 0.3184741
 0.31777558 0.31717482 0.31664073 0.3161258  0.31553185 0.31479737
 0.3139638  0.31308413 0.31223828 0.3114872  0.31087008 0.31039113
 0.3100014  0.3096259  0.30917525 0.30862698 0.3079263  0.3071823
 0.30649203 0.30592102 0.30555812 0.30547285 0.30555218 0.30570248
 0.30584103 0.30586177 0.3056499  0.3052015  0.30453444 0.30379802
 0.30306372 0.30249476 0.30210513 0.30193225 0.30186218 0.301747
 0.30155548 0.30129603 0.30103406 0.30079746 0.30060834 0.30054563
 0.3005621  0.30061388 0.30064934 0.30057576 0.30039582 0.30018717
 0.3000237  0.29990664 0.29989573 0.30001476 0.30015898 0.30031818
 0.3004126  0.3004372  0.30037627 0.30027446 0.30019313 0.30012676
 0.3000582  0.30000436 0.29997697 0.29996625 0.29990345 0.29981044
 0.2997116  0.29957074 0.2994076  0.29918712 0.29893467 0.29862982
 0.2981837  0.29754412 0.29668963 0.29555857 0.29415357 0.2925752
 0.29094285 0.28945628 0.2881534  0.28706333 0.28613093 0.28526872
 0.28443727 0.2835988  0.28281793 0.28220186 0.28179887 0.28153667
 0.28130507 0.28097415 0.28049266 0.2798744  0.2792062  0.27853242
 0.2779367  0.2773726  0.27678344 0.27616605 0.27549687 0.27479756
 0.2740303  0.27321675 0.27241033 0.27161226 0.2708783  0.27023426
 0.2696781  0.2691882  0.26871103 0.2681805  0.2675535  0.2668494
 0.2661099  0.26540485 0.26480997 0.26434892 0.2640424  0.26385286
 0.2636906  0.26349705 0.26318145 0.26264596 0.2619788  0.26119536
 0.26042995 0.259752   0.25919068 0.25875688 0.2584582  0.25820658
 0.2579777  0.2577817  0.25768727 0.25767133 0.25776136 0.2578363
 0.25790605 0.2579375  0.25783047 0.25758666 0.25722757 0.25685516
 0.25653476 0.25637594 0.2564001  0.25655764 0.25671324 0.2568121
 0.25678372 0.25664166 0.2564491  0.25624433 0.2560967  0.25607
 0.25609982 0.2562036  0.2563039  0.25634074 0.25630057 0.25618374
 0.2559874  0.25579798 0.25566813 0.2555929  0.25556806 0.25549498
 0.25530905 0.25486222 0.25407627 0.25286618 0.25129473 0.24941966
 0.24750283 0.24589697 0.24463762 0.24367614 0.24287967 0.24210311
 0.24117327 0.24011675 0.23897874 0.23785771 0.23692076 0.23627299
 0.23580676 0.23528408 0.234666   0.2339539  0.23315157 0.2323335
 0.23156327 0.2308839  0.23032498 0.22981149 0.22931936 0.22876672
 0.22813691 0.22750829 0.22687396 0.2261989  0.22559237 0.22503866
 0.22447567 0.22393964 0.22343235 0.22288987 0.22238667 0.2218707
 0.2214174  0.22099087 0.22063647 0.22039749 0.22028522 0.22029491
 0.22027378 0.22018863 0.21986173 0.21942325 0.21897131 0.21855314
 0.21828519 0.21817304 0.21820569 0.21830718 0.21836507 0.21830069
 0.21816392 0.21810834 0.21813308 0.21825457 0.21857087 0.21895494
 0.2193971  0.21973516 0.21982616 0.21966153 0.21932963 0.21893069
 0.2186386  0.21859483 0.21885297 0.21929005 0.2197876  0.22020446
 0.2203962  0.220397   0.22017162 0.2199383  0.21980993 0.21981929
 0.22004837 0.22040115 0.220797   0.22125818 0.22171739 0.22206132
 0.2223697  0.2226367  0.22292383 0.2232282  0.223515   0.22372213
 0.22377488 0.22363465 0.22320613 0.22240251 0.22118722 0.21966623
 0.21807419 0.2166727  0.2155585  0.21470582 0.21402387 0.21342449
 0.21280558 0.21217878 0.2116089  0.21112172 0.21073    0.21041411
 0.2101282  0.20964377 0.20900735 0.20825261 0.2075269  0.20683248
 0.20621541 0.20566152 0.20510082 0.20444515 0.20364505 0.20261325
 0.20141745 0.20012313 0.19885206 0.19775957 0.1968527  0.1961206
 0.19540425 0.19463094 0.19369292 0.19267307 0.19160216 0.19056928
 0.18964826 0.18901479 0.1886607  0.18854198 0.18841915 0.18829708
 0.18803796 0.18764742 0.18730998 0.18749492 0.1886091  0.1906257 ]
