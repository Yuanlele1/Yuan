Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=22, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_90_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_90_192_FITS_ETTm2_ftM_sl90_ll48_pl192_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34279
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=22, out_features=68, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1340416.0
params:  1564.0
Trainable parameters:  1564
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5423703
	speed: 0.0241s/iter; left time: 642.3916s
	iters: 200, epoch: 1 | loss: 0.3539898
	speed: 0.0164s/iter; left time: 434.2714s
Epoch: 1 cost time: 5.2244789600372314
Epoch: 1, Steps: 267 | Train Loss: 0.4144548 Vali Loss: 0.1939916 Test Loss: 0.2741930
Validation loss decreased (inf --> 0.193992).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2672878
	speed: 0.1031s/iter; left time: 2715.1043s
	iters: 200, epoch: 2 | loss: 0.3088312
	speed: 0.0206s/iter; left time: 539.3677s
Epoch: 2 cost time: 5.977996110916138
Epoch: 2, Steps: 267 | Train Loss: 0.3573843 Vali Loss: 0.1793907 Test Loss: 0.2569461
Validation loss decreased (0.193992 --> 0.179391).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2384422
	speed: 0.0977s/iter; left time: 2547.6503s
	iters: 200, epoch: 3 | loss: 0.4817502
	speed: 0.0245s/iter; left time: 635.7776s
Epoch: 3 cost time: 6.370196342468262
Epoch: 3, Steps: 267 | Train Loss: 0.3470661 Vali Loss: 0.1754252 Test Loss: 0.2520961
Validation loss decreased (0.179391 --> 0.175425).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1932859
	speed: 0.0927s/iter; left time: 2391.3821s
	iters: 200, epoch: 4 | loss: 0.2688145
	speed: 0.0170s/iter; left time: 437.4652s
Epoch: 4 cost time: 5.2201738357543945
Epoch: 4, Steps: 267 | Train Loss: 0.3427374 Vali Loss: 0.1737639 Test Loss: 0.2500152
Validation loss decreased (0.175425 --> 0.173764).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4570284
	speed: 0.0951s/iter; left time: 2428.1639s
	iters: 200, epoch: 5 | loss: 0.3286928
	speed: 0.0237s/iter; left time: 602.8801s
Epoch: 5 cost time: 6.0259904861450195
Epoch: 5, Steps: 267 | Train Loss: 0.3412611 Vali Loss: 0.1732669 Test Loss: 0.2490196
Validation loss decreased (0.173764 --> 0.173267).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4642323
	speed: 0.1011s/iter; left time: 2555.4913s
	iters: 200, epoch: 6 | loss: 0.4039534
	speed: 0.0187s/iter; left time: 469.7603s
Epoch: 6 cost time: 5.738072156906128
Epoch: 6, Steps: 267 | Train Loss: 0.3400317 Vali Loss: 0.1729950 Test Loss: 0.2485831
Validation loss decreased (0.173267 --> 0.172995).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3029904
	speed: 0.1034s/iter; left time: 2585.3634s
	iters: 200, epoch: 7 | loss: 0.3279194
	speed: 0.0179s/iter; left time: 446.6939s
Epoch: 7 cost time: 6.337693452835083
Epoch: 7, Steps: 267 | Train Loss: 0.3391371 Vali Loss: 0.1729235 Test Loss: 0.2482683
Validation loss decreased (0.172995 --> 0.172923).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3370923
	speed: 0.1168s/iter; left time: 2888.0672s
	iters: 200, epoch: 8 | loss: 0.3011936
	speed: 0.0239s/iter; left time: 589.8707s
Epoch: 8 cost time: 8.27785849571228
Epoch: 8, Steps: 267 | Train Loss: 0.3381076 Vali Loss: 0.1728188 Test Loss: 0.2481009
Validation loss decreased (0.172923 --> 0.172819).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3699818
	speed: 0.1048s/iter; left time: 2564.6423s
	iters: 200, epoch: 9 | loss: 0.2735410
	speed: 0.0245s/iter; left time: 598.0477s
Epoch: 9 cost time: 5.917193651199341
Epoch: 9, Steps: 267 | Train Loss: 0.3379439 Vali Loss: 0.1728109 Test Loss: 0.2479976
Validation loss decreased (0.172819 --> 0.172811).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2777689
	speed: 0.1080s/iter; left time: 2613.3118s
	iters: 200, epoch: 10 | loss: 0.5078905
	speed: 0.0224s/iter; left time: 539.3843s
Epoch: 10 cost time: 6.404331684112549
Epoch: 10, Steps: 267 | Train Loss: 0.3373928 Vali Loss: 0.1729408 Test Loss: 0.2479582
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2561961
	speed: 0.1104s/iter; left time: 2642.2322s
	iters: 200, epoch: 11 | loss: 0.2405077
	speed: 0.0182s/iter; left time: 433.1315s
Epoch: 11 cost time: 6.826271295547485
Epoch: 11, Steps: 267 | Train Loss: 0.3377000 Vali Loss: 0.1726428 Test Loss: 0.2478472
Validation loss decreased (0.172811 --> 0.172643).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4699906
	speed: 0.1157s/iter; left time: 2738.9650s
	iters: 200, epoch: 12 | loss: 0.3472111
	speed: 0.0173s/iter; left time: 408.4473s
Epoch: 12 cost time: 5.772029399871826
Epoch: 12, Steps: 267 | Train Loss: 0.3372736 Vali Loss: 0.1728382 Test Loss: 0.2477475
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2393967
	speed: 0.1107s/iter; left time: 2590.6995s
	iters: 200, epoch: 13 | loss: 0.2999867
	speed: 0.0450s/iter; left time: 1048.9532s
Epoch: 13 cost time: 8.99371600151062
Epoch: 13, Steps: 267 | Train Loss: 0.3371603 Vali Loss: 0.1728776 Test Loss: 0.2478453
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3782429
	speed: 0.1379s/iter; left time: 3189.0690s
	iters: 200, epoch: 14 | loss: 0.4228004
	speed: 0.0176s/iter; left time: 404.3083s
Epoch: 14 cost time: 5.527138710021973
Epoch: 14, Steps: 267 | Train Loss: 0.3374143 Vali Loss: 0.1730442 Test Loss: 0.2478226
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3117763
	speed: 0.1084s/iter; left time: 2478.0293s
	iters: 200, epoch: 15 | loss: 0.3305680
	speed: 0.0224s/iter; left time: 509.0333s
Epoch: 15 cost time: 6.0596232414245605
Epoch: 15, Steps: 267 | Train Loss: 0.3369782 Vali Loss: 0.1729499 Test Loss: 0.2478217
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2994785
	speed: 0.0909s/iter; left time: 2054.1329s
	iters: 200, epoch: 16 | loss: 0.3063130
	speed: 0.0184s/iter; left time: 414.4707s
Epoch: 16 cost time: 5.101801633834839
Epoch: 16, Steps: 267 | Train Loss: 0.3367937 Vali Loss: 0.1728942 Test Loss: 0.2477619
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3047031
	speed: 0.1046s/iter; left time: 2335.9258s
	iters: 200, epoch: 17 | loss: 0.3125327
	speed: 0.0367s/iter; left time: 815.1430s
Epoch: 17 cost time: 8.04255986213684
Epoch: 17, Steps: 267 | Train Loss: 0.3363256 Vali Loss: 0.1729304 Test Loss: 0.2477983
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3606538
	speed: 0.1195s/iter; left time: 2637.4936s
	iters: 200, epoch: 18 | loss: 0.3748189
	speed: 0.0285s/iter; left time: 626.3572s
Epoch: 18 cost time: 7.751221418380737
Epoch: 18, Steps: 267 | Train Loss: 0.3366908 Vali Loss: 0.1729776 Test Loss: 0.2477543
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3793409
	speed: 0.1018s/iter; left time: 2219.2906s
	iters: 200, epoch: 19 | loss: 0.3763566
	speed: 0.0424s/iter; left time: 920.6992s
Epoch: 19 cost time: 7.961256980895996
Epoch: 19, Steps: 267 | Train Loss: 0.3357728 Vali Loss: 0.1730338 Test Loss: 0.2477819
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3865795
	speed: 0.1037s/iter; left time: 2232.3593s
	iters: 200, epoch: 20 | loss: 0.3051867
	speed: 0.0168s/iter; left time: 360.9057s
Epoch: 20 cost time: 6.293599605560303
Epoch: 20, Steps: 267 | Train Loss: 0.3364463 Vali Loss: 0.1729998 Test Loss: 0.2478013
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2475011
	speed: 0.0972s/iter; left time: 2066.4836s
	iters: 200, epoch: 21 | loss: 0.2859253
	speed: 0.0200s/iter; left time: 423.8061s
Epoch: 21 cost time: 6.145092010498047
Epoch: 21, Steps: 267 | Train Loss: 0.3364070 Vali Loss: 0.1731287 Test Loss: 0.2478343
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3690716
	speed: 0.0970s/iter; left time: 2036.0606s
	iters: 200, epoch: 22 | loss: 0.3523396
	speed: 0.0250s/iter; left time: 522.4575s
Epoch: 22 cost time: 6.191148042678833
Epoch: 22, Steps: 267 | Train Loss: 0.3364754 Vali Loss: 0.1730070 Test Loss: 0.2478423
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2627950
	speed: 0.0966s/iter; left time: 2001.6176s
	iters: 200, epoch: 23 | loss: 0.3879187
	speed: 0.0161s/iter; left time: 332.8684s
Epoch: 23 cost time: 5.506944179534912
Epoch: 23, Steps: 267 | Train Loss: 0.3361756 Vali Loss: 0.1731784 Test Loss: 0.2478399
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2172413
	speed: 0.1324s/iter; left time: 2708.5931s
	iters: 200, epoch: 24 | loss: 0.3507238
	speed: 0.0229s/iter; left time: 465.6327s
Epoch: 24 cost time: 8.379125595092773
Epoch: 24, Steps: 267 | Train Loss: 0.3363849 Vali Loss: 0.1730988 Test Loss: 0.2478223
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2595226
	speed: 0.0950s/iter; left time: 1917.6161s
	iters: 200, epoch: 25 | loss: 0.2884414
	speed: 0.0171s/iter; left time: 342.7104s
Epoch: 25 cost time: 5.018479824066162
Epoch: 25, Steps: 267 | Train Loss: 0.3359783 Vali Loss: 0.1729889 Test Loss: 0.2478146
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4893352
	speed: 0.1094s/iter; left time: 2179.6816s
	iters: 200, epoch: 26 | loss: 0.4104413
	speed: 0.0157s/iter; left time: 310.6677s
Epoch: 26 cost time: 6.720039129257202
Epoch: 26, Steps: 267 | Train Loss: 0.3365838 Vali Loss: 0.1732635 Test Loss: 0.2478745
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4364787
	speed: 0.1065s/iter; left time: 2094.6133s
	iters: 200, epoch: 27 | loss: 0.3016204
	speed: 0.0179s/iter; left time: 350.1373s
Epoch: 27 cost time: 6.200842380523682
Epoch: 27, Steps: 267 | Train Loss: 0.3362229 Vali Loss: 0.1733204 Test Loss: 0.2478594
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4856775
	speed: 0.1300s/iter; left time: 2521.6050s
	iters: 200, epoch: 28 | loss: 0.2761239
	speed: 0.0203s/iter; left time: 391.5044s
Epoch: 28 cost time: 8.021949052810669
Epoch: 28, Steps: 267 | Train Loss: 0.3363217 Vali Loss: 0.1730554 Test Loss: 0.2478448
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2976976
	speed: 0.1212s/iter; left time: 2317.6415s
	iters: 200, epoch: 29 | loss: 0.3093362
	speed: 0.0195s/iter; left time: 371.1137s
Epoch: 29 cost time: 6.572836399078369
Epoch: 29, Steps: 267 | Train Loss: 0.3363989 Vali Loss: 0.1732697 Test Loss: 0.2478753
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3240582
	speed: 0.1048s/iter; left time: 1975.8134s
	iters: 200, epoch: 30 | loss: 0.4359608
	speed: 0.0183s/iter; left time: 342.3485s
Epoch: 30 cost time: 6.427551507949829
Epoch: 30, Steps: 267 | Train Loss: 0.3362052 Vali Loss: 0.1732876 Test Loss: 0.2478783
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4674192
	speed: 0.0989s/iter; left time: 1838.4372s
	iters: 200, epoch: 31 | loss: 0.2903419
	speed: 0.0164s/iter; left time: 303.4844s
Epoch: 31 cost time: 5.423540830612183
Epoch: 31, Steps: 267 | Train Loss: 0.3362325 Vali Loss: 0.1732504 Test Loss: 0.2478939
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_90_192_FITS_ETTm2_ftM_sl90_ll48_pl192_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.24867749214172363, mae:0.3067477345466614, rse:0.40365779399871826, corr:[0.5690934  0.5689144  0.55954075 0.5593055  0.55990183 0.55610085
 0.55339444 0.5543039  0.5544654  0.55226785 0.55079395 0.5512862
 0.551137   0.549426   0.54833204 0.54873955 0.54840153 0.54651845
 0.544952   0.54474705 0.5443095  0.5427403  0.54142404 0.5414691
 0.5415525  0.54058415 0.53965676 0.5397692  0.53985995 0.5388312
 0.5374069  0.5369471  0.5370081  0.5364542  0.53541756 0.53493387
 0.5347957  0.5340783  0.5328591  0.5320957  0.5319708  0.53173643
 0.5309925  0.5303793  0.5303659  0.530217   0.5294971  0.5285866
 0.5279766  0.52731836 0.5261588  0.52497476 0.52444154 0.52420723
 0.52361387 0.52264935 0.52200675 0.5219196  0.5217729  0.52130824
 0.5209275  0.52097166 0.5211288  0.52100617 0.5207482  0.52076447
 0.5209202  0.52083206 0.52055645 0.52047485 0.5206951  0.5209534
 0.5209505  0.5208499  0.5207872  0.5207717  0.5206968  0.5204591
 0.5202289  0.52009636 0.5199522  0.5196413  0.5192988  0.51909494
 0.5189626  0.51872796 0.5182977  0.5179428  0.51778966 0.51766175
 0.5172971  0.51672953 0.5161823  0.5156202  0.51457864 0.51285356
 0.51092666 0.5091762  0.5073127  0.5051987  0.5033524  0.50205034
 0.5008725  0.49949768 0.49815485 0.49697715 0.49580294 0.49446133
 0.4931161  0.49193886 0.49073797 0.48921084 0.48766476 0.48645496
 0.48548922 0.48432213 0.48286808 0.48160377 0.48077837 0.47988638
 0.4787275  0.47754392 0.47665104 0.4758898  0.474877   0.4736527
 0.4726635  0.47198004 0.47105998 0.46975043 0.4685293  0.46773368
 0.46711326 0.46630806 0.46542472 0.46503085 0.46481803 0.4644823
 0.46389922 0.46351126 0.46343914 0.46313876 0.4624195  0.46167183
 0.46110645 0.46036324 0.45914036 0.45804963 0.45757106 0.45721954
 0.45628387 0.4552276  0.4547132  0.45452762 0.4539827  0.45300663
 0.45234862 0.45257452 0.45272097 0.45229614 0.45175883 0.45176905
 0.4520145  0.45143685 0.45074767 0.45090464 0.45164374 0.45173863
 0.45110816 0.45100942 0.45175913 0.4521176  0.45145515 0.4508787
 0.45145962 0.45222452 0.45179632 0.45089176 0.4511557  0.45227236
 0.45241717 0.4515233  0.45153216 0.45239314 0.45231533 0.45116687
 0.45121616 0.4529005  0.4532985  0.45211792 0.45357028 0.45521235]
