Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=22, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_90_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_90_336_FITS_ETTm2_ftM_sl90_ll48_pl336_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=22, out_features=104, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2050048.0
params:  2392.0
Trainable parameters:  2392
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4944995
	speed: 0.0317s/iter; left time: 838.9372s
	iters: 200, epoch: 1 | loss: 0.5643742
	speed: 0.0171s/iter; left time: 450.7239s
Epoch: 1 cost time: 6.069443464279175
Epoch: 1, Steps: 266 | Train Loss: 0.4656656 Vali Loss: 0.2520245 Test Loss: 0.3489423
Validation loss decreased (inf --> 0.252024).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3675444
	speed: 0.1005s/iter; left time: 2636.9885s
	iters: 200, epoch: 2 | loss: 0.4692619
	speed: 0.0185s/iter; left time: 484.0448s
Epoch: 2 cost time: 6.329097747802734
Epoch: 2, Steps: 266 | Train Loss: 0.3768786 Vali Loss: 0.2268018 Test Loss: 0.3183964
Validation loss decreased (0.252024 --> 0.226802).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2669812
	speed: 0.0934s/iter; left time: 2426.2533s
	iters: 200, epoch: 3 | loss: 0.4231949
	speed: 0.0190s/iter; left time: 491.7324s
Epoch: 3 cost time: 5.457847356796265
Epoch: 3, Steps: 266 | Train Loss: 0.3597823 Vali Loss: 0.2210228 Test Loss: 0.3114162
Validation loss decreased (0.226802 --> 0.221023).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3581482
	speed: 0.0884s/iter; left time: 2272.9285s
	iters: 200, epoch: 4 | loss: 0.3845567
	speed: 0.0177s/iter; left time: 452.8296s
Epoch: 4 cost time: 5.2879979610443115
Epoch: 4, Steps: 266 | Train Loss: 0.3548280 Vali Loss: 0.2191529 Test Loss: 0.3090940
Validation loss decreased (0.221023 --> 0.219153).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3420245
	speed: 0.1055s/iter; left time: 2682.4478s
	iters: 200, epoch: 5 | loss: 0.5181283
	speed: 0.0185s/iter; left time: 469.9023s
Epoch: 5 cost time: 6.568944215774536
Epoch: 5, Steps: 266 | Train Loss: 0.3530250 Vali Loss: 0.2182664 Test Loss: 0.3082403
Validation loss decreased (0.219153 --> 0.218266).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3834254
	speed: 0.1002s/iter; left time: 2521.2225s
	iters: 200, epoch: 6 | loss: 0.3820038
	speed: 0.0257s/iter; left time: 643.9884s
Epoch: 6 cost time: 6.266071557998657
Epoch: 6, Steps: 266 | Train Loss: 0.3523341 Vali Loss: 0.2182996 Test Loss: 0.3078663
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4154676
	speed: 0.0803s/iter; left time: 2000.7545s
	iters: 200, epoch: 7 | loss: 0.2494719
	speed: 0.0140s/iter; left time: 347.2192s
Epoch: 7 cost time: 4.510079622268677
Epoch: 7, Steps: 266 | Train Loss: 0.3514941 Vali Loss: 0.2179367 Test Loss: 0.3076362
Validation loss decreased (0.218266 --> 0.217937).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4383955
	speed: 0.0664s/iter; left time: 1635.5301s
	iters: 200, epoch: 8 | loss: 0.2655651
	speed: 0.0132s/iter; left time: 324.1008s
Epoch: 8 cost time: 4.07947039604187
Epoch: 8, Steps: 266 | Train Loss: 0.3509377 Vali Loss: 0.2181546 Test Loss: 0.3076372
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3736765
	speed: 0.0680s/iter; left time: 1657.3402s
	iters: 200, epoch: 9 | loss: 0.2667094
	speed: 0.0156s/iter; left time: 379.2661s
Epoch: 9 cost time: 4.743327856063843
Epoch: 9, Steps: 266 | Train Loss: 0.3509433 Vali Loss: 0.2181340 Test Loss: 0.3076534
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3666047
	speed: 0.0732s/iter; left time: 1763.5006s
	iters: 200, epoch: 10 | loss: 0.3401414
	speed: 0.0138s/iter; left time: 332.2215s
Epoch: 10 cost time: 4.624928951263428
Epoch: 10, Steps: 266 | Train Loss: 0.3506661 Vali Loss: 0.2182969 Test Loss: 0.3076384
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3419670
	speed: 0.0664s/iter; left time: 1584.0114s
	iters: 200, epoch: 11 | loss: 0.3469634
	speed: 0.0135s/iter; left time: 321.6690s
Epoch: 11 cost time: 4.201334476470947
Epoch: 11, Steps: 266 | Train Loss: 0.3509685 Vali Loss: 0.2183012 Test Loss: 0.3076023
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4499638
	speed: 0.0670s/iter; left time: 1579.8666s
	iters: 200, epoch: 12 | loss: 0.2767554
	speed: 0.0140s/iter; left time: 328.3982s
Epoch: 12 cost time: 4.150837421417236
Epoch: 12, Steps: 266 | Train Loss: 0.3504060 Vali Loss: 0.2182374 Test Loss: 0.3076736
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3309534
	speed: 0.0826s/iter; left time: 1925.2009s
	iters: 200, epoch: 13 | loss: 0.4090793
	speed: 0.0140s/iter; left time: 325.2212s
Epoch: 13 cost time: 5.685361862182617
Epoch: 13, Steps: 266 | Train Loss: 0.3504215 Vali Loss: 0.2185453 Test Loss: 0.3076827
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3585939
	speed: 0.0701s/iter; left time: 1614.8945s
	iters: 200, epoch: 14 | loss: 0.2366281
	speed: 0.0137s/iter; left time: 315.4128s
Epoch: 14 cost time: 4.097036361694336
Epoch: 14, Steps: 266 | Train Loss: 0.3502201 Vali Loss: 0.2186859 Test Loss: 0.3077434
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3991826
	speed: 0.0676s/iter; left time: 1540.8306s
	iters: 200, epoch: 15 | loss: 0.3426012
	speed: 0.0139s/iter; left time: 315.6305s
Epoch: 15 cost time: 4.219428300857544
Epoch: 15, Steps: 266 | Train Loss: 0.3504580 Vali Loss: 0.2185410 Test Loss: 0.3076709
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3208256
	speed: 0.0680s/iter; left time: 1530.8416s
	iters: 200, epoch: 16 | loss: 0.3525316
	speed: 0.0140s/iter; left time: 314.7184s
Epoch: 16 cost time: 4.180508613586426
Epoch: 16, Steps: 266 | Train Loss: 0.3504296 Vali Loss: 0.2188731 Test Loss: 0.3077790
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4767349
	speed: 0.0684s/iter; left time: 1522.6234s
	iters: 200, epoch: 17 | loss: 0.4442262
	speed: 0.0133s/iter; left time: 293.4455s
Epoch: 17 cost time: 4.136290073394775
Epoch: 17, Steps: 266 | Train Loss: 0.3499564 Vali Loss: 0.2185790 Test Loss: 0.3077240
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2587800
	speed: 0.0669s/iter; left time: 1470.2031s
	iters: 200, epoch: 18 | loss: 0.2863908
	speed: 0.0142s/iter; left time: 310.2083s
Epoch: 18 cost time: 4.175259351730347
Epoch: 18, Steps: 266 | Train Loss: 0.3494466 Vali Loss: 0.2185220 Test Loss: 0.3077230
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3707244
	speed: 0.0666s/iter; left time: 1445.6135s
	iters: 200, epoch: 19 | loss: 0.3024704
	speed: 0.0137s/iter; left time: 296.6731s
Epoch: 19 cost time: 4.222879648208618
Epoch: 19, Steps: 266 | Train Loss: 0.3497403 Vali Loss: 0.2186269 Test Loss: 0.3077711
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4370991
	speed: 0.0674s/iter; left time: 1446.2295s
	iters: 200, epoch: 20 | loss: 0.2669268
	speed: 0.0135s/iter; left time: 289.2082s
Epoch: 20 cost time: 4.139371395111084
Epoch: 20, Steps: 266 | Train Loss: 0.3498207 Vali Loss: 0.2185594 Test Loss: 0.3078002
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4086736
	speed: 0.0777s/iter; left time: 1646.1675s
	iters: 200, epoch: 21 | loss: 0.3234818
	speed: 0.0425s/iter; left time: 896.8261s
Epoch: 21 cost time: 8.753546476364136
Epoch: 21, Steps: 266 | Train Loss: 0.3501589 Vali Loss: 0.2188495 Test Loss: 0.3078165
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3417090
	speed: 0.0737s/iter; left time: 1541.6593s
	iters: 200, epoch: 22 | loss: 0.3184992
	speed: 0.0134s/iter; left time: 277.9992s
Epoch: 22 cost time: 4.194189548492432
Epoch: 22, Steps: 266 | Train Loss: 0.3500237 Vali Loss: 0.2188206 Test Loss: 0.3078589
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4108360
	speed: 0.0695s/iter; left time: 1434.6255s
	iters: 200, epoch: 23 | loss: 0.2763191
	speed: 0.0140s/iter; left time: 288.6266s
Epoch: 23 cost time: 4.522554636001587
Epoch: 23, Steps: 266 | Train Loss: 0.3499831 Vali Loss: 0.2189299 Test Loss: 0.3078253
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3044258
	speed: 0.0675s/iter; left time: 1376.7033s
	iters: 200, epoch: 24 | loss: 0.3119378
	speed: 0.0138s/iter; left time: 279.8115s
Epoch: 24 cost time: 4.126321077346802
Epoch: 24, Steps: 266 | Train Loss: 0.3500923 Vali Loss: 0.2190861 Test Loss: 0.3078421
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2775324
	speed: 0.0670s/iter; left time: 1348.8021s
	iters: 200, epoch: 25 | loss: 0.2588255
	speed: 0.0134s/iter; left time: 267.8146s
Epoch: 25 cost time: 4.134676694869995
Epoch: 25, Steps: 266 | Train Loss: 0.3497047 Vali Loss: 0.2187222 Test Loss: 0.3078334
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4330938
	speed: 0.0736s/iter; left time: 1460.7833s
	iters: 200, epoch: 26 | loss: 0.4412875
	speed: 0.0213s/iter; left time: 420.0687s
Epoch: 26 cost time: 5.501904726028442
Epoch: 26, Steps: 266 | Train Loss: 0.3501311 Vali Loss: 0.2191599 Test Loss: 0.3078709
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3203904
	speed: 0.0702s/iter; left time: 1374.6082s
	iters: 200, epoch: 27 | loss: 0.2977218
	speed: 0.0146s/iter; left time: 284.1019s
Epoch: 27 cost time: 4.247332572937012
Epoch: 27, Steps: 266 | Train Loss: 0.3495468 Vali Loss: 0.2192048 Test Loss: 0.3078907
EarlyStopping counter: 20 out of 20
Early stopping
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=22, out_features=104, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2050048.0
params:  2392.0
Trainable parameters:  2392
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6584790
	speed: 0.0197s/iter; left time: 522.5337s
	iters: 200, epoch: 1 | loss: 0.4658209
	speed: 0.0139s/iter; left time: 367.6146s
Epoch: 1 cost time: 4.242562532424927
Epoch: 1, Steps: 266 | Train Loss: 0.4428527 Vali Loss: 0.2179079 Test Loss: 0.3071813
Validation loss decreased (inf --> 0.217908).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3719350
	speed: 0.0667s/iter; left time: 1748.8846s
	iters: 200, epoch: 2 | loss: 0.4391664
	speed: 0.0126s/iter; left time: 330.0157s
Epoch: 2 cost time: 4.03705906867981
Epoch: 2, Steps: 266 | Train Loss: 0.4416872 Vali Loss: 0.2181264 Test Loss: 0.3072864
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4771857
	speed: 0.0713s/iter; left time: 1851.1375s
	iters: 200, epoch: 3 | loss: 0.5291011
	speed: 0.0215s/iter; left time: 554.9369s
Epoch: 3 cost time: 5.273966550827026
Epoch: 3, Steps: 266 | Train Loss: 0.4414880 Vali Loss: 0.2183888 Test Loss: 0.3071980
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3912962
	speed: 0.0727s/iter; left time: 1868.6633s
	iters: 200, epoch: 4 | loss: 0.3773144
	speed: 0.0135s/iter; left time: 344.4666s
Epoch: 4 cost time: 4.16606330871582
Epoch: 4, Steps: 266 | Train Loss: 0.4414328 Vali Loss: 0.2180177 Test Loss: 0.3070577
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.5852047
	speed: 0.0750s/iter; left time: 1908.9763s
	iters: 200, epoch: 5 | loss: 0.5130447
	speed: 0.0142s/iter; left time: 359.7227s
Epoch: 5 cost time: 4.268304109573364
Epoch: 5, Steps: 266 | Train Loss: 0.4414096 Vali Loss: 0.2181360 Test Loss: 0.3071428
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3700859
	speed: 0.0919s/iter; left time: 2312.8103s
	iters: 200, epoch: 6 | loss: 0.3999494
	speed: 0.0153s/iter; left time: 382.6074s
Epoch: 6 cost time: 4.485473871231079
Epoch: 6, Steps: 266 | Train Loss: 0.4411986 Vali Loss: 0.2183721 Test Loss: 0.3072226
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4900625
	speed: 0.0751s/iter; left time: 1869.8851s
	iters: 200, epoch: 7 | loss: 0.3229997
	speed: 0.0278s/iter; left time: 688.3599s
Epoch: 7 cost time: 5.628429412841797
Epoch: 7, Steps: 266 | Train Loss: 0.4408063 Vali Loss: 0.2184695 Test Loss: 0.3071777
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4779511
	speed: 0.0704s/iter; left time: 1734.4754s
	iters: 200, epoch: 8 | loss: 0.3618445
	speed: 0.0137s/iter; left time: 336.1114s
Epoch: 8 cost time: 4.324171543121338
Epoch: 8, Steps: 266 | Train Loss: 0.4408562 Vali Loss: 0.2185249 Test Loss: 0.3072821
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4641555
	speed: 0.0679s/iter; left time: 1654.9427s
	iters: 200, epoch: 9 | loss: 0.5248275
	speed: 0.0137s/iter; left time: 333.6854s
Epoch: 9 cost time: 4.160922050476074
Epoch: 9, Steps: 266 | Train Loss: 0.4405524 Vali Loss: 0.2183832 Test Loss: 0.3072762
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3124732
	speed: 0.0686s/iter; left time: 1653.9875s
	iters: 200, epoch: 10 | loss: 0.4105532
	speed: 0.0233s/iter; left time: 560.3839s
Epoch: 10 cost time: 5.629701852798462
Epoch: 10, Steps: 266 | Train Loss: 0.4406533 Vali Loss: 0.2183913 Test Loss: 0.3072867
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.8783858
	speed: 0.0825s/iter; left time: 1966.2857s
	iters: 200, epoch: 11 | loss: 0.5475475
	speed: 0.0137s/iter; left time: 326.3472s
Epoch: 11 cost time: 4.935965061187744
Epoch: 11, Steps: 266 | Train Loss: 0.4407017 Vali Loss: 0.2185352 Test Loss: 0.3072938
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3989854
	speed: 0.0748s/iter; left time: 1762.3003s
	iters: 200, epoch: 12 | loss: 0.5721192
	speed: 0.0145s/iter; left time: 340.3311s
Epoch: 12 cost time: 4.664795398712158
Epoch: 12, Steps: 266 | Train Loss: 0.4405092 Vali Loss: 0.2184931 Test Loss: 0.3073223
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2688122
	speed: 0.0705s/iter; left time: 1643.0732s
	iters: 200, epoch: 13 | loss: 0.4710422
	speed: 0.0137s/iter; left time: 318.8247s
Epoch: 13 cost time: 4.2595062255859375
Epoch: 13, Steps: 266 | Train Loss: 0.4408501 Vali Loss: 0.2186564 Test Loss: 0.3073655
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4558145
	speed: 0.0688s/iter; left time: 1586.0063s
	iters: 200, epoch: 14 | loss: 0.3927424
	speed: 0.0146s/iter; left time: 334.0570s
Epoch: 14 cost time: 4.330053091049194
Epoch: 14, Steps: 266 | Train Loss: 0.4409084 Vali Loss: 0.2185502 Test Loss: 0.3072617
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4065249
	speed: 0.0687s/iter; left time: 1564.1048s
	iters: 200, epoch: 15 | loss: 0.7486303
	speed: 0.0142s/iter; left time: 322.7326s
Epoch: 15 cost time: 4.307321786880493
Epoch: 15, Steps: 266 | Train Loss: 0.4405141 Vali Loss: 0.2186081 Test Loss: 0.3073230
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4345734
	speed: 0.0679s/iter; left time: 1528.1288s
	iters: 200, epoch: 16 | loss: 0.4149641
	speed: 0.0134s/iter; left time: 299.2214s
Epoch: 16 cost time: 4.094048261642456
Epoch: 16, Steps: 266 | Train Loss: 0.4403731 Vali Loss: 0.2187483 Test Loss: 0.3073010
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4341055
	speed: 0.0656s/iter; left time: 1458.7785s
	iters: 200, epoch: 17 | loss: 0.4296768
	speed: 0.0131s/iter; left time: 289.2562s
Epoch: 17 cost time: 4.105523109436035
Epoch: 17, Steps: 266 | Train Loss: 0.4400077 Vali Loss: 0.2185398 Test Loss: 0.3072998
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4134812
	speed: 0.0841s/iter; left time: 1848.2795s
	iters: 200, epoch: 18 | loss: 0.5971159
	speed: 0.0147s/iter; left time: 321.6953s
Epoch: 18 cost time: 4.303633213043213
Epoch: 18, Steps: 266 | Train Loss: 0.4403179 Vali Loss: 0.2186691 Test Loss: 0.3073543
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.6681472
	speed: 0.0701s/iter; left time: 1522.6834s
	iters: 200, epoch: 19 | loss: 0.4605103
	speed: 0.0137s/iter; left time: 296.5599s
Epoch: 19 cost time: 4.250359296798706
Epoch: 19, Steps: 266 | Train Loss: 0.4399941 Vali Loss: 0.2188436 Test Loss: 0.3073565
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2384651
	speed: 0.0698s/iter; left time: 1497.5631s
	iters: 200, epoch: 20 | loss: 0.3858380
	speed: 0.0136s/iter; left time: 289.6225s
Epoch: 20 cost time: 4.2911536693573
Epoch: 20, Steps: 266 | Train Loss: 0.4402081 Vali Loss: 0.2186789 Test Loss: 0.3073709
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4493408
	speed: 0.0688s/iter; left time: 1458.1906s
	iters: 200, epoch: 21 | loss: 0.4755213
	speed: 0.0383s/iter; left time: 806.8541s
Epoch: 21 cost time: 7.511428117752075
Epoch: 21, Steps: 266 | Train Loss: 0.4397151 Vali Loss: 0.2187556 Test Loss: 0.3073767
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_90_336_FITS_ETTm2_ftM_sl90_ll48_pl336_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.3085683286190033, mae:0.3433002829551697, rse:0.4486795961856842, corr:[0.56063426 0.56102866 0.5544846  0.55143493 0.5520251  0.5513058
 0.54905266 0.547974   0.5481379  0.54753745 0.5461523  0.5452302
 0.5448721  0.5440903  0.5428391  0.5420953  0.54184    0.5412048
 0.5400626  0.5389305  0.5379559  0.5368123  0.53558075 0.53482574
 0.5345756  0.53425664 0.53374326 0.5332209  0.5327166  0.5320921
 0.5313727  0.5307898  0.5302725  0.5296293  0.5288937  0.5283819
 0.5279435  0.52726656 0.5263425  0.52548    0.5249319  0.5246695
 0.5244448  0.52412564 0.52371407 0.5231552  0.5225345  0.52190095
 0.5212056  0.5203054  0.5192566  0.51845735 0.51801974 0.5176382
 0.51707417 0.5163279  0.5156827  0.51531816 0.51506597 0.51482606
 0.51461244 0.5144943  0.51447487 0.51449436 0.51446354 0.5143966
 0.5142602  0.5140256  0.5138557  0.5138675  0.5139755  0.5140345
 0.5139606  0.513914   0.5139153  0.5138907  0.51375496 0.5134544
 0.5130739  0.51271796 0.5124168  0.51219136 0.51208276 0.5120215
 0.5118328  0.5114211  0.51098126 0.51070863 0.5104942  0.51016706
 0.5097708  0.5094006  0.50897723 0.5081482  0.50666696 0.50474125
 0.50273365 0.5006887  0.49856743 0.49662378 0.49504963 0.49365306
 0.49218675 0.4908159  0.48974356 0.48864946 0.48729542 0.48590422
 0.48479083 0.48384503 0.482667   0.4811915  0.47983852 0.4787196
 0.47749743 0.4760407  0.47465065 0.47365093 0.47283936 0.4717194
 0.4704686  0.4694118  0.46857676 0.46769878 0.4666815  0.46575493
 0.46501395 0.4641833  0.46298563 0.46169066 0.4606338  0.45977587
 0.45889622 0.45799273 0.4572419  0.45680988 0.45628837 0.4557265
 0.45536682 0.45526376 0.4551415  0.45470032 0.45411104 0.45357117
 0.452925   0.45197386 0.45080787 0.44994485 0.44939777 0.44881243
 0.4480117  0.44737637 0.44693774 0.44639498 0.4457846  0.44532722
 0.4451401  0.44515818 0.44492483 0.44461757 0.44445854 0.44449452
 0.44456646 0.44421607 0.44379362 0.44365653 0.44393274 0.44441405
 0.44478095 0.44495568 0.44504076 0.44513357 0.4452108  0.44518673
 0.4450872  0.4449929  0.44487062 0.44469845 0.4445654  0.44467402
 0.44493252 0.4449783  0.44465336 0.44402376 0.44353607 0.44339985
 0.44336474 0.44312248 0.44248477 0.44146243 0.4401002  0.43837282
 0.43634242 0.43423775 0.43225726 0.43055615 0.4292269  0.42810005
 0.42689794 0.42562538 0.42458466 0.42375517 0.42282522 0.421553
 0.4201196  0.41890076 0.4177997  0.4164993  0.41495234 0.413515
 0.41235888 0.41137058 0.41025713 0.40895465 0.40760675 0.40632045
 0.40516296 0.4040943  0.403254   0.40245238 0.40142676 0.40017524
 0.39889148 0.39764735 0.3967007  0.39586407 0.39523846 0.39464083
 0.39375025 0.39250907 0.39118063 0.39031193 0.3899004  0.38964152
 0.38932407 0.3890576  0.38886547 0.38846484 0.38783026 0.38724414
 0.38694906 0.38677847 0.3863802  0.38615164 0.3862621  0.38645485
 0.38652927 0.38637194 0.38618985 0.3860406  0.38592955 0.38579598
 0.38567463 0.38576114 0.38603708 0.3863596  0.3867731  0.3872143
 0.38746378 0.38739955 0.3871726  0.38720095 0.38756713 0.3880077
 0.3885016  0.3890615  0.38970786 0.3900925  0.39020717 0.39030346
 0.3904877  0.3907099  0.39084235 0.39105663 0.39157835 0.39221135
 0.39255562 0.39244965 0.39220378 0.39219475 0.39237574 0.39261347
 0.39291477 0.39335012 0.3936362  0.39328918 0.39227974 0.39110142
 0.39010432 0.38919556 0.3882711  0.38768986 0.38763842 0.38780504
 0.38785496 0.3878667  0.3880034  0.38805518 0.38764524 0.38697204
 0.3865067  0.3862194  0.38566515 0.38470712 0.38373414 0.38303342
 0.38231787 0.3812185  0.38004234 0.3792538  0.3786511  0.37780833
 0.37675327 0.3760953  0.37574017 0.37491858 0.37357715 0.37263244
 0.37239355 0.37176806 0.37004328 0.36840582 0.36801705 0.36789116
 0.36638948 0.36442953 0.36414385 0.36467734 0.3633783  0.36086634
 0.3608121  0.36281475 0.3620681  0.3591309  0.3616057  0.3669983 ]
