Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=42, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_360_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_360_336_FITS_ETTm2_ftM_sl360_ll48_pl336_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33865
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=42, out_features=81, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3048192.0
params:  3483.0
Trainable parameters:  3483
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4940162
	speed: 0.0228s/iter; left time: 600.8290s
	iters: 200, epoch: 1 | loss: 0.5642107
	speed: 0.0163s/iter; left time: 427.2649s
Epoch: 1 cost time: 4.918804407119751
Epoch: 1, Steps: 264 | Train Loss: 0.4820261 Vali Loss: 0.2219421 Test Loss: 0.2951567
Validation loss decreased (inf --> 0.221942).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5266450
	speed: 0.0719s/iter; left time: 1871.1836s
	iters: 200, epoch: 2 | loss: 0.5314050
	speed: 0.0129s/iter; left time: 333.8554s
Epoch: 2 cost time: 3.9715349674224854
Epoch: 2, Steps: 264 | Train Loss: 0.4239176 Vali Loss: 0.2107056 Test Loss: 0.2830967
Validation loss decreased (0.221942 --> 0.210706).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4829242
	speed: 0.0682s/iter; left time: 1758.4524s
	iters: 200, epoch: 3 | loss: 0.5357187
	speed: 0.0127s/iter; left time: 326.5854s
Epoch: 3 cost time: 3.9668781757354736
Epoch: 3, Steps: 264 | Train Loss: 0.4111739 Vali Loss: 0.2066071 Test Loss: 0.2788318
Validation loss decreased (0.210706 --> 0.206607).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3346757
	speed: 0.0681s/iter; left time: 1738.2948s
	iters: 200, epoch: 4 | loss: 0.4507908
	speed: 0.0134s/iter; left time: 340.9072s
Epoch: 4 cost time: 4.039525270462036
Epoch: 4, Steps: 264 | Train Loss: 0.4046967 Vali Loss: 0.2043505 Test Loss: 0.2766541
Validation loss decreased (0.206607 --> 0.204351).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3558392
	speed: 0.0690s/iter; left time: 1742.9043s
	iters: 200, epoch: 5 | loss: 0.4468322
	speed: 0.0138s/iter; left time: 345.7643s
Epoch: 5 cost time: 4.205871343612671
Epoch: 5, Steps: 264 | Train Loss: 0.4016992 Vali Loss: 0.2025931 Test Loss: 0.2753372
Validation loss decreased (0.204351 --> 0.202593).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.5673702
	speed: 0.0703s/iter; left time: 1756.1336s
	iters: 200, epoch: 6 | loss: 0.3492571
	speed: 0.0132s/iter; left time: 327.6797s
Epoch: 6 cost time: 4.209841966629028
Epoch: 6, Steps: 264 | Train Loss: 0.3993424 Vali Loss: 0.2020276 Test Loss: 0.2745094
Validation loss decreased (0.202593 --> 0.202028).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.5050952
	speed: 0.0687s/iter; left time: 1697.6118s
	iters: 200, epoch: 7 | loss: 0.3908006
	speed: 0.0132s/iter; left time: 324.2041s
Epoch: 7 cost time: 4.163865804672241
Epoch: 7, Steps: 264 | Train Loss: 0.3973335 Vali Loss: 0.2012565 Test Loss: 0.2740926
Validation loss decreased (0.202028 --> 0.201256).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3695775
	speed: 0.0744s/iter; left time: 1819.5460s
	iters: 200, epoch: 8 | loss: 0.2712207
	speed: 0.0131s/iter; left time: 318.6987s
Epoch: 8 cost time: 4.669508934020996
Epoch: 8, Steps: 264 | Train Loss: 0.3961623 Vali Loss: 0.2006328 Test Loss: 0.2736208
Validation loss decreased (0.201256 --> 0.200633).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3921865
	speed: 0.0687s/iter; left time: 1662.6280s
	iters: 200, epoch: 9 | loss: 0.4393816
	speed: 0.0132s/iter; left time: 318.7173s
Epoch: 9 cost time: 4.0575852394104
Epoch: 9, Steps: 264 | Train Loss: 0.3954282 Vali Loss: 0.2004870 Test Loss: 0.2733035
Validation loss decreased (0.200633 --> 0.200487).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3892263
	speed: 0.0673s/iter; left time: 1610.3686s
	iters: 200, epoch: 10 | loss: 0.4959884
	speed: 0.0129s/iter; left time: 306.3645s
Epoch: 10 cost time: 4.004255294799805
Epoch: 10, Steps: 264 | Train Loss: 0.3945020 Vali Loss: 0.2003348 Test Loss: 0.2730989
Validation loss decreased (0.200487 --> 0.200335).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3527742
	speed: 0.0718s/iter; left time: 1698.5006s
	iters: 200, epoch: 11 | loss: 0.5305306
	speed: 0.0159s/iter; left time: 374.7019s
Epoch: 11 cost time: 4.635668754577637
Epoch: 11, Steps: 264 | Train Loss: 0.3937677 Vali Loss: 0.1997602 Test Loss: 0.2729424
Validation loss decreased (0.200335 --> 0.199760).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4518333
	speed: 0.0738s/iter; left time: 1726.3215s
	iters: 200, epoch: 12 | loss: 0.4283137
	speed: 0.0128s/iter; left time: 299.1574s
Epoch: 12 cost time: 4.0444207191467285
Epoch: 12, Steps: 264 | Train Loss: 0.3934637 Vali Loss: 0.1998695 Test Loss: 0.2728204
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3896606
	speed: 0.0674s/iter; left time: 1558.6901s
	iters: 200, epoch: 13 | loss: 0.3706881
	speed: 0.0130s/iter; left time: 299.0273s
Epoch: 13 cost time: 5.430345058441162
Epoch: 13, Steps: 264 | Train Loss: 0.3924215 Vali Loss: 0.1994953 Test Loss: 0.2727356
Validation loss decreased (0.199760 --> 0.199495).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4627977
	speed: 0.0799s/iter; left time: 1827.4790s
	iters: 200, epoch: 14 | loss: 0.4349906
	speed: 0.0130s/iter; left time: 295.1545s
Epoch: 14 cost time: 3.8859052658081055
Epoch: 14, Steps: 264 | Train Loss: 0.3927351 Vali Loss: 0.1993613 Test Loss: 0.2726158
Validation loss decreased (0.199495 --> 0.199361).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4023332
	speed: 0.0679s/iter; left time: 1533.9315s
	iters: 200, epoch: 15 | loss: 0.2541360
	speed: 0.0132s/iter; left time: 297.9443s
Epoch: 15 cost time: 4.0601630210876465
Epoch: 15, Steps: 264 | Train Loss: 0.3921381 Vali Loss: 0.1992550 Test Loss: 0.2725195
Validation loss decreased (0.199361 --> 0.199255).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3443986
	speed: 0.0736s/iter; left time: 1643.8152s
	iters: 200, epoch: 16 | loss: 0.3915608
	speed: 0.0162s/iter; left time: 360.5557s
Epoch: 16 cost time: 4.810924768447876
Epoch: 16, Steps: 264 | Train Loss: 0.3925305 Vali Loss: 0.1993068 Test Loss: 0.2725498
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4526754
	speed: 0.0729s/iter; left time: 1609.8493s
	iters: 200, epoch: 17 | loss: 0.4305273
	speed: 0.0129s/iter; left time: 282.9280s
Epoch: 17 cost time: 4.011735677719116
Epoch: 17, Steps: 264 | Train Loss: 0.3920280 Vali Loss: 0.1993334 Test Loss: 0.2724657
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2843508
	speed: 0.0682s/iter; left time: 1488.4355s
	iters: 200, epoch: 18 | loss: 0.3600111
	speed: 0.0131s/iter; left time: 284.6622s
Epoch: 18 cost time: 3.981825113296509
Epoch: 18, Steps: 264 | Train Loss: 0.3917954 Vali Loss: 0.1991086 Test Loss: 0.2723738
Validation loss decreased (0.199255 --> 0.199109).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3612801
	speed: 0.0659s/iter; left time: 1420.2104s
	iters: 200, epoch: 19 | loss: 0.3299415
	speed: 0.0127s/iter; left time: 271.4174s
Epoch: 19 cost time: 3.8422718048095703
Epoch: 19, Steps: 264 | Train Loss: 0.3916215 Vali Loss: 0.1990789 Test Loss: 0.2724102
Validation loss decreased (0.199109 --> 0.199079).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2894121
	speed: 0.0671s/iter; left time: 1427.8158s
	iters: 200, epoch: 20 | loss: 0.3056439
	speed: 0.0127s/iter; left time: 269.7370s
Epoch: 20 cost time: 3.968818426132202
Epoch: 20, Steps: 264 | Train Loss: 0.3916770 Vali Loss: 0.1989228 Test Loss: 0.2723732
Validation loss decreased (0.199079 --> 0.198923).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2331606
	speed: 0.0672s/iter; left time: 1412.4683s
	iters: 200, epoch: 21 | loss: 0.5120506
	speed: 0.0129s/iter; left time: 269.9370s
Epoch: 21 cost time: 3.9640586376190186
Epoch: 21, Steps: 264 | Train Loss: 0.3911583 Vali Loss: 0.1989456 Test Loss: 0.2722906
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3057681
	speed: 0.0679s/iter; left time: 1409.3833s
	iters: 200, epoch: 22 | loss: 0.3888856
	speed: 0.0132s/iter; left time: 273.1772s
Epoch: 22 cost time: 4.039247989654541
Epoch: 22, Steps: 264 | Train Loss: 0.3913995 Vali Loss: 0.1989369 Test Loss: 0.2723573
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2908373
	speed: 0.0770s/iter; left time: 1577.3262s
	iters: 200, epoch: 23 | loss: 0.3514132
	speed: 0.0154s/iter; left time: 313.8743s
Epoch: 23 cost time: 5.091282367706299
Epoch: 23, Steps: 264 | Train Loss: 0.3913861 Vali Loss: 0.1988784 Test Loss: 0.2722839
Validation loss decreased (0.198923 --> 0.198878).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4689168
	speed: 0.0686s/iter; left time: 1388.6040s
	iters: 200, epoch: 24 | loss: 0.3527046
	speed: 0.0155s/iter; left time: 312.1951s
Epoch: 24 cost time: 4.442061185836792
Epoch: 24, Steps: 264 | Train Loss: 0.3911615 Vali Loss: 0.1988831 Test Loss: 0.2722888
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4423617
	speed: 0.0693s/iter; left time: 1384.5145s
	iters: 200, epoch: 25 | loss: 0.3195114
	speed: 0.0128s/iter; left time: 253.6409s
Epoch: 25 cost time: 4.036305904388428
Epoch: 25, Steps: 264 | Train Loss: 0.3909330 Vali Loss: 0.1988319 Test Loss: 0.2722431
Validation loss decreased (0.198878 --> 0.198832).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4155090
	speed: 0.0683s/iter; left time: 1345.8248s
	iters: 200, epoch: 26 | loss: 0.4523027
	speed: 0.0131s/iter; left time: 256.7600s
Epoch: 26 cost time: 4.010743141174316
Epoch: 26, Steps: 264 | Train Loss: 0.3908002 Vali Loss: 0.1989632 Test Loss: 0.2722349
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3083799
	speed: 0.0668s/iter; left time: 1297.7450s
	iters: 200, epoch: 27 | loss: 0.4103150
	speed: 0.0279s/iter; left time: 538.8658s
Epoch: 27 cost time: 6.3966429233551025
Epoch: 27, Steps: 264 | Train Loss: 0.3908876 Vali Loss: 0.1989640 Test Loss: 0.2722452
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4000233
	speed: 0.0864s/iter; left time: 1655.6676s
	iters: 200, epoch: 28 | loss: 0.3308909
	speed: 0.0154s/iter; left time: 294.0630s
Epoch: 28 cost time: 4.730571508407593
Epoch: 28, Steps: 264 | Train Loss: 0.3909213 Vali Loss: 0.1987753 Test Loss: 0.2722252
Validation loss decreased (0.198832 --> 0.198775).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3313903
	speed: 0.0759s/iter; left time: 1434.8963s
	iters: 200, epoch: 29 | loss: 0.3350719
	speed: 0.0154s/iter; left time: 289.8337s
Epoch: 29 cost time: 4.664546728134155
Epoch: 29, Steps: 264 | Train Loss: 0.3902327 Vali Loss: 0.1989992 Test Loss: 0.2722308
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3527688
	speed: 0.0746s/iter; left time: 1390.1246s
	iters: 200, epoch: 30 | loss: 0.4054682
	speed: 0.0161s/iter; left time: 298.0819s
Epoch: 30 cost time: 4.755233287811279
Epoch: 30, Steps: 264 | Train Loss: 0.3908603 Vali Loss: 0.1987423 Test Loss: 0.2721867
Validation loss decreased (0.198775 --> 0.198742).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4347018
	speed: 0.0758s/iter; left time: 1393.8887s
	iters: 200, epoch: 31 | loss: 0.3506268
	speed: 0.0154s/iter; left time: 281.1892s
Epoch: 31 cost time: 4.7572174072265625
Epoch: 31, Steps: 264 | Train Loss: 0.3909669 Vali Loss: 0.1987466 Test Loss: 0.2721746
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3830976
	speed: 0.0812s/iter; left time: 1470.2532s
	iters: 200, epoch: 32 | loss: 0.3650066
	speed: 0.0291s/iter; left time: 524.0125s
Epoch: 32 cost time: 6.696199178695679
Epoch: 32, Steps: 264 | Train Loss: 0.3908106 Vali Loss: 0.1989156 Test Loss: 0.2721647
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4206939
	speed: 0.1142s/iter; left time: 2038.7995s
	iters: 200, epoch: 33 | loss: 0.4618757
	speed: 0.0161s/iter; left time: 285.9191s
Epoch: 33 cost time: 4.794821739196777
Epoch: 33, Steps: 264 | Train Loss: 0.3908350 Vali Loss: 0.1987833 Test Loss: 0.2721502
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3575635
	speed: 0.0737s/iter; left time: 1295.9480s
	iters: 200, epoch: 34 | loss: 0.4797974
	speed: 0.0131s/iter; left time: 229.2914s
Epoch: 34 cost time: 4.158438682556152
Epoch: 34, Steps: 264 | Train Loss: 0.3906373 Vali Loss: 0.1987837 Test Loss: 0.2721615
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4358544
	speed: 0.0678s/iter; left time: 1174.8990s
	iters: 200, epoch: 35 | loss: 0.3048577
	speed: 0.0129s/iter; left time: 222.5082s
Epoch: 35 cost time: 3.9961647987365723
Epoch: 35, Steps: 264 | Train Loss: 0.3906619 Vali Loss: 0.1988156 Test Loss: 0.2721480
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3301696
	speed: 0.0677s/iter; left time: 1154.4687s
	iters: 200, epoch: 36 | loss: 0.3993708
	speed: 0.0133s/iter; left time: 226.3504s
Epoch: 36 cost time: 4.20626974105835
Epoch: 36, Steps: 264 | Train Loss: 0.3906829 Vali Loss: 0.1988004 Test Loss: 0.2721568
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3802168
	speed: 0.0704s/iter; left time: 1181.7903s
	iters: 200, epoch: 37 | loss: 0.3928968
	speed: 0.0130s/iter; left time: 217.3091s
Epoch: 37 cost time: 3.996549367904663
Epoch: 37, Steps: 264 | Train Loss: 0.3895587 Vali Loss: 0.1985381 Test Loss: 0.2721258
Validation loss decreased (0.198742 --> 0.198538).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3758708
	speed: 0.0673s/iter; left time: 1112.2804s
	iters: 200, epoch: 38 | loss: 0.3495481
	speed: 0.0128s/iter; left time: 210.2317s
Epoch: 38 cost time: 3.931277275085449
Epoch: 38, Steps: 264 | Train Loss: 0.3906273 Vali Loss: 0.1987106 Test Loss: 0.2721362
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2809524
	speed: 0.0646s/iter; left time: 1051.4348s
	iters: 200, epoch: 39 | loss: 0.4279908
	speed: 0.0127s/iter; left time: 204.8265s
Epoch: 39 cost time: 3.8440542221069336
Epoch: 39, Steps: 264 | Train Loss: 0.3905372 Vali Loss: 0.1988800 Test Loss: 0.2721275
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.4386760
	speed: 0.0667s/iter; left time: 1068.0242s
	iters: 200, epoch: 40 | loss: 0.3204552
	speed: 0.0127s/iter; left time: 202.3622s
Epoch: 40 cost time: 3.8616840839385986
Epoch: 40, Steps: 264 | Train Loss: 0.3905968 Vali Loss: 0.1985878 Test Loss: 0.2721190
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3412991
	speed: 0.0669s/iter; left time: 1053.0721s
	iters: 200, epoch: 41 | loss: 0.6142252
	speed: 0.0128s/iter; left time: 200.4006s
Epoch: 41 cost time: 3.974942684173584
Epoch: 41, Steps: 264 | Train Loss: 0.3906579 Vali Loss: 0.1986172 Test Loss: 0.2721156
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3362952
	speed: 0.0660s/iter; left time: 1021.8707s
	iters: 200, epoch: 42 | loss: 0.3708248
	speed: 0.0131s/iter; left time: 201.5614s
Epoch: 42 cost time: 3.976135015487671
Epoch: 42, Steps: 264 | Train Loss: 0.3904318 Vali Loss: 0.1986810 Test Loss: 0.2721088
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2926833
	speed: 0.0680s/iter; left time: 1034.9975s
	iters: 200, epoch: 43 | loss: 0.2732881
	speed: 0.0133s/iter; left time: 201.1714s
Epoch: 43 cost time: 4.06529688835144
Epoch: 43, Steps: 264 | Train Loss: 0.3898885 Vali Loss: 0.1987768 Test Loss: 0.2721044
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.4923234
	speed: 0.0670s/iter; left time: 1002.2991s
	iters: 200, epoch: 44 | loss: 0.3587134
	speed: 0.0127s/iter; left time: 188.6859s
Epoch: 44 cost time: 3.8960535526275635
Epoch: 44, Steps: 264 | Train Loss: 0.3905265 Vali Loss: 0.1987684 Test Loss: 0.2721016
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.4009599
	speed: 0.0697s/iter; left time: 1023.9110s
	iters: 200, epoch: 45 | loss: 0.2436715
	speed: 0.0303s/iter; left time: 441.8019s
Epoch: 45 cost time: 7.392269849777222
Epoch: 45, Steps: 264 | Train Loss: 0.3906855 Vali Loss: 0.1988098 Test Loss: 0.2720923
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.5154072
	speed: 0.0805s/iter; left time: 1161.1230s
	iters: 200, epoch: 46 | loss: 0.2889884
	speed: 0.0128s/iter; left time: 183.4612s
Epoch: 46 cost time: 3.912837505340576
Epoch: 46, Steps: 264 | Train Loss: 0.3898849 Vali Loss: 0.1987528 Test Loss: 0.2720832
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.3838675
	speed: 0.0670s/iter; left time: 948.1778s
	iters: 200, epoch: 47 | loss: 0.4140949
	speed: 0.0129s/iter; left time: 180.6340s
Epoch: 47 cost time: 3.8358309268951416
Epoch: 47, Steps: 264 | Train Loss: 0.3901699 Vali Loss: 0.1987841 Test Loss: 0.2720729
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.3651671
	speed: 0.0666s/iter; left time: 925.3360s
	iters: 200, epoch: 48 | loss: 0.3989868
	speed: 0.0129s/iter; left time: 178.5555s
Epoch: 48 cost time: 3.9814631938934326
Epoch: 48, Steps: 264 | Train Loss: 0.3903525 Vali Loss: 0.1986952 Test Loss: 0.2720801
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.4585890
	speed: 0.0664s/iter; left time: 904.5474s
	iters: 200, epoch: 49 | loss: 0.4503535
	speed: 0.0129s/iter; left time: 175.0788s
Epoch: 49 cost time: 3.898939609527588
Epoch: 49, Steps: 264 | Train Loss: 0.3905245 Vali Loss: 0.1987648 Test Loss: 0.2720666
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.5640312
	speed: 0.0676s/iter; left time: 903.0368s
	iters: 200, epoch: 50 | loss: 0.2795562
	speed: 0.0132s/iter; left time: 175.3995s
Epoch: 50 cost time: 4.136742115020752
Epoch: 50, Steps: 264 | Train Loss: 0.3904650 Vali Loss: 0.1986701 Test Loss: 0.2720759
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2396242
	speed: 0.0686s/iter; left time: 899.2659s
	iters: 200, epoch: 51 | loss: 0.3517753
	speed: 0.0150s/iter; left time: 194.7330s
Epoch: 51 cost time: 4.39563512802124
Epoch: 51, Steps: 264 | Train Loss: 0.3903783 Vali Loss: 0.1987108 Test Loss: 0.2720639
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.4175506
	speed: 0.0678s/iter; left time: 870.3727s
	iters: 200, epoch: 52 | loss: 0.5070679
	speed: 0.0127s/iter; left time: 161.6372s
Epoch: 52 cost time: 3.871677875518799
Epoch: 52, Steps: 264 | Train Loss: 0.3898707 Vali Loss: 0.1987857 Test Loss: 0.2720670
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.5419868
	speed: 0.0676s/iter; left time: 850.1723s
	iters: 200, epoch: 53 | loss: 0.5021303
	speed: 0.0133s/iter; left time: 165.2829s
Epoch: 53 cost time: 4.011090993881226
Epoch: 53, Steps: 264 | Train Loss: 0.3898242 Vali Loss: 0.1986280 Test Loss: 0.2720594
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.4068555
	speed: 0.0667s/iter; left time: 820.5373s
	iters: 200, epoch: 54 | loss: 0.3296162
	speed: 0.0133s/iter; left time: 162.7396s
Epoch: 54 cost time: 4.063737154006958
Epoch: 54, Steps: 264 | Train Loss: 0.3903541 Vali Loss: 0.1986287 Test Loss: 0.2720516
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.4862985
	speed: 0.0666s/iter; left time: 802.2427s
	iters: 200, epoch: 55 | loss: 0.5102994
	speed: 0.0131s/iter; left time: 156.4579s
Epoch: 55 cost time: 3.8914291858673096
Epoch: 55, Steps: 264 | Train Loss: 0.3901373 Vali Loss: 0.1986217 Test Loss: 0.2720581
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.3952359
	speed: 0.0711s/iter; left time: 837.0780s
	iters: 200, epoch: 56 | loss: 0.4124655
	speed: 0.0133s/iter; left time: 155.8972s
Epoch: 56 cost time: 4.042749643325806
Epoch: 56, Steps: 264 | Train Loss: 0.3901714 Vali Loss: 0.1987632 Test Loss: 0.2720492
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2478863
	speed: 0.0690s/iter; left time: 795.0424s
	iters: 200, epoch: 57 | loss: 0.3038541
	speed: 0.0129s/iter; left time: 147.4732s
Epoch: 57 cost time: 3.998708486557007
Epoch: 57, Steps: 264 | Train Loss: 0.3904469 Vali Loss: 0.1986680 Test Loss: 0.2720525
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_360_336_FITS_ETTm2_ftM_sl360_ll48_pl336_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.27341753244400024, mae:0.32633543014526367, rse:0.42235130071640015, corr:[0.54994583 0.5568605  0.55639607 0.55351275 0.55162495 0.5513719
 0.5522983  0.55328923 0.5534933  0.5528213  0.5517343  0.55091715
 0.5507061  0.5510162  0.5515346  0.5517939  0.55151975 0.5507178
 0.5496731  0.5487315  0.54815066 0.5479958  0.5480675  0.5481574
 0.54802203 0.5475346  0.54682636 0.54610384 0.54554844 0.5451856
 0.5449691  0.5447941  0.5445126  0.5440554  0.5434219  0.5427206
 0.5420485  0.541477   0.5410454  0.5406903  0.54032314 0.5399005
 0.53936523 0.5387161  0.5380011  0.53724885 0.53655666 0.53593254
 0.53530633 0.53463703 0.53387296 0.53308934 0.5322875  0.53147405
 0.53070486 0.5300588  0.5295283  0.52910477 0.52876985 0.52847874
 0.52818704 0.52790105 0.52763355 0.5273711  0.5271235  0.5269124
 0.52672863 0.5265441  0.5263698  0.52621335 0.5260305  0.5258098
 0.5255392  0.52523273 0.52487695 0.52444905 0.5239925  0.52351296
 0.5230315  0.5225523  0.5221067  0.5216486  0.52115804 0.52058685
 0.51999307 0.51942915 0.5189049  0.51846975 0.5181182  0.51779425
 0.5174257  0.5169342  0.5162183  0.51523805 0.51401675 0.5126038
 0.51109    0.5096527  0.5083434  0.5071088  0.5058877  0.5046928
 0.5035355  0.5023569  0.50115407 0.49997705 0.49891979 0.4980123
 0.4972492  0.4965291  0.4958265  0.49509937 0.49434966 0.49356604
 0.4927768  0.4920382  0.4913784  0.49076357 0.49020225 0.48961985
 0.48897085 0.48819286 0.48738077 0.48659828 0.48588493 0.4852695
 0.4847193  0.4841328  0.48342064 0.48258653 0.4817142  0.48088855
 0.48017314 0.47960886 0.47912955 0.47866386 0.47808483 0.47739574
 0.47658274 0.47575396 0.47499856 0.47436157 0.47383398 0.47328356
 0.47261217 0.47174957 0.47074524 0.46969748 0.4687281  0.46793646
 0.46740967 0.46710193 0.4668086  0.46639574 0.4658034  0.46510947
 0.4643615  0.46368384 0.46316656 0.46290252 0.46277487 0.4626192
 0.46236563 0.46196386 0.46150702 0.461099   0.46074095 0.4605427
 0.46047825 0.46050066 0.4604626  0.46024936 0.45982963 0.45927367
 0.45871416 0.45828518 0.4580158  0.45785844 0.45767137 0.45736393
 0.45686412 0.45618498 0.45552927 0.455035   0.45477322 0.45469052
 0.45462382 0.4543982  0.45383036 0.4528013  0.45141238 0.44976142
 0.44808593 0.446641   0.44536793 0.4440924  0.44273916 0.44125235
 0.4396953  0.4381453  0.43672797 0.43552282 0.43454444 0.4336886
 0.4328239  0.43188983 0.4308088  0.42969963 0.42866293 0.42784584
 0.42719397 0.42657694 0.42591456 0.42517585 0.4242942  0.42333323
 0.42235893 0.42127112 0.4202421  0.41934144 0.4185182  0.41768122
 0.41683796 0.41591835 0.41500193 0.41403928 0.413079   0.41209772
 0.411121   0.41022745 0.40932715 0.40844324 0.4075996  0.4068957
 0.40634245 0.40593478 0.40562165 0.40527228 0.40475944 0.4040742
 0.40323707 0.40235224 0.40164396 0.4013657  0.40136608 0.40148816
 0.4016287  0.40162173 0.40135413 0.4009058  0.40045267 0.40022713
 0.40019226 0.4004044  0.40061772 0.40064555 0.40040228 0.39986807
 0.39931235 0.39889202 0.3987975  0.39897937 0.3991916  0.39927244
 0.3991351  0.39881554 0.39844668 0.39809138 0.39790523 0.3980013
 0.39818057 0.398273   0.39812678 0.3977777  0.3972597  0.39675373
 0.3963685  0.39618316 0.39623103 0.3963862  0.39644146 0.39631113
 0.39591333 0.39533022 0.3947156  0.3941806  0.39365417 0.39306122
 0.3922583  0.39129245 0.390057   0.3885986  0.38719168 0.38615438
 0.38560542 0.38544548 0.3854223  0.38509345 0.3843717  0.38335407
 0.3823022  0.38151145 0.38126436 0.38152134 0.38189995 0.38199252
 0.38162544 0.380673   0.37941962 0.37848675 0.37828478 0.3789345
 0.37995973 0.38073093 0.38062832 0.3795247  0.37774688 0.37597114
 0.37499    0.37514916 0.376097   0.37708881 0.37734476 0.37646
 0.37460643 0.37268746 0.37186152 0.37269318 0.3746931  0.37664306
 0.3773177  0.37616965 0.3737472  0.37211528 0.37464657 0.38207456]
