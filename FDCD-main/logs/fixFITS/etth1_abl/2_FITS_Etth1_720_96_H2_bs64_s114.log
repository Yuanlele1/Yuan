Args in experiment:
Namespace(H_order=2, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=72, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H2_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=72, out_features=81, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  5225472.0
params:  5913.0
Trainable parameters:  5913
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 4.92305064201355
Epoch: 1, Steps: 61 | Train Loss: 0.6496803 Vali Loss: 1.4961292 Test Loss: 0.8279119
Validation loss decreased (inf --> 1.496129).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.721916675567627
Epoch: 2, Steps: 61 | Train Loss: 0.5345614 Vali Loss: 1.3508036 Test Loss: 0.7684982
Validation loss decreased (1.496129 --> 1.350804).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 4.9215569496154785
Epoch: 3, Steps: 61 | Train Loss: 0.4646939 Vali Loss: 1.2699476 Test Loss: 0.7377079
Validation loss decreased (1.350804 --> 1.269948).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 4.7450525760650635
Epoch: 4, Steps: 61 | Train Loss: 0.4194395 Vali Loss: 1.2305058 Test Loss: 0.7252228
Validation loss decreased (1.269948 --> 1.230506).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 4.54462194442749
Epoch: 5, Steps: 61 | Train Loss: 0.3876293 Vali Loss: 1.2058384 Test Loss: 0.7167596
Validation loss decreased (1.230506 --> 1.205838).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 4.948585748672485
Epoch: 6, Steps: 61 | Train Loss: 0.3631482 Vali Loss: 1.1960421 Test Loss: 0.7127947
Validation loss decreased (1.205838 --> 1.196042).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 4.8435328006744385
Epoch: 7, Steps: 61 | Train Loss: 0.3432165 Vali Loss: 1.1741254 Test Loss: 0.7062197
Validation loss decreased (1.196042 --> 1.174125).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 4.528167724609375
Epoch: 8, Steps: 61 | Train Loss: 0.3264568 Vali Loss: 1.1577402 Test Loss: 0.6968495
Validation loss decreased (1.174125 --> 1.157740).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 4.493698835372925
Epoch: 9, Steps: 61 | Train Loss: 0.3118428 Vali Loss: 1.1335816 Test Loss: 0.6879770
Validation loss decreased (1.157740 --> 1.133582).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 4.545459270477295
Epoch: 10, Steps: 61 | Train Loss: 0.2988852 Vali Loss: 1.1208296 Test Loss: 0.6792100
Validation loss decreased (1.133582 --> 1.120830).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 4.651618719100952
Epoch: 11, Steps: 61 | Train Loss: 0.2874863 Vali Loss: 1.1029962 Test Loss: 0.6687514
Validation loss decreased (1.120830 --> 1.102996).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 4.396365404129028
Epoch: 12, Steps: 61 | Train Loss: 0.2772781 Vali Loss: 1.0858477 Test Loss: 0.6612808
Validation loss decreased (1.102996 --> 1.085848).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 4.425633192062378
Epoch: 13, Steps: 61 | Train Loss: 0.2680012 Vali Loss: 1.0720366 Test Loss: 0.6531339
Validation loss decreased (1.085848 --> 1.072037).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 4.705198287963867
Epoch: 14, Steps: 61 | Train Loss: 0.2595868 Vali Loss: 1.0643846 Test Loss: 0.6454052
Validation loss decreased (1.072037 --> 1.064385).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 4.375352382659912
Epoch: 15, Steps: 61 | Train Loss: 0.2519202 Vali Loss: 1.0495205 Test Loss: 0.6357308
Validation loss decreased (1.064385 --> 1.049520).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 4.999230146408081
Epoch: 16, Steps: 61 | Train Loss: 0.2449586 Vali Loss: 1.0366155 Test Loss: 0.6286765
Validation loss decreased (1.049520 --> 1.036615).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 5.5024988651275635
Epoch: 17, Steps: 61 | Train Loss: 0.2385385 Vali Loss: 1.0220624 Test Loss: 0.6203357
Validation loss decreased (1.036615 --> 1.022062).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 5.031270742416382
Epoch: 18, Steps: 61 | Train Loss: 0.2326904 Vali Loss: 1.0124123 Test Loss: 0.6133041
Validation loss decreased (1.022062 --> 1.012412).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 5.898136138916016
Epoch: 19, Steps: 61 | Train Loss: 0.2272673 Vali Loss: 1.0028375 Test Loss: 0.6064753
Validation loss decreased (1.012412 --> 1.002838).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.9405388832092285
Epoch: 20, Steps: 61 | Train Loss: 0.2223017 Vali Loss: 0.9947646 Test Loss: 0.6007106
Validation loss decreased (1.002838 --> 0.994765).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 5.372705936431885
Epoch: 21, Steps: 61 | Train Loss: 0.2177199 Vali Loss: 0.9827841 Test Loss: 0.5942808
Validation loss decreased (0.994765 --> 0.982784).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 5.726132392883301
Epoch: 22, Steps: 61 | Train Loss: 0.2134795 Vali Loss: 0.9780194 Test Loss: 0.5893127
Validation loss decreased (0.982784 --> 0.978019).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 4.993593692779541
Epoch: 23, Steps: 61 | Train Loss: 0.2095860 Vali Loss: 0.9671827 Test Loss: 0.5837123
Validation loss decreased (0.978019 --> 0.967183).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 4.32559609413147
Epoch: 24, Steps: 61 | Train Loss: 0.2058250 Vali Loss: 0.9629735 Test Loss: 0.5789806
Validation loss decreased (0.967183 --> 0.962973).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 5.0284435749053955
Epoch: 25, Steps: 61 | Train Loss: 0.2025019 Vali Loss: 0.9531944 Test Loss: 0.5742171
Validation loss decreased (0.962973 --> 0.953194).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 4.9455626010894775
Epoch: 26, Steps: 61 | Train Loss: 0.1993753 Vali Loss: 0.9478006 Test Loss: 0.5697955
Validation loss decreased (0.953194 --> 0.947801).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 4.650141477584839
Epoch: 27, Steps: 61 | Train Loss: 0.1963911 Vali Loss: 0.9416720 Test Loss: 0.5661792
Validation loss decreased (0.947801 --> 0.941672).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 4.572342872619629
Epoch: 28, Steps: 61 | Train Loss: 0.1936402 Vali Loss: 0.9369184 Test Loss: 0.5623109
Validation loss decreased (0.941672 --> 0.936918).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 5.29594612121582
Epoch: 29, Steps: 61 | Train Loss: 0.1911318 Vali Loss: 0.9335360 Test Loss: 0.5585755
Validation loss decreased (0.936918 --> 0.933536).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 5.182279348373413
Epoch: 30, Steps: 61 | Train Loss: 0.1887328 Vali Loss: 0.9223298 Test Loss: 0.5556170
Validation loss decreased (0.933536 --> 0.922330).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 4.617985725402832
Epoch: 31, Steps: 61 | Train Loss: 0.1865063 Vali Loss: 0.9203705 Test Loss: 0.5517898
Validation loss decreased (0.922330 --> 0.920370).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 5.12775731086731
Epoch: 32, Steps: 61 | Train Loss: 0.1843978 Vali Loss: 0.9190522 Test Loss: 0.5489982
Validation loss decreased (0.920370 --> 0.919052).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 4.951724290847778
Epoch: 33, Steps: 61 | Train Loss: 0.1823839 Vali Loss: 0.9151204 Test Loss: 0.5462636
Validation loss decreased (0.919052 --> 0.915120).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 4.679099082946777
Epoch: 34, Steps: 61 | Train Loss: 0.1805997 Vali Loss: 0.9080417 Test Loss: 0.5433497
Validation loss decreased (0.915120 --> 0.908042).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 4.77505350112915
Epoch: 35, Steps: 61 | Train Loss: 0.1788523 Vali Loss: 0.9070284 Test Loss: 0.5411365
Validation loss decreased (0.908042 --> 0.907028).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 5.062053442001343
Epoch: 36, Steps: 61 | Train Loss: 0.1772629 Vali Loss: 0.9002318 Test Loss: 0.5389255
Validation loss decreased (0.907028 --> 0.900232).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 4.747186899185181
Epoch: 37, Steps: 61 | Train Loss: 0.1757067 Vali Loss: 0.9016871 Test Loss: 0.5364922
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 4.383776426315308
Epoch: 38, Steps: 61 | Train Loss: 0.1742493 Vali Loss: 0.8935273 Test Loss: 0.5344244
Validation loss decreased (0.900232 --> 0.893527).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 5.0755884647369385
Epoch: 39, Steps: 61 | Train Loss: 0.1729102 Vali Loss: 0.8925367 Test Loss: 0.5322785
Validation loss decreased (0.893527 --> 0.892537).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 4.865569829940796
Epoch: 40, Steps: 61 | Train Loss: 0.1716684 Vali Loss: 0.8899710 Test Loss: 0.5304056
Validation loss decreased (0.892537 --> 0.889971).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 5.464587450027466
Epoch: 41, Steps: 61 | Train Loss: 0.1704422 Vali Loss: 0.8894709 Test Loss: 0.5285060
Validation loss decreased (0.889971 --> 0.889471).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 4.360717296600342
Epoch: 42, Steps: 61 | Train Loss: 0.1692661 Vali Loss: 0.8846197 Test Loss: 0.5268102
Validation loss decreased (0.889471 --> 0.884620).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 4.390478849411011
Epoch: 43, Steps: 61 | Train Loss: 0.1682120 Vali Loss: 0.8863701 Test Loss: 0.5252411
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 4.9565589427948
Epoch: 44, Steps: 61 | Train Loss: 0.1671644 Vali Loss: 0.8844246 Test Loss: 0.5240290
Validation loss decreased (0.884620 --> 0.884425).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 4.851305961608887
Epoch: 45, Steps: 61 | Train Loss: 0.1662270 Vali Loss: 0.8794471 Test Loss: 0.5223628
Validation loss decreased (0.884425 --> 0.879447).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 4.40697717666626
Epoch: 46, Steps: 61 | Train Loss: 0.1652833 Vali Loss: 0.8778463 Test Loss: 0.5210704
Validation loss decreased (0.879447 --> 0.877846).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 4.990006923675537
Epoch: 47, Steps: 61 | Train Loss: 0.1644825 Vali Loss: 0.8723342 Test Loss: 0.5194439
Validation loss decreased (0.877846 --> 0.872334).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 4.816723108291626
Epoch: 48, Steps: 61 | Train Loss: 0.1636063 Vali Loss: 0.8743258 Test Loss: 0.5185549
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 4.655114412307739
Epoch: 49, Steps: 61 | Train Loss: 0.1628995 Vali Loss: 0.8757650 Test Loss: 0.5173007
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 4.676299810409546
Epoch: 50, Steps: 61 | Train Loss: 0.1621673 Vali Loss: 0.8687971 Test Loss: 0.5162402
Validation loss decreased (0.872334 --> 0.868797).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 4.782583236694336
Epoch: 51, Steps: 61 | Train Loss: 0.1614457 Vali Loss: 0.8686098 Test Loss: 0.5150231
Validation loss decreased (0.868797 --> 0.868610).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 4.655120611190796
Epoch: 52, Steps: 61 | Train Loss: 0.1608475 Vali Loss: 0.8649147 Test Loss: 0.5140045
Validation loss decreased (0.868610 --> 0.864915).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 4.839003801345825
Epoch: 53, Steps: 61 | Train Loss: 0.1601803 Vali Loss: 0.8704144 Test Loss: 0.5133390
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 4.679081201553345
Epoch: 54, Steps: 61 | Train Loss: 0.1596532 Vali Loss: 0.8680203 Test Loss: 0.5124879
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 4.524932384490967
Epoch: 55, Steps: 61 | Train Loss: 0.1590874 Vali Loss: 0.8611041 Test Loss: 0.5114629
Validation loss decreased (0.864915 --> 0.861104).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 4.628206491470337
Epoch: 56, Steps: 61 | Train Loss: 0.1585688 Vali Loss: 0.8646002 Test Loss: 0.5108168
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 4.725208520889282
Epoch: 57, Steps: 61 | Train Loss: 0.1580099 Vali Loss: 0.8599698 Test Loss: 0.5099620
Validation loss decreased (0.861104 --> 0.859970).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 4.286042213439941
Epoch: 58, Steps: 61 | Train Loss: 0.1576215 Vali Loss: 0.8619865 Test Loss: 0.5092721
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 4.796634674072266
Epoch: 59, Steps: 61 | Train Loss: 0.1571290 Vali Loss: 0.8620197 Test Loss: 0.5085572
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 4.818792819976807
Epoch: 60, Steps: 61 | Train Loss: 0.1566837 Vali Loss: 0.8618112 Test Loss: 0.5079286
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 4.542297124862671
Epoch: 61, Steps: 61 | Train Loss: 0.1563118 Vali Loss: 0.8570747 Test Loss: 0.5072374
Validation loss decreased (0.859970 --> 0.857075).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 4.666303873062134
Epoch: 62, Steps: 61 | Train Loss: 0.1558893 Vali Loss: 0.8577940 Test Loss: 0.5066635
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 5.161851644515991
Epoch: 63, Steps: 61 | Train Loss: 0.1555473 Vali Loss: 0.8546632 Test Loss: 0.5060683
Validation loss decreased (0.857075 --> 0.854663).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 5.000290632247925
Epoch: 64, Steps: 61 | Train Loss: 0.1551443 Vali Loss: 0.8548421 Test Loss: 0.5055745
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 5.726907014846802
Epoch: 65, Steps: 61 | Train Loss: 0.1548688 Vali Loss: 0.8532056 Test Loss: 0.5051128
Validation loss decreased (0.854663 --> 0.853206).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 4.872797966003418
Epoch: 66, Steps: 61 | Train Loss: 0.1545582 Vali Loss: 0.8570254 Test Loss: 0.5047212
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 4.746210813522339
Epoch: 67, Steps: 61 | Train Loss: 0.1542461 Vali Loss: 0.8534821 Test Loss: 0.5041004
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 5.182185411453247
Epoch: 68, Steps: 61 | Train Loss: 0.1539550 Vali Loss: 0.8545877 Test Loss: 0.5036898
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 5.054067611694336
Epoch: 69, Steps: 61 | Train Loss: 0.1536901 Vali Loss: 0.8544170 Test Loss: 0.5032602
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 4.880742311477661
Epoch: 70, Steps: 61 | Train Loss: 0.1534385 Vali Loss: 0.8526179 Test Loss: 0.5028523
Validation loss decreased (0.853206 --> 0.852618).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 4.944001913070679
Epoch: 71, Steps: 61 | Train Loss: 0.1532307 Vali Loss: 0.8496961 Test Loss: 0.5025069
Validation loss decreased (0.852618 --> 0.849696).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 5.261040925979614
Epoch: 72, Steps: 61 | Train Loss: 0.1529781 Vali Loss: 0.8533084 Test Loss: 0.5021350
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 5.020665407180786
Epoch: 73, Steps: 61 | Train Loss: 0.1526929 Vali Loss: 0.8494129 Test Loss: 0.5018688
Validation loss decreased (0.849696 --> 0.849413).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 5.751716375350952
Epoch: 74, Steps: 61 | Train Loss: 0.1525198 Vali Loss: 0.8526528 Test Loss: 0.5014743
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 4.488698244094849
Epoch: 75, Steps: 61 | Train Loss: 0.1522873 Vali Loss: 0.8511305 Test Loss: 0.5012028
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 4.533964157104492
Epoch: 76, Steps: 61 | Train Loss: 0.1520923 Vali Loss: 0.8491006 Test Loss: 0.5008873
Validation loss decreased (0.849413 --> 0.849101).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 4.613102912902832
Epoch: 77, Steps: 61 | Train Loss: 0.1519397 Vali Loss: 0.8521070 Test Loss: 0.5006023
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 5.011872053146362
Epoch: 78, Steps: 61 | Train Loss: 0.1517349 Vali Loss: 0.8487799 Test Loss: 0.5003963
Validation loss decreased (0.849101 --> 0.848780).  Saving model ...
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 4.6956281661987305
Epoch: 79, Steps: 61 | Train Loss: 0.1515969 Vali Loss: 0.8452753 Test Loss: 0.5001738
Validation loss decreased (0.848780 --> 0.845275).  Saving model ...
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 4.530719995498657
Epoch: 80, Steps: 61 | Train Loss: 0.1514474 Vali Loss: 0.8484305 Test Loss: 0.4998946
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 4.668769598007202
Epoch: 81, Steps: 61 | Train Loss: 0.1512983 Vali Loss: 0.8470967 Test Loss: 0.4996473
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 4.5233142375946045
Epoch: 82, Steps: 61 | Train Loss: 0.1511541 Vali Loss: 0.8503098 Test Loss: 0.4994914
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 4.342676639556885
Epoch: 83, Steps: 61 | Train Loss: 0.1510520 Vali Loss: 0.8483958 Test Loss: 0.4992519
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 4.379926919937134
Epoch: 84, Steps: 61 | Train Loss: 0.1509534 Vali Loss: 0.8501900 Test Loss: 0.4990783
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 4.92531156539917
Epoch: 85, Steps: 61 | Train Loss: 0.1507833 Vali Loss: 0.8449543 Test Loss: 0.4988490
Validation loss decreased (0.845275 --> 0.844954).  Saving model ...
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 5.329264402389526
Epoch: 86, Steps: 61 | Train Loss: 0.1507047 Vali Loss: 0.8456990 Test Loss: 0.4987277
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 4.498600482940674
Epoch: 87, Steps: 61 | Train Loss: 0.1505891 Vali Loss: 0.8503526 Test Loss: 0.4985321
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 4.897487640380859
Epoch: 88, Steps: 61 | Train Loss: 0.1504378 Vali Loss: 0.8485065 Test Loss: 0.4983876
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 5.027862787246704
Epoch: 89, Steps: 61 | Train Loss: 0.1503938 Vali Loss: 0.8465547 Test Loss: 0.4982188
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 4.734074354171753
Epoch: 90, Steps: 61 | Train Loss: 0.1502537 Vali Loss: 0.8454084 Test Loss: 0.4980657
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 4.266961097717285
Epoch: 91, Steps: 61 | Train Loss: 0.1502091 Vali Loss: 0.8440598 Test Loss: 0.4979480
Validation loss decreased (0.844954 --> 0.844060).  Saving model ...
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 4.113713026046753
Epoch: 92, Steps: 61 | Train Loss: 0.1500995 Vali Loss: 0.8467938 Test Loss: 0.4977974
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 4.943553447723389
Epoch: 93, Steps: 61 | Train Loss: 0.1500532 Vali Loss: 0.8450250 Test Loss: 0.4976943
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 4.955000877380371
Epoch: 94, Steps: 61 | Train Loss: 0.1499521 Vali Loss: 0.8418385 Test Loss: 0.4975743
Validation loss decreased (0.844060 --> 0.841839).  Saving model ...
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 4.856832981109619
Epoch: 95, Steps: 61 | Train Loss: 0.1498877 Vali Loss: 0.8445117 Test Loss: 0.4974973
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 5.316147089004517
Epoch: 96, Steps: 61 | Train Loss: 0.1497998 Vali Loss: 0.8430187 Test Loss: 0.4973890
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 4.6220009326934814
Epoch: 97, Steps: 61 | Train Loss: 0.1497387 Vali Loss: 0.8410542 Test Loss: 0.4972422
Validation loss decreased (0.841839 --> 0.841054).  Saving model ...
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 4.183980941772461
Epoch: 98, Steps: 61 | Train Loss: 0.1496395 Vali Loss: 0.8442855 Test Loss: 0.4971831
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 4.7424211502075195
Epoch: 99, Steps: 61 | Train Loss: 0.1496380 Vali Loss: 0.8481437 Test Loss: 0.4970974
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 4.491555452346802
Epoch: 100, Steps: 61 | Train Loss: 0.1495210 Vali Loss: 0.8440165 Test Loss: 0.4970097
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.1160680107021042e-06
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=72, out_features=81, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  5225472.0
params:  5913.0
Trainable parameters:  5913
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 4.639690399169922
Epoch: 1, Steps: 61 | Train Loss: 0.3746253 Vali Loss: 0.7227224 Test Loss: 0.4107271
Validation loss decreased (inf --> 0.722722).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.1458420753479
Epoch: 2, Steps: 61 | Train Loss: 0.3538011 Vali Loss: 0.7114753 Test Loss: 0.4046566
Validation loss decreased (0.722722 --> 0.711475).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 4.148716688156128
Epoch: 3, Steps: 61 | Train Loss: 0.3511398 Vali Loss: 0.7136202 Test Loss: 0.4049235
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
Epoch: 4 cost time: 5.496243953704834
Epoch: 4, Steps: 61 | Train Loss: 0.3500681 Vali Loss: 0.7112752 Test Loss: 0.4043770
Validation loss decreased (0.711475 --> 0.711275).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 4.894519329071045
Epoch: 5, Steps: 61 | Train Loss: 0.3493970 Vali Loss: 0.7119091 Test Loss: 0.4037904
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 4.250878572463989
Epoch: 6, Steps: 61 | Train Loss: 0.3488528 Vali Loss: 0.7127715 Test Loss: 0.4038890
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 4.840910196304321
Epoch: 7, Steps: 61 | Train Loss: 0.3484699 Vali Loss: 0.7104551 Test Loss: 0.4038223
Validation loss decreased (0.711275 --> 0.710455).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 4.505288362503052
Epoch: 8, Steps: 61 | Train Loss: 0.3480918 Vali Loss: 0.7091781 Test Loss: 0.4040822
Validation loss decreased (0.710455 --> 0.709178).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 4.82177734375
Epoch: 9, Steps: 61 | Train Loss: 0.3476824 Vali Loss: 0.7093981 Test Loss: 0.4040365
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 4.3423333168029785
Epoch: 10, Steps: 61 | Train Loss: 0.3476714 Vali Loss: 0.7097844 Test Loss: 0.4039367
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 4.69599723815918
Epoch: 11, Steps: 61 | Train Loss: 0.3475000 Vali Loss: 0.7091436 Test Loss: 0.4037719
Validation loss decreased (0.709178 --> 0.709144).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 5.173768997192383
Epoch: 12, Steps: 61 | Train Loss: 0.3473610 Vali Loss: 0.7112958 Test Loss: 0.4036362
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 4.785492420196533
Epoch: 13, Steps: 61 | Train Loss: 0.3472903 Vali Loss: 0.7124440 Test Loss: 0.4036005
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 4.648941993713379
Epoch: 14, Steps: 61 | Train Loss: 0.3472764 Vali Loss: 0.7079355 Test Loss: 0.4040169
Validation loss decreased (0.709144 --> 0.707936).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 4.583014488220215
Epoch: 15, Steps: 61 | Train Loss: 0.3468707 Vali Loss: 0.7100909 Test Loss: 0.4039035
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 4.84786581993103
Epoch: 16, Steps: 61 | Train Loss: 0.3468841 Vali Loss: 0.7113342 Test Loss: 0.4038169
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 4.672327756881714
Epoch: 17, Steps: 61 | Train Loss: 0.3469540 Vali Loss: 0.7098398 Test Loss: 0.4034802
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 4.8003551959991455
Epoch: 18, Steps: 61 | Train Loss: 0.3468899 Vali Loss: 0.7039765 Test Loss: 0.4039355
Validation loss decreased (0.707936 --> 0.703977).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 4.671361207962036
Epoch: 19, Steps: 61 | Train Loss: 0.3466571 Vali Loss: 0.7086492 Test Loss: 0.4036665
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.880955934524536
Epoch: 20, Steps: 61 | Train Loss: 0.3467740 Vali Loss: 0.7111188 Test Loss: 0.4035317
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 4.517861604690552
Epoch: 21, Steps: 61 | Train Loss: 0.3466967 Vali Loss: 0.7098623 Test Loss: 0.4038382
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 4.4982054233551025
Epoch: 22, Steps: 61 | Train Loss: 0.3465831 Vali Loss: 0.7104513 Test Loss: 0.4037987
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 4.537573337554932
Epoch: 23, Steps: 61 | Train Loss: 0.3466787 Vali Loss: 0.7109679 Test Loss: 0.4035466
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 4.607794523239136
Epoch: 24, Steps: 61 | Train Loss: 0.3461848 Vali Loss: 0.7111763 Test Loss: 0.4036812
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 4.159996271133423
Epoch: 25, Steps: 61 | Train Loss: 0.3466104 Vali Loss: 0.7103564 Test Loss: 0.4037063
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 4.550787925720215
Epoch: 26, Steps: 61 | Train Loss: 0.3464501 Vali Loss: 0.7066000 Test Loss: 0.4033379
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 5.0014026165008545
Epoch: 27, Steps: 61 | Train Loss: 0.3463921 Vali Loss: 0.7098593 Test Loss: 0.4034930
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 4.4533751010894775
Epoch: 28, Steps: 61 | Train Loss: 0.3464528 Vali Loss: 0.7074221 Test Loss: 0.4035592
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 4.232589483261108
Epoch: 29, Steps: 61 | Train Loss: 0.3462687 Vali Loss: 0.7092740 Test Loss: 0.4037348
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 4.583941459655762
Epoch: 30, Steps: 61 | Train Loss: 0.3462740 Vali Loss: 0.7088631 Test Loss: 0.4036072
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 4.684520244598389
Epoch: 31, Steps: 61 | Train Loss: 0.3461425 Vali Loss: 0.7088434 Test Loss: 0.4036918
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 4.454739332199097
Epoch: 32, Steps: 61 | Train Loss: 0.3462495 Vali Loss: 0.7037194 Test Loss: 0.4036440
Validation loss decreased (0.703977 --> 0.703719).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 4.345571994781494
Epoch: 33, Steps: 61 | Train Loss: 0.3460885 Vali Loss: 0.7112356 Test Loss: 0.4035394
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 4.492973327636719
Epoch: 34, Steps: 61 | Train Loss: 0.3459671 Vali Loss: 0.7093515 Test Loss: 0.4034453
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 4.544871807098389
Epoch: 35, Steps: 61 | Train Loss: 0.3461794 Vali Loss: 0.7136039 Test Loss: 0.4035900
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 4.1695396900177
Epoch: 36, Steps: 61 | Train Loss: 0.3461704 Vali Loss: 0.7108833 Test Loss: 0.4036132
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 4.877666234970093
Epoch: 37, Steps: 61 | Train Loss: 0.3461498 Vali Loss: 0.7106933 Test Loss: 0.4036883
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 4.962300777435303
Epoch: 38, Steps: 61 | Train Loss: 0.3460508 Vali Loss: 0.7078260 Test Loss: 0.4035101
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 4.142649412155151
Epoch: 39, Steps: 61 | Train Loss: 0.3459973 Vali Loss: 0.7053733 Test Loss: 0.4035403
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 4.109431982040405
Epoch: 40, Steps: 61 | Train Loss: 0.3459375 Vali Loss: 0.7095066 Test Loss: 0.4035005
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 4.331128358840942
Epoch: 41, Steps: 61 | Train Loss: 0.3460019 Vali Loss: 0.7064206 Test Loss: 0.4035903
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 4.568168640136719
Epoch: 42, Steps: 61 | Train Loss: 0.3459034 Vali Loss: 0.7069570 Test Loss: 0.4036312
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 4.091572999954224
Epoch: 43, Steps: 61 | Train Loss: 0.3458988 Vali Loss: 0.7082766 Test Loss: 0.4036108
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 4.238292932510376
Epoch: 44, Steps: 61 | Train Loss: 0.3460007 Vali Loss: 0.7055896 Test Loss: 0.4036097
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 4.077717065811157
Epoch: 45, Steps: 61 | Train Loss: 0.3460504 Vali Loss: 0.7094166 Test Loss: 0.4036016
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 4.236279010772705
Epoch: 46, Steps: 61 | Train Loss: 0.3460977 Vali Loss: 0.7118708 Test Loss: 0.4035499
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 3.8229892253875732
Epoch: 47, Steps: 61 | Train Loss: 0.3459640 Vali Loss: 0.7120963 Test Loss: 0.4034817
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 4.230075120925903
Epoch: 48, Steps: 61 | Train Loss: 0.3460699 Vali Loss: 0.7097580 Test Loss: 0.4035327
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 4.276793003082275
Epoch: 49, Steps: 61 | Train Loss: 0.3459113 Vali Loss: 0.7059023 Test Loss: 0.4036228
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 4.332969903945923
Epoch: 50, Steps: 61 | Train Loss: 0.3459933 Vali Loss: 0.7102311 Test Loss: 0.4035075
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 4.151049613952637
Epoch: 51, Steps: 61 | Train Loss: 0.3459060 Vali Loss: 0.7088137 Test Loss: 0.4035775
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 4.220247030258179
Epoch: 52, Steps: 61 | Train Loss: 0.3459419 Vali Loss: 0.7112161 Test Loss: 0.4035993
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H2_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.40330690145492554, mae:0.42511558532714844, rse:0.6032199263572693, corr:[0.27306807 0.2758487  0.27642918 0.27491206 0.27240056 0.2701708
 0.26869586 0.26797676 0.26764017 0.267657   0.26787418 0.26805514
 0.2681599  0.26818523 0.26820502 0.26819775 0.26795948 0.2675907
 0.26717883 0.26680917 0.2666162  0.26678613 0.2669155  0.26698893
 0.26686367 0.26658365 0.2661313  0.26552463 0.26489362 0.26437712
 0.26413998 0.26404735 0.26409483 0.2641907  0.26416606 0.26409137
 0.26408598 0.26412097 0.26416072 0.26417294 0.26426968 0.26434645
 0.26436037 0.26434374 0.26438868 0.2645034  0.26454467 0.2643091
 0.26341996 0.26226228 0.26088026 0.25957045 0.25852802 0.25772113
 0.25720927 0.25698468 0.25683737 0.2567679  0.25657272 0.2562869
 0.2559227  0.25561652 0.25547302 0.255602   0.25585514 0.25609177
 0.25626707 0.25615004 0.255788   0.25533432 0.254879   0.25431162
 0.253726   0.25315    0.25255442 0.2521204  0.25176328 0.25130075
 0.2507207  0.25006878 0.24934049 0.248615   0.24792022 0.24734628
 0.24712476 0.2471995  0.24742885 0.2474886  0.24725717 0.24681415
 0.24626689 0.24583218 0.24588796 0.24685425 0.2485964  0.24949123]
