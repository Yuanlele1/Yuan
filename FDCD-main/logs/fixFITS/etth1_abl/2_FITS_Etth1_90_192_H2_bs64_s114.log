Args in experiment:
Namespace(H_order=2, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=18, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_90_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_90_192_FITS_ETTh1_ftM_sl90_ll48_pl192_H2_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8359
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=18, out_features=56, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  903168.0
params:  1064.0
Trainable parameters:  1064
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.0781424045562744
Epoch: 1, Steps: 65 | Train Loss: 0.8475641 Vali Loss: 1.8094032 Test Loss: 1.0763183
Validation loss decreased (inf --> 1.809403).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.0037200450897217
Epoch: 2, Steps: 65 | Train Loss: 0.6777651 Vali Loss: 1.5618123 Test Loss: 0.8725359
Validation loss decreased (1.809403 --> 1.561812).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.0087196826934814
Epoch: 3, Steps: 65 | Train Loss: 0.5690492 Vali Loss: 1.4090497 Test Loss: 0.7462923
Validation loss decreased (1.561812 --> 1.409050).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.0636041164398193
Epoch: 4, Steps: 65 | Train Loss: 0.4984390 Vali Loss: 1.3076899 Test Loss: 0.6643133
Validation loss decreased (1.409050 --> 1.307690).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.1558763980865479
Epoch: 5, Steps: 65 | Train Loss: 0.4514065 Vali Loss: 1.2399507 Test Loss: 0.6091199
Validation loss decreased (1.307690 --> 1.239951).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.0311427116394043
Epoch: 6, Steps: 65 | Train Loss: 0.4179945 Vali Loss: 1.1925364 Test Loss: 0.5709454
Validation loss decreased (1.239951 --> 1.192536).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.0250158309936523
Epoch: 7, Steps: 65 | Train Loss: 0.3946903 Vali Loss: 1.1585996 Test Loss: 0.5438985
Validation loss decreased (1.192536 --> 1.158600).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 0.992659330368042
Epoch: 8, Steps: 65 | Train Loss: 0.3774761 Vali Loss: 1.1329664 Test Loss: 0.5241073
Validation loss decreased (1.158600 --> 1.132966).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.0212414264678955
Epoch: 9, Steps: 65 | Train Loss: 0.3645221 Vali Loss: 1.1133153 Test Loss: 0.5089910
Validation loss decreased (1.132966 --> 1.113315).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 0.9881699085235596
Epoch: 10, Steps: 65 | Train Loss: 0.3548065 Vali Loss: 1.0978754 Test Loss: 0.4976439
Validation loss decreased (1.113315 --> 1.097875).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.0422978401184082
Epoch: 11, Steps: 65 | Train Loss: 0.3474700 Vali Loss: 1.0854005 Test Loss: 0.4887877
Validation loss decreased (1.097875 --> 1.085400).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.0306265354156494
Epoch: 12, Steps: 65 | Train Loss: 0.3412525 Vali Loss: 1.0766313 Test Loss: 0.4820146
Validation loss decreased (1.085400 --> 1.076631).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.1020381450653076
Epoch: 13, Steps: 65 | Train Loss: 0.3366688 Vali Loss: 1.0684514 Test Loss: 0.4764260
Validation loss decreased (1.076631 --> 1.068451).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.1614723205566406
Epoch: 14, Steps: 65 | Train Loss: 0.3324863 Vali Loss: 1.0623144 Test Loss: 0.4720131
Validation loss decreased (1.068451 --> 1.062314).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.061471700668335
Epoch: 15, Steps: 65 | Train Loss: 0.3295988 Vali Loss: 1.0569129 Test Loss: 0.4684558
Validation loss decreased (1.062314 --> 1.056913).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.1067862510681152
Epoch: 16, Steps: 65 | Train Loss: 0.3268784 Vali Loss: 1.0523096 Test Loss: 0.4654762
Validation loss decreased (1.056913 --> 1.052310).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.0454378128051758
Epoch: 17, Steps: 65 | Train Loss: 0.3245777 Vali Loss: 1.0484928 Test Loss: 0.4631270
Validation loss decreased (1.052310 --> 1.048493).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.0502128601074219
Epoch: 18, Steps: 65 | Train Loss: 0.3227951 Vali Loss: 1.0447359 Test Loss: 0.4610027
Validation loss decreased (1.048493 --> 1.044736).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.0972471237182617
Epoch: 19, Steps: 65 | Train Loss: 0.3209307 Vali Loss: 1.0421946 Test Loss: 0.4592460
Validation loss decreased (1.044736 --> 1.042195).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 0.9661991596221924
Epoch: 20, Steps: 65 | Train Loss: 0.3196601 Vali Loss: 1.0396004 Test Loss: 0.4577691
Validation loss decreased (1.042195 --> 1.039600).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.0576777458190918
Epoch: 21, Steps: 65 | Train Loss: 0.3182946 Vali Loss: 1.0366789 Test Loss: 0.4564949
Validation loss decreased (1.039600 --> 1.036679).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 0.994988203048706
Epoch: 22, Steps: 65 | Train Loss: 0.3175899 Vali Loss: 1.0357002 Test Loss: 0.4554763
Validation loss decreased (1.036679 --> 1.035700).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 0.9631876945495605
Epoch: 23, Steps: 65 | Train Loss: 0.3167443 Vali Loss: 1.0339774 Test Loss: 0.4545475
Validation loss decreased (1.035700 --> 1.033977).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 0.9993276596069336
Epoch: 24, Steps: 65 | Train Loss: 0.3156101 Vali Loss: 1.0325785 Test Loss: 0.4536970
Validation loss decreased (1.033977 --> 1.032578).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.180898666381836
Epoch: 25, Steps: 65 | Train Loss: 0.3148187 Vali Loss: 1.0311188 Test Loss: 0.4529268
Validation loss decreased (1.032578 --> 1.031119).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 0.9648034572601318
Epoch: 26, Steps: 65 | Train Loss: 0.3142151 Vali Loss: 1.0300584 Test Loss: 0.4523641
Validation loss decreased (1.031119 --> 1.030058).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 0.9644734859466553
Epoch: 27, Steps: 65 | Train Loss: 0.3136685 Vali Loss: 1.0290505 Test Loss: 0.4517905
Validation loss decreased (1.030058 --> 1.029050).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.0091888904571533
Epoch: 28, Steps: 65 | Train Loss: 0.3130453 Vali Loss: 1.0280095 Test Loss: 0.4512624
Validation loss decreased (1.029050 --> 1.028010).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 0.9941573143005371
Epoch: 29, Steps: 65 | Train Loss: 0.3125754 Vali Loss: 1.0273000 Test Loss: 0.4508132
Validation loss decreased (1.028010 --> 1.027300).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.0893681049346924
Epoch: 30, Steps: 65 | Train Loss: 0.3121159 Vali Loss: 1.0262170 Test Loss: 0.4503845
Validation loss decreased (1.027300 --> 1.026217).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.0916781425476074
Epoch: 31, Steps: 65 | Train Loss: 0.3117007 Vali Loss: 1.0256222 Test Loss: 0.4500122
Validation loss decreased (1.026217 --> 1.025622).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.1057467460632324
Epoch: 32, Steps: 65 | Train Loss: 0.3113229 Vali Loss: 1.0250145 Test Loss: 0.4496741
Validation loss decreased (1.025622 --> 1.025015).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.0516061782836914
Epoch: 33, Steps: 65 | Train Loss: 0.3113102 Vali Loss: 1.0240268 Test Loss: 0.4493552
Validation loss decreased (1.025015 --> 1.024027).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.1509511470794678
Epoch: 34, Steps: 65 | Train Loss: 0.3104486 Vali Loss: 1.0239278 Test Loss: 0.4490517
Validation loss decreased (1.024027 --> 1.023928).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.0480000972747803
Epoch: 35, Steps: 65 | Train Loss: 0.3104518 Vali Loss: 1.0232160 Test Loss: 0.4488184
Validation loss decreased (1.023928 --> 1.023216).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.0354382991790771
Epoch: 36, Steps: 65 | Train Loss: 0.3101678 Vali Loss: 1.0226042 Test Loss: 0.4485864
Validation loss decreased (1.023216 --> 1.022604).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.2084872722625732
Epoch: 37, Steps: 65 | Train Loss: 0.3100233 Vali Loss: 1.0223593 Test Loss: 0.4483641
Validation loss decreased (1.022604 --> 1.022359).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.0879020690917969
Epoch: 38, Steps: 65 | Train Loss: 0.3097817 Vali Loss: 1.0219449 Test Loss: 0.4481438
Validation loss decreased (1.022359 --> 1.021945).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 0.9846420288085938
Epoch: 39, Steps: 65 | Train Loss: 0.3096433 Vali Loss: 1.0214708 Test Loss: 0.4479564
Validation loss decreased (1.021945 --> 1.021471).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.0626697540283203
Epoch: 40, Steps: 65 | Train Loss: 0.3088638 Vali Loss: 1.0211178 Test Loss: 0.4477928
Validation loss decreased (1.021471 --> 1.021118).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.1285972595214844
Epoch: 41, Steps: 65 | Train Loss: 0.3089299 Vali Loss: 1.0206388 Test Loss: 0.4476215
Validation loss decreased (1.021118 --> 1.020639).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 0.9714255332946777
Epoch: 42, Steps: 65 | Train Loss: 0.3090028 Vali Loss: 1.0206091 Test Loss: 0.4474462
Validation loss decreased (1.020639 --> 1.020609).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.0460131168365479
Epoch: 43, Steps: 65 | Train Loss: 0.3086597 Vali Loss: 1.0203474 Test Loss: 0.4473217
Validation loss decreased (1.020609 --> 1.020347).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 0.9920413494110107
Epoch: 44, Steps: 65 | Train Loss: 0.3086483 Vali Loss: 1.0200990 Test Loss: 0.4472015
Validation loss decreased (1.020347 --> 1.020099).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.168752670288086
Epoch: 45, Steps: 65 | Train Loss: 0.3082708 Vali Loss: 1.0193515 Test Loss: 0.4470964
Validation loss decreased (1.020099 --> 1.019351).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.1077821254730225
Epoch: 46, Steps: 65 | Train Loss: 0.3081939 Vali Loss: 1.0194913 Test Loss: 0.4469635
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.047574520111084
Epoch: 47, Steps: 65 | Train Loss: 0.3080249 Vali Loss: 1.0191050 Test Loss: 0.4468510
Validation loss decreased (1.019351 --> 1.019105).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 0.956416130065918
Epoch: 48, Steps: 65 | Train Loss: 0.3080205 Vali Loss: 1.0186062 Test Loss: 0.4467358
Validation loss decreased (1.019105 --> 1.018606).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.0571329593658447
Epoch: 49, Steps: 65 | Train Loss: 0.3078428 Vali Loss: 1.0188524 Test Loss: 0.4466335
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.0804359912872314
Epoch: 50, Steps: 65 | Train Loss: 0.3075929 Vali Loss: 1.0181215 Test Loss: 0.4465528
Validation loss decreased (1.018606 --> 1.018121).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.1169257164001465
Epoch: 51, Steps: 65 | Train Loss: 0.3076383 Vali Loss: 1.0183818 Test Loss: 0.4464728
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.0441608428955078
Epoch: 52, Steps: 65 | Train Loss: 0.3075382 Vali Loss: 1.0174354 Test Loss: 0.4463814
Validation loss decreased (1.018121 --> 1.017435).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 0.9129056930541992
Epoch: 53, Steps: 65 | Train Loss: 0.3072352 Vali Loss: 1.0177382 Test Loss: 0.4463086
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 0.9816625118255615
Epoch: 54, Steps: 65 | Train Loss: 0.3073473 Vali Loss: 1.0181940 Test Loss: 0.4462120
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.055422306060791
Epoch: 55, Steps: 65 | Train Loss: 0.3073014 Vali Loss: 1.0180480 Test Loss: 0.4461649
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.0231270790100098
Epoch: 56, Steps: 65 | Train Loss: 0.3072702 Vali Loss: 1.0169631 Test Loss: 0.4460910
Validation loss decreased (1.017435 --> 1.016963).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.0309340953826904
Epoch: 57, Steps: 65 | Train Loss: 0.3072181 Vali Loss: 1.0177048 Test Loss: 0.4460390
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.0325021743774414
Epoch: 58, Steps: 65 | Train Loss: 0.3071098 Vali Loss: 1.0166852 Test Loss: 0.4459843
Validation loss decreased (1.016963 --> 1.016685).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 0.8801054954528809
Epoch: 59, Steps: 65 | Train Loss: 0.3070001 Vali Loss: 1.0175140 Test Loss: 0.4459162
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 0.9821035861968994
Epoch: 60, Steps: 65 | Train Loss: 0.3071220 Vali Loss: 1.0173159 Test Loss: 0.4458713
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.1404223442077637
Epoch: 61, Steps: 65 | Train Loss: 0.3069750 Vali Loss: 1.0173235 Test Loss: 0.4458136
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.0961475372314453
Epoch: 62, Steps: 65 | Train Loss: 0.3066000 Vali Loss: 1.0168307 Test Loss: 0.4457649
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 0.9446978569030762
Epoch: 63, Steps: 65 | Train Loss: 0.3067854 Vali Loss: 1.0167437 Test Loss: 0.4457206
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.2388532161712646
Epoch: 64, Steps: 65 | Train Loss: 0.3067649 Vali Loss: 1.0170165 Test Loss: 0.4456849
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.1435375213623047
Epoch: 65, Steps: 65 | Train Loss: 0.3067355 Vali Loss: 1.0170079 Test Loss: 0.4456339
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.1245355606079102
Epoch: 66, Steps: 65 | Train Loss: 0.3066159 Vali Loss: 1.0168989 Test Loss: 0.4456075
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.0507009029388428
Epoch: 67, Steps: 65 | Train Loss: 0.3066398 Vali Loss: 1.0162548 Test Loss: 0.4455700
Validation loss decreased (1.016685 --> 1.016255).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.1267979145050049
Epoch: 68, Steps: 65 | Train Loss: 0.3065120 Vali Loss: 1.0167929 Test Loss: 0.4455364
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.0480482578277588
Epoch: 69, Steps: 65 | Train Loss: 0.3063269 Vali Loss: 1.0163279 Test Loss: 0.4454983
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 0.9428658485412598
Epoch: 70, Steps: 65 | Train Loss: 0.3065626 Vali Loss: 1.0166219 Test Loss: 0.4454628
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.1188690662384033
Epoch: 71, Steps: 65 | Train Loss: 0.3064654 Vali Loss: 1.0155388 Test Loss: 0.4454319
Validation loss decreased (1.016255 --> 1.015539).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 0.9572689533233643
Epoch: 72, Steps: 65 | Train Loss: 0.3063247 Vali Loss: 1.0162631 Test Loss: 0.4454085
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.0601811408996582
Epoch: 73, Steps: 65 | Train Loss: 0.3062020 Vali Loss: 1.0161543 Test Loss: 0.4453788
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 0.989884614944458
Epoch: 74, Steps: 65 | Train Loss: 0.3063555 Vali Loss: 1.0154511 Test Loss: 0.4453555
Validation loss decreased (1.015539 --> 1.015451).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.082265853881836
Epoch: 75, Steps: 65 | Train Loss: 0.3063738 Vali Loss: 1.0154686 Test Loss: 0.4453361
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.0580215454101562
Epoch: 76, Steps: 65 | Train Loss: 0.3062421 Vali Loss: 1.0161389 Test Loss: 0.4453129
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.0737080574035645
Epoch: 77, Steps: 65 | Train Loss: 0.3061499 Vali Loss: 1.0161943 Test Loss: 0.4452893
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.0808610916137695
Epoch: 78, Steps: 65 | Train Loss: 0.3061587 Vali Loss: 1.0160040 Test Loss: 0.4452690
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 0.913280725479126
Epoch: 79, Steps: 65 | Train Loss: 0.3061996 Vali Loss: 1.0161391 Test Loss: 0.4452507
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 0.9931166172027588
Epoch: 80, Steps: 65 | Train Loss: 0.3058537 Vali Loss: 1.0161364 Test Loss: 0.4452315
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 0.9817516803741455
Epoch: 81, Steps: 65 | Train Loss: 0.3060370 Vali Loss: 1.0157955 Test Loss: 0.4452119
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.126563310623169
Epoch: 82, Steps: 65 | Train Loss: 0.3061498 Vali Loss: 1.0157071 Test Loss: 0.4451950
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.0504693984985352
Epoch: 83, Steps: 65 | Train Loss: 0.3060701 Vali Loss: 1.0150673 Test Loss: 0.4451782
Validation loss decreased (1.015451 --> 1.015067).  Saving model ...
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.0202131271362305
Epoch: 84, Steps: 65 | Train Loss: 0.3060653 Vali Loss: 1.0156215 Test Loss: 0.4451596
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.0151035785675049
Epoch: 85, Steps: 65 | Train Loss: 0.3058715 Vali Loss: 1.0159801 Test Loss: 0.4451454
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 0.9150393009185791
Epoch: 86, Steps: 65 | Train Loss: 0.3058025 Vali Loss: 1.0157429 Test Loss: 0.4451365
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 0.9892177581787109
Epoch: 87, Steps: 65 | Train Loss: 0.3060523 Vali Loss: 1.0156683 Test Loss: 0.4451198
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.055081844329834
Epoch: 88, Steps: 65 | Train Loss: 0.3058194 Vali Loss: 1.0158303 Test Loss: 0.4451070
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.0097599029541016
Epoch: 89, Steps: 65 | Train Loss: 0.3057858 Vali Loss: 1.0159228 Test Loss: 0.4450979
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.0333173274993896
Epoch: 90, Steps: 65 | Train Loss: 0.3059317 Vali Loss: 1.0157187 Test Loss: 0.4450860
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.026383876800537
Epoch: 91, Steps: 65 | Train Loss: 0.3058784 Vali Loss: 1.0157452 Test Loss: 0.4450740
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.0164849758148193
Epoch: 92, Steps: 65 | Train Loss: 0.3058888 Vali Loss: 1.0155661 Test Loss: 0.4450637
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 0.9592244625091553
Epoch: 93, Steps: 65 | Train Loss: 0.3060393 Vali Loss: 1.0154433 Test Loss: 0.4450557
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.016474962234497
Epoch: 94, Steps: 65 | Train Loss: 0.3059242 Vali Loss: 1.0157555 Test Loss: 0.4450471
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.2001981735229492
Epoch: 95, Steps: 65 | Train Loss: 0.3058375 Vali Loss: 1.0157495 Test Loss: 0.4450362
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.0714664459228516
Epoch: 96, Steps: 65 | Train Loss: 0.3056842 Vali Loss: 1.0155163 Test Loss: 0.4450260
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 0.9944753646850586
Epoch: 97, Steps: 65 | Train Loss: 0.3059834 Vali Loss: 1.0155637 Test Loss: 0.4450178
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.06494140625
Epoch: 98, Steps: 65 | Train Loss: 0.3057736 Vali Loss: 1.0155703 Test Loss: 0.4450114
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 0.9362943172454834
Epoch: 99, Steps: 65 | Train Loss: 0.3059107 Vali Loss: 1.0156471 Test Loss: 0.4450035
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.0361487865447998
Epoch: 100, Steps: 65 | Train Loss: 0.3057089 Vali Loss: 1.0156655 Test Loss: 0.4449963
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8359
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=18, out_features=56, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  903168.0
params:  1064.0
Trainable parameters:  1064
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.053037405014038
Epoch: 1, Steps: 65 | Train Loss: 0.4297432 Vali Loss: 1.0117449 Test Loss: 0.4428964
Validation loss decreased (inf --> 1.011745).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.0898020267486572
Epoch: 2, Steps: 65 | Train Loss: 0.4280577 Vali Loss: 1.0100698 Test Loss: 0.4421518
Validation loss decreased (1.011745 --> 1.010070).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.1640870571136475
Epoch: 3, Steps: 65 | Train Loss: 0.4275816 Vali Loss: 1.0088166 Test Loss: 0.4421635
Validation loss decreased (1.010070 --> 1.008817).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.0887119770050049
Epoch: 4, Steps: 65 | Train Loss: 0.4271568 Vali Loss: 1.0081743 Test Loss: 0.4419937
Validation loss decreased (1.008817 --> 1.008174).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 0.9885354042053223
Epoch: 5, Steps: 65 | Train Loss: 0.4270575 Vali Loss: 1.0081921 Test Loss: 0.4418882
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.1320993900299072
Epoch: 6, Steps: 65 | Train Loss: 0.4266838 Vali Loss: 1.0079918 Test Loss: 0.4417518
Validation loss decreased (1.008174 --> 1.007992).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.0403268337249756
Epoch: 7, Steps: 65 | Train Loss: 0.4268343 Vali Loss: 1.0065802 Test Loss: 0.4416628
Validation loss decreased (1.007992 --> 1.006580).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.0374183654785156
Epoch: 8, Steps: 65 | Train Loss: 0.4272816 Vali Loss: 1.0074233 Test Loss: 0.4418553
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.019965410232544
Epoch: 9, Steps: 65 | Train Loss: 0.4265139 Vali Loss: 1.0073053 Test Loss: 0.4417745
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.1432316303253174
Epoch: 10, Steps: 65 | Train Loss: 0.4266083 Vali Loss: 1.0067275 Test Loss: 0.4420344
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.0240552425384521
Epoch: 11, Steps: 65 | Train Loss: 0.4263851 Vali Loss: 1.0070610 Test Loss: 0.4418345
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 0.9344699382781982
Epoch: 12, Steps: 65 | Train Loss: 0.4263766 Vali Loss: 1.0065668 Test Loss: 0.4419855
Validation loss decreased (1.006580 --> 1.006567).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.0724666118621826
Epoch: 13, Steps: 65 | Train Loss: 0.4263984 Vali Loss: 1.0062647 Test Loss: 0.4418997
Validation loss decreased (1.006567 --> 1.006265).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.0405173301696777
Epoch: 14, Steps: 65 | Train Loss: 0.4265410 Vali Loss: 1.0065979 Test Loss: 0.4420191
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.0598235130310059
Epoch: 15, Steps: 65 | Train Loss: 0.4266200 Vali Loss: 1.0064290 Test Loss: 0.4421884
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.0877399444580078
Epoch: 16, Steps: 65 | Train Loss: 0.4269881 Vali Loss: 1.0064135 Test Loss: 0.4421824
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.1072335243225098
Epoch: 17, Steps: 65 | Train Loss: 0.4262546 Vali Loss: 1.0064561 Test Loss: 0.4421390
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.1431646347045898
Epoch: 18, Steps: 65 | Train Loss: 0.4267415 Vali Loss: 1.0062282 Test Loss: 0.4422071
Validation loss decreased (1.006265 --> 1.006228).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.0566215515136719
Epoch: 19, Steps: 65 | Train Loss: 0.4263696 Vali Loss: 1.0061637 Test Loss: 0.4422055
Validation loss decreased (1.006228 --> 1.006164).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.02164888381958
Epoch: 20, Steps: 65 | Train Loss: 0.4263846 Vali Loss: 1.0062158 Test Loss: 0.4420702
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.0610017776489258
Epoch: 21, Steps: 65 | Train Loss: 0.4263940 Vali Loss: 1.0062829 Test Loss: 0.4422464
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.14347243309021
Epoch: 22, Steps: 65 | Train Loss: 0.4262246 Vali Loss: 1.0058229 Test Loss: 0.4422490
Validation loss decreased (1.006164 --> 1.005823).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.0432052612304688
Epoch: 23, Steps: 65 | Train Loss: 0.4263488 Vali Loss: 1.0061305 Test Loss: 0.4422677
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.0260710716247559
Epoch: 24, Steps: 65 | Train Loss: 0.4261213 Vali Loss: 1.0060285 Test Loss: 0.4423420
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.131302833557129
Epoch: 25, Steps: 65 | Train Loss: 0.4264923 Vali Loss: 1.0051047 Test Loss: 0.4422802
Validation loss decreased (1.005823 --> 1.005105).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.0210444927215576
Epoch: 26, Steps: 65 | Train Loss: 0.4267973 Vali Loss: 1.0056776 Test Loss: 0.4422876
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.0227973461151123
Epoch: 27, Steps: 65 | Train Loss: 0.4263689 Vali Loss: 1.0059862 Test Loss: 0.4421788
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.019423484802246
Epoch: 28, Steps: 65 | Train Loss: 0.4263924 Vali Loss: 1.0055827 Test Loss: 0.4422743
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 0.9990482330322266
Epoch: 29, Steps: 65 | Train Loss: 0.4264592 Vali Loss: 1.0052615 Test Loss: 0.4421580
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.0960922241210938
Epoch: 30, Steps: 65 | Train Loss: 0.4262351 Vali Loss: 1.0059683 Test Loss: 0.4422989
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.1088340282440186
Epoch: 31, Steps: 65 | Train Loss: 0.4263843 Vali Loss: 1.0060298 Test Loss: 0.4422749
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.1348800659179688
Epoch: 32, Steps: 65 | Train Loss: 0.4265006 Vali Loss: 1.0056617 Test Loss: 0.4422163
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 0.9761080741882324
Epoch: 33, Steps: 65 | Train Loss: 0.4261767 Vali Loss: 1.0056647 Test Loss: 0.4422401
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.0190582275390625
Epoch: 34, Steps: 65 | Train Loss: 0.4261406 Vali Loss: 1.0058236 Test Loss: 0.4423697
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.0469615459442139
Epoch: 35, Steps: 65 | Train Loss: 0.4264085 Vali Loss: 1.0058650 Test Loss: 0.4422624
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 0.958782434463501
Epoch: 36, Steps: 65 | Train Loss: 0.4263894 Vali Loss: 1.0056418 Test Loss: 0.4422885
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 0.9864680767059326
Epoch: 37, Steps: 65 | Train Loss: 0.4264687 Vali Loss: 1.0058645 Test Loss: 0.4423056
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.0227715969085693
Epoch: 38, Steps: 65 | Train Loss: 0.4262111 Vali Loss: 1.0058531 Test Loss: 0.4422994
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.04325532913208
Epoch: 39, Steps: 65 | Train Loss: 0.4264133 Vali Loss: 1.0059435 Test Loss: 0.4423402
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.0031721591949463
Epoch: 40, Steps: 65 | Train Loss: 0.4264175 Vali Loss: 1.0058397 Test Loss: 0.4422876
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.0453863143920898
Epoch: 41, Steps: 65 | Train Loss: 0.4261888 Vali Loss: 1.0054277 Test Loss: 0.4423400
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.0446288585662842
Epoch: 42, Steps: 65 | Train Loss: 0.4262198 Vali Loss: 1.0054764 Test Loss: 0.4423396
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.1108925342559814
Epoch: 43, Steps: 65 | Train Loss: 0.4259324 Vali Loss: 1.0049803 Test Loss: 0.4423628
Validation loss decreased (1.005105 --> 1.004980).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.1094985008239746
Epoch: 44, Steps: 65 | Train Loss: 0.4266269 Vali Loss: 1.0054920 Test Loss: 0.4423222
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.0544352531433105
Epoch: 45, Steps: 65 | Train Loss: 0.4259151 Vali Loss: 1.0057977 Test Loss: 0.4423422
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.172494888305664
Epoch: 46, Steps: 65 | Train Loss: 0.4263252 Vali Loss: 1.0053604 Test Loss: 0.4423620
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.1455442905426025
Epoch: 47, Steps: 65 | Train Loss: 0.4265520 Vali Loss: 1.0058516 Test Loss: 0.4423685
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.0713768005371094
Epoch: 48, Steps: 65 | Train Loss: 0.4261799 Vali Loss: 1.0055388 Test Loss: 0.4423079
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.0805389881134033
Epoch: 49, Steps: 65 | Train Loss: 0.4260592 Vali Loss: 1.0055057 Test Loss: 0.4424102
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 0.9841845035552979
Epoch: 50, Steps: 65 | Train Loss: 0.4264423 Vali Loss: 1.0055830 Test Loss: 0.4423615
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.0680012702941895
Epoch: 51, Steps: 65 | Train Loss: 0.4262903 Vali Loss: 1.0058076 Test Loss: 0.4423582
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.146089792251587
Epoch: 52, Steps: 65 | Train Loss: 0.4262272 Vali Loss: 1.0057057 Test Loss: 0.4423609
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.098513126373291
Epoch: 53, Steps: 65 | Train Loss: 0.4263622 Vali Loss: 1.0052551 Test Loss: 0.4423781
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.1438069343566895
Epoch: 54, Steps: 65 | Train Loss: 0.4263427 Vali Loss: 1.0057237 Test Loss: 0.4423660
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.1172549724578857
Epoch: 55, Steps: 65 | Train Loss: 0.4262558 Vali Loss: 1.0057828 Test Loss: 0.4423999
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.025022268295288
Epoch: 56, Steps: 65 | Train Loss: 0.4263590 Vali Loss: 1.0058236 Test Loss: 0.4423764
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.2348685264587402
Epoch: 57, Steps: 65 | Train Loss: 0.4263055 Vali Loss: 1.0052972 Test Loss: 0.4424096
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.0352587699890137
Epoch: 58, Steps: 65 | Train Loss: 0.4258319 Vali Loss: 1.0058933 Test Loss: 0.4423851
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.3850436210632324
Epoch: 59, Steps: 65 | Train Loss: 0.4266323 Vali Loss: 1.0054961 Test Loss: 0.4423913
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.1109914779663086
Epoch: 60, Steps: 65 | Train Loss: 0.4267439 Vali Loss: 1.0055759 Test Loss: 0.4423692
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.1257352828979492
Epoch: 61, Steps: 65 | Train Loss: 0.4264265 Vali Loss: 1.0053025 Test Loss: 0.4423862
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 3.220445394515991
Epoch: 62, Steps: 65 | Train Loss: 0.4261620 Vali Loss: 1.0052789 Test Loss: 0.4423812
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.384772777557373
Epoch: 63, Steps: 65 | Train Loss: 0.4261443 Vali Loss: 1.0055063 Test Loss: 0.4423964
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_90_192_FITS_ETTh1_ftM_sl90_ll48_pl192_H2_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.4420056641101837, mae:0.427745521068573, rse:0.6313515305519104, corr:[0.26135075 0.26453945 0.26510203 0.26279113 0.25887468 0.25668016
 0.2569413  0.25659877 0.25548616 0.25519848 0.25553742 0.25581747
 0.25532746 0.2543866  0.25411546 0.25464126 0.25524586 0.2552147
 0.25465047 0.25441775 0.25442114 0.25434285 0.253667   0.25261953
 0.25116307 0.25101414 0.2515831  0.25166717 0.2511235  0.2510987
 0.2517699  0.2517404  0.2512237  0.2509043  0.25089514 0.25112826
 0.25109845 0.25065646 0.25045282 0.25085086 0.2516125  0.2520628
 0.25202572 0.25198546 0.25218344 0.25216278 0.25190037 0.251176
 0.24982297 0.24934404 0.24911602 0.24807891 0.2462441  0.24504787
 0.24542744 0.24544862 0.24483211 0.24451907 0.24453108 0.2448739
 0.2448473  0.24424805 0.24368519 0.24356136 0.2440068  0.24446991
 0.24470834 0.24472488 0.24473599 0.24477986 0.24446088 0.24317561
 0.24118638 0.24036089 0.24033083 0.24010542 0.23930131 0.23876433
 0.23920238 0.23914428 0.2386618  0.23819593 0.23789856 0.23792785
 0.23802418 0.23778765 0.23761484 0.23768264 0.23800008 0.23827532
 0.23823568 0.238234   0.23839468 0.23854516 0.23855586 0.23790638
 0.23658507 0.23618303 0.23631957 0.23581141 0.23502363 0.23487993
 0.23549771 0.23549761 0.2349968  0.2346678  0.23456438 0.23457916
 0.2344843  0.23410997 0.23402937 0.23429811 0.23479772 0.23493682
 0.23484653 0.23491916 0.23522884 0.23537622 0.23498113 0.2338347
 0.23200753 0.23103845 0.23043238 0.22937854 0.22832246 0.22820592
 0.22923785 0.22959848 0.22927074 0.22890203 0.22871664 0.2287973
 0.22869587 0.22816096 0.22783187 0.22788838 0.22837096 0.2286116
 0.22856264 0.22864228 0.22884324 0.2289866  0.22873929 0.22768477
 0.22586177 0.22499329 0.22483936 0.22395782 0.22277936 0.22258586
 0.22375906 0.22419742 0.22394861 0.2235872  0.22344282 0.22364558
 0.22361435 0.22309203 0.22252485 0.22237583 0.22269428 0.22301449
 0.22311585 0.22321337 0.22334385 0.22334936 0.22299562 0.22186233
 0.22022589 0.21973667 0.21996902 0.2196411  0.218446   0.2180584
 0.21906829 0.21943682 0.21911067 0.2188673  0.21891637 0.2191257
 0.2191002  0.21838155 0.2176524  0.21731119 0.2175825  0.21823332
 0.21866916 0.2187526  0.21875799 0.2190422  0.21976884 0.2201351 ]
