Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=196, out_features=222, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  38986752.0
params:  43734.0
Trainable parameters:  43734
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.6537420749664307
Epoch: 1, Steps: 61 | Train Loss: 0.5685008 Vali Loss: 0.9363230 Test Loss: 0.4918450
Validation loss decreased (inf --> 0.936323).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.522867202758789
Epoch: 2, Steps: 61 | Train Loss: 0.3965313 Vali Loss: 0.7974574 Test Loss: 0.4066410
Validation loss decreased (0.936323 --> 0.797457).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.3484861850738525
Epoch: 3, Steps: 61 | Train Loss: 0.3606924 Vali Loss: 0.7550759 Test Loss: 0.3862153
Validation loss decreased (0.797457 --> 0.755076).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 4.1202781200408936
Epoch: 4, Steps: 61 | Train Loss: 0.3491721 Vali Loss: 0.7385203 Test Loss: 0.3818085
Validation loss decreased (0.755076 --> 0.738520).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.345456600189209
Epoch: 5, Steps: 61 | Train Loss: 0.3445301 Vali Loss: 0.7324327 Test Loss: 0.3803210
Validation loss decreased (0.738520 --> 0.732433).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 4.350086212158203
Epoch: 6, Steps: 61 | Train Loss: 0.3418995 Vali Loss: 0.7245774 Test Loss: 0.3797082
Validation loss decreased (0.732433 --> 0.724577).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.466830015182495
Epoch: 7, Steps: 61 | Train Loss: 0.3398468 Vali Loss: 0.7220967 Test Loss: 0.3798560
Validation loss decreased (0.724577 --> 0.722097).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.63810133934021
Epoch: 8, Steps: 61 | Train Loss: 0.3385066 Vali Loss: 0.7157629 Test Loss: 0.3795915
Validation loss decreased (0.722097 --> 0.715763).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 4.406479597091675
Epoch: 9, Steps: 61 | Train Loss: 0.3374576 Vali Loss: 0.7157894 Test Loss: 0.3795984
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.4584152698516846
Epoch: 10, Steps: 61 | Train Loss: 0.3366096 Vali Loss: 0.7134547 Test Loss: 0.3791715
Validation loss decreased (0.715763 --> 0.713455).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.4176700115203857
Epoch: 11, Steps: 61 | Train Loss: 0.3357724 Vali Loss: 0.7105839 Test Loss: 0.3794585
Validation loss decreased (0.713455 --> 0.710584).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.6507983207702637
Epoch: 12, Steps: 61 | Train Loss: 0.3352885 Vali Loss: 0.7120267 Test Loss: 0.3791972
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.3045525550842285
Epoch: 13, Steps: 61 | Train Loss: 0.3346446 Vali Loss: 0.7065989 Test Loss: 0.3796445
Validation loss decreased (0.710584 --> 0.706599).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.462095022201538
Epoch: 14, Steps: 61 | Train Loss: 0.3339804 Vali Loss: 0.7063606 Test Loss: 0.3795700
Validation loss decreased (0.706599 --> 0.706361).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.6074020862579346
Epoch: 15, Steps: 61 | Train Loss: 0.3335793 Vali Loss: 0.7087850 Test Loss: 0.3791859
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.614185333251953
Epoch: 16, Steps: 61 | Train Loss: 0.3336740 Vali Loss: 0.7070720 Test Loss: 0.3792327
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.346660852432251
Epoch: 17, Steps: 61 | Train Loss: 0.3330534 Vali Loss: 0.7004861 Test Loss: 0.3790785
Validation loss decreased (0.706361 --> 0.700486).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.2998485565185547
Epoch: 18, Steps: 61 | Train Loss: 0.3329386 Vali Loss: 0.7044963 Test Loss: 0.3792832
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.913428783416748
Epoch: 19, Steps: 61 | Train Loss: 0.3329013 Vali Loss: 0.7073022 Test Loss: 0.3791137
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.6747827529907227
Epoch: 20, Steps: 61 | Train Loss: 0.3326267 Vali Loss: 0.7036482 Test Loss: 0.3793676
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.332858085632324
Epoch: 21, Steps: 61 | Train Loss: 0.3324406 Vali Loss: 0.7072371 Test Loss: 0.3793353
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.547342538833618
Epoch: 22, Steps: 61 | Train Loss: 0.3320414 Vali Loss: 0.7025012 Test Loss: 0.3794313
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.239061117172241
Epoch: 23, Steps: 61 | Train Loss: 0.3319952 Vali Loss: 0.7016888 Test Loss: 0.3790300
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.611868143081665
Epoch: 24, Steps: 61 | Train Loss: 0.3321535 Vali Loss: 0.6977922 Test Loss: 0.3792276
Validation loss decreased (0.700486 --> 0.697792).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.8736529350280762
Epoch: 25, Steps: 61 | Train Loss: 0.3316755 Vali Loss: 0.6966750 Test Loss: 0.3794068
Validation loss decreased (0.697792 --> 0.696675).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.6091482639312744
Epoch: 26, Steps: 61 | Train Loss: 0.3318050 Vali Loss: 0.6964806 Test Loss: 0.3792727
Validation loss decreased (0.696675 --> 0.696481).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.384476900100708
Epoch: 27, Steps: 61 | Train Loss: 0.3317001 Vali Loss: 0.7005029 Test Loss: 0.3793233
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.533752202987671
Epoch: 28, Steps: 61 | Train Loss: 0.3315419 Vali Loss: 0.7004332 Test Loss: 0.3794326
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.5366735458374023
Epoch: 29, Steps: 61 | Train Loss: 0.3311618 Vali Loss: 0.7032651 Test Loss: 0.3794063
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.3752331733703613
Epoch: 30, Steps: 61 | Train Loss: 0.3311012 Vali Loss: 0.6997708 Test Loss: 0.3795455
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.148547410964966
Epoch: 31, Steps: 61 | Train Loss: 0.3311361 Vali Loss: 0.7038617 Test Loss: 0.3795400
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 3.1696155071258545
Epoch: 32, Steps: 61 | Train Loss: 0.3312446 Vali Loss: 0.7027542 Test Loss: 0.3793995
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.67514705657959
Epoch: 33, Steps: 61 | Train Loss: 0.3309741 Vali Loss: 0.7013763 Test Loss: 0.3793899
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.345341920852661
Epoch: 34, Steps: 61 | Train Loss: 0.3311303 Vali Loss: 0.7020884 Test Loss: 0.3794809
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.4265520572662354
Epoch: 35, Steps: 61 | Train Loss: 0.3309477 Vali Loss: 0.6995015 Test Loss: 0.3794226
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.420727491378784
Epoch: 36, Steps: 61 | Train Loss: 0.3307728 Vali Loss: 0.7017632 Test Loss: 0.3794243
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 3.069896936416626
Epoch: 37, Steps: 61 | Train Loss: 0.3309129 Vali Loss: 0.7013702 Test Loss: 0.3793294
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.5295350551605225
Epoch: 38, Steps: 61 | Train Loss: 0.3308567 Vali Loss: 0.6991294 Test Loss: 0.3793918
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.9358370304107666
Epoch: 39, Steps: 61 | Train Loss: 0.3306923 Vali Loss: 0.7011967 Test Loss: 0.3795003
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.2953412532806396
Epoch: 40, Steps: 61 | Train Loss: 0.3307025 Vali Loss: 0.7002265 Test Loss: 0.3794363
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.0821564197540283
Epoch: 41, Steps: 61 | Train Loss: 0.3306843 Vali Loss: 0.7016416 Test Loss: 0.3794768
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.8642990589141846
Epoch: 42, Steps: 61 | Train Loss: 0.3305137 Vali Loss: 0.6961955 Test Loss: 0.3794538
Validation loss decreased (0.696481 --> 0.696196).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.267671823501587
Epoch: 43, Steps: 61 | Train Loss: 0.3306467 Vali Loss: 0.7021165 Test Loss: 0.3794177
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.8536550998687744
Epoch: 44, Steps: 61 | Train Loss: 0.3306178 Vali Loss: 0.6976826 Test Loss: 0.3794789
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 0.8727972507476807
Epoch: 45, Steps: 61 | Train Loss: 0.3305426 Vali Loss: 0.6941681 Test Loss: 0.3795654
Validation loss decreased (0.696196 --> 0.694168).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.3655149936676025
Epoch: 46, Steps: 61 | Train Loss: 0.3304726 Vali Loss: 0.6961365 Test Loss: 0.3794539
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.081254243850708
Epoch: 47, Steps: 61 | Train Loss: 0.3302819 Vali Loss: 0.6989529 Test Loss: 0.3794791
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.3325426578521729
Epoch: 48, Steps: 61 | Train Loss: 0.3304545 Vali Loss: 0.6973437 Test Loss: 0.3794554
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.1764585971832275
Epoch: 49, Steps: 61 | Train Loss: 0.3304430 Vali Loss: 0.6993477 Test Loss: 0.3795341
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.1542625427246094
Epoch: 50, Steps: 61 | Train Loss: 0.3302357 Vali Loss: 0.6991267 Test Loss: 0.3794978
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.1380345821380615
Epoch: 51, Steps: 61 | Train Loss: 0.3298585 Vali Loss: 0.6989959 Test Loss: 0.3794107
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.2278571128845215
Epoch: 52, Steps: 61 | Train Loss: 0.3304230 Vali Loss: 0.6970724 Test Loss: 0.3794776
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.0386404991149902
Epoch: 53, Steps: 61 | Train Loss: 0.3302585 Vali Loss: 0.6992204 Test Loss: 0.3794914
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.0287134647369385
Epoch: 54, Steps: 61 | Train Loss: 0.3303650 Vali Loss: 0.6970955 Test Loss: 0.3795881
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.0521361827850342
Epoch: 55, Steps: 61 | Train Loss: 0.3300975 Vali Loss: 0.7008486 Test Loss: 0.3794902
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.1047923564910889
Epoch: 56, Steps: 61 | Train Loss: 0.3301322 Vali Loss: 0.6966357 Test Loss: 0.3795364
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.0623581409454346
Epoch: 57, Steps: 61 | Train Loss: 0.3301854 Vali Loss: 0.7010843 Test Loss: 0.3794989
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.2264673709869385
Epoch: 58, Steps: 61 | Train Loss: 0.3301679 Vali Loss: 0.6958447 Test Loss: 0.3795409
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 0.9871683120727539
Epoch: 59, Steps: 61 | Train Loss: 0.3301132 Vali Loss: 0.6983405 Test Loss: 0.3795318
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 0.7544333934783936
Epoch: 60, Steps: 61 | Train Loss: 0.3300623 Vali Loss: 0.7011952 Test Loss: 0.3794778
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.0855696201324463
Epoch: 61, Steps: 61 | Train Loss: 0.3302179 Vali Loss: 0.6973073 Test Loss: 0.3795376
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.121084213256836
Epoch: 62, Steps: 61 | Train Loss: 0.3300859 Vali Loss: 0.6973898 Test Loss: 0.3794983
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 0.8732607364654541
Epoch: 63, Steps: 61 | Train Loss: 0.3300008 Vali Loss: 0.7006285 Test Loss: 0.3795392
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 0.8159911632537842
Epoch: 64, Steps: 61 | Train Loss: 0.3300245 Vali Loss: 0.7020269 Test Loss: 0.3795648
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.2545413970947266
Epoch: 65, Steps: 61 | Train Loss: 0.3300869 Vali Loss: 0.7005796 Test Loss: 0.3795048
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.37921610474586487, mae:0.4019671082496643, rse:0.584926426410675, corr:[0.26720598 0.27718493 0.27726763 0.2782238  0.2765306  0.27351543
 0.27205896 0.27197176 0.27155098 0.27127934 0.27147013 0.27125823
 0.27082545 0.2707641  0.27107632 0.27115506 0.27093443 0.2709325
 0.2708284  0.2702295  0.26961613 0.2695772  0.26948807 0.26949823
 0.2695024  0.26927555 0.26912344 0.26914757 0.2689723  0.26839817
 0.26801816 0.26777312 0.26754898 0.26728418 0.26703036 0.26701128
 0.26703924 0.26706925 0.26718014 0.26718798 0.26726294 0.26750833
 0.2678557  0.2679469  0.26766264 0.2674905  0.26791254 0.26836857
 0.26798838 0.2669758  0.26572642 0.26474905 0.2637682  0.26235333
 0.2612939  0.26093096 0.26079136 0.2606303  0.2601771  0.2601123
 0.2600828  0.25983742 0.25956112 0.25964496 0.25974995 0.25958544
 0.25977582 0.259977   0.25970593 0.2592693  0.25934336 0.25939736
 0.2586002  0.2572228  0.25613862 0.25565842 0.2548929  0.2542141
 0.25400364 0.253195   0.25187707 0.25150946 0.25169033 0.2508119
 0.24998736 0.25040862 0.25036252 0.24873538 0.24810198 0.24868743
 0.24710928 0.24556498 0.24696767 0.2452852  0.24331588 0.2533013 ]
