Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=30, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_90_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_90_192_FITS_ETTh1_ftM_sl90_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8359
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=30, out_features=94, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2526720.0
params:  2914.0
Trainable parameters:  2914
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.8157422542572021
Epoch: 1, Steps: 65 | Train Loss: 0.7870379 Vali Loss: 1.6855776 Test Loss: 0.9921053
Validation loss decreased (inf --> 1.685578).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.5456340312957764
Epoch: 2, Steps: 65 | Train Loss: 0.6098959 Vali Loss: 1.4585085 Test Loss: 0.7949541
Validation loss decreased (1.685578 --> 1.458508).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.6575493812561035
Epoch: 3, Steps: 65 | Train Loss: 0.5094280 Vali Loss: 1.3304647 Test Loss: 0.6842042
Validation loss decreased (1.458508 --> 1.330465).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.6369423866271973
Epoch: 4, Steps: 65 | Train Loss: 0.4490148 Vali Loss: 1.2503762 Test Loss: 0.6163383
Validation loss decreased (1.330465 --> 1.250376).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.6546540260314941
Epoch: 5, Steps: 65 | Train Loss: 0.4099668 Vali Loss: 1.1970192 Test Loss: 0.5721983
Validation loss decreased (1.250376 --> 1.197019).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.9513885974884033
Epoch: 6, Steps: 65 | Train Loss: 0.3837822 Vali Loss: 1.1599021 Test Loss: 0.5422647
Validation loss decreased (1.197019 --> 1.159902).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.9879889488220215
Epoch: 7, Steps: 65 | Train Loss: 0.3657947 Vali Loss: 1.1325965 Test Loss: 0.5206726
Validation loss decreased (1.159902 --> 1.132596).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.7100470066070557
Epoch: 8, Steps: 65 | Train Loss: 0.3523331 Vali Loss: 1.1124235 Test Loss: 0.5053455
Validation loss decreased (1.132596 --> 1.112424).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.8824272155761719
Epoch: 9, Steps: 65 | Train Loss: 0.3426525 Vali Loss: 1.0960230 Test Loss: 0.4936653
Validation loss decreased (1.112424 --> 1.096023).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.9729821681976318
Epoch: 10, Steps: 65 | Train Loss: 0.3353558 Vali Loss: 1.0841633 Test Loss: 0.4847817
Validation loss decreased (1.096023 --> 1.084163).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.228389263153076
Epoch: 11, Steps: 65 | Train Loss: 0.3293890 Vali Loss: 1.0743663 Test Loss: 0.4780125
Validation loss decreased (1.084163 --> 1.074366).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.776909351348877
Epoch: 12, Steps: 65 | Train Loss: 0.3253312 Vali Loss: 1.0667311 Test Loss: 0.4727366
Validation loss decreased (1.074366 --> 1.066731).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.5381360054016113
Epoch: 13, Steps: 65 | Train Loss: 0.3216239 Vali Loss: 1.0604478 Test Loss: 0.4683245
Validation loss decreased (1.066731 --> 1.060448).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.1679298877716064
Epoch: 14, Steps: 65 | Train Loss: 0.3185359 Vali Loss: 1.0545481 Test Loss: 0.4650339
Validation loss decreased (1.060448 --> 1.054548).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.9476072788238525
Epoch: 15, Steps: 65 | Train Loss: 0.3162701 Vali Loss: 1.0502729 Test Loss: 0.4620563
Validation loss decreased (1.054548 --> 1.050273).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.4239721298217773
Epoch: 16, Steps: 65 | Train Loss: 0.3140663 Vali Loss: 1.0461977 Test Loss: 0.4596413
Validation loss decreased (1.050273 --> 1.046198).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.5816586017608643
Epoch: 17, Steps: 65 | Train Loss: 0.3125223 Vali Loss: 1.0425227 Test Loss: 0.4577129
Validation loss decreased (1.046198 --> 1.042523).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.7791109085083008
Epoch: 18, Steps: 65 | Train Loss: 0.3109091 Vali Loss: 1.0399274 Test Loss: 0.4560613
Validation loss decreased (1.042523 --> 1.039927).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.580869436264038
Epoch: 19, Steps: 65 | Train Loss: 0.3097340 Vali Loss: 1.0373884 Test Loss: 0.4546883
Validation loss decreased (1.039927 --> 1.037388).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.559147834777832
Epoch: 20, Steps: 65 | Train Loss: 0.3085729 Vali Loss: 1.0351189 Test Loss: 0.4534564
Validation loss decreased (1.037388 --> 1.035119).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.729081392288208
Epoch: 21, Steps: 65 | Train Loss: 0.3077885 Vali Loss: 1.0329342 Test Loss: 0.4524329
Validation loss decreased (1.035119 --> 1.032934).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.4447648525238037
Epoch: 22, Steps: 65 | Train Loss: 0.3070757 Vali Loss: 1.0314517 Test Loss: 0.4514377
Validation loss decreased (1.032934 --> 1.031452).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.3407669067382812
Epoch: 23, Steps: 65 | Train Loss: 0.3060751 Vali Loss: 1.0291073 Test Loss: 0.4506826
Validation loss decreased (1.031452 --> 1.029107).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.5673887729644775
Epoch: 24, Steps: 65 | Train Loss: 0.3054566 Vali Loss: 1.0278528 Test Loss: 0.4498865
Validation loss decreased (1.029107 --> 1.027853).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.2769033908843994
Epoch: 25, Steps: 65 | Train Loss: 0.3045775 Vali Loss: 1.0271201 Test Loss: 0.4492946
Validation loss decreased (1.027853 --> 1.027120).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.621338129043579
Epoch: 26, Steps: 65 | Train Loss: 0.3042375 Vali Loss: 1.0263088 Test Loss: 0.4487126
Validation loss decreased (1.027120 --> 1.026309).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.5461328029632568
Epoch: 27, Steps: 65 | Train Loss: 0.3036292 Vali Loss: 1.0250785 Test Loss: 0.4481842
Validation loss decreased (1.026309 --> 1.025079).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.18170166015625
Epoch: 28, Steps: 65 | Train Loss: 0.3034231 Vali Loss: 1.0238274 Test Loss: 0.4477445
Validation loss decreased (1.025079 --> 1.023827).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.869337558746338
Epoch: 29, Steps: 65 | Train Loss: 0.3028876 Vali Loss: 1.0234922 Test Loss: 0.4472859
Validation loss decreased (1.023827 --> 1.023492).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.7106919288635254
Epoch: 30, Steps: 65 | Train Loss: 0.3027133 Vali Loss: 1.0227683 Test Loss: 0.4469171
Validation loss decreased (1.023492 --> 1.022768).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.6924123764038086
Epoch: 31, Steps: 65 | Train Loss: 0.3018910 Vali Loss: 1.0216296 Test Loss: 0.4465699
Validation loss decreased (1.022768 --> 1.021630).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.503575325012207
Epoch: 32, Steps: 65 | Train Loss: 0.3018488 Vali Loss: 1.0214636 Test Loss: 0.4462850
Validation loss decreased (1.021630 --> 1.021464).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.8446879386901855
Epoch: 33, Steps: 65 | Train Loss: 0.3013425 Vali Loss: 1.0208827 Test Loss: 0.4459739
Validation loss decreased (1.021464 --> 1.020883).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.6469793319702148
Epoch: 34, Steps: 65 | Train Loss: 0.3011884 Vali Loss: 1.0199790 Test Loss: 0.4456852
Validation loss decreased (1.020883 --> 1.019979).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.614820957183838
Epoch: 35, Steps: 65 | Train Loss: 0.3010104 Vali Loss: 1.0193087 Test Loss: 0.4454229
Validation loss decreased (1.019979 --> 1.019309).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.5474827289581299
Epoch: 36, Steps: 65 | Train Loss: 0.3003491 Vali Loss: 1.0188484 Test Loss: 0.4452347
Validation loss decreased (1.019309 --> 1.018848).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.8211479187011719
Epoch: 37, Steps: 65 | Train Loss: 0.3003562 Vali Loss: 1.0184729 Test Loss: 0.4450196
Validation loss decreased (1.018848 --> 1.018473).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.4957568645477295
Epoch: 38, Steps: 65 | Train Loss: 0.3000758 Vali Loss: 1.0182875 Test Loss: 0.4448037
Validation loss decreased (1.018473 --> 1.018288).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.69376802444458
Epoch: 39, Steps: 65 | Train Loss: 0.2998927 Vali Loss: 1.0180734 Test Loss: 0.4446093
Validation loss decreased (1.018288 --> 1.018073).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.5456371307373047
Epoch: 40, Steps: 65 | Train Loss: 0.3002189 Vali Loss: 1.0174499 Test Loss: 0.4444669
Validation loss decreased (1.018073 --> 1.017450).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.6004421710968018
Epoch: 41, Steps: 65 | Train Loss: 0.2996235 Vali Loss: 1.0169156 Test Loss: 0.4443209
Validation loss decreased (1.017450 --> 1.016916).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.6807997226715088
Epoch: 42, Steps: 65 | Train Loss: 0.2995793 Vali Loss: 1.0165802 Test Loss: 0.4441528
Validation loss decreased (1.016916 --> 1.016580).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.7951807975769043
Epoch: 43, Steps: 65 | Train Loss: 0.2995696 Vali Loss: 1.0168787 Test Loss: 0.4440334
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.0439064502716064
Epoch: 44, Steps: 65 | Train Loss: 0.2991307 Vali Loss: 1.0165559 Test Loss: 0.4438793
Validation loss decreased (1.016580 --> 1.016556).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.6200382709503174
Epoch: 45, Steps: 65 | Train Loss: 0.2991941 Vali Loss: 1.0162771 Test Loss: 0.4437823
Validation loss decreased (1.016556 --> 1.016277).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.6268820762634277
Epoch: 46, Steps: 65 | Train Loss: 0.2990885 Vali Loss: 1.0160877 Test Loss: 0.4436410
Validation loss decreased (1.016277 --> 1.016088).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.9893548488616943
Epoch: 47, Steps: 65 | Train Loss: 0.2989000 Vali Loss: 1.0154424 Test Loss: 0.4435532
Validation loss decreased (1.016088 --> 1.015442).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.7661728858947754
Epoch: 48, Steps: 65 | Train Loss: 0.2990077 Vali Loss: 1.0154167 Test Loss: 0.4434257
Validation loss decreased (1.015442 --> 1.015417).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.167069911956787
Epoch: 49, Steps: 65 | Train Loss: 0.2987396 Vali Loss: 1.0152524 Test Loss: 0.4433560
Validation loss decreased (1.015417 --> 1.015252).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.6225731372833252
Epoch: 50, Steps: 65 | Train Loss: 0.2986887 Vali Loss: 1.0143890 Test Loss: 0.4432613
Validation loss decreased (1.015252 --> 1.014389).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.6267354488372803
Epoch: 51, Steps: 65 | Train Loss: 0.2984972 Vali Loss: 1.0150195 Test Loss: 0.4431798
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.5618867874145508
Epoch: 52, Steps: 65 | Train Loss: 0.2981804 Vali Loss: 1.0149242 Test Loss: 0.4430896
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.5760343074798584
Epoch: 53, Steps: 65 | Train Loss: 0.2983754 Vali Loss: 1.0143763 Test Loss: 0.4430153
Validation loss decreased (1.014389 --> 1.014376).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.8149535655975342
Epoch: 54, Steps: 65 | Train Loss: 0.2983284 Vali Loss: 1.0146421 Test Loss: 0.4429232
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.690718173980713
Epoch: 55, Steps: 65 | Train Loss: 0.2981657 Vali Loss: 1.0140871 Test Loss: 0.4428786
Validation loss decreased (1.014376 --> 1.014087).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.731677532196045
Epoch: 56, Steps: 65 | Train Loss: 0.2980237 Vali Loss: 1.0139039 Test Loss: 0.4428171
Validation loss decreased (1.014087 --> 1.013904).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.5535802841186523
Epoch: 57, Steps: 65 | Train Loss: 0.2977933 Vali Loss: 1.0142405 Test Loss: 0.4427673
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.7540333271026611
Epoch: 58, Steps: 65 | Train Loss: 0.2980231 Vali Loss: 1.0140394 Test Loss: 0.4427112
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.9089701175689697
Epoch: 59, Steps: 65 | Train Loss: 0.2978891 Vali Loss: 1.0139447 Test Loss: 0.4426408
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.9094080924987793
Epoch: 60, Steps: 65 | Train Loss: 0.2979861 Vali Loss: 1.0138881 Test Loss: 0.4426002
Validation loss decreased (1.013904 --> 1.013888).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.0668582916259766
Epoch: 61, Steps: 65 | Train Loss: 0.2977630 Vali Loss: 1.0133154 Test Loss: 0.4425530
Validation loss decreased (1.013888 --> 1.013315).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.283029794692993
Epoch: 62, Steps: 65 | Train Loss: 0.2977833 Vali Loss: 1.0134922 Test Loss: 0.4424994
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.7805004119873047
Epoch: 63, Steps: 65 | Train Loss: 0.2976403 Vali Loss: 1.0135680 Test Loss: 0.4424437
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.065335273742676
Epoch: 64, Steps: 65 | Train Loss: 0.2978423 Vali Loss: 1.0134575 Test Loss: 0.4424132
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.6729965209960938
Epoch: 65, Steps: 65 | Train Loss: 0.2977553 Vali Loss: 1.0133696 Test Loss: 0.4423687
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.5724666118621826
Epoch: 66, Steps: 65 | Train Loss: 0.2977204 Vali Loss: 1.0133288 Test Loss: 0.4423330
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.678025722503662
Epoch: 67, Steps: 65 | Train Loss: 0.2977866 Vali Loss: 1.0133252 Test Loss: 0.4422948
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.8304235935211182
Epoch: 68, Steps: 65 | Train Loss: 0.2973424 Vali Loss: 1.0132107 Test Loss: 0.4422598
Validation loss decreased (1.013315 --> 1.013211).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.6942753791809082
Epoch: 69, Steps: 65 | Train Loss: 0.2974112 Vali Loss: 1.0130935 Test Loss: 0.4422231
Validation loss decreased (1.013211 --> 1.013093).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.8451812267303467
Epoch: 70, Steps: 65 | Train Loss: 0.2975855 Vali Loss: 1.0129019 Test Loss: 0.4421926
Validation loss decreased (1.013093 --> 1.012902).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.026413917541504
Epoch: 71, Steps: 65 | Train Loss: 0.2972793 Vali Loss: 1.0125905 Test Loss: 0.4421619
Validation loss decreased (1.012902 --> 1.012591).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.5178823471069336
Epoch: 72, Steps: 65 | Train Loss: 0.2972595 Vali Loss: 1.0128380 Test Loss: 0.4421336
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.05776047706604
Epoch: 73, Steps: 65 | Train Loss: 0.2974201 Vali Loss: 1.0120184 Test Loss: 0.4421112
Validation loss decreased (1.012591 --> 1.012018).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.0510313510894775
Epoch: 74, Steps: 65 | Train Loss: 0.2972467 Vali Loss: 1.0127753 Test Loss: 0.4420839
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.871880292892456
Epoch: 75, Steps: 65 | Train Loss: 0.2971957 Vali Loss: 1.0122439 Test Loss: 0.4420618
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.6090400218963623
Epoch: 76, Steps: 65 | Train Loss: 0.2972695 Vali Loss: 1.0125974 Test Loss: 0.4420290
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.6459543704986572
Epoch: 77, Steps: 65 | Train Loss: 0.2972152 Vali Loss: 1.0127637 Test Loss: 0.4420091
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.6426184177398682
Epoch: 78, Steps: 65 | Train Loss: 0.2966610 Vali Loss: 1.0125042 Test Loss: 0.4419895
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.678814172744751
Epoch: 79, Steps: 65 | Train Loss: 0.2972903 Vali Loss: 1.0123259 Test Loss: 0.4419709
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.0905649662017822
Epoch: 80, Steps: 65 | Train Loss: 0.2971346 Vali Loss: 1.0123545 Test Loss: 0.4419508
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.0045650005340576
Epoch: 81, Steps: 65 | Train Loss: 0.2972296 Vali Loss: 1.0116348 Test Loss: 0.4419374
Validation loss decreased (1.012018 --> 1.011635).  Saving model ...
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.7880289554595947
Epoch: 82, Steps: 65 | Train Loss: 0.2971989 Vali Loss: 1.0123936 Test Loss: 0.4419205
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.6199688911437988
Epoch: 83, Steps: 65 | Train Loss: 0.2969135 Vali Loss: 1.0125057 Test Loss: 0.4419008
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.4988172054290771
Epoch: 84, Steps: 65 | Train Loss: 0.2968248 Vali Loss: 1.0119028 Test Loss: 0.4418847
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.5878000259399414
Epoch: 85, Steps: 65 | Train Loss: 0.2972272 Vali Loss: 1.0115056 Test Loss: 0.4418658
Validation loss decreased (1.011635 --> 1.011506).  Saving model ...
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.6766479015350342
Epoch: 86, Steps: 65 | Train Loss: 0.2971376 Vali Loss: 1.0123616 Test Loss: 0.4418526
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.7731728553771973
Epoch: 87, Steps: 65 | Train Loss: 0.2969068 Vali Loss: 1.0123174 Test Loss: 0.4418406
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.9192087650299072
Epoch: 88, Steps: 65 | Train Loss: 0.2968979 Vali Loss: 1.0113176 Test Loss: 0.4418259
Validation loss decreased (1.011506 --> 1.011318).  Saving model ...
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.6399407386779785
Epoch: 89, Steps: 65 | Train Loss: 0.2970092 Vali Loss: 1.0117455 Test Loss: 0.4418166
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.4729180335998535
Epoch: 90, Steps: 65 | Train Loss: 0.2971065 Vali Loss: 1.0113943 Test Loss: 0.4418006
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.5385982990264893
Epoch: 91, Steps: 65 | Train Loss: 0.2971469 Vali Loss: 1.0119622 Test Loss: 0.4417893
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.799708604812622
Epoch: 92, Steps: 65 | Train Loss: 0.2969534 Vali Loss: 1.0123020 Test Loss: 0.4417776
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.6985299587249756
Epoch: 93, Steps: 65 | Train Loss: 0.2970476 Vali Loss: 1.0120772 Test Loss: 0.4417656
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 2.173839569091797
Epoch: 94, Steps: 65 | Train Loss: 0.2967641 Vali Loss: 1.0116881 Test Loss: 0.4417581
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.762134075164795
Epoch: 95, Steps: 65 | Train Loss: 0.2971326 Vali Loss: 1.0121788 Test Loss: 0.4417465
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.7689735889434814
Epoch: 96, Steps: 65 | Train Loss: 0.2970429 Vali Loss: 1.0121714 Test Loss: 0.4417382
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.8974425792694092
Epoch: 97, Steps: 65 | Train Loss: 0.2968910 Vali Loss: 1.0122441 Test Loss: 0.4417290
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.7967157363891602
Epoch: 98, Steps: 65 | Train Loss: 0.2968589 Vali Loss: 1.0119959 Test Loss: 0.4417202
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.61124849319458
Epoch: 99, Steps: 65 | Train Loss: 0.2967143 Vali Loss: 1.0121272 Test Loss: 0.4417132
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.733933687210083
Epoch: 100, Steps: 65 | Train Loss: 0.2969135 Vali Loss: 1.0119631 Test Loss: 0.4417021
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8359
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=30, out_features=94, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2526720.0
params:  2914.0
Trainable parameters:  2914
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.952207326889038
Epoch: 1, Steps: 65 | Train Loss: 0.4259349 Vali Loss: 1.0068880 Test Loss: 0.4393306
Validation loss decreased (inf --> 1.006888).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.0236399173736572
Epoch: 2, Steps: 65 | Train Loss: 0.4234457 Vali Loss: 1.0057939 Test Loss: 0.4382846
Validation loss decreased (1.006888 --> 1.005794).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.6961512565612793
Epoch: 3, Steps: 65 | Train Loss: 0.4224433 Vali Loss: 1.0049564 Test Loss: 0.4381534
Validation loss decreased (1.005794 --> 1.004956).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.9764695167541504
Epoch: 4, Steps: 65 | Train Loss: 0.4222204 Vali Loss: 1.0041401 Test Loss: 0.4384289
Validation loss decreased (1.004956 --> 1.004140).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.7559974193572998
Epoch: 5, Steps: 65 | Train Loss: 0.4216472 Vali Loss: 1.0033888 Test Loss: 0.4382387
Validation loss decreased (1.004140 --> 1.003389).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.372258424758911
Epoch: 6, Steps: 65 | Train Loss: 0.4217468 Vali Loss: 1.0035212 Test Loss: 0.4380622
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.8213791847229004
Epoch: 7, Steps: 65 | Train Loss: 0.4217916 Vali Loss: 1.0032251 Test Loss: 0.4381573
Validation loss decreased (1.003389 --> 1.003225).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.166213274002075
Epoch: 8, Steps: 65 | Train Loss: 0.4213423 Vali Loss: 1.0032811 Test Loss: 0.4381944
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.6557581424713135
Epoch: 9, Steps: 65 | Train Loss: 0.4212334 Vali Loss: 1.0029351 Test Loss: 0.4381509
Validation loss decreased (1.003225 --> 1.002935).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.125744342803955
Epoch: 10, Steps: 65 | Train Loss: 0.4215596 Vali Loss: 1.0028450 Test Loss: 0.4383184
Validation loss decreased (1.002935 --> 1.002845).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.1115031242370605
Epoch: 11, Steps: 65 | Train Loss: 0.4216522 Vali Loss: 1.0028510 Test Loss: 0.4381885
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.5985219478607178
Epoch: 12, Steps: 65 | Train Loss: 0.4213931 Vali Loss: 1.0025905 Test Loss: 0.4385807
Validation loss decreased (1.002845 --> 1.002591).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.7495841979980469
Epoch: 13, Steps: 65 | Train Loss: 0.4216342 Vali Loss: 1.0024714 Test Loss: 0.4383592
Validation loss decreased (1.002591 --> 1.002471).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.544215440750122
Epoch: 14, Steps: 65 | Train Loss: 0.4210948 Vali Loss: 1.0024283 Test Loss: 0.4384269
Validation loss decreased (1.002471 --> 1.002428).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.155585289001465
Epoch: 15, Steps: 65 | Train Loss: 0.4214979 Vali Loss: 1.0024225 Test Loss: 0.4384483
Validation loss decreased (1.002428 --> 1.002422).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.8015055656433105
Epoch: 16, Steps: 65 | Train Loss: 0.4213510 Vali Loss: 1.0021808 Test Loss: 0.4383747
Validation loss decreased (1.002422 --> 1.002181).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.6874511241912842
Epoch: 17, Steps: 65 | Train Loss: 0.4208232 Vali Loss: 1.0022749 Test Loss: 0.4384023
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.102165460586548
Epoch: 18, Steps: 65 | Train Loss: 0.4214596 Vali Loss: 1.0021831 Test Loss: 0.4385420
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.8321325778961182
Epoch: 19, Steps: 65 | Train Loss: 0.4210708 Vali Loss: 1.0011482 Test Loss: 0.4385786
Validation loss decreased (1.002181 --> 1.001148).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.612830400466919
Epoch: 20, Steps: 65 | Train Loss: 0.4211276 Vali Loss: 1.0017143 Test Loss: 0.4384789
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.677351713180542
Epoch: 21, Steps: 65 | Train Loss: 0.4215143 Vali Loss: 1.0021174 Test Loss: 0.4384768
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.8973238468170166
Epoch: 22, Steps: 65 | Train Loss: 0.4209082 Vali Loss: 1.0020238 Test Loss: 0.4386210
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.5730607509613037
Epoch: 23, Steps: 65 | Train Loss: 0.4213575 Vali Loss: 1.0014609 Test Loss: 0.4385330
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.6920077800750732
Epoch: 24, Steps: 65 | Train Loss: 0.4212402 Vali Loss: 1.0012963 Test Loss: 0.4385431
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.8403077125549316
Epoch: 25, Steps: 65 | Train Loss: 0.4212515 Vali Loss: 1.0019740 Test Loss: 0.4385796
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.7931592464447021
Epoch: 26, Steps: 65 | Train Loss: 0.4214027 Vali Loss: 1.0018518 Test Loss: 0.4386201
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.7485957145690918
Epoch: 27, Steps: 65 | Train Loss: 0.4212512 Vali Loss: 1.0008719 Test Loss: 0.4386313
Validation loss decreased (1.001148 --> 1.000872).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.2318389415740967
Epoch: 28, Steps: 65 | Train Loss: 0.4211451 Vali Loss: 1.0008665 Test Loss: 0.4386200
Validation loss decreased (1.000872 --> 1.000867).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.3651232719421387
Epoch: 29, Steps: 65 | Train Loss: 0.4210180 Vali Loss: 1.0017368 Test Loss: 0.4386163
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.709301471710205
Epoch: 30, Steps: 65 | Train Loss: 0.4209553 Vali Loss: 1.0018028 Test Loss: 0.4386046
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.1004157066345215
Epoch: 31, Steps: 65 | Train Loss: 0.4210265 Vali Loss: 1.0018133 Test Loss: 0.4386582
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.7091758251190186
Epoch: 32, Steps: 65 | Train Loss: 0.4212510 Vali Loss: 1.0017532 Test Loss: 0.4386556
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.6624648571014404
Epoch: 33, Steps: 65 | Train Loss: 0.4208462 Vali Loss: 1.0010488 Test Loss: 0.4386360
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.11814022064209
Epoch: 34, Steps: 65 | Train Loss: 0.4209436 Vali Loss: 1.0016443 Test Loss: 0.4386595
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.5704638957977295
Epoch: 35, Steps: 65 | Train Loss: 0.4211516 Vali Loss: 1.0013657 Test Loss: 0.4387311
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.684298038482666
Epoch: 36, Steps: 65 | Train Loss: 0.4211462 Vali Loss: 1.0006686 Test Loss: 0.4387017
Validation loss decreased (1.000867 --> 1.000669).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.472607135772705
Epoch: 37, Steps: 65 | Train Loss: 0.4210730 Vali Loss: 1.0007601 Test Loss: 0.4387065
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.6750752925872803
Epoch: 38, Steps: 65 | Train Loss: 0.4209977 Vali Loss: 1.0015624 Test Loss: 0.4387610
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.8912522792816162
Epoch: 39, Steps: 65 | Train Loss: 0.4213172 Vali Loss: 1.0015329 Test Loss: 0.4388154
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.6234190464019775
Epoch: 40, Steps: 65 | Train Loss: 0.4208256 Vali Loss: 1.0016043 Test Loss: 0.4387470
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.644190788269043
Epoch: 41, Steps: 65 | Train Loss: 0.4212138 Vali Loss: 1.0015733 Test Loss: 0.4387431
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.9930551052093506
Epoch: 42, Steps: 65 | Train Loss: 0.4211563 Vali Loss: 1.0014474 Test Loss: 0.4387334
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.628814458847046
Epoch: 43, Steps: 65 | Train Loss: 0.4213448 Vali Loss: 1.0005611 Test Loss: 0.4387146
Validation loss decreased (1.000669 --> 1.000561).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.757188081741333
Epoch: 44, Steps: 65 | Train Loss: 0.4209661 Vali Loss: 1.0015597 Test Loss: 0.4387346
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.902714729309082
Epoch: 45, Steps: 65 | Train Loss: 0.4214019 Vali Loss: 1.0007267 Test Loss: 0.4387540
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.295123815536499
Epoch: 46, Steps: 65 | Train Loss: 0.4208891 Vali Loss: 1.0016429 Test Loss: 0.4387771
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.793531894683838
Epoch: 47, Steps: 65 | Train Loss: 0.4210740 Vali Loss: 1.0010476 Test Loss: 0.4387612
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.6853721141815186
Epoch: 48, Steps: 65 | Train Loss: 0.4204495 Vali Loss: 1.0015966 Test Loss: 0.4387559
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.0648374557495117
Epoch: 49, Steps: 65 | Train Loss: 0.4208236 Vali Loss: 1.0013555 Test Loss: 0.4387278
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.6907126903533936
Epoch: 50, Steps: 65 | Train Loss: 0.4213853 Vali Loss: 1.0007597 Test Loss: 0.4387404
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.6960411071777344
Epoch: 51, Steps: 65 | Train Loss: 0.4211399 Vali Loss: 1.0011655 Test Loss: 0.4387530
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.5954527854919434
Epoch: 52, Steps: 65 | Train Loss: 0.4209784 Vali Loss: 1.0010430 Test Loss: 0.4387590
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.6350657939910889
Epoch: 53, Steps: 65 | Train Loss: 0.4210934 Vali Loss: 1.0013219 Test Loss: 0.4387736
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.668668508529663
Epoch: 54, Steps: 65 | Train Loss: 0.4210780 Vali Loss: 1.0016257 Test Loss: 0.4387870
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.6599969863891602
Epoch: 55, Steps: 65 | Train Loss: 0.4213420 Vali Loss: 1.0015306 Test Loss: 0.4387926
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.8131909370422363
Epoch: 56, Steps: 65 | Train Loss: 0.4214975 Vali Loss: 1.0013524 Test Loss: 0.4387725
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.8073515892028809
Epoch: 57, Steps: 65 | Train Loss: 0.4210734 Vali Loss: 1.0015664 Test Loss: 0.4387850
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.7821059226989746
Epoch: 58, Steps: 65 | Train Loss: 0.4213581 Vali Loss: 1.0015543 Test Loss: 0.4387825
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.594818353652954
Epoch: 59, Steps: 65 | Train Loss: 0.4208060 Vali Loss: 1.0011908 Test Loss: 0.4387788
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.690276861190796
Epoch: 60, Steps: 65 | Train Loss: 0.4209489 Vali Loss: 1.0006597 Test Loss: 0.4387846
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.890066146850586
Epoch: 61, Steps: 65 | Train Loss: 0.4208719 Vali Loss: 1.0014719 Test Loss: 0.4387564
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.0404984951019287
Epoch: 62, Steps: 65 | Train Loss: 0.4208947 Vali Loss: 1.0014776 Test Loss: 0.4387821
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.0138607025146484
Epoch: 63, Steps: 65 | Train Loss: 0.4210703 Vali Loss: 1.0013303 Test Loss: 0.4387839
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_90_192_FITS_ETTh1_ftM_sl90_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.43843597173690796, mae:0.4243960380554199, rse:0.6287969350814819, corr:[0.26298842 0.26568905 0.26386786 0.26467854 0.2618037  0.25893533
 0.25851747 0.25791043 0.25740987 0.2578355  0.25746134 0.257251
 0.25724486 0.2567235  0.25650758 0.25661942 0.25675017 0.25670308
 0.25680113 0.25682816 0.25627944 0.25594434 0.25556776 0.25517777
 0.25369146 0.25282076 0.25295407 0.25328875 0.25315058 0.25319538
 0.2534823  0.2532725  0.25302988 0.25272438 0.2524524  0.25258702
 0.2524865  0.2523913  0.2526207  0.25270128 0.25296    0.2533143
 0.25375447 0.25394794 0.25385016 0.2536891  0.253586   0.25328198
 0.25211713 0.2509348  0.25011355 0.2495941  0.24865092 0.24753006
 0.24737641 0.24702804 0.24671537 0.24689038 0.24662206 0.24642523
 0.2463858  0.24632597 0.24608295 0.24583293 0.24595179 0.24597912
 0.24650426 0.24687694 0.24659848 0.24645428 0.24626742 0.24539389
 0.24373983 0.24264398 0.24196336 0.24171254 0.2412735  0.24098249
 0.24124359 0.24095836 0.2406305  0.24042524 0.24020809 0.23994915
 0.23974752 0.23974246 0.23997967 0.24003385 0.24005327 0.24007833
 0.24030729 0.24051698 0.24034484 0.24036457 0.2404494  0.2401575
 0.23913953 0.23833719 0.23788211 0.23757116 0.23742601 0.23728849
 0.23752056 0.23737453 0.23706822 0.23699756 0.23684113 0.2365313
 0.23638529 0.2362819  0.23631372 0.23633283 0.23672673 0.23673849
 0.23696096 0.23732686 0.23732957 0.23737888 0.23716868 0.23621725
 0.2345558  0.23337255 0.23231702 0.2313545  0.23089308 0.2308552
 0.23151827 0.23170482 0.23159786 0.23139517 0.23104922 0.23087692
 0.23069613 0.23042913 0.23035216 0.2302089  0.23043269 0.23041916
 0.23063394 0.23108655 0.23101144 0.23105557 0.23103711 0.23022878
 0.22854587 0.22734557 0.2266036  0.22593716 0.22541797 0.22531396
 0.22611338 0.22615665 0.22601517 0.2260153  0.22587615 0.22571926
 0.22552048 0.22535162 0.22511049 0.22481613 0.22488096 0.22494023
 0.22528918 0.22565334 0.22547762 0.22545613 0.22542983 0.2245894
 0.22295383 0.22189973 0.22153409 0.22155142 0.22093429 0.22062683
 0.22133718 0.22125997 0.22090419 0.2209483  0.22108316 0.22111586
 0.22097339 0.22039475 0.22015768 0.21994673 0.21966977 0.21994336
 0.22069263 0.22079141 0.2208833  0.22147001 0.22135878 0.22231047]
