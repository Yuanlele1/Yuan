Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=30, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_90_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_90_96_FITS_ETTh1_ftM_sl90_ll48_pl96_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8455
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=30, out_features=62, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1666560.0
params:  1922.0
Trainable parameters:  1922
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.8669590950012207
Epoch: 1, Steps: 66 | Train Loss: 0.5883831 Vali Loss: 1.2154623 Test Loss: 0.7745246
Validation loss decreased (inf --> 1.215462).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.7697422504425049
Epoch: 2, Steps: 66 | Train Loss: 0.4587000 Vali Loss: 1.0602102 Test Loss: 0.6398620
Validation loss decreased (1.215462 --> 1.060210).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.589521884918213
Epoch: 3, Steps: 66 | Train Loss: 0.3829899 Vali Loss: 0.9651164 Test Loss: 0.5620415
Validation loss decreased (1.060210 --> 0.965116).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.6852648258209229
Epoch: 4, Steps: 66 | Train Loss: 0.3361037 Vali Loss: 0.9110281 Test Loss: 0.5157210
Validation loss decreased (0.965116 --> 0.911028).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.4294333457946777
Epoch: 5, Steps: 66 | Train Loss: 0.3051565 Vali Loss: 0.8664546 Test Loss: 0.4864511
Validation loss decreased (0.911028 --> 0.866455).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.5688679218292236
Epoch: 6, Steps: 66 | Train Loss: 0.2837287 Vali Loss: 0.8399187 Test Loss: 0.4663793
Validation loss decreased (0.866455 --> 0.839919).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.653418779373169
Epoch: 7, Steps: 66 | Train Loss: 0.2681793 Vali Loss: 0.8183889 Test Loss: 0.4522546
Validation loss decreased (0.839919 --> 0.818389).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.7162413597106934
Epoch: 8, Steps: 66 | Train Loss: 0.2565610 Vali Loss: 0.8049425 Test Loss: 0.4415971
Validation loss decreased (0.818389 --> 0.804943).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.0053584575653076
Epoch: 9, Steps: 66 | Train Loss: 0.2476950 Vali Loss: 0.7913387 Test Loss: 0.4341066
Validation loss decreased (0.804943 --> 0.791339).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.0107719898223877
Epoch: 10, Steps: 66 | Train Loss: 0.2405773 Vali Loss: 0.7833385 Test Loss: 0.4279607
Validation loss decreased (0.791339 --> 0.783339).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.0936574935913086
Epoch: 11, Steps: 66 | Train Loss: 0.2349642 Vali Loss: 0.7705094 Test Loss: 0.4230322
Validation loss decreased (0.783339 --> 0.770509).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.945932388305664
Epoch: 12, Steps: 66 | Train Loss: 0.2302828 Vali Loss: 0.7641893 Test Loss: 0.4194182
Validation loss decreased (0.770509 --> 0.764189).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.1564297676086426
Epoch: 13, Steps: 66 | Train Loss: 0.2264858 Vali Loss: 0.7674640 Test Loss: 0.4162078
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.441737413406372
Epoch: 14, Steps: 66 | Train Loss: 0.2232965 Vali Loss: 0.7596182 Test Loss: 0.4136629
Validation loss decreased (0.764189 --> 0.759618).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.1538174152374268
Epoch: 15, Steps: 66 | Train Loss: 0.2204648 Vali Loss: 0.7508720 Test Loss: 0.4113326
Validation loss decreased (0.759618 --> 0.750872).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.8136768341064453
Epoch: 16, Steps: 66 | Train Loss: 0.2181779 Vali Loss: 0.7478216 Test Loss: 0.4096145
Validation loss decreased (0.750872 --> 0.747822).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.7606298923492432
Epoch: 17, Steps: 66 | Train Loss: 0.2161058 Vali Loss: 0.7478996 Test Loss: 0.4080554
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.6178669929504395
Epoch: 18, Steps: 66 | Train Loss: 0.2143260 Vali Loss: 0.7427030 Test Loss: 0.4068229
Validation loss decreased (0.747822 --> 0.742703).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.9746520519256592
Epoch: 19, Steps: 66 | Train Loss: 0.2127815 Vali Loss: 0.7429793 Test Loss: 0.4057319
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.6871023178100586
Epoch: 20, Steps: 66 | Train Loss: 0.2114988 Vali Loss: 0.7348241 Test Loss: 0.4047934
Validation loss decreased (0.742703 --> 0.734824).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.054568290710449
Epoch: 21, Steps: 66 | Train Loss: 0.2103244 Vali Loss: 0.7364994 Test Loss: 0.4039078
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.5645830631256104
Epoch: 22, Steps: 66 | Train Loss: 0.2092376 Vali Loss: 0.7358577 Test Loss: 0.4031197
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.714550495147705
Epoch: 23, Steps: 66 | Train Loss: 0.2082461 Vali Loss: 0.7330022 Test Loss: 0.4025147
Validation loss decreased (0.734824 --> 0.733002).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.60964035987854
Epoch: 24, Steps: 66 | Train Loss: 0.2074390 Vali Loss: 0.7333328 Test Loss: 0.4019690
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.762791395187378
Epoch: 25, Steps: 66 | Train Loss: 0.2066502 Vali Loss: 0.7348964 Test Loss: 0.4014863
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.6464812755584717
Epoch: 26, Steps: 66 | Train Loss: 0.2059651 Vali Loss: 0.7273653 Test Loss: 0.4010172
Validation loss decreased (0.733002 --> 0.727365).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.6518383026123047
Epoch: 27, Steps: 66 | Train Loss: 0.2052827 Vali Loss: 0.7311734 Test Loss: 0.4006068
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.1648736000061035
Epoch: 28, Steps: 66 | Train Loss: 0.2047153 Vali Loss: 0.7284621 Test Loss: 0.4002507
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.8837878704071045
Epoch: 29, Steps: 66 | Train Loss: 0.2042330 Vali Loss: 0.7295800 Test Loss: 0.3999423
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.6766357421875
Epoch: 30, Steps: 66 | Train Loss: 0.2038019 Vali Loss: 0.7244630 Test Loss: 0.3996567
Validation loss decreased (0.727365 --> 0.724463).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.7332968711853027
Epoch: 31, Steps: 66 | Train Loss: 0.2033708 Vali Loss: 0.7294663 Test Loss: 0.3993894
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.8562638759613037
Epoch: 32, Steps: 66 | Train Loss: 0.2028488 Vali Loss: 0.7254952 Test Loss: 0.3991248
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.7452993392944336
Epoch: 33, Steps: 66 | Train Loss: 0.2025603 Vali Loss: 0.7229928 Test Loss: 0.3989371
Validation loss decreased (0.724463 --> 0.722993).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.4034924507141113
Epoch: 34, Steps: 66 | Train Loss: 0.2022441 Vali Loss: 0.7285339 Test Loss: 0.3987222
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.7925407886505127
Epoch: 35, Steps: 66 | Train Loss: 0.2018685 Vali Loss: 0.7268817 Test Loss: 0.3985605
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.6929306983947754
Epoch: 36, Steps: 66 | Train Loss: 0.2016147 Vali Loss: 0.7282613 Test Loss: 0.3983777
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.126889705657959
Epoch: 37, Steps: 66 | Train Loss: 0.2012895 Vali Loss: 0.7213483 Test Loss: 0.3981984
Validation loss decreased (0.722993 --> 0.721348).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.5446906089782715
Epoch: 38, Steps: 66 | Train Loss: 0.2010644 Vali Loss: 0.7210887 Test Loss: 0.3980663
Validation loss decreased (0.721348 --> 0.721089).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.911766529083252
Epoch: 39, Steps: 66 | Train Loss: 0.2008681 Vali Loss: 0.7265924 Test Loss: 0.3979630
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.5313475131988525
Epoch: 40, Steps: 66 | Train Loss: 0.2006225 Vali Loss: 0.7229172 Test Loss: 0.3978306
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.8605594635009766
Epoch: 41, Steps: 66 | Train Loss: 0.2004953 Vali Loss: 0.7188019 Test Loss: 0.3977235
Validation loss decreased (0.721089 --> 0.718802).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.371211290359497
Epoch: 42, Steps: 66 | Train Loss: 0.2002374 Vali Loss: 0.7249496 Test Loss: 0.3975997
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.89866304397583
Epoch: 43, Steps: 66 | Train Loss: 0.2000627 Vali Loss: 0.7225399 Test Loss: 0.3975064
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.7418715953826904
Epoch: 44, Steps: 66 | Train Loss: 0.1998640 Vali Loss: 0.7221292 Test Loss: 0.3973962
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.5989313125610352
Epoch: 45, Steps: 66 | Train Loss: 0.1997624 Vali Loss: 0.7236486 Test Loss: 0.3973168
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.8369226455688477
Epoch: 46, Steps: 66 | Train Loss: 0.1996142 Vali Loss: 0.7220575 Test Loss: 0.3972227
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.9329249858856201
Epoch: 47, Steps: 66 | Train Loss: 0.1994788 Vali Loss: 0.7205993 Test Loss: 0.3971464
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.0104823112487793
Epoch: 48, Steps: 66 | Train Loss: 0.1993124 Vali Loss: 0.7203416 Test Loss: 0.3970890
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.7230231761932373
Epoch: 49, Steps: 66 | Train Loss: 0.1992194 Vali Loss: 0.7233614 Test Loss: 0.3970172
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.5955777168273926
Epoch: 50, Steps: 66 | Train Loss: 0.1991429 Vali Loss: 0.7190716 Test Loss: 0.3969466
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.9012386798858643
Epoch: 51, Steps: 66 | Train Loss: 0.1989978 Vali Loss: 0.7213567 Test Loss: 0.3968962
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.343353033065796
Epoch: 52, Steps: 66 | Train Loss: 0.1989092 Vali Loss: 0.7192332 Test Loss: 0.3968116
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.4794301986694336
Epoch: 53, Steps: 66 | Train Loss: 0.1987874 Vali Loss: 0.7148947 Test Loss: 0.3967825
Validation loss decreased (0.718802 --> 0.714895).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.9467740058898926
Epoch: 54, Steps: 66 | Train Loss: 0.1987429 Vali Loss: 0.7206817 Test Loss: 0.3967293
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.6177661418914795
Epoch: 55, Steps: 66 | Train Loss: 0.1986354 Vali Loss: 0.7177663 Test Loss: 0.3966656
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.6520764827728271
Epoch: 56, Steps: 66 | Train Loss: 0.1985034 Vali Loss: 0.7160869 Test Loss: 0.3966207
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.8243484497070312
Epoch: 57, Steps: 66 | Train Loss: 0.1985394 Vali Loss: 0.7193736 Test Loss: 0.3965817
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.737638235092163
Epoch: 58, Steps: 66 | Train Loss: 0.1983732 Vali Loss: 0.7144589 Test Loss: 0.3965386
Validation loss decreased (0.714895 --> 0.714459).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.4735918045043945
Epoch: 59, Steps: 66 | Train Loss: 0.1983356 Vali Loss: 0.7192407 Test Loss: 0.3965054
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.5438683032989502
Epoch: 60, Steps: 66 | Train Loss: 0.1982396 Vali Loss: 0.7194117 Test Loss: 0.3964589
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.4711594581604004
Epoch: 61, Steps: 66 | Train Loss: 0.1982485 Vali Loss: 0.7121383 Test Loss: 0.3964269
Validation loss decreased (0.714459 --> 0.712138).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.540264368057251
Epoch: 62, Steps: 66 | Train Loss: 0.1981557 Vali Loss: 0.7150093 Test Loss: 0.3963930
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.6226065158843994
Epoch: 63, Steps: 66 | Train Loss: 0.1980496 Vali Loss: 0.7136410 Test Loss: 0.3963555
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.5633952617645264
Epoch: 64, Steps: 66 | Train Loss: 0.1979785 Vali Loss: 0.7135035 Test Loss: 0.3963259
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.5894372463226318
Epoch: 65, Steps: 66 | Train Loss: 0.1980237 Vali Loss: 0.7187678 Test Loss: 0.3962907
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.5703158378601074
Epoch: 66, Steps: 66 | Train Loss: 0.1979239 Vali Loss: 0.7158933 Test Loss: 0.3962533
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.6308531761169434
Epoch: 67, Steps: 66 | Train Loss: 0.1978728 Vali Loss: 0.7187750 Test Loss: 0.3962339
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.150217294692993
Epoch: 68, Steps: 66 | Train Loss: 0.1978172 Vali Loss: 0.7175870 Test Loss: 0.3962035
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.5711603164672852
Epoch: 69, Steps: 66 | Train Loss: 0.1978087 Vali Loss: 0.7190017 Test Loss: 0.3961812
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.512321710586548
Epoch: 70, Steps: 66 | Train Loss: 0.1977918 Vali Loss: 0.7175439 Test Loss: 0.3961537
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.5336952209472656
Epoch: 71, Steps: 66 | Train Loss: 0.1976935 Vali Loss: 0.7176411 Test Loss: 0.3961304
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.616041660308838
Epoch: 72, Steps: 66 | Train Loss: 0.1976238 Vali Loss: 0.7148224 Test Loss: 0.3961072
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.5976638793945312
Epoch: 73, Steps: 66 | Train Loss: 0.1975780 Vali Loss: 0.7194445 Test Loss: 0.3960860
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.6122586727142334
Epoch: 74, Steps: 66 | Train Loss: 0.1976162 Vali Loss: 0.7124789 Test Loss: 0.3960646
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.6982581615447998
Epoch: 75, Steps: 66 | Train Loss: 0.1975542 Vali Loss: 0.7158664 Test Loss: 0.3960478
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.575066328048706
Epoch: 76, Steps: 66 | Train Loss: 0.1975149 Vali Loss: 0.7180350 Test Loss: 0.3960219
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.3705339431762695
Epoch: 77, Steps: 66 | Train Loss: 0.1974546 Vali Loss: 0.7114746 Test Loss: 0.3960062
Validation loss decreased (0.712138 --> 0.711475).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.6452183723449707
Epoch: 78, Steps: 66 | Train Loss: 0.1974791 Vali Loss: 0.7187475 Test Loss: 0.3959888
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.9907901287078857
Epoch: 79, Steps: 66 | Train Loss: 0.1974624 Vali Loss: 0.7210473 Test Loss: 0.3959737
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.5122277736663818
Epoch: 80, Steps: 66 | Train Loss: 0.1975140 Vali Loss: 0.7161846 Test Loss: 0.3959582
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.5782830715179443
Epoch: 81, Steps: 66 | Train Loss: 0.1973818 Vali Loss: 0.7171062 Test Loss: 0.3959415
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 2.0025854110717773
Epoch: 82, Steps: 66 | Train Loss: 0.1974125 Vali Loss: 0.7124905 Test Loss: 0.3959271
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.158849000930786
Epoch: 83, Steps: 66 | Train Loss: 0.1973615 Vali Loss: 0.7187734 Test Loss: 0.3959125
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.7900035381317139
Epoch: 84, Steps: 66 | Train Loss: 0.1973829 Vali Loss: 0.7150747 Test Loss: 0.3958982
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.1116325855255127
Epoch: 85, Steps: 66 | Train Loss: 0.1973507 Vali Loss: 0.7181249 Test Loss: 0.3958881
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 2.32080078125
Epoch: 86, Steps: 66 | Train Loss: 0.1973302 Vali Loss: 0.7191809 Test Loss: 0.3958747
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.8366222381591797
Epoch: 87, Steps: 66 | Train Loss: 0.1972574 Vali Loss: 0.7162068 Test Loss: 0.3958642
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.8625221252441406
Epoch: 88, Steps: 66 | Train Loss: 0.1973040 Vali Loss: 0.7172602 Test Loss: 0.3958528
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.774498701095581
Epoch: 89, Steps: 66 | Train Loss: 0.1971924 Vali Loss: 0.7175785 Test Loss: 0.3958443
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 2.3871009349823
Epoch: 90, Steps: 66 | Train Loss: 0.1972831 Vali Loss: 0.7185820 Test Loss: 0.3958283
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.117485761642456
Epoch: 91, Steps: 66 | Train Loss: 0.1972694 Vali Loss: 0.7155747 Test Loss: 0.3958222
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 2.1592390537261963
Epoch: 92, Steps: 66 | Train Loss: 0.1971524 Vali Loss: 0.7137014 Test Loss: 0.3958129
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.8929524421691895
Epoch: 93, Steps: 66 | Train Loss: 0.1972403 Vali Loss: 0.7172626 Test Loss: 0.3958048
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.5835447311401367
Epoch: 94, Steps: 66 | Train Loss: 0.1971857 Vali Loss: 0.7173001 Test Loss: 0.3957968
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.5847418308258057
Epoch: 95, Steps: 66 | Train Loss: 0.1971884 Vali Loss: 0.7198098 Test Loss: 0.3957878
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.659717321395874
Epoch: 96, Steps: 66 | Train Loss: 0.1971729 Vali Loss: 0.7195855 Test Loss: 0.3957802
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.6013810634613037
Epoch: 97, Steps: 66 | Train Loss: 0.1971998 Vali Loss: 0.7172682 Test Loss: 0.3957737
EarlyStopping counter: 20 out of 20
Early stopping
train 8455
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=30, out_features=62, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1666560.0
params:  1922.0
Trainable parameters:  1922
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.8670237064361572
Epoch: 1, Steps: 66 | Train Loss: 0.3621355 Vali Loss: 0.7092601 Test Loss: 0.3920863
Validation loss decreased (inf --> 0.709260).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.5389955043792725
Epoch: 2, Steps: 66 | Train Loss: 0.3599185 Vali Loss: 0.7073584 Test Loss: 0.3903308
Validation loss decreased (0.709260 --> 0.707358).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.5945193767547607
Epoch: 3, Steps: 66 | Train Loss: 0.3588814 Vali Loss: 0.7078252 Test Loss: 0.3893802
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.3391096591949463
Epoch: 4, Steps: 66 | Train Loss: 0.3584383 Vali Loss: 0.7095460 Test Loss: 0.3889982
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.514836311340332
Epoch: 5, Steps: 66 | Train Loss: 0.3580178 Vali Loss: 0.7034120 Test Loss: 0.3887968
Validation loss decreased (0.707358 --> 0.703412).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.9796109199523926
Epoch: 6, Steps: 66 | Train Loss: 0.3577309 Vali Loss: 0.7051065 Test Loss: 0.3886473
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.5140292644500732
Epoch: 7, Steps: 66 | Train Loss: 0.3578444 Vali Loss: 0.7025397 Test Loss: 0.3887314
Validation loss decreased (0.703412 --> 0.702540).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.7595875263214111
Epoch: 8, Steps: 66 | Train Loss: 0.3577871 Vali Loss: 0.7088177 Test Loss: 0.3884293
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.4628181457519531
Epoch: 9, Steps: 66 | Train Loss: 0.3575981 Vali Loss: 0.7054364 Test Loss: 0.3882578
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.7118821144104004
Epoch: 10, Steps: 66 | Train Loss: 0.3575900 Vali Loss: 0.7038855 Test Loss: 0.3885169
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.5524232387542725
Epoch: 11, Steps: 66 | Train Loss: 0.3575790 Vali Loss: 0.7069896 Test Loss: 0.3883321
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.7740511894226074
Epoch: 12, Steps: 66 | Train Loss: 0.3573932 Vali Loss: 0.7058077 Test Loss: 0.3883605
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.6009962558746338
Epoch: 13, Steps: 66 | Train Loss: 0.3573303 Vali Loss: 0.7046116 Test Loss: 0.3884877
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.0053415298461914
Epoch: 14, Steps: 66 | Train Loss: 0.3574570 Vali Loss: 0.7030975 Test Loss: 0.3883826
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.6488897800445557
Epoch: 15, Steps: 66 | Train Loss: 0.3574476 Vali Loss: 0.7019939 Test Loss: 0.3882508
Validation loss decreased (0.702540 --> 0.701994).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.303006649017334
Epoch: 16, Steps: 66 | Train Loss: 0.3573026 Vali Loss: 0.7074765 Test Loss: 0.3884345
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.5926222801208496
Epoch: 17, Steps: 66 | Train Loss: 0.3573373 Vali Loss: 0.7054335 Test Loss: 0.3883173
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.7358953952789307
Epoch: 18, Steps: 66 | Train Loss: 0.3573890 Vali Loss: 0.7056667 Test Loss: 0.3883868
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.107451915740967
Epoch: 19, Steps: 66 | Train Loss: 0.3573073 Vali Loss: 0.7009005 Test Loss: 0.3883465
Validation loss decreased (0.701994 --> 0.700900).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.157043933868408
Epoch: 20, Steps: 66 | Train Loss: 0.3572629 Vali Loss: 0.7021680 Test Loss: 0.3883941
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.0447566509246826
Epoch: 21, Steps: 66 | Train Loss: 0.3572088 Vali Loss: 0.7023031 Test Loss: 0.3883869
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.832977056503296
Epoch: 22, Steps: 66 | Train Loss: 0.3572552 Vali Loss: 0.7096235 Test Loss: 0.3883804
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.073486089706421
Epoch: 23, Steps: 66 | Train Loss: 0.3572003 Vali Loss: 0.7009808 Test Loss: 0.3883823
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.6589725017547607
Epoch: 24, Steps: 66 | Train Loss: 0.3572031 Vali Loss: 0.7064103 Test Loss: 0.3883431
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.9348526000976562
Epoch: 25, Steps: 66 | Train Loss: 0.3572245 Vali Loss: 0.7026972 Test Loss: 0.3883512
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.2208175659179688
Epoch: 26, Steps: 66 | Train Loss: 0.3571521 Vali Loss: 0.6995152 Test Loss: 0.3883897
Validation loss decreased (0.700900 --> 0.699515).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.5216612815856934
Epoch: 27, Steps: 66 | Train Loss: 0.3571198 Vali Loss: 0.6996176 Test Loss: 0.3883882
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.8619272708892822
Epoch: 28, Steps: 66 | Train Loss: 0.3572651 Vali Loss: 0.7011402 Test Loss: 0.3883615
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.5261998176574707
Epoch: 29, Steps: 66 | Train Loss: 0.3571444 Vali Loss: 0.7035747 Test Loss: 0.3884157
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.627856731414795
Epoch: 30, Steps: 66 | Train Loss: 0.3571084 Vali Loss: 0.6992642 Test Loss: 0.3884001
Validation loss decreased (0.699515 --> 0.699264).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.6647522449493408
Epoch: 31, Steps: 66 | Train Loss: 0.3570857 Vali Loss: 0.7018176 Test Loss: 0.3883785
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.999640941619873
Epoch: 32, Steps: 66 | Train Loss: 0.3570659 Vali Loss: 0.7034542 Test Loss: 0.3883953
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.07559871673584
Epoch: 33, Steps: 66 | Train Loss: 0.3571575 Vali Loss: 0.7009772 Test Loss: 0.3884373
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.2135646343231201
Epoch: 34, Steps: 66 | Train Loss: 0.3570423 Vali Loss: 0.6966199 Test Loss: 0.3884115
Validation loss decreased (0.699264 --> 0.696620).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.745643138885498
Epoch: 35, Steps: 66 | Train Loss: 0.3569568 Vali Loss: 0.6998320 Test Loss: 0.3884119
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.6153874397277832
Epoch: 36, Steps: 66 | Train Loss: 0.3571208 Vali Loss: 0.7057856 Test Loss: 0.3884266
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.6058578491210938
Epoch: 37, Steps: 66 | Train Loss: 0.3569979 Vali Loss: 0.7019327 Test Loss: 0.3883653
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.6296374797821045
Epoch: 38, Steps: 66 | Train Loss: 0.3570017 Vali Loss: 0.7022441 Test Loss: 0.3883969
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.019444704055786
Epoch: 39, Steps: 66 | Train Loss: 0.3570326 Vali Loss: 0.7048114 Test Loss: 0.3884479
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.906083583831787
Epoch: 40, Steps: 66 | Train Loss: 0.3571326 Vali Loss: 0.7038437 Test Loss: 0.3884254
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.7185568809509277
Epoch: 41, Steps: 66 | Train Loss: 0.3570600 Vali Loss: 0.7049096 Test Loss: 0.3884175
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.6605260372161865
Epoch: 42, Steps: 66 | Train Loss: 0.3570490 Vali Loss: 0.7021652 Test Loss: 0.3884422
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.4521458148956299
Epoch: 43, Steps: 66 | Train Loss: 0.3570265 Vali Loss: 0.7033520 Test Loss: 0.3884430
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.6710529327392578
Epoch: 44, Steps: 66 | Train Loss: 0.3571327 Vali Loss: 0.7016442 Test Loss: 0.3884345
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.9819247722625732
Epoch: 45, Steps: 66 | Train Loss: 0.3570865 Vali Loss: 0.7024294 Test Loss: 0.3884060
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.2239086627960205
Epoch: 46, Steps: 66 | Train Loss: 0.3569559 Vali Loss: 0.7001239 Test Loss: 0.3884073
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.3735196590423584
Epoch: 47, Steps: 66 | Train Loss: 0.3568765 Vali Loss: 0.6981656 Test Loss: 0.3884333
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.5736846923828125
Epoch: 48, Steps: 66 | Train Loss: 0.3570166 Vali Loss: 0.7028698 Test Loss: 0.3884096
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.5682477951049805
Epoch: 49, Steps: 66 | Train Loss: 0.3569491 Vali Loss: 0.7019076 Test Loss: 0.3884472
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.8215463161468506
Epoch: 50, Steps: 66 | Train Loss: 0.3570616 Vali Loss: 0.7039587 Test Loss: 0.3884194
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.8116528987884521
Epoch: 51, Steps: 66 | Train Loss: 0.3570193 Vali Loss: 0.7028444 Test Loss: 0.3884227
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.9815459251403809
Epoch: 52, Steps: 66 | Train Loss: 0.3571153 Vali Loss: 0.6994585 Test Loss: 0.3884449
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.434451103210449
Epoch: 53, Steps: 66 | Train Loss: 0.3569457 Vali Loss: 0.7035495 Test Loss: 0.3884149
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.684511661529541
Epoch: 54, Steps: 66 | Train Loss: 0.3569942 Vali Loss: 0.7015539 Test Loss: 0.3884307
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_90_96_FITS_ETTh1_ftM_sl90_ll48_pl96_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.3876190781593323, mae:0.3952949643135071, rse:0.5913715362548828, corr:[0.27062973 0.27377138 0.27210614 0.2730537  0.27040496 0.2675995
 0.26713765 0.2666216  0.26616958 0.26640117 0.26583186 0.26558793
 0.26566067 0.26513356 0.2648476  0.2649398  0.26512995 0.26513058
 0.26522103 0.26524058 0.26474273 0.26441532 0.26399705 0.26363719
 0.26220208 0.26130125 0.26147938 0.2618583  0.2617088  0.2618086
 0.26216745 0.26189864 0.26162988 0.2613562  0.26107407 0.2610817
 0.26083216 0.2606096  0.26079288 0.26086253 0.26109344 0.26151273
 0.26210123 0.26233843 0.26213953 0.2618953  0.2617664  0.26151434
 0.260447   0.2592312  0.2582725  0.25770855 0.25682664 0.255723
 0.255529   0.25511762 0.25481197 0.25504088 0.25480103 0.25459167
 0.2545693  0.2545877  0.25437912 0.25412974 0.25423667 0.25427365
 0.2548281  0.25518915 0.2548749  0.2547054  0.25448132 0.25353315
 0.25195935 0.25099805 0.2502595  0.24996233 0.24968915 0.2495437
 0.24985369 0.24945526 0.2490703  0.24892119 0.24866407 0.24838504
 0.24807455 0.24792379 0.24814923 0.24805209 0.24780779 0.24792069
 0.24828628 0.24799299 0.24755815 0.24757305 0.24763754 0.24842875]
