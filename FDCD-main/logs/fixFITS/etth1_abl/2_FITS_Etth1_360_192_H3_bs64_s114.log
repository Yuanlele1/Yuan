Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=58, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_360_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_360_192_FITS_ETTh1_ftM_sl360_ll48_pl192_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8089
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=58, out_features=88, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4573184.0
params:  5192.0
Trainable parameters:  5192
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.0612199306488037
Epoch: 1, Steps: 63 | Train Loss: 0.6380718 Vali Loss: 1.6114004 Test Loss: 0.8307180
Validation loss decreased (inf --> 1.611400).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.077483892440796
Epoch: 2, Steps: 63 | Train Loss: 0.5151701 Vali Loss: 1.4417620 Test Loss: 0.7335665
Validation loss decreased (1.611400 --> 1.441762).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.102076768875122
Epoch: 3, Steps: 63 | Train Loss: 0.4420922 Vali Loss: 1.3473073 Test Loss: 0.6803841
Validation loss decreased (1.441762 --> 1.347307).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.1798999309539795
Epoch: 4, Steps: 63 | Train Loss: 0.3969451 Vali Loss: 1.2880557 Test Loss: 0.6478449
Validation loss decreased (1.347307 --> 1.288056).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.2305424213409424
Epoch: 5, Steps: 63 | Train Loss: 0.3663983 Vali Loss: 1.2471703 Test Loss: 0.6256052
Validation loss decreased (1.288056 --> 1.247170).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.2408525943756104
Epoch: 6, Steps: 63 | Train Loss: 0.3444091 Vali Loss: 1.2178357 Test Loss: 0.6092219
Validation loss decreased (1.247170 --> 1.217836).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.1286990642547607
Epoch: 7, Steps: 63 | Train Loss: 0.3270787 Vali Loss: 1.1965765 Test Loss: 0.5977864
Validation loss decreased (1.217836 --> 1.196576).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.377096652984619
Epoch: 8, Steps: 63 | Train Loss: 0.3129409 Vali Loss: 1.1768048 Test Loss: 0.5867015
Validation loss decreased (1.196576 --> 1.176805).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.160736322402954
Epoch: 9, Steps: 63 | Train Loss: 0.3011820 Vali Loss: 1.1621088 Test Loss: 0.5777373
Validation loss decreased (1.176805 --> 1.162109).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.231027841567993
Epoch: 10, Steps: 63 | Train Loss: 0.2908150 Vali Loss: 1.1472639 Test Loss: 0.5686749
Validation loss decreased (1.162109 --> 1.147264).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.8504326343536377
Epoch: 11, Steps: 63 | Train Loss: 0.2817982 Vali Loss: 1.1353483 Test Loss: 0.5612217
Validation loss decreased (1.147264 --> 1.135348).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.2702553272247314
Epoch: 12, Steps: 63 | Train Loss: 0.2740196 Vali Loss: 1.1235788 Test Loss: 0.5540078
Validation loss decreased (1.135348 --> 1.123579).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.7598559856414795
Epoch: 13, Steps: 63 | Train Loss: 0.2670233 Vali Loss: 1.1131641 Test Loss: 0.5473901
Validation loss decreased (1.123579 --> 1.113164).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.1315925121307373
Epoch: 14, Steps: 63 | Train Loss: 0.2608568 Vali Loss: 1.1033589 Test Loss: 0.5409713
Validation loss decreased (1.113164 --> 1.103359).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.452838182449341
Epoch: 15, Steps: 63 | Train Loss: 0.2551801 Vali Loss: 1.0951273 Test Loss: 0.5353128
Validation loss decreased (1.103359 --> 1.095127).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.074850082397461
Epoch: 16, Steps: 63 | Train Loss: 0.2502572 Vali Loss: 1.0870724 Test Loss: 0.5301916
Validation loss decreased (1.095127 --> 1.087072).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.3259031772613525
Epoch: 17, Steps: 63 | Train Loss: 0.2456825 Vali Loss: 1.0796295 Test Loss: 0.5250278
Validation loss decreased (1.087072 --> 1.079630).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.8112094402313232
Epoch: 18, Steps: 63 | Train Loss: 0.2415611 Vali Loss: 1.0735183 Test Loss: 0.5208586
Validation loss decreased (1.079630 --> 1.073518).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.4735257625579834
Epoch: 19, Steps: 63 | Train Loss: 0.2379602 Vali Loss: 1.0671670 Test Loss: 0.5165063
Validation loss decreased (1.073518 --> 1.067167).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.7084555625915527
Epoch: 20, Steps: 63 | Train Loss: 0.2345860 Vali Loss: 1.0616140 Test Loss: 0.5126681
Validation loss decreased (1.067167 --> 1.061614).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.0123252868652344
Epoch: 21, Steps: 63 | Train Loss: 0.2314564 Vali Loss: 1.0560423 Test Loss: 0.5089471
Validation loss decreased (1.061614 --> 1.056042).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.776137113571167
Epoch: 22, Steps: 63 | Train Loss: 0.2286567 Vali Loss: 1.0509092 Test Loss: 0.5053955
Validation loss decreased (1.056042 --> 1.050909).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.6873209476470947
Epoch: 23, Steps: 63 | Train Loss: 0.2260853 Vali Loss: 1.0465095 Test Loss: 0.5022808
Validation loss decreased (1.050909 --> 1.046510).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.0683043003082275
Epoch: 24, Steps: 63 | Train Loss: 0.2237717 Vali Loss: 1.0425558 Test Loss: 0.4995441
Validation loss decreased (1.046510 --> 1.042556).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.5008726119995117
Epoch: 25, Steps: 63 | Train Loss: 0.2215681 Vali Loss: 1.0382619 Test Loss: 0.4968120
Validation loss decreased (1.042556 --> 1.038262).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.671607494354248
Epoch: 26, Steps: 63 | Train Loss: 0.2194631 Vali Loss: 1.0345495 Test Loss: 0.4940998
Validation loss decreased (1.038262 --> 1.034549).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.1381185054779053
Epoch: 27, Steps: 63 | Train Loss: 0.2177367 Vali Loss: 1.0305761 Test Loss: 0.4915457
Validation loss decreased (1.034549 --> 1.030576).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.34037184715271
Epoch: 28, Steps: 63 | Train Loss: 0.2159610 Vali Loss: 1.0274444 Test Loss: 0.4892963
Validation loss decreased (1.030576 --> 1.027444).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.2883222103118896
Epoch: 29, Steps: 63 | Train Loss: 0.2144581 Vali Loss: 1.0249010 Test Loss: 0.4872763
Validation loss decreased (1.027444 --> 1.024901).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.2983288764953613
Epoch: 30, Steps: 63 | Train Loss: 0.2129496 Vali Loss: 1.0218416 Test Loss: 0.4852051
Validation loss decreased (1.024901 --> 1.021842).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.342437267303467
Epoch: 31, Steps: 63 | Train Loss: 0.2116160 Vali Loss: 1.0193198 Test Loss: 0.4835926
Validation loss decreased (1.021842 --> 1.019320).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.1572160720825195
Epoch: 32, Steps: 63 | Train Loss: 0.2102884 Vali Loss: 1.0163360 Test Loss: 0.4815577
Validation loss decreased (1.019320 --> 1.016336).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.923219680786133
Epoch: 33, Steps: 63 | Train Loss: 0.2091732 Vali Loss: 1.0145007 Test Loss: 0.4801153
Validation loss decreased (1.016336 --> 1.014501).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.956230878829956
Epoch: 34, Steps: 63 | Train Loss: 0.2080517 Vali Loss: 1.0120983 Test Loss: 0.4784620
Validation loss decreased (1.014501 --> 1.012098).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.328580856323242
Epoch: 35, Steps: 63 | Train Loss: 0.2070924 Vali Loss: 1.0097251 Test Loss: 0.4770554
Validation loss decreased (1.012098 --> 1.009725).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.382795810699463
Epoch: 36, Steps: 63 | Train Loss: 0.2060411 Vali Loss: 1.0078408 Test Loss: 0.4757267
Validation loss decreased (1.009725 --> 1.007841).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.130906343460083
Epoch: 37, Steps: 63 | Train Loss: 0.2051259 Vali Loss: 1.0059235 Test Loss: 0.4743318
Validation loss decreased (1.007841 --> 1.005924).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.5175364017486572
Epoch: 38, Steps: 63 | Train Loss: 0.2043606 Vali Loss: 1.0039442 Test Loss: 0.4731796
Validation loss decreased (1.005924 --> 1.003944).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.8146345615386963
Epoch: 39, Steps: 63 | Train Loss: 0.2035270 Vali Loss: 1.0025845 Test Loss: 0.4721563
Validation loss decreased (1.003944 --> 1.002584).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.3050622940063477
Epoch: 40, Steps: 63 | Train Loss: 0.2027886 Vali Loss: 1.0010904 Test Loss: 0.4709019
Validation loss decreased (1.002584 --> 1.001090).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.568040132522583
Epoch: 41, Steps: 63 | Train Loss: 0.2020627 Vali Loss: 0.9993811 Test Loss: 0.4699410
Validation loss decreased (1.001090 --> 0.999381).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.4417920112609863
Epoch: 42, Steps: 63 | Train Loss: 0.2015166 Vali Loss: 0.9981613 Test Loss: 0.4689966
Validation loss decreased (0.999381 --> 0.998161).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.8574936389923096
Epoch: 43, Steps: 63 | Train Loss: 0.2007151 Vali Loss: 0.9965903 Test Loss: 0.4679797
Validation loss decreased (0.998161 --> 0.996590).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.5716545581817627
Epoch: 44, Steps: 63 | Train Loss: 0.2002478 Vali Loss: 0.9953021 Test Loss: 0.4672431
Validation loss decreased (0.996590 --> 0.995302).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.8268327713012695
Epoch: 45, Steps: 63 | Train Loss: 0.1996895 Vali Loss: 0.9945077 Test Loss: 0.4664802
Validation loss decreased (0.995302 --> 0.994508).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.7322373390197754
Epoch: 46, Steps: 63 | Train Loss: 0.1992563 Vali Loss: 0.9933829 Test Loss: 0.4657084
Validation loss decreased (0.994508 --> 0.993383).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.8253710269927979
Epoch: 47, Steps: 63 | Train Loss: 0.1987088 Vali Loss: 0.9924665 Test Loss: 0.4649901
Validation loss decreased (0.993383 --> 0.992467).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.833301305770874
Epoch: 48, Steps: 63 | Train Loss: 0.1983228 Vali Loss: 0.9913903 Test Loss: 0.4642677
Validation loss decreased (0.992467 --> 0.991390).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.4983630180358887
Epoch: 49, Steps: 63 | Train Loss: 0.1978252 Vali Loss: 0.9900015 Test Loss: 0.4636618
Validation loss decreased (0.991390 --> 0.990001).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.0138325691223145
Epoch: 50, Steps: 63 | Train Loss: 0.1973685 Vali Loss: 0.9892427 Test Loss: 0.4630283
Validation loss decreased (0.990001 --> 0.989243).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.1347036361694336
Epoch: 51, Steps: 63 | Train Loss: 0.1970599 Vali Loss: 0.9881250 Test Loss: 0.4624151
Validation loss decreased (0.989243 --> 0.988125).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.6304073333740234
Epoch: 52, Steps: 63 | Train Loss: 0.1967026 Vali Loss: 0.9875889 Test Loss: 0.4618428
Validation loss decreased (0.988125 --> 0.987589).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.4150986671447754
Epoch: 53, Steps: 63 | Train Loss: 0.1962811 Vali Loss: 0.9871202 Test Loss: 0.4613633
Validation loss decreased (0.987589 --> 0.987120).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.6512908935546875
Epoch: 54, Steps: 63 | Train Loss: 0.1960065 Vali Loss: 0.9862131 Test Loss: 0.4608298
Validation loss decreased (0.987120 --> 0.986213).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.431734561920166
Epoch: 55, Steps: 63 | Train Loss: 0.1957277 Vali Loss: 0.9854397 Test Loss: 0.4603426
Validation loss decreased (0.986213 --> 0.985440).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.2203991413116455
Epoch: 56, Steps: 63 | Train Loss: 0.1953108 Vali Loss: 0.9849676 Test Loss: 0.4598692
Validation loss decreased (0.985440 --> 0.984968).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.8167946338653564
Epoch: 57, Steps: 63 | Train Loss: 0.1950617 Vali Loss: 0.9839875 Test Loss: 0.4594962
Validation loss decreased (0.984968 --> 0.983988).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.9844951629638672
Epoch: 58, Steps: 63 | Train Loss: 0.1947446 Vali Loss: 0.9836115 Test Loss: 0.4590492
Validation loss decreased (0.983988 --> 0.983612).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.155225992202759
Epoch: 59, Steps: 63 | Train Loss: 0.1945177 Vali Loss: 0.9831814 Test Loss: 0.4587287
Validation loss decreased (0.983612 --> 0.983181).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.230194091796875
Epoch: 60, Steps: 63 | Train Loss: 0.1943299 Vali Loss: 0.9826533 Test Loss: 0.4583528
Validation loss decreased (0.983181 --> 0.982653).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.160259962081909
Epoch: 61, Steps: 63 | Train Loss: 0.1941705 Vali Loss: 0.9822013 Test Loss: 0.4579659
Validation loss decreased (0.982653 --> 0.982201).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.222658157348633
Epoch: 62, Steps: 63 | Train Loss: 0.1938387 Vali Loss: 0.9813277 Test Loss: 0.4576759
Validation loss decreased (0.982201 --> 0.981328).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.7197515964508057
Epoch: 63, Steps: 63 | Train Loss: 0.1936988 Vali Loss: 0.9811715 Test Loss: 0.4573523
Validation loss decreased (0.981328 --> 0.981172).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.951648235321045
Epoch: 64, Steps: 63 | Train Loss: 0.1934855 Vali Loss: 0.9808725 Test Loss: 0.4570688
Validation loss decreased (0.981172 --> 0.980872).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.6718242168426514
Epoch: 65, Steps: 63 | Train Loss: 0.1933348 Vali Loss: 0.9804020 Test Loss: 0.4567495
Validation loss decreased (0.980872 --> 0.980402).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.1204614639282227
Epoch: 66, Steps: 63 | Train Loss: 0.1931277 Vali Loss: 0.9795133 Test Loss: 0.4565021
Validation loss decreased (0.980402 --> 0.979513).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.028160572052002
Epoch: 67, Steps: 63 | Train Loss: 0.1929272 Vali Loss: 0.9795808 Test Loss: 0.4562522
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.7205536365509033
Epoch: 68, Steps: 63 | Train Loss: 0.1928827 Vali Loss: 0.9791017 Test Loss: 0.4560127
Validation loss decreased (0.979513 --> 0.979102).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.0918848514556885
Epoch: 69, Steps: 63 | Train Loss: 0.1926897 Vali Loss: 0.9788023 Test Loss: 0.4557434
Validation loss decreased (0.979102 --> 0.978802).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.8571462631225586
Epoch: 70, Steps: 63 | Train Loss: 0.1926146 Vali Loss: 0.9785151 Test Loss: 0.4555480
Validation loss decreased (0.978802 --> 0.978515).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.8259270191192627
Epoch: 71, Steps: 63 | Train Loss: 0.1924348 Vali Loss: 0.9780080 Test Loss: 0.4553189
Validation loss decreased (0.978515 --> 0.978008).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.8886146545410156
Epoch: 72, Steps: 63 | Train Loss: 0.1922531 Vali Loss: 0.9777024 Test Loss: 0.4550960
Validation loss decreased (0.978008 --> 0.977702).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.8903462886810303
Epoch: 73, Steps: 63 | Train Loss: 0.1921844 Vali Loss: 0.9773191 Test Loss: 0.4549267
Validation loss decreased (0.977702 --> 0.977319).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.590705394744873
Epoch: 74, Steps: 63 | Train Loss: 0.1920289 Vali Loss: 0.9773140 Test Loss: 0.4547311
Validation loss decreased (0.977319 --> 0.977314).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.6636929512023926
Epoch: 75, Steps: 63 | Train Loss: 0.1919869 Vali Loss: 0.9768895 Test Loss: 0.4545767
Validation loss decreased (0.977314 --> 0.976889).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.5349204540252686
Epoch: 76, Steps: 63 | Train Loss: 0.1919076 Vali Loss: 0.9759126 Test Loss: 0.4544109
Validation loss decreased (0.976889 --> 0.975913).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.0093984603881836
Epoch: 77, Steps: 63 | Train Loss: 0.1916996 Vali Loss: 0.9766781 Test Loss: 0.4542719
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.5037975311279297
Epoch: 78, Steps: 63 | Train Loss: 0.1916151 Vali Loss: 0.9762839 Test Loss: 0.4541092
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.7607448101043701
Epoch: 79, Steps: 63 | Train Loss: 0.1916007 Vali Loss: 0.9757467 Test Loss: 0.4539742
Validation loss decreased (0.975913 --> 0.975747).  Saving model ...
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.353123903274536
Epoch: 80, Steps: 63 | Train Loss: 0.1915259 Vali Loss: 0.9760418 Test Loss: 0.4538370
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.549945592880249
Epoch: 81, Steps: 63 | Train Loss: 0.1913853 Vali Loss: 0.9756676 Test Loss: 0.4537112
Validation loss decreased (0.975747 --> 0.975668).  Saving model ...
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.5283763408660889
Epoch: 82, Steps: 63 | Train Loss: 0.1913321 Vali Loss: 0.9755379 Test Loss: 0.4535833
Validation loss decreased (0.975668 --> 0.975538).  Saving model ...
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.501039743423462
Epoch: 83, Steps: 63 | Train Loss: 0.1912135 Vali Loss: 0.9752284 Test Loss: 0.4534720
Validation loss decreased (0.975538 --> 0.975228).  Saving model ...
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.335066080093384
Epoch: 84, Steps: 63 | Train Loss: 0.1912162 Vali Loss: 0.9751608 Test Loss: 0.4533657
Validation loss decreased (0.975228 --> 0.975161).  Saving model ...
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.104081869125366
Epoch: 85, Steps: 63 | Train Loss: 0.1910994 Vali Loss: 0.9751619 Test Loss: 0.4532551
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 2.0595428943634033
Epoch: 86, Steps: 63 | Train Loss: 0.1910103 Vali Loss: 0.9748629 Test Loss: 0.4531535
Validation loss decreased (0.975161 --> 0.974863).  Saving model ...
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.709691047668457
Epoch: 87, Steps: 63 | Train Loss: 0.1909201 Vali Loss: 0.9747763 Test Loss: 0.4530635
Validation loss decreased (0.974863 --> 0.974776).  Saving model ...
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 2.1483404636383057
Epoch: 88, Steps: 63 | Train Loss: 0.1908369 Vali Loss: 0.9744172 Test Loss: 0.4529751
Validation loss decreased (0.974776 --> 0.974417).  Saving model ...
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.559861660003662
Epoch: 89, Steps: 63 | Train Loss: 0.1909235 Vali Loss: 0.9744053 Test Loss: 0.4528891
Validation loss decreased (0.974417 --> 0.974405).  Saving model ...
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.6265835762023926
Epoch: 90, Steps: 63 | Train Loss: 0.1908420 Vali Loss: 0.9740071 Test Loss: 0.4528069
Validation loss decreased (0.974405 --> 0.974007).  Saving model ...
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.18648624420166
Epoch: 91, Steps: 63 | Train Loss: 0.1907538 Vali Loss: 0.9738612 Test Loss: 0.4527241
Validation loss decreased (0.974007 --> 0.973861).  Saving model ...
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.5566291809082031
Epoch: 92, Steps: 63 | Train Loss: 0.1907556 Vali Loss: 0.9741324 Test Loss: 0.4526573
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.9762837886810303
Epoch: 93, Steps: 63 | Train Loss: 0.1906665 Vali Loss: 0.9735842 Test Loss: 0.4525862
Validation loss decreased (0.973861 --> 0.973584).  Saving model ...
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.607555627822876
Epoch: 94, Steps: 63 | Train Loss: 0.1906592 Vali Loss: 0.9736651 Test Loss: 0.4525197
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.56376051902771
Epoch: 95, Steps: 63 | Train Loss: 0.1906003 Vali Loss: 0.9737846 Test Loss: 0.4524560
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.489314317703247
Epoch: 96, Steps: 63 | Train Loss: 0.1905111 Vali Loss: 0.9737710 Test Loss: 0.4523926
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.5814754962921143
Epoch: 97, Steps: 63 | Train Loss: 0.1905009 Vali Loss: 0.9734783 Test Loss: 0.4523364
Validation loss decreased (0.973584 --> 0.973478).  Saving model ...
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.7940611839294434
Epoch: 98, Steps: 63 | Train Loss: 0.1903970 Vali Loss: 0.9735359 Test Loss: 0.4522806
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 2.3399441242218018
Epoch: 99, Steps: 63 | Train Loss: 0.1903906 Vali Loss: 0.9731613 Test Loss: 0.4522380
Validation loss decreased (0.973478 --> 0.973161).  Saving model ...
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 2.5754382610321045
Epoch: 100, Steps: 63 | Train Loss: 0.1904051 Vali Loss: 0.9729832 Test Loss: 0.4521802
Validation loss decreased (0.973161 --> 0.972983).  Saving model ...
Updating learning rate to 3.1160680107021042e-06
train 8089
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=58, out_features=88, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4573184.0
params:  5192.0
Trainable parameters:  5192
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.0739333629608154
Epoch: 1, Steps: 63 | Train Loss: 0.4181444 Vali Loss: 0.9357398 Test Loss: 0.4254357
Validation loss decreased (inf --> 0.935740).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.3737735748291016
Epoch: 2, Steps: 63 | Train Loss: 0.4076489 Vali Loss: 0.9261983 Test Loss: 0.4189937
Validation loss decreased (0.935740 --> 0.926198).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.7655746936798096
Epoch: 3, Steps: 63 | Train Loss: 0.4048661 Vali Loss: 0.9226057 Test Loss: 0.4172425
Validation loss decreased (0.926198 --> 0.922606).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.9140021800994873
Epoch: 4, Steps: 63 | Train Loss: 0.4042779 Vali Loss: 0.9223352 Test Loss: 0.4168550
Validation loss decreased (0.922606 --> 0.922335).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.5920088291168213
Epoch: 5, Steps: 63 | Train Loss: 0.4037866 Vali Loss: 0.9219582 Test Loss: 0.4164306
Validation loss decreased (0.922335 --> 0.921958).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.305659055709839
Epoch: 6, Steps: 63 | Train Loss: 0.4036106 Vali Loss: 0.9217553 Test Loss: 0.4164915
Validation loss decreased (0.921958 --> 0.921755).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.9347994327545166
Epoch: 7, Steps: 63 | Train Loss: 0.4034257 Vali Loss: 0.9207779 Test Loss: 0.4162451
Validation loss decreased (0.921755 --> 0.920778).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.216830253601074
Epoch: 8, Steps: 63 | Train Loss: 0.4033646 Vali Loss: 0.9204982 Test Loss: 0.4160514
Validation loss decreased (0.920778 --> 0.920498).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.7965707778930664
Epoch: 9, Steps: 63 | Train Loss: 0.4032079 Vali Loss: 0.9208508 Test Loss: 0.4163034
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.8335747718811035
Epoch: 10, Steps: 63 | Train Loss: 0.4029030 Vali Loss: 0.9214880 Test Loss: 0.4160127
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.212109088897705
Epoch: 11, Steps: 63 | Train Loss: 0.4028254 Vali Loss: 0.9216980 Test Loss: 0.4164310
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.8709335327148438
Epoch: 12, Steps: 63 | Train Loss: 0.4029397 Vali Loss: 0.9206229 Test Loss: 0.4161604
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.7268102169036865
Epoch: 13, Steps: 63 | Train Loss: 0.4026016 Vali Loss: 0.9208804 Test Loss: 0.4162987
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.7470295429229736
Epoch: 14, Steps: 63 | Train Loss: 0.4024502 Vali Loss: 0.9212373 Test Loss: 0.4160691
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.702277421951294
Epoch: 15, Steps: 63 | Train Loss: 0.4026529 Vali Loss: 0.9208225 Test Loss: 0.4161381
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.9002883434295654
Epoch: 16, Steps: 63 | Train Loss: 0.4027625 Vali Loss: 0.9207714 Test Loss: 0.4161931
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.1732499599456787
Epoch: 17, Steps: 63 | Train Loss: 0.4024771 Vali Loss: 0.9209678 Test Loss: 0.4160672
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.8243703842163086
Epoch: 18, Steps: 63 | Train Loss: 0.4022479 Vali Loss: 0.9208303 Test Loss: 0.4161775
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.548887252807617
Epoch: 19, Steps: 63 | Train Loss: 0.4025624 Vali Loss: 0.9211610 Test Loss: 0.4163073
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.440063953399658
Epoch: 20, Steps: 63 | Train Loss: 0.4023010 Vali Loss: 0.9205626 Test Loss: 0.4161240
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.4372899532318115
Epoch: 21, Steps: 63 | Train Loss: 0.4022516 Vali Loss: 0.9207011 Test Loss: 0.4160521
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.3506598472595215
Epoch: 22, Steps: 63 | Train Loss: 0.4023528 Vali Loss: 0.9205396 Test Loss: 0.4161056
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.8488414287567139
Epoch: 23, Steps: 63 | Train Loss: 0.4023728 Vali Loss: 0.9197770 Test Loss: 0.4160634
Validation loss decreased (0.920498 --> 0.919777).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.852604627609253
Epoch: 24, Steps: 63 | Train Loss: 0.4021703 Vali Loss: 0.9205353 Test Loss: 0.4160216
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.379065990447998
Epoch: 25, Steps: 63 | Train Loss: 0.4021197 Vali Loss: 0.9201204 Test Loss: 0.4162088
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.3963510990142822
Epoch: 26, Steps: 63 | Train Loss: 0.4021597 Vali Loss: 0.9204561 Test Loss: 0.4161462
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.306802749633789
Epoch: 27, Steps: 63 | Train Loss: 0.4023541 Vali Loss: 0.9205199 Test Loss: 0.4161024
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.1441266536712646
Epoch: 28, Steps: 63 | Train Loss: 0.4021173 Vali Loss: 0.9206633 Test Loss: 0.4161509
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.8418047428131104
Epoch: 29, Steps: 63 | Train Loss: 0.4020340 Vali Loss: 0.9201925 Test Loss: 0.4159803
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.742849349975586
Epoch: 30, Steps: 63 | Train Loss: 0.4020974 Vali Loss: 0.9202846 Test Loss: 0.4161451
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.598426103591919
Epoch: 31, Steps: 63 | Train Loss: 0.4020047 Vali Loss: 0.9205881 Test Loss: 0.4160329
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.7801196575164795
Epoch: 32, Steps: 63 | Train Loss: 0.4018436 Vali Loss: 0.9205645 Test Loss: 0.4161561
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.4510436058044434
Epoch: 33, Steps: 63 | Train Loss: 0.4019554 Vali Loss: 0.9202466 Test Loss: 0.4161496
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.8938047885894775
Epoch: 34, Steps: 63 | Train Loss: 0.4019636 Vali Loss: 0.9204204 Test Loss: 0.4161469
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.9213106632232666
Epoch: 35, Steps: 63 | Train Loss: 0.4018848 Vali Loss: 0.9205906 Test Loss: 0.4160990
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.9907712936401367
Epoch: 36, Steps: 63 | Train Loss: 0.4020600 Vali Loss: 0.9206061 Test Loss: 0.4161122
EarlyStopping counter: 13 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.6398863792419434
Epoch: 37, Steps: 63 | Train Loss: 0.4021058 Vali Loss: 0.9204446 Test Loss: 0.4162001
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.36724591255188
Epoch: 38, Steps: 63 | Train Loss: 0.4020384 Vali Loss: 0.9203178 Test Loss: 0.4161631
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.8941748142242432
Epoch: 39, Steps: 63 | Train Loss: 0.4019152 Vali Loss: 0.9204130 Test Loss: 0.4161402
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.360105514526367
Epoch: 40, Steps: 63 | Train Loss: 0.4018813 Vali Loss: 0.9203198 Test Loss: 0.4161351
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 3.088707447052002
Epoch: 41, Steps: 63 | Train Loss: 0.4019063 Vali Loss: 0.9202994 Test Loss: 0.4161316
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.7001144886016846
Epoch: 42, Steps: 63 | Train Loss: 0.4018826 Vali Loss: 0.9201561 Test Loss: 0.4161566
EarlyStopping counter: 19 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 3.331383466720581
Epoch: 43, Steps: 63 | Train Loss: 0.4017541 Vali Loss: 0.9199972 Test Loss: 0.4161897
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_360_192_FITS_ETTh1_ftM_sl360_ll48_pl192_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.4118182957172394, mae:0.41916877031326294, rse:0.6094107627868652, corr:[0.2630379  0.26959744 0.2703273  0.2676337  0.26435488 0.2623082
 0.2614317  0.26145643 0.26144665 0.2612181  0.26092452 0.26067072
 0.26062372 0.26074013 0.26082262 0.2607051  0.26033434 0.259935
 0.25968924 0.25951594 0.25940064 0.25936335 0.25936294 0.2595044
 0.2595348  0.25940734 0.25915614 0.25881886 0.25835535 0.2579022
 0.25758955 0.25742722 0.25737163 0.25726902 0.257131   0.25701046
 0.2570631  0.25741434 0.2578276  0.2580825  0.25828016 0.25830778
 0.25826922 0.25822693 0.25819746 0.25809777 0.25802127 0.25791645
 0.25752065 0.25675768 0.25563878 0.25460848 0.2538021  0.2530589
 0.25258029 0.25237435 0.25228745 0.2522096  0.25200063 0.2518668
 0.2518214  0.251838   0.2518354  0.25184208 0.25182873 0.251861
 0.25199637 0.25203845 0.25209677 0.25224167 0.25232452 0.25207424
 0.25141093 0.25053474 0.2497122  0.2491388  0.24881275 0.24856459
 0.24837258 0.24813165 0.2478772  0.24756715 0.24719888 0.24691375
 0.24691728 0.24710271 0.24728519 0.24726653 0.24712443 0.24703643
 0.24692136 0.24674466 0.24660124 0.24669756 0.24706534 0.24757276
 0.24812503 0.24830632 0.24820794 0.24785195 0.24746305 0.24721998
 0.2471553  0.24725574 0.24731416 0.2472102  0.24695604 0.24661966
 0.2463694  0.2464341  0.2468078  0.24730985 0.24758656 0.2476127
 0.24747229 0.24721475 0.24693176 0.24677278 0.24679247 0.24684757
 0.24673715 0.24621412 0.24529427 0.24429911 0.24358098 0.24318828
 0.24315359 0.24325305 0.24318875 0.24280712 0.24236941 0.24201709
 0.24175286 0.2416492  0.24175686 0.24186182 0.24208201 0.24225391
 0.24232785 0.24230245 0.24228485 0.24233958 0.24239855 0.24229093
 0.24208461 0.24156053 0.24081607 0.2400069  0.23946954 0.23903184
 0.23878677 0.2388075  0.23890178 0.23902223 0.23898146 0.23877154
 0.23842096 0.23822798 0.23824495 0.23832768 0.23836851 0.23842886
 0.23840833 0.23823196 0.2381851  0.23837492 0.23871547 0.23895806
 0.2391666  0.23930073 0.23928884 0.23911376 0.2388759  0.23859815
 0.23829272 0.23805094 0.2379656  0.23824416 0.23857144 0.23845594
 0.23787493 0.23719351 0.23710574 0.23772699 0.2384573  0.23876083
 0.23833176 0.2376167  0.23785633 0.2392133  0.23920101 0.23347446]
