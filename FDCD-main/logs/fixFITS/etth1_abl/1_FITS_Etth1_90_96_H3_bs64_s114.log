Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=22, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_90_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_90_96_FITS_ETTh1_ftM_sl90_ll48_pl96_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8455
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=22, out_features=45, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  887040.0
params:  1035.0
Trainable parameters:  1035
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.342397689819336
Epoch: 1, Steps: 66 | Train Loss: 0.7030859 Vali Loss: 1.2079287 Test Loss: 0.7510628
Validation loss decreased (inf --> 1.207929).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.1926486492156982
Epoch: 2, Steps: 66 | Train Loss: 0.5442598 Vali Loss: 0.9946994 Test Loss: 0.5790984
Validation loss decreased (1.207929 --> 0.994699).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.2259140014648438
Epoch: 3, Steps: 66 | Train Loss: 0.4701436 Vali Loss: 0.8919236 Test Loss: 0.4999042
Validation loss decreased (0.994699 --> 0.891924).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.1840271949768066
Epoch: 4, Steps: 66 | Train Loss: 0.4324872 Vali Loss: 0.8362086 Test Loss: 0.4596955
Validation loss decreased (0.891924 --> 0.836209).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.2854845523834229
Epoch: 5, Steps: 66 | Train Loss: 0.4116845 Vali Loss: 0.7982723 Test Loss: 0.4374351
Validation loss decreased (0.836209 --> 0.798272).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.278303623199463
Epoch: 6, Steps: 66 | Train Loss: 0.3992373 Vali Loss: 0.7818517 Test Loss: 0.4243599
Validation loss decreased (0.798272 --> 0.781852).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.2342963218688965
Epoch: 7, Steps: 66 | Train Loss: 0.3909476 Vali Loss: 0.7641114 Test Loss: 0.4159989
Validation loss decreased (0.781852 --> 0.764111).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.2526676654815674
Epoch: 8, Steps: 66 | Train Loss: 0.3852950 Vali Loss: 0.7569090 Test Loss: 0.4105065
Validation loss decreased (0.764111 --> 0.756909).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.2882308959960938
Epoch: 9, Steps: 66 | Train Loss: 0.3810750 Vali Loss: 0.7459736 Test Loss: 0.4066067
Validation loss decreased (0.756909 --> 0.745974).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.2566859722137451
Epoch: 10, Steps: 66 | Train Loss: 0.3778686 Vali Loss: 0.7427763 Test Loss: 0.4038036
Validation loss decreased (0.745974 --> 0.742776).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.254983901977539
Epoch: 11, Steps: 66 | Train Loss: 0.3754155 Vali Loss: 0.7417843 Test Loss: 0.4017439
Validation loss decreased (0.742776 --> 0.741784).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.2778093814849854
Epoch: 12, Steps: 66 | Train Loss: 0.3732916 Vali Loss: 0.7357721 Test Loss: 0.4000451
Validation loss decreased (0.741784 --> 0.735772).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.3230681419372559
Epoch: 13, Steps: 66 | Train Loss: 0.3716616 Vali Loss: 0.7332106 Test Loss: 0.3987749
Validation loss decreased (0.735772 --> 0.733211).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.2110083103179932
Epoch: 14, Steps: 66 | Train Loss: 0.3704432 Vali Loss: 0.7256960 Test Loss: 0.3977166
Validation loss decreased (0.733211 --> 0.725696).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.2232799530029297
Epoch: 15, Steps: 66 | Train Loss: 0.3693348 Vali Loss: 0.7256543 Test Loss: 0.3968928
Validation loss decreased (0.725696 --> 0.725654).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.2753992080688477
Epoch: 16, Steps: 66 | Train Loss: 0.3683539 Vali Loss: 0.7255585 Test Loss: 0.3961536
Validation loss decreased (0.725654 --> 0.725559).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.0482280254364014
Epoch: 17, Steps: 66 | Train Loss: 0.3675922 Vali Loss: 0.7268401 Test Loss: 0.3955637
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.1565351486206055
Epoch: 18, Steps: 66 | Train Loss: 0.3669160 Vali Loss: 0.7220694 Test Loss: 0.3951595
Validation loss decreased (0.725559 --> 0.722069).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.317162275314331
Epoch: 19, Steps: 66 | Train Loss: 0.3663120 Vali Loss: 0.7220389 Test Loss: 0.3947333
Validation loss decreased (0.722069 --> 0.722039).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.2125890254974365
Epoch: 20, Steps: 66 | Train Loss: 0.3658504 Vali Loss: 0.7209833 Test Loss: 0.3943287
Validation loss decreased (0.722039 --> 0.720983).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.2775933742523193
Epoch: 21, Steps: 66 | Train Loss: 0.3653379 Vali Loss: 0.7155173 Test Loss: 0.3940641
Validation loss decreased (0.720983 --> 0.715517).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.1674458980560303
Epoch: 22, Steps: 66 | Train Loss: 0.3650465 Vali Loss: 0.7170829 Test Loss: 0.3938382
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.1689188480377197
Epoch: 23, Steps: 66 | Train Loss: 0.3645457 Vali Loss: 0.7179737 Test Loss: 0.3935137
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.153723955154419
Epoch: 24, Steps: 66 | Train Loss: 0.3644077 Vali Loss: 0.7176489 Test Loss: 0.3933087
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.2877318859100342
Epoch: 25, Steps: 66 | Train Loss: 0.3641498 Vali Loss: 0.7128632 Test Loss: 0.3931335
Validation loss decreased (0.715517 --> 0.712863).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.3160710334777832
Epoch: 26, Steps: 66 | Train Loss: 0.3637911 Vali Loss: 0.7162309 Test Loss: 0.3929814
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.21366548538208
Epoch: 27, Steps: 66 | Train Loss: 0.3636957 Vali Loss: 0.7152200 Test Loss: 0.3928058
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.2677593231201172
Epoch: 28, Steps: 66 | Train Loss: 0.3633931 Vali Loss: 0.7148605 Test Loss: 0.3926297
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.195819616317749
Epoch: 29, Steps: 66 | Train Loss: 0.3633062 Vali Loss: 0.7170270 Test Loss: 0.3925593
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.3521678447723389
Epoch: 30, Steps: 66 | Train Loss: 0.3631940 Vali Loss: 0.7119918 Test Loss: 0.3924235
Validation loss decreased (0.712863 --> 0.711992).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.291693925857544
Epoch: 31, Steps: 66 | Train Loss: 0.3629458 Vali Loss: 0.7139333 Test Loss: 0.3923231
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.2339098453521729
Epoch: 32, Steps: 66 | Train Loss: 0.3627859 Vali Loss: 0.7146010 Test Loss: 0.3922023
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.3232691287994385
Epoch: 33, Steps: 66 | Train Loss: 0.3628235 Vali Loss: 0.7159394 Test Loss: 0.3921217
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.2415170669555664
Epoch: 34, Steps: 66 | Train Loss: 0.3626853 Vali Loss: 0.7120511 Test Loss: 0.3920352
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.1880881786346436
Epoch: 35, Steps: 66 | Train Loss: 0.3625660 Vali Loss: 0.7136797 Test Loss: 0.3919711
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.2807207107543945
Epoch: 36, Steps: 66 | Train Loss: 0.3625043 Vali Loss: 0.7090330 Test Loss: 0.3919089
Validation loss decreased (0.711992 --> 0.709033).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.2041287422180176
Epoch: 37, Steps: 66 | Train Loss: 0.3620964 Vali Loss: 0.7173796 Test Loss: 0.3918166
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.3037583827972412
Epoch: 38, Steps: 66 | Train Loss: 0.3621326 Vali Loss: 0.7143852 Test Loss: 0.3917424
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.2967393398284912
Epoch: 39, Steps: 66 | Train Loss: 0.3620186 Vali Loss: 0.7124084 Test Loss: 0.3917190
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.2634730339050293
Epoch: 40, Steps: 66 | Train Loss: 0.3621975 Vali Loss: 0.7078544 Test Loss: 0.3916460
Validation loss decreased (0.709033 --> 0.707854).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.300980806350708
Epoch: 41, Steps: 66 | Train Loss: 0.3621579 Vali Loss: 0.7138917 Test Loss: 0.3915934
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.2267968654632568
Epoch: 42, Steps: 66 | Train Loss: 0.3620737 Vali Loss: 0.7088395 Test Loss: 0.3915371
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.2599129676818848
Epoch: 43, Steps: 66 | Train Loss: 0.3620435 Vali Loss: 0.7094092 Test Loss: 0.3915208
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.2368717193603516
Epoch: 44, Steps: 66 | Train Loss: 0.3619479 Vali Loss: 0.7128805 Test Loss: 0.3914462
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.2297210693359375
Epoch: 45, Steps: 66 | Train Loss: 0.3618618 Vali Loss: 0.7115691 Test Loss: 0.3914267
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.3183622360229492
Epoch: 46, Steps: 66 | Train Loss: 0.3618182 Vali Loss: 0.7133188 Test Loss: 0.3913924
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.160001516342163
Epoch: 47, Steps: 66 | Train Loss: 0.3617549 Vali Loss: 0.7093773 Test Loss: 0.3913583
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.2230942249298096
Epoch: 48, Steps: 66 | Train Loss: 0.3617194 Vali Loss: 0.7132511 Test Loss: 0.3913355
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.2380170822143555
Epoch: 49, Steps: 66 | Train Loss: 0.3617680 Vali Loss: 0.7108597 Test Loss: 0.3912988
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.1011767387390137
Epoch: 50, Steps: 66 | Train Loss: 0.3618189 Vali Loss: 0.7118411 Test Loss: 0.3912685
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.2486443519592285
Epoch: 51, Steps: 66 | Train Loss: 0.3617065 Vali Loss: 0.7117472 Test Loss: 0.3912461
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.1937124729156494
Epoch: 52, Steps: 66 | Train Loss: 0.3616609 Vali Loss: 0.7095188 Test Loss: 0.3912085
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.159606695175171
Epoch: 53, Steps: 66 | Train Loss: 0.3616387 Vali Loss: 0.7116605 Test Loss: 0.3911739
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.162235975265503
Epoch: 54, Steps: 66 | Train Loss: 0.3616362 Vali Loss: 0.7106134 Test Loss: 0.3911616
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.1357417106628418
Epoch: 55, Steps: 66 | Train Loss: 0.3614916 Vali Loss: 0.7111636 Test Loss: 0.3911481
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.2005300521850586
Epoch: 56, Steps: 66 | Train Loss: 0.3615687 Vali Loss: 0.7107019 Test Loss: 0.3911279
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.2886333465576172
Epoch: 57, Steps: 66 | Train Loss: 0.3615884 Vali Loss: 0.7133344 Test Loss: 0.3911088
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.4066989421844482
Epoch: 58, Steps: 66 | Train Loss: 0.3614822 Vali Loss: 0.7116529 Test Loss: 0.3910949
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 3.4894633293151855
Epoch: 59, Steps: 66 | Train Loss: 0.3614947 Vali Loss: 0.7135538 Test Loss: 0.3910912
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.2841944694519043
Epoch: 60, Steps: 66 | Train Loss: 0.3614483 Vali Loss: 0.7113431 Test Loss: 0.3910770
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_90_96_FITS_ETTh1_ftM_sl90_ll48_pl96_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.39095887541770935, mae:0.39855170249938965, rse:0.593913733959198, corr:[0.26933157 0.2737363  0.27211666 0.27103066 0.26990616 0.26799574
 0.2666594  0.26584223 0.26591536 0.26618385 0.265489   0.26473272
 0.26448843 0.26444203 0.26440257 0.26419947 0.26419443 0.26453993
 0.2648212  0.26465282 0.26422045 0.26403585 0.2635206  0.2626111
 0.2611204  0.26062134 0.26084784 0.26101866 0.2609287  0.26100755
 0.26119766 0.26084653 0.2606989  0.26082897 0.26065895 0.26032656
 0.26015058 0.26015547 0.26028687 0.2603952  0.2606625  0.26111525
 0.26155567 0.26155013 0.26128027 0.26115423 0.2610647  0.26034454
 0.25869933 0.25770655 0.25723118 0.25652117 0.25522947 0.25413826
 0.25426412 0.25408238 0.25377503 0.25398028 0.2540368  0.2538877
 0.25372759 0.2537308  0.25364038 0.2533403  0.25334805 0.25369322
 0.25406235 0.25398174 0.25352854 0.25321874 0.25290608 0.25179562
 0.2498655  0.24888927 0.2486674  0.248412   0.24787372 0.24768887
 0.24840556 0.24852909 0.24834347 0.24830261 0.24820985 0.2478706
 0.24768956 0.24790587 0.24803188 0.24738988 0.24674334 0.24685362
 0.2470666  0.24615556 0.24395938 0.24300094 0.24527271 0.24579358]
