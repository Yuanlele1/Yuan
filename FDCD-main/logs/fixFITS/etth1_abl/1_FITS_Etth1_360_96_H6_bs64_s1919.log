Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_360_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=1919, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_360_96_FITS_ETTh1_ftM_sl360_ll48_pl96_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8185
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=106, out_features=134, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  12726784.0
params:  14338.0
Trainable parameters:  14338
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.601255178451538
Epoch: 1, Steps: 63 | Train Loss: 0.5689355 Vali Loss: 0.9956873 Test Loss: 0.5335713
Validation loss decreased (inf --> 0.995687).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.8232483863830566
Epoch: 2, Steps: 63 | Train Loss: 0.4172600 Vali Loss: 0.8352066 Test Loss: 0.4351607
Validation loss decreased (0.995687 --> 0.835207).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.6563010215759277
Epoch: 3, Steps: 63 | Train Loss: 0.3758381 Vali Loss: 0.7782646 Test Loss: 0.3992167
Validation loss decreased (0.835207 --> 0.778265).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.5501477718353271
Epoch: 4, Steps: 63 | Train Loss: 0.3584679 Vali Loss: 0.7469214 Test Loss: 0.3845375
Validation loss decreased (0.778265 --> 0.746921).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.6712985038757324
Epoch: 5, Steps: 63 | Train Loss: 0.3506306 Vali Loss: 0.7309510 Test Loss: 0.3786029
Validation loss decreased (0.746921 --> 0.730951).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.5285756587982178
Epoch: 6, Steps: 63 | Train Loss: 0.3468947 Vali Loss: 0.7184737 Test Loss: 0.3760852
Validation loss decreased (0.730951 --> 0.718474).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.5212461948394775
Epoch: 7, Steps: 63 | Train Loss: 0.3451243 Vali Loss: 0.7098963 Test Loss: 0.3750235
Validation loss decreased (0.718474 --> 0.709896).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.5385916233062744
Epoch: 8, Steps: 63 | Train Loss: 0.3431077 Vali Loss: 0.7078421 Test Loss: 0.3745675
Validation loss decreased (0.709896 --> 0.707842).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.5930702686309814
Epoch: 9, Steps: 63 | Train Loss: 0.3423382 Vali Loss: 0.7045026 Test Loss: 0.3739771
Validation loss decreased (0.707842 --> 0.704503).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.8058719635009766
Epoch: 10, Steps: 63 | Train Loss: 0.3412745 Vali Loss: 0.7015249 Test Loss: 0.3738325
Validation loss decreased (0.704503 --> 0.701525).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.59619140625
Epoch: 11, Steps: 63 | Train Loss: 0.3406490 Vali Loss: 0.6999406 Test Loss: 0.3738230
Validation loss decreased (0.701525 --> 0.699941).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.5623173713684082
Epoch: 12, Steps: 63 | Train Loss: 0.3399857 Vali Loss: 0.6912282 Test Loss: 0.3736953
Validation loss decreased (0.699941 --> 0.691228).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.7968790531158447
Epoch: 13, Steps: 63 | Train Loss: 0.3402920 Vali Loss: 0.6895863 Test Loss: 0.3734183
Validation loss decreased (0.691228 --> 0.689586).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.7242379188537598
Epoch: 14, Steps: 63 | Train Loss: 0.3394418 Vali Loss: 0.6873587 Test Loss: 0.3731241
Validation loss decreased (0.689586 --> 0.687359).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.640883445739746
Epoch: 15, Steps: 63 | Train Loss: 0.3391563 Vali Loss: 0.6915796 Test Loss: 0.3733192
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.878258228302002
Epoch: 16, Steps: 63 | Train Loss: 0.3389872 Vali Loss: 0.6921870 Test Loss: 0.3733468
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.5899755954742432
Epoch: 17, Steps: 63 | Train Loss: 0.3390169 Vali Loss: 0.6878018 Test Loss: 0.3732318
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.571079969406128
Epoch: 18, Steps: 63 | Train Loss: 0.3387298 Vali Loss: 0.6867967 Test Loss: 0.3730139
Validation loss decreased (0.687359 --> 0.686797).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.5328025817871094
Epoch: 19, Steps: 63 | Train Loss: 0.3385000 Vali Loss: 0.6873103 Test Loss: 0.3730474
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.5556457042694092
Epoch: 20, Steps: 63 | Train Loss: 0.3386357 Vali Loss: 0.6875108 Test Loss: 0.3730454
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.460216999053955
Epoch: 21, Steps: 63 | Train Loss: 0.3380691 Vali Loss: 0.6847965 Test Loss: 0.3729983
Validation loss decreased (0.686797 --> 0.684796).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.5128045082092285
Epoch: 22, Steps: 63 | Train Loss: 0.3384489 Vali Loss: 0.6868072 Test Loss: 0.3731727
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.8938615322113037
Epoch: 23, Steps: 63 | Train Loss: 0.3382082 Vali Loss: 0.6871002 Test Loss: 0.3730853
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.6238481998443604
Epoch: 24, Steps: 63 | Train Loss: 0.3377848 Vali Loss: 0.6849993 Test Loss: 0.3730695
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.454113483428955
Epoch: 25, Steps: 63 | Train Loss: 0.3380699 Vali Loss: 0.6823106 Test Loss: 0.3729621
Validation loss decreased (0.684796 --> 0.682311).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.587578535079956
Epoch: 26, Steps: 63 | Train Loss: 0.3378848 Vali Loss: 0.6809675 Test Loss: 0.3729808
Validation loss decreased (0.682311 --> 0.680967).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.440490961074829
Epoch: 27, Steps: 63 | Train Loss: 0.3378255 Vali Loss: 0.6865917 Test Loss: 0.3729029
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.578866720199585
Epoch: 28, Steps: 63 | Train Loss: 0.3376413 Vali Loss: 0.6813400 Test Loss: 0.3730105
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.0380516052246094
Epoch: 29, Steps: 63 | Train Loss: 0.3371866 Vali Loss: 0.6818130 Test Loss: 0.3729267
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.9358949661254883
Epoch: 30, Steps: 63 | Train Loss: 0.3369992 Vali Loss: 0.6841705 Test Loss: 0.3729860
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.8693592548370361
Epoch: 31, Steps: 63 | Train Loss: 0.3373238 Vali Loss: 0.6826629 Test Loss: 0.3730637
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.779407024383545
Epoch: 32, Steps: 63 | Train Loss: 0.3376424 Vali Loss: 0.6788327 Test Loss: 0.3730505
Validation loss decreased (0.680967 --> 0.678833).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.6375091075897217
Epoch: 33, Steps: 63 | Train Loss: 0.3371306 Vali Loss: 0.6785250 Test Loss: 0.3730301
Validation loss decreased (0.678833 --> 0.678525).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.5203680992126465
Epoch: 34, Steps: 63 | Train Loss: 0.3376223 Vali Loss: 0.6826396 Test Loss: 0.3729984
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.558358907699585
Epoch: 35, Steps: 63 | Train Loss: 0.3373499 Vali Loss: 0.6786370 Test Loss: 0.3729766
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.625415563583374
Epoch: 36, Steps: 63 | Train Loss: 0.3368428 Vali Loss: 0.6801897 Test Loss: 0.3729943
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.5677337646484375
Epoch: 37, Steps: 63 | Train Loss: 0.3369762 Vali Loss: 0.6795027 Test Loss: 0.3729697
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.4922449588775635
Epoch: 38, Steps: 63 | Train Loss: 0.3371232 Vali Loss: 0.6802168 Test Loss: 0.3730470
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.5184290409088135
Epoch: 39, Steps: 63 | Train Loss: 0.3366126 Vali Loss: 0.6792983 Test Loss: 0.3730139
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.5122699737548828
Epoch: 40, Steps: 63 | Train Loss: 0.3367922 Vali Loss: 0.6802583 Test Loss: 0.3729566
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.5107519626617432
Epoch: 41, Steps: 63 | Train Loss: 0.3373271 Vali Loss: 0.6800503 Test Loss: 0.3729539
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.4271690845489502
Epoch: 42, Steps: 63 | Train Loss: 0.3370901 Vali Loss: 0.6776883 Test Loss: 0.3729410
Validation loss decreased (0.678525 --> 0.677688).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.4316198825836182
Epoch: 43, Steps: 63 | Train Loss: 0.3373057 Vali Loss: 0.6777967 Test Loss: 0.3729343
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.509294033050537
Epoch: 44, Steps: 63 | Train Loss: 0.3368840 Vali Loss: 0.6792243 Test Loss: 0.3729864
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.8422868251800537
Epoch: 45, Steps: 63 | Train Loss: 0.3369731 Vali Loss: 0.6774259 Test Loss: 0.3729675
Validation loss decreased (0.677688 --> 0.677426).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.6494505405426025
Epoch: 46, Steps: 63 | Train Loss: 0.3369500 Vali Loss: 0.6787388 Test Loss: 0.3729797
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.553518295288086
Epoch: 47, Steps: 63 | Train Loss: 0.3368980 Vali Loss: 0.6784583 Test Loss: 0.3729973
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.447068691253662
Epoch: 48, Steps: 63 | Train Loss: 0.3365456 Vali Loss: 0.6798038 Test Loss: 0.3729833
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.4406347274780273
Epoch: 49, Steps: 63 | Train Loss: 0.3365307 Vali Loss: 0.6831874 Test Loss: 0.3729991
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.6577870845794678
Epoch: 50, Steps: 63 | Train Loss: 0.3369895 Vali Loss: 0.6766717 Test Loss: 0.3729853
Validation loss decreased (0.677426 --> 0.676672).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.6575586795806885
Epoch: 51, Steps: 63 | Train Loss: 0.3362621 Vali Loss: 0.6800065 Test Loss: 0.3730145
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.485097885131836
Epoch: 52, Steps: 63 | Train Loss: 0.3370604 Vali Loss: 0.6770219 Test Loss: 0.3730518
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.4825823307037354
Epoch: 53, Steps: 63 | Train Loss: 0.3370086 Vali Loss: 0.6783368 Test Loss: 0.3730069
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.5794179439544678
Epoch: 54, Steps: 63 | Train Loss: 0.3371478 Vali Loss: 0.6832963 Test Loss: 0.3730026
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.493656873703003
Epoch: 55, Steps: 63 | Train Loss: 0.3364522 Vali Loss: 0.6815177 Test Loss: 0.3730153
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.6182096004486084
Epoch: 56, Steps: 63 | Train Loss: 0.3370304 Vali Loss: 0.6787234 Test Loss: 0.3730056
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.5609605312347412
Epoch: 57, Steps: 63 | Train Loss: 0.3366375 Vali Loss: 0.6774920 Test Loss: 0.3730385
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.7510991096496582
Epoch: 58, Steps: 63 | Train Loss: 0.3371138 Vali Loss: 0.6766717 Test Loss: 0.3730386
Validation loss decreased (0.676672 --> 0.676672).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.5335609912872314
Epoch: 59, Steps: 63 | Train Loss: 0.3361827 Vali Loss: 0.6814834 Test Loss: 0.3729970
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.5176515579223633
Epoch: 60, Steps: 63 | Train Loss: 0.3370766 Vali Loss: 0.6782719 Test Loss: 0.3730076
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.535480260848999
Epoch: 61, Steps: 63 | Train Loss: 0.3367344 Vali Loss: 0.6746757 Test Loss: 0.3730188
Validation loss decreased (0.676672 --> 0.674676).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.5284464359283447
Epoch: 62, Steps: 63 | Train Loss: 0.3366126 Vali Loss: 0.6796888 Test Loss: 0.3730444
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.562532901763916
Epoch: 63, Steps: 63 | Train Loss: 0.3369854 Vali Loss: 0.6768371 Test Loss: 0.3730011
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.4213941097259521
Epoch: 64, Steps: 63 | Train Loss: 0.3367244 Vali Loss: 0.6735430 Test Loss: 0.3730184
Validation loss decreased (0.674676 --> 0.673543).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.6129531860351562
Epoch: 65, Steps: 63 | Train Loss: 0.3369406 Vali Loss: 0.6813426 Test Loss: 0.3730349
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.6340296268463135
Epoch: 66, Steps: 63 | Train Loss: 0.3368054 Vali Loss: 0.6814961 Test Loss: 0.3730327
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.64732027053833
Epoch: 67, Steps: 63 | Train Loss: 0.3361670 Vali Loss: 0.6776684 Test Loss: 0.3730337
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.5304734706878662
Epoch: 68, Steps: 63 | Train Loss: 0.3369084 Vali Loss: 0.6784633 Test Loss: 0.3730496
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.5907461643218994
Epoch: 69, Steps: 63 | Train Loss: 0.3368438 Vali Loss: 0.6808726 Test Loss: 0.3730321
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.5180416107177734
Epoch: 70, Steps: 63 | Train Loss: 0.3365929 Vali Loss: 0.6811323 Test Loss: 0.3730407
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.4749865531921387
Epoch: 71, Steps: 63 | Train Loss: 0.3360061 Vali Loss: 0.6764059 Test Loss: 0.3730497
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.486567735671997
Epoch: 72, Steps: 63 | Train Loss: 0.3369302 Vali Loss: 0.6798539 Test Loss: 0.3730414
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.6045582294464111
Epoch: 73, Steps: 63 | Train Loss: 0.3367556 Vali Loss: 0.6772243 Test Loss: 0.3730430
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.567394495010376
Epoch: 74, Steps: 63 | Train Loss: 0.3365946 Vali Loss: 0.6787458 Test Loss: 0.3730300
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.880115270614624
Epoch: 75, Steps: 63 | Train Loss: 0.3366469 Vali Loss: 0.6802114 Test Loss: 0.3730274
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.684192180633545
Epoch: 76, Steps: 63 | Train Loss: 0.3362708 Vali Loss: 0.6786080 Test Loss: 0.3730453
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.5501859188079834
Epoch: 77, Steps: 63 | Train Loss: 0.3365801 Vali Loss: 0.6778048 Test Loss: 0.3730380
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.4166324138641357
Epoch: 78, Steps: 63 | Train Loss: 0.3364636 Vali Loss: 0.6747621 Test Loss: 0.3730326
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.518066167831421
Epoch: 79, Steps: 63 | Train Loss: 0.3364259 Vali Loss: 0.6777693 Test Loss: 0.3730424
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.6279118061065674
Epoch: 80, Steps: 63 | Train Loss: 0.3364454 Vali Loss: 0.6762409 Test Loss: 0.3730347
EarlyStopping counter: 16 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.6869289875030518
Epoch: 81, Steps: 63 | Train Loss: 0.3366135 Vali Loss: 0.6779631 Test Loss: 0.3730364
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.5171008110046387
Epoch: 82, Steps: 63 | Train Loss: 0.3360808 Vali Loss: 0.6736339 Test Loss: 0.3730390
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.5619111061096191
Epoch: 83, Steps: 63 | Train Loss: 0.3372242 Vali Loss: 0.6775907 Test Loss: 0.3730350
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.55857253074646
Epoch: 84, Steps: 63 | Train Loss: 0.3362508 Vali Loss: 0.6803132 Test Loss: 0.3730329
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_360_96_FITS_ETTh1_ftM_sl360_ll48_pl96_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.37206289172172546, mae:0.3945356607437134, rse:0.579383373260498, corr:[0.26926625 0.27749452 0.27797556 0.27963576 0.27698556 0.27472797
 0.27428356 0.27380124 0.27300784 0.27312618 0.27323174 0.27261752
 0.27240342 0.27248266 0.2722015  0.27211228 0.2723007  0.27210096
 0.27180326 0.271639   0.27145475 0.27124083 0.27150956 0.27191782
 0.271561   0.27116194 0.27101564 0.2707019  0.2702463  0.27004367
 0.26976672 0.26907697 0.26864773 0.26866332 0.26854655 0.2682059
 0.26830065 0.26853275 0.2684808  0.26850232 0.2689459  0.2691398
 0.26919377 0.26918745 0.2688773  0.26836655 0.26840878 0.26877812
 0.26847088 0.26741594 0.26645863 0.26596758 0.2652788  0.26410815
 0.26344576 0.26315615 0.26283568 0.26266062 0.26240805 0.26239938
 0.26244774 0.26253793 0.2625033  0.26248348 0.26268643 0.26309428
 0.26343223 0.26333174 0.2631436  0.2632219  0.26339442 0.2633676
 0.2627556  0.26166704 0.26077992 0.26042303 0.26010892 0.25957066
 0.2592551  0.2588958  0.25830713 0.25781208 0.25766245 0.25750166
 0.25724098 0.2573526  0.25759095 0.25724334 0.25712168 0.25743046
 0.2569668  0.25624627 0.2560857  0.25522977 0.25544712 0.25749218]
