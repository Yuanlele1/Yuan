Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=58, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_360_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_360_96_FITS_ETTh1_ftM_sl360_ll48_pl96_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8185
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=58, out_features=73, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3793664.0
params:  4307.0
Trainable parameters:  4307
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.4528977870941162
Epoch: 1, Steps: 63 | Train Loss: 0.6625555 Vali Loss: 1.5376309 Test Loss: 0.8662583
Validation loss decreased (inf --> 1.537631).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.7847225666046143
Epoch: 2, Steps: 63 | Train Loss: 0.5520510 Vali Loss: 1.3997895 Test Loss: 0.7982903
Validation loss decreased (1.537631 --> 1.399789).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.3971662521362305
Epoch: 3, Steps: 63 | Train Loss: 0.4836387 Vali Loss: 1.3183393 Test Loss: 0.7619987
Validation loss decreased (1.399789 --> 1.318339).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.0775184631347656
Epoch: 4, Steps: 63 | Train Loss: 0.4389454 Vali Loss: 1.2785561 Test Loss: 0.7404694
Validation loss decreased (1.318339 --> 1.278556).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.5982210636138916
Epoch: 5, Steps: 63 | Train Loss: 0.4060417 Vali Loss: 1.2412540 Test Loss: 0.7231200
Validation loss decreased (1.278556 --> 1.241254).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.718308448791504
Epoch: 6, Steps: 63 | Train Loss: 0.3812433 Vali Loss: 1.2069842 Test Loss: 0.7076464
Validation loss decreased (1.241254 --> 1.206984).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.7404553890228271
Epoch: 7, Steps: 63 | Train Loss: 0.3607125 Vali Loss: 1.1875036 Test Loss: 0.6936099
Validation loss decreased (1.206984 --> 1.187504).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.6472487449645996
Epoch: 8, Steps: 63 | Train Loss: 0.3435097 Vali Loss: 1.1572104 Test Loss: 0.6808760
Validation loss decreased (1.187504 --> 1.157210).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.101515293121338
Epoch: 9, Steps: 63 | Train Loss: 0.3287684 Vali Loss: 1.1336108 Test Loss: 0.6684702
Validation loss decreased (1.157210 --> 1.133611).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.194819688796997
Epoch: 10, Steps: 63 | Train Loss: 0.3159430 Vali Loss: 1.1127999 Test Loss: 0.6561481
Validation loss decreased (1.133611 --> 1.112800).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.122429132461548
Epoch: 11, Steps: 63 | Train Loss: 0.3042698 Vali Loss: 1.0964552 Test Loss: 0.6465164
Validation loss decreased (1.112800 --> 1.096455).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.6549315452575684
Epoch: 12, Steps: 63 | Train Loss: 0.2936804 Vali Loss: 1.0780716 Test Loss: 0.6367101
Validation loss decreased (1.096455 --> 1.078072).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.4870872497558594
Epoch: 13, Steps: 63 | Train Loss: 0.2842978 Vali Loss: 1.0635751 Test Loss: 0.6259612
Validation loss decreased (1.078072 --> 1.063575).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.711287498474121
Epoch: 14, Steps: 63 | Train Loss: 0.2756891 Vali Loss: 1.0443102 Test Loss: 0.6156554
Validation loss decreased (1.063575 --> 1.044310).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.1849288940429688
Epoch: 15, Steps: 63 | Train Loss: 0.2680072 Vali Loss: 1.0334845 Test Loss: 0.6077859
Validation loss decreased (1.044310 --> 1.033484).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.942885398864746
Epoch: 16, Steps: 63 | Train Loss: 0.2608302 Vali Loss: 1.0193614 Test Loss: 0.5997396
Validation loss decreased (1.033484 --> 1.019361).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.7937674522399902
Epoch: 17, Steps: 63 | Train Loss: 0.2540787 Vali Loss: 1.0089483 Test Loss: 0.5921841
Validation loss decreased (1.019361 --> 1.008948).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.9667744636535645
Epoch: 18, Steps: 63 | Train Loss: 0.2482960 Vali Loss: 0.9975957 Test Loss: 0.5852022
Validation loss decreased (1.008948 --> 0.997596).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.661195993423462
Epoch: 19, Steps: 63 | Train Loss: 0.2427083 Vali Loss: 0.9870930 Test Loss: 0.5785048
Validation loss decreased (0.997596 --> 0.987093).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.7530701160430908
Epoch: 20, Steps: 63 | Train Loss: 0.2375046 Vali Loss: 0.9755692 Test Loss: 0.5722495
Validation loss decreased (0.987093 --> 0.975569).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.3040084838867188
Epoch: 21, Steps: 63 | Train Loss: 0.2331313 Vali Loss: 0.9680082 Test Loss: 0.5668454
Validation loss decreased (0.975569 --> 0.968008).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.166171073913574
Epoch: 22, Steps: 63 | Train Loss: 0.2289272 Vali Loss: 0.9610294 Test Loss: 0.5616385
Validation loss decreased (0.968008 --> 0.961029).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.1489596366882324
Epoch: 23, Steps: 63 | Train Loss: 0.2248097 Vali Loss: 0.9548038 Test Loss: 0.5568788
Validation loss decreased (0.961029 --> 0.954804).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.97994065284729
Epoch: 24, Steps: 63 | Train Loss: 0.2208869 Vali Loss: 0.9462003 Test Loss: 0.5513395
Validation loss decreased (0.954804 --> 0.946200).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.994368076324463
Epoch: 25, Steps: 63 | Train Loss: 0.2178625 Vali Loss: 0.9372433 Test Loss: 0.5474440
Validation loss decreased (0.946200 --> 0.937243).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.0288619995117188
Epoch: 26, Steps: 63 | Train Loss: 0.2146322 Vali Loss: 0.9306436 Test Loss: 0.5429859
Validation loss decreased (0.937243 --> 0.930644).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.6575226783752441
Epoch: 27, Steps: 63 | Train Loss: 0.2118406 Vali Loss: 0.9267882 Test Loss: 0.5383888
Validation loss decreased (0.930644 --> 0.926788).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.8477659225463867
Epoch: 28, Steps: 63 | Train Loss: 0.2089997 Vali Loss: 0.9182985 Test Loss: 0.5343818
Validation loss decreased (0.926788 --> 0.918299).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.1745426654815674
Epoch: 29, Steps: 63 | Train Loss: 0.2062851 Vali Loss: 0.9100773 Test Loss: 0.5309680
Validation loss decreased (0.918299 --> 0.910077).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.8292341232299805
Epoch: 30, Steps: 63 | Train Loss: 0.2039198 Vali Loss: 0.9075988 Test Loss: 0.5279855
Validation loss decreased (0.910077 --> 0.907599).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.1852035522460938
Epoch: 31, Steps: 63 | Train Loss: 0.2014934 Vali Loss: 0.9023581 Test Loss: 0.5250347
Validation loss decreased (0.907599 --> 0.902358).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.0749928951263428
Epoch: 32, Steps: 63 | Train Loss: 0.1995363 Vali Loss: 0.8980593 Test Loss: 0.5221651
Validation loss decreased (0.902358 --> 0.898059).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.0264737606048584
Epoch: 33, Steps: 63 | Train Loss: 0.1976352 Vali Loss: 0.8953770 Test Loss: 0.5193688
Validation loss decreased (0.898059 --> 0.895377).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.382873296737671
Epoch: 34, Steps: 63 | Train Loss: 0.1957711 Vali Loss: 0.8900287 Test Loss: 0.5166274
Validation loss decreased (0.895377 --> 0.890029).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.0112266540527344
Epoch: 35, Steps: 63 | Train Loss: 0.1938739 Vali Loss: 0.8890840 Test Loss: 0.5145550
Validation loss decreased (0.890029 --> 0.889084).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.5102214813232422
Epoch: 36, Steps: 63 | Train Loss: 0.1923368 Vali Loss: 0.8818921 Test Loss: 0.5121055
Validation loss decreased (0.889084 --> 0.881892).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.7301042079925537
Epoch: 37, Steps: 63 | Train Loss: 0.1906922 Vali Loss: 0.8802331 Test Loss: 0.5098258
Validation loss decreased (0.881892 --> 0.880233).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.3815510272979736
Epoch: 38, Steps: 63 | Train Loss: 0.1895558 Vali Loss: 0.8749194 Test Loss: 0.5078840
Validation loss decreased (0.880233 --> 0.874919).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.4669675827026367
Epoch: 39, Steps: 63 | Train Loss: 0.1879714 Vali Loss: 0.8732899 Test Loss: 0.5057318
Validation loss decreased (0.874919 --> 0.873290).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.2848479747772217
Epoch: 40, Steps: 63 | Train Loss: 0.1867179 Vali Loss: 0.8717353 Test Loss: 0.5036080
Validation loss decreased (0.873290 --> 0.871735).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.808049201965332
Epoch: 41, Steps: 63 | Train Loss: 0.1856290 Vali Loss: 0.8720462 Test Loss: 0.5022835
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.3927810192108154
Epoch: 42, Steps: 63 | Train Loss: 0.1842332 Vali Loss: 0.8656522 Test Loss: 0.5006164
Validation loss decreased (0.871735 --> 0.865652).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.8143587112426758
Epoch: 43, Steps: 63 | Train Loss: 0.1833908 Vali Loss: 0.8682015 Test Loss: 0.4991407
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.5773265361785889
Epoch: 44, Steps: 63 | Train Loss: 0.1821411 Vali Loss: 0.8620262 Test Loss: 0.4977272
Validation loss decreased (0.865652 --> 0.862026).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.6434268951416016
Epoch: 45, Steps: 63 | Train Loss: 0.1811227 Vali Loss: 0.8613034 Test Loss: 0.4961819
Validation loss decreased (0.862026 --> 0.861303).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.9492805004119873
Epoch: 46, Steps: 63 | Train Loss: 0.1804344 Vali Loss: 0.8586226 Test Loss: 0.4949894
Validation loss decreased (0.861303 --> 0.858623).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.1627862453460693
Epoch: 47, Steps: 63 | Train Loss: 0.1794409 Vali Loss: 0.8546435 Test Loss: 0.4938681
Validation loss decreased (0.858623 --> 0.854644).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.1619279384613037
Epoch: 48, Steps: 63 | Train Loss: 0.1787102 Vali Loss: 0.8559057 Test Loss: 0.4926591
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.333798885345459
Epoch: 49, Steps: 63 | Train Loss: 0.1780683 Vali Loss: 0.8540816 Test Loss: 0.4916501
Validation loss decreased (0.854644 --> 0.854082).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.9093999862670898
Epoch: 50, Steps: 63 | Train Loss: 0.1771860 Vali Loss: 0.8523695 Test Loss: 0.4903911
Validation loss decreased (0.854082 --> 0.852369).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.613687038421631
Epoch: 51, Steps: 63 | Train Loss: 0.1765734 Vali Loss: 0.8489245 Test Loss: 0.4894584
Validation loss decreased (0.852369 --> 0.848925).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.835902214050293
Epoch: 52, Steps: 63 | Train Loss: 0.1758871 Vali Loss: 0.8517411 Test Loss: 0.4884763
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.798661708831787
Epoch: 53, Steps: 63 | Train Loss: 0.1752067 Vali Loss: 0.8475654 Test Loss: 0.4875096
Validation loss decreased (0.848925 --> 0.847565).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.8670942783355713
Epoch: 54, Steps: 63 | Train Loss: 0.1747380 Vali Loss: 0.8453858 Test Loss: 0.4866997
Validation loss decreased (0.847565 --> 0.845386).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.6348602771759033
Epoch: 55, Steps: 63 | Train Loss: 0.1741267 Vali Loss: 0.8471525 Test Loss: 0.4859367
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.183361053466797
Epoch: 56, Steps: 63 | Train Loss: 0.1735795 Vali Loss: 0.8453891 Test Loss: 0.4851024
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.1466684341430664
Epoch: 57, Steps: 63 | Train Loss: 0.1729743 Vali Loss: 0.8442724 Test Loss: 0.4843002
Validation loss decreased (0.845386 --> 0.844272).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.500156879425049
Epoch: 58, Steps: 63 | Train Loss: 0.1725522 Vali Loss: 0.8397353 Test Loss: 0.4836430
Validation loss decreased (0.844272 --> 0.839735).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 3.2619221210479736
Epoch: 59, Steps: 63 | Train Loss: 0.1720256 Vali Loss: 0.8433971 Test Loss: 0.4829343
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.222761631011963
Epoch: 60, Steps: 63 | Train Loss: 0.1717896 Vali Loss: 0.8430417 Test Loss: 0.4823319
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.7967689037322998
Epoch: 61, Steps: 63 | Train Loss: 0.1711744 Vali Loss: 0.8395625 Test Loss: 0.4817019
Validation loss decreased (0.839735 --> 0.839562).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.7872991561889648
Epoch: 62, Steps: 63 | Train Loss: 0.1707905 Vali Loss: 0.8387107 Test Loss: 0.4812068
Validation loss decreased (0.839562 --> 0.838711).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.4278008937835693
Epoch: 63, Steps: 63 | Train Loss: 0.1704375 Vali Loss: 0.8385972 Test Loss: 0.4806995
Validation loss decreased (0.838711 --> 0.838597).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.5341668128967285
Epoch: 64, Steps: 63 | Train Loss: 0.1702646 Vali Loss: 0.8364305 Test Loss: 0.4801469
Validation loss decreased (0.838597 --> 0.836430).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.5498311519622803
Epoch: 65, Steps: 63 | Train Loss: 0.1698630 Vali Loss: 0.8342757 Test Loss: 0.4796463
Validation loss decreased (0.836430 --> 0.834276).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.4391093254089355
Epoch: 66, Steps: 63 | Train Loss: 0.1694736 Vali Loss: 0.8383376 Test Loss: 0.4790669
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.7840309143066406
Epoch: 67, Steps: 63 | Train Loss: 0.1691773 Vali Loss: 0.8397082 Test Loss: 0.4786839
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.8986716270446777
Epoch: 68, Steps: 63 | Train Loss: 0.1688998 Vali Loss: 0.8336130 Test Loss: 0.4782531
Validation loss decreased (0.834276 --> 0.833613).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.6833794116973877
Epoch: 69, Steps: 63 | Train Loss: 0.1687162 Vali Loss: 0.8337004 Test Loss: 0.4779227
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.1031711101531982
Epoch: 70, Steps: 63 | Train Loss: 0.1683944 Vali Loss: 0.8338491 Test Loss: 0.4775417
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.038642644882202
Epoch: 71, Steps: 63 | Train Loss: 0.1681890 Vali Loss: 0.8332028 Test Loss: 0.4771537
Validation loss decreased (0.833613 --> 0.833203).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.5422027111053467
Epoch: 72, Steps: 63 | Train Loss: 0.1680228 Vali Loss: 0.8348241 Test Loss: 0.4768545
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.2259609699249268
Epoch: 73, Steps: 63 | Train Loss: 0.1676702 Vali Loss: 0.8339015 Test Loss: 0.4765371
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.6553523540496826
Epoch: 74, Steps: 63 | Train Loss: 0.1672318 Vali Loss: 0.8295066 Test Loss: 0.4762069
Validation loss decreased (0.833203 --> 0.829507).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.190133571624756
Epoch: 75, Steps: 63 | Train Loss: 0.1672943 Vali Loss: 0.8311326 Test Loss: 0.4759301
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.2753255367279053
Epoch: 76, Steps: 63 | Train Loss: 0.1671410 Vali Loss: 0.8285509 Test Loss: 0.4756116
Validation loss decreased (0.829507 --> 0.828551).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.8011362552642822
Epoch: 77, Steps: 63 | Train Loss: 0.1669370 Vali Loss: 0.8314646 Test Loss: 0.4753896
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.3807332515716553
Epoch: 78, Steps: 63 | Train Loss: 0.1667667 Vali Loss: 0.8291598 Test Loss: 0.4750511
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.30574107170105
Epoch: 79, Steps: 63 | Train Loss: 0.1666135 Vali Loss: 0.8265961 Test Loss: 0.4748180
Validation loss decreased (0.828551 --> 0.826596).  Saving model ...
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.1265954971313477
Epoch: 80, Steps: 63 | Train Loss: 0.1663223 Vali Loss: 0.8275150 Test Loss: 0.4745981
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.182576894760132
Epoch: 81, Steps: 63 | Train Loss: 0.1662307 Vali Loss: 0.8283716 Test Loss: 0.4743664
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 2.44724702835083
Epoch: 82, Steps: 63 | Train Loss: 0.1661514 Vali Loss: 0.8266470 Test Loss: 0.4741613
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.228107452392578
Epoch: 83, Steps: 63 | Train Loss: 0.1659849 Vali Loss: 0.8309080 Test Loss: 0.4739704
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.7954843044281006
Epoch: 84, Steps: 63 | Train Loss: 0.1656330 Vali Loss: 0.8276046 Test Loss: 0.4738470
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.7646217346191406
Epoch: 85, Steps: 63 | Train Loss: 0.1657295 Vali Loss: 0.8275512 Test Loss: 0.4736309
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.6202211380004883
Epoch: 86, Steps: 63 | Train Loss: 0.1656670 Vali Loss: 0.8257031 Test Loss: 0.4734658
Validation loss decreased (0.826596 --> 0.825703).  Saving model ...
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.4543194770812988
Epoch: 87, Steps: 63 | Train Loss: 0.1653799 Vali Loss: 0.8289539 Test Loss: 0.4732933
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.8889439105987549
Epoch: 88, Steps: 63 | Train Loss: 0.1653128 Vali Loss: 0.8277331 Test Loss: 0.4731003
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.6008045673370361
Epoch: 89, Steps: 63 | Train Loss: 0.1651780 Vali Loss: 0.8299323 Test Loss: 0.4729748
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.3394038677215576
Epoch: 90, Steps: 63 | Train Loss: 0.1651975 Vali Loss: 0.8229221 Test Loss: 0.4728047
Validation loss decreased (0.825703 --> 0.822922).  Saving model ...
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.6259260177612305
Epoch: 91, Steps: 63 | Train Loss: 0.1651182 Vali Loss: 0.8296484 Test Loss: 0.4727277
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.9311039447784424
Epoch: 92, Steps: 63 | Train Loss: 0.1649807 Vali Loss: 0.8247140 Test Loss: 0.4725803
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 2.0567851066589355
Epoch: 93, Steps: 63 | Train Loss: 0.1649814 Vali Loss: 0.8275478 Test Loss: 0.4724698
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.8720324039459229
Epoch: 94, Steps: 63 | Train Loss: 0.1649550 Vali Loss: 0.8248349 Test Loss: 0.4723714
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.5986835956573486
Epoch: 95, Steps: 63 | Train Loss: 0.1649343 Vali Loss: 0.8204871 Test Loss: 0.4722312
Validation loss decreased (0.822922 --> 0.820487).  Saving model ...
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.962794542312622
Epoch: 96, Steps: 63 | Train Loss: 0.1647923 Vali Loss: 0.8243263 Test Loss: 0.4721484
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.9901008605957031
Epoch: 97, Steps: 63 | Train Loss: 0.1646367 Vali Loss: 0.8260000 Test Loss: 0.4720618
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 2.235717296600342
Epoch: 98, Steps: 63 | Train Loss: 0.1646048 Vali Loss: 0.8219939 Test Loss: 0.4719606
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.9912896156311035
Epoch: 99, Steps: 63 | Train Loss: 0.1645175 Vali Loss: 0.8240348 Test Loss: 0.4718742
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.8732807636260986
Epoch: 100, Steps: 63 | Train Loss: 0.1645165 Vali Loss: 0.8242332 Test Loss: 0.4717949
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8185
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=58, out_features=73, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3793664.0
params:  4307.0
Trainable parameters:  4307
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.3901288509368896
Epoch: 1, Steps: 63 | Train Loss: 0.3832537 Vali Loss: 0.7219830 Test Loss: 0.4020698
Validation loss decreased (inf --> 0.721983).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.0940253734588623
Epoch: 2, Steps: 63 | Train Loss: 0.3577962 Vali Loss: 0.6957934 Test Loss: 0.3856935
Validation loss decreased (0.721983 --> 0.695793).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.3774898052215576
Epoch: 3, Steps: 63 | Train Loss: 0.3514634 Vali Loss: 0.6863015 Test Loss: 0.3834240
Validation loss decreased (0.695793 --> 0.686301).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.010331153869629
Epoch: 4, Steps: 63 | Train Loss: 0.3497358 Vali Loss: 0.6876292 Test Loss: 0.3831793
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.487924098968506
Epoch: 5, Steps: 63 | Train Loss: 0.3497439 Vali Loss: 0.6868275 Test Loss: 0.3828690
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.6757516860961914
Epoch: 6, Steps: 63 | Train Loss: 0.3482455 Vali Loss: 0.6795327 Test Loss: 0.3825459
Validation loss decreased (0.686301 --> 0.679533).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.8311097621917725
Epoch: 7, Steps: 63 | Train Loss: 0.3485418 Vali Loss: 0.6860515 Test Loss: 0.3825042
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.7512109279632568
Epoch: 8, Steps: 63 | Train Loss: 0.3483445 Vali Loss: 0.6812457 Test Loss: 0.3825447
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.1543545722961426
Epoch: 9, Steps: 63 | Train Loss: 0.3481893 Vali Loss: 0.6831771 Test Loss: 0.3824504
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.4255273342132568
Epoch: 10, Steps: 63 | Train Loss: 0.3475964 Vali Loss: 0.6827425 Test Loss: 0.3820796
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.6109933853149414
Epoch: 11, Steps: 63 | Train Loss: 0.3479311 Vali Loss: 0.6819792 Test Loss: 0.3821658
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.7672443389892578
Epoch: 12, Steps: 63 | Train Loss: 0.3471828 Vali Loss: 0.6803966 Test Loss: 0.3821566
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.6116535663604736
Epoch: 13, Steps: 63 | Train Loss: 0.3477730 Vali Loss: 0.6805440 Test Loss: 0.3819552
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.092158555984497
Epoch: 14, Steps: 63 | Train Loss: 0.3476127 Vali Loss: 0.6806313 Test Loss: 0.3820610
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.7316913604736328
Epoch: 15, Steps: 63 | Train Loss: 0.3476593 Vali Loss: 0.6804330 Test Loss: 0.3819833
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.5749566555023193
Epoch: 16, Steps: 63 | Train Loss: 0.3473135 Vali Loss: 0.6786231 Test Loss: 0.3819203
Validation loss decreased (0.679533 --> 0.678623).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.8761069774627686
Epoch: 17, Steps: 63 | Train Loss: 0.3473845 Vali Loss: 0.6813859 Test Loss: 0.3818441
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.1703593730926514
Epoch: 18, Steps: 63 | Train Loss: 0.3467140 Vali Loss: 0.6795426 Test Loss: 0.3818317
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.5600013732910156
Epoch: 19, Steps: 63 | Train Loss: 0.3474848 Vali Loss: 0.6774207 Test Loss: 0.3817585
Validation loss decreased (0.678623 --> 0.677421).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.0627198219299316
Epoch: 20, Steps: 63 | Train Loss: 0.3474396 Vali Loss: 0.6814762 Test Loss: 0.3818228
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.0585532188415527
Epoch: 21, Steps: 63 | Train Loss: 0.3472473 Vali Loss: 0.6833504 Test Loss: 0.3820194
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.647113561630249
Epoch: 22, Steps: 63 | Train Loss: 0.3473582 Vali Loss: 0.6786835 Test Loss: 0.3819121
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.9079554080963135
Epoch: 23, Steps: 63 | Train Loss: 0.3470460 Vali Loss: 0.6866157 Test Loss: 0.3818578
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.0040760040283203
Epoch: 24, Steps: 63 | Train Loss: 0.3472527 Vali Loss: 0.6841086 Test Loss: 0.3819581
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.316951274871826
Epoch: 25, Steps: 63 | Train Loss: 0.3473702 Vali Loss: 0.6806466 Test Loss: 0.3818278
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.276871681213379
Epoch: 26, Steps: 63 | Train Loss: 0.3468808 Vali Loss: 0.6783394 Test Loss: 0.3817204
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.5855698585510254
Epoch: 27, Steps: 63 | Train Loss: 0.3474205 Vali Loss: 0.6777436 Test Loss: 0.3818467
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.0486059188842773
Epoch: 28, Steps: 63 | Train Loss: 0.3468134 Vali Loss: 0.6779569 Test Loss: 0.3817924
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.5733370780944824
Epoch: 29, Steps: 63 | Train Loss: 0.3465907 Vali Loss: 0.6804725 Test Loss: 0.3818524
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.4149150848388672
Epoch: 30, Steps: 63 | Train Loss: 0.3467405 Vali Loss: 0.6820006 Test Loss: 0.3818127
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.839212417602539
Epoch: 31, Steps: 63 | Train Loss: 0.3463074 Vali Loss: 0.6783057 Test Loss: 0.3817489
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.9046659469604492
Epoch: 32, Steps: 63 | Train Loss: 0.3473037 Vali Loss: 0.6815602 Test Loss: 0.3818299
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.8290472030639648
Epoch: 33, Steps: 63 | Train Loss: 0.3468004 Vali Loss: 0.6830011 Test Loss: 0.3817575
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.480647087097168
Epoch: 34, Steps: 63 | Train Loss: 0.3466693 Vali Loss: 0.6802852 Test Loss: 0.3817751
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.2147560119628906
Epoch: 35, Steps: 63 | Train Loss: 0.3466712 Vali Loss: 0.6771185 Test Loss: 0.3816354
Validation loss decreased (0.677421 --> 0.677119).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.9613676071166992
Epoch: 36, Steps: 63 | Train Loss: 0.3472171 Vali Loss: 0.6847203 Test Loss: 0.3818322
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.8373725414276123
Epoch: 37, Steps: 63 | Train Loss: 0.3469491 Vali Loss: 0.6815366 Test Loss: 0.3817832
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.8953003883361816
Epoch: 38, Steps: 63 | Train Loss: 0.3466411 Vali Loss: 0.6801629 Test Loss: 0.3818206
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.1586244106292725
Epoch: 39, Steps: 63 | Train Loss: 0.3464926 Vali Loss: 0.6784758 Test Loss: 0.3817590
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.0914318561553955
Epoch: 40, Steps: 63 | Train Loss: 0.3462747 Vali Loss: 0.6816398 Test Loss: 0.3818521
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.2088518142700195
Epoch: 41, Steps: 63 | Train Loss: 0.3468350 Vali Loss: 0.6771364 Test Loss: 0.3818574
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.737612009048462
Epoch: 42, Steps: 63 | Train Loss: 0.3465038 Vali Loss: 0.6770931 Test Loss: 0.3817769
Validation loss decreased (0.677119 --> 0.677093).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.09844970703125
Epoch: 43, Steps: 63 | Train Loss: 0.3461966 Vali Loss: 0.6802056 Test Loss: 0.3818548
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.3314216136932373
Epoch: 44, Steps: 63 | Train Loss: 0.3468420 Vali Loss: 0.6847005 Test Loss: 0.3818716
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.9553380012512207
Epoch: 45, Steps: 63 | Train Loss: 0.3467187 Vali Loss: 0.6789032 Test Loss: 0.3818318
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.6026391983032227
Epoch: 46, Steps: 63 | Train Loss: 0.3467278 Vali Loss: 0.6819682 Test Loss: 0.3818618
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.7909095287322998
Epoch: 47, Steps: 63 | Train Loss: 0.3464861 Vali Loss: 0.6826250 Test Loss: 0.3818374
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.623537302017212
Epoch: 48, Steps: 63 | Train Loss: 0.3461355 Vali Loss: 0.6785601 Test Loss: 0.3818487
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.789994239807129
Epoch: 49, Steps: 63 | Train Loss: 0.3465325 Vali Loss: 0.6806953 Test Loss: 0.3818094
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.361710786819458
Epoch: 50, Steps: 63 | Train Loss: 0.3460129 Vali Loss: 0.6804246 Test Loss: 0.3818072
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.5516183376312256
Epoch: 51, Steps: 63 | Train Loss: 0.3463027 Vali Loss: 0.6818979 Test Loss: 0.3818134
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.5941965579986572
Epoch: 52, Steps: 63 | Train Loss: 0.3460641 Vali Loss: 0.6783676 Test Loss: 0.3817908
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.5789644718170166
Epoch: 53, Steps: 63 | Train Loss: 0.3469071 Vali Loss: 0.6762540 Test Loss: 0.3818235
Validation loss decreased (0.677093 --> 0.676254).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.2611515522003174
Epoch: 54, Steps: 63 | Train Loss: 0.3466953 Vali Loss: 0.6786061 Test Loss: 0.3818452
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.628638505935669
Epoch: 55, Steps: 63 | Train Loss: 0.3465388 Vali Loss: 0.6782416 Test Loss: 0.3818283
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.7391769886016846
Epoch: 56, Steps: 63 | Train Loss: 0.3468222 Vali Loss: 0.6787267 Test Loss: 0.3818211
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.7600340843200684
Epoch: 57, Steps: 63 | Train Loss: 0.3465466 Vali Loss: 0.6801095 Test Loss: 0.3818140
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.7707176208496094
Epoch: 58, Steps: 63 | Train Loss: 0.3459430 Vali Loss: 0.6804578 Test Loss: 0.3817992
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.1485776901245117
Epoch: 59, Steps: 63 | Train Loss: 0.3464969 Vali Loss: 0.6807364 Test Loss: 0.3818129
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.261263847351074
Epoch: 60, Steps: 63 | Train Loss: 0.3469832 Vali Loss: 0.6773654 Test Loss: 0.3817955
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.1735267639160156
Epoch: 61, Steps: 63 | Train Loss: 0.3465606 Vali Loss: 0.6804118 Test Loss: 0.3817844
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.5798897743225098
Epoch: 62, Steps: 63 | Train Loss: 0.3463148 Vali Loss: 0.6805978 Test Loss: 0.3817858
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.7116444110870361
Epoch: 63, Steps: 63 | Train Loss: 0.3463850 Vali Loss: 0.6788372 Test Loss: 0.3818062
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.1937828063964844
Epoch: 64, Steps: 63 | Train Loss: 0.3463852 Vali Loss: 0.6804787 Test Loss: 0.3817864
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.164170742034912
Epoch: 65, Steps: 63 | Train Loss: 0.3464396 Vali Loss: 0.6777666 Test Loss: 0.3818159
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.555798053741455
Epoch: 66, Steps: 63 | Train Loss: 0.3470120 Vali Loss: 0.6779500 Test Loss: 0.3818112
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.4564616680145264
Epoch: 67, Steps: 63 | Train Loss: 0.3461960 Vali Loss: 0.6798051 Test Loss: 0.3818069
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.482370138168335
Epoch: 68, Steps: 63 | Train Loss: 0.3470673 Vali Loss: 0.6792136 Test Loss: 0.3817928
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.4630966186523438
Epoch: 69, Steps: 63 | Train Loss: 0.3461070 Vali Loss: 0.6793571 Test Loss: 0.3818061
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.341073513031006
Epoch: 70, Steps: 63 | Train Loss: 0.3466832 Vali Loss: 0.6777884 Test Loss: 0.3818027
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.2699427604675293
Epoch: 71, Steps: 63 | Train Loss: 0.3465209 Vali Loss: 0.6803483 Test Loss: 0.3817895
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.8634521961212158
Epoch: 72, Steps: 63 | Train Loss: 0.3463197 Vali Loss: 0.6785275 Test Loss: 0.3818029
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.063802480697632
Epoch: 73, Steps: 63 | Train Loss: 0.3466928 Vali Loss: 0.6799968 Test Loss: 0.3817824
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_360_96_FITS_ETTh1_ftM_sl360_ll48_pl96_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.38082465529441833, mae:0.4014609456062317, rse:0.5861656665802002, corr:[0.2708993  0.2776167  0.2784699  0.2760323  0.27299207 0.27100086
 0.27000466 0.2698923  0.269793   0.2695071  0.2692111  0.26892334
 0.26883984 0.26896313 0.26912373 0.26916307 0.26897356 0.2686224
 0.26827303 0.2679028  0.26763308 0.2676159  0.26777327 0.26802716
 0.26800644 0.26777542 0.2674872  0.26719496 0.26677313 0.26628724
 0.26585504 0.2655134  0.2653078  0.2651025  0.26494572 0.2648232
 0.26486996 0.2651006  0.265395   0.26560345 0.26589644 0.26604453
 0.26605746 0.26594684 0.2658087  0.26568288 0.26571858 0.26578522
 0.26550877 0.26477274 0.26358706 0.26247585 0.26158953 0.26077536
 0.26028714 0.26008296 0.25995862 0.2598209  0.25953916 0.25941765
 0.259415   0.25951964 0.25960007 0.259686   0.25975114 0.25983682
 0.25998563 0.25999612 0.2600337  0.260268   0.26052752 0.2604156
 0.25974593 0.25876474 0.25775516 0.25700834 0.25656137 0.25622115
 0.25596893 0.25561526 0.25519663 0.25476405 0.25433904 0.25408432
 0.25414875 0.25432524 0.25442666 0.25434092 0.2542706  0.25435925
 0.25427318 0.25372723 0.25317866 0.25341702 0.25427458 0.2540561 ]
