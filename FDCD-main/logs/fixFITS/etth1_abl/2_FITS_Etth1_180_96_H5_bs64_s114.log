Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=50, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_180_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_180_96_FITS_ETTh1_ftM_sl180_ll48_pl96_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8365
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=50, out_features=76, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3404800.0
params:  3876.0
Trainable parameters:  3876
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.8196165561676025
Epoch: 1, Steps: 65 | Train Loss: 0.5330629 Vali Loss: 1.2080873 Test Loss: 0.6841603
Validation loss decreased (inf --> 1.208087).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.721670150756836
Epoch: 2, Steps: 65 | Train Loss: 0.4088526 Vali Loss: 1.0417267 Test Loss: 0.5852948
Validation loss decreased (1.208087 --> 1.041727).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.2631781101226807
Epoch: 3, Steps: 65 | Train Loss: 0.3414770 Vali Loss: 0.9650931 Test Loss: 0.5367069
Validation loss decreased (1.041727 --> 0.965093).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.6024000644683838
Epoch: 4, Steps: 65 | Train Loss: 0.2999185 Vali Loss: 0.9085874 Test Loss: 0.5103234
Validation loss decreased (0.965093 --> 0.908587).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.8956615924835205
Epoch: 5, Steps: 65 | Train Loss: 0.2725223 Vali Loss: 0.8836039 Test Loss: 0.4944925
Validation loss decreased (0.908587 --> 0.883604).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.1587576866149902
Epoch: 6, Steps: 65 | Train Loss: 0.2530262 Vali Loss: 0.8599396 Test Loss: 0.4844885
Validation loss decreased (0.883604 --> 0.859940).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.6931326389312744
Epoch: 7, Steps: 65 | Train Loss: 0.2388130 Vali Loss: 0.8436458 Test Loss: 0.4766094
Validation loss decreased (0.859940 --> 0.843646).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.6712827682495117
Epoch: 8, Steps: 65 | Train Loss: 0.2275655 Vali Loss: 0.8262902 Test Loss: 0.4703173
Validation loss decreased (0.843646 --> 0.826290).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.500162124633789
Epoch: 9, Steps: 65 | Train Loss: 0.2184679 Vali Loss: 0.8188052 Test Loss: 0.4655936
Validation loss decreased (0.826290 --> 0.818805).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.0398926734924316
Epoch: 10, Steps: 65 | Train Loss: 0.2111602 Vali Loss: 0.8168700 Test Loss: 0.4615998
Validation loss decreased (0.818805 --> 0.816870).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.708749771118164
Epoch: 11, Steps: 65 | Train Loss: 0.2049022 Vali Loss: 0.8075248 Test Loss: 0.4576928
Validation loss decreased (0.816870 --> 0.807525).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.3860254287719727
Epoch: 12, Steps: 65 | Train Loss: 0.1994560 Vali Loss: 0.7974491 Test Loss: 0.4543974
Validation loss decreased (0.807525 --> 0.797449).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 4.034083366394043
Epoch: 13, Steps: 65 | Train Loss: 0.1948011 Vali Loss: 0.7946362 Test Loss: 0.4510834
Validation loss decreased (0.797449 --> 0.794636).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.878774642944336
Epoch: 14, Steps: 65 | Train Loss: 0.1907097 Vali Loss: 0.7900683 Test Loss: 0.4486439
Validation loss decreased (0.794636 --> 0.790068).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.7864439487457275
Epoch: 15, Steps: 65 | Train Loss: 0.1871527 Vali Loss: 0.7894318 Test Loss: 0.4461689
Validation loss decreased (0.790068 --> 0.789432).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.128371238708496
Epoch: 16, Steps: 65 | Train Loss: 0.1838508 Vali Loss: 0.7806553 Test Loss: 0.4435849
Validation loss decreased (0.789432 --> 0.780655).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.1678214073181152
Epoch: 17, Steps: 65 | Train Loss: 0.1811785 Vali Loss: 0.7779603 Test Loss: 0.4414002
Validation loss decreased (0.780655 --> 0.777960).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.9435250759124756
Epoch: 18, Steps: 65 | Train Loss: 0.1786430 Vali Loss: 0.7754545 Test Loss: 0.4397452
Validation loss decreased (0.777960 --> 0.775454).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.130335807800293
Epoch: 19, Steps: 65 | Train Loss: 0.1763312 Vali Loss: 0.7720240 Test Loss: 0.4379592
Validation loss decreased (0.775454 --> 0.772024).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.7455461025238037
Epoch: 20, Steps: 65 | Train Loss: 0.1741399 Vali Loss: 0.7699897 Test Loss: 0.4362212
Validation loss decreased (0.772024 --> 0.769990).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.8285386562347412
Epoch: 21, Steps: 65 | Train Loss: 0.1725610 Vali Loss: 0.7653483 Test Loss: 0.4346583
Validation loss decreased (0.769990 --> 0.765348).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.400691270828247
Epoch: 22, Steps: 65 | Train Loss: 0.1708429 Vali Loss: 0.7655969 Test Loss: 0.4332539
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.4119744300842285
Epoch: 23, Steps: 65 | Train Loss: 0.1691886 Vali Loss: 0.7675568 Test Loss: 0.4319377
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.9803171157836914
Epoch: 24, Steps: 65 | Train Loss: 0.1678931 Vali Loss: 0.7640665 Test Loss: 0.4306631
Validation loss decreased (0.765348 --> 0.764067).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.5795097351074219
Epoch: 25, Steps: 65 | Train Loss: 0.1665549 Vali Loss: 0.7619125 Test Loss: 0.4294719
Validation loss decreased (0.764067 --> 0.761912).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.373000383377075
Epoch: 26, Steps: 65 | Train Loss: 0.1655046 Vali Loss: 0.7610124 Test Loss: 0.4283746
Validation loss decreased (0.761912 --> 0.761012).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 3.455778121948242
Epoch: 27, Steps: 65 | Train Loss: 0.1643765 Vali Loss: 0.7554425 Test Loss: 0.4274206
Validation loss decreased (0.761012 --> 0.755443).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.132275342941284
Epoch: 28, Steps: 65 | Train Loss: 0.1634597 Vali Loss: 0.7586777 Test Loss: 0.4264236
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 3.4318175315856934
Epoch: 29, Steps: 65 | Train Loss: 0.1624576 Vali Loss: 0.7549110 Test Loss: 0.4255717
Validation loss decreased (0.755443 --> 0.754911).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.7206003665924072
Epoch: 30, Steps: 65 | Train Loss: 0.1617407 Vali Loss: 0.7545357 Test Loss: 0.4246788
Validation loss decreased (0.754911 --> 0.754536).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.2341229915618896
Epoch: 31, Steps: 65 | Train Loss: 0.1609831 Vali Loss: 0.7546511 Test Loss: 0.4239087
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.9445254802703857
Epoch: 32, Steps: 65 | Train Loss: 0.1601717 Vali Loss: 0.7544857 Test Loss: 0.4231785
Validation loss decreased (0.754536 --> 0.754486).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.8575246334075928
Epoch: 33, Steps: 65 | Train Loss: 0.1593610 Vali Loss: 0.7553138 Test Loss: 0.4224808
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.8762428760528564
Epoch: 34, Steps: 65 | Train Loss: 0.1588910 Vali Loss: 0.7474441 Test Loss: 0.4218666
Validation loss decreased (0.754486 --> 0.747444).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.664672613143921
Epoch: 35, Steps: 65 | Train Loss: 0.1581691 Vali Loss: 0.7516364 Test Loss: 0.4212312
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.392946243286133
Epoch: 36, Steps: 65 | Train Loss: 0.1576730 Vali Loss: 0.7494184 Test Loss: 0.4206607
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 3.064108371734619
Epoch: 37, Steps: 65 | Train Loss: 0.1573217 Vali Loss: 0.7490762 Test Loss: 0.4201055
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.223245620727539
Epoch: 38, Steps: 65 | Train Loss: 0.1567439 Vali Loss: 0.7455000 Test Loss: 0.4195687
Validation loss decreased (0.747444 --> 0.745500).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.687173843383789
Epoch: 39, Steps: 65 | Train Loss: 0.1562602 Vali Loss: 0.7469268 Test Loss: 0.4190537
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.6179478168487549
Epoch: 40, Steps: 65 | Train Loss: 0.1558282 Vali Loss: 0.7472709 Test Loss: 0.4186008
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.5631964206695557
Epoch: 41, Steps: 65 | Train Loss: 0.1555953 Vali Loss: 0.7458189 Test Loss: 0.4181542
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.897995948791504
Epoch: 42, Steps: 65 | Train Loss: 0.1551525 Vali Loss: 0.7487088 Test Loss: 0.4177457
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.713839054107666
Epoch: 43, Steps: 65 | Train Loss: 0.1548937 Vali Loss: 0.7431533 Test Loss: 0.4173618
Validation loss decreased (0.745500 --> 0.743153).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.6009771823883057
Epoch: 44, Steps: 65 | Train Loss: 0.1545351 Vali Loss: 0.7432088 Test Loss: 0.4169588
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.6987500190734863
Epoch: 45, Steps: 65 | Train Loss: 0.1542741 Vali Loss: 0.7409945 Test Loss: 0.4166117
Validation loss decreased (0.743153 --> 0.740995).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.7076764106750488
Epoch: 46, Steps: 65 | Train Loss: 0.1538772 Vali Loss: 0.7401477 Test Loss: 0.4162832
Validation loss decreased (0.740995 --> 0.740148).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.282924175262451
Epoch: 47, Steps: 65 | Train Loss: 0.1535455 Vali Loss: 0.7443229 Test Loss: 0.4159762
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.1010799407958984
Epoch: 48, Steps: 65 | Train Loss: 0.1532756 Vali Loss: 0.7431414 Test Loss: 0.4156241
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.3761909008026123
Epoch: 49, Steps: 65 | Train Loss: 0.1531411 Vali Loss: 0.7420276 Test Loss: 0.4154098
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.899132251739502
Epoch: 50, Steps: 65 | Train Loss: 0.1528731 Vali Loss: 0.7391888 Test Loss: 0.4150902
Validation loss decreased (0.740148 --> 0.739189).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 3.19197940826416
Epoch: 51, Steps: 65 | Train Loss: 0.1526092 Vali Loss: 0.7419140 Test Loss: 0.4148766
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.797517776489258
Epoch: 52, Steps: 65 | Train Loss: 0.1525013 Vali Loss: 0.7402046 Test Loss: 0.4146001
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.9075922966003418
Epoch: 53, Steps: 65 | Train Loss: 0.1522249 Vali Loss: 0.7453113 Test Loss: 0.4143665
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.89674711227417
Epoch: 54, Steps: 65 | Train Loss: 0.1521309 Vali Loss: 0.7408566 Test Loss: 0.4141390
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.784384250640869
Epoch: 55, Steps: 65 | Train Loss: 0.1519210 Vali Loss: 0.7390861 Test Loss: 0.4139659
Validation loss decreased (0.739189 --> 0.739086).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.6566996574401855
Epoch: 56, Steps: 65 | Train Loss: 0.1517593 Vali Loss: 0.7406541 Test Loss: 0.4137476
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.540104627609253
Epoch: 57, Steps: 65 | Train Loss: 0.1515844 Vali Loss: 0.7411239 Test Loss: 0.4135458
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.0932247638702393
Epoch: 58, Steps: 65 | Train Loss: 0.1515854 Vali Loss: 0.7364277 Test Loss: 0.4133574
Validation loss decreased (0.739086 --> 0.736428).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 3.4817357063293457
Epoch: 59, Steps: 65 | Train Loss: 0.1512788 Vali Loss: 0.7393281 Test Loss: 0.4131944
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.406935453414917
Epoch: 60, Steps: 65 | Train Loss: 0.1511802 Vali Loss: 0.7396129 Test Loss: 0.4130208
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.247499704360962
Epoch: 61, Steps: 65 | Train Loss: 0.1511239 Vali Loss: 0.7445794 Test Loss: 0.4128649
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.5710158348083496
Epoch: 62, Steps: 65 | Train Loss: 0.1509180 Vali Loss: 0.7414774 Test Loss: 0.4127200
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.7955238819122314
Epoch: 63, Steps: 65 | Train Loss: 0.1508546 Vali Loss: 0.7347987 Test Loss: 0.4125846
Validation loss decreased (0.736428 --> 0.734799).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.7154545783996582
Epoch: 64, Steps: 65 | Train Loss: 0.1507489 Vali Loss: 0.7388390 Test Loss: 0.4124480
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.6591103076934814
Epoch: 65, Steps: 65 | Train Loss: 0.1506870 Vali Loss: 0.7375146 Test Loss: 0.4123099
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.8493974208831787
Epoch: 66, Steps: 65 | Train Loss: 0.1505021 Vali Loss: 0.7372611 Test Loss: 0.4121786
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.7231600284576416
Epoch: 67, Steps: 65 | Train Loss: 0.1505173 Vali Loss: 0.7402881 Test Loss: 0.4120671
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.7307486534118652
Epoch: 68, Steps: 65 | Train Loss: 0.1504278 Vali Loss: 0.7387986 Test Loss: 0.4119641
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.376396894454956
Epoch: 69, Steps: 65 | Train Loss: 0.1503752 Vali Loss: 0.7386683 Test Loss: 0.4118449
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.070972204208374
Epoch: 70, Steps: 65 | Train Loss: 0.1501230 Vali Loss: 0.7386389 Test Loss: 0.4117447
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.5326969623565674
Epoch: 71, Steps: 65 | Train Loss: 0.1501669 Vali Loss: 0.7375045 Test Loss: 0.4116697
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.8587987422943115
Epoch: 72, Steps: 65 | Train Loss: 0.1501295 Vali Loss: 0.7388255 Test Loss: 0.4115766
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.6430375576019287
Epoch: 73, Steps: 65 | Train Loss: 0.1499951 Vali Loss: 0.7392352 Test Loss: 0.4114939
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.5866456031799316
Epoch: 74, Steps: 65 | Train Loss: 0.1499094 Vali Loss: 0.7361915 Test Loss: 0.4113994
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.3716838359832764
Epoch: 75, Steps: 65 | Train Loss: 0.1499023 Vali Loss: 0.7388517 Test Loss: 0.4113277
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.9616641998291016
Epoch: 76, Steps: 65 | Train Loss: 0.1497737 Vali Loss: 0.7361231 Test Loss: 0.4112422
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.4237592220306396
Epoch: 77, Steps: 65 | Train Loss: 0.1498217 Vali Loss: 0.7331361 Test Loss: 0.4111753
Validation loss decreased (0.734799 --> 0.733136).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.2895100116729736
Epoch: 78, Steps: 65 | Train Loss: 0.1497354 Vali Loss: 0.7348979 Test Loss: 0.4111009
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.449115753173828
Epoch: 79, Steps: 65 | Train Loss: 0.1496882 Vali Loss: 0.7388081 Test Loss: 0.4110336
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.553149700164795
Epoch: 80, Steps: 65 | Train Loss: 0.1496787 Vali Loss: 0.7362971 Test Loss: 0.4109669
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.533982038497925
Epoch: 81, Steps: 65 | Train Loss: 0.1496452 Vali Loss: 0.7341037 Test Loss: 0.4109157
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 2.441507577896118
Epoch: 82, Steps: 65 | Train Loss: 0.1494854 Vali Loss: 0.7360721 Test Loss: 0.4108591
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.2179222106933594
Epoch: 83, Steps: 65 | Train Loss: 0.1494408 Vali Loss: 0.7365991 Test Loss: 0.4108122
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.922328233718872
Epoch: 84, Steps: 65 | Train Loss: 0.1494480 Vali Loss: 0.7371572 Test Loss: 0.4107527
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.7134089469909668
Epoch: 85, Steps: 65 | Train Loss: 0.1493035 Vali Loss: 0.7348613 Test Loss: 0.4107102
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 2.9103240966796875
Epoch: 86, Steps: 65 | Train Loss: 0.1493715 Vali Loss: 0.7377655 Test Loss: 0.4106673
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 2.126607894897461
Epoch: 87, Steps: 65 | Train Loss: 0.1493899 Vali Loss: 0.7384635 Test Loss: 0.4106231
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.8410704135894775
Epoch: 88, Steps: 65 | Train Loss: 0.1492641 Vali Loss: 0.7393261 Test Loss: 0.4105773
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.332988739013672
Epoch: 89, Steps: 65 | Train Loss: 0.1492319 Vali Loss: 0.7338951 Test Loss: 0.4105375
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 2.6499481201171875
Epoch: 90, Steps: 65 | Train Loss: 0.1491085 Vali Loss: 0.7359151 Test Loss: 0.4104990
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.6951708793640137
Epoch: 91, Steps: 65 | Train Loss: 0.1490737 Vali Loss: 0.7354441 Test Loss: 0.4104666
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.7409405708312988
Epoch: 92, Steps: 65 | Train Loss: 0.1491733 Vali Loss: 0.7327964 Test Loss: 0.4104305
Validation loss decreased (0.733136 --> 0.732796).  Saving model ...
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 2.292121648788452
Epoch: 93, Steps: 65 | Train Loss: 0.1492196 Vali Loss: 0.7374925 Test Loss: 0.4103926
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 2.2315425872802734
Epoch: 94, Steps: 65 | Train Loss: 0.1491630 Vali Loss: 0.7340710 Test Loss: 0.4103639
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.8594708442687988
Epoch: 95, Steps: 65 | Train Loss: 0.1491390 Vali Loss: 0.7370259 Test Loss: 0.4103356
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.752342939376831
Epoch: 96, Steps: 65 | Train Loss: 0.1490776 Vali Loss: 0.7385968 Test Loss: 0.4103038
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 2.981102228164673
Epoch: 97, Steps: 65 | Train Loss: 0.1489996 Vali Loss: 0.7384735 Test Loss: 0.4102783
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 2.7435920238494873
Epoch: 98, Steps: 65 | Train Loss: 0.1489480 Vali Loss: 0.7331699 Test Loss: 0.4102513
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 2.292468309402466
Epoch: 99, Steps: 65 | Train Loss: 0.1490403 Vali Loss: 0.7360120 Test Loss: 0.4102284
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 2.564601182937622
Epoch: 100, Steps: 65 | Train Loss: 0.1491624 Vali Loss: 0.7352632 Test Loss: 0.4102055
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8365
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=50, out_features=76, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3404800.0
params:  3876.0
Trainable parameters:  3876
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.920372724533081
Epoch: 1, Steps: 65 | Train Loss: 0.3598169 Vali Loss: 0.7162187 Test Loss: 0.3936828
Validation loss decreased (inf --> 0.716219).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.2847349643707275
Epoch: 2, Steps: 65 | Train Loss: 0.3531173 Vali Loss: 0.7131742 Test Loss: 0.3873423
Validation loss decreased (0.716219 --> 0.713174).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.626157760620117
Epoch: 3, Steps: 65 | Train Loss: 0.3509854 Vali Loss: 0.7092490 Test Loss: 0.3857911
Validation loss decreased (0.713174 --> 0.709249).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.8214788436889648
Epoch: 4, Steps: 65 | Train Loss: 0.3501080 Vali Loss: 0.7055960 Test Loss: 0.3846727
Validation loss decreased (0.709249 --> 0.705596).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.5004186630249023
Epoch: 5, Steps: 65 | Train Loss: 0.3498882 Vali Loss: 0.7063251 Test Loss: 0.3842691
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.437439441680908
Epoch: 6, Steps: 65 | Train Loss: 0.3495235 Vali Loss: 0.7063472 Test Loss: 0.3837394
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.7734928131103516
Epoch: 7, Steps: 65 | Train Loss: 0.3493622 Vali Loss: 0.7047066 Test Loss: 0.3839346
Validation loss decreased (0.705596 --> 0.704707).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.9435760974884033
Epoch: 8, Steps: 65 | Train Loss: 0.3490853 Vali Loss: 0.7015584 Test Loss: 0.3835839
Validation loss decreased (0.704707 --> 0.701558).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.8278510570526123
Epoch: 9, Steps: 65 | Train Loss: 0.3491492 Vali Loss: 0.7011199 Test Loss: 0.3833571
Validation loss decreased (0.701558 --> 0.701120).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.8129987716674805
Epoch: 10, Steps: 65 | Train Loss: 0.3491725 Vali Loss: 0.7073861 Test Loss: 0.3834392
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.3989670276641846
Epoch: 11, Steps: 65 | Train Loss: 0.3482172 Vali Loss: 0.7071604 Test Loss: 0.3831331
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.378122329711914
Epoch: 12, Steps: 65 | Train Loss: 0.3486900 Vali Loss: 0.7084979 Test Loss: 0.3833588
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.46917986869812
Epoch: 13, Steps: 65 | Train Loss: 0.3487483 Vali Loss: 0.7078123 Test Loss: 0.3832604
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 4.344491243362427
Epoch: 14, Steps: 65 | Train Loss: 0.3485170 Vali Loss: 0.7028688 Test Loss: 0.3832628
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.0441741943359375
Epoch: 15, Steps: 65 | Train Loss: 0.3486921 Vali Loss: 0.7027692 Test Loss: 0.3831801
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.9161603450775146
Epoch: 16, Steps: 65 | Train Loss: 0.3485174 Vali Loss: 0.7045506 Test Loss: 0.3830972
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.2385289669036865
Epoch: 17, Steps: 65 | Train Loss: 0.3483886 Vali Loss: 0.7017654 Test Loss: 0.3833249
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.2929153442382812
Epoch: 18, Steps: 65 | Train Loss: 0.3485038 Vali Loss: 0.7028484 Test Loss: 0.3831775
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.9537856578826904
Epoch: 19, Steps: 65 | Train Loss: 0.3484991 Vali Loss: 0.7030807 Test Loss: 0.3832466
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.3990745544433594
Epoch: 20, Steps: 65 | Train Loss: 0.3485343 Vali Loss: 0.7067256 Test Loss: 0.3831116
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.460683584213257
Epoch: 21, Steps: 65 | Train Loss: 0.3486467 Vali Loss: 0.7020319 Test Loss: 0.3831372
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.761742115020752
Epoch: 22, Steps: 65 | Train Loss: 0.3484382 Vali Loss: 0.7032272 Test Loss: 0.3829514
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.9242274761199951
Epoch: 23, Steps: 65 | Train Loss: 0.3484563 Vali Loss: 0.7048503 Test Loss: 0.3831950
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.5678846836090088
Epoch: 24, Steps: 65 | Train Loss: 0.3485023 Vali Loss: 0.7041063 Test Loss: 0.3830111
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.9228596687316895
Epoch: 25, Steps: 65 | Train Loss: 0.3483507 Vali Loss: 0.7030916 Test Loss: 0.3832448
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.6128230094909668
Epoch: 26, Steps: 65 | Train Loss: 0.3483550 Vali Loss: 0.7006051 Test Loss: 0.3831536
Validation loss decreased (0.701120 --> 0.700605).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.526961088180542
Epoch: 27, Steps: 65 | Train Loss: 0.3481909 Vali Loss: 0.7050549 Test Loss: 0.3831204
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.788137674331665
Epoch: 28, Steps: 65 | Train Loss: 0.3483728 Vali Loss: 0.7025556 Test Loss: 0.3829004
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.2997727394104004
Epoch: 29, Steps: 65 | Train Loss: 0.3483107 Vali Loss: 0.7050438 Test Loss: 0.3831471
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 3.2374186515808105
Epoch: 30, Steps: 65 | Train Loss: 0.3482994 Vali Loss: 0.7055234 Test Loss: 0.3829873
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 3.6731908321380615
Epoch: 31, Steps: 65 | Train Loss: 0.3484594 Vali Loss: 0.7059476 Test Loss: 0.3830404
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.3124091625213623
Epoch: 32, Steps: 65 | Train Loss: 0.3480829 Vali Loss: 0.7032381 Test Loss: 0.3830501
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.7277414798736572
Epoch: 33, Steps: 65 | Train Loss: 0.3481556 Vali Loss: 0.7049419 Test Loss: 0.3830426
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.334610939025879
Epoch: 34, Steps: 65 | Train Loss: 0.3481186 Vali Loss: 0.7045875 Test Loss: 0.3831128
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 3.834252119064331
Epoch: 35, Steps: 65 | Train Loss: 0.3483660 Vali Loss: 0.7060447 Test Loss: 0.3830573
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.385683536529541
Epoch: 36, Steps: 65 | Train Loss: 0.3476608 Vali Loss: 0.7080362 Test Loss: 0.3829680
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.8119134902954102
Epoch: 37, Steps: 65 | Train Loss: 0.3480865 Vali Loss: 0.7045358 Test Loss: 0.3829935
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.3701887130737305
Epoch: 38, Steps: 65 | Train Loss: 0.3482337 Vali Loss: 0.7045275 Test Loss: 0.3830111
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.243853807449341
Epoch: 39, Steps: 65 | Train Loss: 0.3483137 Vali Loss: 0.7062520 Test Loss: 0.3830349
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.141430139541626
Epoch: 40, Steps: 65 | Train Loss: 0.3481052 Vali Loss: 0.7029820 Test Loss: 0.3830297
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.1203277111053467
Epoch: 41, Steps: 65 | Train Loss: 0.3481973 Vali Loss: 0.7049445 Test Loss: 0.3830424
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.2306623458862305
Epoch: 42, Steps: 65 | Train Loss: 0.3484073 Vali Loss: 0.7026329 Test Loss: 0.3830703
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.9383604526519775
Epoch: 43, Steps: 65 | Train Loss: 0.3482892 Vali Loss: 0.7049785 Test Loss: 0.3830214
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.0129318237304688
Epoch: 44, Steps: 65 | Train Loss: 0.3481634 Vali Loss: 0.7024812 Test Loss: 0.3830584
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.9530107975006104
Epoch: 45, Steps: 65 | Train Loss: 0.3483846 Vali Loss: 0.7032000 Test Loss: 0.3830759
EarlyStopping counter: 19 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.641818046569824
Epoch: 46, Steps: 65 | Train Loss: 0.3481737 Vali Loss: 0.7045792 Test Loss: 0.3830309
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_180_96_FITS_ETTh1_ftM_sl180_ll48_pl96_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.3824455738067627, mae:0.3964054584503174, rse:0.5874117612838745, corr:[0.2715274  0.27716872 0.27739474 0.276489   0.27450812 0.27184743
 0.2706866  0.271163   0.27087831 0.2703909  0.27048904 0.2706416
 0.27048862 0.270073   0.2698975  0.2698237  0.26980925 0.26984996
 0.26975495 0.26934308 0.26889464 0.26902038 0.2693704  0.26911333
 0.26821366 0.26779002 0.26725596 0.26669812 0.26628208 0.26602793
 0.2655796  0.26519877 0.26514998 0.2650555  0.26497602 0.2653676
 0.26557642 0.26522574 0.2652205  0.2654601  0.26562306 0.26578635
 0.2660522  0.2661021  0.26591903 0.26606366 0.26676574 0.26687777
 0.2656931  0.2642811  0.26266384 0.2613631  0.2603102  0.2592432
 0.25839487 0.25793782 0.25805253 0.25846335 0.25825042 0.2586902
 0.2592721  0.25896242 0.25882244 0.2588578  0.25870287 0.25855914
 0.2588862  0.25902843 0.2587317  0.25856018 0.2587433  0.25819376
 0.2568307  0.255724   0.25455964 0.25386557 0.25363934 0.25330058
 0.25301126 0.25260827 0.2522972  0.25250977 0.25224602 0.25207952
 0.25245577 0.2522172  0.25200754 0.25201246 0.25199243 0.25179124
 0.25144443 0.25109413 0.25073484 0.2502917  0.25077718 0.25257128]
