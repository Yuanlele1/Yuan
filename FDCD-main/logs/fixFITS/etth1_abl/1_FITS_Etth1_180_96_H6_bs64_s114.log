Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=58, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_180_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_180_96_FITS_ETTh1_ftM_sl180_ll48_pl96_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8365
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=58, out_features=88, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4573184.0
params:  5192.0
Trainable parameters:  5192
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.15897536277771
Epoch: 1, Steps: 65 | Train Loss: 0.5893614 Vali Loss: 1.0332270 Test Loss: 0.5416002
Validation loss decreased (inf --> 1.033227).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.0840582847595215
Epoch: 2, Steps: 65 | Train Loss: 0.4319647 Vali Loss: 0.8654291 Test Loss: 0.4349762
Validation loss decreased (1.033227 --> 0.865429).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.4050028324127197
Epoch: 3, Steps: 65 | Train Loss: 0.3893167 Vali Loss: 0.8077908 Test Loss: 0.4043834
Validation loss decreased (0.865429 --> 0.807791).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.0703105926513672
Epoch: 4, Steps: 65 | Train Loss: 0.3735279 Vali Loss: 0.7797846 Test Loss: 0.3922090
Validation loss decreased (0.807791 --> 0.779785).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 0.9555881023406982
Epoch: 5, Steps: 65 | Train Loss: 0.3652565 Vali Loss: 0.7666631 Test Loss: 0.3861789
Validation loss decreased (0.779785 --> 0.766663).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.0101745128631592
Epoch: 6, Steps: 65 | Train Loss: 0.3604087 Vali Loss: 0.7501798 Test Loss: 0.3831587
Validation loss decreased (0.766663 --> 0.750180).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.0361895561218262
Epoch: 7, Steps: 65 | Train Loss: 0.3574085 Vali Loss: 0.7442211 Test Loss: 0.3814341
Validation loss decreased (0.750180 --> 0.744221).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.1358513832092285
Epoch: 8, Steps: 65 | Train Loss: 0.3550957 Vali Loss: 0.7339961 Test Loss: 0.3809758
Validation loss decreased (0.744221 --> 0.733996).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.433485507965088
Epoch: 9, Steps: 65 | Train Loss: 0.3531899 Vali Loss: 0.7329763 Test Loss: 0.3807005
Validation loss decreased (0.733996 --> 0.732976).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.0322387218475342
Epoch: 10, Steps: 65 | Train Loss: 0.3526003 Vali Loss: 0.7300751 Test Loss: 0.3806880
Validation loss decreased (0.732976 --> 0.730075).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.077643632888794
Epoch: 11, Steps: 65 | Train Loss: 0.3516786 Vali Loss: 0.7298055 Test Loss: 0.3805098
Validation loss decreased (0.730075 --> 0.729805).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.1192433834075928
Epoch: 12, Steps: 65 | Train Loss: 0.3508814 Vali Loss: 0.7276103 Test Loss: 0.3806625
Validation loss decreased (0.729805 --> 0.727610).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.0713284015655518
Epoch: 13, Steps: 65 | Train Loss: 0.3504517 Vali Loss: 0.7258711 Test Loss: 0.3806738
Validation loss decreased (0.727610 --> 0.725871).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.072737455368042
Epoch: 14, Steps: 65 | Train Loss: 0.3500633 Vali Loss: 0.7198814 Test Loss: 0.3807035
Validation loss decreased (0.725871 --> 0.719881).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.0339958667755127
Epoch: 15, Steps: 65 | Train Loss: 0.3493339 Vali Loss: 0.7167395 Test Loss: 0.3807797
Validation loss decreased (0.719881 --> 0.716739).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.1818926334381104
Epoch: 16, Steps: 65 | Train Loss: 0.3491710 Vali Loss: 0.7216066 Test Loss: 0.3809590
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.0252749919891357
Epoch: 17, Steps: 65 | Train Loss: 0.3490180 Vali Loss: 0.7214058 Test Loss: 0.3809712
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 0.9394717216491699
Epoch: 18, Steps: 65 | Train Loss: 0.3487481 Vali Loss: 0.7138091 Test Loss: 0.3809267
Validation loss decreased (0.716739 --> 0.713809).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.0730972290039062
Epoch: 19, Steps: 65 | Train Loss: 0.3486574 Vali Loss: 0.7172591 Test Loss: 0.3810365
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.025108814239502
Epoch: 20, Steps: 65 | Train Loss: 0.3485750 Vali Loss: 0.7171432 Test Loss: 0.3811309
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.0108733177185059
Epoch: 21, Steps: 65 | Train Loss: 0.3482224 Vali Loss: 0.7163627 Test Loss: 0.3811061
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 0.9372086524963379
Epoch: 22, Steps: 65 | Train Loss: 0.3479107 Vali Loss: 0.7179664 Test Loss: 0.3811156
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 0.9868590831756592
Epoch: 23, Steps: 65 | Train Loss: 0.3477891 Vali Loss: 0.7123449 Test Loss: 0.3811709
Validation loss decreased (0.713809 --> 0.712345).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.022136926651001
Epoch: 24, Steps: 65 | Train Loss: 0.3479149 Vali Loss: 0.7124841 Test Loss: 0.3811330
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.052109718322754
Epoch: 25, Steps: 65 | Train Loss: 0.3477622 Vali Loss: 0.7100350 Test Loss: 0.3812223
Validation loss decreased (0.712345 --> 0.710035).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.1125695705413818
Epoch: 26, Steps: 65 | Train Loss: 0.3477430 Vali Loss: 0.7097544 Test Loss: 0.3812555
Validation loss decreased (0.710035 --> 0.709754).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.0215964317321777
Epoch: 27, Steps: 65 | Train Loss: 0.3479021 Vali Loss: 0.7132600 Test Loss: 0.3811876
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.0754425525665283
Epoch: 28, Steps: 65 | Train Loss: 0.3472046 Vali Loss: 0.7118012 Test Loss: 0.3813429
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.0004279613494873
Epoch: 29, Steps: 65 | Train Loss: 0.3474459 Vali Loss: 0.7107800 Test Loss: 0.3812898
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 0.8862271308898926
Epoch: 30, Steps: 65 | Train Loss: 0.3473059 Vali Loss: 0.7129348 Test Loss: 0.3813601
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.1370315551757812
Epoch: 31, Steps: 65 | Train Loss: 0.3473231 Vali Loss: 0.7095317 Test Loss: 0.3812794
Validation loss decreased (0.709754 --> 0.709532).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.2172720432281494
Epoch: 32, Steps: 65 | Train Loss: 0.3469821 Vali Loss: 0.7095330 Test Loss: 0.3813418
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.242326259613037
Epoch: 33, Steps: 65 | Train Loss: 0.3469278 Vali Loss: 0.7097373 Test Loss: 0.3813217
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.0487728118896484
Epoch: 34, Steps: 65 | Train Loss: 0.3469300 Vali Loss: 0.7125184 Test Loss: 0.3812916
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.1050331592559814
Epoch: 35, Steps: 65 | Train Loss: 0.3472304 Vali Loss: 0.7115203 Test Loss: 0.3813913
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.1691045761108398
Epoch: 36, Steps: 65 | Train Loss: 0.3470997 Vali Loss: 0.7074483 Test Loss: 0.3814028
Validation loss decreased (0.709532 --> 0.707448).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.0853602886199951
Epoch: 37, Steps: 65 | Train Loss: 0.3467330 Vali Loss: 0.7126128 Test Loss: 0.3814236
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.0528080463409424
Epoch: 38, Steps: 65 | Train Loss: 0.3470406 Vali Loss: 0.7102600 Test Loss: 0.3814425
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.0338714122772217
Epoch: 39, Steps: 65 | Train Loss: 0.3468879 Vali Loss: 0.7103433 Test Loss: 0.3813809
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.1138062477111816
Epoch: 40, Steps: 65 | Train Loss: 0.3467704 Vali Loss: 0.7095752 Test Loss: 0.3814425
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.0205833911895752
Epoch: 41, Steps: 65 | Train Loss: 0.3466275 Vali Loss: 0.7080061 Test Loss: 0.3814195
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.0592758655548096
Epoch: 42, Steps: 65 | Train Loss: 0.3467581 Vali Loss: 0.7060634 Test Loss: 0.3814428
Validation loss decreased (0.707448 --> 0.706063).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 0.9682085514068604
Epoch: 43, Steps: 65 | Train Loss: 0.3468708 Vali Loss: 0.7064002 Test Loss: 0.3814345
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.0440540313720703
Epoch: 44, Steps: 65 | Train Loss: 0.3465574 Vali Loss: 0.7065118 Test Loss: 0.3814196
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.016059160232544
Epoch: 45, Steps: 65 | Train Loss: 0.3468141 Vali Loss: 0.7073148 Test Loss: 0.3814536
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.0107243061065674
Epoch: 46, Steps: 65 | Train Loss: 0.3469276 Vali Loss: 0.7103629 Test Loss: 0.3814107
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.040482997894287
Epoch: 47, Steps: 65 | Train Loss: 0.3468601 Vali Loss: 0.7078069 Test Loss: 0.3814346
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 0.9700183868408203
Epoch: 48, Steps: 65 | Train Loss: 0.3468081 Vali Loss: 0.7096263 Test Loss: 0.3814622
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.1510002613067627
Epoch: 49, Steps: 65 | Train Loss: 0.3464240 Vali Loss: 0.7096699 Test Loss: 0.3814239
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.066941738128662
Epoch: 50, Steps: 65 | Train Loss: 0.3465316 Vali Loss: 0.7088082 Test Loss: 0.3814563
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.0873465538024902
Epoch: 51, Steps: 65 | Train Loss: 0.3464073 Vali Loss: 0.7047361 Test Loss: 0.3814362
Validation loss decreased (0.706063 --> 0.704736).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.0890836715698242
Epoch: 52, Steps: 65 | Train Loss: 0.3466421 Vali Loss: 0.7062454 Test Loss: 0.3814613
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.0874748229980469
Epoch: 53, Steps: 65 | Train Loss: 0.3467473 Vali Loss: 0.7116712 Test Loss: 0.3814976
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.0480329990386963
Epoch: 54, Steps: 65 | Train Loss: 0.3467271 Vali Loss: 0.7080212 Test Loss: 0.3814752
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.100403070449829
Epoch: 55, Steps: 65 | Train Loss: 0.3466932 Vali Loss: 0.7078042 Test Loss: 0.3814235
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 0.9566929340362549
Epoch: 56, Steps: 65 | Train Loss: 0.3467345 Vali Loss: 0.7079552 Test Loss: 0.3814230
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.0074734687805176
Epoch: 57, Steps: 65 | Train Loss: 0.3463584 Vali Loss: 0.7090954 Test Loss: 0.3814356
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.0458128452301025
Epoch: 58, Steps: 65 | Train Loss: 0.3463703 Vali Loss: 0.7116920 Test Loss: 0.3814643
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.0680961608886719
Epoch: 59, Steps: 65 | Train Loss: 0.3466747 Vali Loss: 0.7080237 Test Loss: 0.3814768
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 0.9963068962097168
Epoch: 60, Steps: 65 | Train Loss: 0.3464001 Vali Loss: 0.7072942 Test Loss: 0.3814802
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.0384752750396729
Epoch: 61, Steps: 65 | Train Loss: 0.3465650 Vali Loss: 0.7039101 Test Loss: 0.3814693
Validation loss decreased (0.704736 --> 0.703910).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.0486574172973633
Epoch: 62, Steps: 65 | Train Loss: 0.3465281 Vali Loss: 0.7119226 Test Loss: 0.3814800
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.0420567989349365
Epoch: 63, Steps: 65 | Train Loss: 0.3464232 Vali Loss: 0.7014719 Test Loss: 0.3814613
Validation loss decreased (0.703910 --> 0.701472).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.018425703048706
Epoch: 64, Steps: 65 | Train Loss: 0.3463400 Vali Loss: 0.7047693 Test Loss: 0.3814794
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.0210049152374268
Epoch: 65, Steps: 65 | Train Loss: 0.3464151 Vali Loss: 0.7111456 Test Loss: 0.3814594
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 0.9447932243347168
Epoch: 66, Steps: 65 | Train Loss: 0.3464801 Vali Loss: 0.7064297 Test Loss: 0.3814658
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 0.9310460090637207
Epoch: 67, Steps: 65 | Train Loss: 0.3458992 Vali Loss: 0.7113927 Test Loss: 0.3814596
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 0.9870989322662354
Epoch: 68, Steps: 65 | Train Loss: 0.3464278 Vali Loss: 0.7081332 Test Loss: 0.3814645
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.0174484252929688
Epoch: 69, Steps: 65 | Train Loss: 0.3463143 Vali Loss: 0.7081603 Test Loss: 0.3814480
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.0601463317871094
Epoch: 70, Steps: 65 | Train Loss: 0.3462462 Vali Loss: 0.7044745 Test Loss: 0.3814574
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 0.9882619380950928
Epoch: 71, Steps: 65 | Train Loss: 0.3464065 Vali Loss: 0.7015100 Test Loss: 0.3814494
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.0107629299163818
Epoch: 72, Steps: 65 | Train Loss: 0.3463610 Vali Loss: 0.7082462 Test Loss: 0.3814500
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 0.999072790145874
Epoch: 73, Steps: 65 | Train Loss: 0.3464846 Vali Loss: 0.7058961 Test Loss: 0.3814605
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 0.9719951152801514
Epoch: 74, Steps: 65 | Train Loss: 0.3466015 Vali Loss: 0.7052995 Test Loss: 0.3814477
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.0839791297912598
Epoch: 75, Steps: 65 | Train Loss: 0.3463510 Vali Loss: 0.7093551 Test Loss: 0.3814513
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.0799226760864258
Epoch: 76, Steps: 65 | Train Loss: 0.3462942 Vali Loss: 0.7031698 Test Loss: 0.3814562
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.202479600906372
Epoch: 77, Steps: 65 | Train Loss: 0.3461093 Vali Loss: 0.7071883 Test Loss: 0.3814544
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.0102884769439697
Epoch: 78, Steps: 65 | Train Loss: 0.3462482 Vali Loss: 0.7070171 Test Loss: 0.3814446
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.0895094871520996
Epoch: 79, Steps: 65 | Train Loss: 0.3462688 Vali Loss: 0.7081821 Test Loss: 0.3814443
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.0326430797576904
Epoch: 80, Steps: 65 | Train Loss: 0.3459467 Vali Loss: 0.7089330 Test Loss: 0.3814463
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 0.9280903339385986
Epoch: 81, Steps: 65 | Train Loss: 0.3464109 Vali Loss: 0.7035234 Test Loss: 0.3814680
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.1019349098205566
Epoch: 82, Steps: 65 | Train Loss: 0.3464917 Vali Loss: 0.7062413 Test Loss: 0.3814528
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 0.9970731735229492
Epoch: 83, Steps: 65 | Train Loss: 0.3462002 Vali Loss: 0.7076989 Test Loss: 0.3814611
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_180_96_FITS_ETTh1_ftM_sl180_ll48_pl96_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.3808095157146454, mae:0.3952527940273285, rse:0.5861539840698242, corr:[0.27099714 0.27702615 0.2764558  0.2769588  0.27444357 0.2718629
 0.27155736 0.2713764  0.27094084 0.2715977  0.27097198 0.27037096
 0.27088696 0.27021608 0.269716   0.2702086  0.27025303 0.27000552
 0.270117   0.26998785 0.26964527 0.26966828 0.26997775 0.2698229
 0.26894698 0.26815987 0.26756254 0.26722288 0.26657745 0.2659833
 0.2658974  0.26566026 0.26504296 0.26505372 0.26529604 0.26520854
 0.26538256 0.26559645 0.26544657 0.2654651  0.2659751  0.2661839
 0.26622203 0.2665283  0.26659212 0.26653564 0.2670294  0.26725814
 0.26618713 0.26445708 0.2627876  0.26184824 0.2606532  0.25917667
 0.25862414 0.25852093 0.25823545 0.25858286 0.25874552 0.2590731
 0.25941965 0.25937262 0.25922257 0.2590624  0.25911266 0.25919312
 0.25935242 0.25936344 0.2591015  0.2590075  0.25907657 0.258488
 0.2573342  0.2561574  0.25484043 0.25439698 0.25425017 0.25372142
 0.2533502  0.2530949  0.25280645 0.25274748 0.25250682 0.25262696
 0.2527173  0.2524814  0.25283405 0.25257862 0.25185972 0.25201285
 0.25182703 0.25084025 0.25069943 0.25020108 0.24990404 0.2521286 ]
