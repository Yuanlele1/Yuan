Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=42, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_180_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_180_336_FITS_ETTh1_ftM_sl180_ll48_pl336_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8125
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=42, out_features=120, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4515840.0
params:  5160.0
Trainable parameters:  5160
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.297870397567749
Epoch: 1, Steps: 63 | Train Loss: 0.8322137 Vali Loss: 1.9520149 Test Loss: 0.9452106
Validation loss decreased (inf --> 1.952015).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.1992266178131104
Epoch: 2, Steps: 63 | Train Loss: 0.6376729 Vali Loss: 1.7056196 Test Loss: 0.7757747
Validation loss decreased (1.952015 --> 1.705620).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.74393892288208
Epoch: 3, Steps: 63 | Train Loss: 0.5344657 Vali Loss: 1.5760943 Test Loss: 0.6834480
Validation loss decreased (1.705620 --> 1.576094).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.6276206970214844
Epoch: 4, Steps: 63 | Train Loss: 0.4734791 Vali Loss: 1.4863949 Test Loss: 0.6261514
Validation loss decreased (1.576094 --> 1.486395).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.7618377208709717
Epoch: 5, Steps: 63 | Train Loss: 0.4345831 Vali Loss: 1.4381527 Test Loss: 0.5887470
Validation loss decreased (1.486395 --> 1.438153).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.6159791946411133
Epoch: 6, Steps: 63 | Train Loss: 0.4093297 Vali Loss: 1.3967285 Test Loss: 0.5637764
Validation loss decreased (1.438153 --> 1.396729).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.6777596473693848
Epoch: 7, Steps: 63 | Train Loss: 0.3917603 Vali Loss: 1.3655427 Test Loss: 0.5465395
Validation loss decreased (1.396729 --> 1.365543).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.376495838165283
Epoch: 8, Steps: 63 | Train Loss: 0.3792563 Vali Loss: 1.3493305 Test Loss: 0.5340582
Validation loss decreased (1.365543 --> 1.349331).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.164149045944214
Epoch: 9, Steps: 63 | Train Loss: 0.3702242 Vali Loss: 1.3351603 Test Loss: 0.5248098
Validation loss decreased (1.349331 --> 1.335160).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.9334449768066406
Epoch: 10, Steps: 63 | Train Loss: 0.3631288 Vali Loss: 1.3213753 Test Loss: 0.5177328
Validation loss decreased (1.335160 --> 1.321375).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.8657615184783936
Epoch: 11, Steps: 63 | Train Loss: 0.3580725 Vali Loss: 1.3077731 Test Loss: 0.5120329
Validation loss decreased (1.321375 --> 1.307773).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.4771201610565186
Epoch: 12, Steps: 63 | Train Loss: 0.3537897 Vali Loss: 1.3082438 Test Loss: 0.5076234
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.3854522705078125
Epoch: 13, Steps: 63 | Train Loss: 0.3503107 Vali Loss: 1.2969040 Test Loss: 0.5037061
Validation loss decreased (1.307773 --> 1.296904).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.1228089332580566
Epoch: 14, Steps: 63 | Train Loss: 0.3472490 Vali Loss: 1.2964801 Test Loss: 0.5006132
Validation loss decreased (1.296904 --> 1.296480).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.9682893753051758
Epoch: 15, Steps: 63 | Train Loss: 0.3452297 Vali Loss: 1.2914472 Test Loss: 0.4978263
Validation loss decreased (1.296480 --> 1.291447).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.8951292037963867
Epoch: 16, Steps: 63 | Train Loss: 0.3429794 Vali Loss: 1.2846136 Test Loss: 0.4953643
Validation loss decreased (1.291447 --> 1.284614).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.421190023422241
Epoch: 17, Steps: 63 | Train Loss: 0.3411223 Vali Loss: 1.2845553 Test Loss: 0.4932834
Validation loss decreased (1.284614 --> 1.284555).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.4863080978393555
Epoch: 18, Steps: 63 | Train Loss: 0.3394390 Vali Loss: 1.2811661 Test Loss: 0.4914454
Validation loss decreased (1.284555 --> 1.281166).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 3.367022752761841
Epoch: 19, Steps: 63 | Train Loss: 0.3380444 Vali Loss: 1.2796835 Test Loss: 0.4895931
Validation loss decreased (1.281166 --> 1.279683).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.844788074493408
Epoch: 20, Steps: 63 | Train Loss: 0.3368662 Vali Loss: 1.2764241 Test Loss: 0.4879031
Validation loss decreased (1.279683 --> 1.276424).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.121865749359131
Epoch: 21, Steps: 63 | Train Loss: 0.3357303 Vali Loss: 1.2774225 Test Loss: 0.4865263
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.3133771419525146
Epoch: 22, Steps: 63 | Train Loss: 0.3348351 Vali Loss: 1.2722791 Test Loss: 0.4852723
Validation loss decreased (1.276424 --> 1.272279).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.9442968368530273
Epoch: 23, Steps: 63 | Train Loss: 0.3338787 Vali Loss: 1.2708203 Test Loss: 0.4840450
Validation loss decreased (1.272279 --> 1.270820).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.0500521659851074
Epoch: 24, Steps: 63 | Train Loss: 0.3330330 Vali Loss: 1.2712842 Test Loss: 0.4829414
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.8749380111694336
Epoch: 25, Steps: 63 | Train Loss: 0.3321364 Vali Loss: 1.2682060 Test Loss: 0.4819161
Validation loss decreased (1.270820 --> 1.268206).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.026376485824585
Epoch: 26, Steps: 63 | Train Loss: 0.3315948 Vali Loss: 1.2648293 Test Loss: 0.4809505
Validation loss decreased (1.268206 --> 1.264829).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.584115982055664
Epoch: 27, Steps: 63 | Train Loss: 0.3306608 Vali Loss: 1.2629315 Test Loss: 0.4800745
Validation loss decreased (1.264829 --> 1.262931).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.9276564121246338
Epoch: 28, Steps: 63 | Train Loss: 0.3301875 Vali Loss: 1.2572037 Test Loss: 0.4792802
Validation loss decreased (1.262931 --> 1.257204).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.0359904766082764
Epoch: 29, Steps: 63 | Train Loss: 0.3297829 Vali Loss: 1.2639323 Test Loss: 0.4785153
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.997652292251587
Epoch: 30, Steps: 63 | Train Loss: 0.3292927 Vali Loss: 1.2678609 Test Loss: 0.4778419
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.7690017223358154
Epoch: 31, Steps: 63 | Train Loss: 0.3288252 Vali Loss: 1.2645609 Test Loss: 0.4771759
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.0307424068450928
Epoch: 32, Steps: 63 | Train Loss: 0.3285091 Vali Loss: 1.2585391 Test Loss: 0.4765616
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.313598394393921
Epoch: 33, Steps: 63 | Train Loss: 0.3278373 Vali Loss: 1.2587568 Test Loss: 0.4760114
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.451237440109253
Epoch: 34, Steps: 63 | Train Loss: 0.3276500 Vali Loss: 1.2560520 Test Loss: 0.4754550
Validation loss decreased (1.257204 --> 1.256052).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.8444578647613525
Epoch: 35, Steps: 63 | Train Loss: 0.3272830 Vali Loss: 1.2605324 Test Loss: 0.4749759
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.0469183921813965
Epoch: 36, Steps: 63 | Train Loss: 0.3267491 Vali Loss: 1.2552917 Test Loss: 0.4744999
Validation loss decreased (1.256052 --> 1.255292).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.7629141807556152
Epoch: 37, Steps: 63 | Train Loss: 0.3265813 Vali Loss: 1.2565666 Test Loss: 0.4740561
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.1002018451690674
Epoch: 38, Steps: 63 | Train Loss: 0.3264456 Vali Loss: 1.2592500 Test Loss: 0.4736713
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.8121538162231445
Epoch: 39, Steps: 63 | Train Loss: 0.3259060 Vali Loss: 1.2522453 Test Loss: 0.4732987
Validation loss decreased (1.255292 --> 1.252245).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.7775776386260986
Epoch: 40, Steps: 63 | Train Loss: 0.3258836 Vali Loss: 1.2539943 Test Loss: 0.4729232
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 4.077680349349976
Epoch: 41, Steps: 63 | Train Loss: 0.3254513 Vali Loss: 1.2525294 Test Loss: 0.4725955
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.718005418777466
Epoch: 42, Steps: 63 | Train Loss: 0.3251032 Vali Loss: 1.2533367 Test Loss: 0.4722683
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.8405654430389404
Epoch: 43, Steps: 63 | Train Loss: 0.3249141 Vali Loss: 1.2519277 Test Loss: 0.4719687
Validation loss decreased (1.252245 --> 1.251928).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.736355781555176
Epoch: 44, Steps: 63 | Train Loss: 0.3250629 Vali Loss: 1.2524905 Test Loss: 0.4717064
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.973034620285034
Epoch: 45, Steps: 63 | Train Loss: 0.3245803 Vali Loss: 1.2541177 Test Loss: 0.4714331
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.368680715560913
Epoch: 46, Steps: 63 | Train Loss: 0.3244470 Vali Loss: 1.2559167 Test Loss: 0.4711663
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 3.18389630317688
Epoch: 47, Steps: 63 | Train Loss: 0.3241614 Vali Loss: 1.2524773 Test Loss: 0.4709427
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 4.08382248878479
Epoch: 48, Steps: 63 | Train Loss: 0.3241190 Vali Loss: 1.2491888 Test Loss: 0.4707257
Validation loss decreased (1.251928 --> 1.249189).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.8244094848632812
Epoch: 49, Steps: 63 | Train Loss: 0.3241461 Vali Loss: 1.2521849 Test Loss: 0.4705112
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.1664106845855713
Epoch: 50, Steps: 63 | Train Loss: 0.3236947 Vali Loss: 1.2477025 Test Loss: 0.4703286
Validation loss decreased (1.249189 --> 1.247702).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.5957770347595215
Epoch: 51, Steps: 63 | Train Loss: 0.3235390 Vali Loss: 1.2544115 Test Loss: 0.4701273
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.5720889568328857
Epoch: 52, Steps: 63 | Train Loss: 0.3236779 Vali Loss: 1.2542781 Test Loss: 0.4699573
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 3.391606092453003
Epoch: 53, Steps: 63 | Train Loss: 0.3233710 Vali Loss: 1.2507713 Test Loss: 0.4698040
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.7373709678649902
Epoch: 54, Steps: 63 | Train Loss: 0.3232291 Vali Loss: 1.2531029 Test Loss: 0.4696281
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.789036273956299
Epoch: 55, Steps: 63 | Train Loss: 0.3228771 Vali Loss: 1.2506484 Test Loss: 0.4694828
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 3.793923854827881
Epoch: 56, Steps: 63 | Train Loss: 0.3231420 Vali Loss: 1.2531151 Test Loss: 0.4693493
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.714059591293335
Epoch: 57, Steps: 63 | Train Loss: 0.3227704 Vali Loss: 1.2509896 Test Loss: 0.4692155
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.911435127258301
Epoch: 58, Steps: 63 | Train Loss: 0.3232787 Vali Loss: 1.2444862 Test Loss: 0.4690844
Validation loss decreased (1.247702 --> 1.244486).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.438566207885742
Epoch: 59, Steps: 63 | Train Loss: 0.3231072 Vali Loss: 1.2515084 Test Loss: 0.4689717
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 3.309220314025879
Epoch: 60, Steps: 63 | Train Loss: 0.3225192 Vali Loss: 1.2488859 Test Loss: 0.4688703
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.071340799331665
Epoch: 61, Steps: 63 | Train Loss: 0.3227920 Vali Loss: 1.2490500 Test Loss: 0.4687605
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.7982819080352783
Epoch: 62, Steps: 63 | Train Loss: 0.3225142 Vali Loss: 1.2503940 Test Loss: 0.4686646
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.780271291732788
Epoch: 63, Steps: 63 | Train Loss: 0.3226614 Vali Loss: 1.2498580 Test Loss: 0.4685583
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.6487834453582764
Epoch: 64, Steps: 63 | Train Loss: 0.3225301 Vali Loss: 1.2473612 Test Loss: 0.4684686
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.7713234424591064
Epoch: 65, Steps: 63 | Train Loss: 0.3224510 Vali Loss: 1.2440344 Test Loss: 0.4683904
Validation loss decreased (1.244486 --> 1.244034).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.9063172340393066
Epoch: 66, Steps: 63 | Train Loss: 0.3223314 Vali Loss: 1.2504876 Test Loss: 0.4683039
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.9151723384857178
Epoch: 67, Steps: 63 | Train Loss: 0.3221958 Vali Loss: 1.2482198 Test Loss: 0.4682244
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.7828373908996582
Epoch: 68, Steps: 63 | Train Loss: 0.3221963 Vali Loss: 1.2474400 Test Loss: 0.4681560
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.0499958992004395
Epoch: 69, Steps: 63 | Train Loss: 0.3220165 Vali Loss: 1.2459183 Test Loss: 0.4680811
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.7878453731536865
Epoch: 70, Steps: 63 | Train Loss: 0.3220133 Vali Loss: 1.2477572 Test Loss: 0.4680210
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.9179561138153076
Epoch: 71, Steps: 63 | Train Loss: 0.3220853 Vali Loss: 1.2461258 Test Loss: 0.4679633
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.7993285655975342
Epoch: 72, Steps: 63 | Train Loss: 0.3217429 Vali Loss: 1.2487534 Test Loss: 0.4679086
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.0067732334136963
Epoch: 73, Steps: 63 | Train Loss: 0.3220932 Vali Loss: 1.2456793 Test Loss: 0.4678427
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.9199655055999756
Epoch: 74, Steps: 63 | Train Loss: 0.3220446 Vali Loss: 1.2476670 Test Loss: 0.4677992
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.701232671737671
Epoch: 75, Steps: 63 | Train Loss: 0.3219004 Vali Loss: 1.2476139 Test Loss: 0.4677479
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 3.3257031440734863
Epoch: 76, Steps: 63 | Train Loss: 0.3217794 Vali Loss: 1.2492836 Test Loss: 0.4677053
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.341575860977173
Epoch: 77, Steps: 63 | Train Loss: 0.3215731 Vali Loss: 1.2388153 Test Loss: 0.4676612
Validation loss decreased (1.244034 --> 1.238815).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.3817803859710693
Epoch: 78, Steps: 63 | Train Loss: 0.3219325 Vali Loss: 1.2486309 Test Loss: 0.4676186
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 3.191962957382202
Epoch: 79, Steps: 63 | Train Loss: 0.3217898 Vali Loss: 1.2504905 Test Loss: 0.4675761
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.9113433361053467
Epoch: 80, Steps: 63 | Train Loss: 0.3216529 Vali Loss: 1.2493807 Test Loss: 0.4675374
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.582089424133301
Epoch: 81, Steps: 63 | Train Loss: 0.3218793 Vali Loss: 1.2450858 Test Loss: 0.4674984
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.919050693511963
Epoch: 82, Steps: 63 | Train Loss: 0.3217732 Vali Loss: 1.2498636 Test Loss: 0.4674698
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.396214723587036
Epoch: 83, Steps: 63 | Train Loss: 0.3214970 Vali Loss: 1.2473663 Test Loss: 0.4674351
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.8638310432434082
Epoch: 84, Steps: 63 | Train Loss: 0.3216240 Vali Loss: 1.2440902 Test Loss: 0.4674055
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.5567104816436768
Epoch: 85, Steps: 63 | Train Loss: 0.3215732 Vali Loss: 1.2470052 Test Loss: 0.4673752
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 2.7995800971984863
Epoch: 86, Steps: 63 | Train Loss: 0.3216614 Vali Loss: 1.2486552 Test Loss: 0.4673462
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 2.09834885597229
Epoch: 87, Steps: 63 | Train Loss: 0.3215596 Vali Loss: 1.2448969 Test Loss: 0.4673195
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 2.2429356575012207
Epoch: 88, Steps: 63 | Train Loss: 0.3215350 Vali Loss: 1.2475694 Test Loss: 0.4672973
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.0484113693237305
Epoch: 89, Steps: 63 | Train Loss: 0.3214915 Vali Loss: 1.2486619 Test Loss: 0.4672724
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 2.1092047691345215
Epoch: 90, Steps: 63 | Train Loss: 0.3209974 Vali Loss: 1.2416774 Test Loss: 0.4672497
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.1878156661987305
Epoch: 91, Steps: 63 | Train Loss: 0.3214779 Vali Loss: 1.2436833 Test Loss: 0.4672300
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 2.5661978721618652
Epoch: 92, Steps: 63 | Train Loss: 0.3214369 Vali Loss: 1.2499480 Test Loss: 0.4672095
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 2.7359704971313477
Epoch: 93, Steps: 63 | Train Loss: 0.3212525 Vali Loss: 1.2481010 Test Loss: 0.4671909
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 2.7748982906341553
Epoch: 94, Steps: 63 | Train Loss: 0.3213828 Vali Loss: 1.2483996 Test Loss: 0.4671730
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.8145520687103271
Epoch: 95, Steps: 63 | Train Loss: 0.3214441 Vali Loss: 1.2490568 Test Loss: 0.4671566
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 3.5442657470703125
Epoch: 96, Steps: 63 | Train Loss: 0.3212093 Vali Loss: 1.2486780 Test Loss: 0.4671405
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 3.346997022628784
Epoch: 97, Steps: 63 | Train Loss: 0.3213638 Vali Loss: 1.2472976 Test Loss: 0.4671256
EarlyStopping counter: 20 out of 20
Early stopping
train 8125
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=42, out_features=120, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4515840.0
params:  5160.0
Trainable parameters:  5160
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.151219367980957
Epoch: 1, Steps: 63 | Train Loss: 0.4733392 Vali Loss: 1.2362573 Test Loss: 0.4611319
Validation loss decreased (inf --> 1.236257).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.396394968032837
Epoch: 2, Steps: 63 | Train Loss: 0.4698270 Vali Loss: 1.2373648 Test Loss: 0.4586070
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.051548719406128
Epoch: 3, Steps: 63 | Train Loss: 0.4687311 Vali Loss: 1.2289801 Test Loss: 0.4577752
Validation loss decreased (1.236257 --> 1.228980).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.565542221069336
Epoch: 4, Steps: 63 | Train Loss: 0.4676290 Vali Loss: 1.2286460 Test Loss: 0.4565603
Validation loss decreased (1.228980 --> 1.228646).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.6720597743988037
Epoch: 5, Steps: 63 | Train Loss: 0.4671603 Vali Loss: 1.2330517 Test Loss: 0.4567107
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.6218125820159912
Epoch: 6, Steps: 63 | Train Loss: 0.4664350 Vali Loss: 1.2264351 Test Loss: 0.4568077
Validation loss decreased (1.228646 --> 1.226435).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.260641574859619
Epoch: 7, Steps: 63 | Train Loss: 0.4663943 Vali Loss: 1.2302845 Test Loss: 0.4564172
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.5852112770080566
Epoch: 8, Steps: 63 | Train Loss: 0.4659797 Vali Loss: 1.2285485 Test Loss: 0.4567403
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.8860995769500732
Epoch: 9, Steps: 63 | Train Loss: 0.4660681 Vali Loss: 1.2271605 Test Loss: 0.4566545
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.1593897342681885
Epoch: 10, Steps: 63 | Train Loss: 0.4665324 Vali Loss: 1.2279850 Test Loss: 0.4568304
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.721301317214966
Epoch: 11, Steps: 63 | Train Loss: 0.4661923 Vali Loss: 1.2309817 Test Loss: 0.4568940
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.0846500396728516
Epoch: 12, Steps: 63 | Train Loss: 0.4663441 Vali Loss: 1.2306305 Test Loss: 0.4568391
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.448887586593628
Epoch: 13, Steps: 63 | Train Loss: 0.4660068 Vali Loss: 1.2274344 Test Loss: 0.4569065
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.352334499359131
Epoch: 14, Steps: 63 | Train Loss: 0.4660272 Vali Loss: 1.2323248 Test Loss: 0.4570109
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.0564682483673096
Epoch: 15, Steps: 63 | Train Loss: 0.4660314 Vali Loss: 1.2327935 Test Loss: 0.4569674
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.754049777984619
Epoch: 16, Steps: 63 | Train Loss: 0.4662495 Vali Loss: 1.2307364 Test Loss: 0.4568961
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.5743343830108643
Epoch: 17, Steps: 63 | Train Loss: 0.4656308 Vali Loss: 1.2266142 Test Loss: 0.4572295
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.503526210784912
Epoch: 18, Steps: 63 | Train Loss: 0.4658165 Vali Loss: 1.2249302 Test Loss: 0.4571223
Validation loss decreased (1.226435 --> 1.224930).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.3922932147979736
Epoch: 19, Steps: 63 | Train Loss: 0.4659197 Vali Loss: 1.2282280 Test Loss: 0.4571317
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.1496002674102783
Epoch: 20, Steps: 63 | Train Loss: 0.4656629 Vali Loss: 1.2271321 Test Loss: 0.4571083
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.1048007011413574
Epoch: 21, Steps: 63 | Train Loss: 0.4659342 Vali Loss: 1.2271644 Test Loss: 0.4571644
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.7201426029205322
Epoch: 22, Steps: 63 | Train Loss: 0.4662035 Vali Loss: 1.2274696 Test Loss: 0.4571212
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.1028223037719727
Epoch: 23, Steps: 63 | Train Loss: 0.4661041 Vali Loss: 1.2268177 Test Loss: 0.4571602
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.1576972007751465
Epoch: 24, Steps: 63 | Train Loss: 0.4657575 Vali Loss: 1.2254993 Test Loss: 0.4571335
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.696791410446167
Epoch: 25, Steps: 63 | Train Loss: 0.4655831 Vali Loss: 1.2265152 Test Loss: 0.4571075
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.196995258331299
Epoch: 26, Steps: 63 | Train Loss: 0.4659831 Vali Loss: 1.2269481 Test Loss: 0.4571023
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.5665652751922607
Epoch: 27, Steps: 63 | Train Loss: 0.4653524 Vali Loss: 1.2278165 Test Loss: 0.4571225
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.4496207237243652
Epoch: 28, Steps: 63 | Train Loss: 0.4660861 Vali Loss: 1.2265805 Test Loss: 0.4572073
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.172520875930786
Epoch: 29, Steps: 63 | Train Loss: 0.4655747 Vali Loss: 1.2271624 Test Loss: 0.4571897
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.875157594680786
Epoch: 30, Steps: 63 | Train Loss: 0.4659730 Vali Loss: 1.2270564 Test Loss: 0.4571957
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.5273783206939697
Epoch: 31, Steps: 63 | Train Loss: 0.4656460 Vali Loss: 1.2268969 Test Loss: 0.4572301
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.7892210483551025
Epoch: 32, Steps: 63 | Train Loss: 0.4658644 Vali Loss: 1.2240099 Test Loss: 0.4571370
Validation loss decreased (1.224930 --> 1.224010).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 3.4495482444763184
Epoch: 33, Steps: 63 | Train Loss: 0.4655554 Vali Loss: 1.2295218 Test Loss: 0.4571575
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.9416985511779785
Epoch: 34, Steps: 63 | Train Loss: 0.4656776 Vali Loss: 1.2287780 Test Loss: 0.4572219
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.6495699882507324
Epoch: 35, Steps: 63 | Train Loss: 0.4657920 Vali Loss: 1.2258984 Test Loss: 0.4571949
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.9305901527404785
Epoch: 36, Steps: 63 | Train Loss: 0.4658285 Vali Loss: 1.2315804 Test Loss: 0.4572450
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.9252102375030518
Epoch: 37, Steps: 63 | Train Loss: 0.4655765 Vali Loss: 1.2229352 Test Loss: 0.4572798
Validation loss decreased (1.224010 --> 1.222935).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.8724651336669922
Epoch: 38, Steps: 63 | Train Loss: 0.4654495 Vali Loss: 1.2319508 Test Loss: 0.4572617
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.964120864868164
Epoch: 39, Steps: 63 | Train Loss: 0.4654535 Vali Loss: 1.2199693 Test Loss: 0.4572411
Validation loss decreased (1.222935 --> 1.219969).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.9969499111175537
Epoch: 40, Steps: 63 | Train Loss: 0.4656737 Vali Loss: 1.2267582 Test Loss: 0.4572522
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.7230021953582764
Epoch: 41, Steps: 63 | Train Loss: 0.4654407 Vali Loss: 1.2204551 Test Loss: 0.4572513
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.0503311157226562
Epoch: 42, Steps: 63 | Train Loss: 0.4659378 Vali Loss: 1.2266773 Test Loss: 0.4572182
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.0988097190856934
Epoch: 43, Steps: 63 | Train Loss: 0.4656187 Vali Loss: 1.2318233 Test Loss: 0.4572558
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.90256929397583
Epoch: 44, Steps: 63 | Train Loss: 0.4657732 Vali Loss: 1.2255219 Test Loss: 0.4572156
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.601405382156372
Epoch: 45, Steps: 63 | Train Loss: 0.4658581 Vali Loss: 1.2278616 Test Loss: 0.4572864
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 3.732858419418335
Epoch: 46, Steps: 63 | Train Loss: 0.4653673 Vali Loss: 1.2287873 Test Loss: 0.4572762
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.9743986129760742
Epoch: 47, Steps: 63 | Train Loss: 0.4651462 Vali Loss: 1.2258290 Test Loss: 0.4572814
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 4.2846057415008545
Epoch: 48, Steps: 63 | Train Loss: 0.4658474 Vali Loss: 1.2261026 Test Loss: 0.4572734
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 3.5119423866271973
Epoch: 49, Steps: 63 | Train Loss: 0.4651590 Vali Loss: 1.2278270 Test Loss: 0.4572916
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.9313111305236816
Epoch: 50, Steps: 63 | Train Loss: 0.4655954 Vali Loss: 1.2253467 Test Loss: 0.4573020
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.5097451210021973
Epoch: 51, Steps: 63 | Train Loss: 0.4654189 Vali Loss: 1.2299364 Test Loss: 0.4573013
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 3.048295259475708
Epoch: 52, Steps: 63 | Train Loss: 0.4656327 Vali Loss: 1.2244647 Test Loss: 0.4573368
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.8755605220794678
Epoch: 53, Steps: 63 | Train Loss: 0.4655788 Vali Loss: 1.2236478 Test Loss: 0.4572930
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.8294034004211426
Epoch: 54, Steps: 63 | Train Loss: 0.4657658 Vali Loss: 1.2295489 Test Loss: 0.4573046
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.8711111545562744
Epoch: 55, Steps: 63 | Train Loss: 0.4657035 Vali Loss: 1.2246393 Test Loss: 0.4573073
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.7629234790802002
Epoch: 56, Steps: 63 | Train Loss: 0.4656619 Vali Loss: 1.2280550 Test Loss: 0.4573172
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.028675079345703
Epoch: 57, Steps: 63 | Train Loss: 0.4656699 Vali Loss: 1.2294530 Test Loss: 0.4573266
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.3583550453186035
Epoch: 58, Steps: 63 | Train Loss: 0.4653750 Vali Loss: 1.2285926 Test Loss: 0.4573352
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.9522371292114258
Epoch: 59, Steps: 63 | Train Loss: 0.4658611 Vali Loss: 1.2322670 Test Loss: 0.4573243
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_180_336_FITS_ETTh1_ftM_sl180_ll48_pl336_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.4565311670303345, mae:0.4362584054470062, rse:0.6432610750198364, corr:[0.25385815 0.2588135  0.25886917 0.25689933 0.25468862 0.25243023
 0.25085032 0.25075793 0.25116414 0.2511337  0.25045848 0.25053158
 0.25112942 0.2505045  0.24959852 0.24970202 0.2502352  0.25009462
 0.24947652 0.2490678  0.24912336 0.24940412 0.2496376  0.24936078
 0.2486199  0.24813892 0.24749385 0.24678326 0.2461789  0.24585937
 0.24553953 0.24505827 0.24478899 0.24500097 0.24518937 0.24536757
 0.24563521 0.24572839 0.24580699 0.24585043 0.24599041 0.24631
 0.24646007 0.24635296 0.24657437 0.24720144 0.24794538 0.24778566
 0.24639542 0.24514784 0.24378008 0.24248761 0.24122545 0.2399801
 0.2392065  0.23905462 0.23908977 0.23928258 0.23914957 0.23963955
 0.24021548 0.24008839 0.23985812 0.23976472 0.2397676  0.23981759
 0.23994747 0.23987746 0.23977044 0.23976976 0.23990408 0.23937194
 0.23808572 0.2370602  0.23609649 0.23552816 0.23535657 0.23509507
 0.23474532 0.23440687 0.23426996 0.23436922 0.2340344  0.23389784
 0.23421673 0.23421769 0.2341248  0.23401698 0.23387827 0.23386112
 0.2337507  0.23345432 0.23342238 0.23390563 0.23461597 0.23481187
 0.23415166 0.23361051 0.23316264 0.2325179  0.2320387  0.2317032
 0.2314825  0.23167342 0.23189096 0.23211549 0.23205413 0.23224969
 0.23250325 0.23221603 0.2319386  0.2320076  0.23217605 0.23227358
 0.23227403 0.23219942 0.23218584 0.23230428 0.23241387 0.23204593
 0.23100561 0.2299976  0.22866821 0.22738515 0.22651926 0.22614196
 0.22603595 0.2262279  0.22635019 0.22655195 0.22663014 0.2271439
 0.22792614 0.22805251 0.22803134 0.22802812 0.2280098  0.22810195
 0.22819944 0.22822203 0.22831081 0.22852632 0.22869302 0.2283557
 0.22743082 0.22655633 0.22552069 0.22412029 0.22318989 0.22275893
 0.22275104 0.2229223  0.22331262 0.22376974 0.2238876  0.22420655
 0.22469275 0.22466142 0.22452357 0.22435904 0.22410311 0.22404374
 0.22405905 0.22401701 0.22409357 0.22440067 0.2246431  0.22430287
 0.22336215 0.22268297 0.2219759  0.22119197 0.22073728 0.2205643
 0.22060625 0.22100124 0.2214945  0.22221115 0.22271222 0.2233726
 0.22414537 0.22422536 0.22399905 0.22384617 0.22382535 0.22410046
 0.22436544 0.2244617  0.22467525 0.22511367 0.22545393 0.22514309
 0.22404236 0.2232315  0.22238125 0.22142208 0.22067018 0.22018276
 0.21994954 0.21997312 0.22024755 0.22063863 0.22066227 0.22106485
 0.22167939 0.22166894 0.22141378 0.22117196 0.22100656 0.2209733
 0.22086658 0.22062029 0.22066213 0.22101119 0.2212818  0.22092706
 0.22005758 0.21958768 0.21912584 0.2184656  0.21803924 0.21762402
 0.2175014  0.2175823  0.21787517 0.21811786 0.2180618  0.21834478
 0.21897173 0.21889026 0.21862186 0.21854806 0.21847332 0.21845381
 0.21839812 0.2182522  0.21827361 0.21861187 0.2190036  0.21875982
 0.21781127 0.2170278  0.21631514 0.21572566 0.2154429  0.21535581
 0.21543409 0.2156392  0.21605057 0.21663019 0.21704425 0.21767572
 0.21844618 0.21860819 0.21865371 0.21867795 0.21864316 0.21866377
 0.21876799 0.21869922 0.21860936 0.21861826 0.21882193 0.21868299
 0.21798761 0.21747713 0.21673128 0.21593416 0.21551768 0.21534885
 0.21531337 0.21539001 0.21551876 0.21581323 0.2159354  0.21611547
 0.21676046 0.21684027 0.21669526 0.21648271 0.21624401 0.21618038
 0.2162227  0.21615337 0.21627624 0.21669193 0.21717893 0.21714859
 0.21650602 0.21621856 0.2160339  0.21576211 0.21558955 0.21583408
 0.21618696 0.21642828 0.21665691 0.21698654 0.21711583 0.21742466
 0.21805042 0.21808979 0.21795861 0.21781887 0.21775712 0.2178554
 0.21802713 0.21803689 0.21804853 0.2182338  0.21861893 0.21847378
 0.21753938 0.21698835 0.21651547 0.21569544 0.21521623 0.21475172
 0.21458451 0.21468969 0.2148862  0.21527089 0.21545671 0.21593164
 0.21697353 0.21716931 0.2171057  0.21727    0.21721727 0.21707897
 0.21714628 0.21714589 0.21617544 0.2153065  0.21618618 0.21600772]
