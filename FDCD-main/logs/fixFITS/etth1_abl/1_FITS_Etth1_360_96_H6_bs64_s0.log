Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_360_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=0, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_360_96_FITS_ETTh1_ftM_sl360_ll48_pl96_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8185
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=106, out_features=134, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  12726784.0
params:  14338.0
Trainable parameters:  14338
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.5219085216522217
Epoch: 1, Steps: 63 | Train Loss: 0.5541034 Vali Loss: 0.9914126 Test Loss: 0.5065174
Validation loss decreased (inf --> 0.991413).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.523026704788208
Epoch: 2, Steps: 63 | Train Loss: 0.4113965 Vali Loss: 0.8431036 Test Loss: 0.4228739
Validation loss decreased (0.991413 --> 0.843104).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.994379997253418
Epoch: 3, Steps: 63 | Train Loss: 0.3735396 Vali Loss: 0.7857351 Test Loss: 0.3934265
Validation loss decreased (0.843104 --> 0.785735).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.5048022270202637
Epoch: 4, Steps: 63 | Train Loss: 0.3584883 Vali Loss: 0.7597498 Test Loss: 0.3823684
Validation loss decreased (0.785735 --> 0.759750).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.7063665390014648
Epoch: 5, Steps: 63 | Train Loss: 0.3516787 Vali Loss: 0.7423663 Test Loss: 0.3778031
Validation loss decreased (0.759750 --> 0.742366).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.54937744140625
Epoch: 6, Steps: 63 | Train Loss: 0.3471974 Vali Loss: 0.7328788 Test Loss: 0.3760487
Validation loss decreased (0.742366 --> 0.732879).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.5534822940826416
Epoch: 7, Steps: 63 | Train Loss: 0.3454613 Vali Loss: 0.7185113 Test Loss: 0.3750909
Validation loss decreased (0.732879 --> 0.718511).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.51218843460083
Epoch: 8, Steps: 63 | Train Loss: 0.3444735 Vali Loss: 0.7151828 Test Loss: 0.3746248
Validation loss decreased (0.718511 --> 0.715183).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.473900318145752
Epoch: 9, Steps: 63 | Train Loss: 0.3437697 Vali Loss: 0.7090413 Test Loss: 0.3744284
Validation loss decreased (0.715183 --> 0.709041).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.4584786891937256
Epoch: 10, Steps: 63 | Train Loss: 0.3420535 Vali Loss: 0.7069334 Test Loss: 0.3740034
Validation loss decreased (0.709041 --> 0.706933).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.3727054595947266
Epoch: 11, Steps: 63 | Train Loss: 0.3419452 Vali Loss: 0.7012233 Test Loss: 0.3737241
Validation loss decreased (0.706933 --> 0.701223).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.599332332611084
Epoch: 12, Steps: 63 | Train Loss: 0.3414255 Vali Loss: 0.6985039 Test Loss: 0.3735934
Validation loss decreased (0.701223 --> 0.698504).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.4625225067138672
Epoch: 13, Steps: 63 | Train Loss: 0.3399603 Vali Loss: 0.6975632 Test Loss: 0.3734372
Validation loss decreased (0.698504 --> 0.697563).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.5255637168884277
Epoch: 14, Steps: 63 | Train Loss: 0.3400632 Vali Loss: 0.6954192 Test Loss: 0.3736039
Validation loss decreased (0.697563 --> 0.695419).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.5517942905426025
Epoch: 15, Steps: 63 | Train Loss: 0.3397564 Vali Loss: 0.6907997 Test Loss: 0.3733852
Validation loss decreased (0.695419 --> 0.690800).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.370924472808838
Epoch: 16, Steps: 63 | Train Loss: 0.3389778 Vali Loss: 0.6931477 Test Loss: 0.3733155
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.4591186046600342
Epoch: 17, Steps: 63 | Train Loss: 0.3397995 Vali Loss: 0.6900586 Test Loss: 0.3731829
Validation loss decreased (0.690800 --> 0.690059).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.5151450634002686
Epoch: 18, Steps: 63 | Train Loss: 0.3393167 Vali Loss: 0.6893950 Test Loss: 0.3732558
Validation loss decreased (0.690059 --> 0.689395).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.6355538368225098
Epoch: 19, Steps: 63 | Train Loss: 0.3390927 Vali Loss: 0.6931923 Test Loss: 0.3732108
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.5063872337341309
Epoch: 20, Steps: 63 | Train Loss: 0.3386469 Vali Loss: 0.6920245 Test Loss: 0.3730915
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.5320520401000977
Epoch: 21, Steps: 63 | Train Loss: 0.3389077 Vali Loss: 0.6838317 Test Loss: 0.3730022
Validation loss decreased (0.689395 --> 0.683832).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.543189525604248
Epoch: 22, Steps: 63 | Train Loss: 0.3385045 Vali Loss: 0.6882403 Test Loss: 0.3730886
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.8535456657409668
Epoch: 23, Steps: 63 | Train Loss: 0.3385715 Vali Loss: 0.6833032 Test Loss: 0.3730050
Validation loss decreased (0.683832 --> 0.683303).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.6747691631317139
Epoch: 24, Steps: 63 | Train Loss: 0.3381135 Vali Loss: 0.6855540 Test Loss: 0.3730571
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.4223804473876953
Epoch: 25, Steps: 63 | Train Loss: 0.3380671 Vali Loss: 0.6854432 Test Loss: 0.3728947
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.7199163436889648
Epoch: 26, Steps: 63 | Train Loss: 0.3379229 Vali Loss: 0.6869966 Test Loss: 0.3728889
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.5411388874053955
Epoch: 27, Steps: 63 | Train Loss: 0.3382548 Vali Loss: 0.6849019 Test Loss: 0.3728538
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.5592422485351562
Epoch: 28, Steps: 63 | Train Loss: 0.3377662 Vali Loss: 0.6814191 Test Loss: 0.3729302
Validation loss decreased (0.683303 --> 0.681419).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.4162952899932861
Epoch: 29, Steps: 63 | Train Loss: 0.3374249 Vali Loss: 0.6823331 Test Loss: 0.3729590
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.3878147602081299
Epoch: 30, Steps: 63 | Train Loss: 0.3378293 Vali Loss: 0.6839154 Test Loss: 0.3729923
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.498441457748413
Epoch: 31, Steps: 63 | Train Loss: 0.3376618 Vali Loss: 0.6792508 Test Loss: 0.3729873
Validation loss decreased (0.681419 --> 0.679251).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.4339625835418701
Epoch: 32, Steps: 63 | Train Loss: 0.3375260 Vali Loss: 0.6846269 Test Loss: 0.3728131
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.4497056007385254
Epoch: 33, Steps: 63 | Train Loss: 0.3365142 Vali Loss: 0.6805622 Test Loss: 0.3729254
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.4917469024658203
Epoch: 34, Steps: 63 | Train Loss: 0.3370030 Vali Loss: 0.6787255 Test Loss: 0.3729046
Validation loss decreased (0.679251 --> 0.678726).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.5950024127960205
Epoch: 35, Steps: 63 | Train Loss: 0.3373198 Vali Loss: 0.6821818 Test Loss: 0.3729399
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.5473439693450928
Epoch: 36, Steps: 63 | Train Loss: 0.3370022 Vali Loss: 0.6810699 Test Loss: 0.3729515
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.4553778171539307
Epoch: 37, Steps: 63 | Train Loss: 0.3371374 Vali Loss: 0.6811985 Test Loss: 0.3729458
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.3987622261047363
Epoch: 38, Steps: 63 | Train Loss: 0.3373718 Vali Loss: 0.6817687 Test Loss: 0.3730406
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.517716407775879
Epoch: 39, Steps: 63 | Train Loss: 0.3372580 Vali Loss: 0.6793049 Test Loss: 0.3729744
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.286515474319458
Epoch: 40, Steps: 63 | Train Loss: 0.3374613 Vali Loss: 0.6788953 Test Loss: 0.3729779
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.419801950454712
Epoch: 41, Steps: 63 | Train Loss: 0.3368449 Vali Loss: 0.6830270 Test Loss: 0.3729636
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.5555446147918701
Epoch: 42, Steps: 63 | Train Loss: 0.3368842 Vali Loss: 0.6761393 Test Loss: 0.3729758
Validation loss decreased (0.678726 --> 0.676139).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.3654804229736328
Epoch: 43, Steps: 63 | Train Loss: 0.3373442 Vali Loss: 0.6801025 Test Loss: 0.3729689
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.4000437259674072
Epoch: 44, Steps: 63 | Train Loss: 0.3371833 Vali Loss: 0.6805274 Test Loss: 0.3730128
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.4800386428833008
Epoch: 45, Steps: 63 | Train Loss: 0.3369138 Vali Loss: 0.6801569 Test Loss: 0.3729646
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.4702985286712646
Epoch: 46, Steps: 63 | Train Loss: 0.3374528 Vali Loss: 0.6783078 Test Loss: 0.3729520
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.4713869094848633
Epoch: 47, Steps: 63 | Train Loss: 0.3372196 Vali Loss: 0.6848665 Test Loss: 0.3729373
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.4164130687713623
Epoch: 48, Steps: 63 | Train Loss: 0.3371566 Vali Loss: 0.6736384 Test Loss: 0.3729379
Validation loss decreased (0.676139 --> 0.673638).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.4392094612121582
Epoch: 49, Steps: 63 | Train Loss: 0.3372124 Vali Loss: 0.6802896 Test Loss: 0.3729027
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.5343017578125
Epoch: 50, Steps: 63 | Train Loss: 0.3368972 Vali Loss: 0.6829587 Test Loss: 0.3729554
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.7493722438812256
Epoch: 51, Steps: 63 | Train Loss: 0.3367014 Vali Loss: 0.6795540 Test Loss: 0.3729696
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.582322359085083
Epoch: 52, Steps: 63 | Train Loss: 0.3365711 Vali Loss: 0.6798183 Test Loss: 0.3729392
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.5856308937072754
Epoch: 53, Steps: 63 | Train Loss: 0.3369582 Vali Loss: 0.6811255 Test Loss: 0.3729284
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.4271292686462402
Epoch: 54, Steps: 63 | Train Loss: 0.3371349 Vali Loss: 0.6778626 Test Loss: 0.3729517
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.206427812576294
Epoch: 55, Steps: 63 | Train Loss: 0.3368225 Vali Loss: 0.6789055 Test Loss: 0.3729581
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.5328528881072998
Epoch: 56, Steps: 63 | Train Loss: 0.3369594 Vali Loss: 0.6757920 Test Loss: 0.3729185
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.4285075664520264
Epoch: 57, Steps: 63 | Train Loss: 0.3367389 Vali Loss: 0.6787434 Test Loss: 0.3729639
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.8310277462005615
Epoch: 58, Steps: 63 | Train Loss: 0.3369966 Vali Loss: 0.6770241 Test Loss: 0.3729639
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.5467290878295898
Epoch: 59, Steps: 63 | Train Loss: 0.3371462 Vali Loss: 0.6820022 Test Loss: 0.3729570
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.430976390838623
Epoch: 60, Steps: 63 | Train Loss: 0.3365104 Vali Loss: 0.6785070 Test Loss: 0.3729143
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.4813849925994873
Epoch: 61, Steps: 63 | Train Loss: 0.3367402 Vali Loss: 0.6808183 Test Loss: 0.3729372
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.786130428314209
Epoch: 62, Steps: 63 | Train Loss: 0.3373620 Vali Loss: 0.6784469 Test Loss: 0.3729399
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.450951099395752
Epoch: 63, Steps: 63 | Train Loss: 0.3364558 Vali Loss: 0.6803073 Test Loss: 0.3729408
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.4031145572662354
Epoch: 64, Steps: 63 | Train Loss: 0.3369184 Vali Loss: 0.6787823 Test Loss: 0.3729627
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.57912015914917
Epoch: 65, Steps: 63 | Train Loss: 0.3367594 Vali Loss: 0.6784361 Test Loss: 0.3729474
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.9304406642913818
Epoch: 66, Steps: 63 | Train Loss: 0.3371474 Vali Loss: 0.6800717 Test Loss: 0.3729628
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.4472692012786865
Epoch: 67, Steps: 63 | Train Loss: 0.3367291 Vali Loss: 0.6824784 Test Loss: 0.3729490
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.2981040477752686
Epoch: 68, Steps: 63 | Train Loss: 0.3367319 Vali Loss: 0.6775481 Test Loss: 0.3729543
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_360_96_FITS_ETTh1_ftM_sl360_ll48_pl96_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.3719749450683594, mae:0.39443206787109375, rse:0.5793148875236511, corr:[0.26855898 0.2784091  0.27828228 0.2795677  0.2770798  0.27482983
 0.27428135 0.2737829  0.27310988 0.2731909  0.2731299  0.27257782
 0.27254882 0.27259418 0.2722486  0.272282   0.2725082  0.272194
 0.27193663 0.27198267 0.27175686 0.27127284 0.27147922 0.27200776
 0.27159545 0.2710293  0.27091897 0.27069807 0.2701633  0.2698502
 0.2696112  0.26900253 0.2685525  0.26857045 0.2685488  0.26825973
 0.26830164 0.26851985 0.2685411  0.26858816 0.2689764  0.26914755
 0.2692311  0.26922345 0.26887286 0.2683873  0.26846376 0.26876172
 0.26836225 0.26735026 0.2665322  0.26605555 0.26527038 0.2640887
 0.26349878 0.2632265  0.26288423 0.26276255 0.2625757  0.2625354
 0.26255688 0.26271006 0.26269105 0.26257065 0.26268575 0.26310593
 0.26345885 0.2632812  0.2630284  0.26317537 0.26341084 0.2632789
 0.26258495 0.2616626  0.26092908 0.26051834 0.26017937 0.25970843
 0.25930154 0.25880554 0.2583281  0.25799608 0.25774187 0.2574701
 0.2573456  0.25755474 0.25768644 0.2572631  0.25715962 0.2574617
 0.25703165 0.2563779  0.2562148  0.25506595 0.25504234 0.25750852]
