Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=22, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_90_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_90_336_FITS_ETTh1_ftM_sl90_ll48_pl336_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8215
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=22, out_features=104, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2050048.0
params:  2392.0
Trainable parameters:  2392
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.3966844081878662
Epoch: 1, Steps: 64 | Train Loss: 1.0430977 Vali Loss: 2.2919788 Test Loss: 1.2221811
Validation loss decreased (inf --> 2.291979).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.365495204925537
Epoch: 2, Steps: 64 | Train Loss: 0.8233798 Vali Loss: 1.9741225 Test Loss: 0.9751877
Validation loss decreased (2.291979 --> 1.974123).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.4460813999176025
Epoch: 3, Steps: 64 | Train Loss: 0.6918998 Vali Loss: 1.7931522 Test Loss: 0.8312010
Validation loss decreased (1.974123 --> 1.793152).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.2564005851745605
Epoch: 4, Steps: 64 | Train Loss: 0.6104959 Vali Loss: 1.6768098 Test Loss: 0.7404908
Validation loss decreased (1.793152 --> 1.676810).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.2870099544525146
Epoch: 5, Steps: 64 | Train Loss: 0.5576563 Vali Loss: 1.5925239 Test Loss: 0.6806406
Validation loss decreased (1.676810 --> 1.592524).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.4220025539398193
Epoch: 6, Steps: 64 | Train Loss: 0.5218234 Vali Loss: 1.5435133 Test Loss: 0.6394525
Validation loss decreased (1.592524 --> 1.543513).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.382141351699829
Epoch: 7, Steps: 64 | Train Loss: 0.4967741 Vali Loss: 1.5020171 Test Loss: 0.6096748
Validation loss decreased (1.543513 --> 1.502017).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.4393041133880615
Epoch: 8, Steps: 64 | Train Loss: 0.4785963 Vali Loss: 1.4721301 Test Loss: 0.5877185
Validation loss decreased (1.502017 --> 1.472130).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.4244115352630615
Epoch: 9, Steps: 64 | Train Loss: 0.4651248 Vali Loss: 1.4491247 Test Loss: 0.5713765
Validation loss decreased (1.472130 --> 1.449125).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.9467518329620361
Epoch: 10, Steps: 64 | Train Loss: 0.4550599 Vali Loss: 1.4272562 Test Loss: 0.5585378
Validation loss decreased (1.449125 --> 1.427256).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.7904410362243652
Epoch: 11, Steps: 64 | Train Loss: 0.4469673 Vali Loss: 1.4097011 Test Loss: 0.5488038
Validation loss decreased (1.427256 --> 1.409701).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.441840887069702
Epoch: 12, Steps: 64 | Train Loss: 0.4409913 Vali Loss: 1.4046034 Test Loss: 0.5411409
Validation loss decreased (1.409701 --> 1.404603).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.4095942974090576
Epoch: 13, Steps: 64 | Train Loss: 0.4358524 Vali Loss: 1.3910526 Test Loss: 0.5346425
Validation loss decreased (1.404603 --> 1.391053).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.32566499710083
Epoch: 14, Steps: 64 | Train Loss: 0.4316860 Vali Loss: 1.3876534 Test Loss: 0.5294900
Validation loss decreased (1.391053 --> 1.387653).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.3705952167510986
Epoch: 15, Steps: 64 | Train Loss: 0.4285436 Vali Loss: 1.3807604 Test Loss: 0.5251102
Validation loss decreased (1.387653 --> 1.380760).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.465430736541748
Epoch: 16, Steps: 64 | Train Loss: 0.4254490 Vali Loss: 1.3654323 Test Loss: 0.5214474
Validation loss decreased (1.380760 --> 1.365432).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.3754143714904785
Epoch: 17, Steps: 64 | Train Loss: 0.4230628 Vali Loss: 1.3639759 Test Loss: 0.5184333
Validation loss decreased (1.365432 --> 1.363976).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.3989028930664062
Epoch: 18, Steps: 64 | Train Loss: 0.4209919 Vali Loss: 1.3599787 Test Loss: 0.5157628
Validation loss decreased (1.363976 --> 1.359979).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.4792678356170654
Epoch: 19, Steps: 64 | Train Loss: 0.4193987 Vali Loss: 1.3599563 Test Loss: 0.5134774
Validation loss decreased (1.359979 --> 1.359956).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.402681589126587
Epoch: 20, Steps: 64 | Train Loss: 0.4177338 Vali Loss: 1.3550371 Test Loss: 0.5115157
Validation loss decreased (1.359956 --> 1.355037).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.34684419631958
Epoch: 21, Steps: 64 | Train Loss: 0.4163072 Vali Loss: 1.3498124 Test Loss: 0.5097595
Validation loss decreased (1.355037 --> 1.349812).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.3857252597808838
Epoch: 22, Steps: 64 | Train Loss: 0.4149502 Vali Loss: 1.3499682 Test Loss: 0.5081903
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.3288516998291016
Epoch: 23, Steps: 64 | Train Loss: 0.4137829 Vali Loss: 1.3491192 Test Loss: 0.5068026
Validation loss decreased (1.349812 --> 1.349119).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.5221412181854248
Epoch: 24, Steps: 64 | Train Loss: 0.4128606 Vali Loss: 1.3329401 Test Loss: 0.5055929
Validation loss decreased (1.349119 --> 1.332940).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.6964025497436523
Epoch: 25, Steps: 64 | Train Loss: 0.4117477 Vali Loss: 1.3376927 Test Loss: 0.5044764
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 4.54384183883667
Epoch: 26, Steps: 64 | Train Loss: 0.4109667 Vali Loss: 1.3351713 Test Loss: 0.5035021
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.422729730606079
Epoch: 27, Steps: 64 | Train Loss: 0.4101160 Vali Loss: 1.3312415 Test Loss: 0.5026326
Validation loss decreased (1.332940 --> 1.331241).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.466907024383545
Epoch: 28, Steps: 64 | Train Loss: 0.4096684 Vali Loss: 1.3373786 Test Loss: 0.5017524
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.4214837551116943
Epoch: 29, Steps: 64 | Train Loss: 0.4089558 Vali Loss: 1.3343744 Test Loss: 0.5009987
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.3627288341522217
Epoch: 30, Steps: 64 | Train Loss: 0.4081598 Vali Loss: 1.3345295 Test Loss: 0.5003259
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.4451992511749268
Epoch: 31, Steps: 64 | Train Loss: 0.4078443 Vali Loss: 1.3301519 Test Loss: 0.4997003
Validation loss decreased (1.331241 --> 1.330152).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.4498631954193115
Epoch: 32, Steps: 64 | Train Loss: 0.4070254 Vali Loss: 1.3258504 Test Loss: 0.4991048
Validation loss decreased (1.330152 --> 1.325850).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.3934788703918457
Epoch: 33, Steps: 64 | Train Loss: 0.4066177 Vali Loss: 1.3274432 Test Loss: 0.4985811
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.4576663970947266
Epoch: 34, Steps: 64 | Train Loss: 0.4063456 Vali Loss: 1.3211290 Test Loss: 0.4980858
Validation loss decreased (1.325850 --> 1.321129).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.43605375289917
Epoch: 35, Steps: 64 | Train Loss: 0.4057523 Vali Loss: 1.3235060 Test Loss: 0.4976126
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.3878355026245117
Epoch: 36, Steps: 64 | Train Loss: 0.4053684 Vali Loss: 1.3252563 Test Loss: 0.4971899
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.3292078971862793
Epoch: 37, Steps: 64 | Train Loss: 0.4049338 Vali Loss: 1.3293098 Test Loss: 0.4967954
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.4460828304290771
Epoch: 38, Steps: 64 | Train Loss: 0.4047121 Vali Loss: 1.3303928 Test Loss: 0.4964190
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.3145201206207275
Epoch: 39, Steps: 64 | Train Loss: 0.4044601 Vali Loss: 1.3259449 Test Loss: 0.4960752
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.367157220840454
Epoch: 40, Steps: 64 | Train Loss: 0.4042205 Vali Loss: 1.3241887 Test Loss: 0.4957305
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.3582725524902344
Epoch: 41, Steps: 64 | Train Loss: 0.4040173 Vali Loss: 1.3266928 Test Loss: 0.4954394
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.2927184104919434
Epoch: 42, Steps: 64 | Train Loss: 0.4035523 Vali Loss: 1.3210675 Test Loss: 0.4951686
Validation loss decreased (1.321129 --> 1.321067).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.3396596908569336
Epoch: 43, Steps: 64 | Train Loss: 0.4032669 Vali Loss: 1.3281054 Test Loss: 0.4948715
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.3222723007202148
Epoch: 44, Steps: 64 | Train Loss: 0.4031114 Vali Loss: 1.3205742 Test Loss: 0.4946291
Validation loss decreased (1.321067 --> 1.320574).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.4202122688293457
Epoch: 45, Steps: 64 | Train Loss: 0.4026247 Vali Loss: 1.3187624 Test Loss: 0.4944100
Validation loss decreased (1.320574 --> 1.318762).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.3931670188903809
Epoch: 46, Steps: 64 | Train Loss: 0.4026660 Vali Loss: 1.3216690 Test Loss: 0.4941683
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.388239860534668
Epoch: 47, Steps: 64 | Train Loss: 0.4023704 Vali Loss: 1.3240999 Test Loss: 0.4939636
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.5398313999176025
Epoch: 48, Steps: 64 | Train Loss: 0.4018307 Vali Loss: 1.3207672 Test Loss: 0.4937634
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.258303165435791
Epoch: 49, Steps: 64 | Train Loss: 0.4020395 Vali Loss: 1.3188316 Test Loss: 0.4935740
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.4357879161834717
Epoch: 50, Steps: 64 | Train Loss: 0.4020096 Vali Loss: 1.3123971 Test Loss: 0.4934130
Validation loss decreased (1.318762 --> 1.312397).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.3841445446014404
Epoch: 51, Steps: 64 | Train Loss: 0.4015458 Vali Loss: 1.3170213 Test Loss: 0.4932204
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.3874576091766357
Epoch: 52, Steps: 64 | Train Loss: 0.4015584 Vali Loss: 1.3133116 Test Loss: 0.4930660
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.4414761066436768
Epoch: 53, Steps: 64 | Train Loss: 0.4011878 Vali Loss: 1.3192396 Test Loss: 0.4929136
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.3421688079833984
Epoch: 54, Steps: 64 | Train Loss: 0.4013256 Vali Loss: 1.3171562 Test Loss: 0.4927800
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.4154305458068848
Epoch: 55, Steps: 64 | Train Loss: 0.4010757 Vali Loss: 1.3146696 Test Loss: 0.4926471
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.4284915924072266
Epoch: 56, Steps: 64 | Train Loss: 0.4006524 Vali Loss: 1.3179778 Test Loss: 0.4925115
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.3702123165130615
Epoch: 57, Steps: 64 | Train Loss: 0.4008133 Vali Loss: 1.3110293 Test Loss: 0.4923910
Validation loss decreased (1.312397 --> 1.311029).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.4579317569732666
Epoch: 58, Steps: 64 | Train Loss: 0.4009656 Vali Loss: 1.3213681 Test Loss: 0.4922730
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.3223330974578857
Epoch: 59, Steps: 64 | Train Loss: 0.4008260 Vali Loss: 1.3162036 Test Loss: 0.4921623
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.428048849105835
Epoch: 60, Steps: 64 | Train Loss: 0.4007609 Vali Loss: 1.3232026 Test Loss: 0.4920620
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.4110782146453857
Epoch: 61, Steps: 64 | Train Loss: 0.4006520 Vali Loss: 1.3128724 Test Loss: 0.4919552
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.3841071128845215
Epoch: 62, Steps: 64 | Train Loss: 0.4002825 Vali Loss: 1.3166263 Test Loss: 0.4918614
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.3544886112213135
Epoch: 63, Steps: 64 | Train Loss: 0.4002854 Vali Loss: 1.3216436 Test Loss: 0.4917766
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.4541869163513184
Epoch: 64, Steps: 64 | Train Loss: 0.4001870 Vali Loss: 1.3170735 Test Loss: 0.4916839
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.46146559715271
Epoch: 65, Steps: 64 | Train Loss: 0.4001390 Vali Loss: 1.3138419 Test Loss: 0.4916106
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.4529390335083008
Epoch: 66, Steps: 64 | Train Loss: 0.4003424 Vali Loss: 1.3157694 Test Loss: 0.4915373
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.2647063732147217
Epoch: 67, Steps: 64 | Train Loss: 0.3998938 Vali Loss: 1.3168582 Test Loss: 0.4914680
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.4436347484588623
Epoch: 68, Steps: 64 | Train Loss: 0.3999341 Vali Loss: 1.3099958 Test Loss: 0.4913945
Validation loss decreased (1.311029 --> 1.309996).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.3918628692626953
Epoch: 69, Steps: 64 | Train Loss: 0.4000023 Vali Loss: 1.3124863 Test Loss: 0.4913277
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.3464610576629639
Epoch: 70, Steps: 64 | Train Loss: 0.3999064 Vali Loss: 1.3203475 Test Loss: 0.4912637
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.4497807025909424
Epoch: 71, Steps: 64 | Train Loss: 0.3997779 Vali Loss: 1.3169044 Test Loss: 0.4912075
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.4351866245269775
Epoch: 72, Steps: 64 | Train Loss: 0.3996066 Vali Loss: 1.3207775 Test Loss: 0.4911464
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.4326462745666504
Epoch: 73, Steps: 64 | Train Loss: 0.3995328 Vali Loss: 1.3153929 Test Loss: 0.4910938
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.5034081935882568
Epoch: 74, Steps: 64 | Train Loss: 0.3996572 Vali Loss: 1.3169739 Test Loss: 0.4910365
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.3190383911132812
Epoch: 75, Steps: 64 | Train Loss: 0.3995143 Vali Loss: 1.3106481 Test Loss: 0.4909912
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.3686518669128418
Epoch: 76, Steps: 64 | Train Loss: 0.3995275 Vali Loss: 1.3060051 Test Loss: 0.4909441
Validation loss decreased (1.309996 --> 1.306005).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.4326155185699463
Epoch: 77, Steps: 64 | Train Loss: 0.3993794 Vali Loss: 1.3177665 Test Loss: 0.4908964
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.4212114810943604
Epoch: 78, Steps: 64 | Train Loss: 0.3993929 Vali Loss: 1.3098507 Test Loss: 0.4908555
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.309086799621582
Epoch: 79, Steps: 64 | Train Loss: 0.3994441 Vali Loss: 1.3093549 Test Loss: 0.4908149
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.4579927921295166
Epoch: 80, Steps: 64 | Train Loss: 0.3992542 Vali Loss: 1.3158071 Test Loss: 0.4907762
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.3913555145263672
Epoch: 81, Steps: 64 | Train Loss: 0.3991960 Vali Loss: 1.3152385 Test Loss: 0.4907436
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.4426465034484863
Epoch: 82, Steps: 64 | Train Loss: 0.3994708 Vali Loss: 1.3119122 Test Loss: 0.4907066
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.469233512878418
Epoch: 83, Steps: 64 | Train Loss: 0.3992774 Vali Loss: 1.3129580 Test Loss: 0.4906736
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.3273332118988037
Epoch: 84, Steps: 64 | Train Loss: 0.3993931 Vali Loss: 1.3113718 Test Loss: 0.4906398
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.3567898273468018
Epoch: 85, Steps: 64 | Train Loss: 0.3992685 Vali Loss: 1.3124442 Test Loss: 0.4906102
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.291919231414795
Epoch: 86, Steps: 64 | Train Loss: 0.3991957 Vali Loss: 1.3092129 Test Loss: 0.4905819
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.418473243713379
Epoch: 87, Steps: 64 | Train Loss: 0.3993086 Vali Loss: 1.3109491 Test Loss: 0.4905551
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.3775875568389893
Epoch: 88, Steps: 64 | Train Loss: 0.3991224 Vali Loss: 1.3099818 Test Loss: 0.4905294
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.4865105152130127
Epoch: 89, Steps: 64 | Train Loss: 0.3991179 Vali Loss: 1.3170694 Test Loss: 0.4905039
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.4028394222259521
Epoch: 90, Steps: 64 | Train Loss: 0.3990285 Vali Loss: 1.3176006 Test Loss: 0.4904813
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.3327772617340088
Epoch: 91, Steps: 64 | Train Loss: 0.3988852 Vali Loss: 1.3108633 Test Loss: 0.4904551
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.3980391025543213
Epoch: 92, Steps: 64 | Train Loss: 0.3988362 Vali Loss: 1.3144693 Test Loss: 0.4904339
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.3808133602142334
Epoch: 93, Steps: 64 | Train Loss: 0.3989146 Vali Loss: 1.3074144 Test Loss: 0.4904158
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.9615120887756348
Epoch: 94, Steps: 64 | Train Loss: 0.3988977 Vali Loss: 1.3183535 Test Loss: 0.4903947
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.4559459686279297
Epoch: 95, Steps: 64 | Train Loss: 0.3989774 Vali Loss: 1.3116031 Test Loss: 0.4903761
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.4866626262664795
Epoch: 96, Steps: 64 | Train Loss: 0.3988889 Vali Loss: 1.3121067 Test Loss: 0.4903595
EarlyStopping counter: 20 out of 20
Early stopping
train 8215
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=22, out_features=104, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2050048.0
params:  2392.0
Trainable parameters:  2392
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.3856918811798096
Epoch: 1, Steps: 64 | Train Loss: 0.4951716 Vali Loss: 1.3024539 Test Loss: 0.4870974
Validation loss decreased (inf --> 1.302454).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.4190740585327148
Epoch: 2, Steps: 64 | Train Loss: 0.4915845 Vali Loss: 1.3058521 Test Loss: 0.4850779
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.3479933738708496
Epoch: 3, Steps: 64 | Train Loss: 0.4900117 Vali Loss: 1.2996732 Test Loss: 0.4839678
Validation loss decreased (1.302454 --> 1.299673).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.4541988372802734
Epoch: 4, Steps: 64 | Train Loss: 0.4893629 Vali Loss: 1.2986053 Test Loss: 0.4830657
Validation loss decreased (1.299673 --> 1.298605).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.344301462173462
Epoch: 5, Steps: 64 | Train Loss: 0.4882873 Vali Loss: 1.3003372 Test Loss: 0.4830441
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.3185701370239258
Epoch: 6, Steps: 64 | Train Loss: 0.4878854 Vali Loss: 1.2943850 Test Loss: 0.4826778
Validation loss decreased (1.298605 --> 1.294385).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.3182086944580078
Epoch: 7, Steps: 64 | Train Loss: 0.4876805 Vali Loss: 1.2959872 Test Loss: 0.4827752
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.3043243885040283
Epoch: 8, Steps: 64 | Train Loss: 0.4870493 Vali Loss: 1.2936510 Test Loss: 0.4825988
Validation loss decreased (1.294385 --> 1.293651).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.3043491840362549
Epoch: 9, Steps: 64 | Train Loss: 0.4871426 Vali Loss: 1.2950855 Test Loss: 0.4826924
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.328042984008789
Epoch: 10, Steps: 64 | Train Loss: 0.4869391 Vali Loss: 1.2928215 Test Loss: 0.4826465
Validation loss decreased (1.293651 --> 1.292822).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.296839952468872
Epoch: 11, Steps: 64 | Train Loss: 0.4870384 Vali Loss: 1.2953120 Test Loss: 0.4825787
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.270453691482544
Epoch: 12, Steps: 64 | Train Loss: 0.4870093 Vali Loss: 1.2959629 Test Loss: 0.4826206
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.302771806716919
Epoch: 13, Steps: 64 | Train Loss: 0.4870304 Vali Loss: 1.2920626 Test Loss: 0.4826594
Validation loss decreased (1.292822 --> 1.292063).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.3604497909545898
Epoch: 14, Steps: 64 | Train Loss: 0.4868245 Vali Loss: 1.2989061 Test Loss: 0.4827085
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.380690336227417
Epoch: 15, Steps: 64 | Train Loss: 0.4868697 Vali Loss: 1.2966509 Test Loss: 0.4828336
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.4610652923583984
Epoch: 16, Steps: 64 | Train Loss: 0.4870910 Vali Loss: 1.2950248 Test Loss: 0.4828704
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.3540356159210205
Epoch: 17, Steps: 64 | Train Loss: 0.4866039 Vali Loss: 1.2988423 Test Loss: 0.4828463
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.474919319152832
Epoch: 18, Steps: 64 | Train Loss: 0.4866573 Vali Loss: 1.2964115 Test Loss: 0.4829050
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.408820390701294
Epoch: 19, Steps: 64 | Train Loss: 0.4865401 Vali Loss: 1.2954468 Test Loss: 0.4828947
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.3480608463287354
Epoch: 20, Steps: 64 | Train Loss: 0.4867242 Vali Loss: 1.2906154 Test Loss: 0.4829744
Validation loss decreased (1.292063 --> 1.290615).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.3059933185577393
Epoch: 21, Steps: 64 | Train Loss: 0.4868659 Vali Loss: 1.2976816 Test Loss: 0.4830754
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.3465824127197266
Epoch: 22, Steps: 64 | Train Loss: 0.4868134 Vali Loss: 1.2879310 Test Loss: 0.4830303
Validation loss decreased (1.290615 --> 1.287931).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.3873662948608398
Epoch: 23, Steps: 64 | Train Loss: 0.4870793 Vali Loss: 1.2945395 Test Loss: 0.4830943
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.4689967632293701
Epoch: 24, Steps: 64 | Train Loss: 0.4867302 Vali Loss: 1.2954266 Test Loss: 0.4830811
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.406437635421753
Epoch: 25, Steps: 64 | Train Loss: 0.4866934 Vali Loss: 1.2893554 Test Loss: 0.4830886
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.4060978889465332
Epoch: 26, Steps: 64 | Train Loss: 0.4866752 Vali Loss: 1.2917732 Test Loss: 0.4831500
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.2733731269836426
Epoch: 27, Steps: 64 | Train Loss: 0.4868202 Vali Loss: 1.2912213 Test Loss: 0.4831246
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.3768706321716309
Epoch: 28, Steps: 64 | Train Loss: 0.4867385 Vali Loss: 1.2913591 Test Loss: 0.4831243
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.3897080421447754
Epoch: 29, Steps: 64 | Train Loss: 0.4868050 Vali Loss: 1.2956420 Test Loss: 0.4831992
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.3771159648895264
Epoch: 30, Steps: 64 | Train Loss: 0.4865035 Vali Loss: 1.2937663 Test Loss: 0.4832138
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.327519416809082
Epoch: 31, Steps: 64 | Train Loss: 0.4865903 Vali Loss: 1.2888378 Test Loss: 0.4832686
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.3028337955474854
Epoch: 32, Steps: 64 | Train Loss: 0.4865671 Vali Loss: 1.2964237 Test Loss: 0.4832278
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.4085941314697266
Epoch: 33, Steps: 64 | Train Loss: 0.4867706 Vali Loss: 1.2995706 Test Loss: 0.4832808
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.3586890697479248
Epoch: 34, Steps: 64 | Train Loss: 0.4865099 Vali Loss: 1.2862571 Test Loss: 0.4832515
Validation loss decreased (1.287931 --> 1.286257).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.347233533859253
Epoch: 35, Steps: 64 | Train Loss: 0.4867389 Vali Loss: 1.2938401 Test Loss: 0.4832186
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.478475570678711
Epoch: 36, Steps: 64 | Train Loss: 0.4867419 Vali Loss: 1.2960688 Test Loss: 0.4832613
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.4467015266418457
Epoch: 37, Steps: 64 | Train Loss: 0.4868363 Vali Loss: 1.2996130 Test Loss: 0.4832537
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.3961787223815918
Epoch: 38, Steps: 64 | Train Loss: 0.4866629 Vali Loss: 1.2899067 Test Loss: 0.4832942
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.3798861503601074
Epoch: 39, Steps: 64 | Train Loss: 0.4864496 Vali Loss: 1.2930658 Test Loss: 0.4833069
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.3584063053131104
Epoch: 40, Steps: 64 | Train Loss: 0.4869609 Vali Loss: 1.2916688 Test Loss: 0.4832918
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.435727596282959
Epoch: 41, Steps: 64 | Train Loss: 0.4867832 Vali Loss: 1.2941504 Test Loss: 0.4833011
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.9755163192749023
Epoch: 42, Steps: 64 | Train Loss: 0.4863541 Vali Loss: 1.2869062 Test Loss: 0.4833115
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.4423260688781738
Epoch: 43, Steps: 64 | Train Loss: 0.4867893 Vali Loss: 1.2941908 Test Loss: 0.4833359
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.3487753868103027
Epoch: 44, Steps: 64 | Train Loss: 0.4866078 Vali Loss: 1.2937046 Test Loss: 0.4833695
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.3900160789489746
Epoch: 45, Steps: 64 | Train Loss: 0.4865063 Vali Loss: 1.2944450 Test Loss: 0.4833492
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.361194133758545
Epoch: 46, Steps: 64 | Train Loss: 0.4865839 Vali Loss: 1.2858720 Test Loss: 0.4833401
Validation loss decreased (1.286257 --> 1.285872).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.3834433555603027
Epoch: 47, Steps: 64 | Train Loss: 0.4866771 Vali Loss: 1.2908070 Test Loss: 0.4833355
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.4306764602661133
Epoch: 48, Steps: 64 | Train Loss: 0.4865295 Vali Loss: 1.2901536 Test Loss: 0.4833561
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.3559882640838623
Epoch: 49, Steps: 64 | Train Loss: 0.4864548 Vali Loss: 1.2926359 Test Loss: 0.4833618
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.4099583625793457
Epoch: 50, Steps: 64 | Train Loss: 0.4863480 Vali Loss: 1.2926298 Test Loss: 0.4833776
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.4522194862365723
Epoch: 51, Steps: 64 | Train Loss: 0.4864078 Vali Loss: 1.2979773 Test Loss: 0.4833714
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.3186945915222168
Epoch: 52, Steps: 64 | Train Loss: 0.4868690 Vali Loss: 1.2950841 Test Loss: 0.4833717
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.4665803909301758
Epoch: 53, Steps: 64 | Train Loss: 0.4867690 Vali Loss: 1.2897149 Test Loss: 0.4833848
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.4408862590789795
Epoch: 54, Steps: 64 | Train Loss: 0.4865776 Vali Loss: 1.2928569 Test Loss: 0.4833893
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.434208869934082
Epoch: 55, Steps: 64 | Train Loss: 0.4866622 Vali Loss: 1.2958636 Test Loss: 0.4833979
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.3787305355072021
Epoch: 56, Steps: 64 | Train Loss: 0.4865891 Vali Loss: 1.2915589 Test Loss: 0.4833905
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.4360876083374023
Epoch: 57, Steps: 64 | Train Loss: 0.4865334 Vali Loss: 1.2929054 Test Loss: 0.4834258
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.5532853603363037
Epoch: 58, Steps: 64 | Train Loss: 0.4863340 Vali Loss: 1.2890775 Test Loss: 0.4834108
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.3403441905975342
Epoch: 59, Steps: 64 | Train Loss: 0.4866530 Vali Loss: 1.2945663 Test Loss: 0.4834235
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.5481481552124023
Epoch: 60, Steps: 64 | Train Loss: 0.4864070 Vali Loss: 1.2962803 Test Loss: 0.4834183
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.3823084831237793
Epoch: 61, Steps: 64 | Train Loss: 0.4865769 Vali Loss: 1.2911514 Test Loss: 0.4834228
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.4281542301177979
Epoch: 62, Steps: 64 | Train Loss: 0.4864876 Vali Loss: 1.2939113 Test Loss: 0.4834133
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.370065689086914
Epoch: 63, Steps: 64 | Train Loss: 0.4864542 Vali Loss: 1.2959056 Test Loss: 0.4834312
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.270702600479126
Epoch: 64, Steps: 64 | Train Loss: 0.4866014 Vali Loss: 1.2905188 Test Loss: 0.4834330
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.292353630065918
Epoch: 65, Steps: 64 | Train Loss: 0.4865372 Vali Loss: 1.2928532 Test Loss: 0.4834285
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.3387997150421143
Epoch: 66, Steps: 64 | Train Loss: 0.4863710 Vali Loss: 1.2916833 Test Loss: 0.4834321
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_90_336_FITS_ETTh1_ftM_sl90_ll48_pl336_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.48287373781204224, mae:0.447449654340744, rse:0.6615594029426575, corr:[0.2521634  0.2547858  0.25390473 0.2525497  0.24980849 0.24739505
 0.24671777 0.24614252 0.2455324  0.24550411 0.24531671 0.24525817
 0.24486263 0.24429916 0.24415576 0.24418728 0.24426727 0.24446142
 0.24449596 0.24433605 0.2438642  0.24362062 0.24342301 0.24292916
 0.24129118 0.24040996 0.24063064 0.24099714 0.24077977 0.24066237
 0.2410243  0.24099214 0.24073714 0.24046534 0.2401395  0.24012358
 0.2400798  0.239892   0.2400267  0.24025665 0.24060518 0.24108446
 0.24156097 0.24164036 0.24156724 0.24151203 0.24156775 0.24119824
 0.23973317 0.23868558 0.23819804 0.23763606 0.2364708  0.23540294
 0.23549259 0.23526864 0.23482023 0.23487814 0.23473154 0.2345793
 0.23431896 0.23425794 0.23428252 0.2339745  0.23389053 0.23429656
 0.2350124  0.23524006 0.23490588 0.234693   0.23461758 0.2337998
 0.23197144 0.2308792  0.23042299 0.2301912  0.22978008 0.22962373
 0.23008718 0.22979073 0.22929065 0.22911729 0.22894795 0.22855386
 0.22821638 0.22824802 0.22857675 0.22846462 0.22824292 0.22846422
 0.22882006 0.22886705 0.22867586 0.2288535  0.2292339  0.22888988
 0.22754169 0.22697742 0.22706869 0.22673765 0.22643955 0.22658761
 0.22718324 0.22702973 0.22652835 0.22641872 0.22634755 0.22598562
 0.22555253 0.22535451 0.2256689  0.22574371 0.22582929 0.22594617
 0.22629865 0.22656465 0.22659183 0.2266335  0.22650732 0.22556454
 0.22359477 0.22223432 0.22145632 0.22053102 0.21988371 0.22001874
 0.22100957 0.22120859 0.22085707 0.22073852 0.22062653 0.22033212
 0.2198594  0.2195727  0.21971917 0.21966714 0.21971695 0.21983093
 0.22009645 0.22039013 0.22042023 0.22056109 0.22064073 0.21990411
 0.21802801 0.21682575 0.21642946 0.21563461 0.21474522 0.21472825
 0.21581033 0.21597387 0.2157172  0.2156618  0.21562093 0.21547496
 0.21510427 0.21479726 0.2147031  0.2146088  0.2146104  0.2147142
 0.21499348 0.21527927 0.21533598 0.21541493 0.21532843 0.21441692
 0.2126878  0.21192901 0.21200489 0.21175398 0.21081178 0.21061312
 0.21153265 0.2115659  0.21118356 0.2112243  0.21143167 0.21135803
 0.21104383 0.21068883 0.21057913 0.2103809  0.21039987 0.21093778
 0.21156313 0.21187302 0.21206619 0.21243517 0.2126395  0.21189244
 0.20990053 0.20901789 0.20892282 0.20850137 0.20777512 0.20783229
 0.20864093 0.20875654 0.20842563 0.20817752 0.20786966 0.20765066
 0.20739338 0.20720942 0.20716733 0.20697767 0.20693856 0.20711452
 0.20745291 0.20768373 0.20763488 0.2077216  0.20774694 0.20704344
 0.20538814 0.20470037 0.20499393 0.20529467 0.20555429 0.20655552
 0.20822583 0.20894338 0.2091013  0.20895778 0.20842838 0.20816574
 0.20818822 0.20804414 0.20797259 0.20790118 0.20785762 0.2078532
 0.20802888 0.20827235 0.20846479 0.20876054 0.2089562  0.20819765
 0.2063788  0.20528965 0.2050242  0.2048363  0.20471433 0.20537092
 0.20681886 0.20741655 0.20760433 0.20764947 0.2072809  0.20671342
 0.20621124 0.2058649  0.20581283 0.20563024 0.20545445 0.20553143
 0.20598078 0.20629442 0.20622341 0.20608608 0.20619509 0.20566998
 0.20403348 0.20330517 0.20348333 0.20381002 0.20395944 0.20482828
 0.2063834  0.2069006  0.20678388 0.20683059 0.20677379 0.2063838
 0.20587064 0.20560445 0.20553385 0.20544904 0.20533712 0.20553638
 0.20594256 0.20624162 0.20641857 0.20670734 0.20698735 0.20646499
 0.20509279 0.20462869 0.2054928  0.20611769 0.20617111 0.20684557
 0.208212   0.20849013 0.2083388  0.20819528 0.20794277 0.20759593
 0.20709498 0.20670621 0.20664689 0.20647675 0.20645878 0.2064989
 0.20678395 0.20711981 0.20726077 0.20727247 0.20717931 0.20618407
 0.20446393 0.20344755 0.20335233 0.2031619  0.20309125 0.20338485
 0.2046365  0.20477971 0.20430067 0.20406815 0.20383883 0.20349838
 0.20306402 0.20283605 0.20285876 0.20300657 0.20286773 0.20285062
 0.20335956 0.20381856 0.2033531  0.20264247 0.20327565 0.20457277]
