Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_90_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_90_336_FITS_ETTh1_ftM_sl90_ll48_pl336_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8215
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=26, out_features=123, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2865408.0
params:  3321.0
Trainable parameters:  3321
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.0446341037750244
Epoch: 1, Steps: 64 | Train Loss: 0.9962124 Vali Loss: 2.1719456 Test Loss: 1.1549002
Validation loss decreased (inf --> 2.171946).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.7005200386047363
Epoch: 2, Steps: 64 | Train Loss: 0.7750888 Vali Loss: 1.8778880 Test Loss: 0.9060068
Validation loss decreased (2.171946 --> 1.877888).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.749276876449585
Epoch: 3, Steps: 64 | Train Loss: 0.6503500 Vali Loss: 1.7102054 Test Loss: 0.7700335
Validation loss decreased (1.877888 --> 1.710205).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.4093711376190186
Epoch: 4, Steps: 64 | Train Loss: 0.5758764 Vali Loss: 1.6002771 Test Loss: 0.6890624
Validation loss decreased (1.710205 --> 1.600277).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.798175811767578
Epoch: 5, Steps: 64 | Train Loss: 0.5286269 Vali Loss: 1.5335264 Test Loss: 0.6368338
Validation loss decreased (1.600277 --> 1.533526).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.1731069087982178
Epoch: 6, Steps: 64 | Train Loss: 0.4969710 Vali Loss: 1.4885825 Test Loss: 0.6020630
Validation loss decreased (1.533526 --> 1.488582).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.5076746940612793
Epoch: 7, Steps: 64 | Train Loss: 0.4753347 Vali Loss: 1.4549366 Test Loss: 0.5777915
Validation loss decreased (1.488582 --> 1.454937).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.911349296569824
Epoch: 8, Steps: 64 | Train Loss: 0.4597851 Vali Loss: 1.4316633 Test Loss: 0.5602658
Validation loss decreased (1.454937 --> 1.431663).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.0694401264190674
Epoch: 9, Steps: 64 | Train Loss: 0.4491497 Vali Loss: 1.4153676 Test Loss: 0.5471739
Validation loss decreased (1.431663 --> 1.415368).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 4.272199630737305
Epoch: 10, Steps: 64 | Train Loss: 0.4405864 Vali Loss: 1.4026443 Test Loss: 0.5372600
Validation loss decreased (1.415368 --> 1.402644).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.1025307178497314
Epoch: 11, Steps: 64 | Train Loss: 0.4340962 Vali Loss: 1.3800761 Test Loss: 0.5296838
Validation loss decreased (1.402644 --> 1.380076).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.9656524658203125
Epoch: 12, Steps: 64 | Train Loss: 0.4290229 Vali Loss: 1.3823128 Test Loss: 0.5235158
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.5212671756744385
Epoch: 13, Steps: 64 | Train Loss: 0.4250845 Vali Loss: 1.3728195 Test Loss: 0.5186189
Validation loss decreased (1.380076 --> 1.372820).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.7653322219848633
Epoch: 14, Steps: 64 | Train Loss: 0.4219911 Vali Loss: 1.3607141 Test Loss: 0.5147576
Validation loss decreased (1.372820 --> 1.360714).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.2708590030670166
Epoch: 15, Steps: 64 | Train Loss: 0.4191096 Vali Loss: 1.3582243 Test Loss: 0.5114700
Validation loss decreased (1.360714 --> 1.358224).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.5109457969665527
Epoch: 16, Steps: 64 | Train Loss: 0.4168723 Vali Loss: 1.3549294 Test Loss: 0.5086997
Validation loss decreased (1.358224 --> 1.354929).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.320535898208618
Epoch: 17, Steps: 64 | Train Loss: 0.4149285 Vali Loss: 1.3533996 Test Loss: 0.5064510
Validation loss decreased (1.354929 --> 1.353400).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.9478600025177002
Epoch: 18, Steps: 64 | Train Loss: 0.4133683 Vali Loss: 1.3420045 Test Loss: 0.5045959
Validation loss decreased (1.353400 --> 1.342005).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.7129805088043213
Epoch: 19, Steps: 64 | Train Loss: 0.4116711 Vali Loss: 1.3454314 Test Loss: 0.5029010
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.0982420444488525
Epoch: 20, Steps: 64 | Train Loss: 0.4107043 Vali Loss: 1.3422499 Test Loss: 0.5014505
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.6455917358398438
Epoch: 21, Steps: 64 | Train Loss: 0.4095722 Vali Loss: 1.3385141 Test Loss: 0.5002009
Validation loss decreased (1.342005 --> 1.338514).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.95162034034729
Epoch: 22, Steps: 64 | Train Loss: 0.4084730 Vali Loss: 1.3345606 Test Loss: 0.4991641
Validation loss decreased (1.338514 --> 1.334561).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.456584930419922
Epoch: 23, Steps: 64 | Train Loss: 0.4078176 Vali Loss: 1.3323101 Test Loss: 0.4982163
Validation loss decreased (1.334561 --> 1.332310).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.6569249629974365
Epoch: 24, Steps: 64 | Train Loss: 0.4070155 Vali Loss: 1.3325168 Test Loss: 0.4973800
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 3.462907552719116
Epoch: 25, Steps: 64 | Train Loss: 0.4062910 Vali Loss: 1.3254255 Test Loss: 0.4966527
Validation loss decreased (1.332310 --> 1.325426).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.8277320861816406
Epoch: 26, Steps: 64 | Train Loss: 0.4055338 Vali Loss: 1.3311603 Test Loss: 0.4959874
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.9997143745422363
Epoch: 27, Steps: 64 | Train Loss: 0.4048892 Vali Loss: 1.3296092 Test Loss: 0.4954221
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.11008620262146
Epoch: 28, Steps: 64 | Train Loss: 0.4044576 Vali Loss: 1.3223405 Test Loss: 0.4948821
Validation loss decreased (1.325426 --> 1.322340).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.391718626022339
Epoch: 29, Steps: 64 | Train Loss: 0.4041275 Vali Loss: 1.3263023 Test Loss: 0.4944125
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.300372838973999
Epoch: 30, Steps: 64 | Train Loss: 0.4034789 Vali Loss: 1.3254818 Test Loss: 0.4939578
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.8016009330749512
Epoch: 31, Steps: 64 | Train Loss: 0.4031186 Vali Loss: 1.3233603 Test Loss: 0.4935768
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.639915943145752
Epoch: 32, Steps: 64 | Train Loss: 0.4026013 Vali Loss: 1.3248262 Test Loss: 0.4932273
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.416621208190918
Epoch: 33, Steps: 64 | Train Loss: 0.4025554 Vali Loss: 1.3179848 Test Loss: 0.4928977
Validation loss decreased (1.322340 --> 1.317985).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.0217485427856445
Epoch: 34, Steps: 64 | Train Loss: 0.4021586 Vali Loss: 1.3211573 Test Loss: 0.4925911
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.511458158493042
Epoch: 35, Steps: 64 | Train Loss: 0.4016674 Vali Loss: 1.3211106 Test Loss: 0.4923195
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.5021729469299316
Epoch: 36, Steps: 64 | Train Loss: 0.4015942 Vali Loss: 1.3180245 Test Loss: 0.4920429
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.1858749389648438
Epoch: 37, Steps: 64 | Train Loss: 0.4013279 Vali Loss: 1.3183161 Test Loss: 0.4918296
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.355292797088623
Epoch: 38, Steps: 64 | Train Loss: 0.4009582 Vali Loss: 1.3103644 Test Loss: 0.4916160
Validation loss decreased (1.317985 --> 1.310364).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.672590732574463
Epoch: 39, Steps: 64 | Train Loss: 0.4004703 Vali Loss: 1.3188146 Test Loss: 0.4914113
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.9877190589904785
Epoch: 40, Steps: 64 | Train Loss: 0.4006671 Vali Loss: 1.3190089 Test Loss: 0.4912093
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.9671778678894043
Epoch: 41, Steps: 64 | Train Loss: 0.4003707 Vali Loss: 1.3194644 Test Loss: 0.4910015
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 3.1359944343566895
Epoch: 42, Steps: 64 | Train Loss: 0.4001565 Vali Loss: 1.3191838 Test Loss: 0.4908664
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.4499573707580566
Epoch: 43, Steps: 64 | Train Loss: 0.3999405 Vali Loss: 1.3200178 Test Loss: 0.4906968
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 4.394791126251221
Epoch: 44, Steps: 64 | Train Loss: 0.3999666 Vali Loss: 1.3099972 Test Loss: 0.4905446
Validation loss decreased (1.310364 --> 1.309997).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.2300124168395996
Epoch: 45, Steps: 64 | Train Loss: 0.3995775 Vali Loss: 1.3131189 Test Loss: 0.4904188
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.3861756324768066
Epoch: 46, Steps: 64 | Train Loss: 0.3994844 Vali Loss: 1.3099818 Test Loss: 0.4902746
Validation loss decreased (1.309997 --> 1.309982).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.1195855140686035
Epoch: 47, Steps: 64 | Train Loss: 0.3994125 Vali Loss: 1.3169776 Test Loss: 0.4901480
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.5439510345458984
Epoch: 48, Steps: 64 | Train Loss: 0.3990381 Vali Loss: 1.3107151 Test Loss: 0.4900497
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.8156521320343018
Epoch: 49, Steps: 64 | Train Loss: 0.3989993 Vali Loss: 1.3185084 Test Loss: 0.4899291
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.2214107513427734
Epoch: 50, Steps: 64 | Train Loss: 0.3988821 Vali Loss: 1.3160506 Test Loss: 0.4898379
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.183593511581421
Epoch: 51, Steps: 64 | Train Loss: 0.3988706 Vali Loss: 1.3186915 Test Loss: 0.4897282
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.879194498062134
Epoch: 52, Steps: 64 | Train Loss: 0.3987503 Vali Loss: 1.3153741 Test Loss: 0.4896365
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.9972608089447021
Epoch: 53, Steps: 64 | Train Loss: 0.3984362 Vali Loss: 1.3129145 Test Loss: 0.4895411
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.3041930198669434
Epoch: 54, Steps: 64 | Train Loss: 0.3985222 Vali Loss: 1.3162588 Test Loss: 0.4894582
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.4432408809661865
Epoch: 55, Steps: 64 | Train Loss: 0.3984525 Vali Loss: 1.3164161 Test Loss: 0.4893695
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.340684413909912
Epoch: 56, Steps: 64 | Train Loss: 0.3982030 Vali Loss: 1.3155112 Test Loss: 0.4893004
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.4251620769500732
Epoch: 57, Steps: 64 | Train Loss: 0.3983081 Vali Loss: 1.3140775 Test Loss: 0.4892362
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.2834739685058594
Epoch: 58, Steps: 64 | Train Loss: 0.3981620 Vali Loss: 1.3115767 Test Loss: 0.4891666
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.7812743186950684
Epoch: 59, Steps: 64 | Train Loss: 0.3980859 Vali Loss: 1.3104607 Test Loss: 0.4891004
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 4.346968173980713
Epoch: 60, Steps: 64 | Train Loss: 0.3980471 Vali Loss: 1.3187698 Test Loss: 0.4890360
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 4.372510671615601
Epoch: 61, Steps: 64 | Train Loss: 0.3979816 Vali Loss: 1.3104937 Test Loss: 0.4889692
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 4.88036847114563
Epoch: 62, Steps: 64 | Train Loss: 0.3977480 Vali Loss: 1.3097411 Test Loss: 0.4889106
Validation loss decreased (1.309982 --> 1.309741).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.6904640197753906
Epoch: 63, Steps: 64 | Train Loss: 0.3977755 Vali Loss: 1.3159268 Test Loss: 0.4888561
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 3.068535804748535
Epoch: 64, Steps: 64 | Train Loss: 0.3978921 Vali Loss: 1.3096520 Test Loss: 0.4888075
Validation loss decreased (1.309741 --> 1.309652).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.4973576068878174
Epoch: 65, Steps: 64 | Train Loss: 0.3976916 Vali Loss: 1.3161939 Test Loss: 0.4887587
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.7918479442596436
Epoch: 66, Steps: 64 | Train Loss: 0.3974364 Vali Loss: 1.3156012 Test Loss: 0.4887149
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 4.350712060928345
Epoch: 67, Steps: 64 | Train Loss: 0.3977067 Vali Loss: 1.3136851 Test Loss: 0.4886685
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 3.0824716091156006
Epoch: 68, Steps: 64 | Train Loss: 0.3976201 Vali Loss: 1.3105017 Test Loss: 0.4886267
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 3.2902591228485107
Epoch: 69, Steps: 64 | Train Loss: 0.3973134 Vali Loss: 1.3152035 Test Loss: 0.4885840
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.810131549835205
Epoch: 70, Steps: 64 | Train Loss: 0.3973109 Vali Loss: 1.3148483 Test Loss: 0.4885441
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.1970455646514893
Epoch: 71, Steps: 64 | Train Loss: 0.3973771 Vali Loss: 1.3183714 Test Loss: 0.4885173
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.8633754253387451
Epoch: 72, Steps: 64 | Train Loss: 0.3973090 Vali Loss: 1.3087258 Test Loss: 0.4884793
Validation loss decreased (1.309652 --> 1.308726).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.055615186691284
Epoch: 73, Steps: 64 | Train Loss: 0.3971189 Vali Loss: 1.3098842 Test Loss: 0.4884431
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.744279146194458
Epoch: 74, Steps: 64 | Train Loss: 0.3973488 Vali Loss: 1.3110059 Test Loss: 0.4884137
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.840925693511963
Epoch: 75, Steps: 64 | Train Loss: 0.3972770 Vali Loss: 1.3127947 Test Loss: 0.4883816
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.007234811782837
Epoch: 76, Steps: 64 | Train Loss: 0.3971836 Vali Loss: 1.3089046 Test Loss: 0.4883531
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 3.2977232933044434
Epoch: 77, Steps: 64 | Train Loss: 0.3970485 Vali Loss: 1.3095442 Test Loss: 0.4883259
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.6874163150787354
Epoch: 78, Steps: 64 | Train Loss: 0.3972557 Vali Loss: 1.3108602 Test Loss: 0.4883025
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.54880952835083
Epoch: 79, Steps: 64 | Train Loss: 0.3969283 Vali Loss: 1.3104151 Test Loss: 0.4882743
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.9196276664733887
Epoch: 80, Steps: 64 | Train Loss: 0.3969082 Vali Loss: 1.3128920 Test Loss: 0.4882495
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.9729595184326172
Epoch: 81, Steps: 64 | Train Loss: 0.3969739 Vali Loss: 1.3102679 Test Loss: 0.4882240
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 2.2583365440368652
Epoch: 82, Steps: 64 | Train Loss: 0.3970596 Vali Loss: 1.3076507 Test Loss: 0.4882030
Validation loss decreased (1.308726 --> 1.307651).  Saving model ...
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.9828073978424072
Epoch: 83, Steps: 64 | Train Loss: 0.3968420 Vali Loss: 1.3171594 Test Loss: 0.4881805
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.4030981063842773
Epoch: 84, Steps: 64 | Train Loss: 0.3970086 Vali Loss: 1.3139508 Test Loss: 0.4881600
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.731022834777832
Epoch: 85, Steps: 64 | Train Loss: 0.3969412 Vali Loss: 1.3087666 Test Loss: 0.4881430
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.8318688869476318
Epoch: 86, Steps: 64 | Train Loss: 0.3970031 Vali Loss: 1.3076887 Test Loss: 0.4881245
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.73502779006958
Epoch: 87, Steps: 64 | Train Loss: 0.3967971 Vali Loss: 1.3068519 Test Loss: 0.4881070
Validation loss decreased (1.307651 --> 1.306852).  Saving model ...
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 2.1539361476898193
Epoch: 88, Steps: 64 | Train Loss: 0.3970068 Vali Loss: 1.3089063 Test Loss: 0.4880899
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.639131546020508
Epoch: 89, Steps: 64 | Train Loss: 0.3968225 Vali Loss: 1.3072673 Test Loss: 0.4880758
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 2.1913399696350098
Epoch: 90, Steps: 64 | Train Loss: 0.3967575 Vali Loss: 1.3109416 Test Loss: 0.4880574
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.8462753295898438
Epoch: 91, Steps: 64 | Train Loss: 0.3966590 Vali Loss: 1.3103566 Test Loss: 0.4880432
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 2.8591694831848145
Epoch: 92, Steps: 64 | Train Loss: 0.3967261 Vali Loss: 1.3117241 Test Loss: 0.4880297
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 2.2729616165161133
Epoch: 93, Steps: 64 | Train Loss: 0.3966503 Vali Loss: 1.3164359 Test Loss: 0.4880166
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 2.441645860671997
Epoch: 94, Steps: 64 | Train Loss: 0.3966454 Vali Loss: 1.3120106 Test Loss: 0.4880038
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 2.5930745601654053
Epoch: 95, Steps: 64 | Train Loss: 0.3967637 Vali Loss: 1.3160334 Test Loss: 0.4879932
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 3.8715896606445312
Epoch: 96, Steps: 64 | Train Loss: 0.3968366 Vali Loss: 1.3126460 Test Loss: 0.4879819
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 3.2361273765563965
Epoch: 97, Steps: 64 | Train Loss: 0.3967055 Vali Loss: 1.3111981 Test Loss: 0.4879719
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 2.488943099975586
Epoch: 98, Steps: 64 | Train Loss: 0.3969918 Vali Loss: 1.3089384 Test Loss: 0.4879617
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 3.054009199142456
Epoch: 99, Steps: 64 | Train Loss: 0.3968382 Vali Loss: 1.3097386 Test Loss: 0.4879521
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 2.955362319946289
Epoch: 100, Steps: 64 | Train Loss: 0.3965301 Vali Loss: 1.3091319 Test Loss: 0.4879420
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8215
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=26, out_features=123, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2865408.0
params:  3321.0
Trainable parameters:  3321
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.4125208854675293
Epoch: 1, Steps: 64 | Train Loss: 0.4935346 Vali Loss: 1.3034967 Test Loss: 0.4851031
Validation loss decreased (inf --> 1.303497).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.824022054672241
Epoch: 2, Steps: 64 | Train Loss: 0.4908682 Vali Loss: 1.2979254 Test Loss: 0.4832027
Validation loss decreased (1.303497 --> 1.297925).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.594027519226074
Epoch: 3, Steps: 64 | Train Loss: 0.4891882 Vali Loss: 1.2958620 Test Loss: 0.4821722
Validation loss decreased (1.297925 --> 1.295862).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.9978489875793457
Epoch: 4, Steps: 64 | Train Loss: 0.4878148 Vali Loss: 1.2980356 Test Loss: 0.4818782
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.1271257400512695
Epoch: 5, Steps: 64 | Train Loss: 0.4870076 Vali Loss: 1.2966359 Test Loss: 0.4816357
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.7635064125061035
Epoch: 6, Steps: 64 | Train Loss: 0.4872495 Vali Loss: 1.2962244 Test Loss: 0.4816997
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 5.380997896194458
Epoch: 7, Steps: 64 | Train Loss: 0.4869493 Vali Loss: 1.2958604 Test Loss: 0.4817239
Validation loss decreased (1.295862 --> 1.295860).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.5500357151031494
Epoch: 8, Steps: 64 | Train Loss: 0.4864614 Vali Loss: 1.2953972 Test Loss: 0.4817851
Validation loss decreased (1.295860 --> 1.295397).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.976323127746582
Epoch: 9, Steps: 64 | Train Loss: 0.4867773 Vali Loss: 1.2980105 Test Loss: 0.4817534
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.464763641357422
Epoch: 10, Steps: 64 | Train Loss: 0.4864559 Vali Loss: 1.2918421 Test Loss: 0.4816893
Validation loss decreased (1.295397 --> 1.291842).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.220385789871216
Epoch: 11, Steps: 64 | Train Loss: 0.4863018 Vali Loss: 1.2958754 Test Loss: 0.4817117
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 5.03938102722168
Epoch: 12, Steps: 64 | Train Loss: 0.4863029 Vali Loss: 1.2958676 Test Loss: 0.4817556
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.5523316860198975
Epoch: 13, Steps: 64 | Train Loss: 0.4861352 Vali Loss: 1.2943984 Test Loss: 0.4819291
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.3070898056030273
Epoch: 14, Steps: 64 | Train Loss: 0.4864242 Vali Loss: 1.2897243 Test Loss: 0.4819461
Validation loss decreased (1.291842 --> 1.289724).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.6189138889312744
Epoch: 15, Steps: 64 | Train Loss: 0.4861099 Vali Loss: 1.2929026 Test Loss: 0.4819466
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.3436343669891357
Epoch: 16, Steps: 64 | Train Loss: 0.4863628 Vali Loss: 1.2937027 Test Loss: 0.4819533
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.6227147579193115
Epoch: 17, Steps: 64 | Train Loss: 0.4860746 Vali Loss: 1.2918599 Test Loss: 0.4820208
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.911482334136963
Epoch: 18, Steps: 64 | Train Loss: 0.4863603 Vali Loss: 1.2879758 Test Loss: 0.4820963
Validation loss decreased (1.289724 --> 1.287976).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.4844985008239746
Epoch: 19, Steps: 64 | Train Loss: 0.4861267 Vali Loss: 1.2951745 Test Loss: 0.4820924
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.7216122150421143
Epoch: 20, Steps: 64 | Train Loss: 0.4862255 Vali Loss: 1.2903061 Test Loss: 0.4821467
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.1864817142486572
Epoch: 21, Steps: 64 | Train Loss: 0.4859651 Vali Loss: 1.2935991 Test Loss: 0.4821860
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.8289976119995117
Epoch: 22, Steps: 64 | Train Loss: 0.4862512 Vali Loss: 1.3037648 Test Loss: 0.4822601
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.660517454147339
Epoch: 23, Steps: 64 | Train Loss: 0.4860020 Vali Loss: 1.2951332 Test Loss: 0.4822213
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.607679605484009
Epoch: 24, Steps: 64 | Train Loss: 0.4860641 Vali Loss: 1.2989295 Test Loss: 0.4822706
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.583256721496582
Epoch: 25, Steps: 64 | Train Loss: 0.4860691 Vali Loss: 1.2939775 Test Loss: 0.4823297
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.4437758922576904
Epoch: 26, Steps: 64 | Train Loss: 0.4861715 Vali Loss: 1.2908481 Test Loss: 0.4823084
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.352175235748291
Epoch: 27, Steps: 64 | Train Loss: 0.4860574 Vali Loss: 1.2903519 Test Loss: 0.4823297
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.5522713661193848
Epoch: 28, Steps: 64 | Train Loss: 0.4861946 Vali Loss: 1.2951255 Test Loss: 0.4823101
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 3.609534740447998
Epoch: 29, Steps: 64 | Train Loss: 0.4859573 Vali Loss: 1.2925953 Test Loss: 0.4823784
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 3.5106687545776367
Epoch: 30, Steps: 64 | Train Loss: 0.4862494 Vali Loss: 1.2889177 Test Loss: 0.4823503
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.8570680618286133
Epoch: 31, Steps: 64 | Train Loss: 0.4859044 Vali Loss: 1.2899405 Test Loss: 0.4823937
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 3.4084396362304688
Epoch: 32, Steps: 64 | Train Loss: 0.4862050 Vali Loss: 1.2912574 Test Loss: 0.4823571
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.1426198482513428
Epoch: 33, Steps: 64 | Train Loss: 0.4856103 Vali Loss: 1.2922941 Test Loss: 0.4824487
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.086211681365967
Epoch: 34, Steps: 64 | Train Loss: 0.4862314 Vali Loss: 1.2952334 Test Loss: 0.4824203
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.2483582496643066
Epoch: 35, Steps: 64 | Train Loss: 0.4860340 Vali Loss: 1.2926835 Test Loss: 0.4824063
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.113884449005127
Epoch: 36, Steps: 64 | Train Loss: 0.4860956 Vali Loss: 1.2879094 Test Loss: 0.4824294
Validation loss decreased (1.287976 --> 1.287909).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.339127779006958
Epoch: 37, Steps: 64 | Train Loss: 0.4860374 Vali Loss: 1.2882057 Test Loss: 0.4824463
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.9458122253417969
Epoch: 38, Steps: 64 | Train Loss: 0.4859113 Vali Loss: 1.2961246 Test Loss: 0.4824498
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.800424098968506
Epoch: 39, Steps: 64 | Train Loss: 0.4863598 Vali Loss: 1.2909611 Test Loss: 0.4824513
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.470238208770752
Epoch: 40, Steps: 64 | Train Loss: 0.4858253 Vali Loss: 1.2964466 Test Loss: 0.4824832
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.7244110107421875
Epoch: 41, Steps: 64 | Train Loss: 0.4857847 Vali Loss: 1.2860619 Test Loss: 0.4824906
Validation loss decreased (1.287909 --> 1.286062).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.7339730262756348
Epoch: 42, Steps: 64 | Train Loss: 0.4861115 Vali Loss: 1.2981850 Test Loss: 0.4824667
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.837714433670044
Epoch: 43, Steps: 64 | Train Loss: 0.4862312 Vali Loss: 1.2867723 Test Loss: 0.4824943
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.7508599758148193
Epoch: 44, Steps: 64 | Train Loss: 0.4861865 Vali Loss: 1.2923758 Test Loss: 0.4824860
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.435497522354126
Epoch: 45, Steps: 64 | Train Loss: 0.4860073 Vali Loss: 1.2927214 Test Loss: 0.4824850
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.7507150173187256
Epoch: 46, Steps: 64 | Train Loss: 0.4860036 Vali Loss: 1.2900975 Test Loss: 0.4825169
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.766634702682495
Epoch: 47, Steps: 64 | Train Loss: 0.4861769 Vali Loss: 1.2903953 Test Loss: 0.4825536
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 5.583935499191284
Epoch: 48, Steps: 64 | Train Loss: 0.4860538 Vali Loss: 1.2955940 Test Loss: 0.4825379
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 4.302157640457153
Epoch: 49, Steps: 64 | Train Loss: 0.4858357 Vali Loss: 1.2937164 Test Loss: 0.4825280
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 4.138779640197754
Epoch: 50, Steps: 64 | Train Loss: 0.4858551 Vali Loss: 1.2923563 Test Loss: 0.4825298
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 3.6599907875061035
Epoch: 51, Steps: 64 | Train Loss: 0.4861299 Vali Loss: 1.2910604 Test Loss: 0.4825482
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.9786794185638428
Epoch: 52, Steps: 64 | Train Loss: 0.4860184 Vali Loss: 1.2905091 Test Loss: 0.4825403
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.714810371398926
Epoch: 53, Steps: 64 | Train Loss: 0.4854848 Vali Loss: 1.2937752 Test Loss: 0.4825312
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.784717082977295
Epoch: 54, Steps: 64 | Train Loss: 0.4860090 Vali Loss: 1.2958523 Test Loss: 0.4825736
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.7068159580230713
Epoch: 55, Steps: 64 | Train Loss: 0.4860209 Vali Loss: 1.2947595 Test Loss: 0.4825369
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 4.778415203094482
Epoch: 56, Steps: 64 | Train Loss: 0.4861778 Vali Loss: 1.2895880 Test Loss: 0.4825542
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.76584792137146
Epoch: 57, Steps: 64 | Train Loss: 0.4857786 Vali Loss: 1.2946773 Test Loss: 0.4825630
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 3.0151824951171875
Epoch: 58, Steps: 64 | Train Loss: 0.4857924 Vali Loss: 1.2984265 Test Loss: 0.4825768
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.503847599029541
Epoch: 59, Steps: 64 | Train Loss: 0.4858287 Vali Loss: 1.2950784 Test Loss: 0.4825795
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.8958303928375244
Epoch: 60, Steps: 64 | Train Loss: 0.4860170 Vali Loss: 1.2956145 Test Loss: 0.4825657
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 3.282831907272339
Epoch: 61, Steps: 64 | Train Loss: 0.4857138 Vali Loss: 1.2926563 Test Loss: 0.4825739
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_90_336_FITS_ETTh1_ftM_sl90_ll48_pl336_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.4820306897163391, mae:0.44652169942855835, rse:0.6609815955162048, corr:[0.25292587 0.25486603 0.25329244 0.25335494 0.250524   0.24745806
 0.24700849 0.24664089 0.24583544 0.24593462 0.24601592 0.24532224
 0.24494073 0.24488321 0.24445881 0.24437997 0.2447328  0.2447018
 0.24470223 0.24475011 0.24430339 0.24395038 0.24362564 0.24331729
 0.24172923 0.24062723 0.24079835 0.24133998 0.2410891  0.24099748
 0.24156484 0.24145047 0.24093527 0.24073042 0.2406042  0.2403303
 0.2402222  0.24028972 0.24036884 0.24044132 0.24089985 0.2413297
 0.24178445 0.24198025 0.24193777 0.24183038 0.24179554 0.2415192
 0.24030192 0.23918094 0.23843902 0.23787017 0.2368915  0.23594496
 0.23591356 0.235617   0.2352425  0.23533188 0.23514822 0.23495467
 0.23472837 0.23476835 0.23469687 0.23439668 0.23451684 0.23477992
 0.23528415 0.23559445 0.23534769 0.23513865 0.235005   0.23425145
 0.2325188  0.23132032 0.23068772 0.23059621 0.23026986 0.23009753
 0.23052163 0.23026508 0.22980896 0.22951733 0.22934477 0.22903916
 0.22863069 0.2286117  0.22891603 0.22879441 0.2286983  0.22891198
 0.22917683 0.22927353 0.22907169 0.22915313 0.22945678 0.22923492
 0.22812122 0.22748107 0.22722912 0.22693902 0.22695142 0.22711217
 0.22744955 0.2273015  0.22702329 0.22685258 0.22658075 0.2263015
 0.22601223 0.22582732 0.22606257 0.22607927 0.22625932 0.22634059
 0.22656627 0.2269077  0.226979   0.22695525 0.22685032 0.22603159
 0.22418417 0.22271188 0.22169094 0.22082712 0.2205154  0.22064252
 0.22132781 0.22157775 0.22149056 0.22129162 0.22088796 0.22069399
 0.22037752 0.22004366 0.22012448 0.22003722 0.22016154 0.22024496
 0.22038496 0.2207487  0.22081685 0.22087263 0.22098446 0.22030212
 0.21846008 0.21720171 0.2167338  0.21600461 0.21530278 0.21529208
 0.21610133 0.21622726 0.21619688 0.21612974 0.21586531 0.21581468
 0.21557891 0.2151835  0.2150467  0.21497498 0.2149761  0.21500333
 0.21525936 0.21563599 0.21570577 0.2156784  0.21563783 0.21485646
 0.2131368  0.21216726 0.2121114  0.21194285 0.21125174 0.2110957
 0.21182854 0.21179235 0.21156774 0.2115929  0.21158458 0.21162298
 0.2115096  0.21105693 0.21089572 0.21075898 0.21075708 0.2111569
 0.2117252  0.2121521  0.21246229 0.21269406 0.21277219 0.21213743
 0.21036397 0.20942514 0.20910604 0.20859134 0.2080483  0.20832671
 0.2090714  0.20903918 0.20875055 0.20849061 0.2079871  0.20777826
 0.2076576  0.20741725 0.20734604 0.20728959 0.20731036 0.20734623
 0.20759079 0.20790812 0.20793499 0.20796718 0.20791057 0.20727798
 0.20581396 0.2050758  0.20520064 0.20545332 0.20587881 0.2070353
 0.20859781 0.20919415 0.20946956 0.20935047 0.20862783 0.20842315
 0.2086009  0.20831949 0.2081259  0.20817491 0.20825069 0.20817916
 0.2082703  0.20852908 0.20876725 0.20905405 0.2092033  0.20843683
 0.20668313 0.20554788 0.20527154 0.20508453 0.20500635 0.20576425
 0.20714694 0.20758015 0.2078436  0.2079871  0.2074762  0.20695804
 0.2066504  0.2061423  0.20593002 0.2058891  0.20579709 0.20577486
 0.20619154 0.2064995  0.20639797 0.20632112 0.20648733 0.20604147
 0.2044285  0.2035469  0.20357487 0.2039714  0.20420575 0.2051501
 0.20673315 0.20716831 0.2071404  0.20731655 0.2070542  0.2065611
 0.20635289 0.20608807 0.20566757 0.20560986 0.20578454 0.20592284
 0.20618367 0.20650679 0.20665704 0.20690762 0.20722555 0.20674494
 0.20536107 0.20481248 0.20563345 0.20636675 0.20645982 0.20718127
 0.20854597 0.20868433 0.20847228 0.20839    0.20806639 0.20762213
 0.20736715 0.20706512 0.20665132 0.20639491 0.20675427 0.20681675
 0.20690425 0.20723349 0.2074381  0.20755254 0.20754087 0.2065019
 0.20480444 0.20379266 0.20341894 0.20334859 0.20360826 0.20377752
 0.20480464 0.20500156 0.20486553 0.204841   0.20430806 0.2035593
 0.2034151  0.20363565 0.20317279 0.20282134 0.20318085 0.20355363
 0.2035013  0.20363419 0.20371859 0.20313768 0.20314431 0.20441382]
