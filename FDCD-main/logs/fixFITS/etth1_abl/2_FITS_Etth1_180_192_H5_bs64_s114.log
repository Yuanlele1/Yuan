Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=50, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_180_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_180_192_FITS_ETTh1_ftM_sl180_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8269
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=50, out_features=103, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4614400.0
params:  5253.0
Trainable parameters:  5253
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.7621066570281982
Epoch: 1, Steps: 64 | Train Loss: 0.6943687 Vali Loss: 1.6399015 Test Loss: 0.8665592
Validation loss decreased (inf --> 1.639902).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.6893203258514404
Epoch: 2, Steps: 64 | Train Loss: 0.5341326 Vali Loss: 1.4344594 Test Loss: 0.7309498
Validation loss decreased (1.639902 --> 1.434459).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.0018601417541504
Epoch: 3, Steps: 64 | Train Loss: 0.4477798 Vali Loss: 1.3159467 Test Loss: 0.6536861
Validation loss decreased (1.434459 --> 1.315947).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.5571582317352295
Epoch: 4, Steps: 64 | Train Loss: 0.3946006 Vali Loss: 1.2399786 Test Loss: 0.6045638
Validation loss decreased (1.315947 --> 1.239979).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.033015012741089
Epoch: 5, Steps: 64 | Train Loss: 0.3595887 Vali Loss: 1.1889989 Test Loss: 0.5725159
Validation loss decreased (1.239979 --> 1.188999).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.7490448951721191
Epoch: 6, Steps: 64 | Train Loss: 0.3352194 Vali Loss: 1.1530485 Test Loss: 0.5504919
Validation loss decreased (1.188999 --> 1.153049).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.6117796897888184
Epoch: 7, Steps: 64 | Train Loss: 0.3175523 Vali Loss: 1.1282316 Test Loss: 0.5349122
Validation loss decreased (1.153049 --> 1.128232).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.6593105792999268
Epoch: 8, Steps: 64 | Train Loss: 0.3042839 Vali Loss: 1.1075327 Test Loss: 0.5227271
Validation loss decreased (1.128232 --> 1.107533).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.285210371017456
Epoch: 9, Steps: 64 | Train Loss: 0.2942443 Vali Loss: 1.0931441 Test Loss: 0.5140599
Validation loss decreased (1.107533 --> 1.093144).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.228550672531128
Epoch: 10, Steps: 64 | Train Loss: 0.2862463 Vali Loss: 1.0803628 Test Loss: 0.5068553
Validation loss decreased (1.093144 --> 1.080363).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.0276906490325928
Epoch: 11, Steps: 64 | Train Loss: 0.2800776 Vali Loss: 1.0709949 Test Loss: 0.5011437
Validation loss decreased (1.080363 --> 1.070995).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.3411178588867188
Epoch: 12, Steps: 64 | Train Loss: 0.2744496 Vali Loss: 1.0630643 Test Loss: 0.4962931
Validation loss decreased (1.070995 --> 1.063064).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.2279155254364014
Epoch: 13, Steps: 64 | Train Loss: 0.2697270 Vali Loss: 1.0563803 Test Loss: 0.4924225
Validation loss decreased (1.063064 --> 1.056380).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.5746355056762695
Epoch: 14, Steps: 64 | Train Loss: 0.2660074 Vali Loss: 1.0505742 Test Loss: 0.4885546
Validation loss decreased (1.056380 --> 1.050574).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 4.1388561725616455
Epoch: 15, Steps: 64 | Train Loss: 0.2629328 Vali Loss: 1.0455892 Test Loss: 0.4854452
Validation loss decreased (1.050574 --> 1.045589).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.839756727218628
Epoch: 16, Steps: 64 | Train Loss: 0.2601533 Vali Loss: 1.0410745 Test Loss: 0.4827430
Validation loss decreased (1.045589 --> 1.041075).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.174794912338257
Epoch: 17, Steps: 64 | Train Loss: 0.2575146 Vali Loss: 1.0371979 Test Loss: 0.4803980
Validation loss decreased (1.041075 --> 1.037198).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.9340052604675293
Epoch: 18, Steps: 64 | Train Loss: 0.2552881 Vali Loss: 1.0330787 Test Loss: 0.4780582
Validation loss decreased (1.037198 --> 1.033079).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.447267532348633
Epoch: 19, Steps: 64 | Train Loss: 0.2533860 Vali Loss: 1.0297118 Test Loss: 0.4760613
Validation loss decreased (1.033079 --> 1.029712).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.1124610900878906
Epoch: 20, Steps: 64 | Train Loss: 0.2513530 Vali Loss: 1.0279185 Test Loss: 0.4743538
Validation loss decreased (1.029712 --> 1.027918).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.834613561630249
Epoch: 21, Steps: 64 | Train Loss: 0.2501107 Vali Loss: 1.0252256 Test Loss: 0.4725252
Validation loss decreased (1.027918 --> 1.025226).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.606546401977539
Epoch: 22, Steps: 64 | Train Loss: 0.2485875 Vali Loss: 1.0223535 Test Loss: 0.4710747
Validation loss decreased (1.025226 --> 1.022354).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.049375534057617
Epoch: 23, Steps: 64 | Train Loss: 0.2472941 Vali Loss: 1.0200858 Test Loss: 0.4695191
Validation loss decreased (1.022354 --> 1.020086).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.5675442218780518
Epoch: 24, Steps: 64 | Train Loss: 0.2462244 Vali Loss: 1.0184877 Test Loss: 0.4682035
Validation loss decreased (1.020086 --> 1.018488).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.390226364135742
Epoch: 25, Steps: 64 | Train Loss: 0.2447152 Vali Loss: 1.0163027 Test Loss: 0.4670037
Validation loss decreased (1.018488 --> 1.016303).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.0532772541046143
Epoch: 26, Steps: 64 | Train Loss: 0.2442358 Vali Loss: 1.0148138 Test Loss: 0.4658008
Validation loss decreased (1.016303 --> 1.014814).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.5667166709899902
Epoch: 27, Steps: 64 | Train Loss: 0.2431466 Vali Loss: 1.0133435 Test Loss: 0.4648433
Validation loss decreased (1.014814 --> 1.013343).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.210554361343384
Epoch: 28, Steps: 64 | Train Loss: 0.2423543 Vali Loss: 1.0119388 Test Loss: 0.4638260
Validation loss decreased (1.013343 --> 1.011939).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.221083879470825
Epoch: 29, Steps: 64 | Train Loss: 0.2416977 Vali Loss: 1.0107003 Test Loss: 0.4628924
Validation loss decreased (1.011939 --> 1.010700).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.198270797729492
Epoch: 30, Steps: 64 | Train Loss: 0.2408825 Vali Loss: 1.0086691 Test Loss: 0.4621016
Validation loss decreased (1.010700 --> 1.008669).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 3.254971981048584
Epoch: 31, Steps: 64 | Train Loss: 0.2401300 Vali Loss: 1.0081298 Test Loss: 0.4613042
Validation loss decreased (1.008669 --> 1.008130).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.7632133960723877
Epoch: 32, Steps: 64 | Train Loss: 0.2396772 Vali Loss: 1.0068928 Test Loss: 0.4604428
Validation loss decreased (1.008130 --> 1.006893).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.7521071434020996
Epoch: 33, Steps: 64 | Train Loss: 0.2389897 Vali Loss: 1.0063711 Test Loss: 0.4598037
Validation loss decreased (1.006893 --> 1.006371).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.7990899085998535
Epoch: 34, Steps: 64 | Train Loss: 0.2385368 Vali Loss: 1.0054621 Test Loss: 0.4591359
Validation loss decreased (1.006371 --> 1.005462).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 3.3929436206817627
Epoch: 35, Steps: 64 | Train Loss: 0.2382257 Vali Loss: 1.0044307 Test Loss: 0.4585539
Validation loss decreased (1.005462 --> 1.004431).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.3182549476623535
Epoch: 36, Steps: 64 | Train Loss: 0.2377301 Vali Loss: 1.0036131 Test Loss: 0.4579929
Validation loss decreased (1.004431 --> 1.003613).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.405526876449585
Epoch: 37, Steps: 64 | Train Loss: 0.2374366 Vali Loss: 1.0026374 Test Loss: 0.4574912
Validation loss decreased (1.003613 --> 1.002637).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.8959298133850098
Epoch: 38, Steps: 64 | Train Loss: 0.2367490 Vali Loss: 1.0021185 Test Loss: 0.4569676
Validation loss decreased (1.002637 --> 1.002118).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.531956434249878
Epoch: 39, Steps: 64 | Train Loss: 0.2365379 Vali Loss: 1.0016073 Test Loss: 0.4564336
Validation loss decreased (1.002118 --> 1.001607).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.503451347351074
Epoch: 40, Steps: 64 | Train Loss: 0.2361694 Vali Loss: 1.0009551 Test Loss: 0.4560641
Validation loss decreased (1.001607 --> 1.000955).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.4285976886749268
Epoch: 41, Steps: 64 | Train Loss: 0.2359216 Vali Loss: 0.9997579 Test Loss: 0.4556728
Validation loss decreased (1.000955 --> 0.999758).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.5138869285583496
Epoch: 42, Steps: 64 | Train Loss: 0.2355206 Vali Loss: 0.9997458 Test Loss: 0.4552465
Validation loss decreased (0.999758 --> 0.999746).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.7036190032958984
Epoch: 43, Steps: 64 | Train Loss: 0.2352486 Vali Loss: 0.9992490 Test Loss: 0.4548827
Validation loss decreased (0.999746 --> 0.999249).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.005516290664673
Epoch: 44, Steps: 64 | Train Loss: 0.2349600 Vali Loss: 0.9986409 Test Loss: 0.4545275
Validation loss decreased (0.999249 --> 0.998641).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.8519811630249023
Epoch: 45, Steps: 64 | Train Loss: 0.2347490 Vali Loss: 0.9980859 Test Loss: 0.4541877
Validation loss decreased (0.998641 --> 0.998086).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.8648443222045898
Epoch: 46, Steps: 64 | Train Loss: 0.2344880 Vali Loss: 0.9977033 Test Loss: 0.4538715
Validation loss decreased (0.998086 --> 0.997703).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.6760931015014648
Epoch: 47, Steps: 64 | Train Loss: 0.2342799 Vali Loss: 0.9972842 Test Loss: 0.4535324
Validation loss decreased (0.997703 --> 0.997284).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.8931431770324707
Epoch: 48, Steps: 64 | Train Loss: 0.2340979 Vali Loss: 0.9967383 Test Loss: 0.4532908
Validation loss decreased (0.997284 --> 0.996738).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.9238505363464355
Epoch: 49, Steps: 64 | Train Loss: 0.2336718 Vali Loss: 0.9963935 Test Loss: 0.4530150
Validation loss decreased (0.996738 --> 0.996394).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.1020138263702393
Epoch: 50, Steps: 64 | Train Loss: 0.2335753 Vali Loss: 0.9959002 Test Loss: 0.4527396
Validation loss decreased (0.996394 --> 0.995900).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 3.4524097442626953
Epoch: 51, Steps: 64 | Train Loss: 0.2334742 Vali Loss: 0.9959029 Test Loss: 0.4525596
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.533543348312378
Epoch: 52, Steps: 64 | Train Loss: 0.2332655 Vali Loss: 0.9956230 Test Loss: 0.4523623
Validation loss decreased (0.995900 --> 0.995623).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.8902950286865234
Epoch: 53, Steps: 64 | Train Loss: 0.2332805 Vali Loss: 0.9953272 Test Loss: 0.4521389
Validation loss decreased (0.995623 --> 0.995327).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.8563268184661865
Epoch: 54, Steps: 64 | Train Loss: 0.2329828 Vali Loss: 0.9946948 Test Loss: 0.4519265
Validation loss decreased (0.995327 --> 0.994695).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 3.5383636951446533
Epoch: 55, Steps: 64 | Train Loss: 0.2327062 Vali Loss: 0.9947484 Test Loss: 0.4517389
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.7932538986206055
Epoch: 56, Steps: 64 | Train Loss: 0.2326261 Vali Loss: 0.9941327 Test Loss: 0.4515684
Validation loss decreased (0.994695 --> 0.994133).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.5968756675720215
Epoch: 57, Steps: 64 | Train Loss: 0.2325988 Vali Loss: 0.9938585 Test Loss: 0.4513971
Validation loss decreased (0.994133 --> 0.993859).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.717003583908081
Epoch: 58, Steps: 64 | Train Loss: 0.2324081 Vali Loss: 0.9940380 Test Loss: 0.4512352
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.153610944747925
Epoch: 59, Steps: 64 | Train Loss: 0.2322042 Vali Loss: 0.9939036 Test Loss: 0.4510906
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 3.279287815093994
Epoch: 60, Steps: 64 | Train Loss: 0.2322902 Vali Loss: 0.9934804 Test Loss: 0.4509420
Validation loss decreased (0.993859 --> 0.993480).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.3321948051452637
Epoch: 61, Steps: 64 | Train Loss: 0.2324411 Vali Loss: 0.9929955 Test Loss: 0.4508082
Validation loss decreased (0.993480 --> 0.992996).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.134533643722534
Epoch: 62, Steps: 64 | Train Loss: 0.2321321 Vali Loss: 0.9933777 Test Loss: 0.4506582
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.9320423603057861
Epoch: 63, Steps: 64 | Train Loss: 0.2319204 Vali Loss: 0.9930985 Test Loss: 0.4505398
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.3750572204589844
Epoch: 64, Steps: 64 | Train Loss: 0.2317888 Vali Loss: 0.9922177 Test Loss: 0.4504281
Validation loss decreased (0.992996 --> 0.992218).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.702913522720337
Epoch: 65, Steps: 64 | Train Loss: 0.2315952 Vali Loss: 0.9926496 Test Loss: 0.4503361
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.3296124935150146
Epoch: 66, Steps: 64 | Train Loss: 0.2316193 Vali Loss: 0.9923932 Test Loss: 0.4502259
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.5114319324493408
Epoch: 67, Steps: 64 | Train Loss: 0.2314287 Vali Loss: 0.9924273 Test Loss: 0.4501079
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.8211555480957031
Epoch: 68, Steps: 64 | Train Loss: 0.2312914 Vali Loss: 0.9920308 Test Loss: 0.4500028
Validation loss decreased (0.992218 --> 0.992031).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.5890376567840576
Epoch: 69, Steps: 64 | Train Loss: 0.2313053 Vali Loss: 0.9917001 Test Loss: 0.4499311
Validation loss decreased (0.992031 --> 0.991700).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.1752588748931885
Epoch: 70, Steps: 64 | Train Loss: 0.2315101 Vali Loss: 0.9915217 Test Loss: 0.4498519
Validation loss decreased (0.991700 --> 0.991522).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.6711108684539795
Epoch: 71, Steps: 64 | Train Loss: 0.2313262 Vali Loss: 0.9919469 Test Loss: 0.4497552
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 3.5287177562713623
Epoch: 72, Steps: 64 | Train Loss: 0.2310307 Vali Loss: 0.9918601 Test Loss: 0.4496843
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 4.925433397293091
Epoch: 73, Steps: 64 | Train Loss: 0.2311505 Vali Loss: 0.9906527 Test Loss: 0.4496102
Validation loss decreased (0.991522 --> 0.990653).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.7188360691070557
Epoch: 74, Steps: 64 | Train Loss: 0.2312727 Vali Loss: 0.9911770 Test Loss: 0.4495444
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.7638399600982666
Epoch: 75, Steps: 64 | Train Loss: 0.2310183 Vali Loss: 0.9915413 Test Loss: 0.4494597
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 4.850203275680542
Epoch: 76, Steps: 64 | Train Loss: 0.2309986 Vali Loss: 0.9908931 Test Loss: 0.4494169
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.4965875148773193
Epoch: 77, Steps: 64 | Train Loss: 0.2310171 Vali Loss: 0.9912647 Test Loss: 0.4493475
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 4.074369192123413
Epoch: 78, Steps: 64 | Train Loss: 0.2309789 Vali Loss: 0.9907575 Test Loss: 0.4492973
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 3.563061475753784
Epoch: 79, Steps: 64 | Train Loss: 0.2309356 Vali Loss: 0.9911047 Test Loss: 0.4492436
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.498889446258545
Epoch: 80, Steps: 64 | Train Loss: 0.2308851 Vali Loss: 0.9903117 Test Loss: 0.4491849
Validation loss decreased (0.990653 --> 0.990312).  Saving model ...
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.3632726669311523
Epoch: 81, Steps: 64 | Train Loss: 0.2307105 Vali Loss: 0.9908233 Test Loss: 0.4491267
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.9613802433013916
Epoch: 82, Steps: 64 | Train Loss: 0.2304638 Vali Loss: 0.9910132 Test Loss: 0.4490838
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.0723841190338135
Epoch: 83, Steps: 64 | Train Loss: 0.2306261 Vali Loss: 0.9903288 Test Loss: 0.4490496
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.4520397186279297
Epoch: 84, Steps: 64 | Train Loss: 0.2306015 Vali Loss: 0.9905196 Test Loss: 0.4490111
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.405484676361084
Epoch: 85, Steps: 64 | Train Loss: 0.2305661 Vali Loss: 0.9903691 Test Loss: 0.4489647
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.7987043857574463
Epoch: 86, Steps: 64 | Train Loss: 0.2307278 Vali Loss: 0.9904860 Test Loss: 0.4489329
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.904040813446045
Epoch: 87, Steps: 64 | Train Loss: 0.2306965 Vali Loss: 0.9905862 Test Loss: 0.4488826
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.9323666095733643
Epoch: 88, Steps: 64 | Train Loss: 0.2305976 Vali Loss: 0.9906653 Test Loss: 0.4488578
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.0987184047698975
Epoch: 89, Steps: 64 | Train Loss: 0.2306070 Vali Loss: 0.9905217 Test Loss: 0.4488289
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 2.0904159545898438
Epoch: 90, Steps: 64 | Train Loss: 0.2305154 Vali Loss: 0.9904282 Test Loss: 0.4487964
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.6064014434814453
Epoch: 91, Steps: 64 | Train Loss: 0.2305765 Vali Loss: 0.9901119 Test Loss: 0.4487689
Validation loss decreased (0.990312 --> 0.990112).  Saving model ...
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 2.632305860519409
Epoch: 92, Steps: 64 | Train Loss: 0.2306150 Vali Loss: 0.9897262 Test Loss: 0.4487426
Validation loss decreased (0.990112 --> 0.989726).  Saving model ...
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.6222350597381592
Epoch: 93, Steps: 64 | Train Loss: 0.2303986 Vali Loss: 0.9903150 Test Loss: 0.4487216
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 2.319835662841797
Epoch: 94, Steps: 64 | Train Loss: 0.2302446 Vali Loss: 0.9899783 Test Loss: 0.4486940
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 2.6069910526275635
Epoch: 95, Steps: 64 | Train Loss: 0.2305951 Vali Loss: 0.9900686 Test Loss: 0.4486725
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 3.922093152999878
Epoch: 96, Steps: 64 | Train Loss: 0.2304661 Vali Loss: 0.9897865 Test Loss: 0.4486547
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 3.4346981048583984
Epoch: 97, Steps: 64 | Train Loss: 0.2303513 Vali Loss: 0.9893230 Test Loss: 0.4486315
Validation loss decreased (0.989726 --> 0.989323).  Saving model ...
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 4.117611646652222
Epoch: 98, Steps: 64 | Train Loss: 0.2302057 Vali Loss: 0.9903194 Test Loss: 0.4486151
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 2.8974618911743164
Epoch: 99, Steps: 64 | Train Loss: 0.2305609 Vali Loss: 0.9902722 Test Loss: 0.4485907
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 2.487419843673706
Epoch: 100, Steps: 64 | Train Loss: 0.2303462 Vali Loss: 0.9902710 Test Loss: 0.4485741
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8269
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=50, out_features=103, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4614400.0
params:  5253.0
Trainable parameters:  5253
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.3374781608581543
Epoch: 1, Steps: 64 | Train Loss: 0.4143131 Vali Loss: 0.9793467 Test Loss: 0.4390526
Validation loss decreased (inf --> 0.979347).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.8263182640075684
Epoch: 2, Steps: 64 | Train Loss: 0.4096236 Vali Loss: 0.9754125 Test Loss: 0.4356009
Validation loss decreased (0.979347 --> 0.975413).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.6759083271026611
Epoch: 3, Steps: 64 | Train Loss: 0.4080779 Vali Loss: 0.9733918 Test Loss: 0.4342815
Validation loss decreased (0.975413 --> 0.973392).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.7152256965637207
Epoch: 4, Steps: 64 | Train Loss: 0.4074185 Vali Loss: 0.9720353 Test Loss: 0.4343384
Validation loss decreased (0.973392 --> 0.972035).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.0470054149627686
Epoch: 5, Steps: 64 | Train Loss: 0.4062974 Vali Loss: 0.9716710 Test Loss: 0.4328876
Validation loss decreased (0.972035 --> 0.971671).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.934837818145752
Epoch: 6, Steps: 64 | Train Loss: 0.4063341 Vali Loss: 0.9712952 Test Loss: 0.4332910
Validation loss decreased (0.971671 --> 0.971295).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.6804125308990479
Epoch: 7, Steps: 64 | Train Loss: 0.4063436 Vali Loss: 0.9707698 Test Loss: 0.4329483
Validation loss decreased (0.971295 --> 0.970770).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.0085439682006836
Epoch: 8, Steps: 64 | Train Loss: 0.4062815 Vali Loss: 0.9704496 Test Loss: 0.4331943
Validation loss decreased (0.970770 --> 0.970450).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.832413911819458
Epoch: 9, Steps: 64 | Train Loss: 0.4065027 Vali Loss: 0.9705138 Test Loss: 0.4332520
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.797771692276001
Epoch: 10, Steps: 64 | Train Loss: 0.4061350 Vali Loss: 0.9699444 Test Loss: 0.4329439
Validation loss decreased (0.970450 --> 0.969944).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.7636468410491943
Epoch: 11, Steps: 64 | Train Loss: 0.4057942 Vali Loss: 0.9696593 Test Loss: 0.4330381
Validation loss decreased (0.969944 --> 0.969659).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.3893237113952637
Epoch: 12, Steps: 64 | Train Loss: 0.4058608 Vali Loss: 0.9692516 Test Loss: 0.4331282
Validation loss decreased (0.969659 --> 0.969252).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.98160982131958
Epoch: 13, Steps: 64 | Train Loss: 0.4059840 Vali Loss: 0.9699197 Test Loss: 0.4326144
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.994706392288208
Epoch: 14, Steps: 64 | Train Loss: 0.4057939 Vali Loss: 0.9695066 Test Loss: 0.4330832
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.7659761905670166
Epoch: 15, Steps: 64 | Train Loss: 0.4058934 Vali Loss: 0.9696628 Test Loss: 0.4330394
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.061224937438965
Epoch: 16, Steps: 64 | Train Loss: 0.4057078 Vali Loss: 0.9693474 Test Loss: 0.4335103
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.100149631500244
Epoch: 17, Steps: 64 | Train Loss: 0.4057831 Vali Loss: 0.9691178 Test Loss: 0.4332291
Validation loss decreased (0.969252 --> 0.969118).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.709604024887085
Epoch: 18, Steps: 64 | Train Loss: 0.4060052 Vali Loss: 0.9695714 Test Loss: 0.4330519
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 3.178392171859741
Epoch: 19, Steps: 64 | Train Loss: 0.4052088 Vali Loss: 0.9695945 Test Loss: 0.4332111
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.090201377868652
Epoch: 20, Steps: 64 | Train Loss: 0.4055309 Vali Loss: 0.9690549 Test Loss: 0.4333186
Validation loss decreased (0.969118 --> 0.969055).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.504228115081787
Epoch: 21, Steps: 64 | Train Loss: 0.4058029 Vali Loss: 0.9689028 Test Loss: 0.4329618
Validation loss decreased (0.969055 --> 0.968903).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.7999229431152344
Epoch: 22, Steps: 64 | Train Loss: 0.4054416 Vali Loss: 0.9691947 Test Loss: 0.4332755
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.282010316848755
Epoch: 23, Steps: 64 | Train Loss: 0.4054790 Vali Loss: 0.9690697 Test Loss: 0.4332248
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.0088112354278564
Epoch: 24, Steps: 64 | Train Loss: 0.4056711 Vali Loss: 0.9689264 Test Loss: 0.4333143
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.2596347332000732
Epoch: 25, Steps: 64 | Train Loss: 0.4053281 Vali Loss: 0.9694060 Test Loss: 0.4333398
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.09674072265625
Epoch: 26, Steps: 64 | Train Loss: 0.4054773 Vali Loss: 0.9690090 Test Loss: 0.4328755
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.8786203861236572
Epoch: 27, Steps: 64 | Train Loss: 0.4051217 Vali Loss: 0.9688913 Test Loss: 0.4331364
Validation loss decreased (0.968903 --> 0.968891).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.038163423538208
Epoch: 28, Steps: 64 | Train Loss: 0.4056322 Vali Loss: 0.9687645 Test Loss: 0.4333735
Validation loss decreased (0.968891 --> 0.968765).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.8493914604187012
Epoch: 29, Steps: 64 | Train Loss: 0.4053424 Vali Loss: 0.9684554 Test Loss: 0.4331425
Validation loss decreased (0.968765 --> 0.968455).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.2044434547424316
Epoch: 30, Steps: 64 | Train Loss: 0.4055522 Vali Loss: 0.9690524 Test Loss: 0.4332618
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.0738422870635986
Epoch: 31, Steps: 64 | Train Loss: 0.4056602 Vali Loss: 0.9686153 Test Loss: 0.4331042
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.932438850402832
Epoch: 32, Steps: 64 | Train Loss: 0.4054291 Vali Loss: 0.9687944 Test Loss: 0.4330810
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.816767930984497
Epoch: 33, Steps: 64 | Train Loss: 0.4049523 Vali Loss: 0.9685510 Test Loss: 0.4330877
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.5420174598693848
Epoch: 34, Steps: 64 | Train Loss: 0.4051648 Vali Loss: 0.9685629 Test Loss: 0.4331908
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.335374593734741
Epoch: 35, Steps: 64 | Train Loss: 0.4056160 Vali Loss: 0.9686289 Test Loss: 0.4332951
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 3.4086644649505615
Epoch: 36, Steps: 64 | Train Loss: 0.4053223 Vali Loss: 0.9689844 Test Loss: 0.4332152
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.563361644744873
Epoch: 37, Steps: 64 | Train Loss: 0.4056082 Vali Loss: 0.9688460 Test Loss: 0.4332038
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 3.5804836750030518
Epoch: 38, Steps: 64 | Train Loss: 0.4055552 Vali Loss: 0.9683314 Test Loss: 0.4331602
Validation loss decreased (0.968455 --> 0.968331).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 3.428971529006958
Epoch: 39, Steps: 64 | Train Loss: 0.4058490 Vali Loss: 0.9682333 Test Loss: 0.4332277
Validation loss decreased (0.968331 --> 0.968233).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.7598323822021484
Epoch: 40, Steps: 64 | Train Loss: 0.4053903 Vali Loss: 0.9688463 Test Loss: 0.4331530
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.13782000541687
Epoch: 41, Steps: 64 | Train Loss: 0.4046831 Vali Loss: 0.9690553 Test Loss: 0.4332393
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.2116458415985107
Epoch: 42, Steps: 64 | Train Loss: 0.4050960 Vali Loss: 0.9688752 Test Loss: 0.4331851
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.1822643280029297
Epoch: 43, Steps: 64 | Train Loss: 0.4052532 Vali Loss: 0.9683015 Test Loss: 0.4332291
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.742964267730713
Epoch: 44, Steps: 64 | Train Loss: 0.4048108 Vali Loss: 0.9689865 Test Loss: 0.4332991
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.338752269744873
Epoch: 45, Steps: 64 | Train Loss: 0.4052864 Vali Loss: 0.9688845 Test Loss: 0.4332014
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.524503707885742
Epoch: 46, Steps: 64 | Train Loss: 0.4056779 Vali Loss: 0.9685362 Test Loss: 0.4332449
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.6502182483673096
Epoch: 47, Steps: 64 | Train Loss: 0.4054048 Vali Loss: 0.9685974 Test Loss: 0.4331824
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.7426776885986328
Epoch: 48, Steps: 64 | Train Loss: 0.4049334 Vali Loss: 0.9685291 Test Loss: 0.4332151
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.9967126846313477
Epoch: 49, Steps: 64 | Train Loss: 0.4052856 Vali Loss: 0.9684147 Test Loss: 0.4331834
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.5502853393554688
Epoch: 50, Steps: 64 | Train Loss: 0.4055228 Vali Loss: 0.9686058 Test Loss: 0.4331809
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.224905014038086
Epoch: 51, Steps: 64 | Train Loss: 0.4054563 Vali Loss: 0.9689636 Test Loss: 0.4332346
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 3.031278371810913
Epoch: 52, Steps: 64 | Train Loss: 0.4055712 Vali Loss: 0.9685343 Test Loss: 0.4332324
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 3.340142011642456
Epoch: 53, Steps: 64 | Train Loss: 0.4055648 Vali Loss: 0.9685421 Test Loss: 0.4332720
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.1242527961730957
Epoch: 54, Steps: 64 | Train Loss: 0.4054781 Vali Loss: 0.9688243 Test Loss: 0.4332261
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.4880151748657227
Epoch: 55, Steps: 64 | Train Loss: 0.4054004 Vali Loss: 0.9687272 Test Loss: 0.4332352
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.572056770324707
Epoch: 56, Steps: 64 | Train Loss: 0.4050176 Vali Loss: 0.9688861 Test Loss: 0.4332191
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.873847007751465
Epoch: 57, Steps: 64 | Train Loss: 0.4051567 Vali Loss: 0.9683859 Test Loss: 0.4332212
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.9478211402893066
Epoch: 58, Steps: 64 | Train Loss: 0.4054511 Vali Loss: 0.9688667 Test Loss: 0.4331754
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 3.45135235786438
Epoch: 59, Steps: 64 | Train Loss: 0.4055263 Vali Loss: 0.9686704 Test Loss: 0.4332327
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_180_192_FITS_ETTh1_ftM_sl180_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.42660534381866455, mae:0.420268714427948, rse:0.6202552914619446, corr:[0.26371723 0.26926553 0.2692357  0.26828435 0.26632553 0.2636308
 0.26242915 0.26273865 0.26236498 0.2621617  0.2624632  0.26253527
 0.26218992 0.26152357 0.2612359  0.26136896 0.26152417 0.26145968
 0.2612033  0.26081723 0.26050586 0.26064536 0.2609     0.2606176
 0.25977328 0.2593428  0.25873837 0.2581482  0.25771615 0.25742534
 0.25701624 0.25670227 0.2566377  0.25657612 0.25653845 0.2569738
 0.2572617  0.25708148 0.2571921  0.25745603 0.25760886 0.25776598
 0.25802276 0.2581037  0.25804183 0.25831488 0.25895202 0.25888136
 0.2575821  0.25623912 0.25472707 0.2533752  0.252234   0.2511689
 0.25038576 0.25002778 0.25010836 0.25047547 0.250355   0.25085434
 0.2513498  0.25091925 0.25063902 0.25061476 0.25049883 0.250364
 0.25055942 0.25061306 0.2503835  0.2503386  0.2506166  0.25012645
 0.24874541 0.2476264  0.24653524 0.24583583 0.24562852 0.24544302
 0.24518113 0.2447442  0.24446233 0.24454294 0.2442753  0.2441969
 0.24450333 0.24440548 0.24449188 0.24457422 0.24434847 0.24416529
 0.24421948 0.24412517 0.2439262  0.24412516 0.24465509 0.24471174
 0.24397844 0.24339935 0.2427322  0.24182737 0.24143629 0.2412998
 0.24097244 0.24094522 0.24124353 0.2415991  0.24150771 0.24163382
 0.2417815  0.2413446  0.2411011  0.24128015 0.24142313 0.24143153
 0.241545   0.24169156 0.24160044 0.24155413 0.24167159 0.24128827
 0.24012963 0.23914953 0.23793252 0.23671539 0.23580317 0.23540069
 0.2352351  0.23530766 0.23556441 0.23589416 0.23588507 0.23637295
 0.23708735 0.23696703 0.23685019 0.23685057 0.23681454 0.23686878
 0.2371442  0.23729658 0.23714665 0.2372098  0.23743062 0.23701075
 0.23584932 0.23490995 0.23392427 0.23264042 0.23185398 0.23145297
 0.23134698 0.23139004 0.23185809 0.2322871  0.23223539 0.2326146
 0.23320642 0.23301649 0.2329392  0.23292807 0.23266193 0.23241849
 0.23250657 0.23258448 0.23237209 0.23239206 0.23271911 0.2323651
 0.23121044 0.23039328 0.22958605 0.2287359  0.22829768 0.22808492
 0.22812901 0.22862819 0.22920078 0.23003691 0.23047733 0.23107447
 0.23200005 0.23189607 0.23139486 0.23123378 0.2313571  0.23140147
 0.23126952 0.2315325  0.23169827 0.23139474 0.23181045 0.23227878]
