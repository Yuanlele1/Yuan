Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_360_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_360_336_FITS_ETTh1_ftM_sl360_ll48_pl336_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7945
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=106, out_features=204, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  19375104.0
params:  21828.0
Trainable parameters:  21828
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.2966463565826416
Epoch: 1, Steps: 62 | Train Loss: 0.7239753 Vali Loss: 1.7674171 Test Loss: 0.8384337
Validation loss decreased (inf --> 1.767417).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.1392691135406494
Epoch: 2, Steps: 62 | Train Loss: 0.5621630 Vali Loss: 1.5988277 Test Loss: 0.7325670
Validation loss decreased (1.767417 --> 1.598828).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.2256035804748535
Epoch: 3, Steps: 62 | Train Loss: 0.4861088 Vali Loss: 1.5209731 Test Loss: 0.6860572
Validation loss decreased (1.598828 --> 1.520973).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.2997512817382812
Epoch: 4, Steps: 62 | Train Loss: 0.4458537 Vali Loss: 1.4899203 Test Loss: 0.6640414
Validation loss decreased (1.520973 --> 1.489920).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.219245433807373
Epoch: 5, Steps: 62 | Train Loss: 0.4203086 Vali Loss: 1.4634143 Test Loss: 0.6473960
Validation loss decreased (1.489920 --> 1.463414).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.1910905838012695
Epoch: 6, Steps: 62 | Train Loss: 0.4014682 Vali Loss: 1.4401432 Test Loss: 0.6351979
Validation loss decreased (1.463414 --> 1.440143).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.2328741550445557
Epoch: 7, Steps: 62 | Train Loss: 0.3863796 Vali Loss: 1.4199666 Test Loss: 0.6239052
Validation loss decreased (1.440143 --> 1.419967).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.1534554958343506
Epoch: 8, Steps: 62 | Train Loss: 0.3735956 Vali Loss: 1.4100336 Test Loss: 0.6144557
Validation loss decreased (1.419967 --> 1.410034).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.19596266746521
Epoch: 9, Steps: 62 | Train Loss: 0.3626086 Vali Loss: 1.3997411 Test Loss: 0.6049479
Validation loss decreased (1.410034 --> 1.399741).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.2836005687713623
Epoch: 10, Steps: 62 | Train Loss: 0.3530794 Vali Loss: 1.3836730 Test Loss: 0.5961460
Validation loss decreased (1.399741 --> 1.383673).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.2406895160675049
Epoch: 11, Steps: 62 | Train Loss: 0.3445609 Vali Loss: 1.3761555 Test Loss: 0.5881819
Validation loss decreased (1.383673 --> 1.376155).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.2013249397277832
Epoch: 12, Steps: 62 | Train Loss: 0.3371322 Vali Loss: 1.3565983 Test Loss: 0.5810252
Validation loss decreased (1.376155 --> 1.356598).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.2185249328613281
Epoch: 13, Steps: 62 | Train Loss: 0.3303539 Vali Loss: 1.3496118 Test Loss: 0.5738699
Validation loss decreased (1.356598 --> 1.349612).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.1317689418792725
Epoch: 14, Steps: 62 | Train Loss: 0.3243930 Vali Loss: 1.3390216 Test Loss: 0.5676330
Validation loss decreased (1.349612 --> 1.339022).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.233201026916504
Epoch: 15, Steps: 62 | Train Loss: 0.3190616 Vali Loss: 1.3340133 Test Loss: 0.5613574
Validation loss decreased (1.339022 --> 1.334013).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.1259822845458984
Epoch: 16, Steps: 62 | Train Loss: 0.3142447 Vali Loss: 1.3263235 Test Loss: 0.5562542
Validation loss decreased (1.334013 --> 1.326324).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.1254127025604248
Epoch: 17, Steps: 62 | Train Loss: 0.3097850 Vali Loss: 1.3164916 Test Loss: 0.5509876
Validation loss decreased (1.326324 --> 1.316492).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.2388172149658203
Epoch: 18, Steps: 62 | Train Loss: 0.3058602 Vali Loss: 1.3118423 Test Loss: 0.5464135
Validation loss decreased (1.316492 --> 1.311842).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.2008047103881836
Epoch: 19, Steps: 62 | Train Loss: 0.3023084 Vali Loss: 1.3038416 Test Loss: 0.5419257
Validation loss decreased (1.311842 --> 1.303842).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.2660560607910156
Epoch: 20, Steps: 62 | Train Loss: 0.2989456 Vali Loss: 1.2944771 Test Loss: 0.5377232
Validation loss decreased (1.303842 --> 1.294477).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.2431881427764893
Epoch: 21, Steps: 62 | Train Loss: 0.2959393 Vali Loss: 1.2963806 Test Loss: 0.5339518
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.2252113819122314
Epoch: 22, Steps: 62 | Train Loss: 0.2931798 Vali Loss: 1.2900324 Test Loss: 0.5303010
Validation loss decreased (1.294477 --> 1.290032).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.2697761058807373
Epoch: 23, Steps: 62 | Train Loss: 0.2906040 Vali Loss: 1.2832941 Test Loss: 0.5272623
Validation loss decreased (1.290032 --> 1.283294).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.1974833011627197
Epoch: 24, Steps: 62 | Train Loss: 0.2882635 Vali Loss: 1.2785597 Test Loss: 0.5242593
Validation loss decreased (1.283294 --> 1.278560).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.276336669921875
Epoch: 25, Steps: 62 | Train Loss: 0.2860565 Vali Loss: 1.2780958 Test Loss: 0.5212772
Validation loss decreased (1.278560 --> 1.278096).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.232086181640625
Epoch: 26, Steps: 62 | Train Loss: 0.2841263 Vali Loss: 1.2756618 Test Loss: 0.5183503
Validation loss decreased (1.278096 --> 1.275662).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.250317096710205
Epoch: 27, Steps: 62 | Train Loss: 0.2823457 Vali Loss: 1.2693511 Test Loss: 0.5159947
Validation loss decreased (1.275662 --> 1.269351).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.2637238502502441
Epoch: 28, Steps: 62 | Train Loss: 0.2805727 Vali Loss: 1.2659616 Test Loss: 0.5137028
Validation loss decreased (1.269351 --> 1.265962).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.1960020065307617
Epoch: 29, Steps: 62 | Train Loss: 0.2789466 Vali Loss: 1.2610852 Test Loss: 0.5113994
Validation loss decreased (1.265962 --> 1.261085).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.2990922927856445
Epoch: 30, Steps: 62 | Train Loss: 0.2774990 Vali Loss: 1.2561852 Test Loss: 0.5090035
Validation loss decreased (1.261085 --> 1.256185).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.1288940906524658
Epoch: 31, Steps: 62 | Train Loss: 0.2762171 Vali Loss: 1.2544371 Test Loss: 0.5072531
Validation loss decreased (1.256185 --> 1.254437).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.1917929649353027
Epoch: 32, Steps: 62 | Train Loss: 0.2748931 Vali Loss: 1.2565454 Test Loss: 0.5053030
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.1815810203552246
Epoch: 33, Steps: 62 | Train Loss: 0.2736570 Vali Loss: 1.2505111 Test Loss: 0.5036560
Validation loss decreased (1.254437 --> 1.250511).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.1732966899871826
Epoch: 34, Steps: 62 | Train Loss: 0.2725319 Vali Loss: 1.2494286 Test Loss: 0.5020252
Validation loss decreased (1.250511 --> 1.249429).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.1603515148162842
Epoch: 35, Steps: 62 | Train Loss: 0.2715013 Vali Loss: 1.2470624 Test Loss: 0.5005067
Validation loss decreased (1.249429 --> 1.247062).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.1786372661590576
Epoch: 36, Steps: 62 | Train Loss: 0.2705844 Vali Loss: 1.2457637 Test Loss: 0.4989667
Validation loss decreased (1.247062 --> 1.245764).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.1970465183258057
Epoch: 37, Steps: 62 | Train Loss: 0.2695556 Vali Loss: 1.2456299 Test Loss: 0.4976706
Validation loss decreased (1.245764 --> 1.245630).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.1128618717193604
Epoch: 38, Steps: 62 | Train Loss: 0.2687334 Vali Loss: 1.2451999 Test Loss: 0.4964148
Validation loss decreased (1.245630 --> 1.245200).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.2053489685058594
Epoch: 39, Steps: 62 | Train Loss: 0.2679413 Vali Loss: 1.2439716 Test Loss: 0.4952279
Validation loss decreased (1.245200 --> 1.243972).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.1488425731658936
Epoch: 40, Steps: 62 | Train Loss: 0.2671946 Vali Loss: 1.2453370 Test Loss: 0.4940459
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.1995198726654053
Epoch: 41, Steps: 62 | Train Loss: 0.2664622 Vali Loss: 1.2414236 Test Loss: 0.4929380
Validation loss decreased (1.243972 --> 1.241424).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.1806237697601318
Epoch: 42, Steps: 62 | Train Loss: 0.2657896 Vali Loss: 1.2370688 Test Loss: 0.4919381
Validation loss decreased (1.241424 --> 1.237069).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.1899538040161133
Epoch: 43, Steps: 62 | Train Loss: 0.2650612 Vali Loss: 1.2363491 Test Loss: 0.4910218
Validation loss decreased (1.237069 --> 1.236349).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.1961524486541748
Epoch: 44, Steps: 62 | Train Loss: 0.2644988 Vali Loss: 1.2375566 Test Loss: 0.4900407
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.2166461944580078
Epoch: 45, Steps: 62 | Train Loss: 0.2639188 Vali Loss: 1.2335882 Test Loss: 0.4892201
Validation loss decreased (1.236349 --> 1.233588).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.1135177612304688
Epoch: 46, Steps: 62 | Train Loss: 0.2634071 Vali Loss: 1.2292832 Test Loss: 0.4883205
Validation loss decreased (1.233588 --> 1.229283).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.1855030059814453
Epoch: 47, Steps: 62 | Train Loss: 0.2629686 Vali Loss: 1.2328244 Test Loss: 0.4876052
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.1400434970855713
Epoch: 48, Steps: 62 | Train Loss: 0.2625254 Vali Loss: 1.2307740 Test Loss: 0.4868467
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.1134777069091797
Epoch: 49, Steps: 62 | Train Loss: 0.2619895 Vali Loss: 1.2289212 Test Loss: 0.4861637
Validation loss decreased (1.229283 --> 1.228921).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.1979451179504395
Epoch: 50, Steps: 62 | Train Loss: 0.2615550 Vali Loss: 1.2291651 Test Loss: 0.4854932
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.1474483013153076
Epoch: 51, Steps: 62 | Train Loss: 0.2611113 Vali Loss: 1.2250730 Test Loss: 0.4849072
Validation loss decreased (1.228921 --> 1.225073).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.2465415000915527
Epoch: 52, Steps: 62 | Train Loss: 0.2607249 Vali Loss: 1.2276343 Test Loss: 0.4842890
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.186152458190918
Epoch: 53, Steps: 62 | Train Loss: 0.2604292 Vali Loss: 1.2260896 Test Loss: 0.4837066
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.1040277481079102
Epoch: 54, Steps: 62 | Train Loss: 0.2600597 Vali Loss: 1.2235283 Test Loss: 0.4831468
Validation loss decreased (1.225073 --> 1.223528).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.2420434951782227
Epoch: 55, Steps: 62 | Train Loss: 0.2597008 Vali Loss: 1.2241551 Test Loss: 0.4826532
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.1618397235870361
Epoch: 56, Steps: 62 | Train Loss: 0.2594756 Vali Loss: 1.2233460 Test Loss: 0.4821829
Validation loss decreased (1.223528 --> 1.223346).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.100189447402954
Epoch: 57, Steps: 62 | Train Loss: 0.2592092 Vali Loss: 1.2239671 Test Loss: 0.4817392
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.2859134674072266
Epoch: 58, Steps: 62 | Train Loss: 0.2588368 Vali Loss: 1.2213686 Test Loss: 0.4813022
Validation loss decreased (1.223346 --> 1.221369).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.2655858993530273
Epoch: 59, Steps: 62 | Train Loss: 0.2586242 Vali Loss: 1.2155607 Test Loss: 0.4808907
Validation loss decreased (1.221369 --> 1.215561).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.1582117080688477
Epoch: 60, Steps: 62 | Train Loss: 0.2583567 Vali Loss: 1.2195421 Test Loss: 0.4805128
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.1870474815368652
Epoch: 61, Steps: 62 | Train Loss: 0.2580773 Vali Loss: 1.2188147 Test Loss: 0.4801244
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.084984540939331
Epoch: 62, Steps: 62 | Train Loss: 0.2579474 Vali Loss: 1.2238159 Test Loss: 0.4797322
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.2795608043670654
Epoch: 63, Steps: 62 | Train Loss: 0.2577410 Vali Loss: 1.2193203 Test Loss: 0.4794445
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.1209783554077148
Epoch: 64, Steps: 62 | Train Loss: 0.2575343 Vali Loss: 1.2205299 Test Loss: 0.4791313
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.212494134902954
Epoch: 65, Steps: 62 | Train Loss: 0.2572768 Vali Loss: 1.2267326 Test Loss: 0.4787888
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.1614913940429688
Epoch: 66, Steps: 62 | Train Loss: 0.2571076 Vali Loss: 1.2207092 Test Loss: 0.4785101
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.2052979469299316
Epoch: 67, Steps: 62 | Train Loss: 0.2568892 Vali Loss: 1.2167332 Test Loss: 0.4782540
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.1993846893310547
Epoch: 68, Steps: 62 | Train Loss: 0.2568437 Vali Loss: 1.2184188 Test Loss: 0.4779764
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.2267882823944092
Epoch: 69, Steps: 62 | Train Loss: 0.2566555 Vali Loss: 1.2178198 Test Loss: 0.4777229
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.279433250427246
Epoch: 70, Steps: 62 | Train Loss: 0.2565103 Vali Loss: 1.2185100 Test Loss: 0.4774858
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.2829442024230957
Epoch: 71, Steps: 62 | Train Loss: 0.2563814 Vali Loss: 1.2201024 Test Loss: 0.4772926
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.141594409942627
Epoch: 72, Steps: 62 | Train Loss: 0.2561803 Vali Loss: 1.2163427 Test Loss: 0.4770563
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.1559042930603027
Epoch: 73, Steps: 62 | Train Loss: 0.2561373 Vali Loss: 1.2187043 Test Loss: 0.4768574
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.2702982425689697
Epoch: 74, Steps: 62 | Train Loss: 0.2559744 Vali Loss: 1.2141534 Test Loss: 0.4766757
Validation loss decreased (1.215561 --> 1.214153).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.2054111957550049
Epoch: 75, Steps: 62 | Train Loss: 0.2558935 Vali Loss: 1.2187494 Test Loss: 0.4764725
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.1523663997650146
Epoch: 76, Steps: 62 | Train Loss: 0.2557685 Vali Loss: 1.2117763 Test Loss: 0.4762962
Validation loss decreased (1.214153 --> 1.211776).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.1558294296264648
Epoch: 77, Steps: 62 | Train Loss: 0.2556808 Vali Loss: 1.2203951 Test Loss: 0.4761349
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.1318919658660889
Epoch: 78, Steps: 62 | Train Loss: 0.2555803 Vali Loss: 1.2182056 Test Loss: 0.4759761
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.1388814449310303
Epoch: 79, Steps: 62 | Train Loss: 0.2554505 Vali Loss: 1.2148339 Test Loss: 0.4758091
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.163381576538086
Epoch: 80, Steps: 62 | Train Loss: 0.2553774 Vali Loss: 1.2161450 Test Loss: 0.4756916
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.1268322467803955
Epoch: 81, Steps: 62 | Train Loss: 0.2552380 Vali Loss: 1.2104201 Test Loss: 0.4755507
Validation loss decreased (1.211776 --> 1.210420).  Saving model ...
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.1486964225769043
Epoch: 82, Steps: 62 | Train Loss: 0.2552459 Vali Loss: 1.2110293 Test Loss: 0.4754155
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.1512548923492432
Epoch: 83, Steps: 62 | Train Loss: 0.2551797 Vali Loss: 1.2129189 Test Loss: 0.4752952
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.2220778465270996
Epoch: 84, Steps: 62 | Train Loss: 0.2550261 Vali Loss: 1.2134918 Test Loss: 0.4751743
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.2280046939849854
Epoch: 85, Steps: 62 | Train Loss: 0.2549887 Vali Loss: 1.2122227 Test Loss: 0.4750678
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.2230234146118164
Epoch: 86, Steps: 62 | Train Loss: 0.2549464 Vali Loss: 1.2117264 Test Loss: 0.4749658
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.1727540493011475
Epoch: 87, Steps: 62 | Train Loss: 0.2548748 Vali Loss: 1.2124748 Test Loss: 0.4748584
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.1234116554260254
Epoch: 88, Steps: 62 | Train Loss: 0.2548119 Vali Loss: 1.2145054 Test Loss: 0.4747696
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.2323815822601318
Epoch: 89, Steps: 62 | Train Loss: 0.2547306 Vali Loss: 1.2126799 Test Loss: 0.4746795
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.1128313541412354
Epoch: 90, Steps: 62 | Train Loss: 0.2546878 Vali Loss: 1.2210523 Test Loss: 0.4745940
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.212724208831787
Epoch: 91, Steps: 62 | Train Loss: 0.2546701 Vali Loss: 1.2186364 Test Loss: 0.4745075
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.2681522369384766
Epoch: 92, Steps: 62 | Train Loss: 0.2546376 Vali Loss: 1.2146858 Test Loss: 0.4744328
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.221297025680542
Epoch: 93, Steps: 62 | Train Loss: 0.2545459 Vali Loss: 1.2126032 Test Loss: 0.4743551
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.167757272720337
Epoch: 94, Steps: 62 | Train Loss: 0.2544929 Vali Loss: 1.2140931 Test Loss: 0.4742840
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.1604044437408447
Epoch: 95, Steps: 62 | Train Loss: 0.2544388 Vali Loss: 1.2146999 Test Loss: 0.4742182
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.0977637767791748
Epoch: 96, Steps: 62 | Train Loss: 0.2544428 Vali Loss: 1.2129984 Test Loss: 0.4741515
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.2145299911499023
Epoch: 97, Steps: 62 | Train Loss: 0.2543659 Vali Loss: 1.2124516 Test Loss: 0.4740907
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.2310774326324463
Epoch: 98, Steps: 62 | Train Loss: 0.2543638 Vali Loss: 1.2160451 Test Loss: 0.4740331
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.2648227214813232
Epoch: 99, Steps: 62 | Train Loss: 0.2542864 Vali Loss: 1.2142050 Test Loss: 0.4739800
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.2081964015960693
Epoch: 100, Steps: 62 | Train Loss: 0.2543114 Vali Loss: 1.2149994 Test Loss: 0.4739293
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.1160680107021042e-06
train 7945
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=106, out_features=204, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  19375104.0
params:  21828.0
Trainable parameters:  21828
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.2388286590576172
Epoch: 1, Steps: 62 | Train Loss: 0.4728779 Vali Loss: 1.1837544 Test Loss: 0.4495789
Validation loss decreased (inf --> 1.183754).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.2543561458587646
Epoch: 2, Steps: 62 | Train Loss: 0.4619851 Vali Loss: 1.1702121 Test Loss: 0.4374769
Validation loss decreased (1.183754 --> 1.170212).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.287092685699463
Epoch: 3, Steps: 62 | Train Loss: 0.4566675 Vali Loss: 1.1635245 Test Loss: 0.4323106
Validation loss decreased (1.170212 --> 1.163525).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.382631778717041
Epoch: 4, Steps: 62 | Train Loss: 0.4543235 Vali Loss: 1.1572441 Test Loss: 0.4299653
Validation loss decreased (1.163525 --> 1.157244).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.288985252380371
Epoch: 5, Steps: 62 | Train Loss: 0.4533405 Vali Loss: 1.1566863 Test Loss: 0.4291656
Validation loss decreased (1.157244 --> 1.156686).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.1948070526123047
Epoch: 6, Steps: 62 | Train Loss: 0.4526555 Vali Loss: 1.1583955 Test Loss: 0.4289593
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.285106897354126
Epoch: 7, Steps: 62 | Train Loss: 0.4523984 Vali Loss: 1.1545666 Test Loss: 0.4287846
Validation loss decreased (1.156686 --> 1.154567).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.381176471710205
Epoch: 8, Steps: 62 | Train Loss: 0.4522259 Vali Loss: 1.1575817 Test Loss: 0.4288376
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.319187879562378
Epoch: 9, Steps: 62 | Train Loss: 0.4520547 Vali Loss: 1.1558276 Test Loss: 0.4288972
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.3548617362976074
Epoch: 10, Steps: 62 | Train Loss: 0.4518306 Vali Loss: 1.1551485 Test Loss: 0.4286750
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.1894845962524414
Epoch: 11, Steps: 62 | Train Loss: 0.4518007 Vali Loss: 1.1537430 Test Loss: 0.4287806
Validation loss decreased (1.154567 --> 1.153743).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.302612066268921
Epoch: 12, Steps: 62 | Train Loss: 0.4515499 Vali Loss: 1.1533458 Test Loss: 0.4286295
Validation loss decreased (1.153743 --> 1.153346).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.2587378025054932
Epoch: 13, Steps: 62 | Train Loss: 0.4516570 Vali Loss: 1.1538793 Test Loss: 0.4287253
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.342696189880371
Epoch: 14, Steps: 62 | Train Loss: 0.4515424 Vali Loss: 1.1555849 Test Loss: 0.4287519
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.3396880626678467
Epoch: 15, Steps: 62 | Train Loss: 0.4514029 Vali Loss: 1.1566226 Test Loss: 0.4286059
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.3514957427978516
Epoch: 16, Steps: 62 | Train Loss: 0.4513843 Vali Loss: 1.1528946 Test Loss: 0.4288428
Validation loss decreased (1.153346 --> 1.152895).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.3566186428070068
Epoch: 17, Steps: 62 | Train Loss: 0.4512884 Vali Loss: 1.1545089 Test Loss: 0.4288525
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.3521068096160889
Epoch: 18, Steps: 62 | Train Loss: 0.4512483 Vali Loss: 1.1598940 Test Loss: 0.4288264
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.338606595993042
Epoch: 19, Steps: 62 | Train Loss: 0.4511736 Vali Loss: 1.1554962 Test Loss: 0.4287547
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.2887184619903564
Epoch: 20, Steps: 62 | Train Loss: 0.4513150 Vali Loss: 1.1499109 Test Loss: 0.4287890
Validation loss decreased (1.152895 --> 1.149911).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.3600449562072754
Epoch: 21, Steps: 62 | Train Loss: 0.4512288 Vali Loss: 1.1537008 Test Loss: 0.4288162
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.2146434783935547
Epoch: 22, Steps: 62 | Train Loss: 0.4511010 Vali Loss: 1.1549278 Test Loss: 0.4288412
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.2826712131500244
Epoch: 23, Steps: 62 | Train Loss: 0.4510181 Vali Loss: 1.1537586 Test Loss: 0.4287739
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.3079063892364502
Epoch: 24, Steps: 62 | Train Loss: 0.4510254 Vali Loss: 1.1523434 Test Loss: 0.4287213
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.376784086227417
Epoch: 25, Steps: 62 | Train Loss: 0.4510624 Vali Loss: 1.1531109 Test Loss: 0.4287888
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.4422028064727783
Epoch: 26, Steps: 62 | Train Loss: 0.4509463 Vali Loss: 1.1532139 Test Loss: 0.4288447
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.3412628173828125
Epoch: 27, Steps: 62 | Train Loss: 0.4509280 Vali Loss: 1.1514475 Test Loss: 0.4289019
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.3012690544128418
Epoch: 28, Steps: 62 | Train Loss: 0.4509789 Vali Loss: 1.1517657 Test Loss: 0.4288377
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.300124168395996
Epoch: 29, Steps: 62 | Train Loss: 0.4510058 Vali Loss: 1.1554816 Test Loss: 0.4288636
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.2699592113494873
Epoch: 30, Steps: 62 | Train Loss: 0.4507788 Vali Loss: 1.1546268 Test Loss: 0.4288624
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.3027620315551758
Epoch: 31, Steps: 62 | Train Loss: 0.4509968 Vali Loss: 1.1591755 Test Loss: 0.4288765
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.2160372734069824
Epoch: 32, Steps: 62 | Train Loss: 0.4509485 Vali Loss: 1.1567730 Test Loss: 0.4289021
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.3331663608551025
Epoch: 33, Steps: 62 | Train Loss: 0.4508651 Vali Loss: 1.1503948 Test Loss: 0.4288545
EarlyStopping counter: 13 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.1986546516418457
Epoch: 34, Steps: 62 | Train Loss: 0.4506939 Vali Loss: 1.1624937 Test Loss: 0.4288835
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.3741285800933838
Epoch: 35, Steps: 62 | Train Loss: 0.4507643 Vali Loss: 1.1553364 Test Loss: 0.4288654
EarlyStopping counter: 15 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.3713774681091309
Epoch: 36, Steps: 62 | Train Loss: 0.4508727 Vali Loss: 1.1529661 Test Loss: 0.4288800
EarlyStopping counter: 16 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.3789780139923096
Epoch: 37, Steps: 62 | Train Loss: 0.4506693 Vali Loss: 1.1539247 Test Loss: 0.4289326
EarlyStopping counter: 17 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.2982628345489502
Epoch: 38, Steps: 62 | Train Loss: 0.4507031 Vali Loss: 1.1508265 Test Loss: 0.4289173
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.1780083179473877
Epoch: 39, Steps: 62 | Train Loss: 0.4508136 Vali Loss: 1.1529129 Test Loss: 0.4289237
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.2976698875427246
Epoch: 40, Steps: 62 | Train Loss: 0.4507203 Vali Loss: 1.1558052 Test Loss: 0.4289065
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_360_336_FITS_ETTh1_ftM_sl360_ll48_pl336_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.42767006158828735, mae:0.42738470435142517, rse:0.6225962042808533, corr:[0.25354877 0.25916705 0.25915787 0.26055205 0.2577716  0.25457928
 0.25390384 0.2538387  0.25281864 0.2528223  0.25318533 0.25249404
 0.25230923 0.25283474 0.2525878  0.25206926 0.25225648 0.25222278
 0.25167832 0.25130767 0.25135416 0.25138468 0.25177354 0.2522994
 0.25189638 0.25145996 0.25156355 0.25127462 0.250523   0.25021183
 0.25007966 0.24947627 0.2490614  0.24931097 0.24942975 0.24910493
 0.2492666  0.24965866 0.24952313 0.24932157 0.24983178 0.2502673
 0.2502558  0.25010836 0.24997196 0.24971056 0.24970546 0.24999684
 0.24986705 0.24913381 0.24831024 0.2477498  0.24721675 0.24635555
 0.24564134 0.24519438 0.2450241  0.24501112 0.2446944  0.2444969
 0.24443786 0.24451722 0.24438186 0.24430728 0.24452333 0.24485154
 0.2451356  0.24507736 0.24496563 0.24506669 0.2451617  0.24495806
 0.24436079 0.24363597 0.24303702 0.24267519 0.24250191 0.2423121
 0.24189496 0.24139452 0.24121611 0.24104309 0.24059527 0.24026002
 0.24017528 0.24007806 0.23994231 0.23999882 0.24009046 0.24002999
 0.2398474  0.23959711 0.23917192 0.23883012 0.2390346  0.24001403
 0.24097078 0.24124494 0.24142227 0.241534   0.24154277 0.24143727
 0.24125087 0.24122463 0.241188   0.24096088 0.24056765 0.24030429
 0.24028584 0.24041155 0.24053542 0.2407344  0.24102156 0.24125032
 0.24129102 0.24107392 0.24070539 0.24036609 0.24013387 0.2402137
 0.24034218 0.23987491 0.23911564 0.23850878 0.23814245 0.2376589
 0.23738872 0.23753051 0.23739833 0.2368608  0.23657744 0.23672275
 0.236736   0.23652753 0.23646785 0.23661615 0.2368821  0.23695545
 0.23700799 0.23702098 0.23687732 0.23674926 0.23662753 0.23654734
 0.23638728 0.23597918 0.2356785  0.23524563 0.23456682 0.23389119
 0.23377992 0.23406523 0.23425785 0.23438753 0.23431726 0.23417084
 0.23415323 0.23443545 0.23459016 0.23437148 0.23413406 0.23415335
 0.2341156  0.23401403 0.23401806 0.23380385 0.23322092 0.23323318
 0.23377019 0.2339176  0.23401812 0.23448212 0.23459832 0.23417112
 0.23403879 0.23435923 0.23443879 0.23438354 0.23452774 0.23455893
 0.23425907 0.23419377 0.23449554 0.23447494 0.23425664 0.23459421
 0.23496112 0.23484601 0.2347505  0.23467031 0.2341907  0.23384443
 0.23385847 0.23368818 0.23301026 0.23237017 0.2317828  0.23109634
 0.2308225  0.23115875 0.23109129 0.23066828 0.23059665 0.23079433
 0.23063816 0.23065622 0.23097782 0.23091353 0.23059307 0.23074992
 0.23120396 0.23104526 0.23059976 0.23032519 0.22985257 0.22968623
 0.2302136  0.23042437 0.23019454 0.22976491 0.22948861 0.22922353
 0.22900364 0.22924893 0.22948627 0.22900255 0.22835651 0.22827683
 0.22815175 0.22789761 0.2280044  0.22813304 0.22813153 0.22816515
 0.22817491 0.22776632 0.22730511 0.22726434 0.22757848 0.227811
 0.22785266 0.22745419 0.22730783 0.22759755 0.2276218  0.22726396
 0.22728042 0.22786874 0.22820516 0.22792342 0.22763792 0.22733717
 0.2267685  0.22665384 0.22727384 0.22744915 0.22704162 0.22697213
 0.22737232 0.22754262 0.2275905  0.2276206  0.2275845  0.22776666
 0.22786723 0.2274534  0.22686648 0.22667006 0.2263889  0.22588319
 0.22564095 0.22560716 0.22525714 0.2249081  0.22506316 0.22505565
 0.22458741 0.22441585 0.22465742 0.22442825 0.22392882 0.22408234
 0.22464538 0.22447658 0.22418931 0.22441477 0.2247096  0.22478482
 0.22495845 0.22520612 0.22570913 0.22612949 0.22616994 0.22605911
 0.22619908 0.22640844 0.2262174  0.22604753 0.22604086 0.22562811
 0.22483875 0.22479379 0.22554499 0.22546259 0.22515059 0.22534671
 0.22554225 0.22529513 0.22549635 0.22577152 0.22550203 0.22551967
 0.22615784 0.22632997 0.22583252 0.22575119 0.22546357 0.22451594
 0.22408795 0.22437532 0.22415374 0.22382145 0.22349262 0.22287825
 0.22256687 0.22316739 0.22328237 0.22260952 0.22296906 0.22399236
 0.22342102 0.2231839  0.2242554  0.22292484 0.22324382 0.22603917]
