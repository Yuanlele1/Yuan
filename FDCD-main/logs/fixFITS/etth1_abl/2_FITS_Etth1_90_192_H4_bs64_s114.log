Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_90_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_90_192_FITS_ETTh1_ftM_sl90_ll48_pl192_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8359
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=26, out_features=81, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1886976.0
params:  2187.0
Trainable parameters:  2187
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.1569912433624268
Epoch: 1, Steps: 65 | Train Loss: 0.8149095 Vali Loss: 1.7759806 Test Loss: 1.0649531
Validation loss decreased (inf --> 1.775981).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 6.190809726715088
Epoch: 2, Steps: 65 | Train Loss: 0.6412284 Vali Loss: 1.5383633 Test Loss: 0.8552971
Validation loss decreased (1.775981 --> 1.538363).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.6412718296051025
Epoch: 3, Steps: 65 | Train Loss: 0.5390731 Vali Loss: 1.3981531 Test Loss: 0.7337438
Validation loss decreased (1.538363 --> 1.398153).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 4.869384050369263
Epoch: 4, Steps: 65 | Train Loss: 0.4762294 Vali Loss: 1.3093855 Test Loss: 0.6584884
Validation loss decreased (1.398153 --> 1.309386).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.3716864585876465
Epoch: 5, Steps: 65 | Train Loss: 0.4349752 Vali Loss: 1.2494880 Test Loss: 0.6095988
Validation loss decreased (1.309386 --> 1.249488).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.254636526107788
Epoch: 6, Steps: 65 | Train Loss: 0.4073463 Vali Loss: 1.2074209 Test Loss: 0.5759082
Validation loss decreased (1.249488 --> 1.207421).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.1483585834503174
Epoch: 7, Steps: 65 | Train Loss: 0.3875670 Vali Loss: 1.1759045 Test Loss: 0.5510405
Validation loss decreased (1.207421 --> 1.175905).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.089365005493164
Epoch: 8, Steps: 65 | Train Loss: 0.3730913 Vali Loss: 1.1517859 Test Loss: 0.5328144
Validation loss decreased (1.175905 --> 1.151786).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 5.130249977111816
Epoch: 9, Steps: 65 | Train Loss: 0.3623083 Vali Loss: 1.1332742 Test Loss: 0.5189280
Validation loss decreased (1.151786 --> 1.133274).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.9652602672576904
Epoch: 10, Steps: 65 | Train Loss: 0.3539401 Vali Loss: 1.1176780 Test Loss: 0.5081184
Validation loss decreased (1.133274 --> 1.117678).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.7742531299591064
Epoch: 11, Steps: 65 | Train Loss: 0.3475320 Vali Loss: 1.1064489 Test Loss: 0.4997408
Validation loss decreased (1.117678 --> 1.106449).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.9860775470733643
Epoch: 12, Steps: 65 | Train Loss: 0.3419124 Vali Loss: 1.0957251 Test Loss: 0.4929141
Validation loss decreased (1.106449 --> 1.095725).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.3014583587646484
Epoch: 13, Steps: 65 | Train Loss: 0.3376200 Vali Loss: 1.0880861 Test Loss: 0.4872597
Validation loss decreased (1.095725 --> 1.088086).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.914536952972412
Epoch: 14, Steps: 65 | Train Loss: 0.3342266 Vali Loss: 1.0810245 Test Loss: 0.4826145
Validation loss decreased (1.088086 --> 1.081025).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.9614043235778809
Epoch: 15, Steps: 65 | Train Loss: 0.3310029 Vali Loss: 1.0749075 Test Loss: 0.4786166
Validation loss decreased (1.081025 --> 1.074908).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.9843616485595703
Epoch: 16, Steps: 65 | Train Loss: 0.3285495 Vali Loss: 1.0692838 Test Loss: 0.4752736
Validation loss decreased (1.074908 --> 1.069284).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 4.536332607269287
Epoch: 17, Steps: 65 | Train Loss: 0.3261529 Vali Loss: 1.0654943 Test Loss: 0.4725428
Validation loss decreased (1.069284 --> 1.065494).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.230304479598999
Epoch: 18, Steps: 65 | Train Loss: 0.3244613 Vali Loss: 1.0610033 Test Loss: 0.4701007
Validation loss decreased (1.065494 --> 1.061003).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.4447696208953857
Epoch: 19, Steps: 65 | Train Loss: 0.3225948 Vali Loss: 1.0576905 Test Loss: 0.4679962
Validation loss decreased (1.061003 --> 1.057691).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.91265869140625
Epoch: 20, Steps: 65 | Train Loss: 0.3210833 Vali Loss: 1.0547751 Test Loss: 0.4661810
Validation loss decreased (1.057691 --> 1.054775).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.0594639778137207
Epoch: 21, Steps: 65 | Train Loss: 0.3198383 Vali Loss: 1.0519570 Test Loss: 0.4645823
Validation loss decreased (1.054775 --> 1.051957).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.542959690093994
Epoch: 22, Steps: 65 | Train Loss: 0.3186230 Vali Loss: 1.0496949 Test Loss: 0.4632094
Validation loss decreased (1.051957 --> 1.049695).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.020019769668579
Epoch: 23, Steps: 65 | Train Loss: 0.3176714 Vali Loss: 1.0470395 Test Loss: 0.4619239
Validation loss decreased (1.049695 --> 1.047040).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.3106276988983154
Epoch: 24, Steps: 65 | Train Loss: 0.3166845 Vali Loss: 1.0455157 Test Loss: 0.4608327
Validation loss decreased (1.047040 --> 1.045516).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 4.530915975570679
Epoch: 25, Steps: 65 | Train Loss: 0.3161006 Vali Loss: 1.0433677 Test Loss: 0.4598475
Validation loss decreased (1.045516 --> 1.043368).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.836496114730835
Epoch: 26, Steps: 65 | Train Loss: 0.3150125 Vali Loss: 1.0416847 Test Loss: 0.4589529
Validation loss decreased (1.043368 --> 1.041685).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.9775691032409668
Epoch: 27, Steps: 65 | Train Loss: 0.3141712 Vali Loss: 1.0406954 Test Loss: 0.4580861
Validation loss decreased (1.041685 --> 1.040695).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.391127109527588
Epoch: 28, Steps: 65 | Train Loss: 0.3135790 Vali Loss: 1.0391600 Test Loss: 0.4573687
Validation loss decreased (1.040695 --> 1.039160).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.892298936843872
Epoch: 29, Steps: 65 | Train Loss: 0.3130571 Vali Loss: 1.0381628 Test Loss: 0.4566426
Validation loss decreased (1.039160 --> 1.038163).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 5.091443061828613
Epoch: 30, Steps: 65 | Train Loss: 0.3123249 Vali Loss: 1.0367966 Test Loss: 0.4560873
Validation loss decreased (1.038163 --> 1.036797).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.3939287662506104
Epoch: 31, Steps: 65 | Train Loss: 0.3119232 Vali Loss: 1.0358192 Test Loss: 0.4554835
Validation loss decreased (1.036797 --> 1.035819).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.9300332069396973
Epoch: 32, Steps: 65 | Train Loss: 0.3112944 Vali Loss: 1.0348086 Test Loss: 0.4549364
Validation loss decreased (1.035819 --> 1.034809).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.891688346862793
Epoch: 33, Steps: 65 | Train Loss: 0.3110636 Vali Loss: 1.0338367 Test Loss: 0.4544566
Validation loss decreased (1.034809 --> 1.033837).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.1300313472747803
Epoch: 34, Steps: 65 | Train Loss: 0.3107325 Vali Loss: 1.0332973 Test Loss: 0.4540313
Validation loss decreased (1.033837 --> 1.033297).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.6582891941070557
Epoch: 35, Steps: 65 | Train Loss: 0.3101864 Vali Loss: 1.0321119 Test Loss: 0.4536128
Validation loss decreased (1.033297 --> 1.032112).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.0760369300842285
Epoch: 36, Steps: 65 | Train Loss: 0.3099323 Vali Loss: 1.0318308 Test Loss: 0.4532429
Validation loss decreased (1.032112 --> 1.031831).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.2097442150115967
Epoch: 37, Steps: 65 | Train Loss: 0.3094806 Vali Loss: 1.0308472 Test Loss: 0.4528799
Validation loss decreased (1.031831 --> 1.030847).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.580622911453247
Epoch: 38, Steps: 65 | Train Loss: 0.3093867 Vali Loss: 1.0302026 Test Loss: 0.4525767
Validation loss decreased (1.030847 --> 1.030203).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.8450963497161865
Epoch: 39, Steps: 65 | Train Loss: 0.3089107 Vali Loss: 1.0296922 Test Loss: 0.4522801
Validation loss decreased (1.030203 --> 1.029692).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.7150123119354248
Epoch: 40, Steps: 65 | Train Loss: 0.3088933 Vali Loss: 1.0289471 Test Loss: 0.4519795
Validation loss decreased (1.029692 --> 1.028947).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 3.2553956508636475
Epoch: 41, Steps: 65 | Train Loss: 0.3085220 Vali Loss: 1.0289065 Test Loss: 0.4517194
Validation loss decreased (1.028947 --> 1.028906).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 3.1669633388519287
Epoch: 42, Steps: 65 | Train Loss: 0.3082447 Vali Loss: 1.0283995 Test Loss: 0.4514711
Validation loss decreased (1.028906 --> 1.028399).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.8356668949127197
Epoch: 43, Steps: 65 | Train Loss: 0.3078970 Vali Loss: 1.0280708 Test Loss: 0.4511853
Validation loss decreased (1.028399 --> 1.028071).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.120683431625366
Epoch: 44, Steps: 65 | Train Loss: 0.3076106 Vali Loss: 1.0276918 Test Loss: 0.4509953
Validation loss decreased (1.028071 --> 1.027692).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.51759934425354
Epoch: 45, Steps: 65 | Train Loss: 0.3076353 Vali Loss: 1.0272444 Test Loss: 0.4507994
Validation loss decreased (1.027692 --> 1.027244).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 5.190228223800659
Epoch: 46, Steps: 65 | Train Loss: 0.3075812 Vali Loss: 1.0268275 Test Loss: 0.4505833
Validation loss decreased (1.027244 --> 1.026827).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 4.056932210922241
Epoch: 47, Steps: 65 | Train Loss: 0.3070293 Vali Loss: 1.0265267 Test Loss: 0.4504163
Validation loss decreased (1.026827 --> 1.026527).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 3.9398016929626465
Epoch: 48, Steps: 65 | Train Loss: 0.3068929 Vali Loss: 1.0260823 Test Loss: 0.4502405
Validation loss decreased (1.026527 --> 1.026082).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 3.093543767929077
Epoch: 49, Steps: 65 | Train Loss: 0.3067978 Vali Loss: 1.0258402 Test Loss: 0.4500774
Validation loss decreased (1.026082 --> 1.025840).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 3.957247018814087
Epoch: 50, Steps: 65 | Train Loss: 0.3067636 Vali Loss: 1.0253512 Test Loss: 0.4499271
Validation loss decreased (1.025840 --> 1.025351).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.8868756294250488
Epoch: 51, Steps: 65 | Train Loss: 0.3064405 Vali Loss: 1.0254427 Test Loss: 0.4497793
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.6101088523864746
Epoch: 52, Steps: 65 | Train Loss: 0.3064866 Vali Loss: 1.0250572 Test Loss: 0.4496502
Validation loss decreased (1.025351 --> 1.025057).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.2056679725646973
Epoch: 53, Steps: 65 | Train Loss: 0.3063864 Vali Loss: 1.0242676 Test Loss: 0.4495094
Validation loss decreased (1.025057 --> 1.024268).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 3.021279811859131
Epoch: 54, Steps: 65 | Train Loss: 0.3061627 Vali Loss: 1.0243031 Test Loss: 0.4493846
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.536195993423462
Epoch: 55, Steps: 65 | Train Loss: 0.3059241 Vali Loss: 1.0244422 Test Loss: 0.4492944
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.9826040267944336
Epoch: 56, Steps: 65 | Train Loss: 0.3059927 Vali Loss: 1.0242099 Test Loss: 0.4491729
Validation loss decreased (1.024268 --> 1.024210).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 3.0489120483398438
Epoch: 57, Steps: 65 | Train Loss: 0.3059451 Vali Loss: 1.0239943 Test Loss: 0.4490575
Validation loss decreased (1.024210 --> 1.023994).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.533059597015381
Epoch: 58, Steps: 65 | Train Loss: 0.3058354 Vali Loss: 1.0235343 Test Loss: 0.4489602
Validation loss decreased (1.023994 --> 1.023534).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.8062353134155273
Epoch: 59, Steps: 65 | Train Loss: 0.3056369 Vali Loss: 1.0231982 Test Loss: 0.4488715
Validation loss decreased (1.023534 --> 1.023198).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.000715732574463
Epoch: 60, Steps: 65 | Train Loss: 0.3056445 Vali Loss: 1.0235182 Test Loss: 0.4487795
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 3.894866466522217
Epoch: 61, Steps: 65 | Train Loss: 0.3054967 Vali Loss: 1.0231832 Test Loss: 0.4487073
Validation loss decreased (1.023198 --> 1.023183).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 4.011033535003662
Epoch: 62, Steps: 65 | Train Loss: 0.3052133 Vali Loss: 1.0231289 Test Loss: 0.4486409
Validation loss decreased (1.023183 --> 1.023129).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.3357856273651123
Epoch: 63, Steps: 65 | Train Loss: 0.3053125 Vali Loss: 1.0230347 Test Loss: 0.4485513
Validation loss decreased (1.023129 --> 1.023035).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.3772006034851074
Epoch: 64, Steps: 65 | Train Loss: 0.3052814 Vali Loss: 1.0229639 Test Loss: 0.4484744
Validation loss decreased (1.023035 --> 1.022964).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.7066378593444824
Epoch: 65, Steps: 65 | Train Loss: 0.3052195 Vali Loss: 1.0217294 Test Loss: 0.4484143
Validation loss decreased (1.022964 --> 1.021729).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.524252414703369
Epoch: 66, Steps: 65 | Train Loss: 0.3051880 Vali Loss: 1.0225559 Test Loss: 0.4483493
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.8602795600891113
Epoch: 67, Steps: 65 | Train Loss: 0.3050530 Vali Loss: 1.0222425 Test Loss: 0.4482869
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.611229658126831
Epoch: 68, Steps: 65 | Train Loss: 0.3049783 Vali Loss: 1.0220449 Test Loss: 0.4482334
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.2330007553100586
Epoch: 69, Steps: 65 | Train Loss: 0.3050018 Vali Loss: 1.0221286 Test Loss: 0.4481727
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.8042354583740234
Epoch: 70, Steps: 65 | Train Loss: 0.3049003 Vali Loss: 1.0218278 Test Loss: 0.4481235
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 3.3302297592163086
Epoch: 71, Steps: 65 | Train Loss: 0.3049065 Vali Loss: 1.0216893 Test Loss: 0.4480672
Validation loss decreased (1.021729 --> 1.021689).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.6295745372772217
Epoch: 72, Steps: 65 | Train Loss: 0.3048192 Vali Loss: 1.0221083 Test Loss: 0.4480297
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.755716323852539
Epoch: 73, Steps: 65 | Train Loss: 0.3044600 Vali Loss: 1.0219991 Test Loss: 0.4479874
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 3.421193838119507
Epoch: 74, Steps: 65 | Train Loss: 0.3048479 Vali Loss: 1.0209687 Test Loss: 0.4479397
Validation loss decreased (1.021689 --> 1.020969).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.6389307975769043
Epoch: 75, Steps: 65 | Train Loss: 0.3045606 Vali Loss: 1.0215849 Test Loss: 0.4479021
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.8792228698730469
Epoch: 76, Steps: 65 | Train Loss: 0.3044793 Vali Loss: 1.0215743 Test Loss: 0.4478685
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 3.176633358001709
Epoch: 77, Steps: 65 | Train Loss: 0.3046184 Vali Loss: 1.0216979 Test Loss: 0.4478237
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.008897066116333
Epoch: 78, Steps: 65 | Train Loss: 0.3044657 Vali Loss: 1.0215672 Test Loss: 0.4477908
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 3.5238921642303467
Epoch: 79, Steps: 65 | Train Loss: 0.3044227 Vali Loss: 1.0211799 Test Loss: 0.4477589
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.778925895690918
Epoch: 80, Steps: 65 | Train Loss: 0.3040696 Vali Loss: 1.0210927 Test Loss: 0.4477307
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.7417306900024414
Epoch: 81, Steps: 65 | Train Loss: 0.3043539 Vali Loss: 1.0214815 Test Loss: 0.4476998
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.9467804431915283
Epoch: 82, Steps: 65 | Train Loss: 0.3043871 Vali Loss: 1.0213704 Test Loss: 0.4476672
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.5497355461120605
Epoch: 83, Steps: 65 | Train Loss: 0.3042687 Vali Loss: 1.0208553 Test Loss: 0.4476419
Validation loss decreased (1.020969 --> 1.020855).  Saving model ...
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.2567126750946045
Epoch: 84, Steps: 65 | Train Loss: 0.3043639 Vali Loss: 1.0212910 Test Loss: 0.4476164
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.2707808017730713
Epoch: 85, Steps: 65 | Train Loss: 0.3044747 Vali Loss: 1.0206996 Test Loss: 0.4475884
Validation loss decreased (1.020855 --> 1.020700).  Saving model ...
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 2.967785358428955
Epoch: 86, Steps: 65 | Train Loss: 0.3041108 Vali Loss: 1.0210013 Test Loss: 0.4475642
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 3.1936540603637695
Epoch: 87, Steps: 65 | Train Loss: 0.3042350 Vali Loss: 1.0208765 Test Loss: 0.4475446
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 3.6614420413970947
Epoch: 88, Steps: 65 | Train Loss: 0.3043926 Vali Loss: 1.0210680 Test Loss: 0.4475232
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.7059478759765625
Epoch: 89, Steps: 65 | Train Loss: 0.3042934 Vali Loss: 1.0202732 Test Loss: 0.4475038
Validation loss decreased (1.020700 --> 1.020273).  Saving model ...
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 4.078325033187866
Epoch: 90, Steps: 65 | Train Loss: 0.3043465 Vali Loss: 1.0210396 Test Loss: 0.4474828
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 5.886509656906128
Epoch: 91, Steps: 65 | Train Loss: 0.3041671 Vali Loss: 1.0204301 Test Loss: 0.4474622
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 4.600131511688232
Epoch: 92, Steps: 65 | Train Loss: 0.3043368 Vali Loss: 1.0207759 Test Loss: 0.4474494
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 2.4739816188812256
Epoch: 93, Steps: 65 | Train Loss: 0.3043774 Vali Loss: 1.0209429 Test Loss: 0.4474314
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.8505308628082275
Epoch: 94, Steps: 65 | Train Loss: 0.3041462 Vali Loss: 1.0205309 Test Loss: 0.4474145
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.8133511543273926
Epoch: 95, Steps: 65 | Train Loss: 0.3043944 Vali Loss: 1.0208833 Test Loss: 0.4474000
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.9303693771362305
Epoch: 96, Steps: 65 | Train Loss: 0.3041225 Vali Loss: 1.0207390 Test Loss: 0.4473874
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.8786933422088623
Epoch: 97, Steps: 65 | Train Loss: 0.3040795 Vali Loss: 1.0204200 Test Loss: 0.4473725
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 2.350268840789795
Epoch: 98, Steps: 65 | Train Loss: 0.3039484 Vali Loss: 1.0205604 Test Loss: 0.4473598
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 2.5912094116210938
Epoch: 99, Steps: 65 | Train Loss: 0.3041023 Vali Loss: 1.0207585 Test Loss: 0.4473490
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 4.341449499130249
Epoch: 100, Steps: 65 | Train Loss: 0.3041002 Vali Loss: 1.0196033 Test Loss: 0.4473362
Validation loss decreased (1.020273 --> 1.019603).  Saving model ...
Updating learning rate to 3.1160680107021042e-06
train 8359
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=26, out_features=81, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1886976.0
params:  2187.0
Trainable parameters:  2187
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 4.039405345916748
Epoch: 1, Steps: 65 | Train Loss: 0.4305995 Vali Loss: 1.0130535 Test Loss: 0.4424828
Validation loss decreased (inf --> 1.013054).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.7721054553985596
Epoch: 2, Steps: 65 | Train Loss: 0.4273889 Vali Loss: 1.0096465 Test Loss: 0.4405419
Validation loss decreased (1.013054 --> 1.009647).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.7737109661102295
Epoch: 3, Steps: 65 | Train Loss: 0.4256516 Vali Loss: 1.0073820 Test Loss: 0.4396064
Validation loss decreased (1.009647 --> 1.007382).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.8850369453430176
Epoch: 4, Steps: 65 | Train Loss: 0.4248465 Vali Loss: 1.0059443 Test Loss: 0.4389893
Validation loss decreased (1.007382 --> 1.005944).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.3141019344329834
Epoch: 5, Steps: 65 | Train Loss: 0.4244403 Vali Loss: 1.0054866 Test Loss: 0.4389530
Validation loss decreased (1.005944 --> 1.005487).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.8834407329559326
Epoch: 6, Steps: 65 | Train Loss: 0.4241918 Vali Loss: 1.0050378 Test Loss: 0.4387459
Validation loss decreased (1.005487 --> 1.005038).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.7406461238861084
Epoch: 7, Steps: 65 | Train Loss: 0.4235613 Vali Loss: 1.0035490 Test Loss: 0.4388677
Validation loss decreased (1.005038 --> 1.003549).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.7292003631591797
Epoch: 8, Steps: 65 | Train Loss: 0.4237239 Vali Loss: 1.0043185 Test Loss: 0.4392242
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.202934503555298
Epoch: 9, Steps: 65 | Train Loss: 0.4235331 Vali Loss: 1.0031388 Test Loss: 0.4389849
Validation loss decreased (1.003549 --> 1.003139).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.727219820022583
Epoch: 10, Steps: 65 | Train Loss: 0.4237605 Vali Loss: 1.0038217 Test Loss: 0.4392726
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.267401933670044
Epoch: 11, Steps: 65 | Train Loss: 0.4234994 Vali Loss: 1.0036191 Test Loss: 0.4391314
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.560452938079834
Epoch: 12, Steps: 65 | Train Loss: 0.4235547 Vali Loss: 1.0037539 Test Loss: 0.4392549
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.7951314449310303
Epoch: 13, Steps: 65 | Train Loss: 0.4233162 Vali Loss: 1.0035551 Test Loss: 0.4392549
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.9670569896697998
Epoch: 14, Steps: 65 | Train Loss: 0.4234041 Vali Loss: 1.0026115 Test Loss: 0.4390584
Validation loss decreased (1.003139 --> 1.002612).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.2793126106262207
Epoch: 15, Steps: 65 | Train Loss: 0.4233102 Vali Loss: 1.0031602 Test Loss: 0.4392064
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.6911745071411133
Epoch: 16, Steps: 65 | Train Loss: 0.4228919 Vali Loss: 1.0033616 Test Loss: 0.4392684
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.210573673248291
Epoch: 17, Steps: 65 | Train Loss: 0.4233812 Vali Loss: 1.0034640 Test Loss: 0.4393921
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.5368032455444336
Epoch: 18, Steps: 65 | Train Loss: 0.4236101 Vali Loss: 1.0022840 Test Loss: 0.4393926
Validation loss decreased (1.002612 --> 1.002284).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.903475761413574
Epoch: 19, Steps: 65 | Train Loss: 0.4233632 Vali Loss: 1.0031519 Test Loss: 0.4393325
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.087573766708374
Epoch: 20, Steps: 65 | Train Loss: 0.4233603 Vali Loss: 1.0032213 Test Loss: 0.4394075
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 4.151699781417847
Epoch: 21, Steps: 65 | Train Loss: 0.4232421 Vali Loss: 1.0028113 Test Loss: 0.4393696
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.002034902572632
Epoch: 22, Steps: 65 | Train Loss: 0.4234686 Vali Loss: 1.0026038 Test Loss: 0.4394239
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.6884515285491943
Epoch: 23, Steps: 65 | Train Loss: 0.4231167 Vali Loss: 1.0029244 Test Loss: 0.4394127
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.0513205528259277
Epoch: 24, Steps: 65 | Train Loss: 0.4229709 Vali Loss: 1.0029986 Test Loss: 0.4394519
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.181187629699707
Epoch: 25, Steps: 65 | Train Loss: 0.4236723 Vali Loss: 1.0030137 Test Loss: 0.4394845
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.7078526020050049
Epoch: 26, Steps: 65 | Train Loss: 0.4233014 Vali Loss: 1.0029850 Test Loss: 0.4393947
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.6400291919708252
Epoch: 27, Steps: 65 | Train Loss: 0.4231983 Vali Loss: 1.0028485 Test Loss: 0.4394320
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.450387954711914
Epoch: 28, Steps: 65 | Train Loss: 0.4233971 Vali Loss: 1.0019194 Test Loss: 0.4394623
Validation loss decreased (1.002284 --> 1.001919).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.1583688259124756
Epoch: 29, Steps: 65 | Train Loss: 0.4232869 Vali Loss: 1.0024198 Test Loss: 0.4393850
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.3162081241607666
Epoch: 30, Steps: 65 | Train Loss: 0.4232757 Vali Loss: 1.0021551 Test Loss: 0.4394775
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.8301124572753906
Epoch: 31, Steps: 65 | Train Loss: 0.4229826 Vali Loss: 1.0028175 Test Loss: 0.4394483
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.1397008895874023
Epoch: 32, Steps: 65 | Train Loss: 0.4232321 Vali Loss: 1.0023034 Test Loss: 0.4394880
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 3.0636990070343018
Epoch: 33, Steps: 65 | Train Loss: 0.4232916 Vali Loss: 1.0024061 Test Loss: 0.4394912
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.395609140396118
Epoch: 34, Steps: 65 | Train Loss: 0.4229311 Vali Loss: 1.0025576 Test Loss: 0.4394717
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 5.3700270652771
Epoch: 35, Steps: 65 | Train Loss: 0.4232508 Vali Loss: 1.0026962 Test Loss: 0.4394903
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 5.012835264205933
Epoch: 36, Steps: 65 | Train Loss: 0.4234325 Vali Loss: 1.0025114 Test Loss: 0.4395738
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.844183921813965
Epoch: 37, Steps: 65 | Train Loss: 0.4231803 Vali Loss: 1.0028841 Test Loss: 0.4395086
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 3.613556146621704
Epoch: 38, Steps: 65 | Train Loss: 0.4231632 Vali Loss: 1.0025829 Test Loss: 0.4395125
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.364647388458252
Epoch: 39, Steps: 65 | Train Loss: 0.4229469 Vali Loss: 1.0029429 Test Loss: 0.4395085
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.743543863296509
Epoch: 40, Steps: 65 | Train Loss: 0.4229149 Vali Loss: 1.0026526 Test Loss: 0.4395940
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.8944456577301025
Epoch: 41, Steps: 65 | Train Loss: 0.4232394 Vali Loss: 1.0026087 Test Loss: 0.4395635
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 3.007378339767456
Epoch: 42, Steps: 65 | Train Loss: 0.4229384 Vali Loss: 1.0026747 Test Loss: 0.4395456
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.3612730503082275
Epoch: 43, Steps: 65 | Train Loss: 0.4227806 Vali Loss: 1.0027814 Test Loss: 0.4395533
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.0916616916656494
Epoch: 44, Steps: 65 | Train Loss: 0.4228628 Vali Loss: 1.0024712 Test Loss: 0.4396349
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.1808645725250244
Epoch: 45, Steps: 65 | Train Loss: 0.4231123 Vali Loss: 1.0025824 Test Loss: 0.4396408
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.034486770629883
Epoch: 46, Steps: 65 | Train Loss: 0.4228205 Vali Loss: 1.0018398 Test Loss: 0.4395773
Validation loss decreased (1.001919 --> 1.001840).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.0593788623809814
Epoch: 47, Steps: 65 | Train Loss: 0.4229914 Vali Loss: 1.0027502 Test Loss: 0.4395503
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.0024921894073486
Epoch: 48, Steps: 65 | Train Loss: 0.4232502 Vali Loss: 1.0027884 Test Loss: 0.4395710
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.2901978492736816
Epoch: 49, Steps: 65 | Train Loss: 0.4233050 Vali Loss: 1.0027725 Test Loss: 0.4396036
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.0415728092193604
Epoch: 50, Steps: 65 | Train Loss: 0.4233256 Vali Loss: 1.0023530 Test Loss: 0.4395691
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.911003589630127
Epoch: 51, Steps: 65 | Train Loss: 0.4228129 Vali Loss: 1.0027968 Test Loss: 0.4395448
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 3.698347330093384
Epoch: 52, Steps: 65 | Train Loss: 0.4232199 Vali Loss: 1.0023009 Test Loss: 0.4395809
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 3.1999547481536865
Epoch: 53, Steps: 65 | Train Loss: 0.4230846 Vali Loss: 1.0026792 Test Loss: 0.4395716
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.1940672397613525
Epoch: 54, Steps: 65 | Train Loss: 0.4231574 Vali Loss: 1.0027052 Test Loss: 0.4396038
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 3.0770320892333984
Epoch: 55, Steps: 65 | Train Loss: 0.4230152 Vali Loss: 1.0027936 Test Loss: 0.4395996
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 3.1605169773101807
Epoch: 56, Steps: 65 | Train Loss: 0.4229610 Vali Loss: 1.0028448 Test Loss: 0.4396093
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 3.604316234588623
Epoch: 57, Steps: 65 | Train Loss: 0.4232368 Vali Loss: 1.0023273 Test Loss: 0.4395886
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.573345899581909
Epoch: 58, Steps: 65 | Train Loss: 0.4229856 Vali Loss: 1.0028352 Test Loss: 0.4396085
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.229917049407959
Epoch: 59, Steps: 65 | Train Loss: 0.4231580 Vali Loss: 1.0022205 Test Loss: 0.4396010
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.394087076187134
Epoch: 60, Steps: 65 | Train Loss: 0.4233229 Vali Loss: 1.0027504 Test Loss: 0.4396074
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.345465660095215
Epoch: 61, Steps: 65 | Train Loss: 0.4231357 Vali Loss: 1.0027037 Test Loss: 0.4396150
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.4035706520080566
Epoch: 62, Steps: 65 | Train Loss: 0.4229174 Vali Loss: 1.0022197 Test Loss: 0.4396155
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.7186217308044434
Epoch: 63, Steps: 65 | Train Loss: 0.4229617 Vali Loss: 1.0027410 Test Loss: 0.4396027
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.9645614624023438
Epoch: 64, Steps: 65 | Train Loss: 0.4229561 Vali Loss: 1.0025076 Test Loss: 0.4395986
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.7620067596435547
Epoch: 65, Steps: 65 | Train Loss: 0.4231782 Vali Loss: 1.0027895 Test Loss: 0.4396037
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.128032684326172
Epoch: 66, Steps: 65 | Train Loss: 0.4230409 Vali Loss: 1.0025641 Test Loss: 0.4396053
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_90_192_FITS_ETTh1_ftM_sl90_ll48_pl192_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.43923068046569824, mae:0.42492786049842834, rse:0.6293665766716003, corr:[0.26290834 0.2655307  0.26432142 0.26436853 0.26183242 0.25904825
 0.25847003 0.25799504 0.25738096 0.25751066 0.25761145 0.25714397
 0.25678593 0.2566867  0.25641376 0.25639313 0.25664946 0.2566302
 0.25665233 0.25670588 0.2562028  0.2558287  0.2554486  0.25500843
 0.2534583  0.2525662  0.2527954  0.25335106 0.2532093  0.2531091
 0.25349903 0.25329623 0.25282988 0.25262752 0.2525818  0.2524737
 0.25226822 0.2523285  0.25254303 0.25261387 0.25287804 0.25323483
 0.25368145 0.25393    0.25384915 0.25362644 0.2535209  0.25314265
 0.25193724 0.25084814 0.25006777 0.24944654 0.24842511 0.247353
 0.24718033 0.24680896 0.24652088 0.24660556 0.24634378 0.24623483
 0.24609417 0.24601698 0.24590401 0.24556416 0.24560907 0.24581967
 0.24627672 0.24665655 0.24651432 0.24623872 0.24605939 0.24531142
 0.24361035 0.24237466 0.2416961  0.24145934 0.24105556 0.24075045
 0.2410108  0.24067064 0.24027406 0.2400831  0.23986334 0.23966688
 0.239442   0.2393594  0.23963413 0.23961623 0.2395933  0.23978774
 0.23997195 0.24006994 0.24001898 0.24004467 0.2401893  0.23984325
 0.23867933 0.23799875 0.23771235 0.23724349 0.237056   0.2370805
 0.23727554 0.23698427 0.23676488 0.23674366 0.23646091 0.23623995
 0.23615766 0.2359502  0.23604871 0.23614335 0.23642042 0.23657604
 0.23678711 0.23704393 0.23717512 0.23713636 0.23685962 0.23601693
 0.23431188 0.23299105 0.23204245 0.23112844 0.23061311 0.23063779
 0.23128286 0.2313713  0.23130539 0.23120181 0.23076174 0.23055683
 0.23047513 0.23017451 0.2300625  0.22996044 0.2301384  0.23018731
 0.23037103 0.2307471  0.23084432 0.2308627  0.23073272 0.22993548
 0.2282098  0.22697534 0.22639415 0.2256352  0.22503147 0.22506002
 0.22582597 0.22573474 0.22564898 0.22571863 0.22545694 0.22529005
 0.22520807 0.22496517 0.22465746 0.22445586 0.22455794 0.2246442
 0.22492921 0.22525743 0.2252318  0.22519775 0.22508205 0.2241868
 0.22243245 0.22145206 0.22134969 0.22126766 0.22052902 0.2202714
 0.2210286  0.22090432 0.22054547 0.22067615 0.22085091 0.22074161
 0.22064778 0.22029893 0.21985415 0.21944875 0.21958116 0.21997863
 0.2201979  0.22052349 0.22081494 0.22065936 0.22081998 0.22211756]
