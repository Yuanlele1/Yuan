Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_360_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_360_192_FITS_ETTh1_ftM_sl360_ll48_pl192_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8089
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=106, out_features=162, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  15386112.0
params:  17334.0
Trainable parameters:  17334
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.2665793895721436
Epoch: 1, Steps: 63 | Train Loss: 0.6512366 Vali Loss: 1.6176213 Test Loss: 0.8358353
Validation loss decreased (inf --> 1.617621).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.3697092533111572
Epoch: 2, Steps: 63 | Train Loss: 0.5110177 Vali Loss: 1.4489011 Test Loss: 0.7368956
Validation loss decreased (1.617621 --> 1.448901).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.3334243297576904
Epoch: 3, Steps: 63 | Train Loss: 0.4414873 Vali Loss: 1.3709202 Test Loss: 0.6942263
Validation loss decreased (1.448901 --> 1.370920).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.1195220947265625
Epoch: 4, Steps: 63 | Train Loss: 0.4019815 Vali Loss: 1.3274022 Test Loss: 0.6721718
Validation loss decreased (1.370920 --> 1.327402).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.1401958465576172
Epoch: 5, Steps: 63 | Train Loss: 0.3752365 Vali Loss: 1.2936925 Test Loss: 0.6543159
Validation loss decreased (1.327402 --> 1.293692).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.1216483116149902
Epoch: 6, Steps: 63 | Train Loss: 0.3543848 Vali Loss: 1.2686145 Test Loss: 0.6409602
Validation loss decreased (1.293692 --> 1.268615).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.1593141555786133
Epoch: 7, Steps: 63 | Train Loss: 0.3372424 Vali Loss: 1.2461009 Test Loss: 0.6280213
Validation loss decreased (1.268615 --> 1.246101).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.2374255657196045
Epoch: 8, Steps: 63 | Train Loss: 0.3228004 Vali Loss: 1.2279782 Test Loss: 0.6170612
Validation loss decreased (1.246101 --> 1.227978).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.2455432415008545
Epoch: 9, Steps: 63 | Train Loss: 0.3099483 Vali Loss: 1.2110753 Test Loss: 0.6070559
Validation loss decreased (1.227978 --> 1.211075).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.1611080169677734
Epoch: 10, Steps: 63 | Train Loss: 0.2987855 Vali Loss: 1.1966696 Test Loss: 0.5975320
Validation loss decreased (1.211075 --> 1.196670).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.1440794467926025
Epoch: 11, Steps: 63 | Train Loss: 0.2888735 Vali Loss: 1.1826570 Test Loss: 0.5886228
Validation loss decreased (1.196670 --> 1.182657).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.1937298774719238
Epoch: 12, Steps: 63 | Train Loss: 0.2801163 Vali Loss: 1.1695108 Test Loss: 0.5796967
Validation loss decreased (1.182657 --> 1.169511).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.1662440299987793
Epoch: 13, Steps: 63 | Train Loss: 0.2722508 Vali Loss: 1.1576154 Test Loss: 0.5717724
Validation loss decreased (1.169511 --> 1.157615).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.2310011386871338
Epoch: 14, Steps: 63 | Train Loss: 0.2652407 Vali Loss: 1.1470876 Test Loss: 0.5649878
Validation loss decreased (1.157615 --> 1.147088).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.2231736183166504
Epoch: 15, Steps: 63 | Train Loss: 0.2590035 Vali Loss: 1.1368451 Test Loss: 0.5580304
Validation loss decreased (1.147088 --> 1.136845).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.0932345390319824
Epoch: 16, Steps: 63 | Train Loss: 0.2531430 Vali Loss: 1.1292971 Test Loss: 0.5526808
Validation loss decreased (1.136845 --> 1.129297).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.1176953315734863
Epoch: 17, Steps: 63 | Train Loss: 0.2480206 Vali Loss: 1.1199089 Test Loss: 0.5460616
Validation loss decreased (1.129297 --> 1.119909).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.1721265316009521
Epoch: 18, Steps: 63 | Train Loss: 0.2433312 Vali Loss: 1.1116873 Test Loss: 0.5405477
Validation loss decreased (1.119909 --> 1.111687).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.1554734706878662
Epoch: 19, Steps: 63 | Train Loss: 0.2390589 Vali Loss: 1.1046610 Test Loss: 0.5359189
Validation loss decreased (1.111687 --> 1.104661).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.1193487644195557
Epoch: 20, Steps: 63 | Train Loss: 0.2350511 Vali Loss: 1.0986862 Test Loss: 0.5315546
Validation loss decreased (1.104661 --> 1.098686).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.2568230628967285
Epoch: 21, Steps: 63 | Train Loss: 0.2316133 Vali Loss: 1.0923407 Test Loss: 0.5273476
Validation loss decreased (1.098686 --> 1.092341).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.0660557746887207
Epoch: 22, Steps: 63 | Train Loss: 0.2282113 Vali Loss: 1.0870733 Test Loss: 0.5235062
Validation loss decreased (1.092341 --> 1.087073).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.258225917816162
Epoch: 23, Steps: 63 | Train Loss: 0.2252823 Vali Loss: 1.0807458 Test Loss: 0.5192028
Validation loss decreased (1.087073 --> 1.080746).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.1678390502929688
Epoch: 24, Steps: 63 | Train Loss: 0.2224757 Vali Loss: 1.0760267 Test Loss: 0.5157806
Validation loss decreased (1.080746 --> 1.076027).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.0861766338348389
Epoch: 25, Steps: 63 | Train Loss: 0.2198685 Vali Loss: 1.0714781 Test Loss: 0.5125122
Validation loss decreased (1.076027 --> 1.071478).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.242366075515747
Epoch: 26, Steps: 63 | Train Loss: 0.2174941 Vali Loss: 1.0668780 Test Loss: 0.5094013
Validation loss decreased (1.071478 --> 1.066878).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.179642677307129
Epoch: 27, Steps: 63 | Train Loss: 0.2153287 Vali Loss: 1.0628551 Test Loss: 0.5068602
Validation loss decreased (1.066878 --> 1.062855).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.257258653640747
Epoch: 28, Steps: 63 | Train Loss: 0.2132901 Vali Loss: 1.0587611 Test Loss: 0.5040025
Validation loss decreased (1.062855 --> 1.058761).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.1046693325042725
Epoch: 29, Steps: 63 | Train Loss: 0.2113557 Vali Loss: 1.0554937 Test Loss: 0.5013944
Validation loss decreased (1.058761 --> 1.055494).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.1277170181274414
Epoch: 30, Steps: 63 | Train Loss: 0.2095587 Vali Loss: 1.0522591 Test Loss: 0.4990451
Validation loss decreased (1.055494 --> 1.052259).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.1715939044952393
Epoch: 31, Steps: 63 | Train Loss: 0.2079886 Vali Loss: 1.0484732 Test Loss: 0.4968635
Validation loss decreased (1.052259 --> 1.048473).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.2568135261535645
Epoch: 32, Steps: 63 | Train Loss: 0.2064870 Vali Loss: 1.0459276 Test Loss: 0.4947841
Validation loss decreased (1.048473 --> 1.045928).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.2061593532562256
Epoch: 33, Steps: 63 | Train Loss: 0.2050475 Vali Loss: 1.0427670 Test Loss: 0.4926751
Validation loss decreased (1.045928 --> 1.042767).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.2224082946777344
Epoch: 34, Steps: 63 | Train Loss: 0.2036730 Vali Loss: 1.0400137 Test Loss: 0.4906540
Validation loss decreased (1.042767 --> 1.040014).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.0975580215454102
Epoch: 35, Steps: 63 | Train Loss: 0.2023693 Vali Loss: 1.0375180 Test Loss: 0.4890638
Validation loss decreased (1.040014 --> 1.037518).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.2361681461334229
Epoch: 36, Steps: 63 | Train Loss: 0.2012648 Vali Loss: 1.0351191 Test Loss: 0.4873491
Validation loss decreased (1.037518 --> 1.035119).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.1099576950073242
Epoch: 37, Steps: 63 | Train Loss: 0.2001130 Vali Loss: 1.0331105 Test Loss: 0.4858634
Validation loss decreased (1.035119 --> 1.033110).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.2433831691741943
Epoch: 38, Steps: 63 | Train Loss: 0.1991536 Vali Loss: 1.0310873 Test Loss: 0.4844691
Validation loss decreased (1.033110 --> 1.031087).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.0799643993377686
Epoch: 39, Steps: 63 | Train Loss: 0.1981041 Vali Loss: 1.0293082 Test Loss: 0.4831980
Validation loss decreased (1.031087 --> 1.029308).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.165482997894287
Epoch: 40, Steps: 63 | Train Loss: 0.1971340 Vali Loss: 1.0270690 Test Loss: 0.4817191
Validation loss decreased (1.029308 --> 1.027069).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.0894756317138672
Epoch: 41, Steps: 63 | Train Loss: 0.1962723 Vali Loss: 1.0252792 Test Loss: 0.4806067
Validation loss decreased (1.027069 --> 1.025279).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.168529748916626
Epoch: 42, Steps: 63 | Train Loss: 0.1955316 Vali Loss: 1.0236626 Test Loss: 0.4792832
Validation loss decreased (1.025279 --> 1.023663).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.1467304229736328
Epoch: 43, Steps: 63 | Train Loss: 0.1947438 Vali Loss: 1.0217787 Test Loss: 0.4781433
Validation loss decreased (1.023663 --> 1.021779).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.160050868988037
Epoch: 44, Steps: 63 | Train Loss: 0.1940232 Vali Loss: 1.0205179 Test Loss: 0.4770945
Validation loss decreased (1.021779 --> 1.020518).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.3286762237548828
Epoch: 45, Steps: 63 | Train Loss: 0.1933696 Vali Loss: 1.0185633 Test Loss: 0.4760987
Validation loss decreased (1.020518 --> 1.018563).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.3035178184509277
Epoch: 46, Steps: 63 | Train Loss: 0.1928044 Vali Loss: 1.0173175 Test Loss: 0.4752664
Validation loss decreased (1.018563 --> 1.017318).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.285438060760498
Epoch: 47, Steps: 63 | Train Loss: 0.1921559 Vali Loss: 1.0160373 Test Loss: 0.4743584
Validation loss decreased (1.017318 --> 1.016037).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.178792953491211
Epoch: 48, Steps: 63 | Train Loss: 0.1915412 Vali Loss: 1.0149540 Test Loss: 0.4735397
Validation loss decreased (1.016037 --> 1.014954).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.1209280490875244
Epoch: 49, Steps: 63 | Train Loss: 0.1910148 Vali Loss: 1.0141736 Test Loss: 0.4727210
Validation loss decreased (1.014954 --> 1.014174).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.2228116989135742
Epoch: 50, Steps: 63 | Train Loss: 0.1905328 Vali Loss: 1.0128980 Test Loss: 0.4720108
Validation loss decreased (1.014174 --> 1.012898).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.2196056842803955
Epoch: 51, Steps: 63 | Train Loss: 0.1900156 Vali Loss: 1.0110213 Test Loss: 0.4712186
Validation loss decreased (1.012898 --> 1.011021).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.2178757190704346
Epoch: 52, Steps: 63 | Train Loss: 0.1896495 Vali Loss: 1.0104626 Test Loss: 0.4705561
Validation loss decreased (1.011021 --> 1.010463).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.0921366214752197
Epoch: 53, Steps: 63 | Train Loss: 0.1891960 Vali Loss: 1.0100231 Test Loss: 0.4699047
Validation loss decreased (1.010463 --> 1.010023).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.1848814487457275
Epoch: 54, Steps: 63 | Train Loss: 0.1887641 Vali Loss: 1.0088814 Test Loss: 0.4692946
Validation loss decreased (1.010023 --> 1.008881).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.2231690883636475
Epoch: 55, Steps: 63 | Train Loss: 0.1883745 Vali Loss: 1.0083121 Test Loss: 0.4687367
Validation loss decreased (1.008881 --> 1.008312).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.10805082321167
Epoch: 56, Steps: 63 | Train Loss: 0.1879986 Vali Loss: 1.0070791 Test Loss: 0.4682413
Validation loss decreased (1.008312 --> 1.007079).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.1539337635040283
Epoch: 57, Steps: 63 | Train Loss: 0.1877136 Vali Loss: 1.0062491 Test Loss: 0.4676467
Validation loss decreased (1.007079 --> 1.006249).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.1582202911376953
Epoch: 58, Steps: 63 | Train Loss: 0.1873973 Vali Loss: 1.0058954 Test Loss: 0.4670845
Validation loss decreased (1.006249 --> 1.005895).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.1595525741577148
Epoch: 59, Steps: 63 | Train Loss: 0.1871155 Vali Loss: 1.0051527 Test Loss: 0.4666581
Validation loss decreased (1.005895 --> 1.005153).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.0749728679656982
Epoch: 60, Steps: 63 | Train Loss: 0.1867801 Vali Loss: 1.0047224 Test Loss: 0.4662536
Validation loss decreased (1.005153 --> 1.004722).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.2483940124511719
Epoch: 61, Steps: 63 | Train Loss: 0.1864400 Vali Loss: 1.0038933 Test Loss: 0.4657750
Validation loss decreased (1.004722 --> 1.003893).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.239175796508789
Epoch: 62, Steps: 63 | Train Loss: 0.1862404 Vali Loss: 1.0028753 Test Loss: 0.4652986
Validation loss decreased (1.003893 --> 1.002875).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.1215968132019043
Epoch: 63, Steps: 63 | Train Loss: 0.1859509 Vali Loss: 1.0023170 Test Loss: 0.4649537
Validation loss decreased (1.002875 --> 1.002317).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.1615688800811768
Epoch: 64, Steps: 63 | Train Loss: 0.1857135 Vali Loss: 1.0017376 Test Loss: 0.4645900
Validation loss decreased (1.002317 --> 1.001738).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.066331386566162
Epoch: 65, Steps: 63 | Train Loss: 0.1854531 Vali Loss: 1.0012203 Test Loss: 0.4642196
Validation loss decreased (1.001738 --> 1.001220).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.2251951694488525
Epoch: 66, Steps: 63 | Train Loss: 0.1851962 Vali Loss: 1.0010821 Test Loss: 0.4639159
Validation loss decreased (1.001220 --> 1.001082).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.192695140838623
Epoch: 67, Steps: 63 | Train Loss: 0.1850188 Vali Loss: 1.0005991 Test Loss: 0.4635569
Validation loss decreased (1.001082 --> 1.000599).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.200495958328247
Epoch: 68, Steps: 63 | Train Loss: 0.1848800 Vali Loss: 0.9998763 Test Loss: 0.4632668
Validation loss decreased (1.000599 --> 0.999876).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.152449607849121
Epoch: 69, Steps: 63 | Train Loss: 0.1845774 Vali Loss: 0.9995005 Test Loss: 0.4629972
Validation loss decreased (0.999876 --> 0.999500).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.1888189315795898
Epoch: 70, Steps: 63 | Train Loss: 0.1844862 Vali Loss: 0.9990317 Test Loss: 0.4627357
Validation loss decreased (0.999500 --> 0.999032).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.2180795669555664
Epoch: 71, Steps: 63 | Train Loss: 0.1843486 Vali Loss: 0.9988077 Test Loss: 0.4624783
Validation loss decreased (0.999032 --> 0.998808).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.1282236576080322
Epoch: 72, Steps: 63 | Train Loss: 0.1841427 Vali Loss: 0.9986169 Test Loss: 0.4622153
Validation loss decreased (0.998808 --> 0.998617).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.1533169746398926
Epoch: 73, Steps: 63 | Train Loss: 0.1839635 Vali Loss: 0.9980372 Test Loss: 0.4619938
Validation loss decreased (0.998617 --> 0.998037).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.1250865459442139
Epoch: 74, Steps: 63 | Train Loss: 0.1838272 Vali Loss: 0.9970991 Test Loss: 0.4617573
Validation loss decreased (0.998037 --> 0.997099).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.0788171291351318
Epoch: 75, Steps: 63 | Train Loss: 0.1837732 Vali Loss: 0.9973279 Test Loss: 0.4615459
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.0694129467010498
Epoch: 76, Steps: 63 | Train Loss: 0.1835152 Vali Loss: 0.9970189 Test Loss: 0.4613440
Validation loss decreased (0.997099 --> 0.997019).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.0673296451568604
Epoch: 77, Steps: 63 | Train Loss: 0.1834610 Vali Loss: 0.9969341 Test Loss: 0.4611547
Validation loss decreased (0.997019 --> 0.996934).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.2163641452789307
Epoch: 78, Steps: 63 | Train Loss: 0.1833246 Vali Loss: 0.9963816 Test Loss: 0.4609838
Validation loss decreased (0.996934 --> 0.996382).  Saving model ...
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.1725432872772217
Epoch: 79, Steps: 63 | Train Loss: 0.1832711 Vali Loss: 0.9965890 Test Loss: 0.4608080
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.1181108951568604
Epoch: 80, Steps: 63 | Train Loss: 0.1832433 Vali Loss: 0.9960645 Test Loss: 0.4606332
Validation loss decreased (0.996382 --> 0.996064).  Saving model ...
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.211960792541504
Epoch: 81, Steps: 63 | Train Loss: 0.1830765 Vali Loss: 0.9957994 Test Loss: 0.4604781
Validation loss decreased (0.996064 --> 0.995799).  Saving model ...
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.0566136837005615
Epoch: 82, Steps: 63 | Train Loss: 0.1829412 Vali Loss: 0.9958791 Test Loss: 0.4603331
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.250356912612915
Epoch: 83, Steps: 63 | Train Loss: 0.1829102 Vali Loss: 0.9956374 Test Loss: 0.4601765
Validation loss decreased (0.995799 --> 0.995637).  Saving model ...
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.1411840915679932
Epoch: 84, Steps: 63 | Train Loss: 0.1827523 Vali Loss: 0.9954575 Test Loss: 0.4600655
Validation loss decreased (0.995637 --> 0.995458).  Saving model ...
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.1057307720184326
Epoch: 85, Steps: 63 | Train Loss: 0.1826687 Vali Loss: 0.9946620 Test Loss: 0.4599161
Validation loss decreased (0.995458 --> 0.994662).  Saving model ...
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.1336827278137207
Epoch: 86, Steps: 63 | Train Loss: 0.1825715 Vali Loss: 0.9946579 Test Loss: 0.4597924
Validation loss decreased (0.994662 --> 0.994658).  Saving model ...
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.0823943614959717
Epoch: 87, Steps: 63 | Train Loss: 0.1825219 Vali Loss: 0.9943748 Test Loss: 0.4596879
Validation loss decreased (0.994658 --> 0.994375).  Saving model ...
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.0823760032653809
Epoch: 88, Steps: 63 | Train Loss: 0.1824687 Vali Loss: 0.9942473 Test Loss: 0.4595809
Validation loss decreased (0.994375 --> 0.994247).  Saving model ...
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.112642765045166
Epoch: 89, Steps: 63 | Train Loss: 0.1824150 Vali Loss: 0.9944394 Test Loss: 0.4594581
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.2389590740203857
Epoch: 90, Steps: 63 | Train Loss: 0.1822821 Vali Loss: 0.9943328 Test Loss: 0.4593664
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.1587369441986084
Epoch: 91, Steps: 63 | Train Loss: 0.1822328 Vali Loss: 0.9941794 Test Loss: 0.4592646
Validation loss decreased (0.994247 --> 0.994179).  Saving model ...
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.2911510467529297
Epoch: 92, Steps: 63 | Train Loss: 0.1821537 Vali Loss: 0.9940572 Test Loss: 0.4591747
Validation loss decreased (0.994179 --> 0.994057).  Saving model ...
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.0811350345611572
Epoch: 93, Steps: 63 | Train Loss: 0.1820751 Vali Loss: 0.9936249 Test Loss: 0.4590811
Validation loss decreased (0.994057 --> 0.993625).  Saving model ...
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.1924855709075928
Epoch: 94, Steps: 63 | Train Loss: 0.1820394 Vali Loss: 0.9929133 Test Loss: 0.4590147
Validation loss decreased (0.993625 --> 0.992913).  Saving model ...
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.2228269577026367
Epoch: 95, Steps: 63 | Train Loss: 0.1820603 Vali Loss: 0.9935950 Test Loss: 0.4589340
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.0517792701721191
Epoch: 96, Steps: 63 | Train Loss: 0.1819275 Vali Loss: 0.9930007 Test Loss: 0.4588500
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.1550061702728271
Epoch: 97, Steps: 63 | Train Loss: 0.1819742 Vali Loss: 0.9932039 Test Loss: 0.4587816
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.2321078777313232
Epoch: 98, Steps: 63 | Train Loss: 0.1818499 Vali Loss: 0.9933617 Test Loss: 0.4587213
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.1904220581054688
Epoch: 99, Steps: 63 | Train Loss: 0.1818506 Vali Loss: 0.9930308 Test Loss: 0.4586545
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.1646239757537842
Epoch: 100, Steps: 63 | Train Loss: 0.1818444 Vali Loss: 0.9929380 Test Loss: 0.4585909
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8089
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=106, out_features=162, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  15386112.0
params:  17334.0
Trainable parameters:  17334
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.274064064025879
Epoch: 1, Steps: 63 | Train Loss: 0.4164642 Vali Loss: 0.9403291 Test Loss: 0.4221694
Validation loss decreased (inf --> 0.940329).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.196962594985962
Epoch: 2, Steps: 63 | Train Loss: 0.4013657 Vali Loss: 0.9223903 Test Loss: 0.4114173
Validation loss decreased (0.940329 --> 0.922390).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.1180369853973389
Epoch: 3, Steps: 63 | Train Loss: 0.3960293 Vali Loss: 0.9167127 Test Loss: 0.4090466
Validation loss decreased (0.922390 --> 0.916713).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.137481689453125
Epoch: 4, Steps: 63 | Train Loss: 0.3947262 Vali Loss: 0.9165858 Test Loss: 0.4091831
Validation loss decreased (0.916713 --> 0.916586).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.2590084075927734
Epoch: 5, Steps: 63 | Train Loss: 0.3940506 Vali Loss: 0.9148726 Test Loss: 0.4088946
Validation loss decreased (0.916586 --> 0.914873).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.180114984512329
Epoch: 6, Steps: 63 | Train Loss: 0.3938442 Vali Loss: 0.9150879 Test Loss: 0.4088393
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.1436564922332764
Epoch: 7, Steps: 63 | Train Loss: 0.3935702 Vali Loss: 0.9155242 Test Loss: 0.4091096
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.1938621997833252
Epoch: 8, Steps: 63 | Train Loss: 0.3934486 Vali Loss: 0.9149116 Test Loss: 0.4088201
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.2709095478057861
Epoch: 9, Steps: 63 | Train Loss: 0.3932283 Vali Loss: 0.9145475 Test Loss: 0.4087503
Validation loss decreased (0.914873 --> 0.914548).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.1077125072479248
Epoch: 10, Steps: 63 | Train Loss: 0.3931658 Vali Loss: 0.9151557 Test Loss: 0.4086676
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.294379711151123
Epoch: 11, Steps: 63 | Train Loss: 0.3928062 Vali Loss: 0.9146740 Test Loss: 0.4088757
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.1359429359436035
Epoch: 12, Steps: 63 | Train Loss: 0.3929864 Vali Loss: 0.9146972 Test Loss: 0.4089022
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.1768429279327393
Epoch: 13, Steps: 63 | Train Loss: 0.3928536 Vali Loss: 0.9143933 Test Loss: 0.4089067
Validation loss decreased (0.914548 --> 0.914393).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.1549408435821533
Epoch: 14, Steps: 63 | Train Loss: 0.3927967 Vali Loss: 0.9142678 Test Loss: 0.4088183
Validation loss decreased (0.914393 --> 0.914268).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.1738462448120117
Epoch: 15, Steps: 63 | Train Loss: 0.3928062 Vali Loss: 0.9139758 Test Loss: 0.4088633
Validation loss decreased (0.914268 --> 0.913976).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.208972454071045
Epoch: 16, Steps: 63 | Train Loss: 0.3926867 Vali Loss: 0.9143588 Test Loss: 0.4088591
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.1317262649536133
Epoch: 17, Steps: 63 | Train Loss: 0.3925426 Vali Loss: 0.9139112 Test Loss: 0.4086376
Validation loss decreased (0.913976 --> 0.913911).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.116567850112915
Epoch: 18, Steps: 63 | Train Loss: 0.3925861 Vali Loss: 0.9142588 Test Loss: 0.4087043
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.0993578433990479
Epoch: 19, Steps: 63 | Train Loss: 0.3927298 Vali Loss: 0.9134082 Test Loss: 0.4088663
Validation loss decreased (0.913911 --> 0.913408).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.1946079730987549
Epoch: 20, Steps: 63 | Train Loss: 0.3925855 Vali Loss: 0.9138498 Test Loss: 0.4085306
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.228379487991333
Epoch: 21, Steps: 63 | Train Loss: 0.3923591 Vali Loss: 0.9135966 Test Loss: 0.4086728
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.2639012336730957
Epoch: 22, Steps: 63 | Train Loss: 0.3923679 Vali Loss: 0.9138953 Test Loss: 0.4085930
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.2704052925109863
Epoch: 23, Steps: 63 | Train Loss: 0.3925665 Vali Loss: 0.9138192 Test Loss: 0.4085902
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.2098145484924316
Epoch: 24, Steps: 63 | Train Loss: 0.3923026 Vali Loss: 0.9139094 Test Loss: 0.4087000
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.3118641376495361
Epoch: 25, Steps: 63 | Train Loss: 0.3920843 Vali Loss: 0.9140027 Test Loss: 0.4087323
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.175405740737915
Epoch: 26, Steps: 63 | Train Loss: 0.3922571 Vali Loss: 0.9139991 Test Loss: 0.4087048
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.227013111114502
Epoch: 27, Steps: 63 | Train Loss: 0.3921928 Vali Loss: 0.9138921 Test Loss: 0.4086755
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.2663524150848389
Epoch: 28, Steps: 63 | Train Loss: 0.3920417 Vali Loss: 0.9142777 Test Loss: 0.4087548
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.1982502937316895
Epoch: 29, Steps: 63 | Train Loss: 0.3922921 Vali Loss: 0.9136644 Test Loss: 0.4086501
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.2453639507293701
Epoch: 30, Steps: 63 | Train Loss: 0.3920586 Vali Loss: 0.9133694 Test Loss: 0.4086309
Validation loss decreased (0.913408 --> 0.913369).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.2012970447540283
Epoch: 31, Steps: 63 | Train Loss: 0.3919668 Vali Loss: 0.9137146 Test Loss: 0.4086254
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.1081974506378174
Epoch: 32, Steps: 63 | Train Loss: 0.3923152 Vali Loss: 0.9138545 Test Loss: 0.4086603
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.190333366394043
Epoch: 33, Steps: 63 | Train Loss: 0.3921633 Vali Loss: 0.9133686 Test Loss: 0.4086164
Validation loss decreased (0.913369 --> 0.913369).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.2038519382476807
Epoch: 34, Steps: 63 | Train Loss: 0.3920012 Vali Loss: 0.9137499 Test Loss: 0.4087004
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.2850191593170166
Epoch: 35, Steps: 63 | Train Loss: 0.3921846 Vali Loss: 0.9134843 Test Loss: 0.4086787
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.1091594696044922
Epoch: 36, Steps: 63 | Train Loss: 0.3918898 Vali Loss: 0.9133685 Test Loss: 0.4086469
Validation loss decreased (0.913369 --> 0.913369).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.168588638305664
Epoch: 37, Steps: 63 | Train Loss: 0.3921423 Vali Loss: 0.9135364 Test Loss: 0.4087110
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.1478049755096436
Epoch: 38, Steps: 63 | Train Loss: 0.3918731 Vali Loss: 0.9136710 Test Loss: 0.4086704
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.1373271942138672
Epoch: 39, Steps: 63 | Train Loss: 0.3920680 Vali Loss: 0.9130566 Test Loss: 0.4086871
Validation loss decreased (0.913369 --> 0.913057).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.135190486907959
Epoch: 40, Steps: 63 | Train Loss: 0.3920919 Vali Loss: 0.9137205 Test Loss: 0.4086786
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.153881311416626
Epoch: 41, Steps: 63 | Train Loss: 0.3921129 Vali Loss: 0.9137112 Test Loss: 0.4086454
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.1085739135742188
Epoch: 42, Steps: 63 | Train Loss: 0.3920108 Vali Loss: 0.9132985 Test Loss: 0.4086527
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.2392728328704834
Epoch: 43, Steps: 63 | Train Loss: 0.3921541 Vali Loss: 0.9136918 Test Loss: 0.4086298
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.2398040294647217
Epoch: 44, Steps: 63 | Train Loss: 0.3917003 Vali Loss: 0.9133485 Test Loss: 0.4086980
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.1229915618896484
Epoch: 45, Steps: 63 | Train Loss: 0.3917186 Vali Loss: 0.9137027 Test Loss: 0.4086156
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.2304677963256836
Epoch: 46, Steps: 63 | Train Loss: 0.3921162 Vali Loss: 0.9137632 Test Loss: 0.4086820
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.175225019454956
Epoch: 47, Steps: 63 | Train Loss: 0.3916042 Vali Loss: 0.9133471 Test Loss: 0.4086643
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.1734211444854736
Epoch: 48, Steps: 63 | Train Loss: 0.3919492 Vali Loss: 0.9136022 Test Loss: 0.4086907
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.1361265182495117
Epoch: 49, Steps: 63 | Train Loss: 0.3919679 Vali Loss: 0.9136094 Test Loss: 0.4086894
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.1505177021026611
Epoch: 50, Steps: 63 | Train Loss: 0.3920283 Vali Loss: 0.9135921 Test Loss: 0.4086796
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.269526720046997
Epoch: 51, Steps: 63 | Train Loss: 0.3915031 Vali Loss: 0.9136168 Test Loss: 0.4086924
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.1527581214904785
Epoch: 52, Steps: 63 | Train Loss: 0.3918869 Vali Loss: 0.9135472 Test Loss: 0.4086700
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.1413841247558594
Epoch: 53, Steps: 63 | Train Loss: 0.3916239 Vali Loss: 0.9133692 Test Loss: 0.4086931
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.0862188339233398
Epoch: 54, Steps: 63 | Train Loss: 0.3915833 Vali Loss: 0.9138130 Test Loss: 0.4086982
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.120790719985962
Epoch: 55, Steps: 63 | Train Loss: 0.3918136 Vali Loss: 0.9133384 Test Loss: 0.4087068
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.241037368774414
Epoch: 56, Steps: 63 | Train Loss: 0.3918189 Vali Loss: 0.9136732 Test Loss: 0.4086790
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.2274341583251953
Epoch: 57, Steps: 63 | Train Loss: 0.3917242 Vali Loss: 0.9132857 Test Loss: 0.4086856
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.24375319480896
Epoch: 58, Steps: 63 | Train Loss: 0.3918523 Vali Loss: 0.9136966 Test Loss: 0.4086868
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.1532971858978271
Epoch: 59, Steps: 63 | Train Loss: 0.3918809 Vali Loss: 0.9133399 Test Loss: 0.4086781
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_360_192_FITS_ETTh1_ftM_sl360_ll48_pl192_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.4046492874622345, mae:0.4133819341659546, rse:0.6040831804275513, corr:[0.2634958  0.26966566 0.27007192 0.2712648  0.26861277 0.26587936
 0.26509637 0.2647592  0.26390892 0.26415104 0.26451492 0.26390728
 0.2637449  0.26406047 0.2637354  0.26344112 0.26369768 0.26357004
 0.26304674 0.2627525  0.26262477 0.26230308 0.26246095 0.26307276
 0.26279423 0.2623184  0.26231277 0.2621445  0.26160058 0.2613467
 0.26120794 0.26059315 0.26009178 0.2602297  0.2603929  0.26021808
 0.26036838 0.2607312  0.26069525 0.26062918 0.2610628  0.2612706
 0.26124114 0.26122677 0.26105738 0.26061907 0.26064825 0.26106706
 0.26079705 0.2597909  0.25889668 0.2584028  0.25772712 0.25660902
 0.255961   0.25566915 0.25538486 0.25526202 0.25505146 0.2549922
 0.25496203 0.2549403  0.254801   0.25472128 0.25481823 0.25503
 0.2552742  0.25523552 0.25510877 0.25520167 0.25536653 0.2552931
 0.254725   0.25382325 0.25303084 0.25263473 0.25248146 0.25221902
 0.251839   0.25138578 0.25108445 0.25081286 0.25051144 0.25032225
 0.25027052 0.25024667 0.25031728 0.25039232 0.2502905  0.25017473
 0.25014147 0.25001943 0.24974148 0.24952203 0.24960351 0.25020745
 0.25086835 0.25092587 0.25104693 0.25112677 0.25100857 0.25078887
 0.2505984  0.25060502 0.25055575 0.25036737 0.25011304 0.24988018
 0.24965954 0.2495458  0.249652   0.2500453  0.25036666 0.25047654
 0.2504575  0.2503726  0.25016665 0.24988447 0.2496227  0.24963588
 0.24970706 0.24924207 0.24853139 0.24789667 0.2473059  0.24660333
 0.2463909  0.24659343 0.2464536  0.24592969 0.24566373 0.24555969
 0.24530247 0.2452933  0.24542953 0.24517025 0.24524035 0.24557617
 0.2458409  0.24586606 0.24585347 0.24583009 0.24554275 0.24541482
 0.24554713 0.2451221  0.24457449 0.24406129 0.2433394  0.24241884
 0.24228784 0.24260911 0.24240184 0.24230525 0.2425903  0.24262582
 0.24208526 0.24205005 0.24235106 0.24209596 0.24180557 0.24210346
 0.24229254 0.24195719 0.24188232 0.24194531 0.24167092 0.24164972
 0.24202225 0.24204959 0.24224596 0.24275313 0.24252355 0.24167882
 0.24163379 0.2420107  0.24161144 0.24146098 0.24193752 0.24167582
 0.24101819 0.24129803 0.24152967 0.24079402 0.24081102 0.2416568
 0.24131131 0.24116734 0.24167256 0.24047597 0.24083845 0.23806326]
