Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=103, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=103, out_features=116, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  10705408.0
params:  12064.0
Trainable parameters:  12064
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 4.802687883377075
Epoch: 1, Steps: 61 | Train Loss: 0.6330733 Vali Loss: 1.4016491 Test Loss: 0.7821960
Validation loss decreased (inf --> 1.401649).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 5.381005048751831
Epoch: 2, Steps: 61 | Train Loss: 0.5110804 Vali Loss: 1.2712169 Test Loss: 0.7323201
Validation loss decreased (1.401649 --> 1.271217).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 4.757651329040527
Epoch: 3, Steps: 61 | Train Loss: 0.4434930 Vali Loss: 1.2286967 Test Loss: 0.7181262
Validation loss decreased (1.271217 --> 1.228697).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 5.810238361358643
Epoch: 4, Steps: 61 | Train Loss: 0.4014537 Vali Loss: 1.2110944 Test Loss: 0.7153417
Validation loss decreased (1.228697 --> 1.211094).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 5.597301483154297
Epoch: 5, Steps: 61 | Train Loss: 0.3711935 Vali Loss: 1.1970714 Test Loss: 0.7100211
Validation loss decreased (1.211094 --> 1.197071).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 5.545918941497803
Epoch: 6, Steps: 61 | Train Loss: 0.3476457 Vali Loss: 1.1713748 Test Loss: 0.6994911
Validation loss decreased (1.197071 --> 1.171375).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 5.691904544830322
Epoch: 7, Steps: 61 | Train Loss: 0.3280310 Vali Loss: 1.1587261 Test Loss: 0.6933785
Validation loss decreased (1.171375 --> 1.158726).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 6.331665754318237
Epoch: 8, Steps: 61 | Train Loss: 0.3113159 Vali Loss: 1.1417750 Test Loss: 0.6844635
Validation loss decreased (1.158726 --> 1.141775).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 5.724837303161621
Epoch: 9, Steps: 61 | Train Loss: 0.2964559 Vali Loss: 1.1160039 Test Loss: 0.6734681
Validation loss decreased (1.141775 --> 1.116004).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 5.243879795074463
Epoch: 10, Steps: 61 | Train Loss: 0.2833895 Vali Loss: 1.1072489 Test Loss: 0.6642527
Validation loss decreased (1.116004 --> 1.107249).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 5.832063913345337
Epoch: 11, Steps: 61 | Train Loss: 0.2717778 Vali Loss: 1.0885710 Test Loss: 0.6519774
Validation loss decreased (1.107249 --> 1.088571).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 5.200916528701782
Epoch: 12, Steps: 61 | Train Loss: 0.2612902 Vali Loss: 1.0753447 Test Loss: 0.6439044
Validation loss decreased (1.088571 --> 1.075345).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 4.84138560295105
Epoch: 13, Steps: 61 | Train Loss: 0.2517240 Vali Loss: 1.0550046 Test Loss: 0.6339532
Validation loss decreased (1.075345 --> 1.055005).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 5.032104730606079
Epoch: 14, Steps: 61 | Train Loss: 0.2431891 Vali Loss: 1.0433534 Test Loss: 0.6256576
Validation loss decreased (1.055005 --> 1.043353).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 5.151668548583984
Epoch: 15, Steps: 61 | Train Loss: 0.2353184 Vali Loss: 1.0308167 Test Loss: 0.6162689
Validation loss decreased (1.043353 --> 1.030817).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 5.332939624786377
Epoch: 16, Steps: 61 | Train Loss: 0.2281282 Vali Loss: 1.0198023 Test Loss: 0.6081467
Validation loss decreased (1.030817 --> 1.019802).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 4.680595874786377
Epoch: 17, Steps: 61 | Train Loss: 0.2216869 Vali Loss: 1.0044186 Test Loss: 0.5996652
Validation loss decreased (1.019802 --> 1.004419).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 5.176167726516724
Epoch: 18, Steps: 61 | Train Loss: 0.2156137 Vali Loss: 0.9974828 Test Loss: 0.5933316
Validation loss decreased (1.004419 --> 0.997483).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 5.172833681106567
Epoch: 19, Steps: 61 | Train Loss: 0.2100850 Vali Loss: 0.9870366 Test Loss: 0.5866268
Validation loss decreased (0.997483 --> 0.987037).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 5.175621271133423
Epoch: 20, Steps: 61 | Train Loss: 0.2050314 Vali Loss: 0.9777258 Test Loss: 0.5797282
Validation loss decreased (0.987037 --> 0.977726).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 4.941578388214111
Epoch: 21, Steps: 61 | Train Loss: 0.2002354 Vali Loss: 0.9661649 Test Loss: 0.5734984
Validation loss decreased (0.977726 --> 0.966165).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 4.679707050323486
Epoch: 22, Steps: 61 | Train Loss: 0.1960384 Vali Loss: 0.9567746 Test Loss: 0.5676860
Validation loss decreased (0.966165 --> 0.956775).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 5.1792521476745605
Epoch: 23, Steps: 61 | Train Loss: 0.1920136 Vali Loss: 0.9523007 Test Loss: 0.5623672
Validation loss decreased (0.956775 --> 0.952301).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 5.415919542312622
Epoch: 24, Steps: 61 | Train Loss: 0.1882144 Vali Loss: 0.9451930 Test Loss: 0.5580299
Validation loss decreased (0.952301 --> 0.945193).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 4.6231443881988525
Epoch: 25, Steps: 61 | Train Loss: 0.1847740 Vali Loss: 0.9339797 Test Loss: 0.5525704
Validation loss decreased (0.945193 --> 0.933980).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 5.227220058441162
Epoch: 26, Steps: 61 | Train Loss: 0.1815680 Vali Loss: 0.9252687 Test Loss: 0.5474995
Validation loss decreased (0.933980 --> 0.925269).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 5.245588541030884
Epoch: 27, Steps: 61 | Train Loss: 0.1785521 Vali Loss: 0.9216768 Test Loss: 0.5437353
Validation loss decreased (0.925269 --> 0.921677).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 4.143918514251709
Epoch: 28, Steps: 61 | Train Loss: 0.1757133 Vali Loss: 0.9209608 Test Loss: 0.5397025
Validation loss decreased (0.921677 --> 0.920961).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 4.69414210319519
Epoch: 29, Steps: 61 | Train Loss: 0.1730586 Vali Loss: 0.9134938 Test Loss: 0.5364463
Validation loss decreased (0.920961 --> 0.913494).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 4.9927356243133545
Epoch: 30, Steps: 61 | Train Loss: 0.1706290 Vali Loss: 0.9096771 Test Loss: 0.5327643
Validation loss decreased (0.913494 --> 0.909677).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 5.179478406906128
Epoch: 31, Steps: 61 | Train Loss: 0.1683471 Vali Loss: 0.9057456 Test Loss: 0.5290267
Validation loss decreased (0.909677 --> 0.905746).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 4.448927640914917
Epoch: 32, Steps: 61 | Train Loss: 0.1663029 Vali Loss: 0.8982350 Test Loss: 0.5267227
Validation loss decreased (0.905746 --> 0.898235).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 4.941981554031372
Epoch: 33, Steps: 61 | Train Loss: 0.1642412 Vali Loss: 0.8939040 Test Loss: 0.5241220
Validation loss decreased (0.898235 --> 0.893904).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 5.053583145141602
Epoch: 34, Steps: 61 | Train Loss: 0.1623598 Vali Loss: 0.8938903 Test Loss: 0.5211325
Validation loss decreased (0.893904 --> 0.893890).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 4.490008115768433
Epoch: 35, Steps: 61 | Train Loss: 0.1605991 Vali Loss: 0.8851203 Test Loss: 0.5182831
Validation loss decreased (0.893890 --> 0.885120).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 4.671114206314087
Epoch: 36, Steps: 61 | Train Loss: 0.1589518 Vali Loss: 0.8836606 Test Loss: 0.5163044
Validation loss decreased (0.885120 --> 0.883661).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 4.943998336791992
Epoch: 37, Steps: 61 | Train Loss: 0.1573731 Vali Loss: 0.8848026 Test Loss: 0.5134854
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 5.4283127784729
Epoch: 38, Steps: 61 | Train Loss: 0.1559605 Vali Loss: 0.8755850 Test Loss: 0.5115764
Validation loss decreased (0.883661 --> 0.875585).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 4.979505300521851
Epoch: 39, Steps: 61 | Train Loss: 0.1544818 Vali Loss: 0.8794740 Test Loss: 0.5097039
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 4.750749111175537
Epoch: 40, Steps: 61 | Train Loss: 0.1532613 Vali Loss: 0.8745832 Test Loss: 0.5078532
Validation loss decreased (0.875585 --> 0.874583).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 5.183895111083984
Epoch: 41, Steps: 61 | Train Loss: 0.1519914 Vali Loss: 0.8709766 Test Loss: 0.5062349
Validation loss decreased (0.874583 --> 0.870977).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 4.892844915390015
Epoch: 42, Steps: 61 | Train Loss: 0.1508051 Vali Loss: 0.8692613 Test Loss: 0.5043254
Validation loss decreased (0.870977 --> 0.869261).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 5.375869512557983
Epoch: 43, Steps: 61 | Train Loss: 0.1497221 Vali Loss: 0.8667341 Test Loss: 0.5028875
Validation loss decreased (0.869261 --> 0.866734).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 4.739402532577515
Epoch: 44, Steps: 61 | Train Loss: 0.1487168 Vali Loss: 0.8655196 Test Loss: 0.5009333
Validation loss decreased (0.866734 --> 0.865520).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 5.0699896812438965
Epoch: 45, Steps: 61 | Train Loss: 0.1477069 Vali Loss: 0.8633021 Test Loss: 0.4998419
Validation loss decreased (0.865520 --> 0.863302).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 4.50673246383667
Epoch: 46, Steps: 61 | Train Loss: 0.1468404 Vali Loss: 0.8615206 Test Loss: 0.4983601
Validation loss decreased (0.863302 --> 0.861521).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 4.712368965148926
Epoch: 47, Steps: 61 | Train Loss: 0.1459281 Vali Loss: 0.8572313 Test Loss: 0.4970150
Validation loss decreased (0.861521 --> 0.857231).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 4.643884181976318
Epoch: 48, Steps: 61 | Train Loss: 0.1451017 Vali Loss: 0.8569431 Test Loss: 0.4955511
Validation loss decreased (0.857231 --> 0.856943).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 5.174062013626099
Epoch: 49, Steps: 61 | Train Loss: 0.1443926 Vali Loss: 0.8543049 Test Loss: 0.4947089
Validation loss decreased (0.856943 --> 0.854305).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 4.413871765136719
Epoch: 50, Steps: 61 | Train Loss: 0.1436213 Vali Loss: 0.8574499 Test Loss: 0.4934747
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 4.633464813232422
Epoch: 51, Steps: 61 | Train Loss: 0.1429023 Vali Loss: 0.8499175 Test Loss: 0.4926329
Validation loss decreased (0.854305 --> 0.849918).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 4.407175064086914
Epoch: 52, Steps: 61 | Train Loss: 0.1421874 Vali Loss: 0.8488672 Test Loss: 0.4914294
Validation loss decreased (0.849918 --> 0.848867).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 4.545959949493408
Epoch: 53, Steps: 61 | Train Loss: 0.1415972 Vali Loss: 0.8500132 Test Loss: 0.4906129
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 4.342151641845703
Epoch: 54, Steps: 61 | Train Loss: 0.1409901 Vali Loss: 0.8506048 Test Loss: 0.4896257
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 4.7913899421691895
Epoch: 55, Steps: 61 | Train Loss: 0.1404025 Vali Loss: 0.8444627 Test Loss: 0.4887968
Validation loss decreased (0.848867 --> 0.844463).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 4.355534076690674
Epoch: 56, Steps: 61 | Train Loss: 0.1399510 Vali Loss: 0.8456526 Test Loss: 0.4881425
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 4.355079650878906
Epoch: 57, Steps: 61 | Train Loss: 0.1394215 Vali Loss: 0.8472354 Test Loss: 0.4870911
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 4.341759204864502
Epoch: 58, Steps: 61 | Train Loss: 0.1389324 Vali Loss: 0.8428890 Test Loss: 0.4864628
Validation loss decreased (0.844463 --> 0.842889).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 5.217696905136108
Epoch: 59, Steps: 61 | Train Loss: 0.1384792 Vali Loss: 0.8417524 Test Loss: 0.4858391
Validation loss decreased (0.842889 --> 0.841752).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 5.084364891052246
Epoch: 60, Steps: 61 | Train Loss: 0.1380345 Vali Loss: 0.8439685 Test Loss: 0.4851325
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 4.930230379104614
Epoch: 61, Steps: 61 | Train Loss: 0.1376367 Vali Loss: 0.8432147 Test Loss: 0.4843582
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 4.268392324447632
Epoch: 62, Steps: 61 | Train Loss: 0.1371683 Vali Loss: 0.8414756 Test Loss: 0.4840205
Validation loss decreased (0.841752 --> 0.841476).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 4.912688970565796
Epoch: 63, Steps: 61 | Train Loss: 0.1368389 Vali Loss: 0.8403959 Test Loss: 0.4833819
Validation loss decreased (0.841476 --> 0.840396).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 4.736806392669678
Epoch: 64, Steps: 61 | Train Loss: 0.1365084 Vali Loss: 0.8421069 Test Loss: 0.4829130
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 4.485558032989502
Epoch: 65, Steps: 61 | Train Loss: 0.1362065 Vali Loss: 0.8371218 Test Loss: 0.4823587
Validation loss decreased (0.840396 --> 0.837122).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 4.865774154663086
Epoch: 66, Steps: 61 | Train Loss: 0.1357801 Vali Loss: 0.8368438 Test Loss: 0.4818352
Validation loss decreased (0.837122 --> 0.836844).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 4.470201015472412
Epoch: 67, Steps: 61 | Train Loss: 0.1355539 Vali Loss: 0.8346986 Test Loss: 0.4814527
Validation loss decreased (0.836844 --> 0.834699).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 4.510378360748291
Epoch: 68, Steps: 61 | Train Loss: 0.1352748 Vali Loss: 0.8333287 Test Loss: 0.4810088
Validation loss decreased (0.834699 --> 0.833329).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 4.271442413330078
Epoch: 69, Steps: 61 | Train Loss: 0.1350118 Vali Loss: 0.8315718 Test Loss: 0.4805954
Validation loss decreased (0.833329 --> 0.831572).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 4.426151275634766
Epoch: 70, Steps: 61 | Train Loss: 0.1347122 Vali Loss: 0.8359196 Test Loss: 0.4802236
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 4.84775185585022
Epoch: 71, Steps: 61 | Train Loss: 0.1344677 Vali Loss: 0.8331469 Test Loss: 0.4798560
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 4.665328741073608
Epoch: 72, Steps: 61 | Train Loss: 0.1342170 Vali Loss: 0.8300655 Test Loss: 0.4794055
Validation loss decreased (0.831572 --> 0.830065).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 4.40350866317749
Epoch: 73, Steps: 61 | Train Loss: 0.1340069 Vali Loss: 0.8346001 Test Loss: 0.4791245
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 4.742562532424927
Epoch: 74, Steps: 61 | Train Loss: 0.1338330 Vali Loss: 0.8341068 Test Loss: 0.4788344
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 4.406193971633911
Epoch: 75, Steps: 61 | Train Loss: 0.1335863 Vali Loss: 0.8315333 Test Loss: 0.4785456
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 4.5531134605407715
Epoch: 76, Steps: 61 | Train Loss: 0.1333937 Vali Loss: 0.8311719 Test Loss: 0.4783009
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 4.257974863052368
Epoch: 77, Steps: 61 | Train Loss: 0.1331929 Vali Loss: 0.8312288 Test Loss: 0.4779992
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 4.238968133926392
Epoch: 78, Steps: 61 | Train Loss: 0.1330747 Vali Loss: 0.8316219 Test Loss: 0.4777030
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 4.569222450256348
Epoch: 79, Steps: 61 | Train Loss: 0.1329444 Vali Loss: 0.8305213 Test Loss: 0.4774206
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 4.691575765609741
Epoch: 80, Steps: 61 | Train Loss: 0.1327585 Vali Loss: 0.8321172 Test Loss: 0.4771800
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 4.378713369369507
Epoch: 81, Steps: 61 | Train Loss: 0.1325873 Vali Loss: 0.8292090 Test Loss: 0.4770031
Validation loss decreased (0.830065 --> 0.829209).  Saving model ...
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 4.992366552352905
Epoch: 82, Steps: 61 | Train Loss: 0.1324553 Vali Loss: 0.8311349 Test Loss: 0.4767706
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 4.79922890663147
Epoch: 83, Steps: 61 | Train Loss: 0.1322705 Vali Loss: 0.8294822 Test Loss: 0.4765308
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 4.762418746948242
Epoch: 84, Steps: 61 | Train Loss: 0.1322156 Vali Loss: 0.8289408 Test Loss: 0.4763257
Validation loss decreased (0.829209 --> 0.828941).  Saving model ...
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 4.588609933853149
Epoch: 85, Steps: 61 | Train Loss: 0.1320564 Vali Loss: 0.8272938 Test Loss: 0.4761490
Validation loss decreased (0.828941 --> 0.827294).  Saving model ...
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 4.918535947799683
Epoch: 86, Steps: 61 | Train Loss: 0.1319102 Vali Loss: 0.8278387 Test Loss: 0.4759275
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 4.948413610458374
Epoch: 87, Steps: 61 | Train Loss: 0.1318326 Vali Loss: 0.8297355 Test Loss: 0.4757848
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 4.676869630813599
Epoch: 88, Steps: 61 | Train Loss: 0.1317474 Vali Loss: 0.8280610 Test Loss: 0.4756341
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 4.744526386260986
Epoch: 89, Steps: 61 | Train Loss: 0.1316569 Vali Loss: 0.8311178 Test Loss: 0.4755049
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 4.5869951248168945
Epoch: 90, Steps: 61 | Train Loss: 0.1315213 Vali Loss: 0.8278381 Test Loss: 0.4753473
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 4.50160813331604
Epoch: 91, Steps: 61 | Train Loss: 0.1314769 Vali Loss: 0.8240315 Test Loss: 0.4752154
Validation loss decreased (0.827294 --> 0.824032).  Saving model ...
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 4.394871950149536
Epoch: 92, Steps: 61 | Train Loss: 0.1313246 Vali Loss: 0.8294376 Test Loss: 0.4751440
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 4.621825933456421
Epoch: 93, Steps: 61 | Train Loss: 0.1312768 Vali Loss: 0.8264174 Test Loss: 0.4749650
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 4.272425174713135
Epoch: 94, Steps: 61 | Train Loss: 0.1312109 Vali Loss: 0.8266416 Test Loss: 0.4748937
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 4.152362823486328
Epoch: 95, Steps: 61 | Train Loss: 0.1311102 Vali Loss: 0.8258955 Test Loss: 0.4747252
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 4.171949148178101
Epoch: 96, Steps: 61 | Train Loss: 0.1310055 Vali Loss: 0.8232826 Test Loss: 0.4746569
Validation loss decreased (0.824032 --> 0.823283).  Saving model ...
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 4.201236248016357
Epoch: 97, Steps: 61 | Train Loss: 0.1309482 Vali Loss: 0.8273137 Test Loss: 0.4745589
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 4.5408430099487305
Epoch: 98, Steps: 61 | Train Loss: 0.1309212 Vali Loss: 0.8258076 Test Loss: 0.4744489
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 4.539064168930054
Epoch: 99, Steps: 61 | Train Loss: 0.1308301 Vali Loss: 0.8252249 Test Loss: 0.4743518
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 4.531437158584595
Epoch: 100, Steps: 61 | Train Loss: 0.1307831 Vali Loss: 0.8266280 Test Loss: 0.4742794
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.1160680107021042e-06
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=103, out_features=116, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  10705408.0
params:  12064.0
Trainable parameters:  12064
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 4.356847047805786
Epoch: 1, Steps: 61 | Train Loss: 0.3660327 Vali Loss: 0.7143933 Test Loss: 0.3927698
Validation loss decreased (inf --> 0.714393).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.680553197860718
Epoch: 2, Steps: 61 | Train Loss: 0.3465371 Vali Loss: 0.7077309 Test Loss: 0.3889292
Validation loss decreased (0.714393 --> 0.707731).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 4.19425630569458
Epoch: 3, Steps: 61 | Train Loss: 0.3438158 Vali Loss: 0.7078274 Test Loss: 0.3885061
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
Epoch: 4 cost time: 4.444425821304321
Epoch: 4, Steps: 61 | Train Loss: 0.3425989 Vali Loss: 0.7055534 Test Loss: 0.3886480
Validation loss decreased (0.707731 --> 0.705553).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 4.55755877494812
Epoch: 5, Steps: 61 | Train Loss: 0.3419118 Vali Loss: 0.6998504 Test Loss: 0.3878267
Validation loss decreased (0.705553 --> 0.699850).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 4.251439332962036
Epoch: 6, Steps: 61 | Train Loss: 0.3411318 Vali Loss: 0.7044780 Test Loss: 0.3882912
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 4.212191581726074
Epoch: 7, Steps: 61 | Train Loss: 0.3409050 Vali Loss: 0.6997847 Test Loss: 0.3877049
Validation loss decreased (0.699850 --> 0.699785).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 4.773241996765137
Epoch: 8, Steps: 61 | Train Loss: 0.3404002 Vali Loss: 0.7030188 Test Loss: 0.3879855
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 4.482962131500244
Epoch: 9, Steps: 61 | Train Loss: 0.3401263 Vali Loss: 0.7054258 Test Loss: 0.3885911
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 4.533231258392334
Epoch: 10, Steps: 61 | Train Loss: 0.3401009 Vali Loss: 0.7028856 Test Loss: 0.3878989
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 4.220999479293823
Epoch: 11, Steps: 61 | Train Loss: 0.3398822 Vali Loss: 0.7038239 Test Loss: 0.3880900
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.8886263370513916
Epoch: 12, Steps: 61 | Train Loss: 0.3397321 Vali Loss: 0.7032319 Test Loss: 0.3877625
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.9629907608032227
Epoch: 13, Steps: 61 | Train Loss: 0.3395128 Vali Loss: 0.7020390 Test Loss: 0.3877517
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.9200353622436523
Epoch: 14, Steps: 61 | Train Loss: 0.3391923 Vali Loss: 0.7049943 Test Loss: 0.3880936
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.9098269939422607
Epoch: 15, Steps: 61 | Train Loss: 0.3393112 Vali Loss: 0.6966937 Test Loss: 0.3878932
Validation loss decreased (0.699785 --> 0.696694).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 4.027547121047974
Epoch: 16, Steps: 61 | Train Loss: 0.3392081 Vali Loss: 0.6986635 Test Loss: 0.3878524
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.9720022678375244
Epoch: 17, Steps: 61 | Train Loss: 0.3390789 Vali Loss: 0.6965588 Test Loss: 0.3875321
Validation loss decreased (0.696694 --> 0.696559).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.9581263065338135
Epoch: 18, Steps: 61 | Train Loss: 0.3390103 Vali Loss: 0.6991833 Test Loss: 0.3875424
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 4.214143991470337
Epoch: 19, Steps: 61 | Train Loss: 0.3388357 Vali Loss: 0.7025102 Test Loss: 0.3877764
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.685753107070923
Epoch: 20, Steps: 61 | Train Loss: 0.3389431 Vali Loss: 0.7024356 Test Loss: 0.3876278
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 4.610824823379517
Epoch: 21, Steps: 61 | Train Loss: 0.3388702 Vali Loss: 0.7005639 Test Loss: 0.3877519
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 4.482737064361572
Epoch: 22, Steps: 61 | Train Loss: 0.3387068 Vali Loss: 0.6995028 Test Loss: 0.3876459
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 4.646662712097168
Epoch: 23, Steps: 61 | Train Loss: 0.3387335 Vali Loss: 0.7017463 Test Loss: 0.3877143
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 4.486469745635986
Epoch: 24, Steps: 61 | Train Loss: 0.3384691 Vali Loss: 0.6997762 Test Loss: 0.3878212
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 4.439566373825073
Epoch: 25, Steps: 61 | Train Loss: 0.3386671 Vali Loss: 0.7002795 Test Loss: 0.3875888
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 4.322408676147461
Epoch: 26, Steps: 61 | Train Loss: 0.3385781 Vali Loss: 0.7029913 Test Loss: 0.3877525
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 4.618841886520386
Epoch: 27, Steps: 61 | Train Loss: 0.3383441 Vali Loss: 0.7002107 Test Loss: 0.3877707
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 4.549070835113525
Epoch: 28, Steps: 61 | Train Loss: 0.3384692 Vali Loss: 0.6983856 Test Loss: 0.3875459
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 4.452454328536987
Epoch: 29, Steps: 61 | Train Loss: 0.3384564 Vali Loss: 0.6982142 Test Loss: 0.3875637
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 4.501590728759766
Epoch: 30, Steps: 61 | Train Loss: 0.3381953 Vali Loss: 0.6972769 Test Loss: 0.3875008
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 4.686648607254028
Epoch: 31, Steps: 61 | Train Loss: 0.3383360 Vali Loss: 0.6993796 Test Loss: 0.3875842
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 4.189011812210083
Epoch: 32, Steps: 61 | Train Loss: 0.3381758 Vali Loss: 0.7014138 Test Loss: 0.3875840
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 4.059699773788452
Epoch: 33, Steps: 61 | Train Loss: 0.3378557 Vali Loss: 0.6974831 Test Loss: 0.3876043
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 4.3301942348480225
Epoch: 34, Steps: 61 | Train Loss: 0.3380928 Vali Loss: 0.7015632 Test Loss: 0.3875025
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 4.568521976470947
Epoch: 35, Steps: 61 | Train Loss: 0.3380110 Vali Loss: 0.6949775 Test Loss: 0.3875755
Validation loss decreased (0.696559 --> 0.694978).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 4.338058233261108
Epoch: 36, Steps: 61 | Train Loss: 0.3381675 Vali Loss: 0.7036039 Test Loss: 0.3876116
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 4.290902614593506
Epoch: 37, Steps: 61 | Train Loss: 0.3381344 Vali Loss: 0.7009444 Test Loss: 0.3876892
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 4.339918375015259
Epoch: 38, Steps: 61 | Train Loss: 0.3379503 Vali Loss: 0.7016737 Test Loss: 0.3875487
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 4.30889105796814
Epoch: 39, Steps: 61 | Train Loss: 0.3379070 Vali Loss: 0.6997182 Test Loss: 0.3874981
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 4.553374290466309
Epoch: 40, Steps: 61 | Train Loss: 0.3380543 Vali Loss: 0.6982751 Test Loss: 0.3875879
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 4.327045679092407
Epoch: 41, Steps: 61 | Train Loss: 0.3381290 Vali Loss: 0.6984345 Test Loss: 0.3875210
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 4.477624893188477
Epoch: 42, Steps: 61 | Train Loss: 0.3380372 Vali Loss: 0.6991502 Test Loss: 0.3875645
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 4.753268003463745
Epoch: 43, Steps: 61 | Train Loss: 0.3379268 Vali Loss: 0.6947938 Test Loss: 0.3875617
Validation loss decreased (0.694978 --> 0.694794).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 4.175542116165161
Epoch: 44, Steps: 61 | Train Loss: 0.3379122 Vali Loss: 0.7002954 Test Loss: 0.3875343
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 4.485443592071533
Epoch: 45, Steps: 61 | Train Loss: 0.3378305 Vali Loss: 0.7007875 Test Loss: 0.3874847
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 4.371166706085205
Epoch: 46, Steps: 61 | Train Loss: 0.3378037 Vali Loss: 0.7002609 Test Loss: 0.3875458
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 4.578458309173584
Epoch: 47, Steps: 61 | Train Loss: 0.3379315 Vali Loss: 0.6977417 Test Loss: 0.3875202
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 4.211770057678223
Epoch: 48, Steps: 61 | Train Loss: 0.3377554 Vali Loss: 0.7000518 Test Loss: 0.3875533
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 4.527454614639282
Epoch: 49, Steps: 61 | Train Loss: 0.3377815 Vali Loss: 0.7006666 Test Loss: 0.3875442
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 4.376254081726074
Epoch: 50, Steps: 61 | Train Loss: 0.3378472 Vali Loss: 0.7011148 Test Loss: 0.3875617
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 4.4231109619140625
Epoch: 51, Steps: 61 | Train Loss: 0.3376669 Vali Loss: 0.7036727 Test Loss: 0.3874971
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 4.413930892944336
Epoch: 52, Steps: 61 | Train Loss: 0.3379210 Vali Loss: 0.7010193 Test Loss: 0.3875695
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 4.185427904129028
Epoch: 53, Steps: 61 | Train Loss: 0.3378011 Vali Loss: 0.7049505 Test Loss: 0.3875721
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 4.600192308425903
Epoch: 54, Steps: 61 | Train Loss: 0.3377821 Vali Loss: 0.7006877 Test Loss: 0.3875379
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 4.288237571716309
Epoch: 55, Steps: 61 | Train Loss: 0.3378003 Vali Loss: 0.7005811 Test Loss: 0.3875413
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 4.156643867492676
Epoch: 56, Steps: 61 | Train Loss: 0.3376663 Vali Loss: 0.7003669 Test Loss: 0.3875494
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 4.485067844390869
Epoch: 57, Steps: 61 | Train Loss: 0.3378515 Vali Loss: 0.7015984 Test Loss: 0.3874964
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 4.574943780899048
Epoch: 58, Steps: 61 | Train Loss: 0.3377374 Vali Loss: 0.6981068 Test Loss: 0.3875807
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 4.44916844367981
Epoch: 59, Steps: 61 | Train Loss: 0.3378079 Vali Loss: 0.7019233 Test Loss: 0.3874709
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 4.712909460067749
Epoch: 60, Steps: 61 | Train Loss: 0.3379235 Vali Loss: 0.6996608 Test Loss: 0.3875653
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 4.302950382232666
Epoch: 61, Steps: 61 | Train Loss: 0.3376813 Vali Loss: 0.6996075 Test Loss: 0.3875357
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 4.508753776550293
Epoch: 62, Steps: 61 | Train Loss: 0.3376181 Vali Loss: 0.7026591 Test Loss: 0.3875460
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 4.3167033195495605
Epoch: 63, Steps: 61 | Train Loss: 0.3376903 Vali Loss: 0.7029082 Test Loss: 0.3875252
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.38714274764060974, mae:0.40818822383880615, rse:0.5910080671310425, corr:[0.2724933  0.27744594 0.27813426 0.275318   0.2717695  0.26919758
 0.26798066 0.26795927 0.26823235 0.2683603  0.2681973  0.2677996
 0.26755095 0.26759788 0.26789188 0.2682291  0.26821834 0.26790988
 0.26734814 0.26671115 0.26626423 0.2662584  0.2662696  0.26633403
 0.2662724  0.26616463 0.26600873 0.26562506 0.26504517 0.2644259
 0.2640072  0.26373294 0.2636891  0.26379687 0.26380187 0.2637456
 0.2637165  0.26373962 0.26381117 0.26391256 0.26420918 0.26445147
 0.26444748 0.26430663 0.26422757 0.2642943  0.2644777  0.2645428
 0.2639634  0.2630504  0.26175842 0.26042128 0.25929275 0.25827423
 0.2575164  0.25708768 0.25681978 0.25673157 0.25654203 0.25633267
 0.25606257 0.25583246 0.2556402  0.25560015 0.25564596 0.2556758
 0.25578585 0.25579575 0.25576603 0.25574467 0.2556161  0.25506648
 0.2542343  0.25334406 0.25248712 0.25195265 0.25159135 0.25114363
 0.25053737 0.24986029 0.24917954 0.2486552  0.24825361 0.24792515
 0.24771817 0.24748082 0.24724765 0.24698357 0.2468736  0.24700134
 0.24705213 0.24676411 0.24639532 0.24664333 0.24830474 0.25079966]
