Args in experiment:
Namespace(H_order=2, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_180_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_180_96_FITS_ETTh1_ftM_sl180_ll48_pl96_H2_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8365
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=26, out_features=39, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  908544.0
params:  1053.0
Trainable parameters:  1053
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.023240089416504
Epoch: 1, Steps: 65 | Train Loss: 0.5769060 Vali Loss: 1.0450773 Test Loss: 0.5592228
Validation loss decreased (inf --> 1.045077).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.058713674545288
Epoch: 2, Steps: 65 | Train Loss: 0.4492984 Vali Loss: 0.8982587 Test Loss: 0.4609443
Validation loss decreased (1.045077 --> 0.898259).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.0700178146362305
Epoch: 3, Steps: 65 | Train Loss: 0.4054693 Vali Loss: 0.8309696 Test Loss: 0.4254283
Validation loss decreased (0.898259 --> 0.830970).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 0.9592874050140381
Epoch: 4, Steps: 65 | Train Loss: 0.3867437 Vali Loss: 0.7999421 Test Loss: 0.4093135
Validation loss decreased (0.830970 --> 0.799942).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 0.9486100673675537
Epoch: 5, Steps: 65 | Train Loss: 0.3772991 Vali Loss: 0.7800184 Test Loss: 0.4008859
Validation loss decreased (0.799942 --> 0.780018).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.0271515846252441
Epoch: 6, Steps: 65 | Train Loss: 0.3711813 Vali Loss: 0.7638250 Test Loss: 0.3962187
Validation loss decreased (0.780018 --> 0.763825).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 0.9369478225708008
Epoch: 7, Steps: 65 | Train Loss: 0.3682763 Vali Loss: 0.7594842 Test Loss: 0.3935531
Validation loss decreased (0.763825 --> 0.759484).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.0056095123291016
Epoch: 8, Steps: 65 | Train Loss: 0.3655154 Vali Loss: 0.7537600 Test Loss: 0.3918317
Validation loss decreased (0.759484 --> 0.753760).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.0511014461517334
Epoch: 9, Steps: 65 | Train Loss: 0.3643552 Vali Loss: 0.7470762 Test Loss: 0.3908269
Validation loss decreased (0.753760 --> 0.747076).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.0039284229278564
Epoch: 10, Steps: 65 | Train Loss: 0.3628509 Vali Loss: 0.7448726 Test Loss: 0.3903501
Validation loss decreased (0.747076 --> 0.744873).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.0320892333984375
Epoch: 11, Steps: 65 | Train Loss: 0.3616336 Vali Loss: 0.7364644 Test Loss: 0.3900734
Validation loss decreased (0.744873 --> 0.736464).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.0514795780181885
Epoch: 12, Steps: 65 | Train Loss: 0.3612988 Vali Loss: 0.7349623 Test Loss: 0.3898880
Validation loss decreased (0.736464 --> 0.734962).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.0577929019927979
Epoch: 13, Steps: 65 | Train Loss: 0.3607384 Vali Loss: 0.7352311 Test Loss: 0.3897788
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 0.9153072834014893
Epoch: 14, Steps: 65 | Train Loss: 0.3600881 Vali Loss: 0.7385247 Test Loss: 0.3898356
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 0.9204940795898438
Epoch: 15, Steps: 65 | Train Loss: 0.3600046 Vali Loss: 0.7307424 Test Loss: 0.3896953
Validation loss decreased (0.734962 --> 0.730742).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 0.9487340450286865
Epoch: 16, Steps: 65 | Train Loss: 0.3599879 Vali Loss: 0.7332122 Test Loss: 0.3896704
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.0017368793487549
Epoch: 17, Steps: 65 | Train Loss: 0.3595565 Vali Loss: 0.7279887 Test Loss: 0.3897508
Validation loss decreased (0.730742 --> 0.727989).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 0.9260835647583008
Epoch: 18, Steps: 65 | Train Loss: 0.3593959 Vali Loss: 0.7221194 Test Loss: 0.3896882
Validation loss decreased (0.727989 --> 0.722119).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 0.9924254417419434
Epoch: 19, Steps: 65 | Train Loss: 0.3591286 Vali Loss: 0.7263350 Test Loss: 0.3896528
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.0659947395324707
Epoch: 20, Steps: 65 | Train Loss: 0.3589515 Vali Loss: 0.7256401 Test Loss: 0.3896967
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 0.9740664958953857
Epoch: 21, Steps: 65 | Train Loss: 0.3588430 Vali Loss: 0.7232921 Test Loss: 0.3897386
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 0.8976516723632812
Epoch: 22, Steps: 65 | Train Loss: 0.3584735 Vali Loss: 0.7253952 Test Loss: 0.3897251
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.0255391597747803
Epoch: 23, Steps: 65 | Train Loss: 0.3588017 Vali Loss: 0.7229934 Test Loss: 0.3896839
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.0318019390106201
Epoch: 24, Steps: 65 | Train Loss: 0.3584556 Vali Loss: 0.7217624 Test Loss: 0.3897512
Validation loss decreased (0.722119 --> 0.721762).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 0.9927346706390381
Epoch: 25, Steps: 65 | Train Loss: 0.3579109 Vali Loss: 0.7242140 Test Loss: 0.3897226
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 0.9850547313690186
Epoch: 26, Steps: 65 | Train Loss: 0.3579003 Vali Loss: 0.7237383 Test Loss: 0.3897561
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.0048072338104248
Epoch: 27, Steps: 65 | Train Loss: 0.3580796 Vali Loss: 0.7227923 Test Loss: 0.3897302
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.0011367797851562
Epoch: 28, Steps: 65 | Train Loss: 0.3581388 Vali Loss: 0.7211576 Test Loss: 0.3897190
Validation loss decreased (0.721762 --> 0.721158).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.0483112335205078
Epoch: 29, Steps: 65 | Train Loss: 0.3580699 Vali Loss: 0.7220356 Test Loss: 0.3897717
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.0260369777679443
Epoch: 30, Steps: 65 | Train Loss: 0.3581417 Vali Loss: 0.7198051 Test Loss: 0.3896821
Validation loss decreased (0.721158 --> 0.719805).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 0.9042091369628906
Epoch: 31, Steps: 65 | Train Loss: 0.3580275 Vali Loss: 0.7197754 Test Loss: 0.3896798
Validation loss decreased (0.719805 --> 0.719775).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 0.9437086582183838
Epoch: 32, Steps: 65 | Train Loss: 0.3577153 Vali Loss: 0.7215303 Test Loss: 0.3896835
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 0.9290146827697754
Epoch: 33, Steps: 65 | Train Loss: 0.3577333 Vali Loss: 0.7166871 Test Loss: 0.3897343
Validation loss decreased (0.719775 --> 0.716687).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 0.9698936939239502
Epoch: 34, Steps: 65 | Train Loss: 0.3577052 Vali Loss: 0.7232548 Test Loss: 0.3897136
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.0658807754516602
Epoch: 35, Steps: 65 | Train Loss: 0.3576776 Vali Loss: 0.7203571 Test Loss: 0.3896997
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 0.9598865509033203
Epoch: 36, Steps: 65 | Train Loss: 0.3576338 Vali Loss: 0.7175586 Test Loss: 0.3897142
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.0113346576690674
Epoch: 37, Steps: 65 | Train Loss: 0.3579214 Vali Loss: 0.7180818 Test Loss: 0.3897120
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 0.9946870803833008
Epoch: 38, Steps: 65 | Train Loss: 0.3577816 Vali Loss: 0.7200911 Test Loss: 0.3896738
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.0858564376831055
Epoch: 39, Steps: 65 | Train Loss: 0.3574958 Vali Loss: 0.7224236 Test Loss: 0.3896853
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.0420706272125244
Epoch: 40, Steps: 65 | Train Loss: 0.3576096 Vali Loss: 0.7163943 Test Loss: 0.3896585
Validation loss decreased (0.716687 --> 0.716394).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 0.8932344913482666
Epoch: 41, Steps: 65 | Train Loss: 0.3572493 Vali Loss: 0.7169896 Test Loss: 0.3896731
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 0.9822680950164795
Epoch: 42, Steps: 65 | Train Loss: 0.3575942 Vali Loss: 0.7164929 Test Loss: 0.3897158
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.0624339580535889
Epoch: 43, Steps: 65 | Train Loss: 0.3572795 Vali Loss: 0.7191251 Test Loss: 0.3896843
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.0048949718475342
Epoch: 44, Steps: 65 | Train Loss: 0.3577310 Vali Loss: 0.7163002 Test Loss: 0.3897109
Validation loss decreased (0.716394 --> 0.716300).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.03645658493042
Epoch: 45, Steps: 65 | Train Loss: 0.3572932 Vali Loss: 0.7230905 Test Loss: 0.3896794
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 0.976283073425293
Epoch: 46, Steps: 65 | Train Loss: 0.3576480 Vali Loss: 0.7179375 Test Loss: 0.3896757
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 0.9505772590637207
Epoch: 47, Steps: 65 | Train Loss: 0.3576365 Vali Loss: 0.7185767 Test Loss: 0.3896754
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.09958815574646
Epoch: 48, Steps: 65 | Train Loss: 0.3575569 Vali Loss: 0.7173792 Test Loss: 0.3897156
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.0867600440979004
Epoch: 49, Steps: 65 | Train Loss: 0.3572447 Vali Loss: 0.7148477 Test Loss: 0.3896737
Validation loss decreased (0.716300 --> 0.714848).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 0.9245181083679199
Epoch: 50, Steps: 65 | Train Loss: 0.3574813 Vali Loss: 0.7173333 Test Loss: 0.3896810
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.038027048110962
Epoch: 51, Steps: 65 | Train Loss: 0.3573265 Vali Loss: 0.7142163 Test Loss: 0.3896487
Validation loss decreased (0.714848 --> 0.714216).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 0.88128662109375
Epoch: 52, Steps: 65 | Train Loss: 0.3577150 Vali Loss: 0.7170579 Test Loss: 0.3896874
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.0211937427520752
Epoch: 53, Steps: 65 | Train Loss: 0.3573881 Vali Loss: 0.7182809 Test Loss: 0.3896906
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 0.9695639610290527
Epoch: 54, Steps: 65 | Train Loss: 0.3573236 Vali Loss: 0.7205079 Test Loss: 0.3896814
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 0.9469089508056641
Epoch: 55, Steps: 65 | Train Loss: 0.3572598 Vali Loss: 0.7173883 Test Loss: 0.3896835
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.002967357635498
Epoch: 56, Steps: 65 | Train Loss: 0.3572130 Vali Loss: 0.7160503 Test Loss: 0.3896865
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 0.9949586391448975
Epoch: 57, Steps: 65 | Train Loss: 0.3573995 Vali Loss: 0.7159501 Test Loss: 0.3896630
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 0.9240005016326904
Epoch: 58, Steps: 65 | Train Loss: 0.3574360 Vali Loss: 0.7193371 Test Loss: 0.3896675
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 0.9728126525878906
Epoch: 59, Steps: 65 | Train Loss: 0.3576488 Vali Loss: 0.7141455 Test Loss: 0.3896605
Validation loss decreased (0.714216 --> 0.714145).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.0162181854248047
Epoch: 60, Steps: 65 | Train Loss: 0.3575486 Vali Loss: 0.7180980 Test Loss: 0.3896613
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 0.9665803909301758
Epoch: 61, Steps: 65 | Train Loss: 0.3574852 Vali Loss: 0.7207243 Test Loss: 0.3896820
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.0173208713531494
Epoch: 62, Steps: 65 | Train Loss: 0.3574300 Vali Loss: 0.7167264 Test Loss: 0.3896690
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.0201003551483154
Epoch: 63, Steps: 65 | Train Loss: 0.3573232 Vali Loss: 0.7187301 Test Loss: 0.3896677
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 0.9241032600402832
Epoch: 64, Steps: 65 | Train Loss: 0.3571737 Vali Loss: 0.7170043 Test Loss: 0.3896782
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.0796945095062256
Epoch: 65, Steps: 65 | Train Loss: 0.3569872 Vali Loss: 0.7172350 Test Loss: 0.3896846
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.0709712505340576
Epoch: 66, Steps: 65 | Train Loss: 0.3570359 Vali Loss: 0.7185496 Test Loss: 0.3896688
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 0.936582088470459
Epoch: 67, Steps: 65 | Train Loss: 0.3574327 Vali Loss: 0.7183026 Test Loss: 0.3896797
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 0.9431688785552979
Epoch: 68, Steps: 65 | Train Loss: 0.3571621 Vali Loss: 0.7174138 Test Loss: 0.3896755
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.034085750579834
Epoch: 69, Steps: 65 | Train Loss: 0.3574407 Vali Loss: 0.7166027 Test Loss: 0.3896623
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 0.9390609264373779
Epoch: 70, Steps: 65 | Train Loss: 0.3569333 Vali Loss: 0.7173480 Test Loss: 0.3896807
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 0.9578402042388916
Epoch: 71, Steps: 65 | Train Loss: 0.3569670 Vali Loss: 0.7179976 Test Loss: 0.3896740
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.1110141277313232
Epoch: 72, Steps: 65 | Train Loss: 0.3572076 Vali Loss: 0.7188382 Test Loss: 0.3896795
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.1829900741577148
Epoch: 73, Steps: 65 | Train Loss: 0.3572755 Vali Loss: 0.7141230 Test Loss: 0.3896688
Validation loss decreased (0.714145 --> 0.714123).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 0.9540717601776123
Epoch: 74, Steps: 65 | Train Loss: 0.3576074 Vali Loss: 0.7170385 Test Loss: 0.3896743
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.0585474967956543
Epoch: 75, Steps: 65 | Train Loss: 0.3572054 Vali Loss: 0.7136227 Test Loss: 0.3896734
Validation loss decreased (0.714123 --> 0.713623).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.000497579574585
Epoch: 76, Steps: 65 | Train Loss: 0.3569785 Vali Loss: 0.7187318 Test Loss: 0.3896683
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.0099239349365234
Epoch: 77, Steps: 65 | Train Loss: 0.3572157 Vali Loss: 0.7151206 Test Loss: 0.3896737
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 0.8730249404907227
Epoch: 78, Steps: 65 | Train Loss: 0.3570840 Vali Loss: 0.7172602 Test Loss: 0.3896742
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.0519874095916748
Epoch: 79, Steps: 65 | Train Loss: 0.3574454 Vali Loss: 0.7184672 Test Loss: 0.3896738
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 0.9784622192382812
Epoch: 80, Steps: 65 | Train Loss: 0.3570423 Vali Loss: 0.7184277 Test Loss: 0.3896762
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 0.94305419921875
Epoch: 81, Steps: 65 | Train Loss: 0.3574407 Vali Loss: 0.7188834 Test Loss: 0.3896728
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 0.9707598686218262
Epoch: 82, Steps: 65 | Train Loss: 0.3573879 Vali Loss: 0.7171201 Test Loss: 0.3896811
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 0.986560583114624
Epoch: 83, Steps: 65 | Train Loss: 0.3574102 Vali Loss: 0.7145336 Test Loss: 0.3896756
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.0111825466156006
Epoch: 84, Steps: 65 | Train Loss: 0.3571441 Vali Loss: 0.7186019 Test Loss: 0.3896698
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 0.9634270668029785
Epoch: 85, Steps: 65 | Train Loss: 0.3570420 Vali Loss: 0.7140902 Test Loss: 0.3896663
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 0.9228696823120117
Epoch: 86, Steps: 65 | Train Loss: 0.3571885 Vali Loss: 0.7186035 Test Loss: 0.3896671
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 0.9305260181427002
Epoch: 87, Steps: 65 | Train Loss: 0.3571356 Vali Loss: 0.7156547 Test Loss: 0.3896728
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 0.9410555362701416
Epoch: 88, Steps: 65 | Train Loss: 0.3572168 Vali Loss: 0.7167415 Test Loss: 0.3896745
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.036076545715332
Epoch: 89, Steps: 65 | Train Loss: 0.3568518 Vali Loss: 0.7135035 Test Loss: 0.3896717
Validation loss decreased (0.713623 --> 0.713504).  Saving model ...
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 0.9920914173126221
Epoch: 90, Steps: 65 | Train Loss: 0.3573911 Vali Loss: 0.7179444 Test Loss: 0.3896680
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 0.9153034687042236
Epoch: 91, Steps: 65 | Train Loss: 0.3573401 Vali Loss: 0.7144418 Test Loss: 0.3896753
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 0.9799196720123291
Epoch: 92, Steps: 65 | Train Loss: 0.3569205 Vali Loss: 0.7166039 Test Loss: 0.3896770
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 0.9995622634887695
Epoch: 93, Steps: 65 | Train Loss: 0.3571549 Vali Loss: 0.7174862 Test Loss: 0.3896790
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 0.9185390472412109
Epoch: 94, Steps: 65 | Train Loss: 0.3571123 Vali Loss: 0.7184964 Test Loss: 0.3896714
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.0085477828979492
Epoch: 95, Steps: 65 | Train Loss: 0.3567303 Vali Loss: 0.7198859 Test Loss: 0.3896809
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.023711919784546
Epoch: 96, Steps: 65 | Train Loss: 0.3571732 Vali Loss: 0.7175677 Test Loss: 0.3896780
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 0.9799115657806396
Epoch: 97, Steps: 65 | Train Loss: 0.3574951 Vali Loss: 0.7200221 Test Loss: 0.3896752
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.0788679122924805
Epoch: 98, Steps: 65 | Train Loss: 0.3571578 Vali Loss: 0.7213027 Test Loss: 0.3896762
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 0.9326653480529785
Epoch: 99, Steps: 65 | Train Loss: 0.3572634 Vali Loss: 0.7148560 Test Loss: 0.3896753
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 0.9546453952789307
Epoch: 100, Steps: 65 | Train Loss: 0.3570420 Vali Loss: 0.7169098 Test Loss: 0.3896732
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.1160680107021042e-06
>>>>>>>testing : ETTh1_180_96_FITS_ETTh1_ftM_sl180_ll48_pl96_H2_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.38899901509284973, mae:0.4020163118839264, rse:0.5924232602119446, corr:[0.2721165  0.27538633 0.27612275 0.27451706 0.27177697 0.2696027
 0.2687319  0.26893955 0.26907852 0.26872653 0.26820564 0.26796326
 0.26797244 0.26766822 0.26726052 0.267115   0.2671707  0.26723707
 0.26716354 0.26700827 0.26690882 0.26695    0.26682353 0.26616165
 0.26509583 0.2646632  0.2645801  0.264413   0.26383016 0.26318032
 0.26276445 0.26258802 0.26254147 0.2624884  0.26247263 0.26269567
 0.26302376 0.26303223 0.2629398  0.263028   0.2633504  0.26357132
 0.26354352 0.2635369  0.26380202 0.26416653 0.26440012 0.26384857
 0.26248807 0.2615085  0.26055837 0.25938728 0.2579359  0.25657263
 0.2558348  0.25576755 0.25590548 0.25604585 0.25597838 0.2563302
 0.25685292 0.25678366 0.25636718 0.25607982 0.2561783  0.25644967
 0.25665444 0.25669548 0.25670758 0.25665772 0.2563554  0.25519553
 0.25349042 0.2526217  0.2523238  0.25209492 0.2515858  0.25088072
 0.25051054 0.25047886 0.2503647  0.25004977 0.24954239 0.24951778
 0.25014552 0.2503264  0.25016013 0.24988614 0.24960415 0.24919789
 0.24853055 0.24791119 0.24791181 0.24858332 0.24956842 0.24921785]
