Args in experiment:
Namespace(H_order=2, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=42, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_360_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_360_96_FITS_ETTh1_ftM_sl360_ll48_pl96_H2_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8185
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=42, out_features=53, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1994496.0
params:  2279.0
Trainable parameters:  2279
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.1394476890563965
Epoch: 1, Steps: 63 | Train Loss: 0.6568005 Vali Loss: 1.1880757 Test Loss: 0.6681004
Validation loss decreased (inf --> 1.188076).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.186241865158081
Epoch: 2, Steps: 63 | Train Loss: 0.4859004 Vali Loss: 0.9511897 Test Loss: 0.5141262
Validation loss decreased (1.188076 --> 0.951190).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.2242696285247803
Epoch: 3, Steps: 63 | Train Loss: 0.4205002 Vali Loss: 0.8420528 Test Loss: 0.4508086
Validation loss decreased (0.951190 --> 0.842053).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.2675840854644775
Epoch: 4, Steps: 63 | Train Loss: 0.3915156 Vali Loss: 0.7914704 Test Loss: 0.4225655
Validation loss decreased (0.842053 --> 0.791470).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.2085857391357422
Epoch: 5, Steps: 63 | Train Loss: 0.3774075 Vali Loss: 0.7654821 Test Loss: 0.4099905
Validation loss decreased (0.791470 --> 0.765482).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.1422090530395508
Epoch: 6, Steps: 63 | Train Loss: 0.3699721 Vali Loss: 0.7480819 Test Loss: 0.4039180
Validation loss decreased (0.765482 --> 0.748082).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.2020423412322998
Epoch: 7, Steps: 63 | Train Loss: 0.3658437 Vali Loss: 0.7404420 Test Loss: 0.4010727
Validation loss decreased (0.748082 --> 0.740442).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.1680448055267334
Epoch: 8, Steps: 63 | Train Loss: 0.3637616 Vali Loss: 0.7324788 Test Loss: 0.3995799
Validation loss decreased (0.740442 --> 0.732479).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.1419122219085693
Epoch: 9, Steps: 63 | Train Loss: 0.3615999 Vali Loss: 0.7252353 Test Loss: 0.3989963
Validation loss decreased (0.732479 --> 0.725235).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.1744310855865479
Epoch: 10, Steps: 63 | Train Loss: 0.3612035 Vali Loss: 0.7194287 Test Loss: 0.3983619
Validation loss decreased (0.725235 --> 0.719429).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.2468082904815674
Epoch: 11, Steps: 63 | Train Loss: 0.3604681 Vali Loss: 0.7190218 Test Loss: 0.3982100
Validation loss decreased (0.719429 --> 0.719022).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.0621929168701172
Epoch: 12, Steps: 63 | Train Loss: 0.3592716 Vali Loss: 0.7143506 Test Loss: 0.3979586
Validation loss decreased (0.719022 --> 0.714351).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.1941697597503662
Epoch: 13, Steps: 63 | Train Loss: 0.3587188 Vali Loss: 0.7118874 Test Loss: 0.3979019
Validation loss decreased (0.714351 --> 0.711887).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.18009352684021
Epoch: 14, Steps: 63 | Train Loss: 0.3582717 Vali Loss: 0.7054927 Test Loss: 0.3978931
Validation loss decreased (0.711887 --> 0.705493).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.1312029361724854
Epoch: 15, Steps: 63 | Train Loss: 0.3581842 Vali Loss: 0.7073538 Test Loss: 0.3977184
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.1671321392059326
Epoch: 16, Steps: 63 | Train Loss: 0.3575005 Vali Loss: 0.7049411 Test Loss: 0.3977216
Validation loss decreased (0.705493 --> 0.704941).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.1376028060913086
Epoch: 17, Steps: 63 | Train Loss: 0.3574121 Vali Loss: 0.7035152 Test Loss: 0.3977311
Validation loss decreased (0.704941 --> 0.703515).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.1445252895355225
Epoch: 18, Steps: 63 | Train Loss: 0.3575117 Vali Loss: 0.7058822 Test Loss: 0.3977669
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.1510193347930908
Epoch: 19, Steps: 63 | Train Loss: 0.3571901 Vali Loss: 0.6979232 Test Loss: 0.3976055
Validation loss decreased (0.703515 --> 0.697923).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.163877248764038
Epoch: 20, Steps: 63 | Train Loss: 0.3572983 Vali Loss: 0.7003520 Test Loss: 0.3975648
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.1326942443847656
Epoch: 21, Steps: 63 | Train Loss: 0.3565043 Vali Loss: 0.7036858 Test Loss: 0.3976067
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.1688218116760254
Epoch: 22, Steps: 63 | Train Loss: 0.3569040 Vali Loss: 0.6976113 Test Loss: 0.3976266
Validation loss decreased (0.697923 --> 0.697611).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.1919620037078857
Epoch: 23, Steps: 63 | Train Loss: 0.3568347 Vali Loss: 0.6987136 Test Loss: 0.3974153
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.2269890308380127
Epoch: 24, Steps: 63 | Train Loss: 0.3565483 Vali Loss: 0.7018908 Test Loss: 0.3972998
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.1711957454681396
Epoch: 25, Steps: 63 | Train Loss: 0.3565563 Vali Loss: 0.6940614 Test Loss: 0.3974106
Validation loss decreased (0.697611 --> 0.694061).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.1496756076812744
Epoch: 26, Steps: 63 | Train Loss: 0.3567413 Vali Loss: 0.6991242 Test Loss: 0.3974694
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.1833710670471191
Epoch: 27, Steps: 63 | Train Loss: 0.3560656 Vali Loss: 0.6985161 Test Loss: 0.3974914
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.1417694091796875
Epoch: 28, Steps: 63 | Train Loss: 0.3561388 Vali Loss: 0.6993300 Test Loss: 0.3974749
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.0633258819580078
Epoch: 29, Steps: 63 | Train Loss: 0.3560078 Vali Loss: 0.6958477 Test Loss: 0.3974342
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.1193463802337646
Epoch: 30, Steps: 63 | Train Loss: 0.3561052 Vali Loss: 0.6951307 Test Loss: 0.3974035
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.2166252136230469
Epoch: 31, Steps: 63 | Train Loss: 0.3557161 Vali Loss: 0.6965566 Test Loss: 0.3974313
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.1658120155334473
Epoch: 32, Steps: 63 | Train Loss: 0.3560161 Vali Loss: 0.6954246 Test Loss: 0.3973588
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.2340786457061768
Epoch: 33, Steps: 63 | Train Loss: 0.3555405 Vali Loss: 0.6958337 Test Loss: 0.3974140
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.1725451946258545
Epoch: 34, Steps: 63 | Train Loss: 0.3555136 Vali Loss: 0.6962305 Test Loss: 0.3974480
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.1294307708740234
Epoch: 35, Steps: 63 | Train Loss: 0.3551947 Vali Loss: 0.6977835 Test Loss: 0.3973645
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.207289218902588
Epoch: 36, Steps: 63 | Train Loss: 0.3558613 Vali Loss: 0.6970221 Test Loss: 0.3974281
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.2113282680511475
Epoch: 37, Steps: 63 | Train Loss: 0.3561308 Vali Loss: 0.6967227 Test Loss: 0.3974112
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.1696555614471436
Epoch: 38, Steps: 63 | Train Loss: 0.3556858 Vali Loss: 0.6941768 Test Loss: 0.3973761
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.1847589015960693
Epoch: 39, Steps: 63 | Train Loss: 0.3559114 Vali Loss: 0.6949673 Test Loss: 0.3973569
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.1655845642089844
Epoch: 40, Steps: 63 | Train Loss: 0.3553729 Vali Loss: 0.6954328 Test Loss: 0.3974111
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.1510200500488281
Epoch: 41, Steps: 63 | Train Loss: 0.3556755 Vali Loss: 0.6935982 Test Loss: 0.3973635
Validation loss decreased (0.694061 --> 0.693598).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.2077651023864746
Epoch: 42, Steps: 63 | Train Loss: 0.3554030 Vali Loss: 0.6947160 Test Loss: 0.3973765
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.1896333694458008
Epoch: 43, Steps: 63 | Train Loss: 0.3553280 Vali Loss: 0.6924188 Test Loss: 0.3973351
Validation loss decreased (0.693598 --> 0.692419).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.1646876335144043
Epoch: 44, Steps: 63 | Train Loss: 0.3555301 Vali Loss: 0.6919234 Test Loss: 0.3973061
Validation loss decreased (0.692419 --> 0.691923).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.1849803924560547
Epoch: 45, Steps: 63 | Train Loss: 0.3556959 Vali Loss: 0.6924732 Test Loss: 0.3973754
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.1396913528442383
Epoch: 46, Steps: 63 | Train Loss: 0.3555263 Vali Loss: 0.6954085 Test Loss: 0.3973883
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.1971325874328613
Epoch: 47, Steps: 63 | Train Loss: 0.3549645 Vali Loss: 0.6956660 Test Loss: 0.3972817
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.090714454650879
Epoch: 48, Steps: 63 | Train Loss: 0.3554130 Vali Loss: 0.6964083 Test Loss: 0.3973299
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.1048061847686768
Epoch: 49, Steps: 63 | Train Loss: 0.3554951 Vali Loss: 0.6972865 Test Loss: 0.3973581
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.148834228515625
Epoch: 50, Steps: 63 | Train Loss: 0.3542316 Vali Loss: 0.6964182 Test Loss: 0.3973403
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.216500997543335
Epoch: 51, Steps: 63 | Train Loss: 0.3550420 Vali Loss: 0.6970251 Test Loss: 0.3972899
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.113039493560791
Epoch: 52, Steps: 63 | Train Loss: 0.3559834 Vali Loss: 0.6914785 Test Loss: 0.3972997
Validation loss decreased (0.691923 --> 0.691478).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.2289669513702393
Epoch: 53, Steps: 63 | Train Loss: 0.3552601 Vali Loss: 0.6951274 Test Loss: 0.3972957
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.058244228363037
Epoch: 54, Steps: 63 | Train Loss: 0.3552113 Vali Loss: 0.6916488 Test Loss: 0.3973068
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.1575171947479248
Epoch: 55, Steps: 63 | Train Loss: 0.3560240 Vali Loss: 0.6967978 Test Loss: 0.3973193
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.1080093383789062
Epoch: 56, Steps: 63 | Train Loss: 0.3553664 Vali Loss: 0.6944938 Test Loss: 0.3973175
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.1633632183074951
Epoch: 57, Steps: 63 | Train Loss: 0.3555538 Vali Loss: 0.6953682 Test Loss: 0.3973108
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.1831040382385254
Epoch: 58, Steps: 63 | Train Loss: 0.3546884 Vali Loss: 0.6919042 Test Loss: 0.3973376
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.1441786289215088
Epoch: 59, Steps: 63 | Train Loss: 0.3551145 Vali Loss: 0.6972543 Test Loss: 0.3973262
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.1880946159362793
Epoch: 60, Steps: 63 | Train Loss: 0.3549523 Vali Loss: 0.6949350 Test Loss: 0.3972954
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.0458288192749023
Epoch: 61, Steps: 63 | Train Loss: 0.3551577 Vali Loss: 0.6925697 Test Loss: 0.3973122
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.1233837604522705
Epoch: 62, Steps: 63 | Train Loss: 0.3553067 Vali Loss: 0.6930825 Test Loss: 0.3973212
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.125138282775879
Epoch: 63, Steps: 63 | Train Loss: 0.3549797 Vali Loss: 0.6946441 Test Loss: 0.3973240
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.1182031631469727
Epoch: 64, Steps: 63 | Train Loss: 0.3552852 Vali Loss: 0.6937200 Test Loss: 0.3973234
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.2674505710601807
Epoch: 65, Steps: 63 | Train Loss: 0.3553164 Vali Loss: 0.6917639 Test Loss: 0.3973116
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.1640186309814453
Epoch: 66, Steps: 63 | Train Loss: 0.3550921 Vali Loss: 0.6912779 Test Loss: 0.3973290
Validation loss decreased (0.691478 --> 0.691278).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.1844382286071777
Epoch: 67, Steps: 63 | Train Loss: 0.3550030 Vali Loss: 0.6921290 Test Loss: 0.3973167
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.1563103199005127
Epoch: 68, Steps: 63 | Train Loss: 0.3554630 Vali Loss: 0.6941761 Test Loss: 0.3973288
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.171854019165039
Epoch: 69, Steps: 63 | Train Loss: 0.3551792 Vali Loss: 0.6926411 Test Loss: 0.3973196
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.2215259075164795
Epoch: 70, Steps: 63 | Train Loss: 0.3547777 Vali Loss: 0.6945809 Test Loss: 0.3973227
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.1642427444458008
Epoch: 71, Steps: 63 | Train Loss: 0.3552501 Vali Loss: 0.6898847 Test Loss: 0.3973275
Validation loss decreased (0.691278 --> 0.689885).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.2072985172271729
Epoch: 72, Steps: 63 | Train Loss: 0.3551141 Vali Loss: 0.6924709 Test Loss: 0.3973187
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.3137266635894775
Epoch: 73, Steps: 63 | Train Loss: 0.3548702 Vali Loss: 0.6924516 Test Loss: 0.3973232
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.2043921947479248
Epoch: 74, Steps: 63 | Train Loss: 0.3554891 Vali Loss: 0.6915448 Test Loss: 0.3973291
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.038583517074585
Epoch: 75, Steps: 63 | Train Loss: 0.3550585 Vali Loss: 0.6940026 Test Loss: 0.3973319
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.1334846019744873
Epoch: 76, Steps: 63 | Train Loss: 0.3553054 Vali Loss: 0.6941532 Test Loss: 0.3973244
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.1042375564575195
Epoch: 77, Steps: 63 | Train Loss: 0.3554249 Vali Loss: 0.6967555 Test Loss: 0.3973275
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.1364309787750244
Epoch: 78, Steps: 63 | Train Loss: 0.3551071 Vali Loss: 0.6927800 Test Loss: 0.3973280
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.231544017791748
Epoch: 79, Steps: 63 | Train Loss: 0.3548113 Vali Loss: 0.6953329 Test Loss: 0.3973202
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.203263521194458
Epoch: 80, Steps: 63 | Train Loss: 0.3551789 Vali Loss: 0.6927900 Test Loss: 0.3973245
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.2708408832550049
Epoch: 81, Steps: 63 | Train Loss: 0.3551400 Vali Loss: 0.6945201 Test Loss: 0.3973239
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.2341299057006836
Epoch: 82, Steps: 63 | Train Loss: 0.3555789 Vali Loss: 0.6937299 Test Loss: 0.3973236
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.1846837997436523
Epoch: 83, Steps: 63 | Train Loss: 0.3555002 Vali Loss: 0.6883718 Test Loss: 0.3973252
Validation loss decreased (0.689885 --> 0.688372).  Saving model ...
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.1945369243621826
Epoch: 84, Steps: 63 | Train Loss: 0.3551400 Vali Loss: 0.6934461 Test Loss: 0.3973211
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.2965545654296875
Epoch: 85, Steps: 63 | Train Loss: 0.3552136 Vali Loss: 0.6906816 Test Loss: 0.3973247
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.1596786975860596
Epoch: 86, Steps: 63 | Train Loss: 0.3549525 Vali Loss: 0.6903737 Test Loss: 0.3973279
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.2462708950042725
Epoch: 87, Steps: 63 | Train Loss: 0.3550492 Vali Loss: 0.6924406 Test Loss: 0.3973250
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.2255361080169678
Epoch: 88, Steps: 63 | Train Loss: 0.3550033 Vali Loss: 0.6932232 Test Loss: 0.3973269
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.225881576538086
Epoch: 89, Steps: 63 | Train Loss: 0.3546845 Vali Loss: 0.6960896 Test Loss: 0.3973268
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.1873962879180908
Epoch: 90, Steps: 63 | Train Loss: 0.3556105 Vali Loss: 0.6920741 Test Loss: 0.3973248
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.1265044212341309
Epoch: 91, Steps: 63 | Train Loss: 0.3554382 Vali Loss: 0.6939879 Test Loss: 0.3973298
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.2034976482391357
Epoch: 92, Steps: 63 | Train Loss: 0.3554580 Vali Loss: 0.6912581 Test Loss: 0.3973267
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.1594231128692627
Epoch: 93, Steps: 63 | Train Loss: 0.3553196 Vali Loss: 0.6872746 Test Loss: 0.3973281
Validation loss decreased (0.688372 --> 0.687275).  Saving model ...
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.2270159721374512
Epoch: 94, Steps: 63 | Train Loss: 0.3551543 Vali Loss: 0.6923348 Test Loss: 0.3973255
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.2164547443389893
Epoch: 95, Steps: 63 | Train Loss: 0.3552715 Vali Loss: 0.6909348 Test Loss: 0.3973286
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.25764799118042
Epoch: 96, Steps: 63 | Train Loss: 0.3548030 Vali Loss: 0.6919809 Test Loss: 0.3973310
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.3065569400787354
Epoch: 97, Steps: 63 | Train Loss: 0.3546650 Vali Loss: 0.6893792 Test Loss: 0.3973278
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.1538035869598389
Epoch: 98, Steps: 63 | Train Loss: 0.3551258 Vali Loss: 0.6952922 Test Loss: 0.3973274
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.130953073501587
Epoch: 99, Steps: 63 | Train Loss: 0.3547934 Vali Loss: 0.6958860 Test Loss: 0.3973279
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.1948976516723633
Epoch: 100, Steps: 63 | Train Loss: 0.3550295 Vali Loss: 0.6906874 Test Loss: 0.3973301
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.1160680107021042e-06
>>>>>>>testing : ETTh1_360_96_FITS_ETTh1_ftM_sl360_ll48_pl96_H2_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.3964730501174927, mae:0.4184161126613617, rse:0.5980874300003052, corr:[0.27050045 0.27657908 0.27787754 0.27602166 0.27311692 0.27092698
 0.26986203 0.2698167  0.27008566 0.2702997  0.2703071  0.2700075
 0.26962596 0.26940855 0.26942804 0.26959622 0.26966083 0.26955867
 0.2693818  0.26914632 0.26900375 0.26909786 0.26923886 0.26936716
 0.26928246 0.268976   0.2684943  0.26793513 0.2672949  0.26668227
 0.26619664 0.2658159  0.26556772 0.26537335 0.26526394 0.26521656
 0.26528788 0.26550794 0.26580885 0.26605904 0.2662897  0.2663637
 0.2663656  0.26638982 0.26654482 0.26681048 0.26709792 0.26713204
 0.26661143 0.26550797 0.26385605 0.2621999  0.26086682 0.25990328
 0.25953656 0.25959188 0.25974306 0.2598079  0.25965264 0.25945997
 0.25926438 0.2591627  0.25920826 0.25946105 0.25979614 0.26014653
 0.26045308 0.26050594 0.26044205 0.2604946  0.2606015  0.26051828
 0.2601115  0.2594238  0.2585409  0.25762597 0.25678343 0.25603306
 0.25557455 0.25531766 0.25520578 0.25511134 0.25492597 0.2546723
 0.25452518 0.25449124 0.2544404  0.2542048  0.25385725 0.25358075
 0.2533661  0.25316012 0.25308663 0.25338528 0.25372687 0.25300094]
