Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=58, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_360_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_360_96_FITS_ETTh1_ftM_sl360_ll48_pl96_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8185
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=58, out_features=73, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3793664.0
params:  4307.0
Trainable parameters:  4307
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.6901438236236572
Epoch: 1, Steps: 63 | Train Loss: 0.6276515 Vali Loss: 1.1475664 Test Loss: 0.6102202
Validation loss decreased (inf --> 1.147566).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.6057891845703125
Epoch: 2, Steps: 63 | Train Loss: 0.4668928 Vali Loss: 0.9377969 Test Loss: 0.4813070
Validation loss decreased (1.147566 --> 0.937797).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.5945656299591064
Epoch: 3, Steps: 63 | Train Loss: 0.4083151 Vali Loss: 0.8375489 Test Loss: 0.4267297
Validation loss decreased (0.937797 --> 0.837549).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.8197460174560547
Epoch: 4, Steps: 63 | Train Loss: 0.3822393 Vali Loss: 0.7942697 Test Loss: 0.4018017
Validation loss decreased (0.837549 --> 0.794270).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.9240193367004395
Epoch: 5, Steps: 63 | Train Loss: 0.3690330 Vali Loss: 0.7654605 Test Loss: 0.3912512
Validation loss decreased (0.794270 --> 0.765460).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.4056031703948975
Epoch: 6, Steps: 63 | Train Loss: 0.3618623 Vali Loss: 0.7483009 Test Loss: 0.3866072
Validation loss decreased (0.765460 --> 0.748301).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.828566551208496
Epoch: 7, Steps: 63 | Train Loss: 0.3584143 Vali Loss: 0.7435838 Test Loss: 0.3842515
Validation loss decreased (0.748301 --> 0.743584).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.3848490715026855
Epoch: 8, Steps: 63 | Train Loss: 0.3561068 Vali Loss: 0.7298211 Test Loss: 0.3835619
Validation loss decreased (0.743584 --> 0.729821).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.4853572845458984
Epoch: 9, Steps: 63 | Train Loss: 0.3545850 Vali Loss: 0.7234653 Test Loss: 0.3832111
Validation loss decreased (0.729821 --> 0.723465).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.8011512756347656
Epoch: 10, Steps: 63 | Train Loss: 0.3545275 Vali Loss: 0.7186830 Test Loss: 0.3828770
Validation loss decreased (0.723465 --> 0.718683).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.6073966026306152
Epoch: 11, Steps: 63 | Train Loss: 0.3533322 Vali Loss: 0.7165305 Test Loss: 0.3827439
Validation loss decreased (0.718683 --> 0.716531).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.9503798484802246
Epoch: 12, Steps: 63 | Train Loss: 0.3523613 Vali Loss: 0.7129803 Test Loss: 0.3825221
Validation loss decreased (0.716531 --> 0.712980).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.7001559734344482
Epoch: 13, Steps: 63 | Train Loss: 0.3518643 Vali Loss: 0.7117444 Test Loss: 0.3823459
Validation loss decreased (0.712980 --> 0.711744).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.908351182937622
Epoch: 14, Steps: 63 | Train Loss: 0.3512307 Vali Loss: 0.7067043 Test Loss: 0.3823974
Validation loss decreased (0.711744 --> 0.706704).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.472465991973877
Epoch: 15, Steps: 63 | Train Loss: 0.3515744 Vali Loss: 0.7063586 Test Loss: 0.3820699
Validation loss decreased (0.706704 --> 0.706359).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.755223274230957
Epoch: 16, Steps: 63 | Train Loss: 0.3511720 Vali Loss: 0.7038785 Test Loss: 0.3820513
Validation loss decreased (0.706359 --> 0.703879).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.5343165397644043
Epoch: 17, Steps: 63 | Train Loss: 0.3501969 Vali Loss: 0.7029781 Test Loss: 0.3819799
Validation loss decreased (0.703879 --> 0.702978).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.8431739807128906
Epoch: 18, Steps: 63 | Train Loss: 0.3505904 Vali Loss: 0.7023700 Test Loss: 0.3819079
Validation loss decreased (0.702978 --> 0.702370).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.4730620384216309
Epoch: 19, Steps: 63 | Train Loss: 0.3502087 Vali Loss: 0.7022656 Test Loss: 0.3818491
Validation loss decreased (0.702370 --> 0.702266).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.179652690887451
Epoch: 20, Steps: 63 | Train Loss: 0.3489412 Vali Loss: 0.6983865 Test Loss: 0.3817403
Validation loss decreased (0.702266 --> 0.698386).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.6537175178527832
Epoch: 21, Steps: 63 | Train Loss: 0.3498435 Vali Loss: 0.6977292 Test Loss: 0.3816808
Validation loss decreased (0.698386 --> 0.697729).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.76822829246521
Epoch: 22, Steps: 63 | Train Loss: 0.3496179 Vali Loss: 0.6970983 Test Loss: 0.3817932
Validation loss decreased (0.697729 --> 0.697098).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.7587590217590332
Epoch: 23, Steps: 63 | Train Loss: 0.3494687 Vali Loss: 0.6979589 Test Loss: 0.3817061
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.6647605895996094
Epoch: 24, Steps: 63 | Train Loss: 0.3490857 Vali Loss: 0.6981658 Test Loss: 0.3816237
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.9181208610534668
Epoch: 25, Steps: 63 | Train Loss: 0.3496725 Vali Loss: 0.6939374 Test Loss: 0.3815703
Validation loss decreased (0.697098 --> 0.693937).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.6641323566436768
Epoch: 26, Steps: 63 | Train Loss: 0.3489767 Vali Loss: 0.6934450 Test Loss: 0.3815866
Validation loss decreased (0.693937 --> 0.693445).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.6306288242340088
Epoch: 27, Steps: 63 | Train Loss: 0.3487255 Vali Loss: 0.6969504 Test Loss: 0.3816901
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.7396042346954346
Epoch: 28, Steps: 63 | Train Loss: 0.3485210 Vali Loss: 0.6935636 Test Loss: 0.3815828
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.8563790321350098
Epoch: 29, Steps: 63 | Train Loss: 0.3485593 Vali Loss: 0.6898611 Test Loss: 0.3816984
Validation loss decreased (0.693445 --> 0.689861).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.6411468982696533
Epoch: 30, Steps: 63 | Train Loss: 0.3485278 Vali Loss: 0.6923531 Test Loss: 0.3815777
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.5601933002471924
Epoch: 31, Steps: 63 | Train Loss: 0.3481518 Vali Loss: 0.6891628 Test Loss: 0.3815891
Validation loss decreased (0.689861 --> 0.689163).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.118077278137207
Epoch: 32, Steps: 63 | Train Loss: 0.3481834 Vali Loss: 0.6904718 Test Loss: 0.3815690
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.050546407699585
Epoch: 33, Steps: 63 | Train Loss: 0.3484197 Vali Loss: 0.6917583 Test Loss: 0.3816318
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.6318559646606445
Epoch: 34, Steps: 63 | Train Loss: 0.3483770 Vali Loss: 0.6900757 Test Loss: 0.3816004
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.1852593421936035
Epoch: 35, Steps: 63 | Train Loss: 0.3483675 Vali Loss: 0.6915892 Test Loss: 0.3815871
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.1953744888305664
Epoch: 36, Steps: 63 | Train Loss: 0.3484290 Vali Loss: 0.6866986 Test Loss: 0.3815896
Validation loss decreased (0.689163 --> 0.686699).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.218777656555176
Epoch: 37, Steps: 63 | Train Loss: 0.3477313 Vali Loss: 0.6893331 Test Loss: 0.3815706
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.7517344951629639
Epoch: 38, Steps: 63 | Train Loss: 0.3485446 Vali Loss: 0.6859847 Test Loss: 0.3815572
Validation loss decreased (0.686699 --> 0.685985).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.5599968433380127
Epoch: 39, Steps: 63 | Train Loss: 0.3476350 Vali Loss: 0.6881030 Test Loss: 0.3815234
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.6702723503112793
Epoch: 40, Steps: 63 | Train Loss: 0.3479065 Vali Loss: 0.6904960 Test Loss: 0.3815379
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.6212916374206543
Epoch: 41, Steps: 63 | Train Loss: 0.3484597 Vali Loss: 0.6910674 Test Loss: 0.3814900
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.867757797241211
Epoch: 42, Steps: 63 | Train Loss: 0.3481481 Vali Loss: 0.6873652 Test Loss: 0.3815118
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.472733497619629
Epoch: 43, Steps: 63 | Train Loss: 0.3487015 Vali Loss: 0.6932853 Test Loss: 0.3815164
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.5258500576019287
Epoch: 44, Steps: 63 | Train Loss: 0.3475142 Vali Loss: 0.6883321 Test Loss: 0.3815074
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.712350606918335
Epoch: 45, Steps: 63 | Train Loss: 0.3474621 Vali Loss: 0.6893567 Test Loss: 0.3815034
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.2046196460723877
Epoch: 46, Steps: 63 | Train Loss: 0.3476498 Vali Loss: 0.6879462 Test Loss: 0.3815065
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.859001874923706
Epoch: 47, Steps: 63 | Train Loss: 0.3475534 Vali Loss: 0.6861788 Test Loss: 0.3815121
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.2117178440093994
Epoch: 48, Steps: 63 | Train Loss: 0.3478769 Vali Loss: 0.6889739 Test Loss: 0.3814919
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.3875763416290283
Epoch: 49, Steps: 63 | Train Loss: 0.3480309 Vali Loss: 0.6900266 Test Loss: 0.3814892
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.7130961418151855
Epoch: 50, Steps: 63 | Train Loss: 0.3477372 Vali Loss: 0.6883202 Test Loss: 0.3815204
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.0624701976776123
Epoch: 51, Steps: 63 | Train Loss: 0.3474869 Vali Loss: 0.6872203 Test Loss: 0.3814796
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.9582929611206055
Epoch: 52, Steps: 63 | Train Loss: 0.3480109 Vali Loss: 0.6914211 Test Loss: 0.3815126
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.2035539150238037
Epoch: 53, Steps: 63 | Train Loss: 0.3474355 Vali Loss: 0.6891990 Test Loss: 0.3815065
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.825718402862549
Epoch: 54, Steps: 63 | Train Loss: 0.3480308 Vali Loss: 0.6875002 Test Loss: 0.3815390
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.3367769718170166
Epoch: 55, Steps: 63 | Train Loss: 0.3481111 Vali Loss: 0.6902301 Test Loss: 0.3814974
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.6999108791351318
Epoch: 56, Steps: 63 | Train Loss: 0.3478375 Vali Loss: 0.6885467 Test Loss: 0.3815117
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.0175154209136963
Epoch: 57, Steps: 63 | Train Loss: 0.3475811 Vali Loss: 0.6893436 Test Loss: 0.3815286
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.1793289184570312
Epoch: 58, Steps: 63 | Train Loss: 0.3474811 Vali Loss: 0.6865566 Test Loss: 0.3815462
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_360_96_FITS_ETTh1_ftM_sl360_ll48_pl96_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.3805936276912689, mae:0.4012835621833801, rse:0.5859878659248352, corr:[0.2679454  0.27811572 0.27930892 0.2764128  0.2733141  0.27153406
 0.27069125 0.27057698 0.27048418 0.27016982 0.26974264 0.2692698
 0.2689958  0.2690283  0.26924992 0.2694383  0.26938838 0.2691343
 0.26884872 0.26857993 0.26842627 0.26846996 0.26860783 0.26874977
 0.26861715 0.26827106 0.26786467 0.26746127 0.26697183 0.2664794
 0.26609394 0.26583308 0.26568758 0.26548356 0.2652481  0.26503745
 0.26505128 0.265336   0.26573825 0.26604506 0.26632616 0.26639363
 0.26632193 0.26620436 0.2661111  0.26603907 0.2660399  0.2659496
 0.2654877  0.26461512 0.26337048 0.26224995 0.2613907  0.2606331
 0.26017946 0.25999707 0.25990137 0.25977045 0.25947616 0.2593135
 0.2592724  0.25938463 0.25955963 0.25978753 0.25997117 0.2601098
 0.26024753 0.2602175  0.2602073  0.2604019  0.26064184 0.26052848
 0.25989163 0.25893894 0.25791726 0.25710422 0.25658575 0.25624335
 0.25607377 0.25585723 0.25554216 0.2550856  0.2544924  0.25401953
 0.2539459  0.25416633 0.25447673 0.25455445 0.2544201  0.25421244
 0.25372326 0.25282833 0.25208008 0.25229573 0.25327492 0.2527336 ]
