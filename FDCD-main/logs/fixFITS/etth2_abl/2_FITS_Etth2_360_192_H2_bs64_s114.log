Args in experiment:
Namespace(H_order=2, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=42, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_360_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_360_192_FITS_ETTh2_ftM_sl360_ll48_pl192_H2_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8089
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=42, out_features=64, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2408448.0
params:  2752.0
Trainable parameters:  2752
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.7705779075622559
Epoch: 1, Steps: 63 | Train Loss: 0.5678777 Vali Loss: 0.4129424 Test Loss: 0.4654785
Validation loss decreased (inf --> 0.412942).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.7284541130065918
Epoch: 2, Steps: 63 | Train Loss: 0.4716996 Vali Loss: 0.3788809 Test Loss: 0.4364355
Validation loss decreased (0.412942 --> 0.378881).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.6431150436401367
Epoch: 3, Steps: 63 | Train Loss: 0.4128538 Vali Loss: 0.3581527 Test Loss: 0.4194570
Validation loss decreased (0.378881 --> 0.358153).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.5583579540252686
Epoch: 4, Steps: 63 | Train Loss: 0.3731637 Vali Loss: 0.3450131 Test Loss: 0.4092064
Validation loss decreased (0.358153 --> 0.345013).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.814972162246704
Epoch: 5, Steps: 63 | Train Loss: 0.3455710 Vali Loss: 0.3366346 Test Loss: 0.4027774
Validation loss decreased (0.345013 --> 0.336635).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.7937099933624268
Epoch: 6, Steps: 63 | Train Loss: 0.3259759 Vali Loss: 0.3308577 Test Loss: 0.3985611
Validation loss decreased (0.336635 --> 0.330858).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.737107753753662
Epoch: 7, Steps: 63 | Train Loss: 0.3110794 Vali Loss: 0.3264090 Test Loss: 0.3955052
Validation loss decreased (0.330858 --> 0.326409).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.749112844467163
Epoch: 8, Steps: 63 | Train Loss: 0.2991100 Vali Loss: 0.3228341 Test Loss: 0.3930037
Validation loss decreased (0.326409 --> 0.322834).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.9294087886810303
Epoch: 9, Steps: 63 | Train Loss: 0.2895901 Vali Loss: 0.3201822 Test Loss: 0.3910426
Validation loss decreased (0.322834 --> 0.320182).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.253917694091797
Epoch: 10, Steps: 63 | Train Loss: 0.2811179 Vali Loss: 0.3177513 Test Loss: 0.3893806
Validation loss decreased (0.320182 --> 0.317751).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.5768752098083496
Epoch: 11, Steps: 63 | Train Loss: 0.2747096 Vali Loss: 0.3155989 Test Loss: 0.3877339
Validation loss decreased (0.317751 --> 0.315599).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.6716315746307373
Epoch: 12, Steps: 63 | Train Loss: 0.2684936 Vali Loss: 0.3139143 Test Loss: 0.3863863
Validation loss decreased (0.315599 --> 0.313914).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.7412707805633545
Epoch: 13, Steps: 63 | Train Loss: 0.2634211 Vali Loss: 0.3122770 Test Loss: 0.3850329
Validation loss decreased (0.313914 --> 0.312277).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.138690948486328
Epoch: 14, Steps: 63 | Train Loss: 0.2588495 Vali Loss: 0.3109619 Test Loss: 0.3838270
Validation loss decreased (0.312277 --> 0.310962).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.551750898361206
Epoch: 15, Steps: 63 | Train Loss: 0.2551581 Vali Loss: 0.3093921 Test Loss: 0.3826363
Validation loss decreased (0.310962 --> 0.309392).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.816868543624878
Epoch: 16, Steps: 63 | Train Loss: 0.2513300 Vali Loss: 0.3080705 Test Loss: 0.3816797
Validation loss decreased (0.309392 --> 0.308071).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.9793777465820312
Epoch: 17, Steps: 63 | Train Loss: 0.2479575 Vali Loss: 0.3074307 Test Loss: 0.3807565
Validation loss decreased (0.308071 --> 0.307431).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.2990164756774902
Epoch: 18, Steps: 63 | Train Loss: 0.2456211 Vali Loss: 0.3064823 Test Loss: 0.3797715
Validation loss decreased (0.307431 --> 0.306482).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.7659680843353271
Epoch: 19, Steps: 63 | Train Loss: 0.2428144 Vali Loss: 0.3053166 Test Loss: 0.3789332
Validation loss decreased (0.306482 --> 0.305317).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.7553317546844482
Epoch: 20, Steps: 63 | Train Loss: 0.2408617 Vali Loss: 0.3047585 Test Loss: 0.3782492
Validation loss decreased (0.305317 --> 0.304758).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.0423574447631836
Epoch: 21, Steps: 63 | Train Loss: 0.2382290 Vali Loss: 0.3041038 Test Loss: 0.3775002
Validation loss decreased (0.304758 --> 0.304104).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.7039811611175537
Epoch: 22, Steps: 63 | Train Loss: 0.2363178 Vali Loss: 0.3033756 Test Loss: 0.3768294
Validation loss decreased (0.304104 --> 0.303376).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.6877129077911377
Epoch: 23, Steps: 63 | Train Loss: 0.2348498 Vali Loss: 0.3027493 Test Loss: 0.3761907
Validation loss decreased (0.303376 --> 0.302749).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.8246338367462158
Epoch: 24, Steps: 63 | Train Loss: 0.2333622 Vali Loss: 0.3021576 Test Loss: 0.3755671
Validation loss decreased (0.302749 --> 0.302158).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.8256444931030273
Epoch: 25, Steps: 63 | Train Loss: 0.2323637 Vali Loss: 0.3017103 Test Loss: 0.3750874
Validation loss decreased (0.302158 --> 0.301710).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.951362133026123
Epoch: 26, Steps: 63 | Train Loss: 0.2306951 Vali Loss: 0.3011852 Test Loss: 0.3745154
Validation loss decreased (0.301710 --> 0.301185).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.938281774520874
Epoch: 27, Steps: 63 | Train Loss: 0.2295097 Vali Loss: 0.3007316 Test Loss: 0.3740568
Validation loss decreased (0.301185 --> 0.300732).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.4689536094665527
Epoch: 28, Steps: 63 | Train Loss: 0.2285927 Vali Loss: 0.3003908 Test Loss: 0.3735795
Validation loss decreased (0.300732 --> 0.300391).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.9900753498077393
Epoch: 29, Steps: 63 | Train Loss: 0.2279646 Vali Loss: 0.2998222 Test Loss: 0.3731693
Validation loss decreased (0.300391 --> 0.299822).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.5784285068511963
Epoch: 30, Steps: 63 | Train Loss: 0.2268976 Vali Loss: 0.2995666 Test Loss: 0.3727538
Validation loss decreased (0.299822 --> 0.299567).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.8201968669891357
Epoch: 31, Steps: 63 | Train Loss: 0.2259272 Vali Loss: 0.2991947 Test Loss: 0.3723853
Validation loss decreased (0.299567 --> 0.299195).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.9585492610931396
Epoch: 32, Steps: 63 | Train Loss: 0.2254121 Vali Loss: 0.2988213 Test Loss: 0.3720442
Validation loss decreased (0.299195 --> 0.298821).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.0468828678131104
Epoch: 33, Steps: 63 | Train Loss: 0.2243517 Vali Loss: 0.2985929 Test Loss: 0.3717444
Validation loss decreased (0.298821 --> 0.298593).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.4712812900543213
Epoch: 34, Steps: 63 | Train Loss: 0.2238931 Vali Loss: 0.2982990 Test Loss: 0.3713720
Validation loss decreased (0.298593 --> 0.298299).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 5.653716087341309
Epoch: 35, Steps: 63 | Train Loss: 0.2231896 Vali Loss: 0.2980197 Test Loss: 0.3710755
Validation loss decreased (0.298299 --> 0.298020).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 3.048720598220825
Epoch: 36, Steps: 63 | Train Loss: 0.2229787 Vali Loss: 0.2974283 Test Loss: 0.3708163
Validation loss decreased (0.298020 --> 0.297428).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 6.13956093788147
Epoch: 37, Steps: 63 | Train Loss: 0.2222942 Vali Loss: 0.2975129 Test Loss: 0.3705414
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 5.801784992218018
Epoch: 38, Steps: 63 | Train Loss: 0.2213843 Vali Loss: 0.2972866 Test Loss: 0.3703071
Validation loss decreased (0.297428 --> 0.297287).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 5.308434963226318
Epoch: 39, Steps: 63 | Train Loss: 0.2211406 Vali Loss: 0.2967871 Test Loss: 0.3700969
Validation loss decreased (0.297287 --> 0.296787).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.6760833263397217
Epoch: 40, Steps: 63 | Train Loss: 0.2208242 Vali Loss: 0.2969118 Test Loss: 0.3698699
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 4.536651611328125
Epoch: 41, Steps: 63 | Train Loss: 0.2207020 Vali Loss: 0.2967708 Test Loss: 0.3696127
Validation loss decreased (0.296787 --> 0.296771).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 4.641740322113037
Epoch: 42, Steps: 63 | Train Loss: 0.2201411 Vali Loss: 0.2965174 Test Loss: 0.3694659
Validation loss decreased (0.296771 --> 0.296517).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 5.32588791847229
Epoch: 43, Steps: 63 | Train Loss: 0.2197387 Vali Loss: 0.2964278 Test Loss: 0.3692541
Validation loss decreased (0.296517 --> 0.296428).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 5.064188003540039
Epoch: 44, Steps: 63 | Train Loss: 0.2193914 Vali Loss: 0.2962971 Test Loss: 0.3690798
Validation loss decreased (0.296428 --> 0.296297).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 4.992280006408691
Epoch: 45, Steps: 63 | Train Loss: 0.2190182 Vali Loss: 0.2961530 Test Loss: 0.3689111
Validation loss decreased (0.296297 --> 0.296153).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 4.292378902435303
Epoch: 46, Steps: 63 | Train Loss: 0.2188567 Vali Loss: 0.2959933 Test Loss: 0.3687682
Validation loss decreased (0.296153 --> 0.295993).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 3.5019946098327637
Epoch: 47, Steps: 63 | Train Loss: 0.2183102 Vali Loss: 0.2958428 Test Loss: 0.3686210
Validation loss decreased (0.295993 --> 0.295843).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.883554697036743
Epoch: 48, Steps: 63 | Train Loss: 0.2181653 Vali Loss: 0.2957757 Test Loss: 0.3684444
Validation loss decreased (0.295843 --> 0.295776).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 4.311591148376465
Epoch: 49, Steps: 63 | Train Loss: 0.2180636 Vali Loss: 0.2955737 Test Loss: 0.3683574
Validation loss decreased (0.295776 --> 0.295574).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 5.641428709030151
Epoch: 50, Steps: 63 | Train Loss: 0.2175469 Vali Loss: 0.2953711 Test Loss: 0.3682105
Validation loss decreased (0.295574 --> 0.295371).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.4692611694335938
Epoch: 51, Steps: 63 | Train Loss: 0.2177669 Vali Loss: 0.2954510 Test Loss: 0.3680899
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.7730562686920166
Epoch: 52, Steps: 63 | Train Loss: 0.2176914 Vali Loss: 0.2952953 Test Loss: 0.3680035
Validation loss decreased (0.295371 --> 0.295295).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.849107265472412
Epoch: 53, Steps: 63 | Train Loss: 0.2172751 Vali Loss: 0.2949353 Test Loss: 0.3678637
Validation loss decreased (0.295295 --> 0.294935).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.9670257568359375
Epoch: 54, Steps: 63 | Train Loss: 0.2170788 Vali Loss: 0.2951547 Test Loss: 0.3677871
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.9089241027832031
Epoch: 55, Steps: 63 | Train Loss: 0.2171118 Vali Loss: 0.2950607 Test Loss: 0.3676639
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.8017807006835938
Epoch: 56, Steps: 63 | Train Loss: 0.2166538 Vali Loss: 0.2949485 Test Loss: 0.3675719
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.9115545749664307
Epoch: 57, Steps: 63 | Train Loss: 0.2167225 Vali Loss: 0.2949281 Test Loss: 0.3675102
Validation loss decreased (0.294935 --> 0.294928).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.8746280670166016
Epoch: 58, Steps: 63 | Train Loss: 0.2165470 Vali Loss: 0.2948305 Test Loss: 0.3674120
Validation loss decreased (0.294928 --> 0.294831).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.7061963081359863
Epoch: 59, Steps: 63 | Train Loss: 0.2163017 Vali Loss: 0.2947395 Test Loss: 0.3673253
Validation loss decreased (0.294831 --> 0.294739).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.6396832466125488
Epoch: 60, Steps: 63 | Train Loss: 0.2152464 Vali Loss: 0.2946684 Test Loss: 0.3672622
Validation loss decreased (0.294739 --> 0.294668).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.9476971626281738
Epoch: 61, Steps: 63 | Train Loss: 0.2160509 Vali Loss: 0.2946338 Test Loss: 0.3672099
Validation loss decreased (0.294668 --> 0.294634).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.005474328994751
Epoch: 62, Steps: 63 | Train Loss: 0.2160831 Vali Loss: 0.2946147 Test Loss: 0.3671313
Validation loss decreased (0.294634 --> 0.294615).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.7510943412780762
Epoch: 63, Steps: 63 | Train Loss: 0.2158084 Vali Loss: 0.2945636 Test Loss: 0.3670696
Validation loss decreased (0.294615 --> 0.294564).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.182729482650757
Epoch: 64, Steps: 63 | Train Loss: 0.2155212 Vali Loss: 0.2944933 Test Loss: 0.3670176
Validation loss decreased (0.294564 --> 0.294493).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.7907869815826416
Epoch: 65, Steps: 63 | Train Loss: 0.2158173 Vali Loss: 0.2944191 Test Loss: 0.3669653
Validation loss decreased (0.294493 --> 0.294419).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.061403274536133
Epoch: 66, Steps: 63 | Train Loss: 0.2154940 Vali Loss: 0.2943524 Test Loss: 0.3668847
Validation loss decreased (0.294419 --> 0.294352).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 4.022731065750122
Epoch: 67, Steps: 63 | Train Loss: 0.2153143 Vali Loss: 0.2942979 Test Loss: 0.3668333
Validation loss decreased (0.294352 --> 0.294298).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 3.583606243133545
Epoch: 68, Steps: 63 | Train Loss: 0.2150662 Vali Loss: 0.2943112 Test Loss: 0.3667949
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 6.540631294250488
Epoch: 69, Steps: 63 | Train Loss: 0.2153991 Vali Loss: 0.2939906 Test Loss: 0.3667531
Validation loss decreased (0.294298 --> 0.293991).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 5.79390025138855
Epoch: 70, Steps: 63 | Train Loss: 0.2151509 Vali Loss: 0.2942670 Test Loss: 0.3667061
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 5.935123682022095
Epoch: 71, Steps: 63 | Train Loss: 0.2153495 Vali Loss: 0.2940701 Test Loss: 0.3666747
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 4.740569591522217
Epoch: 72, Steps: 63 | Train Loss: 0.2150206 Vali Loss: 0.2941714 Test Loss: 0.3666241
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 4.2414610385894775
Epoch: 73, Steps: 63 | Train Loss: 0.2152429 Vali Loss: 0.2941228 Test Loss: 0.3665847
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 4.955683469772339
Epoch: 74, Steps: 63 | Train Loss: 0.2151672 Vali Loss: 0.2940868 Test Loss: 0.3665516
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 4.647929430007935
Epoch: 75, Steps: 63 | Train Loss: 0.2149846 Vali Loss: 0.2939985 Test Loss: 0.3665117
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 3.923919677734375
Epoch: 76, Steps: 63 | Train Loss: 0.2145117 Vali Loss: 0.2940617 Test Loss: 0.3664737
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 6.378417491912842
Epoch: 77, Steps: 63 | Train Loss: 0.2149879 Vali Loss: 0.2938751 Test Loss: 0.3664516
Validation loss decreased (0.293991 --> 0.293875).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 5.214590072631836
Epoch: 78, Steps: 63 | Train Loss: 0.2149743 Vali Loss: 0.2939798 Test Loss: 0.3664194
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 5.735441207885742
Epoch: 79, Steps: 63 | Train Loss: 0.2149544 Vali Loss: 0.2936283 Test Loss: 0.3663838
Validation loss decreased (0.293875 --> 0.293628).  Saving model ...
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 5.257291316986084
Epoch: 80, Steps: 63 | Train Loss: 0.2145242 Vali Loss: 0.2939600 Test Loss: 0.3663572
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 3.95538067817688
Epoch: 81, Steps: 63 | Train Loss: 0.2147827 Vali Loss: 0.2938115 Test Loss: 0.3663346
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 6.5050904750823975
Epoch: 82, Steps: 63 | Train Loss: 0.2148617 Vali Loss: 0.2939376 Test Loss: 0.3663121
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.9512851238250732
Epoch: 83, Steps: 63 | Train Loss: 0.2145887 Vali Loss: 0.2939001 Test Loss: 0.3662859
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.5100436210632324
Epoch: 84, Steps: 63 | Train Loss: 0.2148128 Vali Loss: 0.2938126 Test Loss: 0.3662640
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.080714464187622
Epoch: 85, Steps: 63 | Train Loss: 0.2146313 Vali Loss: 0.2938157 Test Loss: 0.3662466
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.968839168548584
Epoch: 86, Steps: 63 | Train Loss: 0.2142566 Vali Loss: 0.2938167 Test Loss: 0.3662233
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.9502809047698975
Epoch: 87, Steps: 63 | Train Loss: 0.2143298 Vali Loss: 0.2937916 Test Loss: 0.3662051
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.5716683864593506
Epoch: 88, Steps: 63 | Train Loss: 0.2143661 Vali Loss: 0.2938125 Test Loss: 0.3661878
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.076261281967163
Epoch: 89, Steps: 63 | Train Loss: 0.2143081 Vali Loss: 0.2937931 Test Loss: 0.3661734
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.8782408237457275
Epoch: 90, Steps: 63 | Train Loss: 0.2140857 Vali Loss: 0.2937935 Test Loss: 0.3661574
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.950279712677002
Epoch: 91, Steps: 63 | Train Loss: 0.2144853 Vali Loss: 0.2937784 Test Loss: 0.3661387
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.6023972034454346
Epoch: 92, Steps: 63 | Train Loss: 0.2143459 Vali Loss: 0.2937746 Test Loss: 0.3661297
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.8642544746398926
Epoch: 93, Steps: 63 | Train Loss: 0.2144167 Vali Loss: 0.2937286 Test Loss: 0.3661142
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.724015712738037
Epoch: 94, Steps: 63 | Train Loss: 0.2135908 Vali Loss: 0.2933444 Test Loss: 0.3661000
Validation loss decreased (0.293628 --> 0.293344).  Saving model ...
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.9141390323638916
Epoch: 95, Steps: 63 | Train Loss: 0.2142644 Vali Loss: 0.2937492 Test Loss: 0.3660876
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.6956253051757812
Epoch: 96, Steps: 63 | Train Loss: 0.2142433 Vali Loss: 0.2937246 Test Loss: 0.3660756
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 2.342094659805298
Epoch: 97, Steps: 63 | Train Loss: 0.2141548 Vali Loss: 0.2936861 Test Loss: 0.3660668
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 2.132455348968506
Epoch: 98, Steps: 63 | Train Loss: 0.2140858 Vali Loss: 0.2936729 Test Loss: 0.3660569
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 2.041569709777832
Epoch: 99, Steps: 63 | Train Loss: 0.2140452 Vali Loss: 0.2937270 Test Loss: 0.3660444
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.8699696063995361
Epoch: 100, Steps: 63 | Train Loss: 0.2140536 Vali Loss: 0.2936037 Test Loss: 0.3660369
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8089
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=42, out_features=64, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2408448.0
params:  2752.0
Trainable parameters:  2752
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.1134352684020996
Epoch: 1, Steps: 63 | Train Loss: 0.5213348 Vali Loss: 0.2886098 Test Loss: 0.3592931
Validation loss decreased (inf --> 0.288610).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.8921539783477783
Epoch: 2, Steps: 63 | Train Loss: 0.5159615 Vali Loss: 0.2862736 Test Loss: 0.3569014
Validation loss decreased (0.288610 --> 0.286274).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.349257707595825
Epoch: 3, Steps: 63 | Train Loss: 0.5124871 Vali Loss: 0.2845275 Test Loss: 0.3566339
Validation loss decreased (0.286274 --> 0.284528).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.8119897842407227
Epoch: 4, Steps: 63 | Train Loss: 0.5122816 Vali Loss: 0.2839462 Test Loss: 0.3559842
Validation loss decreased (0.284528 --> 0.283946).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.7291088104248047
Epoch: 5, Steps: 63 | Train Loss: 0.5112658 Vali Loss: 0.2838588 Test Loss: 0.3557970
Validation loss decreased (0.283946 --> 0.283859).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.7421388626098633
Epoch: 6, Steps: 63 | Train Loss: 0.5115190 Vali Loss: 0.2836010 Test Loss: 0.3555226
Validation loss decreased (0.283859 --> 0.283601).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.9988012313842773
Epoch: 7, Steps: 63 | Train Loss: 0.5108197 Vali Loss: 0.2830364 Test Loss: 0.3557218
Validation loss decreased (0.283601 --> 0.283036).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.9917595386505127
Epoch: 8, Steps: 63 | Train Loss: 0.5109199 Vali Loss: 0.2828729 Test Loss: 0.3556288
Validation loss decreased (0.283036 --> 0.282873).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.1170833110809326
Epoch: 9, Steps: 63 | Train Loss: 0.5098416 Vali Loss: 0.2827030 Test Loss: 0.3553678
Validation loss decreased (0.282873 --> 0.282703).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.8134255409240723
Epoch: 10, Steps: 63 | Train Loss: 0.5101174 Vali Loss: 0.2825468 Test Loss: 0.3554403
Validation loss decreased (0.282703 --> 0.282547).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 5.001007795333862
Epoch: 11, Steps: 63 | Train Loss: 0.5094482 Vali Loss: 0.2823154 Test Loss: 0.3553421
Validation loss decreased (0.282547 --> 0.282315).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 6.659211158752441
Epoch: 12, Steps: 63 | Train Loss: 0.5099212 Vali Loss: 0.2822863 Test Loss: 0.3552380
Validation loss decreased (0.282315 --> 0.282286).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 5.623048305511475
Epoch: 13, Steps: 63 | Train Loss: 0.5089610 Vali Loss: 0.2822875 Test Loss: 0.3551924
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 4.165944814682007
Epoch: 14, Steps: 63 | Train Loss: 0.5098518 Vali Loss: 0.2819495 Test Loss: 0.3553119
Validation loss decreased (0.282286 --> 0.281949).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.9481935501098633
Epoch: 15, Steps: 63 | Train Loss: 0.5085533 Vali Loss: 0.2819341 Test Loss: 0.3551025
Validation loss decreased (0.281949 --> 0.281934).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 5.258774518966675
Epoch: 16, Steps: 63 | Train Loss: 0.5084834 Vali Loss: 0.2819782 Test Loss: 0.3550897
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.5047924518585205
Epoch: 17, Steps: 63 | Train Loss: 0.5081802 Vali Loss: 0.2815676 Test Loss: 0.3552311
Validation loss decreased (0.281934 --> 0.281568).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.7798314094543457
Epoch: 18, Steps: 63 | Train Loss: 0.5091894 Vali Loss: 0.2816779 Test Loss: 0.3550945
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 4.63203501701355
Epoch: 19, Steps: 63 | Train Loss: 0.5082407 Vali Loss: 0.2817154 Test Loss: 0.3549780
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 6.279646635055542
Epoch: 20, Steps: 63 | Train Loss: 0.5092975 Vali Loss: 0.2816577 Test Loss: 0.3550485
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 6.488851070404053
Epoch: 21, Steps: 63 | Train Loss: 0.5077704 Vali Loss: 0.2812632 Test Loss: 0.3551710
Validation loss decreased (0.281568 --> 0.281263).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 5.619261264801025
Epoch: 22, Steps: 63 | Train Loss: 0.5072934 Vali Loss: 0.2809794 Test Loss: 0.3551477
Validation loss decreased (0.281263 --> 0.280979).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 5.501028060913086
Epoch: 23, Steps: 63 | Train Loss: 0.5083196 Vali Loss: 0.2813776 Test Loss: 0.3551164
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.9433906078338623
Epoch: 24, Steps: 63 | Train Loss: 0.5082671 Vali Loss: 0.2813374 Test Loss: 0.3550678
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.540578603744507
Epoch: 25, Steps: 63 | Train Loss: 0.5085840 Vali Loss: 0.2812917 Test Loss: 0.3550754
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.6612088680267334
Epoch: 26, Steps: 63 | Train Loss: 0.5069536 Vali Loss: 0.2811750 Test Loss: 0.3550783
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.9769787788391113
Epoch: 27, Steps: 63 | Train Loss: 0.5078208 Vali Loss: 0.2811663 Test Loss: 0.3550688
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.2578248977661133
Epoch: 28, Steps: 63 | Train Loss: 0.5084529 Vali Loss: 0.2810662 Test Loss: 0.3550369
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.2416529655456543
Epoch: 29, Steps: 63 | Train Loss: 0.5087114 Vali Loss: 0.2810552 Test Loss: 0.3549932
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.0869650840759277
Epoch: 30, Steps: 63 | Train Loss: 0.5078331 Vali Loss: 0.2809620 Test Loss: 0.3550352
Validation loss decreased (0.280979 --> 0.280962).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.6424269676208496
Epoch: 31, Steps: 63 | Train Loss: 0.5068279 Vali Loss: 0.2810608 Test Loss: 0.3550256
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.7161614894866943
Epoch: 32, Steps: 63 | Train Loss: 0.5079945 Vali Loss: 0.2809479 Test Loss: 0.3550511
Validation loss decreased (0.280962 --> 0.280948).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.704434871673584
Epoch: 33, Steps: 63 | Train Loss: 0.5076990 Vali Loss: 0.2809589 Test Loss: 0.3550226
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.0372440814971924
Epoch: 34, Steps: 63 | Train Loss: 0.5074795 Vali Loss: 0.2808635 Test Loss: 0.3550137
Validation loss decreased (0.280948 --> 0.280864).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.1318087577819824
Epoch: 35, Steps: 63 | Train Loss: 0.5081819 Vali Loss: 0.2805916 Test Loss: 0.3550375
Validation loss decreased (0.280864 --> 0.280592).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.6253244876861572
Epoch: 36, Steps: 63 | Train Loss: 0.5077853 Vali Loss: 0.2808967 Test Loss: 0.3549539
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.533367395401001
Epoch: 37, Steps: 63 | Train Loss: 0.5070780 Vali Loss: 0.2808459 Test Loss: 0.3550355
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.0176939964294434
Epoch: 38, Steps: 63 | Train Loss: 0.5077358 Vali Loss: 0.2808275 Test Loss: 0.3550437
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.9120616912841797
Epoch: 39, Steps: 63 | Train Loss: 0.5071429 Vali Loss: 0.2808654 Test Loss: 0.3549950
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.7814912796020508
Epoch: 40, Steps: 63 | Train Loss: 0.5075903 Vali Loss: 0.2808472 Test Loss: 0.3549960
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.052140235900879
Epoch: 41, Steps: 63 | Train Loss: 0.5056498 Vali Loss: 0.2807585 Test Loss: 0.3550147
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.9709010124206543
Epoch: 42, Steps: 63 | Train Loss: 0.5075463 Vali Loss: 0.2804724 Test Loss: 0.3549836
Validation loss decreased (0.280592 --> 0.280472).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.1925601959228516
Epoch: 43, Steps: 63 | Train Loss: 0.5063334 Vali Loss: 0.2807580 Test Loss: 0.3550103
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.12210750579834
Epoch: 44, Steps: 63 | Train Loss: 0.5078830 Vali Loss: 0.2808064 Test Loss: 0.3549881
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.4367620944976807
Epoch: 45, Steps: 63 | Train Loss: 0.5077534 Vali Loss: 0.2807272 Test Loss: 0.3549822
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.092686891555786
Epoch: 46, Steps: 63 | Train Loss: 0.5063092 Vali Loss: 0.2803796 Test Loss: 0.3550039
Validation loss decreased (0.280472 --> 0.280380).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.196488380432129
Epoch: 47, Steps: 63 | Train Loss: 0.5082567 Vali Loss: 0.2807869 Test Loss: 0.3549831
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.2654757499694824
Epoch: 48, Steps: 63 | Train Loss: 0.5074562 Vali Loss: 0.2807363 Test Loss: 0.3549871
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.003896951675415
Epoch: 49, Steps: 63 | Train Loss: 0.5078293 Vali Loss: 0.2807002 Test Loss: 0.3550238
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.3725802898406982
Epoch: 50, Steps: 63 | Train Loss: 0.5060606 Vali Loss: 0.2803124 Test Loss: 0.3549685
Validation loss decreased (0.280380 --> 0.280312).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.531709909439087
Epoch: 51, Steps: 63 | Train Loss: 0.5069272 Vali Loss: 0.2806925 Test Loss: 0.3550021
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.3323259353637695
Epoch: 52, Steps: 63 | Train Loss: 0.5074412 Vali Loss: 0.2807077 Test Loss: 0.3549922
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.9654512405395508
Epoch: 53, Steps: 63 | Train Loss: 0.5080217 Vali Loss: 0.2806796 Test Loss: 0.3549584
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.494450330734253
Epoch: 54, Steps: 63 | Train Loss: 0.5072032 Vali Loss: 0.2806971 Test Loss: 0.3549501
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.693110704421997
Epoch: 55, Steps: 63 | Train Loss: 0.5073802 Vali Loss: 0.2806531 Test Loss: 0.3549682
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.8938276767730713
Epoch: 56, Steps: 63 | Train Loss: 0.5070748 Vali Loss: 0.2806610 Test Loss: 0.3549601
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.744568109512329
Epoch: 57, Steps: 63 | Train Loss: 0.5079567 Vali Loss: 0.2806843 Test Loss: 0.3549447
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.323401689529419
Epoch: 58, Steps: 63 | Train Loss: 0.5073200 Vali Loss: 0.2806683 Test Loss: 0.3549637
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.9551970958709717
Epoch: 59, Steps: 63 | Train Loss: 0.5079915 Vali Loss: 0.2803315 Test Loss: 0.3549434
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.0514163970947266
Epoch: 60, Steps: 63 | Train Loss: 0.5082645 Vali Loss: 0.2806568 Test Loss: 0.3549522
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.872239351272583
Epoch: 61, Steps: 63 | Train Loss: 0.5077054 Vali Loss: 0.2802594 Test Loss: 0.3549583
Validation loss decreased (0.280312 --> 0.280259).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.510901927947998
Epoch: 62, Steps: 63 | Train Loss: 0.5075070 Vali Loss: 0.2806318 Test Loss: 0.3549584
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.537994384765625
Epoch: 63, Steps: 63 | Train Loss: 0.5061431 Vali Loss: 0.2806205 Test Loss: 0.3549525
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.938735008239746
Epoch: 64, Steps: 63 | Train Loss: 0.5078850 Vali Loss: 0.2806205 Test Loss: 0.3549624
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.9463093280792236
Epoch: 65, Steps: 63 | Train Loss: 0.5071055 Vali Loss: 0.2806513 Test Loss: 0.3549528
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.6967790126800537
Epoch: 66, Steps: 63 | Train Loss: 0.5080364 Vali Loss: 0.2805783 Test Loss: 0.3549420
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.9834928512573242
Epoch: 67, Steps: 63 | Train Loss: 0.5072410 Vali Loss: 0.2806184 Test Loss: 0.3549452
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.8643181324005127
Epoch: 68, Steps: 63 | Train Loss: 0.5073530 Vali Loss: 0.2803536 Test Loss: 0.3549442
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.1097195148468018
Epoch: 69, Steps: 63 | Train Loss: 0.5080698 Vali Loss: 0.2806284 Test Loss: 0.3549453
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.8260595798492432
Epoch: 70, Steps: 63 | Train Loss: 0.5080689 Vali Loss: 0.2805941 Test Loss: 0.3549387
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.9537169933319092
Epoch: 71, Steps: 63 | Train Loss: 0.5079075 Vali Loss: 0.2805582 Test Loss: 0.3549314
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.993645191192627
Epoch: 72, Steps: 63 | Train Loss: 0.5080175 Vali Loss: 0.2806307 Test Loss: 0.3549410
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.0594425201416016
Epoch: 73, Steps: 63 | Train Loss: 0.5073529 Vali Loss: 0.2805582 Test Loss: 0.3549415
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.9423277378082275
Epoch: 74, Steps: 63 | Train Loss: 0.5082092 Vali Loss: 0.2806131 Test Loss: 0.3549370
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.183582305908203
Epoch: 75, Steps: 63 | Train Loss: 0.5057116 Vali Loss: 0.2806064 Test Loss: 0.3549388
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.481182336807251
Epoch: 76, Steps: 63 | Train Loss: 0.5078415 Vali Loss: 0.2805303 Test Loss: 0.3549347
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.7636377811431885
Epoch: 77, Steps: 63 | Train Loss: 0.5078927 Vali Loss: 0.2805729 Test Loss: 0.3549438
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.1765036582946777
Epoch: 78, Steps: 63 | Train Loss: 0.5076427 Vali Loss: 0.2803379 Test Loss: 0.3549320
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.382874011993408
Epoch: 79, Steps: 63 | Train Loss: 0.5070825 Vali Loss: 0.2805601 Test Loss: 0.3549372
EarlyStopping counter: 18 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.0246806144714355
Epoch: 80, Steps: 63 | Train Loss: 0.5079586 Vali Loss: 0.2805425 Test Loss: 0.3549299
EarlyStopping counter: 19 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.3868913650512695
Epoch: 81, Steps: 63 | Train Loss: 0.5082631 Vali Loss: 0.2806185 Test Loss: 0.3549376
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_360_192_FITS_ETTh2_ftM_sl360_ll48_pl192_H2_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.33641934394836426, mae:0.3765047788619995, rse:0.4651374816894531, corr:[0.26639506 0.26782152 0.26799306 0.2667783  0.26488963 0.2632375
 0.2622093  0.26138762 0.26067933 0.25957164 0.25815704 0.25646695
 0.25502473 0.2540303  0.25340277 0.25313294 0.25278383 0.25230348
 0.2514678  0.2502873  0.24891019 0.24725954 0.24548459 0.24345544
 0.24143201 0.23952062 0.23794907 0.23645496 0.23490447 0.23331268
 0.23182753 0.23030283 0.22874385 0.22724086 0.22592227 0.22476178
 0.2236799  0.22263962 0.22185959 0.22114675 0.22045684 0.21973082
 0.21877775 0.21755856 0.21622705 0.2148303  0.21337457 0.21175678
 0.20999815 0.2083023  0.20679258 0.20533872 0.20376475 0.20201582
 0.2000131  0.19789499 0.19611807 0.19451994 0.1933621  0.19273391
 0.1926724  0.1926848  0.19267607 0.19244842 0.19188367 0.19118258
 0.19031848 0.18934171 0.18841481 0.18760769 0.18693647 0.18634626
 0.18560308 0.18473554 0.18370672 0.18253948 0.18163358 0.18105885
 0.18060079 0.18007785 0.17983134 0.17944288 0.17900497 0.17847157
 0.17807992 0.17777261 0.17760488 0.17752221 0.17730993 0.17708641
 0.1767127  0.17613067 0.17567307 0.17519    0.17472005 0.1742567
 0.17379348 0.17311174 0.17228019 0.17118677 0.16999145 0.16895269
 0.16837433 0.16802256 0.1680467  0.16825277 0.16825959 0.16818486
 0.16757438 0.16671582 0.16575138 0.16527055 0.16499643 0.1649631
 0.1649589  0.16452129 0.16376537 0.16245337 0.1607928  0.15902966
 0.15761569 0.1563318  0.15541519 0.1548315  0.15409888 0.15312012
 0.15208216 0.15110727 0.15029408 0.14963248 0.14930578 0.1490806
 0.14889273 0.14841339 0.14762783 0.14681451 0.14614029 0.14587098
 0.1456879  0.14572093 0.1457808  0.14528584 0.14400771 0.14227504
 0.14043541 0.13869944 0.13724656 0.13627432 0.13578789 0.13533983
 0.13504237 0.1343206  0.13360839 0.13310526 0.13284257 0.1327444
 0.13281158 0.13316055 0.13306646 0.13286671 0.13248326 0.13212085
 0.13199802 0.13208283 0.13234022 0.1323113  0.13194013 0.13080245
 0.12933151 0.12782334 0.12640242 0.12525092 0.12439726 0.123508
 0.12236486 0.12082452 0.11906511 0.1173954  0.11620552 0.11545639
 0.11538075 0.11565737 0.11561814 0.11499771 0.11337811 0.11107933
 0.10947902 0.10913421 0.11033116 0.11248006 0.11387648 0.11184131]
