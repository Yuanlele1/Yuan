Args in experiment:
Namespace(H_order=2, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=18, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_90_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_90_192_FITS_ETTh2_ftM_sl90_ll48_pl192_H2_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8359
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=18, out_features=56, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  903168.0
params:  1064.0
Trainable parameters:  1064
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.6156604290008545
Epoch: 1, Steps: 65 | Train Loss: 0.6579405 Vali Loss: 0.3930405 Test Loss: 0.5507384
Validation loss decreased (inf --> 0.393041).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.3450982570648193
Epoch: 2, Steps: 65 | Train Loss: 0.5715985 Vali Loss: 0.3610347 Test Loss: 0.5068201
Validation loss decreased (0.393041 --> 0.361035).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.2201626300811768
Epoch: 3, Steps: 65 | Train Loss: 0.5138195 Vali Loss: 0.3401030 Test Loss: 0.4780976
Validation loss decreased (0.361035 --> 0.340103).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.194530487060547
Epoch: 4, Steps: 65 | Train Loss: 0.4815256 Vali Loss: 0.3258364 Test Loss: 0.4587225
Validation loss decreased (0.340103 --> 0.325836).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.652700662612915
Epoch: 5, Steps: 65 | Train Loss: 0.4563867 Vali Loss: 0.3157291 Test Loss: 0.4449743
Validation loss decreased (0.325836 --> 0.315729).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.9615192413330078
Epoch: 6, Steps: 65 | Train Loss: 0.4396001 Vali Loss: 0.3085439 Test Loss: 0.4353177
Validation loss decreased (0.315729 --> 0.308544).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.1641757488250732
Epoch: 7, Steps: 65 | Train Loss: 0.4255447 Vali Loss: 0.3031371 Test Loss: 0.4281478
Validation loss decreased (0.308544 --> 0.303137).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.2353830337524414
Epoch: 8, Steps: 65 | Train Loss: 0.4171626 Vali Loss: 0.2991104 Test Loss: 0.4229126
Validation loss decreased (0.303137 --> 0.299110).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.4725005626678467
Epoch: 9, Steps: 65 | Train Loss: 0.4105449 Vali Loss: 0.2959624 Test Loss: 0.4188088
Validation loss decreased (0.299110 --> 0.295962).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.7498278617858887
Epoch: 10, Steps: 65 | Train Loss: 0.4064881 Vali Loss: 0.2934903 Test Loss: 0.4157045
Validation loss decreased (0.295962 --> 0.293490).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.456773281097412
Epoch: 11, Steps: 65 | Train Loss: 0.4019273 Vali Loss: 0.2915104 Test Loss: 0.4132255
Validation loss decreased (0.293490 --> 0.291510).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.092639207839966
Epoch: 12, Steps: 65 | Train Loss: 0.3987345 Vali Loss: 0.2898608 Test Loss: 0.4110999
Validation loss decreased (0.291510 --> 0.289861).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.8563952445983887
Epoch: 13, Steps: 65 | Train Loss: 0.3963683 Vali Loss: 0.2885030 Test Loss: 0.4094285
Validation loss decreased (0.289861 --> 0.288503).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.4956262111663818
Epoch: 14, Steps: 65 | Train Loss: 0.3954995 Vali Loss: 0.2873783 Test Loss: 0.4081150
Validation loss decreased (0.288503 --> 0.287378).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.180293321609497
Epoch: 15, Steps: 65 | Train Loss: 0.3937871 Vali Loss: 0.2863674 Test Loss: 0.4069544
Validation loss decreased (0.287378 --> 0.286367).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.34805965423584
Epoch: 16, Steps: 65 | Train Loss: 0.3907547 Vali Loss: 0.2855731 Test Loss: 0.4060155
Validation loss decreased (0.286367 --> 0.285573).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.5338802337646484
Epoch: 17, Steps: 65 | Train Loss: 0.3900261 Vali Loss: 0.2848627 Test Loss: 0.4052052
Validation loss decreased (0.285573 --> 0.284863).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.9731578826904297
Epoch: 18, Steps: 65 | Train Loss: 0.3895428 Vali Loss: 0.2842163 Test Loss: 0.4045183
Validation loss decreased (0.284863 --> 0.284216).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.8059759140014648
Epoch: 19, Steps: 65 | Train Loss: 0.3889137 Vali Loss: 0.2836798 Test Loss: 0.4039365
Validation loss decreased (0.284216 --> 0.283680).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.027831554412842
Epoch: 20, Steps: 65 | Train Loss: 0.3871106 Vali Loss: 0.2831791 Test Loss: 0.4033832
Validation loss decreased (0.283680 --> 0.283179).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.9373507499694824
Epoch: 21, Steps: 65 | Train Loss: 0.3873524 Vali Loss: 0.2827224 Test Loss: 0.4029457
Validation loss decreased (0.283179 --> 0.282722).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.753936767578125
Epoch: 22, Steps: 65 | Train Loss: 0.3852271 Vali Loss: 0.2823062 Test Loss: 0.4025345
Validation loss decreased (0.282722 --> 0.282306).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.5619161128997803
Epoch: 23, Steps: 65 | Train Loss: 0.3859548 Vali Loss: 0.2819816 Test Loss: 0.4021721
Validation loss decreased (0.282306 --> 0.281982).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.102994441986084
Epoch: 24, Steps: 65 | Train Loss: 0.3841148 Vali Loss: 0.2813189 Test Loss: 0.4018275
Validation loss decreased (0.281982 --> 0.281319).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.6325275897979736
Epoch: 25, Steps: 65 | Train Loss: 0.3842864 Vali Loss: 0.2813638 Test Loss: 0.4016114
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.039307117462158
Epoch: 26, Steps: 65 | Train Loss: 0.3849092 Vali Loss: 0.2810749 Test Loss: 0.4013658
Validation loss decreased (0.281319 --> 0.281075).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.3453662395477295
Epoch: 27, Steps: 65 | Train Loss: 0.3843069 Vali Loss: 0.2808030 Test Loss: 0.4011374
Validation loss decreased (0.281075 --> 0.280803).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.7609775066375732
Epoch: 28, Steps: 65 | Train Loss: 0.3836400 Vali Loss: 0.2805811 Test Loss: 0.4009406
Validation loss decreased (0.280803 --> 0.280581).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.086763858795166
Epoch: 29, Steps: 65 | Train Loss: 0.3832770 Vali Loss: 0.2804186 Test Loss: 0.4007608
Validation loss decreased (0.280581 --> 0.280419).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 3.3908934593200684
Epoch: 30, Steps: 65 | Train Loss: 0.3831250 Vali Loss: 0.2802232 Test Loss: 0.4005886
Validation loss decreased (0.280419 --> 0.280223).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.4834773540496826
Epoch: 31, Steps: 65 | Train Loss: 0.3820838 Vali Loss: 0.2797897 Test Loss: 0.4004627
Validation loss decreased (0.280223 --> 0.279790).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.330653429031372
Epoch: 32, Steps: 65 | Train Loss: 0.3814044 Vali Loss: 0.2798782 Test Loss: 0.4003184
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.6830837726593018
Epoch: 33, Steps: 65 | Train Loss: 0.3826935 Vali Loss: 0.2797951 Test Loss: 0.4002112
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.8509812355041504
Epoch: 34, Steps: 65 | Train Loss: 0.3821884 Vali Loss: 0.2795916 Test Loss: 0.4000930
Validation loss decreased (0.279790 --> 0.279592).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.6492090225219727
Epoch: 35, Steps: 65 | Train Loss: 0.3822536 Vali Loss: 0.2795416 Test Loss: 0.4000193
Validation loss decreased (0.279592 --> 0.279542).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.6324360370635986
Epoch: 36, Steps: 65 | Train Loss: 0.3818992 Vali Loss: 0.2793711 Test Loss: 0.3999162
Validation loss decreased (0.279542 --> 0.279371).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.3077657222747803
Epoch: 37, Steps: 65 | Train Loss: 0.3822720 Vali Loss: 0.2791803 Test Loss: 0.3998213
Validation loss decreased (0.279371 --> 0.279180).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.8310647010803223
Epoch: 38, Steps: 65 | Train Loss: 0.3817256 Vali Loss: 0.2791207 Test Loss: 0.3997557
Validation loss decreased (0.279180 --> 0.279121).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.739347219467163
Epoch: 39, Steps: 65 | Train Loss: 0.3807821 Vali Loss: 0.2790783 Test Loss: 0.3996826
Validation loss decreased (0.279121 --> 0.279078).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.0934977531433105
Epoch: 40, Steps: 65 | Train Loss: 0.3817986 Vali Loss: 0.2790188 Test Loss: 0.3996200
Validation loss decreased (0.279078 --> 0.279019).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.9408049583435059
Epoch: 41, Steps: 65 | Train Loss: 0.3814457 Vali Loss: 0.2788827 Test Loss: 0.3995662
Validation loss decreased (0.279019 --> 0.278883).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.727174997329712
Epoch: 42, Steps: 65 | Train Loss: 0.3810561 Vali Loss: 0.2785111 Test Loss: 0.3995226
Validation loss decreased (0.278883 --> 0.278511).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.8322608470916748
Epoch: 43, Steps: 65 | Train Loss: 0.3777954 Vali Loss: 0.2786655 Test Loss: 0.3994737
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.001584768295288
Epoch: 44, Steps: 65 | Train Loss: 0.3806841 Vali Loss: 0.2786179 Test Loss: 0.3994269
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.008554220199585
Epoch: 45, Steps: 65 | Train Loss: 0.3804771 Vali Loss: 0.2786216 Test Loss: 0.3993758
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.933220863342285
Epoch: 46, Steps: 65 | Train Loss: 0.3808193 Vali Loss: 0.2785720 Test Loss: 0.3993434
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.9681003093719482
Epoch: 47, Steps: 65 | Train Loss: 0.3802702 Vali Loss: 0.2785209 Test Loss: 0.3992974
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.908452272415161
Epoch: 48, Steps: 65 | Train Loss: 0.3811001 Vali Loss: 0.2784151 Test Loss: 0.3992730
Validation loss decreased (0.278511 --> 0.278415).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.7323622703552246
Epoch: 49, Steps: 65 | Train Loss: 0.3811021 Vali Loss: 0.2784090 Test Loss: 0.3992438
Validation loss decreased (0.278415 --> 0.278409).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.6792750358581543
Epoch: 50, Steps: 65 | Train Loss: 0.3790181 Vali Loss: 0.2783111 Test Loss: 0.3992190
Validation loss decreased (0.278409 --> 0.278311).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 3.0303518772125244
Epoch: 51, Steps: 65 | Train Loss: 0.3803120 Vali Loss: 0.2783154 Test Loss: 0.3991879
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.493990421295166
Epoch: 52, Steps: 65 | Train Loss: 0.3804529 Vali Loss: 0.2781918 Test Loss: 0.3991659
Validation loss decreased (0.278311 --> 0.278192).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.3638715744018555
Epoch: 53, Steps: 65 | Train Loss: 0.3796309 Vali Loss: 0.2781327 Test Loss: 0.3991395
Validation loss decreased (0.278192 --> 0.278133).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 3.0899884700775146
Epoch: 54, Steps: 65 | Train Loss: 0.3797131 Vali Loss: 0.2781412 Test Loss: 0.3991242
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.40134596824646
Epoch: 55, Steps: 65 | Train Loss: 0.3798693 Vali Loss: 0.2781439 Test Loss: 0.3990968
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.488745927810669
Epoch: 56, Steps: 65 | Train Loss: 0.3798232 Vali Loss: 0.2780358 Test Loss: 0.3990778
Validation loss decreased (0.278133 --> 0.278036).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.317375421524048
Epoch: 57, Steps: 65 | Train Loss: 0.3788781 Vali Loss: 0.2780742 Test Loss: 0.3990707
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.9120521545410156
Epoch: 58, Steps: 65 | Train Loss: 0.3795926 Vali Loss: 0.2779363 Test Loss: 0.3990445
Validation loss decreased (0.278036 --> 0.277936).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.666276454925537
Epoch: 59, Steps: 65 | Train Loss: 0.3803231 Vali Loss: 0.2779642 Test Loss: 0.3990326
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.718881368637085
Epoch: 60, Steps: 65 | Train Loss: 0.3775615 Vali Loss: 0.2780114 Test Loss: 0.3990149
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.946852445602417
Epoch: 61, Steps: 65 | Train Loss: 0.3801672 Vali Loss: 0.2778562 Test Loss: 0.3990049
Validation loss decreased (0.277936 --> 0.277856).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.8059966564178467
Epoch: 62, Steps: 65 | Train Loss: 0.3802909 Vali Loss: 0.2777987 Test Loss: 0.3989921
Validation loss decreased (0.277856 --> 0.277799).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.728318214416504
Epoch: 63, Steps: 65 | Train Loss: 0.3788571 Vali Loss: 0.2777371 Test Loss: 0.3989796
Validation loss decreased (0.277799 --> 0.277737).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.9776206016540527
Epoch: 64, Steps: 65 | Train Loss: 0.3801226 Vali Loss: 0.2778998 Test Loss: 0.3989702
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.024754524230957
Epoch: 65, Steps: 65 | Train Loss: 0.3796273 Vali Loss: 0.2778329 Test Loss: 0.3989633
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.918799638748169
Epoch: 66, Steps: 65 | Train Loss: 0.3799696 Vali Loss: 0.2778500 Test Loss: 0.3989496
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.132561445236206
Epoch: 67, Steps: 65 | Train Loss: 0.3797000 Vali Loss: 0.2778187 Test Loss: 0.3989367
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.9879493713378906
Epoch: 68, Steps: 65 | Train Loss: 0.3795569 Vali Loss: 0.2778202 Test Loss: 0.3989289
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.684811592102051
Epoch: 69, Steps: 65 | Train Loss: 0.3786863 Vali Loss: 0.2778218 Test Loss: 0.3989215
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.723069906234741
Epoch: 70, Steps: 65 | Train Loss: 0.3789073 Vali Loss: 0.2776780 Test Loss: 0.3989128
Validation loss decreased (0.277737 --> 0.277678).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.7769007682800293
Epoch: 71, Steps: 65 | Train Loss: 0.3791475 Vali Loss: 0.2776655 Test Loss: 0.3989081
Validation loss decreased (0.277678 --> 0.277665).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.602836847305298
Epoch: 72, Steps: 65 | Train Loss: 0.3798202 Vali Loss: 0.2777362 Test Loss: 0.3988979
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.8486061096191406
Epoch: 73, Steps: 65 | Train Loss: 0.3793918 Vali Loss: 0.2777193 Test Loss: 0.3988914
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.1386191844940186
Epoch: 74, Steps: 65 | Train Loss: 0.3792312 Vali Loss: 0.2776485 Test Loss: 0.3988895
Validation loss decreased (0.277665 --> 0.277649).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.6535606384277344
Epoch: 75, Steps: 65 | Train Loss: 0.3785034 Vali Loss: 0.2775540 Test Loss: 0.3988828
Validation loss decreased (0.277649 --> 0.277554).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.7255439758300781
Epoch: 76, Steps: 65 | Train Loss: 0.3782160 Vali Loss: 0.2777014 Test Loss: 0.3988764
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.6692399978637695
Epoch: 77, Steps: 65 | Train Loss: 0.3793494 Vali Loss: 0.2776459 Test Loss: 0.3988698
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.7645289897918701
Epoch: 78, Steps: 65 | Train Loss: 0.3792693 Vali Loss: 0.2777010 Test Loss: 0.3988655
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.6414477825164795
Epoch: 79, Steps: 65 | Train Loss: 0.3792091 Vali Loss: 0.2776735 Test Loss: 0.3988625
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 3.2695415019989014
Epoch: 80, Steps: 65 | Train Loss: 0.3790374 Vali Loss: 0.2775510 Test Loss: 0.3988584
Validation loss decreased (0.277554 --> 0.277551).  Saving model ...
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.2097206115722656
Epoch: 81, Steps: 65 | Train Loss: 0.3795508 Vali Loss: 0.2776684 Test Loss: 0.3988533
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 3.478186845779419
Epoch: 82, Steps: 65 | Train Loss: 0.3786174 Vali Loss: 0.2776580 Test Loss: 0.3988490
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.8974368572235107
Epoch: 83, Steps: 65 | Train Loss: 0.3788702 Vali Loss: 0.2775684 Test Loss: 0.3988478
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.241624116897583
Epoch: 84, Steps: 65 | Train Loss: 0.3790715 Vali Loss: 0.2776430 Test Loss: 0.3988421
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.0741465091705322
Epoch: 85, Steps: 65 | Train Loss: 0.3798955 Vali Loss: 0.2776030 Test Loss: 0.3988394
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.996847152709961
Epoch: 86, Steps: 65 | Train Loss: 0.3794687 Vali Loss: 0.2776309 Test Loss: 0.3988370
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 2.0155813694000244
Epoch: 87, Steps: 65 | Train Loss: 0.3783352 Vali Loss: 0.2776209 Test Loss: 0.3988350
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.9319312572479248
Epoch: 88, Steps: 65 | Train Loss: 0.3793630 Vali Loss: 0.2775028 Test Loss: 0.3988321
Validation loss decreased (0.277551 --> 0.277503).  Saving model ...
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.803391456604004
Epoch: 89, Steps: 65 | Train Loss: 0.3796999 Vali Loss: 0.2775945 Test Loss: 0.3988290
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.852449893951416
Epoch: 90, Steps: 65 | Train Loss: 0.3791003 Vali Loss: 0.2775707 Test Loss: 0.3988261
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.1800365447998047
Epoch: 91, Steps: 65 | Train Loss: 0.3788724 Vali Loss: 0.2775181 Test Loss: 0.3988250
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 2.5757274627685547
Epoch: 92, Steps: 65 | Train Loss: 0.3786533 Vali Loss: 0.2775553 Test Loss: 0.3988211
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 2.011505126953125
Epoch: 93, Steps: 65 | Train Loss: 0.3794570 Vali Loss: 0.2775532 Test Loss: 0.3988200
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.8647873401641846
Epoch: 94, Steps: 65 | Train Loss: 0.3789078 Vali Loss: 0.2775598 Test Loss: 0.3988183
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 2.4656219482421875
Epoch: 95, Steps: 65 | Train Loss: 0.3767773 Vali Loss: 0.2775607 Test Loss: 0.3988166
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 2.113957643508911
Epoch: 96, Steps: 65 | Train Loss: 0.3786328 Vali Loss: 0.2775782 Test Loss: 0.3988144
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.7156119346618652
Epoch: 97, Steps: 65 | Train Loss: 0.3786609 Vali Loss: 0.2775152 Test Loss: 0.3988130
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.9423487186431885
Epoch: 98, Steps: 65 | Train Loss: 0.3777902 Vali Loss: 0.2775352 Test Loss: 0.3988122
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 2.1501996517181396
Epoch: 99, Steps: 65 | Train Loss: 0.3795171 Vali Loss: 0.2775519 Test Loss: 0.3988102
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.6036250591278076
Epoch: 100, Steps: 65 | Train Loss: 0.3789734 Vali Loss: 0.2774732 Test Loss: 0.3988087
Validation loss decreased (0.277503 --> 0.277473).  Saving model ...
Updating learning rate to 3.1160680107021042e-06
train 8359
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=18, out_features=56, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  903168.0
params:  1064.0
Trainable parameters:  1064
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.6577363014221191
Epoch: 1, Steps: 65 | Train Loss: 0.5432658 Vali Loss: 0.2767400 Test Loss: 0.3981243
Validation loss decreased (inf --> 0.276740).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.907127857208252
Epoch: 2, Steps: 65 | Train Loss: 0.5414599 Vali Loss: 0.2761920 Test Loss: 0.3978598
Validation loss decreased (0.276740 --> 0.276192).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.6335489749908447
Epoch: 3, Steps: 65 | Train Loss: 0.5407991 Vali Loss: 0.2758873 Test Loss: 0.3977305
Validation loss decreased (0.276192 --> 0.275887).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.9911158084869385
Epoch: 4, Steps: 65 | Train Loss: 0.5395056 Vali Loss: 0.2755269 Test Loss: 0.3976199
Validation loss decreased (0.275887 --> 0.275527).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.7437756061553955
Epoch: 5, Steps: 65 | Train Loss: 0.5388569 Vali Loss: 0.2750508 Test Loss: 0.3976831
Validation loss decreased (0.275527 --> 0.275051).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.884976625442505
Epoch: 6, Steps: 65 | Train Loss: 0.5394229 Vali Loss: 0.2752512 Test Loss: 0.3976465
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.194418430328369
Epoch: 7, Steps: 65 | Train Loss: 0.5390068 Vali Loss: 0.2749468 Test Loss: 0.3976233
Validation loss decreased (0.275051 --> 0.274947).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.8413643836975098
Epoch: 8, Steps: 65 | Train Loss: 0.5379292 Vali Loss: 0.2744921 Test Loss: 0.3975030
Validation loss decreased (0.274947 --> 0.274492).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.0562734603881836
Epoch: 9, Steps: 65 | Train Loss: 0.5369595 Vali Loss: 0.2746669 Test Loss: 0.3975558
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.1120026111602783
Epoch: 10, Steps: 65 | Train Loss: 0.5394597 Vali Loss: 0.2746194 Test Loss: 0.3975482
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.7955718040466309
Epoch: 11, Steps: 65 | Train Loss: 0.5371163 Vali Loss: 0.2745124 Test Loss: 0.3975696
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.7652873992919922
Epoch: 12, Steps: 65 | Train Loss: 0.5393314 Vali Loss: 0.2743761 Test Loss: 0.3975509
Validation loss decreased (0.274492 --> 0.274376).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.1627180576324463
Epoch: 13, Steps: 65 | Train Loss: 0.5383289 Vali Loss: 0.2743731 Test Loss: 0.3976261
Validation loss decreased (0.274376 --> 0.274373).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.036578893661499
Epoch: 14, Steps: 65 | Train Loss: 0.5376179 Vali Loss: 0.2742639 Test Loss: 0.3976807
Validation loss decreased (0.274373 --> 0.274264).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.3478641510009766
Epoch: 15, Steps: 65 | Train Loss: 0.5378701 Vali Loss: 0.2741596 Test Loss: 0.3976172
Validation loss decreased (0.274264 --> 0.274160).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.1551239490509033
Epoch: 16, Steps: 65 | Train Loss: 0.5378955 Vali Loss: 0.2740773 Test Loss: 0.3976922
Validation loss decreased (0.274160 --> 0.274077).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.1555349826812744
Epoch: 17, Steps: 65 | Train Loss: 0.5384969 Vali Loss: 0.2740574 Test Loss: 0.3976950
Validation loss decreased (0.274077 --> 0.274057).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.6485307216644287
Epoch: 18, Steps: 65 | Train Loss: 0.5374096 Vali Loss: 0.2740827 Test Loss: 0.3977364
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.9657599925994873
Epoch: 19, Steps: 65 | Train Loss: 0.5380707 Vali Loss: 0.2740358 Test Loss: 0.3977576
Validation loss decreased (0.274057 --> 0.274036).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.9287309646606445
Epoch: 20, Steps: 65 | Train Loss: 0.5380219 Vali Loss: 0.2739526 Test Loss: 0.3977429
Validation loss decreased (0.274036 --> 0.273953).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.5104730129241943
Epoch: 21, Steps: 65 | Train Loss: 0.5366097 Vali Loss: 0.2739794 Test Loss: 0.3978114
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.152601718902588
Epoch: 22, Steps: 65 | Train Loss: 0.5374638 Vali Loss: 0.2739135 Test Loss: 0.3978131
Validation loss decreased (0.273953 --> 0.273914).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.5623528957366943
Epoch: 23, Steps: 65 | Train Loss: 0.5380999 Vali Loss: 0.2739184 Test Loss: 0.3978343
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.081601619720459
Epoch: 24, Steps: 65 | Train Loss: 0.5367407 Vali Loss: 0.2738559 Test Loss: 0.3978596
Validation loss decreased (0.273914 --> 0.273856).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.7346422672271729
Epoch: 25, Steps: 65 | Train Loss: 0.5365357 Vali Loss: 0.2737476 Test Loss: 0.3978707
Validation loss decreased (0.273856 --> 0.273748).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.42274808883667
Epoch: 26, Steps: 65 | Train Loss: 0.5374719 Vali Loss: 0.2738178 Test Loss: 0.3978757
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.7763564586639404
Epoch: 27, Steps: 65 | Train Loss: 0.5372017 Vali Loss: 0.2738323 Test Loss: 0.3979256
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.131387233734131
Epoch: 28, Steps: 65 | Train Loss: 0.5375150 Vali Loss: 0.2737479 Test Loss: 0.3978779
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.3447399139404297
Epoch: 29, Steps: 65 | Train Loss: 0.5335125 Vali Loss: 0.2736781 Test Loss: 0.3979163
Validation loss decreased (0.273748 --> 0.273678).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.9684178829193115
Epoch: 30, Steps: 65 | Train Loss: 0.5374527 Vali Loss: 0.2737618 Test Loss: 0.3979530
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.792517900466919
Epoch: 31, Steps: 65 | Train Loss: 0.5362797 Vali Loss: 0.2736230 Test Loss: 0.3979392
Validation loss decreased (0.273678 --> 0.273623).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.644939422607422
Epoch: 32, Steps: 65 | Train Loss: 0.5369144 Vali Loss: 0.2737317 Test Loss: 0.3979599
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.2855825424194336
Epoch: 33, Steps: 65 | Train Loss: 0.5373077 Vali Loss: 0.2736723 Test Loss: 0.3979502
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.186755418777466
Epoch: 34, Steps: 65 | Train Loss: 0.5381415 Vali Loss: 0.2736847 Test Loss: 0.3979526
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.7523746490478516
Epoch: 35, Steps: 65 | Train Loss: 0.5365608 Vali Loss: 0.2736608 Test Loss: 0.3979691
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.640130043029785
Epoch: 36, Steps: 65 | Train Loss: 0.5346747 Vali Loss: 0.2736080 Test Loss: 0.3979685
Validation loss decreased (0.273623 --> 0.273608).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.5751218795776367
Epoch: 37, Steps: 65 | Train Loss: 0.5362497 Vali Loss: 0.2736436 Test Loss: 0.3979923
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.6641523838043213
Epoch: 38, Steps: 65 | Train Loss: 0.5359340 Vali Loss: 0.2733231 Test Loss: 0.3980042
Validation loss decreased (0.273608 --> 0.273323).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.1393394470214844
Epoch: 39, Steps: 65 | Train Loss: 0.5368199 Vali Loss: 0.2732330 Test Loss: 0.3980024
Validation loss decreased (0.273323 --> 0.273233).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.7933259010314941
Epoch: 40, Steps: 65 | Train Loss: 0.5375510 Vali Loss: 0.2732767 Test Loss: 0.3979942
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 3.968618631362915
Epoch: 41, Steps: 65 | Train Loss: 0.5360259 Vali Loss: 0.2735469 Test Loss: 0.3980082
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.033421039581299
Epoch: 42, Steps: 65 | Train Loss: 0.5363320 Vali Loss: 0.2734521 Test Loss: 0.3980099
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.082629442214966
Epoch: 43, Steps: 65 | Train Loss: 0.5359991 Vali Loss: 0.2734944 Test Loss: 0.3980174
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.7336342334747314
Epoch: 44, Steps: 65 | Train Loss: 0.5376794 Vali Loss: 0.2735243 Test Loss: 0.3980306
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.033684253692627
Epoch: 45, Steps: 65 | Train Loss: 0.5349696 Vali Loss: 0.2734209 Test Loss: 0.3980251
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.617548942565918
Epoch: 46, Steps: 65 | Train Loss: 0.5368431 Vali Loss: 0.2735784 Test Loss: 0.3980384
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.3145627975463867
Epoch: 47, Steps: 65 | Train Loss: 0.5362943 Vali Loss: 0.2734925 Test Loss: 0.3980511
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.0564687252044678
Epoch: 48, Steps: 65 | Train Loss: 0.5369169 Vali Loss: 0.2735185 Test Loss: 0.3980562
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.9190573692321777
Epoch: 49, Steps: 65 | Train Loss: 0.5367580 Vali Loss: 0.2735232 Test Loss: 0.3980579
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.5581636428833008
Epoch: 50, Steps: 65 | Train Loss: 0.5365489 Vali Loss: 0.2735476 Test Loss: 0.3980627
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.8103954792022705
Epoch: 51, Steps: 65 | Train Loss: 0.5365240 Vali Loss: 0.2731171 Test Loss: 0.3980709
Validation loss decreased (0.273233 --> 0.273117).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.851088285446167
Epoch: 52, Steps: 65 | Train Loss: 0.5361123 Vali Loss: 0.2735199 Test Loss: 0.3980733
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.7282235622406006
Epoch: 53, Steps: 65 | Train Loss: 0.5376574 Vali Loss: 0.2735439 Test Loss: 0.3980716
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.390462875366211
Epoch: 54, Steps: 65 | Train Loss: 0.5374974 Vali Loss: 0.2734306 Test Loss: 0.3980754
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 3.1851072311401367
Epoch: 55, Steps: 65 | Train Loss: 0.5335692 Vali Loss: 0.2735133 Test Loss: 0.3980851
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.699859619140625
Epoch: 56, Steps: 65 | Train Loss: 0.5370696 Vali Loss: 0.2735107 Test Loss: 0.3980843
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.2619714736938477
Epoch: 57, Steps: 65 | Train Loss: 0.5363185 Vali Loss: 0.2734730 Test Loss: 0.3980849
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.9767308235168457
Epoch: 58, Steps: 65 | Train Loss: 0.5370172 Vali Loss: 0.2734757 Test Loss: 0.3980977
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.3447229862213135
Epoch: 59, Steps: 65 | Train Loss: 0.5362883 Vali Loss: 0.2735089 Test Loss: 0.3980909
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.2383618354797363
Epoch: 60, Steps: 65 | Train Loss: 0.5367092 Vali Loss: 0.2735211 Test Loss: 0.3980938
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.807908535003662
Epoch: 61, Steps: 65 | Train Loss: 0.5361939 Vali Loss: 0.2734937 Test Loss: 0.3980931
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.7624330520629883
Epoch: 62, Steps: 65 | Train Loss: 0.5349692 Vali Loss: 0.2734401 Test Loss: 0.3981027
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.6365222930908203
Epoch: 63, Steps: 65 | Train Loss: 0.5371467 Vali Loss: 0.2734760 Test Loss: 0.3981015
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.9844388961791992
Epoch: 64, Steps: 65 | Train Loss: 0.5369217 Vali Loss: 0.2734837 Test Loss: 0.3981092
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.329224109649658
Epoch: 65, Steps: 65 | Train Loss: 0.5364534 Vali Loss: 0.2733411 Test Loss: 0.3981059
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.417018413543701
Epoch: 66, Steps: 65 | Train Loss: 0.5359157 Vali Loss: 0.2734597 Test Loss: 0.3981104
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.809370756149292
Epoch: 67, Steps: 65 | Train Loss: 0.5351838 Vali Loss: 0.2734414 Test Loss: 0.3981113
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.7696864604949951
Epoch: 68, Steps: 65 | Train Loss: 0.5362240 Vali Loss: 0.2734702 Test Loss: 0.3981099
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.1081409454345703
Epoch: 69, Steps: 65 | Train Loss: 0.5357469 Vali Loss: 0.2734694 Test Loss: 0.3981168
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.9376773834228516
Epoch: 70, Steps: 65 | Train Loss: 0.5371239 Vali Loss: 0.2735026 Test Loss: 0.3981190
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.3914778232574463
Epoch: 71, Steps: 65 | Train Loss: 0.5369117 Vali Loss: 0.2733744 Test Loss: 0.3981212
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_90_192_FITS_ETTh2_ftM_sl90_ll48_pl192_H2_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.3770466446876526, mae:0.3908693194389343, rse:0.49242308735847473, corr:[0.26694897 0.26992074 0.26827118 0.26639485 0.26582792 0.2656034
 0.26489046 0.2633868  0.26258373 0.26201    0.26101395 0.25906238
 0.25690657 0.25564188 0.25499263 0.25456354 0.25399166 0.25342095
 0.25279978 0.25181544 0.2506952  0.24946639 0.24805968 0.24605215
 0.2430269  0.24041446 0.23810439 0.23635717 0.2349646  0.23363183
 0.2325462  0.2307561  0.22913602 0.22771597 0.22675323 0.22544986
 0.22372018 0.22230233 0.22117059 0.22030783 0.21986431 0.2196289
 0.21922302 0.21809614 0.21706712 0.21626514 0.21507528 0.2128412
 0.20917743 0.20626238 0.20395778 0.20208515 0.20024583 0.19817102
 0.19624087 0.19360296 0.19191046 0.19052212 0.18954055 0.1881665
 0.18690045 0.18673529 0.18683243 0.18651713 0.18591836 0.18559466
 0.18547527 0.18480268 0.18405406 0.1834736  0.18262301 0.18130143
 0.17877859 0.17701074 0.17547853 0.17430852 0.17353857 0.17325291
 0.17312342 0.17173082 0.17094393 0.17074093 0.17074063 0.17019983
 0.16928655 0.16906463 0.16929935 0.16940609 0.1689501  0.16834143
 0.16796727 0.16751957 0.16746065 0.16727681 0.16651532 0.16511945
 0.16277811 0.16107027 0.15940815 0.1577828  0.15640198 0.15560018
 0.15591362 0.15523209 0.1546141  0.15421706 0.15435378 0.15433659
 0.1535207  0.15276398 0.15212283 0.1518387  0.15161836 0.15125199
 0.15094775 0.15026292 0.14972454 0.14907718 0.14757141 0.14516471
 0.14215218 0.14023425 0.13876148 0.13772668 0.13635926 0.13519494
 0.1349208  0.13430196 0.13390993 0.1333811  0.13303123 0.13238259
 0.13160524 0.13108474 0.1306635  0.1302613  0.12988937 0.12959579
 0.12919313 0.12841874 0.12791905 0.12766346 0.12659685 0.12437843
 0.12086327 0.11828964 0.11636213 0.11502184 0.11388975 0.11283653
 0.1125218  0.11159799 0.11122428 0.11095861 0.11090147 0.11042077
 0.10981389 0.10970834 0.10961558 0.10953018 0.10936676 0.10928622
 0.10930607 0.10883342 0.10864548 0.10876275 0.10865876 0.10741477
 0.10446908 0.10238591 0.10093404 0.10014488 0.09955917 0.09902277
 0.09898796 0.09808878 0.09761296 0.09738133 0.09758627 0.09701721
 0.09612084 0.09599127 0.09598168 0.09595121 0.09535296 0.09515253
 0.09576616 0.09572584 0.09536275 0.0957799  0.09743171 0.09926115]
