Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=810, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=196, out_features=222, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  38986752.0
params:  43734.0
Trainable parameters:  43734
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.337794542312622
Epoch: 1, Steps: 61 | Train Loss: 0.5332605 Vali Loss: 0.3816461 Test Loss: 0.3790519
Validation loss decreased (inf --> 0.381646).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.610591173171997
Epoch: 2, Steps: 61 | Train Loss: 0.4053986 Vali Loss: 0.3289469 Test Loss: 0.3412841
Validation loss decreased (0.381646 --> 0.328947).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.4756128787994385
Epoch: 3, Steps: 61 | Train Loss: 0.3443249 Vali Loss: 0.3133948 Test Loss: 0.3291730
Validation loss decreased (0.328947 --> 0.313395).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.3755719661712646
Epoch: 4, Steps: 61 | Train Loss: 0.3077060 Vali Loss: 0.3072709 Test Loss: 0.3249229
Validation loss decreased (0.313395 --> 0.307271).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.438777208328247
Epoch: 5, Steps: 61 | Train Loss: 0.2811421 Vali Loss: 0.3043623 Test Loss: 0.3226629
Validation loss decreased (0.307271 --> 0.304362).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.2683043479919434
Epoch: 6, Steps: 61 | Train Loss: 0.2608910 Vali Loss: 0.3007515 Test Loss: 0.3214202
Validation loss decreased (0.304362 --> 0.300752).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.3480734825134277
Epoch: 7, Steps: 61 | Train Loss: 0.2440383 Vali Loss: 0.2994130 Test Loss: 0.3202472
Validation loss decreased (0.300752 --> 0.299413).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.2890410423278809
Epoch: 8, Steps: 61 | Train Loss: 0.2294707 Vali Loss: 0.2968894 Test Loss: 0.3186614
Validation loss decreased (0.299413 --> 0.296889).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.3623521327972412
Epoch: 9, Steps: 61 | Train Loss: 0.2171316 Vali Loss: 0.2939133 Test Loss: 0.3170797
Validation loss decreased (0.296889 --> 0.293913).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.3990497589111328
Epoch: 10, Steps: 61 | Train Loss: 0.2059043 Vali Loss: 0.2920436 Test Loss: 0.3154286
Validation loss decreased (0.293913 --> 0.292044).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.5267701148986816
Epoch: 11, Steps: 61 | Train Loss: 0.1961767 Vali Loss: 0.2895225 Test Loss: 0.3140443
Validation loss decreased (0.292044 --> 0.289522).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.3325140476226807
Epoch: 12, Steps: 61 | Train Loss: 0.1877240 Vali Loss: 0.2854590 Test Loss: 0.3121752
Validation loss decreased (0.289522 --> 0.285459).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.2696049213409424
Epoch: 13, Steps: 61 | Train Loss: 0.1797093 Vali Loss: 0.2837474 Test Loss: 0.3103158
Validation loss decreased (0.285459 --> 0.283747).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.3130972385406494
Epoch: 14, Steps: 61 | Train Loss: 0.1728776 Vali Loss: 0.2809073 Test Loss: 0.3090199
Validation loss decreased (0.283747 --> 0.280907).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.3172426223754883
Epoch: 15, Steps: 61 | Train Loss: 0.1663808 Vali Loss: 0.2794112 Test Loss: 0.3074478
Validation loss decreased (0.280907 --> 0.279411).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.3415586948394775
Epoch: 16, Steps: 61 | Train Loss: 0.1606806 Vali Loss: 0.2773441 Test Loss: 0.3061428
Validation loss decreased (0.279411 --> 0.277344).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.357327938079834
Epoch: 17, Steps: 61 | Train Loss: 0.1552862 Vali Loss: 0.2745132 Test Loss: 0.3046618
Validation loss decreased (0.277344 --> 0.274513).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.320831060409546
Epoch: 18, Steps: 61 | Train Loss: 0.1508405 Vali Loss: 0.2734899 Test Loss: 0.3033282
Validation loss decreased (0.274513 --> 0.273490).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.3137800693511963
Epoch: 19, Steps: 61 | Train Loss: 0.1464196 Vali Loss: 0.2729575 Test Loss: 0.3021746
Validation loss decreased (0.273490 --> 0.272958).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.2619538307189941
Epoch: 20, Steps: 61 | Train Loss: 0.1423969 Vali Loss: 0.2704852 Test Loss: 0.3010812
Validation loss decreased (0.272958 --> 0.270485).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.2979638576507568
Epoch: 21, Steps: 61 | Train Loss: 0.1388462 Vali Loss: 0.2689866 Test Loss: 0.3000560
Validation loss decreased (0.270485 --> 0.268987).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.282350778579712
Epoch: 22, Steps: 61 | Train Loss: 0.1355078 Vali Loss: 0.2675109 Test Loss: 0.2990264
Validation loss decreased (0.268987 --> 0.267511).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.3681707382202148
Epoch: 23, Steps: 61 | Train Loss: 0.1324439 Vali Loss: 0.2657106 Test Loss: 0.2981815
Validation loss decreased (0.267511 --> 0.265711).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.4255127906799316
Epoch: 24, Steps: 61 | Train Loss: 0.1294333 Vali Loss: 0.2643877 Test Loss: 0.2972490
Validation loss decreased (0.265711 --> 0.264388).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.2723536491394043
Epoch: 25, Steps: 61 | Train Loss: 0.1269364 Vali Loss: 0.2632511 Test Loss: 0.2964160
Validation loss decreased (0.264388 --> 0.263251).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.348093032836914
Epoch: 26, Steps: 61 | Train Loss: 0.1245720 Vali Loss: 0.2622474 Test Loss: 0.2955924
Validation loss decreased (0.263251 --> 0.262247).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.3776862621307373
Epoch: 27, Steps: 61 | Train Loss: 0.1223086 Vali Loss: 0.2619385 Test Loss: 0.2949527
Validation loss decreased (0.262247 --> 0.261939).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.3017001152038574
Epoch: 28, Steps: 61 | Train Loss: 0.1201043 Vali Loss: 0.2605541 Test Loss: 0.2942180
Validation loss decreased (0.261939 --> 0.260554).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.3019726276397705
Epoch: 29, Steps: 61 | Train Loss: 0.1182750 Vali Loss: 0.2607859 Test Loss: 0.2935919
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.2615113258361816
Epoch: 30, Steps: 61 | Train Loss: 0.1163781 Vali Loss: 0.2582912 Test Loss: 0.2929689
Validation loss decreased (0.260554 --> 0.258291).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.302628993988037
Epoch: 31, Steps: 61 | Train Loss: 0.1149031 Vali Loss: 0.2569866 Test Loss: 0.2924199
Validation loss decreased (0.258291 --> 0.256987).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.2900512218475342
Epoch: 32, Steps: 61 | Train Loss: 0.1132820 Vali Loss: 0.2569686 Test Loss: 0.2918954
Validation loss decreased (0.256987 --> 0.256969).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.3515527248382568
Epoch: 33, Steps: 61 | Train Loss: 0.1118454 Vali Loss: 0.2570656 Test Loss: 0.2914262
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.2789726257324219
Epoch: 34, Steps: 61 | Train Loss: 0.1104294 Vali Loss: 0.2552506 Test Loss: 0.2909416
Validation loss decreased (0.256969 --> 0.255251).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.295318841934204
Epoch: 35, Steps: 61 | Train Loss: 0.1091210 Vali Loss: 0.2554572 Test Loss: 0.2905237
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.2054364681243896
Epoch: 36, Steps: 61 | Train Loss: 0.1078805 Vali Loss: 0.2535147 Test Loss: 0.2900923
Validation loss decreased (0.255251 --> 0.253515).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.3506371974945068
Epoch: 37, Steps: 61 | Train Loss: 0.1068413 Vali Loss: 0.2531667 Test Loss: 0.2897206
Validation loss decreased (0.253515 --> 0.253167).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.2373905181884766
Epoch: 38, Steps: 61 | Train Loss: 0.1055949 Vali Loss: 0.2531324 Test Loss: 0.2893988
Validation loss decreased (0.253167 --> 0.253132).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.3510422706604004
Epoch: 39, Steps: 61 | Train Loss: 0.1046834 Vali Loss: 0.2526722 Test Loss: 0.2890205
Validation loss decreased (0.253132 --> 0.252672).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.3195412158966064
Epoch: 40, Steps: 61 | Train Loss: 0.1039119 Vali Loss: 0.2509222 Test Loss: 0.2887225
Validation loss decreased (0.252672 --> 0.250922).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.3520801067352295
Epoch: 41, Steps: 61 | Train Loss: 0.1030161 Vali Loss: 0.2507026 Test Loss: 0.2884672
Validation loss decreased (0.250922 --> 0.250703).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.441608190536499
Epoch: 42, Steps: 61 | Train Loss: 0.1021606 Vali Loss: 0.2507867 Test Loss: 0.2881107
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.315990686416626
Epoch: 43, Steps: 61 | Train Loss: 0.1014908 Vali Loss: 0.2507947 Test Loss: 0.2879246
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.2681305408477783
Epoch: 44, Steps: 61 | Train Loss: 0.1005264 Vali Loss: 0.2494715 Test Loss: 0.2876747
Validation loss decreased (0.250703 --> 0.249472).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.348689079284668
Epoch: 45, Steps: 61 | Train Loss: 0.0998752 Vali Loss: 0.2496661 Test Loss: 0.2873904
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.2933294773101807
Epoch: 46, Steps: 61 | Train Loss: 0.0993419 Vali Loss: 0.2497578 Test Loss: 0.2871731
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.2815921306610107
Epoch: 47, Steps: 61 | Train Loss: 0.0985782 Vali Loss: 0.2478299 Test Loss: 0.2869732
Validation loss decreased (0.249472 --> 0.247830).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.3266346454620361
Epoch: 48, Steps: 61 | Train Loss: 0.0982384 Vali Loss: 0.2487088 Test Loss: 0.2867725
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.2307078838348389
Epoch: 49, Steps: 61 | Train Loss: 0.0974972 Vali Loss: 0.2485422 Test Loss: 0.2865855
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.2871341705322266
Epoch: 50, Steps: 61 | Train Loss: 0.0971009 Vali Loss: 0.2480103 Test Loss: 0.2863956
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.2558708190917969
Epoch: 51, Steps: 61 | Train Loss: 0.0965453 Vali Loss: 0.2483272 Test Loss: 0.2862032
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.299729347229004
Epoch: 52, Steps: 61 | Train Loss: 0.0961496 Vali Loss: 0.2476772 Test Loss: 0.2860684
Validation loss decreased (0.247830 --> 0.247677).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.2489309310913086
Epoch: 53, Steps: 61 | Train Loss: 0.0957231 Vali Loss: 0.2476419 Test Loss: 0.2859130
Validation loss decreased (0.247677 --> 0.247642).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.2493817806243896
Epoch: 54, Steps: 61 | Train Loss: 0.0952809 Vali Loss: 0.2471589 Test Loss: 0.2857625
Validation loss decreased (0.247642 --> 0.247159).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.2822303771972656
Epoch: 55, Steps: 61 | Train Loss: 0.0949298 Vali Loss: 0.2477125 Test Loss: 0.2856167
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.2870681285858154
Epoch: 56, Steps: 61 | Train Loss: 0.0945475 Vali Loss: 0.2468181 Test Loss: 0.2854921
Validation loss decreased (0.247159 --> 0.246818).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.315185785293579
Epoch: 57, Steps: 61 | Train Loss: 0.0941782 Vali Loss: 0.2476125 Test Loss: 0.2853461
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.2697672843933105
Epoch: 58, Steps: 61 | Train Loss: 0.0938358 Vali Loss: 0.2468741 Test Loss: 0.2852615
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.3092424869537354
Epoch: 59, Steps: 61 | Train Loss: 0.0935521 Vali Loss: 0.2459678 Test Loss: 0.2851193
Validation loss decreased (0.246818 --> 0.245968).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.2614598274230957
Epoch: 60, Steps: 61 | Train Loss: 0.0932531 Vali Loss: 0.2458579 Test Loss: 0.2850238
Validation loss decreased (0.245968 --> 0.245858).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.2578294277191162
Epoch: 61, Steps: 61 | Train Loss: 0.0929278 Vali Loss: 0.2472589 Test Loss: 0.2849354
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.2816150188446045
Epoch: 62, Steps: 61 | Train Loss: 0.0926371 Vali Loss: 0.2448559 Test Loss: 0.2848438
Validation loss decreased (0.245858 --> 0.244856).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.354196310043335
Epoch: 63, Steps: 61 | Train Loss: 0.0922354 Vali Loss: 0.2453202 Test Loss: 0.2847452
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.2197959423065186
Epoch: 64, Steps: 61 | Train Loss: 0.0921909 Vali Loss: 0.2451152 Test Loss: 0.2846647
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.281968593597412
Epoch: 65, Steps: 61 | Train Loss: 0.0918564 Vali Loss: 0.2459220 Test Loss: 0.2845936
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.3922367095947266
Epoch: 66, Steps: 61 | Train Loss: 0.0917142 Vali Loss: 0.2461289 Test Loss: 0.2845188
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.334444284439087
Epoch: 67, Steps: 61 | Train Loss: 0.0915290 Vali Loss: 0.2448887 Test Loss: 0.2844301
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.4799590110778809
Epoch: 68, Steps: 61 | Train Loss: 0.0912965 Vali Loss: 0.2454064 Test Loss: 0.2843678
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.3515429496765137
Epoch: 69, Steps: 61 | Train Loss: 0.0911705 Vali Loss: 0.2439697 Test Loss: 0.2842961
Validation loss decreased (0.244856 --> 0.243970).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.4113221168518066
Epoch: 70, Steps: 61 | Train Loss: 0.0907567 Vali Loss: 0.2438147 Test Loss: 0.2842499
Validation loss decreased (0.243970 --> 0.243815).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.3413193225860596
Epoch: 71, Steps: 61 | Train Loss: 0.0907742 Vali Loss: 0.2440047 Test Loss: 0.2841835
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.2534422874450684
Epoch: 72, Steps: 61 | Train Loss: 0.0906263 Vali Loss: 0.2436671 Test Loss: 0.2841228
Validation loss decreased (0.243815 --> 0.243667).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.3777165412902832
Epoch: 73, Steps: 61 | Train Loss: 0.0904725 Vali Loss: 0.2449222 Test Loss: 0.2840715
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.3309109210968018
Epoch: 74, Steps: 61 | Train Loss: 0.0903265 Vali Loss: 0.2446394 Test Loss: 0.2840125
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.3214457035064697
Epoch: 75, Steps: 61 | Train Loss: 0.0901446 Vali Loss: 0.2439573 Test Loss: 0.2839696
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.306955099105835
Epoch: 76, Steps: 61 | Train Loss: 0.0901170 Vali Loss: 0.2445296 Test Loss: 0.2839257
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.347640037536621
Epoch: 77, Steps: 61 | Train Loss: 0.0898820 Vali Loss: 0.2442896 Test Loss: 0.2838812
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.358229398727417
Epoch: 78, Steps: 61 | Train Loss: 0.0897860 Vali Loss: 0.2442074 Test Loss: 0.2838355
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.3278825283050537
Epoch: 79, Steps: 61 | Train Loss: 0.0897369 Vali Loss: 0.2442427 Test Loss: 0.2837942
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.2777748107910156
Epoch: 80, Steps: 61 | Train Loss: 0.0895973 Vali Loss: 0.2438163 Test Loss: 0.2837609
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.3478143215179443
Epoch: 81, Steps: 61 | Train Loss: 0.0895029 Vali Loss: 0.2428073 Test Loss: 0.2837261
Validation loss decreased (0.243667 --> 0.242807).  Saving model ...
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.3655543327331543
Epoch: 82, Steps: 61 | Train Loss: 0.0893344 Vali Loss: 0.2434554 Test Loss: 0.2836862
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.2542462348937988
Epoch: 83, Steps: 61 | Train Loss: 0.0893526 Vali Loss: 0.2433128 Test Loss: 0.2836567
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.2461576461791992
Epoch: 84, Steps: 61 | Train Loss: 0.0891723 Vali Loss: 0.2440468 Test Loss: 0.2836256
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.3355300426483154
Epoch: 85, Steps: 61 | Train Loss: 0.0891084 Vali Loss: 0.2433107 Test Loss: 0.2836015
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.3427882194519043
Epoch: 86, Steps: 61 | Train Loss: 0.0890174 Vali Loss: 0.2439324 Test Loss: 0.2835732
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.3267812728881836
Epoch: 87, Steps: 61 | Train Loss: 0.0887049 Vali Loss: 0.2428563 Test Loss: 0.2835387
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.2966632843017578
Epoch: 88, Steps: 61 | Train Loss: 0.0888767 Vali Loss: 0.2433782 Test Loss: 0.2835220
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.3607687950134277
Epoch: 89, Steps: 61 | Train Loss: 0.0887723 Vali Loss: 0.2425256 Test Loss: 0.2834945
Validation loss decreased (0.242807 --> 0.242526).  Saving model ...
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.3271420001983643
Epoch: 90, Steps: 61 | Train Loss: 0.0886576 Vali Loss: 0.2434365 Test Loss: 0.2834719
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.325026512145996
Epoch: 91, Steps: 61 | Train Loss: 0.0886467 Vali Loss: 0.2430209 Test Loss: 0.2834560
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.2968237400054932
Epoch: 92, Steps: 61 | Train Loss: 0.0886178 Vali Loss: 0.2433969 Test Loss: 0.2834270
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.2847371101379395
Epoch: 93, Steps: 61 | Train Loss: 0.0883935 Vali Loss: 0.2429223 Test Loss: 0.2834039
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.3851087093353271
Epoch: 94, Steps: 61 | Train Loss: 0.0884948 Vali Loss: 0.2425945 Test Loss: 0.2833901
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.3899729251861572
Epoch: 95, Steps: 61 | Train Loss: 0.0884555 Vali Loss: 0.2438259 Test Loss: 0.2833733
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.2501037120819092
Epoch: 96, Steps: 61 | Train Loss: 0.0882956 Vali Loss: 0.2433107 Test Loss: 0.2833545
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.367652177810669
Epoch: 97, Steps: 61 | Train Loss: 0.0884387 Vali Loss: 0.2430454 Test Loss: 0.2833345
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.3030290603637695
Epoch: 98, Steps: 61 | Train Loss: 0.0883147 Vali Loss: 0.2441494 Test Loss: 0.2833237
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.2257819175720215
Epoch: 99, Steps: 61 | Train Loss: 0.0882475 Vali Loss: 0.2420337 Test Loss: 0.2833093
Validation loss decreased (0.242526 --> 0.242034).  Saving model ...
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.2944667339324951
Epoch: 100, Steps: 61 | Train Loss: 0.0882533 Vali Loss: 0.2429595 Test Loss: 0.2832950
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1160680107021042e-06
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=196, out_features=222, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  38986752.0
params:  43734.0
Trainable parameters:  43734
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.2760026454925537
Epoch: 1, Steps: 61 | Train Loss: 0.4215329 Vali Loss: 0.2225111 Test Loss: 0.2736602
Validation loss decreased (inf --> 0.222511).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.3222393989562988
Epoch: 2, Steps: 61 | Train Loss: 0.4088922 Vali Loss: 0.2182532 Test Loss: 0.2731374
Validation loss decreased (0.222511 --> 0.218253).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.355600357055664
Epoch: 3, Steps: 61 | Train Loss: 0.4063061 Vali Loss: 0.2177228 Test Loss: 0.2731065
Validation loss decreased (0.218253 --> 0.217723).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.278076171875
Epoch: 4, Steps: 61 | Train Loss: 0.4049537 Vali Loss: 0.2158909 Test Loss: 0.2731205
Validation loss decreased (0.217723 --> 0.215891).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.3260304927825928
Epoch: 5, Steps: 61 | Train Loss: 0.4035229 Vali Loss: 0.2150308 Test Loss: 0.2725587
Validation loss decreased (0.215891 --> 0.215031).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.2823524475097656
Epoch: 6, Steps: 61 | Train Loss: 0.4025525 Vali Loss: 0.2149450 Test Loss: 0.2723267
Validation loss decreased (0.215031 --> 0.214945).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.3473176956176758
Epoch: 7, Steps: 61 | Train Loss: 0.4004847 Vali Loss: 0.2143074 Test Loss: 0.2723395
Validation loss decreased (0.214945 --> 0.214307).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.2552571296691895
Epoch: 8, Steps: 61 | Train Loss: 0.4001166 Vali Loss: 0.2125178 Test Loss: 0.2721957
Validation loss decreased (0.214307 --> 0.212518).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.2970807552337646
Epoch: 9, Steps: 61 | Train Loss: 0.4006543 Vali Loss: 0.2127173 Test Loss: 0.2719706
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.3563203811645508
Epoch: 10, Steps: 61 | Train Loss: 0.4005403 Vali Loss: 0.2139668 Test Loss: 0.2722659
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.3036205768585205
Epoch: 11, Steps: 61 | Train Loss: 0.4007678 Vali Loss: 0.2130000 Test Loss: 0.2716398
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.276564121246338
Epoch: 12, Steps: 61 | Train Loss: 0.3995855 Vali Loss: 0.2127915 Test Loss: 0.2718371
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.3359789848327637
Epoch: 13, Steps: 61 | Train Loss: 0.4001270 Vali Loss: 0.2122912 Test Loss: 0.2719561
Validation loss decreased (0.212518 --> 0.212291).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.3629686832427979
Epoch: 14, Steps: 61 | Train Loss: 0.3988928 Vali Loss: 0.2124338 Test Loss: 0.2717964
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.3591995239257812
Epoch: 15, Steps: 61 | Train Loss: 0.3984315 Vali Loss: 0.2120941 Test Loss: 0.2717780
Validation loss decreased (0.212291 --> 0.212094).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.2888753414154053
Epoch: 16, Steps: 61 | Train Loss: 0.3991340 Vali Loss: 0.2122432 Test Loss: 0.2715884
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.2958526611328125
Epoch: 17, Steps: 61 | Train Loss: 0.3983604 Vali Loss: 0.2106407 Test Loss: 0.2716686
Validation loss decreased (0.212094 --> 0.210641).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.3188471794128418
Epoch: 18, Steps: 61 | Train Loss: 0.3993347 Vali Loss: 0.2117783 Test Loss: 0.2717355
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.3044180870056152
Epoch: 19, Steps: 61 | Train Loss: 0.3978222 Vali Loss: 0.2124850 Test Loss: 0.2716110
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.2501471042633057
Epoch: 20, Steps: 61 | Train Loss: 0.3989331 Vali Loss: 0.2114700 Test Loss: 0.2714979
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.3654227256774902
Epoch: 21, Steps: 61 | Train Loss: 0.3984294 Vali Loss: 0.2116680 Test Loss: 0.2715900
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.4005889892578125
Epoch: 22, Steps: 61 | Train Loss: 0.3985364 Vali Loss: 0.2111815 Test Loss: 0.2715724
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.388138771057129
Epoch: 23, Steps: 61 | Train Loss: 0.3979950 Vali Loss: 0.2120261 Test Loss: 0.2715342
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.263321876525879
Epoch: 24, Steps: 61 | Train Loss: 0.3978692 Vali Loss: 0.2128045 Test Loss: 0.2714433
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.4571433067321777
Epoch: 25, Steps: 61 | Train Loss: 0.3981464 Vali Loss: 0.2120025 Test Loss: 0.2714755
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.402355432510376
Epoch: 26, Steps: 61 | Train Loss: 0.3976581 Vali Loss: 0.2114241 Test Loss: 0.2713747
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.3139188289642334
Epoch: 27, Steps: 61 | Train Loss: 0.3980991 Vali Loss: 0.2113479 Test Loss: 0.2713896
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.343994140625
Epoch: 28, Steps: 61 | Train Loss: 0.3979976 Vali Loss: 0.2113309 Test Loss: 0.2713495
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.3497426509857178
Epoch: 29, Steps: 61 | Train Loss: 0.3980139 Vali Loss: 0.2112864 Test Loss: 0.2715251
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.333749771118164
Epoch: 30, Steps: 61 | Train Loss: 0.3981948 Vali Loss: 0.2121741 Test Loss: 0.2714224
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.3231914043426514
Epoch: 31, Steps: 61 | Train Loss: 0.3980388 Vali Loss: 0.2119928 Test Loss: 0.2714228
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.3741540908813477
Epoch: 32, Steps: 61 | Train Loss: 0.3978915 Vali Loss: 0.2120978 Test Loss: 0.2714792
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.3524689674377441
Epoch: 33, Steps: 61 | Train Loss: 0.3965743 Vali Loss: 0.2115957 Test Loss: 0.2714490
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.5687925815582275
Epoch: 34, Steps: 61 | Train Loss: 0.3968463 Vali Loss: 0.2111224 Test Loss: 0.2713483
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.3544182777404785
Epoch: 35, Steps: 61 | Train Loss: 0.3971504 Vali Loss: 0.2123911 Test Loss: 0.2712958
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.4319329261779785
Epoch: 36, Steps: 61 | Train Loss: 0.3979005 Vali Loss: 0.2120482 Test Loss: 0.2713642
EarlyStopping counter: 19 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.358543872833252
Epoch: 37, Steps: 61 | Train Loss: 0.3976897 Vali Loss: 0.2118758 Test Loss: 0.2713370
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.27139967679977417, mae:0.33616507053375244, rse:0.41984206438064575, corr:[0.27387813 0.27664062 0.27553853 0.2754947  0.2748865  0.2735699
 0.2729824  0.27250057 0.27136797 0.27006072 0.26921585 0.26797423
 0.26619166 0.26474944 0.26400763 0.26349756 0.2629425  0.26283604
 0.2625186  0.26111633 0.25960052 0.2589695  0.25817683 0.25594708
 0.25338122 0.25193384 0.25081757 0.24898346 0.24735244 0.24641034
 0.24529706 0.24385019 0.242598   0.2414818  0.23982018 0.23842214
 0.23776574 0.23670071 0.23495106 0.23386732 0.23372072 0.23309527
 0.23208512 0.23161128 0.23112853 0.2297954  0.22865497 0.22794789
 0.226471   0.22426313 0.22283474 0.22158878 0.21991652 0.21796705
 0.21656515 0.21547177 0.21318784 0.21052286 0.2092153  0.20852984
 0.20757726 0.20697574 0.20724674 0.20748064 0.20680708 0.20664074
 0.20654047 0.20589304 0.20534179 0.20467345 0.20328693 0.20231843
 0.2021054  0.20142469 0.20000789 0.1985589  0.19841775 0.1983458
 0.19823119 0.19777332 0.19762465 0.19716583 0.19655347 0.19625263
 0.19556996 0.19574097 0.19684508 0.19701661 0.19533144 0.19524488
 0.19560023 0.1941249  0.19431333 0.19557035 0.19313017 0.19244432]
