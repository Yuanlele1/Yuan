Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=58, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_360_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_360_96_FITS_ETTh2_ftM_sl360_ll48_pl96_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8185
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=58, out_features=73, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3793664.0
params:  4307.0
Trainable parameters:  4307
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.1270904541015625
Epoch: 1, Steps: 63 | Train Loss: 0.6140190 Vali Loss: 0.2939864 Test Loss: 0.3616962
Validation loss decreased (inf --> 0.293986).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.725259780883789
Epoch: 2, Steps: 63 | Train Loss: 0.4992982 Vali Loss: 0.2589720 Test Loss: 0.3264448
Validation loss decreased (0.293986 --> 0.258972).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.0879359245300293
Epoch: 3, Steps: 63 | Train Loss: 0.4644284 Vali Loss: 0.2437842 Test Loss: 0.3122637
Validation loss decreased (0.258972 --> 0.243784).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.449310779571533
Epoch: 4, Steps: 63 | Train Loss: 0.4499831 Vali Loss: 0.2357520 Test Loss: 0.3042914
Validation loss decreased (0.243784 --> 0.235752).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.8954687118530273
Epoch: 5, Steps: 63 | Train Loss: 0.4397990 Vali Loss: 0.2330656 Test Loss: 0.2993807
Validation loss decreased (0.235752 --> 0.233066).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 4.419717073440552
Epoch: 6, Steps: 63 | Train Loss: 0.4335038 Vali Loss: 0.2300427 Test Loss: 0.2959083
Validation loss decreased (0.233066 --> 0.230043).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.8154633045196533
Epoch: 7, Steps: 63 | Train Loss: 0.4264305 Vali Loss: 0.2277302 Test Loss: 0.2931861
Validation loss decreased (0.230043 --> 0.227730).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.0238096714019775
Epoch: 8, Steps: 63 | Train Loss: 0.4252405 Vali Loss: 0.2262372 Test Loss: 0.2912399
Validation loss decreased (0.227730 --> 0.226237).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.8431060314178467
Epoch: 9, Steps: 63 | Train Loss: 0.4225683 Vali Loss: 0.2249669 Test Loss: 0.2897066
Validation loss decreased (0.226237 --> 0.224967).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.7970266342163086
Epoch: 10, Steps: 63 | Train Loss: 0.4199457 Vali Loss: 0.2241179 Test Loss: 0.2882869
Validation loss decreased (0.224967 --> 0.224118).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.90012264251709
Epoch: 11, Steps: 63 | Train Loss: 0.4203044 Vali Loss: 0.2232159 Test Loss: 0.2872602
Validation loss decreased (0.224118 --> 0.223216).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.8175089359283447
Epoch: 12, Steps: 63 | Train Loss: 0.4163357 Vali Loss: 0.2214355 Test Loss: 0.2865706
Validation loss decreased (0.223216 --> 0.221436).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.996732473373413
Epoch: 13, Steps: 63 | Train Loss: 0.4160260 Vali Loss: 0.2213605 Test Loss: 0.2856348
Validation loss decreased (0.221436 --> 0.221361).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.3983514308929443
Epoch: 14, Steps: 63 | Train Loss: 0.4151885 Vali Loss: 0.2215012 Test Loss: 0.2849162
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.330997943878174
Epoch: 15, Steps: 63 | Train Loss: 0.4132078 Vali Loss: 0.2208756 Test Loss: 0.2842355
Validation loss decreased (0.221361 --> 0.220876).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.965486526489258
Epoch: 16, Steps: 63 | Train Loss: 0.4135157 Vali Loss: 0.2201379 Test Loss: 0.2836654
Validation loss decreased (0.220876 --> 0.220138).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.454587459564209
Epoch: 17, Steps: 63 | Train Loss: 0.4108263 Vali Loss: 0.2191417 Test Loss: 0.2832735
Validation loss decreased (0.220138 --> 0.219142).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.9732813835144043
Epoch: 18, Steps: 63 | Train Loss: 0.4108776 Vali Loss: 0.2194581 Test Loss: 0.2827618
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.3404648303985596
Epoch: 19, Steps: 63 | Train Loss: 0.4098274 Vali Loss: 0.2193694 Test Loss: 0.2824810
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.6102547645568848
Epoch: 20, Steps: 63 | Train Loss: 0.4086404 Vali Loss: 0.2186746 Test Loss: 0.2821192
Validation loss decreased (0.219142 --> 0.218675).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.0559585094451904
Epoch: 21, Steps: 63 | Train Loss: 0.4083352 Vali Loss: 0.2183833 Test Loss: 0.2818029
Validation loss decreased (0.218675 --> 0.218383).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.4094977378845215
Epoch: 22, Steps: 63 | Train Loss: 0.4085965 Vali Loss: 0.2169501 Test Loss: 0.2815599
Validation loss decreased (0.218383 --> 0.216950).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.6303811073303223
Epoch: 23, Steps: 63 | Train Loss: 0.4079523 Vali Loss: 0.2183082 Test Loss: 0.2813579
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.659440040588379
Epoch: 24, Steps: 63 | Train Loss: 0.4047803 Vali Loss: 0.2169006 Test Loss: 0.2810938
Validation loss decreased (0.216950 --> 0.216901).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.894029140472412
Epoch: 25, Steps: 63 | Train Loss: 0.4082755 Vali Loss: 0.2173074 Test Loss: 0.2808760
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.724635601043701
Epoch: 26, Steps: 63 | Train Loss: 0.4088704 Vali Loss: 0.2165400 Test Loss: 0.2807123
Validation loss decreased (0.216901 --> 0.216540).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.2408223152160645
Epoch: 27, Steps: 63 | Train Loss: 0.4083885 Vali Loss: 0.2172572 Test Loss: 0.2804640
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.1068193912506104
Epoch: 28, Steps: 63 | Train Loss: 0.4086840 Vali Loss: 0.2171602 Test Loss: 0.2803149
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 3.3969228267669678
Epoch: 29, Steps: 63 | Train Loss: 0.4080360 Vali Loss: 0.2158014 Test Loss: 0.2802496
Validation loss decreased (0.216540 --> 0.215801).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 3.631044626235962
Epoch: 30, Steps: 63 | Train Loss: 0.4072658 Vali Loss: 0.2169950 Test Loss: 0.2801057
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.4630181789398193
Epoch: 31, Steps: 63 | Train Loss: 0.4062287 Vali Loss: 0.2171197 Test Loss: 0.2799499
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.3728983402252197
Epoch: 32, Steps: 63 | Train Loss: 0.4075330 Vali Loss: 0.2162835 Test Loss: 0.2798850
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.7498581409454346
Epoch: 33, Steps: 63 | Train Loss: 0.4061614 Vali Loss: 0.2157919 Test Loss: 0.2797123
Validation loss decreased (0.215801 --> 0.215792).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.5249104499816895
Epoch: 34, Steps: 63 | Train Loss: 0.4058657 Vali Loss: 0.2167577 Test Loss: 0.2796465
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.4543824195861816
Epoch: 35, Steps: 63 | Train Loss: 0.4043748 Vali Loss: 0.2166907 Test Loss: 0.2795918
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.491624116897583
Epoch: 36, Steps: 63 | Train Loss: 0.4077569 Vali Loss: 0.2167795 Test Loss: 0.2795134
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.6954386234283447
Epoch: 37, Steps: 63 | Train Loss: 0.4065427 Vali Loss: 0.2169017 Test Loss: 0.2794043
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.927438497543335
Epoch: 38, Steps: 63 | Train Loss: 0.4038619 Vali Loss: 0.2161426 Test Loss: 0.2794137
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.839521884918213
Epoch: 39, Steps: 63 | Train Loss: 0.4072241 Vali Loss: 0.2155357 Test Loss: 0.2792657
Validation loss decreased (0.215792 --> 0.215536).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.640577554702759
Epoch: 40, Steps: 63 | Train Loss: 0.4064185 Vali Loss: 0.2158145 Test Loss: 0.2792119
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.309605598449707
Epoch: 41, Steps: 63 | Train Loss: 0.4044061 Vali Loss: 0.2161511 Test Loss: 0.2791795
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.4468700885772705
Epoch: 42, Steps: 63 | Train Loss: 0.4037706 Vali Loss: 0.2154556 Test Loss: 0.2791761
Validation loss decreased (0.215536 --> 0.215456).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.201049327850342
Epoch: 43, Steps: 63 | Train Loss: 0.4065700 Vali Loss: 0.2161624 Test Loss: 0.2791319
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.270118474960327
Epoch: 44, Steps: 63 | Train Loss: 0.4030800 Vali Loss: 0.2154908 Test Loss: 0.2790540
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 3.5104472637176514
Epoch: 45, Steps: 63 | Train Loss: 0.4036138 Vali Loss: 0.2155403 Test Loss: 0.2790200
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 3.9314866065979004
Epoch: 46, Steps: 63 | Train Loss: 0.4033982 Vali Loss: 0.2149547 Test Loss: 0.2789805
Validation loss decreased (0.215456 --> 0.214955).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 3.4947571754455566
Epoch: 47, Steps: 63 | Train Loss: 0.4040411 Vali Loss: 0.2151152 Test Loss: 0.2789258
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 3.5753114223480225
Epoch: 48, Steps: 63 | Train Loss: 0.4045979 Vali Loss: 0.2162321 Test Loss: 0.2789133
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 3.4613640308380127
Epoch: 49, Steps: 63 | Train Loss: 0.4055380 Vali Loss: 0.2152269 Test Loss: 0.2788640
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.3367738723754883
Epoch: 50, Steps: 63 | Train Loss: 0.4047534 Vali Loss: 0.2153949 Test Loss: 0.2788179
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 3.73579740524292
Epoch: 51, Steps: 63 | Train Loss: 0.4026681 Vali Loss: 0.2150050 Test Loss: 0.2788010
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 3.124323844909668
Epoch: 52, Steps: 63 | Train Loss: 0.4054660 Vali Loss: 0.2161385 Test Loss: 0.2787869
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.7163147926330566
Epoch: 53, Steps: 63 | Train Loss: 0.4054727 Vali Loss: 0.2143950 Test Loss: 0.2787438
Validation loss decreased (0.214955 --> 0.214395).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.6037089824676514
Epoch: 54, Steps: 63 | Train Loss: 0.4046888 Vali Loss: 0.2146287 Test Loss: 0.2787046
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 3.1609513759613037
Epoch: 55, Steps: 63 | Train Loss: 0.4039170 Vali Loss: 0.2136696 Test Loss: 0.2786691
Validation loss decreased (0.214395 --> 0.213670).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.6024725437164307
Epoch: 56, Steps: 63 | Train Loss: 0.4037249 Vali Loss: 0.2153653 Test Loss: 0.2786825
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.63259220123291
Epoch: 57, Steps: 63 | Train Loss: 0.4037718 Vali Loss: 0.2148933 Test Loss: 0.2786418
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.6501352787017822
Epoch: 58, Steps: 63 | Train Loss: 0.4050981 Vali Loss: 0.2149028 Test Loss: 0.2786214
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.269465208053589
Epoch: 59, Steps: 63 | Train Loss: 0.4018734 Vali Loss: 0.2151908 Test Loss: 0.2786217
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.7652499675750732
Epoch: 60, Steps: 63 | Train Loss: 0.4049512 Vali Loss: 0.2145211 Test Loss: 0.2786030
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.585880756378174
Epoch: 61, Steps: 63 | Train Loss: 0.4050450 Vali Loss: 0.2159416 Test Loss: 0.2785617
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.84893798828125
Epoch: 62, Steps: 63 | Train Loss: 0.4032904 Vali Loss: 0.2148800 Test Loss: 0.2785610
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.7340104579925537
Epoch: 63, Steps: 63 | Train Loss: 0.4042822 Vali Loss: 0.2154990 Test Loss: 0.2785491
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.674950361251831
Epoch: 64, Steps: 63 | Train Loss: 0.4034659 Vali Loss: 0.2157937 Test Loss: 0.2785257
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 3.342752695083618
Epoch: 65, Steps: 63 | Train Loss: 0.4051423 Vali Loss: 0.2149067 Test Loss: 0.2785142
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.8282973766326904
Epoch: 66, Steps: 63 | Train Loss: 0.4031108 Vali Loss: 0.2153379 Test Loss: 0.2785062
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 3.3447399139404297
Epoch: 67, Steps: 63 | Train Loss: 0.4045994 Vali Loss: 0.2134273 Test Loss: 0.2784880
Validation loss decreased (0.213670 --> 0.213427).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 3.7986977100372314
Epoch: 68, Steps: 63 | Train Loss: 0.4029892 Vali Loss: 0.2148435 Test Loss: 0.2784697
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.8453969955444336
Epoch: 69, Steps: 63 | Train Loss: 0.4049817 Vali Loss: 0.2143401 Test Loss: 0.2784794
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 4.064692258834839
Epoch: 70, Steps: 63 | Train Loss: 0.4039499 Vali Loss: 0.2145838 Test Loss: 0.2784674
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 3.4394352436065674
Epoch: 71, Steps: 63 | Train Loss: 0.4039450 Vali Loss: 0.2148015 Test Loss: 0.2784594
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.995027542114258
Epoch: 72, Steps: 63 | Train Loss: 0.4022912 Vali Loss: 0.2156121 Test Loss: 0.2784392
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.3353564739227295
Epoch: 73, Steps: 63 | Train Loss: 0.4033058 Vali Loss: 0.2145156 Test Loss: 0.2784409
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.2270729541778564
Epoch: 74, Steps: 63 | Train Loss: 0.4037481 Vali Loss: 0.2148655 Test Loss: 0.2784372
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.635493040084839
Epoch: 75, Steps: 63 | Train Loss: 0.4048959 Vali Loss: 0.2151587 Test Loss: 0.2784281
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.4488120079040527
Epoch: 76, Steps: 63 | Train Loss: 0.4042468 Vali Loss: 0.2150467 Test Loss: 0.2784196
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.5307438373565674
Epoch: 77, Steps: 63 | Train Loss: 0.4042026 Vali Loss: 0.2151936 Test Loss: 0.2784061
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 3.07344388961792
Epoch: 78, Steps: 63 | Train Loss: 0.4029868 Vali Loss: 0.2149222 Test Loss: 0.2784011
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 4.462514638900757
Epoch: 79, Steps: 63 | Train Loss: 0.4023986 Vali Loss: 0.2151289 Test Loss: 0.2783943
EarlyStopping counter: 12 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.344569206237793
Epoch: 80, Steps: 63 | Train Loss: 0.4047359 Vali Loss: 0.2144846 Test Loss: 0.2783963
EarlyStopping counter: 13 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 3.293832540512085
Epoch: 81, Steps: 63 | Train Loss: 0.4036148 Vali Loss: 0.2155577 Test Loss: 0.2783836
EarlyStopping counter: 14 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 2.917675018310547
Epoch: 82, Steps: 63 | Train Loss: 0.4041433 Vali Loss: 0.2140760 Test Loss: 0.2783811
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 3.6188502311706543
Epoch: 83, Steps: 63 | Train Loss: 0.4039246 Vali Loss: 0.2148104 Test Loss: 0.2783742
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 3.6553518772125244
Epoch: 84, Steps: 63 | Train Loss: 0.4006322 Vali Loss: 0.2151449 Test Loss: 0.2783711
EarlyStopping counter: 17 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 3.2359836101531982
Epoch: 85, Steps: 63 | Train Loss: 0.4049506 Vali Loss: 0.2159494 Test Loss: 0.2783651
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 2.339639902114868
Epoch: 86, Steps: 63 | Train Loss: 0.4044054 Vali Loss: 0.2153562 Test Loss: 0.2783656
EarlyStopping counter: 19 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 2.230426788330078
Epoch: 87, Steps: 63 | Train Loss: 0.4047936 Vali Loss: 0.2138737 Test Loss: 0.2783640
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_360_96_FITS_ETTh2_ftM_sl360_ll48_pl96_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.27812790870666504, mae:0.3402443826198578, rse:0.4250143766403198, corr:[0.27182814 0.27604428 0.27611384 0.273798   0.27218947 0.2714358
 0.2708462  0.269716   0.26816317 0.2664792  0.26485306 0.26314223
 0.26170576 0.26078898 0.26029113 0.26003706 0.25947422 0.25853506
 0.25733334 0.25619486 0.25515935 0.25396174 0.25229084 0.24995595
 0.24748409 0.24549678 0.24425893 0.24326542 0.24201587 0.24037245
 0.23862234 0.23703647 0.2356761  0.23452632 0.23329116 0.23175216
 0.23009616 0.22879608 0.22826509 0.22801013 0.22758631 0.2268018
 0.22573297 0.22472742 0.22408691 0.2234521  0.22237147 0.22054355
 0.21829    0.21637374 0.21525966 0.21453007 0.21355063 0.21201673
 0.2099715  0.20786566 0.20637877 0.2051701  0.20414424 0.20339198
 0.2029677  0.20282345 0.20307568 0.20336139 0.2032175  0.20271103
 0.20200138 0.20135117 0.20109293 0.20100193 0.20074873 0.20007226
 0.19897328 0.19789657 0.19725583 0.19682662 0.19658466 0.19616972
 0.19536525 0.1943593  0.19418369 0.19429997 0.19435702 0.19403444
 0.19368877 0.19367813 0.19420107 0.19477138 0.19435231 0.19328523
 0.19194005 0.19095199 0.19128047 0.19150683 0.18944213 0.18306132]
