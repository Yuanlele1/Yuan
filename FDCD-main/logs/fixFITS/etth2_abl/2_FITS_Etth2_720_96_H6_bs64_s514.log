Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=514, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=196, out_features=222, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  38986752.0
params:  43734.0
Trainable parameters:  43734
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.6954998970031738
Epoch: 1, Steps: 61 | Train Loss: 0.5428793 Vali Loss: 0.3852412 Test Loss: 0.3796583
Validation loss decreased (inf --> 0.385241).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.5030009746551514
Epoch: 2, Steps: 61 | Train Loss: 0.4171182 Vali Loss: 0.3316941 Test Loss: 0.3419299
Validation loss decreased (0.385241 --> 0.331694).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.4467191696166992
Epoch: 3, Steps: 61 | Train Loss: 0.3557500 Vali Loss: 0.3157998 Test Loss: 0.3301316
Validation loss decreased (0.331694 --> 0.315800).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.4066741466522217
Epoch: 4, Steps: 61 | Train Loss: 0.3186468 Vali Loss: 0.3112313 Test Loss: 0.3255924
Validation loss decreased (0.315800 --> 0.311231).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.6493308544158936
Epoch: 5, Steps: 61 | Train Loss: 0.2923798 Vali Loss: 0.3074942 Test Loss: 0.3242962
Validation loss decreased (0.311231 --> 0.307494).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.474015474319458
Epoch: 6, Steps: 61 | Train Loss: 0.2714726 Vali Loss: 0.3053766 Test Loss: 0.3229914
Validation loss decreased (0.307494 --> 0.305377).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.8425085544586182
Epoch: 7, Steps: 61 | Train Loss: 0.2540770 Vali Loss: 0.3033192 Test Loss: 0.3217783
Validation loss decreased (0.305377 --> 0.303319).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.5698065757751465
Epoch: 8, Steps: 61 | Train Loss: 0.2391563 Vali Loss: 0.3013719 Test Loss: 0.3204421
Validation loss decreased (0.303319 --> 0.301372).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.9788577556610107
Epoch: 9, Steps: 61 | Train Loss: 0.2264438 Vali Loss: 0.2979063 Test Loss: 0.3193536
Validation loss decreased (0.301372 --> 0.297906).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.448774814605713
Epoch: 10, Steps: 61 | Train Loss: 0.2153356 Vali Loss: 0.2965961 Test Loss: 0.3179268
Validation loss decreased (0.297906 --> 0.296596).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.479830026626587
Epoch: 11, Steps: 61 | Train Loss: 0.2051759 Vali Loss: 0.2941502 Test Loss: 0.3162671
Validation loss decreased (0.296596 --> 0.294150).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.4818053245544434
Epoch: 12, Steps: 61 | Train Loss: 0.1959524 Vali Loss: 0.2905776 Test Loss: 0.3147722
Validation loss decreased (0.294150 --> 0.290578).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.4840149879455566
Epoch: 13, Steps: 61 | Train Loss: 0.1881810 Vali Loss: 0.2885785 Test Loss: 0.3130873
Validation loss decreased (0.290578 --> 0.288579).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.5596413612365723
Epoch: 14, Steps: 61 | Train Loss: 0.1807635 Vali Loss: 0.2869507 Test Loss: 0.3115133
Validation loss decreased (0.288579 --> 0.286951).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.3737471103668213
Epoch: 15, Steps: 61 | Train Loss: 0.1740519 Vali Loss: 0.2831053 Test Loss: 0.3102654
Validation loss decreased (0.286951 --> 0.283105).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.4632658958435059
Epoch: 16, Steps: 61 | Train Loss: 0.1681030 Vali Loss: 0.2820528 Test Loss: 0.3086488
Validation loss decreased (0.283105 --> 0.282053).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.1023404598236084
Epoch: 17, Steps: 61 | Train Loss: 0.1627344 Vali Loss: 0.2790422 Test Loss: 0.3073938
Validation loss decreased (0.282053 --> 0.279042).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.4190313816070557
Epoch: 18, Steps: 61 | Train Loss: 0.1577122 Vali Loss: 0.2789078 Test Loss: 0.3060117
Validation loss decreased (0.279042 --> 0.278908).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.4290320873260498
Epoch: 19, Steps: 61 | Train Loss: 0.1532212 Vali Loss: 0.2760497 Test Loss: 0.3047571
Validation loss decreased (0.278908 --> 0.276050).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.4005050659179688
Epoch: 20, Steps: 61 | Train Loss: 0.1491412 Vali Loss: 0.2740840 Test Loss: 0.3036757
Validation loss decreased (0.276050 --> 0.274084).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.588653564453125
Epoch: 21, Steps: 61 | Train Loss: 0.1452568 Vali Loss: 0.2731699 Test Loss: 0.3027087
Validation loss decreased (0.274084 --> 0.273170).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.4474821090698242
Epoch: 22, Steps: 61 | Train Loss: 0.1415801 Vali Loss: 0.2722440 Test Loss: 0.3015444
Validation loss decreased (0.273170 --> 0.272244).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.4843049049377441
Epoch: 23, Steps: 61 | Train Loss: 0.1385487 Vali Loss: 0.2692862 Test Loss: 0.3006496
Validation loss decreased (0.272244 --> 0.269286).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.4179112911224365
Epoch: 24, Steps: 61 | Train Loss: 0.1356482 Vali Loss: 0.2685272 Test Loss: 0.2997017
Validation loss decreased (0.269286 --> 0.268527).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.2735486030578613
Epoch: 25, Steps: 61 | Train Loss: 0.1328879 Vali Loss: 0.2674598 Test Loss: 0.2987977
Validation loss decreased (0.268527 --> 0.267460).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.3344619274139404
Epoch: 26, Steps: 61 | Train Loss: 0.1302154 Vali Loss: 0.2661083 Test Loss: 0.2980179
Validation loss decreased (0.267460 --> 0.266108).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.4208824634552002
Epoch: 27, Steps: 61 | Train Loss: 0.1278637 Vali Loss: 0.2652772 Test Loss: 0.2972193
Validation loss decreased (0.266108 --> 0.265277).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.475757360458374
Epoch: 28, Steps: 61 | Train Loss: 0.1256868 Vali Loss: 0.2644765 Test Loss: 0.2965921
Validation loss decreased (0.265277 --> 0.264477).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.41237473487854
Epoch: 29, Steps: 61 | Train Loss: 0.1237074 Vali Loss: 0.2634279 Test Loss: 0.2959628
Validation loss decreased (0.264477 --> 0.263428).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.5253806114196777
Epoch: 30, Steps: 61 | Train Loss: 0.1217755 Vali Loss: 0.2617617 Test Loss: 0.2952800
Validation loss decreased (0.263428 --> 0.261762).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.5587530136108398
Epoch: 31, Steps: 61 | Train Loss: 0.1200219 Vali Loss: 0.2615272 Test Loss: 0.2947088
Validation loss decreased (0.261762 --> 0.261527).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.7022149562835693
Epoch: 32, Steps: 61 | Train Loss: 0.1183724 Vali Loss: 0.2607940 Test Loss: 0.2941409
Validation loss decreased (0.261527 --> 0.260794).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.496140956878662
Epoch: 33, Steps: 61 | Train Loss: 0.1168525 Vali Loss: 0.2604597 Test Loss: 0.2936226
Validation loss decreased (0.260794 --> 0.260460).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.5446083545684814
Epoch: 34, Steps: 61 | Train Loss: 0.1153986 Vali Loss: 0.2590401 Test Loss: 0.2931092
Validation loss decreased (0.260460 --> 0.259040).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.57733154296875
Epoch: 35, Steps: 61 | Train Loss: 0.1139841 Vali Loss: 0.2582389 Test Loss: 0.2926925
Validation loss decreased (0.259040 --> 0.258239).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.5551025867462158
Epoch: 36, Steps: 61 | Train Loss: 0.1127255 Vali Loss: 0.2576127 Test Loss: 0.2922441
Validation loss decreased (0.258239 --> 0.257613).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.4536054134368896
Epoch: 37, Steps: 61 | Train Loss: 0.1115425 Vali Loss: 0.2574486 Test Loss: 0.2918562
Validation loss decreased (0.257613 --> 0.257449).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.4048378467559814
Epoch: 38, Steps: 61 | Train Loss: 0.1103880 Vali Loss: 0.2556249 Test Loss: 0.2914606
Validation loss decreased (0.257449 --> 0.255625).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.4237275123596191
Epoch: 39, Steps: 61 | Train Loss: 0.1093692 Vali Loss: 0.2557001 Test Loss: 0.2910572
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.3612174987792969
Epoch: 40, Steps: 61 | Train Loss: 0.1084155 Vali Loss: 0.2561984 Test Loss: 0.2907963
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.4149396419525146
Epoch: 41, Steps: 61 | Train Loss: 0.1075088 Vali Loss: 0.2550816 Test Loss: 0.2904371
Validation loss decreased (0.255625 --> 0.255082).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.6152763366699219
Epoch: 42, Steps: 61 | Train Loss: 0.1065157 Vali Loss: 0.2542070 Test Loss: 0.2901156
Validation loss decreased (0.255082 --> 0.254207).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.4247512817382812
Epoch: 43, Steps: 61 | Train Loss: 0.1058077 Vali Loss: 0.2535179 Test Loss: 0.2898531
Validation loss decreased (0.254207 --> 0.253518).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.5295779705047607
Epoch: 44, Steps: 61 | Train Loss: 0.1050484 Vali Loss: 0.2531545 Test Loss: 0.2895692
Validation loss decreased (0.253518 --> 0.253155).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.498131513595581
Epoch: 45, Steps: 61 | Train Loss: 0.1042814 Vali Loss: 0.2530316 Test Loss: 0.2892835
Validation loss decreased (0.253155 --> 0.253032).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.4372305870056152
Epoch: 46, Steps: 61 | Train Loss: 0.1036269 Vali Loss: 0.2518056 Test Loss: 0.2890660
Validation loss decreased (0.253032 --> 0.251806).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.4535644054412842
Epoch: 47, Steps: 61 | Train Loss: 0.1026679 Vali Loss: 0.2519343 Test Loss: 0.2888274
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.5191714763641357
Epoch: 48, Steps: 61 | Train Loss: 0.1023222 Vali Loss: 0.2512024 Test Loss: 0.2885891
Validation loss decreased (0.251806 --> 0.251202).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.7276926040649414
Epoch: 49, Steps: 61 | Train Loss: 0.1018057 Vali Loss: 0.2520378 Test Loss: 0.2883857
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.471750020980835
Epoch: 50, Steps: 61 | Train Loss: 0.1012335 Vali Loss: 0.2512153 Test Loss: 0.2882178
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.5886638164520264
Epoch: 51, Steps: 61 | Train Loss: 0.1005641 Vali Loss: 0.2513752 Test Loss: 0.2880151
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.4256842136383057
Epoch: 52, Steps: 61 | Train Loss: 0.1002457 Vali Loss: 0.2504114 Test Loss: 0.2878356
Validation loss decreased (0.251202 --> 0.250411).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.4219207763671875
Epoch: 53, Steps: 61 | Train Loss: 0.0995640 Vali Loss: 0.2504978 Test Loss: 0.2876608
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.421091079711914
Epoch: 54, Steps: 61 | Train Loss: 0.0993353 Vali Loss: 0.2503023 Test Loss: 0.2875047
Validation loss decreased (0.250411 --> 0.250302).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.388976812362671
Epoch: 55, Steps: 61 | Train Loss: 0.0989072 Vali Loss: 0.2498292 Test Loss: 0.2873723
Validation loss decreased (0.250302 --> 0.249829).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.7128801345825195
Epoch: 56, Steps: 61 | Train Loss: 0.0984943 Vali Loss: 0.2499491 Test Loss: 0.2872065
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.4197063446044922
Epoch: 57, Steps: 61 | Train Loss: 0.0981302 Vali Loss: 0.2495895 Test Loss: 0.2870729
Validation loss decreased (0.249829 --> 0.249590).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.4231486320495605
Epoch: 58, Steps: 61 | Train Loss: 0.0976928 Vali Loss: 0.2499383 Test Loss: 0.2869598
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.4109821319580078
Epoch: 59, Steps: 61 | Train Loss: 0.0972744 Vali Loss: 0.2492157 Test Loss: 0.2868063
Validation loss decreased (0.249590 --> 0.249216).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.4159553050994873
Epoch: 60, Steps: 61 | Train Loss: 0.0970009 Vali Loss: 0.2494751 Test Loss: 0.2867083
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.3930158615112305
Epoch: 61, Steps: 61 | Train Loss: 0.0964514 Vali Loss: 0.2482561 Test Loss: 0.2865935
Validation loss decreased (0.249216 --> 0.248256).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.316126823425293
Epoch: 62, Steps: 61 | Train Loss: 0.0965055 Vali Loss: 0.2495010 Test Loss: 0.2864905
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.289334774017334
Epoch: 63, Steps: 61 | Train Loss: 0.0962824 Vali Loss: 0.2480776 Test Loss: 0.2863930
Validation loss decreased (0.248256 --> 0.248078).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.375277042388916
Epoch: 64, Steps: 61 | Train Loss: 0.0959439 Vali Loss: 0.2494500 Test Loss: 0.2863023
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.3288254737854004
Epoch: 65, Steps: 61 | Train Loss: 0.0956688 Vali Loss: 0.2485822 Test Loss: 0.2861947
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.453050136566162
Epoch: 66, Steps: 61 | Train Loss: 0.0954981 Vali Loss: 0.2481263 Test Loss: 0.2861345
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.4305551052093506
Epoch: 67, Steps: 61 | Train Loss: 0.0951848 Vali Loss: 0.2470548 Test Loss: 0.2860570
Validation loss decreased (0.248078 --> 0.247055).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.4289188385009766
Epoch: 68, Steps: 61 | Train Loss: 0.0949934 Vali Loss: 0.2484849 Test Loss: 0.2859603
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.3974735736846924
Epoch: 69, Steps: 61 | Train Loss: 0.0946404 Vali Loss: 0.2470588 Test Loss: 0.2859010
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.463608741760254
Epoch: 70, Steps: 61 | Train Loss: 0.0946991 Vali Loss: 0.2464759 Test Loss: 0.2858223
Validation loss decreased (0.247055 --> 0.246476).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.4547820091247559
Epoch: 71, Steps: 61 | Train Loss: 0.0944977 Vali Loss: 0.2477533 Test Loss: 0.2857611
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.428804874420166
Epoch: 72, Steps: 61 | Train Loss: 0.0943302 Vali Loss: 0.2478553 Test Loss: 0.2856941
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.4127867221832275
Epoch: 73, Steps: 61 | Train Loss: 0.0941571 Vali Loss: 0.2471097 Test Loss: 0.2856322
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.3370068073272705
Epoch: 74, Steps: 61 | Train Loss: 0.0939561 Vali Loss: 0.2469854 Test Loss: 0.2855778
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.3966076374053955
Epoch: 75, Steps: 61 | Train Loss: 0.0937850 Vali Loss: 0.2476606 Test Loss: 0.2855261
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.359419822692871
Epoch: 76, Steps: 61 | Train Loss: 0.0936647 Vali Loss: 0.2471769 Test Loss: 0.2854749
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.3788790702819824
Epoch: 77, Steps: 61 | Train Loss: 0.0935501 Vali Loss: 0.2467401 Test Loss: 0.2854152
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.3212180137634277
Epoch: 78, Steps: 61 | Train Loss: 0.0934267 Vali Loss: 0.2467204 Test Loss: 0.2853678
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.4021580219268799
Epoch: 79, Steps: 61 | Train Loss: 0.0931565 Vali Loss: 0.2466554 Test Loss: 0.2853296
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.4085752964019775
Epoch: 80, Steps: 61 | Train Loss: 0.0931453 Vali Loss: 0.2465257 Test Loss: 0.2852865
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.3765814304351807
Epoch: 81, Steps: 61 | Train Loss: 0.0930249 Vali Loss: 0.2464157 Test Loss: 0.2852429
Validation loss decreased (0.246476 --> 0.246416).  Saving model ...
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.3774969577789307
Epoch: 82, Steps: 61 | Train Loss: 0.0930332 Vali Loss: 0.2472858 Test Loss: 0.2852114
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.4436817169189453
Epoch: 83, Steps: 61 | Train Loss: 0.0928800 Vali Loss: 0.2469894 Test Loss: 0.2851703
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.4266459941864014
Epoch: 84, Steps: 61 | Train Loss: 0.0927962 Vali Loss: 0.2456283 Test Loss: 0.2851403
Validation loss decreased (0.246416 --> 0.245628).  Saving model ...
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.06414532661438
Epoch: 85, Steps: 61 | Train Loss: 0.0926604 Vali Loss: 0.2475652 Test Loss: 0.2851034
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.4474730491638184
Epoch: 86, Steps: 61 | Train Loss: 0.0925988 Vali Loss: 0.2466362 Test Loss: 0.2850696
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.457615613937378
Epoch: 87, Steps: 61 | Train Loss: 0.0925718 Vali Loss: 0.2446890 Test Loss: 0.2850458
Validation loss decreased (0.245628 --> 0.244689).  Saving model ...
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.453629732131958
Epoch: 88, Steps: 61 | Train Loss: 0.0923384 Vali Loss: 0.2464396 Test Loss: 0.2850152
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.5492432117462158
Epoch: 89, Steps: 61 | Train Loss: 0.0924029 Vali Loss: 0.2465751 Test Loss: 0.2849861
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.3900859355926514
Epoch: 90, Steps: 61 | Train Loss: 0.0921879 Vali Loss: 0.2456253 Test Loss: 0.2849619
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.3864552974700928
Epoch: 91, Steps: 61 | Train Loss: 0.0922782 Vali Loss: 0.2476961 Test Loss: 0.2849404
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.2997632026672363
Epoch: 92, Steps: 61 | Train Loss: 0.0922454 Vali Loss: 0.2458876 Test Loss: 0.2849182
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.4157965183258057
Epoch: 93, Steps: 61 | Train Loss: 0.0921170 Vali Loss: 0.2457187 Test Loss: 0.2848996
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.509465217590332
Epoch: 94, Steps: 61 | Train Loss: 0.0920735 Vali Loss: 0.2463329 Test Loss: 0.2848756
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.3788635730743408
Epoch: 95, Steps: 61 | Train Loss: 0.0920488 Vali Loss: 0.2461986 Test Loss: 0.2848564
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.4489414691925049
Epoch: 96, Steps: 61 | Train Loss: 0.0919656 Vali Loss: 0.2465558 Test Loss: 0.2848371
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.6221222877502441
Epoch: 97, Steps: 61 | Train Loss: 0.0919332 Vali Loss: 0.2463510 Test Loss: 0.2848208
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.4966473579406738
Epoch: 98, Steps: 61 | Train Loss: 0.0918569 Vali Loss: 0.2455329 Test Loss: 0.2848058
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.5324044227600098
Epoch: 99, Steps: 61 | Train Loss: 0.0918059 Vali Loss: 0.2457774 Test Loss: 0.2847914
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.3763699531555176
Epoch: 100, Steps: 61 | Train Loss: 0.0916581 Vali Loss: 0.2451913 Test Loss: 0.2847691
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.1160680107021042e-06
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=196, out_features=222, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  38986752.0
params:  43734.0
Trainable parameters:  43734
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.444366216659546
Epoch: 1, Steps: 61 | Train Loss: 0.4229261 Vali Loss: 0.2250601 Test Loss: 0.2733713
Validation loss decreased (inf --> 0.225060).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.4363312721252441
Epoch: 2, Steps: 61 | Train Loss: 0.4100430 Vali Loss: 0.2193260 Test Loss: 0.2730984
Validation loss decreased (0.225060 --> 0.219326).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.4593536853790283
Epoch: 3, Steps: 61 | Train Loss: 0.4057450 Vali Loss: 0.2175166 Test Loss: 0.2731155
Validation loss decreased (0.219326 --> 0.217517).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.4247171878814697
Epoch: 4, Steps: 61 | Train Loss: 0.4051029 Vali Loss: 0.2160504 Test Loss: 0.2732173
Validation loss decreased (0.217517 --> 0.216050).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.3990843296051025
Epoch: 5, Steps: 61 | Train Loss: 0.4037419 Vali Loss: 0.2141598 Test Loss: 0.2728376
Validation loss decreased (0.216050 --> 0.214160).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.4444823265075684
Epoch: 6, Steps: 61 | Train Loss: 0.4032594 Vali Loss: 0.2147084 Test Loss: 0.2725084
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.3661532402038574
Epoch: 7, Steps: 61 | Train Loss: 0.4021602 Vali Loss: 0.2129773 Test Loss: 0.2726552
Validation loss decreased (0.214160 --> 0.212977).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.4950668811798096
Epoch: 8, Steps: 61 | Train Loss: 0.4015639 Vali Loss: 0.2140616 Test Loss: 0.2722528
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.428541660308838
Epoch: 9, Steps: 61 | Train Loss: 0.4014697 Vali Loss: 0.2118299 Test Loss: 0.2719379
Validation loss decreased (0.212977 --> 0.211830).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.3839080333709717
Epoch: 10, Steps: 61 | Train Loss: 0.4009582 Vali Loss: 0.2134527 Test Loss: 0.2723187
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.704810619354248
Epoch: 11, Steps: 61 | Train Loss: 0.4007775 Vali Loss: 0.2132782 Test Loss: 0.2720039
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.3878636360168457
Epoch: 12, Steps: 61 | Train Loss: 0.3995270 Vali Loss: 0.2140251 Test Loss: 0.2719786
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.418156623840332
Epoch: 13, Steps: 61 | Train Loss: 0.4001769 Vali Loss: 0.2131087 Test Loss: 0.2717641
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.3012216091156006
Epoch: 14, Steps: 61 | Train Loss: 0.4000970 Vali Loss: 0.2124564 Test Loss: 0.2718015
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.3401086330413818
Epoch: 15, Steps: 61 | Train Loss: 0.3997708 Vali Loss: 0.2126947 Test Loss: 0.2715552
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.345700740814209
Epoch: 16, Steps: 61 | Train Loss: 0.3995584 Vali Loss: 0.2130706 Test Loss: 0.2718327
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.433589220046997
Epoch: 17, Steps: 61 | Train Loss: 0.3993993 Vali Loss: 0.2131707 Test Loss: 0.2717329
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.4172301292419434
Epoch: 18, Steps: 61 | Train Loss: 0.3989575 Vali Loss: 0.2120483 Test Loss: 0.2715961
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.443932294845581
Epoch: 19, Steps: 61 | Train Loss: 0.3989571 Vali Loss: 0.2121723 Test Loss: 0.2716874
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.439681053161621
Epoch: 20, Steps: 61 | Train Loss: 0.3988376 Vali Loss: 0.2123844 Test Loss: 0.2714638
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.412553310394287
Epoch: 21, Steps: 61 | Train Loss: 0.3988128 Vali Loss: 0.2126956 Test Loss: 0.2716744
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.3616645336151123
Epoch: 22, Steps: 61 | Train Loss: 0.3977427 Vali Loss: 0.2115988 Test Loss: 0.2716119
Validation loss decreased (0.211830 --> 0.211599).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.4772493839263916
Epoch: 23, Steps: 61 | Train Loss: 0.3988607 Vali Loss: 0.2117274 Test Loss: 0.2714660
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.377978801727295
Epoch: 24, Steps: 61 | Train Loss: 0.3982980 Vali Loss: 0.2119340 Test Loss: 0.2713715
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.358635425567627
Epoch: 25, Steps: 61 | Train Loss: 0.3987415 Vali Loss: 0.2121601 Test Loss: 0.2714177
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.4607698917388916
Epoch: 26, Steps: 61 | Train Loss: 0.3985435 Vali Loss: 0.2124403 Test Loss: 0.2713082
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.394141435623169
Epoch: 27, Steps: 61 | Train Loss: 0.3980140 Vali Loss: 0.2111163 Test Loss: 0.2713109
Validation loss decreased (0.211599 --> 0.211116).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.3954215049743652
Epoch: 28, Steps: 61 | Train Loss: 0.3975499 Vali Loss: 0.2111282 Test Loss: 0.2713826
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.4406652450561523
Epoch: 29, Steps: 61 | Train Loss: 0.3980492 Vali Loss: 0.2117370 Test Loss: 0.2714123
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.378199577331543
Epoch: 30, Steps: 61 | Train Loss: 0.3971714 Vali Loss: 0.2110349 Test Loss: 0.2714307
Validation loss decreased (0.211116 --> 0.211035).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.3560400009155273
Epoch: 31, Steps: 61 | Train Loss: 0.3976824 Vali Loss: 0.2114954 Test Loss: 0.2713394
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.352827548980713
Epoch: 32, Steps: 61 | Train Loss: 0.3980463 Vali Loss: 0.2111726 Test Loss: 0.2714526
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.4027974605560303
Epoch: 33, Steps: 61 | Train Loss: 0.3978650 Vali Loss: 0.2114902 Test Loss: 0.2713479
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.4255411624908447
Epoch: 34, Steps: 61 | Train Loss: 0.3974171 Vali Loss: 0.2113730 Test Loss: 0.2713365
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.4236149787902832
Epoch: 35, Steps: 61 | Train Loss: 0.3972631 Vali Loss: 0.2116969 Test Loss: 0.2713766
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.6440391540527344
Epoch: 36, Steps: 61 | Train Loss: 0.3978409 Vali Loss: 0.2115970 Test Loss: 0.2714536
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.4446806907653809
Epoch: 37, Steps: 61 | Train Loss: 0.3973739 Vali Loss: 0.2120021 Test Loss: 0.2713192
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.3900949954986572
Epoch: 38, Steps: 61 | Train Loss: 0.3974778 Vali Loss: 0.2118718 Test Loss: 0.2713766
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.4466056823730469
Epoch: 39, Steps: 61 | Train Loss: 0.3962294 Vali Loss: 0.2115633 Test Loss: 0.2713287
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.37105131149292
Epoch: 40, Steps: 61 | Train Loss: 0.3962931 Vali Loss: 0.2115858 Test Loss: 0.2713600
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.4323925971984863
Epoch: 41, Steps: 61 | Train Loss: 0.3973032 Vali Loss: 0.2106655 Test Loss: 0.2713104
Validation loss decreased (0.211035 --> 0.210666).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.4550695419311523
Epoch: 42, Steps: 61 | Train Loss: 0.3975311 Vali Loss: 0.2116065 Test Loss: 0.2713175
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.3209288120269775
Epoch: 43, Steps: 61 | Train Loss: 0.3976059 Vali Loss: 0.2108155 Test Loss: 0.2713148
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.3233678340911865
Epoch: 44, Steps: 61 | Train Loss: 0.3965890 Vali Loss: 0.2120836 Test Loss: 0.2712881
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.3095402717590332
Epoch: 45, Steps: 61 | Train Loss: 0.3975423 Vali Loss: 0.2113833 Test Loss: 0.2712994
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.3799142837524414
Epoch: 46, Steps: 61 | Train Loss: 0.3968384 Vali Loss: 0.2101984 Test Loss: 0.2712319
Validation loss decreased (0.210666 --> 0.210198).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.3389360904693604
Epoch: 47, Steps: 61 | Train Loss: 0.3957849 Vali Loss: 0.2112671 Test Loss: 0.2712640
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.4494850635528564
Epoch: 48, Steps: 61 | Train Loss: 0.3971807 Vali Loss: 0.2115997 Test Loss: 0.2712350
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.4839515686035156
Epoch: 49, Steps: 61 | Train Loss: 0.3971910 Vali Loss: 0.2122422 Test Loss: 0.2711810
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.3776609897613525
Epoch: 50, Steps: 61 | Train Loss: 0.3974166 Vali Loss: 0.2116018 Test Loss: 0.2712692
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.4217679500579834
Epoch: 51, Steps: 61 | Train Loss: 0.3970717 Vali Loss: 0.2113580 Test Loss: 0.2712424
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.4512155055999756
Epoch: 52, Steps: 61 | Train Loss: 0.3971474 Vali Loss: 0.2112236 Test Loss: 0.2712402
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.375976324081421
Epoch: 53, Steps: 61 | Train Loss: 0.3972578 Vali Loss: 0.2119660 Test Loss: 0.2712439
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.3501472473144531
Epoch: 54, Steps: 61 | Train Loss: 0.3963835 Vali Loss: 0.2120612 Test Loss: 0.2712314
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.3454961776733398
Epoch: 55, Steps: 61 | Train Loss: 0.3967155 Vali Loss: 0.2108767 Test Loss: 0.2712330
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.4124629497528076
Epoch: 56, Steps: 61 | Train Loss: 0.3960636 Vali Loss: 0.2110713 Test Loss: 0.2712456
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.3001704216003418
Epoch: 57, Steps: 61 | Train Loss: 0.3971711 Vali Loss: 0.2119314 Test Loss: 0.2712651
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.3660786151885986
Epoch: 58, Steps: 61 | Train Loss: 0.3973304 Vali Loss: 0.2110931 Test Loss: 0.2712770
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.4408516883850098
Epoch: 59, Steps: 61 | Train Loss: 0.3966985 Vali Loss: 0.2118814 Test Loss: 0.2712383
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.3437960147857666
Epoch: 60, Steps: 61 | Train Loss: 0.3957393 Vali Loss: 0.2115206 Test Loss: 0.2712355
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.4356045722961426
Epoch: 61, Steps: 61 | Train Loss: 0.3966702 Vali Loss: 0.2110686 Test Loss: 0.2712625
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.347001552581787
Epoch: 62, Steps: 61 | Train Loss: 0.3972860 Vali Loss: 0.2108982 Test Loss: 0.2712543
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.3746569156646729
Epoch: 63, Steps: 61 | Train Loss: 0.3971308 Vali Loss: 0.2109708 Test Loss: 0.2712375
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.4476397037506104
Epoch: 64, Steps: 61 | Train Loss: 0.3960205 Vali Loss: 0.2105168 Test Loss: 0.2712435
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.4344043731689453
Epoch: 65, Steps: 61 | Train Loss: 0.3967025 Vali Loss: 0.2119165 Test Loss: 0.2712422
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.4037301540374756
Epoch: 66, Steps: 61 | Train Loss: 0.3968382 Vali Loss: 0.2121160 Test Loss: 0.2712520
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.2709610164165497, mae:0.33593717217445374, rse:0.4195026457309723, corr:[0.27403483 0.27605343 0.27476332 0.27500927 0.27440044 0.27297336
 0.2724159  0.27215144 0.27122974 0.2698907  0.26890284 0.26761708
 0.2659071  0.26453522 0.26385957 0.2635134  0.26296523 0.2626036
 0.2621224  0.26092002 0.25939637 0.25837907 0.25757787 0.25586087
 0.25348732 0.25156277 0.25022477 0.24880466 0.24747893 0.24639398
 0.24512455 0.24361484 0.2422452  0.24121298 0.23979402 0.2383498
 0.23751406 0.23673065 0.23556627 0.23451312 0.23408277 0.23359914
 0.23285095 0.23204269 0.2311063  0.2297975  0.2287645  0.2277489
 0.2259175  0.22358423 0.22193924 0.22060283 0.21961556 0.21848987
 0.21678573 0.2149146  0.21285482 0.2110792  0.20980981 0.20852965
 0.20753755 0.20736425 0.20773196 0.20768984 0.20681274 0.20659539
 0.20631093 0.20543721 0.20510131 0.20508581 0.20415425 0.20305406
 0.20261261 0.20205057 0.20078768 0.19921377 0.19876291 0.19838525
 0.19805333 0.19767682 0.19765706 0.19692993 0.19624746 0.19660874
 0.1963347  0.19587496 0.19650878 0.19708766 0.19541563 0.19478975
 0.1954716  0.19414945 0.19333737 0.19503127 0.19396894 0.19150788]
