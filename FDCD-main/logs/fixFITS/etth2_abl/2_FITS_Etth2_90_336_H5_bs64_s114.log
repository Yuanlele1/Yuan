Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=30, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_90_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_90_336_FITS_ETTh2_ftM_sl90_ll48_pl336_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8215
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=30, out_features=142, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3816960.0
params:  4402.0
Trainable parameters:  4402
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.662280321121216
Epoch: 1, Steps: 64 | Train Loss: 0.8366898 Vali Loss: 0.4927525 Test Loss: 0.5807554
Validation loss decreased (inf --> 0.492752).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.063384294509888
Epoch: 2, Steps: 64 | Train Loss: 0.7134420 Vali Loss: 0.4522337 Test Loss: 0.5261400
Validation loss decreased (0.492752 --> 0.452234).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.0306665897369385
Epoch: 3, Steps: 64 | Train Loss: 0.6472087 Vali Loss: 0.4254274 Test Loss: 0.4943594
Validation loss decreased (0.452234 --> 0.425427).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.843038558959961
Epoch: 4, Steps: 64 | Train Loss: 0.6072303 Vali Loss: 0.4102335 Test Loss: 0.4742911
Validation loss decreased (0.425427 --> 0.410233).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.683741569519043
Epoch: 5, Steps: 64 | Train Loss: 0.5836784 Vali Loss: 0.4021313 Test Loss: 0.4613549
Validation loss decreased (0.410233 --> 0.402131).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.7069075107574463
Epoch: 6, Steps: 64 | Train Loss: 0.5678487 Vali Loss: 0.3958178 Test Loss: 0.4527992
Validation loss decreased (0.402131 --> 0.395818).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.720470666885376
Epoch: 7, Steps: 64 | Train Loss: 0.5567234 Vali Loss: 0.3885125 Test Loss: 0.4468159
Validation loss decreased (0.395818 --> 0.388513).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.289443016052246
Epoch: 8, Steps: 64 | Train Loss: 0.5501472 Vali Loss: 0.3869453 Test Loss: 0.4426258
Validation loss decreased (0.388513 --> 0.386945).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.4400811195373535
Epoch: 9, Steps: 64 | Train Loss: 0.5439387 Vali Loss: 0.3836641 Test Loss: 0.4395185
Validation loss decreased (0.386945 --> 0.383664).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.8264546394348145
Epoch: 10, Steps: 64 | Train Loss: 0.5402857 Vali Loss: 0.3818517 Test Loss: 0.4372106
Validation loss decreased (0.383664 --> 0.381852).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.5696866512298584
Epoch: 11, Steps: 64 | Train Loss: 0.5373639 Vali Loss: 0.3780586 Test Loss: 0.4353767
Validation loss decreased (0.381852 --> 0.378059).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.4888577461242676
Epoch: 12, Steps: 64 | Train Loss: 0.5347142 Vali Loss: 0.3767367 Test Loss: 0.4339260
Validation loss decreased (0.378059 --> 0.376737).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.954317092895508
Epoch: 13, Steps: 64 | Train Loss: 0.5326642 Vali Loss: 0.3770165 Test Loss: 0.4328309
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.044093132019043
Epoch: 14, Steps: 64 | Train Loss: 0.5308218 Vali Loss: 0.3733799 Test Loss: 0.4318064
Validation loss decreased (0.376737 --> 0.373380).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.0377936363220215
Epoch: 15, Steps: 64 | Train Loss: 0.5298803 Vali Loss: 0.3725197 Test Loss: 0.4309939
Validation loss decreased (0.373380 --> 0.372520).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.9375250339508057
Epoch: 16, Steps: 64 | Train Loss: 0.5289911 Vali Loss: 0.3754252 Test Loss: 0.4302980
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.575329065322876
Epoch: 17, Steps: 64 | Train Loss: 0.5267955 Vali Loss: 0.3730887 Test Loss: 0.4297446
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.1399567127227783
Epoch: 18, Steps: 64 | Train Loss: 0.5253168 Vali Loss: 0.3740388 Test Loss: 0.4292022
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.492020606994629
Epoch: 19, Steps: 64 | Train Loss: 0.5256748 Vali Loss: 0.3738329 Test Loss: 0.4287591
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.694422721862793
Epoch: 20, Steps: 64 | Train Loss: 0.5260032 Vali Loss: 0.3735415 Test Loss: 0.4283112
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.5861623287200928
Epoch: 21, Steps: 64 | Train Loss: 0.5249595 Vali Loss: 0.3697311 Test Loss: 0.4279877
Validation loss decreased (0.372520 --> 0.369731).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 5.289244651794434
Epoch: 22, Steps: 64 | Train Loss: 0.5242951 Vali Loss: 0.3708435 Test Loss: 0.4276405
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.537612199783325
Epoch: 23, Steps: 64 | Train Loss: 0.5232796 Vali Loss: 0.3724508 Test Loss: 0.4273512
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.9890525341033936
Epoch: 24, Steps: 64 | Train Loss: 0.5223210 Vali Loss: 0.3700211 Test Loss: 0.4271089
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.6265830993652344
Epoch: 25, Steps: 64 | Train Loss: 0.5228398 Vali Loss: 0.3695015 Test Loss: 0.4268884
Validation loss decreased (0.369731 --> 0.369502).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 5.020543098449707
Epoch: 26, Steps: 64 | Train Loss: 0.5226475 Vali Loss: 0.3691373 Test Loss: 0.4266407
Validation loss decreased (0.369502 --> 0.369137).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.8745198249816895
Epoch: 27, Steps: 64 | Train Loss: 0.5225943 Vali Loss: 0.3669527 Test Loss: 0.4264562
Validation loss decreased (0.369137 --> 0.366953).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.6079299449920654
Epoch: 28, Steps: 64 | Train Loss: 0.5221753 Vali Loss: 0.3676072 Test Loss: 0.4262787
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.516357660293579
Epoch: 29, Steps: 64 | Train Loss: 0.5217179 Vali Loss: 0.3711952 Test Loss: 0.4260840
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.1917386054992676
Epoch: 30, Steps: 64 | Train Loss: 0.5213847 Vali Loss: 0.3694304 Test Loss: 0.4259674
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.611422300338745
Epoch: 31, Steps: 64 | Train Loss: 0.5204832 Vali Loss: 0.3710279 Test Loss: 0.4257899
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.915724277496338
Epoch: 32, Steps: 64 | Train Loss: 0.5202933 Vali Loss: 0.3687029 Test Loss: 0.4256794
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.149932861328125
Epoch: 33, Steps: 64 | Train Loss: 0.5209615 Vali Loss: 0.3664390 Test Loss: 0.4255680
Validation loss decreased (0.366953 --> 0.366439).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.2386627197265625
Epoch: 34, Steps: 64 | Train Loss: 0.5198197 Vali Loss: 0.3704418 Test Loss: 0.4254568
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.642889976501465
Epoch: 35, Steps: 64 | Train Loss: 0.5205632 Vali Loss: 0.3689150 Test Loss: 0.4253466
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 3.4273877143859863
Epoch: 36, Steps: 64 | Train Loss: 0.5202455 Vali Loss: 0.3705532 Test Loss: 0.4252496
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.9456276893615723
Epoch: 37, Steps: 64 | Train Loss: 0.5206404 Vali Loss: 0.3697887 Test Loss: 0.4251729
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 3.747223138809204
Epoch: 38, Steps: 64 | Train Loss: 0.5202289 Vali Loss: 0.3685647 Test Loss: 0.4250633
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 3.5954082012176514
Epoch: 39, Steps: 64 | Train Loss: 0.5203155 Vali Loss: 0.3668573 Test Loss: 0.4249803
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.7509021759033203
Epoch: 40, Steps: 64 | Train Loss: 0.5201076 Vali Loss: 0.3674216 Test Loss: 0.4249214
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 3.50062894821167
Epoch: 41, Steps: 64 | Train Loss: 0.5198178 Vali Loss: 0.3662496 Test Loss: 0.4248548
Validation loss decreased (0.366439 --> 0.366250).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.960367202758789
Epoch: 42, Steps: 64 | Train Loss: 0.5201792 Vali Loss: 0.3696292 Test Loss: 0.4247814
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.9304635524749756
Epoch: 43, Steps: 64 | Train Loss: 0.5191971 Vali Loss: 0.3652429 Test Loss: 0.4247253
Validation loss decreased (0.366250 --> 0.365243).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.891723394393921
Epoch: 44, Steps: 64 | Train Loss: 0.5196020 Vali Loss: 0.3681726 Test Loss: 0.4246591
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 3.0502467155456543
Epoch: 45, Steps: 64 | Train Loss: 0.5197798 Vali Loss: 0.3674627 Test Loss: 0.4246219
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.2151782512664795
Epoch: 46, Steps: 64 | Train Loss: 0.5176326 Vali Loss: 0.3682768 Test Loss: 0.4245740
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.700812578201294
Epoch: 47, Steps: 64 | Train Loss: 0.5185164 Vali Loss: 0.3668085 Test Loss: 0.4245171
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.546341896057129
Epoch: 48, Steps: 64 | Train Loss: 0.5185528 Vali Loss: 0.3675981 Test Loss: 0.4244649
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.232374906539917
Epoch: 49, Steps: 64 | Train Loss: 0.5185460 Vali Loss: 0.3652039 Test Loss: 0.4244353
Validation loss decreased (0.365243 --> 0.365204).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 3.2926018238067627
Epoch: 50, Steps: 64 | Train Loss: 0.5185331 Vali Loss: 0.3683582 Test Loss: 0.4243969
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.2223148345947266
Epoch: 51, Steps: 64 | Train Loss: 0.5192117 Vali Loss: 0.3702426 Test Loss: 0.4243606
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 3.221900701522827
Epoch: 52, Steps: 64 | Train Loss: 0.5187846 Vali Loss: 0.3670701 Test Loss: 0.4243259
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 3.180793046951294
Epoch: 53, Steps: 64 | Train Loss: 0.5189913 Vali Loss: 0.3668020 Test Loss: 0.4242918
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 3.0905184745788574
Epoch: 54, Steps: 64 | Train Loss: 0.5184475 Vali Loss: 0.3701853 Test Loss: 0.4242584
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.7789089679718018
Epoch: 55, Steps: 64 | Train Loss: 0.5192909 Vali Loss: 0.3684681 Test Loss: 0.4242323
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.715214967727661
Epoch: 56, Steps: 64 | Train Loss: 0.5186381 Vali Loss: 0.3668497 Test Loss: 0.4241994
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.812166690826416
Epoch: 57, Steps: 64 | Train Loss: 0.5191412 Vali Loss: 0.3678740 Test Loss: 0.4241766
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.647052526473999
Epoch: 58, Steps: 64 | Train Loss: 0.5192322 Vali Loss: 0.3667017 Test Loss: 0.4241505
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 3.1268820762634277
Epoch: 59, Steps: 64 | Train Loss: 0.5182202 Vali Loss: 0.3679388 Test Loss: 0.4241259
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 3.0331969261169434
Epoch: 60, Steps: 64 | Train Loss: 0.5186729 Vali Loss: 0.3690658 Test Loss: 0.4241044
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 4.517241716384888
Epoch: 61, Steps: 64 | Train Loss: 0.5185024 Vali Loss: 0.3673123 Test Loss: 0.4240913
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 5.218461275100708
Epoch: 62, Steps: 64 | Train Loss: 0.5185851 Vali Loss: 0.3679005 Test Loss: 0.4240679
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 3.87265682220459
Epoch: 63, Steps: 64 | Train Loss: 0.5182789 Vali Loss: 0.3668157 Test Loss: 0.4240467
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.648742914199829
Epoch: 64, Steps: 64 | Train Loss: 0.5187429 Vali Loss: 0.3664227 Test Loss: 0.4240321
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 3.487955093383789
Epoch: 65, Steps: 64 | Train Loss: 0.5189034 Vali Loss: 0.3680080 Test Loss: 0.4240175
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 4.803717613220215
Epoch: 66, Steps: 64 | Train Loss: 0.5183979 Vali Loss: 0.3665091 Test Loss: 0.4239951
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.8574252128601074
Epoch: 67, Steps: 64 | Train Loss: 0.5182514 Vali Loss: 0.3650659 Test Loss: 0.4239826
Validation loss decreased (0.365204 --> 0.365066).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 3.0636422634124756
Epoch: 68, Steps: 64 | Train Loss: 0.5186006 Vali Loss: 0.3657102 Test Loss: 0.4239711
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.3486874103546143
Epoch: 69, Steps: 64 | Train Loss: 0.5180638 Vali Loss: 0.3667454 Test Loss: 0.4239515
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.8043742179870605
Epoch: 70, Steps: 64 | Train Loss: 0.5180805 Vali Loss: 0.3683598 Test Loss: 0.4239408
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 3.231175422668457
Epoch: 71, Steps: 64 | Train Loss: 0.5188937 Vali Loss: 0.3659465 Test Loss: 0.4239283
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.5434587001800537
Epoch: 72, Steps: 64 | Train Loss: 0.5185776 Vali Loss: 0.3654790 Test Loss: 0.4239161
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.7783102989196777
Epoch: 73, Steps: 64 | Train Loss: 0.5187845 Vali Loss: 0.3686604 Test Loss: 0.4239064
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.8599581718444824
Epoch: 74, Steps: 64 | Train Loss: 0.5180940 Vali Loss: 0.3677354 Test Loss: 0.4238971
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 4.1633124351501465
Epoch: 75, Steps: 64 | Train Loss: 0.5184765 Vali Loss: 0.3648485 Test Loss: 0.4238834
Validation loss decreased (0.365066 --> 0.364849).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 3.014789581298828
Epoch: 76, Steps: 64 | Train Loss: 0.5179780 Vali Loss: 0.3629471 Test Loss: 0.4238764
Validation loss decreased (0.364849 --> 0.362947).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 4.040688991546631
Epoch: 77, Steps: 64 | Train Loss: 0.5181359 Vali Loss: 0.3671085 Test Loss: 0.4238684
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.2686641216278076
Epoch: 78, Steps: 64 | Train Loss: 0.5186988 Vali Loss: 0.3667562 Test Loss: 0.4238596
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.8567087650299072
Epoch: 79, Steps: 64 | Train Loss: 0.5176463 Vali Loss: 0.3673624 Test Loss: 0.4238495
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.381765127182007
Epoch: 80, Steps: 64 | Train Loss: 0.5175095 Vali Loss: 0.3660276 Test Loss: 0.4238444
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 3.286132574081421
Epoch: 81, Steps: 64 | Train Loss: 0.5186720 Vali Loss: 0.3670270 Test Loss: 0.4238366
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 3.9023261070251465
Epoch: 82, Steps: 64 | Train Loss: 0.5177184 Vali Loss: 0.3653187 Test Loss: 0.4238290
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.769118309020996
Epoch: 83, Steps: 64 | Train Loss: 0.5182536 Vali Loss: 0.3685874 Test Loss: 0.4238246
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.2236297130584717
Epoch: 84, Steps: 64 | Train Loss: 0.5177232 Vali Loss: 0.3662699 Test Loss: 0.4238164
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.858942747116089
Epoch: 85, Steps: 64 | Train Loss: 0.5182676 Vali Loss: 0.3674068 Test Loss: 0.4238095
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 2.5815021991729736
Epoch: 86, Steps: 64 | Train Loss: 0.5172068 Vali Loss: 0.3657540 Test Loss: 0.4238041
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 3.0394887924194336
Epoch: 87, Steps: 64 | Train Loss: 0.5178996 Vali Loss: 0.3651431 Test Loss: 0.4237983
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 3.192774772644043
Epoch: 88, Steps: 64 | Train Loss: 0.5183034 Vali Loss: 0.3685589 Test Loss: 0.4237958
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.850165367126465
Epoch: 89, Steps: 64 | Train Loss: 0.5185817 Vali Loss: 0.3632659 Test Loss: 0.4237905
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 4.765322208404541
Epoch: 90, Steps: 64 | Train Loss: 0.5174941 Vali Loss: 0.3634142 Test Loss: 0.4237858
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 3.6658856868743896
Epoch: 91, Steps: 64 | Train Loss: 0.5177380 Vali Loss: 0.3691472 Test Loss: 0.4237803
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 3.636798143386841
Epoch: 92, Steps: 64 | Train Loss: 0.5176515 Vali Loss: 0.3678551 Test Loss: 0.4237756
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 3.7491910457611084
Epoch: 93, Steps: 64 | Train Loss: 0.5182122 Vali Loss: 0.3688331 Test Loss: 0.4237738
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 3.300208330154419
Epoch: 94, Steps: 64 | Train Loss: 0.5177629 Vali Loss: 0.3666511 Test Loss: 0.4237693
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 3.4341962337493896
Epoch: 95, Steps: 64 | Train Loss: 0.5175461 Vali Loss: 0.3677593 Test Loss: 0.4237657
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 2.366135597229004
Epoch: 96, Steps: 64 | Train Loss: 0.5177492 Vali Loss: 0.3680507 Test Loss: 0.4237620
EarlyStopping counter: 20 out of 20
Early stopping
train 8215
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=30, out_features=142, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3816960.0
params:  4402.0
Trainable parameters:  4402
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 5.14246392250061
Epoch: 1, Steps: 64 | Train Loss: 0.6509536 Vali Loss: 0.3669407 Test Loss: 0.4231002
Validation loss decreased (inf --> 0.366941).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.466816186904907
Epoch: 2, Steps: 64 | Train Loss: 0.6516535 Vali Loss: 0.3676813 Test Loss: 0.4226945
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.000475
Epoch: 3 cost time: 5.215653419494629
Epoch: 3, Steps: 64 | Train Loss: 0.6503714 Vali Loss: 0.3676292 Test Loss: 0.4224266
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.6966934204101562
Epoch: 4, Steps: 64 | Train Loss: 0.6481920 Vali Loss: 0.3667581 Test Loss: 0.4220854
Validation loss decreased (0.366941 --> 0.366758).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.7213454246520996
Epoch: 5, Steps: 64 | Train Loss: 0.6493559 Vali Loss: 0.3630190 Test Loss: 0.4219863
Validation loss decreased (0.366758 --> 0.363019).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.702636241912842
Epoch: 6, Steps: 64 | Train Loss: 0.6487244 Vali Loss: 0.3652273 Test Loss: 0.4218452
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 5.239244222640991
Epoch: 7, Steps: 64 | Train Loss: 0.6491678 Vali Loss: 0.3655066 Test Loss: 0.4217069
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.8495850563049316
Epoch: 8, Steps: 64 | Train Loss: 0.6482138 Vali Loss: 0.3642258 Test Loss: 0.4215496
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.6969728469848633
Epoch: 9, Steps: 64 | Train Loss: 0.6479820 Vali Loss: 0.3637142 Test Loss: 0.4214498
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.6870133876800537
Epoch: 10, Steps: 64 | Train Loss: 0.6475041 Vali Loss: 0.3659712 Test Loss: 0.4214540
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 4.764612197875977
Epoch: 11, Steps: 64 | Train Loss: 0.6481993 Vali Loss: 0.3638502 Test Loss: 0.4213108
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.6730105876922607
Epoch: 12, Steps: 64 | Train Loss: 0.6479776 Vali Loss: 0.3621736 Test Loss: 0.4212674
Validation loss decreased (0.363019 --> 0.362174).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.1455442905426025
Epoch: 13, Steps: 64 | Train Loss: 0.6475540 Vali Loss: 0.3620789 Test Loss: 0.4212357
Validation loss decreased (0.362174 --> 0.362079).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.2489233016967773
Epoch: 14, Steps: 64 | Train Loss: 0.6471761 Vali Loss: 0.3641805 Test Loss: 0.4211563
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.4987518787384033
Epoch: 15, Steps: 64 | Train Loss: 0.6474826 Vali Loss: 0.3623058 Test Loss: 0.4211403
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.66383957862854
Epoch: 16, Steps: 64 | Train Loss: 0.6457961 Vali Loss: 0.3645540 Test Loss: 0.4211170
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.4318623542785645
Epoch: 17, Steps: 64 | Train Loss: 0.6471833 Vali Loss: 0.3613697 Test Loss: 0.4211192
Validation loss decreased (0.362079 --> 0.361370).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.7061574459075928
Epoch: 18, Steps: 64 | Train Loss: 0.6460219 Vali Loss: 0.3634935 Test Loss: 0.4210496
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.8978338241577148
Epoch: 19, Steps: 64 | Train Loss: 0.6467672 Vali Loss: 0.3610790 Test Loss: 0.4210743
Validation loss decreased (0.361370 --> 0.361079).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.7092175483703613
Epoch: 20, Steps: 64 | Train Loss: 0.6459381 Vali Loss: 0.3621140 Test Loss: 0.4210363
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.474520683288574
Epoch: 21, Steps: 64 | Train Loss: 0.6461338 Vali Loss: 0.3643731 Test Loss: 0.4209959
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.157158136367798
Epoch: 22, Steps: 64 | Train Loss: 0.6464947 Vali Loss: 0.3643156 Test Loss: 0.4209200
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.1487948894500732
Epoch: 23, Steps: 64 | Train Loss: 0.6455221 Vali Loss: 0.3633901 Test Loss: 0.4209517
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.9496345520019531
Epoch: 24, Steps: 64 | Train Loss: 0.6455913 Vali Loss: 0.3631594 Test Loss: 0.4209286
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.647017240524292
Epoch: 25, Steps: 64 | Train Loss: 0.6462574 Vali Loss: 0.3638465 Test Loss: 0.4209279
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.0400383472442627
Epoch: 26, Steps: 64 | Train Loss: 0.6459507 Vali Loss: 0.3649001 Test Loss: 0.4209200
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 3.604231834411621
Epoch: 27, Steps: 64 | Train Loss: 0.6447829 Vali Loss: 0.3609045 Test Loss: 0.4208928
Validation loss decreased (0.361079 --> 0.360905).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.035181999206543
Epoch: 28, Steps: 64 | Train Loss: 0.6458781 Vali Loss: 0.3602256 Test Loss: 0.4208761
Validation loss decreased (0.360905 --> 0.360226).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.2619216442108154
Epoch: 29, Steps: 64 | Train Loss: 0.6464465 Vali Loss: 0.3617760 Test Loss: 0.4209008
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.86759877204895
Epoch: 30, Steps: 64 | Train Loss: 0.6453178 Vali Loss: 0.3660137 Test Loss: 0.4208508
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.4899613857269287
Epoch: 31, Steps: 64 | Train Loss: 0.6458358 Vali Loss: 0.3624697 Test Loss: 0.4208404
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 3.7140793800354004
Epoch: 32, Steps: 64 | Train Loss: 0.6428396 Vali Loss: 0.3627173 Test Loss: 0.4208488
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.573613405227661
Epoch: 33, Steps: 64 | Train Loss: 0.6449615 Vali Loss: 0.3633196 Test Loss: 0.4208450
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.5517892837524414
Epoch: 34, Steps: 64 | Train Loss: 0.6462557 Vali Loss: 0.3617536 Test Loss: 0.4208182
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 3.0992350578308105
Epoch: 35, Steps: 64 | Train Loss: 0.6446674 Vali Loss: 0.3647616 Test Loss: 0.4208071
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.234998941421509
Epoch: 36, Steps: 64 | Train Loss: 0.6462165 Vali Loss: 0.3635058 Test Loss: 0.4207947
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 3.948369026184082
Epoch: 37, Steps: 64 | Train Loss: 0.6455543 Vali Loss: 0.3622483 Test Loss: 0.4207924
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.836303472518921
Epoch: 38, Steps: 64 | Train Loss: 0.6460184 Vali Loss: 0.3623508 Test Loss: 0.4208028
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 3.857593536376953
Epoch: 39, Steps: 64 | Train Loss: 0.6452922 Vali Loss: 0.3647316 Test Loss: 0.4207982
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 3.4113340377807617
Epoch: 40, Steps: 64 | Train Loss: 0.6455172 Vali Loss: 0.3609773 Test Loss: 0.4207981
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 4.168395280838013
Epoch: 41, Steps: 64 | Train Loss: 0.6443294 Vali Loss: 0.3631141 Test Loss: 0.4207893
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.718752861022949
Epoch: 42, Steps: 64 | Train Loss: 0.6445327 Vali Loss: 0.3596480 Test Loss: 0.4207809
Validation loss decreased (0.360226 --> 0.359648).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 4.217646837234497
Epoch: 43, Steps: 64 | Train Loss: 0.6437947 Vali Loss: 0.3602125 Test Loss: 0.4207772
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.782841920852661
Epoch: 44, Steps: 64 | Train Loss: 0.6450285 Vali Loss: 0.3631931 Test Loss: 0.4207813
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 4.167650461196899
Epoch: 45, Steps: 64 | Train Loss: 0.6446754 Vali Loss: 0.3610724 Test Loss: 0.4207748
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 4.092480659484863
Epoch: 46, Steps: 64 | Train Loss: 0.6452120 Vali Loss: 0.3597046 Test Loss: 0.4207765
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 3.5459606647491455
Epoch: 47, Steps: 64 | Train Loss: 0.6436960 Vali Loss: 0.3591795 Test Loss: 0.4207627
Validation loss decreased (0.359648 --> 0.359179).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 3.7121899127960205
Epoch: 48, Steps: 64 | Train Loss: 0.6455554 Vali Loss: 0.3646995 Test Loss: 0.4207535
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 4.1324076652526855
Epoch: 49, Steps: 64 | Train Loss: 0.6455971 Vali Loss: 0.3636599 Test Loss: 0.4207653
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 4.349181890487671
Epoch: 50, Steps: 64 | Train Loss: 0.6461099 Vali Loss: 0.3638206 Test Loss: 0.4207442
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.469881772994995
Epoch: 51, Steps: 64 | Train Loss: 0.6447981 Vali Loss: 0.3618195 Test Loss: 0.4207445
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.696754217147827
Epoch: 52, Steps: 64 | Train Loss: 0.6456214 Vali Loss: 0.3598210 Test Loss: 0.4207557
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.539379835128784
Epoch: 53, Steps: 64 | Train Loss: 0.6446692 Vali Loss: 0.3622824 Test Loss: 0.4207412
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 3.064436912536621
Epoch: 54, Steps: 64 | Train Loss: 0.6451628 Vali Loss: 0.3607945 Test Loss: 0.4207425
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.802459955215454
Epoch: 55, Steps: 64 | Train Loss: 0.6451544 Vali Loss: 0.3615175 Test Loss: 0.4207393
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.4932241439819336
Epoch: 56, Steps: 64 | Train Loss: 0.6446906 Vali Loss: 0.3597941 Test Loss: 0.4207347
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 3.040449857711792
Epoch: 57, Steps: 64 | Train Loss: 0.6440064 Vali Loss: 0.3636745 Test Loss: 0.4207448
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.858009099960327
Epoch: 58, Steps: 64 | Train Loss: 0.6456940 Vali Loss: 0.3588668 Test Loss: 0.4207343
Validation loss decreased (0.359179 --> 0.358867).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 3.145888090133667
Epoch: 59, Steps: 64 | Train Loss: 0.6448827 Vali Loss: 0.3623160 Test Loss: 0.4207396
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.281768798828125
Epoch: 60, Steps: 64 | Train Loss: 0.6444809 Vali Loss: 0.3624548 Test Loss: 0.4207346
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 3.117304563522339
Epoch: 61, Steps: 64 | Train Loss: 0.6442413 Vali Loss: 0.3596269 Test Loss: 0.4207314
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 3.2202870845794678
Epoch: 62, Steps: 64 | Train Loss: 0.6449559 Vali Loss: 0.3632180 Test Loss: 0.4207315
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.9559762477874756
Epoch: 63, Steps: 64 | Train Loss: 0.6451028 Vali Loss: 0.3635833 Test Loss: 0.4207271
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.513456106185913
Epoch: 64, Steps: 64 | Train Loss: 0.6458241 Vali Loss: 0.3615691 Test Loss: 0.4207241
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.357599973678589
Epoch: 65, Steps: 64 | Train Loss: 0.6444679 Vali Loss: 0.3634687 Test Loss: 0.4207244
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.9873321056365967
Epoch: 66, Steps: 64 | Train Loss: 0.6446479 Vali Loss: 0.3603035 Test Loss: 0.4207219
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.408738851547241
Epoch: 67, Steps: 64 | Train Loss: 0.6442348 Vali Loss: 0.3602631 Test Loss: 0.4207262
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.1817357540130615
Epoch: 68, Steps: 64 | Train Loss: 0.6456747 Vali Loss: 0.3600090 Test Loss: 0.4207219
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 3.93591570854187
Epoch: 69, Steps: 64 | Train Loss: 0.6452904 Vali Loss: 0.3574741 Test Loss: 0.4207265
Validation loss decreased (0.358867 --> 0.357474).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 3.1689751148223877
Epoch: 70, Steps: 64 | Train Loss: 0.6451458 Vali Loss: 0.3616388 Test Loss: 0.4207224
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.9228954315185547
Epoch: 71, Steps: 64 | Train Loss: 0.6454322 Vali Loss: 0.3618335 Test Loss: 0.4207218
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 3.2593860626220703
Epoch: 72, Steps: 64 | Train Loss: 0.6449116 Vali Loss: 0.3632809 Test Loss: 0.4207191
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 3.7323970794677734
Epoch: 73, Steps: 64 | Train Loss: 0.6451030 Vali Loss: 0.3605762 Test Loss: 0.4207204
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 3.686923027038574
Epoch: 74, Steps: 64 | Train Loss: 0.6442818 Vali Loss: 0.3606671 Test Loss: 0.4207174
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 4.259588956832886
Epoch: 75, Steps: 64 | Train Loss: 0.6447274 Vali Loss: 0.3639896 Test Loss: 0.4207171
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.7287943363189697
Epoch: 76, Steps: 64 | Train Loss: 0.6442965 Vali Loss: 0.3579271 Test Loss: 0.4207181
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.7639174461364746
Epoch: 77, Steps: 64 | Train Loss: 0.6440463 Vali Loss: 0.3616382 Test Loss: 0.4207200
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 3.532855272293091
Epoch: 78, Steps: 64 | Train Loss: 0.6450564 Vali Loss: 0.3629514 Test Loss: 0.4207214
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.3705573081970215
Epoch: 79, Steps: 64 | Train Loss: 0.6455911 Vali Loss: 0.3594532 Test Loss: 0.4207169
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.4584217071533203
Epoch: 80, Steps: 64 | Train Loss: 0.6440154 Vali Loss: 0.3627017 Test Loss: 0.4207160
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.988643169403076
Epoch: 81, Steps: 64 | Train Loss: 0.6440681 Vali Loss: 0.3631405 Test Loss: 0.4207161
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 3.9996519088745117
Epoch: 82, Steps: 64 | Train Loss: 0.6454559 Vali Loss: 0.3591680 Test Loss: 0.4207145
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.9640278816223145
Epoch: 83, Steps: 64 | Train Loss: 0.6445696 Vali Loss: 0.3644527 Test Loss: 0.4207146
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.950711727142334
Epoch: 84, Steps: 64 | Train Loss: 0.6455508 Vali Loss: 0.3619520 Test Loss: 0.4207132
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 4.219708204269409
Epoch: 85, Steps: 64 | Train Loss: 0.6453977 Vali Loss: 0.3624700 Test Loss: 0.4207152
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 3.9599192142486572
Epoch: 86, Steps: 64 | Train Loss: 0.6448465 Vali Loss: 0.3593067 Test Loss: 0.4207121
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 3.3650729656219482
Epoch: 87, Steps: 64 | Train Loss: 0.6446408 Vali Loss: 0.3606872 Test Loss: 0.4207138
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 3.8845601081848145
Epoch: 88, Steps: 64 | Train Loss: 0.6437773 Vali Loss: 0.3627757 Test Loss: 0.4207123
EarlyStopping counter: 19 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.3151888847351074
Epoch: 89, Steps: 64 | Train Loss: 0.6453215 Vali Loss: 0.3586474 Test Loss: 0.4207132
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_90_336_FITS_ETTh2_ftM_sl90_ll48_pl336_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.41600924730300903, mae:0.42484936118125916, rse:0.5156927704811096, corr:[0.26436514 0.26513654 0.26361886 0.26381588 0.26141483 0.26042476
 0.2597133  0.25806016 0.25743577 0.25624797 0.25503185 0.25388306
 0.25205672 0.25059575 0.2498019  0.24892658 0.24826977 0.24787658
 0.2470001  0.24594253 0.24511398 0.2440571  0.24307707 0.24148342
 0.23853897 0.23634669 0.23441622 0.23317902 0.23210555 0.23094516
 0.2302533  0.22920842 0.22791794 0.22660169 0.22592977 0.22487985
 0.22348306 0.22258438 0.22156191 0.22055484 0.21995007 0.21935777
 0.21887456 0.21812788 0.2171683  0.21606106 0.2151355  0.21310838
 0.20943111 0.20661198 0.20391798 0.2018219  0.20014723 0.1982268
 0.19671123 0.19443388 0.19314481 0.19153102 0.19036773 0.18922208
 0.18798879 0.18745324 0.18717891 0.18716419 0.186758   0.18621677
 0.18570119 0.1847793  0.18411174 0.18369778 0.18280874 0.18124829
 0.17844714 0.17678042 0.17529592 0.17406438 0.17302229 0.1726955
 0.17288998 0.17174631 0.17121893 0.17084156 0.17045411 0.16995068
 0.16924636 0.16885808 0.16891009 0.16899619 0.16838047 0.16796339
 0.16789104 0.16704771 0.16672932 0.16683382 0.16638666 0.16528322
 0.16329728 0.16141742 0.15960301 0.15846923 0.15741129 0.1566108
 0.15702681 0.15650694 0.15644246 0.15621161 0.15613493 0.15592591
 0.15540005 0.15486029 0.15401377 0.15381391 0.15336595 0.152723
 0.15256402 0.15179619 0.15103805 0.15035288 0.14884776 0.14654063
 0.14382651 0.14175542 0.13972247 0.13877578 0.13760625 0.13652
 0.13630942 0.13567302 0.13515216 0.13452125 0.13421254 0.13358293
 0.13278928 0.13216889 0.13169257 0.13140394 0.13088557 0.13029936
 0.12991834 0.12911779 0.12857713 0.1281981  0.12703036 0.12470321
 0.12122047 0.11865105 0.1163493  0.11487144 0.11350714 0.11249048
 0.11244085 0.11162381 0.11117857 0.11080892 0.11072779 0.11023615
 0.10951573 0.1092431  0.10900886 0.10910646 0.10896429 0.10862429
 0.10855611 0.10810913 0.1079274  0.1079817  0.1076737  0.10588896
 0.10278604 0.10095472 0.09931251 0.09833921 0.09745947 0.09683627
 0.09732825 0.09701945 0.09687636 0.0966446  0.09672758 0.09631639
 0.09579091 0.09569825 0.09556971 0.09583886 0.09578255 0.09581346
 0.09621322 0.09628456 0.09644629 0.09699958 0.09728192 0.09673912
 0.09505995 0.09431662 0.09355675 0.09316315 0.09319694 0.09325884
 0.09432471 0.09492041 0.09534523 0.09531839 0.09570915 0.09556413
 0.09491139 0.09469384 0.09443206 0.09429178 0.09416665 0.09434633
 0.09452491 0.09454613 0.09465522 0.0946641  0.09453986 0.09325589
 0.09088088 0.08917858 0.08739679 0.08647466 0.08600269 0.08613329
 0.08722884 0.0883192  0.08904339 0.08893558 0.08893678 0.08843973
 0.0876546  0.08711318 0.08686049 0.086892   0.08713046 0.08753189
 0.08795061 0.08839444 0.0888596  0.0891696  0.08893599 0.08798472
 0.08582865 0.08433105 0.08287736 0.08236575 0.08245274 0.08303115
 0.08460297 0.08551073 0.08649752 0.08681714 0.08712045 0.08724333
 0.08694779 0.08735478 0.08774694 0.08849645 0.089072   0.08991097
 0.09035768 0.09059867 0.0909317  0.09145039 0.09166482 0.09116381
 0.08991514 0.08938464 0.08908166 0.08926743 0.08956613 0.09037924
 0.09201775 0.09298362 0.09356888 0.09358792 0.09398256 0.09373477
 0.09313493 0.09283165 0.09312163 0.09331773 0.09334768 0.09350818
 0.09385095 0.09392646 0.09412486 0.09446021 0.09473253 0.09461264
 0.0934726  0.09266113 0.09185811 0.09139368 0.09131772 0.091258
 0.09152808 0.09163579 0.09231116 0.0924194  0.09285472 0.09307495
 0.0924935  0.09246201 0.09301582 0.09365076 0.09400614 0.09480096
 0.09554636 0.09597211 0.0969055  0.09731491 0.09768645 0.09746992
 0.09562881 0.09491377 0.09445307 0.09441703 0.09442459 0.09466325
 0.09554258 0.09647749 0.097697   0.09757949 0.09800303 0.09854138
 0.09805339 0.09766068 0.09789477 0.09777938 0.09786603 0.09839506
 0.09830187 0.09806425 0.09875945 0.09859289 0.0990804  0.09929549]
