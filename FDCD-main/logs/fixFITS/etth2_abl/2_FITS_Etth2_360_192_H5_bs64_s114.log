Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_360_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_360_192_FITS_ETTh2_ftM_sl360_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8089
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=90, out_features=138, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  11128320.0
params:  12558.0
Trainable parameters:  12558
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 6.969226837158203
Epoch: 1, Steps: 63 | Train Loss: 0.5656573 Vali Loss: 0.4230981 Test Loss: 0.4794429
Validation loss decreased (inf --> 0.423098).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.261324882507324
Epoch: 2, Steps: 63 | Train Loss: 0.4505997 Vali Loss: 0.3821044 Test Loss: 0.4409392
Validation loss decreased (0.423098 --> 0.382104).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.5239903926849365
Epoch: 3, Steps: 63 | Train Loss: 0.3861247 Vali Loss: 0.3590746 Test Loss: 0.4222533
Validation loss decreased (0.382104 --> 0.359075).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 4.2539708614349365
Epoch: 4, Steps: 63 | Train Loss: 0.3492498 Vali Loss: 0.3456808 Test Loss: 0.4123068
Validation loss decreased (0.359075 --> 0.345681).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.8944039344787598
Epoch: 5, Steps: 63 | Train Loss: 0.3248575 Vali Loss: 0.3364682 Test Loss: 0.4062918
Validation loss decreased (0.345681 --> 0.336468).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.772660255432129
Epoch: 6, Steps: 63 | Train Loss: 0.3066574 Vali Loss: 0.3300548 Test Loss: 0.4023689
Validation loss decreased (0.336468 --> 0.330055).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.5895278453826904
Epoch: 7, Steps: 63 | Train Loss: 0.2923790 Vali Loss: 0.3250882 Test Loss: 0.3992728
Validation loss decreased (0.330055 --> 0.325088).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.4504482746124268
Epoch: 8, Steps: 63 | Train Loss: 0.2812384 Vali Loss: 0.3211010 Test Loss: 0.3967296
Validation loss decreased (0.325088 --> 0.321101).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.3498902320861816
Epoch: 9, Steps: 63 | Train Loss: 0.2721137 Vali Loss: 0.3176042 Test Loss: 0.3946464
Validation loss decreased (0.321101 --> 0.317604).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.6655046939849854
Epoch: 10, Steps: 63 | Train Loss: 0.2639525 Vali Loss: 0.3150216 Test Loss: 0.3927712
Validation loss decreased (0.317604 --> 0.315022).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.4681804180145264
Epoch: 11, Steps: 63 | Train Loss: 0.2577048 Vali Loss: 0.3126012 Test Loss: 0.3910004
Validation loss decreased (0.315022 --> 0.312601).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 4.048514127731323
Epoch: 12, Steps: 63 | Train Loss: 0.2518339 Vali Loss: 0.3105303 Test Loss: 0.3893854
Validation loss decreased (0.312601 --> 0.310530).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.2870161533355713
Epoch: 13, Steps: 63 | Train Loss: 0.2467992 Vali Loss: 0.3086849 Test Loss: 0.3878712
Validation loss decreased (0.310530 --> 0.308685).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 4.3195555210113525
Epoch: 14, Steps: 63 | Train Loss: 0.2423480 Vali Loss: 0.3069159 Test Loss: 0.3863629
Validation loss decreased (0.308685 --> 0.306916).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 4.612937927246094
Epoch: 15, Steps: 63 | Train Loss: 0.2384225 Vali Loss: 0.3055197 Test Loss: 0.3851689
Validation loss decreased (0.306916 --> 0.305520).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.1681933403015137
Epoch: 16, Steps: 63 | Train Loss: 0.2346405 Vali Loss: 0.3042871 Test Loss: 0.3839753
Validation loss decreased (0.305520 --> 0.304287).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.075333595275879
Epoch: 17, Steps: 63 | Train Loss: 0.2324018 Vali Loss: 0.3031911 Test Loss: 0.3827412
Validation loss decreased (0.304287 --> 0.303191).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.7324843406677246
Epoch: 18, Steps: 63 | Train Loss: 0.2296675 Vali Loss: 0.3020388 Test Loss: 0.3817656
Validation loss decreased (0.303191 --> 0.302039).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.5449819564819336
Epoch: 19, Steps: 63 | Train Loss: 0.2273029 Vali Loss: 0.3011099 Test Loss: 0.3806716
Validation loss decreased (0.302039 --> 0.301110).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.7563347816467285
Epoch: 20, Steps: 63 | Train Loss: 0.2246872 Vali Loss: 0.3002705 Test Loss: 0.3796829
Validation loss decreased (0.301110 --> 0.300270).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.2773663997650146
Epoch: 21, Steps: 63 | Train Loss: 0.2229947 Vali Loss: 0.2993448 Test Loss: 0.3788662
Validation loss decreased (0.300270 --> 0.299345).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.524214506149292
Epoch: 22, Steps: 63 | Train Loss: 0.2213063 Vali Loss: 0.2986358 Test Loss: 0.3780406
Validation loss decreased (0.299345 --> 0.298636).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.6826741695404053
Epoch: 23, Steps: 63 | Train Loss: 0.2196259 Vali Loss: 0.2978866 Test Loss: 0.3771924
Validation loss decreased (0.298636 --> 0.297887).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.9601430892944336
Epoch: 24, Steps: 63 | Train Loss: 0.2180124 Vali Loss: 0.2973807 Test Loss: 0.3764770
Validation loss decreased (0.297887 --> 0.297381).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 5.2992753982543945
Epoch: 25, Steps: 63 | Train Loss: 0.2165195 Vali Loss: 0.2967319 Test Loss: 0.3757344
Validation loss decreased (0.297381 --> 0.296732).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 4.194226980209351
Epoch: 26, Steps: 63 | Train Loss: 0.2154001 Vali Loss: 0.2960848 Test Loss: 0.3750555
Validation loss decreased (0.296732 --> 0.296085).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 3.268620491027832
Epoch: 27, Steps: 63 | Train Loss: 0.2141114 Vali Loss: 0.2957367 Test Loss: 0.3745095
Validation loss decreased (0.296085 --> 0.295737).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 4.2891011238098145
Epoch: 28, Steps: 63 | Train Loss: 0.2135792 Vali Loss: 0.2952791 Test Loss: 0.3738985
Validation loss decreased (0.295737 --> 0.295279).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.45210862159729
Epoch: 29, Steps: 63 | Train Loss: 0.2123933 Vali Loss: 0.2948357 Test Loss: 0.3734287
Validation loss decreased (0.295279 --> 0.294836).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 3.380635976791382
Epoch: 30, Steps: 63 | Train Loss: 0.2112422 Vali Loss: 0.2944098 Test Loss: 0.3729253
Validation loss decreased (0.294836 --> 0.294410).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 3.715869665145874
Epoch: 31, Steps: 63 | Train Loss: 0.2109298 Vali Loss: 0.2941507 Test Loss: 0.3724490
Validation loss decreased (0.294410 --> 0.294151).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.631601095199585
Epoch: 32, Steps: 63 | Train Loss: 0.2102970 Vali Loss: 0.2938127 Test Loss: 0.3719534
Validation loss decreased (0.294151 --> 0.293813).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 3.5356674194335938
Epoch: 33, Steps: 63 | Train Loss: 0.2092668 Vali Loss: 0.2934318 Test Loss: 0.3715005
Validation loss decreased (0.293813 --> 0.293432).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.1926441192626953
Epoch: 34, Steps: 63 | Train Loss: 0.2082267 Vali Loss: 0.2930706 Test Loss: 0.3711518
Validation loss decreased (0.293432 --> 0.293071).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 4.740267515182495
Epoch: 35, Steps: 63 | Train Loss: 0.2082058 Vali Loss: 0.2928630 Test Loss: 0.3707748
Validation loss decreased (0.293071 --> 0.292863).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 3.888117551803589
Epoch: 36, Steps: 63 | Train Loss: 0.2076998 Vali Loss: 0.2926466 Test Loss: 0.3703583
Validation loss decreased (0.292863 --> 0.292647).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.831679344177246
Epoch: 37, Steps: 63 | Train Loss: 0.2068677 Vali Loss: 0.2923932 Test Loss: 0.3700376
Validation loss decreased (0.292647 --> 0.292393).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.9481306076049805
Epoch: 38, Steps: 63 | Train Loss: 0.2066855 Vali Loss: 0.2921679 Test Loss: 0.3697445
Validation loss decreased (0.292393 --> 0.292168).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 4.717129230499268
Epoch: 39, Steps: 63 | Train Loss: 0.2064261 Vali Loss: 0.2919506 Test Loss: 0.3694208
Validation loss decreased (0.292168 --> 0.291951).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.68839955329895
Epoch: 40, Steps: 63 | Train Loss: 0.2055573 Vali Loss: 0.2917123 Test Loss: 0.3691899
Validation loss decreased (0.291951 --> 0.291712).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.3242862224578857
Epoch: 41, Steps: 63 | Train Loss: 0.2055513 Vali Loss: 0.2914167 Test Loss: 0.3689328
Validation loss decreased (0.291712 --> 0.291417).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 3.6075196266174316
Epoch: 42, Steps: 63 | Train Loss: 0.2047119 Vali Loss: 0.2909209 Test Loss: 0.3686837
Validation loss decreased (0.291417 --> 0.290921).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.3452391624450684
Epoch: 43, Steps: 63 | Train Loss: 0.2048871 Vali Loss: 0.2910961 Test Loss: 0.3684499
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.681279182434082
Epoch: 44, Steps: 63 | Train Loss: 0.2046376 Vali Loss: 0.2910684 Test Loss: 0.3681930
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 3.197150945663452
Epoch: 45, Steps: 63 | Train Loss: 0.2044023 Vali Loss: 0.2906670 Test Loss: 0.3679887
Validation loss decreased (0.290921 --> 0.290667).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 3.924994945526123
Epoch: 46, Steps: 63 | Train Loss: 0.2035399 Vali Loss: 0.2907060 Test Loss: 0.3678185
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 3.4868738651275635
Epoch: 47, Steps: 63 | Train Loss: 0.2038657 Vali Loss: 0.2906349 Test Loss: 0.3675929
Validation loss decreased (0.290667 --> 0.290635).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 3.4376611709594727
Epoch: 48, Steps: 63 | Train Loss: 0.2029209 Vali Loss: 0.2904619 Test Loss: 0.3674586
Validation loss decreased (0.290635 --> 0.290462).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.8481221199035645
Epoch: 49, Steps: 63 | Train Loss: 0.2029703 Vali Loss: 0.2903841 Test Loss: 0.3672818
Validation loss decreased (0.290462 --> 0.290384).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 4.5338664054870605
Epoch: 50, Steps: 63 | Train Loss: 0.2028776 Vali Loss: 0.2902420 Test Loss: 0.3671125
Validation loss decreased (0.290384 --> 0.290242).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 3.7979705333709717
Epoch: 51, Steps: 63 | Train Loss: 0.2029893 Vali Loss: 0.2901225 Test Loss: 0.3669735
Validation loss decreased (0.290242 --> 0.290123).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 4.373099327087402
Epoch: 52, Steps: 63 | Train Loss: 0.2025813 Vali Loss: 0.2900905 Test Loss: 0.3668090
Validation loss decreased (0.290123 --> 0.290091).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 4.04201602935791
Epoch: 53, Steps: 63 | Train Loss: 0.2025578 Vali Loss: 0.2899786 Test Loss: 0.3666765
Validation loss decreased (0.290091 --> 0.289979).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 3.4185118675231934
Epoch: 54, Steps: 63 | Train Loss: 0.2025019 Vali Loss: 0.2898590 Test Loss: 0.3665425
Validation loss decreased (0.289979 --> 0.289859).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.4292044639587402
Epoch: 55, Steps: 63 | Train Loss: 0.2019430 Vali Loss: 0.2898028 Test Loss: 0.3664322
Validation loss decreased (0.289859 --> 0.289803).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 4.279885530471802
Epoch: 56, Steps: 63 | Train Loss: 0.2019981 Vali Loss: 0.2894633 Test Loss: 0.3663001
Validation loss decreased (0.289803 --> 0.289463).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.3217661380767822
Epoch: 57, Steps: 63 | Train Loss: 0.2019307 Vali Loss: 0.2896403 Test Loss: 0.3661903
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.748814582824707
Epoch: 58, Steps: 63 | Train Loss: 0.2018542 Vali Loss: 0.2895375 Test Loss: 0.3660749
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 3.785259485244751
Epoch: 59, Steps: 63 | Train Loss: 0.2015269 Vali Loss: 0.2894644 Test Loss: 0.3659918
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 3.23429799079895
Epoch: 60, Steps: 63 | Train Loss: 0.2013865 Vali Loss: 0.2893917 Test Loss: 0.3658918
Validation loss decreased (0.289463 --> 0.289392).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 3.7822141647338867
Epoch: 61, Steps: 63 | Train Loss: 0.2015883 Vali Loss: 0.2893640 Test Loss: 0.3657832
Validation loss decreased (0.289392 --> 0.289364).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.990786075592041
Epoch: 62, Steps: 63 | Train Loss: 0.2013202 Vali Loss: 0.2893219 Test Loss: 0.3656992
Validation loss decreased (0.289364 --> 0.289322).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.8417398929595947
Epoch: 63, Steps: 63 | Train Loss: 0.2008728 Vali Loss: 0.2892471 Test Loss: 0.3656104
Validation loss decreased (0.289322 --> 0.289247).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 3.2166507244110107
Epoch: 64, Steps: 63 | Train Loss: 0.2011745 Vali Loss: 0.2891407 Test Loss: 0.3655331
Validation loss decreased (0.289247 --> 0.289141).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 4.191962242126465
Epoch: 65, Steps: 63 | Train Loss: 0.2006586 Vali Loss: 0.2891450 Test Loss: 0.3654653
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 3.1262001991271973
Epoch: 66, Steps: 63 | Train Loss: 0.2010395 Vali Loss: 0.2891446 Test Loss: 0.3653850
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 3.010223865509033
Epoch: 67, Steps: 63 | Train Loss: 0.2005149 Vali Loss: 0.2891071 Test Loss: 0.3653099
Validation loss decreased (0.289141 --> 0.289107).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.897742748260498
Epoch: 68, Steps: 63 | Train Loss: 0.2007944 Vali Loss: 0.2890880 Test Loss: 0.3652629
Validation loss decreased (0.289107 --> 0.289088).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 3.4342153072357178
Epoch: 69, Steps: 63 | Train Loss: 0.2008849 Vali Loss: 0.2889951 Test Loss: 0.3651859
Validation loss decreased (0.289088 --> 0.288995).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.3159704208374023
Epoch: 70, Steps: 63 | Train Loss: 0.2004063 Vali Loss: 0.2889682 Test Loss: 0.3651402
Validation loss decreased (0.288995 --> 0.288968).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 3.472388505935669
Epoch: 71, Steps: 63 | Train Loss: 0.2004827 Vali Loss: 0.2889670 Test Loss: 0.3650837
Validation loss decreased (0.288968 --> 0.288967).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.8908729553222656
Epoch: 72, Steps: 63 | Train Loss: 0.2005230 Vali Loss: 0.2889281 Test Loss: 0.3650212
Validation loss decreased (0.288967 --> 0.288928).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 3.3212101459503174
Epoch: 73, Steps: 63 | Train Loss: 0.2005592 Vali Loss: 0.2886019 Test Loss: 0.3649756
Validation loss decreased (0.288928 --> 0.288602).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 4.954719543457031
Epoch: 74, Steps: 63 | Train Loss: 0.1996814 Vali Loss: 0.2888825 Test Loss: 0.3649232
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 3.4225053787231445
Epoch: 75, Steps: 63 | Train Loss: 0.1996264 Vali Loss: 0.2887516 Test Loss: 0.3648900
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 3.455023765563965
Epoch: 76, Steps: 63 | Train Loss: 0.2001489 Vali Loss: 0.2888022 Test Loss: 0.3648425
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 3.964094877243042
Epoch: 77, Steps: 63 | Train Loss: 0.2004173 Vali Loss: 0.2887999 Test Loss: 0.3648022
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 3.2335078716278076
Epoch: 78, Steps: 63 | Train Loss: 0.2002778 Vali Loss: 0.2886966 Test Loss: 0.3647622
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 3.2826051712036133
Epoch: 79, Steps: 63 | Train Loss: 0.2000288 Vali Loss: 0.2887610 Test Loss: 0.3647228
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.586193561553955
Epoch: 80, Steps: 63 | Train Loss: 0.2001995 Vali Loss: 0.2886848 Test Loss: 0.3646796
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 3.03153395652771
Epoch: 81, Steps: 63 | Train Loss: 0.1999476 Vali Loss: 0.2886589 Test Loss: 0.3646588
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 3.557840585708618
Epoch: 82, Steps: 63 | Train Loss: 0.2000908 Vali Loss: 0.2886419 Test Loss: 0.3646159
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.5131442546844482
Epoch: 83, Steps: 63 | Train Loss: 0.1997134 Vali Loss: 0.2886684 Test Loss: 0.3645881
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 3.4723923206329346
Epoch: 84, Steps: 63 | Train Loss: 0.1997737 Vali Loss: 0.2886320 Test Loss: 0.3645578
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 3.0222620964050293
Epoch: 85, Steps: 63 | Train Loss: 0.2000650 Vali Loss: 0.2886307 Test Loss: 0.3645270
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 2.9408178329467773
Epoch: 86, Steps: 63 | Train Loss: 0.1996947 Vali Loss: 0.2885702 Test Loss: 0.3645071
Validation loss decreased (0.288602 --> 0.288570).  Saving model ...
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 3.7928974628448486
Epoch: 87, Steps: 63 | Train Loss: 0.2000363 Vali Loss: 0.2886015 Test Loss: 0.3644744
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 3.485447883605957
Epoch: 88, Steps: 63 | Train Loss: 0.1998518 Vali Loss: 0.2884773 Test Loss: 0.3644542
Validation loss decreased (0.288570 --> 0.288477).  Saving model ...
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.8629026412963867
Epoch: 89, Steps: 63 | Train Loss: 0.1996466 Vali Loss: 0.2885206 Test Loss: 0.3644311
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 3.325469493865967
Epoch: 90, Steps: 63 | Train Loss: 0.1997133 Vali Loss: 0.2884896 Test Loss: 0.3644024
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 3.5275332927703857
Epoch: 91, Steps: 63 | Train Loss: 0.1993721 Vali Loss: 0.2885219 Test Loss: 0.3643866
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 3.888432502746582
Epoch: 92, Steps: 63 | Train Loss: 0.1998311 Vali Loss: 0.2885267 Test Loss: 0.3643641
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 4.431413650512695
Epoch: 93, Steps: 63 | Train Loss: 0.1993511 Vali Loss: 0.2885316 Test Loss: 0.3643424
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 3.1028335094451904
Epoch: 94, Steps: 63 | Train Loss: 0.1997835 Vali Loss: 0.2883911 Test Loss: 0.3643275
Validation loss decreased (0.288477 --> 0.288391).  Saving model ...
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 3.468853235244751
Epoch: 95, Steps: 63 | Train Loss: 0.1994137 Vali Loss: 0.2884877 Test Loss: 0.3643092
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 3.1428866386413574
Epoch: 96, Steps: 63 | Train Loss: 0.1995300 Vali Loss: 0.2885033 Test Loss: 0.3642918
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 2.5532751083374023
Epoch: 97, Steps: 63 | Train Loss: 0.1994437 Vali Loss: 0.2884683 Test Loss: 0.3642785
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 2.861325263977051
Epoch: 98, Steps: 63 | Train Loss: 0.1995544 Vali Loss: 0.2884421 Test Loss: 0.3642622
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 3.0017290115356445
Epoch: 99, Steps: 63 | Train Loss: 0.1996849 Vali Loss: 0.2884518 Test Loss: 0.3642469
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 4.147023677825928
Epoch: 100, Steps: 63 | Train Loss: 0.1996140 Vali Loss: 0.2882764 Test Loss: 0.3642332
Validation loss decreased (0.288391 --> 0.288276).  Saving model ...
Updating learning rate to 3.1160680107021042e-06
train 8089
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=90, out_features=138, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  11128320.0
params:  12558.0
Trainable parameters:  12558
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.6292672157287598
Epoch: 1, Steps: 63 | Train Loss: 0.5147779 Vali Loss: 0.2837722 Test Loss: 0.3577076
Validation loss decreased (inf --> 0.283772).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.8670995235443115
Epoch: 2, Steps: 63 | Train Loss: 0.5101076 Vali Loss: 0.2816689 Test Loss: 0.3558821
Validation loss decreased (0.283772 --> 0.281669).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.3922665119171143
Epoch: 3, Steps: 63 | Train Loss: 0.5080063 Vali Loss: 0.2808865 Test Loss: 0.3547829
Validation loss decreased (0.281669 --> 0.280886).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.770429849624634
Epoch: 4, Steps: 63 | Train Loss: 0.5078001 Vali Loss: 0.2804859 Test Loss: 0.3548351
Validation loss decreased (0.280886 --> 0.280486).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.4659221172332764
Epoch: 5, Steps: 63 | Train Loss: 0.5063514 Vali Loss: 0.2797822 Test Loss: 0.3545685
Validation loss decreased (0.280486 --> 0.279782).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.2343242168426514
Epoch: 6, Steps: 63 | Train Loss: 0.5069060 Vali Loss: 0.2798131 Test Loss: 0.3544601
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.035005569458008
Epoch: 7, Steps: 63 | Train Loss: 0.5063488 Vali Loss: 0.2793845 Test Loss: 0.3544783
Validation loss decreased (0.279782 --> 0.279384).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.7307727336883545
Epoch: 8, Steps: 63 | Train Loss: 0.5049519 Vali Loss: 0.2790493 Test Loss: 0.3544621
Validation loss decreased (0.279384 --> 0.279049).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 4.648766040802002
Epoch: 9, Steps: 63 | Train Loss: 0.5050730 Vali Loss: 0.2789168 Test Loss: 0.3544170
Validation loss decreased (0.279049 --> 0.278917).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 4.35733962059021
Epoch: 10, Steps: 63 | Train Loss: 0.5049473 Vali Loss: 0.2788436 Test Loss: 0.3542614
Validation loss decreased (0.278917 --> 0.278844).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.747174024581909
Epoch: 11, Steps: 63 | Train Loss: 0.5052723 Vali Loss: 0.2786779 Test Loss: 0.3541321
Validation loss decreased (0.278844 --> 0.278678).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.031031370162964
Epoch: 12, Steps: 63 | Train Loss: 0.5053798 Vali Loss: 0.2786089 Test Loss: 0.3540416
Validation loss decreased (0.278678 --> 0.278609).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.1478421688079834
Epoch: 13, Steps: 63 | Train Loss: 0.5037219 Vali Loss: 0.2782989 Test Loss: 0.3542445
Validation loss decreased (0.278609 --> 0.278299).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 4.056235313415527
Epoch: 14, Steps: 63 | Train Loss: 0.5033423 Vali Loss: 0.2781114 Test Loss: 0.3541230
Validation loss decreased (0.278299 --> 0.278111).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.921626329421997
Epoch: 15, Steps: 63 | Train Loss: 0.5043480 Vali Loss: 0.2781995 Test Loss: 0.3540414
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.2015511989593506
Epoch: 16, Steps: 63 | Train Loss: 0.5043978 Vali Loss: 0.2780299 Test Loss: 0.3542208
Validation loss decreased (0.278111 --> 0.278030).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.6267175674438477
Epoch: 17, Steps: 63 | Train Loss: 0.5048430 Vali Loss: 0.2779699 Test Loss: 0.3540637
Validation loss decreased (0.278030 --> 0.277970).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.678574800491333
Epoch: 18, Steps: 63 | Train Loss: 0.5028878 Vali Loss: 0.2779416 Test Loss: 0.3540937
Validation loss decreased (0.277970 --> 0.277942).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 3.085416316986084
Epoch: 19, Steps: 63 | Train Loss: 0.5031769 Vali Loss: 0.2778557 Test Loss: 0.3540254
Validation loss decreased (0.277942 --> 0.277856).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.631047248840332
Epoch: 20, Steps: 63 | Train Loss: 0.5043387 Vali Loss: 0.2778849 Test Loss: 0.3539867
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.0988240242004395
Epoch: 21, Steps: 63 | Train Loss: 0.5035668 Vali Loss: 0.2775521 Test Loss: 0.3539547
Validation loss decreased (0.277856 --> 0.277552).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.1335806846618652
Epoch: 22, Steps: 63 | Train Loss: 0.5039023 Vali Loss: 0.2776692 Test Loss: 0.3540554
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.91607666015625
Epoch: 23, Steps: 63 | Train Loss: 0.5027221 Vali Loss: 0.2774854 Test Loss: 0.3540884
Validation loss decreased (0.277552 --> 0.277485).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.7116119861602783
Epoch: 24, Steps: 63 | Train Loss: 0.5036866 Vali Loss: 0.2776120 Test Loss: 0.3538987
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 3.9897282123565674
Epoch: 25, Steps: 63 | Train Loss: 0.5033345 Vali Loss: 0.2772371 Test Loss: 0.3540322
Validation loss decreased (0.277485 --> 0.277237).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.824331283569336
Epoch: 26, Steps: 63 | Train Loss: 0.5034693 Vali Loss: 0.2773839 Test Loss: 0.3540598
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 3.483194589614868
Epoch: 27, Steps: 63 | Train Loss: 0.5033845 Vali Loss: 0.2774677 Test Loss: 0.3539613
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.3038971424102783
Epoch: 28, Steps: 63 | Train Loss: 0.5030043 Vali Loss: 0.2773339 Test Loss: 0.3540036
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 3.036123752593994
Epoch: 29, Steps: 63 | Train Loss: 0.5032553 Vali Loss: 0.2772410 Test Loss: 0.3540433
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.2886784076690674
Epoch: 30, Steps: 63 | Train Loss: 0.5037278 Vali Loss: 0.2772846 Test Loss: 0.3540191
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.770148515701294
Epoch: 31, Steps: 63 | Train Loss: 0.5036330 Vali Loss: 0.2772464 Test Loss: 0.3540150
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.7008841037750244
Epoch: 32, Steps: 63 | Train Loss: 0.5037008 Vali Loss: 0.2770655 Test Loss: 0.3540624
Validation loss decreased (0.277237 --> 0.277065).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 3.205920696258545
Epoch: 33, Steps: 63 | Train Loss: 0.5021156 Vali Loss: 0.2771991 Test Loss: 0.3539634
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.6267173290252686
Epoch: 34, Steps: 63 | Train Loss: 0.5037130 Vali Loss: 0.2771860 Test Loss: 0.3539768
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 4.065974712371826
Epoch: 35, Steps: 63 | Train Loss: 0.5020200 Vali Loss: 0.2771594 Test Loss: 0.3539781
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 3.4647703170776367
Epoch: 36, Steps: 63 | Train Loss: 0.5030663 Vali Loss: 0.2768671 Test Loss: 0.3539336
Validation loss decreased (0.277065 --> 0.276867).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 3.434016466140747
Epoch: 37, Steps: 63 | Train Loss: 0.5025680 Vali Loss: 0.2771702 Test Loss: 0.3539650
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 3.6820740699768066
Epoch: 38, Steps: 63 | Train Loss: 0.5021231 Vali Loss: 0.2771307 Test Loss: 0.3539272
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 3.4889039993286133
Epoch: 39, Steps: 63 | Train Loss: 0.5028354 Vali Loss: 0.2770609 Test Loss: 0.3539352
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 3.897646427154541
Epoch: 40, Steps: 63 | Train Loss: 0.5033463 Vali Loss: 0.2771098 Test Loss: 0.3539219
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.318298578262329
Epoch: 41, Steps: 63 | Train Loss: 0.5035462 Vali Loss: 0.2771078 Test Loss: 0.3538640
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.2334787845611572
Epoch: 42, Steps: 63 | Train Loss: 0.5031664 Vali Loss: 0.2771193 Test Loss: 0.3539242
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 3.4664547443389893
Epoch: 43, Steps: 63 | Train Loss: 0.5030903 Vali Loss: 0.2770779 Test Loss: 0.3539050
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 4.228494644165039
Epoch: 44, Steps: 63 | Train Loss: 0.5016898 Vali Loss: 0.2770882 Test Loss: 0.3539185
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 4.257317066192627
Epoch: 45, Steps: 63 | Train Loss: 0.5019654 Vali Loss: 0.2770177 Test Loss: 0.3539346
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 4.449389934539795
Epoch: 46, Steps: 63 | Train Loss: 0.5024023 Vali Loss: 0.2769914 Test Loss: 0.3539200
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 3.2451279163360596
Epoch: 47, Steps: 63 | Train Loss: 0.5015298 Vali Loss: 0.2769602 Test Loss: 0.3539290
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 3.6166179180145264
Epoch: 48, Steps: 63 | Train Loss: 0.5026949 Vali Loss: 0.2768001 Test Loss: 0.3538968
Validation loss decreased (0.276867 --> 0.276800).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 3.2289397716522217
Epoch: 49, Steps: 63 | Train Loss: 0.5022224 Vali Loss: 0.2768467 Test Loss: 0.3539066
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.9424312114715576
Epoch: 50, Steps: 63 | Train Loss: 0.5020504 Vali Loss: 0.2766985 Test Loss: 0.3539019
Validation loss decreased (0.276800 --> 0.276698).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 3.2960145473480225
Epoch: 51, Steps: 63 | Train Loss: 0.5030616 Vali Loss: 0.2769301 Test Loss: 0.3539126
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.6114673614501953
Epoch: 52, Steps: 63 | Train Loss: 0.5030052 Vali Loss: 0.2769468 Test Loss: 0.3538972
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 4.155966758728027
Epoch: 53, Steps: 63 | Train Loss: 0.5027750 Vali Loss: 0.2769568 Test Loss: 0.3538973
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.8646392822265625
Epoch: 54, Steps: 63 | Train Loss: 0.5020765 Vali Loss: 0.2769776 Test Loss: 0.3538773
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.699287176132202
Epoch: 55, Steps: 63 | Train Loss: 0.5028665 Vali Loss: 0.2769080 Test Loss: 0.3538816
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.692260265350342
Epoch: 56, Steps: 63 | Train Loss: 0.5030298 Vali Loss: 0.2768693 Test Loss: 0.3539141
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 3.790668249130249
Epoch: 57, Steps: 63 | Train Loss: 0.5020518 Vali Loss: 0.2769490 Test Loss: 0.3538967
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 3.569443464279175
Epoch: 58, Steps: 63 | Train Loss: 0.5025190 Vali Loss: 0.2769248 Test Loss: 0.3538871
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 4.004240274429321
Epoch: 59, Steps: 63 | Train Loss: 0.5029262 Vali Loss: 0.2769239 Test Loss: 0.3538914
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.483232259750366
Epoch: 60, Steps: 63 | Train Loss: 0.5029767 Vali Loss: 0.2769560 Test Loss: 0.3538862
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.4431567192077637
Epoch: 61, Steps: 63 | Train Loss: 0.5005786 Vali Loss: 0.2769250 Test Loss: 0.3538867
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 3.0230321884155273
Epoch: 62, Steps: 63 | Train Loss: 0.5026154 Vali Loss: 0.2769177 Test Loss: 0.3538719
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 3.7904551029205322
Epoch: 63, Steps: 63 | Train Loss: 0.5020032 Vali Loss: 0.2769325 Test Loss: 0.3538867
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 3.0284664630889893
Epoch: 64, Steps: 63 | Train Loss: 0.5020243 Vali Loss: 0.2767761 Test Loss: 0.3538956
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.970550775527954
Epoch: 65, Steps: 63 | Train Loss: 0.5031522 Vali Loss: 0.2768922 Test Loss: 0.3538837
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 3.56363844871521
Epoch: 66, Steps: 63 | Train Loss: 0.5012420 Vali Loss: 0.2768623 Test Loss: 0.3539038
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.7762081623077393
Epoch: 67, Steps: 63 | Train Loss: 0.5023040 Vali Loss: 0.2768719 Test Loss: 0.3538936
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.941382646560669
Epoch: 68, Steps: 63 | Train Loss: 0.5021865 Vali Loss: 0.2768739 Test Loss: 0.3538872
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 3.5957844257354736
Epoch: 69, Steps: 63 | Train Loss: 0.5020816 Vali Loss: 0.2768502 Test Loss: 0.3538840
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 3.766744375228882
Epoch: 70, Steps: 63 | Train Loss: 0.5031678 Vali Loss: 0.2767036 Test Loss: 0.3538786
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_360_192_FITS_ETTh2_ftM_sl360_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.3344752788543701, mae:0.3753911554813385, rse:0.4637915790081024, corr:[0.26751238 0.27036133 0.26760313 0.2667831  0.26647538 0.2648318
 0.26343438 0.26279148 0.26208127 0.26049805 0.25899592 0.25761908
 0.2563214  0.255169   0.2543761  0.25413302 0.25384444 0.25338504
 0.25254756 0.25144657 0.2503021  0.2490962  0.24762528 0.2455235
 0.24316604 0.24098058 0.23906885 0.23745081 0.23632315 0.23529056
 0.23392244 0.23213825 0.23054004 0.22926907 0.2279147  0.22660065
 0.225457   0.22437994 0.22338794 0.22259733 0.22232443 0.22202086
 0.2211004  0.21984594 0.21889295 0.21793431 0.21652614 0.21465576
 0.21282262 0.21109647 0.20936273 0.20784003 0.20658511 0.20506623
 0.20288137 0.2007646  0.19943173 0.1979125  0.1963474  0.195273
 0.19504032 0.19481638 0.19452609 0.19430624 0.19422796 0.19390415
 0.19294004 0.19201033 0.19173406 0.19134195 0.19020754 0.18903637
 0.18841295 0.1879791  0.18691532 0.18563965 0.18509492 0.1847446
 0.18381332 0.18276136 0.18267298 0.18247758 0.18195516 0.18141739
 0.18136919 0.18127729 0.1809862  0.18073225 0.18045354 0.17998838
 0.1791459  0.17851125 0.17871325 0.17869097 0.17816992 0.17758709
 0.17715865 0.17616063 0.17477117 0.17361484 0.17310871 0.17260899
 0.17181063 0.17091821 0.17083263 0.17085756 0.17037879 0.17040846
 0.1704846  0.17014745 0.16897416 0.16833769 0.16815475 0.16800995
 0.1674056  0.16661072 0.16644141 0.16582859 0.16437913 0.16276027
 0.16168882 0.16034175 0.15893507 0.15797807 0.15724263 0.15630262
 0.15524141 0.15449622 0.15410036 0.15340188 0.15254842 0.15202329
 0.15201582 0.15158142 0.15062971 0.15019369 0.15028906 0.15005033
 0.1488852  0.14843576 0.14900756 0.14883576 0.14744326 0.14600879
 0.14494714 0.14339484 0.14136659 0.14021271 0.14009939 0.13951531
 0.1386114  0.13771361 0.1377903  0.137779   0.13685314 0.1361377
 0.13615176 0.13636269 0.13577904 0.13598381 0.13646102 0.1361826
 0.13532248 0.13510005 0.13582705 0.13587308 0.13511556 0.1339969
 0.13320692 0.13180445 0.13005228 0.12935811 0.12924619 0.12774995
 0.12536499 0.12403826 0.12353221 0.1221251  0.12040407 0.11977305
 0.11977337 0.1185558  0.11713103 0.11771592 0.11783335 0.11512519
 0.11329482 0.11443547 0.11494321 0.11263265 0.11447469 0.12227884]
