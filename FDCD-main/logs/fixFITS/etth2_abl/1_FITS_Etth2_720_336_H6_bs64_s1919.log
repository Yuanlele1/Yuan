Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=1919, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_336_FITS_ETTh2_ftM_sl720_ll48_pl336_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=196, out_features=287, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  50401792.0
params:  56539.0
Trainable parameters:  56539
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.5121071338653564
Epoch: 1, Steps: 59 | Train Loss: 0.8292190 Vali Loss: 0.5052519 Test Loss: 0.3936288
Validation loss decreased (inf --> 0.505252).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.645566463470459
Epoch: 2, Steps: 59 | Train Loss: 0.6975948 Vali Loss: 0.4521504 Test Loss: 0.3743186
Validation loss decreased (0.505252 --> 0.452150).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.5609958171844482
Epoch: 3, Steps: 59 | Train Loss: 0.6676334 Vali Loss: 0.4341661 Test Loss: 0.3682167
Validation loss decreased (0.452150 --> 0.434166).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.7998592853546143
Epoch: 4, Steps: 59 | Train Loss: 0.6538630 Vali Loss: 0.4173119 Test Loss: 0.3651513
Validation loss decreased (0.434166 --> 0.417312).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.49302077293396
Epoch: 5, Steps: 59 | Train Loss: 0.6451578 Vali Loss: 0.4128715 Test Loss: 0.3630472
Validation loss decreased (0.417312 --> 0.412871).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.5270776748657227
Epoch: 6, Steps: 59 | Train Loss: 0.6376324 Vali Loss: 0.4089326 Test Loss: 0.3616070
Validation loss decreased (0.412871 --> 0.408933).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.443251132965088
Epoch: 7, Steps: 59 | Train Loss: 0.6347608 Vali Loss: 0.4009012 Test Loss: 0.3609169
Validation loss decreased (0.408933 --> 0.400901).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.4105339050292969
Epoch: 8, Steps: 59 | Train Loss: 0.6294126 Vali Loss: 0.4006749 Test Loss: 0.3605402
Validation loss decreased (0.400901 --> 0.400675).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.3868777751922607
Epoch: 9, Steps: 59 | Train Loss: 0.6277981 Vali Loss: 0.3967469 Test Loss: 0.3600025
Validation loss decreased (0.400675 --> 0.396747).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.4762747287750244
Epoch: 10, Steps: 59 | Train Loss: 0.6259682 Vali Loss: 0.3943402 Test Loss: 0.3597161
Validation loss decreased (0.396747 --> 0.394340).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.4209039211273193
Epoch: 11, Steps: 59 | Train Loss: 0.6255076 Vali Loss: 0.3954933 Test Loss: 0.3593989
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.472783088684082
Epoch: 12, Steps: 59 | Train Loss: 0.6219352 Vali Loss: 0.3935607 Test Loss: 0.3592595
Validation loss decreased (0.394340 --> 0.393561).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.4734385013580322
Epoch: 13, Steps: 59 | Train Loss: 0.6231239 Vali Loss: 0.3938285 Test Loss: 0.3591733
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.4239583015441895
Epoch: 14, Steps: 59 | Train Loss: 0.6207698 Vali Loss: 0.3892145 Test Loss: 0.3591314
Validation loss decreased (0.393561 --> 0.389214).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.494680643081665
Epoch: 15, Steps: 59 | Train Loss: 0.6196965 Vali Loss: 0.3894600 Test Loss: 0.3590433
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.4833426475524902
Epoch: 16, Steps: 59 | Train Loss: 0.6198029 Vali Loss: 0.3876026 Test Loss: 0.3589823
Validation loss decreased (0.389214 --> 0.387603).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.7930071353912354
Epoch: 17, Steps: 59 | Train Loss: 0.6200408 Vali Loss: 0.3874844 Test Loss: 0.3588709
Validation loss decreased (0.387603 --> 0.387484).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.6296463012695312
Epoch: 18, Steps: 59 | Train Loss: 0.6183129 Vali Loss: 0.3852746 Test Loss: 0.3589101
Validation loss decreased (0.387484 --> 0.385275).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.5676541328430176
Epoch: 19, Steps: 59 | Train Loss: 0.6179237 Vali Loss: 0.3873074 Test Loss: 0.3587779
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.420055627822876
Epoch: 20, Steps: 59 | Train Loss: 0.6181219 Vali Loss: 0.3841443 Test Loss: 0.3588114
Validation loss decreased (0.385275 --> 0.384144).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.436424970626831
Epoch: 21, Steps: 59 | Train Loss: 0.6175774 Vali Loss: 0.3857435 Test Loss: 0.3586705
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.6770515441894531
Epoch: 22, Steps: 59 | Train Loss: 0.6156766 Vali Loss: 0.3856398 Test Loss: 0.3586807
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.4865660667419434
Epoch: 23, Steps: 59 | Train Loss: 0.6168527 Vali Loss: 0.3857386 Test Loss: 0.3586054
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.4773292541503906
Epoch: 24, Steps: 59 | Train Loss: 0.6160708 Vali Loss: 0.3848592 Test Loss: 0.3587591
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.7409582138061523
Epoch: 25, Steps: 59 | Train Loss: 0.6153392 Vali Loss: 0.3862396 Test Loss: 0.3586940
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.6550729274749756
Epoch: 26, Steps: 59 | Train Loss: 0.6163711 Vali Loss: 0.3823959 Test Loss: 0.3586144
Validation loss decreased (0.384144 --> 0.382396).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.5334908962249756
Epoch: 27, Steps: 59 | Train Loss: 0.6150613 Vali Loss: 0.3828404 Test Loss: 0.3585016
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.7712738513946533
Epoch: 28, Steps: 59 | Train Loss: 0.6150385 Vali Loss: 0.3824442 Test Loss: 0.3585089
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.524278163909912
Epoch: 29, Steps: 59 | Train Loss: 0.6142941 Vali Loss: 0.3846985 Test Loss: 0.3586429
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.4245481491088867
Epoch: 30, Steps: 59 | Train Loss: 0.6143920 Vali Loss: 0.3833838 Test Loss: 0.3584956
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.4717657566070557
Epoch: 31, Steps: 59 | Train Loss: 0.6146806 Vali Loss: 0.3835556 Test Loss: 0.3585427
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.30953311920166
Epoch: 32, Steps: 59 | Train Loss: 0.6144656 Vali Loss: 0.3800789 Test Loss: 0.3585101
Validation loss decreased (0.382396 --> 0.380079).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.9046368598937988
Epoch: 33, Steps: 59 | Train Loss: 0.6145484 Vali Loss: 0.3843586 Test Loss: 0.3584368
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.122972011566162
Epoch: 34, Steps: 59 | Train Loss: 0.6148846 Vali Loss: 0.3806457 Test Loss: 0.3584254
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.5767898559570312
Epoch: 35, Steps: 59 | Train Loss: 0.6145533 Vali Loss: 0.3824982 Test Loss: 0.3584068
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.4585158824920654
Epoch: 36, Steps: 59 | Train Loss: 0.6133664 Vali Loss: 0.3823703 Test Loss: 0.3584338
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.4834322929382324
Epoch: 37, Steps: 59 | Train Loss: 0.6141832 Vali Loss: 0.3829705 Test Loss: 0.3583803
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.50341796875
Epoch: 38, Steps: 59 | Train Loss: 0.6140195 Vali Loss: 0.3813354 Test Loss: 0.3584235
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.471980094909668
Epoch: 39, Steps: 59 | Train Loss: 0.6124534 Vali Loss: 0.3818367 Test Loss: 0.3584277
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.4689419269561768
Epoch: 40, Steps: 59 | Train Loss: 0.6140649 Vali Loss: 0.3821437 Test Loss: 0.3583695
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.5027077198028564
Epoch: 41, Steps: 59 | Train Loss: 0.6139263 Vali Loss: 0.3823770 Test Loss: 0.3584047
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.4168448448181152
Epoch: 42, Steps: 59 | Train Loss: 0.6126131 Vali Loss: 0.3828458 Test Loss: 0.3583790
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.5400059223175049
Epoch: 43, Steps: 59 | Train Loss: 0.6136579 Vali Loss: 0.3820020 Test Loss: 0.3584386
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.477442741394043
Epoch: 44, Steps: 59 | Train Loss: 0.6118766 Vali Loss: 0.3822025 Test Loss: 0.3583910
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.5129516124725342
Epoch: 45, Steps: 59 | Train Loss: 0.6130181 Vali Loss: 0.3801299 Test Loss: 0.3583893
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.4570021629333496
Epoch: 46, Steps: 59 | Train Loss: 0.6126728 Vali Loss: 0.3798319 Test Loss: 0.3583434
Validation loss decreased (0.380079 --> 0.379832).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.435018539428711
Epoch: 47, Steps: 59 | Train Loss: 0.6136903 Vali Loss: 0.3804822 Test Loss: 0.3584019
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.4532430171966553
Epoch: 48, Steps: 59 | Train Loss: 0.6120670 Vali Loss: 0.3792380 Test Loss: 0.3583919
Validation loss decreased (0.379832 --> 0.379238).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.4958748817443848
Epoch: 49, Steps: 59 | Train Loss: 0.6119784 Vali Loss: 0.3808486 Test Loss: 0.3583670
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.5083842277526855
Epoch: 50, Steps: 59 | Train Loss: 0.6121706 Vali Loss: 0.3799599 Test Loss: 0.3583807
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.5087957382202148
Epoch: 51, Steps: 59 | Train Loss: 0.6133309 Vali Loss: 0.3817039 Test Loss: 0.3583586
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.7106173038482666
Epoch: 52, Steps: 59 | Train Loss: 0.6122328 Vali Loss: 0.3803724 Test Loss: 0.3583733
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.106060028076172
Epoch: 53, Steps: 59 | Train Loss: 0.6112401 Vali Loss: 0.3824129 Test Loss: 0.3583424
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.5637502670288086
Epoch: 54, Steps: 59 | Train Loss: 0.6133038 Vali Loss: 0.3828877 Test Loss: 0.3583665
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.5908739566802979
Epoch: 55, Steps: 59 | Train Loss: 0.6108710 Vali Loss: 0.3795110 Test Loss: 0.3583655
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.4750640392303467
Epoch: 56, Steps: 59 | Train Loss: 0.6130603 Vali Loss: 0.3799425 Test Loss: 0.3583555
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.5028913021087646
Epoch: 57, Steps: 59 | Train Loss: 0.6134987 Vali Loss: 0.3803944 Test Loss: 0.3583675
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.5520298480987549
Epoch: 58, Steps: 59 | Train Loss: 0.6126846 Vali Loss: 0.3804967 Test Loss: 0.3583609
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.4763972759246826
Epoch: 59, Steps: 59 | Train Loss: 0.6113167 Vali Loss: 0.3793843 Test Loss: 0.3583654
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.6217920780181885
Epoch: 60, Steps: 59 | Train Loss: 0.6125878 Vali Loss: 0.3817551 Test Loss: 0.3583532
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.4365389347076416
Epoch: 61, Steps: 59 | Train Loss: 0.6132609 Vali Loss: 0.3786860 Test Loss: 0.3583730
Validation loss decreased (0.379238 --> 0.378686).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.8027946949005127
Epoch: 62, Steps: 59 | Train Loss: 0.6120426 Vali Loss: 0.3809233 Test Loss: 0.3583602
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.476163625717163
Epoch: 63, Steps: 59 | Train Loss: 0.6110740 Vali Loss: 0.3821431 Test Loss: 0.3583534
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.4233038425445557
Epoch: 64, Steps: 59 | Train Loss: 0.6103685 Vali Loss: 0.3798756 Test Loss: 0.3583749
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.9717435836791992
Epoch: 65, Steps: 59 | Train Loss: 0.6113661 Vali Loss: 0.3827660 Test Loss: 0.3583699
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.6028378009796143
Epoch: 66, Steps: 59 | Train Loss: 0.6137281 Vali Loss: 0.3817821 Test Loss: 0.3583506
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.5161361694335938
Epoch: 67, Steps: 59 | Train Loss: 0.6117437 Vali Loss: 0.3771995 Test Loss: 0.3583631
Validation loss decreased (0.378686 --> 0.377200).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.4241416454315186
Epoch: 68, Steps: 59 | Train Loss: 0.6126231 Vali Loss: 0.3812036 Test Loss: 0.3583565
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.5265865325927734
Epoch: 69, Steps: 59 | Train Loss: 0.6108661 Vali Loss: 0.3771309 Test Loss: 0.3583600
Validation loss decreased (0.377200 --> 0.377131).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.874925136566162
Epoch: 70, Steps: 59 | Train Loss: 0.6107807 Vali Loss: 0.3811293 Test Loss: 0.3583627
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.4394962787628174
Epoch: 71, Steps: 59 | Train Loss: 0.6124799 Vali Loss: 0.3810805 Test Loss: 0.3583663
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.5535109043121338
Epoch: 72, Steps: 59 | Train Loss: 0.6117901 Vali Loss: 0.3815401 Test Loss: 0.3583661
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.6754376888275146
Epoch: 73, Steps: 59 | Train Loss: 0.6127836 Vali Loss: 0.3790569 Test Loss: 0.3583644
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.4458212852478027
Epoch: 74, Steps: 59 | Train Loss: 0.6123855 Vali Loss: 0.3805170 Test Loss: 0.3583612
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.419753074645996
Epoch: 75, Steps: 59 | Train Loss: 0.6130839 Vali Loss: 0.3810278 Test Loss: 0.3583507
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.4267702102661133
Epoch: 76, Steps: 59 | Train Loss: 0.6122711 Vali Loss: 0.3795974 Test Loss: 0.3583702
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.505185842514038
Epoch: 77, Steps: 59 | Train Loss: 0.6125318 Vali Loss: 0.3801771 Test Loss: 0.3583549
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.7997093200683594
Epoch: 78, Steps: 59 | Train Loss: 0.6108268 Vali Loss: 0.3771685 Test Loss: 0.3583532
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.5088894367218018
Epoch: 79, Steps: 59 | Train Loss: 0.6117139 Vali Loss: 0.3802862 Test Loss: 0.3583525
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.6788287162780762
Epoch: 80, Steps: 59 | Train Loss: 0.6113471 Vali Loss: 0.3802175 Test Loss: 0.3583493
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.4610893726348877
Epoch: 81, Steps: 59 | Train Loss: 0.6123118 Vali Loss: 0.3782203 Test Loss: 0.3583552
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.5173931121826172
Epoch: 82, Steps: 59 | Train Loss: 0.6124859 Vali Loss: 0.3803411 Test Loss: 0.3583531
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.4476168155670166
Epoch: 83, Steps: 59 | Train Loss: 0.6125796 Vali Loss: 0.3776227 Test Loss: 0.3583573
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.3961269855499268
Epoch: 84, Steps: 59 | Train Loss: 0.6125472 Vali Loss: 0.3804914 Test Loss: 0.3583542
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.3588447570800781
Epoch: 85, Steps: 59 | Train Loss: 0.6098356 Vali Loss: 0.3800377 Test Loss: 0.3583584
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.4749538898468018
Epoch: 86, Steps: 59 | Train Loss: 0.6129260 Vali Loss: 0.3799480 Test Loss: 0.3583523
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.494734287261963
Epoch: 87, Steps: 59 | Train Loss: 0.6118789 Vali Loss: 0.3805238 Test Loss: 0.3583560
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.5598585605621338
Epoch: 88, Steps: 59 | Train Loss: 0.6118944 Vali Loss: 0.3805302 Test Loss: 0.3583555
EarlyStopping counter: 19 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.6987812519073486
Epoch: 89, Steps: 59 | Train Loss: 0.6125892 Vali Loss: 0.3807904 Test Loss: 0.3583568
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_720_336_FITS_ETTh2_ftM_sl720_ll48_pl336_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.35410594940185547, mae:0.39558717608451843, rse:0.4757799506187439, corr:[0.25857782 0.26337162 0.2614218  0.26315722 0.26237422 0.26062533
 0.26107135 0.26097077 0.25916874 0.25818524 0.2577483  0.25637525
 0.25502524 0.25415814 0.25330445 0.25243798 0.25207424 0.25159982
 0.2505851  0.2494158  0.24853109 0.24774766 0.24652311 0.2451658
 0.24365477 0.24229093 0.24116716 0.2402423  0.23932965 0.23847826
 0.2377562  0.23683923 0.2358942  0.23505303 0.2341663  0.23311894
 0.23241772 0.23205137 0.2311529  0.22994792 0.22927897 0.22894011
 0.2282124  0.22722761 0.22636376 0.22554523 0.22412553 0.22228837
 0.2207852  0.2194472  0.21784684 0.2164293  0.21524335 0.21354567
 0.21165447 0.21037205 0.20900205 0.20713446 0.20567968 0.2048767
 0.20399831 0.20331955 0.20349987 0.2037169  0.20302261 0.2024328
 0.20219448 0.20178476 0.20103374 0.20054501 0.20015097 0.19933105
 0.19819027 0.19729257 0.19641897 0.19513385 0.19425455 0.19394517
 0.1933854  0.19246913 0.19217038 0.19204786 0.19142318 0.19075967
 0.19061722 0.19052625 0.19004576 0.18968524 0.18958436 0.18922262
 0.18859701 0.1883881  0.18869136 0.18851903 0.18811002 0.18811521
 0.18808313 0.18725193 0.1863323  0.1859649  0.18560362 0.18467169
 0.18420774 0.18431865 0.18412839 0.18317896 0.1827995  0.18301776
 0.18250127 0.18148433 0.18093485 0.18078446 0.18000408 0.17927732
 0.17912586 0.17889608 0.17806178 0.17706865 0.17650804 0.17553644
 0.17405233 0.1729932  0.17250328 0.17159837 0.1704236  0.16986746
 0.16952235 0.16871363 0.16787015 0.16726443 0.16637865 0.16515121
 0.16452155 0.16428643 0.163827   0.16329238 0.16298538 0.1624857
 0.16145664 0.16077897 0.16075224 0.16030681 0.15919198 0.1580246
 0.1568052  0.15529251 0.1538659  0.15307593 0.1523562  0.15135469
 0.15060353 0.15012492 0.14946286 0.14841071 0.14777076 0.14741124
 0.14669062 0.14607081 0.14621006 0.14615089 0.14509514 0.14444663
 0.14440645 0.1438997  0.14315012 0.14328466 0.14370644 0.14269622
 0.14093192 0.13984428 0.13928139 0.13807128 0.13675256 0.13582377
 0.13502184 0.13357091 0.13253465 0.1321663  0.13128121 0.13022064
 0.12968513 0.12951036 0.12912947 0.12892419 0.12872536 0.12841296
 0.12789369 0.12780736 0.12819219 0.12817298 0.12822542 0.12838647
 0.12816706 0.1273131  0.12657921 0.12659642 0.12628657 0.12529655
 0.12472231 0.12460438 0.12421533 0.12349269 0.12335095 0.12340449
 0.12281825 0.12240962 0.12253298 0.1227102  0.12245287 0.12257067
 0.12301014 0.12304491 0.12281229 0.12294259 0.12303552 0.12224657
 0.12127023 0.12064598 0.11973867 0.11871321 0.11838118 0.11887072
 0.11856177 0.11813871 0.11832053 0.11847351 0.11762808 0.11659803
 0.11636191 0.11629838 0.11571141 0.11588889 0.11662278 0.11695342
 0.11687075 0.11741438 0.11812117 0.11812993 0.11793061 0.11812577
 0.11792653 0.11699045 0.11650961 0.11684531 0.11652548 0.11562011
 0.1156025  0.11586653 0.11572155 0.1156252  0.11597859 0.11616109
 0.11590975 0.11683296 0.11815505 0.11909471 0.11944918 0.12063453
 0.12153807 0.12158599 0.12185942 0.12267763 0.12339858 0.12330069
 0.12370805 0.12422688 0.12399764 0.12349512 0.12370634 0.12398081
 0.12328211 0.12290563 0.12370314 0.12367198 0.12311426 0.12299713
 0.12352266 0.12332377 0.12300921 0.12386674 0.12464429 0.12406691
 0.12369542 0.12457376 0.12452962 0.12332215 0.12334075 0.12449434
 0.12435734 0.12318458 0.12281366 0.12272406 0.12146174 0.12023963
 0.12045928 0.12007802 0.11869377 0.11848523 0.11952557 0.11885717
 0.11712525 0.11776039 0.11918015 0.11923981 0.11883593 0.12033346
 0.12070416 0.11992989 0.12028619 0.12155899 0.12121884 0.12017743
 0.12066362 0.12034284 0.11859155 0.1178687  0.11840249 0.11714281
 0.11539299 0.11686068 0.11845964 0.11762427 0.1169725  0.11930405
 0.12009149 0.11881965 0.11993935 0.12230501 0.12180479 0.12102468
 0.12257982 0.12232488 0.12081291 0.12292292 0.12427733 0.11532664]
