Args in experiment:
Namespace(H_order=2, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=72, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H2_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=72, out_features=91, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  5870592.0
params:  6643.0
Trainable parameters:  6643
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.543646812438965
Epoch: 1, Steps: 60 | Train Loss: 0.7386944 Vali Loss: 0.4014312 Test Loss: 0.4053443
Validation loss decreased (inf --> 0.401431).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.402517795562744
Epoch: 2, Steps: 60 | Train Loss: 0.6039900 Vali Loss: 0.3497338 Test Loss: 0.3743370
Validation loss decreased (0.401431 --> 0.349734).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.8866336345672607
Epoch: 3, Steps: 60 | Train Loss: 0.5693757 Vali Loss: 0.3303047 Test Loss: 0.3658111
Validation loss decreased (0.349734 --> 0.330305).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.879966974258423
Epoch: 4, Steps: 60 | Train Loss: 0.5560323 Vali Loss: 0.3204053 Test Loss: 0.3624032
Validation loss decreased (0.330305 --> 0.320405).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.075763463973999
Epoch: 5, Steps: 60 | Train Loss: 0.5483106 Vali Loss: 0.3144116 Test Loss: 0.3608499
Validation loss decreased (0.320405 --> 0.314412).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.908306837081909
Epoch: 6, Steps: 60 | Train Loss: 0.5420609 Vali Loss: 0.3093922 Test Loss: 0.3600417
Validation loss decreased (0.314412 --> 0.309392).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.70512318611145
Epoch: 7, Steps: 60 | Train Loss: 0.5377076 Vali Loss: 0.3067899 Test Loss: 0.3593663
Validation loss decreased (0.309392 --> 0.306790).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.317996025085449
Epoch: 8, Steps: 60 | Train Loss: 0.5356361 Vali Loss: 0.3044298 Test Loss: 0.3589518
Validation loss decreased (0.306790 --> 0.304430).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.535632371902466
Epoch: 9, Steps: 60 | Train Loss: 0.5344108 Vali Loss: 0.3021894 Test Loss: 0.3586365
Validation loss decreased (0.304430 --> 0.302189).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.7278056144714355
Epoch: 10, Steps: 60 | Train Loss: 0.5328595 Vali Loss: 0.3005916 Test Loss: 0.3583979
Validation loss decreased (0.302189 --> 0.300592).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.5295169353485107
Epoch: 11, Steps: 60 | Train Loss: 0.5308142 Vali Loss: 0.2991911 Test Loss: 0.3580065
Validation loss decreased (0.300592 --> 0.299191).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.460714101791382
Epoch: 12, Steps: 60 | Train Loss: 0.5299375 Vali Loss: 0.2981303 Test Loss: 0.3577528
Validation loss decreased (0.299191 --> 0.298130).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.922332286834717
Epoch: 13, Steps: 60 | Train Loss: 0.5271722 Vali Loss: 0.2971256 Test Loss: 0.3575356
Validation loss decreased (0.298130 --> 0.297126).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.24299693107605
Epoch: 14, Steps: 60 | Train Loss: 0.5268341 Vali Loss: 0.2961810 Test Loss: 0.3573147
Validation loss decreased (0.297126 --> 0.296181).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.5492329597473145
Epoch: 15, Steps: 60 | Train Loss: 0.5255700 Vali Loss: 0.2953999 Test Loss: 0.3570645
Validation loss decreased (0.296181 --> 0.295400).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.387145519256592
Epoch: 16, Steps: 60 | Train Loss: 0.5254600 Vali Loss: 0.2949778 Test Loss: 0.3568889
Validation loss decreased (0.295400 --> 0.294978).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.256932020187378
Epoch: 17, Steps: 60 | Train Loss: 0.5246052 Vali Loss: 0.2941295 Test Loss: 0.3567564
Validation loss decreased (0.294978 --> 0.294129).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.6903369426727295
Epoch: 18, Steps: 60 | Train Loss: 0.5243003 Vali Loss: 0.2934816 Test Loss: 0.3566026
Validation loss decreased (0.294129 --> 0.293482).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.3721959590911865
Epoch: 19, Steps: 60 | Train Loss: 0.5200416 Vali Loss: 0.2929171 Test Loss: 0.3564806
Validation loss decreased (0.293482 --> 0.292917).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.326704740524292
Epoch: 20, Steps: 60 | Train Loss: 0.5223214 Vali Loss: 0.2924271 Test Loss: 0.3563963
Validation loss decreased (0.292917 --> 0.292427).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.1197776794433594
Epoch: 21, Steps: 60 | Train Loss: 0.5217828 Vali Loss: 0.2921612 Test Loss: 0.3562562
Validation loss decreased (0.292427 --> 0.292161).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.550489664077759
Epoch: 22, Steps: 60 | Train Loss: 0.5228268 Vali Loss: 0.2916459 Test Loss: 0.3561507
Validation loss decreased (0.292161 --> 0.291646).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 4.326653480529785
Epoch: 23, Steps: 60 | Train Loss: 0.5218282 Vali Loss: 0.2915823 Test Loss: 0.3560271
Validation loss decreased (0.291646 --> 0.291582).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.5679566860198975
Epoch: 24, Steps: 60 | Train Loss: 0.5199031 Vali Loss: 0.2913611 Test Loss: 0.3559618
Validation loss decreased (0.291582 --> 0.291361).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 3.020638942718506
Epoch: 25, Steps: 60 | Train Loss: 0.5215524 Vali Loss: 0.2906656 Test Loss: 0.3559000
Validation loss decreased (0.291361 --> 0.290666).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.4091641902923584
Epoch: 26, Steps: 60 | Train Loss: 0.5187670 Vali Loss: 0.2904969 Test Loss: 0.3558008
Validation loss decreased (0.290666 --> 0.290497).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.786100149154663
Epoch: 27, Steps: 60 | Train Loss: 0.5207145 Vali Loss: 0.2905486 Test Loss: 0.3557571
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.9815423488616943
Epoch: 28, Steps: 60 | Train Loss: 0.5198263 Vali Loss: 0.2903517 Test Loss: 0.3557104
Validation loss decreased (0.290497 --> 0.290352).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 3.003443956375122
Epoch: 29, Steps: 60 | Train Loss: 0.5206136 Vali Loss: 0.2899803 Test Loss: 0.3556878
Validation loss decreased (0.290352 --> 0.289980).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.6752545833587646
Epoch: 30, Steps: 60 | Train Loss: 0.5198962 Vali Loss: 0.2898104 Test Loss: 0.3556140
Validation loss decreased (0.289980 --> 0.289810).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.530578374862671
Epoch: 31, Steps: 60 | Train Loss: 0.5204923 Vali Loss: 0.2899877 Test Loss: 0.3554851
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.5309460163116455
Epoch: 32, Steps: 60 | Train Loss: 0.5187261 Vali Loss: 0.2896571 Test Loss: 0.3554861
Validation loss decreased (0.289810 --> 0.289657).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.8907384872436523
Epoch: 33, Steps: 60 | Train Loss: 0.5203179 Vali Loss: 0.2894815 Test Loss: 0.3554502
Validation loss decreased (0.289657 --> 0.289482).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.6958534717559814
Epoch: 34, Steps: 60 | Train Loss: 0.5193061 Vali Loss: 0.2894790 Test Loss: 0.3553948
Validation loss decreased (0.289482 --> 0.289479).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 3.3509104251861572
Epoch: 35, Steps: 60 | Train Loss: 0.5177620 Vali Loss: 0.2893485 Test Loss: 0.3553845
Validation loss decreased (0.289479 --> 0.289348).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.825669765472412
Epoch: 36, Steps: 60 | Train Loss: 0.5171307 Vali Loss: 0.2891290 Test Loss: 0.3553734
Validation loss decreased (0.289348 --> 0.289129).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.926939010620117
Epoch: 37, Steps: 60 | Train Loss: 0.5189573 Vali Loss: 0.2890386 Test Loss: 0.3553338
Validation loss decreased (0.289129 --> 0.289039).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 3.290984630584717
Epoch: 38, Steps: 60 | Train Loss: 0.5180636 Vali Loss: 0.2888344 Test Loss: 0.3553025
Validation loss decreased (0.289039 --> 0.288834).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.4646592140197754
Epoch: 39, Steps: 60 | Train Loss: 0.5176617 Vali Loss: 0.2888799 Test Loss: 0.3552515
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.276524305343628
Epoch: 40, Steps: 60 | Train Loss: 0.5180647 Vali Loss: 0.2886767 Test Loss: 0.3552374
Validation loss decreased (0.288834 --> 0.288677).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.547840118408203
Epoch: 41, Steps: 60 | Train Loss: 0.5188079 Vali Loss: 0.2886986 Test Loss: 0.3552166
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 3.9011740684509277
Epoch: 42, Steps: 60 | Train Loss: 0.5188745 Vali Loss: 0.2885859 Test Loss: 0.3552269
Validation loss decreased (0.288677 --> 0.288586).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.3067829608917236
Epoch: 43, Steps: 60 | Train Loss: 0.5165921 Vali Loss: 0.2885454 Test Loss: 0.3551710
Validation loss decreased (0.288586 --> 0.288545).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.27134108543396
Epoch: 44, Steps: 60 | Train Loss: 0.5170977 Vali Loss: 0.2884722 Test Loss: 0.3551531
Validation loss decreased (0.288545 --> 0.288472).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.954624652862549
Epoch: 45, Steps: 60 | Train Loss: 0.5168987 Vali Loss: 0.2884141 Test Loss: 0.3551308
Validation loss decreased (0.288472 --> 0.288414).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.8133645057678223
Epoch: 46, Steps: 60 | Train Loss: 0.5173983 Vali Loss: 0.2878881 Test Loss: 0.3551593
Validation loss decreased (0.288414 --> 0.287888).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.4087367057800293
Epoch: 47, Steps: 60 | Train Loss: 0.5165398 Vali Loss: 0.2882501 Test Loss: 0.3551050
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 3.309467077255249
Epoch: 48, Steps: 60 | Train Loss: 0.5183501 Vali Loss: 0.2881851 Test Loss: 0.3550650
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.7361505031585693
Epoch: 49, Steps: 60 | Train Loss: 0.5189121 Vali Loss: 0.2882685 Test Loss: 0.3550805
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.8495190143585205
Epoch: 50, Steps: 60 | Train Loss: 0.5181591 Vali Loss: 0.2881657 Test Loss: 0.3550812
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.9702961444854736
Epoch: 51, Steps: 60 | Train Loss: 0.5184447 Vali Loss: 0.2880313 Test Loss: 0.3550402
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.7605767250061035
Epoch: 52, Steps: 60 | Train Loss: 0.5167208 Vali Loss: 0.2880654 Test Loss: 0.3550315
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.618929624557495
Epoch: 53, Steps: 60 | Train Loss: 0.5169075 Vali Loss: 0.2880611 Test Loss: 0.3550350
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.669724225997925
Epoch: 54, Steps: 60 | Train Loss: 0.5166454 Vali Loss: 0.2876820 Test Loss: 0.3550264
Validation loss decreased (0.287888 --> 0.287682).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.3783624172210693
Epoch: 55, Steps: 60 | Train Loss: 0.5180565 Vali Loss: 0.2879957 Test Loss: 0.3550182
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.6071207523345947
Epoch: 56, Steps: 60 | Train Loss: 0.5184121 Vali Loss: 0.2879510 Test Loss: 0.3550167
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.5323588848114014
Epoch: 57, Steps: 60 | Train Loss: 0.5164766 Vali Loss: 0.2878578 Test Loss: 0.3550081
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.441080331802368
Epoch: 58, Steps: 60 | Train Loss: 0.5186057 Vali Loss: 0.2879276 Test Loss: 0.3549794
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.911064386367798
Epoch: 59, Steps: 60 | Train Loss: 0.5177119 Vali Loss: 0.2878311 Test Loss: 0.3550135
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.4814436435699463
Epoch: 60, Steps: 60 | Train Loss: 0.5164515 Vali Loss: 0.2878783 Test Loss: 0.3549587
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.6761443614959717
Epoch: 61, Steps: 60 | Train Loss: 0.5178125 Vali Loss: 0.2877876 Test Loss: 0.3549464
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.5142672061920166
Epoch: 62, Steps: 60 | Train Loss: 0.5161589 Vali Loss: 0.2877691 Test Loss: 0.3549606
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.6053757667541504
Epoch: 63, Steps: 60 | Train Loss: 0.5176570 Vali Loss: 0.2877562 Test Loss: 0.3549575
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.6724367141723633
Epoch: 64, Steps: 60 | Train Loss: 0.5183160 Vali Loss: 0.2877496 Test Loss: 0.3549529
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 3.2089226245880127
Epoch: 65, Steps: 60 | Train Loss: 0.5163375 Vali Loss: 0.2875524 Test Loss: 0.3549348
Validation loss decreased (0.287682 --> 0.287552).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.6235408782958984
Epoch: 66, Steps: 60 | Train Loss: 0.5157764 Vali Loss: 0.2877055 Test Loss: 0.3549422
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.9763550758361816
Epoch: 67, Steps: 60 | Train Loss: 0.5154575 Vali Loss: 0.2876348 Test Loss: 0.3549224
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.6047780513763428
Epoch: 68, Steps: 60 | Train Loss: 0.5167448 Vali Loss: 0.2876642 Test Loss: 0.3549224
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.581214427947998
Epoch: 69, Steps: 60 | Train Loss: 0.5170912 Vali Loss: 0.2876345 Test Loss: 0.3549301
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.392390727996826
Epoch: 70, Steps: 60 | Train Loss: 0.5154653 Vali Loss: 0.2875722 Test Loss: 0.3549180
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.58100962638855
Epoch: 71, Steps: 60 | Train Loss: 0.5167638 Vali Loss: 0.2873382 Test Loss: 0.3549156
Validation loss decreased (0.287552 --> 0.287338).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.4065704345703125
Epoch: 72, Steps: 60 | Train Loss: 0.5178771 Vali Loss: 0.2876157 Test Loss: 0.3549066
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.3632607460021973
Epoch: 73, Steps: 60 | Train Loss: 0.5167803 Vali Loss: 0.2872967 Test Loss: 0.3549164
Validation loss decreased (0.287338 --> 0.287297).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.766585350036621
Epoch: 74, Steps: 60 | Train Loss: 0.5178056 Vali Loss: 0.2875591 Test Loss: 0.3549108
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.4089207649230957
Epoch: 75, Steps: 60 | Train Loss: 0.5175830 Vali Loss: 0.2872884 Test Loss: 0.3548993
Validation loss decreased (0.287297 --> 0.287288).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.4731295108795166
Epoch: 76, Steps: 60 | Train Loss: 0.5168591 Vali Loss: 0.2875627 Test Loss: 0.3549027
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.868788480758667
Epoch: 77, Steps: 60 | Train Loss: 0.5173082 Vali Loss: 0.2875834 Test Loss: 0.3548898
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.544274091720581
Epoch: 78, Steps: 60 | Train Loss: 0.5181059 Vali Loss: 0.2875072 Test Loss: 0.3548921
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.402231454849243
Epoch: 79, Steps: 60 | Train Loss: 0.5171511 Vali Loss: 0.2875431 Test Loss: 0.3548833
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.4961602687835693
Epoch: 80, Steps: 60 | Train Loss: 0.5160491 Vali Loss: 0.2875506 Test Loss: 0.3548799
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.745605230331421
Epoch: 81, Steps: 60 | Train Loss: 0.5179518 Vali Loss: 0.2875261 Test Loss: 0.3548801
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 2.480416774749756
Epoch: 82, Steps: 60 | Train Loss: 0.5158931 Vali Loss: 0.2873886 Test Loss: 0.3548751
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.8234424591064453
Epoch: 83, Steps: 60 | Train Loss: 0.5142030 Vali Loss: 0.2875088 Test Loss: 0.3548737
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.5130302906036377
Epoch: 84, Steps: 60 | Train Loss: 0.5166836 Vali Loss: 0.2874978 Test Loss: 0.3548695
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.195261001586914
Epoch: 85, Steps: 60 | Train Loss: 0.5179160 Vali Loss: 0.2871422 Test Loss: 0.3548632
Validation loss decreased (0.287288 --> 0.287142).  Saving model ...
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 2.900805711746216
Epoch: 86, Steps: 60 | Train Loss: 0.5173688 Vali Loss: 0.2875136 Test Loss: 0.3548693
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 2.712751865386963
Epoch: 87, Steps: 60 | Train Loss: 0.5174722 Vali Loss: 0.2874822 Test Loss: 0.3548654
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 2.513338327407837
Epoch: 88, Steps: 60 | Train Loss: 0.5159852 Vali Loss: 0.2874827 Test Loss: 0.3548653
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.878990888595581
Epoch: 89, Steps: 60 | Train Loss: 0.5175077 Vali Loss: 0.2874487 Test Loss: 0.3548633
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 2.402121067047119
Epoch: 90, Steps: 60 | Train Loss: 0.5164798 Vali Loss: 0.2874903 Test Loss: 0.3548653
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.8827121257781982
Epoch: 91, Steps: 60 | Train Loss: 0.5170559 Vali Loss: 0.2874622 Test Loss: 0.3548626
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 2.5368378162384033
Epoch: 92, Steps: 60 | Train Loss: 0.5166817 Vali Loss: 0.2870820 Test Loss: 0.3548600
Validation loss decreased (0.287142 --> 0.287082).  Saving model ...
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 2.544816493988037
Epoch: 93, Steps: 60 | Train Loss: 0.5167566 Vali Loss: 0.2874728 Test Loss: 0.3548635
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 2.643383741378784
Epoch: 94, Steps: 60 | Train Loss: 0.5165836 Vali Loss: 0.2874566 Test Loss: 0.3548581
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 2.430971622467041
Epoch: 95, Steps: 60 | Train Loss: 0.5143557 Vali Loss: 0.2874419 Test Loss: 0.3548628
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 2.6367027759552
Epoch: 96, Steps: 60 | Train Loss: 0.5175950 Vali Loss: 0.2874216 Test Loss: 0.3548570
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 2.454289197921753
Epoch: 97, Steps: 60 | Train Loss: 0.5165627 Vali Loss: 0.2874342 Test Loss: 0.3548552
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 2.489531993865967
Epoch: 98, Steps: 60 | Train Loss: 0.5173409 Vali Loss: 0.2874149 Test Loss: 0.3548545
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 2.8793838024139404
Epoch: 99, Steps: 60 | Train Loss: 0.5180320 Vali Loss: 0.2874111 Test Loss: 0.3548552
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 2.6105031967163086
Epoch: 100, Steps: 60 | Train Loss: 0.5154933 Vali Loss: 0.2874510 Test Loss: 0.3548526
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.1160680107021042e-06
>>>>>>>testing : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H2_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.3344930410385132, mae:0.3762799799442291, rse:0.46380388736724854, corr:[0.2621708  0.2647067  0.26657417 0.26693827 0.26590282 0.2645801
 0.2635495  0.26272374 0.26193672 0.26096198 0.25988317 0.2587357
 0.25770018 0.25683808 0.25607052 0.25540605 0.2546968  0.2538565
 0.25281987 0.2515799  0.2501242  0.24844328 0.24666864 0.24487023
 0.24328111 0.241864   0.24060671 0.23932922 0.23792529 0.23635411
 0.23479968 0.2331636  0.23169452 0.23038778 0.22936252 0.22845224
 0.22761194 0.22684997 0.22624238 0.22560823 0.22486246 0.2239331
 0.22278896 0.22149359 0.22010835 0.21872357 0.21737044 0.2159657
 0.21445188 0.21288136 0.21127805 0.20947336 0.20757052 0.20563836
 0.20352297 0.20159677 0.2000779  0.19889526 0.19810683 0.19756883
 0.19724569 0.19676939 0.19620411 0.19562463 0.19491231 0.19430271
 0.19375971 0.19325893 0.19275646 0.19219647 0.19141927 0.19047147
 0.18934463 0.18817613 0.18704939 0.18587692 0.1849322  0.18424222
 0.18376239 0.18327801 0.18300581 0.18272154 0.18235286 0.1818661
 0.1813359  0.18088575 0.1804764  0.18013452 0.17976409 0.17949915
 0.17932874 0.17907403 0.17885661 0.1784899  0.17788644 0.17705724
 0.17598057 0.17480509 0.17370151 0.17272203 0.17189404 0.17115805
 0.17067854 0.17028755 0.17002909 0.16974872 0.16934969 0.16890392
 0.168164   0.16728659 0.16637622 0.16573668 0.16521347 0.1648992
 0.16460596 0.1641382  0.16347784 0.16239247 0.16098176 0.15920056
 0.15737028 0.15560633 0.15428147 0.15342806 0.15279146 0.15222402
 0.15169    0.15095176 0.14998488 0.14878267 0.14760987 0.14643386
 0.14550857 0.14485002 0.14451599 0.1444951  0.14451866 0.1444171
 0.14401758 0.1432341  0.14213972 0.14076981 0.13933927 0.13800064
 0.13677368 0.13579611 0.13493548 0.13393143 0.13264953 0.13110837
 0.12966162 0.12822485 0.12739609 0.12726851 0.12767021 0.1280248
 0.12832452 0.12842171 0.12816884 0.1277116  0.1269774  0.12644207
 0.12633346 0.12658472 0.12693776 0.12690377 0.12641475 0.12524176
 0.12367178 0.12190279 0.12047216 0.11937698 0.1187999  0.11827153
 0.11771853 0.11662303 0.11498007 0.11320128 0.11119302 0.1098213
 0.1094124  0.11018968 0.11203608 0.11416817 0.11524205 0.1150316
 0.11379447 0.11186028 0.11088409 0.11200593 0.11672378 0.12385556]
