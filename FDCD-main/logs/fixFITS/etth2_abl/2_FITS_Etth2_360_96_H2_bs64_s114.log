Args in experiment:
Namespace(H_order=2, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=42, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_360_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_360_96_FITS_ETTh2_ftM_sl360_ll48_pl96_H2_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8185
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=42, out_features=53, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1994496.0
params:  2279.0
Trainable parameters:  2279
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.6606173515319824
Epoch: 1, Steps: 63 | Train Loss: 0.4828645 Vali Loss: 0.3560736 Test Loss: 0.4254781
Validation loss decreased (inf --> 0.356074).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.5083131790161133
Epoch: 2, Steps: 63 | Train Loss: 0.3950096 Vali Loss: 0.3186648 Test Loss: 0.3888042
Validation loss decreased (0.356074 --> 0.318665).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.447737693786621
Epoch: 3, Steps: 63 | Train Loss: 0.3397001 Vali Loss: 0.2935338 Test Loss: 0.3662493
Validation loss decreased (0.318665 --> 0.293534).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.8510820865631104
Epoch: 4, Steps: 63 | Train Loss: 0.3014053 Vali Loss: 0.2803230 Test Loss: 0.3522040
Validation loss decreased (0.293534 --> 0.280323).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.6594924926757812
Epoch: 5, Steps: 63 | Train Loss: 0.2739834 Vali Loss: 0.2714520 Test Loss: 0.3432328
Validation loss decreased (0.280323 --> 0.271452).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.024073362350464
Epoch: 6, Steps: 63 | Train Loss: 0.2545695 Vali Loss: 0.2645726 Test Loss: 0.3373794
Validation loss decreased (0.271452 --> 0.264573).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.7907352447509766
Epoch: 7, Steps: 63 | Train Loss: 0.2390476 Vali Loss: 0.2594486 Test Loss: 0.3328241
Validation loss decreased (0.264573 --> 0.259449).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.571171283721924
Epoch: 8, Steps: 63 | Train Loss: 0.2270268 Vali Loss: 0.2555282 Test Loss: 0.3292395
Validation loss decreased (0.259449 --> 0.255528).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.724931001663208
Epoch: 9, Steps: 63 | Train Loss: 0.2164778 Vali Loss: 0.2544460 Test Loss: 0.3264234
Validation loss decreased (0.255528 --> 0.254446).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.8921406269073486
Epoch: 10, Steps: 63 | Train Loss: 0.2073689 Vali Loss: 0.2503679 Test Loss: 0.3238257
Validation loss decreased (0.254446 --> 0.250368).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.646108627319336
Epoch: 11, Steps: 63 | Train Loss: 0.1994747 Vali Loss: 0.2491463 Test Loss: 0.3216489
Validation loss decreased (0.250368 --> 0.249146).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.198136568069458
Epoch: 12, Steps: 63 | Train Loss: 0.1934817 Vali Loss: 0.2472529 Test Loss: 0.3195361
Validation loss decreased (0.249146 --> 0.247253).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.0825083255767822
Epoch: 13, Steps: 63 | Train Loss: 0.1878778 Vali Loss: 0.2450924 Test Loss: 0.3177883
Validation loss decreased (0.247253 --> 0.245092).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.7808454036712646
Epoch: 14, Steps: 63 | Train Loss: 0.1815995 Vali Loss: 0.2450313 Test Loss: 0.3160357
Validation loss decreased (0.245092 --> 0.245031).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.83072829246521
Epoch: 15, Steps: 63 | Train Loss: 0.1780490 Vali Loss: 0.2433215 Test Loss: 0.3145124
Validation loss decreased (0.245031 --> 0.243321).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.6831533908843994
Epoch: 16, Steps: 63 | Train Loss: 0.1743537 Vali Loss: 0.2431579 Test Loss: 0.3130047
Validation loss decreased (0.243321 --> 0.243158).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.8789198398590088
Epoch: 17, Steps: 63 | Train Loss: 0.1701201 Vali Loss: 0.2409960 Test Loss: 0.3116709
Validation loss decreased (0.243158 --> 0.240996).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.7203395366668701
Epoch: 18, Steps: 63 | Train Loss: 0.1665778 Vali Loss: 0.2402130 Test Loss: 0.3102671
Validation loss decreased (0.240996 --> 0.240213).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.6469130516052246
Epoch: 19, Steps: 63 | Train Loss: 0.1647299 Vali Loss: 0.2395117 Test Loss: 0.3090912
Validation loss decreased (0.240213 --> 0.239512).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.952451467514038
Epoch: 20, Steps: 63 | Train Loss: 0.1611792 Vali Loss: 0.2395339 Test Loss: 0.3078584
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.9215624332427979
Epoch: 21, Steps: 63 | Train Loss: 0.1597799 Vali Loss: 0.2378634 Test Loss: 0.3067675
Validation loss decreased (0.239512 --> 0.237863).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.6627092361450195
Epoch: 22, Steps: 63 | Train Loss: 0.1570405 Vali Loss: 0.2378131 Test Loss: 0.3057491
Validation loss decreased (0.237863 --> 0.237813).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.9337575435638428
Epoch: 23, Steps: 63 | Train Loss: 0.1556943 Vali Loss: 0.2371478 Test Loss: 0.3047625
Validation loss decreased (0.237813 --> 0.237148).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.0769917964935303
Epoch: 24, Steps: 63 | Train Loss: 0.1539294 Vali Loss: 0.2362285 Test Loss: 0.3039603
Validation loss decreased (0.237148 --> 0.236229).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.5288987159729004
Epoch: 25, Steps: 63 | Train Loss: 0.1520820 Vali Loss: 0.2360951 Test Loss: 0.3030334
Validation loss decreased (0.236229 --> 0.236095).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.536405563354492
Epoch: 26, Steps: 63 | Train Loss: 0.1509050 Vali Loss: 0.2365165 Test Loss: 0.3022805
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.4984638690948486
Epoch: 27, Steps: 63 | Train Loss: 0.1489772 Vali Loss: 0.2345183 Test Loss: 0.3015018
Validation loss decreased (0.236095 --> 0.234518).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.831892490386963
Epoch: 28, Steps: 63 | Train Loss: 0.1476402 Vali Loss: 0.2354865 Test Loss: 0.3007798
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.5491549968719482
Epoch: 29, Steps: 63 | Train Loss: 0.1465966 Vali Loss: 0.2347478 Test Loss: 0.3001093
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.7420828342437744
Epoch: 30, Steps: 63 | Train Loss: 0.1456037 Vali Loss: 0.2337294 Test Loss: 0.2995551
Validation loss decreased (0.234518 --> 0.233729).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.0817887783050537
Epoch: 31, Steps: 63 | Train Loss: 0.1444019 Vali Loss: 0.2341916 Test Loss: 0.2989866
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.091073751449585
Epoch: 32, Steps: 63 | Train Loss: 0.1431818 Vali Loss: 0.2330065 Test Loss: 0.2985092
Validation loss decreased (0.233729 --> 0.233006).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.6794068813323975
Epoch: 33, Steps: 63 | Train Loss: 0.1418529 Vali Loss: 0.2330507 Test Loss: 0.2979780
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.9774982929229736
Epoch: 34, Steps: 63 | Train Loss: 0.1416504 Vali Loss: 0.2318909 Test Loss: 0.2975498
Validation loss decreased (0.233006 --> 0.231891).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.7363817691802979
Epoch: 35, Steps: 63 | Train Loss: 0.1413305 Vali Loss: 0.2315260 Test Loss: 0.2970385
Validation loss decreased (0.231891 --> 0.231526).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.902008295059204
Epoch: 36, Steps: 63 | Train Loss: 0.1403333 Vali Loss: 0.2325075 Test Loss: 0.2966243
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.814363718032837
Epoch: 37, Steps: 63 | Train Loss: 0.1399755 Vali Loss: 0.2316726 Test Loss: 0.2962297
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.0958502292633057
Epoch: 38, Steps: 63 | Train Loss: 0.1388968 Vali Loss: 0.2316059 Test Loss: 0.2958391
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.9657883644104004
Epoch: 39, Steps: 63 | Train Loss: 0.1384006 Vali Loss: 0.2305097 Test Loss: 0.2954880
Validation loss decreased (0.231526 --> 0.230510).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.862708568572998
Epoch: 40, Steps: 63 | Train Loss: 0.1380142 Vali Loss: 0.2307420 Test Loss: 0.2951904
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.7890634536743164
Epoch: 41, Steps: 63 | Train Loss: 0.1369142 Vali Loss: 0.2314031 Test Loss: 0.2948312
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.9084677696228027
Epoch: 42, Steps: 63 | Train Loss: 0.1369083 Vali Loss: 0.2306092 Test Loss: 0.2945180
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.5418610572814941
Epoch: 43, Steps: 63 | Train Loss: 0.1362046 Vali Loss: 0.2311535 Test Loss: 0.2942372
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.5787601470947266
Epoch: 44, Steps: 63 | Train Loss: 0.1362394 Vali Loss: 0.2300876 Test Loss: 0.2939971
Validation loss decreased (0.230510 --> 0.230088).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.9603626728057861
Epoch: 45, Steps: 63 | Train Loss: 0.1354407 Vali Loss: 0.2293280 Test Loss: 0.2937147
Validation loss decreased (0.230088 --> 0.229328).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.024369478225708
Epoch: 46, Steps: 63 | Train Loss: 0.1352708 Vali Loss: 0.2289717 Test Loss: 0.2934946
Validation loss decreased (0.229328 --> 0.228972).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.7457034587860107
Epoch: 47, Steps: 63 | Train Loss: 0.1351774 Vali Loss: 0.2294712 Test Loss: 0.2932568
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.8911511898040771
Epoch: 48, Steps: 63 | Train Loss: 0.1351378 Vali Loss: 0.2304190 Test Loss: 0.2930187
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.698453664779663
Epoch: 49, Steps: 63 | Train Loss: 0.1339682 Vali Loss: 0.2293359 Test Loss: 0.2928227
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.482489824295044
Epoch: 50, Steps: 63 | Train Loss: 0.1343066 Vali Loss: 0.2302308 Test Loss: 0.2926317
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.869908094406128
Epoch: 51, Steps: 63 | Train Loss: 0.1339635 Vali Loss: 0.2300005 Test Loss: 0.2924682
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.5762858390808105
Epoch: 52, Steps: 63 | Train Loss: 0.1330180 Vali Loss: 0.2299384 Test Loss: 0.2922616
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.9185750484466553
Epoch: 53, Steps: 63 | Train Loss: 0.1329037 Vali Loss: 0.2294327 Test Loss: 0.2920988
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.5617403984069824
Epoch: 54, Steps: 63 | Train Loss: 0.1328538 Vali Loss: 0.2292095 Test Loss: 0.2919657
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.9621565341949463
Epoch: 55, Steps: 63 | Train Loss: 0.1329331 Vali Loss: 0.2288506 Test Loss: 0.2918074
Validation loss decreased (0.228972 --> 0.228851).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.5402510166168213
Epoch: 56, Steps: 63 | Train Loss: 0.1322611 Vali Loss: 0.2296940 Test Loss: 0.2916731
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.8752632141113281
Epoch: 57, Steps: 63 | Train Loss: 0.1328626 Vali Loss: 0.2290671 Test Loss: 0.2915119
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.8855199813842773
Epoch: 58, Steps: 63 | Train Loss: 0.1322449 Vali Loss: 0.2281409 Test Loss: 0.2913732
Validation loss decreased (0.228851 --> 0.228141).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.6597263813018799
Epoch: 59, Steps: 63 | Train Loss: 0.1322158 Vali Loss: 0.2292122 Test Loss: 0.2912907
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.082294225692749
Epoch: 60, Steps: 63 | Train Loss: 0.1317801 Vali Loss: 0.2288194 Test Loss: 0.2911447
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.7782237529754639
Epoch: 61, Steps: 63 | Train Loss: 0.1319254 Vali Loss: 0.2295510 Test Loss: 0.2910542
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.8668694496154785
Epoch: 62, Steps: 63 | Train Loss: 0.1315581 Vali Loss: 0.2300053 Test Loss: 0.2909300
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.722635269165039
Epoch: 63, Steps: 63 | Train Loss: 0.1308843 Vali Loss: 0.2285475 Test Loss: 0.2908512
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.7421000003814697
Epoch: 64, Steps: 63 | Train Loss: 0.1308599 Vali Loss: 0.2291812 Test Loss: 0.2907622
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.7862892150878906
Epoch: 65, Steps: 63 | Train Loss: 0.1310131 Vali Loss: 0.2301674 Test Loss: 0.2906780
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.3126070499420166
Epoch: 66, Steps: 63 | Train Loss: 0.1310410 Vali Loss: 0.2286409 Test Loss: 0.2905788
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.6863319873809814
Epoch: 67, Steps: 63 | Train Loss: 0.1306736 Vali Loss: 0.2281833 Test Loss: 0.2904942
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.6426568031311035
Epoch: 68, Steps: 63 | Train Loss: 0.1311114 Vali Loss: 0.2287503 Test Loss: 0.2904019
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.8986122608184814
Epoch: 69, Steps: 63 | Train Loss: 0.1309449 Vali Loss: 0.2283374 Test Loss: 0.2903379
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.7138113975524902
Epoch: 70, Steps: 63 | Train Loss: 0.1302961 Vali Loss: 0.2282378 Test Loss: 0.2902663
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.675426721572876
Epoch: 71, Steps: 63 | Train Loss: 0.1305181 Vali Loss: 0.2281999 Test Loss: 0.2902009
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.6368143558502197
Epoch: 72, Steps: 63 | Train Loss: 0.1306693 Vali Loss: 0.2283460 Test Loss: 0.2901515
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.6222374439239502
Epoch: 73, Steps: 63 | Train Loss: 0.1302904 Vali Loss: 0.2285907 Test Loss: 0.2900680
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.6589741706848145
Epoch: 74, Steps: 63 | Train Loss: 0.1303539 Vali Loss: 0.2284054 Test Loss: 0.2900172
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.863541603088379
Epoch: 75, Steps: 63 | Train Loss: 0.1302857 Vali Loss: 0.2272148 Test Loss: 0.2899581
Validation loss decreased (0.228141 --> 0.227215).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.858832836151123
Epoch: 76, Steps: 63 | Train Loss: 0.1304522 Vali Loss: 0.2271624 Test Loss: 0.2899095
Validation loss decreased (0.227215 --> 0.227162).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.8784878253936768
Epoch: 77, Steps: 63 | Train Loss: 0.1296256 Vali Loss: 0.2284405 Test Loss: 0.2898501
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.6196098327636719
Epoch: 78, Steps: 63 | Train Loss: 0.1301831 Vali Loss: 0.2278119 Test Loss: 0.2898061
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.4445240497589111
Epoch: 79, Steps: 63 | Train Loss: 0.1296828 Vali Loss: 0.2280671 Test Loss: 0.2897618
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.5960898399353027
Epoch: 80, Steps: 63 | Train Loss: 0.1298982 Vali Loss: 0.2290872 Test Loss: 0.2897125
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.7381794452667236
Epoch: 81, Steps: 63 | Train Loss: 0.1300628 Vali Loss: 0.2272886 Test Loss: 0.2896743
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 2.2768406867980957
Epoch: 82, Steps: 63 | Train Loss: 0.1299501 Vali Loss: 0.2279593 Test Loss: 0.2896362
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.6296286582946777
Epoch: 83, Steps: 63 | Train Loss: 0.1299561 Vali Loss: 0.2281990 Test Loss: 0.2895925
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.7919602394104004
Epoch: 84, Steps: 63 | Train Loss: 0.1299608 Vali Loss: 0.2285597 Test Loss: 0.2895534
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.7749652862548828
Epoch: 85, Steps: 63 | Train Loss: 0.1297342 Vali Loss: 0.2286299 Test Loss: 0.2895165
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.8253014087677002
Epoch: 86, Steps: 63 | Train Loss: 0.1295187 Vali Loss: 0.2284281 Test Loss: 0.2894883
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.6926109790802002
Epoch: 87, Steps: 63 | Train Loss: 0.1295641 Vali Loss: 0.2278116 Test Loss: 0.2894541
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 2.073315143585205
Epoch: 88, Steps: 63 | Train Loss: 0.1296183 Vali Loss: 0.2269188 Test Loss: 0.2894221
Validation loss decreased (0.227162 --> 0.226919).  Saving model ...
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.692786455154419
Epoch: 89, Steps: 63 | Train Loss: 0.1296042 Vali Loss: 0.2274873 Test Loss: 0.2893976
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.8048160076141357
Epoch: 90, Steps: 63 | Train Loss: 0.1295642 Vali Loss: 0.2292495 Test Loss: 0.2893669
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.183586597442627
Epoch: 91, Steps: 63 | Train Loss: 0.1298152 Vali Loss: 0.2272123 Test Loss: 0.2893416
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.5991284847259521
Epoch: 92, Steps: 63 | Train Loss: 0.1295528 Vali Loss: 0.2271765 Test Loss: 0.2893166
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 2.066878080368042
Epoch: 93, Steps: 63 | Train Loss: 0.1295669 Vali Loss: 0.2271694 Test Loss: 0.2892968
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.7600722312927246
Epoch: 94, Steps: 63 | Train Loss: 0.1292969 Vali Loss: 0.2279956 Test Loss: 0.2892717
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.9119465351104736
Epoch: 95, Steps: 63 | Train Loss: 0.1291430 Vali Loss: 0.2281073 Test Loss: 0.2892532
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.5552644729614258
Epoch: 96, Steps: 63 | Train Loss: 0.1294380 Vali Loss: 0.2277448 Test Loss: 0.2892350
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 2.4652459621429443
Epoch: 97, Steps: 63 | Train Loss: 0.1292114 Vali Loss: 0.2281744 Test Loss: 0.2892154
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 2.0516130924224854
Epoch: 98, Steps: 63 | Train Loss: 0.1291815 Vali Loss: 0.2287538 Test Loss: 0.2891964
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.7664368152618408
Epoch: 99, Steps: 63 | Train Loss: 0.1296500 Vali Loss: 0.2276853 Test Loss: 0.2891769
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.652007818222046
Epoch: 100, Steps: 63 | Train Loss: 0.1285025 Vali Loss: 0.2279423 Test Loss: 0.2891613
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8185
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=42, out_features=53, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1994496.0
params:  2279.0
Trainable parameters:  2279
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.6981348991394043
Epoch: 1, Steps: 63 | Train Loss: 0.4177500 Vali Loss: 0.2205105 Test Loss: 0.2810023
Validation loss decreased (inf --> 0.220511).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.68800687789917
Epoch: 2, Steps: 63 | Train Loss: 0.4134876 Vali Loss: 0.2179719 Test Loss: 0.2793709
Validation loss decreased (0.220511 --> 0.217972).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.6143434047698975
Epoch: 3, Steps: 63 | Train Loss: 0.4084960 Vali Loss: 0.2172002 Test Loss: 0.2788817
Validation loss decreased (0.217972 --> 0.217200).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.8081369400024414
Epoch: 4, Steps: 63 | Train Loss: 0.4073762 Vali Loss: 0.2168659 Test Loss: 0.2787256
Validation loss decreased (0.217200 --> 0.216866).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.5520670413970947
Epoch: 5, Steps: 63 | Train Loss: 0.4062714 Vali Loss: 0.2178562 Test Loss: 0.2784374
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.9214870929718018
Epoch: 6, Steps: 63 | Train Loss: 0.4079915 Vali Loss: 0.2165724 Test Loss: 0.2781451
Validation loss decreased (0.216866 --> 0.216572).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.6951415538787842
Epoch: 7, Steps: 63 | Train Loss: 0.4070704 Vali Loss: 0.2167026 Test Loss: 0.2779252
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.920492172241211
Epoch: 8, Steps: 63 | Train Loss: 0.4048730 Vali Loss: 0.2157051 Test Loss: 0.2778844
Validation loss decreased (0.216572 --> 0.215705).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.0960886478424072
Epoch: 9, Steps: 63 | Train Loss: 0.4046563 Vali Loss: 0.2153923 Test Loss: 0.2777048
Validation loss decreased (0.215705 --> 0.215392).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.9039130210876465
Epoch: 10, Steps: 63 | Train Loss: 0.4036884 Vali Loss: 0.2160943 Test Loss: 0.2777967
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.6477899551391602
Epoch: 11, Steps: 63 | Train Loss: 0.4061279 Vali Loss: 0.2151490 Test Loss: 0.2778405
Validation loss decreased (0.215392 --> 0.215149).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.7170748710632324
Epoch: 12, Steps: 63 | Train Loss: 0.4028395 Vali Loss: 0.2154217 Test Loss: 0.2776065
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.8898591995239258
Epoch: 13, Steps: 63 | Train Loss: 0.4057796 Vali Loss: 0.2141065 Test Loss: 0.2776819
Validation loss decreased (0.215149 --> 0.214106).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.8423635959625244
Epoch: 14, Steps: 63 | Train Loss: 0.4056925 Vali Loss: 0.2154199 Test Loss: 0.2776859
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.98264741897583
Epoch: 15, Steps: 63 | Train Loss: 0.4022807 Vali Loss: 0.2151089 Test Loss: 0.2772701
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.6358656883239746
Epoch: 16, Steps: 63 | Train Loss: 0.4052627 Vali Loss: 0.2137605 Test Loss: 0.2773351
Validation loss decreased (0.214106 --> 0.213760).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.226858377456665
Epoch: 17, Steps: 63 | Train Loss: 0.4048578 Vali Loss: 0.2140928 Test Loss: 0.2772242
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.0408201217651367
Epoch: 18, Steps: 63 | Train Loss: 0.4037521 Vali Loss: 0.2150021 Test Loss: 0.2771626
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.673807144165039
Epoch: 19, Steps: 63 | Train Loss: 0.4061731 Vali Loss: 0.2144170 Test Loss: 0.2772157
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.7837917804718018
Epoch: 20, Steps: 63 | Train Loss: 0.4019452 Vali Loss: 0.2147438 Test Loss: 0.2771662
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.7332465648651123
Epoch: 21, Steps: 63 | Train Loss: 0.4047883 Vali Loss: 0.2131694 Test Loss: 0.2772050
Validation loss decreased (0.213760 --> 0.213169).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.9033570289611816
Epoch: 22, Steps: 63 | Train Loss: 0.4034751 Vali Loss: 0.2138829 Test Loss: 0.2771837
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.019103765487671
Epoch: 23, Steps: 63 | Train Loss: 0.4035129 Vali Loss: 0.2146783 Test Loss: 0.2770709
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.5014874935150146
Epoch: 24, Steps: 63 | Train Loss: 0.4043617 Vali Loss: 0.2154118 Test Loss: 0.2770191
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.920785903930664
Epoch: 25, Steps: 63 | Train Loss: 0.4021940 Vali Loss: 0.2139377 Test Loss: 0.2770143
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.865166187286377
Epoch: 26, Steps: 63 | Train Loss: 0.4043525 Vali Loss: 0.2142470 Test Loss: 0.2770308
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.5363996028900146
Epoch: 27, Steps: 63 | Train Loss: 0.4046399 Vali Loss: 0.2148889 Test Loss: 0.2769921
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.6136581897735596
Epoch: 28, Steps: 63 | Train Loss: 0.4044923 Vali Loss: 0.2147523 Test Loss: 0.2769701
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.6560273170471191
Epoch: 29, Steps: 63 | Train Loss: 0.4041656 Vali Loss: 0.2143435 Test Loss: 0.2769530
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.2327003479003906
Epoch: 30, Steps: 63 | Train Loss: 0.4031761 Vali Loss: 0.2138929 Test Loss: 0.2770326
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.0249483585357666
Epoch: 31, Steps: 63 | Train Loss: 0.4039154 Vali Loss: 0.2138033 Test Loss: 0.2769309
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.1840195655822754
Epoch: 32, Steps: 63 | Train Loss: 0.4029075 Vali Loss: 0.2138773 Test Loss: 0.2768743
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.8380472660064697
Epoch: 33, Steps: 63 | Train Loss: 0.4031912 Vali Loss: 0.2141383 Test Loss: 0.2769215
EarlyStopping counter: 12 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.9686319828033447
Epoch: 34, Steps: 63 | Train Loss: 0.4042491 Vali Loss: 0.2140875 Test Loss: 0.2769307
EarlyStopping counter: 13 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.200479745864868
Epoch: 35, Steps: 63 | Train Loss: 0.4021868 Vali Loss: 0.2144411 Test Loss: 0.2769814
EarlyStopping counter: 14 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.9221842288970947
Epoch: 36, Steps: 63 | Train Loss: 0.4048154 Vali Loss: 0.2141164 Test Loss: 0.2768874
EarlyStopping counter: 15 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.2241992950439453
Epoch: 37, Steps: 63 | Train Loss: 0.4016843 Vali Loss: 0.2130504 Test Loss: 0.2768946
Validation loss decreased (0.213169 --> 0.213050).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.09680438041687
Epoch: 38, Steps: 63 | Train Loss: 0.4047285 Vali Loss: 0.2148245 Test Loss: 0.2768855
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.024165630340576
Epoch: 39, Steps: 63 | Train Loss: 0.4041312 Vali Loss: 0.2143545 Test Loss: 0.2768701
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.876396894454956
Epoch: 40, Steps: 63 | Train Loss: 0.4026791 Vali Loss: 0.2145233 Test Loss: 0.2768544
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.7330455780029297
Epoch: 41, Steps: 63 | Train Loss: 0.4044089 Vali Loss: 0.2133687 Test Loss: 0.2768998
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.0078253746032715
Epoch: 42, Steps: 63 | Train Loss: 0.4037377 Vali Loss: 0.2134467 Test Loss: 0.2768806
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.8356692790985107
Epoch: 43, Steps: 63 | Train Loss: 0.4034864 Vali Loss: 0.2151559 Test Loss: 0.2768961
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.8944668769836426
Epoch: 44, Steps: 63 | Train Loss: 0.4038748 Vali Loss: 0.2141924 Test Loss: 0.2768887
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.7228574752807617
Epoch: 45, Steps: 63 | Train Loss: 0.4030638 Vali Loss: 0.2140309 Test Loss: 0.2768896
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.877934455871582
Epoch: 46, Steps: 63 | Train Loss: 0.4027186 Vali Loss: 0.2141669 Test Loss: 0.2768792
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.816817283630371
Epoch: 47, Steps: 63 | Train Loss: 0.4026956 Vali Loss: 0.2131875 Test Loss: 0.2768582
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.0261402130126953
Epoch: 48, Steps: 63 | Train Loss: 0.4026189 Vali Loss: 0.2139492 Test Loss: 0.2768826
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.694427490234375
Epoch: 49, Steps: 63 | Train Loss: 0.4027244 Vali Loss: 0.2140728 Test Loss: 0.2768131
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.0849239826202393
Epoch: 50, Steps: 63 | Train Loss: 0.4022024 Vali Loss: 0.2140069 Test Loss: 0.2768503
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.281757116317749
Epoch: 51, Steps: 63 | Train Loss: 0.4015517 Vali Loss: 0.2143468 Test Loss: 0.2768537
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.262158155441284
Epoch: 52, Steps: 63 | Train Loss: 0.4034360 Vali Loss: 0.2137342 Test Loss: 0.2768077
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.1531646251678467
Epoch: 53, Steps: 63 | Train Loss: 0.4044691 Vali Loss: 0.2138170 Test Loss: 0.2768215
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.101456880569458
Epoch: 54, Steps: 63 | Train Loss: 0.4044533 Vali Loss: 0.2154205 Test Loss: 0.2768399
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.889836311340332
Epoch: 55, Steps: 63 | Train Loss: 0.4026004 Vali Loss: 0.2137556 Test Loss: 0.2768465
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.6137590408325195
Epoch: 56, Steps: 63 | Train Loss: 0.4003999 Vali Loss: 0.2140571 Test Loss: 0.2768518
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.6445138454437256
Epoch: 57, Steps: 63 | Train Loss: 0.4021569 Vali Loss: 0.2140997 Test Loss: 0.2768734
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_360_96_FITS_ETTh2_ftM_sl360_ll48_pl96_H2_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.27663475275039673, mae:0.33863896131515503, rse:0.4238719642162323, corr:[0.27470276 0.2754298  0.27525988 0.2740876  0.27231303 0.27067584
 0.2695501  0.26857695 0.26771972 0.26655406 0.26514626 0.26347864
 0.26201588 0.26097447 0.26028162 0.2600049  0.259694   0.25934738
 0.25866902 0.25764805 0.25637624 0.25478137 0.25305983 0.25110215
 0.24917984 0.2474406  0.24610442 0.24484693 0.24347588 0.2419546
 0.24042316 0.23892139 0.23739308 0.23602466 0.2348612  0.23381162
 0.23276941 0.23163956 0.23073806 0.22995009 0.22933535 0.22887813
 0.22831209 0.22741726 0.22635455 0.22503741 0.22355336 0.22186168
 0.22003075 0.218399   0.21723056 0.21629919 0.21525587 0.21386114
 0.21190856 0.20959179 0.2075929  0.20594345 0.20483984 0.2044999
 0.20470811 0.2049422  0.20499338 0.20470408 0.20410426 0.20352075
 0.20305628 0.20258777 0.20215549 0.20159602 0.20090637 0.2000559
 0.1990388  0.19800487 0.19712533 0.19638745 0.19607502 0.1959683
 0.19556168 0.19453412 0.19360621 0.19263607 0.1919344  0.19163446
 0.19176239 0.19195034 0.19184488 0.19124658 0.18989694 0.18853715
 0.18749858 0.18685105 0.18696721 0.18676263 0.18480188 0.1794494 ]
