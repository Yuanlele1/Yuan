Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=58, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_180_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_180_96_FITS_ETTh2_ftM_sl180_ll48_pl96_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8365
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=58, out_features=88, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4573184.0
params:  5192.0
Trainable parameters:  5192
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.2734107971191406
Epoch: 1, Steps: 65 | Train Loss: 0.5775192 Vali Loss: 0.2679349 Test Loss: 0.3651477
Validation loss decreased (inf --> 0.267935).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.5256187915802002
Epoch: 2, Steps: 65 | Train Loss: 0.4841454 Vali Loss: 0.2409579 Test Loss: 0.3284129
Validation loss decreased (0.267935 --> 0.240958).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.5575292110443115
Epoch: 3, Steps: 65 | Train Loss: 0.4540532 Vali Loss: 0.2301310 Test Loss: 0.3151705
Validation loss decreased (0.240958 --> 0.230131).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.3121249675750732
Epoch: 4, Steps: 65 | Train Loss: 0.4422368 Vali Loss: 0.2240139 Test Loss: 0.3084661
Validation loss decreased (0.230131 --> 0.224014).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.7665090560913086
Epoch: 5, Steps: 65 | Train Loss: 0.4346782 Vali Loss: 0.2202062 Test Loss: 0.3042826
Validation loss decreased (0.224014 --> 0.220206).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.0793554782867432
Epoch: 6, Steps: 65 | Train Loss: 0.4302024 Vali Loss: 0.2186375 Test Loss: 0.3016495
Validation loss decreased (0.220206 --> 0.218637).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.145824909210205
Epoch: 7, Steps: 65 | Train Loss: 0.4251615 Vali Loss: 0.2180611 Test Loss: 0.2996041
Validation loss decreased (0.218637 --> 0.218061).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.3674533367156982
Epoch: 8, Steps: 65 | Train Loss: 0.4224469 Vali Loss: 0.2153442 Test Loss: 0.2982436
Validation loss decreased (0.218061 --> 0.215344).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.5813486576080322
Epoch: 9, Steps: 65 | Train Loss: 0.4214810 Vali Loss: 0.2160691 Test Loss: 0.2969633
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.1435861587524414
Epoch: 10, Steps: 65 | Train Loss: 0.4209271 Vali Loss: 0.2129208 Test Loss: 0.2959006
Validation loss decreased (0.215344 --> 0.212921).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.2335162162780762
Epoch: 11, Steps: 65 | Train Loss: 0.4175835 Vali Loss: 0.2128540 Test Loss: 0.2950734
Validation loss decreased (0.212921 --> 0.212854).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.6563520431518555
Epoch: 12, Steps: 65 | Train Loss: 0.4181909 Vali Loss: 0.2131827 Test Loss: 0.2944286
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.0559940338134766
Epoch: 13, Steps: 65 | Train Loss: 0.4154707 Vali Loss: 0.2127670 Test Loss: 0.2937645
Validation loss decreased (0.212854 --> 0.212767).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.4151866436004639
Epoch: 14, Steps: 65 | Train Loss: 0.4158682 Vali Loss: 0.2117203 Test Loss: 0.2932905
Validation loss decreased (0.212767 --> 0.211720).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.7093157768249512
Epoch: 15, Steps: 65 | Train Loss: 0.4147211 Vali Loss: 0.2104687 Test Loss: 0.2928061
Validation loss decreased (0.211720 --> 0.210469).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.6390595436096191
Epoch: 16, Steps: 65 | Train Loss: 0.4126421 Vali Loss: 0.2107239 Test Loss: 0.2923412
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.3844542503356934
Epoch: 17, Steps: 65 | Train Loss: 0.4136299 Vali Loss: 0.2107872 Test Loss: 0.2920026
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.4715847969055176
Epoch: 18, Steps: 65 | Train Loss: 0.4132688 Vali Loss: 0.2103259 Test Loss: 0.2916758
Validation loss decreased (0.210469 --> 0.210326).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.265066385269165
Epoch: 19, Steps: 65 | Train Loss: 0.4093500 Vali Loss: 0.2106372 Test Loss: 0.2913702
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.125173330307007
Epoch: 20, Steps: 65 | Train Loss: 0.4120539 Vali Loss: 0.2103108 Test Loss: 0.2911421
Validation loss decreased (0.210326 --> 0.210311).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.3551568984985352
Epoch: 21, Steps: 65 | Train Loss: 0.4117215 Vali Loss: 0.2100783 Test Loss: 0.2908821
Validation loss decreased (0.210311 --> 0.210078).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.0545413494110107
Epoch: 22, Steps: 65 | Train Loss: 0.4101917 Vali Loss: 0.2098427 Test Loss: 0.2907078
Validation loss decreased (0.210078 --> 0.209843).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.628431797027588
Epoch: 23, Steps: 65 | Train Loss: 0.4089349 Vali Loss: 0.2093272 Test Loss: 0.2904822
Validation loss decreased (0.209843 --> 0.209327).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.1564605236053467
Epoch: 24, Steps: 65 | Train Loss: 0.4089407 Vali Loss: 0.2076700 Test Loss: 0.2902544
Validation loss decreased (0.209327 --> 0.207670).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.7951436042785645
Epoch: 25, Steps: 65 | Train Loss: 0.4104542 Vali Loss: 0.2091301 Test Loss: 0.2901237
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.4236571788787842
Epoch: 26, Steps: 65 | Train Loss: 0.4102085 Vali Loss: 0.2093886 Test Loss: 0.2900082
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.3910353183746338
Epoch: 27, Steps: 65 | Train Loss: 0.4095108 Vali Loss: 0.2096231 Test Loss: 0.2898947
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.5014612674713135
Epoch: 28, Steps: 65 | Train Loss: 0.4089682 Vali Loss: 0.2093286 Test Loss: 0.2897838
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.32588791847229
Epoch: 29, Steps: 65 | Train Loss: 0.4095818 Vali Loss: 0.2088879 Test Loss: 0.2896649
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.660320520401001
Epoch: 30, Steps: 65 | Train Loss: 0.4090384 Vali Loss: 0.2087717 Test Loss: 0.2895536
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.2398231029510498
Epoch: 31, Steps: 65 | Train Loss: 0.4087470 Vali Loss: 0.2098249 Test Loss: 0.2894765
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.3924312591552734
Epoch: 32, Steps: 65 | Train Loss: 0.4083797 Vali Loss: 0.2091648 Test Loss: 0.2894146
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.4561247825622559
Epoch: 33, Steps: 65 | Train Loss: 0.4089095 Vali Loss: 0.2087247 Test Loss: 0.2893128
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.9559400081634521
Epoch: 34, Steps: 65 | Train Loss: 0.4068669 Vali Loss: 0.2087606 Test Loss: 0.2892354
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 0.9997568130493164
Epoch: 35, Steps: 65 | Train Loss: 0.4073853 Vali Loss: 0.2079840 Test Loss: 0.2891146
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.379328966140747
Epoch: 36, Steps: 65 | Train Loss: 0.4081131 Vali Loss: 0.2091448 Test Loss: 0.2891109
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.159613609313965
Epoch: 37, Steps: 65 | Train Loss: 0.4079928 Vali Loss: 0.2087223 Test Loss: 0.2890003
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.775989055633545
Epoch: 38, Steps: 65 | Train Loss: 0.4068383 Vali Loss: 0.2082398 Test Loss: 0.2889584
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.3942680358886719
Epoch: 39, Steps: 65 | Train Loss: 0.4081885 Vali Loss: 0.2083490 Test Loss: 0.2889070
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.4087409973144531
Epoch: 40, Steps: 65 | Train Loss: 0.4071332 Vali Loss: 0.2073791 Test Loss: 0.2888573
Validation loss decreased (0.207670 --> 0.207379).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.180743932723999
Epoch: 41, Steps: 65 | Train Loss: 0.4076857 Vali Loss: 0.2082087 Test Loss: 0.2888150
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.3340976238250732
Epoch: 42, Steps: 65 | Train Loss: 0.4057810 Vali Loss: 0.2080829 Test Loss: 0.2887570
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.4490234851837158
Epoch: 43, Steps: 65 | Train Loss: 0.4073064 Vali Loss: 0.2087845 Test Loss: 0.2887321
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.3556270599365234
Epoch: 44, Steps: 65 | Train Loss: 0.4072056 Vali Loss: 0.2087702 Test Loss: 0.2886792
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.1776926517486572
Epoch: 45, Steps: 65 | Train Loss: 0.4047022 Vali Loss: 0.2072228 Test Loss: 0.2886429
Validation loss decreased (0.207379 --> 0.207223).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.1904404163360596
Epoch: 46, Steps: 65 | Train Loss: 0.4074727 Vali Loss: 0.2088887 Test Loss: 0.2885987
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.2343778610229492
Epoch: 47, Steps: 65 | Train Loss: 0.4067129 Vali Loss: 0.2078887 Test Loss: 0.2885601
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.5935332775115967
Epoch: 48, Steps: 65 | Train Loss: 0.4056720 Vali Loss: 0.2081169 Test Loss: 0.2885209
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.0820047855377197
Epoch: 49, Steps: 65 | Train Loss: 0.4073721 Vali Loss: 0.2077403 Test Loss: 0.2885099
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.6917712688446045
Epoch: 50, Steps: 65 | Train Loss: 0.4069624 Vali Loss: 0.2077434 Test Loss: 0.2884802
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.2992489337921143
Epoch: 51, Steps: 65 | Train Loss: 0.4047502 Vali Loss: 0.2074853 Test Loss: 0.2884678
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.592846393585205
Epoch: 52, Steps: 65 | Train Loss: 0.4070927 Vali Loss: 0.2079638 Test Loss: 0.2884248
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.8839571475982666
Epoch: 53, Steps: 65 | Train Loss: 0.4063628 Vali Loss: 0.2079581 Test Loss: 0.2884251
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.4148483276367188
Epoch: 54, Steps: 65 | Train Loss: 0.4059140 Vali Loss: 0.2069520 Test Loss: 0.2883767
Validation loss decreased (0.207223 --> 0.206952).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.5909347534179688
Epoch: 55, Steps: 65 | Train Loss: 0.4050240 Vali Loss: 0.2079504 Test Loss: 0.2883697
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.7037551403045654
Epoch: 56, Steps: 65 | Train Loss: 0.4060964 Vali Loss: 0.2073250 Test Loss: 0.2883528
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.4086213111877441
Epoch: 57, Steps: 65 | Train Loss: 0.4069450 Vali Loss: 0.2072806 Test Loss: 0.2883456
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.9106247425079346
Epoch: 58, Steps: 65 | Train Loss: 0.4054553 Vali Loss: 0.2076781 Test Loss: 0.2883248
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.6974091529846191
Epoch: 59, Steps: 65 | Train Loss: 0.4064568 Vali Loss: 0.2080118 Test Loss: 0.2883150
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.666860580444336
Epoch: 60, Steps: 65 | Train Loss: 0.4059991 Vali Loss: 0.2074699 Test Loss: 0.2883032
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.2963776588439941
Epoch: 61, Steps: 65 | Train Loss: 0.4062339 Vali Loss: 0.2081713 Test Loss: 0.2882799
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.1321113109588623
Epoch: 62, Steps: 65 | Train Loss: 0.4054977 Vali Loss: 0.2076723 Test Loss: 0.2882753
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.3718791007995605
Epoch: 63, Steps: 65 | Train Loss: 0.4066494 Vali Loss: 0.2084460 Test Loss: 0.2882729
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.3002009391784668
Epoch: 64, Steps: 65 | Train Loss: 0.4069961 Vali Loss: 0.2072633 Test Loss: 0.2882475
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.2095856666564941
Epoch: 65, Steps: 65 | Train Loss: 0.4063796 Vali Loss: 0.2071797 Test Loss: 0.2882394
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.7516982555389404
Epoch: 66, Steps: 65 | Train Loss: 0.4057866 Vali Loss: 0.2074809 Test Loss: 0.2882279
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.5180025100708008
Epoch: 67, Steps: 65 | Train Loss: 0.4068569 Vali Loss: 0.2075221 Test Loss: 0.2882231
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.3042936325073242
Epoch: 68, Steps: 65 | Train Loss: 0.4065356 Vali Loss: 0.2077481 Test Loss: 0.2882085
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.667243480682373
Epoch: 69, Steps: 65 | Train Loss: 0.4057675 Vali Loss: 0.2075284 Test Loss: 0.2882053
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.7495853900909424
Epoch: 70, Steps: 65 | Train Loss: 0.4028899 Vali Loss: 0.2069366 Test Loss: 0.2881933
Validation loss decreased (0.206952 --> 0.206937).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.4969751834869385
Epoch: 71, Steps: 65 | Train Loss: 0.4065277 Vali Loss: 0.2075613 Test Loss: 0.2881841
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.3736703395843506
Epoch: 72, Steps: 65 | Train Loss: 0.4049071 Vali Loss: 0.2079992 Test Loss: 0.2881764
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.3938379287719727
Epoch: 73, Steps: 65 | Train Loss: 0.4041263 Vali Loss: 0.2075787 Test Loss: 0.2881677
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.2789390087127686
Epoch: 74, Steps: 65 | Train Loss: 0.4054397 Vali Loss: 0.2084150 Test Loss: 0.2881658
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.3635141849517822
Epoch: 75, Steps: 65 | Train Loss: 0.4059990 Vali Loss: 0.2072633 Test Loss: 0.2881557
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.665304183959961
Epoch: 76, Steps: 65 | Train Loss: 0.4065708 Vali Loss: 0.2079477 Test Loss: 0.2881513
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.168137550354004
Epoch: 77, Steps: 65 | Train Loss: 0.4055046 Vali Loss: 0.2076578 Test Loss: 0.2881453
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.619765281677246
Epoch: 78, Steps: 65 | Train Loss: 0.4059111 Vali Loss: 0.2071313 Test Loss: 0.2881422
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.522367000579834
Epoch: 79, Steps: 65 | Train Loss: 0.4060854 Vali Loss: 0.2078765 Test Loss: 0.2881334
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.1996026039123535
Epoch: 80, Steps: 65 | Train Loss: 0.4062636 Vali Loss: 0.2079607 Test Loss: 0.2881317
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.424368143081665
Epoch: 81, Steps: 65 | Train Loss: 0.4057846 Vali Loss: 0.2073685 Test Loss: 0.2881236
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.2935078144073486
Epoch: 82, Steps: 65 | Train Loss: 0.4069137 Vali Loss: 0.2079199 Test Loss: 0.2881180
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.0862278938293457
Epoch: 83, Steps: 65 | Train Loss: 0.4063474 Vali Loss: 0.2071293 Test Loss: 0.2881193
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.227874755859375
Epoch: 84, Steps: 65 | Train Loss: 0.4050653 Vali Loss: 0.2069638 Test Loss: 0.2881154
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.242103099822998
Epoch: 85, Steps: 65 | Train Loss: 0.4038443 Vali Loss: 0.2071044 Test Loss: 0.2881065
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.0492205619812012
Epoch: 86, Steps: 65 | Train Loss: 0.4061013 Vali Loss: 0.2078282 Test Loss: 0.2881047
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.5985608100891113
Epoch: 87, Steps: 65 | Train Loss: 0.4065455 Vali Loss: 0.2068747 Test Loss: 0.2881031
Validation loss decreased (0.206937 --> 0.206875).  Saving model ...
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.3849952220916748
Epoch: 88, Steps: 65 | Train Loss: 0.4067392 Vali Loss: 0.2072912 Test Loss: 0.2880997
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.180925130844116
Epoch: 89, Steps: 65 | Train Loss: 0.4067174 Vali Loss: 0.2067600 Test Loss: 0.2880986
Validation loss decreased (0.206875 --> 0.206760).  Saving model ...
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.136596441268921
Epoch: 90, Steps: 65 | Train Loss: 0.4057824 Vali Loss: 0.2078175 Test Loss: 0.2880941
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.1013975143432617
Epoch: 91, Steps: 65 | Train Loss: 0.4066706 Vali Loss: 0.2072041 Test Loss: 0.2880896
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.2839019298553467
Epoch: 92, Steps: 65 | Train Loss: 0.4059147 Vali Loss: 0.2082361 Test Loss: 0.2880867
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.6822178363800049
Epoch: 93, Steps: 65 | Train Loss: 0.4039044 Vali Loss: 0.2073458 Test Loss: 0.2880853
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 0.9822564125061035
Epoch: 94, Steps: 65 | Train Loss: 0.4059305 Vali Loss: 0.2071206 Test Loss: 0.2880817
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.1683688163757324
Epoch: 95, Steps: 65 | Train Loss: 0.4041682 Vali Loss: 0.2079202 Test Loss: 0.2880796
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.6573066711425781
Epoch: 96, Steps: 65 | Train Loss: 0.4057628 Vali Loss: 0.2071303 Test Loss: 0.2880804
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.8073079586029053
Epoch: 97, Steps: 65 | Train Loss: 0.4030450 Vali Loss: 0.2074459 Test Loss: 0.2880772
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.9880998134613037
Epoch: 98, Steps: 65 | Train Loss: 0.4067341 Vali Loss: 0.2083431 Test Loss: 0.2880752
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.2507290840148926
Epoch: 99, Steps: 65 | Train Loss: 0.4064923 Vali Loss: 0.2073854 Test Loss: 0.2880730
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.2248799800872803
Epoch: 100, Steps: 65 | Train Loss: 0.4064871 Vali Loss: 0.2078311 Test Loss: 0.2880730
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.1160680107021042e-06
>>>>>>>testing : ETTh2_180_96_FITS_ETTh2_ftM_sl180_ll48_pl96_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.28781381249427795, mae:0.34055963158607483, rse:0.43235164880752563, corr:[0.27271742 0.27712098 0.27501303 0.2765355  0.2747879  0.2734147
 0.2731576  0.2717048  0.27043763 0.26937076 0.2680534  0.2664668
 0.2647151  0.2634912  0.26276997 0.26202494 0.26154003 0.26086304
 0.25985602 0.25889125 0.25761363 0.25642583 0.25547382 0.2532991
 0.2501851  0.24828082 0.24639812 0.2443103  0.24309413 0.24156865
 0.23927164 0.23782073 0.23605967 0.2336214  0.23257798 0.2314855
 0.22914732 0.22805664 0.2277667  0.22587353 0.22515832 0.22537303
 0.22404912 0.22288167 0.22270581 0.22106184 0.21954675 0.21847218
 0.21500377 0.21222512 0.2113545  0.2091205  0.2067596  0.20640503
 0.20406787 0.20082538 0.20035778 0.19892642 0.19648722 0.19620581
 0.19589573 0.19400759 0.19488907 0.19523868 0.19361684 0.19362079
 0.1935845  0.19144168 0.19143508 0.19195028 0.1898522  0.18892147
 0.18776186 0.18480164 0.18385929 0.18392889 0.18098485 0.18028472
 0.18154363 0.17945823 0.1785452  0.1802084  0.1795177  0.17885196
 0.18070522 0.1797043  0.17956543 0.18184707 0.1805068  0.17912789
 0.18153478 0.17931294 0.17917909 0.18309815 0.17973623 0.18533924]
