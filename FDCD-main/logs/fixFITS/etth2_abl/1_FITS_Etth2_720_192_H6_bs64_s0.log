Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=0, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=196, out_features=248, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  43552768.0
params:  48856.0
Trainable parameters:  48856
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.5017452239990234
Epoch: 1, Steps: 60 | Train Loss: 0.7150881 Vali Loss: 0.3810891 Test Loss: 0.3906355
Validation loss decreased (inf --> 0.381089).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.5186312198638916
Epoch: 2, Steps: 60 | Train Loss: 0.5846249 Vali Loss: 0.3361616 Test Loss: 0.3708880
Validation loss decreased (0.381089 --> 0.336162).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.466005563735962
Epoch: 3, Steps: 60 | Train Loss: 0.5596650 Vali Loss: 0.3202412 Test Loss: 0.3641089
Validation loss decreased (0.336162 --> 0.320241).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.5892541408538818
Epoch: 4, Steps: 60 | Train Loss: 0.5459243 Vali Loss: 0.3117464 Test Loss: 0.3612020
Validation loss decreased (0.320241 --> 0.311746).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.4357123374938965
Epoch: 5, Steps: 60 | Train Loss: 0.5371239 Vali Loss: 0.3064296 Test Loss: 0.3594832
Validation loss decreased (0.311746 --> 0.306430).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.2987217903137207
Epoch: 6, Steps: 60 | Train Loss: 0.5327242 Vali Loss: 0.3030907 Test Loss: 0.3581465
Validation loss decreased (0.306430 --> 0.303091).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.503711462020874
Epoch: 7, Steps: 60 | Train Loss: 0.5298579 Vali Loss: 0.3001555 Test Loss: 0.3575858
Validation loss decreased (0.303091 --> 0.300155).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.6832776069641113
Epoch: 8, Steps: 60 | Train Loss: 0.5276696 Vali Loss: 0.2984902 Test Loss: 0.3566955
Validation loss decreased (0.300155 --> 0.298490).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.511655330657959
Epoch: 9, Steps: 60 | Train Loss: 0.5231485 Vali Loss: 0.2962497 Test Loss: 0.3562923
Validation loss decreased (0.298490 --> 0.296250).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.6358366012573242
Epoch: 10, Steps: 60 | Train Loss: 0.5209815 Vali Loss: 0.2944315 Test Loss: 0.3559351
Validation loss decreased (0.296250 --> 0.294432).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.3180084228515625
Epoch: 11, Steps: 60 | Train Loss: 0.5210488 Vali Loss: 0.2936087 Test Loss: 0.3554602
Validation loss decreased (0.294432 --> 0.293609).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.4540603160858154
Epoch: 12, Steps: 60 | Train Loss: 0.5208765 Vali Loss: 0.2927131 Test Loss: 0.3551300
Validation loss decreased (0.293609 --> 0.292713).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.5061440467834473
Epoch: 13, Steps: 60 | Train Loss: 0.5171586 Vali Loss: 0.2918316 Test Loss: 0.3548000
Validation loss decreased (0.292713 --> 0.291832).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.6661067008972168
Epoch: 14, Steps: 60 | Train Loss: 0.5180760 Vali Loss: 0.2909653 Test Loss: 0.3546337
Validation loss decreased (0.291832 --> 0.290965).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.3686749935150146
Epoch: 15, Steps: 60 | Train Loss: 0.5182914 Vali Loss: 0.2901421 Test Loss: 0.3543934
Validation loss decreased (0.290965 --> 0.290142).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.6331381797790527
Epoch: 16, Steps: 60 | Train Loss: 0.5169607 Vali Loss: 0.2894017 Test Loss: 0.3542254
Validation loss decreased (0.290142 --> 0.289402).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.4900686740875244
Epoch: 17, Steps: 60 | Train Loss: 0.5166722 Vali Loss: 0.2891442 Test Loss: 0.3541055
Validation loss decreased (0.289402 --> 0.289144).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.3979437351226807
Epoch: 18, Steps: 60 | Train Loss: 0.5148290 Vali Loss: 0.2884468 Test Loss: 0.3540505
Validation loss decreased (0.289144 --> 0.288447).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.42582106590271
Epoch: 19, Steps: 60 | Train Loss: 0.5149494 Vali Loss: 0.2880776 Test Loss: 0.3538412
Validation loss decreased (0.288447 --> 0.288078).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.3912408351898193
Epoch: 20, Steps: 60 | Train Loss: 0.5131249 Vali Loss: 0.2873830 Test Loss: 0.3538166
Validation loss decreased (0.288078 --> 0.287383).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.444652795791626
Epoch: 21, Steps: 60 | Train Loss: 0.5150188 Vali Loss: 0.2870618 Test Loss: 0.3536786
Validation loss decreased (0.287383 --> 0.287062).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.4180407524108887
Epoch: 22, Steps: 60 | Train Loss: 0.5138934 Vali Loss: 0.2872071 Test Loss: 0.3534578
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.3202357292175293
Epoch: 23, Steps: 60 | Train Loss: 0.5124463 Vali Loss: 0.2866036 Test Loss: 0.3534213
Validation loss decreased (0.287062 --> 0.286604).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.47538423538208
Epoch: 24, Steps: 60 | Train Loss: 0.5126841 Vali Loss: 0.2864704 Test Loss: 0.3532667
Validation loss decreased (0.286604 --> 0.286470).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.4699296951293945
Epoch: 25, Steps: 60 | Train Loss: 0.5101493 Vali Loss: 0.2861499 Test Loss: 0.3532724
Validation loss decreased (0.286470 --> 0.286150).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.4582724571228027
Epoch: 26, Steps: 60 | Train Loss: 0.5103922 Vali Loss: 0.2857167 Test Loss: 0.3533307
Validation loss decreased (0.286150 --> 0.285717).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.4701063632965088
Epoch: 27, Steps: 60 | Train Loss: 0.5136701 Vali Loss: 0.2858073 Test Loss: 0.3531191
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.367095708847046
Epoch: 28, Steps: 60 | Train Loss: 0.5121600 Vali Loss: 0.2854661 Test Loss: 0.3531340
Validation loss decreased (0.285717 --> 0.285466).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.3502628803253174
Epoch: 29, Steps: 60 | Train Loss: 0.5118867 Vali Loss: 0.2853977 Test Loss: 0.3531523
Validation loss decreased (0.285466 --> 0.285398).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.4149627685546875
Epoch: 30, Steps: 60 | Train Loss: 0.5104707 Vali Loss: 0.2852599 Test Loss: 0.3529844
Validation loss decreased (0.285398 --> 0.285260).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.5193376541137695
Epoch: 31, Steps: 60 | Train Loss: 0.5112586 Vali Loss: 0.2848598 Test Loss: 0.3530217
Validation loss decreased (0.285260 --> 0.284860).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.2958831787109375
Epoch: 32, Steps: 60 | Train Loss: 0.5124972 Vali Loss: 0.2848793 Test Loss: 0.3529145
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.4353885650634766
Epoch: 33, Steps: 60 | Train Loss: 0.5118012 Vali Loss: 0.2849594 Test Loss: 0.3528093
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.4220101833343506
Epoch: 34, Steps: 60 | Train Loss: 0.5117578 Vali Loss: 0.2846604 Test Loss: 0.3527967
Validation loss decreased (0.284860 --> 0.284660).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.355393648147583
Epoch: 35, Steps: 60 | Train Loss: 0.5097899 Vali Loss: 0.2846819 Test Loss: 0.3527974
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.4661102294921875
Epoch: 36, Steps: 60 | Train Loss: 0.5101034 Vali Loss: 0.2845820 Test Loss: 0.3527521
Validation loss decreased (0.284660 --> 0.284582).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.5727603435516357
Epoch: 37, Steps: 60 | Train Loss: 0.5110001 Vali Loss: 0.2840784 Test Loss: 0.3527553
Validation loss decreased (0.284582 --> 0.284078).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.4939236640930176
Epoch: 38, Steps: 60 | Train Loss: 0.5105777 Vali Loss: 0.2843834 Test Loss: 0.3527708
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.3210206031799316
Epoch: 39, Steps: 60 | Train Loss: 0.5099841 Vali Loss: 0.2842316 Test Loss: 0.3527127
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.4934966564178467
Epoch: 40, Steps: 60 | Train Loss: 0.5090444 Vali Loss: 0.2840756 Test Loss: 0.3526917
Validation loss decreased (0.284078 --> 0.284076).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.5602524280548096
Epoch: 41, Steps: 60 | Train Loss: 0.5111448 Vali Loss: 0.2840107 Test Loss: 0.3526528
Validation loss decreased (0.284076 --> 0.284011).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.5615472793579102
Epoch: 42, Steps: 60 | Train Loss: 0.5099625 Vali Loss: 0.2839475 Test Loss: 0.3526790
Validation loss decreased (0.284011 --> 0.283947).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.4728896617889404
Epoch: 43, Steps: 60 | Train Loss: 0.5109026 Vali Loss: 0.2838511 Test Loss: 0.3526194
Validation loss decreased (0.283947 --> 0.283851).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.3961992263793945
Epoch: 44, Steps: 60 | Train Loss: 0.5105458 Vali Loss: 0.2837627 Test Loss: 0.3526079
Validation loss decreased (0.283851 --> 0.283763).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.3762996196746826
Epoch: 45, Steps: 60 | Train Loss: 0.5104900 Vali Loss: 0.2837087 Test Loss: 0.3525972
Validation loss decreased (0.283763 --> 0.283709).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.475196361541748
Epoch: 46, Steps: 60 | Train Loss: 0.5088210 Vali Loss: 0.2835998 Test Loss: 0.3525761
Validation loss decreased (0.283709 --> 0.283600).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.3436989784240723
Epoch: 47, Steps: 60 | Train Loss: 0.5092511 Vali Loss: 0.2836268 Test Loss: 0.3525450
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.456247091293335
Epoch: 48, Steps: 60 | Train Loss: 0.5105550 Vali Loss: 0.2835915 Test Loss: 0.3525568
Validation loss decreased (0.283600 --> 0.283592).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.443871259689331
Epoch: 49, Steps: 60 | Train Loss: 0.5102578 Vali Loss: 0.2833198 Test Loss: 0.3525091
Validation loss decreased (0.283592 --> 0.283320).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.3983745574951172
Epoch: 50, Steps: 60 | Train Loss: 0.5103963 Vali Loss: 0.2833889 Test Loss: 0.3525206
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.3054981231689453
Epoch: 51, Steps: 60 | Train Loss: 0.5108838 Vali Loss: 0.2834260 Test Loss: 0.3525195
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.325746774673462
Epoch: 52, Steps: 60 | Train Loss: 0.5080953 Vali Loss: 0.2834123 Test Loss: 0.3524910
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.3368644714355469
Epoch: 53, Steps: 60 | Train Loss: 0.5105201 Vali Loss: 0.2832972 Test Loss: 0.3524777
Validation loss decreased (0.283320 --> 0.283297).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.410346508026123
Epoch: 54, Steps: 60 | Train Loss: 0.5096456 Vali Loss: 0.2830640 Test Loss: 0.3524739
Validation loss decreased (0.283297 --> 0.283064).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.434748888015747
Epoch: 55, Steps: 60 | Train Loss: 0.5098748 Vali Loss: 0.2833182 Test Loss: 0.3524265
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.4046061038970947
Epoch: 56, Steps: 60 | Train Loss: 0.5081599 Vali Loss: 0.2832301 Test Loss: 0.3524589
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.4264683723449707
Epoch: 57, Steps: 60 | Train Loss: 0.5084896 Vali Loss: 0.2831623 Test Loss: 0.3524141
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.3745310306549072
Epoch: 58, Steps: 60 | Train Loss: 0.5084363 Vali Loss: 0.2830572 Test Loss: 0.3524381
Validation loss decreased (0.283064 --> 0.283057).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.8641455173492432
Epoch: 59, Steps: 60 | Train Loss: 0.5097793 Vali Loss: 0.2831828 Test Loss: 0.3524103
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.3029892444610596
Epoch: 60, Steps: 60 | Train Loss: 0.5097000 Vali Loss: 0.2830580 Test Loss: 0.3524014
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.3756535053253174
Epoch: 61, Steps: 60 | Train Loss: 0.5094629 Vali Loss: 0.2827720 Test Loss: 0.3523880
Validation loss decreased (0.283057 --> 0.282772).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.3918051719665527
Epoch: 62, Steps: 60 | Train Loss: 0.5087631 Vali Loss: 0.2830562 Test Loss: 0.3523974
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.4576020240783691
Epoch: 63, Steps: 60 | Train Loss: 0.5093364 Vali Loss: 0.2830831 Test Loss: 0.3523946
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.3931474685668945
Epoch: 64, Steps: 60 | Train Loss: 0.5096846 Vali Loss: 0.2830575 Test Loss: 0.3523824
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.8673598766326904
Epoch: 65, Steps: 60 | Train Loss: 0.5103056 Vali Loss: 0.2830989 Test Loss: 0.3523723
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.2319085597991943
Epoch: 66, Steps: 60 | Train Loss: 0.5091916 Vali Loss: 0.2830152 Test Loss: 0.3523692
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.6452915668487549
Epoch: 67, Steps: 60 | Train Loss: 0.5090164 Vali Loss: 0.2830108 Test Loss: 0.3523692
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.8282556533813477
Epoch: 68, Steps: 60 | Train Loss: 0.5105842 Vali Loss: 0.2830059 Test Loss: 0.3523647
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.4201738834381104
Epoch: 69, Steps: 60 | Train Loss: 0.5087631 Vali Loss: 0.2829752 Test Loss: 0.3523709
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.3567314147949219
Epoch: 70, Steps: 60 | Train Loss: 0.5097356 Vali Loss: 0.2830323 Test Loss: 0.3523529
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.689831018447876
Epoch: 71, Steps: 60 | Train Loss: 0.5083477 Vali Loss: 0.2829904 Test Loss: 0.3523493
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.4238030910491943
Epoch: 72, Steps: 60 | Train Loss: 0.5094957 Vali Loss: 0.2829550 Test Loss: 0.3523515
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.4267492294311523
Epoch: 73, Steps: 60 | Train Loss: 0.5091443 Vali Loss: 0.2829441 Test Loss: 0.3523432
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.933126449584961
Epoch: 74, Steps: 60 | Train Loss: 0.5104762 Vali Loss: 0.2825226 Test Loss: 0.3523472
Validation loss decreased (0.282772 --> 0.282523).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.6072068214416504
Epoch: 75, Steps: 60 | Train Loss: 0.5097656 Vali Loss: 0.2829767 Test Loss: 0.3523369
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.447270393371582
Epoch: 76, Steps: 60 | Train Loss: 0.5092645 Vali Loss: 0.2829491 Test Loss: 0.3523381
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.367671012878418
Epoch: 77, Steps: 60 | Train Loss: 0.5102644 Vali Loss: 0.2826413 Test Loss: 0.3523294
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.3826322555541992
Epoch: 78, Steps: 60 | Train Loss: 0.5094158 Vali Loss: 0.2825788 Test Loss: 0.3523224
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.3420283794403076
Epoch: 79, Steps: 60 | Train Loss: 0.5077894 Vali Loss: 0.2829269 Test Loss: 0.3523202
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.4476981163024902
Epoch: 80, Steps: 60 | Train Loss: 0.5092172 Vali Loss: 0.2829369 Test Loss: 0.3523210
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.5520408153533936
Epoch: 81, Steps: 60 | Train Loss: 0.5090141 Vali Loss: 0.2829076 Test Loss: 0.3523278
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.470036506652832
Epoch: 82, Steps: 60 | Train Loss: 0.5085524 Vali Loss: 0.2828736 Test Loss: 0.3523273
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.3715169429779053
Epoch: 83, Steps: 60 | Train Loss: 0.5085831 Vali Loss: 0.2828948 Test Loss: 0.3523180
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.3886830806732178
Epoch: 84, Steps: 60 | Train Loss: 0.5093454 Vali Loss: 0.2827770 Test Loss: 0.3523209
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.3718304634094238
Epoch: 85, Steps: 60 | Train Loss: 0.5098143 Vali Loss: 0.2828813 Test Loss: 0.3523176
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.436908483505249
Epoch: 86, Steps: 60 | Train Loss: 0.5082467 Vali Loss: 0.2828489 Test Loss: 0.3523215
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.3737149238586426
Epoch: 87, Steps: 60 | Train Loss: 0.5095189 Vali Loss: 0.2828091 Test Loss: 0.3523141
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.7683277130126953
Epoch: 88, Steps: 60 | Train Loss: 0.5084297 Vali Loss: 0.2827979 Test Loss: 0.3523104
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.3984665870666504
Epoch: 89, Steps: 60 | Train Loss: 0.5094960 Vali Loss: 0.2828078 Test Loss: 0.3523111
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.3857300281524658
Epoch: 90, Steps: 60 | Train Loss: 0.5090701 Vali Loss: 0.2828185 Test Loss: 0.3523078
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.425079345703125
Epoch: 91, Steps: 60 | Train Loss: 0.5082193 Vali Loss: 0.2828136 Test Loss: 0.3523049
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.7736742496490479
Epoch: 92, Steps: 60 | Train Loss: 0.5070291 Vali Loss: 0.2828296 Test Loss: 0.3523084
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.4727730751037598
Epoch: 93, Steps: 60 | Train Loss: 0.5083315 Vali Loss: 0.2826909 Test Loss: 0.3523049
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.4323794841766357
Epoch: 94, Steps: 60 | Train Loss: 0.5103006 Vali Loss: 0.2827955 Test Loss: 0.3523062
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.3315489590167999, mae:0.3746451735496521, rse:0.46175825595855713, corr:[0.26284552 0.26743457 0.26595846 0.26721928 0.266876   0.26553234
 0.265519   0.26539445 0.26409087 0.26289073 0.262066   0.2609212
 0.25952542 0.25825527 0.2576086  0.25736377 0.25693694 0.2562482
 0.2554137  0.25423092 0.25275198 0.2516074  0.25058836 0.24888171
 0.24662349 0.24493654 0.24373089 0.24202485 0.24024883 0.23917407
 0.23820682 0.23642637 0.23505083 0.23433106 0.23309071 0.23135439
 0.2304553  0.23010325 0.22886905 0.22749758 0.22720866 0.22699869
 0.22585939 0.22472136 0.22415036 0.22320956 0.22157016 0.22002928
 0.21863176 0.2167358  0.21476276 0.21349011 0.21231893 0.21023422
 0.20805399 0.2067634  0.20514053 0.20295851 0.2017522  0.20110491
 0.20002574 0.19919774 0.19951902 0.1996488  0.19866711 0.19812007
 0.19809206 0.19742551 0.1963737  0.19590183 0.19544528 0.19422907
 0.19298013 0.19243008 0.191525   0.18976751 0.18889612 0.18889102
 0.18821262 0.18697357 0.18688306 0.18685134 0.18590045 0.18521844
 0.1854234  0.1853999  0.18464562 0.18437198 0.18439743 0.1838191
 0.1829408  0.18275319 0.18295434 0.18226434 0.18160374 0.1817361
 0.18139753 0.17999144 0.17888339 0.17846751 0.17756313 0.17602375
 0.17530872 0.17498487 0.17422631 0.17333166 0.17320487 0.17330156
 0.17239495 0.1715262  0.17110759 0.17062059 0.1697308  0.16950452
 0.16934799 0.16846605 0.1676068  0.16702703 0.16608417 0.1642132
 0.16262712 0.16152743 0.16032311 0.15890296 0.15795176 0.15721501
 0.15614352 0.15508436 0.15464115 0.15387306 0.15269452 0.15185404
 0.15155835 0.150764   0.14984103 0.14976542 0.1496733  0.14885677
 0.14803931 0.14776264 0.14735162 0.1465642  0.14608462 0.14512998
 0.14288744 0.14089231 0.14004181 0.13893767 0.13712716 0.13625088
 0.13642344 0.13528925 0.1339696  0.13393196 0.13398002 0.13266018
 0.13192071 0.13263066 0.13303061 0.13259856 0.13231331 0.13282141
 0.13245228 0.1315358  0.13182259 0.13222541 0.13167031 0.13079005
 0.1303133  0.12865683 0.12697281 0.12668046 0.12661262 0.12425803
 0.12223673 0.12188074 0.12081689 0.11889803 0.11819    0.11888181
 0.11768659 0.11669649 0.11870763 0.11990524 0.11795229 0.11839952
 0.12001959 0.1177109  0.11826093 0.12292553 0.12137305 0.12309805]
