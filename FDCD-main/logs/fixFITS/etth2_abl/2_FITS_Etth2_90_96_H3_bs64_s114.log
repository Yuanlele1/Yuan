Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=22, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_90_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_90_96_FITS_ETTh2_ftM_sl90_ll48_pl96_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8455
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=22, out_features=45, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  887040.0
params:  1035.0
Trainable parameters:  1035
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.6394128799438477
Epoch: 1, Steps: 66 | Train Loss: 0.4758516 Vali Loss: 0.3130728 Test Loss: 0.4167841
Validation loss decreased (inf --> 0.313073).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.7111079692840576
Epoch: 2, Steps: 66 | Train Loss: 0.4117273 Vali Loss: 0.2907735 Test Loss: 0.3856981
Validation loss decreased (0.313073 --> 0.290773).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.487459659576416
Epoch: 3, Steps: 66 | Train Loss: 0.3695674 Vali Loss: 0.2754059 Test Loss: 0.3645858
Validation loss decreased (0.290773 --> 0.275406).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.3839664459228516
Epoch: 4, Steps: 66 | Train Loss: 0.3405402 Vali Loss: 0.2637987 Test Loss: 0.3500338
Validation loss decreased (0.275406 --> 0.263799).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.7179276943206787
Epoch: 5, Steps: 66 | Train Loss: 0.3195311 Vali Loss: 0.2566592 Test Loss: 0.3397457
Validation loss decreased (0.263799 --> 0.256659).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.5107448101043701
Epoch: 6, Steps: 66 | Train Loss: 0.3053243 Vali Loss: 0.2501957 Test Loss: 0.3321849
Validation loss decreased (0.256659 --> 0.250196).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.794870376586914
Epoch: 7, Steps: 66 | Train Loss: 0.2941033 Vali Loss: 0.2463710 Test Loss: 0.3264438
Validation loss decreased (0.250196 --> 0.246371).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.8580412864685059
Epoch: 8, Steps: 66 | Train Loss: 0.2849844 Vali Loss: 0.2429417 Test Loss: 0.3221340
Validation loss decreased (0.246371 --> 0.242942).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.4476604461669922
Epoch: 9, Steps: 66 | Train Loss: 0.2784995 Vali Loss: 0.2403370 Test Loss: 0.3187565
Validation loss decreased (0.242942 --> 0.240337).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.6831586360931396
Epoch: 10, Steps: 66 | Train Loss: 0.2730182 Vali Loss: 0.2363648 Test Loss: 0.3159686
Validation loss decreased (0.240337 --> 0.236365).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.5170350074768066
Epoch: 11, Steps: 66 | Train Loss: 0.2681300 Vali Loss: 0.2355835 Test Loss: 0.3136637
Validation loss decreased (0.236365 --> 0.235583).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 4.049631357192993
Epoch: 12, Steps: 66 | Train Loss: 0.2649394 Vali Loss: 0.2327301 Test Loss: 0.3117402
Validation loss decreased (0.235583 --> 0.232730).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 4.556590795516968
Epoch: 13, Steps: 66 | Train Loss: 0.2616926 Vali Loss: 0.2317311 Test Loss: 0.3101009
Validation loss decreased (0.232730 --> 0.231731).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 5.990264415740967
Epoch: 14, Steps: 66 | Train Loss: 0.2590305 Vali Loss: 0.2313115 Test Loss: 0.3086986
Validation loss decreased (0.231731 --> 0.231311).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 6.333626985549927
Epoch: 15, Steps: 66 | Train Loss: 0.2567976 Vali Loss: 0.2301433 Test Loss: 0.3074267
Validation loss decreased (0.231311 --> 0.230143).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 4.5256969928741455
Epoch: 16, Steps: 66 | Train Loss: 0.2548222 Vali Loss: 0.2298295 Test Loss: 0.3063706
Validation loss decreased (0.230143 --> 0.229829).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 7.060765266418457
Epoch: 17, Steps: 66 | Train Loss: 0.2530234 Vali Loss: 0.2279393 Test Loss: 0.3054043
Validation loss decreased (0.229829 --> 0.227939).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 6.484598398208618
Epoch: 18, Steps: 66 | Train Loss: 0.2514676 Vali Loss: 0.2268250 Test Loss: 0.3045492
Validation loss decreased (0.227939 --> 0.226825).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 3.895817756652832
Epoch: 19, Steps: 66 | Train Loss: 0.2499948 Vali Loss: 0.2257119 Test Loss: 0.3037824
Validation loss decreased (0.226825 --> 0.225712).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 6.869495391845703
Epoch: 20, Steps: 66 | Train Loss: 0.2488168 Vali Loss: 0.2256814 Test Loss: 0.3030864
Validation loss decreased (0.225712 --> 0.225681).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 6.046045541763306
Epoch: 21, Steps: 66 | Train Loss: 0.2477450 Vali Loss: 0.2254704 Test Loss: 0.3024674
Validation loss decreased (0.225681 --> 0.225470).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.634213924407959
Epoch: 22, Steps: 66 | Train Loss: 0.2466126 Vali Loss: 0.2249733 Test Loss: 0.3019086
Validation loss decreased (0.225470 --> 0.224973).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.6760270595550537
Epoch: 23, Steps: 66 | Train Loss: 0.2458381 Vali Loss: 0.2246281 Test Loss: 0.3014043
Validation loss decreased (0.224973 --> 0.224628).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 4.917709827423096
Epoch: 24, Steps: 66 | Train Loss: 0.2443091 Vali Loss: 0.2230038 Test Loss: 0.3009471
Validation loss decreased (0.224628 --> 0.223004).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 6.088658571243286
Epoch: 25, Steps: 66 | Train Loss: 0.2442931 Vali Loss: 0.2241256 Test Loss: 0.3005326
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 6.525007009506226
Epoch: 26, Steps: 66 | Train Loss: 0.2436010 Vali Loss: 0.2220720 Test Loss: 0.3001372
Validation loss decreased (0.223004 --> 0.222072).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 6.7057812213897705
Epoch: 27, Steps: 66 | Train Loss: 0.2428972 Vali Loss: 0.2235702 Test Loss: 0.2997985
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.1627867221832275
Epoch: 28, Steps: 66 | Train Loss: 0.2423272 Vali Loss: 0.2214567 Test Loss: 0.2994635
Validation loss decreased (0.222072 --> 0.221457).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.9541175365447998
Epoch: 29, Steps: 66 | Train Loss: 0.2417033 Vali Loss: 0.2233332 Test Loss: 0.2991801
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.7000083923339844
Epoch: 30, Steps: 66 | Train Loss: 0.2413912 Vali Loss: 0.2218872 Test Loss: 0.2989121
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.8673663139343262
Epoch: 31, Steps: 66 | Train Loss: 0.2407717 Vali Loss: 0.2219287 Test Loss: 0.2986664
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.5653297901153564
Epoch: 32, Steps: 66 | Train Loss: 0.2404656 Vali Loss: 0.2215156 Test Loss: 0.2984245
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.6051502227783203
Epoch: 33, Steps: 66 | Train Loss: 0.2391846 Vali Loss: 0.2203954 Test Loss: 0.2982190
Validation loss decreased (0.221457 --> 0.220395).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.0143091678619385
Epoch: 34, Steps: 66 | Train Loss: 0.2397903 Vali Loss: 0.2214090 Test Loss: 0.2980207
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.034358263015747
Epoch: 35, Steps: 66 | Train Loss: 0.2394871 Vali Loss: 0.2204149 Test Loss: 0.2978387
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.792729377746582
Epoch: 36, Steps: 66 | Train Loss: 0.2391336 Vali Loss: 0.2215534 Test Loss: 0.2976609
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.2366514205932617
Epoch: 37, Steps: 66 | Train Loss: 0.2386259 Vali Loss: 0.2203231 Test Loss: 0.2975099
Validation loss decreased (0.220395 --> 0.220323).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.695174217224121
Epoch: 38, Steps: 66 | Train Loss: 0.2386191 Vali Loss: 0.2212784 Test Loss: 0.2973793
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.5628340244293213
Epoch: 39, Steps: 66 | Train Loss: 0.2382696 Vali Loss: 0.2202027 Test Loss: 0.2972361
Validation loss decreased (0.220323 --> 0.220203).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.985297679901123
Epoch: 40, Steps: 66 | Train Loss: 0.2381499 Vali Loss: 0.2200251 Test Loss: 0.2971046
Validation loss decreased (0.220203 --> 0.220025).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.71360182762146
Epoch: 41, Steps: 66 | Train Loss: 0.2373005 Vali Loss: 0.2204925 Test Loss: 0.2969868
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.4002501964569092
Epoch: 42, Steps: 66 | Train Loss: 0.2376587 Vali Loss: 0.2194836 Test Loss: 0.2968847
Validation loss decreased (0.220025 --> 0.219484).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.393812656402588
Epoch: 43, Steps: 66 | Train Loss: 0.2374953 Vali Loss: 0.2203335 Test Loss: 0.2967735
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.0979268550872803
Epoch: 44, Steps: 66 | Train Loss: 0.2372113 Vali Loss: 0.2200600 Test Loss: 0.2966864
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.9855015277862549
Epoch: 45, Steps: 66 | Train Loss: 0.2369561 Vali Loss: 0.2205493 Test Loss: 0.2965935
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.4689009189605713
Epoch: 46, Steps: 66 | Train Loss: 0.2368209 Vali Loss: 0.2192736 Test Loss: 0.2965089
Validation loss decreased (0.219484 --> 0.219274).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.5405921936035156
Epoch: 47, Steps: 66 | Train Loss: 0.2368680 Vali Loss: 0.2184993 Test Loss: 0.2964271
Validation loss decreased (0.219274 --> 0.218499).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.0558485984802246
Epoch: 48, Steps: 66 | Train Loss: 0.2366161 Vali Loss: 0.2188960 Test Loss: 0.2963544
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.8625457286834717
Epoch: 49, Steps: 66 | Train Loss: 0.2365623 Vali Loss: 0.2191349 Test Loss: 0.2962833
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.5412304401397705
Epoch: 50, Steps: 66 | Train Loss: 0.2359537 Vali Loss: 0.2180569 Test Loss: 0.2962194
Validation loss decreased (0.218499 --> 0.218057).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.4331517219543457
Epoch: 51, Steps: 66 | Train Loss: 0.2363029 Vali Loss: 0.2183029 Test Loss: 0.2961554
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.578016757965088
Epoch: 52, Steps: 66 | Train Loss: 0.2362576 Vali Loss: 0.2176642 Test Loss: 0.2960971
Validation loss decreased (0.218057 --> 0.217664).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.5136425495147705
Epoch: 53, Steps: 66 | Train Loss: 0.2360491 Vali Loss: 0.2187077 Test Loss: 0.2960494
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.3757896423339844
Epoch: 54, Steps: 66 | Train Loss: 0.2357053 Vali Loss: 0.2177463 Test Loss: 0.2959930
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.3528382778167725
Epoch: 55, Steps: 66 | Train Loss: 0.2357567 Vali Loss: 0.2181002 Test Loss: 0.2959433
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.9401159286499023
Epoch: 56, Steps: 66 | Train Loss: 0.2358355 Vali Loss: 0.2184975 Test Loss: 0.2958997
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.9518122673034668
Epoch: 57, Steps: 66 | Train Loss: 0.2357507 Vali Loss: 0.2191030 Test Loss: 0.2958560
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.471031665802002
Epoch: 58, Steps: 66 | Train Loss: 0.2357076 Vali Loss: 0.2187446 Test Loss: 0.2958132
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.5018856525421143
Epoch: 59, Steps: 66 | Train Loss: 0.2356308 Vali Loss: 0.2191329 Test Loss: 0.2957754
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.5359859466552734
Epoch: 60, Steps: 66 | Train Loss: 0.2355572 Vali Loss: 0.2184927 Test Loss: 0.2957361
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.6037230491638184
Epoch: 61, Steps: 66 | Train Loss: 0.2354966 Vali Loss: 0.2181360 Test Loss: 0.2957055
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.1393823623657227
Epoch: 62, Steps: 66 | Train Loss: 0.2353035 Vali Loss: 0.2183954 Test Loss: 0.2956732
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.3724558353424072
Epoch: 63, Steps: 66 | Train Loss: 0.2353758 Vali Loss: 0.2184408 Test Loss: 0.2956422
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.4791574478149414
Epoch: 64, Steps: 66 | Train Loss: 0.2353487 Vali Loss: 0.2184855 Test Loss: 0.2956154
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.8920347690582275
Epoch: 65, Steps: 66 | Train Loss: 0.2352834 Vali Loss: 0.2181028 Test Loss: 0.2955846
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.756683349609375
Epoch: 66, Steps: 66 | Train Loss: 0.2351618 Vali Loss: 0.2191527 Test Loss: 0.2955615
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.2246463298797607
Epoch: 67, Steps: 66 | Train Loss: 0.2350724 Vali Loss: 0.2186559 Test Loss: 0.2955334
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.4315199851989746
Epoch: 68, Steps: 66 | Train Loss: 0.2351530 Vali Loss: 0.2183273 Test Loss: 0.2955110
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.5628745555877686
Epoch: 69, Steps: 66 | Train Loss: 0.2344816 Vali Loss: 0.2175987 Test Loss: 0.2954902
Validation loss decreased (0.217664 --> 0.217599).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.6343815326690674
Epoch: 70, Steps: 66 | Train Loss: 0.2350648 Vali Loss: 0.2171064 Test Loss: 0.2954710
Validation loss decreased (0.217599 --> 0.217106).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.812568187713623
Epoch: 71, Steps: 66 | Train Loss: 0.2348610 Vali Loss: 0.2186497 Test Loss: 0.2954501
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.7299370765686035
Epoch: 72, Steps: 66 | Train Loss: 0.2349155 Vali Loss: 0.2185529 Test Loss: 0.2954301
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.9224903583526611
Epoch: 73, Steps: 66 | Train Loss: 0.2349536 Vali Loss: 0.2186102 Test Loss: 0.2954106
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.7641346454620361
Epoch: 74, Steps: 66 | Train Loss: 0.2347583 Vali Loss: 0.2184667 Test Loss: 0.2953960
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.3564975261688232
Epoch: 75, Steps: 66 | Train Loss: 0.2347733 Vali Loss: 0.2188386 Test Loss: 0.2953790
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.225520372390747
Epoch: 76, Steps: 66 | Train Loss: 0.2346514 Vali Loss: 0.2180778 Test Loss: 0.2953643
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.673349142074585
Epoch: 77, Steps: 66 | Train Loss: 0.2347825 Vali Loss: 0.2184391 Test Loss: 0.2953506
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.4476768970489502
Epoch: 78, Steps: 66 | Train Loss: 0.2348333 Vali Loss: 0.2179847 Test Loss: 0.2953355
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.5914428234100342
Epoch: 79, Steps: 66 | Train Loss: 0.2347591 Vali Loss: 0.2178614 Test Loss: 0.2953238
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.7877817153930664
Epoch: 80, Steps: 66 | Train Loss: 0.2345465 Vali Loss: 0.2179714 Test Loss: 0.2953109
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.6303191184997559
Epoch: 81, Steps: 66 | Train Loss: 0.2347090 Vali Loss: 0.2188158 Test Loss: 0.2952984
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.538071870803833
Epoch: 82, Steps: 66 | Train Loss: 0.2346891 Vali Loss: 0.2183564 Test Loss: 0.2952886
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.4141592979431152
Epoch: 83, Steps: 66 | Train Loss: 0.2346914 Vali Loss: 0.2176297 Test Loss: 0.2952773
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.883065938949585
Epoch: 84, Steps: 66 | Train Loss: 0.2346222 Vali Loss: 0.2179555 Test Loss: 0.2952666
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.0740485191345215
Epoch: 85, Steps: 66 | Train Loss: 0.2346580 Vali Loss: 0.2178472 Test Loss: 0.2952576
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 2.904853343963623
Epoch: 86, Steps: 66 | Train Loss: 0.2345836 Vali Loss: 0.2176692 Test Loss: 0.2952493
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.8081097602844238
Epoch: 87, Steps: 66 | Train Loss: 0.2345137 Vali Loss: 0.2182023 Test Loss: 0.2952396
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.8504815101623535
Epoch: 88, Steps: 66 | Train Loss: 0.2345432 Vali Loss: 0.2175289 Test Loss: 0.2952322
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.414705753326416
Epoch: 89, Steps: 66 | Train Loss: 0.2339862 Vali Loss: 0.2181485 Test Loss: 0.2952236
EarlyStopping counter: 19 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.686396598815918
Epoch: 90, Steps: 66 | Train Loss: 0.2344452 Vali Loss: 0.2168487 Test Loss: 0.2952161
Validation loss decreased (0.217106 --> 0.216849).  Saving model ...
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.336580753326416
Epoch: 91, Steps: 66 | Train Loss: 0.2345313 Vali Loss: 0.2167680 Test Loss: 0.2952094
Validation loss decreased (0.216849 --> 0.216768).  Saving model ...
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.9369652271270752
Epoch: 92, Steps: 66 | Train Loss: 0.2345101 Vali Loss: 0.2169713 Test Loss: 0.2952028
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.3477139472961426
Epoch: 93, Steps: 66 | Train Loss: 0.2343868 Vali Loss: 0.2174255 Test Loss: 0.2951954
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.9209890365600586
Epoch: 94, Steps: 66 | Train Loss: 0.2339083 Vali Loss: 0.2181875 Test Loss: 0.2951899
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.6972389221191406
Epoch: 95, Steps: 66 | Train Loss: 0.2343981 Vali Loss: 0.2171757 Test Loss: 0.2951844
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.4028213024139404
Epoch: 96, Steps: 66 | Train Loss: 0.2345093 Vali Loss: 0.2171461 Test Loss: 0.2951790
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.6346149444580078
Epoch: 97, Steps: 66 | Train Loss: 0.2343609 Vali Loss: 0.2177958 Test Loss: 0.2951734
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.3775644302368164
Epoch: 98, Steps: 66 | Train Loss: 0.2343276 Vali Loss: 0.2179768 Test Loss: 0.2951687
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.7855610847473145
Epoch: 99, Steps: 66 | Train Loss: 0.2338511 Vali Loss: 0.2178216 Test Loss: 0.2951638
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.4596915245056152
Epoch: 100, Steps: 66 | Train Loss: 0.2343885 Vali Loss: 0.2172870 Test Loss: 0.2951594
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8455
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=22, out_features=45, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  887040.0
params:  1035.0
Trainable parameters:  1035
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.4647436141967773
Epoch: 1, Steps: 66 | Train Loss: 0.4279151 Vali Loss: 0.2155482 Test Loss: 0.2932760
Validation loss decreased (inf --> 0.215548).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.4117348194122314
Epoch: 2, Steps: 66 | Train Loss: 0.4258531 Vali Loss: 0.2155968 Test Loss: 0.2925150
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.393690586090088
Epoch: 3, Steps: 66 | Train Loss: 0.4243741 Vali Loss: 0.2135655 Test Loss: 0.2919987
Validation loss decreased (0.215548 --> 0.213566).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.7002723217010498
Epoch: 4, Steps: 66 | Train Loss: 0.4229011 Vali Loss: 0.2131312 Test Loss: 0.2916816
Validation loss decreased (0.213566 --> 0.213131).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.5485005378723145
Epoch: 5, Steps: 66 | Train Loss: 0.4229972 Vali Loss: 0.2134379 Test Loss: 0.2915131
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.3699615001678467
Epoch: 6, Steps: 66 | Train Loss: 0.4224222 Vali Loss: 0.2134145 Test Loss: 0.2914214
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.597747802734375
Epoch: 7, Steps: 66 | Train Loss: 0.4220563 Vali Loss: 0.2124726 Test Loss: 0.2912577
Validation loss decreased (0.213131 --> 0.212473).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.5804641246795654
Epoch: 8, Steps: 66 | Train Loss: 0.4214224 Vali Loss: 0.2136372 Test Loss: 0.2911962
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.908743143081665
Epoch: 9, Steps: 66 | Train Loss: 0.4215688 Vali Loss: 0.2133781 Test Loss: 0.2910517
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.6343066692352295
Epoch: 10, Steps: 66 | Train Loss: 0.4212040 Vali Loss: 0.2129081 Test Loss: 0.2910618
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.6052296161651611
Epoch: 11, Steps: 66 | Train Loss: 0.4209773 Vali Loss: 0.2121658 Test Loss: 0.2909870
Validation loss decreased (0.212473 --> 0.212166).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.3834526538848877
Epoch: 12, Steps: 66 | Train Loss: 0.4209030 Vali Loss: 0.2117765 Test Loss: 0.2909623
Validation loss decreased (0.212166 --> 0.211776).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.48994779586792
Epoch: 13, Steps: 66 | Train Loss: 0.4206321 Vali Loss: 0.2113581 Test Loss: 0.2909527
Validation loss decreased (0.211776 --> 0.211358).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.6023643016815186
Epoch: 14, Steps: 66 | Train Loss: 0.4203220 Vali Loss: 0.2126636 Test Loss: 0.2909054
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.3678998947143555
Epoch: 15, Steps: 66 | Train Loss: 0.4204056 Vali Loss: 0.2111288 Test Loss: 0.2908859
Validation loss decreased (0.211358 --> 0.211129).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.961256980895996
Epoch: 16, Steps: 66 | Train Loss: 0.4202610 Vali Loss: 0.2120811 Test Loss: 0.2908460
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.5710585117340088
Epoch: 17, Steps: 66 | Train Loss: 0.4203865 Vali Loss: 0.2124330 Test Loss: 0.2908302
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.366708517074585
Epoch: 18, Steps: 66 | Train Loss: 0.4201743 Vali Loss: 0.2123951 Test Loss: 0.2907939
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.2938404083251953
Epoch: 19, Steps: 66 | Train Loss: 0.4202419 Vali Loss: 0.2118682 Test Loss: 0.2908055
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.766587495803833
Epoch: 20, Steps: 66 | Train Loss: 0.4200615 Vali Loss: 0.2108685 Test Loss: 0.2907901
Validation loss decreased (0.211129 --> 0.210869).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.8229641914367676
Epoch: 21, Steps: 66 | Train Loss: 0.4200472 Vali Loss: 0.2122830 Test Loss: 0.2907825
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.042658567428589
Epoch: 22, Steps: 66 | Train Loss: 0.4198023 Vali Loss: 0.2128109 Test Loss: 0.2907493
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.7169735431671143
Epoch: 23, Steps: 66 | Train Loss: 0.4197905 Vali Loss: 0.2114649 Test Loss: 0.2907565
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.7878010272979736
Epoch: 24, Steps: 66 | Train Loss: 0.4199139 Vali Loss: 0.2111532 Test Loss: 0.2907459
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.5875732898712158
Epoch: 25, Steps: 66 | Train Loss: 0.4198148 Vali Loss: 0.2119803 Test Loss: 0.2907150
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.814537763595581
Epoch: 26, Steps: 66 | Train Loss: 0.4188671 Vali Loss: 0.2116779 Test Loss: 0.2907102
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.6927642822265625
Epoch: 27, Steps: 66 | Train Loss: 0.4197347 Vali Loss: 0.2116652 Test Loss: 0.2906950
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.9574759006500244
Epoch: 28, Steps: 66 | Train Loss: 0.4197642 Vali Loss: 0.2120684 Test Loss: 0.2906967
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.614314079284668
Epoch: 29, Steps: 66 | Train Loss: 0.4185900 Vali Loss: 0.2116524 Test Loss: 0.2906897
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.4202041625976562
Epoch: 30, Steps: 66 | Train Loss: 0.4196547 Vali Loss: 0.2121993 Test Loss: 0.2906766
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.532599925994873
Epoch: 31, Steps: 66 | Train Loss: 0.4196424 Vali Loss: 0.2111109 Test Loss: 0.2906691
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.5745646953582764
Epoch: 32, Steps: 66 | Train Loss: 0.4193406 Vali Loss: 0.2115316 Test Loss: 0.2906746
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.466167688369751
Epoch: 33, Steps: 66 | Train Loss: 0.4195906 Vali Loss: 0.2117749 Test Loss: 0.2906666
EarlyStopping counter: 13 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.3473608493804932
Epoch: 34, Steps: 66 | Train Loss: 0.4194006 Vali Loss: 0.2118096 Test Loss: 0.2906519
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.3990848064422607
Epoch: 35, Steps: 66 | Train Loss: 0.4195885 Vali Loss: 0.2112582 Test Loss: 0.2906414
EarlyStopping counter: 15 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.5361707210540771
Epoch: 36, Steps: 66 | Train Loss: 0.4194846 Vali Loss: 0.2114098 Test Loss: 0.2906509
EarlyStopping counter: 16 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.7357163429260254
Epoch: 37, Steps: 66 | Train Loss: 0.4193643 Vali Loss: 0.2126448 Test Loss: 0.2906460
EarlyStopping counter: 17 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.2711002826690674
Epoch: 38, Steps: 66 | Train Loss: 0.4193683 Vali Loss: 0.2119780 Test Loss: 0.2906554
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.4119534492492676
Epoch: 39, Steps: 66 | Train Loss: 0.4184801 Vali Loss: 0.2112370 Test Loss: 0.2906422
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 6.446359157562256
Epoch: 40, Steps: 66 | Train Loss: 0.4193077 Vali Loss: 0.2120706 Test Loss: 0.2906348
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_90_96_FITS_ETTh2_ftM_sl90_ll48_pl96_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.29133304953575134, mae:0.33959975838661194, rse:0.4349868893623352, corr:[0.2756447  0.27813426 0.27580988 0.27444047 0.27410212 0.27318498
 0.27191496 0.27083895 0.2702631  0.26933748 0.2680439  0.26637742
 0.26460606 0.26333943 0.26234776 0.26172444 0.26125148 0.26085755
 0.26021    0.25907978 0.25796744 0.25702414 0.25585175 0.2538396
 0.2506467  0.24814874 0.24613036 0.24452159 0.24313913 0.2419192
 0.24097757 0.23924221 0.23746487 0.23619406 0.23542751 0.23406896
 0.232199   0.23093984 0.23011477 0.22920899 0.22845152 0.22816621
 0.22810309 0.22718969 0.2261183  0.22532852 0.22447705 0.22253078
 0.2188682  0.21603714 0.21409994 0.21251461 0.21073818 0.20883031
 0.20734528 0.20511276 0.20334013 0.20176828 0.20086068 0.19966783
 0.19820249 0.19791324 0.19832192 0.19839321 0.19775319 0.19710769
 0.19692396 0.19646557 0.19590999 0.19533494 0.19451733 0.19326131
 0.19074787 0.18914716 0.18796983 0.18700361 0.18592496 0.18537828
 0.18546414 0.18427123 0.18338124 0.18297236 0.18310274 0.18283741
 0.18164873 0.18110488 0.18166733 0.18243258 0.18157381 0.18001954
 0.17966089 0.17975509 0.17908934 0.1778912  0.17939773 0.18081686]
