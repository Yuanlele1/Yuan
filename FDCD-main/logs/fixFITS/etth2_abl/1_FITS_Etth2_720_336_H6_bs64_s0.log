Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=0, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_336_FITS_ETTh2_ftM_sl720_ll48_pl336_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=196, out_features=287, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  50401792.0
params:  56539.0
Trainable parameters:  56539
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.5906720161437988
Epoch: 1, Steps: 59 | Train Loss: 0.8340803 Vali Loss: 0.5110115 Test Loss: 0.3930194
Validation loss decreased (inf --> 0.511011).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.4640514850616455
Epoch: 2, Steps: 59 | Train Loss: 0.6999010 Vali Loss: 0.4548141 Test Loss: 0.3746885
Validation loss decreased (0.511011 --> 0.454814).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.4573462009429932
Epoch: 3, Steps: 59 | Train Loss: 0.6686453 Vali Loss: 0.4333588 Test Loss: 0.3685083
Validation loss decreased (0.454814 --> 0.433359).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.4916727542877197
Epoch: 4, Steps: 59 | Train Loss: 0.6543295 Vali Loss: 0.4170642 Test Loss: 0.3655184
Validation loss decreased (0.433359 --> 0.417064).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.5015809535980225
Epoch: 5, Steps: 59 | Train Loss: 0.6455294 Vali Loss: 0.4167782 Test Loss: 0.3632706
Validation loss decreased (0.417064 --> 0.416778).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.4204061031341553
Epoch: 6, Steps: 59 | Train Loss: 0.6388196 Vali Loss: 0.4104740 Test Loss: 0.3622203
Validation loss decreased (0.416778 --> 0.410474).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.446460247039795
Epoch: 7, Steps: 59 | Train Loss: 0.6359876 Vali Loss: 0.4046524 Test Loss: 0.3612398
Validation loss decreased (0.410474 --> 0.404652).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.4151675701141357
Epoch: 8, Steps: 59 | Train Loss: 0.6330510 Vali Loss: 0.4013082 Test Loss: 0.3605715
Validation loss decreased (0.404652 --> 0.401308).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.536750316619873
Epoch: 9, Steps: 59 | Train Loss: 0.6303095 Vali Loss: 0.3973682 Test Loss: 0.3601921
Validation loss decreased (0.401308 --> 0.397368).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.6642162799835205
Epoch: 10, Steps: 59 | Train Loss: 0.6282288 Vali Loss: 0.3983658 Test Loss: 0.3598866
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.5599579811096191
Epoch: 11, Steps: 59 | Train Loss: 0.6267533 Vali Loss: 0.3937038 Test Loss: 0.3596155
Validation loss decreased (0.397368 --> 0.393704).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.5721781253814697
Epoch: 12, Steps: 59 | Train Loss: 0.6240712 Vali Loss: 0.3945904 Test Loss: 0.3594682
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.3379449844360352
Epoch: 13, Steps: 59 | Train Loss: 0.6233047 Vali Loss: 0.3914283 Test Loss: 0.3594087
Validation loss decreased (0.393704 --> 0.391428).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.4694862365722656
Epoch: 14, Steps: 59 | Train Loss: 0.6219878 Vali Loss: 0.3914421 Test Loss: 0.3591695
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.4685559272766113
Epoch: 15, Steps: 59 | Train Loss: 0.6206037 Vali Loss: 0.3888479 Test Loss: 0.3591821
Validation loss decreased (0.391428 --> 0.388848).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.538116693496704
Epoch: 16, Steps: 59 | Train Loss: 0.6200758 Vali Loss: 0.3893524 Test Loss: 0.3590745
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.582779884338379
Epoch: 17, Steps: 59 | Train Loss: 0.6206196 Vali Loss: 0.3894550 Test Loss: 0.3589820
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.8269720077514648
Epoch: 18, Steps: 59 | Train Loss: 0.6198908 Vali Loss: 0.3870762 Test Loss: 0.3589323
Validation loss decreased (0.388848 --> 0.387076).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.457848310470581
Epoch: 19, Steps: 59 | Train Loss: 0.6188810 Vali Loss: 0.3893126 Test Loss: 0.3588552
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.3874738216400146
Epoch: 20, Steps: 59 | Train Loss: 0.6177934 Vali Loss: 0.3871310 Test Loss: 0.3586570
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.6390635967254639
Epoch: 21, Steps: 59 | Train Loss: 0.6179973 Vali Loss: 0.3860878 Test Loss: 0.3587096
Validation loss decreased (0.387076 --> 0.386088).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.5017004013061523
Epoch: 22, Steps: 59 | Train Loss: 0.6158425 Vali Loss: 0.3863502 Test Loss: 0.3586686
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.4554760456085205
Epoch: 23, Steps: 59 | Train Loss: 0.6174914 Vali Loss: 0.3861493 Test Loss: 0.3587018
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.4790453910827637
Epoch: 24, Steps: 59 | Train Loss: 0.6172271 Vali Loss: 0.3848698 Test Loss: 0.3587072
Validation loss decreased (0.386088 --> 0.384870).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.525097370147705
Epoch: 25, Steps: 59 | Train Loss: 0.6159189 Vali Loss: 0.3864479 Test Loss: 0.3586020
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.4497880935668945
Epoch: 26, Steps: 59 | Train Loss: 0.6160143 Vali Loss: 0.3833569 Test Loss: 0.3585316
Validation loss decreased (0.384870 --> 0.383357).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.6451539993286133
Epoch: 27, Steps: 59 | Train Loss: 0.6153901 Vali Loss: 0.3845631 Test Loss: 0.3585771
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.5251550674438477
Epoch: 28, Steps: 59 | Train Loss: 0.6152409 Vali Loss: 0.3829195 Test Loss: 0.3586031
Validation loss decreased (0.383357 --> 0.382919).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.445368766784668
Epoch: 29, Steps: 59 | Train Loss: 0.6159382 Vali Loss: 0.3861099 Test Loss: 0.3586490
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.4672911167144775
Epoch: 30, Steps: 59 | Train Loss: 0.6157568 Vali Loss: 0.3839380 Test Loss: 0.3585068
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.425870418548584
Epoch: 31, Steps: 59 | Train Loss: 0.6141791 Vali Loss: 0.3850964 Test Loss: 0.3585158
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.3965086936950684
Epoch: 32, Steps: 59 | Train Loss: 0.6151231 Vali Loss: 0.3840979 Test Loss: 0.3584932
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.5096995830535889
Epoch: 33, Steps: 59 | Train Loss: 0.6146245 Vali Loss: 0.3842096 Test Loss: 0.3585015
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.4924333095550537
Epoch: 34, Steps: 59 | Train Loss: 0.6140445 Vali Loss: 0.3825992 Test Loss: 0.3584800
Validation loss decreased (0.382919 --> 0.382599).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.4705851078033447
Epoch: 35, Steps: 59 | Train Loss: 0.6148304 Vali Loss: 0.3819097 Test Loss: 0.3585125
Validation loss decreased (0.382599 --> 0.381910).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.4197721481323242
Epoch: 36, Steps: 59 | Train Loss: 0.6147189 Vali Loss: 0.3800082 Test Loss: 0.3585187
Validation loss decreased (0.381910 --> 0.380008).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.405226469039917
Epoch: 37, Steps: 59 | Train Loss: 0.6147501 Vali Loss: 0.3820716 Test Loss: 0.3584657
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.6994273662567139
Epoch: 38, Steps: 59 | Train Loss: 0.6144277 Vali Loss: 0.3825271 Test Loss: 0.3584237
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.5127744674682617
Epoch: 39, Steps: 59 | Train Loss: 0.6143347 Vali Loss: 0.3842271 Test Loss: 0.3584205
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.3943891525268555
Epoch: 40, Steps: 59 | Train Loss: 0.6146479 Vali Loss: 0.3834301 Test Loss: 0.3584648
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.6468453407287598
Epoch: 41, Steps: 59 | Train Loss: 0.6140343 Vali Loss: 0.3792224 Test Loss: 0.3584450
Validation loss decreased (0.380008 --> 0.379222).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.3546440601348877
Epoch: 42, Steps: 59 | Train Loss: 0.6113033 Vali Loss: 0.3818339 Test Loss: 0.3584501
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.40803861618042
Epoch: 43, Steps: 59 | Train Loss: 0.6129374 Vali Loss: 0.3824011 Test Loss: 0.3584711
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.7832648754119873
Epoch: 44, Steps: 59 | Train Loss: 0.6129750 Vali Loss: 0.3789514 Test Loss: 0.3584416
Validation loss decreased (0.379222 --> 0.378951).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.3253982067108154
Epoch: 45, Steps: 59 | Train Loss: 0.6130634 Vali Loss: 0.3838127 Test Loss: 0.3584173
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.3875186443328857
Epoch: 46, Steps: 59 | Train Loss: 0.6131230 Vali Loss: 0.3813056 Test Loss: 0.3584577
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.3770520687103271
Epoch: 47, Steps: 59 | Train Loss: 0.6120159 Vali Loss: 0.3807129 Test Loss: 0.3584312
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.4838595390319824
Epoch: 48, Steps: 59 | Train Loss: 0.6133388 Vali Loss: 0.3826034 Test Loss: 0.3584127
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.3665506839752197
Epoch: 49, Steps: 59 | Train Loss: 0.6134432 Vali Loss: 0.3811822 Test Loss: 0.3584333
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.5138912200927734
Epoch: 50, Steps: 59 | Train Loss: 0.6136493 Vali Loss: 0.3831712 Test Loss: 0.3584403
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.541623830795288
Epoch: 51, Steps: 59 | Train Loss: 0.6118885 Vali Loss: 0.3820140 Test Loss: 0.3584480
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.3874804973602295
Epoch: 52, Steps: 59 | Train Loss: 0.6133782 Vali Loss: 0.3804453 Test Loss: 0.3584273
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.4693634510040283
Epoch: 53, Steps: 59 | Train Loss: 0.6130157 Vali Loss: 0.3808549 Test Loss: 0.3584232
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.3788580894470215
Epoch: 54, Steps: 59 | Train Loss: 0.6128924 Vali Loss: 0.3787057 Test Loss: 0.3584321
Validation loss decreased (0.378951 --> 0.378706).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.4162707328796387
Epoch: 55, Steps: 59 | Train Loss: 0.6120299 Vali Loss: 0.3806319 Test Loss: 0.3583996
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.4366555213928223
Epoch: 56, Steps: 59 | Train Loss: 0.6122750 Vali Loss: 0.3807195 Test Loss: 0.3584225
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.4479808807373047
Epoch: 57, Steps: 59 | Train Loss: 0.6132127 Vali Loss: 0.3799381 Test Loss: 0.3584119
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.4107592105865479
Epoch: 58, Steps: 59 | Train Loss: 0.6120554 Vali Loss: 0.3792132 Test Loss: 0.3584165
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.4957904815673828
Epoch: 59, Steps: 59 | Train Loss: 0.6118722 Vali Loss: 0.3783465 Test Loss: 0.3584148
Validation loss decreased (0.378706 --> 0.378346).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.1866166591644287
Epoch: 60, Steps: 59 | Train Loss: 0.6125872 Vali Loss: 0.3805352 Test Loss: 0.3584254
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.4457154273986816
Epoch: 61, Steps: 59 | Train Loss: 0.6126768 Vali Loss: 0.3819851 Test Loss: 0.3584172
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.4214036464691162
Epoch: 62, Steps: 59 | Train Loss: 0.6129956 Vali Loss: 0.3803700 Test Loss: 0.3584237
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.403799057006836
Epoch: 63, Steps: 59 | Train Loss: 0.6118128 Vali Loss: 0.3820231 Test Loss: 0.3584226
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.4372813701629639
Epoch: 64, Steps: 59 | Train Loss: 0.6125020 Vali Loss: 0.3799840 Test Loss: 0.3584172
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.5065603256225586
Epoch: 65, Steps: 59 | Train Loss: 0.6123810 Vali Loss: 0.3814202 Test Loss: 0.3584185
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.412637710571289
Epoch: 66, Steps: 59 | Train Loss: 0.6129959 Vali Loss: 0.3799096 Test Loss: 0.3584149
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.439570426940918
Epoch: 67, Steps: 59 | Train Loss: 0.6130304 Vali Loss: 0.3818523 Test Loss: 0.3584287
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.6258597373962402
Epoch: 68, Steps: 59 | Train Loss: 0.6128822 Vali Loss: 0.3809638 Test Loss: 0.3584205
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.4591343402862549
Epoch: 69, Steps: 59 | Train Loss: 0.6134299 Vali Loss: 0.3768491 Test Loss: 0.3584144
Validation loss decreased (0.378346 --> 0.376849).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.3580856323242188
Epoch: 70, Steps: 59 | Train Loss: 0.6127095 Vali Loss: 0.3821809 Test Loss: 0.3584196
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.5180027484893799
Epoch: 71, Steps: 59 | Train Loss: 0.6110570 Vali Loss: 0.3807819 Test Loss: 0.3584076
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.5027387142181396
Epoch: 72, Steps: 59 | Train Loss: 0.6114485 Vali Loss: 0.3808437 Test Loss: 0.3584071
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.4568803310394287
Epoch: 73, Steps: 59 | Train Loss: 0.6114384 Vali Loss: 0.3798567 Test Loss: 0.3584046
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.740159273147583
Epoch: 74, Steps: 59 | Train Loss: 0.6138066 Vali Loss: 0.3800265 Test Loss: 0.3584064
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.4608371257781982
Epoch: 75, Steps: 59 | Train Loss: 0.6131756 Vali Loss: 0.3807954 Test Loss: 0.3584064
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.3674957752227783
Epoch: 76, Steps: 59 | Train Loss: 0.6102665 Vali Loss: 0.3789150 Test Loss: 0.3584036
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.4999194145202637
Epoch: 77, Steps: 59 | Train Loss: 0.6120438 Vali Loss: 0.3798077 Test Loss: 0.3584044
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.4379873275756836
Epoch: 78, Steps: 59 | Train Loss: 0.6136305 Vali Loss: 0.3821595 Test Loss: 0.3584026
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.457622766494751
Epoch: 79, Steps: 59 | Train Loss: 0.6124770 Vali Loss: 0.3821234 Test Loss: 0.3584016
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.4511690139770508
Epoch: 80, Steps: 59 | Train Loss: 0.6117082 Vali Loss: 0.3793483 Test Loss: 0.3584042
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.4615542888641357
Epoch: 81, Steps: 59 | Train Loss: 0.6124171 Vali Loss: 0.3812778 Test Loss: 0.3584018
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.3949451446533203
Epoch: 82, Steps: 59 | Train Loss: 0.6125588 Vali Loss: 0.3816478 Test Loss: 0.3584001
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.8596279621124268
Epoch: 83, Steps: 59 | Train Loss: 0.6112111 Vali Loss: 0.3824539 Test Loss: 0.3584003
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.4264166355133057
Epoch: 84, Steps: 59 | Train Loss: 0.6135866 Vali Loss: 0.3816747 Test Loss: 0.3584060
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.5541205406188965
Epoch: 85, Steps: 59 | Train Loss: 0.6113495 Vali Loss: 0.3798941 Test Loss: 0.3584068
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.5049419403076172
Epoch: 86, Steps: 59 | Train Loss: 0.6124164 Vali Loss: 0.3781700 Test Loss: 0.3584000
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.4545202255249023
Epoch: 87, Steps: 59 | Train Loss: 0.6131732 Vali Loss: 0.3778312 Test Loss: 0.3584028
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.5357441902160645
Epoch: 88, Steps: 59 | Train Loss: 0.6124596 Vali Loss: 0.3818091 Test Loss: 0.3583957
EarlyStopping counter: 19 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.4452786445617676
Epoch: 89, Steps: 59 | Train Loss: 0.6135991 Vali Loss: 0.3808188 Test Loss: 0.3583982
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_720_336_FITS_ETTh2_ftM_sl720_ll48_pl336_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.3541506826877594, mae:0.39560484886169434, rse:0.4758099913597107, corr:[0.25859544 0.263245   0.26124036 0.26314142 0.26242343 0.2605894
 0.2610678  0.2610028  0.2591631  0.25818858 0.257758   0.25630307
 0.25493047 0.25412196 0.2532529  0.2523557  0.25202137 0.25152397
 0.25043255 0.24928111 0.24842817 0.24753784 0.24629664 0.24513696
 0.24375565 0.24228086 0.24111827 0.24027467 0.23925567 0.23819202
 0.2375093  0.23673849 0.23572125 0.23472296 0.2339007  0.2329569
 0.23219405 0.23178491 0.23094828 0.22968486 0.22890666 0.22866428
 0.22808105 0.22699584 0.2260322  0.22530864 0.2239374  0.22203277
 0.22060633 0.21939483 0.21767999 0.21613693 0.21506128 0.21342546
 0.21136545 0.20998958 0.20867014 0.20666371 0.20501615 0.20436509
 0.2037972  0.20313366 0.20318341 0.20344456 0.20283075 0.20216386
 0.20190145 0.20158246 0.20078517 0.20019232 0.19990243 0.1992181
 0.19798724 0.1970335  0.19635537 0.19513057 0.19400294 0.1936147
 0.19328187 0.19245365 0.19200271 0.1917967  0.19113462 0.19031642
 0.19018002 0.19036646 0.18997985 0.18937406 0.18922618 0.18911438
 0.18848528 0.18798399 0.18827887 0.18837602 0.1879643  0.18772756
 0.18764941 0.18688115 0.18584757 0.1854315  0.1852453  0.18432368
 0.18359609 0.18362308 0.18360962 0.18271582 0.18230774 0.18269579
 0.18235809 0.1812326  0.1806033  0.18064642 0.17999445 0.1791183
 0.17890358 0.17884997 0.17807776 0.17697744 0.17642763 0.17553136
 0.17392854 0.17270784 0.17224774 0.17140622 0.17020518 0.16970767
 0.1694498  0.1684965  0.16741468 0.16684344 0.16617872 0.16506216
 0.16447854 0.16430998 0.16377854 0.16307418 0.16281958 0.1625135
 0.16143554 0.16059591 0.1606755  0.16043147 0.15922369 0.15786564
 0.15669951 0.15527397 0.15372194 0.15281269 0.1521163  0.15106763
 0.1501789  0.14972198 0.14916682 0.14809532 0.14743736 0.1471435
 0.14635277 0.14551133 0.14561127 0.14571059 0.14469902 0.14399745
 0.14407842 0.14373069 0.14291444 0.14296852 0.14350945 0.142606
 0.14081407 0.13980521 0.13940358 0.13816844 0.13674197 0.13589558
 0.1351333  0.13346356 0.13230988 0.13218124 0.1314521  0.13021933
 0.12964559 0.12973681 0.12944177 0.128992   0.12870863 0.12856047
 0.12805888 0.127877   0.12835407 0.12843093 0.12832887 0.12839265
 0.12836638 0.12763105 0.12677008 0.12674105 0.12653418 0.12551276
 0.12484653 0.12482885 0.12454633 0.12372699 0.123562   0.12379801
 0.12323941 0.12264371 0.12281416 0.1232245  0.12285779 0.12265207
 0.12309239 0.1232892  0.12289698 0.12282312 0.12309498 0.12249311
 0.12135056 0.12060196 0.11989158 0.11898607 0.11850919 0.11890924
 0.11861404 0.11805577 0.1181495  0.11853068 0.11793348 0.1168735
 0.11657152 0.11648782 0.11568303 0.11565912 0.1166691  0.11739491
 0.11715617 0.11733758 0.1181327  0.1183699  0.11801282 0.11802845
 0.11801503 0.11718139 0.11646329 0.11673331 0.11665222 0.11574439
 0.11543959 0.11567757 0.11574414 0.1156768  0.11602712 0.1163802
 0.11612688 0.11678319 0.11810628 0.11933567 0.11963294 0.12048411
 0.12134286 0.12152549 0.12170456 0.12248926 0.12350492 0.1235243
 0.12365121 0.12408135 0.12414023 0.12375206 0.12385191 0.1242668
 0.12382658 0.12335624 0.12396222 0.12411072 0.12379818 0.12358391
 0.12391639 0.12371827 0.12339737 0.12425155 0.1252104  0.12476438
 0.12417085 0.12476134 0.1247486  0.12366373 0.12368131 0.12488113
 0.12481857 0.12353537 0.12307771 0.12322387 0.12221711 0.12083858
 0.12075736 0.12036862 0.11907228 0.11879162 0.11976491 0.11912752
 0.11732886 0.11786095 0.11931483 0.11941264 0.11896171 0.12051778
 0.12092772 0.11988967 0.11999529 0.12143716 0.12129541 0.12011172
 0.12052346 0.12037663 0.118572   0.1176002  0.11825629 0.11728189
 0.1153129  0.11641064 0.11809838 0.11741248 0.11654386 0.11875582
 0.11956223 0.11807328 0.11919915 0.1220864  0.1216721  0.12042159
 0.12209208 0.12215582 0.1201138  0.12235693 0.12479006 0.11403646]
