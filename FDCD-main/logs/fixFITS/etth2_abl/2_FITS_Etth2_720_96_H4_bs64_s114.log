Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=134, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=134, out_features=151, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  18129664.0
params:  20385.0
Trainable parameters:  20385
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.8750956058502197
Epoch: 1, Steps: 61 | Train Loss: 0.5567964 Vali Loss: 0.3881299 Test Loss: 0.3922635
Validation loss decreased (inf --> 0.388130).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.9862947463989258
Epoch: 2, Steps: 61 | Train Loss: 0.4346520 Vali Loss: 0.3417651 Test Loss: 0.3521745
Validation loss decreased (0.388130 --> 0.341765).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.9180235862731934
Epoch: 3, Steps: 61 | Train Loss: 0.3694460 Vali Loss: 0.3231464 Test Loss: 0.3357202
Validation loss decreased (0.341765 --> 0.323146).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.7639713287353516
Epoch: 4, Steps: 61 | Train Loss: 0.3289413 Vali Loss: 0.3140866 Test Loss: 0.3281066
Validation loss decreased (0.323146 --> 0.314087).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.7284619808197021
Epoch: 5, Steps: 61 | Train Loss: 0.3005850 Vali Loss: 0.3097622 Test Loss: 0.3246930
Validation loss decreased (0.314087 --> 0.309762).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.883225679397583
Epoch: 6, Steps: 61 | Train Loss: 0.2785146 Vali Loss: 0.3067574 Test Loss: 0.3224631
Validation loss decreased (0.309762 --> 0.306757).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.7976293563842773
Epoch: 7, Steps: 61 | Train Loss: 0.2609322 Vali Loss: 0.3047095 Test Loss: 0.3207133
Validation loss decreased (0.306757 --> 0.304710).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.6525928974151611
Epoch: 8, Steps: 61 | Train Loss: 0.2458477 Vali Loss: 0.3010626 Test Loss: 0.3193302
Validation loss decreased (0.304710 --> 0.301063).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.5634660720825195
Epoch: 9, Steps: 61 | Train Loss: 0.2326394 Vali Loss: 0.3000919 Test Loss: 0.3179016
Validation loss decreased (0.301063 --> 0.300092).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.9178109169006348
Epoch: 10, Steps: 61 | Train Loss: 0.2215377 Vali Loss: 0.2981820 Test Loss: 0.3163748
Validation loss decreased (0.300092 --> 0.298182).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.987485647201538
Epoch: 11, Steps: 61 | Train Loss: 0.2115003 Vali Loss: 0.2950283 Test Loss: 0.3148956
Validation loss decreased (0.298182 --> 0.295028).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.918372631072998
Epoch: 12, Steps: 61 | Train Loss: 0.2023839 Vali Loss: 0.2928947 Test Loss: 0.3133477
Validation loss decreased (0.295028 --> 0.292895).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.6983580589294434
Epoch: 13, Steps: 61 | Train Loss: 0.1943116 Vali Loss: 0.2902997 Test Loss: 0.3119439
Validation loss decreased (0.292895 --> 0.290300).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.7477035522460938
Epoch: 14, Steps: 61 | Train Loss: 0.1873291 Vali Loss: 0.2882703 Test Loss: 0.3105422
Validation loss decreased (0.290300 --> 0.288270).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.7208821773529053
Epoch: 15, Steps: 61 | Train Loss: 0.1808608 Vali Loss: 0.2863297 Test Loss: 0.3091026
Validation loss decreased (0.288270 --> 0.286330).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.8232605457305908
Epoch: 16, Steps: 61 | Train Loss: 0.1750642 Vali Loss: 0.2833079 Test Loss: 0.3079427
Validation loss decreased (0.286330 --> 0.283308).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.7695016860961914
Epoch: 17, Steps: 61 | Train Loss: 0.1696508 Vali Loss: 0.2827315 Test Loss: 0.3064566
Validation loss decreased (0.283308 --> 0.282732).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.7865591049194336
Epoch: 18, Steps: 61 | Train Loss: 0.1648306 Vali Loss: 0.2812031 Test Loss: 0.3052169
Validation loss decreased (0.282732 --> 0.281203).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.6093635559082031
Epoch: 19, Steps: 61 | Train Loss: 0.1604027 Vali Loss: 0.2789215 Test Loss: 0.3041390
Validation loss decreased (0.281203 --> 0.278922).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.8700940608978271
Epoch: 20, Steps: 61 | Train Loss: 0.1563304 Vali Loss: 0.2774153 Test Loss: 0.3030385
Validation loss decreased (0.278922 --> 0.277415).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.7623412609100342
Epoch: 21, Steps: 61 | Train Loss: 0.1526036 Vali Loss: 0.2755981 Test Loss: 0.3020203
Validation loss decreased (0.277415 --> 0.275598).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.818382978439331
Epoch: 22, Steps: 61 | Train Loss: 0.1490348 Vali Loss: 0.2747448 Test Loss: 0.3011125
Validation loss decreased (0.275598 --> 0.274745).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.7041218280792236
Epoch: 23, Steps: 61 | Train Loss: 0.1460019 Vali Loss: 0.2721937 Test Loss: 0.3002147
Validation loss decreased (0.274745 --> 0.272194).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.7217233180999756
Epoch: 24, Steps: 61 | Train Loss: 0.1430736 Vali Loss: 0.2706783 Test Loss: 0.2992783
Validation loss decreased (0.272194 --> 0.270678).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.7657461166381836
Epoch: 25, Steps: 61 | Train Loss: 0.1402889 Vali Loss: 0.2711765 Test Loss: 0.2985198
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.8403544425964355
Epoch: 26, Steps: 61 | Train Loss: 0.1379215 Vali Loss: 0.2692183 Test Loss: 0.2977346
Validation loss decreased (0.270678 --> 0.269218).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.5677671432495117
Epoch: 27, Steps: 61 | Train Loss: 0.1356546 Vali Loss: 0.2683840 Test Loss: 0.2970012
Validation loss decreased (0.269218 --> 0.268384).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.677779197692871
Epoch: 28, Steps: 61 | Train Loss: 0.1335083 Vali Loss: 0.2666806 Test Loss: 0.2963858
Validation loss decreased (0.268384 --> 0.266681).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.5871670246124268
Epoch: 29, Steps: 61 | Train Loss: 0.1314873 Vali Loss: 0.2656659 Test Loss: 0.2957056
Validation loss decreased (0.266681 --> 0.265666).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.8317680358886719
Epoch: 30, Steps: 61 | Train Loss: 0.1295220 Vali Loss: 0.2647040 Test Loss: 0.2951591
Validation loss decreased (0.265666 --> 0.264704).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.7304272651672363
Epoch: 31, Steps: 61 | Train Loss: 0.1279073 Vali Loss: 0.2641420 Test Loss: 0.2945988
Validation loss decreased (0.264704 --> 0.264142).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.6555218696594238
Epoch: 32, Steps: 61 | Train Loss: 0.1263032 Vali Loss: 0.2638309 Test Loss: 0.2940956
Validation loss decreased (0.264142 --> 0.263831).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.7077887058258057
Epoch: 33, Steps: 61 | Train Loss: 0.1247293 Vali Loss: 0.2627026 Test Loss: 0.2935678
Validation loss decreased (0.263831 --> 0.262703).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.8102543354034424
Epoch: 34, Steps: 61 | Train Loss: 0.1234060 Vali Loss: 0.2620090 Test Loss: 0.2931744
Validation loss decreased (0.262703 --> 0.262009).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.55155348777771
Epoch: 35, Steps: 61 | Train Loss: 0.1220886 Vali Loss: 0.2616554 Test Loss: 0.2927141
Validation loss decreased (0.262009 --> 0.261655).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.7841393947601318
Epoch: 36, Steps: 61 | Train Loss: 0.1208830 Vali Loss: 0.2610493 Test Loss: 0.2923257
Validation loss decreased (0.261655 --> 0.261049).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.7716567516326904
Epoch: 37, Steps: 61 | Train Loss: 0.1196364 Vali Loss: 0.2601581 Test Loss: 0.2919138
Validation loss decreased (0.261049 --> 0.260158).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.7015297412872314
Epoch: 38, Steps: 61 | Train Loss: 0.1186149 Vali Loss: 0.2591455 Test Loss: 0.2915778
Validation loss decreased (0.260158 --> 0.259145).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.7580227851867676
Epoch: 39, Steps: 61 | Train Loss: 0.1176063 Vali Loss: 0.2592155 Test Loss: 0.2912108
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.0943169593811035
Epoch: 40, Steps: 61 | Train Loss: 0.1165740 Vali Loss: 0.2580531 Test Loss: 0.2909131
Validation loss decreased (0.259145 --> 0.258053).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.8523304462432861
Epoch: 41, Steps: 61 | Train Loss: 0.1156354 Vali Loss: 0.2578968 Test Loss: 0.2905669
Validation loss decreased (0.258053 --> 0.257897).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.6268982887268066
Epoch: 42, Steps: 61 | Train Loss: 0.1149284 Vali Loss: 0.2573656 Test Loss: 0.2902589
Validation loss decreased (0.257897 --> 0.257366).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.7933025360107422
Epoch: 43, Steps: 61 | Train Loss: 0.1140692 Vali Loss: 0.2576274 Test Loss: 0.2899973
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.6851575374603271
Epoch: 44, Steps: 61 | Train Loss: 0.1133580 Vali Loss: 0.2562310 Test Loss: 0.2897469
Validation loss decreased (0.257366 --> 0.256231).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.893369436264038
Epoch: 45, Steps: 61 | Train Loss: 0.1126342 Vali Loss: 0.2559148 Test Loss: 0.2894807
Validation loss decreased (0.256231 --> 0.255915).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.7898883819580078
Epoch: 46, Steps: 61 | Train Loss: 0.1119094 Vali Loss: 0.2566877 Test Loss: 0.2892646
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.7525990009307861
Epoch: 47, Steps: 61 | Train Loss: 0.1113046 Vali Loss: 0.2550479 Test Loss: 0.2890522
Validation loss decreased (0.255915 --> 0.255048).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.9155826568603516
Epoch: 48, Steps: 61 | Train Loss: 0.1104500 Vali Loss: 0.2550114 Test Loss: 0.2887995
Validation loss decreased (0.255048 --> 0.255011).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.7103569507598877
Epoch: 49, Steps: 61 | Train Loss: 0.1100655 Vali Loss: 0.2545443 Test Loss: 0.2886400
Validation loss decreased (0.255011 --> 0.254544).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.657397985458374
Epoch: 50, Steps: 61 | Train Loss: 0.1095847 Vali Loss: 0.2541918 Test Loss: 0.2884575
Validation loss decreased (0.254544 --> 0.254192).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.7430799007415771
Epoch: 51, Steps: 61 | Train Loss: 0.1091269 Vali Loss: 0.2544035 Test Loss: 0.2882964
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.7333600521087646
Epoch: 52, Steps: 61 | Train Loss: 0.1086473 Vali Loss: 0.2538010 Test Loss: 0.2881156
Validation loss decreased (0.254192 --> 0.253801).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.448768138885498
Epoch: 53, Steps: 61 | Train Loss: 0.1080904 Vali Loss: 0.2539236 Test Loss: 0.2879791
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.8001186847686768
Epoch: 54, Steps: 61 | Train Loss: 0.1077162 Vali Loss: 0.2535306 Test Loss: 0.2877994
Validation loss decreased (0.253801 --> 0.253531).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.7269930839538574
Epoch: 55, Steps: 61 | Train Loss: 0.1073770 Vali Loss: 0.2526563 Test Loss: 0.2876588
Validation loss decreased (0.253531 --> 0.252656).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.576094627380371
Epoch: 56, Steps: 61 | Train Loss: 0.1068364 Vali Loss: 0.2524243 Test Loss: 0.2875328
Validation loss decreased (0.252656 --> 0.252424).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.4377689361572266
Epoch: 57, Steps: 61 | Train Loss: 0.1066221 Vali Loss: 0.2519116 Test Loss: 0.2874218
Validation loss decreased (0.252424 --> 0.251912).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.7928745746612549
Epoch: 58, Steps: 61 | Train Loss: 0.1062236 Vali Loss: 0.2523326 Test Loss: 0.2872753
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.6931393146514893
Epoch: 59, Steps: 61 | Train Loss: 0.1059310 Vali Loss: 0.2523156 Test Loss: 0.2871863
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.5478198528289795
Epoch: 60, Steps: 61 | Train Loss: 0.1055801 Vali Loss: 0.2524514 Test Loss: 0.2870707
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.5172631740570068
Epoch: 61, Steps: 61 | Train Loss: 0.1051822 Vali Loss: 0.2518243 Test Loss: 0.2869344
Validation loss decreased (0.251912 --> 0.251824).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.7054157257080078
Epoch: 62, Steps: 61 | Train Loss: 0.1050112 Vali Loss: 0.2516792 Test Loss: 0.2868380
Validation loss decreased (0.251824 --> 0.251679).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.5345165729522705
Epoch: 63, Steps: 61 | Train Loss: 0.1047446 Vali Loss: 0.2510906 Test Loss: 0.2867495
Validation loss decreased (0.251679 --> 0.251091).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.6153390407562256
Epoch: 64, Steps: 61 | Train Loss: 0.1044963 Vali Loss: 0.2508321 Test Loss: 0.2866694
Validation loss decreased (0.251091 --> 0.250832).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.5891211032867432
Epoch: 65, Steps: 61 | Train Loss: 0.1041781 Vali Loss: 0.2516175 Test Loss: 0.2865853
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.5854828357696533
Epoch: 66, Steps: 61 | Train Loss: 0.1039580 Vali Loss: 0.2504186 Test Loss: 0.2864950
Validation loss decreased (0.250832 --> 0.250419).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.445692777633667
Epoch: 67, Steps: 61 | Train Loss: 0.1037452 Vali Loss: 0.2515095 Test Loss: 0.2864200
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.6073358058929443
Epoch: 68, Steps: 61 | Train Loss: 0.1034915 Vali Loss: 0.2492884 Test Loss: 0.2863453
Validation loss decreased (0.250419 --> 0.249288).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.862065315246582
Epoch: 69, Steps: 61 | Train Loss: 0.1033840 Vali Loss: 0.2520274 Test Loss: 0.2862916
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.8622045516967773
Epoch: 70, Steps: 61 | Train Loss: 0.1031371 Vali Loss: 0.2511769 Test Loss: 0.2862200
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.569856882095337
Epoch: 71, Steps: 61 | Train Loss: 0.1029882 Vali Loss: 0.2508101 Test Loss: 0.2861581
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.6112799644470215
Epoch: 72, Steps: 61 | Train Loss: 0.1027060 Vali Loss: 0.2512060 Test Loss: 0.2860927
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.8085503578186035
Epoch: 73, Steps: 61 | Train Loss: 0.1026771 Vali Loss: 0.2507843 Test Loss: 0.2860393
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.758469581604004
Epoch: 74, Steps: 61 | Train Loss: 0.1026348 Vali Loss: 0.2493528 Test Loss: 0.2859885
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.6152546405792236
Epoch: 75, Steps: 61 | Train Loss: 0.1023666 Vali Loss: 0.2504988 Test Loss: 0.2859400
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.6970584392547607
Epoch: 76, Steps: 61 | Train Loss: 0.1023487 Vali Loss: 0.2510739 Test Loss: 0.2858918
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.717235803604126
Epoch: 77, Steps: 61 | Train Loss: 0.1021633 Vali Loss: 0.2505030 Test Loss: 0.2858452
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.5862252712249756
Epoch: 78, Steps: 61 | Train Loss: 0.1020490 Vali Loss: 0.2500003 Test Loss: 0.2858005
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.8110730648040771
Epoch: 79, Steps: 61 | Train Loss: 0.1018216 Vali Loss: 0.2505108 Test Loss: 0.2857589
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.9267945289611816
Epoch: 80, Steps: 61 | Train Loss: 0.1017844 Vali Loss: 0.2498434 Test Loss: 0.2857194
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.9662988185882568
Epoch: 81, Steps: 61 | Train Loss: 0.1016848 Vali Loss: 0.2500180 Test Loss: 0.2856790
EarlyStopping counter: 13 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.9160740375518799
Epoch: 82, Steps: 61 | Train Loss: 0.1015818 Vali Loss: 0.2506517 Test Loss: 0.2856464
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.7950286865234375
Epoch: 83, Steps: 61 | Train Loss: 0.1014093 Vali Loss: 0.2500923 Test Loss: 0.2856100
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.7999002933502197
Epoch: 84, Steps: 61 | Train Loss: 0.1013678 Vali Loss: 0.2496223 Test Loss: 0.2855773
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.157278537750244
Epoch: 85, Steps: 61 | Train Loss: 0.1012840 Vali Loss: 0.2502530 Test Loss: 0.2855458
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.853996753692627
Epoch: 86, Steps: 61 | Train Loss: 0.1011072 Vali Loss: 0.2495769 Test Loss: 0.2855129
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.8386964797973633
Epoch: 87, Steps: 61 | Train Loss: 0.1012012 Vali Loss: 0.2502667 Test Loss: 0.2854878
EarlyStopping counter: 19 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.901484727859497
Epoch: 88, Steps: 61 | Train Loss: 0.1010147 Vali Loss: 0.2499568 Test Loss: 0.2854626
EarlyStopping counter: 20 out of 20
Early stopping
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=134, out_features=151, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  18129664.0
params:  20385.0
Trainable parameters:  20385
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.7744596004486084
Epoch: 1, Steps: 61 | Train Loss: 0.4266303 Vali Loss: 0.2261939 Test Loss: 0.2744241
Validation loss decreased (inf --> 0.226194).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.8190484046936035
Epoch: 2, Steps: 61 | Train Loss: 0.4137760 Vali Loss: 0.2202201 Test Loss: 0.2737368
Validation loss decreased (0.226194 --> 0.220220).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.9102864265441895
Epoch: 3, Steps: 61 | Train Loss: 0.4102311 Vali Loss: 0.2190885 Test Loss: 0.2741009
Validation loss decreased (0.220220 --> 0.219088).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.8933117389678955
Epoch: 4, Steps: 61 | Train Loss: 0.4082636 Vali Loss: 0.2189513 Test Loss: 0.2736956
Validation loss decreased (0.219088 --> 0.218951).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.89813232421875
Epoch: 5, Steps: 61 | Train Loss: 0.4072000 Vali Loss: 0.2164098 Test Loss: 0.2734855
Validation loss decreased (0.218951 --> 0.216410).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.8190491199493408
Epoch: 6, Steps: 61 | Train Loss: 0.4055755 Vali Loss: 0.2164632 Test Loss: 0.2735326
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.0009987354278564
Epoch: 7, Steps: 61 | Train Loss: 0.4052060 Vali Loss: 0.2157997 Test Loss: 0.2734454
Validation loss decreased (0.216410 --> 0.215800).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.7087204456329346
Epoch: 8, Steps: 61 | Train Loss: 0.4050607 Vali Loss: 0.2146879 Test Loss: 0.2731068
Validation loss decreased (0.215800 --> 0.214688).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.90144681930542
Epoch: 9, Steps: 61 | Train Loss: 0.4040955 Vali Loss: 0.2134955 Test Loss: 0.2730049
Validation loss decreased (0.214688 --> 0.213496).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.8331117630004883
Epoch: 10, Steps: 61 | Train Loss: 0.4031953 Vali Loss: 0.2135744 Test Loss: 0.2731631
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.743603229522705
Epoch: 11, Steps: 61 | Train Loss: 0.4012742 Vali Loss: 0.2140894 Test Loss: 0.2730148
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.836336612701416
Epoch: 12, Steps: 61 | Train Loss: 0.4022480 Vali Loss: 0.2130569 Test Loss: 0.2727190
Validation loss decreased (0.213496 --> 0.213057).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.0023016929626465
Epoch: 13, Steps: 61 | Train Loss: 0.4025540 Vali Loss: 0.2128097 Test Loss: 0.2727417
Validation loss decreased (0.213057 --> 0.212810).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.9921398162841797
Epoch: 14, Steps: 61 | Train Loss: 0.4028648 Vali Loss: 0.2118985 Test Loss: 0.2727862
Validation loss decreased (0.212810 --> 0.211898).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.8649623394012451
Epoch: 15, Steps: 61 | Train Loss: 0.4028981 Vali Loss: 0.2136789 Test Loss: 0.2728830
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.8262994289398193
Epoch: 16, Steps: 61 | Train Loss: 0.4022423 Vali Loss: 0.2136717 Test Loss: 0.2727124
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.944969892501831
Epoch: 17, Steps: 61 | Train Loss: 0.4023000 Vali Loss: 0.2130757 Test Loss: 0.2725145
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.0832111835479736
Epoch: 18, Steps: 61 | Train Loss: 0.4021984 Vali Loss: 0.2140635 Test Loss: 0.2727258
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.936549425125122
Epoch: 19, Steps: 61 | Train Loss: 0.4019444 Vali Loss: 0.2135358 Test Loss: 0.2725459
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.8136892318725586
Epoch: 20, Steps: 61 | Train Loss: 0.4018098 Vali Loss: 0.2133090 Test Loss: 0.2725859
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.840712547302246
Epoch: 21, Steps: 61 | Train Loss: 0.4018978 Vali Loss: 0.2138977 Test Loss: 0.2725547
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.6734001636505127
Epoch: 22, Steps: 61 | Train Loss: 0.4005940 Vali Loss: 0.2131130 Test Loss: 0.2725118
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.9625349044799805
Epoch: 23, Steps: 61 | Train Loss: 0.4008638 Vali Loss: 0.2124495 Test Loss: 0.2725272
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.772576093673706
Epoch: 24, Steps: 61 | Train Loss: 0.4012959 Vali Loss: 0.2133206 Test Loss: 0.2724395
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.846708059310913
Epoch: 25, Steps: 61 | Train Loss: 0.4013532 Vali Loss: 0.2132222 Test Loss: 0.2725136
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.7504210472106934
Epoch: 26, Steps: 61 | Train Loss: 0.4013472 Vali Loss: 0.2125225 Test Loss: 0.2724257
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.8919768333435059
Epoch: 27, Steps: 61 | Train Loss: 0.4002828 Vali Loss: 0.2124912 Test Loss: 0.2724878
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.9114725589752197
Epoch: 28, Steps: 61 | Train Loss: 0.4010620 Vali Loss: 0.2128264 Test Loss: 0.2723983
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.85117506980896
Epoch: 29, Steps: 61 | Train Loss: 0.3999395 Vali Loss: 0.2119802 Test Loss: 0.2724170
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.9441490173339844
Epoch: 30, Steps: 61 | Train Loss: 0.4007496 Vali Loss: 0.2126504 Test Loss: 0.2724751
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.9452030658721924
Epoch: 31, Steps: 61 | Train Loss: 0.4009382 Vali Loss: 0.2133237 Test Loss: 0.2724489
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.1204159259796143
Epoch: 32, Steps: 61 | Train Loss: 0.4008753 Vali Loss: 0.2135636 Test Loss: 0.2723827
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.042279005050659
Epoch: 33, Steps: 61 | Train Loss: 0.4002357 Vali Loss: 0.2126775 Test Loss: 0.2724448
EarlyStopping counter: 19 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.9395813941955566
Epoch: 34, Steps: 61 | Train Loss: 0.4007200 Vali Loss: 0.2115281 Test Loss: 0.2723611
Validation loss decreased (0.211898 --> 0.211528).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.6526451110839844
Epoch: 35, Steps: 61 | Train Loss: 0.4000180 Vali Loss: 0.2126013 Test Loss: 0.2723342
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.8639509677886963
Epoch: 36, Steps: 61 | Train Loss: 0.4007517 Vali Loss: 0.2125861 Test Loss: 0.2723948
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.967132568359375
Epoch: 37, Steps: 61 | Train Loss: 0.4002174 Vali Loss: 0.2126664 Test Loss: 0.2723644
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.9668495655059814
Epoch: 38, Steps: 61 | Train Loss: 0.4008023 Vali Loss: 0.2117391 Test Loss: 0.2723035
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.8880817890167236
Epoch: 39, Steps: 61 | Train Loss: 0.4000855 Vali Loss: 0.2131952 Test Loss: 0.2723870
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.9399724006652832
Epoch: 40, Steps: 61 | Train Loss: 0.4006000 Vali Loss: 0.2126705 Test Loss: 0.2723589
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.231692314147949
Epoch: 41, Steps: 61 | Train Loss: 0.4006467 Vali Loss: 0.2124560 Test Loss: 0.2723283
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.9068372249603271
Epoch: 42, Steps: 61 | Train Loss: 0.3995316 Vali Loss: 0.2120791 Test Loss: 0.2723241
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.9662988185882568
Epoch: 43, Steps: 61 | Train Loss: 0.4003587 Vali Loss: 0.2120833 Test Loss: 0.2723542
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.5997669696807861
Epoch: 44, Steps: 61 | Train Loss: 0.4004838 Vali Loss: 0.2122484 Test Loss: 0.2723998
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.800825595855713
Epoch: 45, Steps: 61 | Train Loss: 0.3991273 Vali Loss: 0.2115034 Test Loss: 0.2722988
Validation loss decreased (0.211528 --> 0.211503).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.863879919052124
Epoch: 46, Steps: 61 | Train Loss: 0.3987509 Vali Loss: 0.2125194 Test Loss: 0.2723293
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.9012367725372314
Epoch: 47, Steps: 61 | Train Loss: 0.4003986 Vali Loss: 0.2122740 Test Loss: 0.2723609
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.9230351448059082
Epoch: 48, Steps: 61 | Train Loss: 0.4004117 Vali Loss: 0.2120333 Test Loss: 0.2723211
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.8402369022369385
Epoch: 49, Steps: 61 | Train Loss: 0.3989833 Vali Loss: 0.2126902 Test Loss: 0.2723430
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.7215662002563477
Epoch: 50, Steps: 61 | Train Loss: 0.4001731 Vali Loss: 0.2116582 Test Loss: 0.2723259
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.697282075881958
Epoch: 51, Steps: 61 | Train Loss: 0.4001922 Vali Loss: 0.2124696 Test Loss: 0.2723197
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.9576177597045898
Epoch: 52, Steps: 61 | Train Loss: 0.3998324 Vali Loss: 0.2110936 Test Loss: 0.2723094
Validation loss decreased (0.211503 --> 0.211094).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.9655630588531494
Epoch: 53, Steps: 61 | Train Loss: 0.4001506 Vali Loss: 0.2120753 Test Loss: 0.2722987
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.858130693435669
Epoch: 54, Steps: 61 | Train Loss: 0.3999418 Vali Loss: 0.2115136 Test Loss: 0.2722845
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.0161941051483154
Epoch: 55, Steps: 61 | Train Loss: 0.4003364 Vali Loss: 0.2123273 Test Loss: 0.2722795
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.018752098083496
Epoch: 56, Steps: 61 | Train Loss: 0.3998218 Vali Loss: 0.2122283 Test Loss: 0.2722860
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.948789119720459
Epoch: 57, Steps: 61 | Train Loss: 0.3995263 Vali Loss: 0.2118325 Test Loss: 0.2722677
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.834465503692627
Epoch: 58, Steps: 61 | Train Loss: 0.3997422 Vali Loss: 0.2122740 Test Loss: 0.2722895
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.011230230331421
Epoch: 59, Steps: 61 | Train Loss: 0.4002139 Vali Loss: 0.2118373 Test Loss: 0.2722936
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.8655943870544434
Epoch: 60, Steps: 61 | Train Loss: 0.3981460 Vali Loss: 0.2122997 Test Loss: 0.2723055
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.0775222778320312
Epoch: 61, Steps: 61 | Train Loss: 0.4002318 Vali Loss: 0.2116821 Test Loss: 0.2722956
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.927696704864502
Epoch: 62, Steps: 61 | Train Loss: 0.4000772 Vali Loss: 0.2127034 Test Loss: 0.2722988
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.9277312755584717
Epoch: 63, Steps: 61 | Train Loss: 0.4002685 Vali Loss: 0.2123949 Test Loss: 0.2723099
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.766101598739624
Epoch: 64, Steps: 61 | Train Loss: 0.3993516 Vali Loss: 0.2124799 Test Loss: 0.2722689
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.7371001243591309
Epoch: 65, Steps: 61 | Train Loss: 0.3995137 Vali Loss: 0.2120551 Test Loss: 0.2722812
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.8404314517974854
Epoch: 66, Steps: 61 | Train Loss: 0.4002963 Vali Loss: 0.2131988 Test Loss: 0.2722834
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.9525578022003174
Epoch: 67, Steps: 61 | Train Loss: 0.4001020 Vali Loss: 0.2111194 Test Loss: 0.2722628
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.9652221202850342
Epoch: 68, Steps: 61 | Train Loss: 0.3993949 Vali Loss: 0.2130520 Test Loss: 0.2722778
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.0227341651916504
Epoch: 69, Steps: 61 | Train Loss: 0.4002155 Vali Loss: 0.2115483 Test Loss: 0.2722765
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.7903532981872559
Epoch: 70, Steps: 61 | Train Loss: 0.4003452 Vali Loss: 0.2125939 Test Loss: 0.2722796
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.843693494796753
Epoch: 71, Steps: 61 | Train Loss: 0.4001141 Vali Loss: 0.2122597 Test Loss: 0.2722867
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.9113969802856445
Epoch: 72, Steps: 61 | Train Loss: 0.4001304 Vali Loss: 0.2123625 Test Loss: 0.2722815
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.2720305323600769, mae:0.33675968647003174, rse:0.420329749584198, corr:[0.27367434 0.27584162 0.2750085  0.27381408 0.27314168 0.27290395
 0.27240548 0.2713619  0.2704398  0.2695148  0.2684553  0.2668304
 0.26513854 0.2639743  0.26329738 0.26308262 0.26272604 0.2620384
 0.26102033 0.2599979  0.2591383  0.2581047  0.25665706 0.25466892
 0.2526043  0.25089234 0.2495625  0.24828699 0.24697784 0.24569601
 0.24444757 0.24312772 0.24160863 0.24026082 0.23916245 0.23807673
 0.23688127 0.23565364 0.23475817 0.23400712 0.23344882 0.23293233
 0.23217243 0.23108551 0.23011474 0.22925855 0.22833355 0.22681653
 0.22472928 0.22267172 0.22129957 0.22008508 0.21899505 0.21761535
 0.21556896 0.21354602 0.21182704 0.21021056 0.20870808 0.2075827
 0.20703979 0.20669524 0.20658152 0.20665509 0.20612207 0.20568542
 0.20534328 0.20491177 0.20426805 0.20351121 0.20266342 0.2021733
 0.20180602 0.20107526 0.19997989 0.19830649 0.19725895 0.19693746
 0.19695176 0.19619343 0.19576335 0.19584921 0.19575515 0.19527271
 0.19459136 0.19454667 0.19505931 0.19555782 0.19469595 0.19344804
 0.19285358 0.19325809 0.19399227 0.19304107 0.19074108 0.19187683]
