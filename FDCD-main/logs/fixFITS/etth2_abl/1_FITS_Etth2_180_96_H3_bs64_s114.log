Args in experiment:
Namespace(H_order=3, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=34, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_180_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_180_96_FITS_ETTh2_ftM_sl180_ll48_pl96_H3_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8365
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=34, out_features=52, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1584128.0
params:  1820.0
Trainable parameters:  1820
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.0639665126800537
Epoch: 1, Steps: 65 | Train Loss: 0.5910910 Vali Loss: 0.2762402 Test Loss: 0.3771278
Validation loss decreased (inf --> 0.276240).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.3162133693695068
Epoch: 2, Steps: 65 | Train Loss: 0.4969647 Vali Loss: 0.2452557 Test Loss: 0.3364511
Validation loss decreased (0.276240 --> 0.245256).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.4872725009918213
Epoch: 3, Steps: 65 | Train Loss: 0.4648768 Vali Loss: 0.2303155 Test Loss: 0.3195523
Validation loss decreased (0.245256 --> 0.230315).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.3415777683258057
Epoch: 4, Steps: 65 | Train Loss: 0.4493360 Vali Loss: 0.2252098 Test Loss: 0.3112017
Validation loss decreased (0.230315 --> 0.225210).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.8313379287719727
Epoch: 5, Steps: 65 | Train Loss: 0.4398306 Vali Loss: 0.2230235 Test Loss: 0.3064407
Validation loss decreased (0.225210 --> 0.223024).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.952439546585083
Epoch: 6, Steps: 65 | Train Loss: 0.4331010 Vali Loss: 0.2203107 Test Loss: 0.3033563
Validation loss decreased (0.223024 --> 0.220311).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.769263505935669
Epoch: 7, Steps: 65 | Train Loss: 0.4299882 Vali Loss: 0.2184392 Test Loss: 0.3012051
Validation loss decreased (0.220311 --> 0.218439).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.7824888229370117
Epoch: 8, Steps: 65 | Train Loss: 0.4282597 Vali Loss: 0.2166766 Test Loss: 0.2993888
Validation loss decreased (0.218439 --> 0.216677).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.4344146251678467
Epoch: 9, Steps: 65 | Train Loss: 0.4247403 Vali Loss: 0.2161839 Test Loss: 0.2981176
Validation loss decreased (0.216677 --> 0.216184).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.6137330532073975
Epoch: 10, Steps: 65 | Train Loss: 0.4226245 Vali Loss: 0.2139436 Test Loss: 0.2970074
Validation loss decreased (0.216184 --> 0.213944).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.0596115589141846
Epoch: 11, Steps: 65 | Train Loss: 0.4215308 Vali Loss: 0.2151285 Test Loss: 0.2961494
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.961069107055664
Epoch: 12, Steps: 65 | Train Loss: 0.4213702 Vali Loss: 0.2138854 Test Loss: 0.2953368
Validation loss decreased (0.213944 --> 0.213885).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.524456262588501
Epoch: 13, Steps: 65 | Train Loss: 0.4202295 Vali Loss: 0.2130673 Test Loss: 0.2946722
Validation loss decreased (0.213885 --> 0.213067).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.4367740154266357
Epoch: 14, Steps: 65 | Train Loss: 0.4184058 Vali Loss: 0.2127449 Test Loss: 0.2940804
Validation loss decreased (0.213067 --> 0.212745).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.6282365322113037
Epoch: 15, Steps: 65 | Train Loss: 0.4175780 Vali Loss: 0.2128613 Test Loss: 0.2935070
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.6363756656646729
Epoch: 16, Steps: 65 | Train Loss: 0.4173510 Vali Loss: 0.2119542 Test Loss: 0.2931447
Validation loss decreased (0.212745 --> 0.211954).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.5699245929718018
Epoch: 17, Steps: 65 | Train Loss: 0.4164936 Vali Loss: 0.2113672 Test Loss: 0.2927979
Validation loss decreased (0.211954 --> 0.211367).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.705625295639038
Epoch: 18, Steps: 65 | Train Loss: 0.4150351 Vali Loss: 0.2116232 Test Loss: 0.2925216
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.6041016578674316
Epoch: 19, Steps: 65 | Train Loss: 0.4154031 Vali Loss: 0.2113331 Test Loss: 0.2921458
Validation loss decreased (0.211367 --> 0.211333).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.8145813941955566
Epoch: 20, Steps: 65 | Train Loss: 0.4147880 Vali Loss: 0.2102408 Test Loss: 0.2918957
Validation loss decreased (0.211333 --> 0.210241).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 5.812122344970703
Epoch: 21, Steps: 65 | Train Loss: 0.4145763 Vali Loss: 0.2105784 Test Loss: 0.2916794
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.7220563888549805
Epoch: 22, Steps: 65 | Train Loss: 0.4137426 Vali Loss: 0.2112318 Test Loss: 0.2914761
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.4264249801635742
Epoch: 23, Steps: 65 | Train Loss: 0.4126275 Vali Loss: 0.2094804 Test Loss: 0.2911825
Validation loss decreased (0.210241 --> 0.209480).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.824683427810669
Epoch: 24, Steps: 65 | Train Loss: 0.4105171 Vali Loss: 0.2095602 Test Loss: 0.2910604
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.9389090538024902
Epoch: 25, Steps: 65 | Train Loss: 0.4134770 Vali Loss: 0.2102152 Test Loss: 0.2908769
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.5338435173034668
Epoch: 26, Steps: 65 | Train Loss: 0.4120701 Vali Loss: 0.2095509 Test Loss: 0.2907987
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.0008952617645264
Epoch: 27, Steps: 65 | Train Loss: 0.4125421 Vali Loss: 0.2113162 Test Loss: 0.2905893
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.8002715110778809
Epoch: 28, Steps: 65 | Train Loss: 0.4109835 Vali Loss: 0.2100497 Test Loss: 0.2904833
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.6070895195007324
Epoch: 29, Steps: 65 | Train Loss: 0.4117766 Vali Loss: 0.2105129 Test Loss: 0.2903963
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.4648175239562988
Epoch: 30, Steps: 65 | Train Loss: 0.4119453 Vali Loss: 0.2091361 Test Loss: 0.2902734
Validation loss decreased (0.209480 --> 0.209136).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.7630679607391357
Epoch: 31, Steps: 65 | Train Loss: 0.4115549 Vali Loss: 0.2079024 Test Loss: 0.2901810
Validation loss decreased (0.209136 --> 0.207902).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.3115720748901367
Epoch: 32, Steps: 65 | Train Loss: 0.4110944 Vali Loss: 0.2111335 Test Loss: 0.2901161
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.8681342601776123
Epoch: 33, Steps: 65 | Train Loss: 0.4104134 Vali Loss: 0.2108979 Test Loss: 0.2900301
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.9063537120819092
Epoch: 34, Steps: 65 | Train Loss: 0.4108485 Vali Loss: 0.2100242 Test Loss: 0.2899680
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.704221487045288
Epoch: 35, Steps: 65 | Train Loss: 0.4112009 Vali Loss: 0.2085725 Test Loss: 0.2898848
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.5654332637786865
Epoch: 36, Steps: 65 | Train Loss: 0.4096345 Vali Loss: 0.2095507 Test Loss: 0.2898516
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.5668010711669922
Epoch: 37, Steps: 65 | Train Loss: 0.4110722 Vali Loss: 0.2091525 Test Loss: 0.2897587
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.8267152309417725
Epoch: 38, Steps: 65 | Train Loss: 0.4103924 Vali Loss: 0.2087670 Test Loss: 0.2896999
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.714461088180542
Epoch: 39, Steps: 65 | Train Loss: 0.4099440 Vali Loss: 0.2086472 Test Loss: 0.2896515
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.3015074729919434
Epoch: 40, Steps: 65 | Train Loss: 0.4103599 Vali Loss: 0.2092093 Test Loss: 0.2896257
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.3939871788024902
Epoch: 41, Steps: 65 | Train Loss: 0.4103978 Vali Loss: 0.2097556 Test Loss: 0.2895836
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.8357913494110107
Epoch: 42, Steps: 65 | Train Loss: 0.4101237 Vali Loss: 0.2091496 Test Loss: 0.2895050
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.736386775970459
Epoch: 43, Steps: 65 | Train Loss: 0.4106355 Vali Loss: 0.2088865 Test Loss: 0.2895108
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.4460198879241943
Epoch: 44, Steps: 65 | Train Loss: 0.4087531 Vali Loss: 0.2088717 Test Loss: 0.2894692
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.7938337326049805
Epoch: 45, Steps: 65 | Train Loss: 0.4102973 Vali Loss: 0.2095238 Test Loss: 0.2894216
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.7957394123077393
Epoch: 46, Steps: 65 | Train Loss: 0.4084680 Vali Loss: 0.2101046 Test Loss: 0.2893777
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.6591839790344238
Epoch: 47, Steps: 65 | Train Loss: 0.4104027 Vali Loss: 0.2085998 Test Loss: 0.2893628
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.2890944480895996
Epoch: 48, Steps: 65 | Train Loss: 0.4099721 Vali Loss: 0.2088572 Test Loss: 0.2893326
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.7901418209075928
Epoch: 49, Steps: 65 | Train Loss: 0.4097813 Vali Loss: 0.2089700 Test Loss: 0.2893075
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.952434778213501
Epoch: 50, Steps: 65 | Train Loss: 0.4103331 Vali Loss: 0.2093510 Test Loss: 0.2892843
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.794769048690796
Epoch: 51, Steps: 65 | Train Loss: 0.4098542 Vali Loss: 0.2088464 Test Loss: 0.2892521
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_180_96_FITS_ETTh2_ftM_sl180_ll48_pl96_H3_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.2898031771183014, mae:0.3420286178588867, rse:0.4338432848453522, corr:[0.2728876  0.27765742 0.27725977 0.2750355  0.27397856 0.27347717
 0.27255887 0.27122506 0.27003625 0.2688595  0.26732767 0.26543903
 0.26396006 0.26295242 0.26213953 0.26123857 0.26032206 0.2595393
 0.25874117 0.25777003 0.2564894  0.25501224 0.25341794 0.25146574
 0.2489296  0.24633425 0.24414091 0.2428272  0.2417727  0.24029753
 0.23805039 0.23554544 0.23368914 0.2326283  0.2316008  0.22985387
 0.22769785 0.22597201 0.2254241  0.22509965 0.22435476 0.22302972
 0.22187665 0.22133237 0.22110349 0.22012213 0.21793716 0.21522264
 0.21261701 0.21075957 0.20890352 0.20679455 0.20469086 0.20331521
 0.20212658 0.20047542 0.19843736 0.19644733 0.19542179 0.19508058
 0.1948846  0.19381209 0.19289882 0.19260474 0.19294408 0.19291289
 0.19185476 0.1902754  0.1896904  0.19017132 0.19007553 0.18853481
 0.18553069 0.18325748 0.18255413 0.18243358 0.18145101 0.1798988
 0.17865129 0.17848733 0.17925824 0.17934427 0.17854889 0.17787874
 0.17867337 0.17980152 0.18012117 0.17893298 0.17793825 0.17858243
 0.1800317  0.17971073 0.17797433 0.17817807 0.18155468 0.18332413]
