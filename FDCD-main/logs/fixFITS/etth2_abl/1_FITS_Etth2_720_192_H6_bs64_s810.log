Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=810, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=196, out_features=248, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  43552768.0
params:  48856.0
Trainable parameters:  48856
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.602781057357788
Epoch: 1, Steps: 60 | Train Loss: 0.7160205 Vali Loss: 0.3799093 Test Loss: 0.3958308
Validation loss decreased (inf --> 0.379909).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.7001233100891113
Epoch: 2, Steps: 60 | Train Loss: 0.5839433 Vali Loss: 0.3340854 Test Loss: 0.3740723
Validation loss decreased (0.379909 --> 0.334085).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.5351245403289795
Epoch: 3, Steps: 60 | Train Loss: 0.5547325 Vali Loss: 0.3172272 Test Loss: 0.3664736
Validation loss decreased (0.334085 --> 0.317227).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.5782887935638428
Epoch: 4, Steps: 60 | Train Loss: 0.5426525 Vali Loss: 0.3094209 Test Loss: 0.3625634
Validation loss decreased (0.317227 --> 0.309421).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.4100937843322754
Epoch: 5, Steps: 60 | Train Loss: 0.5361996 Vali Loss: 0.3044999 Test Loss: 0.3603354
Validation loss decreased (0.309421 --> 0.304500).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.4109413623809814
Epoch: 6, Steps: 60 | Train Loss: 0.5321481 Vali Loss: 0.3007316 Test Loss: 0.3591655
Validation loss decreased (0.304500 --> 0.300732).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.9895706176757812
Epoch: 7, Steps: 60 | Train Loss: 0.5285002 Vali Loss: 0.2986012 Test Loss: 0.3580225
Validation loss decreased (0.300732 --> 0.298601).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.5143308639526367
Epoch: 8, Steps: 60 | Train Loss: 0.5231493 Vali Loss: 0.2960957 Test Loss: 0.3576602
Validation loss decreased (0.298601 --> 0.296096).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.4129033088684082
Epoch: 9, Steps: 60 | Train Loss: 0.5219867 Vali Loss: 0.2943043 Test Loss: 0.3569915
Validation loss decreased (0.296096 --> 0.294304).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.4614105224609375
Epoch: 10, Steps: 60 | Train Loss: 0.5225654 Vali Loss: 0.2930832 Test Loss: 0.3565378
Validation loss decreased (0.294304 --> 0.293083).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.3998050689697266
Epoch: 11, Steps: 60 | Train Loss: 0.5198882 Vali Loss: 0.2925295 Test Loss: 0.3558674
Validation loss decreased (0.293083 --> 0.292529).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.3930914402008057
Epoch: 12, Steps: 60 | Train Loss: 0.5190641 Vali Loss: 0.2911476 Test Loss: 0.3557214
Validation loss decreased (0.292529 --> 0.291148).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.420952320098877
Epoch: 13, Steps: 60 | Train Loss: 0.5181946 Vali Loss: 0.2906462 Test Loss: 0.3553260
Validation loss decreased (0.291148 --> 0.290646).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.5263206958770752
Epoch: 14, Steps: 60 | Train Loss: 0.5173933 Vali Loss: 0.2895253 Test Loss: 0.3552789
Validation loss decreased (0.290646 --> 0.289525).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.436079978942871
Epoch: 15, Steps: 60 | Train Loss: 0.5162401 Vali Loss: 0.2888888 Test Loss: 0.3551009
Validation loss decreased (0.289525 --> 0.288889).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.4639854431152344
Epoch: 16, Steps: 60 | Train Loss: 0.5164639 Vali Loss: 0.2887022 Test Loss: 0.3547585
Validation loss decreased (0.288889 --> 0.288702).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.4223237037658691
Epoch: 17, Steps: 60 | Train Loss: 0.5150405 Vali Loss: 0.2882027 Test Loss: 0.3545926
Validation loss decreased (0.288702 --> 0.288203).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.3706867694854736
Epoch: 18, Steps: 60 | Train Loss: 0.5130783 Vali Loss: 0.2875749 Test Loss: 0.3545168
Validation loss decreased (0.288203 --> 0.287575).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.452291488647461
Epoch: 19, Steps: 60 | Train Loss: 0.5149951 Vali Loss: 0.2871157 Test Loss: 0.3544025
Validation loss decreased (0.287575 --> 0.287116).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.454355239868164
Epoch: 20, Steps: 60 | Train Loss: 0.5142134 Vali Loss: 0.2870351 Test Loss: 0.3542011
Validation loss decreased (0.287116 --> 0.287035).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.512265920639038
Epoch: 21, Steps: 60 | Train Loss: 0.5148607 Vali Loss: 0.2865504 Test Loss: 0.3540889
Validation loss decreased (0.287035 --> 0.286550).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.4149346351623535
Epoch: 22, Steps: 60 | Train Loss: 0.5116586 Vali Loss: 0.2863343 Test Loss: 0.3539912
Validation loss decreased (0.286550 --> 0.286334).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.6971242427825928
Epoch: 23, Steps: 60 | Train Loss: 0.5136745 Vali Loss: 0.2859708 Test Loss: 0.3537699
Validation loss decreased (0.286334 --> 0.285971).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.7181932926177979
Epoch: 24, Steps: 60 | Train Loss: 0.5116299 Vali Loss: 0.2856613 Test Loss: 0.3537855
Validation loss decreased (0.285971 --> 0.285661).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.6517064571380615
Epoch: 25, Steps: 60 | Train Loss: 0.5127368 Vali Loss: 0.2855285 Test Loss: 0.3536279
Validation loss decreased (0.285661 --> 0.285528).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.7148463726043701
Epoch: 26, Steps: 60 | Train Loss: 0.5131656 Vali Loss: 0.2853954 Test Loss: 0.3536141
Validation loss decreased (0.285528 --> 0.285395).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.434112310409546
Epoch: 27, Steps: 60 | Train Loss: 0.5127451 Vali Loss: 0.2850752 Test Loss: 0.3535579
Validation loss decreased (0.285395 --> 0.285075).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.546922206878662
Epoch: 28, Steps: 60 | Train Loss: 0.5099038 Vali Loss: 0.2851019 Test Loss: 0.3534785
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.4967925548553467
Epoch: 29, Steps: 60 | Train Loss: 0.5113009 Vali Loss: 0.2846461 Test Loss: 0.3534854
Validation loss decreased (0.285075 --> 0.284646).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.4669439792633057
Epoch: 30, Steps: 60 | Train Loss: 0.5100938 Vali Loss: 0.2845325 Test Loss: 0.3534344
Validation loss decreased (0.284646 --> 0.284532).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.8651185035705566
Epoch: 31, Steps: 60 | Train Loss: 0.5117127 Vali Loss: 0.2843001 Test Loss: 0.3533945
Validation loss decreased (0.284532 --> 0.284300).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.454099178314209
Epoch: 32, Steps: 60 | Train Loss: 0.5103046 Vali Loss: 0.2840793 Test Loss: 0.3533471
Validation loss decreased (0.284300 --> 0.284079).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.4862794876098633
Epoch: 33, Steps: 60 | Train Loss: 0.5108593 Vali Loss: 0.2841761 Test Loss: 0.3532532
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.5148241519927979
Epoch: 34, Steps: 60 | Train Loss: 0.5097710 Vali Loss: 0.2840607 Test Loss: 0.3532250
Validation loss decreased (0.284079 --> 0.284061).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.4036147594451904
Epoch: 35, Steps: 60 | Train Loss: 0.5098015 Vali Loss: 0.2841017 Test Loss: 0.3532069
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.3900294303894043
Epoch: 36, Steps: 60 | Train Loss: 0.5111907 Vali Loss: 0.2839371 Test Loss: 0.3532065
Validation loss decreased (0.284061 --> 0.283937).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.4264814853668213
Epoch: 37, Steps: 60 | Train Loss: 0.5113604 Vali Loss: 0.2838695 Test Loss: 0.3531383
Validation loss decreased (0.283937 --> 0.283869).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.4552183151245117
Epoch: 38, Steps: 60 | Train Loss: 0.5107860 Vali Loss: 0.2837640 Test Loss: 0.3531404
Validation loss decreased (0.283869 --> 0.283764).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.4512534141540527
Epoch: 39, Steps: 60 | Train Loss: 0.5089041 Vali Loss: 0.2834845 Test Loss: 0.3531297
Validation loss decreased (0.283764 --> 0.283485).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.41632080078125
Epoch: 40, Steps: 60 | Train Loss: 0.5098360 Vali Loss: 0.2836735 Test Loss: 0.3530973
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.9556701183319092
Epoch: 41, Steps: 60 | Train Loss: 0.5089038 Vali Loss: 0.2835893 Test Loss: 0.3530116
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.4386732578277588
Epoch: 42, Steps: 60 | Train Loss: 0.5099884 Vali Loss: 0.2835572 Test Loss: 0.3529826
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.2645950317382812
Epoch: 43, Steps: 60 | Train Loss: 0.5104465 Vali Loss: 0.2835092 Test Loss: 0.3529747
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.5256321430206299
Epoch: 44, Steps: 60 | Train Loss: 0.5100752 Vali Loss: 0.2834683 Test Loss: 0.3529513
Validation loss decreased (0.283485 --> 0.283468).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.5402519702911377
Epoch: 45, Steps: 60 | Train Loss: 0.5105324 Vali Loss: 0.2833082 Test Loss: 0.3529272
Validation loss decreased (0.283468 --> 0.283308).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.445859432220459
Epoch: 46, Steps: 60 | Train Loss: 0.5100183 Vali Loss: 0.2833510 Test Loss: 0.3529346
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.52370023727417
Epoch: 47, Steps: 60 | Train Loss: 0.5095229 Vali Loss: 0.2830543 Test Loss: 0.3529271
Validation loss decreased (0.283308 --> 0.283054).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.5610268115997314
Epoch: 48, Steps: 60 | Train Loss: 0.5087049 Vali Loss: 0.2828099 Test Loss: 0.3529119
Validation loss decreased (0.283054 --> 0.282810).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.4187395572662354
Epoch: 49, Steps: 60 | Train Loss: 0.5102620 Vali Loss: 0.2827802 Test Loss: 0.3528898
Validation loss decreased (0.282810 --> 0.282780).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.4227042198181152
Epoch: 50, Steps: 60 | Train Loss: 0.5089952 Vali Loss: 0.2831885 Test Loss: 0.3528933
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.490926504135132
Epoch: 51, Steps: 60 | Train Loss: 0.5100059 Vali Loss: 0.2830980 Test Loss: 0.3528763
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.5123088359832764
Epoch: 52, Steps: 60 | Train Loss: 0.5095671 Vali Loss: 0.2830414 Test Loss: 0.3528822
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.3967573642730713
Epoch: 53, Steps: 60 | Train Loss: 0.5099253 Vali Loss: 0.2830143 Test Loss: 0.3528346
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.5822808742523193
Epoch: 54, Steps: 60 | Train Loss: 0.5085590 Vali Loss: 0.2829923 Test Loss: 0.3528502
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.4575133323669434
Epoch: 55, Steps: 60 | Train Loss: 0.5087129 Vali Loss: 0.2829710 Test Loss: 0.3528274
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.446946144104004
Epoch: 56, Steps: 60 | Train Loss: 0.5091314 Vali Loss: 0.2827981 Test Loss: 0.3528266
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.5343601703643799
Epoch: 57, Steps: 60 | Train Loss: 0.5084748 Vali Loss: 0.2828606 Test Loss: 0.3528230
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.4633398056030273
Epoch: 58, Steps: 60 | Train Loss: 0.5086975 Vali Loss: 0.2828581 Test Loss: 0.3528134
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.4173252582550049
Epoch: 59, Steps: 60 | Train Loss: 0.5097988 Vali Loss: 0.2828300 Test Loss: 0.3528152
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.3628895282745361
Epoch: 60, Steps: 60 | Train Loss: 0.5100482 Vali Loss: 0.2826815 Test Loss: 0.3528058
Validation loss decreased (0.282780 --> 0.282682).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.4009122848510742
Epoch: 61, Steps: 60 | Train Loss: 0.5098014 Vali Loss: 0.2827860 Test Loss: 0.3528014
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.4111688137054443
Epoch: 62, Steps: 60 | Train Loss: 0.5094793 Vali Loss: 0.2826501 Test Loss: 0.3527745
Validation loss decreased (0.282682 --> 0.282650).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.8123283386230469
Epoch: 63, Steps: 60 | Train Loss: 0.5101971 Vali Loss: 0.2825510 Test Loss: 0.3527720
Validation loss decreased (0.282650 --> 0.282551).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.431408405303955
Epoch: 64, Steps: 60 | Train Loss: 0.5095555 Vali Loss: 0.2826585 Test Loss: 0.3527718
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.8059563636779785
Epoch: 65, Steps: 60 | Train Loss: 0.5089552 Vali Loss: 0.2827247 Test Loss: 0.3527614
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.5446689128875732
Epoch: 66, Steps: 60 | Train Loss: 0.5091395 Vali Loss: 0.2827245 Test Loss: 0.3527527
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.376711368560791
Epoch: 67, Steps: 60 | Train Loss: 0.5088796 Vali Loss: 0.2826258 Test Loss: 0.3527411
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.4585413932800293
Epoch: 68, Steps: 60 | Train Loss: 0.5100648 Vali Loss: 0.2826861 Test Loss: 0.3527353
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.3948616981506348
Epoch: 69, Steps: 60 | Train Loss: 0.5093631 Vali Loss: 0.2826583 Test Loss: 0.3527338
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.4388458728790283
Epoch: 70, Steps: 60 | Train Loss: 0.5086159 Vali Loss: 0.2826675 Test Loss: 0.3527381
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.1118838787078857
Epoch: 71, Steps: 60 | Train Loss: 0.5092702 Vali Loss: 0.2826512 Test Loss: 0.3527366
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.5223658084869385
Epoch: 72, Steps: 60 | Train Loss: 0.5079597 Vali Loss: 0.2825254 Test Loss: 0.3527207
Validation loss decreased (0.282551 --> 0.282525).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.6601834297180176
Epoch: 73, Steps: 60 | Train Loss: 0.5098074 Vali Loss: 0.2825980 Test Loss: 0.3527310
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.4895174503326416
Epoch: 74, Steps: 60 | Train Loss: 0.5097603 Vali Loss: 0.2825943 Test Loss: 0.3527225
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.3929588794708252
Epoch: 75, Steps: 60 | Train Loss: 0.5078968 Vali Loss: 0.2826382 Test Loss: 0.3527192
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.4759368896484375
Epoch: 76, Steps: 60 | Train Loss: 0.5092584 Vali Loss: 0.2825375 Test Loss: 0.3527126
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.4277896881103516
Epoch: 77, Steps: 60 | Train Loss: 0.5080168 Vali Loss: 0.2825293 Test Loss: 0.3527052
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.427642583847046
Epoch: 78, Steps: 60 | Train Loss: 0.5080468 Vali Loss: 0.2825545 Test Loss: 0.3527191
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.4590675830841064
Epoch: 79, Steps: 60 | Train Loss: 0.5099629 Vali Loss: 0.2825414 Test Loss: 0.3527102
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.396028757095337
Epoch: 80, Steps: 60 | Train Loss: 0.5083178 Vali Loss: 0.2825813 Test Loss: 0.3527063
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.4357428550720215
Epoch: 81, Steps: 60 | Train Loss: 0.5070929 Vali Loss: 0.2825259 Test Loss: 0.3526998
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.3112380504608154
Epoch: 82, Steps: 60 | Train Loss: 0.5096135 Vali Loss: 0.2821638 Test Loss: 0.3527065
Validation loss decreased (0.282525 --> 0.282164).  Saving model ...
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.3875112533569336
Epoch: 83, Steps: 60 | Train Loss: 0.5068945 Vali Loss: 0.2825888 Test Loss: 0.3526987
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.4277963638305664
Epoch: 84, Steps: 60 | Train Loss: 0.5086208 Vali Loss: 0.2825086 Test Loss: 0.3526977
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.689241647720337
Epoch: 85, Steps: 60 | Train Loss: 0.5096262 Vali Loss: 0.2824493 Test Loss: 0.3526942
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.3889796733856201
Epoch: 86, Steps: 60 | Train Loss: 0.5077923 Vali Loss: 0.2825405 Test Loss: 0.3526948
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.6488230228424072
Epoch: 87, Steps: 60 | Train Loss: 0.5077548 Vali Loss: 0.2824584 Test Loss: 0.3526952
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.4339826107025146
Epoch: 88, Steps: 60 | Train Loss: 0.5091303 Vali Loss: 0.2825029 Test Loss: 0.3526933
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.3804068565368652
Epoch: 89, Steps: 60 | Train Loss: 0.5087308 Vali Loss: 0.2824973 Test Loss: 0.3526853
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.4005167484283447
Epoch: 90, Steps: 60 | Train Loss: 0.5093404 Vali Loss: 0.2824171 Test Loss: 0.3526842
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.8364646434783936
Epoch: 91, Steps: 60 | Train Loss: 0.5093986 Vali Loss: 0.2825053 Test Loss: 0.3526867
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.5407521724700928
Epoch: 92, Steps: 60 | Train Loss: 0.5084313 Vali Loss: 0.2824757 Test Loss: 0.3526844
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.5000193119049072
Epoch: 93, Steps: 60 | Train Loss: 0.5097079 Vali Loss: 0.2824667 Test Loss: 0.3526815
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.5843546390533447
Epoch: 94, Steps: 60 | Train Loss: 0.5077083 Vali Loss: 0.2824920 Test Loss: 0.3526826
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.8701932430267334
Epoch: 95, Steps: 60 | Train Loss: 0.5067081 Vali Loss: 0.2825042 Test Loss: 0.3526857
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.3617448806762695
Epoch: 96, Steps: 60 | Train Loss: 0.5080657 Vali Loss: 0.2824063 Test Loss: 0.3526819
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 2.02726149559021
Epoch: 97, Steps: 60 | Train Loss: 0.5084776 Vali Loss: 0.2825018 Test Loss: 0.3526771
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.7857191562652588
Epoch: 98, Steps: 60 | Train Loss: 0.5086347 Vali Loss: 0.2823266 Test Loss: 0.3526767
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.4102320671081543
Epoch: 99, Steps: 60 | Train Loss: 0.5071338 Vali Loss: 0.2824859 Test Loss: 0.3526765
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.5198180675506592
Epoch: 100, Steps: 60 | Train Loss: 0.5082982 Vali Loss: 0.2824878 Test Loss: 0.3526720
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.1160680107021042e-06
>>>>>>>testing : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.3315237760543823, mae:0.37457793951034546, rse:0.46174073219299316, corr:[0.26282653 0.26743746 0.2658122  0.26713383 0.2669816  0.26562485
 0.26554638 0.26550236 0.26423305 0.2629088  0.26198277 0.2608772
 0.25950974 0.25818384 0.25750512 0.25728488 0.25687087 0.2561793
 0.25534642 0.25415298 0.25264847 0.25150433 0.25048795 0.24874006
 0.2464377  0.24475154 0.2435472  0.24181393 0.24007398 0.23910204
 0.23817591 0.23634171 0.23491655 0.2341627  0.23287794 0.23116204
 0.23037386 0.23003198 0.22867584 0.22725952 0.22707799 0.22694442
 0.22579549 0.2246686  0.22413754 0.22314733 0.22144972 0.21995997
 0.21864721 0.21671838 0.21469934 0.21346645 0.21233171 0.21021597
 0.20799123 0.20669407 0.20512088 0.20304416 0.20192257 0.20126612
 0.20015009 0.19932935 0.19963877 0.19970958 0.19872618 0.19826002
 0.19825608 0.19749112 0.19641325 0.19606784 0.19567585 0.19432423
 0.192944   0.19246984 0.19167815 0.18985844 0.1888512  0.18882984
 0.18819624 0.18691127 0.18673979 0.18676199 0.18592508 0.18521897
 0.1853154  0.18530639 0.18465638 0.18438993 0.18434235 0.18374848
 0.18289082 0.18265387 0.18281896 0.18222986 0.18168528 0.18176039
 0.18132703 0.18000829 0.1790256  0.17851335 0.17742068 0.175896
 0.1753052  0.17495929 0.17412151 0.17331764 0.17333919 0.17342323
 0.17243592 0.17161909 0.1713001  0.17080829 0.16989942 0.16974328
 0.16965443 0.16874038 0.16782454 0.16724329 0.16631882 0.1644892
 0.16298229 0.16193566 0.16071323 0.15926862 0.15831724 0.1575044
 0.15626764 0.15514861 0.15484186 0.15419482 0.15294096 0.15198646
 0.15171836 0.15100436 0.15007897 0.15000917 0.14998862 0.14912814
 0.14811671 0.14775383 0.14746745 0.14676543 0.14617987 0.1451326
 0.14293024 0.14094755 0.13997659 0.13880722 0.1370735  0.13625883
 0.13641049 0.13526903 0.13400465 0.1340452  0.13415305 0.13284506
 0.13204321 0.1326926  0.13303572 0.13252619 0.13227582 0.13292684
 0.1325393  0.13144137 0.13173182 0.13234062 0.13178602 0.13066116
 0.13008381 0.12850127 0.1267754  0.12638696 0.12637743 0.12408881
 0.12207162 0.12185694 0.12098788 0.11899516 0.11819596 0.1191479
 0.1180798  0.11678908 0.1187576  0.12027231 0.11806395 0.11805322
 0.12019544 0.11846186 0.11840211 0.12312831 0.12264092 0.12223563]
