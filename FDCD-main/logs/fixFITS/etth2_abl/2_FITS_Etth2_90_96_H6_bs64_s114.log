Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=34, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_90_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_90_96_FITS_ETTh2_ftM_sl90_ll48_pl96_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8455
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=34, out_features=70, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2132480.0
params:  2450.0
Trainable parameters:  2450
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.2771821022033691
Epoch: 1, Steps: 66 | Train Loss: 0.4677935 Vali Loss: 0.3092606 Test Loss: 0.4086285
Validation loss decreased (inf --> 0.309261).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.311962366104126
Epoch: 2, Steps: 66 | Train Loss: 0.3946497 Vali Loss: 0.2852110 Test Loss: 0.3749418
Validation loss decreased (0.309261 --> 0.285211).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.2413768768310547
Epoch: 3, Steps: 66 | Train Loss: 0.3518346 Vali Loss: 0.2701016 Test Loss: 0.3545772
Validation loss decreased (0.285211 --> 0.270102).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.229405164718628
Epoch: 4, Steps: 66 | Train Loss: 0.3248695 Vali Loss: 0.2603287 Test Loss: 0.3415430
Validation loss decreased (0.270102 --> 0.260329).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.0113251209259033
Epoch: 5, Steps: 66 | Train Loss: 0.3059554 Vali Loss: 0.2535150 Test Loss: 0.3326561
Validation loss decreased (0.260329 --> 0.253515).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.0614936351776123
Epoch: 6, Steps: 66 | Train Loss: 0.2926735 Vali Loss: 0.2478753 Test Loss: 0.3263100
Validation loss decreased (0.253515 --> 0.247875).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.3780462741851807
Epoch: 7, Steps: 66 | Train Loss: 0.2824540 Vali Loss: 0.2436476 Test Loss: 0.3216894
Validation loss decreased (0.247875 --> 0.243648).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.312272548675537
Epoch: 8, Steps: 66 | Train Loss: 0.2749190 Vali Loss: 0.2394405 Test Loss: 0.3181390
Validation loss decreased (0.243648 --> 0.239440).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.1629486083984375
Epoch: 9, Steps: 66 | Train Loss: 0.2689214 Vali Loss: 0.2380346 Test Loss: 0.3153443
Validation loss decreased (0.239440 --> 0.238035).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.2121498584747314
Epoch: 10, Steps: 66 | Train Loss: 0.2639216 Vali Loss: 0.2355899 Test Loss: 0.3130959
Validation loss decreased (0.238035 --> 0.235590).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.095276117324829
Epoch: 11, Steps: 66 | Train Loss: 0.2600204 Vali Loss: 0.2336380 Test Loss: 0.3111728
Validation loss decreased (0.235590 --> 0.233638).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.33231520652771
Epoch: 12, Steps: 66 | Train Loss: 0.2565980 Vali Loss: 0.2322985 Test Loss: 0.3095144
Validation loss decreased (0.233638 --> 0.232299).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.210646629333496
Epoch: 13, Steps: 66 | Train Loss: 0.2537756 Vali Loss: 0.2313295 Test Loss: 0.3081275
Validation loss decreased (0.232299 --> 0.231330).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.2105827331542969
Epoch: 14, Steps: 66 | Train Loss: 0.2514236 Vali Loss: 0.2298718 Test Loss: 0.3069053
Validation loss decreased (0.231330 --> 0.229872).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.0029730796813965
Epoch: 15, Steps: 66 | Train Loss: 0.2492833 Vali Loss: 0.2289383 Test Loss: 0.3058173
Validation loss decreased (0.229872 --> 0.228938).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 0.967695951461792
Epoch: 16, Steps: 66 | Train Loss: 0.2473987 Vali Loss: 0.2274659 Test Loss: 0.3048770
Validation loss decreased (0.228938 --> 0.227466).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.27390456199646
Epoch: 17, Steps: 66 | Train Loss: 0.2457756 Vali Loss: 0.2280256 Test Loss: 0.3040247
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.0775682926177979
Epoch: 18, Steps: 66 | Train Loss: 0.2443538 Vali Loss: 0.2265784 Test Loss: 0.3032580
Validation loss decreased (0.227466 --> 0.226578).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.3978261947631836
Epoch: 19, Steps: 66 | Train Loss: 0.2429625 Vali Loss: 0.2252221 Test Loss: 0.3025760
Validation loss decreased (0.226578 --> 0.225222).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.5802946090698242
Epoch: 20, Steps: 66 | Train Loss: 0.2417195 Vali Loss: 0.2254404 Test Loss: 0.3019442
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.0585908889770508
Epoch: 21, Steps: 66 | Train Loss: 0.2408329 Vali Loss: 0.2244391 Test Loss: 0.3014011
Validation loss decreased (0.225222 --> 0.224439).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.001586675643921
Epoch: 22, Steps: 66 | Train Loss: 0.2398663 Vali Loss: 0.2241206 Test Loss: 0.3008955
Validation loss decreased (0.224439 --> 0.224121).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.7301766872406006
Epoch: 23, Steps: 66 | Train Loss: 0.2387468 Vali Loss: 0.2245682 Test Loss: 0.3004079
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 0.9855363368988037
Epoch: 24, Steps: 66 | Train Loss: 0.2382539 Vali Loss: 0.2223412 Test Loss: 0.2999757
Validation loss decreased (0.224121 --> 0.222341).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.0709583759307861
Epoch: 25, Steps: 66 | Train Loss: 0.2375241 Vali Loss: 0.2230075 Test Loss: 0.2996078
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 0.9931755065917969
Epoch: 26, Steps: 66 | Train Loss: 0.2369653 Vali Loss: 0.2223098 Test Loss: 0.2992598
Validation loss decreased (0.222341 --> 0.222310).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.343390941619873
Epoch: 27, Steps: 66 | Train Loss: 0.2363930 Vali Loss: 0.2220472 Test Loss: 0.2989081
Validation loss decreased (0.222310 --> 0.222047).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.2833194732666016
Epoch: 28, Steps: 66 | Train Loss: 0.2357821 Vali Loss: 0.2216659 Test Loss: 0.2986283
Validation loss decreased (0.222047 --> 0.221666).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.272397994995117
Epoch: 29, Steps: 66 | Train Loss: 0.2353821 Vali Loss: 0.2208053 Test Loss: 0.2983454
Validation loss decreased (0.221666 --> 0.220805).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.1594321727752686
Epoch: 30, Steps: 66 | Train Loss: 0.2348854 Vali Loss: 0.2205211 Test Loss: 0.2981079
Validation loss decreased (0.220805 --> 0.220521).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.1824109554290771
Epoch: 31, Steps: 66 | Train Loss: 0.2344320 Vali Loss: 0.2217685 Test Loss: 0.2978726
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.7371764183044434
Epoch: 32, Steps: 66 | Train Loss: 0.2337911 Vali Loss: 0.2199602 Test Loss: 0.2976419
Validation loss decreased (0.220521 --> 0.219960).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.5979149341583252
Epoch: 33, Steps: 66 | Train Loss: 0.2336834 Vali Loss: 0.2211050 Test Loss: 0.2974730
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.1677608489990234
Epoch: 34, Steps: 66 | Train Loss: 0.2333252 Vali Loss: 0.2199867 Test Loss: 0.2972732
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.7051801681518555
Epoch: 35, Steps: 66 | Train Loss: 0.2330724 Vali Loss: 0.2198255 Test Loss: 0.2970940
Validation loss decreased (0.219960 --> 0.219825).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.942140817642212
Epoch: 36, Steps: 66 | Train Loss: 0.2327544 Vali Loss: 0.2204217 Test Loss: 0.2969421
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.7746715545654297
Epoch: 37, Steps: 66 | Train Loss: 0.2324879 Vali Loss: 0.2198977 Test Loss: 0.2967994
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.5580921173095703
Epoch: 38, Steps: 66 | Train Loss: 0.2322642 Vali Loss: 0.2193246 Test Loss: 0.2966636
Validation loss decreased (0.219825 --> 0.219325).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.6133179664611816
Epoch: 39, Steps: 66 | Train Loss: 0.2319919 Vali Loss: 0.2198704 Test Loss: 0.2965450
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.158719778060913
Epoch: 40, Steps: 66 | Train Loss: 0.2317177 Vali Loss: 0.2191376 Test Loss: 0.2964285
Validation loss decreased (0.219325 --> 0.219138).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.2400295734405518
Epoch: 41, Steps: 66 | Train Loss: 0.2315866 Vali Loss: 0.2193699 Test Loss: 0.2963047
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.7432630062103271
Epoch: 42, Steps: 66 | Train Loss: 0.2313967 Vali Loss: 0.2198180 Test Loss: 0.2961965
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.9726953506469727
Epoch: 43, Steps: 66 | Train Loss: 0.2311567 Vali Loss: 0.2190793 Test Loss: 0.2961020
Validation loss decreased (0.219138 --> 0.219079).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.589555025100708
Epoch: 44, Steps: 66 | Train Loss: 0.2309508 Vali Loss: 0.2182119 Test Loss: 0.2960235
Validation loss decreased (0.219079 --> 0.218212).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.0039734840393066
Epoch: 45, Steps: 66 | Train Loss: 0.2308933 Vali Loss: 0.2189562 Test Loss: 0.2959364
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.1005859375
Epoch: 46, Steps: 66 | Train Loss: 0.2307650 Vali Loss: 0.2181720 Test Loss: 0.2958462
Validation loss decreased (0.218212 --> 0.218172).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.3224060535430908
Epoch: 47, Steps: 66 | Train Loss: 0.2305376 Vali Loss: 0.2188774 Test Loss: 0.2957774
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.3221311569213867
Epoch: 48, Steps: 66 | Train Loss: 0.2303167 Vali Loss: 0.2181979 Test Loss: 0.2957099
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.7132577896118164
Epoch: 49, Steps: 66 | Train Loss: 0.2301493 Vali Loss: 0.2186597 Test Loss: 0.2956519
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.4804399013519287
Epoch: 50, Steps: 66 | Train Loss: 0.2302399 Vali Loss: 0.2182369 Test Loss: 0.2955834
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.810378074645996
Epoch: 51, Steps: 66 | Train Loss: 0.2300835 Vali Loss: 0.2173861 Test Loss: 0.2955223
Validation loss decreased (0.218172 --> 0.217386).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.1336491107940674
Epoch: 52, Steps: 66 | Train Loss: 0.2299646 Vali Loss: 0.2172405 Test Loss: 0.2954729
Validation loss decreased (0.217386 --> 0.217240).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.6982293128967285
Epoch: 53, Steps: 66 | Train Loss: 0.2299138 Vali Loss: 0.2180173 Test Loss: 0.2954277
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.675492763519287
Epoch: 54, Steps: 66 | Train Loss: 0.2297435 Vali Loss: 0.2181946 Test Loss: 0.2953701
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.4526104927062988
Epoch: 55, Steps: 66 | Train Loss: 0.2294380 Vali Loss: 0.2181480 Test Loss: 0.2953221
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.0564062595367432
Epoch: 56, Steps: 66 | Train Loss: 0.2295613 Vali Loss: 0.2183249 Test Loss: 0.2952797
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.912001609802246
Epoch: 57, Steps: 66 | Train Loss: 0.2295304 Vali Loss: 0.2192982 Test Loss: 0.2952376
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 0.9776260852813721
Epoch: 58, Steps: 66 | Train Loss: 0.2294724 Vali Loss: 0.2180838 Test Loss: 0.2952053
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.086575984954834
Epoch: 59, Steps: 66 | Train Loss: 0.2294208 Vali Loss: 0.2181434 Test Loss: 0.2951704
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.3326194286346436
Epoch: 60, Steps: 66 | Train Loss: 0.2293402 Vali Loss: 0.2182936 Test Loss: 0.2951341
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.1273207664489746
Epoch: 61, Steps: 66 | Train Loss: 0.2292553 Vali Loss: 0.2179743 Test Loss: 0.2951041
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.163557529449463
Epoch: 62, Steps: 66 | Train Loss: 0.2289641 Vali Loss: 0.2175549 Test Loss: 0.2950747
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.416910171508789
Epoch: 63, Steps: 66 | Train Loss: 0.2291201 Vali Loss: 0.2176509 Test Loss: 0.2950438
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.0654351711273193
Epoch: 64, Steps: 66 | Train Loss: 0.2291154 Vali Loss: 0.2172663 Test Loss: 0.2950138
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.624082088470459
Epoch: 65, Steps: 66 | Train Loss: 0.2290702 Vali Loss: 0.2182582 Test Loss: 0.2949880
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.5942211151123047
Epoch: 66, Steps: 66 | Train Loss: 0.2284393 Vali Loss: 0.2179810 Test Loss: 0.2949600
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.5167937278747559
Epoch: 67, Steps: 66 | Train Loss: 0.2288908 Vali Loss: 0.2178255 Test Loss: 0.2949467
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.3093068599700928
Epoch: 68, Steps: 66 | Train Loss: 0.2288629 Vali Loss: 0.2170162 Test Loss: 0.2949190
Validation loss decreased (0.217240 --> 0.217016).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.6989097595214844
Epoch: 69, Steps: 66 | Train Loss: 0.2282494 Vali Loss: 0.2186626 Test Loss: 0.2949005
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.2161264419555664
Epoch: 70, Steps: 66 | Train Loss: 0.2287995 Vali Loss: 0.2170843 Test Loss: 0.2948793
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.1705596446990967
Epoch: 71, Steps: 66 | Train Loss: 0.2287723 Vali Loss: 0.2175175 Test Loss: 0.2948614
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.2255809307098389
Epoch: 72, Steps: 66 | Train Loss: 0.2287184 Vali Loss: 0.2169537 Test Loss: 0.2948432
Validation loss decreased (0.217016 --> 0.216954).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.3139674663543701
Epoch: 73, Steps: 66 | Train Loss: 0.2287317 Vali Loss: 0.2167643 Test Loss: 0.2948246
Validation loss decreased (0.216954 --> 0.216764).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.5745010375976562
Epoch: 74, Steps: 66 | Train Loss: 0.2286692 Vali Loss: 0.2180575 Test Loss: 0.2948111
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.1449203491210938
Epoch: 75, Steps: 66 | Train Loss: 0.2286250 Vali Loss: 0.2168765 Test Loss: 0.2947968
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.2359027862548828
Epoch: 76, Steps: 66 | Train Loss: 0.2285308 Vali Loss: 0.2170070 Test Loss: 0.2947810
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.162923812866211
Epoch: 77, Steps: 66 | Train Loss: 0.2286166 Vali Loss: 0.2172458 Test Loss: 0.2947665
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.3212780952453613
Epoch: 78, Steps: 66 | Train Loss: 0.2285691 Vali Loss: 0.2180450 Test Loss: 0.2947550
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.2384355068206787
Epoch: 79, Steps: 66 | Train Loss: 0.2284793 Vali Loss: 0.2158032 Test Loss: 0.2947433
Validation loss decreased (0.216764 --> 0.215803).  Saving model ...
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.338383674621582
Epoch: 80, Steps: 66 | Train Loss: 0.2284382 Vali Loss: 0.2168460 Test Loss: 0.2947308
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.1458029747009277
Epoch: 81, Steps: 66 | Train Loss: 0.2281811 Vali Loss: 0.2167616 Test Loss: 0.2947199
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.0255169868469238
Epoch: 82, Steps: 66 | Train Loss: 0.2284769 Vali Loss: 0.2183429 Test Loss: 0.2947104
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.311112880706787
Epoch: 83, Steps: 66 | Train Loss: 0.2284237 Vali Loss: 0.2180477 Test Loss: 0.2947003
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.0810859203338623
Epoch: 84, Steps: 66 | Train Loss: 0.2284092 Vali Loss: 0.2165583 Test Loss: 0.2946927
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.0826828479766846
Epoch: 85, Steps: 66 | Train Loss: 0.2283919 Vali Loss: 0.2174240 Test Loss: 0.2946831
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.3005003929138184
Epoch: 86, Steps: 66 | Train Loss: 0.2281632 Vali Loss: 0.2178353 Test Loss: 0.2946745
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 3.6314260959625244
Epoch: 87, Steps: 66 | Train Loss: 0.2283949 Vali Loss: 0.2181522 Test Loss: 0.2946656
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.385878324508667
Epoch: 88, Steps: 66 | Train Loss: 0.2282655 Vali Loss: 0.2167007 Test Loss: 0.2946585
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.1123683452606201
Epoch: 89, Steps: 66 | Train Loss: 0.2280988 Vali Loss: 0.2170921 Test Loss: 0.2946531
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.352649211883545
Epoch: 90, Steps: 66 | Train Loss: 0.2282298 Vali Loss: 0.2170616 Test Loss: 0.2946458
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.4844343662261963
Epoch: 91, Steps: 66 | Train Loss: 0.2283515 Vali Loss: 0.2172143 Test Loss: 0.2946384
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 2.0968453884124756
Epoch: 92, Steps: 66 | Train Loss: 0.2283064 Vali Loss: 0.2171999 Test Loss: 0.2946325
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.6492106914520264
Epoch: 93, Steps: 66 | Train Loss: 0.2282833 Vali Loss: 0.2163457 Test Loss: 0.2946275
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.9275541305541992
Epoch: 94, Steps: 66 | Train Loss: 0.2281213 Vali Loss: 0.2172434 Test Loss: 0.2946220
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.470811367034912
Epoch: 95, Steps: 66 | Train Loss: 0.2282836 Vali Loss: 0.2164099 Test Loss: 0.2946169
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.3715910911560059
Epoch: 96, Steps: 66 | Train Loss: 0.2282375 Vali Loss: 0.2162588 Test Loss: 0.2946112
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.6796414852142334
Epoch: 97, Steps: 66 | Train Loss: 0.2278847 Vali Loss: 0.2155408 Test Loss: 0.2946067
Validation loss decreased (0.215803 --> 0.215541).  Saving model ...
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.2122704982757568
Epoch: 98, Steps: 66 | Train Loss: 0.2281162 Vali Loss: 0.2175587 Test Loss: 0.2946030
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.127164363861084
Epoch: 99, Steps: 66 | Train Loss: 0.2281552 Vali Loss: 0.2173651 Test Loss: 0.2945984
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.232525110244751
Epoch: 100, Steps: 66 | Train Loss: 0.2273790 Vali Loss: 0.2169983 Test Loss: 0.2945946
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8455
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=34, out_features=70, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2132480.0
params:  2450.0
Trainable parameters:  2450
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.4442946910858154
Epoch: 1, Steps: 66 | Train Loss: 0.4267368 Vali Loss: 0.2160141 Test Loss: 0.2928711
Validation loss decreased (inf --> 0.216014).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.5786521434783936
Epoch: 2, Steps: 66 | Train Loss: 0.4242927 Vali Loss: 0.2143008 Test Loss: 0.2919715
Validation loss decreased (0.216014 --> 0.214301).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.4793424606323242
Epoch: 3, Steps: 66 | Train Loss: 0.4224706 Vali Loss: 0.2133040 Test Loss: 0.2913339
Validation loss decreased (0.214301 --> 0.213304).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.645585536956787
Epoch: 4, Steps: 66 | Train Loss: 0.4217365 Vali Loss: 0.2129924 Test Loss: 0.2909521
Validation loss decreased (0.213304 --> 0.212992).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.4477956295013428
Epoch: 5, Steps: 66 | Train Loss: 0.4205598 Vali Loss: 0.2129814 Test Loss: 0.2907594
Validation loss decreased (0.212992 --> 0.212981).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.5035426616668701
Epoch: 6, Steps: 66 | Train Loss: 0.4198864 Vali Loss: 0.2131633 Test Loss: 0.2906073
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.4549806118011475
Epoch: 7, Steps: 66 | Train Loss: 0.4197199 Vali Loss: 0.2129586 Test Loss: 0.2904929
Validation loss decreased (0.212981 --> 0.212959).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.2383861541748047
Epoch: 8, Steps: 66 | Train Loss: 0.4192161 Vali Loss: 0.2121568 Test Loss: 0.2904042
Validation loss decreased (0.212959 --> 0.212157).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.5482804775238037
Epoch: 9, Steps: 66 | Train Loss: 0.4192358 Vali Loss: 0.2113683 Test Loss: 0.2902658
Validation loss decreased (0.212157 --> 0.211368).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.6308822631835938
Epoch: 10, Steps: 66 | Train Loss: 0.4189902 Vali Loss: 0.2117013 Test Loss: 0.2902585
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.3960070610046387
Epoch: 11, Steps: 66 | Train Loss: 0.4187247 Vali Loss: 0.2113818 Test Loss: 0.2901371
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.250237226486206
Epoch: 12, Steps: 66 | Train Loss: 0.4186908 Vali Loss: 0.2102231 Test Loss: 0.2901325
Validation loss decreased (0.211368 --> 0.210223).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.311680555343628
Epoch: 13, Steps: 66 | Train Loss: 0.4185857 Vali Loss: 0.2115542 Test Loss: 0.2901301
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.4119606018066406
Epoch: 14, Steps: 66 | Train Loss: 0.4183172 Vali Loss: 0.2102024 Test Loss: 0.2900635
Validation loss decreased (0.210223 --> 0.210202).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.0259442329406738
Epoch: 15, Steps: 66 | Train Loss: 0.4183888 Vali Loss: 0.2110447 Test Loss: 0.2900415
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.268427610397339
Epoch: 16, Steps: 66 | Train Loss: 0.4181516 Vali Loss: 0.2115173 Test Loss: 0.2900038
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.087782621383667
Epoch: 17, Steps: 66 | Train Loss: 0.4178181 Vali Loss: 0.2106781 Test Loss: 0.2900144
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.429224729537964
Epoch: 18, Steps: 66 | Train Loss: 0.4179714 Vali Loss: 0.2108497 Test Loss: 0.2899743
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 0.9999463558197021
Epoch: 19, Steps: 66 | Train Loss: 0.4171311 Vali Loss: 0.2110901 Test Loss: 0.2899646
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.9066073894500732
Epoch: 20, Steps: 66 | Train Loss: 0.4178879 Vali Loss: 0.2111510 Test Loss: 0.2899511
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.1016669273376465
Epoch: 21, Steps: 66 | Train Loss: 0.4177615 Vali Loss: 0.2107244 Test Loss: 0.2899512
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.4932899475097656
Epoch: 22, Steps: 66 | Train Loss: 0.4173120 Vali Loss: 0.2107694 Test Loss: 0.2899236
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.5553290843963623
Epoch: 23, Steps: 66 | Train Loss: 0.4177052 Vali Loss: 0.2116362 Test Loss: 0.2899164
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.749290943145752
Epoch: 24, Steps: 66 | Train Loss: 0.4175656 Vali Loss: 0.2112651 Test Loss: 0.2898980
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.4343791007995605
Epoch: 25, Steps: 66 | Train Loss: 0.4161491 Vali Loss: 0.2105159 Test Loss: 0.2898648
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.1992497444152832
Epoch: 26, Steps: 66 | Train Loss: 0.4175440 Vali Loss: 0.2108891 Test Loss: 0.2899213
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.4214732646942139
Epoch: 27, Steps: 66 | Train Loss: 0.4175338 Vali Loss: 0.2096571 Test Loss: 0.2898959
Validation loss decreased (0.210202 --> 0.209657).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.4402236938476562
Epoch: 28, Steps: 66 | Train Loss: 0.4172877 Vali Loss: 0.2104759 Test Loss: 0.2898816
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.0375909805297852
Epoch: 29, Steps: 66 | Train Loss: 0.4174405 Vali Loss: 0.2109302 Test Loss: 0.2898588
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.5433528423309326
Epoch: 30, Steps: 66 | Train Loss: 0.4170807 Vali Loss: 0.2101635 Test Loss: 0.2898586
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.3031470775604248
Epoch: 31, Steps: 66 | Train Loss: 0.4173217 Vali Loss: 0.2112889 Test Loss: 0.2898602
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.1253085136413574
Epoch: 32, Steps: 66 | Train Loss: 0.4173495 Vali Loss: 0.2099417 Test Loss: 0.2898438
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.073150634765625
Epoch: 33, Steps: 66 | Train Loss: 0.4171128 Vali Loss: 0.2104986 Test Loss: 0.2898446
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.0593295097351074
Epoch: 34, Steps: 66 | Train Loss: 0.4172396 Vali Loss: 0.2102471 Test Loss: 0.2898408
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.0131933689117432
Epoch: 35, Steps: 66 | Train Loss: 0.4172625 Vali Loss: 0.2112040 Test Loss: 0.2898344
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.973318099975586
Epoch: 36, Steps: 66 | Train Loss: 0.4170328 Vali Loss: 0.2106150 Test Loss: 0.2898377
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.3290915489196777
Epoch: 37, Steps: 66 | Train Loss: 0.4171327 Vali Loss: 0.2105142 Test Loss: 0.2898272
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.916961908340454
Epoch: 38, Steps: 66 | Train Loss: 0.4171342 Vali Loss: 0.2100908 Test Loss: 0.2898043
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.461824893951416
Epoch: 39, Steps: 66 | Train Loss: 0.4171116 Vali Loss: 0.2107605 Test Loss: 0.2898244
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.166539192199707
Epoch: 40, Steps: 66 | Train Loss: 0.4171787 Vali Loss: 0.2104475 Test Loss: 0.2898259
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.5969791412353516
Epoch: 41, Steps: 66 | Train Loss: 0.4170258 Vali Loss: 0.2113162 Test Loss: 0.2898115
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.2442214488983154
Epoch: 42, Steps: 66 | Train Loss: 0.4171766 Vali Loss: 0.2104162 Test Loss: 0.2898161
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.6619384288787842
Epoch: 43, Steps: 66 | Train Loss: 0.4170423 Vali Loss: 0.2114595 Test Loss: 0.2898043
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.1450319290161133
Epoch: 44, Steps: 66 | Train Loss: 0.4157921 Vali Loss: 0.2110295 Test Loss: 0.2897997
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.0918169021606445
Epoch: 45, Steps: 66 | Train Loss: 0.4170772 Vali Loss: 0.2102377 Test Loss: 0.2898131
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.5764877796173096
Epoch: 46, Steps: 66 | Train Loss: 0.4170143 Vali Loss: 0.2108038 Test Loss: 0.2898012
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.3314542770385742
Epoch: 47, Steps: 66 | Train Loss: 0.4170673 Vali Loss: 0.2099070 Test Loss: 0.2897938
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_90_96_FITS_ETTh2_ftM_sl90_ll48_pl96_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.2904663383960724, mae:0.33892378211021423, rse:0.43433937430381775, corr:[0.2767948  0.27740824 0.27558902 0.27590585 0.27382246 0.27323222
 0.27223265 0.27137354 0.2706176  0.26933894 0.26863798 0.266964
 0.2650341  0.26376063 0.26258877 0.2619643  0.26139185 0.26104343
 0.26046166 0.25930002 0.25846016 0.25752065 0.2565685  0.2548131
 0.2516601  0.24907902 0.24664102 0.24513607 0.24378254 0.24230944
 0.24143358 0.24015042 0.23876466 0.23709966 0.23599294 0.23494701
 0.23309512 0.23166761 0.23072512 0.22953042 0.22897287 0.22869767
 0.22815815 0.22762893 0.22708647 0.22603118 0.22513758 0.22335595
 0.22017276 0.21720766 0.2146229  0.21307817 0.21104585 0.20956424
 0.20840299 0.20573679 0.20467417 0.20280164 0.20163149 0.20079666
 0.19913135 0.19899017 0.19890209 0.19830759 0.19859645 0.19809344
 0.19735521 0.19715469 0.19636095 0.19582012 0.19558273 0.19416484
 0.19150826 0.18972471 0.18838482 0.1876357  0.1860698  0.18589036
 0.18613163 0.18462142 0.18457422 0.18372026 0.18354875 0.18363763
 0.18223347 0.18243709 0.18263203 0.18241991 0.18217763 0.18107064
 0.18132289 0.18021646 0.17906335 0.18007271 0.1774692  0.18141721]
