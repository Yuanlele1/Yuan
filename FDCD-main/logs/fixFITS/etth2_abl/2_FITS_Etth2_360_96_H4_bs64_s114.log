Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=74, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_360_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_360_96_FITS_ETTh2_ftM_sl360_ll48_pl96_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8185
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=74, out_features=93, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6166272.0
params:  6975.0
Trainable parameters:  6975
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 4.081140995025635
Epoch: 1, Steps: 63 | Train Loss: 0.4918412 Vali Loss: 0.3486184 Test Loss: 0.4162091
Validation loss decreased (inf --> 0.348618).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.0184998512268066
Epoch: 2, Steps: 63 | Train Loss: 0.3966350 Vali Loss: 0.3094552 Test Loss: 0.3807688
Validation loss decreased (0.348618 --> 0.309455).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.8384859561920166
Epoch: 3, Steps: 63 | Train Loss: 0.3393386 Vali Loss: 0.2878020 Test Loss: 0.3622418
Validation loss decreased (0.309455 --> 0.287802).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.177644968032837
Epoch: 4, Steps: 63 | Train Loss: 0.3040991 Vali Loss: 0.2749904 Test Loss: 0.3519713
Validation loss decreased (0.287802 --> 0.274990).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.9380195140838623
Epoch: 5, Steps: 63 | Train Loss: 0.2782167 Vali Loss: 0.2675965 Test Loss: 0.3455158
Validation loss decreased (0.274990 --> 0.267596).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.4666388034820557
Epoch: 6, Steps: 63 | Train Loss: 0.2584733 Vali Loss: 0.2612727 Test Loss: 0.3409351
Validation loss decreased (0.267596 --> 0.261273).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.884657859802246
Epoch: 7, Steps: 63 | Train Loss: 0.2424889 Vali Loss: 0.2580574 Test Loss: 0.3374855
Validation loss decreased (0.261273 --> 0.258057).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.437619924545288
Epoch: 8, Steps: 63 | Train Loss: 0.2304208 Vali Loss: 0.2555695 Test Loss: 0.3343492
Validation loss decreased (0.258057 --> 0.255569).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.055201530456543
Epoch: 9, Steps: 63 | Train Loss: 0.2187197 Vali Loss: 0.2535500 Test Loss: 0.3315528
Validation loss decreased (0.255569 --> 0.253550).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 4.2033531665802
Epoch: 10, Steps: 63 | Train Loss: 0.2092581 Vali Loss: 0.2504643 Test Loss: 0.3291724
Validation loss decreased (0.253550 --> 0.250464).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.803148031234741
Epoch: 11, Steps: 63 | Train Loss: 0.2015665 Vali Loss: 0.2495663 Test Loss: 0.3269517
Validation loss decreased (0.250464 --> 0.249566).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 4.865438938140869
Epoch: 12, Steps: 63 | Train Loss: 0.1939384 Vali Loss: 0.2470856 Test Loss: 0.3246786
Validation loss decreased (0.249566 --> 0.247086).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 5.581453084945679
Epoch: 13, Steps: 63 | Train Loss: 0.1882691 Vali Loss: 0.2469439 Test Loss: 0.3227595
Validation loss decreased (0.247086 --> 0.246944).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 4.480904579162598
Epoch: 14, Steps: 63 | Train Loss: 0.1825898 Vali Loss: 0.2458730 Test Loss: 0.3208614
Validation loss decreased (0.246944 --> 0.245873).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 7.054497241973877
Epoch: 15, Steps: 63 | Train Loss: 0.1766125 Vali Loss: 0.2433845 Test Loss: 0.3192199
Validation loss decreased (0.245873 --> 0.243385).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.660736083984375
Epoch: 16, Steps: 63 | Train Loss: 0.1723737 Vali Loss: 0.2420577 Test Loss: 0.3175373
Validation loss decreased (0.243385 --> 0.242058).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.7299869060516357
Epoch: 17, Steps: 63 | Train Loss: 0.1682218 Vali Loss: 0.2418348 Test Loss: 0.3159845
Validation loss decreased (0.242058 --> 0.241835).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.8882462978363037
Epoch: 18, Steps: 63 | Train Loss: 0.1648640 Vali Loss: 0.2400395 Test Loss: 0.3145338
Validation loss decreased (0.241835 --> 0.240040).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 4.728126525878906
Epoch: 19, Steps: 63 | Train Loss: 0.1613275 Vali Loss: 0.2400047 Test Loss: 0.3130774
Validation loss decreased (0.240040 --> 0.240005).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.4904463291168213
Epoch: 20, Steps: 63 | Train Loss: 0.1590395 Vali Loss: 0.2388232 Test Loss: 0.3118140
Validation loss decreased (0.240005 --> 0.238823).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 4.46842622756958
Epoch: 21, Steps: 63 | Train Loss: 0.1556105 Vali Loss: 0.2378992 Test Loss: 0.3106006
Validation loss decreased (0.238823 --> 0.237899).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.732762575149536
Epoch: 22, Steps: 63 | Train Loss: 0.1527964 Vali Loss: 0.2372823 Test Loss: 0.3095361
Validation loss decreased (0.237899 --> 0.237282).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.803816556930542
Epoch: 23, Steps: 63 | Train Loss: 0.1508298 Vali Loss: 0.2359617 Test Loss: 0.3083864
Validation loss decreased (0.237282 --> 0.235962).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.465696096420288
Epoch: 24, Steps: 63 | Train Loss: 0.1488274 Vali Loss: 0.2359001 Test Loss: 0.3073755
Validation loss decreased (0.235962 --> 0.235900).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 4.448559761047363
Epoch: 25, Steps: 63 | Train Loss: 0.1466501 Vali Loss: 0.2358864 Test Loss: 0.3064936
Validation loss decreased (0.235900 --> 0.235886).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.529261589050293
Epoch: 26, Steps: 63 | Train Loss: 0.1444886 Vali Loss: 0.2351723 Test Loss: 0.3056514
Validation loss decreased (0.235886 --> 0.235172).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 4.292271852493286
Epoch: 27, Steps: 63 | Train Loss: 0.1437818 Vali Loss: 0.2344093 Test Loss: 0.3047619
Validation loss decreased (0.235172 --> 0.234409).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.5140573978424072
Epoch: 28, Steps: 63 | Train Loss: 0.1414134 Vali Loss: 0.2326892 Test Loss: 0.3040167
Validation loss decreased (0.234409 --> 0.232689).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.6916542053222656
Epoch: 29, Steps: 63 | Train Loss: 0.1404071 Vali Loss: 0.2318027 Test Loss: 0.3032705
Validation loss decreased (0.232689 --> 0.231803).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 4.226163625717163
Epoch: 30, Steps: 63 | Train Loss: 0.1391154 Vali Loss: 0.2329287 Test Loss: 0.3025049
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.2407073974609375
Epoch: 31, Steps: 63 | Train Loss: 0.1372756 Vali Loss: 0.2314741 Test Loss: 0.3018569
Validation loss decreased (0.231803 --> 0.231474).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.307485580444336
Epoch: 32, Steps: 63 | Train Loss: 0.1364229 Vali Loss: 0.2321781 Test Loss: 0.3012757
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.9419033527374268
Epoch: 33, Steps: 63 | Train Loss: 0.1349238 Vali Loss: 0.2318555 Test Loss: 0.3006367
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 4.13000750541687
Epoch: 34, Steps: 63 | Train Loss: 0.1349376 Vali Loss: 0.2315573 Test Loss: 0.3001573
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.2706797122955322
Epoch: 35, Steps: 63 | Train Loss: 0.1333276 Vali Loss: 0.2306155 Test Loss: 0.2996568
Validation loss decreased (0.231474 --> 0.230615).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 3.160209894180298
Epoch: 36, Steps: 63 | Train Loss: 0.1332535 Vali Loss: 0.2310193 Test Loss: 0.2990927
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 4.010864019393921
Epoch: 37, Steps: 63 | Train Loss: 0.1320800 Vali Loss: 0.2311796 Test Loss: 0.2986409
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 4.702436447143555
Epoch: 38, Steps: 63 | Train Loss: 0.1315694 Vali Loss: 0.2296257 Test Loss: 0.2982367
Validation loss decreased (0.230615 --> 0.229626).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 4.5409955978393555
Epoch: 39, Steps: 63 | Train Loss: 0.1309429 Vali Loss: 0.2297210 Test Loss: 0.2978471
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 4.11711573600769
Epoch: 40, Steps: 63 | Train Loss: 0.1302706 Vali Loss: 0.2291783 Test Loss: 0.2974209
Validation loss decreased (0.229626 --> 0.229178).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 3.5361998081207275
Epoch: 41, Steps: 63 | Train Loss: 0.1299258 Vali Loss: 0.2289684 Test Loss: 0.2970288
Validation loss decreased (0.229178 --> 0.228968).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 4.2124810218811035
Epoch: 42, Steps: 63 | Train Loss: 0.1291936 Vali Loss: 0.2296336 Test Loss: 0.2967018
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.4908297061920166
Epoch: 43, Steps: 63 | Train Loss: 0.1288394 Vali Loss: 0.2286088 Test Loss: 0.2963765
Validation loss decreased (0.228968 --> 0.228609).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 5.745252847671509
Epoch: 44, Steps: 63 | Train Loss: 0.1278455 Vali Loss: 0.2284934 Test Loss: 0.2960621
Validation loss decreased (0.228609 --> 0.228493).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 3.1595101356506348
Epoch: 45, Steps: 63 | Train Loss: 0.1279443 Vali Loss: 0.2285871 Test Loss: 0.2957747
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 5.034353733062744
Epoch: 46, Steps: 63 | Train Loss: 0.1275369 Vali Loss: 0.2265444 Test Loss: 0.2955148
Validation loss decreased (0.228493 --> 0.226544).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 4.721832036972046
Epoch: 47, Steps: 63 | Train Loss: 0.1268516 Vali Loss: 0.2281581 Test Loss: 0.2952259
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 4.037616968154907
Epoch: 48, Steps: 63 | Train Loss: 0.1263549 Vali Loss: 0.2290381 Test Loss: 0.2949470
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 3.7536041736602783
Epoch: 49, Steps: 63 | Train Loss: 0.1255527 Vali Loss: 0.2280790 Test Loss: 0.2947387
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 5.331801891326904
Epoch: 50, Steps: 63 | Train Loss: 0.1251607 Vali Loss: 0.2280107 Test Loss: 0.2945028
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 3.879094362258911
Epoch: 51, Steps: 63 | Train Loss: 0.1252690 Vali Loss: 0.2278668 Test Loss: 0.2942754
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 4.100051403045654
Epoch: 52, Steps: 63 | Train Loss: 0.1249799 Vali Loss: 0.2286779 Test Loss: 0.2940621
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 3.192246198654175
Epoch: 53, Steps: 63 | Train Loss: 0.1248819 Vali Loss: 0.2279742 Test Loss: 0.2938603
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 4.680332660675049
Epoch: 54, Steps: 63 | Train Loss: 0.1246826 Vali Loss: 0.2279307 Test Loss: 0.2936832
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.9477896690368652
Epoch: 55, Steps: 63 | Train Loss: 0.1238670 Vali Loss: 0.2273444 Test Loss: 0.2935035
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 3.0147316455841064
Epoch: 56, Steps: 63 | Train Loss: 0.1242319 Vali Loss: 0.2274154 Test Loss: 0.2933496
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.905893325805664
Epoch: 57, Steps: 63 | Train Loss: 0.1237228 Vali Loss: 0.2276654 Test Loss: 0.2931775
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 3.0529370307922363
Epoch: 58, Steps: 63 | Train Loss: 0.1237372 Vali Loss: 0.2271372 Test Loss: 0.2930356
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 3.9447028636932373
Epoch: 59, Steps: 63 | Train Loss: 0.1231864 Vali Loss: 0.2266218 Test Loss: 0.2928811
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 3.3503429889678955
Epoch: 60, Steps: 63 | Train Loss: 0.1225017 Vali Loss: 0.2280841 Test Loss: 0.2927382
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 3.838752508163452
Epoch: 61, Steps: 63 | Train Loss: 0.1229752 Vali Loss: 0.2260048 Test Loss: 0.2926102
Validation loss decreased (0.226544 --> 0.226005).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 4.057370901107788
Epoch: 62, Steps: 63 | Train Loss: 0.1225457 Vali Loss: 0.2265889 Test Loss: 0.2924896
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 3.3172645568847656
Epoch: 63, Steps: 63 | Train Loss: 0.1228594 Vali Loss: 0.2266795 Test Loss: 0.2923670
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.9585607051849365
Epoch: 64, Steps: 63 | Train Loss: 0.1220337 Vali Loss: 0.2268316 Test Loss: 0.2922634
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 4.754992485046387
Epoch: 65, Steps: 63 | Train Loss: 0.1219723 Vali Loss: 0.2263629 Test Loss: 0.2921566
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 3.45790958404541
Epoch: 66, Steps: 63 | Train Loss: 0.1222936 Vali Loss: 0.2263752 Test Loss: 0.2920544
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.9288041591644287
Epoch: 67, Steps: 63 | Train Loss: 0.1220000 Vali Loss: 0.2268640 Test Loss: 0.2919500
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 3.3341739177703857
Epoch: 68, Steps: 63 | Train Loss: 0.1214331 Vali Loss: 0.2261654 Test Loss: 0.2918621
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 3.185283899307251
Epoch: 69, Steps: 63 | Train Loss: 0.1217891 Vali Loss: 0.2259886 Test Loss: 0.2917836
Validation loss decreased (0.226005 --> 0.225989).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 3.602952480316162
Epoch: 70, Steps: 63 | Train Loss: 0.1210656 Vali Loss: 0.2258241 Test Loss: 0.2916895
Validation loss decreased (0.225989 --> 0.225824).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.8123562335968018
Epoch: 71, Steps: 63 | Train Loss: 0.1212939 Vali Loss: 0.2261262 Test Loss: 0.2915986
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 3.490469217300415
Epoch: 72, Steps: 63 | Train Loss: 0.1212309 Vali Loss: 0.2267232 Test Loss: 0.2915321
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 4.320236682891846
Epoch: 73, Steps: 63 | Train Loss: 0.1211217 Vali Loss: 0.2258072 Test Loss: 0.2914642
Validation loss decreased (0.225824 --> 0.225807).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 3.526887893676758
Epoch: 74, Steps: 63 | Train Loss: 0.1212159 Vali Loss: 0.2258507 Test Loss: 0.2913898
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 5.417096376419067
Epoch: 75, Steps: 63 | Train Loss: 0.1206824 Vali Loss: 0.2259595 Test Loss: 0.2913235
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 3.1001503467559814
Epoch: 76, Steps: 63 | Train Loss: 0.1207975 Vali Loss: 0.2270567 Test Loss: 0.2912691
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 4.426160573959351
Epoch: 77, Steps: 63 | Train Loss: 0.1207755 Vali Loss: 0.2249586 Test Loss: 0.2911967
Validation loss decreased (0.225807 --> 0.224959).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 3.7517454624176025
Epoch: 78, Steps: 63 | Train Loss: 0.1204160 Vali Loss: 0.2265795 Test Loss: 0.2911504
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 3.420971155166626
Epoch: 79, Steps: 63 | Train Loss: 0.1203223 Vali Loss: 0.2258989 Test Loss: 0.2910876
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.814701795578003
Epoch: 80, Steps: 63 | Train Loss: 0.1206024 Vali Loss: 0.2262119 Test Loss: 0.2910393
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.8876268863677979
Epoch: 81, Steps: 63 | Train Loss: 0.1201065 Vali Loss: 0.2264777 Test Loss: 0.2909897
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 3.8285768032073975
Epoch: 82, Steps: 63 | Train Loss: 0.1206673 Vali Loss: 0.2248000 Test Loss: 0.2909415
Validation loss decreased (0.224959 --> 0.224800).  Saving model ...
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 5.811230897903442
Epoch: 83, Steps: 63 | Train Loss: 0.1204518 Vali Loss: 0.2253793 Test Loss: 0.2908959
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 5.08700966835022
Epoch: 84, Steps: 63 | Train Loss: 0.1198685 Vali Loss: 0.2253920 Test Loss: 0.2908531
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 4.168315887451172
Epoch: 85, Steps: 63 | Train Loss: 0.1203558 Vali Loss: 0.2254846 Test Loss: 0.2908171
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 5.9218995571136475
Epoch: 86, Steps: 63 | Train Loss: 0.1201296 Vali Loss: 0.2251080 Test Loss: 0.2907765
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 3.29175066947937
Epoch: 87, Steps: 63 | Train Loss: 0.1203607 Vali Loss: 0.2259392 Test Loss: 0.2907372
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 3.6333208084106445
Epoch: 88, Steps: 63 | Train Loss: 0.1201362 Vali Loss: 0.2256584 Test Loss: 0.2907022
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 3.409557580947876
Epoch: 89, Steps: 63 | Train Loss: 0.1200063 Vali Loss: 0.2259770 Test Loss: 0.2906665
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 2.8088061809539795
Epoch: 90, Steps: 63 | Train Loss: 0.1200144 Vali Loss: 0.2254276 Test Loss: 0.2906346
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 4.670634984970093
Epoch: 91, Steps: 63 | Train Loss: 0.1198083 Vali Loss: 0.2258844 Test Loss: 0.2906056
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 3.2752082347869873
Epoch: 92, Steps: 63 | Train Loss: 0.1197471 Vali Loss: 0.2259456 Test Loss: 0.2905728
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 2.5771684646606445
Epoch: 93, Steps: 63 | Train Loss: 0.1198249 Vali Loss: 0.2256654 Test Loss: 0.2905429
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 3.114020586013794
Epoch: 94, Steps: 63 | Train Loss: 0.1195585 Vali Loss: 0.2255293 Test Loss: 0.2905204
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 3.3496432304382324
Epoch: 95, Steps: 63 | Train Loss: 0.1196021 Vali Loss: 0.2244698 Test Loss: 0.2904930
Validation loss decreased (0.224800 --> 0.224470).  Saving model ...
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 4.273125410079956
Epoch: 96, Steps: 63 | Train Loss: 0.1196394 Vali Loss: 0.2254920 Test Loss: 0.2904736
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 3.671238422393799
Epoch: 97, Steps: 63 | Train Loss: 0.1193269 Vali Loss: 0.2250625 Test Loss: 0.2904483
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 4.714772701263428
Epoch: 98, Steps: 63 | Train Loss: 0.1198288 Vali Loss: 0.2259775 Test Loss: 0.2904288
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 3.860135316848755
Epoch: 99, Steps: 63 | Train Loss: 0.1196398 Vali Loss: 0.2258251 Test Loss: 0.2904132
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 3.514488935470581
Epoch: 100, Steps: 63 | Train Loss: 0.1194775 Vali Loss: 0.2259222 Test Loss: 0.2903917
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8185
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=74, out_features=93, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6166272.0
params:  6975.0
Trainable parameters:  6975
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 4.250648260116577
Epoch: 1, Steps: 63 | Train Loss: 0.4126591 Vali Loss: 0.2180678 Test Loss: 0.2807967
Validation loss decreased (inf --> 0.218068).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.564518928527832
Epoch: 2, Steps: 63 | Train Loss: 0.4065859 Vali Loss: 0.2159819 Test Loss: 0.2784964
Validation loss decreased (0.218068 --> 0.215982).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.826202154159546
Epoch: 3, Steps: 63 | Train Loss: 0.4047203 Vali Loss: 0.2150797 Test Loss: 0.2772773
Validation loss decreased (0.215982 --> 0.215080).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.6940813064575195
Epoch: 4, Steps: 63 | Train Loss: 0.4030509 Vali Loss: 0.2124371 Test Loss: 0.2768438
Validation loss decreased (0.215080 --> 0.212437).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.4876327514648438
Epoch: 5, Steps: 63 | Train Loss: 0.4013041 Vali Loss: 0.2124558 Test Loss: 0.2764337
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.5280067920684814
Epoch: 6, Steps: 63 | Train Loss: 0.4026780 Vali Loss: 0.2124251 Test Loss: 0.2760007
Validation loss decreased (0.212437 --> 0.212425).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.4415204524993896
Epoch: 7, Steps: 63 | Train Loss: 0.4018272 Vali Loss: 0.2125757 Test Loss: 0.2758837
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 6.401410341262817
Epoch: 8, Steps: 63 | Train Loss: 0.4000242 Vali Loss: 0.2114494 Test Loss: 0.2757142
Validation loss decreased (0.212425 --> 0.211449).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 4.146967649459839
Epoch: 9, Steps: 63 | Train Loss: 0.3984795 Vali Loss: 0.2115579 Test Loss: 0.2753804
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 5.7296648025512695
Epoch: 10, Steps: 63 | Train Loss: 0.3986286 Vali Loss: 0.2114777 Test Loss: 0.2754166
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 4.526539087295532
Epoch: 11, Steps: 63 | Train Loss: 0.3988321 Vali Loss: 0.2117808 Test Loss: 0.2752544
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 4.726020574569702
Epoch: 12, Steps: 63 | Train Loss: 0.4003810 Vali Loss: 0.2112124 Test Loss: 0.2750436
Validation loss decreased (0.211449 --> 0.211212).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 4.282236099243164
Epoch: 13, Steps: 63 | Train Loss: 0.3983237 Vali Loss: 0.2118240 Test Loss: 0.2750636
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 5.1317784786224365
Epoch: 14, Steps: 63 | Train Loss: 0.3955109 Vali Loss: 0.2102232 Test Loss: 0.2751040
Validation loss decreased (0.211212 --> 0.210223).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.759709119796753
Epoch: 15, Steps: 63 | Train Loss: 0.4004528 Vali Loss: 0.2113579 Test Loss: 0.2751291
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.9105420112609863
Epoch: 16, Steps: 63 | Train Loss: 0.4002321 Vali Loss: 0.2113837 Test Loss: 0.2749335
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.6675753593444824
Epoch: 17, Steps: 63 | Train Loss: 0.4000089 Vali Loss: 0.2099308 Test Loss: 0.2749066
Validation loss decreased (0.210223 --> 0.209931).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.0386290550231934
Epoch: 18, Steps: 63 | Train Loss: 0.3997549 Vali Loss: 0.2112553 Test Loss: 0.2748483
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.8624963760375977
Epoch: 19, Steps: 63 | Train Loss: 0.3993252 Vali Loss: 0.2112591 Test Loss: 0.2747360
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.6042585372924805
Epoch: 20, Steps: 63 | Train Loss: 0.3981932 Vali Loss: 0.2121640 Test Loss: 0.2747118
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.86745548248291
Epoch: 21, Steps: 63 | Train Loss: 0.3980838 Vali Loss: 0.2109754 Test Loss: 0.2745682
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.3445651531219482
Epoch: 22, Steps: 63 | Train Loss: 0.3984845 Vali Loss: 0.2099550 Test Loss: 0.2747715
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.8635125160217285
Epoch: 23, Steps: 63 | Train Loss: 0.3991015 Vali Loss: 0.2102277 Test Loss: 0.2746556
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 4.715794324874878
Epoch: 24, Steps: 63 | Train Loss: 0.3965706 Vali Loss: 0.2097741 Test Loss: 0.2747076
Validation loss decreased (0.209931 --> 0.209774).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 3.6688852310180664
Epoch: 25, Steps: 63 | Train Loss: 0.3993925 Vali Loss: 0.2099928 Test Loss: 0.2747037
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 4.631874322891235
Epoch: 26, Steps: 63 | Train Loss: 0.3988920 Vali Loss: 0.2105889 Test Loss: 0.2746415
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.5113582611083984
Epoch: 27, Steps: 63 | Train Loss: 0.3996765 Vali Loss: 0.2106659 Test Loss: 0.2746025
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.0812599658966064
Epoch: 28, Steps: 63 | Train Loss: 0.3989892 Vali Loss: 0.2114505 Test Loss: 0.2744916
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.9512526988983154
Epoch: 29, Steps: 63 | Train Loss: 0.3991444 Vali Loss: 0.2111389 Test Loss: 0.2744965
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.902463436126709
Epoch: 30, Steps: 63 | Train Loss: 0.3969185 Vali Loss: 0.2113370 Test Loss: 0.2745464
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 3.1481945514678955
Epoch: 31, Steps: 63 | Train Loss: 0.3969041 Vali Loss: 0.2100473 Test Loss: 0.2745443
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 4.536556005477905
Epoch: 32, Steps: 63 | Train Loss: 0.3984147 Vali Loss: 0.2108318 Test Loss: 0.2745462
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 4.240556001663208
Epoch: 33, Steps: 63 | Train Loss: 0.3986012 Vali Loss: 0.2100011 Test Loss: 0.2745509
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.3777196407318115
Epoch: 34, Steps: 63 | Train Loss: 0.3995029 Vali Loss: 0.2103552 Test Loss: 0.2745049
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 4.483554124832153
Epoch: 35, Steps: 63 | Train Loss: 0.3981173 Vali Loss: 0.2106541 Test Loss: 0.2744752
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 4.230926990509033
Epoch: 36, Steps: 63 | Train Loss: 0.3975553 Vali Loss: 0.2099871 Test Loss: 0.2745432
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 4.331171751022339
Epoch: 37, Steps: 63 | Train Loss: 0.3959964 Vali Loss: 0.2098004 Test Loss: 0.2744049
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 4.2938196659088135
Epoch: 38, Steps: 63 | Train Loss: 0.3994023 Vali Loss: 0.2101759 Test Loss: 0.2743707
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 4.277704954147339
Epoch: 39, Steps: 63 | Train Loss: 0.3982079 Vali Loss: 0.2104246 Test Loss: 0.2743908
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 3.3587474822998047
Epoch: 40, Steps: 63 | Train Loss: 0.3984420 Vali Loss: 0.2099774 Test Loss: 0.2744050
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 3.9508872032165527
Epoch: 41, Steps: 63 | Train Loss: 0.3976031 Vali Loss: 0.2103403 Test Loss: 0.2744575
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 4.457407712936401
Epoch: 42, Steps: 63 | Train Loss: 0.3985984 Vali Loss: 0.2104583 Test Loss: 0.2744127
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 3.3920090198516846
Epoch: 43, Steps: 63 | Train Loss: 0.3959155 Vali Loss: 0.2103729 Test Loss: 0.2744728
EarlyStopping counter: 19 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.143144130706787
Epoch: 44, Steps: 63 | Train Loss: 0.3956745 Vali Loss: 0.2099679 Test Loss: 0.2744163
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_360_96_FITS_ETTh2_ftM_sl360_ll48_pl96_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.274494469165802, mae:0.3371294140815735, rse:0.4222290515899658, corr:[0.27562    0.27804777 0.27609903 0.27390075 0.27286118 0.27223092
 0.2711986  0.26973805 0.26866877 0.26754662 0.266161   0.26437333
 0.2628433  0.26180163 0.26112187 0.26084736 0.26050916 0.26013955
 0.25935847 0.25831437 0.25731528 0.25625655 0.254935   0.25285298
 0.2504354  0.24829115 0.24672791 0.2453251  0.24402928 0.24296765
 0.24203275 0.24077956 0.2389124  0.23700853 0.2356851  0.23491423
 0.23397313 0.23246898 0.23123936 0.2306434  0.23063704 0.23058218
 0.22983499 0.228577   0.22775176 0.22724175 0.22647329 0.22474197
 0.22236879 0.22046112 0.21951221 0.21873243 0.217536   0.21590573
 0.21411952 0.21239553 0.21091649 0.20908807 0.20744123 0.2067287
 0.20683903 0.20696704 0.20699848 0.20680279 0.20655254 0.20633788
 0.20581722 0.20490871 0.20426202 0.20403197 0.20393571 0.2034404
 0.20232847 0.20111877 0.20036808 0.19967219 0.19907837 0.19838347
 0.19760962 0.19680373 0.19657709 0.19580686 0.1947235  0.193995
 0.19425705 0.19479664 0.19485736 0.1942031  0.19308716 0.19257404
 0.19178711 0.18974368 0.18816254 0.18794107 0.18789141 0.18295394]
