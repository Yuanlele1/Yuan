Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=134, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=134, out_features=169, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  20290816.0
params:  22815.0
Trainable parameters:  22815
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.9229509830474854
Epoch: 1, Steps: 60 | Train Loss: 0.5939043 Vali Loss: 0.4738082 Test Loss: 0.4555569
Validation loss decreased (inf --> 0.473808).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.8939030170440674
Epoch: 2, Steps: 60 | Train Loss: 0.4656968 Vali Loss: 0.4178649 Test Loss: 0.4160650
Validation loss decreased (0.473808 --> 0.417865).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.841874122619629
Epoch: 3, Steps: 60 | Train Loss: 0.3980339 Vali Loss: 0.3906931 Test Loss: 0.3986507
Validation loss decreased (0.417865 --> 0.390693).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.6949496269226074
Epoch: 4, Steps: 60 | Train Loss: 0.3580892 Vali Loss: 0.3759646 Test Loss: 0.3908110
Validation loss decreased (0.390693 --> 0.375965).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.7940444946289062
Epoch: 5, Steps: 60 | Train Loss: 0.3298921 Vali Loss: 0.3677008 Test Loss: 0.3870026
Validation loss decreased (0.375965 --> 0.367701).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.787886381149292
Epoch: 6, Steps: 60 | Train Loss: 0.3089573 Vali Loss: 0.3616729 Test Loss: 0.3848561
Validation loss decreased (0.367701 --> 0.361673).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.8129024505615234
Epoch: 7, Steps: 60 | Train Loss: 0.2919407 Vali Loss: 0.3567288 Test Loss: 0.3833959
Validation loss decreased (0.361673 --> 0.356729).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.7820563316345215
Epoch: 8, Steps: 60 | Train Loss: 0.2768771 Vali Loss: 0.3526848 Test Loss: 0.3820576
Validation loss decreased (0.356729 --> 0.352685).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.837909460067749
Epoch: 9, Steps: 60 | Train Loss: 0.2645118 Vali Loss: 0.3499402 Test Loss: 0.3809455
Validation loss decreased (0.352685 --> 0.349940).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.977170467376709
Epoch: 10, Steps: 60 | Train Loss: 0.2538239 Vali Loss: 0.3469704 Test Loss: 0.3799384
Validation loss decreased (0.349940 --> 0.346970).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.7212128639221191
Epoch: 11, Steps: 60 | Train Loss: 0.2446774 Vali Loss: 0.3444183 Test Loss: 0.3790458
Validation loss decreased (0.346970 --> 0.344418).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.868929386138916
Epoch: 12, Steps: 60 | Train Loss: 0.2359196 Vali Loss: 0.3419819 Test Loss: 0.3779882
Validation loss decreased (0.344418 --> 0.341982).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.9196462631225586
Epoch: 13, Steps: 60 | Train Loss: 0.2292066 Vali Loss: 0.3399659 Test Loss: 0.3771471
Validation loss decreased (0.341982 --> 0.339966).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.952601432800293
Epoch: 14, Steps: 60 | Train Loss: 0.2224996 Vali Loss: 0.3377579 Test Loss: 0.3762632
Validation loss decreased (0.339966 --> 0.337758).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.8665013313293457
Epoch: 15, Steps: 60 | Train Loss: 0.2164935 Vali Loss: 0.3358575 Test Loss: 0.3754286
Validation loss decreased (0.337758 --> 0.335858).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.891826868057251
Epoch: 16, Steps: 60 | Train Loss: 0.2111164 Vali Loss: 0.3342285 Test Loss: 0.3745472
Validation loss decreased (0.335858 --> 0.334229).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.9088115692138672
Epoch: 17, Steps: 60 | Train Loss: 0.2067531 Vali Loss: 0.3326064 Test Loss: 0.3737303
Validation loss decreased (0.334229 --> 0.332606).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.7907381057739258
Epoch: 18, Steps: 60 | Train Loss: 0.2025826 Vali Loss: 0.3311454 Test Loss: 0.3728938
Validation loss decreased (0.332606 --> 0.331145).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.9023487567901611
Epoch: 19, Steps: 60 | Train Loss: 0.1984012 Vali Loss: 0.3296781 Test Loss: 0.3723323
Validation loss decreased (0.331145 --> 0.329678).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.231898069381714
Epoch: 20, Steps: 60 | Train Loss: 0.1947686 Vali Loss: 0.3284117 Test Loss: 0.3716643
Validation loss decreased (0.329678 --> 0.328412).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.062647819519043
Epoch: 21, Steps: 60 | Train Loss: 0.1914572 Vali Loss: 0.3270485 Test Loss: 0.3711030
Validation loss decreased (0.328412 --> 0.327049).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.9455041885375977
Epoch: 22, Steps: 60 | Train Loss: 0.1884117 Vali Loss: 0.3261195 Test Loss: 0.3705539
Validation loss decreased (0.327049 --> 0.326119).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.0489230155944824
Epoch: 23, Steps: 60 | Train Loss: 0.1856673 Vali Loss: 0.3248470 Test Loss: 0.3699881
Validation loss decreased (0.326119 --> 0.324847).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.9258689880371094
Epoch: 24, Steps: 60 | Train Loss: 0.1827355 Vali Loss: 0.3239642 Test Loss: 0.3695048
Validation loss decreased (0.324847 --> 0.323964).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.9165775775909424
Epoch: 25, Steps: 60 | Train Loss: 0.1812314 Vali Loss: 0.3228785 Test Loss: 0.3689981
Validation loss decreased (0.323964 --> 0.322879).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.9380955696105957
Epoch: 26, Steps: 60 | Train Loss: 0.1786750 Vali Loss: 0.3219979 Test Loss: 0.3685990
Validation loss decreased (0.322879 --> 0.321998).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.864424228668213
Epoch: 27, Steps: 60 | Train Loss: 0.1771497 Vali Loss: 0.3211747 Test Loss: 0.3682202
Validation loss decreased (0.321998 --> 0.321175).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.8105566501617432
Epoch: 28, Steps: 60 | Train Loss: 0.1751240 Vali Loss: 0.3203598 Test Loss: 0.3677838
Validation loss decreased (0.321175 --> 0.320360).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.053365707397461
Epoch: 29, Steps: 60 | Train Loss: 0.1735988 Vali Loss: 0.3195608 Test Loss: 0.3674617
Validation loss decreased (0.320360 --> 0.319561).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.868847131729126
Epoch: 30, Steps: 60 | Train Loss: 0.1720200 Vali Loss: 0.3190534 Test Loss: 0.3671193
Validation loss decreased (0.319561 --> 0.319053).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.8603286743164062
Epoch: 31, Steps: 60 | Train Loss: 0.1705368 Vali Loss: 0.3181489 Test Loss: 0.3668159
Validation loss decreased (0.319053 --> 0.318149).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.9935250282287598
Epoch: 32, Steps: 60 | Train Loss: 0.1694224 Vali Loss: 0.3176308 Test Loss: 0.3665299
Validation loss decreased (0.318149 --> 0.317631).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.7207136154174805
Epoch: 33, Steps: 60 | Train Loss: 0.1681103 Vali Loss: 0.3171782 Test Loss: 0.3662386
Validation loss decreased (0.317631 --> 0.317178).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.8973345756530762
Epoch: 34, Steps: 60 | Train Loss: 0.1669600 Vali Loss: 0.3165509 Test Loss: 0.3660296
Validation loss decreased (0.317178 --> 0.316551).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.853682041168213
Epoch: 35, Steps: 60 | Train Loss: 0.1656879 Vali Loss: 0.3158225 Test Loss: 0.3657476
Validation loss decreased (0.316551 --> 0.315822).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.7988574504852295
Epoch: 36, Steps: 60 | Train Loss: 0.1646299 Vali Loss: 0.3154874 Test Loss: 0.3655607
Validation loss decreased (0.315822 --> 0.315487).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.80979323387146
Epoch: 37, Steps: 60 | Train Loss: 0.1639466 Vali Loss: 0.3149219 Test Loss: 0.3653341
Validation loss decreased (0.315487 --> 0.314922).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.0322420597076416
Epoch: 38, Steps: 60 | Train Loss: 0.1630490 Vali Loss: 0.3145966 Test Loss: 0.3651320
Validation loss decreased (0.314922 --> 0.314597).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.8119611740112305
Epoch: 39, Steps: 60 | Train Loss: 0.1624021 Vali Loss: 0.3140511 Test Loss: 0.3649707
Validation loss decreased (0.314597 --> 0.314051).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.8905293941497803
Epoch: 40, Steps: 60 | Train Loss: 0.1614848 Vali Loss: 0.3136921 Test Loss: 0.3647602
Validation loss decreased (0.314051 --> 0.313692).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.9495184421539307
Epoch: 41, Steps: 60 | Train Loss: 0.1607696 Vali Loss: 0.3133493 Test Loss: 0.3646741
Validation loss decreased (0.313692 --> 0.313349).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.9990458488464355
Epoch: 42, Steps: 60 | Train Loss: 0.1602484 Vali Loss: 0.3130389 Test Loss: 0.3644878
Validation loss decreased (0.313349 --> 0.313039).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.9905757904052734
Epoch: 43, Steps: 60 | Train Loss: 0.1593284 Vali Loss: 0.3126297 Test Loss: 0.3643384
Validation loss decreased (0.313039 --> 0.312630).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.9770357608795166
Epoch: 44, Steps: 60 | Train Loss: 0.1585048 Vali Loss: 0.3123672 Test Loss: 0.3641692
Validation loss decreased (0.312630 --> 0.312367).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.9406764507293701
Epoch: 45, Steps: 60 | Train Loss: 0.1577804 Vali Loss: 0.3120352 Test Loss: 0.3640774
Validation loss decreased (0.312367 --> 0.312035).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.7118735313415527
Epoch: 46, Steps: 60 | Train Loss: 0.1575657 Vali Loss: 0.3118007 Test Loss: 0.3639748
Validation loss decreased (0.312035 --> 0.311801).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.7830924987792969
Epoch: 47, Steps: 60 | Train Loss: 0.1571745 Vali Loss: 0.3115519 Test Loss: 0.3638625
Validation loss decreased (0.311801 --> 0.311552).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.947824478149414
Epoch: 48, Steps: 60 | Train Loss: 0.1570129 Vali Loss: 0.3112846 Test Loss: 0.3637549
Validation loss decreased (0.311552 --> 0.311285).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.8581740856170654
Epoch: 49, Steps: 60 | Train Loss: 0.1560025 Vali Loss: 0.3110180 Test Loss: 0.3636668
Validation loss decreased (0.311285 --> 0.311018).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.8141179084777832
Epoch: 50, Steps: 60 | Train Loss: 0.1556990 Vali Loss: 0.3107873 Test Loss: 0.3635444
Validation loss decreased (0.311018 --> 0.310787).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.7590103149414062
Epoch: 51, Steps: 60 | Train Loss: 0.1554929 Vali Loss: 0.3105709 Test Loss: 0.3634901
Validation loss decreased (0.310787 --> 0.310571).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.8405330181121826
Epoch: 52, Steps: 60 | Train Loss: 0.1548172 Vali Loss: 0.3102517 Test Loss: 0.3634190
Validation loss decreased (0.310571 --> 0.310252).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.8409836292266846
Epoch: 53, Steps: 60 | Train Loss: 0.1547485 Vali Loss: 0.3099635 Test Loss: 0.3633136
Validation loss decreased (0.310252 --> 0.309963).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.8105762004852295
Epoch: 54, Steps: 60 | Train Loss: 0.1543146 Vali Loss: 0.3099138 Test Loss: 0.3632451
Validation loss decreased (0.309963 --> 0.309914).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.9681954383850098
Epoch: 55, Steps: 60 | Train Loss: 0.1537953 Vali Loss: 0.3097599 Test Loss: 0.3631775
Validation loss decreased (0.309914 --> 0.309760).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.7733070850372314
Epoch: 56, Steps: 60 | Train Loss: 0.1539822 Vali Loss: 0.3096239 Test Loss: 0.3631036
Validation loss decreased (0.309760 --> 0.309624).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.8025751113891602
Epoch: 57, Steps: 60 | Train Loss: 0.1534987 Vali Loss: 0.3094787 Test Loss: 0.3630443
Validation loss decreased (0.309624 --> 0.309479).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.9022002220153809
Epoch: 58, Steps: 60 | Train Loss: 0.1533311 Vali Loss: 0.3090401 Test Loss: 0.3630017
Validation loss decreased (0.309479 --> 0.309040).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.9112987518310547
Epoch: 59, Steps: 60 | Train Loss: 0.1530800 Vali Loss: 0.3091322 Test Loss: 0.3629460
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.9308838844299316
Epoch: 60, Steps: 60 | Train Loss: 0.1525568 Vali Loss: 0.3089584 Test Loss: 0.3628938
Validation loss decreased (0.309040 --> 0.308958).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.8998479843139648
Epoch: 61, Steps: 60 | Train Loss: 0.1524671 Vali Loss: 0.3086685 Test Loss: 0.3628502
Validation loss decreased (0.308958 --> 0.308668).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.8890166282653809
Epoch: 62, Steps: 60 | Train Loss: 0.1522858 Vali Loss: 0.3087462 Test Loss: 0.3627982
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.9159836769104004
Epoch: 63, Steps: 60 | Train Loss: 0.1521766 Vali Loss: 0.3084596 Test Loss: 0.3627523
Validation loss decreased (0.308668 --> 0.308460).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.9060282707214355
Epoch: 64, Steps: 60 | Train Loss: 0.1516715 Vali Loss: 0.3085083 Test Loss: 0.3627070
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.7730467319488525
Epoch: 65, Steps: 60 | Train Loss: 0.1514878 Vali Loss: 0.3083783 Test Loss: 0.3626888
Validation loss decreased (0.308460 --> 0.308378).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.9373421669006348
Epoch: 66, Steps: 60 | Train Loss: 0.1517602 Vali Loss: 0.3082641 Test Loss: 0.3626375
Validation loss decreased (0.308378 --> 0.308264).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.8134872913360596
Epoch: 67, Steps: 60 | Train Loss: 0.1516158 Vali Loss: 0.3082062 Test Loss: 0.3626141
Validation loss decreased (0.308264 --> 0.308206).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.8669912815093994
Epoch: 68, Steps: 60 | Train Loss: 0.1512268 Vali Loss: 0.3080432 Test Loss: 0.3625741
Validation loss decreased (0.308206 --> 0.308043).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.9698905944824219
Epoch: 69, Steps: 60 | Train Loss: 0.1509145 Vali Loss: 0.3079066 Test Loss: 0.3625477
Validation loss decreased (0.308043 --> 0.307907).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.9567699432373047
Epoch: 70, Steps: 60 | Train Loss: 0.1510247 Vali Loss: 0.3078724 Test Loss: 0.3625231
Validation loss decreased (0.307907 --> 0.307872).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.8589868545532227
Epoch: 71, Steps: 60 | Train Loss: 0.1508342 Vali Loss: 0.3078758 Test Loss: 0.3624892
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.9284894466400146
Epoch: 72, Steps: 60 | Train Loss: 0.1506204 Vali Loss: 0.3077180 Test Loss: 0.3624754
Validation loss decreased (0.307872 --> 0.307718).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.9641962051391602
Epoch: 73, Steps: 60 | Train Loss: 0.1506486 Vali Loss: 0.3076730 Test Loss: 0.3624464
Validation loss decreased (0.307718 --> 0.307673).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.852020502090454
Epoch: 74, Steps: 60 | Train Loss: 0.1503569 Vali Loss: 0.3076254 Test Loss: 0.3624232
Validation loss decreased (0.307673 --> 0.307625).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.8834469318389893
Epoch: 75, Steps: 60 | Train Loss: 0.1501981 Vali Loss: 0.3075094 Test Loss: 0.3624077
Validation loss decreased (0.307625 --> 0.307509).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.8635039329528809
Epoch: 76, Steps: 60 | Train Loss: 0.1504276 Vali Loss: 0.3074310 Test Loss: 0.3623855
Validation loss decreased (0.307509 --> 0.307431).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.8591234683990479
Epoch: 77, Steps: 60 | Train Loss: 0.1501783 Vali Loss: 0.3074280 Test Loss: 0.3623585
Validation loss decreased (0.307431 --> 0.307428).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.9316251277923584
Epoch: 78, Steps: 60 | Train Loss: 0.1500948 Vali Loss: 0.3073607 Test Loss: 0.3623534
Validation loss decreased (0.307428 --> 0.307361).  Saving model ...
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.9480817317962646
Epoch: 79, Steps: 60 | Train Loss: 0.1497000 Vali Loss: 0.3073442 Test Loss: 0.3623245
Validation loss decreased (0.307361 --> 0.307344).  Saving model ...
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.8819921016693115
Epoch: 80, Steps: 60 | Train Loss: 0.1499266 Vali Loss: 0.3072370 Test Loss: 0.3623092
Validation loss decreased (0.307344 --> 0.307237).  Saving model ...
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.9057562351226807
Epoch: 81, Steps: 60 | Train Loss: 0.1497288 Vali Loss: 0.3069164 Test Loss: 0.3623042
Validation loss decreased (0.307237 --> 0.306916).  Saving model ...
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.9059126377105713
Epoch: 82, Steps: 60 | Train Loss: 0.1500144 Vali Loss: 0.3071443 Test Loss: 0.3622803
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.9339213371276855
Epoch: 83, Steps: 60 | Train Loss: 0.1496188 Vali Loss: 0.3071258 Test Loss: 0.3622649
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.9978642463684082
Epoch: 84, Steps: 60 | Train Loss: 0.1492950 Vali Loss: 0.3067156 Test Loss: 0.3622554
Validation loss decreased (0.306916 --> 0.306716).  Saving model ...
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.022679090499878
Epoch: 85, Steps: 60 | Train Loss: 0.1495965 Vali Loss: 0.3070728 Test Loss: 0.3622380
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.9059257507324219
Epoch: 86, Steps: 60 | Train Loss: 0.1491915 Vali Loss: 0.3069434 Test Loss: 0.3622317
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.8856394290924072
Epoch: 87, Steps: 60 | Train Loss: 0.1493497 Vali Loss: 0.3068990 Test Loss: 0.3622263
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.8347797393798828
Epoch: 88, Steps: 60 | Train Loss: 0.1491330 Vali Loss: 0.3069378 Test Loss: 0.3622126
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.047621488571167
Epoch: 89, Steps: 60 | Train Loss: 0.1491357 Vali Loss: 0.3068548 Test Loss: 0.3622011
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.941227912902832
Epoch: 90, Steps: 60 | Train Loss: 0.1493811 Vali Loss: 0.3064995 Test Loss: 0.3621955
Validation loss decreased (0.306716 --> 0.306499).  Saving model ...
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.7991580963134766
Epoch: 91, Steps: 60 | Train Loss: 0.1490205 Vali Loss: 0.3067979 Test Loss: 0.3621902
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.902595043182373
Epoch: 92, Steps: 60 | Train Loss: 0.1488419 Vali Loss: 0.3067954 Test Loss: 0.3621762
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.749584436416626
Epoch: 93, Steps: 60 | Train Loss: 0.1487505 Vali Loss: 0.3067406 Test Loss: 0.3621736
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.988940715789795
Epoch: 94, Steps: 60 | Train Loss: 0.1492540 Vali Loss: 0.3067569 Test Loss: 0.3621670
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.7396204471588135
Epoch: 95, Steps: 60 | Train Loss: 0.1489335 Vali Loss: 0.3066853 Test Loss: 0.3621611
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.8951640129089355
Epoch: 96, Steps: 60 | Train Loss: 0.1489741 Vali Loss: 0.3066757 Test Loss: 0.3621483
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.807701826095581
Epoch: 97, Steps: 60 | Train Loss: 0.1485776 Vali Loss: 0.3066625 Test Loss: 0.3621422
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.8935372829437256
Epoch: 98, Steps: 60 | Train Loss: 0.1488322 Vali Loss: 0.3065821 Test Loss: 0.3621379
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.8191814422607422
Epoch: 99, Steps: 60 | Train Loss: 0.1486969 Vali Loss: 0.3066505 Test Loss: 0.3621310
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.9042437076568604
Epoch: 100, Steps: 60 | Train Loss: 0.1487415 Vali Loss: 0.3065948 Test Loss: 0.3621286
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.1160680107021042e-06
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=134, out_features=169, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  20290816.0
params:  22815.0
Trainable parameters:  22815
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.7386071681976318
Epoch: 1, Steps: 60 | Train Loss: 0.5299411 Vali Loss: 0.2916459 Test Loss: 0.3560154
Validation loss decreased (inf --> 0.291646).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.895899772644043
Epoch: 2, Steps: 60 | Train Loss: 0.5204086 Vali Loss: 0.2884023 Test Loss: 0.3547640
Validation loss decreased (0.291646 --> 0.288402).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.8445990085601807
Epoch: 3, Steps: 60 | Train Loss: 0.5167347 Vali Loss: 0.2861056 Test Loss: 0.3550012
Validation loss decreased (0.288402 --> 0.286106).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.011195182800293
Epoch: 4, Steps: 60 | Train Loss: 0.5135968 Vali Loss: 0.2851940 Test Loss: 0.3544078
Validation loss decreased (0.286106 --> 0.285194).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.9965665340423584
Epoch: 5, Steps: 60 | Train Loss: 0.5135924 Vali Loss: 0.2846466 Test Loss: 0.3543829
Validation loss decreased (0.285194 --> 0.284647).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.8982539176940918
Epoch: 6, Steps: 60 | Train Loss: 0.5134032 Vali Loss: 0.2834674 Test Loss: 0.3541795
Validation loss decreased (0.284647 --> 0.283467).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.8332293033599854
Epoch: 7, Steps: 60 | Train Loss: 0.5135142 Vali Loss: 0.2830914 Test Loss: 0.3540212
Validation loss decreased (0.283467 --> 0.283091).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.807201623916626
Epoch: 8, Steps: 60 | Train Loss: 0.5124102 Vali Loss: 0.2830732 Test Loss: 0.3536701
Validation loss decreased (0.283091 --> 0.283073).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.9565389156341553
Epoch: 9, Steps: 60 | Train Loss: 0.5131037 Vali Loss: 0.2825295 Test Loss: 0.3538141
Validation loss decreased (0.283073 --> 0.282529).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.8549678325653076
Epoch: 10, Steps: 60 | Train Loss: 0.5105587 Vali Loss: 0.2819331 Test Loss: 0.3536205
Validation loss decreased (0.282529 --> 0.281933).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.755711317062378
Epoch: 11, Steps: 60 | Train Loss: 0.5122003 Vali Loss: 0.2817435 Test Loss: 0.3535651
Validation loss decreased (0.281933 --> 0.281744).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.8903226852416992
Epoch: 12, Steps: 60 | Train Loss: 0.5080550 Vali Loss: 0.2811773 Test Loss: 0.3535346
Validation loss decreased (0.281744 --> 0.281177).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.8128623962402344
Epoch: 13, Steps: 60 | Train Loss: 0.5107130 Vali Loss: 0.2813290 Test Loss: 0.3533244
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.8758163452148438
Epoch: 14, Steps: 60 | Train Loss: 0.5100313 Vali Loss: 0.2810660 Test Loss: 0.3532792
Validation loss decreased (0.281177 --> 0.281066).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.806222677230835
Epoch: 15, Steps: 60 | Train Loss: 0.5092604 Vali Loss: 0.2809671 Test Loss: 0.3532201
Validation loss decreased (0.281066 --> 0.280967).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.8984432220458984
Epoch: 16, Steps: 60 | Train Loss: 0.5100697 Vali Loss: 0.2811471 Test Loss: 0.3531580
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.669818639755249
Epoch: 17, Steps: 60 | Train Loss: 0.5106160 Vali Loss: 0.2811514 Test Loss: 0.3530225
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.8278603553771973
Epoch: 18, Steps: 60 | Train Loss: 0.5098975 Vali Loss: 0.2809160 Test Loss: 0.3531086
Validation loss decreased (0.280967 --> 0.280916).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.733734369277954
Epoch: 19, Steps: 60 | Train Loss: 0.5084628 Vali Loss: 0.2805285 Test Loss: 0.3530297
Validation loss decreased (0.280916 --> 0.280528).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.2025301456451416
Epoch: 20, Steps: 60 | Train Loss: 0.5107492 Vali Loss: 0.2806669 Test Loss: 0.3529749
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.733102798461914
Epoch: 21, Steps: 60 | Train Loss: 0.5098819 Vali Loss: 0.2805200 Test Loss: 0.3529102
Validation loss decreased (0.280528 --> 0.280520).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.8493103981018066
Epoch: 22, Steps: 60 | Train Loss: 0.5089751 Vali Loss: 0.2806741 Test Loss: 0.3528029
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.03230357170105
Epoch: 23, Steps: 60 | Train Loss: 0.5105480 Vali Loss: 0.2806515 Test Loss: 0.3527860
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.902937889099121
Epoch: 24, Steps: 60 | Train Loss: 0.5094241 Vali Loss: 0.2805564 Test Loss: 0.3527517
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.8988962173461914
Epoch: 25, Steps: 60 | Train Loss: 0.5085249 Vali Loss: 0.2805424 Test Loss: 0.3527532
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.7684252262115479
Epoch: 26, Steps: 60 | Train Loss: 0.5087151 Vali Loss: 0.2803716 Test Loss: 0.3527367
Validation loss decreased (0.280520 --> 0.280372).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.9260540008544922
Epoch: 27, Steps: 60 | Train Loss: 0.5082752 Vali Loss: 0.2805129 Test Loss: 0.3526857
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.8664555549621582
Epoch: 28, Steps: 60 | Train Loss: 0.5087865 Vali Loss: 0.2803818 Test Loss: 0.3527298
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.6734035015106201
Epoch: 29, Steps: 60 | Train Loss: 0.5094585 Vali Loss: 0.2801837 Test Loss: 0.3527140
Validation loss decreased (0.280372 --> 0.280184).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.755812644958496
Epoch: 30, Steps: 60 | Train Loss: 0.5094654 Vali Loss: 0.2803297 Test Loss: 0.3526270
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.9623689651489258
Epoch: 31, Steps: 60 | Train Loss: 0.5089610 Vali Loss: 0.2801529 Test Loss: 0.3526466
Validation loss decreased (0.280184 --> 0.280153).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.9445271492004395
Epoch: 32, Steps: 60 | Train Loss: 0.5087098 Vali Loss: 0.2801185 Test Loss: 0.3526649
Validation loss decreased (0.280153 --> 0.280118).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.7149779796600342
Epoch: 33, Steps: 60 | Train Loss: 0.5084706 Vali Loss: 0.2800579 Test Loss: 0.3527147
Validation loss decreased (0.280118 --> 0.280058).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.9945001602172852
Epoch: 34, Steps: 60 | Train Loss: 0.5089691 Vali Loss: 0.2802924 Test Loss: 0.3526124
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.0312302112579346
Epoch: 35, Steps: 60 | Train Loss: 0.5085400 Vali Loss: 0.2801098 Test Loss: 0.3526053
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.9444124698638916
Epoch: 36, Steps: 60 | Train Loss: 0.5079491 Vali Loss: 0.2801011 Test Loss: 0.3525736
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.994485855102539
Epoch: 37, Steps: 60 | Train Loss: 0.5090840 Vali Loss: 0.2801181 Test Loss: 0.3525875
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.9767391681671143
Epoch: 38, Steps: 60 | Train Loss: 0.5085789 Vali Loss: 0.2800691 Test Loss: 0.3525717
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.8549833297729492
Epoch: 39, Steps: 60 | Train Loss: 0.5096271 Vali Loss: 0.2800457 Test Loss: 0.3525321
Validation loss decreased (0.280058 --> 0.280046).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.9535999298095703
Epoch: 40, Steps: 60 | Train Loss: 0.5079103 Vali Loss: 0.2801184 Test Loss: 0.3525459
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.7760562896728516
Epoch: 41, Steps: 60 | Train Loss: 0.5081748 Vali Loss: 0.2799855 Test Loss: 0.3525633
Validation loss decreased (0.280046 --> 0.279985).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.9590849876403809
Epoch: 42, Steps: 60 | Train Loss: 0.5084532 Vali Loss: 0.2799891 Test Loss: 0.3525499
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.7560412883758545
Epoch: 43, Steps: 60 | Train Loss: 0.5082493 Vali Loss: 0.2799658 Test Loss: 0.3525764
Validation loss decreased (0.279985 --> 0.279966).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.752420425415039
Epoch: 44, Steps: 60 | Train Loss: 0.5074899 Vali Loss: 0.2799811 Test Loss: 0.3525495
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.8376681804656982
Epoch: 45, Steps: 60 | Train Loss: 0.5079633 Vali Loss: 0.2800015 Test Loss: 0.3525680
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.8424439430236816
Epoch: 46, Steps: 60 | Train Loss: 0.5089782 Vali Loss: 0.2799142 Test Loss: 0.3525504
Validation loss decreased (0.279966 --> 0.279914).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.9964725971221924
Epoch: 47, Steps: 60 | Train Loss: 0.5073007 Vali Loss: 0.2799154 Test Loss: 0.3525598
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.8614256381988525
Epoch: 48, Steps: 60 | Train Loss: 0.5077440 Vali Loss: 0.2799093 Test Loss: 0.3524944
Validation loss decreased (0.279914 --> 0.279909).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.7044193744659424
Epoch: 49, Steps: 60 | Train Loss: 0.5069960 Vali Loss: 0.2797484 Test Loss: 0.3525465
Validation loss decreased (0.279909 --> 0.279748).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.7717225551605225
Epoch: 50, Steps: 60 | Train Loss: 0.5078253 Vali Loss: 0.2798660 Test Loss: 0.3525096
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.950361728668213
Epoch: 51, Steps: 60 | Train Loss: 0.5083357 Vali Loss: 0.2798561 Test Loss: 0.3525127
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.7207262516021729
Epoch: 52, Steps: 60 | Train Loss: 0.5090608 Vali Loss: 0.2798946 Test Loss: 0.3525232
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.889723539352417
Epoch: 53, Steps: 60 | Train Loss: 0.5086451 Vali Loss: 0.2797821 Test Loss: 0.3525052
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.7688744068145752
Epoch: 54, Steps: 60 | Train Loss: 0.5082222 Vali Loss: 0.2798652 Test Loss: 0.3525111
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.8510162830352783
Epoch: 55, Steps: 60 | Train Loss: 0.5090807 Vali Loss: 0.2798931 Test Loss: 0.3524964
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.8738973140716553
Epoch: 56, Steps: 60 | Train Loss: 0.5070584 Vali Loss: 0.2798284 Test Loss: 0.3525162
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.8811447620391846
Epoch: 57, Steps: 60 | Train Loss: 0.5094578 Vali Loss: 0.2798547 Test Loss: 0.3525210
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.9293289184570312
Epoch: 58, Steps: 60 | Train Loss: 0.5079013 Vali Loss: 0.2798573 Test Loss: 0.3524919
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.8366708755493164
Epoch: 59, Steps: 60 | Train Loss: 0.5085918 Vali Loss: 0.2798207 Test Loss: 0.3525203
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.752601146697998
Epoch: 60, Steps: 60 | Train Loss: 0.5073509 Vali Loss: 0.2797996 Test Loss: 0.3525132
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.7497386932373047
Epoch: 61, Steps: 60 | Train Loss: 0.5090528 Vali Loss: 0.2798347 Test Loss: 0.3525130
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.8279507160186768
Epoch: 62, Steps: 60 | Train Loss: 0.5084199 Vali Loss: 0.2798294 Test Loss: 0.3525056
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.743006706237793
Epoch: 63, Steps: 60 | Train Loss: 0.5089402 Vali Loss: 0.2798797 Test Loss: 0.3525028
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.8666212558746338
Epoch: 64, Steps: 60 | Train Loss: 0.5071560 Vali Loss: 0.2798422 Test Loss: 0.3524930
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.8787095546722412
Epoch: 65, Steps: 60 | Train Loss: 0.5083090 Vali Loss: 0.2798460 Test Loss: 0.3524942
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.8205022811889648
Epoch: 66, Steps: 60 | Train Loss: 0.5065931 Vali Loss: 0.2798163 Test Loss: 0.3525031
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.8579349517822266
Epoch: 67, Steps: 60 | Train Loss: 0.5086628 Vali Loss: 0.2798129 Test Loss: 0.3525083
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.0254335403442383
Epoch: 68, Steps: 60 | Train Loss: 0.5068559 Vali Loss: 0.2798391 Test Loss: 0.3524974
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.879838228225708
Epoch: 69, Steps: 60 | Train Loss: 0.5081284 Vali Loss: 0.2797806 Test Loss: 0.3525122
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.33247482776641846, mae:0.37491679191589355, rse:0.4624025821685791, corr:[0.26552814 0.26817188 0.26734588 0.26626417 0.26592815 0.26598042
 0.26557398 0.26451632 0.26362187 0.26273406 0.26166254 0.26006353
 0.2585115  0.25751883 0.25696346 0.25673932 0.25630343 0.25553283
 0.25450805 0.2535388  0.25262392 0.25148132 0.24993224 0.24792835
 0.24594787 0.2442403  0.24282207 0.24144077 0.24008165 0.2387363
 0.23744932 0.23602432 0.23460056 0.23333628 0.2322909  0.23115528
 0.22987594 0.22877564 0.2281364  0.22764868 0.22711015 0.22637102
 0.22536151 0.22430444 0.22345611 0.22255558 0.22128713 0.2194129
 0.21730138 0.21553755 0.21428654 0.21295571 0.21143472 0.20961238
 0.20733747 0.2052273  0.20349696 0.20188674 0.20051189 0.19942577
 0.19885959 0.19846487 0.19828768 0.19819896 0.19764389 0.1970505
 0.19643    0.19581844 0.195229   0.19456415 0.1936842  0.19280423
 0.19191799 0.19101872 0.18999933 0.18866235 0.18760324 0.18696514
 0.18658717 0.18587095 0.18536578 0.18486221 0.18436797 0.18404086
 0.18391888 0.1839056  0.18362321 0.18311448 0.18241161 0.18188806
 0.18149705 0.18093348 0.18072423 0.18069527 0.18057163 0.18007708
 0.17910379 0.17799966 0.17707738 0.17625013 0.17536886 0.17431015
 0.1735049  0.1728316  0.17249651 0.17218432 0.17169465 0.1712997
 0.17056271 0.1698612  0.1691998  0.1687803  0.16817375 0.16772477
 0.16738504 0.16692981 0.16628432 0.16504537 0.16360506 0.16203532
 0.16071497 0.15939577 0.15824077 0.15720846 0.15615071 0.15516259
 0.15434472 0.15330803 0.15225938 0.15140226 0.15099625 0.15045992
 0.14965847 0.14864397 0.14783987 0.14764002 0.14760283 0.14722115
 0.14632882 0.14541918 0.14516377 0.145259   0.14497483 0.14362204
 0.14130907 0.13929778 0.13825546 0.13775733 0.13688836 0.13545644
 0.13432485 0.13363777 0.13387723 0.13407229 0.1333689  0.13195597
 0.13133527 0.1318752  0.13278313 0.13318993 0.13243818 0.13172273
 0.1317443  0.1321133  0.1321183  0.13148469 0.13102455 0.13075246
 0.1305244  0.12943996 0.12787327 0.12631904 0.12588829 0.12574536
 0.12505232 0.1229611  0.12075544 0.12020323 0.1204553  0.12055112
 0.11941574 0.1181389  0.11877374 0.12112517 0.12206459 0.12057289
 0.11836846 0.11827792 0.12113568 0.12236501 0.11925191 0.11621933]
