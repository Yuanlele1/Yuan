Args in experiment:
Namespace(H_order=2, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_180_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_180_96_FITS_ETTh2_ftM_sl180_ll48_pl96_H2_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8365
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=26, out_features=39, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  908544.0
params:  1053.0
Trainable parameters:  1053
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.6959295272827148
Epoch: 1, Steps: 65 | Train Loss: 0.4434529 Vali Loss: 0.2989625 Test Loss: 0.4074939
Validation loss decreased (inf --> 0.298963).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.4439342021942139
Epoch: 2, Steps: 65 | Train Loss: 0.3693627 Vali Loss: 0.2741493 Test Loss: 0.3740819
Validation loss decreased (0.298963 --> 0.274149).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.549691915512085
Epoch: 3, Steps: 65 | Train Loss: 0.3220425 Vali Loss: 0.2592962 Test Loss: 0.3524483
Validation loss decreased (0.274149 --> 0.259296).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.386983871459961
Epoch: 4, Steps: 65 | Train Loss: 0.2886202 Vali Loss: 0.2478801 Test Loss: 0.3382704
Validation loss decreased (0.259296 --> 0.247880).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.733694076538086
Epoch: 5, Steps: 65 | Train Loss: 0.2653992 Vali Loss: 0.2429308 Test Loss: 0.3285780
Validation loss decreased (0.247880 --> 0.242931).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.6523947715759277
Epoch: 6, Steps: 65 | Train Loss: 0.2483420 Vali Loss: 0.2368675 Test Loss: 0.3218203
Validation loss decreased (0.242931 --> 0.236868).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.3917381763458252
Epoch: 7, Steps: 65 | Train Loss: 0.2352362 Vali Loss: 0.2336379 Test Loss: 0.3171183
Validation loss decreased (0.236868 --> 0.233638).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.5924506187438965
Epoch: 8, Steps: 65 | Train Loss: 0.2259422 Vali Loss: 0.2315706 Test Loss: 0.3135293
Validation loss decreased (0.233638 --> 0.231571).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.8335371017456055
Epoch: 9, Steps: 65 | Train Loss: 0.2159878 Vali Loss: 0.2297979 Test Loss: 0.3107750
Validation loss decreased (0.231571 --> 0.229798).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.375105857849121
Epoch: 10, Steps: 65 | Train Loss: 0.2116857 Vali Loss: 0.2278820 Test Loss: 0.3086179
Validation loss decreased (0.229798 --> 0.227882).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.5770297050476074
Epoch: 11, Steps: 65 | Train Loss: 0.2062601 Vali Loss: 0.2257231 Test Loss: 0.3068971
Validation loss decreased (0.227882 --> 0.225723).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.5051512718200684
Epoch: 12, Steps: 65 | Train Loss: 0.2018557 Vali Loss: 0.2254500 Test Loss: 0.3054820
Validation loss decreased (0.225723 --> 0.225450).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.9032320976257324
Epoch: 13, Steps: 65 | Train Loss: 0.1981210 Vali Loss: 0.2250056 Test Loss: 0.3042588
Validation loss decreased (0.225450 --> 0.225006).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.5862832069396973
Epoch: 14, Steps: 65 | Train Loss: 0.1949162 Vali Loss: 0.2229907 Test Loss: 0.3032326
Validation loss decreased (0.225006 --> 0.222991).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.4324588775634766
Epoch: 15, Steps: 65 | Train Loss: 0.1919555 Vali Loss: 0.2228929 Test Loss: 0.3022778
Validation loss decreased (0.222991 --> 0.222893).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.3841769695281982
Epoch: 16, Steps: 65 | Train Loss: 0.1898255 Vali Loss: 0.2220246 Test Loss: 0.3013902
Validation loss decreased (0.222893 --> 0.222025).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.8294458389282227
Epoch: 17, Steps: 65 | Train Loss: 0.1879178 Vali Loss: 0.2211517 Test Loss: 0.3007243
Validation loss decreased (0.222025 --> 0.221152).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.5370261669158936
Epoch: 18, Steps: 65 | Train Loss: 0.1856936 Vali Loss: 0.2201364 Test Loss: 0.3001074
Validation loss decreased (0.221152 --> 0.220136).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.6656489372253418
Epoch: 19, Steps: 65 | Train Loss: 0.1847884 Vali Loss: 0.2214947 Test Loss: 0.2995220
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.561722755432129
Epoch: 20, Steps: 65 | Train Loss: 0.1826665 Vali Loss: 0.2199004 Test Loss: 0.2990214
Validation loss decreased (0.220136 --> 0.219900).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.8821334838867188
Epoch: 21, Steps: 65 | Train Loss: 0.1817910 Vali Loss: 0.2199674 Test Loss: 0.2984963
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.267303705215454
Epoch: 22, Steps: 65 | Train Loss: 0.1803290 Vali Loss: 0.2185568 Test Loss: 0.2980934
Validation loss decreased (0.219900 --> 0.218557).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.4466521739959717
Epoch: 23, Steps: 65 | Train Loss: 0.1800629 Vali Loss: 0.2182054 Test Loss: 0.2977090
Validation loss decreased (0.218557 --> 0.218205).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.085029363632202
Epoch: 24, Steps: 65 | Train Loss: 0.1786120 Vali Loss: 0.2193138 Test Loss: 0.2973573
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.706545352935791
Epoch: 25, Steps: 65 | Train Loss: 0.1781997 Vali Loss: 0.2171597 Test Loss: 0.2970217
Validation loss decreased (0.218205 --> 0.217160).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.9568519592285156
Epoch: 26, Steps: 65 | Train Loss: 0.1775394 Vali Loss: 0.2190373 Test Loss: 0.2967225
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.8356242179870605
Epoch: 27, Steps: 65 | Train Loss: 0.1769439 Vali Loss: 0.2174588 Test Loss: 0.2964199
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.962904930114746
Epoch: 28, Steps: 65 | Train Loss: 0.1760105 Vali Loss: 0.2171229 Test Loss: 0.2961905
Validation loss decreased (0.217160 --> 0.217123).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.8881738185882568
Epoch: 29, Steps: 65 | Train Loss: 0.1758147 Vali Loss: 0.2166679 Test Loss: 0.2959602
Validation loss decreased (0.217123 --> 0.216668).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.6255395412445068
Epoch: 30, Steps: 65 | Train Loss: 0.1752684 Vali Loss: 0.2176811 Test Loss: 0.2957717
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.4748730659484863
Epoch: 31, Steps: 65 | Train Loss: 0.1741359 Vali Loss: 0.2180683 Test Loss: 0.2955415
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.7684967517852783
Epoch: 32, Steps: 65 | Train Loss: 0.1742951 Vali Loss: 0.2175390 Test Loss: 0.2953567
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.4873366355895996
Epoch: 33, Steps: 65 | Train Loss: 0.1734159 Vali Loss: 0.2169089 Test Loss: 0.2952052
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.4608526229858398
Epoch: 34, Steps: 65 | Train Loss: 0.1733055 Vali Loss: 0.2178355 Test Loss: 0.2950697
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.6352543830871582
Epoch: 35, Steps: 65 | Train Loss: 0.1734113 Vali Loss: 0.2160889 Test Loss: 0.2949069
Validation loss decreased (0.216668 --> 0.216089).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.4067528247833252
Epoch: 36, Steps: 65 | Train Loss: 0.1723741 Vali Loss: 0.2172038 Test Loss: 0.2947926
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.3539564609527588
Epoch: 37, Steps: 65 | Train Loss: 0.1725380 Vali Loss: 0.2176034 Test Loss: 0.2946313
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.4587547779083252
Epoch: 38, Steps: 65 | Train Loss: 0.1721654 Vali Loss: 0.2163045 Test Loss: 0.2945415
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.3746800422668457
Epoch: 39, Steps: 65 | Train Loss: 0.1713260 Vali Loss: 0.2169467 Test Loss: 0.2944363
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.6555547714233398
Epoch: 40, Steps: 65 | Train Loss: 0.1713693 Vali Loss: 0.2161406 Test Loss: 0.2943421
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.365159273147583
Epoch: 41, Steps: 65 | Train Loss: 0.1714177 Vali Loss: 0.2155088 Test Loss: 0.2942390
Validation loss decreased (0.216089 --> 0.215509).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.619471549987793
Epoch: 42, Steps: 65 | Train Loss: 0.1715066 Vali Loss: 0.2166901 Test Loss: 0.2941431
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.4810290336608887
Epoch: 43, Steps: 65 | Train Loss: 0.1712475 Vali Loss: 0.2159576 Test Loss: 0.2940703
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.2121086120605469
Epoch: 44, Steps: 65 | Train Loss: 0.1707814 Vali Loss: 0.2162933 Test Loss: 0.2939722
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.3784914016723633
Epoch: 45, Steps: 65 | Train Loss: 0.1704759 Vali Loss: 0.2150181 Test Loss: 0.2939148
Validation loss decreased (0.215509 --> 0.215018).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.654341459274292
Epoch: 46, Steps: 65 | Train Loss: 0.1703652 Vali Loss: 0.2155430 Test Loss: 0.2938483
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.5810868740081787
Epoch: 47, Steps: 65 | Train Loss: 0.1706237 Vali Loss: 0.2150916 Test Loss: 0.2937895
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.851884365081787
Epoch: 48, Steps: 65 | Train Loss: 0.1706104 Vali Loss: 0.2152629 Test Loss: 0.2937516
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.917140007019043
Epoch: 49, Steps: 65 | Train Loss: 0.1703496 Vali Loss: 0.2161498 Test Loss: 0.2936909
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.5361902713775635
Epoch: 50, Steps: 65 | Train Loss: 0.1702719 Vali Loss: 0.2154953 Test Loss: 0.2936350
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.7120795249938965
Epoch: 51, Steps: 65 | Train Loss: 0.1695978 Vali Loss: 0.2155894 Test Loss: 0.2935854
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.7320952415466309
Epoch: 52, Steps: 65 | Train Loss: 0.1689894 Vali Loss: 0.2158637 Test Loss: 0.2935424
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.7726695537567139
Epoch: 53, Steps: 65 | Train Loss: 0.1699878 Vali Loss: 0.2150204 Test Loss: 0.2934985
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.5969128608703613
Epoch: 54, Steps: 65 | Train Loss: 0.1689293 Vali Loss: 0.2143207 Test Loss: 0.2934442
Validation loss decreased (0.215018 --> 0.214321).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.491971731185913
Epoch: 55, Steps: 65 | Train Loss: 0.1698012 Vali Loss: 0.2154803 Test Loss: 0.2934159
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.5662791728973389
Epoch: 56, Steps: 65 | Train Loss: 0.1692623 Vali Loss: 0.2141242 Test Loss: 0.2933683
Validation loss decreased (0.214321 --> 0.214124).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.4467744827270508
Epoch: 57, Steps: 65 | Train Loss: 0.1694350 Vali Loss: 0.2154416 Test Loss: 0.2933445
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.4120757579803467
Epoch: 58, Steps: 65 | Train Loss: 0.1696313 Vali Loss: 0.2146534 Test Loss: 0.2933125
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.7254388332366943
Epoch: 59, Steps: 65 | Train Loss: 0.1694528 Vali Loss: 0.2152392 Test Loss: 0.2932910
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.039839744567871
Epoch: 60, Steps: 65 | Train Loss: 0.1687374 Vali Loss: 0.2148133 Test Loss: 0.2932644
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.8572726249694824
Epoch: 61, Steps: 65 | Train Loss: 0.1688908 Vali Loss: 0.2153413 Test Loss: 0.2932306
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.2509822845458984
Epoch: 62, Steps: 65 | Train Loss: 0.1693102 Vali Loss: 0.2151511 Test Loss: 0.2932174
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.8895025253295898
Epoch: 63, Steps: 65 | Train Loss: 0.1692592 Vali Loss: 0.2145430 Test Loss: 0.2931924
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.5878033638000488
Epoch: 64, Steps: 65 | Train Loss: 0.1689352 Vali Loss: 0.2144313 Test Loss: 0.2931667
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.5411648750305176
Epoch: 65, Steps: 65 | Train Loss: 0.1689075 Vali Loss: 0.2151449 Test Loss: 0.2931455
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.3532016277313232
Epoch: 66, Steps: 65 | Train Loss: 0.1688799 Vali Loss: 0.2153865 Test Loss: 0.2931260
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.784712314605713
Epoch: 67, Steps: 65 | Train Loss: 0.1684793 Vali Loss: 0.2149943 Test Loss: 0.2931050
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.6771621704101562
Epoch: 68, Steps: 65 | Train Loss: 0.1691125 Vali Loss: 0.2141801 Test Loss: 0.2930890
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.0809593200683594
Epoch: 69, Steps: 65 | Train Loss: 0.1686775 Vali Loss: 0.2148539 Test Loss: 0.2930725
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.575150966644287
Epoch: 70, Steps: 65 | Train Loss: 0.1689283 Vali Loss: 0.2149656 Test Loss: 0.2930563
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.4585859775543213
Epoch: 71, Steps: 65 | Train Loss: 0.1686302 Vali Loss: 0.2145417 Test Loss: 0.2930425
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.636352300643921
Epoch: 72, Steps: 65 | Train Loss: 0.1687586 Vali Loss: 0.2138557 Test Loss: 0.2930292
Validation loss decreased (0.214124 --> 0.213856).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.9969637393951416
Epoch: 73, Steps: 65 | Train Loss: 0.1688022 Vali Loss: 0.2153549 Test Loss: 0.2930166
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.3613102436065674
Epoch: 74, Steps: 65 | Train Loss: 0.1683552 Vali Loss: 0.2142420 Test Loss: 0.2930038
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.427959680557251
Epoch: 75, Steps: 65 | Train Loss: 0.1687767 Vali Loss: 0.2146700 Test Loss: 0.2929911
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.5019996166229248
Epoch: 76, Steps: 65 | Train Loss: 0.1685197 Vali Loss: 0.2142982 Test Loss: 0.2929781
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.4126832485198975
Epoch: 77, Steps: 65 | Train Loss: 0.1686952 Vali Loss: 0.2150382 Test Loss: 0.2929679
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.560394048690796
Epoch: 78, Steps: 65 | Train Loss: 0.1679508 Vali Loss: 0.2145996 Test Loss: 0.2929578
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.494300127029419
Epoch: 79, Steps: 65 | Train Loss: 0.1681436 Vali Loss: 0.2149725 Test Loss: 0.2929488
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.6453804969787598
Epoch: 80, Steps: 65 | Train Loss: 0.1687346 Vali Loss: 0.2151533 Test Loss: 0.2929433
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.6859149932861328
Epoch: 81, Steps: 65 | Train Loss: 0.1685398 Vali Loss: 0.2133668 Test Loss: 0.2929334
Validation loss decreased (0.213856 --> 0.213367).  Saving model ...
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.5399763584136963
Epoch: 82, Steps: 65 | Train Loss: 0.1684662 Vali Loss: 0.2139333 Test Loss: 0.2929229
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.8139889240264893
Epoch: 83, Steps: 65 | Train Loss: 0.1684937 Vali Loss: 0.2152807 Test Loss: 0.2929175
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.5695717334747314
Epoch: 84, Steps: 65 | Train Loss: 0.1686117 Vali Loss: 0.2157279 Test Loss: 0.2929092
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.4270329475402832
Epoch: 85, Steps: 65 | Train Loss: 0.1685526 Vali Loss: 0.2139639 Test Loss: 0.2929041
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.6598961353302002
Epoch: 86, Steps: 65 | Train Loss: 0.1684716 Vali Loss: 0.2154832 Test Loss: 0.2928964
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.690702199935913
Epoch: 87, Steps: 65 | Train Loss: 0.1680355 Vali Loss: 0.2148878 Test Loss: 0.2928895
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.578145980834961
Epoch: 88, Steps: 65 | Train Loss: 0.1673706 Vali Loss: 0.2136893 Test Loss: 0.2928851
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.006967544555664
Epoch: 89, Steps: 65 | Train Loss: 0.1678381 Vali Loss: 0.2150934 Test Loss: 0.2928781
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.5749623775482178
Epoch: 90, Steps: 65 | Train Loss: 0.1685787 Vali Loss: 0.2141141 Test Loss: 0.2928738
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.6723966598510742
Epoch: 91, Steps: 65 | Train Loss: 0.1684458 Vali Loss: 0.2144255 Test Loss: 0.2928656
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.6645822525024414
Epoch: 92, Steps: 65 | Train Loss: 0.1683646 Vali Loss: 0.2148932 Test Loss: 0.2928604
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.669468879699707
Epoch: 93, Steps: 65 | Train Loss: 0.1677019 Vali Loss: 0.2149936 Test Loss: 0.2928564
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.6602697372436523
Epoch: 94, Steps: 65 | Train Loss: 0.1683349 Vali Loss: 0.2147819 Test Loss: 0.2928525
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.5552215576171875
Epoch: 95, Steps: 65 | Train Loss: 0.1683038 Vali Loss: 0.2146342 Test Loss: 0.2928492
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.3295338153839111
Epoch: 96, Steps: 65 | Train Loss: 0.1680481 Vali Loss: 0.2138889 Test Loss: 0.2928454
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.3663768768310547
Epoch: 97, Steps: 65 | Train Loss: 0.1682794 Vali Loss: 0.2146797 Test Loss: 0.2928407
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.8481066226959229
Epoch: 98, Steps: 65 | Train Loss: 0.1681239 Vali Loss: 0.2141814 Test Loss: 0.2928386
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 2.2512729167938232
Epoch: 99, Steps: 65 | Train Loss: 0.1680543 Vali Loss: 0.2146921 Test Loss: 0.2928354
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.657606840133667
Epoch: 100, Steps: 65 | Train Loss: 0.1673762 Vali Loss: 0.2143191 Test Loss: 0.2928315
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8365
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=26, out_features=39, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  908544.0
params:  1053.0
Trainable parameters:  1053
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.5452847480773926
Epoch: 1, Steps: 65 | Train Loss: 0.4143178 Vali Loss: 0.2121804 Test Loss: 0.2910738
Validation loss decreased (inf --> 0.212180).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.6860783100128174
Epoch: 2, Steps: 65 | Train Loss: 0.4126911 Vali Loss: 0.2101996 Test Loss: 0.2903015
Validation loss decreased (0.212180 --> 0.210200).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.3820288181304932
Epoch: 3, Steps: 65 | Train Loss: 0.4100822 Vali Loss: 0.2108007 Test Loss: 0.2898729
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.4787843227386475
Epoch: 4, Steps: 65 | Train Loss: 0.4092544 Vali Loss: 0.2105498 Test Loss: 0.2897193
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.4478790760040283
Epoch: 5, Steps: 65 | Train Loss: 0.4082185 Vali Loss: 0.2098880 Test Loss: 0.2896054
Validation loss decreased (0.210200 --> 0.209888).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.5179133415222168
Epoch: 6, Steps: 65 | Train Loss: 0.4086784 Vali Loss: 0.2099492 Test Loss: 0.2894123
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.8774895668029785
Epoch: 7, Steps: 65 | Train Loss: 0.4086346 Vali Loss: 0.2088617 Test Loss: 0.2892592
Validation loss decreased (0.209888 --> 0.208862).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.5271079540252686
Epoch: 8, Steps: 65 | Train Loss: 0.4089943 Vali Loss: 0.2094886 Test Loss: 0.2890433
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.391232967376709
Epoch: 9, Steps: 65 | Train Loss: 0.4068943 Vali Loss: 0.2097997 Test Loss: 0.2889576
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.5900039672851562
Epoch: 10, Steps: 65 | Train Loss: 0.4084038 Vali Loss: 0.2090671 Test Loss: 0.2888715
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.2657814025878906
Epoch: 11, Steps: 65 | Train Loss: 0.4082601 Vali Loss: 0.2096448 Test Loss: 0.2887906
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.504936695098877
Epoch: 12, Steps: 65 | Train Loss: 0.4077322 Vali Loss: 0.2094378 Test Loss: 0.2887467
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.215045213699341
Epoch: 13, Steps: 65 | Train Loss: 0.4051239 Vali Loss: 0.2095265 Test Loss: 0.2886502
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.4855115413665771
Epoch: 14, Steps: 65 | Train Loss: 0.4069161 Vali Loss: 0.2095250 Test Loss: 0.2885354
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.4048254489898682
Epoch: 15, Steps: 65 | Train Loss: 0.4069799 Vali Loss: 0.2086145 Test Loss: 0.2884181
Validation loss decreased (0.208862 --> 0.208615).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.411076307296753
Epoch: 16, Steps: 65 | Train Loss: 0.4072947 Vali Loss: 0.2096314 Test Loss: 0.2885169
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.4713637828826904
Epoch: 17, Steps: 65 | Train Loss: 0.4076351 Vali Loss: 0.2090507 Test Loss: 0.2883569
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.8181464672088623
Epoch: 18, Steps: 65 | Train Loss: 0.4052577 Vali Loss: 0.2080616 Test Loss: 0.2883337
Validation loss decreased (0.208615 --> 0.208062).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.7176694869995117
Epoch: 19, Steps: 65 | Train Loss: 0.4075823 Vali Loss: 0.2090795 Test Loss: 0.2882849
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.8750979900360107
Epoch: 20, Steps: 65 | Train Loss: 0.4073293 Vali Loss: 0.2101790 Test Loss: 0.2883030
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.4833886623382568
Epoch: 21, Steps: 65 | Train Loss: 0.4031432 Vali Loss: 0.2084042 Test Loss: 0.2883013
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.5726938247680664
Epoch: 22, Steps: 65 | Train Loss: 0.4070130 Vali Loss: 0.2078103 Test Loss: 0.2883255
Validation loss decreased (0.208062 --> 0.207810).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.3291659355163574
Epoch: 23, Steps: 65 | Train Loss: 0.4070719 Vali Loss: 0.2086559 Test Loss: 0.2882603
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.400881290435791
Epoch: 24, Steps: 65 | Train Loss: 0.4063269 Vali Loss: 0.2092797 Test Loss: 0.2882098
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.5746128559112549
Epoch: 25, Steps: 65 | Train Loss: 0.4069645 Vali Loss: 0.2096232 Test Loss: 0.2882113
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.5768439769744873
Epoch: 26, Steps: 65 | Train Loss: 0.4059030 Vali Loss: 0.2087372 Test Loss: 0.2881727
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.330735683441162
Epoch: 27, Steps: 65 | Train Loss: 0.4068814 Vali Loss: 0.2083549 Test Loss: 0.2881739
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.293562650680542
Epoch: 28, Steps: 65 | Train Loss: 0.4066896 Vali Loss: 0.2096102 Test Loss: 0.2881501
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.5842299461364746
Epoch: 29, Steps: 65 | Train Loss: 0.4054907 Vali Loss: 0.2086499 Test Loss: 0.2881118
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.3100059032440186
Epoch: 30, Steps: 65 | Train Loss: 0.4048987 Vali Loss: 0.2083681 Test Loss: 0.2880720
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.4833455085754395
Epoch: 31, Steps: 65 | Train Loss: 0.4067165 Vali Loss: 0.2086664 Test Loss: 0.2880790
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.6876542568206787
Epoch: 32, Steps: 65 | Train Loss: 0.4052511 Vali Loss: 0.2078718 Test Loss: 0.2880726
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.9799220561981201
Epoch: 33, Steps: 65 | Train Loss: 0.4063250 Vali Loss: 0.2093713 Test Loss: 0.2880188
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.5957016944885254
Epoch: 34, Steps: 65 | Train Loss: 0.4068254 Vali Loss: 0.2087635 Test Loss: 0.2880532
EarlyStopping counter: 12 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.8113467693328857
Epoch: 35, Steps: 65 | Train Loss: 0.4042902 Vali Loss: 0.2092131 Test Loss: 0.2880703
EarlyStopping counter: 13 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.876938819885254
Epoch: 36, Steps: 65 | Train Loss: 0.4058816 Vali Loss: 0.2083495 Test Loss: 0.2880351
EarlyStopping counter: 14 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.3306663036346436
Epoch: 37, Steps: 65 | Train Loss: 0.4055344 Vali Loss: 0.2086451 Test Loss: 0.2880517
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.4292519092559814
Epoch: 38, Steps: 65 | Train Loss: 0.4060139 Vali Loss: 0.2086384 Test Loss: 0.2879991
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.5799033641815186
Epoch: 39, Steps: 65 | Train Loss: 0.4065090 Vali Loss: 0.2086936 Test Loss: 0.2880208
EarlyStopping counter: 17 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.549447774887085
Epoch: 40, Steps: 65 | Train Loss: 0.4039416 Vali Loss: 0.2088606 Test Loss: 0.2879927
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.6111836433410645
Epoch: 41, Steps: 65 | Train Loss: 0.4058303 Vali Loss: 0.2080109 Test Loss: 0.2879853
EarlyStopping counter: 19 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.46177077293396
Epoch: 42, Steps: 65 | Train Loss: 0.4057871 Vali Loss: 0.2087619 Test Loss: 0.2879955
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_180_96_FITS_ETTh2_ftM_sl180_ll48_pl96_H2_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.2881074845790863, mae:0.3413611054420471, rse:0.4325721859931946, corr:[0.27566862 0.27695423 0.27661273 0.2751338  0.27345717 0.27226046
 0.27151763 0.2707117  0.2697608  0.2682941  0.26671246 0.26494923
 0.2636117  0.2625588  0.26178685 0.2611151  0.26045737 0.25974253
 0.2588948  0.257965   0.25691748 0.2556139  0.25395054 0.25188342
 0.24932641 0.24697073 0.2447863  0.24299711 0.24138035 0.23999886
 0.2386011  0.23691219 0.23482753 0.23278348 0.23122844 0.23002534
 0.22903991 0.22774152 0.22658016 0.22520033 0.22419277 0.22353832
 0.22317792 0.22270022 0.22203851 0.2208374  0.2189269  0.21668874
 0.21389064 0.21152268 0.20950699 0.2077988  0.20595662 0.20413156
 0.20210327 0.20005985 0.19846994 0.19705093 0.1959038  0.19480713
 0.19418582 0.19340728 0.19316335 0.19285508 0.19258678 0.19237274
 0.19208542 0.19145143 0.1906936  0.189956   0.18880375 0.187606
 0.18585056 0.18422921 0.18270922 0.18150762 0.18070216 0.18063186
 0.18050052 0.17983805 0.17932723 0.17897552 0.17912608 0.1796664
 0.18065402 0.18117109 0.18143123 0.18101223 0.1804146  0.17988268
 0.17982817 0.17977758 0.18005715 0.18051204 0.18039605 0.18024188]
