Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=134, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=134, out_features=151, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  18129664.0
params:  20385.0
Trainable parameters:  20385
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.9102420806884766
Epoch: 1, Steps: 61 | Train Loss: 0.5905101 Vali Loss: 0.2809253 Test Loss: 0.3097096
Validation loss decreased (inf --> 0.280925).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.8053638935089111
Epoch: 2, Steps: 61 | Train Loss: 0.4697817 Vali Loss: 0.2503036 Test Loss: 0.2876990
Validation loss decreased (0.280925 --> 0.250304).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.769249677658081
Epoch: 3, Steps: 61 | Train Loss: 0.4462493 Vali Loss: 0.2392676 Test Loss: 0.2825502
Validation loss decreased (0.250304 --> 0.239268).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.8335812091827393
Epoch: 4, Steps: 61 | Train Loss: 0.4351286 Vali Loss: 0.2345479 Test Loss: 0.2800957
Validation loss decreased (0.239268 --> 0.234548).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.7678468227386475
Epoch: 5, Steps: 61 | Train Loss: 0.4285501 Vali Loss: 0.2297699 Test Loss: 0.2790653
Validation loss decreased (0.234548 --> 0.229770).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.8802502155303955
Epoch: 6, Steps: 61 | Train Loss: 0.4236986 Vali Loss: 0.2279387 Test Loss: 0.2778234
Validation loss decreased (0.229770 --> 0.227939).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.920882225036621
Epoch: 7, Steps: 61 | Train Loss: 0.4200658 Vali Loss: 0.2260412 Test Loss: 0.2769214
Validation loss decreased (0.227939 --> 0.226041).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.0072054862976074
Epoch: 8, Steps: 61 | Train Loss: 0.4180381 Vali Loss: 0.2228653 Test Loss: 0.2766780
Validation loss decreased (0.226041 --> 0.222865).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.6811027526855469
Epoch: 9, Steps: 61 | Train Loss: 0.4148757 Vali Loss: 0.2231447 Test Loss: 0.2762375
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.8263678550720215
Epoch: 10, Steps: 61 | Train Loss: 0.4146239 Vali Loss: 0.2225027 Test Loss: 0.2755665
Validation loss decreased (0.222865 --> 0.222503).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.9012129306793213
Epoch: 11, Steps: 61 | Train Loss: 0.4132080 Vali Loss: 0.2215710 Test Loss: 0.2756617
Validation loss decreased (0.222503 --> 0.221571).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.8310251235961914
Epoch: 12, Steps: 61 | Train Loss: 0.4111266 Vali Loss: 0.2203328 Test Loss: 0.2750252
Validation loss decreased (0.221571 --> 0.220333).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.8291141986846924
Epoch: 13, Steps: 61 | Train Loss: 0.4113586 Vali Loss: 0.2195628 Test Loss: 0.2748294
Validation loss decreased (0.220333 --> 0.219563).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.799701452255249
Epoch: 14, Steps: 61 | Train Loss: 0.4104613 Vali Loss: 0.2193556 Test Loss: 0.2746605
Validation loss decreased (0.219563 --> 0.219356).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.9973554611206055
Epoch: 15, Steps: 61 | Train Loss: 0.4093730 Vali Loss: 0.2187217 Test Loss: 0.2746138
Validation loss decreased (0.219356 --> 0.218722).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.8025355339050293
Epoch: 16, Steps: 61 | Train Loss: 0.4094441 Vali Loss: 0.2172264 Test Loss: 0.2743513
Validation loss decreased (0.218722 --> 0.217226).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.802626609802246
Epoch: 17, Steps: 61 | Train Loss: 0.4080457 Vali Loss: 0.2185008 Test Loss: 0.2742704
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.7755701541900635
Epoch: 18, Steps: 61 | Train Loss: 0.4084801 Vali Loss: 0.2184434 Test Loss: 0.2740185
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.8343148231506348
Epoch: 19, Steps: 61 | Train Loss: 0.4078582 Vali Loss: 0.2173901 Test Loss: 0.2739250
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.7226827144622803
Epoch: 20, Steps: 61 | Train Loss: 0.4068462 Vali Loss: 0.2175928 Test Loss: 0.2738055
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.911017656326294
Epoch: 21, Steps: 61 | Train Loss: 0.4068292 Vali Loss: 0.2168427 Test Loss: 0.2736672
Validation loss decreased (0.217226 --> 0.216843).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.7252914905548096
Epoch: 22, Steps: 61 | Train Loss: 0.4055682 Vali Loss: 0.2172441 Test Loss: 0.2736638
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.8528177738189697
Epoch: 23, Steps: 61 | Train Loss: 0.4063149 Vali Loss: 0.2161691 Test Loss: 0.2736270
Validation loss decreased (0.216843 --> 0.216169).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.896775722503662
Epoch: 24, Steps: 61 | Train Loss: 0.4057443 Vali Loss: 0.2158699 Test Loss: 0.2735164
Validation loss decreased (0.216169 --> 0.215870).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.7464969158172607
Epoch: 25, Steps: 61 | Train Loss: 0.4057752 Vali Loss: 0.2169914 Test Loss: 0.2735260
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.8225939273834229
Epoch: 26, Steps: 61 | Train Loss: 0.4059309 Vali Loss: 0.2158075 Test Loss: 0.2733197
Validation loss decreased (0.215870 --> 0.215808).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.7581779956817627
Epoch: 27, Steps: 61 | Train Loss: 0.4056648 Vali Loss: 0.2156047 Test Loss: 0.2733523
Validation loss decreased (0.215808 --> 0.215605).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.8375494480133057
Epoch: 28, Steps: 61 | Train Loss: 0.4051399 Vali Loss: 0.2149970 Test Loss: 0.2732497
Validation loss decreased (0.215605 --> 0.214997).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.7833502292633057
Epoch: 29, Steps: 61 | Train Loss: 0.4052886 Vali Loss: 0.2151760 Test Loss: 0.2733710
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.8555960655212402
Epoch: 30, Steps: 61 | Train Loss: 0.4043969 Vali Loss: 0.2153797 Test Loss: 0.2732170
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.7255167961120605
Epoch: 31, Steps: 61 | Train Loss: 0.4050868 Vali Loss: 0.2153582 Test Loss: 0.2731727
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.8713045120239258
Epoch: 32, Steps: 61 | Train Loss: 0.4047910 Vali Loss: 0.2154861 Test Loss: 0.2732635
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.8148436546325684
Epoch: 33, Steps: 61 | Train Loss: 0.4041875 Vali Loss: 0.2154320 Test Loss: 0.2731886
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.75262451171875
Epoch: 34, Steps: 61 | Train Loss: 0.4045911 Vali Loss: 0.2149505 Test Loss: 0.2731049
Validation loss decreased (0.214997 --> 0.214951).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.7210898399353027
Epoch: 35, Steps: 61 | Train Loss: 0.4045103 Vali Loss: 0.2155196 Test Loss: 0.2730946
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.8448669910430908
Epoch: 36, Steps: 61 | Train Loss: 0.4045186 Vali Loss: 0.2151451 Test Loss: 0.2730702
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.7990715503692627
Epoch: 37, Steps: 61 | Train Loss: 0.4037233 Vali Loss: 0.2154884 Test Loss: 0.2730850
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.6593654155731201
Epoch: 38, Steps: 61 | Train Loss: 0.4040670 Vali Loss: 0.2143805 Test Loss: 0.2730040
Validation loss decreased (0.214951 --> 0.214381).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.6864397525787354
Epoch: 39, Steps: 61 | Train Loss: 0.4038911 Vali Loss: 0.2151850 Test Loss: 0.2730529
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.7191367149353027
Epoch: 40, Steps: 61 | Train Loss: 0.4033158 Vali Loss: 0.2143616 Test Loss: 0.2730143
Validation loss decreased (0.214381 --> 0.214362).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.7659368515014648
Epoch: 41, Steps: 61 | Train Loss: 0.4034313 Vali Loss: 0.2149126 Test Loss: 0.2729756
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.6246087551116943
Epoch: 42, Steps: 61 | Train Loss: 0.4038600 Vali Loss: 0.2147402 Test Loss: 0.2729618
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.7536416053771973
Epoch: 43, Steps: 61 | Train Loss: 0.4035849 Vali Loss: 0.2153027 Test Loss: 0.2729711
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.7936139106750488
Epoch: 44, Steps: 61 | Train Loss: 0.4037897 Vali Loss: 0.2141597 Test Loss: 0.2729637
Validation loss decreased (0.214362 --> 0.214160).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.828429937362671
Epoch: 45, Steps: 61 | Train Loss: 0.4036701 Vali Loss: 0.2139945 Test Loss: 0.2729333
Validation loss decreased (0.214160 --> 0.213994).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.7064197063446045
Epoch: 46, Steps: 61 | Train Loss: 0.4035258 Vali Loss: 0.2155834 Test Loss: 0.2729234
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.5624277591705322
Epoch: 47, Steps: 61 | Train Loss: 0.4034293 Vali Loss: 0.2144130 Test Loss: 0.2729392
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.7954134941101074
Epoch: 48, Steps: 61 | Train Loss: 0.4017365 Vali Loss: 0.2145040 Test Loss: 0.2728594
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.6484262943267822
Epoch: 49, Steps: 61 | Train Loss: 0.4031150 Vali Loss: 0.2143376 Test Loss: 0.2729017
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.8292944431304932
Epoch: 50, Steps: 61 | Train Loss: 0.4031160 Vali Loss: 0.2143250 Test Loss: 0.2728900
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.8701183795928955
Epoch: 51, Steps: 61 | Train Loss: 0.4033718 Vali Loss: 0.2149523 Test Loss: 0.2728918
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.7157080173492432
Epoch: 52, Steps: 61 | Train Loss: 0.4033688 Vali Loss: 0.2144388 Test Loss: 0.2728962
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.7714250087738037
Epoch: 53, Steps: 61 | Train Loss: 0.4027121 Vali Loss: 0.2146350 Test Loss: 0.2729023
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.8307805061340332
Epoch: 54, Steps: 61 | Train Loss: 0.4030209 Vali Loss: 0.2146768 Test Loss: 0.2728601
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.7872705459594727
Epoch: 55, Steps: 61 | Train Loss: 0.4033419 Vali Loss: 0.2137947 Test Loss: 0.2728690
Validation loss decreased (0.213994 --> 0.213795).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.8138227462768555
Epoch: 56, Steps: 61 | Train Loss: 0.4022898 Vali Loss: 0.2140334 Test Loss: 0.2728558
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.7402911186218262
Epoch: 57, Steps: 61 | Train Loss: 0.4032781 Vali Loss: 0.2134813 Test Loss: 0.2728807
Validation loss decreased (0.213795 --> 0.213481).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.6026687622070312
Epoch: 58, Steps: 61 | Train Loss: 0.4030291 Vali Loss: 0.2140982 Test Loss: 0.2728537
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.6851892471313477
Epoch: 59, Steps: 61 | Train Loss: 0.4032446 Vali Loss: 0.2141303 Test Loss: 0.2728574
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.8411118984222412
Epoch: 60, Steps: 61 | Train Loss: 0.4030373 Vali Loss: 0.2147767 Test Loss: 0.2728504
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.758944034576416
Epoch: 61, Steps: 61 | Train Loss: 0.4021522 Vali Loss: 0.2143904 Test Loss: 0.2728022
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.9919497966766357
Epoch: 62, Steps: 61 | Train Loss: 0.4029313 Vali Loss: 0.2140605 Test Loss: 0.2728203
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.8912436962127686
Epoch: 63, Steps: 61 | Train Loss: 0.4028163 Vali Loss: 0.2137219 Test Loss: 0.2728167
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.992584228515625
Epoch: 64, Steps: 61 | Train Loss: 0.4027649 Vali Loss: 0.2135924 Test Loss: 0.2728118
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.8075556755065918
Epoch: 65, Steps: 61 | Train Loss: 0.4027747 Vali Loss: 0.2144827 Test Loss: 0.2728082
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.872563123703003
Epoch: 66, Steps: 61 | Train Loss: 0.4023209 Vali Loss: 0.2134453 Test Loss: 0.2727996
Validation loss decreased (0.213481 --> 0.213445).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 3.02325701713562
Epoch: 67, Steps: 61 | Train Loss: 0.4025329 Vali Loss: 0.2146905 Test Loss: 0.2727961
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.7941656112670898
Epoch: 68, Steps: 61 | Train Loss: 0.4018156 Vali Loss: 0.2122664 Test Loss: 0.2727924
Validation loss decreased (0.213445 --> 0.212266).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.9596951007843018
Epoch: 69, Steps: 61 | Train Loss: 0.4027481 Vali Loss: 0.2155760 Test Loss: 0.2728077
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.9109973907470703
Epoch: 70, Steps: 61 | Train Loss: 0.4024288 Vali Loss: 0.2146288 Test Loss: 0.2728006
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.815330982208252
Epoch: 71, Steps: 61 | Train Loss: 0.4027442 Vali Loss: 0.2144143 Test Loss: 0.2727903
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.7841873168945312
Epoch: 72, Steps: 61 | Train Loss: 0.4015452 Vali Loss: 0.2149481 Test Loss: 0.2727911
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.7468087673187256
Epoch: 73, Steps: 61 | Train Loss: 0.4026156 Vali Loss: 0.2143784 Test Loss: 0.2727853
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.7194361686706543
Epoch: 74, Steps: 61 | Train Loss: 0.4031636 Vali Loss: 0.2132564 Test Loss: 0.2727907
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.7321946620941162
Epoch: 75, Steps: 61 | Train Loss: 0.4023322 Vali Loss: 0.2145320 Test Loss: 0.2727883
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.8093745708465576
Epoch: 76, Steps: 61 | Train Loss: 0.4030727 Vali Loss: 0.2150778 Test Loss: 0.2727897
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.8461167812347412
Epoch: 77, Steps: 61 | Train Loss: 0.4028254 Vali Loss: 0.2146086 Test Loss: 0.2727862
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.824519157409668
Epoch: 78, Steps: 61 | Train Loss: 0.4027841 Vali Loss: 0.2142066 Test Loss: 0.2727852
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.7584152221679688
Epoch: 79, Steps: 61 | Train Loss: 0.4023464 Vali Loss: 0.2145144 Test Loss: 0.2727742
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.840961217880249
Epoch: 80, Steps: 61 | Train Loss: 0.4025793 Vali Loss: 0.2139141 Test Loss: 0.2727860
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.749769926071167
Epoch: 81, Steps: 61 | Train Loss: 0.4028380 Vali Loss: 0.2142729 Test Loss: 0.2727808
EarlyStopping counter: 13 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.7016057968139648
Epoch: 82, Steps: 61 | Train Loss: 0.4027590 Vali Loss: 0.2151554 Test Loss: 0.2727787
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.8162062168121338
Epoch: 83, Steps: 61 | Train Loss: 0.4020328 Vali Loss: 0.2147500 Test Loss: 0.2727810
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.7768607139587402
Epoch: 84, Steps: 61 | Train Loss: 0.4024562 Vali Loss: 0.2141620 Test Loss: 0.2727796
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.6695640087127686
Epoch: 85, Steps: 61 | Train Loss: 0.4023411 Vali Loss: 0.2149017 Test Loss: 0.2727804
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.6856555938720703
Epoch: 86, Steps: 61 | Train Loss: 0.4014855 Vali Loss: 0.2144752 Test Loss: 0.2727747
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.6448090076446533
Epoch: 87, Steps: 61 | Train Loss: 0.4029515 Vali Loss: 0.2147568 Test Loss: 0.2727765
EarlyStopping counter: 19 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.6639623641967773
Epoch: 88, Steps: 61 | Train Loss: 0.4025924 Vali Loss: 0.2146425 Test Loss: 0.2727738
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.27238401770591736, mae:0.33725184202194214, rse:0.4206027388572693, corr:[0.27108744 0.27569157 0.27491337 0.27348635 0.27298623 0.27309307
 0.27269778 0.2716042  0.27052662 0.2694006  0.26826182 0.26687315
 0.2655551  0.2645128  0.26364976 0.26318893 0.26281294 0.2622046
 0.2612028  0.26003313 0.25897473 0.25795162 0.2566273  0.254759
 0.25264245 0.25081405 0.2495151  0.24846771 0.24733524 0.24589854
 0.24429363 0.24284501 0.24163745 0.2406433  0.23953353 0.23809448
 0.236661   0.23565692 0.23516443 0.23458499 0.23375218 0.23284861
 0.232056   0.23135683 0.23071659 0.22978489 0.22843929 0.22666942
 0.22475961 0.22305499 0.22175731 0.22037718 0.21910565 0.21781437
 0.2160402  0.21407887 0.21208635 0.21023542 0.20886442 0.20813219
 0.20781156 0.20731273 0.20686418 0.20679133 0.20649837 0.20628251
 0.20579351 0.20499001 0.20420226 0.20373891 0.203328   0.20278287
 0.20175213 0.2003298  0.19915448 0.1980331  0.19738132 0.19673364
 0.19604236 0.19506913 0.1950793  0.19562465 0.19531743 0.19414335
 0.19314668 0.19363032 0.1948154  0.19510575 0.19329031 0.19151323
 0.19156396 0.1926906  0.1927603  0.19052474 0.1895105  0.19527343]
