Args in experiment:
Namespace(H_order=2, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_180_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_180_96_FITS_ETTh2_ftM_sl180_ll48_pl96_H2_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8365
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=26, out_features=39, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  908544.0
params:  1053.0
Trainable parameters:  1053
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.8138172626495361
Epoch: 1, Steps: 65 | Train Loss: 0.5789249 Vali Loss: 0.2688159 Test Loss: 0.3690967
Validation loss decreased (inf --> 0.268816).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.9674923419952393
Epoch: 2, Steps: 65 | Train Loss: 0.4964711 Vali Loss: 0.2439658 Test Loss: 0.3355117
Validation loss decreased (0.268816 --> 0.243966).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.7308361530303955
Epoch: 3, Steps: 65 | Train Loss: 0.4665833 Vali Loss: 0.2336946 Test Loss: 0.3207604
Validation loss decreased (0.243966 --> 0.233695).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.9314210414886475
Epoch: 4, Steps: 65 | Train Loss: 0.4503124 Vali Loss: 0.2266810 Test Loss: 0.3132097
Validation loss decreased (0.233695 --> 0.226681).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.0248618125915527
Epoch: 5, Steps: 65 | Train Loss: 0.4420057 Vali Loss: 0.2253406 Test Loss: 0.3085375
Validation loss decreased (0.226681 --> 0.225341).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.855870246887207
Epoch: 6, Steps: 65 | Train Loss: 0.4363957 Vali Loss: 0.2214294 Test Loss: 0.3053400
Validation loss decreased (0.225341 --> 0.221429).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.814121961593628
Epoch: 7, Steps: 65 | Train Loss: 0.4319637 Vali Loss: 0.2201478 Test Loss: 0.3032220
Validation loss decreased (0.221429 --> 0.220148).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.7537968158721924
Epoch: 8, Steps: 65 | Train Loss: 0.4309924 Vali Loss: 0.2193168 Test Loss: 0.3014415
Validation loss decreased (0.220148 --> 0.219317).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.9537429809570312
Epoch: 9, Steps: 65 | Train Loss: 0.4233517 Vali Loss: 0.2185677 Test Loss: 0.3000591
Validation loss decreased (0.219317 --> 0.218568).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.5551934242248535
Epoch: 10, Steps: 65 | Train Loss: 0.4265195 Vali Loss: 0.2171953 Test Loss: 0.2990144
Validation loss decreased (0.218568 --> 0.217195).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.8669681549072266
Epoch: 11, Steps: 65 | Train Loss: 0.4247364 Vali Loss: 0.2158457 Test Loss: 0.2981195
Validation loss decreased (0.217195 --> 0.215846).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.083611011505127
Epoch: 12, Steps: 65 | Train Loss: 0.4231396 Vali Loss: 0.2159898 Test Loss: 0.2973983
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.9874541759490967
Epoch: 13, Steps: 65 | Train Loss: 0.4217101 Vali Loss: 0.2160043 Test Loss: 0.2967800
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.8986537456512451
Epoch: 14, Steps: 65 | Train Loss: 0.4205589 Vali Loss: 0.2142691 Test Loss: 0.2962147
Validation loss decreased (0.215846 --> 0.214269).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.652632236480713
Epoch: 15, Steps: 65 | Train Loss: 0.4189745 Vali Loss: 0.2145500 Test Loss: 0.2956581
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.012510061264038
Epoch: 16, Steps: 65 | Train Loss: 0.4187168 Vali Loss: 0.2140218 Test Loss: 0.2951390
Validation loss decreased (0.214269 --> 0.214022).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.6564624309539795
Epoch: 17, Steps: 65 | Train Loss: 0.4183205 Vali Loss: 0.2134367 Test Loss: 0.2948370
Validation loss decreased (0.214022 --> 0.213437).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.5714051723480225
Epoch: 18, Steps: 65 | Train Loss: 0.4167849 Vali Loss: 0.2125774 Test Loss: 0.2945526
Validation loss decreased (0.213437 --> 0.212577).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.630159854888916
Epoch: 19, Steps: 65 | Train Loss: 0.4178288 Vali Loss: 0.2141708 Test Loss: 0.2942403
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.7367658615112305
Epoch: 20, Steps: 65 | Train Loss: 0.4154172 Vali Loss: 0.2127772 Test Loss: 0.2939963
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.726649284362793
Epoch: 21, Steps: 65 | Train Loss: 0.4160017 Vali Loss: 0.2130553 Test Loss: 0.2936416
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.6327741146087646
Epoch: 22, Steps: 65 | Train Loss: 0.4146933 Vali Loss: 0.2118758 Test Loss: 0.2934598
Validation loss decreased (0.212577 --> 0.211876).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.8004016876220703
Epoch: 23, Steps: 65 | Train Loss: 0.4162954 Vali Loss: 0.2117035 Test Loss: 0.2932646
Validation loss decreased (0.211876 --> 0.211703).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.6413030624389648
Epoch: 24, Steps: 65 | Train Loss: 0.4144947 Vali Loss: 0.2129516 Test Loss: 0.2931082
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.2781176567077637
Epoch: 25, Steps: 65 | Train Loss: 0.4151870 Vali Loss: 0.2109841 Test Loss: 0.2928771
Validation loss decreased (0.211703 --> 0.210984).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.6985340118408203
Epoch: 26, Steps: 65 | Train Loss: 0.4151063 Vali Loss: 0.2127768 Test Loss: 0.2927594
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.5858325958251953
Epoch: 27, Steps: 65 | Train Loss: 0.4151386 Vali Loss: 0.2114956 Test Loss: 0.2925376
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.7255268096923828
Epoch: 28, Steps: 65 | Train Loss: 0.4139733 Vali Loss: 0.2112460 Test Loss: 0.2924243
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.671767234802246
Epoch: 29, Steps: 65 | Train Loss: 0.4147577 Vali Loss: 0.2109264 Test Loss: 0.2923306
Validation loss decreased (0.210984 --> 0.210926).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.7482936382293701
Epoch: 30, Steps: 65 | Train Loss: 0.4144686 Vali Loss: 0.2120331 Test Loss: 0.2922385
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.6822938919067383
Epoch: 31, Steps: 65 | Train Loss: 0.4123916 Vali Loss: 0.2124959 Test Loss: 0.2920989
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.979768991470337
Epoch: 32, Steps: 65 | Train Loss: 0.4138484 Vali Loss: 0.2121146 Test Loss: 0.2919910
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.6935510635375977
Epoch: 33, Steps: 65 | Train Loss: 0.4123064 Vali Loss: 0.2115198 Test Loss: 0.2919366
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.7784359455108643
Epoch: 34, Steps: 65 | Train Loss: 0.4129060 Vali Loss: 0.2125901 Test Loss: 0.2918636
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.1587741374969482
Epoch: 35, Steps: 65 | Train Loss: 0.4138916 Vali Loss: 0.2108623 Test Loss: 0.2917599
Validation loss decreased (0.210926 --> 0.210862).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.9517204761505127
Epoch: 36, Steps: 65 | Train Loss: 0.4117453 Vali Loss: 0.2120233 Test Loss: 0.2917107
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.814692735671997
Epoch: 37, Steps: 65 | Train Loss: 0.4129048 Vali Loss: 0.2124974 Test Loss: 0.2915913
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.1106555461883545
Epoch: 38, Steps: 65 | Train Loss: 0.4125093 Vali Loss: 0.2112332 Test Loss: 0.2915616
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.5779392719268799
Epoch: 39, Steps: 65 | Train Loss: 0.4107052 Vali Loss: 0.2120090 Test Loss: 0.2914988
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.0944559574127197
Epoch: 40, Steps: 65 | Train Loss: 0.4113528 Vali Loss: 0.2112370 Test Loss: 0.2914448
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.8212671279907227
Epoch: 41, Steps: 65 | Train Loss: 0.4119639 Vali Loss: 0.2105962 Test Loss: 0.2913710
Validation loss decreased (0.210862 --> 0.210596).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.8827269077301025
Epoch: 42, Steps: 65 | Train Loss: 0.4126397 Vali Loss: 0.2118604 Test Loss: 0.2913221
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.821850299835205
Epoch: 43, Steps: 65 | Train Loss: 0.4123696 Vali Loss: 0.2112143 Test Loss: 0.2912804
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.912423849105835
Epoch: 44, Steps: 65 | Train Loss: 0.4114586 Vali Loss: 0.2115417 Test Loss: 0.2912186
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.9459843635559082
Epoch: 45, Steps: 65 | Train Loss: 0.4109543 Vali Loss: 0.2103629 Test Loss: 0.2911812
Validation loss decreased (0.210596 --> 0.210363).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.8498249053955078
Epoch: 46, Steps: 65 | Train Loss: 0.4110229 Vali Loss: 0.2108739 Test Loss: 0.2911600
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.1629436016082764
Epoch: 47, Steps: 65 | Train Loss: 0.4119966 Vali Loss: 0.2105312 Test Loss: 0.2911284
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.6356258392333984
Epoch: 48, Steps: 65 | Train Loss: 0.4123542 Vali Loss: 0.2107421 Test Loss: 0.2911232
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.9725189208984375
Epoch: 49, Steps: 65 | Train Loss: 0.4119131 Vali Loss: 0.2116421 Test Loss: 0.2910741
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.431643486022949
Epoch: 50, Steps: 65 | Train Loss: 0.4119114 Vali Loss: 0.2109763 Test Loss: 0.2910397
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.5509657859802246
Epoch: 51, Steps: 65 | Train Loss: 0.4103543 Vali Loss: 0.2111114 Test Loss: 0.2910083
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.642867088317871
Epoch: 52, Steps: 65 | Train Loss: 0.4087620 Vali Loss: 0.2113720 Test Loss: 0.2909887
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.8913958072662354
Epoch: 53, Steps: 65 | Train Loss: 0.4118050 Vali Loss: 0.2105557 Test Loss: 0.2909611
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.5752248764038086
Epoch: 54, Steps: 65 | Train Loss: 0.4091644 Vali Loss: 0.2099252 Test Loss: 0.2909208
Validation loss decreased (0.210363 --> 0.209925).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.5642344951629639
Epoch: 55, Steps: 65 | Train Loss: 0.4117596 Vali Loss: 0.2111562 Test Loss: 0.2909056
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.6099905967712402
Epoch: 56, Steps: 65 | Train Loss: 0.4103379 Vali Loss: 0.2098369 Test Loss: 0.2908695
Validation loss decreased (0.209925 --> 0.209837).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.9120619297027588
Epoch: 57, Steps: 65 | Train Loss: 0.4110731 Vali Loss: 0.2110942 Test Loss: 0.2908609
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.6206398010253906
Epoch: 58, Steps: 65 | Train Loss: 0.4118180 Vali Loss: 0.2103851 Test Loss: 0.2908403
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.5020570755004883
Epoch: 59, Steps: 65 | Train Loss: 0.4114157 Vali Loss: 0.2109808 Test Loss: 0.2908320
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.6383411884307861
Epoch: 60, Steps: 65 | Train Loss: 0.4095292 Vali Loss: 0.2104886 Test Loss: 0.2908148
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.0207130908966064
Epoch: 61, Steps: 65 | Train Loss: 0.4101537 Vali Loss: 0.2111191 Test Loss: 0.2907915
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.5431439876556396
Epoch: 62, Steps: 65 | Train Loss: 0.4114387 Vali Loss: 0.2109253 Test Loss: 0.2907858
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.6938362121582031
Epoch: 63, Steps: 65 | Train Loss: 0.4114211 Vali Loss: 0.2103198 Test Loss: 0.2907711
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.0761899948120117
Epoch: 64, Steps: 65 | Train Loss: 0.4106438 Vali Loss: 0.2102391 Test Loss: 0.2907588
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.9980652332305908
Epoch: 65, Steps: 65 | Train Loss: 0.4106678 Vali Loss: 0.2109237 Test Loss: 0.2907407
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.8670110702514648
Epoch: 66, Steps: 65 | Train Loss: 0.4106586 Vali Loss: 0.2111559 Test Loss: 0.2907280
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.8728036880493164
Epoch: 67, Steps: 65 | Train Loss: 0.4097021 Vali Loss: 0.2108441 Test Loss: 0.2907151
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.6816816329956055
Epoch: 68, Steps: 65 | Train Loss: 0.4115878 Vali Loss: 0.2099910 Test Loss: 0.2907055
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.223137140274048
Epoch: 69, Steps: 65 | Train Loss: 0.4104100 Vali Loss: 0.2107710 Test Loss: 0.2906949
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.742500066757202
Epoch: 70, Steps: 65 | Train Loss: 0.4112229 Vali Loss: 0.2108387 Test Loss: 0.2906843
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.2287909984588623
Epoch: 71, Steps: 65 | Train Loss: 0.4104728 Vali Loss: 0.2104649 Test Loss: 0.2906738
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.1409482955932617
Epoch: 72, Steps: 65 | Train Loss: 0.4108799 Vali Loss: 0.2097354 Test Loss: 0.2906646
Validation loss decreased (0.209837 --> 0.209735).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.6253178119659424
Epoch: 73, Steps: 65 | Train Loss: 0.4110748 Vali Loss: 0.2113070 Test Loss: 0.2906576
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.812807559967041
Epoch: 74, Steps: 65 | Train Loss: 0.4099136 Vali Loss: 0.2101610 Test Loss: 0.2906506
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.4759995937347412
Epoch: 75, Steps: 65 | Train Loss: 0.4111826 Vali Loss: 0.2106785 Test Loss: 0.2906408
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.0257794857025146
Epoch: 76, Steps: 65 | Train Loss: 0.4104723 Vali Loss: 0.2102376 Test Loss: 0.2906323
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.7691938877105713
Epoch: 77, Steps: 65 | Train Loss: 0.4110855 Vali Loss: 0.2110092 Test Loss: 0.2906254
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.7347323894500732
Epoch: 78, Steps: 65 | Train Loss: 0.4090118 Vali Loss: 0.2105646 Test Loss: 0.2906186
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.6968817710876465
Epoch: 79, Steps: 65 | Train Loss: 0.4095933 Vali Loss: 0.2109580 Test Loss: 0.2906132
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.601884126663208
Epoch: 80, Steps: 65 | Train Loss: 0.4112640 Vali Loss: 0.2111497 Test Loss: 0.2906110
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.7863705158233643
Epoch: 81, Steps: 65 | Train Loss: 0.4108471 Vali Loss: 0.2093364 Test Loss: 0.2906040
Validation loss decreased (0.209735 --> 0.209336).  Saving model ...
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.794764518737793
Epoch: 82, Steps: 65 | Train Loss: 0.4106749 Vali Loss: 0.2098432 Test Loss: 0.2905990
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.826716423034668
Epoch: 83, Steps: 65 | Train Loss: 0.4108400 Vali Loss: 0.2112816 Test Loss: 0.2905945
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.596691608428955
Epoch: 84, Steps: 65 | Train Loss: 0.4111229 Vali Loss: 0.2117173 Test Loss: 0.2905874
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.6051697731018066
Epoch: 85, Steps: 65 | Train Loss: 0.4109862 Vali Loss: 0.2099899 Test Loss: 0.2905854
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.4938981533050537
Epoch: 86, Steps: 65 | Train Loss: 0.4108178 Vali Loss: 0.2115419 Test Loss: 0.2905804
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 2.1530861854553223
Epoch: 87, Steps: 65 | Train Loss: 0.4097556 Vali Loss: 0.2109065 Test Loss: 0.2905752
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.964477777481079
Epoch: 88, Steps: 65 | Train Loss: 0.4078320 Vali Loss: 0.2097224 Test Loss: 0.2905740
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.810185194015503
Epoch: 89, Steps: 65 | Train Loss: 0.4092502 Vali Loss: 0.2110962 Test Loss: 0.2905674
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.7611596584320068
Epoch: 90, Steps: 65 | Train Loss: 0.4112713 Vali Loss: 0.2101392 Test Loss: 0.2905650
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.5994923114776611
Epoch: 91, Steps: 65 | Train Loss: 0.4109440 Vali Loss: 0.2104825 Test Loss: 0.2905581
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 2.1959962844848633
Epoch: 92, Steps: 65 | Train Loss: 0.4107709 Vali Loss: 0.2109072 Test Loss: 0.2905551
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.71964430809021
Epoch: 93, Steps: 65 | Train Loss: 0.4089763 Vali Loss: 0.2110243 Test Loss: 0.2905528
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.7052240371704102
Epoch: 94, Steps: 65 | Train Loss: 0.4107179 Vali Loss: 0.2108173 Test Loss: 0.2905497
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.7305924892425537
Epoch: 95, Steps: 65 | Train Loss: 0.4106077 Vali Loss: 0.2106627 Test Loss: 0.2905483
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 2.0061540603637695
Epoch: 96, Steps: 65 | Train Loss: 0.4100118 Vali Loss: 0.2099581 Test Loss: 0.2905457
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.8548269271850586
Epoch: 97, Steps: 65 | Train Loss: 0.4105698 Vali Loss: 0.2107278 Test Loss: 0.2905424
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 2.1079447269439697
Epoch: 98, Steps: 65 | Train Loss: 0.4101902 Vali Loss: 0.2102875 Test Loss: 0.2905414
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.7871415615081787
Epoch: 99, Steps: 65 | Train Loss: 0.4100346 Vali Loss: 0.2106686 Test Loss: 0.2905398
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.7562437057495117
Epoch: 100, Steps: 65 | Train Loss: 0.4082108 Vali Loss: 0.2104156 Test Loss: 0.2905363
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.1160680107021042e-06
>>>>>>>testing : ETTh2_180_96_FITS_ETTh2_ftM_sl180_ll48_pl96_H2_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.290314257144928, mae:0.34251490235328674, rse:0.4342256784439087, corr:[0.27293858 0.2762718  0.27681547 0.27516377 0.27320984 0.27205062
 0.27149862 0.2708338  0.2697662  0.26816404 0.26649433 0.26489657
 0.26369345 0.26263976 0.26163957 0.26073033 0.25995696 0.25925532
 0.25849843 0.25757468 0.2563368  0.2547492  0.25288835 0.2508634
 0.24865662 0.24660188 0.24453826 0.24257036 0.24070008 0.2391745
 0.23785016 0.23639421 0.23455705 0.23250516 0.23056337 0.2288689
 0.22759628 0.22645624 0.22560032 0.22456783 0.22359979 0.22267507
 0.221929   0.22126712 0.22065091 0.2196079  0.21778774 0.21533468
 0.21220706 0.20948441 0.2074186  0.20603818 0.20473354 0.20326984
 0.20124178 0.19889553 0.1969362  0.1955074  0.19473815 0.19420013
 0.19383754 0.19292235 0.19206466 0.19114986 0.19063398 0.19062243
 0.19074392 0.19041258 0.189566   0.18835478 0.18678318 0.18548414
 0.18415281 0.18309711 0.18186586 0.18036455 0.17880374 0.17793758
 0.17758547 0.17743126 0.17766272 0.17768918 0.17742504 0.176953
 0.17694409 0.17728786 0.17824347 0.17891905 0.17896771 0.17815456
 0.17715955 0.17662331 0.17782286 0.18030371 0.18193567 0.18134725]
