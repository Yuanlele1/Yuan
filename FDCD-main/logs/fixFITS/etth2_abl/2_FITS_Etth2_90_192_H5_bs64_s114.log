Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=30, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_90_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_90_192_FITS_ETTh2_ftM_sl90_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8359
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=30, out_features=94, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2526720.0
params:  2914.0
Trainable parameters:  2914
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 5.4717817306518555
Epoch: 1, Steps: 65 | Train Loss: 0.6353314 Vali Loss: 0.3804915 Test Loss: 0.5346480
Validation loss decreased (inf --> 0.380492).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.18186616897583
Epoch: 2, Steps: 65 | Train Loss: 0.5430622 Vali Loss: 0.3487039 Test Loss: 0.4901252
Validation loss decreased (0.380492 --> 0.348704).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 5.806311130523682
Epoch: 3, Steps: 65 | Train Loss: 0.4895619 Vali Loss: 0.3294842 Test Loss: 0.4634105
Validation loss decreased (0.348704 --> 0.329484).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.677701950073242
Epoch: 4, Steps: 65 | Train Loss: 0.4549636 Vali Loss: 0.3169125 Test Loss: 0.4460922
Validation loss decreased (0.329484 --> 0.316913).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.4366679191589355
Epoch: 5, Steps: 65 | Train Loss: 0.4355345 Vali Loss: 0.3083566 Test Loss: 0.4346545
Validation loss decreased (0.316913 --> 0.308357).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.574446678161621
Epoch: 6, Steps: 65 | Train Loss: 0.4221778 Vali Loss: 0.3023441 Test Loss: 0.4267578
Validation loss decreased (0.308357 --> 0.302344).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.458907127380371
Epoch: 7, Steps: 65 | Train Loss: 0.4116027 Vali Loss: 0.2979718 Test Loss: 0.4209808
Validation loss decreased (0.302344 --> 0.297972).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.4233646392822266
Epoch: 8, Steps: 65 | Train Loss: 0.4038339 Vali Loss: 0.2947168 Test Loss: 0.4169172
Validation loss decreased (0.297972 --> 0.294717).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.327781915664673
Epoch: 9, Steps: 65 | Train Loss: 0.3992833 Vali Loss: 0.2921200 Test Loss: 0.4136774
Validation loss decreased (0.294717 --> 0.292120).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.432420492172241
Epoch: 10, Steps: 65 | Train Loss: 0.3944883 Vali Loss: 0.2902186 Test Loss: 0.4113515
Validation loss decreased (0.292120 --> 0.290219).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 4.096668481826782
Epoch: 11, Steps: 65 | Train Loss: 0.3927113 Vali Loss: 0.2886351 Test Loss: 0.4095056
Validation loss decreased (0.290219 --> 0.288635).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.0422866344451904
Epoch: 12, Steps: 65 | Train Loss: 0.3902075 Vali Loss: 0.2873288 Test Loss: 0.4079626
Validation loss decreased (0.288635 --> 0.287329).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.7686164379119873
Epoch: 13, Steps: 65 | Train Loss: 0.3882406 Vali Loss: 0.2862391 Test Loss: 0.4067626
Validation loss decreased (0.287329 --> 0.286239).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.0805225372314453
Epoch: 14, Steps: 65 | Train Loss: 0.3869049 Vali Loss: 0.2853266 Test Loss: 0.4057049
Validation loss decreased (0.286239 --> 0.285327).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.5117785930633545
Epoch: 15, Steps: 65 | Train Loss: 0.3846423 Vali Loss: 0.2845779 Test Loss: 0.4049378
Validation loss decreased (0.285327 --> 0.284578).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.8254547119140625
Epoch: 16, Steps: 65 | Train Loss: 0.3836193 Vali Loss: 0.2837461 Test Loss: 0.4042406
Validation loss decreased (0.284578 --> 0.283746).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.5768685340881348
Epoch: 17, Steps: 65 | Train Loss: 0.3838881 Vali Loss: 0.2832573 Test Loss: 0.4036097
Validation loss decreased (0.283746 --> 0.283257).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.560575008392334
Epoch: 18, Steps: 65 | Train Loss: 0.3816293 Vali Loss: 0.2826566 Test Loss: 0.4030586
Validation loss decreased (0.283257 --> 0.282657).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.6974575519561768
Epoch: 19, Steps: 65 | Train Loss: 0.3812630 Vali Loss: 0.2823056 Test Loss: 0.4025986
Validation loss decreased (0.282657 --> 0.282306).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.491023540496826
Epoch: 20, Steps: 65 | Train Loss: 0.3810088 Vali Loss: 0.2819461 Test Loss: 0.4022255
Validation loss decreased (0.282306 --> 0.281946).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.602607250213623
Epoch: 21, Steps: 65 | Train Loss: 0.3806776 Vali Loss: 0.2815978 Test Loss: 0.4018644
Validation loss decreased (0.281946 --> 0.281598).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.688164472579956
Epoch: 22, Steps: 65 | Train Loss: 0.3800989 Vali Loss: 0.2812563 Test Loss: 0.4015558
Validation loss decreased (0.281598 --> 0.281256).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 4.0003111362457275
Epoch: 23, Steps: 65 | Train Loss: 0.3783335 Vali Loss: 0.2808750 Test Loss: 0.4012537
Validation loss decreased (0.281256 --> 0.280875).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 4.248059988021851
Epoch: 24, Steps: 65 | Train Loss: 0.3788874 Vali Loss: 0.2806825 Test Loss: 0.4010380
Validation loss decreased (0.280875 --> 0.280682).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 3.9021127223968506
Epoch: 25, Steps: 65 | Train Loss: 0.3781202 Vali Loss: 0.2804055 Test Loss: 0.4007716
Validation loss decreased (0.280682 --> 0.280405).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.019451141357422
Epoch: 26, Steps: 65 | Train Loss: 0.3782747 Vali Loss: 0.2800447 Test Loss: 0.4005722
Validation loss decreased (0.280405 --> 0.280045).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.924550771713257
Epoch: 27, Steps: 65 | Train Loss: 0.3774869 Vali Loss: 0.2799835 Test Loss: 0.4004087
Validation loss decreased (0.280045 --> 0.279983).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.328512191772461
Epoch: 28, Steps: 65 | Train Loss: 0.3756218 Vali Loss: 0.2797993 Test Loss: 0.4002242
Validation loss decreased (0.279983 --> 0.279799).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 4.411656141281128
Epoch: 29, Steps: 65 | Train Loss: 0.3774953 Vali Loss: 0.2795836 Test Loss: 0.4000732
Validation loss decreased (0.279799 --> 0.279584).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.5081100463867188
Epoch: 30, Steps: 65 | Train Loss: 0.3765095 Vali Loss: 0.2794655 Test Loss: 0.3999292
Validation loss decreased (0.279584 --> 0.279465).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.5691049098968506
Epoch: 31, Steps: 65 | Train Loss: 0.3775903 Vali Loss: 0.2793337 Test Loss: 0.3998010
Validation loss decreased (0.279465 --> 0.279334).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.404653310775757
Epoch: 32, Steps: 65 | Train Loss: 0.3769146 Vali Loss: 0.2791738 Test Loss: 0.3996875
Validation loss decreased (0.279334 --> 0.279174).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.1231510639190674
Epoch: 33, Steps: 65 | Train Loss: 0.3766770 Vali Loss: 0.2790384 Test Loss: 0.3995852
Validation loss decreased (0.279174 --> 0.279038).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.989243268966675
Epoch: 34, Steps: 65 | Train Loss: 0.3770341 Vali Loss: 0.2789668 Test Loss: 0.3994884
Validation loss decreased (0.279038 --> 0.278967).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.0022382736206055
Epoch: 35, Steps: 65 | Train Loss: 0.3767139 Vali Loss: 0.2788010 Test Loss: 0.3994088
Validation loss decreased (0.278967 --> 0.278801).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.6388370990753174
Epoch: 36, Steps: 65 | Train Loss: 0.3767843 Vali Loss: 0.2786818 Test Loss: 0.3992991
Validation loss decreased (0.278801 --> 0.278682).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 3.3683648109436035
Epoch: 37, Steps: 65 | Train Loss: 0.3753777 Vali Loss: 0.2785635 Test Loss: 0.3992328
Validation loss decreased (0.278682 --> 0.278563).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 3.0408217906951904
Epoch: 38, Steps: 65 | Train Loss: 0.3760753 Vali Loss: 0.2785287 Test Loss: 0.3991784
Validation loss decreased (0.278563 --> 0.278529).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 4.192375421524048
Epoch: 39, Steps: 65 | Train Loss: 0.3753575 Vali Loss: 0.2784092 Test Loss: 0.3991185
Validation loss decreased (0.278529 --> 0.278409).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 4.458611249923706
Epoch: 40, Steps: 65 | Train Loss: 0.3760002 Vali Loss: 0.2784106 Test Loss: 0.3990693
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 4.138408899307251
Epoch: 41, Steps: 65 | Train Loss: 0.3755164 Vali Loss: 0.2782573 Test Loss: 0.3990041
Validation loss decreased (0.278409 --> 0.278257).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 3.3745832443237305
Epoch: 42, Steps: 65 | Train Loss: 0.3756788 Vali Loss: 0.2782182 Test Loss: 0.3989536
Validation loss decreased (0.278257 --> 0.278218).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 3.095750093460083
Epoch: 43, Steps: 65 | Train Loss: 0.3755228 Vali Loss: 0.2781663 Test Loss: 0.3988893
Validation loss decreased (0.278218 --> 0.278166).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 4.292989253997803
Epoch: 44, Steps: 65 | Train Loss: 0.3734441 Vali Loss: 0.2780495 Test Loss: 0.3988487
Validation loss decreased (0.278166 --> 0.278049).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 2.352404832839966
Epoch: 45, Steps: 65 | Train Loss: 0.3756119 Vali Loss: 0.2779281 Test Loss: 0.3988038
Validation loss decreased (0.278049 --> 0.277928).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.4876441955566406
Epoch: 46, Steps: 65 | Train Loss: 0.3739799 Vali Loss: 0.2776250 Test Loss: 0.3987746
Validation loss decreased (0.277928 --> 0.277625).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.9959616661071777
Epoch: 47, Steps: 65 | Train Loss: 0.3758624 Vali Loss: 0.2777901 Test Loss: 0.3987288
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.2058465480804443
Epoch: 48, Steps: 65 | Train Loss: 0.3743305 Vali Loss: 0.2778728 Test Loss: 0.3986963
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.7772440910339355
Epoch: 49, Steps: 65 | Train Loss: 0.3747287 Vali Loss: 0.2778164 Test Loss: 0.3986650
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.320972442626953
Epoch: 50, Steps: 65 | Train Loss: 0.3748948 Vali Loss: 0.2776997 Test Loss: 0.3986431
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.069673776626587
Epoch: 51, Steps: 65 | Train Loss: 0.3740360 Vali Loss: 0.2777705 Test Loss: 0.3986081
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 3.15919828414917
Epoch: 52, Steps: 65 | Train Loss: 0.3744772 Vali Loss: 0.2777000 Test Loss: 0.3985890
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.707780361175537
Epoch: 53, Steps: 65 | Train Loss: 0.3751061 Vali Loss: 0.2777111 Test Loss: 0.3985569
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 3.421687126159668
Epoch: 54, Steps: 65 | Train Loss: 0.3744647 Vali Loss: 0.2772942 Test Loss: 0.3985362
Validation loss decreased (0.277625 --> 0.277294).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 3.1111648082733154
Epoch: 55, Steps: 65 | Train Loss: 0.3747567 Vali Loss: 0.2774811 Test Loss: 0.3985157
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.242173910140991
Epoch: 56, Steps: 65 | Train Loss: 0.3736559 Vali Loss: 0.2775159 Test Loss: 0.3984930
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.8676326274871826
Epoch: 57, Steps: 65 | Train Loss: 0.3747721 Vali Loss: 0.2775534 Test Loss: 0.3984626
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.6938369274139404
Epoch: 58, Steps: 65 | Train Loss: 0.3751556 Vali Loss: 0.2775176 Test Loss: 0.3984518
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.973313331604004
Epoch: 59, Steps: 65 | Train Loss: 0.3738231 Vali Loss: 0.2773982 Test Loss: 0.3984390
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.143714427947998
Epoch: 60, Steps: 65 | Train Loss: 0.3743769 Vali Loss: 0.2774189 Test Loss: 0.3984191
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.6709492206573486
Epoch: 61, Steps: 65 | Train Loss: 0.3741855 Vali Loss: 0.2773790 Test Loss: 0.3983964
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 3.2408573627471924
Epoch: 62, Steps: 65 | Train Loss: 0.3733929 Vali Loss: 0.2774474 Test Loss: 0.3983797
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 3.7426419258117676
Epoch: 63, Steps: 65 | Train Loss: 0.3746026 Vali Loss: 0.2771670 Test Loss: 0.3983749
Validation loss decreased (0.277294 --> 0.277167).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 3.092376470565796
Epoch: 64, Steps: 65 | Train Loss: 0.3749456 Vali Loss: 0.2772624 Test Loss: 0.3983544
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.7922751903533936
Epoch: 65, Steps: 65 | Train Loss: 0.3742246 Vali Loss: 0.2770023 Test Loss: 0.3983459
Validation loss decreased (0.277167 --> 0.277002).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 3.4824891090393066
Epoch: 66, Steps: 65 | Train Loss: 0.3741519 Vali Loss: 0.2773128 Test Loss: 0.3983352
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.34101939201355
Epoch: 67, Steps: 65 | Train Loss: 0.3739558 Vali Loss: 0.2772943 Test Loss: 0.3983215
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 3.3144311904907227
Epoch: 68, Steps: 65 | Train Loss: 0.3730880 Vali Loss: 0.2772563 Test Loss: 0.3983150
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.4209232330322266
Epoch: 69, Steps: 65 | Train Loss: 0.3735983 Vali Loss: 0.2769440 Test Loss: 0.3983018
Validation loss decreased (0.277002 --> 0.276944).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.686645746231079
Epoch: 70, Steps: 65 | Train Loss: 0.3747440 Vali Loss: 0.2772056 Test Loss: 0.3982931
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.392070770263672
Epoch: 71, Steps: 65 | Train Loss: 0.3726643 Vali Loss: 0.2772715 Test Loss: 0.3982820
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.2222166061401367
Epoch: 72, Steps: 65 | Train Loss: 0.3739584 Vali Loss: 0.2772018 Test Loss: 0.3982727
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 3.0647571086883545
Epoch: 73, Steps: 65 | Train Loss: 0.3740971 Vali Loss: 0.2771776 Test Loss: 0.3982686
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.222874879837036
Epoch: 74, Steps: 65 | Train Loss: 0.3747257 Vali Loss: 0.2769052 Test Loss: 0.3982625
Validation loss decreased (0.276944 --> 0.276905).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 3.3962316513061523
Epoch: 75, Steps: 65 | Train Loss: 0.3742413 Vali Loss: 0.2772408 Test Loss: 0.3982516
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 3.3169732093811035
Epoch: 76, Steps: 65 | Train Loss: 0.3744806 Vali Loss: 0.2772346 Test Loss: 0.3982454
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.198756217956543
Epoch: 77, Steps: 65 | Train Loss: 0.3741356 Vali Loss: 0.2771995 Test Loss: 0.3982379
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.5063905715942383
Epoch: 78, Steps: 65 | Train Loss: 0.3746192 Vali Loss: 0.2771525 Test Loss: 0.3982341
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 3.426194429397583
Epoch: 79, Steps: 65 | Train Loss: 0.3737706 Vali Loss: 0.2771611 Test Loss: 0.3982271
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.072225570678711
Epoch: 80, Steps: 65 | Train Loss: 0.3740166 Vali Loss: 0.2771488 Test Loss: 0.3982209
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.978745698928833
Epoch: 81, Steps: 65 | Train Loss: 0.3739718 Vali Loss: 0.2771196 Test Loss: 0.3982135
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 3.5487875938415527
Epoch: 82, Steps: 65 | Train Loss: 0.3741450 Vali Loss: 0.2771693 Test Loss: 0.3982113
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.517202854156494
Epoch: 83, Steps: 65 | Train Loss: 0.3740325 Vali Loss: 0.2770731 Test Loss: 0.3982045
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.336962938308716
Epoch: 84, Steps: 65 | Train Loss: 0.3743822 Vali Loss: 0.2770807 Test Loss: 0.3981991
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.648099422454834
Epoch: 85, Steps: 65 | Train Loss: 0.3743684 Vali Loss: 0.2770875 Test Loss: 0.3981963
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 3.712106704711914
Epoch: 86, Steps: 65 | Train Loss: 0.3737559 Vali Loss: 0.2768101 Test Loss: 0.3981910
Validation loss decreased (0.276905 --> 0.276810).  Saving model ...
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 2.61269211769104
Epoch: 87, Steps: 65 | Train Loss: 0.3732993 Vali Loss: 0.2770593 Test Loss: 0.3981870
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 3.3599696159362793
Epoch: 88, Steps: 65 | Train Loss: 0.3737871 Vali Loss: 0.2770938 Test Loss: 0.3981837
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.530963897705078
Epoch: 89, Steps: 65 | Train Loss: 0.3739048 Vali Loss: 0.2770914 Test Loss: 0.3981806
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 3.640921115875244
Epoch: 90, Steps: 65 | Train Loss: 0.3734961 Vali Loss: 0.2769385 Test Loss: 0.3981754
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.3577117919921875
Epoch: 91, Steps: 65 | Train Loss: 0.3736017 Vali Loss: 0.2770707 Test Loss: 0.3981739
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 2.641164541244507
Epoch: 92, Steps: 65 | Train Loss: 0.3739954 Vali Loss: 0.2770594 Test Loss: 0.3981695
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 2.422299385070801
Epoch: 93, Steps: 65 | Train Loss: 0.3734390 Vali Loss: 0.2770764 Test Loss: 0.3981667
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 2.3573031425476074
Epoch: 94, Steps: 65 | Train Loss: 0.3736782 Vali Loss: 0.2771013 Test Loss: 0.3981640
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 3.5621044635772705
Epoch: 95, Steps: 65 | Train Loss: 0.3733092 Vali Loss: 0.2769372 Test Loss: 0.3981618
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 2.3994662761688232
Epoch: 96, Steps: 65 | Train Loss: 0.3730394 Vali Loss: 0.2770738 Test Loss: 0.3981586
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 2.836982488632202
Epoch: 97, Steps: 65 | Train Loss: 0.3737473 Vali Loss: 0.2770347 Test Loss: 0.3981563
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 3.2168796062469482
Epoch: 98, Steps: 65 | Train Loss: 0.3740750 Vali Loss: 0.2770450 Test Loss: 0.3981541
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 2.1726937294006348
Epoch: 99, Steps: 65 | Train Loss: 0.3745089 Vali Loss: 0.2767058 Test Loss: 0.3981520
Validation loss decreased (0.276810 --> 0.276706).  Saving model ...
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 3.478349447250366
Epoch: 100, Steps: 65 | Train Loss: 0.3736058 Vali Loss: 0.2770529 Test Loss: 0.3981501
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8359
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=30, out_features=94, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2526720.0
params:  2914.0
Trainable parameters:  2914
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.9390902519226074
Epoch: 1, Steps: 65 | Train Loss: 0.5393677 Vali Loss: 0.2761399 Test Loss: 0.3973167
Validation loss decreased (inf --> 0.276140).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.976638078689575
Epoch: 2, Steps: 65 | Train Loss: 0.5401531 Vali Loss: 0.2756023 Test Loss: 0.3969361
Validation loss decreased (0.276140 --> 0.275602).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.051727533340454
Epoch: 3, Steps: 65 | Train Loss: 0.5387543 Vali Loss: 0.2748511 Test Loss: 0.3967815
Validation loss decreased (0.275602 --> 0.274851).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.7495644092559814
Epoch: 4, Steps: 65 | Train Loss: 0.5391973 Vali Loss: 0.2748042 Test Loss: 0.3965555
Validation loss decreased (0.274851 --> 0.274804).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.017040252685547
Epoch: 5, Steps: 65 | Train Loss: 0.5382267 Vali Loss: 0.2746401 Test Loss: 0.3965511
Validation loss decreased (0.274804 --> 0.274640).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.2665772438049316
Epoch: 6, Steps: 65 | Train Loss: 0.5371549 Vali Loss: 0.2745544 Test Loss: 0.3965575
Validation loss decreased (0.274640 --> 0.274554).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.9805872440338135
Epoch: 7, Steps: 65 | Train Loss: 0.5355705 Vali Loss: 0.2743209 Test Loss: 0.3964809
Validation loss decreased (0.274554 --> 0.274321).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.781468391418457
Epoch: 8, Steps: 65 | Train Loss: 0.5371370 Vali Loss: 0.2741563 Test Loss: 0.3965052
Validation loss decreased (0.274321 --> 0.274156).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.892575979232788
Epoch: 9, Steps: 65 | Train Loss: 0.5363105 Vali Loss: 0.2740828 Test Loss: 0.3965377
Validation loss decreased (0.274156 --> 0.274083).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.2499475479125977
Epoch: 10, Steps: 65 | Train Loss: 0.5367388 Vali Loss: 0.2739290 Test Loss: 0.3965153
Validation loss decreased (0.274083 --> 0.273929).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.9576284885406494
Epoch: 11, Steps: 65 | Train Loss: 0.5363886 Vali Loss: 0.2739446 Test Loss: 0.3966252
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.0314254760742188
Epoch: 12, Steps: 65 | Train Loss: 0.5374935 Vali Loss: 0.2738136 Test Loss: 0.3966238
Validation loss decreased (0.273929 --> 0.273814).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.8277268409729004
Epoch: 13, Steps: 65 | Train Loss: 0.5365190 Vali Loss: 0.2736612 Test Loss: 0.3965792
Validation loss decreased (0.273814 --> 0.273661).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.051032781600952
Epoch: 14, Steps: 65 | Train Loss: 0.5360589 Vali Loss: 0.2732664 Test Loss: 0.3966019
Validation loss decreased (0.273661 --> 0.273266).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.9867115020751953
Epoch: 15, Steps: 65 | Train Loss: 0.5372518 Vali Loss: 0.2733294 Test Loss: 0.3966289
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.5886070728302
Epoch: 16, Steps: 65 | Train Loss: 0.5351940 Vali Loss: 0.2735701 Test Loss: 0.3966997
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.032931089401245
Epoch: 17, Steps: 65 | Train Loss: 0.5355927 Vali Loss: 0.2733830 Test Loss: 0.3966881
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.1594486236572266
Epoch: 18, Steps: 65 | Train Loss: 0.5360508 Vali Loss: 0.2730634 Test Loss: 0.3967052
Validation loss decreased (0.273266 --> 0.273063).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.4233622550964355
Epoch: 19, Steps: 65 | Train Loss: 0.5346418 Vali Loss: 0.2733425 Test Loss: 0.3967542
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.376116991043091
Epoch: 20, Steps: 65 | Train Loss: 0.5348789 Vali Loss: 0.2733091 Test Loss: 0.3967435
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.0967156887054443
Epoch: 21, Steps: 65 | Train Loss: 0.5349492 Vali Loss: 0.2729164 Test Loss: 0.3967483
Validation loss decreased (0.273063 --> 0.272916).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 5.993192672729492
Epoch: 22, Steps: 65 | Train Loss: 0.5346359 Vali Loss: 0.2732108 Test Loss: 0.3967482
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.4255309104919434
Epoch: 23, Steps: 65 | Train Loss: 0.5348736 Vali Loss: 0.2731854 Test Loss: 0.3967530
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.7252743244171143
Epoch: 24, Steps: 65 | Train Loss: 0.5347186 Vali Loss: 0.2731231 Test Loss: 0.3967492
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.1631364822387695
Epoch: 25, Steps: 65 | Train Loss: 0.5360365 Vali Loss: 0.2728353 Test Loss: 0.3967967
Validation loss decreased (0.272916 --> 0.272835).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.24640154838562
Epoch: 26, Steps: 65 | Train Loss: 0.5348662 Vali Loss: 0.2731064 Test Loss: 0.3968162
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.282419443130493
Epoch: 27, Steps: 65 | Train Loss: 0.5359430 Vali Loss: 0.2731284 Test Loss: 0.3967967
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.4453940391540527
Epoch: 28, Steps: 65 | Train Loss: 0.5355135 Vali Loss: 0.2730033 Test Loss: 0.3968413
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.8949806690216064
Epoch: 29, Steps: 65 | Train Loss: 0.5335381 Vali Loss: 0.2731315 Test Loss: 0.3968702
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.9844703674316406
Epoch: 30, Steps: 65 | Train Loss: 0.5344018 Vali Loss: 0.2730420 Test Loss: 0.3968396
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 3.582524061203003
Epoch: 31, Steps: 65 | Train Loss: 0.5354569 Vali Loss: 0.2730272 Test Loss: 0.3968489
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.3419368267059326
Epoch: 32, Steps: 65 | Train Loss: 0.5347571 Vali Loss: 0.2729464 Test Loss: 0.3968857
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.4297380447387695
Epoch: 33, Steps: 65 | Train Loss: 0.5342270 Vali Loss: 0.2730352 Test Loss: 0.3968539
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.9480199813842773
Epoch: 34, Steps: 65 | Train Loss: 0.5352749 Vali Loss: 0.2730505 Test Loss: 0.3968924
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 3.715482473373413
Epoch: 35, Steps: 65 | Train Loss: 0.5353483 Vali Loss: 0.2730306 Test Loss: 0.3969092
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.264169216156006
Epoch: 36, Steps: 65 | Train Loss: 0.5348568 Vali Loss: 0.2728729 Test Loss: 0.3969046
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.0629971027374268
Epoch: 37, Steps: 65 | Train Loss: 0.5340747 Vali Loss: 0.2729698 Test Loss: 0.3969048
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.2081735134124756
Epoch: 38, Steps: 65 | Train Loss: 0.5351413 Vali Loss: 0.2730001 Test Loss: 0.3969155
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 3.408198118209839
Epoch: 39, Steps: 65 | Train Loss: 0.5340305 Vali Loss: 0.2729746 Test Loss: 0.3969213
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.849731683731079
Epoch: 40, Steps: 65 | Train Loss: 0.5354482 Vali Loss: 0.2729558 Test Loss: 0.3969306
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 3.6625494956970215
Epoch: 41, Steps: 65 | Train Loss: 0.5344066 Vali Loss: 0.2726737 Test Loss: 0.3969499
Validation loss decreased (0.272835 --> 0.272674).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.863409996032715
Epoch: 42, Steps: 65 | Train Loss: 0.5354034 Vali Loss: 0.2729756 Test Loss: 0.3969356
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.3246471881866455
Epoch: 43, Steps: 65 | Train Loss: 0.5348902 Vali Loss: 0.2729275 Test Loss: 0.3969443
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.81427001953125
Epoch: 44, Steps: 65 | Train Loss: 0.5337280 Vali Loss: 0.2729547 Test Loss: 0.3969543
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 3.3345282077789307
Epoch: 45, Steps: 65 | Train Loss: 0.5351357 Vali Loss: 0.2728610 Test Loss: 0.3969809
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.821709394454956
Epoch: 46, Steps: 65 | Train Loss: 0.5337402 Vali Loss: 0.2729058 Test Loss: 0.3969723
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.874950647354126
Epoch: 47, Steps: 65 | Train Loss: 0.5356533 Vali Loss: 0.2728941 Test Loss: 0.3969721
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.982187032699585
Epoch: 48, Steps: 65 | Train Loss: 0.5354025 Vali Loss: 0.2728574 Test Loss: 0.3969707
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.566441535949707
Epoch: 49, Steps: 65 | Train Loss: 0.5335182 Vali Loss: 0.2729314 Test Loss: 0.3969862
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.8188562393188477
Epoch: 50, Steps: 65 | Train Loss: 0.5334546 Vali Loss: 0.2728858 Test Loss: 0.3969976
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.7445077896118164
Epoch: 51, Steps: 65 | Train Loss: 0.5340752 Vali Loss: 0.2729243 Test Loss: 0.3969943
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 3.381695508956909
Epoch: 52, Steps: 65 | Train Loss: 0.5351362 Vali Loss: 0.2728427 Test Loss: 0.3969966
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.1971640586853027
Epoch: 53, Steps: 65 | Train Loss: 0.5342625 Vali Loss: 0.2728769 Test Loss: 0.3969980
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.7281076908111572
Epoch: 54, Steps: 65 | Train Loss: 0.5353844 Vali Loss: 0.2728202 Test Loss: 0.3969971
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.864203929901123
Epoch: 55, Steps: 65 | Train Loss: 0.5355040 Vali Loss: 0.2728751 Test Loss: 0.3970071
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 3.029608964920044
Epoch: 56, Steps: 65 | Train Loss: 0.5335274 Vali Loss: 0.2727838 Test Loss: 0.3970030
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.453956365585327
Epoch: 57, Steps: 65 | Train Loss: 0.5349510 Vali Loss: 0.2725451 Test Loss: 0.3970138
Validation loss decreased (0.272674 --> 0.272545).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.1406257152557373
Epoch: 58, Steps: 65 | Train Loss: 0.5349786 Vali Loss: 0.2728637 Test Loss: 0.3970110
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 3.1584649085998535
Epoch: 59, Steps: 65 | Train Loss: 0.5355173 Vali Loss: 0.2728613 Test Loss: 0.3970123
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 4.087732791900635
Epoch: 60, Steps: 65 | Train Loss: 0.5349388 Vali Loss: 0.2728588 Test Loss: 0.3970146
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 4.08313775062561
Epoch: 61, Steps: 65 | Train Loss: 0.5346737 Vali Loss: 0.2728306 Test Loss: 0.3970137
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 3.7047276496887207
Epoch: 62, Steps: 65 | Train Loss: 0.5330570 Vali Loss: 0.2727975 Test Loss: 0.3970196
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 3.3115594387054443
Epoch: 63, Steps: 65 | Train Loss: 0.5349283 Vali Loss: 0.2728387 Test Loss: 0.3970264
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.9007856845855713
Epoch: 64, Steps: 65 | Train Loss: 0.5341430 Vali Loss: 0.2728424 Test Loss: 0.3970188
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 5.360627889633179
Epoch: 65, Steps: 65 | Train Loss: 0.5347929 Vali Loss: 0.2727697 Test Loss: 0.3970209
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 4.431044816970825
Epoch: 66, Steps: 65 | Train Loss: 0.5338557 Vali Loss: 0.2728415 Test Loss: 0.3970182
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 3.5063371658325195
Epoch: 67, Steps: 65 | Train Loss: 0.5347869 Vali Loss: 0.2728495 Test Loss: 0.3970255
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 2.655081033706665
Epoch: 68, Steps: 65 | Train Loss: 0.5325569 Vali Loss: 0.2728578 Test Loss: 0.3970218
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 2.4824280738830566
Epoch: 69, Steps: 65 | Train Loss: 0.5344807 Vali Loss: 0.2728493 Test Loss: 0.3970250
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.7238500118255615
Epoch: 70, Steps: 65 | Train Loss: 0.5355392 Vali Loss: 0.2728721 Test Loss: 0.3970300
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.0631933212280273
Epoch: 71, Steps: 65 | Train Loss: 0.5335883 Vali Loss: 0.2728044 Test Loss: 0.3970278
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.2263550758361816
Epoch: 72, Steps: 65 | Train Loss: 0.5340084 Vali Loss: 0.2728271 Test Loss: 0.3970251
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.7522714138031006
Epoch: 73, Steps: 65 | Train Loss: 0.5334833 Vali Loss: 0.2728296 Test Loss: 0.3970318
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.2046802043914795
Epoch: 74, Steps: 65 | Train Loss: 0.5349845 Vali Loss: 0.2727233 Test Loss: 0.3970313
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.3595235347747803
Epoch: 75, Steps: 65 | Train Loss: 0.5342908 Vali Loss: 0.2728461 Test Loss: 0.3970316
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.8152568340301514
Epoch: 76, Steps: 65 | Train Loss: 0.5343095 Vali Loss: 0.2726362 Test Loss: 0.3970336
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 3.1304855346679688
Epoch: 77, Steps: 65 | Train Loss: 0.5356045 Vali Loss: 0.2728583 Test Loss: 0.3970381
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_90_192_FITS_ETTh2_ftM_sl90_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.3764287531375885, mae:0.39036890864372253, rse:0.4920194149017334, corr:[0.2685049  0.2697657  0.26768926 0.26823974 0.2662607  0.26527512
 0.26512042 0.2637754  0.26316142 0.26228377 0.2609994  0.25961468
 0.2577727  0.25626275 0.2553691  0.2546923  0.2541455  0.25387287
 0.2531955  0.25208333 0.2511184  0.2500389  0.2489526  0.24704145
 0.2438176  0.24113713 0.23868482 0.2370693  0.23554264 0.23393095
 0.23308614 0.23170993 0.23003204 0.22849168 0.22756182 0.22608499
 0.22434908 0.22306341 0.22185384 0.22096817 0.22038735 0.21989994
 0.21966182 0.21880463 0.21770266 0.21679142 0.21592265 0.21377748
 0.21012817 0.20740667 0.20466968 0.20248762 0.20073572 0.19875112
 0.19706033 0.19457234 0.19317472 0.19171642 0.19054297 0.18910083
 0.18795589 0.18748981 0.1871406  0.1871652  0.18683985 0.18625551
 0.18592708 0.18509123 0.18444179 0.18410915 0.18333083 0.18183915
 0.17925173 0.17771082 0.17618915 0.17500995 0.17392561 0.17338324
 0.17357479 0.17246929 0.1718926  0.1715736  0.17129822 0.1708222
 0.17021987 0.16989616 0.16983594 0.17005269 0.16956197 0.1690797
 0.16901207 0.16817836 0.16772038 0.16778469 0.16734663 0.16608267
 0.1639562  0.16201253 0.15988374 0.15858895 0.15747182 0.15632503
 0.15636845 0.15571597 0.15549965 0.15529951 0.15521426 0.15496133
 0.15442006 0.15384966 0.15298222 0.15280113 0.15241915 0.1517632
 0.15179469 0.15119514 0.15034063 0.14974767 0.14841264 0.14611623
 0.1435285  0.14152591 0.13945507 0.13856277 0.13741906 0.1361604
 0.1359059  0.13535483 0.1348494  0.13432175 0.13408369 0.13333993
 0.1325966  0.13201807 0.13146357 0.13124709 0.13082913 0.13027455
 0.13004418 0.1294315  0.12883104 0.12868144 0.12771915 0.1254002
 0.12216338 0.11980082 0.11746136 0.11604079 0.1147619  0.11356965
 0.11357088 0.11280733 0.11233049 0.11200408 0.11206816 0.11155463
 0.11091982 0.11068887 0.1103668  0.1106061  0.1104029  0.1099166
 0.11008969 0.10970189 0.10942354 0.10983515 0.10978999 0.10800644
 0.10518248 0.10350797 0.10171223 0.10100546 0.10028574 0.0992099
 0.09944386 0.09904998 0.09863749 0.09817731 0.09839686 0.09782786
 0.09709581 0.09688607 0.09660598 0.09695815 0.0965024  0.09621131
 0.0966588  0.09597944 0.09614074 0.09731565 0.09696714 0.09966954]
