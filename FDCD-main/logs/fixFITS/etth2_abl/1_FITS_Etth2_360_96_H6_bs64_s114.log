Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_360_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_360_96_FITS_ETTh2_ftM_sl360_ll48_pl96_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8185
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=106, out_features=134, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  12726784.0
params:  14338.0
Trainable parameters:  14338
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.2615888118743896
Epoch: 1, Steps: 63 | Train Loss: 0.6043895 Vali Loss: 0.2878708 Test Loss: 0.3506356
Validation loss decreased (inf --> 0.287871).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.3215618133544922
Epoch: 2, Steps: 63 | Train Loss: 0.4838601 Vali Loss: 0.2525779 Test Loss: 0.3192830
Validation loss decreased (0.287871 --> 0.252578).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.3428020477294922
Epoch: 3, Steps: 63 | Train Loss: 0.4531088 Vali Loss: 0.2392790 Test Loss: 0.3063860
Validation loss decreased (0.252578 --> 0.239279).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.3888437747955322
Epoch: 4, Steps: 63 | Train Loss: 0.4380990 Vali Loss: 0.2324475 Test Loss: 0.2992301
Validation loss decreased (0.239279 --> 0.232447).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.50655198097229
Epoch: 5, Steps: 63 | Train Loss: 0.4306157 Vali Loss: 0.2272211 Test Loss: 0.2945501
Validation loss decreased (0.232447 --> 0.227221).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.3040485382080078
Epoch: 6, Steps: 63 | Train Loss: 0.4231461 Vali Loss: 0.2260019 Test Loss: 0.2915174
Validation loss decreased (0.227221 --> 0.226002).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.60664701461792
Epoch: 7, Steps: 63 | Train Loss: 0.4213379 Vali Loss: 0.2220116 Test Loss: 0.2891996
Validation loss decreased (0.226002 --> 0.222012).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.6193270683288574
Epoch: 8, Steps: 63 | Train Loss: 0.4186799 Vali Loss: 0.2213830 Test Loss: 0.2872729
Validation loss decreased (0.222012 --> 0.221383).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.5389659404754639
Epoch: 9, Steps: 63 | Train Loss: 0.4154440 Vali Loss: 0.2212504 Test Loss: 0.2860286
Validation loss decreased (0.221383 --> 0.221250).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.6821281909942627
Epoch: 10, Steps: 63 | Train Loss: 0.4148031 Vali Loss: 0.2201594 Test Loss: 0.2849772
Validation loss decreased (0.221250 --> 0.220159).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.6205384731292725
Epoch: 11, Steps: 63 | Train Loss: 0.4129847 Vali Loss: 0.2192415 Test Loss: 0.2840167
Validation loss decreased (0.220159 --> 0.219241).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.5389494895935059
Epoch: 12, Steps: 63 | Train Loss: 0.4109125 Vali Loss: 0.2181568 Test Loss: 0.2828739
Validation loss decreased (0.219241 --> 0.218157).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.8685708045959473
Epoch: 13, Steps: 63 | Train Loss: 0.4105381 Vali Loss: 0.2173002 Test Loss: 0.2821874
Validation loss decreased (0.218157 --> 0.217300).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.6027629375457764
Epoch: 14, Steps: 63 | Train Loss: 0.4084959 Vali Loss: 0.2175247 Test Loss: 0.2816589
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.2839601039886475
Epoch: 15, Steps: 63 | Train Loss: 0.4083857 Vali Loss: 0.2172095 Test Loss: 0.2811565
Validation loss decreased (0.217300 --> 0.217209).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.205995798110962
Epoch: 16, Steps: 63 | Train Loss: 0.4068373 Vali Loss: 0.2160660 Test Loss: 0.2806457
Validation loss decreased (0.217209 --> 0.216066).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.783722162246704
Epoch: 17, Steps: 63 | Train Loss: 0.4069364 Vali Loss: 0.2146930 Test Loss: 0.2804018
Validation loss decreased (0.216066 --> 0.214693).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.473128080368042
Epoch: 18, Steps: 63 | Train Loss: 0.4066847 Vali Loss: 0.2146973 Test Loss: 0.2799394
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.3439216613769531
Epoch: 19, Steps: 63 | Train Loss: 0.4027494 Vali Loss: 0.2161082 Test Loss: 0.2795003
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.3548574447631836
Epoch: 20, Steps: 63 | Train Loss: 0.4046083 Vali Loss: 0.2146298 Test Loss: 0.2792105
Validation loss decreased (0.214693 --> 0.214630).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.4081177711486816
Epoch: 21, Steps: 63 | Train Loss: 0.4054853 Vali Loss: 0.2150141 Test Loss: 0.2789772
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.6390526294708252
Epoch: 22, Steps: 63 | Train Loss: 0.4039772 Vali Loss: 0.2146602 Test Loss: 0.2789706
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.6826744079589844
Epoch: 23, Steps: 63 | Train Loss: 0.4027526 Vali Loss: 0.2139939 Test Loss: 0.2786417
Validation loss decreased (0.214630 --> 0.213994).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.3805763721466064
Epoch: 24, Steps: 63 | Train Loss: 0.4033613 Vali Loss: 0.2146723 Test Loss: 0.2783461
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.1825032234191895
Epoch: 25, Steps: 63 | Train Loss: 0.4011998 Vali Loss: 0.2132942 Test Loss: 0.2782314
Validation loss decreased (0.213994 --> 0.213294).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.6777675151824951
Epoch: 26, Steps: 63 | Train Loss: 0.4007685 Vali Loss: 0.2141340 Test Loss: 0.2779768
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.4214069843292236
Epoch: 27, Steps: 63 | Train Loss: 0.4029135 Vali Loss: 0.2134024 Test Loss: 0.2779379
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.5937180519104004
Epoch: 28, Steps: 63 | Train Loss: 0.4030725 Vali Loss: 0.2128339 Test Loss: 0.2778133
Validation loss decreased (0.213294 --> 0.212834).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.240121603012085
Epoch: 29, Steps: 63 | Train Loss: 0.4012347 Vali Loss: 0.2140186 Test Loss: 0.2777747
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.801851511001587
Epoch: 30, Steps: 63 | Train Loss: 0.4021635 Vali Loss: 0.2133342 Test Loss: 0.2775877
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.6414990425109863
Epoch: 31, Steps: 63 | Train Loss: 0.4013562 Vali Loss: 0.2132384 Test Loss: 0.2774794
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.5057404041290283
Epoch: 32, Steps: 63 | Train Loss: 0.4021481 Vali Loss: 0.2132820 Test Loss: 0.2773566
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.1810216903686523
Epoch: 33, Steps: 63 | Train Loss: 0.4015798 Vali Loss: 0.2131314 Test Loss: 0.2772684
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.5839390754699707
Epoch: 34, Steps: 63 | Train Loss: 0.4023361 Vali Loss: 0.2134057 Test Loss: 0.2771389
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.5259275436401367
Epoch: 35, Steps: 63 | Train Loss: 0.3987895 Vali Loss: 0.2127435 Test Loss: 0.2771034
Validation loss decreased (0.212834 --> 0.212744).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.6550283432006836
Epoch: 36, Steps: 63 | Train Loss: 0.3975913 Vali Loss: 0.2123481 Test Loss: 0.2771102
Validation loss decreased (0.212744 --> 0.212348).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.6590943336486816
Epoch: 37, Steps: 63 | Train Loss: 0.4004601 Vali Loss: 0.2129444 Test Loss: 0.2770080
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.7238781452178955
Epoch: 38, Steps: 63 | Train Loss: 0.3999088 Vali Loss: 0.2124954 Test Loss: 0.2769542
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.2490484714508057
Epoch: 39, Steps: 63 | Train Loss: 0.4002152 Vali Loss: 0.2126200 Test Loss: 0.2769981
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.978870153427124
Epoch: 40, Steps: 63 | Train Loss: 0.4005412 Vali Loss: 0.2129194 Test Loss: 0.2768559
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.6329593658447266
Epoch: 41, Steps: 63 | Train Loss: 0.3996065 Vali Loss: 0.2121505 Test Loss: 0.2768291
Validation loss decreased (0.212348 --> 0.212151).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.7392029762268066
Epoch: 42, Steps: 63 | Train Loss: 0.4013377 Vali Loss: 0.2124806 Test Loss: 0.2766784
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.215897560119629
Epoch: 43, Steps: 63 | Train Loss: 0.3983127 Vali Loss: 0.2123653 Test Loss: 0.2766837
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.4467811584472656
Epoch: 44, Steps: 63 | Train Loss: 0.3984016 Vali Loss: 0.2121184 Test Loss: 0.2767200
Validation loss decreased (0.212151 --> 0.212118).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.1992082595825195
Epoch: 45, Steps: 63 | Train Loss: 0.3988638 Vali Loss: 0.2124911 Test Loss: 0.2766846
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.3907544612884521
Epoch: 46, Steps: 63 | Train Loss: 0.4000866 Vali Loss: 0.2120344 Test Loss: 0.2766505
Validation loss decreased (0.212118 --> 0.212034).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.4512596130371094
Epoch: 47, Steps: 63 | Train Loss: 0.3987572 Vali Loss: 0.2121789 Test Loss: 0.2765926
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.4992129802703857
Epoch: 48, Steps: 63 | Train Loss: 0.3993088 Vali Loss: 0.2121611 Test Loss: 0.2765661
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.4636375904083252
Epoch: 49, Steps: 63 | Train Loss: 0.3981476 Vali Loss: 0.2122583 Test Loss: 0.2765373
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.4849176406860352
Epoch: 50, Steps: 63 | Train Loss: 0.3948804 Vali Loss: 0.2123151 Test Loss: 0.2765156
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.2489068508148193
Epoch: 51, Steps: 63 | Train Loss: 0.3992869 Vali Loss: 0.2122435 Test Loss: 0.2764918
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.765343427658081
Epoch: 52, Steps: 63 | Train Loss: 0.4005923 Vali Loss: 0.2127481 Test Loss: 0.2764579
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.668999195098877
Epoch: 53, Steps: 63 | Train Loss: 0.3995090 Vali Loss: 0.2113282 Test Loss: 0.2764391
Validation loss decreased (0.212034 --> 0.211328).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.6011121273040771
Epoch: 54, Steps: 63 | Train Loss: 0.4011258 Vali Loss: 0.2114691 Test Loss: 0.2764152
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.4961917400360107
Epoch: 55, Steps: 63 | Train Loss: 0.3973497 Vali Loss: 0.2111327 Test Loss: 0.2764264
Validation loss decreased (0.211328 --> 0.211133).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.172045946121216
Epoch: 56, Steps: 63 | Train Loss: 0.3999624 Vali Loss: 0.2113908 Test Loss: 0.2763888
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.9936957359313965
Epoch: 57, Steps: 63 | Train Loss: 0.3997801 Vali Loss: 0.2118770 Test Loss: 0.2763761
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.6820294857025146
Epoch: 58, Steps: 63 | Train Loss: 0.3985848 Vali Loss: 0.2125193 Test Loss: 0.2763734
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.5957133769989014
Epoch: 59, Steps: 63 | Train Loss: 0.3998237 Vali Loss: 0.2127829 Test Loss: 0.2763516
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.5774493217468262
Epoch: 60, Steps: 63 | Train Loss: 0.3994739 Vali Loss: 0.2120841 Test Loss: 0.2763268
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.0301342010498047
Epoch: 61, Steps: 63 | Train Loss: 0.4002903 Vali Loss: 0.2113778 Test Loss: 0.2763150
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.0268828868865967
Epoch: 62, Steps: 63 | Train Loss: 0.4002630 Vali Loss: 0.2116621 Test Loss: 0.2762921
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.9504590034484863
Epoch: 63, Steps: 63 | Train Loss: 0.3981900 Vali Loss: 0.2115745 Test Loss: 0.2763035
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.191661834716797
Epoch: 64, Steps: 63 | Train Loss: 0.4003800 Vali Loss: 0.2117864 Test Loss: 0.2762570
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.0567564964294434
Epoch: 65, Steps: 63 | Train Loss: 0.3989476 Vali Loss: 0.2122949 Test Loss: 0.2762668
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.7514030933380127
Epoch: 66, Steps: 63 | Train Loss: 0.4008332 Vali Loss: 0.2111251 Test Loss: 0.2762752
Validation loss decreased (0.211133 --> 0.211125).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.7657170295715332
Epoch: 67, Steps: 63 | Train Loss: 0.3971197 Vali Loss: 0.2108986 Test Loss: 0.2762577
Validation loss decreased (0.211125 --> 0.210899).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.4617843627929688
Epoch: 68, Steps: 63 | Train Loss: 0.4001398 Vali Loss: 0.2126753 Test Loss: 0.2762508
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.4602487087249756
Epoch: 69, Steps: 63 | Train Loss: 0.3980952 Vali Loss: 0.2116322 Test Loss: 0.2762311
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.3299987316131592
Epoch: 70, Steps: 63 | Train Loss: 0.3980841 Vali Loss: 0.2114480 Test Loss: 0.2762073
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.0566658973693848
Epoch: 71, Steps: 63 | Train Loss: 0.4006868 Vali Loss: 0.2118793 Test Loss: 0.2761991
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.5784156322479248
Epoch: 72, Steps: 63 | Train Loss: 0.4009616 Vali Loss: 0.2119720 Test Loss: 0.2761879
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.5048105716705322
Epoch: 73, Steps: 63 | Train Loss: 0.3994470 Vali Loss: 0.2127562 Test Loss: 0.2761977
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.8043358325958252
Epoch: 74, Steps: 63 | Train Loss: 0.3972204 Vali Loss: 0.2116507 Test Loss: 0.2761922
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.7418229579925537
Epoch: 75, Steps: 63 | Train Loss: 0.3998083 Vali Loss: 0.2112454 Test Loss: 0.2761788
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.761606216430664
Epoch: 76, Steps: 63 | Train Loss: 0.3983397 Vali Loss: 0.2123537 Test Loss: 0.2761841
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.5553555488586426
Epoch: 77, Steps: 63 | Train Loss: 0.3953548 Vali Loss: 0.2109527 Test Loss: 0.2761706
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.766739845275879
Epoch: 78, Steps: 63 | Train Loss: 0.3989235 Vali Loss: 0.2118427 Test Loss: 0.2761693
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.4827032089233398
Epoch: 79, Steps: 63 | Train Loss: 0.4003158 Vali Loss: 0.2121105 Test Loss: 0.2761560
EarlyStopping counter: 12 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.8316736221313477
Epoch: 80, Steps: 63 | Train Loss: 0.3970226 Vali Loss: 0.2127175 Test Loss: 0.2761602
EarlyStopping counter: 13 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.205338954925537
Epoch: 81, Steps: 63 | Train Loss: 0.3990139 Vali Loss: 0.2118944 Test Loss: 0.2761593
EarlyStopping counter: 14 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.951197624206543
Epoch: 82, Steps: 63 | Train Loss: 0.3965872 Vali Loss: 0.2114670 Test Loss: 0.2761603
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.136803388595581
Epoch: 83, Steps: 63 | Train Loss: 0.3990125 Vali Loss: 0.2122621 Test Loss: 0.2761470
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.8795733451843262
Epoch: 84, Steps: 63 | Train Loss: 0.3999388 Vali Loss: 0.2116675 Test Loss: 0.2761499
EarlyStopping counter: 17 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.869105339050293
Epoch: 85, Steps: 63 | Train Loss: 0.3988867 Vali Loss: 0.2119513 Test Loss: 0.2761466
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.602095603942871
Epoch: 86, Steps: 63 | Train Loss: 0.3998837 Vali Loss: 0.2114554 Test Loss: 0.2761406
EarlyStopping counter: 19 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.3935127258300781
Epoch: 87, Steps: 63 | Train Loss: 0.3990399 Vali Loss: 0.2120750 Test Loss: 0.2761326
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_360_96_FITS_ETTh2_ftM_sl360_ll48_pl96_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.27592992782592773, mae:0.33867374062538147, rse:0.423331618309021, corr:[0.27269772 0.27778658 0.274926   0.27559143 0.27423978 0.27231994
 0.27175355 0.270654   0.26907358 0.26772782 0.26650572 0.2650439
 0.26331493 0.2620495  0.26169997 0.2612677  0.2603915  0.25998628
 0.2593977  0.2580025  0.25671855 0.2558613  0.25415665 0.25192508
 0.24999714 0.24782619 0.24561557 0.24454084 0.24362627 0.24185991
 0.24071148 0.23979998 0.23746188 0.23550047 0.23512597 0.23401506
 0.231695   0.23093288 0.23086838 0.22933984 0.22847308 0.22890629
 0.22816512 0.22677423 0.22650559 0.22583364 0.22412618 0.22284484
 0.2215647  0.21920131 0.21757089 0.21709673 0.2158072  0.2139952
 0.21287136 0.21121442 0.20899671 0.20779495 0.20719558 0.20565584
 0.20497936 0.20566179 0.20565383 0.20506951 0.2055545  0.20552781
 0.20422864 0.2038973  0.20435885 0.20332216 0.2024826  0.20274179
 0.2015916  0.19999075 0.20047712 0.20016575 0.19802338 0.19772965
 0.1986994  0.19717069 0.19614221 0.19718988 0.19715826 0.19571431
 0.19637646 0.19715215 0.19604297 0.19631192 0.19705282 0.1951637
 0.19359644 0.1944867  0.19312239 0.18991323 0.19153646 0.18311693]
