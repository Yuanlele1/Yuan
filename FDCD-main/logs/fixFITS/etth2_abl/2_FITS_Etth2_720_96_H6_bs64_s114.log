Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=196, out_features=222, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  38986752.0
params:  43734.0
Trainable parameters:  43734
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.6724956035614014
Epoch: 1, Steps: 61 | Train Loss: 0.5475246 Vali Loss: 0.3884942 Test Loss: 0.3826737
Validation loss decreased (inf --> 0.388494).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.8077666759490967
Epoch: 2, Steps: 61 | Train Loss: 0.4226359 Vali Loss: 0.3375756 Test Loss: 0.3478466
Validation loss decreased (0.388494 --> 0.337576).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.6995646953582764
Epoch: 3, Steps: 61 | Train Loss: 0.3612738 Vali Loss: 0.3223671 Test Loss: 0.3369028
Validation loss decreased (0.337576 --> 0.322367).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.767514944076538
Epoch: 4, Steps: 61 | Train Loss: 0.3243973 Vali Loss: 0.3174089 Test Loss: 0.3331976
Validation loss decreased (0.322367 --> 0.317409).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.9206297397613525
Epoch: 5, Steps: 61 | Train Loss: 0.2977336 Vali Loss: 0.3144380 Test Loss: 0.3312860
Validation loss decreased (0.317409 --> 0.314438).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.8922431468963623
Epoch: 6, Steps: 61 | Train Loss: 0.2761965 Vali Loss: 0.3107733 Test Loss: 0.3292876
Validation loss decreased (0.314438 --> 0.310773).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.9459407329559326
Epoch: 7, Steps: 61 | Train Loss: 0.2586079 Vali Loss: 0.3080987 Test Loss: 0.3280731
Validation loss decreased (0.310773 --> 0.308099).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.0217206478118896
Epoch: 8, Steps: 61 | Train Loss: 0.2438606 Vali Loss: 0.3053064 Test Loss: 0.3263333
Validation loss decreased (0.308099 --> 0.305306).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.9234285354614258
Epoch: 9, Steps: 61 | Train Loss: 0.2305788 Vali Loss: 0.3051359 Test Loss: 0.3244267
Validation loss decreased (0.305306 --> 0.305136).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.8484044075012207
Epoch: 10, Steps: 61 | Train Loss: 0.2190649 Vali Loss: 0.3007593 Test Loss: 0.3224695
Validation loss decreased (0.305136 --> 0.300759).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.7933721542358398
Epoch: 11, Steps: 61 | Train Loss: 0.2088715 Vali Loss: 0.2977470 Test Loss: 0.3206625
Validation loss decreased (0.300759 --> 0.297747).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.7936019897460938
Epoch: 12, Steps: 61 | Train Loss: 0.1999550 Vali Loss: 0.2951589 Test Loss: 0.3190029
Validation loss decreased (0.297747 --> 0.295159).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.018178701400757
Epoch: 13, Steps: 61 | Train Loss: 0.1916907 Vali Loss: 0.2921478 Test Loss: 0.3169509
Validation loss decreased (0.295159 --> 0.292148).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.7501797676086426
Epoch: 14, Steps: 61 | Train Loss: 0.1840969 Vali Loss: 0.2901726 Test Loss: 0.3152334
Validation loss decreased (0.292148 --> 0.290173).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.8107824325561523
Epoch: 15, Steps: 61 | Train Loss: 0.1776324 Vali Loss: 0.2871624 Test Loss: 0.3135063
Validation loss decreased (0.290173 --> 0.287162).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.811551809310913
Epoch: 16, Steps: 61 | Train Loss: 0.1714576 Vali Loss: 0.2856914 Test Loss: 0.3119121
Validation loss decreased (0.287162 --> 0.285691).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.0906734466552734
Epoch: 17, Steps: 61 | Train Loss: 0.1660007 Vali Loss: 0.2845884 Test Loss: 0.3104421
Validation loss decreased (0.285691 --> 0.284588).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.9663751125335693
Epoch: 18, Steps: 61 | Train Loss: 0.1610253 Vali Loss: 0.2804615 Test Loss: 0.3089955
Validation loss decreased (0.284588 --> 0.280461).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.0549230575561523
Epoch: 19, Steps: 61 | Train Loss: 0.1562393 Vali Loss: 0.2803798 Test Loss: 0.3076534
Validation loss decreased (0.280461 --> 0.280380).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.7142186164855957
Epoch: 20, Steps: 61 | Train Loss: 0.1522556 Vali Loss: 0.2779406 Test Loss: 0.3062218
Validation loss decreased (0.280380 --> 0.277941).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.0062968730926514
Epoch: 21, Steps: 61 | Train Loss: 0.1483115 Vali Loss: 0.2757632 Test Loss: 0.3051279
Validation loss decreased (0.277941 --> 0.275763).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.9924957752227783
Epoch: 22, Steps: 61 | Train Loss: 0.1448702 Vali Loss: 0.2743711 Test Loss: 0.3040085
Validation loss decreased (0.275763 --> 0.274371).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.2292685508728027
Epoch: 23, Steps: 61 | Train Loss: 0.1415400 Vali Loss: 0.2737406 Test Loss: 0.3029683
Validation loss decreased (0.274371 --> 0.273741).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.191101551055908
Epoch: 24, Steps: 61 | Train Loss: 0.1384746 Vali Loss: 0.2721662 Test Loss: 0.3020442
Validation loss decreased (0.273741 --> 0.272166).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.205446243286133
Epoch: 25, Steps: 61 | Train Loss: 0.1357561 Vali Loss: 0.2699207 Test Loss: 0.3010862
Validation loss decreased (0.272166 --> 0.269921).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.3777661323547363
Epoch: 26, Steps: 61 | Train Loss: 0.1331293 Vali Loss: 0.2691009 Test Loss: 0.3002518
Validation loss decreased (0.269921 --> 0.269101).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.735365867614746
Epoch: 27, Steps: 61 | Train Loss: 0.1306225 Vali Loss: 0.2671021 Test Loss: 0.2993640
Validation loss decreased (0.269101 --> 0.267102).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.1732969284057617
Epoch: 28, Steps: 61 | Train Loss: 0.1284918 Vali Loss: 0.2668066 Test Loss: 0.2985939
Validation loss decreased (0.267102 --> 0.266807).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.086989402770996
Epoch: 29, Steps: 61 | Train Loss: 0.1264239 Vali Loss: 0.2662243 Test Loss: 0.2979073
Validation loss decreased (0.266807 --> 0.266224).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 5.642643928527832
Epoch: 30, Steps: 61 | Train Loss: 0.1244895 Vali Loss: 0.2649834 Test Loss: 0.2973499
Validation loss decreased (0.266224 --> 0.264983).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 5.195349454879761
Epoch: 31, Steps: 61 | Train Loss: 0.1225126 Vali Loss: 0.2643328 Test Loss: 0.2966312
Validation loss decreased (0.264983 --> 0.264333).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 5.944684743881226
Epoch: 32, Steps: 61 | Train Loss: 0.1209067 Vali Loss: 0.2634298 Test Loss: 0.2960531
Validation loss decreased (0.264333 --> 0.263430).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 5.556367635726929
Epoch: 33, Steps: 61 | Train Loss: 0.1194092 Vali Loss: 0.2614475 Test Loss: 0.2954645
Validation loss decreased (0.263430 --> 0.261448).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 5.806833505630493
Epoch: 34, Steps: 61 | Train Loss: 0.1177821 Vali Loss: 0.2612364 Test Loss: 0.2949933
Validation loss decreased (0.261448 --> 0.261236).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 5.604936599731445
Epoch: 35, Steps: 61 | Train Loss: 0.1165029 Vali Loss: 0.2614172 Test Loss: 0.2945169
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.3968887329101562
Epoch: 36, Steps: 61 | Train Loss: 0.1150784 Vali Loss: 0.2610137 Test Loss: 0.2940596
Validation loss decreased (0.261236 --> 0.261014).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.826810836791992
Epoch: 37, Steps: 61 | Train Loss: 0.1140233 Vali Loss: 0.2591961 Test Loss: 0.2936089
Validation loss decreased (0.261014 --> 0.259196).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.4233810901641846
Epoch: 38, Steps: 61 | Train Loss: 0.1128985 Vali Loss: 0.2591535 Test Loss: 0.2931374
Validation loss decreased (0.259196 --> 0.259154).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 3.224684476852417
Epoch: 39, Steps: 61 | Train Loss: 0.1117895 Vali Loss: 0.2585349 Test Loss: 0.2928276
Validation loss decreased (0.259154 --> 0.258535).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 3.2000458240509033
Epoch: 40, Steps: 61 | Train Loss: 0.1106692 Vali Loss: 0.2576826 Test Loss: 0.2924471
Validation loss decreased (0.258535 --> 0.257683).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.8984861373901367
Epoch: 41, Steps: 61 | Train Loss: 0.1098542 Vali Loss: 0.2573799 Test Loss: 0.2920977
Validation loss decreased (0.257683 --> 0.257380).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 3.1996982097625732
Epoch: 42, Steps: 61 | Train Loss: 0.1090285 Vali Loss: 0.2575324 Test Loss: 0.2917781
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.2340946197509766
Epoch: 43, Steps: 61 | Train Loss: 0.1082125 Vali Loss: 0.2556356 Test Loss: 0.2914267
Validation loss decreased (0.257380 --> 0.255636).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.030742645263672
Epoch: 44, Steps: 61 | Train Loss: 0.1072671 Vali Loss: 0.2547775 Test Loss: 0.2911541
Validation loss decreased (0.255636 --> 0.254777).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 3.1458282470703125
Epoch: 45, Steps: 61 | Train Loss: 0.1066312 Vali Loss: 0.2560013 Test Loss: 0.2908806
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.7020530700683594
Epoch: 46, Steps: 61 | Train Loss: 0.1059114 Vali Loss: 0.2546861 Test Loss: 0.2906248
Validation loss decreased (0.254777 --> 0.254686).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 3.0794777870178223
Epoch: 47, Steps: 61 | Train Loss: 0.1050282 Vali Loss: 0.2537436 Test Loss: 0.2903626
Validation loss decreased (0.254686 --> 0.253744).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.312450647354126
Epoch: 48, Steps: 61 | Train Loss: 0.1046644 Vali Loss: 0.2542467 Test Loss: 0.2901272
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 3.0693328380584717
Epoch: 49, Steps: 61 | Train Loss: 0.1040391 Vali Loss: 0.2543717 Test Loss: 0.2899465
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 3.1078028678894043
Epoch: 50, Steps: 61 | Train Loss: 0.1035358 Vali Loss: 0.2534482 Test Loss: 0.2897521
Validation loss decreased (0.253744 --> 0.253448).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.510531425476074
Epoch: 51, Steps: 61 | Train Loss: 0.1030056 Vali Loss: 0.2530575 Test Loss: 0.2895151
Validation loss decreased (0.253448 --> 0.253057).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.7944223880767822
Epoch: 52, Steps: 61 | Train Loss: 0.1025560 Vali Loss: 0.2533143 Test Loss: 0.2893657
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 3.2469542026519775
Epoch: 53, Steps: 61 | Train Loss: 0.1020758 Vali Loss: 0.2539608 Test Loss: 0.2891629
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.1602976322174072
Epoch: 54, Steps: 61 | Train Loss: 0.1016024 Vali Loss: 0.2525869 Test Loss: 0.2890055
Validation loss decreased (0.253057 --> 0.252587).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 3.1445424556732178
Epoch: 55, Steps: 61 | Train Loss: 0.1011468 Vali Loss: 0.2521366 Test Loss: 0.2888487
Validation loss decreased (0.252587 --> 0.252137).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.873885154724121
Epoch: 56, Steps: 61 | Train Loss: 0.1006998 Vali Loss: 0.2523316 Test Loss: 0.2886986
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 3.7384746074676514
Epoch: 57, Steps: 61 | Train Loss: 0.1003069 Vali Loss: 0.2524721 Test Loss: 0.2885479
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 3.0479228496551514
Epoch: 58, Steps: 61 | Train Loss: 0.0999763 Vali Loss: 0.2518840 Test Loss: 0.2884248
Validation loss decreased (0.252137 --> 0.251884).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 3.2201595306396484
Epoch: 59, Steps: 61 | Train Loss: 0.0996856 Vali Loss: 0.2504303 Test Loss: 0.2882870
Validation loss decreased (0.251884 --> 0.250430).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 5.83433985710144
Epoch: 60, Steps: 61 | Train Loss: 0.0993516 Vali Loss: 0.2516541 Test Loss: 0.2881621
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 5.672090530395508
Epoch: 61, Steps: 61 | Train Loss: 0.0989710 Vali Loss: 0.2515022 Test Loss: 0.2880647
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 5.216893911361694
Epoch: 62, Steps: 61 | Train Loss: 0.0987304 Vali Loss: 0.2506510 Test Loss: 0.2879271
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 5.227593898773193
Epoch: 63, Steps: 61 | Train Loss: 0.0984887 Vali Loss: 0.2508409 Test Loss: 0.2878312
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 7.937472581863403
Epoch: 64, Steps: 61 | Train Loss: 0.0982936 Vali Loss: 0.2508467 Test Loss: 0.2877320
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 7.8513383865356445
Epoch: 65, Steps: 61 | Train Loss: 0.0978991 Vali Loss: 0.2510116 Test Loss: 0.2876448
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 7.9172203540802
Epoch: 66, Steps: 61 | Train Loss: 0.0976859 Vali Loss: 0.2510997 Test Loss: 0.2875476
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 8.087640047073364
Epoch: 67, Steps: 61 | Train Loss: 0.0974619 Vali Loss: 0.2504867 Test Loss: 0.2874742
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 8.216805934906006
Epoch: 68, Steps: 61 | Train Loss: 0.0972687 Vali Loss: 0.2492301 Test Loss: 0.2874025
Validation loss decreased (0.250430 --> 0.249230).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 8.178303480148315
Epoch: 69, Steps: 61 | Train Loss: 0.0971158 Vali Loss: 0.2495177 Test Loss: 0.2873197
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 8.223320960998535
Epoch: 70, Steps: 61 | Train Loss: 0.0967339 Vali Loss: 0.2494369 Test Loss: 0.2872545
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 7.851160526275635
Epoch: 71, Steps: 61 | Train Loss: 0.0966617 Vali Loss: 0.2494809 Test Loss: 0.2871725
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 7.842578172683716
Epoch: 72, Steps: 61 | Train Loss: 0.0964854 Vali Loss: 0.2487994 Test Loss: 0.2871006
Validation loss decreased (0.249230 --> 0.248799).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 7.7222185134887695
Epoch: 73, Steps: 61 | Train Loss: 0.0962711 Vali Loss: 0.2491729 Test Loss: 0.2870377
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 8.070780277252197
Epoch: 74, Steps: 61 | Train Loss: 0.0962364 Vali Loss: 0.2489914 Test Loss: 0.2869759
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 8.054709672927856
Epoch: 75, Steps: 61 | Train Loss: 0.0959953 Vali Loss: 0.2500150 Test Loss: 0.2869241
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 7.727137088775635
Epoch: 76, Steps: 61 | Train Loss: 0.0958935 Vali Loss: 0.2498087 Test Loss: 0.2868653
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 8.00237226486206
Epoch: 77, Steps: 61 | Train Loss: 0.0956918 Vali Loss: 0.2492123 Test Loss: 0.2868210
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 7.813177108764648
Epoch: 78, Steps: 61 | Train Loss: 0.0955516 Vali Loss: 0.2488560 Test Loss: 0.2867701
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 7.910500526428223
Epoch: 79, Steps: 61 | Train Loss: 0.0955478 Vali Loss: 0.2497796 Test Loss: 0.2867258
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 7.84330677986145
Epoch: 80, Steps: 61 | Train Loss: 0.0952582 Vali Loss: 0.2491109 Test Loss: 0.2866720
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 7.692520380020142
Epoch: 81, Steps: 61 | Train Loss: 0.0952419 Vali Loss: 0.2499814 Test Loss: 0.2866333
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 7.829589128494263
Epoch: 82, Steps: 61 | Train Loss: 0.0951838 Vali Loss: 0.2494588 Test Loss: 0.2865906
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 7.989219903945923
Epoch: 83, Steps: 61 | Train Loss: 0.0951089 Vali Loss: 0.2484685 Test Loss: 0.2865472
Validation loss decreased (0.248799 --> 0.248468).  Saving model ...
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 7.883581161499023
Epoch: 84, Steps: 61 | Train Loss: 0.0949442 Vali Loss: 0.2486565 Test Loss: 0.2865100
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 7.616167068481445
Epoch: 85, Steps: 61 | Train Loss: 0.0948778 Vali Loss: 0.2487909 Test Loss: 0.2864798
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 7.860995769500732
Epoch: 86, Steps: 61 | Train Loss: 0.0946965 Vali Loss: 0.2476494 Test Loss: 0.2864471
Validation loss decreased (0.248468 --> 0.247649).  Saving model ...
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 7.819830656051636
Epoch: 87, Steps: 61 | Train Loss: 0.0947241 Vali Loss: 0.2483195 Test Loss: 0.2864214
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 7.773496150970459
Epoch: 88, Steps: 61 | Train Loss: 0.0946066 Vali Loss: 0.2485082 Test Loss: 0.2863916
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 7.773193359375
Epoch: 89, Steps: 61 | Train Loss: 0.0945968 Vali Loss: 0.2481005 Test Loss: 0.2863636
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 7.787174224853516
Epoch: 90, Steps: 61 | Train Loss: 0.0943695 Vali Loss: 0.2484214 Test Loss: 0.2863327
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 7.655900955200195
Epoch: 91, Steps: 61 | Train Loss: 0.0944489 Vali Loss: 0.2480660 Test Loss: 0.2863083
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 8.008389472961426
Epoch: 92, Steps: 61 | Train Loss: 0.0943677 Vali Loss: 0.2476394 Test Loss: 0.2862848
Validation loss decreased (0.247649 --> 0.247639).  Saving model ...
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 7.744272947311401
Epoch: 93, Steps: 61 | Train Loss: 0.0943233 Vali Loss: 0.2488972 Test Loss: 0.2862596
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 7.841749429702759
Epoch: 94, Steps: 61 | Train Loss: 0.0940765 Vali Loss: 0.2474160 Test Loss: 0.2862351
Validation loss decreased (0.247639 --> 0.247416).  Saving model ...
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 7.838005065917969
Epoch: 95, Steps: 61 | Train Loss: 0.0941686 Vali Loss: 0.2483650 Test Loss: 0.2862183
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 7.692782640457153
Epoch: 96, Steps: 61 | Train Loss: 0.0940634 Vali Loss: 0.2479907 Test Loss: 0.2861988
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 7.714127063751221
Epoch: 97, Steps: 61 | Train Loss: 0.0941066 Vali Loss: 0.2481819 Test Loss: 0.2861801
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 7.954055547714233
Epoch: 98, Steps: 61 | Train Loss: 0.0939685 Vali Loss: 0.2479978 Test Loss: 0.2861611
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 7.736659526824951
Epoch: 99, Steps: 61 | Train Loss: 0.0939461 Vali Loss: 0.2485714 Test Loss: 0.2861434
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 7.89266037940979
Epoch: 100, Steps: 61 | Train Loss: 0.0939405 Vali Loss: 0.2478287 Test Loss: 0.2861271
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.1160680107021042e-06
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=196, out_features=222, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  38986752.0
params:  43734.0
Trainable parameters:  43734
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 7.755454778671265
Epoch: 1, Steps: 61 | Train Loss: 0.4246887 Vali Loss: 0.2232694 Test Loss: 0.2736162
Validation loss decreased (inf --> 0.223269).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 8.042288780212402
Epoch: 2, Steps: 61 | Train Loss: 0.4098061 Vali Loss: 0.2207807 Test Loss: 0.2732820
Validation loss decreased (0.223269 --> 0.220781).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 7.66051173210144
Epoch: 3, Steps: 61 | Train Loss: 0.4068111 Vali Loss: 0.2158855 Test Loss: 0.2727037
Validation loss decreased (0.220781 --> 0.215886).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 7.732548236846924
Epoch: 4, Steps: 61 | Train Loss: 0.4052815 Vali Loss: 0.2173006 Test Loss: 0.2727061
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 7.819952726364136
Epoch: 5, Steps: 61 | Train Loss: 0.4039908 Vali Loss: 0.2154534 Test Loss: 0.2724017
Validation loss decreased (0.215886 --> 0.215453).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 7.749191522598267
Epoch: 6, Steps: 61 | Train Loss: 0.4024798 Vali Loss: 0.2141862 Test Loss: 0.2725098
Validation loss decreased (0.215453 --> 0.214186).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 8.047325372695923
Epoch: 7, Steps: 61 | Train Loss: 0.4011458 Vali Loss: 0.2147189 Test Loss: 0.2723335
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 8.223217725753784
Epoch: 8, Steps: 61 | Train Loss: 0.4014235 Vali Loss: 0.2141508 Test Loss: 0.2720267
Validation loss decreased (0.214186 --> 0.214151).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 7.7781360149383545
Epoch: 9, Steps: 61 | Train Loss: 0.4014727 Vali Loss: 0.2150716 Test Loss: 0.2722024
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 5.41007661819458
Epoch: 10, Steps: 61 | Train Loss: 0.4005614 Vali Loss: 0.2130269 Test Loss: 0.2717272
Validation loss decreased (0.214151 --> 0.213027).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 7.742593050003052
Epoch: 11, Steps: 61 | Train Loss: 0.4008860 Vali Loss: 0.2132241 Test Loss: 0.2717365
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 7.763851165771484
Epoch: 12, Steps: 61 | Train Loss: 0.3994457 Vali Loss: 0.2136779 Test Loss: 0.2719657
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 7.685056924819946
Epoch: 13, Steps: 61 | Train Loss: 0.4003517 Vali Loss: 0.2126415 Test Loss: 0.2717644
Validation loss decreased (0.213027 --> 0.212641).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 7.917422533035278
Epoch: 14, Steps: 61 | Train Loss: 0.3998110 Vali Loss: 0.2133161 Test Loss: 0.2716983
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 7.746038913726807
Epoch: 15, Steps: 61 | Train Loss: 0.3993895 Vali Loss: 0.2118132 Test Loss: 0.2717032
Validation loss decreased (0.212641 --> 0.211813).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 7.741805791854858
Epoch: 16, Steps: 61 | Train Loss: 0.3995913 Vali Loss: 0.2132251 Test Loss: 0.2716693
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 8.148190021514893
Epoch: 17, Steps: 61 | Train Loss: 0.3991260 Vali Loss: 0.2123875 Test Loss: 0.2715831
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 7.840232610702515
Epoch: 18, Steps: 61 | Train Loss: 0.3985360 Vali Loss: 0.2118574 Test Loss: 0.2715628
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 7.886908531188965
Epoch: 19, Steps: 61 | Train Loss: 0.3984860 Vali Loss: 0.2127570 Test Loss: 0.2715890
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 8.232327938079834
Epoch: 20, Steps: 61 | Train Loss: 0.3984682 Vali Loss: 0.2113236 Test Loss: 0.2715437
Validation loss decreased (0.211813 --> 0.211324).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 7.741177320480347
Epoch: 21, Steps: 61 | Train Loss: 0.3985709 Vali Loss: 0.2120096 Test Loss: 0.2715935
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 7.900912523269653
Epoch: 22, Steps: 61 | Train Loss: 0.3983733 Vali Loss: 0.2129666 Test Loss: 0.2715269
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 7.5533013343811035
Epoch: 23, Steps: 61 | Train Loss: 0.3987487 Vali Loss: 0.2129277 Test Loss: 0.2714062
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 7.827901124954224
Epoch: 24, Steps: 61 | Train Loss: 0.3983175 Vali Loss: 0.2124613 Test Loss: 0.2714002
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 7.398086071014404
Epoch: 25, Steps: 61 | Train Loss: 0.3985662 Vali Loss: 0.2124638 Test Loss: 0.2715373
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 7.7142112255096436
Epoch: 26, Steps: 61 | Train Loss: 0.3985114 Vali Loss: 0.2114773 Test Loss: 0.2713833
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 7.551800012588501
Epoch: 27, Steps: 61 | Train Loss: 0.3980458 Vali Loss: 0.2123380 Test Loss: 0.2713383
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 7.272713899612427
Epoch: 28, Steps: 61 | Train Loss: 0.3975174 Vali Loss: 0.2121504 Test Loss: 0.2714087
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 7.2434937953948975
Epoch: 29, Steps: 61 | Train Loss: 0.3977204 Vali Loss: 0.2113813 Test Loss: 0.2713621
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 7.549321413040161
Epoch: 30, Steps: 61 | Train Loss: 0.3967330 Vali Loss: 0.2113833 Test Loss: 0.2714086
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 7.493770360946655
Epoch: 31, Steps: 61 | Train Loss: 0.3970686 Vali Loss: 0.2119714 Test Loss: 0.2713724
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 7.556432008743286
Epoch: 32, Steps: 61 | Train Loss: 0.3978386 Vali Loss: 0.2113696 Test Loss: 0.2714115
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 7.614784479141235
Epoch: 33, Steps: 61 | Train Loss: 0.3978285 Vali Loss: 0.2114308 Test Loss: 0.2713979
EarlyStopping counter: 13 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 7.205814361572266
Epoch: 34, Steps: 61 | Train Loss: 0.3976358 Vali Loss: 0.2118139 Test Loss: 0.2713497
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 6.9334094524383545
Epoch: 35, Steps: 61 | Train Loss: 0.3978184 Vali Loss: 0.2118018 Test Loss: 0.2712767
EarlyStopping counter: 15 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 6.715970516204834
Epoch: 36, Steps: 61 | Train Loss: 0.3979679 Vali Loss: 0.2115773 Test Loss: 0.2713870
EarlyStopping counter: 16 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 6.869494915008545
Epoch: 37, Steps: 61 | Train Loss: 0.3974048 Vali Loss: 0.2112673 Test Loss: 0.2712950
Validation loss decreased (0.211324 --> 0.211267).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 6.6892900466918945
Epoch: 38, Steps: 61 | Train Loss: 0.3975687 Vali Loss: 0.2120390 Test Loss: 0.2713062
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 6.981448650360107
Epoch: 39, Steps: 61 | Train Loss: 0.3973999 Vali Loss: 0.2116957 Test Loss: 0.2713349
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 6.76086163520813
Epoch: 40, Steps: 61 | Train Loss: 0.3963396 Vali Loss: 0.2112360 Test Loss: 0.2712714
Validation loss decreased (0.211267 --> 0.211236).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 7.043457746505737
Epoch: 41, Steps: 61 | Train Loss: 0.3973228 Vali Loss: 0.2095728 Test Loss: 0.2713010
Validation loss decreased (0.211236 --> 0.209573).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 6.705629348754883
Epoch: 42, Steps: 61 | Train Loss: 0.3973509 Vali Loss: 0.2120962 Test Loss: 0.2712611
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 6.833383560180664
Epoch: 43, Steps: 61 | Train Loss: 0.3975029 Vali Loss: 0.2115637 Test Loss: 0.2712865
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 6.651820421218872
Epoch: 44, Steps: 61 | Train Loss: 0.3953096 Vali Loss: 0.2115046 Test Loss: 0.2713354
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 7.06050181388855
Epoch: 45, Steps: 61 | Train Loss: 0.3974645 Vali Loss: 0.2114342 Test Loss: 0.2712914
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 6.8753821849823
Epoch: 46, Steps: 61 | Train Loss: 0.3973809 Vali Loss: 0.2116769 Test Loss: 0.2712686
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 7.398224353790283
Epoch: 47, Steps: 61 | Train Loss: 0.3970084 Vali Loss: 0.2121034 Test Loss: 0.2712424
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 6.927201271057129
Epoch: 48, Steps: 61 | Train Loss: 0.3973125 Vali Loss: 0.2110094 Test Loss: 0.2712973
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 7.020942449569702
Epoch: 49, Steps: 61 | Train Loss: 0.3960112 Vali Loss: 0.2112252 Test Loss: 0.2713004
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 7.142189025878906
Epoch: 50, Steps: 61 | Train Loss: 0.3970936 Vali Loss: 0.2103286 Test Loss: 0.2713129
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 6.867494583129883
Epoch: 51, Steps: 61 | Train Loss: 0.3974031 Vali Loss: 0.2110581 Test Loss: 0.2712468
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 6.864550590515137
Epoch: 52, Steps: 61 | Train Loss: 0.3966906 Vali Loss: 0.2111328 Test Loss: 0.2712557
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 7.234407424926758
Epoch: 53, Steps: 61 | Train Loss: 0.3971610 Vali Loss: 0.2112759 Test Loss: 0.2712529
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 7.260622978210449
Epoch: 54, Steps: 61 | Train Loss: 0.3968653 Vali Loss: 0.2109057 Test Loss: 0.2712612
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 7.231428861618042
Epoch: 55, Steps: 61 | Train Loss: 0.3969954 Vali Loss: 0.2116355 Test Loss: 0.2712574
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 7.236811876296997
Epoch: 56, Steps: 61 | Train Loss: 0.3971441 Vali Loss: 0.2118160 Test Loss: 0.2712722
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 6.419548273086548
Epoch: 57, Steps: 61 | Train Loss: 0.3969070 Vali Loss: 0.2104698 Test Loss: 0.2712421
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 6.934683322906494
Epoch: 58, Steps: 61 | Train Loss: 0.3967877 Vali Loss: 0.2116514 Test Loss: 0.2712771
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 7.20068883895874
Epoch: 59, Steps: 61 | Train Loss: 0.3972327 Vali Loss: 0.2115901 Test Loss: 0.2712778
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 4.550043344497681
Epoch: 60, Steps: 61 | Train Loss: 0.3972935 Vali Loss: 0.2112030 Test Loss: 0.2712398
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 6.811803579330444
Epoch: 61, Steps: 61 | Train Loss: 0.3969410 Vali Loss: 0.2110874 Test Loss: 0.2712436
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.2710283398628235, mae:0.3360006511211395, rse:0.419554740190506, corr:[0.2740885  0.27608857 0.2747804  0.27496323 0.2743845  0.27303293
 0.27251637 0.27219895 0.27121657 0.26989698 0.26892886 0.26760012
 0.2658432  0.26449993 0.26391813 0.26359624 0.26294422 0.26242644
 0.26193726 0.2609135  0.25955817 0.2585034  0.25757337 0.25590298
 0.25372595 0.25182635 0.25030673 0.24877332 0.24748076 0.24645284
 0.24523091 0.24381682 0.24245666 0.241251   0.23972322 0.23841691
 0.23770732 0.23677516 0.235389   0.23433144 0.23398761 0.23348995
 0.23276718 0.23211156 0.23122238 0.2297148  0.22845182 0.22741716
 0.22574066 0.22363952 0.22224538 0.22103932 0.21992233 0.21856219
 0.21674213 0.21484388 0.21269603 0.21082227 0.20959882 0.20846568
 0.20758371 0.2074057  0.20761834 0.20745176 0.20683786 0.20708421
 0.2067777  0.20522119 0.20448427 0.20490478 0.20444629 0.20310047
 0.20220502 0.20174082 0.20078243 0.1991005  0.19844158 0.19809182
 0.19763601 0.19697316 0.19721283 0.19723506 0.19674288 0.19659467
 0.19613172 0.19597013 0.19651096 0.1966803  0.19517274 0.19513826
 0.1958756  0.19430691 0.19341803 0.19470277 0.19296879 0.1912156 ]
