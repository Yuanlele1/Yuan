Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_360_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_360_96_FITS_ETTh2_ftM_sl360_ll48_pl96_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8185
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=106, out_features=134, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  12726784.0
params:  14338.0
Trainable parameters:  14338
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.722581148147583
Epoch: 1, Steps: 63 | Train Loss: 0.4929901 Vali Loss: 0.3567639 Test Loss: 0.4249114
Validation loss decreased (inf --> 0.356764).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.1959619522094727
Epoch: 2, Steps: 63 | Train Loss: 0.3883818 Vali Loss: 0.3164064 Test Loss: 0.3860805
Validation loss decreased (0.356764 --> 0.316406).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.2770678997039795
Epoch: 3, Steps: 63 | Train Loss: 0.3294326 Vali Loss: 0.2950377 Test Loss: 0.3668570
Validation loss decreased (0.316406 --> 0.295038).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.4645965099334717
Epoch: 4, Steps: 63 | Train Loss: 0.2926042 Vali Loss: 0.2829910 Test Loss: 0.3567445
Validation loss decreased (0.295038 --> 0.282991).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.697178840637207
Epoch: 5, Steps: 63 | Train Loss: 0.2682983 Vali Loss: 0.2739337 Test Loss: 0.3504630
Validation loss decreased (0.282991 --> 0.273934).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.7461576461791992
Epoch: 6, Steps: 63 | Train Loss: 0.2487807 Vali Loss: 0.2703168 Test Loss: 0.3460590
Validation loss decreased (0.273934 --> 0.270317).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.546658992767334
Epoch: 7, Steps: 63 | Train Loss: 0.2337130 Vali Loss: 0.2638443 Test Loss: 0.3422749
Validation loss decreased (0.270317 --> 0.263844).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.9465382099151611
Epoch: 8, Steps: 63 | Train Loss: 0.2213606 Vali Loss: 0.2615506 Test Loss: 0.3388514
Validation loss decreased (0.263844 --> 0.261551).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.6176023483276367
Epoch: 9, Steps: 63 | Train Loss: 0.2097547 Vali Loss: 0.2602138 Test Loss: 0.3361669
Validation loss decreased (0.261551 --> 0.260214).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.6718215942382812
Epoch: 10, Steps: 63 | Train Loss: 0.2014735 Vali Loss: 0.2576031 Test Loss: 0.3334271
Validation loss decreased (0.260214 --> 0.257603).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.6660730838775635
Epoch: 11, Steps: 63 | Train Loss: 0.1932185 Vali Loss: 0.2554716 Test Loss: 0.3309142
Validation loss decreased (0.257603 --> 0.255472).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.812234878540039
Epoch: 12, Steps: 63 | Train Loss: 0.1857447 Vali Loss: 0.2529256 Test Loss: 0.3283772
Validation loss decreased (0.255472 --> 0.252926).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.128408908843994
Epoch: 13, Steps: 63 | Train Loss: 0.1799214 Vali Loss: 0.2507051 Test Loss: 0.3259190
Validation loss decreased (0.252926 --> 0.250705).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.5657873153686523
Epoch: 14, Steps: 63 | Train Loss: 0.1740382 Vali Loss: 0.2498528 Test Loss: 0.3237568
Validation loss decreased (0.250705 --> 0.249853).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.8264586925506592
Epoch: 15, Steps: 63 | Train Loss: 0.1693756 Vali Loss: 0.2485432 Test Loss: 0.3219369
Validation loss decreased (0.249853 --> 0.248543).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.3228192329406738
Epoch: 16, Steps: 63 | Train Loss: 0.1646520 Vali Loss: 0.2464915 Test Loss: 0.3200493
Validation loss decreased (0.248543 --> 0.246492).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.401479959487915
Epoch: 17, Steps: 63 | Train Loss: 0.1609269 Vali Loss: 0.2442193 Test Loss: 0.3183530
Validation loss decreased (0.246492 --> 0.244219).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.6935417652130127
Epoch: 18, Steps: 63 | Train Loss: 0.1573783 Vali Loss: 0.2431977 Test Loss: 0.3166361
Validation loss decreased (0.244219 --> 0.243198).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.6084859371185303
Epoch: 19, Steps: 63 | Train Loss: 0.1532976 Vali Loss: 0.2438906 Test Loss: 0.3150832
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.751659870147705
Epoch: 20, Steps: 63 | Train Loss: 0.1508226 Vali Loss: 0.2416328 Test Loss: 0.3135776
Validation loss decreased (0.243198 --> 0.241633).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.5238947868347168
Epoch: 21, Steps: 63 | Train Loss: 0.1485106 Vali Loss: 0.2411374 Test Loss: 0.3122470
Validation loss decreased (0.241633 --> 0.241137).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.0591371059417725
Epoch: 22, Steps: 63 | Train Loss: 0.1457520 Vali Loss: 0.2404208 Test Loss: 0.3111733
Validation loss decreased (0.241137 --> 0.240421).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.0354950428009033
Epoch: 23, Steps: 63 | Train Loss: 0.1433858 Vali Loss: 0.2389283 Test Loss: 0.3099113
Validation loss decreased (0.240421 --> 0.238928).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.30092191696167
Epoch: 24, Steps: 63 | Train Loss: 0.1415529 Vali Loss: 0.2391446 Test Loss: 0.3087043
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.37056303024292
Epoch: 25, Steps: 63 | Train Loss: 0.1392359 Vali Loss: 0.2371387 Test Loss: 0.3077104
Validation loss decreased (0.238928 --> 0.237139).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.1975843906402588
Epoch: 26, Steps: 63 | Train Loss: 0.1373910 Vali Loss: 0.2375826 Test Loss: 0.3067009
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.1619353294372559
Epoch: 27, Steps: 63 | Train Loss: 0.1362114 Vali Loss: 0.2361089 Test Loss: 0.3057813
Validation loss decreased (0.237139 --> 0.236109).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.6617403030395508
Epoch: 28, Steps: 63 | Train Loss: 0.1348979 Vali Loss: 0.2350640 Test Loss: 0.3049684
Validation loss decreased (0.236109 --> 0.235064).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.8632237911224365
Epoch: 29, Steps: 63 | Train Loss: 0.1332548 Vali Loss: 0.2360690 Test Loss: 0.3042364
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.3739352226257324
Epoch: 30, Steps: 63 | Train Loss: 0.1321767 Vali Loss: 0.2350007 Test Loss: 0.3034445
Validation loss decreased (0.235064 --> 0.235001).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.489971399307251
Epoch: 31, Steps: 63 | Train Loss: 0.1308641 Vali Loss: 0.2344648 Test Loss: 0.3027252
Validation loss decreased (0.235001 --> 0.234465).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.5372769832611084
Epoch: 32, Steps: 63 | Train Loss: 0.1299737 Vali Loss: 0.2339676 Test Loss: 0.3020180
Validation loss decreased (0.234465 --> 0.233968).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.905151605606079
Epoch: 33, Steps: 63 | Train Loss: 0.1288946 Vali Loss: 0.2335924 Test Loss: 0.3013361
Validation loss decreased (0.233968 --> 0.233592).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.8486578464508057
Epoch: 34, Steps: 63 | Train Loss: 0.1280114 Vali Loss: 0.2335277 Test Loss: 0.3007364
Validation loss decreased (0.233592 --> 0.233528).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.547957420349121
Epoch: 35, Steps: 63 | Train Loss: 0.1263603 Vali Loss: 0.2327039 Test Loss: 0.3002087
Validation loss decreased (0.233528 --> 0.232704).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.3305015563964844
Epoch: 36, Steps: 63 | Train Loss: 0.1253152 Vali Loss: 0.2319750 Test Loss: 0.2997322
Validation loss decreased (0.232704 --> 0.231975).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.283195972442627
Epoch: 37, Steps: 63 | Train Loss: 0.1252048 Vali Loss: 0.2323535 Test Loss: 0.2992204
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.5730326175689697
Epoch: 38, Steps: 63 | Train Loss: 0.1244357 Vali Loss: 0.2316112 Test Loss: 0.2987580
Validation loss decreased (0.231975 --> 0.231611).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.1652419567108154
Epoch: 39, Steps: 63 | Train Loss: 0.1238932 Vali Loss: 0.2315516 Test Loss: 0.2984070
Validation loss decreased (0.231611 --> 0.231552).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.4650487899780273
Epoch: 40, Steps: 63 | Train Loss: 0.1233384 Vali Loss: 0.2315150 Test Loss: 0.2979308
Validation loss decreased (0.231552 --> 0.231515).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.5645289421081543
Epoch: 41, Steps: 63 | Train Loss: 0.1225072 Vali Loss: 0.2304973 Test Loss: 0.2975543
Validation loss decreased (0.231515 --> 0.230497).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.471480369567871
Epoch: 42, Steps: 63 | Train Loss: 0.1224447 Vali Loss: 0.2307503 Test Loss: 0.2970820
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.6501121520996094
Epoch: 43, Steps: 63 | Train Loss: 0.1211056 Vali Loss: 0.2303573 Test Loss: 0.2967612
Validation loss decreased (0.230497 --> 0.230357).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.2983355522155762
Epoch: 44, Steps: 63 | Train Loss: 0.1207916 Vali Loss: 0.2298733 Test Loss: 0.2964944
Validation loss decreased (0.230357 --> 0.229873).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.5591816902160645
Epoch: 45, Steps: 63 | Train Loss: 0.1204070 Vali Loss: 0.2301164 Test Loss: 0.2961733
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.3459246158599854
Epoch: 46, Steps: 63 | Train Loss: 0.1202440 Vali Loss: 0.2294771 Test Loss: 0.2958697
Validation loss decreased (0.229873 --> 0.229477).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.2367563247680664
Epoch: 47, Steps: 63 | Train Loss: 0.1195805 Vali Loss: 0.2294528 Test Loss: 0.2955996
Validation loss decreased (0.229477 --> 0.229453).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.3023736476898193
Epoch: 48, Steps: 63 | Train Loss: 0.1193286 Vali Loss: 0.2293457 Test Loss: 0.2953263
Validation loss decreased (0.229453 --> 0.229346).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.6990280151367188
Epoch: 49, Steps: 63 | Train Loss: 0.1186796 Vali Loss: 0.2292589 Test Loss: 0.2950495
Validation loss decreased (0.229346 --> 0.229259).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.5200085639953613
Epoch: 50, Steps: 63 | Train Loss: 0.1176977 Vali Loss: 0.2293524 Test Loss: 0.2948283
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.2570149898529053
Epoch: 51, Steps: 63 | Train Loss: 0.1183570 Vali Loss: 0.2293770 Test Loss: 0.2945916
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.519622564315796
Epoch: 52, Steps: 63 | Train Loss: 0.1183115 Vali Loss: 0.2295702 Test Loss: 0.2943557
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.9970929622650146
Epoch: 53, Steps: 63 | Train Loss: 0.1178131 Vali Loss: 0.2280369 Test Loss: 0.2941724
Validation loss decreased (0.229259 --> 0.228037).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.9518365859985352
Epoch: 54, Steps: 63 | Train Loss: 0.1179264 Vali Loss: 0.2280327 Test Loss: 0.2939396
Validation loss decreased (0.228037 --> 0.228033).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.4509100914001465
Epoch: 55, Steps: 63 | Train Loss: 0.1168279 Vali Loss: 0.2275980 Test Loss: 0.2937889
Validation loss decreased (0.228033 --> 0.227598).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.6100163459777832
Epoch: 56, Steps: 63 | Train Loss: 0.1171223 Vali Loss: 0.2277137 Test Loss: 0.2936058
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.7804200649261475
Epoch: 57, Steps: 63 | Train Loss: 0.1168383 Vali Loss: 0.2280622 Test Loss: 0.2934346
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.4845364093780518
Epoch: 58, Steps: 63 | Train Loss: 0.1164192 Vali Loss: 0.2286875 Test Loss: 0.2932759
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.3335275650024414
Epoch: 59, Steps: 63 | Train Loss: 0.1165162 Vali Loss: 0.2289757 Test Loss: 0.2931321
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.7977302074432373
Epoch: 60, Steps: 63 | Train Loss: 0.1162023 Vali Loss: 0.2281261 Test Loss: 0.2929765
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.7301383018493652
Epoch: 61, Steps: 63 | Train Loss: 0.1161795 Vali Loss: 0.2271640 Test Loss: 0.2928461
Validation loss decreased (0.227598 --> 0.227164).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.6357166767120361
Epoch: 62, Steps: 63 | Train Loss: 0.1160480 Vali Loss: 0.2275330 Test Loss: 0.2926922
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.4957590103149414
Epoch: 63, Steps: 63 | Train Loss: 0.1154380 Vali Loss: 0.2274585 Test Loss: 0.2925985
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.620116949081421
Epoch: 64, Steps: 63 | Train Loss: 0.1157197 Vali Loss: 0.2274714 Test Loss: 0.2924497
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.7809491157531738
Epoch: 65, Steps: 63 | Train Loss: 0.1153034 Vali Loss: 0.2282095 Test Loss: 0.2923572
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.076136827468872
Epoch: 66, Steps: 63 | Train Loss: 0.1155955 Vali Loss: 0.2267781 Test Loss: 0.2922590
Validation loss decreased (0.227164 --> 0.226778).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.6236157417297363
Epoch: 67, Steps: 63 | Train Loss: 0.1146435 Vali Loss: 0.2265236 Test Loss: 0.2921450
Validation loss decreased (0.226778 --> 0.226524).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.731896162033081
Epoch: 68, Steps: 63 | Train Loss: 0.1151650 Vali Loss: 0.2281835 Test Loss: 0.2920549
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.5541942119598389
Epoch: 69, Steps: 63 | Train Loss: 0.1146318 Vali Loss: 0.2272018 Test Loss: 0.2919556
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.4238848686218262
Epoch: 70, Steps: 63 | Train Loss: 0.1144510 Vali Loss: 0.2268127 Test Loss: 0.2918627
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.4251575469970703
Epoch: 71, Steps: 63 | Train Loss: 0.1149440 Vali Loss: 0.2271298 Test Loss: 0.2917783
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.8197767734527588
Epoch: 72, Steps: 63 | Train Loss: 0.1148450 Vali Loss: 0.2274014 Test Loss: 0.2916908
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.3618667125701904
Epoch: 73, Steps: 63 | Train Loss: 0.1144469 Vali Loss: 0.2281236 Test Loss: 0.2916252
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.4145407676696777
Epoch: 74, Steps: 63 | Train Loss: 0.1138924 Vali Loss: 0.2269624 Test Loss: 0.2915547
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.7271575927734375
Epoch: 75, Steps: 63 | Train Loss: 0.1143352 Vali Loss: 0.2263469 Test Loss: 0.2914848
Validation loss decreased (0.226524 --> 0.226347).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.588475227355957
Epoch: 76, Steps: 63 | Train Loss: 0.1139209 Vali Loss: 0.2277078 Test Loss: 0.2914211
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.7232799530029297
Epoch: 77, Steps: 63 | Train Loss: 0.1132206 Vali Loss: 0.2261665 Test Loss: 0.2913547
Validation loss decreased (0.226347 --> 0.226166).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.4979462623596191
Epoch: 78, Steps: 63 | Train Loss: 0.1139240 Vali Loss: 0.2268662 Test Loss: 0.2912934
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.4294543266296387
Epoch: 79, Steps: 63 | Train Loss: 0.1141723 Vali Loss: 0.2271840 Test Loss: 0.2912327
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.3573534488677979
Epoch: 80, Steps: 63 | Train Loss: 0.1134043 Vali Loss: 0.2278271 Test Loss: 0.2911857
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.9824843406677246
Epoch: 81, Steps: 63 | Train Loss: 0.1137947 Vali Loss: 0.2269271 Test Loss: 0.2911350
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.620633602142334
Epoch: 82, Steps: 63 | Train Loss: 0.1131602 Vali Loss: 0.2265851 Test Loss: 0.2910973
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.5950956344604492
Epoch: 83, Steps: 63 | Train Loss: 0.1135956 Vali Loss: 0.2272867 Test Loss: 0.2910388
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.6511178016662598
Epoch: 84, Steps: 63 | Train Loss: 0.1137568 Vali Loss: 0.2266638 Test Loss: 0.2910011
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.5513010025024414
Epoch: 85, Steps: 63 | Train Loss: 0.1134598 Vali Loss: 0.2269895 Test Loss: 0.2909603
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.4812819957733154
Epoch: 86, Steps: 63 | Train Loss: 0.1137011 Vali Loss: 0.2263556 Test Loss: 0.2909166
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.6583173274993896
Epoch: 87, Steps: 63 | Train Loss: 0.1134280 Vali Loss: 0.2269602 Test Loss: 0.2908764
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.4344191551208496
Epoch: 88, Steps: 63 | Train Loss: 0.1130838 Vali Loss: 0.2265100 Test Loss: 0.2908417
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.2550406455993652
Epoch: 89, Steps: 63 | Train Loss: 0.1130958 Vali Loss: 0.2265202 Test Loss: 0.2908073
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.621699333190918
Epoch: 90, Steps: 63 | Train Loss: 0.1135657 Vali Loss: 0.2262699 Test Loss: 0.2907729
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.038660764694214
Epoch: 91, Steps: 63 | Train Loss: 0.1132990 Vali Loss: 0.2266553 Test Loss: 0.2907372
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.749692678451538
Epoch: 92, Steps: 63 | Train Loss: 0.1132793 Vali Loss: 0.2269957 Test Loss: 0.2907075
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.7457959651947021
Epoch: 93, Steps: 63 | Train Loss: 0.1132365 Vali Loss: 0.2262047 Test Loss: 0.2906779
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.6392083168029785
Epoch: 94, Steps: 63 | Train Loss: 0.1130005 Vali Loss: 0.2263995 Test Loss: 0.2906472
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.6128675937652588
Epoch: 95, Steps: 63 | Train Loss: 0.1126560 Vali Loss: 0.2260215 Test Loss: 0.2906231
Validation loss decreased (0.226166 --> 0.226021).  Saving model ...
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.7322535514831543
Epoch: 96, Steps: 63 | Train Loss: 0.1133258 Vali Loss: 0.2258442 Test Loss: 0.2905965
Validation loss decreased (0.226021 --> 0.225844).  Saving model ...
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.9802343845367432
Epoch: 97, Steps: 63 | Train Loss: 0.1128972 Vali Loss: 0.2261275 Test Loss: 0.2905762
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.7670724391937256
Epoch: 98, Steps: 63 | Train Loss: 0.1127381 Vali Loss: 0.2266854 Test Loss: 0.2905518
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.7498679161071777
Epoch: 99, Steps: 63 | Train Loss: 0.1123481 Vali Loss: 0.2272354 Test Loss: 0.2905321
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.8601315021514893
Epoch: 100, Steps: 63 | Train Loss: 0.1131591 Vali Loss: 0.2262284 Test Loss: 0.2905105
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8185
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=106, out_features=134, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  12726784.0
params:  14338.0
Trainable parameters:  14338
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.749678611755371
Epoch: 1, Steps: 63 | Train Loss: 0.4119171 Vali Loss: 0.2164163 Test Loss: 0.2798300
Validation loss decreased (inf --> 0.216416).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.5183110237121582
Epoch: 2, Steps: 63 | Train Loss: 0.4062234 Vali Loss: 0.2143732 Test Loss: 0.2772254
Validation loss decreased (0.216416 --> 0.214373).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.72408127784729
Epoch: 3, Steps: 63 | Train Loss: 0.4016620 Vali Loss: 0.2129991 Test Loss: 0.2762474
Validation loss decreased (0.214373 --> 0.212999).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.3508176803588867
Epoch: 4, Steps: 63 | Train Loss: 0.4007494 Vali Loss: 0.2125344 Test Loss: 0.2756427
Validation loss decreased (0.212999 --> 0.212534).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.7123692035675049
Epoch: 5, Steps: 63 | Train Loss: 0.3980797 Vali Loss: 0.2122104 Test Loss: 0.2755167
Validation loss decreased (0.212534 --> 0.212210).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.8100340366363525
Epoch: 6, Steps: 63 | Train Loss: 0.3982829 Vali Loss: 0.2119420 Test Loss: 0.2752272
Validation loss decreased (0.212210 --> 0.211942).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.963735580444336
Epoch: 7, Steps: 63 | Train Loss: 0.3997501 Vali Loss: 0.2118021 Test Loss: 0.2748863
Validation loss decreased (0.211942 --> 0.211802).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.6565263271331787
Epoch: 8, Steps: 63 | Train Loss: 0.3978084 Vali Loss: 0.2119408 Test Loss: 0.2747358
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.6411375999450684
Epoch: 9, Steps: 63 | Train Loss: 0.3973835 Vali Loss: 0.2100182 Test Loss: 0.2747571
Validation loss decreased (0.211802 --> 0.210018).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.213223934173584
Epoch: 10, Steps: 63 | Train Loss: 0.3979565 Vali Loss: 0.2106198 Test Loss: 0.2745062
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.445453405380249
Epoch: 11, Steps: 63 | Train Loss: 0.3954699 Vali Loss: 0.2104845 Test Loss: 0.2744644
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.6270842552185059
Epoch: 12, Steps: 63 | Train Loss: 0.3978787 Vali Loss: 0.2094029 Test Loss: 0.2744485
Validation loss decreased (0.210018 --> 0.209403).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.5790469646453857
Epoch: 13, Steps: 63 | Train Loss: 0.3952262 Vali Loss: 0.2113015 Test Loss: 0.2741390
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.153444528579712
Epoch: 14, Steps: 63 | Train Loss: 0.3988774 Vali Loss: 0.2108693 Test Loss: 0.2740257
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.6161797046661377
Epoch: 15, Steps: 63 | Train Loss: 0.3954583 Vali Loss: 0.2106891 Test Loss: 0.2741413
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.651099443435669
Epoch: 16, Steps: 63 | Train Loss: 0.3975989 Vali Loss: 0.2107296 Test Loss: 0.2742224
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.4569551944732666
Epoch: 17, Steps: 63 | Train Loss: 0.3962918 Vali Loss: 0.2102294 Test Loss: 0.2739017
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.613447666168213
Epoch: 18, Steps: 63 | Train Loss: 0.3954521 Vali Loss: 0.2093102 Test Loss: 0.2742075
Validation loss decreased (0.209403 --> 0.209310).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.1961371898651123
Epoch: 19, Steps: 63 | Train Loss: 0.3973775 Vali Loss: 0.2083410 Test Loss: 0.2741030
Validation loss decreased (0.209310 --> 0.208341).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.3921196460723877
Epoch: 20, Steps: 63 | Train Loss: 0.3964460 Vali Loss: 0.2088195 Test Loss: 0.2739974
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.5325896739959717
Epoch: 21, Steps: 63 | Train Loss: 0.3944495 Vali Loss: 0.2094901 Test Loss: 0.2739107
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.8904485702514648
Epoch: 22, Steps: 63 | Train Loss: 0.3953106 Vali Loss: 0.2095576 Test Loss: 0.2739366
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.63712739944458
Epoch: 23, Steps: 63 | Train Loss: 0.3921945 Vali Loss: 0.2092915 Test Loss: 0.2740450
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.5864543914794922
Epoch: 24, Steps: 63 | Train Loss: 0.3955051 Vali Loss: 0.2087867 Test Loss: 0.2738783
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.034597635269165
Epoch: 25, Steps: 63 | Train Loss: 0.3943292 Vali Loss: 0.2090061 Test Loss: 0.2738010
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.5593140125274658
Epoch: 26, Steps: 63 | Train Loss: 0.3935200 Vali Loss: 0.2104357 Test Loss: 0.2738399
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.3978798389434814
Epoch: 27, Steps: 63 | Train Loss: 0.3948215 Vali Loss: 0.2092843 Test Loss: 0.2738632
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.61539888381958
Epoch: 28, Steps: 63 | Train Loss: 0.3943426 Vali Loss: 0.2097286 Test Loss: 0.2738619
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.7956547737121582
Epoch: 29, Steps: 63 | Train Loss: 0.3963228 Vali Loss: 0.2097016 Test Loss: 0.2737163
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.0106427669525146
Epoch: 30, Steps: 63 | Train Loss: 0.3960834 Vali Loss: 0.2087951 Test Loss: 0.2737339
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.5401999950408936
Epoch: 31, Steps: 63 | Train Loss: 0.3955197 Vali Loss: 0.2095406 Test Loss: 0.2737573
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.7142274379730225
Epoch: 32, Steps: 63 | Train Loss: 0.3958934 Vali Loss: 0.2102312 Test Loss: 0.2736874
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.2768356800079346
Epoch: 33, Steps: 63 | Train Loss: 0.3957603 Vali Loss: 0.2100330 Test Loss: 0.2737086
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.3554978370666504
Epoch: 34, Steps: 63 | Train Loss: 0.3945259 Vali Loss: 0.2086633 Test Loss: 0.2736584
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.1658143997192383
Epoch: 35, Steps: 63 | Train Loss: 0.3947345 Vali Loss: 0.2088528 Test Loss: 0.2737375
EarlyStopping counter: 16 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.2671027183532715
Epoch: 36, Steps: 63 | Train Loss: 0.3934781 Vali Loss: 0.2096801 Test Loss: 0.2737246
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.4695158004760742
Epoch: 37, Steps: 63 | Train Loss: 0.3931240 Vali Loss: 0.2103962 Test Loss: 0.2737326
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.5509390830993652
Epoch: 38, Steps: 63 | Train Loss: 0.3945528 Vali Loss: 0.2089459 Test Loss: 0.2737130
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.6012310981750488
Epoch: 39, Steps: 63 | Train Loss: 0.3932998 Vali Loss: 0.2095698 Test Loss: 0.2736888
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_360_96_FITS_ETTh2_ftM_sl360_ll48_pl96_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.27388259768486023, mae:0.33675798773765564, rse:0.4217582046985626, corr:[0.275947   0.2781487  0.27568567 0.27540934 0.2740342  0.2720561
 0.27136004 0.27043542 0.26893535 0.26757184 0.26636815 0.26477155
 0.26323977 0.26216596 0.26153412 0.2612244  0.26085374 0.26044858
 0.25975078 0.25886917 0.25776988 0.2564697  0.2551304  0.25349936
 0.25133398 0.24892068 0.24718659 0.24610257 0.24489105 0.2434521
 0.24252132 0.24135755 0.23911825 0.23748998 0.23703998 0.2361455
 0.23426992 0.23315586 0.23279601 0.2316025  0.23081605 0.23105045
 0.23056585 0.22916782 0.2284341  0.22796778 0.22689119 0.22522327
 0.22343364 0.2214464  0.21989858 0.21913701 0.21823838 0.21656112
 0.21476786 0.21324179 0.21172261 0.2098096  0.20831305 0.2072049
 0.20682795 0.20706998 0.20726964 0.20690203 0.20694579 0.20702107
 0.20629925 0.20555423 0.20561944 0.20505707 0.20403351 0.2035976
 0.2028992  0.20170178 0.2013875  0.20090923 0.19923404 0.1981595
 0.19848022 0.19764437 0.19659603 0.19693533 0.19757186 0.19624649
 0.19521292 0.19575216 0.19557582 0.1946583  0.19437486 0.1935483
 0.19161768 0.19115274 0.19065554 0.18705873 0.18764475 0.18588758]
