Args in experiment:
Namespace(H_order=2, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_180_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_180_192_FITS_ETTh2_ftM_sl180_ll48_pl192_H2_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8269
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=26, out_features=53, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1234688.0
params:  1431.0
Trainable parameters:  1431
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.6430342197418213
Epoch: 1, Steps: 64 | Train Loss: 0.7012216 Vali Loss: 0.3453456 Test Loss: 0.4760095
Validation loss decreased (inf --> 0.345346).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.8368210792541504
Epoch: 2, Steps: 64 | Train Loss: 0.6113381 Vali Loss: 0.3146253 Test Loss: 0.4353209
Validation loss decreased (0.345346 --> 0.314625).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.4710023403167725
Epoch: 3, Steps: 64 | Train Loss: 0.5735114 Vali Loss: 0.3005739 Test Loss: 0.4172695
Validation loss decreased (0.314625 --> 0.300574).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.0464398860931396
Epoch: 4, Steps: 64 | Train Loss: 0.5569519 Vali Loss: 0.2935785 Test Loss: 0.4083920
Validation loss decreased (0.300574 --> 0.293578).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.5968585014343262
Epoch: 5, Steps: 64 | Train Loss: 0.5463744 Vali Loss: 0.2895200 Test Loss: 0.4032469
Validation loss decreased (0.293578 --> 0.289520).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.7443628311157227
Epoch: 6, Steps: 64 | Train Loss: 0.5422882 Vali Loss: 0.2868966 Test Loss: 0.4000058
Validation loss decreased (0.289520 --> 0.286897).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.4686434268951416
Epoch: 7, Steps: 64 | Train Loss: 0.5379236 Vali Loss: 0.2849213 Test Loss: 0.3977473
Validation loss decreased (0.286897 --> 0.284921).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.181884527206421
Epoch: 8, Steps: 64 | Train Loss: 0.5372430 Vali Loss: 0.2835646 Test Loss: 0.3959122
Validation loss decreased (0.284921 --> 0.283565).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.1342194080352783
Epoch: 9, Steps: 64 | Train Loss: 0.5341909 Vali Loss: 0.2821976 Test Loss: 0.3945948
Validation loss decreased (0.283565 --> 0.282198).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.275885820388794
Epoch: 10, Steps: 64 | Train Loss: 0.5307068 Vali Loss: 0.2814382 Test Loss: 0.3933595
Validation loss decreased (0.282198 --> 0.281438).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.668806552886963
Epoch: 11, Steps: 64 | Train Loss: 0.5310465 Vali Loss: 0.2808183 Test Loss: 0.3923403
Validation loss decreased (0.281438 --> 0.280818).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.9395802021026611
Epoch: 12, Steps: 64 | Train Loss: 0.5291864 Vali Loss: 0.2801023 Test Loss: 0.3914993
Validation loss decreased (0.280818 --> 0.280102).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.0132522583007812
Epoch: 13, Steps: 64 | Train Loss: 0.5276860 Vali Loss: 0.2796615 Test Loss: 0.3907413
Validation loss decreased (0.280102 --> 0.279661).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.1078004837036133
Epoch: 14, Steps: 64 | Train Loss: 0.5278855 Vali Loss: 0.2791685 Test Loss: 0.3900107
Validation loss decreased (0.279661 --> 0.279168).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.029625177383423
Epoch: 15, Steps: 64 | Train Loss: 0.5263382 Vali Loss: 0.2787744 Test Loss: 0.3895015
Validation loss decreased (0.279168 --> 0.278774).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.6002347469329834
Epoch: 16, Steps: 64 | Train Loss: 0.5283614 Vali Loss: 0.2784320 Test Loss: 0.3889565
Validation loss decreased (0.278774 --> 0.278432).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.306180238723755
Epoch: 17, Steps: 64 | Train Loss: 0.5235575 Vali Loss: 0.2781755 Test Loss: 0.3884568
Validation loss decreased (0.278432 --> 0.278176).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.669814109802246
Epoch: 18, Steps: 64 | Train Loss: 0.5245211 Vali Loss: 0.2779197 Test Loss: 0.3880013
Validation loss decreased (0.278176 --> 0.277920).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.6982357501983643
Epoch: 19, Steps: 64 | Train Loss: 0.5234488 Vali Loss: 0.2776083 Test Loss: 0.3877055
Validation loss decreased (0.277920 --> 0.277608).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.8484175205230713
Epoch: 20, Steps: 64 | Train Loss: 0.5235311 Vali Loss: 0.2773517 Test Loss: 0.3872695
Validation loss decreased (0.277608 --> 0.277352).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.2501888275146484
Epoch: 21, Steps: 64 | Train Loss: 0.5240711 Vali Loss: 0.2771600 Test Loss: 0.3869493
Validation loss decreased (0.277352 --> 0.277160).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.964385986328125
Epoch: 22, Steps: 64 | Train Loss: 0.5246352 Vali Loss: 0.2770057 Test Loss: 0.3866871
Validation loss decreased (0.277160 --> 0.277006).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.340879201889038
Epoch: 23, Steps: 64 | Train Loss: 0.5235724 Vali Loss: 0.2766395 Test Loss: 0.3863873
Validation loss decreased (0.277006 --> 0.276640).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.7423534393310547
Epoch: 24, Steps: 64 | Train Loss: 0.5203193 Vali Loss: 0.2767144 Test Loss: 0.3861749
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.539512872695923
Epoch: 25, Steps: 64 | Train Loss: 0.5219168 Vali Loss: 0.2765519 Test Loss: 0.3859468
Validation loss decreased (0.276640 --> 0.276552).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.0106375217437744
Epoch: 26, Steps: 64 | Train Loss: 0.5210415 Vali Loss: 0.2764628 Test Loss: 0.3857131
Validation loss decreased (0.276552 --> 0.276463).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.155545473098755
Epoch: 27, Steps: 64 | Train Loss: 0.5204785 Vali Loss: 0.2764190 Test Loss: 0.3855308
Validation loss decreased (0.276463 --> 0.276419).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.394273042678833
Epoch: 28, Steps: 64 | Train Loss: 0.5218308 Vali Loss: 0.2762831 Test Loss: 0.3853586
Validation loss decreased (0.276419 --> 0.276283).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.2575392723083496
Epoch: 29, Steps: 64 | Train Loss: 0.5220220 Vali Loss: 0.2761658 Test Loss: 0.3851817
Validation loss decreased (0.276283 --> 0.276166).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.5290210247039795
Epoch: 30, Steps: 64 | Train Loss: 0.5214628 Vali Loss: 0.2759862 Test Loss: 0.3850536
Validation loss decreased (0.276166 --> 0.275986).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.1216657161712646
Epoch: 31, Steps: 64 | Train Loss: 0.5214287 Vali Loss: 0.2760157 Test Loss: 0.3848651
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.3731420040130615
Epoch: 32, Steps: 64 | Train Loss: 0.5203776 Vali Loss: 0.2758787 Test Loss: 0.3847932
Validation loss decreased (0.275986 --> 0.275879).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.1011693477630615
Epoch: 33, Steps: 64 | Train Loss: 0.5211403 Vali Loss: 0.2757932 Test Loss: 0.3846484
Validation loss decreased (0.275879 --> 0.275793).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.062084197998047
Epoch: 34, Steps: 64 | Train Loss: 0.5190206 Vali Loss: 0.2757911 Test Loss: 0.3845685
Validation loss decreased (0.275793 --> 0.275791).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.2507455348968506
Epoch: 35, Steps: 64 | Train Loss: 0.5210998 Vali Loss: 0.2757453 Test Loss: 0.3844039
Validation loss decreased (0.275791 --> 0.275745).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.9604229927062988
Epoch: 36, Steps: 64 | Train Loss: 0.5209582 Vali Loss: 0.2756768 Test Loss: 0.3843339
Validation loss decreased (0.275745 --> 0.275677).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.198610305786133
Epoch: 37, Steps: 64 | Train Loss: 0.5178095 Vali Loss: 0.2755767 Test Loss: 0.3842364
Validation loss decreased (0.275677 --> 0.275577).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.750288486480713
Epoch: 38, Steps: 64 | Train Loss: 0.5203479 Vali Loss: 0.2755564 Test Loss: 0.3841214
Validation loss decreased (0.275577 --> 0.275556).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.9027600288391113
Epoch: 39, Steps: 64 | Train Loss: 0.5209531 Vali Loss: 0.2755185 Test Loss: 0.3840548
Validation loss decreased (0.275556 --> 0.275518).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.9944241046905518
Epoch: 40, Steps: 64 | Train Loss: 0.5183722 Vali Loss: 0.2753864 Test Loss: 0.3839694
Validation loss decreased (0.275518 --> 0.275386).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.9266939163208008
Epoch: 41, Steps: 64 | Train Loss: 0.5196377 Vali Loss: 0.2753229 Test Loss: 0.3839081
Validation loss decreased (0.275386 --> 0.275323).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.3132143020629883
Epoch: 42, Steps: 64 | Train Loss: 0.5208397 Vali Loss: 0.2754079 Test Loss: 0.3838114
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.8649799823760986
Epoch: 43, Steps: 64 | Train Loss: 0.5190719 Vali Loss: 0.2753910 Test Loss: 0.3837638
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.6058945655822754
Epoch: 44, Steps: 64 | Train Loss: 0.5208929 Vali Loss: 0.2753132 Test Loss: 0.3837019
Validation loss decreased (0.275323 --> 0.275313).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.875605821609497
Epoch: 45, Steps: 64 | Train Loss: 0.5179546 Vali Loss: 0.2753117 Test Loss: 0.3836426
Validation loss decreased (0.275313 --> 0.275312).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.7305891513824463
Epoch: 46, Steps: 64 | Train Loss: 0.5196982 Vali Loss: 0.2752170 Test Loss: 0.3836243
Validation loss decreased (0.275312 --> 0.275217).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.2558934688568115
Epoch: 47, Steps: 64 | Train Loss: 0.5197270 Vali Loss: 0.2752305 Test Loss: 0.3835739
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.8731582164764404
Epoch: 48, Steps: 64 | Train Loss: 0.5188554 Vali Loss: 0.2751791 Test Loss: 0.3835214
Validation loss decreased (0.275217 --> 0.275179).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 3.174642562866211
Epoch: 49, Steps: 64 | Train Loss: 0.5192366 Vali Loss: 0.2748536 Test Loss: 0.3834594
Validation loss decreased (0.275179 --> 0.274854).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 3.344815492630005
Epoch: 50, Steps: 64 | Train Loss: 0.5202803 Vali Loss: 0.2748272 Test Loss: 0.3834208
Validation loss decreased (0.274854 --> 0.274827).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.166151762008667
Epoch: 51, Steps: 64 | Train Loss: 0.5188141 Vali Loss: 0.2751553 Test Loss: 0.3833897
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.9978182315826416
Epoch: 52, Steps: 64 | Train Loss: 0.5197646 Vali Loss: 0.2750471 Test Loss: 0.3833641
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.909356117248535
Epoch: 53, Steps: 64 | Train Loss: 0.5195655 Vali Loss: 0.2750852 Test Loss: 0.3833251
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.642585515975952
Epoch: 54, Steps: 64 | Train Loss: 0.5188209 Vali Loss: 0.2750181 Test Loss: 0.3832915
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.0379321575164795
Epoch: 55, Steps: 64 | Train Loss: 0.5194800 Vali Loss: 0.2750536 Test Loss: 0.3832466
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.8602588176727295
Epoch: 56, Steps: 64 | Train Loss: 0.5181108 Vali Loss: 0.2749187 Test Loss: 0.3832428
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.6446704864501953
Epoch: 57, Steps: 64 | Train Loss: 0.5177192 Vali Loss: 0.2749996 Test Loss: 0.3832047
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.9091286659240723
Epoch: 58, Steps: 64 | Train Loss: 0.5183924 Vali Loss: 0.2750227 Test Loss: 0.3831829
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.4803504943847656
Epoch: 59, Steps: 64 | Train Loss: 0.5204080 Vali Loss: 0.2750263 Test Loss: 0.3831525
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.262455463409424
Epoch: 60, Steps: 64 | Train Loss: 0.5188418 Vali Loss: 0.2749770 Test Loss: 0.3831271
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.9787883758544922
Epoch: 61, Steps: 64 | Train Loss: 0.5172875 Vali Loss: 0.2749245 Test Loss: 0.3831023
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.24002742767334
Epoch: 62, Steps: 64 | Train Loss: 0.5181096 Vali Loss: 0.2749436 Test Loss: 0.3830861
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.407381296157837
Epoch: 63, Steps: 64 | Train Loss: 0.5202994 Vali Loss: 0.2749484 Test Loss: 0.3830577
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.1013753414154053
Epoch: 64, Steps: 64 | Train Loss: 0.5194578 Vali Loss: 0.2749488 Test Loss: 0.3830390
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.389303207397461
Epoch: 65, Steps: 64 | Train Loss: 0.5178316 Vali Loss: 0.2748997 Test Loss: 0.3830236
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.204254388809204
Epoch: 66, Steps: 64 | Train Loss: 0.5183447 Vali Loss: 0.2748921 Test Loss: 0.3830084
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.9957916736602783
Epoch: 67, Steps: 64 | Train Loss: 0.5170453 Vali Loss: 0.2747900 Test Loss: 0.3829954
Validation loss decreased (0.274827 --> 0.274790).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.862635612487793
Epoch: 68, Steps: 64 | Train Loss: 0.5175589 Vali Loss: 0.2748731 Test Loss: 0.3829781
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.7146327495574951
Epoch: 69, Steps: 64 | Train Loss: 0.5187228 Vali Loss: 0.2749243 Test Loss: 0.3829601
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.780573844909668
Epoch: 70, Steps: 64 | Train Loss: 0.5203316 Vali Loss: 0.2748823 Test Loss: 0.3829462
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.6651713848114014
Epoch: 71, Steps: 64 | Train Loss: 0.5192581 Vali Loss: 0.2749109 Test Loss: 0.3829375
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.9569270610809326
Epoch: 72, Steps: 64 | Train Loss: 0.5185703 Vali Loss: 0.2748545 Test Loss: 0.3829308
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.9310333728790283
Epoch: 73, Steps: 64 | Train Loss: 0.5190567 Vali Loss: 0.2748525 Test Loss: 0.3829158
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.9022295475006104
Epoch: 74, Steps: 64 | Train Loss: 0.5199183 Vali Loss: 0.2748792 Test Loss: 0.3829018
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.043937921524048
Epoch: 75, Steps: 64 | Train Loss: 0.5170156 Vali Loss: 0.2748833 Test Loss: 0.3828948
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.1038310527801514
Epoch: 76, Steps: 64 | Train Loss: 0.5161319 Vali Loss: 0.2748496 Test Loss: 0.3828830
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.7952935695648193
Epoch: 77, Steps: 64 | Train Loss: 0.5169221 Vali Loss: 0.2746029 Test Loss: 0.3828709
Validation loss decreased (0.274790 --> 0.274603).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.8642871379852295
Epoch: 78, Steps: 64 | Train Loss: 0.5177243 Vali Loss: 0.2748168 Test Loss: 0.3828605
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.91245698928833
Epoch: 79, Steps: 64 | Train Loss: 0.5188434 Vali Loss: 0.2748618 Test Loss: 0.3828520
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.965799331665039
Epoch: 80, Steps: 64 | Train Loss: 0.5192377 Vali Loss: 0.2746965 Test Loss: 0.3828439
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 3.007634162902832
Epoch: 81, Steps: 64 | Train Loss: 0.5199571 Vali Loss: 0.2745157 Test Loss: 0.3828368
Validation loss decreased (0.274603 --> 0.274516).  Saving model ...
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 2.3336760997772217
Epoch: 82, Steps: 64 | Train Loss: 0.5185297 Vali Loss: 0.2748503 Test Loss: 0.3828279
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.7514548301696777
Epoch: 83, Steps: 64 | Train Loss: 0.5161501 Vali Loss: 0.2747843 Test Loss: 0.3828207
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.8046340942382812
Epoch: 84, Steps: 64 | Train Loss: 0.5189863 Vali Loss: 0.2748225 Test Loss: 0.3828149
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.9834227561950684
Epoch: 85, Steps: 64 | Train Loss: 0.5194675 Vali Loss: 0.2748038 Test Loss: 0.3828060
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 2.281094789505005
Epoch: 86, Steps: 64 | Train Loss: 0.5187830 Vali Loss: 0.2747447 Test Loss: 0.3828034
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 2.2726457118988037
Epoch: 87, Steps: 64 | Train Loss: 0.5199161 Vali Loss: 0.2748040 Test Loss: 0.3827963
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 2.0588855743408203
Epoch: 88, Steps: 64 | Train Loss: 0.5179942 Vali Loss: 0.2748224 Test Loss: 0.3827901
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.063666343688965
Epoch: 89, Steps: 64 | Train Loss: 0.5179870 Vali Loss: 0.2745022 Test Loss: 0.3827835
Validation loss decreased (0.274516 --> 0.274502).  Saving model ...
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 2.536054849624634
Epoch: 90, Steps: 64 | Train Loss: 0.5198175 Vali Loss: 0.2748018 Test Loss: 0.3827786
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.7686498165130615
Epoch: 91, Steps: 64 | Train Loss: 0.5198499 Vali Loss: 0.2748143 Test Loss: 0.3827758
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 3.1616790294647217
Epoch: 92, Steps: 64 | Train Loss: 0.5174558 Vali Loss: 0.2748184 Test Loss: 0.3827691
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 3.2924206256866455
Epoch: 93, Steps: 64 | Train Loss: 0.5178271 Vali Loss: 0.2747925 Test Loss: 0.3827673
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 3.7643933296203613
Epoch: 94, Steps: 64 | Train Loss: 0.5184180 Vali Loss: 0.2747491 Test Loss: 0.3827629
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.8583378791809082
Epoch: 95, Steps: 64 | Train Loss: 0.5172930 Vali Loss: 0.2744936 Test Loss: 0.3827585
Validation loss decreased (0.274502 --> 0.274494).  Saving model ...
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 2.1062729358673096
Epoch: 96, Steps: 64 | Train Loss: 0.5192006 Vali Loss: 0.2747007 Test Loss: 0.3827560
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 2.827465772628784
Epoch: 97, Steps: 64 | Train Loss: 0.5195085 Vali Loss: 0.2746916 Test Loss: 0.3827526
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 2.588836669921875
Epoch: 98, Steps: 64 | Train Loss: 0.5182284 Vali Loss: 0.2748013 Test Loss: 0.3827501
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.8658161163330078
Epoch: 99, Steps: 64 | Train Loss: 0.5181888 Vali Loss: 0.2747491 Test Loss: 0.3827471
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.8419311046600342
Epoch: 100, Steps: 64 | Train Loss: 0.5186298 Vali Loss: 0.2748037 Test Loss: 0.3827436
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.1160680107021042e-06
>>>>>>>testing : ETTh2_180_192_FITS_ETTh2_ftM_sl180_ll48_pl192_H2_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.36199456453323364, mae:0.38862448930740356, rse:0.48249396681785583, corr:[0.2646405  0.26868388 0.2693784  0.26762927 0.26574755 0.26483306
 0.2645628  0.26407194 0.2630058  0.2612662  0.25947848 0.2579022
 0.25684443 0.25596827 0.2550919  0.25417292 0.2532851  0.25242788
 0.25154394 0.25060174 0.2494119  0.24789163 0.24611337 0.24405411
 0.24176355 0.2394809  0.23720334 0.23511277 0.23319608 0.23161899
 0.23025523 0.22861047 0.22668056 0.22452839 0.2226878  0.2211234
 0.21985286 0.21865106 0.21764307 0.21648191 0.21539511 0.2143772
 0.21354724 0.21280561 0.21196659 0.21060033 0.20851657 0.20594631
 0.20297585 0.20049065 0.19849207 0.19683702 0.19503072 0.19303544
 0.19074543 0.18848602 0.18684717 0.18566644 0.18496378 0.18419154
 0.18353976 0.18249969 0.18162103 0.18081802 0.18041852 0.18037716
 0.18029046 0.17976297 0.17883344 0.17773965 0.17645264 0.17530847
 0.17388956 0.17248148 0.17092745 0.16936308 0.1680693  0.16738145
 0.16699316 0.16653469 0.16621847 0.16574018 0.16531067 0.16494653
 0.16493225 0.1649833  0.16507913 0.1648375  0.16427675 0.16347934
 0.16285795 0.16253418 0.16264339 0.16277936 0.16242675 0.16162463
 0.16001496 0.15833214 0.15675987 0.1557611  0.15502657 0.15436734
 0.15377824 0.15317208 0.15282664 0.15256765 0.15259747 0.15259457
 0.15258633 0.15216132 0.15153706 0.15083098 0.15034868 0.15013039
 0.15020691 0.15017189 0.14966735 0.1486625  0.14717898 0.14555348
 0.14386766 0.14231558 0.1407786  0.13945161 0.13812895 0.13691768
 0.136032   0.13533469 0.13470267 0.1340038  0.13341549 0.13278997
 0.13240853 0.13183661 0.13133627 0.13085446 0.13051231 0.13012297
 0.12978028 0.12953721 0.1293043  0.12896585 0.12801224 0.12662433
 0.12448061 0.12258095 0.12076811 0.11947495 0.11870943 0.11836703
 0.11827578 0.1179127  0.11756424 0.11727663 0.11738199 0.11743384
 0.11800491 0.11837973 0.11843383 0.11810154 0.11777737 0.11752041
 0.11749908 0.11779826 0.11805849 0.11798182 0.1172576  0.11600965
 0.11409307 0.11274797 0.11144616 0.1104532  0.10950388 0.10840805
 0.10750005 0.10665616 0.10603043 0.10524172 0.10500476 0.10507279
 0.10566058 0.10585786 0.10570432 0.10527293 0.10478204 0.10416549
 0.10407721 0.10408644 0.10429223 0.10447653 0.10396484 0.10278063]
