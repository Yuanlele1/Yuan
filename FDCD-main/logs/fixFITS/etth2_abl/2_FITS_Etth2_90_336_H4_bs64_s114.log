Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_90_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_90_336_FITS_ETTh2_ftM_sl90_ll48_pl336_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8215
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=26, out_features=123, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2865408.0
params:  3321.0
Trainable parameters:  3321
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.1730453968048096
Epoch: 1, Steps: 64 | Train Loss: 0.8300626 Vali Loss: 0.5037301 Test Loss: 0.5931873
Validation loss decreased (inf --> 0.503730).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.3434982299804688
Epoch: 2, Steps: 64 | Train Loss: 0.7141005 Vali Loss: 0.4584382 Test Loss: 0.5358193
Validation loss decreased (0.503730 --> 0.458438).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.519634962081909
Epoch: 3, Steps: 64 | Train Loss: 0.6503953 Vali Loss: 0.4322173 Test Loss: 0.5015904
Validation loss decreased (0.458438 --> 0.432217).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.9144840240478516
Epoch: 4, Steps: 64 | Train Loss: 0.6107453 Vali Loss: 0.4174249 Test Loss: 0.4797805
Validation loss decreased (0.432217 --> 0.417425).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.1261353492736816
Epoch: 5, Steps: 64 | Train Loss: 0.5858709 Vali Loss: 0.4073707 Test Loss: 0.4654880
Validation loss decreased (0.417425 --> 0.407371).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.9117021560668945
Epoch: 6, Steps: 64 | Train Loss: 0.5700374 Vali Loss: 0.3956314 Test Loss: 0.4558465
Validation loss decreased (0.407371 --> 0.395631).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.9323391914367676
Epoch: 7, Steps: 64 | Train Loss: 0.5585917 Vali Loss: 0.3916480 Test Loss: 0.4491570
Validation loss decreased (0.395631 --> 0.391648).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.956789493560791
Epoch: 8, Steps: 64 | Train Loss: 0.5497289 Vali Loss: 0.3893087 Test Loss: 0.4444145
Validation loss decreased (0.391648 --> 0.389309).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.7516207695007324
Epoch: 9, Steps: 64 | Train Loss: 0.5452010 Vali Loss: 0.3856018 Test Loss: 0.4410473
Validation loss decreased (0.389309 --> 0.385602).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.517202377319336
Epoch: 10, Steps: 64 | Train Loss: 0.5406864 Vali Loss: 0.3825701 Test Loss: 0.4384221
Validation loss decreased (0.385602 --> 0.382570).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.3113622665405273
Epoch: 11, Steps: 64 | Train Loss: 0.5384236 Vali Loss: 0.3832723 Test Loss: 0.4364530
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.0091934204101562
Epoch: 12, Steps: 64 | Train Loss: 0.5356809 Vali Loss: 0.3790116 Test Loss: 0.4349551
Validation loss decreased (0.382570 --> 0.379012).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.408468008041382
Epoch: 13, Steps: 64 | Train Loss: 0.5337693 Vali Loss: 0.3743311 Test Loss: 0.4337294
Validation loss decreased (0.379012 --> 0.374331).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.6421570777893066
Epoch: 14, Steps: 64 | Train Loss: 0.5322264 Vali Loss: 0.3782280 Test Loss: 0.4327270
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.0681040287017822
Epoch: 15, Steps: 64 | Train Loss: 0.5316253 Vali Loss: 0.3758521 Test Loss: 0.4319277
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.013190507888794
Epoch: 16, Steps: 64 | Train Loss: 0.5293819 Vali Loss: 0.3764162 Test Loss: 0.4312031
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.13042950630188
Epoch: 17, Steps: 64 | Train Loss: 0.5295816 Vali Loss: 0.3739029 Test Loss: 0.4306397
Validation loss decreased (0.374331 --> 0.373903).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.01432728767395
Epoch: 18, Steps: 64 | Train Loss: 0.5284682 Vali Loss: 0.3736549 Test Loss: 0.4301665
Validation loss decreased (0.373903 --> 0.373655).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.8923561573028564
Epoch: 19, Steps: 64 | Train Loss: 0.5273972 Vali Loss: 0.3741297 Test Loss: 0.4297114
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.905717372894287
Epoch: 20, Steps: 64 | Train Loss: 0.5260308 Vali Loss: 0.3732332 Test Loss: 0.4293047
Validation loss decreased (0.373655 --> 0.373233).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.1921920776367188
Epoch: 21, Steps: 64 | Train Loss: 0.5263727 Vali Loss: 0.3720860 Test Loss: 0.4289989
Validation loss decreased (0.373233 --> 0.372086).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.138651132583618
Epoch: 22, Steps: 64 | Train Loss: 0.5257178 Vali Loss: 0.3717620 Test Loss: 0.4286386
Validation loss decreased (0.372086 --> 0.371762).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.2023637294769287
Epoch: 23, Steps: 64 | Train Loss: 0.5248333 Vali Loss: 0.3723266 Test Loss: 0.4283993
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.3048908710479736
Epoch: 24, Steps: 64 | Train Loss: 0.5250078 Vali Loss: 0.3715929 Test Loss: 0.4281689
Validation loss decreased (0.371762 --> 0.371593).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.0875048637390137
Epoch: 25, Steps: 64 | Train Loss: 0.5233791 Vali Loss: 0.3716218 Test Loss: 0.4279123
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.3740787506103516
Epoch: 26, Steps: 64 | Train Loss: 0.5241691 Vali Loss: 0.3689799 Test Loss: 0.4277027
Validation loss decreased (0.371593 --> 0.368980).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.105470895767212
Epoch: 27, Steps: 64 | Train Loss: 0.5236690 Vali Loss: 0.3713529 Test Loss: 0.4275156
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.5031940937042236
Epoch: 28, Steps: 64 | Train Loss: 0.5240553 Vali Loss: 0.3714610 Test Loss: 0.4273190
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.164611577987671
Epoch: 29, Steps: 64 | Train Loss: 0.5235297 Vali Loss: 0.3706359 Test Loss: 0.4271382
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.5951390266418457
Epoch: 30, Steps: 64 | Train Loss: 0.5230633 Vali Loss: 0.3714391 Test Loss: 0.4270216
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.2851920127868652
Epoch: 31, Steps: 64 | Train Loss: 0.5234092 Vali Loss: 0.3712547 Test Loss: 0.4268720
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.4814212322235107
Epoch: 32, Steps: 64 | Train Loss: 0.5226828 Vali Loss: 0.3672131 Test Loss: 0.4267503
Validation loss decreased (0.368980 --> 0.367213).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.2469100952148438
Epoch: 33, Steps: 64 | Train Loss: 0.5221740 Vali Loss: 0.3694344 Test Loss: 0.4266322
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.992466926574707
Epoch: 34, Steps: 64 | Train Loss: 0.5227098 Vali Loss: 0.3685172 Test Loss: 0.4265154
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.8370029926300049
Epoch: 35, Steps: 64 | Train Loss: 0.5228726 Vali Loss: 0.3697080 Test Loss: 0.4263998
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.143261671066284
Epoch: 36, Steps: 64 | Train Loss: 0.5223127 Vali Loss: 0.3707147 Test Loss: 0.4263194
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 3.5127127170562744
Epoch: 37, Steps: 64 | Train Loss: 0.5215965 Vali Loss: 0.3709279 Test Loss: 0.4262183
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.6274662017822266
Epoch: 38, Steps: 64 | Train Loss: 0.5221580 Vali Loss: 0.3694983 Test Loss: 0.4261107
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.52685546875
Epoch: 39, Steps: 64 | Train Loss: 0.5214613 Vali Loss: 0.3705644 Test Loss: 0.4260234
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.334469795227051
Epoch: 40, Steps: 64 | Train Loss: 0.5213167 Vali Loss: 0.3702224 Test Loss: 0.4259716
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.9181549549102783
Epoch: 41, Steps: 64 | Train Loss: 0.5210093 Vali Loss: 0.3699440 Test Loss: 0.4258937
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.104456663131714
Epoch: 42, Steps: 64 | Train Loss: 0.5216037 Vali Loss: 0.3690688 Test Loss: 0.4258258
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.9982361793518066
Epoch: 43, Steps: 64 | Train Loss: 0.5215983 Vali Loss: 0.3669799 Test Loss: 0.4257726
Validation loss decreased (0.367213 --> 0.366980).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 2.0791444778442383
Epoch: 44, Steps: 64 | Train Loss: 0.5213966 Vali Loss: 0.3715928 Test Loss: 0.4256920
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.789703130722046
Epoch: 45, Steps: 64 | Train Loss: 0.5209269 Vali Loss: 0.3702061 Test Loss: 0.4256440
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.196070909500122
Epoch: 46, Steps: 64 | Train Loss: 0.5198906 Vali Loss: 0.3691286 Test Loss: 0.4255901
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.1586050987243652
Epoch: 47, Steps: 64 | Train Loss: 0.5208077 Vali Loss: 0.3693090 Test Loss: 0.4255462
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.1880240440368652
Epoch: 48, Steps: 64 | Train Loss: 0.5214668 Vali Loss: 0.3690169 Test Loss: 0.4254929
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.161102771759033
Epoch: 49, Steps: 64 | Train Loss: 0.5199898 Vali Loss: 0.3694542 Test Loss: 0.4254510
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 2.1088461875915527
Epoch: 50, Steps: 64 | Train Loss: 0.5203577 Vali Loss: 0.3696043 Test Loss: 0.4254061
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.336268663406372
Epoch: 51, Steps: 64 | Train Loss: 0.5207740 Vali Loss: 0.3679325 Test Loss: 0.4253572
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.0719141960144043
Epoch: 52, Steps: 64 | Train Loss: 0.5204734 Vali Loss: 0.3693542 Test Loss: 0.4253144
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.8756036758422852
Epoch: 53, Steps: 64 | Train Loss: 0.5194230 Vali Loss: 0.3695605 Test Loss: 0.4252853
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 2.9251534938812256
Epoch: 54, Steps: 64 | Train Loss: 0.5200682 Vali Loss: 0.3678375 Test Loss: 0.4252540
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.182939052581787
Epoch: 55, Steps: 64 | Train Loss: 0.5201722 Vali Loss: 0.3687822 Test Loss: 0.4252198
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.9702091217041016
Epoch: 56, Steps: 64 | Train Loss: 0.5199212 Vali Loss: 0.3665295 Test Loss: 0.4251842
Validation loss decreased (0.366980 --> 0.366530).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.457426071166992
Epoch: 57, Steps: 64 | Train Loss: 0.5206262 Vali Loss: 0.3691388 Test Loss: 0.4251577
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.1422348022460938
Epoch: 58, Steps: 64 | Train Loss: 0.5207264 Vali Loss: 0.3700133 Test Loss: 0.4251277
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 2.410348892211914
Epoch: 59, Steps: 64 | Train Loss: 0.5200377 Vali Loss: 0.3673198 Test Loss: 0.4251034
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 2.0114731788635254
Epoch: 60, Steps: 64 | Train Loss: 0.5209866 Vali Loss: 0.3677655 Test Loss: 0.4250769
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 2.693497657775879
Epoch: 61, Steps: 64 | Train Loss: 0.5199216 Vali Loss: 0.3673517 Test Loss: 0.4250520
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.251253128051758
Epoch: 62, Steps: 64 | Train Loss: 0.5209915 Vali Loss: 0.3685955 Test Loss: 0.4250290
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 2.383013963699341
Epoch: 63, Steps: 64 | Train Loss: 0.5209627 Vali Loss: 0.3659218 Test Loss: 0.4250100
Validation loss decreased (0.366530 --> 0.365922).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.2682578563690186
Epoch: 64, Steps: 64 | Train Loss: 0.5209055 Vali Loss: 0.3686194 Test Loss: 0.4249867
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 2.112978458404541
Epoch: 65, Steps: 64 | Train Loss: 0.5200597 Vali Loss: 0.3704467 Test Loss: 0.4249702
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.558873414993286
Epoch: 66, Steps: 64 | Train Loss: 0.5208078 Vali Loss: 0.3649916 Test Loss: 0.4249477
Validation loss decreased (0.365922 --> 0.364992).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.5142104625701904
Epoch: 67, Steps: 64 | Train Loss: 0.5204388 Vali Loss: 0.3675436 Test Loss: 0.4249313
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.880364179611206
Epoch: 68, Steps: 64 | Train Loss: 0.5193671 Vali Loss: 0.3673135 Test Loss: 0.4249159
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.9325876235961914
Epoch: 69, Steps: 64 | Train Loss: 0.5196424 Vali Loss: 0.3657886 Test Loss: 0.4248986
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.9379501342773438
Epoch: 70, Steps: 64 | Train Loss: 0.5206225 Vali Loss: 0.3665932 Test Loss: 0.4248870
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.461566686630249
Epoch: 71, Steps: 64 | Train Loss: 0.5203093 Vali Loss: 0.3696349 Test Loss: 0.4248676
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 2.28645396232605
Epoch: 72, Steps: 64 | Train Loss: 0.5206735 Vali Loss: 0.3681062 Test Loss: 0.4248565
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 2.4400930404663086
Epoch: 73, Steps: 64 | Train Loss: 0.5200899 Vali Loss: 0.3705549 Test Loss: 0.4248408
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.106480836868286
Epoch: 74, Steps: 64 | Train Loss: 0.5199201 Vali Loss: 0.3680179 Test Loss: 0.4248321
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 2.1458747386932373
Epoch: 75, Steps: 64 | Train Loss: 0.5204464 Vali Loss: 0.3683039 Test Loss: 0.4248186
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.059110641479492
Epoch: 76, Steps: 64 | Train Loss: 0.5199888 Vali Loss: 0.3652453 Test Loss: 0.4248067
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.8575878143310547
Epoch: 77, Steps: 64 | Train Loss: 0.5195049 Vali Loss: 0.3676891 Test Loss: 0.4247938
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.9689021110534668
Epoch: 78, Steps: 64 | Train Loss: 0.5192731 Vali Loss: 0.3680219 Test Loss: 0.4247889
EarlyStopping counter: 12 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.6386630535125732
Epoch: 79, Steps: 64 | Train Loss: 0.5195771 Vali Loss: 0.3684649 Test Loss: 0.4247775
EarlyStopping counter: 13 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.134636878967285
Epoch: 80, Steps: 64 | Train Loss: 0.5201239 Vali Loss: 0.3685497 Test Loss: 0.4247671
EarlyStopping counter: 14 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.9811372756958008
Epoch: 81, Steps: 64 | Train Loss: 0.5186163 Vali Loss: 0.3685914 Test Loss: 0.4247580
EarlyStopping counter: 15 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 2.6988766193389893
Epoch: 82, Steps: 64 | Train Loss: 0.5196403 Vali Loss: 0.3681819 Test Loss: 0.4247501
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.821350574493408
Epoch: 83, Steps: 64 | Train Loss: 0.5201566 Vali Loss: 0.3685778 Test Loss: 0.4247448
EarlyStopping counter: 17 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 2.3539040088653564
Epoch: 84, Steps: 64 | Train Loss: 0.5192257 Vali Loss: 0.3680362 Test Loss: 0.4247375
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 2.1408960819244385
Epoch: 85, Steps: 64 | Train Loss: 0.5184063 Vali Loss: 0.3696810 Test Loss: 0.4247282
EarlyStopping counter: 19 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.8658387660980225
Epoch: 86, Steps: 64 | Train Loss: 0.5187709 Vali Loss: 0.3699163 Test Loss: 0.4247240
EarlyStopping counter: 20 out of 20
Early stopping
train 8215
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=26, out_features=123, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2865408.0
params:  3321.0
Trainable parameters:  3321
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.8570170402526855
Epoch: 1, Steps: 64 | Train Loss: 0.6538026 Vali Loss: 0.3688491 Test Loss: 0.4238245
Validation loss decreased (inf --> 0.368849).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.146150827407837
Epoch: 2, Steps: 64 | Train Loss: 0.6513948 Vali Loss: 0.3680427 Test Loss: 0.4231125
Validation loss decreased (0.368849 --> 0.368043).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.182742118835449
Epoch: 3, Steps: 64 | Train Loss: 0.6500807 Vali Loss: 0.3669595 Test Loss: 0.4224999
Validation loss decreased (0.368043 --> 0.366960).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.3734843730926514
Epoch: 4, Steps: 64 | Train Loss: 0.6508198 Vali Loss: 0.3648554 Test Loss: 0.4222197
Validation loss decreased (0.366960 --> 0.364855).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.8924503326416016
Epoch: 5, Steps: 64 | Train Loss: 0.6483163 Vali Loss: 0.3652984 Test Loss: 0.4220099
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.7740046977996826
Epoch: 6, Steps: 64 | Train Loss: 0.6481332 Vali Loss: 0.3650528 Test Loss: 0.4218696
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.9698941707611084
Epoch: 7, Steps: 64 | Train Loss: 0.6482136 Vali Loss: 0.3636687 Test Loss: 0.4217092
Validation loss decreased (0.364855 --> 0.363669).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.1011581420898438
Epoch: 8, Steps: 64 | Train Loss: 0.6489049 Vali Loss: 0.3650046 Test Loss: 0.4216060
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.726243495941162
Epoch: 9, Steps: 64 | Train Loss: 0.6482466 Vali Loss: 0.3646851 Test Loss: 0.4214579
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.188836097717285
Epoch: 10, Steps: 64 | Train Loss: 0.6477406 Vali Loss: 0.3663571 Test Loss: 0.4214509
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.999701738357544
Epoch: 11, Steps: 64 | Train Loss: 0.6484167 Vali Loss: 0.3628837 Test Loss: 0.4213521
Validation loss decreased (0.363669 --> 0.362884).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.046672821044922
Epoch: 12, Steps: 64 | Train Loss: 0.6484375 Vali Loss: 0.3651459 Test Loss: 0.4212797
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.8250772953033447
Epoch: 13, Steps: 64 | Train Loss: 0.6479908 Vali Loss: 0.3621534 Test Loss: 0.4211828
Validation loss decreased (0.362884 --> 0.362153).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.651414394378662
Epoch: 14, Steps: 64 | Train Loss: 0.6465000 Vali Loss: 0.3636488 Test Loss: 0.4212353
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.9865484237670898
Epoch: 15, Steps: 64 | Train Loss: 0.6478944 Vali Loss: 0.3617506 Test Loss: 0.4211625
Validation loss decreased (0.362153 --> 0.361751).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.9347903728485107
Epoch: 16, Steps: 64 | Train Loss: 0.6477676 Vali Loss: 0.3623046 Test Loss: 0.4210638
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.3464622497558594
Epoch: 17, Steps: 64 | Train Loss: 0.6463210 Vali Loss: 0.3648930 Test Loss: 0.4210790
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.1264121532440186
Epoch: 18, Steps: 64 | Train Loss: 0.6472792 Vali Loss: 0.3624383 Test Loss: 0.4210478
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.118593215942383
Epoch: 19, Steps: 64 | Train Loss: 0.6452466 Vali Loss: 0.3607276 Test Loss: 0.4210436
Validation loss decreased (0.361751 --> 0.360728).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.2301721572875977
Epoch: 20, Steps: 64 | Train Loss: 0.6456833 Vali Loss: 0.3636506 Test Loss: 0.4209926
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.82694411277771
Epoch: 21, Steps: 64 | Train Loss: 0.6456694 Vali Loss: 0.3617802 Test Loss: 0.4209761
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.9051828384399414
Epoch: 22, Steps: 64 | Train Loss: 0.6463443 Vali Loss: 0.3624233 Test Loss: 0.4209860
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.049131155014038
Epoch: 23, Steps: 64 | Train Loss: 0.6462987 Vali Loss: 0.3614112 Test Loss: 0.4209741
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.3225929737091064
Epoch: 24, Steps: 64 | Train Loss: 0.6467256 Vali Loss: 0.3605758 Test Loss: 0.4209386
Validation loss decreased (0.360728 --> 0.360576).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.0027408599853516
Epoch: 25, Steps: 64 | Train Loss: 0.6457005 Vali Loss: 0.3643776 Test Loss: 0.4209123
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.7447435855865479
Epoch: 26, Steps: 64 | Train Loss: 0.6465509 Vali Loss: 0.3622834 Test Loss: 0.4208695
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.8309974670410156
Epoch: 27, Steps: 64 | Train Loss: 0.6454716 Vali Loss: 0.3636801 Test Loss: 0.4208822
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.992551326751709
Epoch: 28, Steps: 64 | Train Loss: 0.6447908 Vali Loss: 0.3623733 Test Loss: 0.4208571
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.289869546890259
Epoch: 29, Steps: 64 | Train Loss: 0.6450590 Vali Loss: 0.3610818 Test Loss: 0.4208598
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.7750370502471924
Epoch: 30, Steps: 64 | Train Loss: 0.6450054 Vali Loss: 0.3616734 Test Loss: 0.4208663
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.9620163440704346
Epoch: 31, Steps: 64 | Train Loss: 0.6464221 Vali Loss: 0.3627172 Test Loss: 0.4208317
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.0954606533050537
Epoch: 32, Steps: 64 | Train Loss: 0.6454820 Vali Loss: 0.3654198 Test Loss: 0.4208397
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.9064397811889648
Epoch: 33, Steps: 64 | Train Loss: 0.6449871 Vali Loss: 0.3633463 Test Loss: 0.4208221
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.2513840198516846
Epoch: 34, Steps: 64 | Train Loss: 0.6446221 Vali Loss: 0.3621251 Test Loss: 0.4208112
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.0967977046966553
Epoch: 35, Steps: 64 | Train Loss: 0.6459112 Vali Loss: 0.3622262 Test Loss: 0.4208092
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.150050163269043
Epoch: 36, Steps: 64 | Train Loss: 0.6457697 Vali Loss: 0.3597822 Test Loss: 0.4207973
Validation loss decreased (0.360576 --> 0.359782).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.2958197593688965
Epoch: 37, Steps: 64 | Train Loss: 0.6449644 Vali Loss: 0.3603599 Test Loss: 0.4208009
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.914505958557129
Epoch: 38, Steps: 64 | Train Loss: 0.6454177 Vali Loss: 0.3637268 Test Loss: 0.4208100
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.140526533126831
Epoch: 39, Steps: 64 | Train Loss: 0.6453727 Vali Loss: 0.3618564 Test Loss: 0.4207879
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.9372003078460693
Epoch: 40, Steps: 64 | Train Loss: 0.6447303 Vali Loss: 0.3608247 Test Loss: 0.4207787
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.3293445110321045
Epoch: 41, Steps: 64 | Train Loss: 0.6459096 Vali Loss: 0.3624233 Test Loss: 0.4207622
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.194312810897827
Epoch: 42, Steps: 64 | Train Loss: 0.6436099 Vali Loss: 0.3640009 Test Loss: 0.4207759
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.299081325531006
Epoch: 43, Steps: 64 | Train Loss: 0.6459737 Vali Loss: 0.3602417 Test Loss: 0.4207750
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.9340648651123047
Epoch: 44, Steps: 64 | Train Loss: 0.6446473 Vali Loss: 0.3624299 Test Loss: 0.4207627
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 3.477792978286743
Epoch: 45, Steps: 64 | Train Loss: 0.6452453 Vali Loss: 0.3610349 Test Loss: 0.4207705
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.6914730072021484
Epoch: 46, Steps: 64 | Train Loss: 0.6458472 Vali Loss: 0.3627030 Test Loss: 0.4207556
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 2.3509695529937744
Epoch: 47, Steps: 64 | Train Loss: 0.6453371 Vali Loss: 0.3611344 Test Loss: 0.4207551
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 2.0611135959625244
Epoch: 48, Steps: 64 | Train Loss: 0.6452276 Vali Loss: 0.3624929 Test Loss: 0.4207636
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.9299285411834717
Epoch: 49, Steps: 64 | Train Loss: 0.6456920 Vali Loss: 0.3616776 Test Loss: 0.4207487
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.9857580661773682
Epoch: 50, Steps: 64 | Train Loss: 0.6442800 Vali Loss: 0.3622154 Test Loss: 0.4207341
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.118257522583008
Epoch: 51, Steps: 64 | Train Loss: 0.6450096 Vali Loss: 0.3625658 Test Loss: 0.4207489
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.2750954627990723
Epoch: 52, Steps: 64 | Train Loss: 0.6449407 Vali Loss: 0.3609702 Test Loss: 0.4207411
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.2489445209503174
Epoch: 53, Steps: 64 | Train Loss: 0.6439361 Vali Loss: 0.3634576 Test Loss: 0.4207417
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.8304128646850586
Epoch: 54, Steps: 64 | Train Loss: 0.6442744 Vali Loss: 0.3648791 Test Loss: 0.4207342
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.2181396484375
Epoch: 55, Steps: 64 | Train Loss: 0.6447144 Vali Loss: 0.3619006 Test Loss: 0.4207417
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.061790704727173
Epoch: 56, Steps: 64 | Train Loss: 0.6456502 Vali Loss: 0.3598976 Test Loss: 0.4207329
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_90_336_FITS_ETTh2_ftM_sl90_ll48_pl336_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.41608452796936035, mae:0.4249255359172821, rse:0.5157394409179688, corr:[0.26389033 0.26580235 0.26340258 0.26370013 0.26201093 0.26003286
 0.259783   0.2584662  0.25690114 0.256213   0.25544205 0.25346
 0.25181025 0.2508088  0.24964567 0.2488158  0.24848771 0.24780595
 0.24677965 0.2459142  0.24503061 0.24387741 0.24284104 0.24127527
 0.23822951 0.2358908  0.23426513 0.23303036 0.23163007 0.23061863
 0.23011546 0.22877628 0.2274854  0.22648269 0.22565228 0.22444323
 0.22320223 0.22233045 0.2212827  0.2202757  0.21961623 0.21910922
 0.21868727 0.21774393 0.21670029 0.2157634  0.21470943 0.21259679
 0.20908917 0.20630273 0.20363143 0.20146386 0.19987692 0.19806947
 0.1964204  0.1941339  0.19277982 0.19122617 0.1902322  0.18914165
 0.18772554 0.18720987 0.18717073 0.1870456  0.1865077  0.18609476
 0.18570788 0.1847212  0.1839451  0.1836552  0.18280303 0.18101712
 0.17823276 0.17669317 0.17516343 0.17383237 0.17301717 0.17276719
 0.17265628 0.1715187  0.17103657 0.17066576 0.17039213 0.16989431
 0.16909939 0.16873546 0.1687573  0.16872495 0.16823901 0.16784596
 0.16773553 0.16702914 0.16657649 0.16658936 0.16641074 0.16521229
 0.16288447 0.1612565  0.15961753 0.15811615 0.15712714 0.15659696
 0.15684867 0.15617356 0.15613665 0.15592839 0.15582818 0.15562767
 0.15505984 0.15454692 0.15368097 0.15327917 0.15299885 0.15256922
 0.15223333 0.15146661 0.15083541 0.14994928 0.14841372 0.14622808
 0.14327845 0.14124185 0.13948283 0.1383139  0.13713704 0.13634844
 0.13607618 0.13524088 0.13480674 0.13431042 0.13392521 0.1332091
 0.13240968 0.13189062 0.13146351 0.13110097 0.13063684 0.13010322
 0.12963073 0.1288698  0.12838912 0.12788063 0.12664367 0.12436775
 0.12083361 0.11830099 0.11613131 0.11441912 0.11299916 0.11217645
 0.11216529 0.11130671 0.11085113 0.11055195 0.11050896 0.11005148
 0.10927095 0.10899133 0.10890855 0.10897805 0.10879728 0.10850541
 0.10841735 0.10795384 0.10779577 0.10777901 0.10741094 0.10571325
 0.10251962 0.10059102 0.0992237  0.09818351 0.09715762 0.09661631
 0.09702776 0.09669493 0.0965968  0.09638155 0.09646133 0.09611779
 0.09555243 0.09545842 0.09547623 0.09577629 0.09570361 0.0956718
 0.09606475 0.0962735  0.09650742 0.09690404 0.0970033  0.09641845
 0.09471278 0.09385592 0.0931839  0.09280591 0.0927527  0.09281645
 0.09390444 0.09454158 0.09500299 0.09498729 0.09531903 0.09527306
 0.09469596 0.094444   0.09436952 0.09437293 0.09413207 0.09424872
 0.09450812 0.09444077 0.09453104 0.0946321  0.09435347 0.09299077
 0.09070135 0.08899774 0.08734974 0.08649461 0.08598768 0.08606324
 0.08696241 0.08800063 0.08894564 0.08889772 0.08865223 0.08819155
 0.08770094 0.08726059 0.0870051  0.08711758 0.08725532 0.08755764
 0.08819447 0.08873529 0.08902775 0.08925697 0.08900877 0.0879814
 0.08575671 0.08427695 0.08285581 0.08225898 0.08238249 0.08306086
 0.08467311 0.08555783 0.08647858 0.08692564 0.0872363  0.08726166
 0.08705497 0.08752394 0.08798433 0.08885694 0.08940104 0.08999403
 0.09037112 0.09069924 0.09108651 0.09156343 0.09172751 0.09121743
 0.0899149  0.08931497 0.08910482 0.08938409 0.0896773  0.09034979
 0.09180778 0.09274179 0.09360322 0.09382699 0.09394746 0.09349572
 0.09306047 0.09284003 0.0930734  0.09341911 0.09354834 0.09358922
 0.09387771 0.0939621  0.09418744 0.09452803 0.0946328  0.09440303
 0.09337556 0.09260625 0.09167973 0.09114048 0.0911763  0.09115854
 0.09144133 0.0915091  0.09230992 0.09262214 0.09274687 0.09288608
 0.09280343 0.09276994 0.09298158 0.09389178 0.09439994 0.09480569
 0.09557352 0.09611336 0.09676348 0.09714335 0.09747213 0.09707563
 0.0953314  0.09470519 0.09429254 0.09421553 0.09425263 0.09472634
 0.09554803 0.09599238 0.09749605 0.09811778 0.09785277 0.09805218
 0.09876248 0.09833048 0.097603   0.09822778 0.09877215 0.09829485
 0.09837121 0.09869279 0.09859948 0.09835406 0.09923401 0.09909773]
