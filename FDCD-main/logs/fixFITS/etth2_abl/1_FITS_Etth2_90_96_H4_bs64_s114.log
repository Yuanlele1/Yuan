Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_90_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_90_96_FITS_ETTh2_ftM_sl90_ll48_pl96_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8455
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=26, out_features=53, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1234688.0
params:  1431.0
Trainable parameters:  1431
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.4853205680847168
Epoch: 1, Steps: 66 | Train Loss: 0.5824779 Vali Loss: 0.2772061 Test Loss: 0.3695458
Validation loss decreased (inf --> 0.277206).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.3682808876037598
Epoch: 2, Steps: 66 | Train Loss: 0.5096048 Vali Loss: 0.2505184 Test Loss: 0.3351152
Validation loss decreased (0.277206 --> 0.250518).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.362255334854126
Epoch: 3, Steps: 66 | Train Loss: 0.4791647 Vali Loss: 0.2379369 Test Loss: 0.3193790
Validation loss decreased (0.250518 --> 0.237937).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.4512455463409424
Epoch: 4, Steps: 66 | Train Loss: 0.4639973 Vali Loss: 0.2323195 Test Loss: 0.3115368
Validation loss decreased (0.237937 --> 0.232320).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.3255016803741455
Epoch: 5, Steps: 66 | Train Loss: 0.4548993 Vali Loss: 0.2281789 Test Loss: 0.3070477
Validation loss decreased (0.232320 --> 0.228179).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.6819815635681152
Epoch: 6, Steps: 66 | Train Loss: 0.4504147 Vali Loss: 0.2264505 Test Loss: 0.3043038
Validation loss decreased (0.228179 --> 0.226450).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.7230963706970215
Epoch: 7, Steps: 66 | Train Loss: 0.4467587 Vali Loss: 0.2240600 Test Loss: 0.3023801
Validation loss decreased (0.226450 --> 0.224060).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.5858097076416016
Epoch: 8, Steps: 66 | Train Loss: 0.4439779 Vali Loss: 0.2222501 Test Loss: 0.3009785
Validation loss decreased (0.224060 --> 0.222250).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.7057571411132812
Epoch: 9, Steps: 66 | Train Loss: 0.4416481 Vali Loss: 0.2221525 Test Loss: 0.2998604
Validation loss decreased (0.222250 --> 0.222152).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.3989410400390625
Epoch: 10, Steps: 66 | Train Loss: 0.4397891 Vali Loss: 0.2201517 Test Loss: 0.2990085
Validation loss decreased (0.222152 --> 0.220152).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.781468152999878
Epoch: 11, Steps: 66 | Train Loss: 0.4371545 Vali Loss: 0.2208156 Test Loss: 0.2982010
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.2063939571380615
Epoch: 12, Steps: 66 | Train Loss: 0.4369150 Vali Loss: 0.2192118 Test Loss: 0.2975815
Validation loss decreased (0.220152 --> 0.219212).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.6960632801055908
Epoch: 13, Steps: 66 | Train Loss: 0.4358011 Vali Loss: 0.2189745 Test Loss: 0.2970011
Validation loss decreased (0.219212 --> 0.218975).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.204892158508301
Epoch: 14, Steps: 66 | Train Loss: 0.4347941 Vali Loss: 0.2183745 Test Loss: 0.2965244
Validation loss decreased (0.218975 --> 0.218375).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.6581077575683594
Epoch: 15, Steps: 66 | Train Loss: 0.4339081 Vali Loss: 0.2165096 Test Loss: 0.2960685
Validation loss decreased (0.218375 --> 0.216510).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.4365768432617188
Epoch: 16, Steps: 66 | Train Loss: 0.4330843 Vali Loss: 0.2185972 Test Loss: 0.2957251
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.2349436283111572
Epoch: 17, Steps: 66 | Train Loss: 0.4322073 Vali Loss: 0.2174208 Test Loss: 0.2953587
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.8202455043792725
Epoch: 18, Steps: 66 | Train Loss: 0.4311901 Vali Loss: 0.2179423 Test Loss: 0.2950483
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.2015621662139893
Epoch: 19, Steps: 66 | Train Loss: 0.4310908 Vali Loss: 0.2167304 Test Loss: 0.2947700
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.4140028953552246
Epoch: 20, Steps: 66 | Train Loss: 0.4305647 Vali Loss: 0.2159998 Test Loss: 0.2945596
Validation loss decreased (0.216510 --> 0.216000).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.4408819675445557
Epoch: 21, Steps: 66 | Train Loss: 0.4299827 Vali Loss: 0.2163836 Test Loss: 0.2943441
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.2968521118164062
Epoch: 22, Steps: 66 | Train Loss: 0.4296683 Vali Loss: 0.2159483 Test Loss: 0.2941603
Validation loss decreased (0.216000 --> 0.215948).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.3780558109283447
Epoch: 23, Steps: 66 | Train Loss: 0.4293103 Vali Loss: 0.2152725 Test Loss: 0.2939799
Validation loss decreased (0.215948 --> 0.215272).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.345348834991455
Epoch: 24, Steps: 66 | Train Loss: 0.4289495 Vali Loss: 0.2154010 Test Loss: 0.2938099
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.068155288696289
Epoch: 25, Steps: 66 | Train Loss: 0.4286247 Vali Loss: 0.2163190 Test Loss: 0.2936634
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.0196142196655273
Epoch: 26, Steps: 66 | Train Loss: 0.4282806 Vali Loss: 0.2154132 Test Loss: 0.2935532
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.5911765098571777
Epoch: 27, Steps: 66 | Train Loss: 0.4278446 Vali Loss: 0.2162457 Test Loss: 0.2934330
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.5318882465362549
Epoch: 28, Steps: 66 | Train Loss: 0.4277335 Vali Loss: 0.2153670 Test Loss: 0.2932926
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.1990408897399902
Epoch: 29, Steps: 66 | Train Loss: 0.4271984 Vali Loss: 0.2157635 Test Loss: 0.2932203
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.8017480373382568
Epoch: 30, Steps: 66 | Train Loss: 0.4272969 Vali Loss: 0.2149110 Test Loss: 0.2931177
Validation loss decreased (0.215272 --> 0.214911).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.230438470840454
Epoch: 31, Steps: 66 | Train Loss: 0.4270358 Vali Loss: 0.2143323 Test Loss: 0.2930404
Validation loss decreased (0.214911 --> 0.214332).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.2300570011138916
Epoch: 32, Steps: 66 | Train Loss: 0.4266947 Vali Loss: 0.2147744 Test Loss: 0.2929698
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.7233250141143799
Epoch: 33, Steps: 66 | Train Loss: 0.4264094 Vali Loss: 0.2152215 Test Loss: 0.2928890
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.451542615890503
Epoch: 34, Steps: 66 | Train Loss: 0.4263725 Vali Loss: 0.2142884 Test Loss: 0.2928337
Validation loss decreased (0.214332 --> 0.214288).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.2816779613494873
Epoch: 35, Steps: 66 | Train Loss: 0.4260835 Vali Loss: 0.2147839 Test Loss: 0.2927734
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.3130924701690674
Epoch: 36, Steps: 66 | Train Loss: 0.4259946 Vali Loss: 0.2150305 Test Loss: 0.2927198
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.6239805221557617
Epoch: 37, Steps: 66 | Train Loss: 0.4261132 Vali Loss: 0.2135490 Test Loss: 0.2926480
Validation loss decreased (0.214288 --> 0.213549).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.6046302318572998
Epoch: 38, Steps: 66 | Train Loss: 0.4259744 Vali Loss: 0.2135273 Test Loss: 0.2926053
Validation loss decreased (0.213549 --> 0.213527).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.4755980968475342
Epoch: 39, Steps: 66 | Train Loss: 0.4256624 Vali Loss: 0.2150256 Test Loss: 0.2925725
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.5061790943145752
Epoch: 40, Steps: 66 | Train Loss: 0.4255718 Vali Loss: 0.2146334 Test Loss: 0.2925257
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.31219482421875
Epoch: 41, Steps: 66 | Train Loss: 0.4255027 Vali Loss: 0.2140831 Test Loss: 0.2924891
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.5326521396636963
Epoch: 42, Steps: 66 | Train Loss: 0.4253453 Vali Loss: 0.2146949 Test Loss: 0.2924501
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.4808177947998047
Epoch: 43, Steps: 66 | Train Loss: 0.4246015 Vali Loss: 0.2141553 Test Loss: 0.2924084
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.637406349182129
Epoch: 44, Steps: 66 | Train Loss: 0.4252264 Vali Loss: 0.2140440 Test Loss: 0.2923792
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.6805870532989502
Epoch: 45, Steps: 66 | Train Loss: 0.4252131 Vali Loss: 0.2141607 Test Loss: 0.2923562
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.4629161357879639
Epoch: 46, Steps: 66 | Train Loss: 0.4239889 Vali Loss: 0.2153254 Test Loss: 0.2923230
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.3861429691314697
Epoch: 47, Steps: 66 | Train Loss: 0.4249263 Vali Loss: 0.2138530 Test Loss: 0.2922992
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.4176628589630127
Epoch: 48, Steps: 66 | Train Loss: 0.4247106 Vali Loss: 0.2138627 Test Loss: 0.2922683
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.4284954071044922
Epoch: 49, Steps: 66 | Train Loss: 0.4249923 Vali Loss: 0.2136870 Test Loss: 0.2922523
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.8754518032073975
Epoch: 50, Steps: 66 | Train Loss: 0.4248685 Vali Loss: 0.2148780 Test Loss: 0.2922276
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.4065978527069092
Epoch: 51, Steps: 66 | Train Loss: 0.4244453 Vali Loss: 0.2141848 Test Loss: 0.2922054
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.4444019794464111
Epoch: 52, Steps: 66 | Train Loss: 0.4244434 Vali Loss: 0.2141653 Test Loss: 0.2921916
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.5476162433624268
Epoch: 53, Steps: 66 | Train Loss: 0.4247153 Vali Loss: 0.2135151 Test Loss: 0.2921741
Validation loss decreased (0.213527 --> 0.213515).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.4678239822387695
Epoch: 54, Steps: 66 | Train Loss: 0.4246583 Vali Loss: 0.2148851 Test Loss: 0.2921579
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.1703946590423584
Epoch: 55, Steps: 66 | Train Loss: 0.4244738 Vali Loss: 0.2139896 Test Loss: 0.2921382
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.5525236129760742
Epoch: 56, Steps: 66 | Train Loss: 0.4239779 Vali Loss: 0.2136162 Test Loss: 0.2921227
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 2.1836752891540527
Epoch: 57, Steps: 66 | Train Loss: 0.4237228 Vali Loss: 0.2142562 Test Loss: 0.2921136
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.6625053882598877
Epoch: 58, Steps: 66 | Train Loss: 0.4240068 Vali Loss: 0.2135881 Test Loss: 0.2920979
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.4424378871917725
Epoch: 59, Steps: 66 | Train Loss: 0.4240075 Vali Loss: 0.2129624 Test Loss: 0.2920831
Validation loss decreased (0.213515 --> 0.212962).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.442335844039917
Epoch: 60, Steps: 66 | Train Loss: 0.4243071 Vali Loss: 0.2134272 Test Loss: 0.2920726
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.4153721332550049
Epoch: 61, Steps: 66 | Train Loss: 0.4242372 Vali Loss: 0.2150672 Test Loss: 0.2920617
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.3744475841522217
Epoch: 62, Steps: 66 | Train Loss: 0.4237674 Vali Loss: 0.2132759 Test Loss: 0.2920519
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.4193816184997559
Epoch: 63, Steps: 66 | Train Loss: 0.4241152 Vali Loss: 0.2151346 Test Loss: 0.2920407
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.5803852081298828
Epoch: 64, Steps: 66 | Train Loss: 0.4242343 Vali Loss: 0.2142210 Test Loss: 0.2920316
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.504115343093872
Epoch: 65, Steps: 66 | Train Loss: 0.4239190 Vali Loss: 0.2131379 Test Loss: 0.2920214
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.5397894382476807
Epoch: 66, Steps: 66 | Train Loss: 0.4242144 Vali Loss: 0.2133719 Test Loss: 0.2920137
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.7052278518676758
Epoch: 67, Steps: 66 | Train Loss: 0.4241656 Vali Loss: 0.2139962 Test Loss: 0.2920020
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.2760958671569824
Epoch: 68, Steps: 66 | Train Loss: 0.4242531 Vali Loss: 0.2134179 Test Loss: 0.2919971
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.2812168598175049
Epoch: 69, Steps: 66 | Train Loss: 0.4240044 Vali Loss: 0.2134448 Test Loss: 0.2919870
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.988581895828247
Epoch: 70, Steps: 66 | Train Loss: 0.4240365 Vali Loss: 0.2142939 Test Loss: 0.2919828
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.4228343963623047
Epoch: 71, Steps: 66 | Train Loss: 0.4241531 Vali Loss: 0.2143425 Test Loss: 0.2919751
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.2395484447479248
Epoch: 72, Steps: 66 | Train Loss: 0.4241686 Vali Loss: 0.2127089 Test Loss: 0.2919697
Validation loss decreased (0.212962 --> 0.212709).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.6214592456817627
Epoch: 73, Steps: 66 | Train Loss: 0.4240514 Vali Loss: 0.2134426 Test Loss: 0.2919644
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.4483189582824707
Epoch: 74, Steps: 66 | Train Loss: 0.4239902 Vali Loss: 0.2131623 Test Loss: 0.2919610
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.4971883296966553
Epoch: 75, Steps: 66 | Train Loss: 0.4232298 Vali Loss: 0.2143552 Test Loss: 0.2919544
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.3629300594329834
Epoch: 76, Steps: 66 | Train Loss: 0.4240230 Vali Loss: 0.2129839 Test Loss: 0.2919489
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.3859121799468994
Epoch: 77, Steps: 66 | Train Loss: 0.4238476 Vali Loss: 0.2131019 Test Loss: 0.2919438
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 1.500185251235962
Epoch: 78, Steps: 66 | Train Loss: 0.4240652 Vali Loss: 0.2130130 Test Loss: 0.2919403
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.464240312576294
Epoch: 79, Steps: 66 | Train Loss: 0.4239323 Vali Loss: 0.2141316 Test Loss: 0.2919351
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 1.3007681369781494
Epoch: 80, Steps: 66 | Train Loss: 0.4240282 Vali Loss: 0.2136432 Test Loss: 0.2919336
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 2.0437824726104736
Epoch: 81, Steps: 66 | Train Loss: 0.4235768 Vali Loss: 0.2131456 Test Loss: 0.2919288
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.4704785346984863
Epoch: 82, Steps: 66 | Train Loss: 0.4235351 Vali Loss: 0.2136820 Test Loss: 0.2919257
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 2.3318684101104736
Epoch: 83, Steps: 66 | Train Loss: 0.4239506 Vali Loss: 0.2126883 Test Loss: 0.2919214
Validation loss decreased (0.212709 --> 0.212688).  Saving model ...
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.4351646900177002
Epoch: 84, Steps: 66 | Train Loss: 0.4238516 Vali Loss: 0.2138336 Test Loss: 0.2919188
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.3574519157409668
Epoch: 85, Steps: 66 | Train Loss: 0.4239940 Vali Loss: 0.2132890 Test Loss: 0.2919151
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.5760719776153564
Epoch: 86, Steps: 66 | Train Loss: 0.4239433 Vali Loss: 0.2129751 Test Loss: 0.2919109
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.5553326606750488
Epoch: 87, Steps: 66 | Train Loss: 0.4236188 Vali Loss: 0.2141737 Test Loss: 0.2919103
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.4258224964141846
Epoch: 88, Steps: 66 | Train Loss: 0.4239892 Vali Loss: 0.2133713 Test Loss: 0.2919073
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.3870713710784912
Epoch: 89, Steps: 66 | Train Loss: 0.4239867 Vali Loss: 0.2138368 Test Loss: 0.2919057
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 2.3034398555755615
Epoch: 90, Steps: 66 | Train Loss: 0.4238364 Vali Loss: 0.2138984 Test Loss: 0.2919020
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.4270000457763672
Epoch: 91, Steps: 66 | Train Loss: 0.4233802 Vali Loss: 0.2136981 Test Loss: 0.2919004
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.5776445865631104
Epoch: 92, Steps: 66 | Train Loss: 0.4236406 Vali Loss: 0.2129961 Test Loss: 0.2918980
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 2.0794472694396973
Epoch: 93, Steps: 66 | Train Loss: 0.4237044 Vali Loss: 0.2136138 Test Loss: 0.2918958
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.4064953327178955
Epoch: 94, Steps: 66 | Train Loss: 0.4237268 Vali Loss: 0.2134801 Test Loss: 0.2918944
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.4992635250091553
Epoch: 95, Steps: 66 | Train Loss: 0.4238475 Vali Loss: 0.2135836 Test Loss: 0.2918923
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.5074961185455322
Epoch: 96, Steps: 66 | Train Loss: 0.4236877 Vali Loss: 0.2131711 Test Loss: 0.2918907
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.8015706539154053
Epoch: 97, Steps: 66 | Train Loss: 0.4238726 Vali Loss: 0.2126991 Test Loss: 0.2918891
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 1.3153645992279053
Epoch: 98, Steps: 66 | Train Loss: 0.4239542 Vali Loss: 0.2142067 Test Loss: 0.2918872
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 1.6831762790679932
Epoch: 99, Steps: 66 | Train Loss: 0.4225991 Vali Loss: 0.2132796 Test Loss: 0.2918856
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 1.5909514427185059
Epoch: 100, Steps: 66 | Train Loss: 0.4237651 Vali Loss: 0.2129254 Test Loss: 0.2918849
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.1160680107021042e-06
>>>>>>>testing : ETTh2_90_96_FITS_ETTh2_ftM_sl90_ll48_pl96_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.29243752360343933, mae:0.34007057547569275, rse:0.4358106553554535, corr:[0.27439922 0.27859    0.27500856 0.27516684 0.2742369  0.27212632
 0.27167726 0.27102825 0.26957408 0.26867694 0.26792926 0.26607263
 0.26426592 0.26325947 0.26224202 0.26136944 0.2609174  0.26036406
 0.2593609  0.25833768 0.25743482 0.25634232 0.25507167 0.25315365
 0.25004858 0.24737872 0.24534373 0.24368195 0.24193014 0.24059327
 0.23976152 0.23828585 0.23699437 0.23599811 0.23489246 0.23346482
 0.23222995 0.23112692 0.22994493 0.22918941 0.22868289 0.22803919
 0.22761837 0.22713186 0.22631083 0.22525053 0.22435533 0.22249219
 0.21888    0.21595812 0.21372744 0.21173151 0.20997274 0.20860216
 0.2071494  0.20473763 0.20362926 0.2028558  0.20175534 0.2004407
 0.19975474 0.19948398 0.1989245  0.19895528 0.19912048 0.19827627
 0.19735153 0.19715732 0.19690867 0.19579615 0.19490993 0.19405966
 0.19134977 0.18936306 0.18849722 0.1873161  0.18547031 0.18509646
 0.18551548 0.18401732 0.18328853 0.18388198 0.18373911 0.18256977
 0.18232502 0.1827129  0.18173431 0.1814805  0.18224485 0.18090536
 0.17851911 0.17898896 0.17960007 0.17637083 0.17798512 0.1797817 ]
