Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=34, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_90_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_90_192_FITS_ETTh2_ftM_sl90_ll48_pl192_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8359
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=34, out_features=106, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3229184.0
params:  3710.0
Trainable parameters:  3710
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 1.8488483428955078
Epoch: 1, Steps: 65 | Train Loss: 0.6292674 Vali Loss: 0.3757836 Test Loss: 0.5246280
Validation loss decreased (inf --> 0.375784).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.5671110153198242
Epoch: 2, Steps: 65 | Train Loss: 0.5372771 Vali Loss: 0.3451392 Test Loss: 0.4828731
Validation loss decreased (0.375784 --> 0.345139).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.3564834594726562
Epoch: 3, Steps: 65 | Train Loss: 0.4844046 Vali Loss: 0.3265714 Test Loss: 0.4578657
Validation loss decreased (0.345139 --> 0.326571).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.2706682682037354
Epoch: 4, Steps: 65 | Train Loss: 0.4525788 Vali Loss: 0.3145679 Test Loss: 0.4419276
Validation loss decreased (0.326571 --> 0.314568).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.2637805938720703
Epoch: 5, Steps: 65 | Train Loss: 0.4332748 Vali Loss: 0.3065023 Test Loss: 0.4314398
Validation loss decreased (0.314568 --> 0.306502).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.215785264968872
Epoch: 6, Steps: 65 | Train Loss: 0.4185288 Vali Loss: 0.3009270 Test Loss: 0.4242437
Validation loss decreased (0.306502 --> 0.300927).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.278928279876709
Epoch: 7, Steps: 65 | Train Loss: 0.4114038 Vali Loss: 0.2969137 Test Loss: 0.4192476
Validation loss decreased (0.300927 --> 0.296914).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.366924524307251
Epoch: 8, Steps: 65 | Train Loss: 0.4038120 Vali Loss: 0.2938897 Test Loss: 0.4154954
Validation loss decreased (0.296914 --> 0.293890).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.5721547603607178
Epoch: 9, Steps: 65 | Train Loss: 0.3987281 Vali Loss: 0.2914806 Test Loss: 0.4126355
Validation loss decreased (0.293890 --> 0.291481).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.4270224571228027
Epoch: 10, Steps: 65 | Train Loss: 0.3944312 Vali Loss: 0.2896909 Test Loss: 0.4105192
Validation loss decreased (0.291481 --> 0.289691).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.4713523387908936
Epoch: 11, Steps: 65 | Train Loss: 0.3909334 Vali Loss: 0.2881823 Test Loss: 0.4087953
Validation loss decreased (0.289691 --> 0.288182).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.3384652137756348
Epoch: 12, Steps: 65 | Train Loss: 0.3884607 Vali Loss: 0.2869561 Test Loss: 0.4073575
Validation loss decreased (0.288182 --> 0.286956).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.1305415630340576
Epoch: 13, Steps: 65 | Train Loss: 0.3874731 Vali Loss: 0.2858633 Test Loss: 0.4061410
Validation loss decreased (0.286956 --> 0.285863).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.5264084339141846
Epoch: 14, Steps: 65 | Train Loss: 0.3860736 Vali Loss: 0.2850222 Test Loss: 0.4051844
Validation loss decreased (0.285863 --> 0.285022).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.147456169128418
Epoch: 15, Steps: 65 | Train Loss: 0.3839246 Vali Loss: 0.2839833 Test Loss: 0.4043543
Validation loss decreased (0.285022 --> 0.283983).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.4631714820861816
Epoch: 16, Steps: 65 | Train Loss: 0.3820558 Vali Loss: 0.2835639 Test Loss: 0.4035951
Validation loss decreased (0.283983 --> 0.283564).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.943772315979004
Epoch: 17, Steps: 65 | Train Loss: 0.3816552 Vali Loss: 0.2829421 Test Loss: 0.4030018
Validation loss decreased (0.283564 --> 0.282942).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.5493052005767822
Epoch: 18, Steps: 65 | Train Loss: 0.3815683 Vali Loss: 0.2823657 Test Loss: 0.4023986
Validation loss decreased (0.282942 --> 0.282366).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.347442865371704
Epoch: 19, Steps: 65 | Train Loss: 0.3796578 Vali Loss: 0.2819755 Test Loss: 0.4019601
Validation loss decreased (0.282366 --> 0.281975).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.558777093887329
Epoch: 20, Steps: 65 | Train Loss: 0.3790058 Vali Loss: 0.2813882 Test Loss: 0.4015082
Validation loss decreased (0.281975 --> 0.281388).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.2271599769592285
Epoch: 21, Steps: 65 | Train Loss: 0.3788684 Vali Loss: 0.2811777 Test Loss: 0.4011402
Validation loss decreased (0.281388 --> 0.281178).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.5021889209747314
Epoch: 22, Steps: 65 | Train Loss: 0.3786299 Vali Loss: 0.2808641 Test Loss: 0.4008526
Validation loss decreased (0.281178 --> 0.280864).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.452073335647583
Epoch: 23, Steps: 65 | Train Loss: 0.3782020 Vali Loss: 0.2805378 Test Loss: 0.4005161
Validation loss decreased (0.280864 --> 0.280538).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.471398115158081
Epoch: 24, Steps: 65 | Train Loss: 0.3776705 Vali Loss: 0.2799435 Test Loss: 0.4002739
Validation loss decreased (0.280538 --> 0.279943).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.8289847373962402
Epoch: 25, Steps: 65 | Train Loss: 0.3777094 Vali Loss: 0.2800362 Test Loss: 0.4000416
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.322713851928711
Epoch: 26, Steps: 65 | Train Loss: 0.3763919 Vali Loss: 0.2798044 Test Loss: 0.3998083
Validation loss decreased (0.279943 --> 0.279804).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.1815459728240967
Epoch: 27, Steps: 65 | Train Loss: 0.3755350 Vali Loss: 0.2794614 Test Loss: 0.3996315
Validation loss decreased (0.279804 --> 0.279461).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.415581464767456
Epoch: 28, Steps: 65 | Train Loss: 0.3765761 Vali Loss: 0.2793735 Test Loss: 0.3994618
Validation loss decreased (0.279461 --> 0.279373).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.9291603565216064
Epoch: 29, Steps: 65 | Train Loss: 0.3754284 Vali Loss: 0.2788703 Test Loss: 0.3993206
Validation loss decreased (0.279373 --> 0.278870).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 1.2942087650299072
Epoch: 30, Steps: 65 | Train Loss: 0.3756128 Vali Loss: 0.2790573 Test Loss: 0.3991781
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.5150716304779053
Epoch: 31, Steps: 65 | Train Loss: 0.3751953 Vali Loss: 0.2788488 Test Loss: 0.3990276
Validation loss decreased (0.278870 --> 0.278849).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 1.5747694969177246
Epoch: 32, Steps: 65 | Train Loss: 0.3746047 Vali Loss: 0.2786405 Test Loss: 0.3989038
Validation loss decreased (0.278849 --> 0.278641).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.7971417903900146
Epoch: 33, Steps: 65 | Train Loss: 0.3750572 Vali Loss: 0.2786074 Test Loss: 0.3988359
Validation loss decreased (0.278641 --> 0.278607).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.3844873905181885
Epoch: 34, Steps: 65 | Train Loss: 0.3747469 Vali Loss: 0.2784991 Test Loss: 0.3987379
Validation loss decreased (0.278607 --> 0.278499).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 1.9742987155914307
Epoch: 35, Steps: 65 | Train Loss: 0.3744586 Vali Loss: 0.2783884 Test Loss: 0.3986192
Validation loss decreased (0.278499 --> 0.278388).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 3.3690686225891113
Epoch: 36, Steps: 65 | Train Loss: 0.3749762 Vali Loss: 0.2782029 Test Loss: 0.3985370
Validation loss decreased (0.278388 --> 0.278203).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 3.0029637813568115
Epoch: 37, Steps: 65 | Train Loss: 0.3745496 Vali Loss: 0.2781068 Test Loss: 0.3984644
Validation loss decreased (0.278203 --> 0.278107).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.762571096420288
Epoch: 38, Steps: 65 | Train Loss: 0.3737626 Vali Loss: 0.2780362 Test Loss: 0.3983793
Validation loss decreased (0.278107 --> 0.278036).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.60929536819458
Epoch: 39, Steps: 65 | Train Loss: 0.3735174 Vali Loss: 0.2779363 Test Loss: 0.3983212
Validation loss decreased (0.278036 --> 0.277936).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.8625712394714355
Epoch: 40, Steps: 65 | Train Loss: 0.3743320 Vali Loss: 0.2778645 Test Loss: 0.3982658
Validation loss decreased (0.277936 --> 0.277865).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.194413423538208
Epoch: 41, Steps: 65 | Train Loss: 0.3722491 Vali Loss: 0.2777253 Test Loss: 0.3981993
Validation loss decreased (0.277865 --> 0.277725).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.9818623065948486
Epoch: 42, Steps: 65 | Train Loss: 0.3743010 Vali Loss: 0.2775679 Test Loss: 0.3981524
Validation loss decreased (0.277725 --> 0.277568).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.6218271255493164
Epoch: 43, Steps: 65 | Train Loss: 0.3736577 Vali Loss: 0.2776506 Test Loss: 0.3980993
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 4.148809194564819
Epoch: 44, Steps: 65 | Train Loss: 0.3729385 Vali Loss: 0.2775953 Test Loss: 0.3980499
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 3.814296007156372
Epoch: 45, Steps: 65 | Train Loss: 0.3737964 Vali Loss: 0.2775244 Test Loss: 0.3979916
Validation loss decreased (0.277568 --> 0.277524).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.421433448791504
Epoch: 46, Steps: 65 | Train Loss: 0.3729134 Vali Loss: 0.2774526 Test Loss: 0.3979582
Validation loss decreased (0.277524 --> 0.277453).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 3.5311219692230225
Epoch: 47, Steps: 65 | Train Loss: 0.3737873 Vali Loss: 0.2773814 Test Loss: 0.3979247
Validation loss decreased (0.277453 --> 0.277381).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 6.057506322860718
Epoch: 48, Steps: 65 | Train Loss: 0.3723451 Vali Loss: 0.2773625 Test Loss: 0.3978862
Validation loss decreased (0.277381 --> 0.277362).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 2.874871253967285
Epoch: 49, Steps: 65 | Train Loss: 0.3723823 Vali Loss: 0.2772967 Test Loss: 0.3978543
Validation loss decreased (0.277362 --> 0.277297).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 3.5792391300201416
Epoch: 50, Steps: 65 | Train Loss: 0.3734049 Vali Loss: 0.2772328 Test Loss: 0.3978201
Validation loss decreased (0.277297 --> 0.277233).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 2.2356338500976562
Epoch: 51, Steps: 65 | Train Loss: 0.3736486 Vali Loss: 0.2772565 Test Loss: 0.3978054
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 2.462339162826538
Epoch: 52, Steps: 65 | Train Loss: 0.3730615 Vali Loss: 0.2772034 Test Loss: 0.3977733
Validation loss decreased (0.277233 --> 0.277203).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.7308175563812256
Epoch: 53, Steps: 65 | Train Loss: 0.3729996 Vali Loss: 0.2768004 Test Loss: 0.3977566
Validation loss decreased (0.277203 --> 0.276800).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.8670730590820312
Epoch: 54, Steps: 65 | Train Loss: 0.3732906 Vali Loss: 0.2770512 Test Loss: 0.3977249
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.909416675567627
Epoch: 55, Steps: 65 | Train Loss: 0.3708043 Vali Loss: 0.2770976 Test Loss: 0.3977018
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 3.888836145401001
Epoch: 56, Steps: 65 | Train Loss: 0.3733343 Vali Loss: 0.2770914 Test Loss: 0.3976883
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 3.5955684185028076
Epoch: 57, Steps: 65 | Train Loss: 0.3734957 Vali Loss: 0.2770098 Test Loss: 0.3976667
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 2.734355926513672
Epoch: 58, Steps: 65 | Train Loss: 0.3732227 Vali Loss: 0.2770067 Test Loss: 0.3976436
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 3.586400032043457
Epoch: 59, Steps: 65 | Train Loss: 0.3725214 Vali Loss: 0.2769795 Test Loss: 0.3976226
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 3.0779898166656494
Epoch: 60, Steps: 65 | Train Loss: 0.3728204 Vali Loss: 0.2769734 Test Loss: 0.3976098
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 3.0051865577697754
Epoch: 61, Steps: 65 | Train Loss: 0.3732264 Vali Loss: 0.2769043 Test Loss: 0.3975991
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 2.462557077407837
Epoch: 62, Steps: 65 | Train Loss: 0.3729636 Vali Loss: 0.2768319 Test Loss: 0.3975863
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 3.5313782691955566
Epoch: 63, Steps: 65 | Train Loss: 0.3722952 Vali Loss: 0.2768714 Test Loss: 0.3975729
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 2.201632261276245
Epoch: 64, Steps: 65 | Train Loss: 0.3724143 Vali Loss: 0.2768843 Test Loss: 0.3975587
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 3.04270339012146
Epoch: 65, Steps: 65 | Train Loss: 0.3721919 Vali Loss: 0.2765265 Test Loss: 0.3975494
Validation loss decreased (0.276800 --> 0.276527).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 2.236316204071045
Epoch: 66, Steps: 65 | Train Loss: 0.3719130 Vali Loss: 0.2767018 Test Loss: 0.3975288
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 2.0461573600769043
Epoch: 67, Steps: 65 | Train Loss: 0.3728716 Vali Loss: 0.2767003 Test Loss: 0.3975173
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 3.045178174972534
Epoch: 68, Steps: 65 | Train Loss: 0.3725365 Vali Loss: 0.2767690 Test Loss: 0.3975110
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 3.5657129287719727
Epoch: 69, Steps: 65 | Train Loss: 0.3732802 Vali Loss: 0.2767107 Test Loss: 0.3975017
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 2.6196391582489014
Epoch: 70, Steps: 65 | Train Loss: 0.3726892 Vali Loss: 0.2767349 Test Loss: 0.3974888
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 2.3211660385131836
Epoch: 71, Steps: 65 | Train Loss: 0.3722440 Vali Loss: 0.2767325 Test Loss: 0.3974805
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 3.9572715759277344
Epoch: 72, Steps: 65 | Train Loss: 0.3730221 Vali Loss: 0.2766750 Test Loss: 0.3974713
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 3.284445285797119
Epoch: 73, Steps: 65 | Train Loss: 0.3724411 Vali Loss: 0.2766118 Test Loss: 0.3974679
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 2.6311612129211426
Epoch: 74, Steps: 65 | Train Loss: 0.3723557 Vali Loss: 0.2766688 Test Loss: 0.3974579
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 3.154095411300659
Epoch: 75, Steps: 65 | Train Loss: 0.3728289 Vali Loss: 0.2766981 Test Loss: 0.3974542
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 2.971458673477173
Epoch: 76, Steps: 65 | Train Loss: 0.3727752 Vali Loss: 0.2766144 Test Loss: 0.3974470
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 2.3155412673950195
Epoch: 77, Steps: 65 | Train Loss: 0.3718975 Vali Loss: 0.2763080 Test Loss: 0.3974397
Validation loss decreased (0.276527 --> 0.276308).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 3.00752329826355
Epoch: 78, Steps: 65 | Train Loss: 0.3725601 Vali Loss: 0.2766564 Test Loss: 0.3974361
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 2.7635395526885986
Epoch: 79, Steps: 65 | Train Loss: 0.3703011 Vali Loss: 0.2766627 Test Loss: 0.3974302
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.762089729309082
Epoch: 80, Steps: 65 | Train Loss: 0.3724671 Vali Loss: 0.2765367 Test Loss: 0.3974261
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 3.2739622592926025
Epoch: 81, Steps: 65 | Train Loss: 0.3722077 Vali Loss: 0.2766058 Test Loss: 0.3974194
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 3.192424774169922
Epoch: 82, Steps: 65 | Train Loss: 0.3724120 Vali Loss: 0.2766406 Test Loss: 0.3974171
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 4.587075233459473
Epoch: 83, Steps: 65 | Train Loss: 0.3729892 Vali Loss: 0.2765675 Test Loss: 0.3974111
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 3.3030354976654053
Epoch: 84, Steps: 65 | Train Loss: 0.3715726 Vali Loss: 0.2764912 Test Loss: 0.3974059
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 3.452622413635254
Epoch: 85, Steps: 65 | Train Loss: 0.3710543 Vali Loss: 0.2765346 Test Loss: 0.3974006
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 4.31759786605835
Epoch: 86, Steps: 65 | Train Loss: 0.3728735 Vali Loss: 0.2765890 Test Loss: 0.3973986
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 6.154765367507935
Epoch: 87, Steps: 65 | Train Loss: 0.3726898 Vali Loss: 0.2765688 Test Loss: 0.3973948
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 3.0879552364349365
Epoch: 88, Steps: 65 | Train Loss: 0.3714847 Vali Loss: 0.2762294 Test Loss: 0.3973905
Validation loss decreased (0.276308 --> 0.276229).  Saving model ...
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 2.306004762649536
Epoch: 89, Steps: 65 | Train Loss: 0.3725180 Vali Loss: 0.2765301 Test Loss: 0.3973876
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 3.03965163230896
Epoch: 90, Steps: 65 | Train Loss: 0.3716585 Vali Loss: 0.2765715 Test Loss: 0.3973829
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 2.3199872970581055
Epoch: 91, Steps: 65 | Train Loss: 0.3721029 Vali Loss: 0.2765323 Test Loss: 0.3973822
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 2.6295325756073
Epoch: 92, Steps: 65 | Train Loss: 0.3723131 Vali Loss: 0.2764508 Test Loss: 0.3973794
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 2.564431667327881
Epoch: 93, Steps: 65 | Train Loss: 0.3724589 Vali Loss: 0.2765340 Test Loss: 0.3973766
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 2.747596025466919
Epoch: 94, Steps: 65 | Train Loss: 0.3720658 Vali Loss: 0.2765417 Test Loss: 0.3973729
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 3.3622074127197266
Epoch: 95, Steps: 65 | Train Loss: 0.3726762 Vali Loss: 0.2764726 Test Loss: 0.3973708
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 3.7167656421661377
Epoch: 96, Steps: 65 | Train Loss: 0.3723948 Vali Loss: 0.2765477 Test Loss: 0.3973683
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 2.8893392086029053
Epoch: 97, Steps: 65 | Train Loss: 0.3721985 Vali Loss: 0.2764944 Test Loss: 0.3973668
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 3.7336063385009766
Epoch: 98, Steps: 65 | Train Loss: 0.3728705 Vali Loss: 0.2765294 Test Loss: 0.3973644
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 3.093574285507202
Epoch: 99, Steps: 65 | Train Loss: 0.3730129 Vali Loss: 0.2765100 Test Loss: 0.3973615
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 3.02655291557312
Epoch: 100, Steps: 65 | Train Loss: 0.3726479 Vali Loss: 0.2765194 Test Loss: 0.3973612
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.1160680107021042e-06
train 8359
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=34, out_features=106, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3229184.0
params:  3710.0
Trainable parameters:  3710
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.4850780963897705
Epoch: 1, Steps: 65 | Train Loss: 0.5407963 Vali Loss: 0.2756406 Test Loss: 0.3966546
Validation loss decreased (inf --> 0.275641).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.0449349880218506
Epoch: 2, Steps: 65 | Train Loss: 0.5388811 Vali Loss: 0.2751113 Test Loss: 0.3962981
Validation loss decreased (0.275641 --> 0.275111).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.5738296508789062
Epoch: 3, Steps: 65 | Train Loss: 0.5390205 Vali Loss: 0.2747461 Test Loss: 0.3960848
Validation loss decreased (0.275111 --> 0.274746).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.76725435256958
Epoch: 4, Steps: 65 | Train Loss: 0.5377776 Vali Loss: 0.2743423 Test Loss: 0.3959765
Validation loss decreased (0.274746 --> 0.274342).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.8673036098480225
Epoch: 5, Steps: 65 | Train Loss: 0.5378932 Vali Loss: 0.2741118 Test Loss: 0.3959608
Validation loss decreased (0.274342 --> 0.274112).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.382659673690796
Epoch: 6, Steps: 65 | Train Loss: 0.5360470 Vali Loss: 0.2738102 Test Loss: 0.3958720
Validation loss decreased (0.274112 --> 0.273810).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.4407029151916504
Epoch: 7, Steps: 65 | Train Loss: 0.5377130 Vali Loss: 0.2738380 Test Loss: 0.3958535
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.5388994216918945
Epoch: 8, Steps: 65 | Train Loss: 0.5351585 Vali Loss: 0.2736791 Test Loss: 0.3958131
Validation loss decreased (0.273810 --> 0.273679).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 4.319960117340088
Epoch: 9, Steps: 65 | Train Loss: 0.5355808 Vali Loss: 0.2735994 Test Loss: 0.3959021
Validation loss decreased (0.273679 --> 0.273599).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.1946308612823486
Epoch: 10, Steps: 65 | Train Loss: 0.5353260 Vali Loss: 0.2734248 Test Loss: 0.3958423
Validation loss decreased (0.273599 --> 0.273425).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.8325283527374268
Epoch: 11, Steps: 65 | Train Loss: 0.5360462 Vali Loss: 0.2733834 Test Loss: 0.3958505
Validation loss decreased (0.273425 --> 0.273383).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.472155809402466
Epoch: 12, Steps: 65 | Train Loss: 0.5359316 Vali Loss: 0.2732840 Test Loss: 0.3958983
Validation loss decreased (0.273383 --> 0.273284).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.9502077102661133
Epoch: 13, Steps: 65 | Train Loss: 0.5369298 Vali Loss: 0.2732266 Test Loss: 0.3959517
Validation loss decreased (0.273284 --> 0.273227).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.8652470111846924
Epoch: 14, Steps: 65 | Train Loss: 0.5349766 Vali Loss: 0.2731931 Test Loss: 0.3959975
Validation loss decreased (0.273227 --> 0.273193).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.81815242767334
Epoch: 15, Steps: 65 | Train Loss: 0.5343670 Vali Loss: 0.2731545 Test Loss: 0.3960011
Validation loss decreased (0.273193 --> 0.273155).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.6319057941436768
Epoch: 16, Steps: 65 | Train Loss: 0.5354165 Vali Loss: 0.2729991 Test Loss: 0.3960472
Validation loss decreased (0.273155 --> 0.272999).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.7371413707733154
Epoch: 17, Steps: 65 | Train Loss: 0.5347843 Vali Loss: 0.2730066 Test Loss: 0.3960197
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.889936923980713
Epoch: 18, Steps: 65 | Train Loss: 0.5350210 Vali Loss: 0.2729031 Test Loss: 0.3959735
Validation loss decreased (0.272999 --> 0.272903).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 3.318911552429199
Epoch: 19, Steps: 65 | Train Loss: 0.5363052 Vali Loss: 0.2728026 Test Loss: 0.3959697
Validation loss decreased (0.272903 --> 0.272803).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.385334014892578
Epoch: 20, Steps: 65 | Train Loss: 0.5344997 Vali Loss: 0.2728357 Test Loss: 0.3959983
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.1450514793395996
Epoch: 21, Steps: 65 | Train Loss: 0.5350108 Vali Loss: 0.2728146 Test Loss: 0.3960289
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.9225480556488037
Epoch: 22, Steps: 65 | Train Loss: 0.5335456 Vali Loss: 0.2727663 Test Loss: 0.3960609
Validation loss decreased (0.272803 --> 0.272766).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 4.11803126335144
Epoch: 23, Steps: 65 | Train Loss: 0.5350341 Vali Loss: 0.2727623 Test Loss: 0.3960603
Validation loss decreased (0.272766 --> 0.272762).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.9501099586486816
Epoch: 24, Steps: 65 | Train Loss: 0.5349794 Vali Loss: 0.2727349 Test Loss: 0.3960852
Validation loss decreased (0.272762 --> 0.272735).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 6.173157215118408
Epoch: 25, Steps: 65 | Train Loss: 0.5332093 Vali Loss: 0.2726330 Test Loss: 0.3960974
Validation loss decreased (0.272735 --> 0.272633).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.3320751190185547
Epoch: 26, Steps: 65 | Train Loss: 0.5345296 Vali Loss: 0.2726145 Test Loss: 0.3960798
Validation loss decreased (0.272633 --> 0.272615).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.235804796218872
Epoch: 27, Steps: 65 | Train Loss: 0.5353053 Vali Loss: 0.2726661 Test Loss: 0.3961287
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.0049805641174316
Epoch: 28, Steps: 65 | Train Loss: 0.5354564 Vali Loss: 0.2725964 Test Loss: 0.3960942
Validation loss decreased (0.272615 --> 0.272596).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.9268083572387695
Epoch: 29, Steps: 65 | Train Loss: 0.5340845 Vali Loss: 0.2725112 Test Loss: 0.3961379
Validation loss decreased (0.272596 --> 0.272511).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.412200450897217
Epoch: 30, Steps: 65 | Train Loss: 0.5331861 Vali Loss: 0.2726161 Test Loss: 0.3961303
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.8345417976379395
Epoch: 31, Steps: 65 | Train Loss: 0.5355769 Vali Loss: 0.2725757 Test Loss: 0.3961453
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.6356730461120605
Epoch: 32, Steps: 65 | Train Loss: 0.5349636 Vali Loss: 0.2725069 Test Loss: 0.3961816
Validation loss decreased (0.272511 --> 0.272507).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 3.156360626220703
Epoch: 33, Steps: 65 | Train Loss: 0.5351145 Vali Loss: 0.2725631 Test Loss: 0.3961803
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.2201075553894043
Epoch: 34, Steps: 65 | Train Loss: 0.5335915 Vali Loss: 0.2725615 Test Loss: 0.3961906
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 3.099130630493164
Epoch: 35, Steps: 65 | Train Loss: 0.5352044 Vali Loss: 0.2725318 Test Loss: 0.3961826
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 3.9497592449188232
Epoch: 36, Steps: 65 | Train Loss: 0.5349269 Vali Loss: 0.2724641 Test Loss: 0.3961880
Validation loss decreased (0.272507 --> 0.272464).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.6961989402770996
Epoch: 37, Steps: 65 | Train Loss: 0.5322676 Vali Loss: 0.2721341 Test Loss: 0.3962060
Validation loss decreased (0.272464 --> 0.272134).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.9424452781677246
Epoch: 38, Steps: 65 | Train Loss: 0.5349483 Vali Loss: 0.2721311 Test Loss: 0.3961945
Validation loss decreased (0.272134 --> 0.272131).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.324254035949707
Epoch: 39, Steps: 65 | Train Loss: 0.5349578 Vali Loss: 0.2724847 Test Loss: 0.3961890
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.5010948181152344
Epoch: 40, Steps: 65 | Train Loss: 0.5348212 Vali Loss: 0.2724164 Test Loss: 0.3962092
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.6668732166290283
Epoch: 41, Steps: 65 | Train Loss: 0.5337126 Vali Loss: 0.2724466 Test Loss: 0.3962112
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.161499500274658
Epoch: 42, Steps: 65 | Train Loss: 0.5333697 Vali Loss: 0.2724600 Test Loss: 0.3962291
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.6204543113708496
Epoch: 43, Steps: 65 | Train Loss: 0.5343701 Vali Loss: 0.2724604 Test Loss: 0.3962220
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.6795332431793213
Epoch: 44, Steps: 65 | Train Loss: 0.5351657 Vali Loss: 0.2724476 Test Loss: 0.3962394
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 4.42313027381897
Epoch: 45, Steps: 65 | Train Loss: 0.5335956 Vali Loss: 0.2723718 Test Loss: 0.3962316
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 2.1683144569396973
Epoch: 46, Steps: 65 | Train Loss: 0.5346656 Vali Loss: 0.2723574 Test Loss: 0.3962373
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 4.562620401382446
Epoch: 47, Steps: 65 | Train Loss: 0.5342389 Vali Loss: 0.2723530 Test Loss: 0.3962585
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 3.3214142322540283
Epoch: 48, Steps: 65 | Train Loss: 0.5340743 Vali Loss: 0.2723773 Test Loss: 0.3962512
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 3.122485637664795
Epoch: 49, Steps: 65 | Train Loss: 0.5350025 Vali Loss: 0.2724375 Test Loss: 0.3962581
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 3.926440715789795
Epoch: 50, Steps: 65 | Train Loss: 0.5340762 Vali Loss: 0.2724013 Test Loss: 0.3962702
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 3.227210760116577
Epoch: 51, Steps: 65 | Train Loss: 0.5343171 Vali Loss: 0.2724052 Test Loss: 0.3962645
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.814859390258789
Epoch: 52, Steps: 65 | Train Loss: 0.5326723 Vali Loss: 0.2724265 Test Loss: 0.3962730
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 2.5639142990112305
Epoch: 53, Steps: 65 | Train Loss: 0.5326007 Vali Loss: 0.2723598 Test Loss: 0.3962821
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 3.189990997314453
Epoch: 54, Steps: 65 | Train Loss: 0.5322657 Vali Loss: 0.2723390 Test Loss: 0.3962778
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 2.3363726139068604
Epoch: 55, Steps: 65 | Train Loss: 0.5345753 Vali Loss: 0.2723438 Test Loss: 0.3962808
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 2.2204627990722656
Epoch: 56, Steps: 65 | Train Loss: 0.5341765 Vali Loss: 0.2722838 Test Loss: 0.3962884
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 3.726726770401001
Epoch: 57, Steps: 65 | Train Loss: 0.5292068 Vali Loss: 0.2723342 Test Loss: 0.3962798
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 5.615321159362793
Epoch: 58, Steps: 65 | Train Loss: 0.5350398 Vali Loss: 0.2723069 Test Loss: 0.3962851
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_90_192_FITS_ETTh2_ftM_sl90_ll48_pl192_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.3764805495738983, mae:0.39038312435150146, rse:0.49205324053764343, corr:[0.2688532  0.26947206 0.26810515 0.2681936  0.26620033 0.26575252
 0.26475444 0.26403493 0.26337543 0.2620389  0.2612849  0.25961423
 0.25766945 0.25644696 0.25538158 0.25471953 0.25414902 0.25381038
 0.25315502 0.25201222 0.25109217 0.250002   0.2489498  0.24700074
 0.24377179 0.24116985 0.23866181 0.23700933 0.2354831  0.23394313
 0.23302542 0.23163946 0.23026094 0.2285947  0.22746594 0.22623783
 0.22435911 0.22294804 0.22196582 0.22093032 0.22037628 0.22000472
 0.21942051 0.21875525 0.21790618 0.21661304 0.21580984 0.2138331
 0.21010679 0.20733371 0.20468836 0.2024883  0.20050931 0.19871679
 0.19698253 0.19453827 0.19350912 0.19162266 0.19047046 0.18937427
 0.18790697 0.18746643 0.18724456 0.18694921 0.18675199 0.18627644
 0.18571931 0.18509105 0.18458404 0.18408102 0.18338268 0.18190517
 0.17914335 0.17757282 0.17617773 0.17499933 0.17370595 0.17332754
 0.17352939 0.1724084  0.17205936 0.17146215 0.17134526 0.17108461
 0.17001483 0.1698261  0.16991964 0.169815   0.16967836 0.1692447
 0.16866139 0.16815911 0.16799629 0.16766101 0.16721918 0.1661285
 0.16393076 0.16188505 0.15982081 0.15858541 0.15727398 0.15629521
 0.1563135  0.15551253 0.15563843 0.15525281 0.15508324 0.15506549
 0.15431237 0.153887   0.15313411 0.15269782 0.15251952 0.15194869
 0.15168427 0.1512003  0.15047646 0.14973164 0.14847176 0.14624132
 0.14363517 0.14161095 0.13960478 0.13865712 0.13737585 0.13629456
 0.13593781 0.13534628 0.13510612 0.13434882 0.13415907 0.13367829
 0.13256936 0.13205455 0.13169259 0.13114296 0.1309539  0.13055214
 0.12989122 0.12952496 0.1291943  0.12873009 0.1278801  0.12572737
 0.12241048 0.11992193 0.11763509 0.11623557 0.11472867 0.11371701
 0.11378586 0.1129876  0.1126925  0.11217958 0.11232442 0.11206108
 0.11108615 0.11094329 0.11088935 0.11074309 0.11065691 0.11041482
 0.11028076 0.11009523 0.1097904  0.10987569 0.11017939 0.10834817
 0.10535191 0.10369334 0.10181863 0.10112078 0.10029711 0.09941323
 0.09968615 0.09914022 0.09873741 0.09830633 0.09856207 0.09789906
 0.09719216 0.09707695 0.09665305 0.09700514 0.09682564 0.0964257
 0.09670483 0.09631721 0.09629628 0.09747086 0.09732158 0.0998073 ]
