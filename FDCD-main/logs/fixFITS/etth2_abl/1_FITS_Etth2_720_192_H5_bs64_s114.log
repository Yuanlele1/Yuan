Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=165, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=165, out_features=209, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  30898560.0
params:  34694.0
Trainable parameters:  34694
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.002084255218506
Epoch: 1, Steps: 60 | Train Loss: 0.7266541 Vali Loss: 0.3898551 Test Loss: 0.3916116
Validation loss decreased (inf --> 0.389855).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.8858938217163086
Epoch: 2, Steps: 60 | Train Loss: 0.5932668 Vali Loss: 0.3427808 Test Loss: 0.3706144
Validation loss decreased (0.389855 --> 0.342781).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 1.9472944736480713
Epoch: 3, Steps: 60 | Train Loss: 0.5616183 Vali Loss: 0.3250397 Test Loss: 0.3638083
Validation loss decreased (0.342781 --> 0.325040).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 1.9187915325164795
Epoch: 4, Steps: 60 | Train Loss: 0.5507412 Vali Loss: 0.3163123 Test Loss: 0.3604243
Validation loss decreased (0.325040 --> 0.316312).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 1.8460791110992432
Epoch: 5, Steps: 60 | Train Loss: 0.5412737 Vali Loss: 0.3103412 Test Loss: 0.3588821
Validation loss decreased (0.316312 --> 0.310341).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 1.773256778717041
Epoch: 6, Steps: 60 | Train Loss: 0.5375219 Vali Loss: 0.3057990 Test Loss: 0.3580306
Validation loss decreased (0.310341 --> 0.305799).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 1.807394027709961
Epoch: 7, Steps: 60 | Train Loss: 0.5328516 Vali Loss: 0.3027614 Test Loss: 0.3572851
Validation loss decreased (0.305799 --> 0.302761).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 1.8937535285949707
Epoch: 8, Steps: 60 | Train Loss: 0.5307522 Vali Loss: 0.3002657 Test Loss: 0.3567329
Validation loss decreased (0.302761 --> 0.300266).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 1.8477637767791748
Epoch: 9, Steps: 60 | Train Loss: 0.5279147 Vali Loss: 0.2986348 Test Loss: 0.3560706
Validation loss decreased (0.300266 --> 0.298635).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 1.7337336540222168
Epoch: 10, Steps: 60 | Train Loss: 0.5257669 Vali Loss: 0.2975632 Test Loss: 0.3557433
Validation loss decreased (0.298635 --> 0.297563).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 1.7995836734771729
Epoch: 11, Steps: 60 | Train Loss: 0.5233510 Vali Loss: 0.2954721 Test Loss: 0.3554564
Validation loss decreased (0.297563 --> 0.295472).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 1.6217467784881592
Epoch: 12, Steps: 60 | Train Loss: 0.5231030 Vali Loss: 0.2943934 Test Loss: 0.3552513
Validation loss decreased (0.295472 --> 0.294393).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 1.8139042854309082
Epoch: 13, Steps: 60 | Train Loss: 0.5200760 Vali Loss: 0.2934603 Test Loss: 0.3549142
Validation loss decreased (0.294393 --> 0.293460).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.7527563571929932
Epoch: 14, Steps: 60 | Train Loss: 0.5210341 Vali Loss: 0.2923722 Test Loss: 0.3547854
Validation loss decreased (0.293460 --> 0.292372).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 1.8048045635223389
Epoch: 15, Steps: 60 | Train Loss: 0.5200485 Vali Loss: 0.2917769 Test Loss: 0.3545645
Validation loss decreased (0.292372 --> 0.291777).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 1.640216588973999
Epoch: 16, Steps: 60 | Train Loss: 0.5185585 Vali Loss: 0.2911856 Test Loss: 0.3543299
Validation loss decreased (0.291777 --> 0.291186).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 1.789574146270752
Epoch: 17, Steps: 60 | Train Loss: 0.5192785 Vali Loss: 0.2902365 Test Loss: 0.3542388
Validation loss decreased (0.291186 --> 0.290237).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 1.6643390655517578
Epoch: 18, Steps: 60 | Train Loss: 0.5185035 Vali Loss: 0.2900782 Test Loss: 0.3540691
Validation loss decreased (0.290237 --> 0.290078).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 1.949368953704834
Epoch: 19, Steps: 60 | Train Loss: 0.5187688 Vali Loss: 0.2896957 Test Loss: 0.3538692
Validation loss decreased (0.290078 --> 0.289696).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 1.9527554512023926
Epoch: 20, Steps: 60 | Train Loss: 0.5176193 Vali Loss: 0.2890955 Test Loss: 0.3538806
Validation loss decreased (0.289696 --> 0.289096).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 1.803175926208496
Epoch: 21, Steps: 60 | Train Loss: 0.5173753 Vali Loss: 0.2884203 Test Loss: 0.3538394
Validation loss decreased (0.289096 --> 0.288420).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 1.865952491760254
Epoch: 22, Steps: 60 | Train Loss: 0.5164729 Vali Loss: 0.2883065 Test Loss: 0.3535862
Validation loss decreased (0.288420 --> 0.288306).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 1.9544861316680908
Epoch: 23, Steps: 60 | Train Loss: 0.5160957 Vali Loss: 0.2880588 Test Loss: 0.3536511
Validation loss decreased (0.288306 --> 0.288059).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 1.58945894241333
Epoch: 24, Steps: 60 | Train Loss: 0.5156087 Vali Loss: 0.2877955 Test Loss: 0.3534492
Validation loss decreased (0.288059 --> 0.287796).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 1.8138136863708496
Epoch: 25, Steps: 60 | Train Loss: 0.5158447 Vali Loss: 0.2875124 Test Loss: 0.3534310
Validation loss decreased (0.287796 --> 0.287512).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 1.8690252304077148
Epoch: 26, Steps: 60 | Train Loss: 0.5155871 Vali Loss: 0.2871794 Test Loss: 0.3533522
Validation loss decreased (0.287512 --> 0.287179).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 1.8961966037750244
Epoch: 27, Steps: 60 | Train Loss: 0.5140928 Vali Loss: 0.2871089 Test Loss: 0.3532560
Validation loss decreased (0.287179 --> 0.287109).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 1.975642442703247
Epoch: 28, Steps: 60 | Train Loss: 0.5150420 Vali Loss: 0.2866507 Test Loss: 0.3532546
Validation loss decreased (0.287109 --> 0.286651).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 1.8186445236206055
Epoch: 29, Steps: 60 | Train Loss: 0.5132926 Vali Loss: 0.2867732 Test Loss: 0.3532143
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.074913740158081
Epoch: 30, Steps: 60 | Train Loss: 0.5139839 Vali Loss: 0.2863573 Test Loss: 0.3532096
Validation loss decreased (0.286651 --> 0.286357).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 1.5521900653839111
Epoch: 31, Steps: 60 | Train Loss: 0.5141710 Vali Loss: 0.2863352 Test Loss: 0.3531053
Validation loss decreased (0.286357 --> 0.286335).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.06231689453125
Epoch: 32, Steps: 60 | Train Loss: 0.5141574 Vali Loss: 0.2862396 Test Loss: 0.3530234
Validation loss decreased (0.286335 --> 0.286240).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 1.8236145973205566
Epoch: 33, Steps: 60 | Train Loss: 0.5145196 Vali Loss: 0.2857623 Test Loss: 0.3530904
Validation loss decreased (0.286240 --> 0.285762).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 1.631406545639038
Epoch: 34, Steps: 60 | Train Loss: 0.5124090 Vali Loss: 0.2856827 Test Loss: 0.3530016
Validation loss decreased (0.285762 --> 0.285683).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.197835922241211
Epoch: 35, Steps: 60 | Train Loss: 0.5141201 Vali Loss: 0.2858026 Test Loss: 0.3529930
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 1.925166368484497
Epoch: 36, Steps: 60 | Train Loss: 0.5133886 Vali Loss: 0.2856097 Test Loss: 0.3529982
Validation loss decreased (0.285683 --> 0.285610).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 1.8873660564422607
Epoch: 37, Steps: 60 | Train Loss: 0.5120657 Vali Loss: 0.2854760 Test Loss: 0.3529763
Validation loss decreased (0.285610 --> 0.285476).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 1.7362709045410156
Epoch: 38, Steps: 60 | Train Loss: 0.5139998 Vali Loss: 0.2855008 Test Loss: 0.3529128
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 1.8165225982666016
Epoch: 39, Steps: 60 | Train Loss: 0.5125924 Vali Loss: 0.2853461 Test Loss: 0.3528875
Validation loss decreased (0.285476 --> 0.285346).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 1.958367109298706
Epoch: 40, Steps: 60 | Train Loss: 0.5103798 Vali Loss: 0.2852024 Test Loss: 0.3529533
Validation loss decreased (0.285346 --> 0.285202).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 1.9172616004943848
Epoch: 41, Steps: 60 | Train Loss: 0.5132449 Vali Loss: 0.2850768 Test Loss: 0.3528816
Validation loss decreased (0.285202 --> 0.285077).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 1.9211628437042236
Epoch: 42, Steps: 60 | Train Loss: 0.5136678 Vali Loss: 0.2851017 Test Loss: 0.3528769
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 1.922309160232544
Epoch: 43, Steps: 60 | Train Loss: 0.5130777 Vali Loss: 0.2850882 Test Loss: 0.3528341
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 1.8927562236785889
Epoch: 44, Steps: 60 | Train Loss: 0.5113902 Vali Loss: 0.2849270 Test Loss: 0.3528810
Validation loss decreased (0.285077 --> 0.284927).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 1.8645374774932861
Epoch: 45, Steps: 60 | Train Loss: 0.5132771 Vali Loss: 0.2848419 Test Loss: 0.3528007
Validation loss decreased (0.284927 --> 0.284842).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 1.9621326923370361
Epoch: 46, Steps: 60 | Train Loss: 0.5124334 Vali Loss: 0.2848972 Test Loss: 0.3528117
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 1.566938877105713
Epoch: 47, Steps: 60 | Train Loss: 0.5131157 Vali Loss: 0.2848103 Test Loss: 0.3528063
Validation loss decreased (0.284842 --> 0.284810).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 1.8515808582305908
Epoch: 48, Steps: 60 | Train Loss: 0.5119026 Vali Loss: 0.2846670 Test Loss: 0.3528280
Validation loss decreased (0.284810 --> 0.284667).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 1.6185083389282227
Epoch: 49, Steps: 60 | Train Loss: 0.5120890 Vali Loss: 0.2847680 Test Loss: 0.3527630
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 1.628221035003662
Epoch: 50, Steps: 60 | Train Loss: 0.5108613 Vali Loss: 0.2846214 Test Loss: 0.3527736
Validation loss decreased (0.284667 --> 0.284621).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 1.7126708030700684
Epoch: 51, Steps: 60 | Train Loss: 0.5133668 Vali Loss: 0.2841921 Test Loss: 0.3527810
Validation loss decreased (0.284621 --> 0.284192).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 1.5427322387695312
Epoch: 52, Steps: 60 | Train Loss: 0.5112919 Vali Loss: 0.2845122 Test Loss: 0.3527486
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 1.56559157371521
Epoch: 53, Steps: 60 | Train Loss: 0.5123659 Vali Loss: 0.2844552 Test Loss: 0.3527237
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 1.6117327213287354
Epoch: 54, Steps: 60 | Train Loss: 0.5124386 Vali Loss: 0.2844393 Test Loss: 0.3527187
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 1.7398037910461426
Epoch: 55, Steps: 60 | Train Loss: 0.5106601 Vali Loss: 0.2843764 Test Loss: 0.3527048
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 1.882521629333496
Epoch: 56, Steps: 60 | Train Loss: 0.5127553 Vali Loss: 0.2839543 Test Loss: 0.3527395
Validation loss decreased (0.284192 --> 0.283954).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 1.6018099784851074
Epoch: 57, Steps: 60 | Train Loss: 0.5121835 Vali Loss: 0.2843847 Test Loss: 0.3527233
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 1.4356129169464111
Epoch: 58, Steps: 60 | Train Loss: 0.5120541 Vali Loss: 0.2842250 Test Loss: 0.3526959
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 1.7980096340179443
Epoch: 59, Steps: 60 | Train Loss: 0.5108165 Vali Loss: 0.2840449 Test Loss: 0.3526735
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 1.7584044933319092
Epoch: 60, Steps: 60 | Train Loss: 0.5120981 Vali Loss: 0.2843176 Test Loss: 0.3526870
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 1.7563261985778809
Epoch: 61, Steps: 60 | Train Loss: 0.5106242 Vali Loss: 0.2841334 Test Loss: 0.3527178
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 1.7053158283233643
Epoch: 62, Steps: 60 | Train Loss: 0.5116924 Vali Loss: 0.2841876 Test Loss: 0.3526717
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 1.919388771057129
Epoch: 63, Steps: 60 | Train Loss: 0.5102965 Vali Loss: 0.2841715 Test Loss: 0.3526708
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 1.9265201091766357
Epoch: 64, Steps: 60 | Train Loss: 0.5119292 Vali Loss: 0.2842182 Test Loss: 0.3526666
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 1.979557991027832
Epoch: 65, Steps: 60 | Train Loss: 0.5119552 Vali Loss: 0.2841653 Test Loss: 0.3526611
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 1.7718961238861084
Epoch: 66, Steps: 60 | Train Loss: 0.5117490 Vali Loss: 0.2841120 Test Loss: 0.3526674
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 1.8469061851501465
Epoch: 67, Steps: 60 | Train Loss: 0.5113008 Vali Loss: 0.2840865 Test Loss: 0.3526737
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 1.511625051498413
Epoch: 68, Steps: 60 | Train Loss: 0.5120084 Vali Loss: 0.2840757 Test Loss: 0.3526542
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 1.5025479793548584
Epoch: 69, Steps: 60 | Train Loss: 0.5106022 Vali Loss: 0.2840856 Test Loss: 0.3526568
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 1.7892327308654785
Epoch: 70, Steps: 60 | Train Loss: 0.5108452 Vali Loss: 0.2840339 Test Loss: 0.3526581
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 1.7316033840179443
Epoch: 71, Steps: 60 | Train Loss: 0.5114952 Vali Loss: 0.2840210 Test Loss: 0.3526412
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 1.6078438758850098
Epoch: 72, Steps: 60 | Train Loss: 0.5115367 Vali Loss: 0.2840257 Test Loss: 0.3526456
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 1.570521354675293
Epoch: 73, Steps: 60 | Train Loss: 0.5119498 Vali Loss: 0.2839930 Test Loss: 0.3526402
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 1.7096049785614014
Epoch: 74, Steps: 60 | Train Loss: 0.5123880 Vali Loss: 0.2839462 Test Loss: 0.3526426
Validation loss decreased (0.283954 --> 0.283946).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 1.786750316619873
Epoch: 75, Steps: 60 | Train Loss: 0.5094846 Vali Loss: 0.2839798 Test Loss: 0.3526337
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 1.7292418479919434
Epoch: 76, Steps: 60 | Train Loss: 0.5124454 Vali Loss: 0.2839067 Test Loss: 0.3526345
Validation loss decreased (0.283946 --> 0.283907).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 1.8793087005615234
Epoch: 77, Steps: 60 | Train Loss: 0.5123314 Vali Loss: 0.2837593 Test Loss: 0.3526364
Validation loss decreased (0.283907 --> 0.283759).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 2.020085573196411
Epoch: 78, Steps: 60 | Train Loss: 0.5092913 Vali Loss: 0.2839336 Test Loss: 0.3526376
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 1.7777783870697021
Epoch: 79, Steps: 60 | Train Loss: 0.5101677 Vali Loss: 0.2839414 Test Loss: 0.3526306
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 2.0085558891296387
Epoch: 80, Steps: 60 | Train Loss: 0.5108786 Vali Loss: 0.2838551 Test Loss: 0.3526307
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 1.85695481300354
Epoch: 81, Steps: 60 | Train Loss: 0.5107070 Vali Loss: 0.2839329 Test Loss: 0.3526306
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 1.8057632446289062
Epoch: 82, Steps: 60 | Train Loss: 0.5114402 Vali Loss: 0.2839353 Test Loss: 0.3526217
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 1.8802006244659424
Epoch: 83, Steps: 60 | Train Loss: 0.5117087 Vali Loss: 0.2838763 Test Loss: 0.3526272
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 1.7552292346954346
Epoch: 84, Steps: 60 | Train Loss: 0.5114105 Vali Loss: 0.2838451 Test Loss: 0.3526230
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 1.5416903495788574
Epoch: 85, Steps: 60 | Train Loss: 0.5117902 Vali Loss: 0.2838942 Test Loss: 0.3526223
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 1.9276127815246582
Epoch: 86, Steps: 60 | Train Loss: 0.5106734 Vali Loss: 0.2839040 Test Loss: 0.3526174
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 1.7451550960540771
Epoch: 87, Steps: 60 | Train Loss: 0.5120784 Vali Loss: 0.2838822 Test Loss: 0.3526162
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 1.7990944385528564
Epoch: 88, Steps: 60 | Train Loss: 0.5118013 Vali Loss: 0.2838441 Test Loss: 0.3526175
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 1.783433437347412
Epoch: 89, Steps: 60 | Train Loss: 0.5113949 Vali Loss: 0.2838841 Test Loss: 0.3526186
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 1.668015718460083
Epoch: 90, Steps: 60 | Train Loss: 0.5120397 Vali Loss: 0.2838871 Test Loss: 0.3526132
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 1.9034693241119385
Epoch: 91, Steps: 60 | Train Loss: 0.5111561 Vali Loss: 0.2838727 Test Loss: 0.3526145
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 1.867347002029419
Epoch: 92, Steps: 60 | Train Loss: 0.5101190 Vali Loss: 0.2837991 Test Loss: 0.3526119
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 1.7395777702331543
Epoch: 93, Steps: 60 | Train Loss: 0.5119633 Vali Loss: 0.2838216 Test Loss: 0.3526109
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 1.8999392986297607
Epoch: 94, Steps: 60 | Train Loss: 0.5124497 Vali Loss: 0.2838210 Test Loss: 0.3526087
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 1.4924616813659668
Epoch: 95, Steps: 60 | Train Loss: 0.5118183 Vali Loss: 0.2838263 Test Loss: 0.3526087
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 1.6926403045654297
Epoch: 96, Steps: 60 | Train Loss: 0.5081832 Vali Loss: 0.2838479 Test Loss: 0.3526126
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 1.8968579769134521
Epoch: 97, Steps: 60 | Train Loss: 0.5095621 Vali Loss: 0.2838284 Test Loss: 0.3526109
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.33212220668792725, mae:0.37505197525024414, rse:0.462157279253006, corr:[0.2621934  0.26738343 0.26542088 0.2654762  0.26624423 0.26552927
 0.26450354 0.26419795 0.26385304 0.26257718 0.2610269  0.25974047
 0.25876337 0.2578903  0.25709328 0.25660405 0.25628766 0.25569156
 0.25452548 0.25324932 0.25213382 0.25111523 0.24969609 0.24786162
 0.24597006 0.24437292 0.24291761 0.2413529  0.23974241 0.23834684
 0.23731302 0.2361081  0.23477985 0.23339267 0.2323138  0.23146169
 0.23044007 0.22925115 0.22825731 0.22762112 0.22711115 0.22641784
 0.22550005 0.22460599 0.22380741 0.2228805  0.221518   0.21973373
 0.21796216 0.21633111 0.21470699 0.21310204 0.21170487 0.21008688
 0.20795232 0.2060661  0.20457758 0.20301937 0.20145935 0.20033598
 0.19992985 0.19960907 0.19928156 0.19904889 0.19867876 0.19828531
 0.19761518 0.19687915 0.19640543 0.19589444 0.19497176 0.19394365
 0.1931154  0.19228424 0.19103657 0.18947229 0.18862924 0.18843094
 0.18800561 0.18695994 0.18638583 0.18622176 0.18587828 0.18518703
 0.18467599 0.18475291 0.18480226 0.18431686 0.18348464 0.1830712
 0.18296616 0.18249705 0.18202774 0.18176611 0.18170054 0.18132962
 0.18043897 0.17949821 0.17882213 0.17801042 0.17683604 0.17562743
 0.17500852 0.1745086  0.17381878 0.17298366 0.17256588 0.17268571
 0.17218386 0.17112611 0.17015737 0.1699182  0.16965981 0.16917607
 0.16853593 0.16803055 0.16754098 0.16638279 0.16494453 0.16360593
 0.16255952 0.16113898 0.1595632  0.15834755 0.15756644 0.1567268
 0.15556538 0.15430982 0.15363249 0.15314528 0.15229467 0.15102929
 0.15032533 0.1501103  0.14961565 0.1488584  0.1483558  0.14823005
 0.14763735 0.14646344 0.14578447 0.14587694 0.14559503 0.14383638
 0.1413416  0.13986215 0.13913323 0.13773292 0.135765   0.13467823
 0.13488874 0.13430595 0.13288805 0.13183072 0.13189553 0.1318329
 0.13103542 0.13025136 0.13068682 0.13172187 0.13127257 0.13021849
 0.13009936 0.13067912 0.13049254 0.12943567 0.12924486 0.12957764
 0.12863728 0.12578136 0.12387834 0.12415216 0.12462498 0.12234118
 0.11919986 0.1179882  0.11841744 0.11760601 0.11476814 0.11396791
 0.11556808 0.1159931  0.11468933 0.11508354 0.11726832 0.11765312
 0.11516801 0.11457174 0.11919713 0.12063035 0.11751059 0.12615705]
