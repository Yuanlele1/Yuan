Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=144, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=25, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='weather.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=21, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=True, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Weather_360_j192_H5', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=2021, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Weather_360_j192_H5_FITS_custom_ftM_sl360_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36336
val 5079
test 10348
Model(
  (freq_upsampler): ModuleList(
    (0): Linear(in_features=25, out_features=38, bias=True)
    (1): Linear(in_features=25, out_features=38, bias=True)
    (2): Linear(in_features=25, out_features=38, bias=True)
    (3): Linear(in_features=25, out_features=38, bias=True)
    (4): Linear(in_features=25, out_features=38, bias=True)
    (5): Linear(in_features=25, out_features=38, bias=True)
    (6): Linear(in_features=25, out_features=38, bias=True)
    (7): Linear(in_features=25, out_features=38, bias=True)
    (8): Linear(in_features=25, out_features=38, bias=True)
    (9): Linear(in_features=25, out_features=38, bias=True)
    (10): Linear(in_features=25, out_features=38, bias=True)
    (11): Linear(in_features=25, out_features=38, bias=True)
    (12): Linear(in_features=25, out_features=38, bias=True)
    (13): Linear(in_features=25, out_features=38, bias=True)
    (14): Linear(in_features=25, out_features=38, bias=True)
    (15): Linear(in_features=25, out_features=38, bias=True)
    (16): Linear(in_features=25, out_features=38, bias=True)
    (17): Linear(in_features=25, out_features=38, bias=True)
    (18): Linear(in_features=25, out_features=38, bias=True)
    (19): Linear(in_features=25, out_features=38, bias=True)
    (20): Linear(in_features=25, out_features=38, bias=True)
  )
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1276800.0
params:  20748.0
Trainable parameters:  20748
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5385559
	speed: 0.0459s/iter; left time: 2599.7422s
	iters: 200, epoch: 1 | loss: 0.7642050
	speed: 0.0444s/iter; left time: 2505.9203s
	iters: 300, epoch: 1 | loss: 0.4493088
	speed: 0.0541s/iter; left time: 3049.5373s
	iters: 400, epoch: 1 | loss: 0.6423342
	speed: 0.0527s/iter; left time: 2966.6569s
	iters: 500, epoch: 1 | loss: 0.6447133
	speed: 0.0510s/iter; left time: 2866.0218s
Epoch: 1 cost time: 28.0850887298584
Epoch: 1, Steps: 567 | Train Loss: 0.5660025 Vali Loss: 0.4802881 Test Loss: 0.2137427
Validation loss decreased (inf --> 0.480288).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3339480
	speed: 0.1760s/iter; left time: 9860.5168s
	iters: 200, epoch: 2 | loss: 0.3883682
	speed: 0.0547s/iter; left time: 3057.1238s
	iters: 300, epoch: 2 | loss: 0.4451385
	speed: 0.0362s/iter; left time: 2021.8937s
	iters: 400, epoch: 2 | loss: 0.4690421
	speed: 0.0447s/iter; left time: 2492.1426s
	iters: 500, epoch: 2 | loss: 0.4419571
	speed: 0.0482s/iter; left time: 2679.7949s
Epoch: 2 cost time: 25.966293334960938
Epoch: 2, Steps: 567 | Train Loss: 0.4829671 Vali Loss: 0.4657409 Test Loss: 0.2028394
Validation loss decreased (0.480288 --> 0.465741).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3993882
	speed: 0.1682s/iter; left time: 9331.9604s
	iters: 200, epoch: 3 | loss: 0.3858323
	speed: 0.0507s/iter; left time: 2808.5414s
	iters: 300, epoch: 3 | loss: 0.4504624
	speed: 0.0561s/iter; left time: 3098.3108s
	iters: 400, epoch: 3 | loss: 0.4186960
	speed: 0.0482s/iter; left time: 2660.4871s
	iters: 500, epoch: 3 | loss: 0.6496640
	speed: 0.0440s/iter; left time: 2420.9434s
Epoch: 3 cost time: 27.06440258026123
Epoch: 3, Steps: 567 | Train Loss: 0.4743152 Vali Loss: 0.4597511 Test Loss: 0.1981793
Validation loss decreased (0.465741 --> 0.459751).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.6212618
	speed: 0.1611s/iter; left time: 8846.2309s
	iters: 200, epoch: 4 | loss: 0.6511672
	speed: 0.0525s/iter; left time: 2875.7491s
	iters: 300, epoch: 4 | loss: 0.3633228
	speed: 0.0460s/iter; left time: 2515.4435s
	iters: 400, epoch: 4 | loss: 0.3633940
	speed: 0.0355s/iter; left time: 1940.5105s
	iters: 500, epoch: 4 | loss: 0.3239978
	speed: 0.0454s/iter; left time: 2472.3947s
Epoch: 4 cost time: 26.479072332382202
Epoch: 4, Steps: 567 | Train Loss: 0.4702063 Vali Loss: 0.4574650 Test Loss: 0.1956427
Validation loss decreased (0.459751 --> 0.457465).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.6464343
	speed: 0.1792s/iter; left time: 9734.4422s
	iters: 200, epoch: 5 | loss: 0.3592124
	speed: 0.0325s/iter; left time: 1763.8548s
	iters: 300, epoch: 5 | loss: 0.4608082
	speed: 0.0330s/iter; left time: 1785.7573s
	iters: 400, epoch: 5 | loss: 0.3744706
	speed: 0.0392s/iter; left time: 2117.6649s
	iters: 500, epoch: 5 | loss: 0.3904425
	speed: 0.0400s/iter; left time: 2156.4609s
Epoch: 5 cost time: 23.570781707763672
Epoch: 5, Steps: 567 | Train Loss: 0.4676955 Vali Loss: 0.4565859 Test Loss: 0.1940964
Validation loss decreased (0.457465 --> 0.456586).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3884118
	speed: 0.2005s/iter; left time: 10781.0222s
	iters: 200, epoch: 6 | loss: 0.4293174
	speed: 0.0496s/iter; left time: 2663.9508s
	iters: 300, epoch: 6 | loss: 0.5123245
	speed: 0.0322s/iter; left time: 1726.0759s
	iters: 400, epoch: 6 | loss: 0.3321915
	speed: 0.0323s/iter; left time: 1724.3301s
	iters: 500, epoch: 6 | loss: 0.4654601
	speed: 0.0445s/iter; left time: 2377.1837s
Epoch: 6 cost time: 23.11095690727234
Epoch: 6, Steps: 567 | Train Loss: 0.4663862 Vali Loss: 0.4544460 Test Loss: 0.1928144
Validation loss decreased (0.456586 --> 0.454446).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.6536636
	speed: 0.1690s/iter; left time: 8988.3442s
	iters: 200, epoch: 7 | loss: 0.3286421
	speed: 0.0384s/iter; left time: 2040.8151s
	iters: 300, epoch: 7 | loss: 0.4538009
	speed: 0.0502s/iter; left time: 2662.7636s
	iters: 400, epoch: 7 | loss: 0.4873917
	speed: 0.0481s/iter; left time: 2543.1774s
	iters: 500, epoch: 7 | loss: 0.3373573
	speed: 0.0308s/iter; left time: 1628.7094s
Epoch: 7 cost time: 25.01960277557373
Epoch: 7, Steps: 567 | Train Loss: 0.4656900 Vali Loss: 0.4540290 Test Loss: 0.1921636
Validation loss decreased (0.454446 --> 0.454029).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.5895419
	speed: 0.1711s/iter; left time: 9005.9867s
	iters: 200, epoch: 8 | loss: 0.6426786
	speed: 0.0465s/iter; left time: 2440.9127s
	iters: 300, epoch: 8 | loss: 0.6287159
	speed: 0.0465s/iter; left time: 2436.5927s
	iters: 400, epoch: 8 | loss: 0.6162633
	speed: 0.0328s/iter; left time: 1715.7300s
	iters: 500, epoch: 8 | loss: 0.4301735
	speed: 0.0430s/iter; left time: 2244.3410s
Epoch: 8 cost time: 23.94017744064331
Epoch: 8, Steps: 567 | Train Loss: 0.4648873 Vali Loss: 0.4527985 Test Loss: 0.1915117
Validation loss decreased (0.454029 --> 0.452799).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3813890
	speed: 0.1608s/iter; left time: 8374.0979s
	iters: 200, epoch: 9 | loss: 0.4098478
	speed: 0.0434s/iter; left time: 2256.1553s
	iters: 300, epoch: 9 | loss: 0.4486977
	speed: 0.0415s/iter; left time: 2154.3723s
	iters: 400, epoch: 9 | loss: 0.3567000
	speed: 0.0334s/iter; left time: 1729.9009s
	iters: 500, epoch: 9 | loss: 0.3629760
	speed: 0.0325s/iter; left time: 1679.7844s
Epoch: 9 cost time: 21.690680980682373
Epoch: 9, Steps: 567 | Train Loss: 0.4643641 Vali Loss: 0.4529878 Test Loss: 0.1911150
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 1.1780205
	speed: 0.1557s/iter; left time: 8019.5114s
	iters: 200, epoch: 10 | loss: 0.6503959
	speed: 0.0553s/iter; left time: 2841.4576s
	iters: 300, epoch: 10 | loss: 0.3236570
	speed: 0.0552s/iter; left time: 2829.0999s
	iters: 400, epoch: 10 | loss: 0.6510184
	speed: 0.0426s/iter; left time: 2181.3834s
	iters: 500, epoch: 10 | loss: 0.4471681
	speed: 0.0358s/iter; left time: 1829.1312s
Epoch: 10 cost time: 25.648207664489746
Epoch: 10, Steps: 567 | Train Loss: 0.4638016 Vali Loss: 0.4523593 Test Loss: 0.1908562
Validation loss decreased (0.452799 --> 0.452359).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4296620
	speed: 0.1582s/iter; left time: 8056.8046s
	iters: 200, epoch: 11 | loss: 0.4220554
	speed: 0.0385s/iter; left time: 1955.2266s
	iters: 300, epoch: 11 | loss: 0.5740703
	speed: 0.0419s/iter; left time: 2125.6091s
	iters: 400, epoch: 11 | loss: 0.3040191
	speed: 0.0359s/iter; left time: 1819.9579s
	iters: 500, epoch: 11 | loss: 0.5865898
	speed: 0.0263s/iter; left time: 1328.0871s
Epoch: 11 cost time: 21.384944915771484
Epoch: 11, Steps: 567 | Train Loss: 0.4630511 Vali Loss: 0.4522381 Test Loss: 0.1906199
Validation loss decreased (0.452359 --> 0.452238).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4143324
	speed: 0.1691s/iter; left time: 8517.3446s
	iters: 200, epoch: 12 | loss: 0.3219342
	speed: 0.0312s/iter; left time: 1569.6561s
	iters: 300, epoch: 12 | loss: 0.6017793
	speed: 0.0340s/iter; left time: 1706.4797s
	iters: 400, epoch: 12 | loss: 0.3157947
	speed: 0.0439s/iter; left time: 2196.4777s
	iters: 500, epoch: 12 | loss: 0.6187232
	speed: 0.0428s/iter; left time: 2139.5227s
Epoch: 12 cost time: 23.66168975830078
Epoch: 12, Steps: 567 | Train Loss: 0.4630823 Vali Loss: 0.4518943 Test Loss: 0.1903431
Validation loss decreased (0.452238 --> 0.451894).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.6225480
	speed: 0.1719s/iter; left time: 8559.9436s
	iters: 200, epoch: 13 | loss: 0.4230836
	speed: 0.0430s/iter; left time: 2136.6801s
	iters: 300, epoch: 13 | loss: 0.3326839
	speed: 0.0395s/iter; left time: 1959.9336s
	iters: 400, epoch: 13 | loss: 0.4007722
	speed: 0.0333s/iter; left time: 1650.5906s
	iters: 500, epoch: 13 | loss: 0.7026192
	speed: 0.0379s/iter; left time: 1873.4605s
Epoch: 13 cost time: 22.299619913101196
Epoch: 13, Steps: 567 | Train Loss: 0.4627831 Vali Loss: 0.4504777 Test Loss: 0.1900832
Validation loss decreased (0.451894 --> 0.450478).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4555860
	speed: 0.1644s/iter; left time: 8092.9094s
	iters: 200, epoch: 14 | loss: 0.3304113
	speed: 0.0388s/iter; left time: 1905.8720s
	iters: 300, epoch: 14 | loss: 0.4214579
	speed: 0.0476s/iter; left time: 2332.0148s
	iters: 400, epoch: 14 | loss: 0.7787818
	speed: 0.0436s/iter; left time: 2133.0625s
	iters: 500, epoch: 14 | loss: 0.5399348
	speed: 0.0513s/iter; left time: 2503.1091s
Epoch: 14 cost time: 25.520061016082764
Epoch: 14, Steps: 567 | Train Loss: 0.4621519 Vali Loss: 0.4512904 Test Loss: 0.1898801
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.8954800
	speed: 0.1751s/iter; left time: 8522.8239s
	iters: 200, epoch: 15 | loss: 0.3880375
	speed: 0.0379s/iter; left time: 1838.1134s
	iters: 300, epoch: 15 | loss: 0.6107398
	speed: 0.0383s/iter; left time: 1855.5928s
	iters: 400, epoch: 15 | loss: 0.3908131
	speed: 0.0381s/iter; left time: 1843.0882s
	iters: 500, epoch: 15 | loss: 0.4377727
	speed: 0.0449s/iter; left time: 2168.4887s
Epoch: 15 cost time: 22.946248054504395
Epoch: 15, Steps: 567 | Train Loss: 0.4623543 Vali Loss: 0.4508924 Test Loss: 0.1898443
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3712750
	speed: 0.1533s/iter; left time: 7372.1864s
	iters: 200, epoch: 16 | loss: 0.3963363
	speed: 0.0345s/iter; left time: 1653.7737s
	iters: 300, epoch: 16 | loss: 0.7038397
	speed: 0.0339s/iter; left time: 1625.5312s
	iters: 400, epoch: 16 | loss: 0.4109500
	speed: 0.0417s/iter; left time: 1992.6485s
	iters: 500, epoch: 16 | loss: 0.3495979
	speed: 0.0436s/iter; left time: 2078.9400s
Epoch: 16 cost time: 21.890531301498413
Epoch: 16, Steps: 567 | Train Loss: 0.4620984 Vali Loss: 0.4506604 Test Loss: 0.1895320
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Weather_360_j192_H5_FITS_custom_ftM_sl360_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10348
mse:0.19033178687095642, mae:0.2399689257144928, rse:0.5742801427841187, corr:[0.47620887 0.47713974 0.4772169  0.47673884 0.47584987 0.47469074
 0.4735345  0.4726134  0.4719334  0.47145712 0.4710361  0.47059235
 0.47001228 0.46926722 0.46839297 0.46740696 0.46639147 0.46536058
 0.4644195  0.46353087 0.4626855  0.46184167 0.4609767  0.46004114
 0.45900372 0.45786425 0.4566401  0.45538786 0.45420545 0.4531607
 0.45233884 0.45167553 0.45119354 0.45079058 0.45047736 0.45015806
 0.4498571  0.44948325 0.44897377 0.4483742  0.44768727 0.44701725
 0.44627512 0.44553962 0.44479468 0.44407794 0.44342127 0.44289997
 0.44236365 0.4418222  0.44129488 0.44079435 0.44032633 0.4398437
 0.4393737  0.43887985 0.43838584 0.43790817 0.43759143 0.43736875
 0.43724242 0.43711197 0.43704265 0.4369364  0.4368267  0.4367024
 0.4365214  0.4362284  0.4359228  0.43561995 0.43535483 0.43501338
 0.43466532 0.43436834 0.43405282 0.43376622 0.43354872 0.4334333
 0.43338275 0.4333387  0.43331417 0.433273   0.4331768  0.43305296
 0.43289784 0.43274012 0.4325893  0.4323952  0.432221   0.43203178
 0.4318818  0.43179178 0.43171978 0.43170023 0.43169853 0.43169293
 0.43166724 0.4315927  0.43146473 0.43126345 0.43102586 0.43074295
 0.43048164 0.43022895 0.4299554  0.42968562 0.42940605 0.42919022
 0.42899832 0.4288625  0.4287597  0.42865032 0.42846885 0.42827192
 0.42803177 0.42775598 0.42748713 0.42722294 0.4269698  0.42672527
 0.42652187 0.42639875 0.4263371  0.42631143 0.42630523 0.42628205
 0.42624658 0.4261506  0.42598563 0.4257537  0.4254588  0.4251293
 0.42480078 0.4244655  0.42416415 0.4238692  0.42361686 0.42339924
 0.42321277 0.4230448  0.42289993 0.42277226 0.422687   0.422553
 0.42237788 0.42213985 0.4218643  0.42156425 0.42122748 0.42088866
 0.4205114  0.4201317  0.4197654  0.41949904 0.41925192 0.4189951
 0.4187419  0.4184144  0.41804603 0.41763222 0.41719344 0.4167613
 0.41636658 0.41599578 0.41568014 0.41542175 0.41519827 0.4149721
 0.41472137 0.41441953 0.41404486 0.41359806 0.41308892 0.41259855
 0.41207558 0.41160324 0.4111522  0.4107858  0.41050178 0.41029292
 0.41014972 0.40999588 0.40980095 0.409545   0.40924385 0.40891227
 0.40857318 0.40823555 0.40791464 0.40765435 0.40735373 0.40683764]
