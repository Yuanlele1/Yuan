Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=144, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=34, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='weather.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=21, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=True, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Weather_360_j720_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=3, pred_len=720, root_path='./dataset/', seed=2021, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Weather_360_j720_H8_FITS_custom_ftM_sl360_ll48_pl720_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 35808
val 4551
test 9820
Model(
  (freq_upsampler): ModuleList(
    (0): Linear(in_features=34, out_features=102, bias=True)
    (1): Linear(in_features=34, out_features=102, bias=True)
    (2): Linear(in_features=34, out_features=102, bias=True)
    (3): Linear(in_features=34, out_features=102, bias=True)
    (4): Linear(in_features=34, out_features=102, bias=True)
    (5): Linear(in_features=34, out_features=102, bias=True)
    (6): Linear(in_features=34, out_features=102, bias=True)
    (7): Linear(in_features=34, out_features=102, bias=True)
    (8): Linear(in_features=34, out_features=102, bias=True)
    (9): Linear(in_features=34, out_features=102, bias=True)
    (10): Linear(in_features=34, out_features=102, bias=True)
    (11): Linear(in_features=34, out_features=102, bias=True)
    (12): Linear(in_features=34, out_features=102, bias=True)
    (13): Linear(in_features=34, out_features=102, bias=True)
    (14): Linear(in_features=34, out_features=102, bias=True)
    (15): Linear(in_features=34, out_features=102, bias=True)
    (16): Linear(in_features=34, out_features=102, bias=True)
    (17): Linear(in_features=34, out_features=102, bias=True)
    (18): Linear(in_features=34, out_features=102, bias=True)
    (19): Linear(in_features=34, out_features=102, bias=True)
    (20): Linear(in_features=34, out_features=102, bias=True)
  )
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4660992.0
params:  74970.0
Trainable parameters:  74970
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.7003911
	speed: 0.0354s/iter; left time: 1972.6205s
	iters: 200, epoch: 1 | loss: 0.6106698
	speed: 0.0314s/iter; left time: 1749.4266s
	iters: 300, epoch: 1 | loss: 0.5286896
	speed: 0.0320s/iter; left time: 1776.6692s
	iters: 400, epoch: 1 | loss: 0.5144157
	speed: 0.0316s/iter; left time: 1753.2374s
	iters: 500, epoch: 1 | loss: 0.4908598
	speed: 0.0374s/iter; left time: 2071.3857s
Epoch: 1 cost time: 19.17834234237671
Epoch: 1, Steps: 559 | Train Loss: 0.6518389 Vali Loss: 0.6931973 Test Loss: 0.3408464
Validation loss decreased (inf --> 0.693197).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4574146
	speed: 0.1582s/iter; left time: 8738.9327s
	iters: 200, epoch: 2 | loss: 0.4813567
	speed: 0.0447s/iter; left time: 2466.5442s
	iters: 300, epoch: 2 | loss: 0.3605469
	speed: 0.0447s/iter; left time: 2462.3394s
	iters: 400, epoch: 2 | loss: 0.5728521
	speed: 0.0372s/iter; left time: 2042.3475s
	iters: 500, epoch: 2 | loss: 0.5714856
	speed: 0.0305s/iter; left time: 1674.4153s
Epoch: 2 cost time: 22.516247749328613
Epoch: 2, Steps: 559 | Train Loss: 0.4660927 Vali Loss: 0.6633620 Test Loss: 0.3301176
Validation loss decreased (0.693197 --> 0.663362).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3890428
	speed: 0.1506s/iter; left time: 8236.4498s
	iters: 200, epoch: 3 | loss: 0.5094623
	speed: 0.0285s/iter; left time: 1557.5629s
	iters: 300, epoch: 3 | loss: 0.3922287
	speed: 0.0299s/iter; left time: 1629.0224s
	iters: 400, epoch: 3 | loss: 0.4527958
	speed: 0.0292s/iter; left time: 1590.2615s
	iters: 500, epoch: 3 | loss: 0.4016972
	speed: 0.0370s/iter; left time: 2007.6774s
Epoch: 3 cost time: 18.417369604110718
Epoch: 3, Steps: 559 | Train Loss: 0.4448461 Vali Loss: 0.6552753 Test Loss: 0.3259211
Validation loss decreased (0.663362 --> 0.655275).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4759967
	speed: 0.1454s/iter; left time: 7871.6210s
	iters: 200, epoch: 4 | loss: 0.4580970
	speed: 0.0322s/iter; left time: 1740.0397s
	iters: 300, epoch: 4 | loss: 0.5285127
	speed: 0.0361s/iter; left time: 1946.2438s
	iters: 400, epoch: 4 | loss: 0.4027014
	speed: 0.0315s/iter; left time: 1694.6822s
	iters: 500, epoch: 4 | loss: 0.4041729
	speed: 0.0325s/iter; left time: 1747.2672s
Epoch: 4 cost time: 18.9815731048584
Epoch: 4, Steps: 559 | Train Loss: 0.4387809 Vali Loss: 0.6515489 Test Loss: 0.3238811
Validation loss decreased (0.655275 --> 0.651549).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.5458468
	speed: 0.1389s/iter; left time: 7441.8577s
	iters: 200, epoch: 5 | loss: 0.4801510
	speed: 0.0326s/iter; left time: 1744.8758s
	iters: 300, epoch: 5 | loss: 0.3847938
	speed: 0.0482s/iter; left time: 2574.2224s
	iters: 400, epoch: 5 | loss: 0.5292860
	speed: 0.0362s/iter; left time: 1929.8088s
	iters: 500, epoch: 5 | loss: 0.3547758
	speed: 0.0413s/iter; left time: 2197.0607s
Epoch: 5 cost time: 21.3971004486084
Epoch: 5, Steps: 559 | Train Loss: 0.4361870 Vali Loss: 0.6494412 Test Loss: 0.3225552
Validation loss decreased (0.651549 --> 0.649441).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3904070
	speed: 0.1392s/iter; left time: 7376.1768s
	iters: 200, epoch: 6 | loss: 0.3665781
	speed: 0.0346s/iter; left time: 1829.0364s
	iters: 300, epoch: 6 | loss: 0.3912442
	speed: 0.0318s/iter; left time: 1676.6922s
	iters: 400, epoch: 6 | loss: 0.4521150
	speed: 0.0343s/iter; left time: 1807.9680s
	iters: 500, epoch: 6 | loss: 0.3753459
	speed: 0.0355s/iter; left time: 1867.5195s
Epoch: 6 cost time: 19.762502431869507
Epoch: 6, Steps: 559 | Train Loss: 0.4352072 Vali Loss: 0.6475472 Test Loss: 0.3218461
Validation loss decreased (0.649441 --> 0.647547).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4324006
	speed: 0.1413s/iter; left time: 7409.0509s
	iters: 200, epoch: 7 | loss: 0.4959698
	speed: 0.0386s/iter; left time: 2022.3130s
	iters: 300, epoch: 7 | loss: 0.5238655
	speed: 0.0350s/iter; left time: 1826.7787s
	iters: 400, epoch: 7 | loss: 0.5175682
	speed: 0.0313s/iter; left time: 1630.5689s
	iters: 500, epoch: 7 | loss: 0.5352958
	speed: 0.0374s/iter; left time: 1947.6213s
Epoch: 7 cost time: 19.714325428009033
Epoch: 7, Steps: 559 | Train Loss: 0.4344912 Vali Loss: 0.6467277 Test Loss: 0.3214439
Validation loss decreased (0.647547 --> 0.646728).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3767675
	speed: 0.1298s/iter; left time: 6735.6369s
	iters: 200, epoch: 8 | loss: 0.3290025
	speed: 0.0334s/iter; left time: 1727.9934s
	iters: 300, epoch: 8 | loss: 0.3972242
	speed: 0.0323s/iter; left time: 1668.1628s
	iters: 400, epoch: 8 | loss: 0.3539930
	speed: 0.0408s/iter; left time: 2106.8744s
	iters: 500, epoch: 8 | loss: 0.4197637
	speed: 0.0419s/iter; left time: 2159.6196s
Epoch: 8 cost time: 20.4360249042511
Epoch: 8, Steps: 559 | Train Loss: 0.4342427 Vali Loss: 0.6470435 Test Loss: 0.3211321
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.5462627
	speed: 0.1629s/iter; left time: 8361.7658s
	iters: 200, epoch: 9 | loss: 0.4036786
	speed: 0.0454s/iter; left time: 2324.9378s
	iters: 300, epoch: 9 | loss: 0.4595593
	speed: 0.0332s/iter; left time: 1695.3249s
	iters: 400, epoch: 9 | loss: 0.4423443
	speed: 0.0357s/iter; left time: 1821.2643s
	iters: 500, epoch: 9 | loss: 0.4345993
	speed: 0.0351s/iter; left time: 1789.1704s
Epoch: 9 cost time: 22.727627754211426
Epoch: 9, Steps: 559 | Train Loss: 0.4339135 Vali Loss: 0.6454510 Test Loss: 0.3207293
Validation loss decreased (0.646728 --> 0.645451).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4071557
	speed: 0.1449s/iter; left time: 7357.9233s
	iters: 200, epoch: 10 | loss: 0.5066046
	speed: 0.0298s/iter; left time: 1508.6917s
	iters: 300, epoch: 10 | loss: 0.4165148
	speed: 0.0320s/iter; left time: 1620.6866s
	iters: 400, epoch: 10 | loss: 0.4470971
	speed: 0.0326s/iter; left time: 1645.8837s
	iters: 500, epoch: 10 | loss: 0.4060070
	speed: 0.0321s/iter; left time: 1617.8577s
Epoch: 10 cost time: 18.354161739349365
Epoch: 10, Steps: 559 | Train Loss: 0.4337636 Vali Loss: 0.6447387 Test Loss: 0.3204795
Validation loss decreased (0.645451 --> 0.644739).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3767472
	speed: 0.1382s/iter; left time: 6940.7862s
	iters: 200, epoch: 11 | loss: 0.4418131
	speed: 0.0323s/iter; left time: 1618.9502s
	iters: 300, epoch: 11 | loss: 0.4210223
	speed: 0.0320s/iter; left time: 1602.5450s
	iters: 400, epoch: 11 | loss: 0.4590406
	speed: 0.0335s/iter; left time: 1671.0205s
	iters: 500, epoch: 11 | loss: 0.3771922
	speed: 0.0470s/iter; left time: 2340.0195s
Epoch: 11 cost time: 20.402875900268555
Epoch: 11, Steps: 559 | Train Loss: 0.4336460 Vali Loss: 0.6455277 Test Loss: 0.3203792
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4712781
	speed: 0.1659s/iter; left time: 8236.5185s
	iters: 200, epoch: 12 | loss: 0.3719908
	speed: 0.0314s/iter; left time: 1555.7011s
	iters: 300, epoch: 12 | loss: 0.4071490
	speed: 0.0375s/iter; left time: 1853.9575s
	iters: 400, epoch: 12 | loss: 0.4643940
	speed: 0.0367s/iter; left time: 1809.9959s
	iters: 500, epoch: 12 | loss: 0.4257337
	speed: 0.0393s/iter; left time: 1937.9028s
Epoch: 12 cost time: 21.853713512420654
Epoch: 12, Steps: 559 | Train Loss: 0.4334462 Vali Loss: 0.6449360 Test Loss: 0.3202209
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.5434254
	speed: 0.1334s/iter; left time: 6550.9309s
	iters: 200, epoch: 13 | loss: 0.4226007
	speed: 0.0391s/iter; left time: 1915.9581s
	iters: 300, epoch: 13 | loss: 0.4247804
	speed: 0.0355s/iter; left time: 1735.1903s
	iters: 400, epoch: 13 | loss: 0.4356828
	speed: 0.0379s/iter; left time: 1848.2668s
	iters: 500, epoch: 13 | loss: 0.4369232
	speed: 0.0364s/iter; left time: 1773.0595s
Epoch: 13 cost time: 21.146676063537598
Epoch: 13, Steps: 559 | Train Loss: 0.4333513 Vali Loss: 0.6447607 Test Loss: 0.3200445
EarlyStopping counter: 3 out of 3
Early stopping
train 35808
val 4551
test 9820
Model(
  (freq_upsampler): ModuleList(
    (0): Linear(in_features=34, out_features=102, bias=True)
    (1): Linear(in_features=34, out_features=102, bias=True)
    (2): Linear(in_features=34, out_features=102, bias=True)
    (3): Linear(in_features=34, out_features=102, bias=True)
    (4): Linear(in_features=34, out_features=102, bias=True)
    (5): Linear(in_features=34, out_features=102, bias=True)
    (6): Linear(in_features=34, out_features=102, bias=True)
    (7): Linear(in_features=34, out_features=102, bias=True)
    (8): Linear(in_features=34, out_features=102, bias=True)
    (9): Linear(in_features=34, out_features=102, bias=True)
    (10): Linear(in_features=34, out_features=102, bias=True)
    (11): Linear(in_features=34, out_features=102, bias=True)
    (12): Linear(in_features=34, out_features=102, bias=True)
    (13): Linear(in_features=34, out_features=102, bias=True)
    (14): Linear(in_features=34, out_features=102, bias=True)
    (15): Linear(in_features=34, out_features=102, bias=True)
    (16): Linear(in_features=34, out_features=102, bias=True)
    (17): Linear(in_features=34, out_features=102, bias=True)
    (18): Linear(in_features=34, out_features=102, bias=True)
    (19): Linear(in_features=34, out_features=102, bias=True)
    (20): Linear(in_features=34, out_features=102, bias=True)
  )
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4660992.0
params:  74970.0
Trainable parameters:  74970
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6498429
	speed: 0.0374s/iter; left time: 2085.0991s
	iters: 200, epoch: 1 | loss: 0.5220679
	speed: 0.0343s/iter; left time: 1912.9021s
	iters: 300, epoch: 1 | loss: 0.5417880
	speed: 0.0338s/iter; left time: 1877.7220s
	iters: 400, epoch: 1 | loss: 0.5797036
	speed: 0.0358s/iter; left time: 1987.4210s
	iters: 500, epoch: 1 | loss: 0.7494946
	speed: 0.0327s/iter; left time: 1810.5876s
Epoch: 1 cost time: 19.72153615951538
Epoch: 1, Steps: 559 | Train Loss: 0.5949075 Vali Loss: 0.6430497 Test Loss: 0.3198752
Validation loss decreased (inf --> 0.643050).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4845083
	speed: 0.1351s/iter; left time: 7465.8069s
	iters: 200, epoch: 2 | loss: 0.6307707
	speed: 0.0301s/iter; left time: 1661.1166s
	iters: 300, epoch: 2 | loss: 0.5888652
	speed: 0.0457s/iter; left time: 2514.8433s
	iters: 400, epoch: 2 | loss: 0.5446904
	speed: 0.0312s/iter; left time: 1716.2094s
	iters: 500, epoch: 2 | loss: 0.5078496
	speed: 0.0301s/iter; left time: 1652.0370s
Epoch: 2 cost time: 19.327038288116455
Epoch: 2, Steps: 559 | Train Loss: 0.5937461 Vali Loss: 0.6413327 Test Loss: 0.3192869
Validation loss decreased (0.643050 --> 0.641333).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.6657780
	speed: 0.1717s/iter; left time: 9388.3437s
	iters: 200, epoch: 3 | loss: 0.5456918
	speed: 0.0409s/iter; left time: 2232.0445s
	iters: 300, epoch: 3 | loss: 0.7380405
	speed: 0.0504s/iter; left time: 2748.1253s
	iters: 400, epoch: 3 | loss: 0.5635580
	speed: 0.0388s/iter; left time: 2112.5115s
	iters: 500, epoch: 3 | loss: 0.5777093
	speed: 0.0432s/iter; left time: 2343.5960s
Epoch: 3 cost time: 24.73621106147766
Epoch: 3, Steps: 559 | Train Loss: 0.5930437 Vali Loss: 0.6407514 Test Loss: 0.3189132
Validation loss decreased (0.641333 --> 0.640751).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.6209503
	speed: 0.1510s/iter; left time: 8173.3846s
	iters: 200, epoch: 4 | loss: 0.5640621
	speed: 0.0310s/iter; left time: 1673.6460s
	iters: 300, epoch: 4 | loss: 0.5136265
	speed: 0.0303s/iter; left time: 1632.8278s
	iters: 400, epoch: 4 | loss: 0.6271252
	speed: 0.0337s/iter; left time: 1813.1701s
	iters: 500, epoch: 4 | loss: 0.4811631
	speed: 0.0344s/iter; left time: 1846.1060s
Epoch: 4 cost time: 18.11328911781311
Epoch: 4, Steps: 559 | Train Loss: 0.5927065 Vali Loss: 0.6404270 Test Loss: 0.3185501
Validation loss decreased (0.640751 --> 0.640427).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.5291373
	speed: 0.1361s/iter; left time: 7288.5544s
	iters: 200, epoch: 5 | loss: 0.5480371
	speed: 0.0308s/iter; left time: 1646.8937s
	iters: 300, epoch: 5 | loss: 0.6319095
	speed: 0.0354s/iter; left time: 1886.8921s
	iters: 400, epoch: 5 | loss: 0.7215204
	speed: 0.0326s/iter; left time: 1735.7012s
	iters: 500, epoch: 5 | loss: 0.6753786
	speed: 0.0355s/iter; left time: 1885.2594s
Epoch: 5 cost time: 19.365122318267822
Epoch: 5, Steps: 559 | Train Loss: 0.5923203 Vali Loss: 0.6403409 Test Loss: 0.3184383
Validation loss decreased (0.640427 --> 0.640341).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.7447567
	speed: 0.1402s/iter; left time: 7433.0982s
	iters: 200, epoch: 6 | loss: 0.5939766
	speed: 0.0323s/iter; left time: 1707.8273s
	iters: 300, epoch: 6 | loss: 0.5792019
	speed: 0.0332s/iter; left time: 1753.2629s
	iters: 400, epoch: 6 | loss: 0.5668094
	speed: 0.0465s/iter; left time: 2451.9313s
	iters: 500, epoch: 6 | loss: 0.5275618
	speed: 0.0368s/iter; left time: 1937.3225s
Epoch: 6 cost time: 21.219513416290283
Epoch: 6, Steps: 559 | Train Loss: 0.5920602 Vali Loss: 0.6402842 Test Loss: 0.3181072
Validation loss decreased (0.640341 --> 0.640284).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.5917997
	speed: 0.1509s/iter; left time: 7914.7686s
	iters: 200, epoch: 7 | loss: 0.5504202
	speed: 0.0341s/iter; left time: 1783.8435s
	iters: 300, epoch: 7 | loss: 0.6100299
	speed: 0.0307s/iter; left time: 1602.5046s
	iters: 400, epoch: 7 | loss: 0.6744011
	speed: 0.0349s/iter; left time: 1822.1144s
	iters: 500, epoch: 7 | loss: 0.5376340
	speed: 0.0311s/iter; left time: 1618.5490s
Epoch: 7 cost time: 19.28765058517456
Epoch: 7, Steps: 559 | Train Loss: 0.5919404 Vali Loss: 0.6401005 Test Loss: 0.3181396
Validation loss decreased (0.640284 --> 0.640100).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.5140520
	speed: 0.1695s/iter; left time: 8794.2966s
	iters: 200, epoch: 8 | loss: 0.5046106
	speed: 0.0339s/iter; left time: 1757.1315s
	iters: 300, epoch: 8 | loss: 0.6609273
	speed: 0.0363s/iter; left time: 1878.6617s
	iters: 400, epoch: 8 | loss: 0.5406716
	speed: 0.0359s/iter; left time: 1854.3211s
	iters: 500, epoch: 8 | loss: 0.6002411
	speed: 0.0453s/iter; left time: 2332.5192s
Epoch: 8 cost time: 21.102794408798218
Epoch: 8, Steps: 559 | Train Loss: 0.5912885 Vali Loss: 0.6393116 Test Loss: 0.3180144
Validation loss decreased (0.640100 --> 0.639312).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.6456930
	speed: 0.1367s/iter; left time: 7018.3773s
	iters: 200, epoch: 9 | loss: 0.7824891
	speed: 0.0347s/iter; left time: 1777.6445s
	iters: 300, epoch: 9 | loss: 0.5316024
	speed: 0.0357s/iter; left time: 1825.7754s
	iters: 400, epoch: 9 | loss: 0.4752800
	speed: 0.0346s/iter; left time: 1764.6156s
	iters: 500, epoch: 9 | loss: 0.5665942
	speed: 0.0332s/iter; left time: 1689.9991s
Epoch: 9 cost time: 20.684103965759277
Epoch: 9, Steps: 559 | Train Loss: 0.5913581 Vali Loss: 0.6399298 Test Loss: 0.3178575
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.5791603
	speed: 0.1549s/iter; left time: 7863.5372s
	iters: 200, epoch: 10 | loss: 0.5673684
	speed: 0.0368s/iter; left time: 1866.2978s
	iters: 300, epoch: 10 | loss: 0.5573609
	speed: 0.0316s/iter; left time: 1595.5511s
	iters: 400, epoch: 10 | loss: 0.6244171
	speed: 0.0323s/iter; left time: 1630.5414s
	iters: 500, epoch: 10 | loss: 0.5879460
	speed: 0.0322s/iter; left time: 1621.7639s
Epoch: 10 cost time: 18.944810390472412
Epoch: 10, Steps: 559 | Train Loss: 0.5912286 Vali Loss: 0.6393902 Test Loss: 0.3177702
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4700315
	speed: 0.1348s/iter; left time: 6767.4589s
	iters: 200, epoch: 11 | loss: 0.6233256
	speed: 0.0337s/iter; left time: 1686.2814s
	iters: 300, epoch: 11 | loss: 0.6664933
	speed: 0.0350s/iter; left time: 1751.6625s
	iters: 400, epoch: 11 | loss: 0.6663095
	speed: 0.0385s/iter; left time: 1921.7572s
	iters: 500, epoch: 11 | loss: 0.6439339
	speed: 0.0346s/iter; left time: 1721.1672s
Epoch: 11 cost time: 19.96311926841736
Epoch: 11, Steps: 559 | Train Loss: 0.5912419 Vali Loss: 0.6384835 Test Loss: 0.3176666
Validation loss decreased (0.639312 --> 0.638483).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.5123203
	speed: 0.1541s/iter; left time: 7651.1510s
	iters: 200, epoch: 12 | loss: 0.4925802
	speed: 0.0328s/iter; left time: 1626.1770s
	iters: 300, epoch: 12 | loss: 0.6087832
	speed: 0.0457s/iter; left time: 2257.7075s
	iters: 400, epoch: 12 | loss: 0.5340816
	speed: 0.0309s/iter; left time: 1523.3151s
	iters: 500, epoch: 12 | loss: 0.5106527
	speed: 0.0299s/iter; left time: 1472.0676s
Epoch: 12 cost time: 20.566024780273438
Epoch: 12, Steps: 559 | Train Loss: 0.5909790 Vali Loss: 0.6388760 Test Loss: 0.3176031
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.5287985
	speed: 0.1379s/iter; left time: 6770.9886s
	iters: 200, epoch: 13 | loss: 0.5140451
	speed: 0.0292s/iter; left time: 1431.9757s
	iters: 300, epoch: 13 | loss: 0.5091802
	speed: 0.0301s/iter; left time: 1469.8374s
	iters: 400, epoch: 13 | loss: 0.5422654
	speed: 0.0349s/iter; left time: 1703.1258s
	iters: 500, epoch: 13 | loss: 0.4966065
	speed: 0.0378s/iter; left time: 1840.9474s
Epoch: 13 cost time: 19.173470973968506
Epoch: 13, Steps: 559 | Train Loss: 0.5908946 Vali Loss: 0.6382716 Test Loss: 0.3175499
Validation loss decreased (0.638483 --> 0.638272).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.6123734
	speed: 0.1474s/iter; left time: 7155.4835s
	iters: 200, epoch: 14 | loss: 0.5538958
	speed: 0.0324s/iter; left time: 1571.0178s
	iters: 300, epoch: 14 | loss: 0.5644739
	speed: 0.0326s/iter; left time: 1577.1775s
	iters: 400, epoch: 14 | loss: 0.6062616
	speed: 0.0369s/iter; left time: 1779.3083s
	iters: 500, epoch: 14 | loss: 0.6725430
	speed: 0.0322s/iter; left time: 1549.8508s
Epoch: 14 cost time: 19.91255235671997
Epoch: 14, Steps: 559 | Train Loss: 0.5908127 Vali Loss: 0.6381255 Test Loss: 0.3174000
Validation loss decreased (0.638272 --> 0.638125).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.5121537
	speed: 0.1385s/iter; left time: 6644.4435s
	iters: 200, epoch: 15 | loss: 0.6513651
	speed: 0.0431s/iter; left time: 2061.5542s
	iters: 300, epoch: 15 | loss: 0.7426260
	speed: 0.0317s/iter; left time: 1513.4986s
	iters: 400, epoch: 15 | loss: 0.6167404
	speed: 0.0305s/iter; left time: 1455.3508s
	iters: 500, epoch: 15 | loss: 0.5557272
	speed: 0.0325s/iter; left time: 1545.2754s
Epoch: 15 cost time: 19.62542700767517
Epoch: 15, Steps: 559 | Train Loss: 0.5905444 Vali Loss: 0.6384234 Test Loss: 0.3172865
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.5343730
	speed: 0.1393s/iter; left time: 6603.5811s
	iters: 200, epoch: 16 | loss: 0.5662671
	speed: 0.0379s/iter; left time: 1791.9715s
	iters: 300, epoch: 16 | loss: 0.5574446
	speed: 0.0348s/iter; left time: 1643.9760s
	iters: 400, epoch: 16 | loss: 0.7104176
	speed: 0.0395s/iter; left time: 1862.2735s
	iters: 500, epoch: 16 | loss: 0.6074609
	speed: 0.0303s/iter; left time: 1424.6283s
Epoch: 16 cost time: 19.842752933502197
Epoch: 16, Steps: 559 | Train Loss: 0.5905697 Vali Loss: 0.6381245 Test Loss: 0.3172599
Validation loss decreased (0.638125 --> 0.638125).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.6063035
	speed: 0.1296s/iter; left time: 6073.3048s
	iters: 200, epoch: 17 | loss: 0.7967073
	speed: 0.0311s/iter; left time: 1455.3084s
	iters: 300, epoch: 17 | loss: 0.5246080
	speed: 0.0322s/iter; left time: 1503.1212s
	iters: 400, epoch: 17 | loss: 0.5067863
	speed: 0.0312s/iter; left time: 1450.5884s
	iters: 500, epoch: 17 | loss: 0.6270920
	speed: 0.0309s/iter; left time: 1436.1327s
Epoch: 17 cost time: 17.984009504318237
Epoch: 17, Steps: 559 | Train Loss: 0.5903937 Vali Loss: 0.6382086 Test Loss: 0.3172428
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.5677123
	speed: 0.1305s/iter; left time: 6041.9651s
	iters: 200, epoch: 18 | loss: 0.5940531
	speed: 0.0299s/iter; left time: 1381.9522s
	iters: 300, epoch: 18 | loss: 0.5368121
	speed: 0.0359s/iter; left time: 1655.6275s
	iters: 400, epoch: 18 | loss: 0.5246634
	speed: 0.0388s/iter; left time: 1782.4799s
	iters: 500, epoch: 18 | loss: 0.5975160
	speed: 0.0411s/iter; left time: 1884.9144s
Epoch: 18 cost time: 20.371015310287476
Epoch: 18, Steps: 559 | Train Loss: 0.5903933 Vali Loss: 0.6373181 Test Loss: 0.3171931
Validation loss decreased (0.638125 --> 0.637318).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.5661984
	speed: 0.1687s/iter; left time: 7715.3665s
	iters: 200, epoch: 19 | loss: 0.5968676
	speed: 0.0356s/iter; left time: 1626.8553s
	iters: 300, epoch: 19 | loss: 0.4579375
	speed: 0.0343s/iter; left time: 1564.0211s
	iters: 400, epoch: 19 | loss: 0.7089243
	speed: 0.0324s/iter; left time: 1472.7530s
	iters: 500, epoch: 19 | loss: 0.6778804
	speed: 0.0304s/iter; left time: 1377.5333s
Epoch: 19 cost time: 20.663872718811035
Epoch: 19, Steps: 559 | Train Loss: 0.5900516 Vali Loss: 0.6378704 Test Loss: 0.3171775
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.6684742
	speed: 0.1413s/iter; left time: 6385.0452s
	iters: 200, epoch: 20 | loss: 0.6512797
	speed: 0.0307s/iter; left time: 1381.7279s
	iters: 300, epoch: 20 | loss: 0.4830922
	speed: 0.0325s/iter; left time: 1461.7138s
	iters: 400, epoch: 20 | loss: 0.5960460
	speed: 0.0320s/iter; left time: 1434.7521s
	iters: 500, epoch: 20 | loss: 0.5604087
	speed: 0.0310s/iter; left time: 1388.0623s
Epoch: 20 cost time: 17.97663164138794
Epoch: 20, Steps: 559 | Train Loss: 0.5902718 Vali Loss: 0.6374478 Test Loss: 0.3171697
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.6109822
	speed: 0.1359s/iter; left time: 6061.8548s
	iters: 200, epoch: 21 | loss: 0.6481777
	speed: 0.0307s/iter; left time: 1366.1790s
	iters: 300, epoch: 21 | loss: 0.5457554
	speed: 0.0308s/iter; left time: 1366.9747s
	iters: 400, epoch: 21 | loss: 0.7305026
	speed: 0.0347s/iter; left time: 1539.3964s
	iters: 500, epoch: 21 | loss: 0.5331162
	speed: 0.0341s/iter; left time: 1506.2635s
Epoch: 21 cost time: 18.888450622558594
Epoch: 21, Steps: 559 | Train Loss: 0.5900125 Vali Loss: 0.6379572 Test Loss: 0.3171226
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Weather_360_j720_H8_FITS_custom_ftM_sl360_ll48_pl720_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
mse:0.31675633788108826, mae:0.33150026202201843, rse:0.7406187653541565, corr:[0.4719201  0.47304755 0.47293067 0.4723305  0.47150293 0.47058842
 0.46980762 0.46914232 0.46848953 0.4677714  0.46695608 0.46615976
 0.46532685 0.46452332 0.46379244 0.46309137 0.46237445 0.46159378
 0.46077055 0.4598783  0.45891184 0.45787638 0.45685405 0.4558455
 0.45488796 0.4539601  0.45300484 0.4519974  0.4509745  0.44997746
 0.4491178  0.44833514 0.44767454 0.44704124 0.44646528 0.44586268
 0.44531536 0.44473773 0.44407612 0.44338965 0.44268188 0.44210517
 0.44152805 0.4409887  0.4404256  0.43985087 0.4393015  0.43885362
 0.43830007 0.4376686  0.43703318 0.4364498  0.43593422 0.43544483
 0.43499213 0.434534   0.4340947  0.4336623  0.43342757 0.43326873
 0.4331783  0.43301725 0.4328679  0.4326422  0.4323994  0.43217635
 0.43193918 0.43163633 0.43138108 0.43119216 0.43108717 0.43088838
 0.43064764 0.43041915 0.43012676 0.42983574 0.4296224  0.42952564
 0.4295009  0.42947906 0.42948943 0.42946517 0.4293507  0.42917502
 0.42895907 0.42877772 0.42864177 0.4285066  0.42841142 0.42829996
 0.42821258 0.42814627 0.42804423 0.42792764 0.42777666 0.42759764
 0.42741007 0.4272061  0.42703068 0.42685685 0.42670962 0.42657226
 0.42648995 0.4264035  0.42625257 0.42604792 0.42578086 0.42551944
 0.42524529 0.42500785 0.42480654 0.42461112 0.42436945 0.42415273
 0.4239234  0.42371    0.42353493 0.42337677 0.42321813 0.423041
 0.42286384 0.4227182  0.42258796 0.4224664  0.42233935 0.42219195
 0.4220472  0.42186233 0.42166007 0.42143556 0.42119157 0.42095804
 0.42075408 0.42054802 0.4203731  0.4201512  0.41991046 0.41961685
 0.41927886 0.41891018 0.41854316 0.41819778 0.41793135 0.41766143
 0.41739836 0.41713107 0.41686502 0.41659403 0.4162916  0.41596732
 0.41558033 0.4151783  0.41476    0.41441622 0.41405964 0.4136711
 0.41329473 0.4128614  0.41241172 0.4119294  0.41143993 0.41095802
 0.410489   0.41001573 0.4095467  0.40909126 0.40863603 0.4081447
 0.40763262 0.40708712 0.40650144 0.40589952 0.40529713 0.40479177
 0.40429413 0.4038438  0.403374   0.40291435 0.40244913 0.40196145
 0.401472   0.40095472 0.4004484  0.3999776  0.39961132 0.39934656
 0.39917517 0.3990446  0.39891398 0.39881137 0.39864448 0.39842668
 0.3982171  0.39796692 0.39765796 0.39737293 0.39707607 0.39683264
 0.39665726 0.39649093 0.39633045 0.3961164  0.3959444  0.39574787
 0.39558968 0.3954568  0.3953698  0.3952824  0.3951975  0.39511162
 0.3950072  0.39484245 0.39462247 0.3944028  0.39413935 0.39383942
 0.39350796 0.39320216 0.39291778 0.39262262 0.39233628 0.39205635
 0.39182562 0.39161104 0.3914179  0.3911962  0.39103407 0.39087135
 0.3907055  0.39049086 0.39023918 0.3899061  0.389455   0.3888748
 0.38823953 0.38765746 0.38712433 0.3866972  0.38635552 0.38611087
 0.38598305 0.38594452 0.38588104 0.38579553 0.38565132 0.38537025
 0.38496906 0.3844644  0.38390982 0.38339484 0.38292903 0.38255095
 0.38225758 0.38191834 0.38158253 0.38125587 0.38090298 0.38055694
 0.38022694 0.3799189  0.37964046 0.37939772 0.37918353 0.37900993
 0.37884018 0.37865058 0.37839943 0.3781138  0.3777597  0.37735942
 0.37691268 0.37648833 0.37607846 0.37567973 0.37528312 0.37489203
 0.37449786 0.37404898 0.37356308 0.37306938 0.37253612 0.37200212
 0.37143072 0.37080273 0.3701315  0.3695079  0.36890167 0.3682891
 0.3676773  0.36709395 0.36647457 0.36579943 0.3650843  0.36443347
 0.36375198 0.36310303 0.36246184 0.36184084 0.36120617 0.3605678
 0.35985819 0.3590866  0.3582884  0.35749206 0.3567182  0.35595575
 0.35523102 0.3544869  0.35376576 0.35305846 0.352444   0.35185948
 0.35128295 0.3507336  0.35021213 0.34970993 0.34923992 0.34872976
 0.34819674 0.34761837 0.34700215 0.34634018 0.3456886  0.3450412
 0.3444327  0.3439112  0.3434206  0.34301424 0.34267083 0.3423552
 0.34210137 0.34188977 0.34170532 0.34158206 0.34143808 0.34129947
 0.34109944 0.3408953  0.34070998 0.34050444 0.3402883  0.34015334
 0.34004825 0.33991545 0.33981803 0.3397138  0.33959818 0.3394567
 0.33930868 0.33911896 0.33889866 0.3385841  0.33830467 0.33803737
 0.33782429 0.33770317 0.33766586 0.3376468  0.3376563  0.33761054
 0.33748215 0.33731002 0.33710384 0.33690494 0.33671373 0.33658257
 0.3364836  0.3363986  0.33632898 0.3362146  0.3360654  0.3358882
 0.33567613 0.33543074 0.3351889  0.33495048 0.3348096  0.33467504
 0.3345337  0.3343284  0.3340862  0.33382705 0.33354077 0.33318228
 0.33276603 0.3323355  0.33194098 0.3315961  0.33134446 0.3311408
 0.33094952 0.3307923  0.33064684 0.3304931  0.33030608 0.33007342
 0.32979152 0.32945454 0.32912555 0.32878965 0.3284986  0.32823727
 0.3280599  0.32789162 0.32772654 0.32748842 0.32722086 0.32689545
 0.32655922 0.3262643  0.32603264 0.32580417 0.32563767 0.32552165
 0.3254193  0.32531756 0.32521534 0.32509735 0.32488018 0.32460395
 0.32426223 0.3239012  0.32347965 0.32308772 0.32268304 0.32226557
 0.3218494  0.3214862  0.32111728 0.32072082 0.32030398 0.31989437
 0.31947628 0.31899396 0.31848204 0.31794336 0.31735325 0.31673887
 0.31611633 0.3154805  0.3148433  0.31418556 0.3135218  0.31271002
 0.3118419  0.31094497 0.31000492 0.30913535 0.30835226 0.30768406
 0.30712992 0.3066705  0.30625698 0.30583778 0.30543137 0.30499482
 0.30454805 0.30411917 0.3036085  0.3030887  0.30252713 0.30203873
 0.30158287 0.30118984 0.30087912 0.30063504 0.30040666 0.30016124
 0.2998989  0.2996457  0.2993602  0.2990648  0.29879656 0.2985994
 0.2985039  0.2984269  0.29837307 0.29838276 0.29841736 0.2984083
 0.2984233  0.29840282 0.29831904 0.2982433  0.29813528 0.29804367
 0.2978931  0.2977292  0.29758263 0.29746932 0.2973629  0.29724455
 0.29715475 0.29710093 0.29705092 0.2969939  0.29688072 0.29676008
 0.29664144 0.29654726 0.29646105 0.29638922 0.2963152  0.29623786
 0.29613912 0.29600546 0.29581615 0.2955356  0.29520354 0.29483685
 0.29446688 0.29411373 0.29380983 0.29353514 0.293283   0.29305837
 0.2928298  0.29258144 0.29228494 0.29193467 0.2915421  0.29108128
 0.29058585 0.29011124 0.28965375 0.28926378 0.2889058  0.288619
 0.28839675 0.28823012 0.28803703 0.28782243 0.28755137 0.28718618
 0.28674498 0.2862383  0.28570327 0.2851917  0.28469375 0.28423983
 0.28385797 0.2835461  0.28329533 0.2830845  0.282889   0.28269103
 0.28249043 0.28228799 0.28210926 0.28189638 0.28171518 0.2815516
 0.28141868 0.2812856  0.2811725  0.28102833 0.2808714  0.28065917
 0.2803619  0.28001997 0.2796365  0.27922902 0.2787647  0.27828342
 0.27783018 0.27743557 0.27711007 0.27682889 0.27656016 0.27630812
 0.27601814 0.27569258 0.27528283 0.27478668 0.27424905 0.27365917
 0.27304634 0.27244174 0.2718398  0.27120683 0.27055684 0.2699212
 0.26926565 0.2685969  0.26791453 0.2672499  0.2665782  0.26597062
 0.26543513 0.26498806 0.26454854 0.2641342  0.26369628 0.26325688
 0.2627599  0.26216048 0.2615005  0.26080906 0.26009887 0.25942418
 0.25878555 0.2581343  0.25747624 0.25680685 0.25616592 0.25557715
 0.25503483 0.25457662 0.25416434 0.25377294 0.25338784 0.25300103
 0.25256553 0.2521191  0.25172    0.25123242 0.250836   0.2504694
 0.25022188 0.25007772 0.24992155 0.24985568 0.24981189 0.2497881
 0.24973586 0.24961059 0.24948086 0.24936406 0.24930675 0.24928898
 0.24927963 0.24929954 0.24938022 0.24943791 0.24950783 0.24956743
 0.24961251 0.24960582 0.24963334 0.24961138 0.24956083 0.24949001
 0.24952321 0.24957497 0.24970193 0.24984102 0.25003052 0.25020453
 0.2503683  0.25046736 0.25052705 0.25052378 0.25051197 0.25045425
 0.25039473 0.25031415 0.25024763 0.25017154 0.25008422 0.25002053
 0.24991855 0.24981943 0.24967502 0.24948907 0.24926315 0.24899574
 0.24871072 0.24844715 0.24819335 0.24791977 0.24764426 0.2473281
 0.2470176  0.24671298 0.24641788 0.24613121 0.24586436 0.24565701
 0.2454772  0.24532704 0.24519674 0.24508096 0.24496298 0.24477527
 0.2445348  0.2442424  0.2439225  0.24360707 0.24336545 0.24320278
 0.24312532 0.24310373 0.24314359 0.24320325 0.2432344  0.24317388
 0.24302219 0.2427711  0.24248473 0.24222347 0.24201608 0.24188243
 0.2418622  0.24193174 0.24200357 0.24203359 0.24194904 0.24173698
 0.24144351 0.24112846 0.24083476 0.24064718 0.24045803 0.2402483
 0.23991941 0.23953106 0.23910366 0.23870865 0.2383403  0.23800339]
