Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=144, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=18, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='weather.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=21, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=True, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Weather_90_j720_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=3, pred_len=720, root_path='./dataset/', seed=2021, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Weather_90_j720_H8_FITS_custom_ftM_sl90_ll48_pl720_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36078
val 4551
test 9820
Model(
  (freq_upsampler): ModuleList(
    (0): Linear(in_features=18, out_features=162, bias=True)
    (1): Linear(in_features=18, out_features=162, bias=True)
    (2): Linear(in_features=18, out_features=162, bias=True)
    (3): Linear(in_features=18, out_features=162, bias=True)
    (4): Linear(in_features=18, out_features=162, bias=True)
    (5): Linear(in_features=18, out_features=162, bias=True)
    (6): Linear(in_features=18, out_features=162, bias=True)
    (7): Linear(in_features=18, out_features=162, bias=True)
    (8): Linear(in_features=18, out_features=162, bias=True)
    (9): Linear(in_features=18, out_features=162, bias=True)
    (10): Linear(in_features=18, out_features=162, bias=True)
    (11): Linear(in_features=18, out_features=162, bias=True)
    (12): Linear(in_features=18, out_features=162, bias=True)
    (13): Linear(in_features=18, out_features=162, bias=True)
    (14): Linear(in_features=18, out_features=162, bias=True)
    (15): Linear(in_features=18, out_features=162, bias=True)
    (16): Linear(in_features=18, out_features=162, bias=True)
    (17): Linear(in_features=18, out_features=162, bias=True)
    (18): Linear(in_features=18, out_features=162, bias=True)
    (19): Linear(in_features=18, out_features=162, bias=True)
    (20): Linear(in_features=18, out_features=162, bias=True)
  )
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3919104.0
params:  64638.0
Trainable parameters:  64638
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 1.6973829
	speed: 0.0381s/iter; left time: 2138.9126s
	iters: 200, epoch: 1 | loss: 0.8515481
	speed: 0.0356s/iter; left time: 1996.4421s
	iters: 300, epoch: 1 | loss: 0.8285974
	speed: 0.0304s/iter; left time: 1701.2672s
	iters: 400, epoch: 1 | loss: 0.8474982
	speed: 0.0378s/iter; left time: 2114.9187s
	iters: 500, epoch: 1 | loss: 0.7870297
	speed: 0.0312s/iter; left time: 1742.5175s
Epoch: 1 cost time: 19.43400287628174
Epoch: 1, Steps: 563 | Train Loss: 1.0929922 Vali Loss: 0.8319388 Test Loss: 0.3754368
Validation loss decreased (inf --> 0.831939).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6585872
	speed: 0.1326s/iter; left time: 7376.5287s
	iters: 200, epoch: 2 | loss: 0.6587357
	speed: 0.0389s/iter; left time: 2159.6751s
	iters: 300, epoch: 2 | loss: 0.6288542
	speed: 0.0319s/iter; left time: 1769.8176s
	iters: 400, epoch: 2 | loss: 0.7973732
	speed: 0.0310s/iter; left time: 1717.1713s
	iters: 500, epoch: 2 | loss: 0.7199746
	speed: 0.0312s/iter; left time: 1724.5788s
Epoch: 2 cost time: 19.021645307540894
Epoch: 2, Steps: 563 | Train Loss: 0.7819628 Vali Loss: 0.7623797 Test Loss: 0.3623831
Validation loss decreased (0.831939 --> 0.762380).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.8076478
	speed: 0.1198s/iter; left time: 6598.6229s
	iters: 200, epoch: 3 | loss: 0.5840273
	speed: 0.0278s/iter; left time: 1526.1386s
	iters: 300, epoch: 3 | loss: 0.8419403
	speed: 0.0298s/iter; left time: 1632.8868s
	iters: 400, epoch: 3 | loss: 0.7440394
	speed: 0.0307s/iter; left time: 1681.6243s
	iters: 500, epoch: 3 | loss: 0.5948743
	speed: 0.0301s/iter; left time: 1645.3679s
Epoch: 3 cost time: 16.73982524871826
Epoch: 3, Steps: 563 | Train Loss: 0.7311429 Vali Loss: 0.7474375 Test Loss: 0.3591430
Validation loss decreased (0.762380 --> 0.747437).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.6297210
	speed: 0.1328s/iter; left time: 7236.6787s
	iters: 200, epoch: 4 | loss: 0.6448869
	speed: 0.0390s/iter; left time: 2121.5397s
	iters: 300, epoch: 4 | loss: 0.6291128
	speed: 0.0298s/iter; left time: 1620.2210s
	iters: 400, epoch: 4 | loss: 0.5964210
	speed: 0.0304s/iter; left time: 1650.3912s
	iters: 500, epoch: 4 | loss: 0.7553710
	speed: 0.0296s/iter; left time: 1602.4223s
Epoch: 4 cost time: 18.829621076583862
Epoch: 4, Steps: 563 | Train Loss: 0.7115931 Vali Loss: 0.7394774 Test Loss: 0.3575439
Validation loss decreased (0.747437 --> 0.739477).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.7553169
	speed: 0.1204s/iter; left time: 6494.0509s
	iters: 200, epoch: 5 | loss: 0.8921078
	speed: 0.0302s/iter; left time: 1627.3185s
	iters: 300, epoch: 5 | loss: 0.6836047
	speed: 0.0299s/iter; left time: 1608.2450s
	iters: 400, epoch: 5 | loss: 0.7344555
	speed: 0.0316s/iter; left time: 1695.6080s
	iters: 500, epoch: 5 | loss: 0.7697982
	speed: 0.0330s/iter; left time: 1767.6786s
Epoch: 5 cost time: 17.780597686767578
Epoch: 5, Steps: 563 | Train Loss: 0.7014314 Vali Loss: 0.7349499 Test Loss: 0.3567069
Validation loss decreased (0.739477 --> 0.734950).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.5871820
	speed: 0.1300s/iter; left time: 6941.2935s
	iters: 200, epoch: 6 | loss: 0.7900225
	speed: 0.0270s/iter; left time: 1438.8036s
	iters: 300, epoch: 6 | loss: 0.5668586
	speed: 0.0320s/iter; left time: 1703.6508s
	iters: 400, epoch: 6 | loss: 0.7596200
	speed: 0.0399s/iter; left time: 2119.7180s
	iters: 500, epoch: 6 | loss: 0.6596828
	speed: 0.0288s/iter; left time: 1526.6170s
Epoch: 6 cost time: 18.14677143096924
Epoch: 6, Steps: 563 | Train Loss: 0.6967116 Vali Loss: 0.7322292 Test Loss: 0.3560761
Validation loss decreased (0.734950 --> 0.732229).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.6568919
	speed: 0.1237s/iter; left time: 6536.1395s
	iters: 200, epoch: 7 | loss: 0.6681171
	speed: 0.0296s/iter; left time: 1560.5905s
	iters: 300, epoch: 7 | loss: 0.5541471
	speed: 0.0285s/iter; left time: 1498.8551s
	iters: 400, epoch: 7 | loss: 0.6972100
	speed: 0.0288s/iter; left time: 1511.5970s
	iters: 500, epoch: 7 | loss: 0.6207826
	speed: 0.0379s/iter; left time: 1984.2210s
Epoch: 7 cost time: 17.73022985458374
Epoch: 7, Steps: 563 | Train Loss: 0.6937784 Vali Loss: 0.7302240 Test Loss: 0.3555566
Validation loss decreased (0.732229 --> 0.730224).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.6078103
	speed: 0.1339s/iter; left time: 6998.1239s
	iters: 200, epoch: 8 | loss: 0.6387044
	speed: 0.0294s/iter; left time: 1532.8748s
	iters: 300, epoch: 8 | loss: 0.5636233
	speed: 0.0326s/iter; left time: 1698.9272s
	iters: 400, epoch: 8 | loss: 0.8684599
	speed: 0.0314s/iter; left time: 1632.2475s
	iters: 500, epoch: 8 | loss: 0.7192701
	speed: 0.0282s/iter; left time: 1462.8644s
Epoch: 8 cost time: 17.940232515335083
Epoch: 8, Steps: 563 | Train Loss: 0.6921237 Vali Loss: 0.7282662 Test Loss: 0.3551640
Validation loss decreased (0.730224 --> 0.728266).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.6263233
	speed: 0.1218s/iter; left time: 6296.3903s
	iters: 200, epoch: 9 | loss: 0.7020266
	speed: 0.0290s/iter; left time: 1495.0824s
	iters: 300, epoch: 9 | loss: 0.7452324
	speed: 0.0283s/iter; left time: 1458.6658s
	iters: 400, epoch: 9 | loss: 0.7142080
	speed: 0.0308s/iter; left time: 1582.2324s
	iters: 500, epoch: 9 | loss: 0.7384827
	speed: 0.0300s/iter; left time: 1539.4842s
Epoch: 9 cost time: 17.0545871257782
Epoch: 9, Steps: 563 | Train Loss: 0.6908913 Vali Loss: 0.7271803 Test Loss: 0.3547892
Validation loss decreased (0.728266 --> 0.727180).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.6518667
	speed: 0.1210s/iter; left time: 6189.2627s
	iters: 200, epoch: 10 | loss: 0.7360600
	speed: 0.0288s/iter; left time: 1469.9395s
	iters: 300, epoch: 10 | loss: 0.7866829
	speed: 0.0309s/iter; left time: 1571.7525s
	iters: 400, epoch: 10 | loss: 0.5369146
	speed: 0.0306s/iter; left time: 1555.2983s
	iters: 500, epoch: 10 | loss: 0.6915876
	speed: 0.0305s/iter; left time: 1546.3765s
Epoch: 10 cost time: 17.094876766204834
Epoch: 10, Steps: 563 | Train Loss: 0.6897298 Vali Loss: 0.7264007 Test Loss: 0.3544436
Validation loss decreased (0.727180 --> 0.726401).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.7115553
	speed: 0.1298s/iter; left time: 6562.3867s
	iters: 200, epoch: 11 | loss: 0.7271790
	speed: 0.0302s/iter; left time: 1525.5065s
	iters: 300, epoch: 11 | loss: 0.6445363
	speed: 0.0316s/iter; left time: 1593.8331s
	iters: 400, epoch: 11 | loss: 0.7052178
	speed: 0.0361s/iter; left time: 1813.0063s
	iters: 500, epoch: 11 | loss: 0.6145391
	speed: 0.0298s/iter; left time: 1494.6289s
Epoch: 11 cost time: 18.328667879104614
Epoch: 11, Steps: 563 | Train Loss: 0.6888051 Vali Loss: 0.7259940 Test Loss: 0.3541712
Validation loss decreased (0.726401 --> 0.725994).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.8136940
	speed: 0.1250s/iter; left time: 6251.0185s
	iters: 200, epoch: 12 | loss: 0.7895800
	speed: 0.0274s/iter; left time: 1367.8102s
	iters: 300, epoch: 12 | loss: 0.7158268
	speed: 0.0278s/iter; left time: 1385.5214s
	iters: 400, epoch: 12 | loss: 0.7316451
	speed: 0.0281s/iter; left time: 1396.9366s
	iters: 500, epoch: 12 | loss: 0.7349891
	speed: 0.0278s/iter; left time: 1380.1368s
Epoch: 12 cost time: 16.11089777946472
Epoch: 12, Steps: 563 | Train Loss: 0.6883385 Vali Loss: 0.7252252 Test Loss: 0.3537747
Validation loss decreased (0.725994 --> 0.725225).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.6069677
	speed: 0.1200s/iter; left time: 5932.2365s
	iters: 200, epoch: 13 | loss: 0.6262984
	speed: 0.0285s/iter; left time: 1408.3499s
	iters: 300, epoch: 13 | loss: 0.6021277
	speed: 0.0298s/iter; left time: 1469.2245s
	iters: 400, epoch: 13 | loss: 0.7044939
	speed: 0.0292s/iter; left time: 1435.2023s
	iters: 500, epoch: 13 | loss: 0.6156397
	speed: 0.0302s/iter; left time: 1480.8810s
Epoch: 13 cost time: 16.96491050720215
Epoch: 13, Steps: 563 | Train Loss: 0.6876219 Vali Loss: 0.7245226 Test Loss: 0.3535626
Validation loss decreased (0.725225 --> 0.724523).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.5859081
	speed: 0.1224s/iter; left time: 5981.7104s
	iters: 200, epoch: 14 | loss: 0.6167369
	speed: 0.0259s/iter; left time: 1261.9710s
	iters: 300, epoch: 14 | loss: 0.6018057
	speed: 0.0266s/iter; left time: 1294.1584s
	iters: 400, epoch: 14 | loss: 0.6784875
	speed: 0.0270s/iter; left time: 1311.3723s
	iters: 500, epoch: 14 | loss: 0.7898935
	speed: 0.0277s/iter; left time: 1342.5912s
Epoch: 14 cost time: 15.744569301605225
Epoch: 14, Steps: 563 | Train Loss: 0.6869502 Vali Loss: 0.7235876 Test Loss: 0.3532842
Validation loss decreased (0.724523 --> 0.723588).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.7320324
	speed: 0.1211s/iter; left time: 5851.9595s
	iters: 200, epoch: 15 | loss: 0.5999948
	speed: 0.0277s/iter; left time: 1334.8718s
	iters: 300, epoch: 15 | loss: 0.8005790
	speed: 0.0289s/iter; left time: 1388.9124s
	iters: 400, epoch: 15 | loss: 0.5735982
	speed: 0.0357s/iter; left time: 1711.9682s
	iters: 500, epoch: 15 | loss: 0.6373491
	speed: 0.0315s/iter; left time: 1510.9961s
Epoch: 15 cost time: 17.531433582305908
Epoch: 15, Steps: 563 | Train Loss: 0.6866074 Vali Loss: 0.7227548 Test Loss: 0.3530517
Validation loss decreased (0.723588 --> 0.722755).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.6442247
	speed: 0.1244s/iter; left time: 5939.6783s
	iters: 200, epoch: 16 | loss: 0.6171711
	speed: 0.0271s/iter; left time: 1290.6978s
	iters: 300, epoch: 16 | loss: 0.6280043
	speed: 0.0273s/iter; left time: 1295.9079s
	iters: 400, epoch: 16 | loss: 0.7694961
	speed: 0.0266s/iter; left time: 1262.4406s
	iters: 500, epoch: 16 | loss: 0.7037268
	speed: 0.0283s/iter; left time: 1340.9507s
Epoch: 16 cost time: 15.977735996246338
Epoch: 16, Steps: 563 | Train Loss: 0.6861934 Vali Loss: 0.7228211 Test Loss: 0.3529570
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.5481270
	speed: 0.1226s/iter; left time: 5785.3847s
	iters: 200, epoch: 17 | loss: 0.5825998
	speed: 0.0260s/iter; left time: 1226.3860s
	iters: 300, epoch: 17 | loss: 0.8255119
	speed: 0.0285s/iter; left time: 1340.4295s
	iters: 400, epoch: 17 | loss: 0.8090017
	speed: 0.0282s/iter; left time: 1323.6785s
	iters: 500, epoch: 17 | loss: 0.6771148
	speed: 0.0274s/iter; left time: 1282.0112s
Epoch: 17 cost time: 15.84822940826416
Epoch: 17, Steps: 563 | Train Loss: 0.6857648 Vali Loss: 0.7214398 Test Loss: 0.3526839
Validation loss decreased (0.722755 --> 0.721440).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.6213937
	speed: 0.1211s/iter; left time: 5646.9693s
	iters: 200, epoch: 18 | loss: 0.7468367
	speed: 0.0268s/iter; left time: 1247.2780s
	iters: 300, epoch: 18 | loss: 0.5685793
	speed: 0.0287s/iter; left time: 1334.5086s
	iters: 400, epoch: 18 | loss: 0.9282089
	speed: 0.0278s/iter; left time: 1288.1676s
	iters: 500, epoch: 18 | loss: 0.7139311
	speed: 0.0287s/iter; left time: 1327.8959s
Epoch: 18 cost time: 16.233611345291138
Epoch: 18, Steps: 563 | Train Loss: 0.6853459 Vali Loss: 0.7218170 Test Loss: 0.3526072
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.5515043
	speed: 0.1214s/iter; left time: 5594.0570s
	iters: 200, epoch: 19 | loss: 0.6234018
	speed: 0.0277s/iter; left time: 1273.5966s
	iters: 300, epoch: 19 | loss: 0.6759934
	speed: 0.0297s/iter; left time: 1364.2031s
	iters: 400, epoch: 19 | loss: 0.7023028
	speed: 0.0298s/iter; left time: 1364.3151s
	iters: 500, epoch: 19 | loss: 0.7020804
	speed: 0.0296s/iter; left time: 1351.3989s
Epoch: 19 cost time: 16.695099115371704
Epoch: 19, Steps: 563 | Train Loss: 0.6849745 Vali Loss: 0.7213787 Test Loss: 0.3524213
Validation loss decreased (0.721440 --> 0.721379).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.7671676
	speed: 0.1253s/iter; left time: 5701.5559s
	iters: 200, epoch: 20 | loss: 0.7405695
	speed: 0.0284s/iter; left time: 1288.3920s
	iters: 300, epoch: 20 | loss: 0.6271766
	speed: 0.0276s/iter; left time: 1248.3253s
	iters: 400, epoch: 20 | loss: 0.6585047
	speed: 0.0286s/iter; left time: 1294.1718s
	iters: 500, epoch: 20 | loss: 0.7338621
	speed: 0.0380s/iter; left time: 1715.9985s
Epoch: 20 cost time: 17.812271118164062
Epoch: 20, Steps: 563 | Train Loss: 0.6848364 Vali Loss: 0.7208858 Test Loss: 0.3523171
Validation loss decreased (0.721379 --> 0.720886).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.6892157
	speed: 0.1310s/iter; left time: 5886.8467s
	iters: 200, epoch: 21 | loss: 0.6906663
	speed: 0.0303s/iter; left time: 1359.7409s
	iters: 300, epoch: 21 | loss: 0.7031550
	speed: 0.0279s/iter; left time: 1246.9131s
	iters: 400, epoch: 21 | loss: 0.6492590
	speed: 0.0370s/iter; left time: 1653.3970s
	iters: 500, epoch: 21 | loss: 0.5896152
	speed: 0.0279s/iter; left time: 1244.1157s
Epoch: 21 cost time: 18.22647190093994
Epoch: 21, Steps: 563 | Train Loss: 0.6846468 Vali Loss: 0.7205909 Test Loss: 0.3521744
Validation loss decreased (0.720886 --> 0.720591).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.6037860
	speed: 0.1285s/iter; left time: 5703.6374s
	iters: 200, epoch: 22 | loss: 0.6520314
	speed: 0.0268s/iter; left time: 1187.7661s
	iters: 300, epoch: 22 | loss: 0.6983145
	speed: 0.0274s/iter; left time: 1211.0186s
	iters: 400, epoch: 22 | loss: 0.7984578
	speed: 0.0286s/iter; left time: 1261.2678s
	iters: 500, epoch: 22 | loss: 0.6269588
	speed: 0.0295s/iter; left time: 1298.5896s
Epoch: 22 cost time: 16.13227891921997
Epoch: 22, Steps: 563 | Train Loss: 0.6844589 Vali Loss: 0.7200322 Test Loss: 0.3520400
Validation loss decreased (0.720591 --> 0.720032).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.7221623
	speed: 0.1391s/iter; left time: 6094.8484s
	iters: 200, epoch: 23 | loss: 0.6563264
	speed: 0.0341s/iter; left time: 1489.8584s
	iters: 300, epoch: 23 | loss: 0.6394953
	speed: 0.0338s/iter; left time: 1474.8832s
	iters: 400, epoch: 23 | loss: 0.6777450
	speed: 0.0284s/iter; left time: 1234.9956s
	iters: 500, epoch: 23 | loss: 0.6741673
	speed: 0.0319s/iter; left time: 1384.1658s
Epoch: 23 cost time: 19.133013486862183
Epoch: 23, Steps: 563 | Train Loss: 0.6840185 Vali Loss: 0.7198550 Test Loss: 0.3519436
Validation loss decreased (0.720032 --> 0.719855).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.6591842
	speed: 0.1314s/iter; left time: 5685.3533s
	iters: 200, epoch: 24 | loss: 0.7634699
	speed: 0.0279s/iter; left time: 1201.8560s
	iters: 300, epoch: 24 | loss: 0.6084643
	speed: 0.0323s/iter; left time: 1388.5842s
	iters: 400, epoch: 24 | loss: 0.6483032
	speed: 0.0295s/iter; left time: 1266.5473s
	iters: 500, epoch: 24 | loss: 0.8443432
	speed: 0.0305s/iter; left time: 1306.5670s
Epoch: 24 cost time: 17.39095187187195
Epoch: 24, Steps: 563 | Train Loss: 0.6839496 Vali Loss: 0.7196226 Test Loss: 0.3518443
Validation loss decreased (0.719855 --> 0.719623).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.7625448
	speed: 0.1287s/iter; left time: 5495.9023s
	iters: 200, epoch: 25 | loss: 0.7128882
	speed: 0.0350s/iter; left time: 1489.8569s
	iters: 300, epoch: 25 | loss: 0.6867853
	speed: 0.0284s/iter; left time: 1205.2353s
	iters: 400, epoch: 25 | loss: 0.6997147
	speed: 0.0375s/iter; left time: 1587.8501s
	iters: 500, epoch: 25 | loss: 0.6165949
	speed: 0.0287s/iter; left time: 1215.2645s
Epoch: 25 cost time: 18.803330183029175
Epoch: 25, Steps: 563 | Train Loss: 0.6838033 Vali Loss: 0.7193927 Test Loss: 0.3517432
Validation loss decreased (0.719623 --> 0.719393).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.7306876
	speed: 0.1599s/iter; left time: 6734.5209s
	iters: 200, epoch: 26 | loss: 0.6586210
	speed: 0.0338s/iter; left time: 1419.8169s
	iters: 300, epoch: 26 | loss: 0.7636787
	speed: 0.0293s/iter; left time: 1226.7898s
	iters: 400, epoch: 26 | loss: 0.7094520
	speed: 0.0289s/iter; left time: 1208.8217s
	iters: 500, epoch: 26 | loss: 0.7252143
	speed: 0.0300s/iter; left time: 1252.6958s
Epoch: 26 cost time: 17.479151487350464
Epoch: 26, Steps: 563 | Train Loss: 0.6835153 Vali Loss: 0.7185325 Test Loss: 0.3516451
Validation loss decreased (0.719393 --> 0.718533).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.7200974
	speed: 0.1220s/iter; left time: 5072.5394s
	iters: 200, epoch: 27 | loss: 0.7247573
	speed: 0.0287s/iter; left time: 1189.8598s
	iters: 300, epoch: 27 | loss: 0.5857382
	speed: 0.0310s/iter; left time: 1283.7313s
	iters: 400, epoch: 27 | loss: 0.6044081
	speed: 0.0319s/iter; left time: 1314.3499s
	iters: 500, epoch: 27 | loss: 0.8432058
	speed: 0.0300s/iter; left time: 1236.3486s
Epoch: 27 cost time: 17.955926418304443
Epoch: 27, Steps: 563 | Train Loss: 0.6832660 Vali Loss: 0.7192210 Test Loss: 0.3515790
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.6904454
	speed: 0.1346s/iter; left time: 5517.6818s
	iters: 200, epoch: 28 | loss: 0.6580857
	speed: 0.0283s/iter; left time: 1159.4109s
	iters: 300, epoch: 28 | loss: 0.8101550
	speed: 0.0288s/iter; left time: 1173.9978s
	iters: 400, epoch: 28 | loss: 0.7176427
	speed: 0.0288s/iter; left time: 1173.5133s
	iters: 500, epoch: 28 | loss: 0.9114127
	speed: 0.0271s/iter; left time: 1100.3603s
Epoch: 28 cost time: 16.68689250946045
Epoch: 28, Steps: 563 | Train Loss: 0.6831367 Vali Loss: 0.7189427 Test Loss: 0.3514878
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.6777112
	speed: 0.1222s/iter; left time: 4943.1526s
	iters: 200, epoch: 29 | loss: 0.6606855
	speed: 0.0285s/iter; left time: 1150.7626s
	iters: 300, epoch: 29 | loss: 0.6660926
	speed: 0.0263s/iter; left time: 1059.4853s
	iters: 400, epoch: 29 | loss: 0.6632122
	speed: 0.0271s/iter; left time: 1088.1384s
	iters: 500, epoch: 29 | loss: 0.7092406
	speed: 0.0289s/iter; left time: 1157.2550s
Epoch: 29 cost time: 16.12233853340149
Epoch: 29, Steps: 563 | Train Loss: 0.6828154 Vali Loss: 0.7186936 Test Loss: 0.3514200
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Weather_90_j720_H8_FITS_custom_ftM_sl90_ll48_pl720_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
mse:0.35080480575561523, mae:0.3471987247467041, rse:0.7794079184532166, corr:[0.47454306 0.47603485 0.47439775 0.47351092 0.47273338 0.47128072
 0.46929213 0.4672581  0.46520332 0.46284416 0.46031803 0.4578594
 0.45540798 0.4528335  0.45007032 0.44713995 0.44437057 0.44147822
 0.43842924 0.43532488 0.4322476  0.42921165 0.42629233 0.42338374
 0.42075947 0.41847146 0.41637588 0.41449565 0.4130247  0.4121121
 0.4117807  0.4116856  0.41196746 0.41237417 0.4130283  0.41379645
 0.41463614 0.41548368 0.4163152  0.4170529  0.41783854 0.4186839
 0.4194557  0.4201452  0.42060152 0.42083785 0.4209749  0.42120802
 0.4213446  0.4214688  0.4214675  0.42137367 0.42135322 0.42147624
 0.42163116 0.4216103  0.42141235 0.42128444 0.42123088 0.4212437
 0.4212937  0.42133072 0.4212309  0.42095932 0.4207714  0.42064956
 0.42040503 0.4201065  0.41970843 0.4193875  0.41920197 0.41889414
 0.41858155 0.41825885 0.41799912 0.4176432  0.41727167 0.41693914
 0.41658264 0.41626674 0.4161875  0.41615888 0.41589686 0.4153914
 0.41491005 0.4144115  0.41405413 0.4136719  0.413321   0.41296244
 0.41257444 0.41226813 0.41209725 0.4119519  0.41176993 0.41155446
 0.41129413 0.4110328  0.41081655 0.41055098 0.41037238 0.41024747
 0.41013163 0.41009125 0.41002715 0.40996096 0.40979603 0.40967372
 0.4095594  0.40946734 0.409365   0.40926337 0.40914094 0.40915495
 0.40910724 0.40897942 0.40886006 0.4087978  0.4087421  0.40855753
 0.40824392 0.4078849  0.40745455 0.40709794 0.406872   0.4066995
 0.40644994 0.40602997 0.4055827  0.4051242  0.40466934 0.404099
 0.4035149  0.40289742 0.4023289  0.4018215  0.40134746 0.4008808
 0.40030998 0.3995388  0.3986642  0.39775378 0.3968836  0.39598048
 0.3950557  0.3940644  0.3929756  0.39171112 0.39037117 0.3888134
 0.38697678 0.38479573 0.38258624 0.38052145 0.37843746 0.37625128
 0.37395293 0.37141246 0.3687326  0.36569464 0.36257356 0.3594644
 0.35640007 0.3534079  0.3503568  0.34744743 0.34468856 0.34218028
 0.3399201  0.3379491  0.33650628 0.33569425 0.33557296 0.336205
 0.3372788  0.338781   0.34050578 0.34237006 0.34439957 0.34649956
 0.34850928 0.3504052  0.35216188 0.35389945 0.35561043 0.35739857
 0.35909492 0.36062533 0.3620625  0.36342067 0.36461577 0.36559135
 0.36652294 0.36740166 0.36835942 0.36924765 0.3699892  0.37061226
 0.3711836  0.37161076 0.37200075 0.3724334  0.37272733 0.3727843
 0.37277815 0.37278655 0.37284777 0.37290424 0.37288752 0.37275848
 0.37268633 0.37254608 0.37242216 0.37228706 0.37210968 0.37188855
 0.37164226 0.37139183 0.37113026 0.37090713 0.37060198 0.370399
 0.37018833 0.3699213  0.369637   0.36929983 0.3689197  0.36856365
 0.3682012  0.367877   0.36756378 0.36727557 0.36685124 0.3664389
 0.36599028 0.36543316 0.36488658 0.36435702 0.3637503  0.36325416
 0.3629227  0.36272588 0.3625093  0.36225808 0.36211395 0.36204523
 0.3620226  0.36192098 0.3615922  0.36134356 0.3611801  0.36112252
 0.36112052 0.3610551  0.36088482 0.36063507 0.3603459  0.36014152
 0.36004177 0.36011577 0.3601427  0.36013922 0.35994196 0.3595766
 0.35925823 0.358955   0.35876223 0.35860702 0.35841838 0.35812476
 0.35788336 0.3575726  0.3573328  0.35706022 0.3567996  0.35644856
 0.3560982  0.3556227  0.35501567 0.35434696 0.35363504 0.35298526
 0.3523204  0.3515715  0.35066113 0.3496376  0.34844133 0.34717712
 0.3458245  0.34438604 0.34278876 0.34098488 0.3391524  0.33745757
 0.33556053 0.3333835  0.33091706 0.32838428 0.3257735  0.32312438
 0.32017192 0.31689996 0.31350124 0.31029367 0.30734956 0.30433404
 0.30121353 0.2978692  0.2947533  0.29207268 0.28966543 0.28743026
 0.2853545  0.28373823 0.2826564  0.28230253 0.28261685 0.28353587
 0.28477967 0.2861036  0.28763005 0.28958932 0.2917693  0.2939503
 0.29602024 0.29806748 0.29991478 0.3017573  0.30384037 0.3059872
 0.30828884 0.31035504 0.3122983  0.3139467  0.31538895 0.31675053
 0.3180788  0.31927365 0.32042018 0.3213145  0.3220671  0.32258856
 0.32301304 0.32348132 0.32381332 0.324052   0.32421985 0.32439002
 0.32457954 0.32468802 0.32478502 0.32459456 0.3243536  0.32430962
 0.32443652 0.32467356 0.32492477 0.32503536 0.32513937 0.32510993
 0.32492772 0.3246373  0.3243032  0.32399815 0.323664   0.32343063
 0.32313278 0.32283786 0.3226042  0.32226047 0.32198524 0.3216762
 0.3214964  0.3212144  0.32074615 0.32033646 0.32007864 0.31975174
 0.31931594 0.31873682 0.31812617 0.31759518 0.31703806 0.3164852
 0.31595847 0.3154846  0.31524834 0.31498    0.31479585 0.3147301
 0.31475183 0.3149599  0.31529707 0.31555557 0.3157521  0.3159602
 0.3162192  0.3164185  0.3166056  0.31659397 0.3164797  0.31642812
 0.3165881  0.31667987 0.31666556 0.3164836  0.31637734 0.31622347
 0.31617686 0.31611988 0.31603715 0.31591412 0.31598482 0.3161645
 0.316301   0.31625953 0.3162142  0.316312   0.31629992 0.31627005
 0.3159736  0.31557044 0.31495827 0.31449547 0.31402934 0.313389
 0.31263667 0.3119145  0.31111836 0.310138   0.30898842 0.3078131
 0.30655485 0.305091   0.30358627 0.3019796  0.30029738 0.29847655
 0.29643145 0.2940995  0.29160932 0.28911275 0.28661066 0.2841132
 0.28147876 0.27861723 0.27538046 0.27208334 0.2687344  0.26544377
 0.26208577 0.25864485 0.25520557 0.2518245  0.24870528 0.24579555
 0.24336639 0.2416008  0.24045853 0.24008793 0.24032521 0.24132517
 0.24292701 0.24511    0.24764037 0.2503294  0.25296763 0.2556183
 0.25839195 0.2612368  0.26390997 0.2662677  0.26867598 0.2710695
 0.2734239  0.27568522 0.2777252  0.27954623 0.28114685 0.28257474
 0.28386512 0.28507563 0.28616494 0.28732353 0.28827626 0.2890984
 0.2896574  0.29013175 0.2905392  0.29090807 0.2912783  0.2914094
 0.29142562 0.29130927 0.29115227 0.29106173 0.2909926  0.2908097
 0.2905626  0.29030916 0.2901274  0.289968   0.2898372  0.28966826
 0.28941172 0.28920305 0.2890065  0.28870797 0.28838474 0.28803477
 0.287734   0.28745744 0.28719404 0.2868572  0.28643438 0.285978
 0.28548142 0.28493676 0.28430188 0.2836782  0.28317133 0.28275508
 0.2823621  0.28192008 0.28134653 0.2808878  0.28043014 0.2799897
 0.2794845  0.27894214 0.27844447 0.2780877  0.27782446 0.27748182
 0.27718467 0.2769064  0.27670082 0.27657217 0.2763284  0.27601096
 0.2756711  0.27549848 0.27540958 0.27533925 0.27516302 0.27499482
 0.27485335 0.27477068 0.27468345 0.274595   0.2745308  0.27449167
 0.2744315  0.274249   0.27398157 0.27362317 0.27337024 0.273146
 0.2727597  0.27229238 0.27176026 0.27143037 0.2708623  0.27018392
 0.26935956 0.26858193 0.26790103 0.2671271  0.26625308 0.2653547
 0.26444092 0.26346198 0.26253006 0.26137605 0.26007125 0.2586161
 0.25704578 0.25539744 0.25377008 0.2520486  0.25009203 0.2479709
 0.24580856 0.24372192 0.24165298 0.23938388 0.23669522 0.23381698
 0.23088802 0.2280042  0.22508036 0.22217233 0.21912803 0.21600308
 0.21286593 0.20973243 0.20679782 0.20413736 0.20166036 0.1992456
 0.19713016 0.19542108 0.19425978 0.19366811 0.19365932 0.19450815
 0.19593732 0.19796829 0.20041381 0.20288517 0.2052038  0.20754592
 0.20984004 0.21217282 0.21461532 0.21677865 0.2189921  0.22110724
 0.22319062 0.22540873 0.2275662  0.22940835 0.23128343 0.23318213
 0.23504043 0.23667257 0.23826668 0.23965457 0.24103491 0.24206667
 0.24287991 0.24350442 0.2440798  0.24468467 0.24524991 0.24558894
 0.24589083 0.2460578  0.24646632 0.24685569 0.24715215 0.24736243
 0.24750392 0.24764583 0.24788089 0.24801998 0.24834493 0.2486523
 0.24893953 0.2489836  0.24896972 0.24883422 0.24859947 0.24823654
 0.24794145 0.24766973 0.24739817 0.24697538 0.2465298  0.24601944
 0.24550915 0.24507563 0.24446553 0.24378695 0.24319924 0.24277656
 0.24253698 0.24221958 0.24166526 0.24101742 0.24052133 0.24010885
 0.23970743 0.2392335  0.23876424 0.23839504 0.23821643 0.23808557
 0.23771231 0.23736678 0.23717983 0.23713504 0.23719864 0.23714586
 0.23698387 0.23691322 0.23697871 0.23698862 0.23683828 0.23676284
 0.23686433 0.23708889 0.23722549 0.23719196 0.23706    0.23706126
 0.23736867 0.23769449 0.2377563  0.23768571 0.23773217 0.23795831
 0.23822217 0.23816212 0.23769641 0.23747705 0.23763399 0.23792759
 0.23782878 0.23737493 0.23709022 0.23723684 0.23726028 0.23676316
 0.2359647  0.23570344 0.23555902 0.23500758 0.23366591 0.23243822]
