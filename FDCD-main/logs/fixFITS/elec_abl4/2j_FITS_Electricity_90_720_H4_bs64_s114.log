Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_90_j720_H4', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_90_j720_H4_FITS_custom_ftM_sl90_ll48_pl720_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17603
val 1913
test 4541
Model(
  (freq_upsampler): Linear(in_features=26, out_features=234, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  249979392.0
params:  6318.0
Trainable parameters:  6318
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 1.3308828
	speed: 0.2048s/iter; left time: 2785.0059s
Epoch: 1 cost time: 27.82635474205017
Epoch: 1, Steps: 137 | Train Loss: 1.8654953 Vali Loss: 0.9865226 Test Loss: 1.0900630
Validation loss decreased (inf --> 0.986523).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.7556739
	speed: 0.5458s/iter; left time: 7348.9500s
Epoch: 2 cost time: 29.909637451171875
Epoch: 2, Steps: 137 | Train Loss: 0.8500016 Vali Loss: 0.6020731 Test Loss: 0.6734655
Validation loss decreased (0.986523 --> 0.602073).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5450682
	speed: 0.5136s/iter; left time: 6845.3388s
Epoch: 3 cost time: 27.776172399520874
Epoch: 3, Steps: 137 | Train Loss: 0.5802352 Vali Loss: 0.4585408 Test Loss: 0.5177612
Validation loss decreased (0.602073 --> 0.458541).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4488130
	speed: 0.5187s/iter; left time: 6841.1648s
Epoch: 4 cost time: 28.015893936157227
Epoch: 4, Steps: 137 | Train Loss: 0.4623720 Vali Loss: 0.3830599 Test Loss: 0.4352219
Validation loss decreased (0.458541 --> 0.383060).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3967824
	speed: 0.5253s/iter; left time: 6857.2873s
Epoch: 5 cost time: 28.541149377822876
Epoch: 5, Steps: 137 | Train Loss: 0.3957503 Vali Loss: 0.3383568 Test Loss: 0.3849809
Validation loss decreased (0.383060 --> 0.338357).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3366574
	speed: 0.5575s/iter; left time: 7201.0727s
Epoch: 6 cost time: 30.032927989959717
Epoch: 6, Steps: 137 | Train Loss: 0.3540795 Vali Loss: 0.3102276 Test Loss: 0.3527194
Validation loss decreased (0.338357 --> 0.310228).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3299952
	speed: 0.5313s/iter; left time: 6789.8531s
Epoch: 7 cost time: 29.600406169891357
Epoch: 7, Steps: 137 | Train Loss: 0.3270320 Vali Loss: 0.2910275 Test Loss: 0.3313357
Validation loss decreased (0.310228 --> 0.291027).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3134805
	speed: 0.5130s/iter; left time: 6485.7480s
Epoch: 8 cost time: 28.62110710144043
Epoch: 8, Steps: 137 | Train Loss: 0.3089414 Vali Loss: 0.2785141 Test Loss: 0.3165458
Validation loss decreased (0.291027 --> 0.278514).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2968437
	speed: 0.5391s/iter; left time: 6741.9693s
Epoch: 9 cost time: 29.6214337348938
Epoch: 9, Steps: 137 | Train Loss: 0.2964136 Vali Loss: 0.2695076 Test Loss: 0.3063529
Validation loss decreased (0.278514 --> 0.269508).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2786547
	speed: 0.5076s/iter; left time: 6277.4580s
Epoch: 10 cost time: 27.710573434829712
Epoch: 10, Steps: 137 | Train Loss: 0.2875815 Vali Loss: 0.2635656 Test Loss: 0.2989340
Validation loss decreased (0.269508 --> 0.263566).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2708985
	speed: 0.5479s/iter; left time: 6700.8697s
Epoch: 11 cost time: 30.546114206314087
Epoch: 11, Steps: 137 | Train Loss: 0.2812045 Vali Loss: 0.2584629 Test Loss: 0.2935201
Validation loss decreased (0.263566 --> 0.258463).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2935632
	speed: 0.5381s/iter; left time: 6508.2957s
Epoch: 12 cost time: 29.158532857894897
Epoch: 12, Steps: 137 | Train Loss: 0.2763877 Vali Loss: 0.2551545 Test Loss: 0.2894216
Validation loss decreased (0.258463 --> 0.255155).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2780516
	speed: 0.5369s/iter; left time: 6419.6046s
Epoch: 13 cost time: 28.93175196647644
Epoch: 13, Steps: 137 | Train Loss: 0.2728212 Vali Loss: 0.2518850 Test Loss: 0.2862493
Validation loss decreased (0.255155 --> 0.251885).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2659526
	speed: 0.5237s/iter; left time: 6190.1091s
Epoch: 14 cost time: 29.710911989212036
Epoch: 14, Steps: 137 | Train Loss: 0.2699286 Vali Loss: 0.2502289 Test Loss: 0.2837161
Validation loss decreased (0.251885 --> 0.250229).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2733753
	speed: 0.5478s/iter; left time: 6399.4173s
Epoch: 15 cost time: 31.091450452804565
Epoch: 15, Steps: 137 | Train Loss: 0.2676204 Vali Loss: 0.2483425 Test Loss: 0.2817079
Validation loss decreased (0.250229 --> 0.248343).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2556637
	speed: 0.5481s/iter; left time: 6328.4920s
Epoch: 16 cost time: 29.24659562110901
Epoch: 16, Steps: 137 | Train Loss: 0.2658426 Vali Loss: 0.2468063 Test Loss: 0.2800560
Validation loss decreased (0.248343 --> 0.246806).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2585720
	speed: 0.5469s/iter; left time: 6239.1140s
Epoch: 17 cost time: 29.099196434020996
Epoch: 17, Steps: 137 | Train Loss: 0.2642761 Vali Loss: 0.2455324 Test Loss: 0.2786660
Validation loss decreased (0.246806 --> 0.245532).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2580424
	speed: 0.5503s/iter; left time: 6202.5566s
Epoch: 18 cost time: 31.546168565750122
Epoch: 18, Steps: 137 | Train Loss: 0.2629820 Vali Loss: 0.2448431 Test Loss: 0.2774834
Validation loss decreased (0.245532 --> 0.244843).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2644346
	speed: 0.5479s/iter; left time: 6100.3638s
Epoch: 19 cost time: 28.313183069229126
Epoch: 19, Steps: 137 | Train Loss: 0.2618709 Vali Loss: 0.2439035 Test Loss: 0.2765014
Validation loss decreased (0.244843 --> 0.243904).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2509877
	speed: 0.5241s/iter; left time: 5764.4877s
Epoch: 20 cost time: 28.989895582199097
Epoch: 20, Steps: 137 | Train Loss: 0.2609849 Vali Loss: 0.2430385 Test Loss: 0.2756484
Validation loss decreased (0.243904 --> 0.243038).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2670722
	speed: 0.5192s/iter; left time: 5639.3062s
Epoch: 21 cost time: 30.523793935775757
Epoch: 21, Steps: 137 | Train Loss: 0.2601332 Vali Loss: 0.2415947 Test Loss: 0.2749541
Validation loss decreased (0.243038 --> 0.241595).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2688617
	speed: 0.5337s/iter; left time: 5723.9265s
Epoch: 22 cost time: 28.93379807472229
Epoch: 22, Steps: 137 | Train Loss: 0.2594167 Vali Loss: 0.2415725 Test Loss: 0.2742547
Validation loss decreased (0.241595 --> 0.241573).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2588446
	speed: 0.5370s/iter; left time: 5685.3644s
Epoch: 23 cost time: 28.4641056060791
Epoch: 23, Steps: 137 | Train Loss: 0.2587175 Vali Loss: 0.2410351 Test Loss: 0.2737032
Validation loss decreased (0.241573 --> 0.241035).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2555712
	speed: 0.5296s/iter; left time: 5533.9289s
Epoch: 24 cost time: 28.454533576965332
Epoch: 24, Steps: 137 | Train Loss: 0.2582613 Vali Loss: 0.2408905 Test Loss: 0.2732019
Validation loss decreased (0.241035 --> 0.240890).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2517220
	speed: 0.4935s/iter; left time: 5089.2119s
Epoch: 25 cost time: 26.08849573135376
Epoch: 25, Steps: 137 | Train Loss: 0.2577026 Vali Loss: 0.2399655 Test Loss: 0.2727407
Validation loss decreased (0.240890 --> 0.239965).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2598724
	speed: 0.4982s/iter; left time: 5069.3283s
Epoch: 26 cost time: 27.688671827316284
Epoch: 26, Steps: 137 | Train Loss: 0.2572967 Vali Loss: 0.2394982 Test Loss: 0.2723353
Validation loss decreased (0.239965 --> 0.239498).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2583556
	speed: 0.5037s/iter; left time: 5056.3564s
Epoch: 27 cost time: 28.545416831970215
Epoch: 27, Steps: 137 | Train Loss: 0.2569280 Vali Loss: 0.2394520 Test Loss: 0.2719890
Validation loss decreased (0.239498 --> 0.239452).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2536720
	speed: 0.5551s/iter; left time: 5496.7251s
Epoch: 28 cost time: 30.03278660774231
Epoch: 28, Steps: 137 | Train Loss: 0.2566010 Vali Loss: 0.2391428 Test Loss: 0.2716438
Validation loss decreased (0.239452 --> 0.239143).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2533837
	speed: 0.5385s/iter; left time: 5258.3493s
Epoch: 29 cost time: 28.956761360168457
Epoch: 29, Steps: 137 | Train Loss: 0.2563074 Vali Loss: 0.2383957 Test Loss: 0.2713754
Validation loss decreased (0.239143 --> 0.238396).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2613665
	speed: 0.5130s/iter; left time: 4938.8641s
Epoch: 30 cost time: 28.55268144607544
Epoch: 30, Steps: 137 | Train Loss: 0.2558512 Vali Loss: 0.2390194 Test Loss: 0.2710802
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2529079
	speed: 0.5209s/iter; left time: 4943.4192s
Epoch: 31 cost time: 29.103387355804443
Epoch: 31, Steps: 137 | Train Loss: 0.2557758 Vali Loss: 0.2385211 Test Loss: 0.2708552
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2490489
	speed: 0.5188s/iter; left time: 4852.8183s
Epoch: 32 cost time: 28.84976553916931
Epoch: 32, Steps: 137 | Train Loss: 0.2555204 Vali Loss: 0.2386919 Test Loss: 0.2706074
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2569957
	speed: 0.5161s/iter; left time: 4756.4901s
Epoch: 33 cost time: 28.54037833213806
Epoch: 33, Steps: 137 | Train Loss: 0.2552403 Vali Loss: 0.2376421 Test Loss: 0.2704017
Validation loss decreased (0.238396 --> 0.237642).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2502404
	speed: 0.5354s/iter; left time: 4861.3177s
Epoch: 34 cost time: 28.260441303253174
Epoch: 34, Steps: 137 | Train Loss: 0.2550587 Vali Loss: 0.2375713 Test Loss: 0.2702263
Validation loss decreased (0.237642 --> 0.237571).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2538944
	speed: 0.5291s/iter; left time: 4731.7815s
Epoch: 35 cost time: 28.980858325958252
Epoch: 35, Steps: 137 | Train Loss: 0.2548983 Vali Loss: 0.2375024 Test Loss: 0.2700500
Validation loss decreased (0.237571 --> 0.237502).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2537948
	speed: 0.5193s/iter; left time: 4573.0098s
Epoch: 36 cost time: 28.60802173614502
Epoch: 36, Steps: 137 | Train Loss: 0.2547104 Vali Loss: 0.2376339 Test Loss: 0.2699006
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2639272
	speed: 0.5147s/iter; left time: 4462.2410s
Epoch: 37 cost time: 27.73085880279541
Epoch: 37, Steps: 137 | Train Loss: 0.2545148 Vali Loss: 0.2374023 Test Loss: 0.2697486
Validation loss decreased (0.237502 --> 0.237402).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2643137
	speed: 0.5011s/iter; left time: 4275.3688s
Epoch: 38 cost time: 28.2023663520813
Epoch: 38, Steps: 137 | Train Loss: 0.2543154 Vali Loss: 0.2372438 Test Loss: 0.2695969
Validation loss decreased (0.237402 --> 0.237244).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2550910
	speed: 0.5532s/iter; left time: 4643.8768s
Epoch: 39 cost time: 30.512325286865234
Epoch: 39, Steps: 137 | Train Loss: 0.2542928 Vali Loss: 0.2373357 Test Loss: 0.2694545
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2463235
	speed: 0.5327s/iter; left time: 4398.8096s
Epoch: 40 cost time: 27.785622119903564
Epoch: 40, Steps: 137 | Train Loss: 0.2540177 Vali Loss: 0.2372398 Test Loss: 0.2693304
Validation loss decreased (0.237244 --> 0.237240).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2452602
	speed: 0.5613s/iter; left time: 4558.2912s
Epoch: 41 cost time: 31.76274037361145
Epoch: 41, Steps: 137 | Train Loss: 0.2540254 Vali Loss: 0.2375329 Test Loss: 0.2692187
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2692952
	speed: 0.5778s/iter; left time: 4612.9737s
Epoch: 42 cost time: 29.2041757106781
Epoch: 42, Steps: 137 | Train Loss: 0.2539058 Vali Loss: 0.2369427 Test Loss: 0.2691087
Validation loss decreased (0.237240 --> 0.236943).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2561117
	speed: 0.5716s/iter; left time: 4485.0567s
Epoch: 43 cost time: 31.76725935935974
Epoch: 43, Steps: 137 | Train Loss: 0.2537876 Vali Loss: 0.2368287 Test Loss: 0.2690060
Validation loss decreased (0.236943 --> 0.236829).  Saving model ...
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2462778
	speed: 0.5182s/iter; left time: 3995.0457s
Epoch: 44 cost time: 27.52423357963562
Epoch: 44, Steps: 137 | Train Loss: 0.2537548 Vali Loss: 0.2371412 Test Loss: 0.2689210
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2572648
	speed: 0.5389s/iter; left time: 4081.0755s
Epoch: 45 cost time: 30.41420817375183
Epoch: 45, Steps: 137 | Train Loss: 0.2535813 Vali Loss: 0.2364956 Test Loss: 0.2688180
Validation loss decreased (0.236829 --> 0.236496).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2459875
	speed: 0.5199s/iter; left time: 3866.2803s
Epoch: 46 cost time: 28.25438690185547
Epoch: 46, Steps: 137 | Train Loss: 0.2534992 Vali Loss: 0.2368861 Test Loss: 0.2687281
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2565856
	speed: 0.5538s/iter; left time: 4042.3644s
Epoch: 47 cost time: 32.320255279541016
Epoch: 47, Steps: 137 | Train Loss: 0.2533518 Vali Loss: 0.2368569 Test Loss: 0.2686455
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2592039
	speed: 0.5639s/iter; left time: 4038.5012s
Epoch: 48 cost time: 31.590662956237793
Epoch: 48, Steps: 137 | Train Loss: 0.2532785 Vali Loss: 0.2363028 Test Loss: 0.2685804
Validation loss decreased (0.236496 --> 0.236303).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2705416
	speed: 0.5698s/iter; left time: 4002.6727s
Epoch: 49 cost time: 28.629756927490234
Epoch: 49, Steps: 137 | Train Loss: 0.2532639 Vali Loss: 0.2365301 Test Loss: 0.2684995
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2459635
	speed: 0.5485s/iter; left time: 3778.0586s
Epoch: 50 cost time: 31.343761920928955
Epoch: 50, Steps: 137 | Train Loss: 0.2531363 Vali Loss: 0.2364218 Test Loss: 0.2684344
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2544447
	speed: 0.5090s/iter; left time: 3436.2041s
Epoch: 51 cost time: 26.960203647613525
Epoch: 51, Steps: 137 | Train Loss: 0.2531207 Vali Loss: 0.2364024 Test Loss: 0.2683697
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2535528
	speed: 0.4975s/iter; left time: 3290.2925s
Epoch: 52 cost time: 27.775707006454468
Epoch: 52, Steps: 137 | Train Loss: 0.2529889 Vali Loss: 0.2361146 Test Loss: 0.2682993
Validation loss decreased (0.236303 --> 0.236115).  Saving model ...
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2442532
	speed: 0.5301s/iter; left time: 3433.3964s
Epoch: 53 cost time: 30.042893648147583
Epoch: 53, Steps: 137 | Train Loss: 0.2529393 Vali Loss: 0.2357522 Test Loss: 0.2682413
Validation loss decreased (0.236115 --> 0.235752).  Saving model ...
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2645751
	speed: 0.5327s/iter; left time: 3377.1499s
Epoch: 54 cost time: 30.100252628326416
Epoch: 54, Steps: 137 | Train Loss: 0.2528455 Vali Loss: 0.2359407 Test Loss: 0.2681942
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2609367
	speed: 0.5596s/iter; left time: 3470.9129s
Epoch: 55 cost time: 30.96576166152954
Epoch: 55, Steps: 137 | Train Loss: 0.2528263 Vali Loss: 0.2358694 Test Loss: 0.2681433
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2467184
	speed: 0.5755s/iter; left time: 3491.0527s
Epoch: 56 cost time: 29.965397357940674
Epoch: 56, Steps: 137 | Train Loss: 0.2528185 Vali Loss: 0.2358449 Test Loss: 0.2680901
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2551170
	speed: 0.6070s/iter; left time: 3598.9630s
Epoch: 57 cost time: 31.73623824119568
Epoch: 57, Steps: 137 | Train Loss: 0.2527000 Vali Loss: 0.2356535 Test Loss: 0.2680412
Validation loss decreased (0.235752 --> 0.235654).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2527938
	speed: 0.5865s/iter; left time: 3397.2489s
Epoch: 58 cost time: 32.52641677856445
Epoch: 58, Steps: 137 | Train Loss: 0.2527296 Vali Loss: 0.2363226 Test Loss: 0.2680055
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2719699
	speed: 0.5985s/iter; left time: 3384.7940s
Epoch: 59 cost time: 32.57844376564026
Epoch: 59, Steps: 137 | Train Loss: 0.2526170 Vali Loss: 0.2355316 Test Loss: 0.2679628
Validation loss decreased (0.235654 --> 0.235532).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.2511240
	speed: 0.5806s/iter; left time: 3203.5970s
Epoch: 60 cost time: 33.8146755695343
Epoch: 60, Steps: 137 | Train Loss: 0.2526298 Vali Loss: 0.2359293 Test Loss: 0.2679170
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.2519957
	speed: 0.6035s/iter; left time: 3247.4829s
Epoch: 61 cost time: 33.78712201118469
Epoch: 61, Steps: 137 | Train Loss: 0.2524995 Vali Loss: 0.2359947 Test Loss: 0.2678776
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.2590870
	speed: 0.5412s/iter; left time: 2838.1218s
Epoch: 62 cost time: 29.499195337295532
Epoch: 62, Steps: 137 | Train Loss: 0.2525596 Vali Loss: 0.2353520 Test Loss: 0.2678403
Validation loss decreased (0.235532 --> 0.235352).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.2549320
	speed: 0.5502s/iter; left time: 2809.9223s
Epoch: 63 cost time: 29.62987470626831
Epoch: 63, Steps: 137 | Train Loss: 0.2524473 Vali Loss: 0.2360426 Test Loss: 0.2678083
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.2565732
	speed: 0.6118s/iter; left time: 3040.6258s
Epoch: 64 cost time: 31.91905975341797
Epoch: 64, Steps: 137 | Train Loss: 0.2524738 Vali Loss: 0.2359436 Test Loss: 0.2677828
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.2529204
	speed: 0.5278s/iter; left time: 2550.6462s
Epoch: 65 cost time: 29.088869333267212
Epoch: 65, Steps: 137 | Train Loss: 0.2524105 Vali Loss: 0.2354539 Test Loss: 0.2677487
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.2642950
	speed: 0.5539s/iter; left time: 2601.2270s
Epoch: 66 cost time: 29.796913862228394
Epoch: 66, Steps: 137 | Train Loss: 0.2523863 Vali Loss: 0.2350573 Test Loss: 0.2677253
Validation loss decreased (0.235352 --> 0.235057).  Saving model ...
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.2508821
	speed: 0.5649s/iter; left time: 2575.5818s
Epoch: 67 cost time: 29.626813888549805
Epoch: 67, Steps: 137 | Train Loss: 0.2524038 Vali Loss: 0.2351602 Test Loss: 0.2676994
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.2540767
	speed: 0.5438s/iter; left time: 2404.5529s
Epoch: 68 cost time: 29.6879985332489
Epoch: 68, Steps: 137 | Train Loss: 0.2522786 Vali Loss: 0.2358360 Test Loss: 0.2676731
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.2489209
	speed: 0.5507s/iter; left time: 2359.7686s
Epoch: 69 cost time: 31.68834114074707
Epoch: 69, Steps: 137 | Train Loss: 0.2523156 Vali Loss: 0.2356957 Test Loss: 0.2676471
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.2486760
	speed: 0.5993s/iter; left time: 2485.9685s
Epoch: 70 cost time: 32.94801712036133
Epoch: 70, Steps: 137 | Train Loss: 0.2522461 Vali Loss: 0.2355025 Test Loss: 0.2676267
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.2598623
	speed: 0.5999s/iter; left time: 2406.1844s
Epoch: 71 cost time: 31.254617929458618
Epoch: 71, Steps: 137 | Train Loss: 0.2522033 Vali Loss: 0.2355897 Test Loss: 0.2676085
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.2548193
	speed: 0.5385s/iter; left time: 2085.9810s
Epoch: 72 cost time: 28.7213191986084
Epoch: 72, Steps: 137 | Train Loss: 0.2522496 Vali Loss: 0.2351723 Test Loss: 0.2675815
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.2509525
	speed: 0.5532s/iter; left time: 2067.3062s
Epoch: 73 cost time: 33.03582286834717
Epoch: 73, Steps: 137 | Train Loss: 0.2522745 Vali Loss: 0.2351005 Test Loss: 0.2675635
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.2483951
	speed: 0.5803s/iter; left time: 2089.1114s
Epoch: 74 cost time: 30.086963176727295
Epoch: 74, Steps: 137 | Train Loss: 0.2521436 Vali Loss: 0.2354269 Test Loss: 0.2675456
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.2398682
	speed: 0.5817s/iter; left time: 2014.4975s
Epoch: 75 cost time: 33.419164180755615
Epoch: 75, Steps: 137 | Train Loss: 0.2521695 Vali Loss: 0.2351997 Test Loss: 0.2675304
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.2484142
	speed: 0.6187s/iter; left time: 2057.6777s
Epoch: 76 cost time: 33.21973395347595
Epoch: 76, Steps: 137 | Train Loss: 0.2521238 Vali Loss: 0.2354739 Test Loss: 0.2675146
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.2607398
	speed: 0.5571s/iter; left time: 1776.4884s
Epoch: 77 cost time: 28.900846481323242
Epoch: 77, Steps: 137 | Train Loss: 0.2522075 Vali Loss: 0.2357132 Test Loss: 0.2675004
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.2559684
	speed: 0.5810s/iter; left time: 1773.1685s
Epoch: 78 cost time: 31.755764484405518
Epoch: 78, Steps: 137 | Train Loss: 0.2520634 Vali Loss: 0.2356682 Test Loss: 0.2674851
EarlyStopping counter: 12 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.2449942
	speed: 0.5355s/iter; left time: 1560.9876s
Epoch: 79 cost time: 28.23848819732666
Epoch: 79, Steps: 137 | Train Loss: 0.2520661 Vali Loss: 0.2355968 Test Loss: 0.2674725
EarlyStopping counter: 13 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.2513472
	speed: 0.5996s/iter; left time: 1665.7174s
Epoch: 80 cost time: 30.772934913635254
Epoch: 80, Steps: 137 | Train Loss: 0.2520358 Vali Loss: 0.2355885 Test Loss: 0.2674590
EarlyStopping counter: 14 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.2499439
	speed: 0.5061s/iter; left time: 1336.6208s
Epoch: 81 cost time: 29.420003175735474
Epoch: 81, Steps: 137 | Train Loss: 0.2520993 Vali Loss: 0.2352531 Test Loss: 0.2674496
EarlyStopping counter: 15 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.2506032
	speed: 0.5068s/iter; left time: 1268.9975s
Epoch: 82 cost time: 27.66024684906006
Epoch: 82, Steps: 137 | Train Loss: 0.2519762 Vali Loss: 0.2346353 Test Loss: 0.2674362
Validation loss decreased (0.235057 --> 0.234635).  Saving model ...
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.2719530
	speed: 0.5351s/iter; left time: 1266.4787s
Epoch: 83 cost time: 30.232555150985718
Epoch: 83, Steps: 137 | Train Loss: 0.2521192 Vali Loss: 0.2356679 Test Loss: 0.2674249
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.2673412
	speed: 0.6026s/iter; left time: 1343.7750s
Epoch: 84 cost time: 30.775742769241333
Epoch: 84, Steps: 137 | Train Loss: 0.2519321 Vali Loss: 0.2349052 Test Loss: 0.2674145
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.2545886
	speed: 0.5962s/iter; left time: 1247.7425s
Epoch: 85 cost time: 31.901336908340454
Epoch: 85, Steps: 137 | Train Loss: 0.2520470 Vali Loss: 0.2355972 Test Loss: 0.2674052
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.2620054
	speed: 0.5724s/iter; left time: 1119.7030s
Epoch: 86 cost time: 32.58233332633972
Epoch: 86, Steps: 137 | Train Loss: 0.2520940 Vali Loss: 0.2353447 Test Loss: 0.2673956
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.2416987
	speed: 0.5334s/iter; left time: 970.3421s
Epoch: 87 cost time: 29.32158589363098
Epoch: 87, Steps: 137 | Train Loss: 0.2519470 Vali Loss: 0.2355842 Test Loss: 0.2673889
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.2483444
	speed: 0.5619s/iter; left time: 945.1925s
Epoch: 88 cost time: 32.62290287017822
Epoch: 88, Steps: 137 | Train Loss: 0.2520010 Vali Loss: 0.2350948 Test Loss: 0.2673793
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.2610857
	speed: 0.5683s/iter; left time: 877.9875s
Epoch: 89 cost time: 30.484642028808594
Epoch: 89, Steps: 137 | Train Loss: 0.2519778 Vali Loss: 0.2354456 Test Loss: 0.2673721
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.2426375
	speed: 0.5293s/iter; left time: 745.3044s
Epoch: 90 cost time: 28.438331127166748
Epoch: 90, Steps: 137 | Train Loss: 0.2520007 Vali Loss: 0.2348790 Test Loss: 0.2673654
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.204402478767869e-06
	iters: 100, epoch: 91 | loss: 0.2539523
	speed: 0.5686s/iter; left time: 722.6920s
Epoch: 91 cost time: 29.637243509292603
Epoch: 91, Steps: 137 | Train Loss: 0.2519663 Vali Loss: 0.2351751 Test Loss: 0.2673596
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.944182354829475e-06
	iters: 100, epoch: 92 | loss: 0.2415635
	speed: 0.5801s/iter; left time: 657.8835s
Epoch: 92 cost time: 31.35728907585144
Epoch: 92, Steps: 137 | Train Loss: 0.2519808 Vali Loss: 0.2356946 Test Loss: 0.2673526
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.696973237088e-06
	iters: 100, epoch: 93 | loss: 0.2572194
	speed: 0.5409s/iter; left time: 539.2533s
Epoch: 93 cost time: 29.7892644405365
Epoch: 93, Steps: 137 | Train Loss: 0.2519397 Vali Loss: 0.2349361 Test Loss: 0.2673464
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.462124575233601e-06
	iters: 100, epoch: 94 | loss: 0.2408924
	speed: 0.6071s/iter; left time: 522.1018s
Epoch: 94 cost time: 33.37140202522278
Epoch: 94, Steps: 137 | Train Loss: 0.2520084 Vali Loss: 0.2351315 Test Loss: 0.2673410
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.239018346471921e-06
	iters: 100, epoch: 95 | loss: 0.2509338
	speed: 0.6119s/iter; left time: 442.4075s
Epoch: 95 cost time: 32.55716514587402
Epoch: 95, Steps: 137 | Train Loss: 0.2519409 Vali Loss: 0.2355899 Test Loss: 0.2673355
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.027067429148324e-06
	iters: 100, epoch: 96 | loss: 0.2479647
	speed: 0.5991s/iter; left time: 351.0449s
Epoch: 96 cost time: 30.965014219284058
Epoch: 96, Steps: 137 | Train Loss: 0.2519553 Vali Loss: 0.2350093 Test Loss: 0.2673306
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.825714057690908e-06
	iters: 100, epoch: 97 | loss: 0.2502194
	speed: 0.5306s/iter; left time: 238.2270s
Epoch: 97 cost time: 28.536664485931396
Epoch: 97, Steps: 137 | Train Loss: 0.2519530 Vali Loss: 0.2355111 Test Loss: 0.2673256
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.6344283548063623e-06
	iters: 100, epoch: 98 | loss: 0.2648839
	speed: 0.5180s/iter; left time: 161.6292s
Epoch: 98 cost time: 30.179144144058228
Epoch: 98, Steps: 137 | Train Loss: 0.2518595 Vali Loss: 0.2355238 Test Loss: 0.2673205
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.452706937066044e-06
	iters: 100, epoch: 99 | loss: 0.2508924
	speed: 0.5770s/iter; left time: 100.9746s
Epoch: 99 cost time: 30.672784566879272
Epoch: 99, Steps: 137 | Train Loss: 0.2519048 Vali Loss: 0.2353423 Test Loss: 0.2673168
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.2800715902127414e-06
	iters: 100, epoch: 100 | loss: 0.2536138
	speed: 0.5699s/iter; left time: 21.6547s
Epoch: 100 cost time: 30.4383385181427
Epoch: 100, Steps: 137 | Train Loss: 0.2519454 Vali Loss: 0.2351787 Test Loss: 0.2673125
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.1160680107021042e-06
train 17603
val 1913
test 4541
Model(
  (freq_upsampler): Linear(in_features=26, out_features=234, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  249979392.0
params:  6318.0
Trainable parameters:  6318
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2795079
	speed: 0.2088s/iter; left time: 2839.5468s
Epoch: 1 cost time: 28.244253635406494
Epoch: 1, Steps: 137 | Train Loss: 0.2799826 Vali Loss: 0.2345252 Test Loss: 0.2664210
Validation loss decreased (inf --> 0.234525).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2672195
	speed: 0.5699s/iter; left time: 7673.3540s
Epoch: 2 cost time: 28.690797805786133
Epoch: 2, Steps: 137 | Train Loss: 0.2796161 Vali Loss: 0.2339578 Test Loss: 0.2663296
Validation loss decreased (0.234525 --> 0.233958).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2838007
	speed: 0.5371s/iter; left time: 7158.2572s
Epoch: 3 cost time: 28.84916639328003
Epoch: 3, Steps: 137 | Train Loss: 0.2794650 Vali Loss: 0.2340647 Test Loss: 0.2662070
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2679414
	speed: 0.5496s/iter; left time: 7249.6800s
Epoch: 4 cost time: 30.345659255981445
Epoch: 4, Steps: 137 | Train Loss: 0.2794266 Vali Loss: 0.2337497 Test Loss: 0.2662332
Validation loss decreased (0.233958 --> 0.233750).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2771837
	speed: 0.5920s/iter; left time: 7726.7480s
Epoch: 5 cost time: 32.86091995239258
Epoch: 5, Steps: 137 | Train Loss: 0.2794244 Vali Loss: 0.2337336 Test Loss: 0.2662781
Validation loss decreased (0.233750 --> 0.233734).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2875417
	speed: 0.5526s/iter; left time: 7137.0257s
Epoch: 6 cost time: 29.57664728164673
Epoch: 6, Steps: 137 | Train Loss: 0.2794348 Vali Loss: 0.2344744 Test Loss: 0.2662031
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2910176
	speed: 0.5268s/iter; left time: 6732.3544s
Epoch: 7 cost time: 29.11947226524353
Epoch: 7, Steps: 137 | Train Loss: 0.2793116 Vali Loss: 0.2336076 Test Loss: 0.2662352
Validation loss decreased (0.233734 --> 0.233608).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2813830
	speed: 0.5516s/iter; left time: 6973.2525s
Epoch: 8 cost time: 32.340489625930786
Epoch: 8, Steps: 137 | Train Loss: 0.2791748 Vali Loss: 0.2336780 Test Loss: 0.2661636
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2866441
	speed: 0.5886s/iter; left time: 7360.4131s
Epoch: 9 cost time: 29.491727590560913
Epoch: 9, Steps: 137 | Train Loss: 0.2793143 Vali Loss: 0.2340290 Test Loss: 0.2661874
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2748797
	speed: 0.5784s/iter; left time: 7153.9964s
Epoch: 10 cost time: 32.46070957183838
Epoch: 10, Steps: 137 | Train Loss: 0.2793890 Vali Loss: 0.2338032 Test Loss: 0.2661130
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2708876
	speed: 0.5630s/iter; left time: 6885.4705s
Epoch: 11 cost time: 29.82416820526123
Epoch: 11, Steps: 137 | Train Loss: 0.2793161 Vali Loss: 0.2341660 Test Loss: 0.2662288
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2692469
	speed: 0.6102s/iter; left time: 7380.1763s
Epoch: 12 cost time: 32.91884160041809
Epoch: 12, Steps: 137 | Train Loss: 0.2793644 Vali Loss: 0.2340155 Test Loss: 0.2662006
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3015548
	speed: 0.6147s/iter; left time: 7350.3937s
Epoch: 13 cost time: 32.12689781188965
Epoch: 13, Steps: 137 | Train Loss: 0.2792920 Vali Loss: 0.2339850 Test Loss: 0.2661819
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2892992
	speed: 0.5882s/iter; left time: 6952.8303s
Epoch: 14 cost time: 34.12889289855957
Epoch: 14, Steps: 137 | Train Loss: 0.2793744 Vali Loss: 0.2337404 Test Loss: 0.2661778
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2873096
	speed: 0.5800s/iter; left time: 6775.8879s
Epoch: 15 cost time: 29.402573347091675
Epoch: 15, Steps: 137 | Train Loss: 0.2792852 Vali Loss: 0.2340262 Test Loss: 0.2661607
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2766965
	speed: 0.5798s/iter; left time: 6693.9072s
Epoch: 16 cost time: 32.30047130584717
Epoch: 16, Steps: 137 | Train Loss: 0.2791754 Vali Loss: 0.2339915 Test Loss: 0.2661520
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2661639
	speed: 0.5464s/iter; left time: 6233.5362s
Epoch: 17 cost time: 30.389381408691406
Epoch: 17, Steps: 137 | Train Loss: 0.2792546 Vali Loss: 0.2336527 Test Loss: 0.2661539
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2894197
	speed: 0.6122s/iter; left time: 6900.5419s
Epoch: 18 cost time: 33.11666131019592
Epoch: 18, Steps: 137 | Train Loss: 0.2792104 Vali Loss: 0.2339293 Test Loss: 0.2661507
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2903160
	speed: 0.5594s/iter; left time: 6229.4408s
Epoch: 19 cost time: 29.143734216690063
Epoch: 19, Steps: 137 | Train Loss: 0.2792757 Vali Loss: 0.2340157 Test Loss: 0.2661308
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2667767
	speed: 0.5432s/iter; left time: 5974.2645s
Epoch: 20 cost time: 31.102088928222656
Epoch: 20, Steps: 137 | Train Loss: 0.2793076 Vali Loss: 0.2336164 Test Loss: 0.2661852
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2729140
	speed: 0.5369s/iter; left time: 5831.0795s
Epoch: 21 cost time: 31.196725606918335
Epoch: 21, Steps: 137 | Train Loss: 0.2792689 Vali Loss: 0.2338087 Test Loss: 0.2661609
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2764935
	speed: 0.5451s/iter; left time: 5845.3045s
Epoch: 22 cost time: 31.597330331802368
Epoch: 22, Steps: 137 | Train Loss: 0.2792768 Vali Loss: 0.2343490 Test Loss: 0.2662100
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2924463
	speed: 0.6182s/iter; left time: 6544.4883s
Epoch: 23 cost time: 32.78237795829773
Epoch: 23, Steps: 137 | Train Loss: 0.2792252 Vali Loss: 0.2339712 Test Loss: 0.2661889
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2700880
	speed: 0.5841s/iter; left time: 6103.6586s
Epoch: 24 cost time: 32.54881978034973
Epoch: 24, Steps: 137 | Train Loss: 0.2792637 Vali Loss: 0.2342260 Test Loss: 0.2661454
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2872433
	speed: 0.5457s/iter; left time: 5628.2817s
Epoch: 25 cost time: 31.96359944343567
Epoch: 25, Steps: 137 | Train Loss: 0.2793188 Vali Loss: 0.2334100 Test Loss: 0.2661801
Validation loss decreased (0.233608 --> 0.233410).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2964012
	speed: 0.5583s/iter; left time: 5681.0109s
Epoch: 26 cost time: 28.809213638305664
Epoch: 26, Steps: 137 | Train Loss: 0.2792327 Vali Loss: 0.2332578 Test Loss: 0.2661674
Validation loss decreased (0.233410 --> 0.233258).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2982871
	speed: 0.5481s/iter; left time: 5502.1134s
Epoch: 27 cost time: 30.812150239944458
Epoch: 27, Steps: 137 | Train Loss: 0.2791495 Vali Loss: 0.2338256 Test Loss: 0.2661553
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2789075
	speed: 0.5264s/iter; left time: 5212.3075s
Epoch: 28 cost time: 28.676613569259644
Epoch: 28, Steps: 137 | Train Loss: 0.2793563 Vali Loss: 0.2339490 Test Loss: 0.2661679
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2827994
	speed: 0.5200s/iter; left time: 5078.1357s
Epoch: 29 cost time: 28.074153184890747
Epoch: 29, Steps: 137 | Train Loss: 0.2792122 Vali Loss: 0.2336942 Test Loss: 0.2661674
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2779379
	speed: 0.5131s/iter; left time: 4939.9891s
Epoch: 30 cost time: 28.949578523635864
Epoch: 30, Steps: 137 | Train Loss: 0.2791888 Vali Loss: 0.2337575 Test Loss: 0.2661422
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2698495
	speed: 0.5228s/iter; left time: 4961.8927s
Epoch: 31 cost time: 29.95597004890442
Epoch: 31, Steps: 137 | Train Loss: 0.2793095 Vali Loss: 0.2334140 Test Loss: 0.2661730
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2926114
	speed: 0.5314s/iter; left time: 4970.7878s
Epoch: 32 cost time: 29.562678337097168
Epoch: 32, Steps: 137 | Train Loss: 0.2792408 Vali Loss: 0.2334010 Test Loss: 0.2661628
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2738093
	speed: 0.5181s/iter; left time: 4775.2700s
Epoch: 33 cost time: 25.233875036239624
Epoch: 33, Steps: 137 | Train Loss: 0.2792852 Vali Loss: 0.2334661 Test Loss: 0.2661309
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2811635
	speed: 0.4349s/iter; left time: 3948.4418s
Epoch: 34 cost time: 24.215022087097168
Epoch: 34, Steps: 137 | Train Loss: 0.2792953 Vali Loss: 0.2338619 Test Loss: 0.2661549
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2946155
	speed: 0.4936s/iter; left time: 4414.0894s
Epoch: 35 cost time: 31.021459102630615
Epoch: 35, Steps: 137 | Train Loss: 0.2791816 Vali Loss: 0.2339787 Test Loss: 0.2661441
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2722565
	speed: 0.5582s/iter; left time: 4915.3360s
Epoch: 36 cost time: 30.983767986297607
Epoch: 36, Steps: 137 | Train Loss: 0.2792359 Vali Loss: 0.2338112 Test Loss: 0.2661446
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2736497
	speed: 0.5382s/iter; left time: 4665.8287s
Epoch: 37 cost time: 29.627315282821655
Epoch: 37, Steps: 137 | Train Loss: 0.2791681 Vali Loss: 0.2335592 Test Loss: 0.2661606
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2790551
	speed: 0.5506s/iter; left time: 4698.1226s
Epoch: 38 cost time: 29.38792061805725
Epoch: 38, Steps: 137 | Train Loss: 0.2792575 Vali Loss: 0.2340115 Test Loss: 0.2661516
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2697211
	speed: 0.5280s/iter; left time: 4432.4572s
Epoch: 39 cost time: 29.580227851867676
Epoch: 39, Steps: 137 | Train Loss: 0.2793214 Vali Loss: 0.2333582 Test Loss: 0.2661546
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2725276
	speed: 0.5492s/iter; left time: 4534.9785s
Epoch: 40 cost time: 31.105454206466675
Epoch: 40, Steps: 137 | Train Loss: 0.2792025 Vali Loss: 0.2333375 Test Loss: 0.2661504
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2826650
	speed: 0.5223s/iter; left time: 4241.7820s
Epoch: 41 cost time: 30.984281301498413
Epoch: 41, Steps: 137 | Train Loss: 0.2792902 Vali Loss: 0.2336631 Test Loss: 0.2661431
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2672651
	speed: 0.5534s/iter; left time: 4418.0331s
Epoch: 42 cost time: 31.115870714187622
Epoch: 42, Steps: 137 | Train Loss: 0.2793205 Vali Loss: 0.2336331 Test Loss: 0.2661514
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2811845
	speed: 0.5674s/iter; left time: 4452.0457s
Epoch: 43 cost time: 31.126885175704956
Epoch: 43, Steps: 137 | Train Loss: 0.2791256 Vali Loss: 0.2337966 Test Loss: 0.2661444
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2861257
	speed: 0.5558s/iter; left time: 4285.2123s
Epoch: 44 cost time: 29.37368893623352
Epoch: 44, Steps: 137 | Train Loss: 0.2792367 Vali Loss: 0.2336915 Test Loss: 0.2661682
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2846655
	speed: 0.5479s/iter; left time: 4149.4661s
Epoch: 45 cost time: 30.27338981628418
Epoch: 45, Steps: 137 | Train Loss: 0.2792190 Vali Loss: 0.2340336 Test Loss: 0.2661452
EarlyStopping counter: 19 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2735201
	speed: 0.5662s/iter; left time: 4210.1121s
Epoch: 46 cost time: 31.03439974784851
Epoch: 46, Steps: 137 | Train Loss: 0.2792821 Vali Loss: 0.2336656 Test Loss: 0.2661547
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_90_j720_H4_FITS_custom_ftM_sl90_ll48_pl720_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
mse:0.2648441791534424, mae:0.3371509611606598, rse:0.5133606791496277, corr:[0.44107956 0.44168326 0.44033858 0.43905592 0.4379728  0.43685463
 0.43707174 0.43615916 0.43497923 0.43438697 0.43361044 0.43288076
 0.43279606 0.43235266 0.43180344 0.43185863 0.43192992 0.4319565
 0.43207482 0.43199638 0.4319577  0.43199363 0.43159267 0.4303342
 0.42826885 0.42716143 0.4260423  0.42496142 0.42446196 0.42457122
 0.42571086 0.42594025 0.42567772 0.42533714 0.4248824  0.42440405
 0.42443365 0.4243891  0.4240252  0.42388076 0.42389804 0.4239043
 0.4239581  0.42403683 0.42416102 0.4242914  0.42428032 0.42398337
 0.42295912 0.4226673  0.42263666 0.42275634 0.4234051  0.42475224
 0.42701885 0.4284712  0.4288945  0.42870638 0.4284922  0.4282032
 0.4280609  0.42794085 0.42781365 0.4280251  0.4283467  0.42851114
 0.4286945  0.42896944 0.42930895 0.42960307 0.4299716  0.43041027
 0.43048227 0.43106836 0.4318265  0.4329994  0.43472093 0.43704283
 0.44019854 0.44263425 0.44344738 0.44295004 0.44241977 0.44194567
 0.4415973  0.44145256 0.44134977 0.4414372  0.44174856 0.44197205
 0.44216618 0.44234836 0.44242737 0.44255188 0.44281566 0.44292217
 0.4425905  0.44259936 0.442623   0.44252184 0.44247904 0.44259506
 0.44298485 0.44294393 0.442677   0.44224274 0.44188368 0.44156286
 0.44134787 0.44128177 0.44124568 0.44134563 0.44162995 0.44177172
 0.44182578 0.44198233 0.44207913 0.4421153  0.44232172 0.44253057
 0.44226795 0.44227335 0.442309   0.44223517 0.4421762  0.44221213
 0.44245407 0.4422418  0.44196746 0.4416521  0.44131693 0.44104648
 0.44094837 0.4410032  0.44104263 0.4411177  0.44143218 0.441709
 0.44182098 0.44203085 0.44224676 0.44235978 0.44248274 0.44250965
 0.4420597  0.44192612 0.44191557 0.44183245 0.44175038 0.44180396
 0.44213545 0.44201055 0.44166914 0.4412561  0.4408892  0.4405895
 0.4404858  0.44062713 0.44084442 0.44102588 0.44138026 0.44181463
 0.44202211 0.44204956 0.4420245  0.44173202 0.44068214 0.43852645
 0.4355811  0.43345082 0.43187174 0.4303511  0.429239   0.42865252
 0.42860922 0.42809847 0.4276859  0.42725194 0.42684287 0.42658356
 0.42648527 0.42637882 0.42622256 0.42594814 0.42590013 0.42597246
 0.4258548  0.42573196 0.42564738 0.42536247 0.42459446 0.4231173
 0.42087924 0.4194969  0.41847965 0.4175142  0.4170775  0.41750532
 0.4186293  0.418883   0.41890362 0.41867542 0.41837084 0.41817844
 0.41816288 0.41811168 0.4180353  0.41791397 0.4179236  0.417953
 0.417867   0.41792932 0.4180535  0.41796783 0.41772223 0.41738477
 0.41637632 0.41590735 0.41593406 0.4162812  0.4170699  0.4186079
 0.42083466 0.42234468 0.42308185 0.42305067 0.42275974 0.42257938
 0.4224337  0.42222503 0.42215705 0.42229274 0.42259338 0.42285246
 0.42296967 0.42319065 0.42357847 0.42386344 0.42414218 0.42452434
 0.42461658 0.42524645 0.4260644  0.42720133 0.4288291  0.4313067
 0.43455184 0.43693352 0.43786964 0.43760008 0.43715385 0.4368444
 0.43656048 0.43629366 0.43621176 0.43629995 0.43651175 0.43671337
 0.4368806  0.43706915 0.4371889  0.4372821  0.43745682 0.43751612
 0.43718985 0.43715873 0.4371733  0.43711683 0.43706465 0.4372442
 0.43773094 0.43772268 0.43752432 0.437215   0.43683746 0.43654776
 0.43638873 0.4362368  0.4361961  0.43625835 0.4364494  0.43666247
 0.43675104 0.4368111  0.43688628 0.43697745 0.43719494 0.43735346
 0.43705383 0.43700063 0.43700108 0.43696827 0.43694317 0.43701088
 0.43730912 0.43706512 0.43672425 0.43649963 0.43616664 0.4358722
 0.4358186  0.43585178 0.4359399  0.4360415  0.43619645 0.4364529
 0.43671012 0.4369762  0.43715793 0.43722996 0.43731308 0.4373
 0.43684104 0.43661815 0.4365187  0.43646777 0.4364463  0.43649417
 0.43685985 0.4367555  0.43644518 0.4361444  0.43576494 0.4354077
 0.43531913 0.43536144 0.4354752  0.435657   0.43596992 0.4364029
 0.43664318 0.4366029  0.43650416 0.43617946 0.43501976 0.43268332
 0.4296702  0.42750442 0.4258149  0.4242835  0.42322657 0.4226515
 0.42270353 0.4222745  0.42174828 0.4212538  0.42084438 0.42053312
 0.42038745 0.42019686 0.419966   0.41974044 0.41974437 0.41980666
 0.41973147 0.4196218  0.41952395 0.4192017  0.41829333 0.4166631
 0.4143965  0.41294673 0.41175997 0.41076526 0.41041473 0.41078597
 0.41189098 0.41224658 0.41223016 0.41193616 0.4115943  0.411339
 0.41134864 0.41130796 0.41111973 0.41097125 0.41098022 0.4110067
 0.41097593 0.41104692 0.41114807 0.41115278 0.41094425 0.41048
 0.40939593 0.40899843 0.40907177 0.40948012 0.41047454 0.41219985
 0.4146101  0.4162959  0.41703132 0.4169785  0.41675425 0.41655234
 0.4164166  0.41624323 0.4161049  0.41621983 0.4165384  0.41674626
 0.41684014 0.41708136 0.41747588 0.4178527  0.4181835  0.41849822
 0.41853377 0.4192523  0.4202151  0.42152035 0.42341217 0.42610866
 0.42947093 0.43201554 0.43302387 0.43275973 0.43245766 0.4322139
 0.4319112  0.43167856 0.43162906 0.4317599  0.43200186 0.43216762
 0.43234587 0.43255523 0.43264553 0.4327176  0.43293792 0.4330364
 0.4327077  0.43266997 0.43268478 0.43261585 0.43262607 0.43284866
 0.43333778 0.43339846 0.43322366 0.4328341  0.4324107  0.43206203
 0.4318571  0.43180677 0.43184412 0.43192032 0.43213022 0.43229607
 0.4323605  0.43247992 0.43257433 0.43265155 0.4328896  0.4331165
 0.43287075 0.4328357  0.4328529  0.43282312 0.43284255 0.43294883
 0.4331814  0.43294734 0.4326599  0.4323828  0.4320587  0.43178716
 0.43167076 0.4316766  0.4317625  0.43186432 0.43210799 0.43237972
 0.43258354 0.43287244 0.43310374 0.43321845 0.43333715 0.43335247
 0.43293905 0.43279117 0.43274996 0.43268278 0.4326892  0.43283966
 0.43319124 0.43308094 0.43277445 0.4324183  0.43207443 0.4317905
 0.4316593  0.43174204 0.43193847 0.4320638  0.4323646  0.43282986
 0.43308052 0.4330716  0.43298453 0.43264145 0.43147436 0.42916682
 0.426111   0.42381757 0.42213142 0.42068607 0.41973594 0.41928583
 0.41927227 0.4187234  0.41825    0.4178212  0.41739413 0.4171099
 0.41698837 0.41681725 0.41666788 0.4164673  0.41646925 0.4165768
 0.41651893 0.4163988  0.41625294 0.41169924 0.4149751  0.413352
 0.41096306 0.40514728 0.4040355  0.40314922 0.40279368 0.40312487
 0.40401897 0.40417877 0.40420452 0.40401682 0.4036733  0.40344727
 0.40343234 0.4075019  0.40317705 0.40304333 0.403037   0.40310997
 0.40304896 0.40308508 0.40326568 0.40329015 0.40304688 0.4026093
 0.4015772  0.40108135 0.40106887 0.40139234 0.4022445  0.4038991
 0.40627077 0.40777877 0.40843594 0.40842375 0.40816987 0.4079754
 0.40780634 0.40749067 0.4073128  0.4073927  0.4076199  0.40778735
 0.40788746 0.4081734  0.4086241  0.4089743  0.40926105 0.4096199
 0.4097441  0.41037223 0.4112476  0.41249645 0.41423294 0.4168217
 0.4201689  0.4225486  0.42340428 0.42309892 0.42269695 0.42246947
 0.42222437 0.4219036  0.42178568 0.42190313 0.42210782 0.42229488
 0.42247045 0.4226625  0.42285463 0.42307112 0.4233121  0.42335504
 0.42302787 0.4229652  0.42294478 0.4229253  0.42297316 0.42319465
 0.4236415  0.42352492 0.4232017  0.42287984 0.4225303  0.42221212
 0.42199475 0.42178386 0.42173162 0.42185932 0.42200336 0.4221293
 0.42226088 0.4223789  0.42245305 0.42253637 0.42271477 0.42283338
 0.42258358 0.42259902 0.4226507  0.422631   0.42256662 0.4225743
 0.42289364 0.42273006 0.42241523 0.42214912 0.42179033 0.42152625
 0.42151272 0.42148623 0.4214832  0.42163467 0.42183575 0.42204633
 0.42231047 0.42261592 0.4228165  0.42292342 0.42302665 0.42296344
 0.4225301  0.422396   0.4223331  0.42229164 0.42228487 0.42232135
 0.42270198 0.4226095  0.42226687 0.4220214  0.4217423  0.42139047
 0.42128634 0.42135525 0.42144504 0.42163113 0.42184398 0.4220843
 0.42231452 0.42232135 0.42221826 0.4219149  0.42080656 0.41838005
 0.41523108 0.4130229  0.41133487 0.4098955  0.4090002  0.4083756
 0.4083673  0.4079759  0.40745777 0.40696612 0.40658897 0.40617412
 0.40593025 0.40568298 0.40532786 0.40518802 0.40525088 0.40519837
 0.40510836 0.40501937 0.4048532  0.40460795 0.40395874 0.4023252
 0.3998976  0.39861494 0.3976244  0.39676508 0.3966401  0.39690134
 0.3979002  0.3982881  0.39806107 0.3975711  0.39731544 0.39679152
 0.39641085 0.39627022 0.39580175 0.3954127  0.39526743 0.39508632
 0.39536062 0.39556766 0.3954506  0.39590153 0.3967596  0.39633262]
