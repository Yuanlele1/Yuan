Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=34, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_90_j336_H6', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_90_j336_H6_FITS_custom_ftM_sl90_ll48_pl336_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17987
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=34, out_features=160, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  223518720.0
params:  5600.0
Trainable parameters:  5600
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.8852629
	speed: 0.1278s/iter; left time: 1776.4172s
Epoch: 1 cost time: 17.306975841522217
Epoch: 1, Steps: 140 | Train Loss: 1.1439717 Vali Loss: 0.6500398 Test Loss: 0.7251486
Validation loss decreased (inf --> 0.650040).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5128692
	speed: 0.3088s/iter; left time: 4249.2324s
Epoch: 2 cost time: 17.4934663772583
Epoch: 2, Steps: 140 | Train Loss: 0.5629801 Vali Loss: 0.4372366 Test Loss: 0.4923299
Validation loss decreased (0.650040 --> 0.437237).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3630758
	speed: 0.3179s/iter; left time: 4330.7146s
Epoch: 3 cost time: 17.904248237609863
Epoch: 3, Steps: 140 | Train Loss: 0.4024707 Vali Loss: 0.3471873 Test Loss: 0.3922812
Validation loss decreased (0.437237 --> 0.347187).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3162742
	speed: 0.3169s/iter; left time: 4272.1741s
Epoch: 4 cost time: 17.56756329536438
Epoch: 4, Steps: 140 | Train Loss: 0.3246873 Vali Loss: 0.2973588 Test Loss: 0.3365571
Validation loss decreased (0.347187 --> 0.297359).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2798572
	speed: 0.3130s/iter; left time: 4175.9862s
Epoch: 5 cost time: 17.902982234954834
Epoch: 5, Steps: 140 | Train Loss: 0.2799870 Vali Loss: 0.2678609 Test Loss: 0.3029366
Validation loss decreased (0.297359 --> 0.267861).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2459300
	speed: 0.3178s/iter; left time: 4195.3739s
Epoch: 6 cost time: 17.817827701568604
Epoch: 6, Steps: 140 | Train Loss: 0.2526123 Vali Loss: 0.2492360 Test Loss: 0.2816593
Validation loss decreased (0.267861 --> 0.249236).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2325108
	speed: 0.3132s/iter; left time: 4090.3744s
Epoch: 7 cost time: 17.240195512771606
Epoch: 7, Steps: 140 | Train Loss: 0.2349750 Vali Loss: 0.2371261 Test Loss: 0.2676472
Validation loss decreased (0.249236 --> 0.237126).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2333750
	speed: 0.3156s/iter; left time: 4077.4214s
Epoch: 8 cost time: 18.016469717025757
Epoch: 8, Steps: 140 | Train Loss: 0.2233326 Vali Loss: 0.2288989 Test Loss: 0.2582025
Validation loss decreased (0.237126 --> 0.228899).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2040876
	speed: 0.3153s/iter; left time: 4030.1350s
Epoch: 9 cost time: 17.748074293136597
Epoch: 9, Steps: 140 | Train Loss: 0.2153143 Vali Loss: 0.2230219 Test Loss: 0.2514615
Validation loss decreased (0.228899 --> 0.223022).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2040731
	speed: 0.3143s/iter; left time: 3973.0425s
Epoch: 10 cost time: 18.04264545440674
Epoch: 10, Steps: 140 | Train Loss: 0.2095481 Vali Loss: 0.2183097 Test Loss: 0.2466402
Validation loss decreased (0.223022 --> 0.218310).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2103301
	speed: 0.3169s/iter; left time: 3961.5995s
Epoch: 11 cost time: 18.20621633529663
Epoch: 11, Steps: 140 | Train Loss: 0.2052984 Vali Loss: 0.2151946 Test Loss: 0.2428862
Validation loss decreased (0.218310 --> 0.215195).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2081187
	speed: 0.3137s/iter; left time: 3878.1945s
Epoch: 12 cost time: 17.943885803222656
Epoch: 12, Steps: 140 | Train Loss: 0.2020980 Vali Loss: 0.2126962 Test Loss: 0.2401203
Validation loss decreased (0.215195 --> 0.212696).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2018133
	speed: 0.3136s/iter; left time: 3832.5642s
Epoch: 13 cost time: 17.928553104400635
Epoch: 13, Steps: 140 | Train Loss: 0.1994609 Vali Loss: 0.2103793 Test Loss: 0.2378364
Validation loss decreased (0.212696 --> 0.210379).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1967188
	speed: 0.3151s/iter; left time: 3806.4183s
Epoch: 14 cost time: 17.883177757263184
Epoch: 14, Steps: 140 | Train Loss: 0.1975155 Vali Loss: 0.2092621 Test Loss: 0.2360167
Validation loss decreased (0.210379 --> 0.209262).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1970140
	speed: 0.3159s/iter; left time: 3772.4028s
Epoch: 15 cost time: 17.860950231552124
Epoch: 15, Steps: 140 | Train Loss: 0.1957993 Vali Loss: 0.2074764 Test Loss: 0.2345112
Validation loss decreased (0.209262 --> 0.207476).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1945649
	speed: 0.3164s/iter; left time: 3733.7536s
Epoch: 16 cost time: 17.762766122817993
Epoch: 16, Steps: 140 | Train Loss: 0.1944555 Vali Loss: 0.2066657 Test Loss: 0.2332207
Validation loss decreased (0.207476 --> 0.206666).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1895449
	speed: 0.3136s/iter; left time: 3656.6639s
Epoch: 17 cost time: 18.053117036819458
Epoch: 17, Steps: 140 | Train Loss: 0.1932601 Vali Loss: 0.2054069 Test Loss: 0.2321307
Validation loss decreased (0.206666 --> 0.205407).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1822736
	speed: 0.3140s/iter; left time: 3617.8252s
Epoch: 18 cost time: 17.274105548858643
Epoch: 18, Steps: 140 | Train Loss: 0.1922968 Vali Loss: 0.2046172 Test Loss: 0.2312159
Validation loss decreased (0.205407 --> 0.204617).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1953437
	speed: 0.3183s/iter; left time: 3622.9867s
Epoch: 19 cost time: 17.877070665359497
Epoch: 19, Steps: 140 | Train Loss: 0.1914435 Vali Loss: 0.2041239 Test Loss: 0.2304265
Validation loss decreased (0.204617 --> 0.204124).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1855884
	speed: 0.3171s/iter; left time: 3564.3129s
Epoch: 20 cost time: 17.85614323616028
Epoch: 20, Steps: 140 | Train Loss: 0.1906694 Vali Loss: 0.2033516 Test Loss: 0.2297298
Validation loss decreased (0.204124 --> 0.203352).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1833706
	speed: 0.3138s/iter; left time: 3483.2611s
Epoch: 21 cost time: 17.482961654663086
Epoch: 21, Steps: 140 | Train Loss: 0.1899523 Vali Loss: 0.2028018 Test Loss: 0.2291387
Validation loss decreased (0.203352 --> 0.202802).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1835218
	speed: 0.3142s/iter; left time: 3443.5940s
Epoch: 22 cost time: 17.36345338821411
Epoch: 22, Steps: 140 | Train Loss: 0.1894643 Vali Loss: 0.2023522 Test Loss: 0.2285815
Validation loss decreased (0.202802 --> 0.202352).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1814221
	speed: 0.3162s/iter; left time: 3422.1153s
Epoch: 23 cost time: 17.76641321182251
Epoch: 23, Steps: 140 | Train Loss: 0.1889397 Vali Loss: 0.2019092 Test Loss: 0.2281182
Validation loss decreased (0.202352 --> 0.201909).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1871091
	speed: 0.3197s/iter; left time: 3414.9760s
Epoch: 24 cost time: 18.203402519226074
Epoch: 24, Steps: 140 | Train Loss: 0.1884852 Vali Loss: 0.2011228 Test Loss: 0.2276858
Validation loss decreased (0.201909 --> 0.201123).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1839194
	speed: 0.3129s/iter; left time: 3298.1241s
Epoch: 25 cost time: 17.321492671966553
Epoch: 25, Steps: 140 | Train Loss: 0.1880383 Vali Loss: 0.2009876 Test Loss: 0.2273017
Validation loss decreased (0.201123 --> 0.200988).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1876829
	speed: 0.3115s/iter; left time: 3240.0508s
Epoch: 26 cost time: 17.827269554138184
Epoch: 26, Steps: 140 | Train Loss: 0.1876872 Vali Loss: 0.2007703 Test Loss: 0.2269668
Validation loss decreased (0.200988 --> 0.200770).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1900854
	speed: 0.3176s/iter; left time: 3258.5955s
Epoch: 27 cost time: 18.16655468940735
Epoch: 27, Steps: 140 | Train Loss: 0.1873492 Vali Loss: 0.2005786 Test Loss: 0.2266825
Validation loss decreased (0.200770 --> 0.200579).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1754712
	speed: 0.3191s/iter; left time: 3229.6511s
Epoch: 28 cost time: 18.07567548751831
Epoch: 28, Steps: 140 | Train Loss: 0.1870458 Vali Loss: 0.2004604 Test Loss: 0.2264044
Validation loss decreased (0.200579 --> 0.200460).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1841553
	speed: 0.3137s/iter; left time: 3131.2727s
Epoch: 29 cost time: 17.978347301483154
Epoch: 29, Steps: 140 | Train Loss: 0.1868362 Vali Loss: 0.2002078 Test Loss: 0.2261229
Validation loss decreased (0.200460 --> 0.200208).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1875532
	speed: 0.3144s/iter; left time: 3094.3994s
Epoch: 30 cost time: 18.201777458190918
Epoch: 30, Steps: 140 | Train Loss: 0.1865109 Vali Loss: 0.1997770 Test Loss: 0.2258929
Validation loss decreased (0.200208 --> 0.199777).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1882426
	speed: 0.3140s/iter; left time: 3045.9834s
Epoch: 31 cost time: 17.812349796295166
Epoch: 31, Steps: 140 | Train Loss: 0.1863026 Vali Loss: 0.1996651 Test Loss: 0.2256918
Validation loss decreased (0.199777 --> 0.199665).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1946251
	speed: 0.3160s/iter; left time: 3021.2466s
Epoch: 32 cost time: 17.846393823623657
Epoch: 32, Steps: 140 | Train Loss: 0.1861577 Vali Loss: 0.1993796 Test Loss: 0.2255014
Validation loss decreased (0.199665 --> 0.199380).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1910953
	speed: 0.3131s/iter; left time: 2949.3732s
Epoch: 33 cost time: 17.907146453857422
Epoch: 33, Steps: 140 | Train Loss: 0.1858987 Vali Loss: 0.1990778 Test Loss: 0.2253123
Validation loss decreased (0.199380 --> 0.199078).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1814640
	speed: 0.3183s/iter; left time: 2954.0493s
Epoch: 34 cost time: 18.06234908103943
Epoch: 34, Steps: 140 | Train Loss: 0.1857459 Vali Loss: 0.1994242 Test Loss: 0.2251418
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1782574
	speed: 0.3128s/iter; left time: 2858.8990s
Epoch: 35 cost time: 17.66486382484436
Epoch: 35, Steps: 140 | Train Loss: 0.1855234 Vali Loss: 0.1988396 Test Loss: 0.2249889
Validation loss decreased (0.199078 --> 0.198840).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1793319
	speed: 0.3191s/iter; left time: 2871.9477s
Epoch: 36 cost time: 17.55983853340149
Epoch: 36, Steps: 140 | Train Loss: 0.1853765 Vali Loss: 0.1992778 Test Loss: 0.2248460
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1770459
	speed: 0.3183s/iter; left time: 2820.2627s
Epoch: 37 cost time: 17.881516933441162
Epoch: 37, Steps: 140 | Train Loss: 0.1852452 Vali Loss: 0.1988459 Test Loss: 0.2247128
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1817413
	speed: 0.3158s/iter; left time: 2754.1650s
Epoch: 38 cost time: 17.664711475372314
Epoch: 38, Steps: 140 | Train Loss: 0.1851098 Vali Loss: 0.1985957 Test Loss: 0.2245820
Validation loss decreased (0.198840 --> 0.198596).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1805015
	speed: 0.3167s/iter; left time: 2717.2404s
Epoch: 39 cost time: 17.742066144943237
Epoch: 39, Steps: 140 | Train Loss: 0.1849884 Vali Loss: 0.1986603 Test Loss: 0.2244719
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1792043
	speed: 0.3140s/iter; left time: 2650.5422s
Epoch: 40 cost time: 17.820159673690796
Epoch: 40, Steps: 140 | Train Loss: 0.1848251 Vali Loss: 0.1983379 Test Loss: 0.2243504
Validation loss decreased (0.198596 --> 0.198338).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1818415
	speed: 0.3222s/iter; left time: 2674.5900s
Epoch: 41 cost time: 18.0449435710907
Epoch: 41, Steps: 140 | Train Loss: 0.1847999 Vali Loss: 0.1981885 Test Loss: 0.2242445
Validation loss decreased (0.198338 --> 0.198188).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1831556
	speed: 0.3129s/iter; left time: 2553.3698s
Epoch: 42 cost time: 17.653456687927246
Epoch: 42, Steps: 140 | Train Loss: 0.1846222 Vali Loss: 0.1984565 Test Loss: 0.2241592
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1771046
	speed: 0.3137s/iter; left time: 2516.2751s
Epoch: 43 cost time: 17.773669719696045
Epoch: 43, Steps: 140 | Train Loss: 0.1845920 Vali Loss: 0.1981899 Test Loss: 0.2240690
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1819960
	speed: 0.3161s/iter; left time: 2491.5400s
Epoch: 44 cost time: 17.88481116294861
Epoch: 44, Steps: 140 | Train Loss: 0.1844862 Vali Loss: 0.1982740 Test Loss: 0.2239740
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1890410
	speed: 0.3173s/iter; left time: 2456.4381s
Epoch: 45 cost time: 17.954344511032104
Epoch: 45, Steps: 140 | Train Loss: 0.1843091 Vali Loss: 0.1981088 Test Loss: 0.2238913
Validation loss decreased (0.198188 --> 0.198109).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1867518
	speed: 0.3139s/iter; left time: 2385.8236s
Epoch: 46 cost time: 18.292271375656128
Epoch: 46, Steps: 140 | Train Loss: 0.1842565 Vali Loss: 0.1978187 Test Loss: 0.2238252
Validation loss decreased (0.198109 --> 0.197819).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1898120
	speed: 0.3161s/iter; left time: 2358.1080s
Epoch: 47 cost time: 17.913464307785034
Epoch: 47, Steps: 140 | Train Loss: 0.1841867 Vali Loss: 0.1976029 Test Loss: 0.2237494
Validation loss decreased (0.197819 --> 0.197603).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1859328
	speed: 0.3162s/iter; left time: 2315.2005s
Epoch: 48 cost time: 18.007285118103027
Epoch: 48, Steps: 140 | Train Loss: 0.1841689 Vali Loss: 0.1975878 Test Loss: 0.2236871
Validation loss decreased (0.197603 --> 0.197588).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1664321
	speed: 0.3225s/iter; left time: 2315.9964s
Epoch: 49 cost time: 18.39813232421875
Epoch: 49, Steps: 140 | Train Loss: 0.1840539 Vali Loss: 0.1974922 Test Loss: 0.2236177
Validation loss decreased (0.197588 --> 0.197492).  Saving model ...
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1770277
	speed: 0.3182s/iter; left time: 2240.4101s
Epoch: 50 cost time: 17.785366535186768
Epoch: 50, Steps: 140 | Train Loss: 0.1839788 Vali Loss: 0.1973097 Test Loss: 0.2235634
Validation loss decreased (0.197492 --> 0.197310).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1814848
	speed: 0.3223s/iter; left time: 2224.1410s
Epoch: 51 cost time: 17.888160705566406
Epoch: 51, Steps: 140 | Train Loss: 0.1839485 Vali Loss: 0.1975142 Test Loss: 0.2235114
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1895315
	speed: 0.3141s/iter; left time: 2123.5366s
Epoch: 52 cost time: 17.493128299713135
Epoch: 52, Steps: 140 | Train Loss: 0.1838648 Vali Loss: 0.1976011 Test Loss: 0.2234543
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1898147
	speed: 0.3155s/iter; left time: 2088.9058s
Epoch: 53 cost time: 17.555084466934204
Epoch: 53, Steps: 140 | Train Loss: 0.1838182 Vali Loss: 0.1975978 Test Loss: 0.2234063
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1800189
	speed: 0.3135s/iter; left time: 2031.7677s
Epoch: 54 cost time: 17.5263729095459
Epoch: 54, Steps: 140 | Train Loss: 0.1837328 Vali Loss: 0.1978362 Test Loss: 0.2233568
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1856560
	speed: 0.3139s/iter; left time: 1990.6186s
Epoch: 55 cost time: 17.679854154586792
Epoch: 55, Steps: 140 | Train Loss: 0.1836805 Vali Loss: 0.1971442 Test Loss: 0.2233070
Validation loss decreased (0.197310 --> 0.197144).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1794549
	speed: 0.3197s/iter; left time: 1982.6226s
Epoch: 56 cost time: 17.983094215393066
Epoch: 56, Steps: 140 | Train Loss: 0.1836749 Vali Loss: 0.1971720 Test Loss: 0.2232685
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.1840585
	speed: 0.3154s/iter; left time: 1911.8674s
Epoch: 57 cost time: 17.89128279685974
Epoch: 57, Steps: 140 | Train Loss: 0.1835489 Vali Loss: 0.1972141 Test Loss: 0.2232209
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1855510
	speed: 0.3126s/iter; left time: 1851.0663s
Epoch: 58 cost time: 17.907546520233154
Epoch: 58, Steps: 140 | Train Loss: 0.1836076 Vali Loss: 0.1972909 Test Loss: 0.2231850
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1892887
	speed: 0.3140s/iter; left time: 1815.1218s
Epoch: 59 cost time: 17.86407971382141
Epoch: 59, Steps: 140 | Train Loss: 0.1836021 Vali Loss: 0.1972395 Test Loss: 0.2231547
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1842833
	speed: 0.3147s/iter; left time: 1775.1066s
Epoch: 60 cost time: 17.898265838623047
Epoch: 60, Steps: 140 | Train Loss: 0.1834812 Vali Loss: 0.1972773 Test Loss: 0.2231206
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1842695
	speed: 0.3181s/iter; left time: 1749.9554s
Epoch: 61 cost time: 18.2341787815094
Epoch: 61, Steps: 140 | Train Loss: 0.1835259 Vali Loss: 0.1970844 Test Loss: 0.2230907
Validation loss decreased (0.197144 --> 0.197084).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1791621
	speed: 0.3170s/iter; left time: 1699.4680s
Epoch: 62 cost time: 18.146132469177246
Epoch: 62, Steps: 140 | Train Loss: 0.1834547 Vali Loss: 0.1968274 Test Loss: 0.2230595
Validation loss decreased (0.197084 --> 0.196827).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1835441
	speed: 0.3142s/iter; left time: 1640.3826s
Epoch: 63 cost time: 18.02101421356201
Epoch: 63, Steps: 140 | Train Loss: 0.1834265 Vali Loss: 0.1972433 Test Loss: 0.2230314
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1810381
	speed: 0.3171s/iter; left time: 1611.1900s
Epoch: 64 cost time: 18.436673402786255
Epoch: 64, Steps: 140 | Train Loss: 0.1833837 Vali Loss: 0.1971512 Test Loss: 0.2230050
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.1804632
	speed: 0.3131s/iter; left time: 1546.9303s
Epoch: 65 cost time: 17.53615689277649
Epoch: 65, Steps: 140 | Train Loss: 0.1833027 Vali Loss: 0.1969727 Test Loss: 0.2229808
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.2030765
	speed: 0.3134s/iter; left time: 1504.4384s
Epoch: 66 cost time: 17.73257613182068
Epoch: 66, Steps: 140 | Train Loss: 0.1833181 Vali Loss: 0.1969748 Test Loss: 0.2229573
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.1974930
	speed: 0.3095s/iter; left time: 1442.7317s
Epoch: 67 cost time: 17.779881477355957
Epoch: 67, Steps: 140 | Train Loss: 0.1832951 Vali Loss: 0.1972047 Test Loss: 0.2229364
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.1924142
	speed: 0.3150s/iter; left time: 1424.2227s
Epoch: 68 cost time: 17.74363422393799
Epoch: 68, Steps: 140 | Train Loss: 0.1832745 Vali Loss: 0.1968566 Test Loss: 0.2229122
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.1834317
	speed: 0.3179s/iter; left time: 1392.6494s
Epoch: 69 cost time: 17.84326171875
Epoch: 69, Steps: 140 | Train Loss: 0.1832671 Vali Loss: 0.1970153 Test Loss: 0.2228952
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.1838821
	speed: 0.3154s/iter; left time: 1337.7657s
Epoch: 70 cost time: 17.50565505027771
Epoch: 70, Steps: 140 | Train Loss: 0.1832425 Vali Loss: 0.1970715 Test Loss: 0.2228786
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.1726869
	speed: 0.3122s/iter; left time: 1280.2276s
Epoch: 71 cost time: 17.43677043914795
Epoch: 71, Steps: 140 | Train Loss: 0.1832671 Vali Loss: 0.1971297 Test Loss: 0.2228604
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.1778761
	speed: 0.3122s/iter; left time: 1236.5339s
Epoch: 72 cost time: 17.648436546325684
Epoch: 72, Steps: 140 | Train Loss: 0.1831985 Vali Loss: 0.1970137 Test Loss: 0.2228442
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.1829784
	speed: 0.3172s/iter; left time: 1212.1714s
Epoch: 73 cost time: 17.62282943725586
Epoch: 73, Steps: 140 | Train Loss: 0.1831954 Vali Loss: 0.1971333 Test Loss: 0.2228302
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.1801603
	speed: 0.3131s/iter; left time: 1152.6771s
Epoch: 74 cost time: 17.85198950767517
Epoch: 74, Steps: 140 | Train Loss: 0.1831709 Vali Loss: 0.1970821 Test Loss: 0.2228156
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.1819302
	speed: 0.3212s/iter; left time: 1137.3039s
Epoch: 75 cost time: 18.08992862701416
Epoch: 75, Steps: 140 | Train Loss: 0.1831855 Vali Loss: 0.1971426 Test Loss: 0.2228010
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.1894329
	speed: 0.3165s/iter; left time: 1076.3165s
Epoch: 76 cost time: 17.846630334854126
Epoch: 76, Steps: 140 | Train Loss: 0.1831063 Vali Loss: 0.1968792 Test Loss: 0.2227904
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.1875219
	speed: 0.3086s/iter; left time: 1006.3848s
Epoch: 77 cost time: 17.433152437210083
Epoch: 77, Steps: 140 | Train Loss: 0.1831019 Vali Loss: 0.1969574 Test Loss: 0.2227760
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.1886537
	speed: 0.3150s/iter; left time: 983.0866s
Epoch: 78 cost time: 17.860761880874634
Epoch: 78, Steps: 140 | Train Loss: 0.1831029 Vali Loss: 0.1970804 Test Loss: 0.2227668
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.1853800
	speed: 0.3186s/iter; left time: 949.7333s
Epoch: 79 cost time: 17.667590618133545
Epoch: 79, Steps: 140 | Train Loss: 0.1830214 Vali Loss: 0.1969958 Test Loss: 0.2227562
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.1825854
	speed: 0.3136s/iter; left time: 890.9306s
Epoch: 80 cost time: 17.987318515777588
Epoch: 80, Steps: 140 | Train Loss: 0.1830851 Vali Loss: 0.1968359 Test Loss: 0.2227439
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.1810260
	speed: 0.3144s/iter; left time: 849.2583s
Epoch: 81 cost time: 18.06362509727478
Epoch: 81, Steps: 140 | Train Loss: 0.1830530 Vali Loss: 0.1968742 Test Loss: 0.2227358
EarlyStopping counter: 19 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.1812658
	speed: 0.3172s/iter; left time: 812.2572s
Epoch: 82 cost time: 18.61993908882141
Epoch: 82, Steps: 140 | Train Loss: 0.1830688 Vali Loss: 0.1968834 Test Loss: 0.2227262
EarlyStopping counter: 20 out of 20
Early stopping
train 17987
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=34, out_features=160, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  223518720.0
params:  5600.0
Trainable parameters:  5600
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2338004
	speed: 0.1335s/iter; left time: 1855.7998s
Epoch: 1 cost time: 18.25129723548889
Epoch: 1, Steps: 140 | Train Loss: 0.2359178 Vali Loss: 0.1990751 Test Loss: 0.2251671
Validation loss decreased (inf --> 0.199075).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2267988
	speed: 0.3222s/iter; left time: 4433.9390s
Epoch: 2 cost time: 18.23503303527832
Epoch: 2, Steps: 140 | Train Loss: 0.2297650 Vali Loss: 0.1966751 Test Loss: 0.2225161
Validation loss decreased (0.199075 --> 0.196675).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2247691
	speed: 0.3155s/iter; left time: 4297.9170s
Epoch: 3 cost time: 17.58916926383972
Epoch: 3, Steps: 140 | Train Loss: 0.2281184 Vali Loss: 0.1960512 Test Loss: 0.2217171
Validation loss decreased (0.196675 --> 0.196051).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2308010
	speed: 0.3173s/iter; left time: 4277.8388s
Epoch: 4 cost time: 17.81573510169983
Epoch: 4, Steps: 140 | Train Loss: 0.2276362 Vali Loss: 0.1960310 Test Loss: 0.2214759
Validation loss decreased (0.196051 --> 0.196031).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2258624
	speed: 0.3161s/iter; left time: 4217.4242s
Epoch: 5 cost time: 17.78119707107544
Epoch: 5, Steps: 140 | Train Loss: 0.2274617 Vali Loss: 0.1955851 Test Loss: 0.2213909
Validation loss decreased (0.196031 --> 0.195585).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2350009
	speed: 0.3132s/iter; left time: 4134.3400s
Epoch: 6 cost time: 17.586591482162476
Epoch: 6, Steps: 140 | Train Loss: 0.2273836 Vali Loss: 0.1958740 Test Loss: 0.2213168
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2245007
	speed: 0.3141s/iter; left time: 4101.9194s
Epoch: 7 cost time: 17.658685445785522
Epoch: 7, Steps: 140 | Train Loss: 0.2273425 Vali Loss: 0.1953629 Test Loss: 0.2213045
Validation loss decreased (0.195585 --> 0.195363).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2247298
	speed: 0.3163s/iter; left time: 4087.5356s
Epoch: 8 cost time: 17.703494787216187
Epoch: 8, Steps: 140 | Train Loss: 0.2273235 Vali Loss: 0.1956399 Test Loss: 0.2212904
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2216944
	speed: 0.3146s/iter; left time: 4020.9802s
Epoch: 9 cost time: 17.82457947731018
Epoch: 9, Steps: 140 | Train Loss: 0.2272913 Vali Loss: 0.1949943 Test Loss: 0.2213008
Validation loss decreased (0.195363 --> 0.194994).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2424958
	speed: 0.3131s/iter; left time: 3958.2559s
Epoch: 10 cost time: 18.090826511383057
Epoch: 10, Steps: 140 | Train Loss: 0.2272631 Vali Loss: 0.1953062 Test Loss: 0.2212692
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2268949
	speed: 0.3130s/iter; left time: 3912.7932s
Epoch: 11 cost time: 17.91793155670166
Epoch: 11, Steps: 140 | Train Loss: 0.2272859 Vali Loss: 0.1956037 Test Loss: 0.2212530
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2238770
	speed: 0.3164s/iter; left time: 3911.4225s
Epoch: 12 cost time: 18.33109736442566
Epoch: 12, Steps: 140 | Train Loss: 0.2273337 Vali Loss: 0.1955974 Test Loss: 0.2212423
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2209613
	speed: 0.3251s/iter; left time: 3973.4939s
Epoch: 13 cost time: 18.39369010925293
Epoch: 13, Steps: 140 | Train Loss: 0.2272025 Vali Loss: 0.1956168 Test Loss: 0.2212292
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2385930
	speed: 0.3217s/iter; left time: 3886.8007s
Epoch: 14 cost time: 18.45050311088562
Epoch: 14, Steps: 140 | Train Loss: 0.2272573 Vali Loss: 0.1953181 Test Loss: 0.2212655
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2183631
	speed: 0.3194s/iter; left time: 3813.4686s
Epoch: 15 cost time: 17.99666690826416
Epoch: 15, Steps: 140 | Train Loss: 0.2272275 Vali Loss: 0.1955883 Test Loss: 0.2212422
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2289217
	speed: 0.3212s/iter; left time: 3790.1334s
Epoch: 16 cost time: 18.29353666305542
Epoch: 16, Steps: 140 | Train Loss: 0.2273028 Vali Loss: 0.1954469 Test Loss: 0.2212387
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2298744
	speed: 0.3204s/iter; left time: 3735.9598s
Epoch: 17 cost time: 18.215535163879395
Epoch: 17, Steps: 140 | Train Loss: 0.2272467 Vali Loss: 0.1953457 Test Loss: 0.2212369
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2322531
	speed: 0.3205s/iter; left time: 3692.4569s
Epoch: 18 cost time: 18.15322494506836
Epoch: 18, Steps: 140 | Train Loss: 0.2271528 Vali Loss: 0.1956004 Test Loss: 0.2212222
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2333387
	speed: 0.3221s/iter; left time: 3666.2181s
Epoch: 19 cost time: 18.137654542922974
Epoch: 19, Steps: 140 | Train Loss: 0.2271991 Vali Loss: 0.1954103 Test Loss: 0.2212373
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2345723
	speed: 0.3209s/iter; left time: 3607.2605s
Epoch: 20 cost time: 17.990488290786743
Epoch: 20, Steps: 140 | Train Loss: 0.2271918 Vali Loss: 0.1957033 Test Loss: 0.2212327
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2227809
	speed: 0.3181s/iter; left time: 3531.1552s
Epoch: 21 cost time: 17.772576332092285
Epoch: 21, Steps: 140 | Train Loss: 0.2271921 Vali Loss: 0.1955739 Test Loss: 0.2212282
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2431578
	speed: 0.3200s/iter; left time: 3507.5591s
Epoch: 22 cost time: 18.156924724578857
Epoch: 22, Steps: 140 | Train Loss: 0.2272278 Vali Loss: 0.1956680 Test Loss: 0.2212381
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2287147
	speed: 0.3232s/iter; left time: 3497.8606s
Epoch: 23 cost time: 18.02061915397644
Epoch: 23, Steps: 140 | Train Loss: 0.2271689 Vali Loss: 0.1954294 Test Loss: 0.2212142
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2256555
	speed: 0.3221s/iter; left time: 3439.9037s
Epoch: 24 cost time: 17.77314257621765
Epoch: 24, Steps: 140 | Train Loss: 0.2271454 Vali Loss: 0.1955017 Test Loss: 0.2212139
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2284216
	speed: 0.3082s/iter; left time: 3248.9674s
Epoch: 25 cost time: 16.667967081069946
Epoch: 25, Steps: 140 | Train Loss: 0.2272422 Vali Loss: 0.1957649 Test Loss: 0.2212436
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2228131
	speed: 0.2788s/iter; left time: 2899.3363s
Epoch: 26 cost time: 15.760712146759033
Epoch: 26, Steps: 140 | Train Loss: 0.2271757 Vali Loss: 0.1956372 Test Loss: 0.2212249
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2302512
	speed: 0.2915s/iter; left time: 2990.8127s
Epoch: 27 cost time: 17.590679168701172
Epoch: 27, Steps: 140 | Train Loss: 0.2272282 Vali Loss: 0.1955367 Test Loss: 0.2212137
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2243173
	speed: 0.3050s/iter; left time: 3087.3980s
Epoch: 28 cost time: 17.264307498931885
Epoch: 28, Steps: 140 | Train Loss: 0.2271411 Vali Loss: 0.1953755 Test Loss: 0.2212157
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2197067
	speed: 0.3143s/iter; left time: 3136.6018s
Epoch: 29 cost time: 17.24688982963562
Epoch: 29, Steps: 140 | Train Loss: 0.2270952 Vali Loss: 0.1953518 Test Loss: 0.2212277
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_90_j336_H6_FITS_custom_ftM_sl90_ll48_pl336_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4925
mse:0.22827662527561188, mae:0.3112330138683319, rse:0.47552353143692017, corr:[0.45239303 0.4503083  0.44770214 0.4457871  0.4450131  0.44418764
 0.44510543 0.44551334 0.44479874 0.44451517 0.44446218 0.44411156
 0.44393963 0.4438861  0.44354784 0.4432508  0.44383422 0.44419447
 0.44417045 0.44417202 0.4437674  0.44324932 0.44247225 0.44041434
 0.43712294 0.43489647 0.43320903 0.43235022 0.43252215 0.43323603
 0.43512934 0.43609306 0.43619287 0.43637282 0.436234   0.43575427
 0.43549326 0.4352406  0.434961   0.43468165 0.4349603  0.4352397
 0.43542603 0.43560916 0.43544877 0.43514702 0.43466178 0.43363062
 0.43177933 0.4307298  0.4297133  0.42978793 0.43155655 0.4338236
 0.43718395 0.43941224 0.43995592 0.44027576 0.44031444 0.43989643
 0.4394365  0.43888032 0.43879017 0.43908527 0.43959698 0.43981132
 0.4399885  0.44026065 0.4402245  0.44018382 0.44027364 0.43979824
 0.4387549  0.43925998 0.4397335  0.44038093 0.4427753  0.44624335
 0.45074114 0.4542561  0.45515418 0.45469505 0.4541607  0.4536695
 0.45304883 0.45244825 0.45267105 0.45292735 0.45332628 0.45376208
 0.45402774 0.45422092 0.45413467 0.45410162 0.45431647 0.454123
 0.45320392 0.45274836 0.4522813  0.45222983 0.45269462 0.45333132
 0.45455715 0.45503208 0.454952   0.45485273 0.45428556 0.45350814
 0.45326725 0.45294628 0.4528551  0.4531195  0.45361185 0.45397344
 0.45424142 0.45442098 0.45416152 0.45397016 0.45408648 0.453849
 0.45318142 0.45324644 0.45260853 0.4521805  0.45279175 0.4531407
 0.4538997  0.4543661  0.45418364 0.45379138 0.4534164  0.4529485
 0.45249793 0.45222583 0.45256767 0.45292315 0.45353207 0.454162
 0.4543121  0.45432174 0.45433524 0.45429862 0.45410717 0.45370364
 0.4528276  0.45249045 0.4518983  0.45158213 0.45199713 0.45245898
 0.45359373 0.45417657 0.4537675  0.45317337 0.45253605 0.45191795
 0.4517566  0.45155653 0.45182145 0.45247874 0.45319012 0.4536818
 0.4539332  0.4539095  0.45339933 0.45305187 0.45226166 0.4491805
 0.44481504 0.44186857 0.43936107 0.43772662 0.43757248 0.43740422
 0.43827164 0.43906394 0.4389443  0.4384003  0.4380281  0.43742752
 0.43694168 0.43678698 0.4368297  0.43670782 0.43688083 0.43704134
 0.43681678 0.43673003 0.4362958  0.43561813 0.43468565 0.43254533
 0.4292058  0.42713428 0.42538705 0.4241942  0.42452425 0.4260617
 0.42834383 0.42942756 0.4296374  0.42956305 0.4292984  0.42869446
 0.42832038 0.4280479  0.4280633  0.42827666 0.4285949  0.4287242
 0.42850444 0.4284102  0.42821985 0.42811027 0.42781815 0.42677408
 0.4249738  0.42435873 0.42366546 0.4237735  0.42530897 0.4277988
 0.43143427 0.4338168  0.43418425 0.4338577  0.43370807 0.4332217
 0.4329371  0.43280464 0.43279704 0.43303415 0.43355864 0.4338266
 0.43357256 0.43349066 0.43343708 0.43351236 0.4338276  0.43385345
 0.4330981  0.43338552 0.43384832 0.43501684 0.43772838 0.44123435
 0.445383   0.44864094 0.44942915 0.44864783 0.44798115 0.4473569
 0.44689986 0.44662535 0.44691184 0.44725096 0.44780126 0.44840568
 0.44857833 0.4487046  0.44856378 0.44854933 0.448692   0.44853508
 0.44803786 0.4479691  0.44728377 0.44713485 0.44777992 0.4484476
 0.44949317 0.45005035 0.44973433 0.4488387  0.4482387  0.44755408
 0.44711664 0.4469003  0.44715372 0.44764388 0.44825023 0.44873258
 0.4486066  0.44865644 0.44849738 0.44833887 0.4486342  0.4486137
 0.4480606  0.44828838 0.44778895 0.447315   0.44779417 0.44844466
 0.44922167 0.44949633 0.4491078  0.44814232 0.4476062  0.4469879
 0.44664523 0.44652328 0.44673502 0.447123   0.4477484  0.44839194
 0.44815192 0.4480807  0.4479233  0.4478832  0.44825247 0.4481494
 0.4474696  0.44744858 0.44687003 0.4469493  0.44758394 0.44803727
 0.4488339  0.44940162 0.44911155 0.44784752 0.44768158 0.44677633
 0.44619548 0.44631553 0.44653067 0.44623858 0.4466903  0.44753566
 0.44578537 0.4468801  0.4469185  0.44488612 0.4474778  0.43890095]
