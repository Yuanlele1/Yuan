Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=34, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_90_j336_H6', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_90_j336_H6_FITS_custom_ftM_sl90_ll48_pl336_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17987
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=34, out_features=160, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  223518720.0
params:  5600.0
Trainable parameters:  5600
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.7105962
	speed: 0.1317s/iter; left time: 1830.7230s
Epoch: 1 cost time: 17.97997546195984
Epoch: 1, Steps: 140 | Train Loss: 0.9812323 Vali Loss: 0.4815333 Test Loss: 0.5347448
Validation loss decreased (inf --> 0.481533).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3910149
	speed: 0.3285s/iter; left time: 4520.6687s
Epoch: 2 cost time: 19.340171575546265
Epoch: 2, Steps: 140 | Train Loss: 0.4334943 Vali Loss: 0.3065099 Test Loss: 0.3426011
Validation loss decreased (0.481533 --> 0.306510).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2881757
	speed: 0.3334s/iter; left time: 4541.8955s
Epoch: 3 cost time: 18.5171480178833
Epoch: 3, Steps: 140 | Train Loss: 0.3171615 Vali Loss: 0.2519612 Test Loss: 0.2826145
Validation loss decreased (0.306510 --> 0.251961).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2778371
	speed: 0.3256s/iter; left time: 4389.4363s
Epoch: 4 cost time: 18.622272491455078
Epoch: 4, Steps: 140 | Train Loss: 0.2769004 Vali Loss: 0.2297546 Test Loss: 0.2585523
Validation loss decreased (0.251961 --> 0.229755).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2635131
	speed: 0.3267s/iter; left time: 4358.0410s
Epoch: 5 cost time: 18.693776607513428
Epoch: 5, Steps: 140 | Train Loss: 0.2592560 Vali Loss: 0.2188885 Test Loss: 0.2465389
Validation loss decreased (0.229755 --> 0.218889).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2452299
	speed: 0.3303s/iter; left time: 4360.5816s
Epoch: 6 cost time: 18.715102195739746
Epoch: 6, Steps: 140 | Train Loss: 0.2497802 Vali Loss: 0.2125522 Test Loss: 0.2394554
Validation loss decreased (0.218889 --> 0.212552).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2428163
	speed: 0.3340s/iter; left time: 4362.9253s
Epoch: 7 cost time: 18.600915670394897
Epoch: 7, Steps: 140 | Train Loss: 0.2438197 Vali Loss: 0.2082854 Test Loss: 0.2348954
Validation loss decreased (0.212552 --> 0.208285).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2529567
	speed: 0.3198s/iter; left time: 4132.6393s
Epoch: 8 cost time: 18.373504877090454
Epoch: 8, Steps: 140 | Train Loss: 0.2399262 Vali Loss: 0.2054914 Test Loss: 0.2317915
Validation loss decreased (0.208285 --> 0.205491).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2249987
	speed: 0.3272s/iter; left time: 4181.6700s
Epoch: 9 cost time: 18.421751737594604
Epoch: 9, Steps: 140 | Train Loss: 0.2372018 Vali Loss: 0.2035271 Test Loss: 0.2295905
Validation loss decreased (0.205491 --> 0.203527).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2290428
	speed: 0.3293s/iter; left time: 4163.2621s
Epoch: 10 cost time: 18.598873615264893
Epoch: 10, Steps: 140 | Train Loss: 0.2351968 Vali Loss: 0.2015211 Test Loss: 0.2280039
Validation loss decreased (0.203527 --> 0.201521).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2405036
	speed: 0.3384s/iter; left time: 4230.1673s
Epoch: 11 cost time: 19.121724605560303
Epoch: 11, Steps: 140 | Train Loss: 0.2337288 Vali Loss: 0.2006127 Test Loss: 0.2268022
Validation loss decreased (0.201521 --> 0.200613).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2407027
	speed: 0.3258s/iter; left time: 4026.9880s
Epoch: 12 cost time: 18.331858158111572
Epoch: 12, Steps: 140 | Train Loss: 0.2326808 Vali Loss: 0.1997830 Test Loss: 0.2259122
Validation loss decreased (0.200613 --> 0.199783).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2341676
	speed: 0.3278s/iter; left time: 4005.6607s
Epoch: 13 cost time: 18.727592945098877
Epoch: 13, Steps: 140 | Train Loss: 0.2317185 Vali Loss: 0.1988202 Test Loss: 0.2252013
Validation loss decreased (0.199783 --> 0.198820).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2307043
	speed: 0.3252s/iter; left time: 3928.2860s
Epoch: 14 cost time: 18.171507358551025
Epoch: 14, Steps: 140 | Train Loss: 0.2311805 Vali Loss: 0.1988806 Test Loss: 0.2246484
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2317495
	speed: 0.3303s/iter; left time: 3944.5583s
Epoch: 15 cost time: 19.060724020004272
Epoch: 15, Steps: 140 | Train Loss: 0.2305802 Vali Loss: 0.1980392 Test Loss: 0.2241838
Validation loss decreased (0.198820 --> 0.198039).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2306914
	speed: 0.3342s/iter; left time: 3943.6354s
Epoch: 16 cost time: 18.781858682632446
Epoch: 16, Steps: 140 | Train Loss: 0.2302145 Vali Loss: 0.1980226 Test Loss: 0.2237950
Validation loss decreased (0.198039 --> 0.198023).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2255193
	speed: 0.3300s/iter; left time: 3848.3754s
Epoch: 17 cost time: 19.021852254867554
Epoch: 17, Steps: 140 | Train Loss: 0.2298172 Vali Loss: 0.1974671 Test Loss: 0.2234778
Validation loss decreased (0.198023 --> 0.197467).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2171190
	speed: 0.3123s/iter; left time: 3597.7139s
Epoch: 18 cost time: 16.284632682800293
Epoch: 18, Steps: 140 | Train Loss: 0.2295601 Vali Loss: 0.1973104 Test Loss: 0.2232109
Validation loss decreased (0.197467 --> 0.197310).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2344981
	speed: 0.2933s/iter; left time: 3337.6370s
Epoch: 19 cost time: 17.61838126182556
Epoch: 19, Steps: 140 | Train Loss: 0.2293051 Vali Loss: 0.1973293 Test Loss: 0.2229827
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2230686
	speed: 0.3350s/iter; left time: 3765.5822s
Epoch: 20 cost time: 18.687909603118896
Epoch: 20, Steps: 140 | Train Loss: 0.2290450 Vali Loss: 0.1970354 Test Loss: 0.2227813
Validation loss decreased (0.197310 --> 0.197035).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2213626
	speed: 0.3267s/iter; left time: 3626.3275s
Epoch: 21 cost time: 18.42481756210327
Epoch: 21, Steps: 140 | Train Loss: 0.2287645 Vali Loss: 0.1968518 Test Loss: 0.2226110
Validation loss decreased (0.197035 --> 0.196852).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2208700
	speed: 0.3263s/iter; left time: 3576.6918s
Epoch: 22 cost time: 18.53102684020996
Epoch: 22, Steps: 140 | Train Loss: 0.2287016 Vali Loss: 0.1967819 Test Loss: 0.2224559
Validation loss decreased (0.196852 --> 0.196782).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2186261
	speed: 0.3242s/iter; left time: 3507.9903s
Epoch: 23 cost time: 18.60054039955139
Epoch: 23, Steps: 140 | Train Loss: 0.2285218 Vali Loss: 0.1966284 Test Loss: 0.2223241
Validation loss decreased (0.196782 --> 0.196628).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2270047
	speed: 0.3271s/iter; left time: 3493.9548s
Epoch: 24 cost time: 19.055264949798584
Epoch: 24, Steps: 140 | Train Loss: 0.2283871 Vali Loss: 0.1961350 Test Loss: 0.2221978
Validation loss decreased (0.196628 --> 0.196135).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2227615
	speed: 0.3298s/iter; left time: 3475.9051s
Epoch: 25 cost time: 18.442689180374146
Epoch: 25, Steps: 140 | Train Loss: 0.2282141 Vali Loss: 0.1962493 Test Loss: 0.2221008
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2276512
	speed: 0.3293s/iter; left time: 3425.1894s
Epoch: 26 cost time: 18.26157832145691
Epoch: 26, Steps: 140 | Train Loss: 0.2281196 Vali Loss: 0.1962658 Test Loss: 0.2220089
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2318091
	speed: 0.3204s/iter; left time: 3287.1762s
Epoch: 27 cost time: 18.053787231445312
Epoch: 27, Steps: 140 | Train Loss: 0.2280206 Vali Loss: 0.1962705 Test Loss: 0.2219257
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2135902
	speed: 0.3228s/iter; left time: 3267.2158s
Epoch: 28 cost time: 18.631744861602783
Epoch: 28, Steps: 140 | Train Loss: 0.2279269 Vali Loss: 0.1963363 Test Loss: 0.2218588
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2244831
	speed: 0.3364s/iter; left time: 3357.9492s
Epoch: 29 cost time: 18.352264404296875
Epoch: 29, Steps: 140 | Train Loss: 0.2279267 Vali Loss: 0.1962896 Test Loss: 0.2217848
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2292851
	speed: 0.3244s/iter; left time: 3191.9863s
Epoch: 30 cost time: 18.033970832824707
Epoch: 30, Steps: 140 | Train Loss: 0.2277669 Vali Loss: 0.1959708 Test Loss: 0.2217272
Validation loss decreased (0.196135 --> 0.195971).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2299690
	speed: 0.3205s/iter; left time: 3109.6470s
Epoch: 31 cost time: 17.861064910888672
Epoch: 31, Steps: 140 | Train Loss: 0.2277298 Vali Loss: 0.1960240 Test Loss: 0.2216816
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2386857
	speed: 0.3231s/iter; left time: 3089.0986s
Epoch: 32 cost time: 18.11997938156128
Epoch: 32, Steps: 140 | Train Loss: 0.2277607 Vali Loss: 0.1958877 Test Loss: 0.2216354
Validation loss decreased (0.195971 --> 0.195888).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2341193
	speed: 0.3285s/iter; left time: 3094.6581s
Epoch: 33 cost time: 18.04632806777954
Epoch: 33, Steps: 140 | Train Loss: 0.2276310 Vali Loss: 0.1956861 Test Loss: 0.2215875
Validation loss decreased (0.195888 --> 0.195686).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2220857
	speed: 0.3193s/iter; left time: 2963.6620s
Epoch: 34 cost time: 17.787870168685913
Epoch: 34, Steps: 140 | Train Loss: 0.2276236 Vali Loss: 0.1961851 Test Loss: 0.2215476
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2183890
	speed: 0.3180s/iter; left time: 2906.5780s
Epoch: 35 cost time: 17.860421657562256
Epoch: 35, Steps: 140 | Train Loss: 0.2275173 Vali Loss: 0.1956909 Test Loss: 0.2215206
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2197449
	speed: 0.3254s/iter; left time: 2928.7230s
Epoch: 36 cost time: 17.810063362121582
Epoch: 36, Steps: 140 | Train Loss: 0.2274915 Vali Loss: 0.1962478 Test Loss: 0.2214896
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2168036
	speed: 0.3315s/iter; left time: 2937.8585s
Epoch: 37 cost time: 18.62027597427368
Epoch: 37, Steps: 140 | Train Loss: 0.2274760 Vali Loss: 0.1959146 Test Loss: 0.2214613
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2229481
	speed: 0.3239s/iter; left time: 2824.3594s
Epoch: 38 cost time: 18.421637773513794
Epoch: 38, Steps: 140 | Train Loss: 0.2274537 Vali Loss: 0.1957556 Test Loss: 0.2214428
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2220610
	speed: 0.3282s/iter; left time: 2816.5278s
Epoch: 39 cost time: 18.175962686538696
Epoch: 39, Steps: 140 | Train Loss: 0.2274328 Vali Loss: 0.1959328 Test Loss: 0.2214257
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2203455
	speed: 0.3206s/iter; left time: 2705.9572s
Epoch: 40 cost time: 18.163304090499878
Epoch: 40, Steps: 140 | Train Loss: 0.2273583 Vali Loss: 0.1956655 Test Loss: 0.2214015
Validation loss decreased (0.195686 --> 0.195665).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2237400
	speed: 0.3230s/iter; left time: 2681.1740s
Epoch: 41 cost time: 18.80002188682556
Epoch: 41, Steps: 140 | Train Loss: 0.2274507 Vali Loss: 0.1956026 Test Loss: 0.2213837
Validation loss decreased (0.195665 --> 0.195603).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2258348
	speed: 0.3249s/iter; left time: 2651.2651s
Epoch: 42 cost time: 18.137794017791748
Epoch: 42, Steps: 140 | Train Loss: 0.2273409 Vali Loss: 0.1959623 Test Loss: 0.2213729
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2179314
	speed: 0.3272s/iter; left time: 2624.8274s
Epoch: 43 cost time: 18.602699995040894
Epoch: 43, Steps: 140 | Train Loss: 0.2274138 Vali Loss: 0.1957601 Test Loss: 0.2213582
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2240897
	speed: 0.3293s/iter; left time: 2595.1580s
Epoch: 44 cost time: 18.63520050048828
Epoch: 44, Steps: 140 | Train Loss: 0.2273864 Vali Loss: 0.1959093 Test Loss: 0.2213457
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2332732
	speed: 0.3249s/iter; left time: 2515.1238s
Epoch: 45 cost time: 18.573265552520752
Epoch: 45, Steps: 140 | Train Loss: 0.2272574 Vali Loss: 0.1958316 Test Loss: 0.2213355
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2300666
	speed: 0.3310s/iter; left time: 2516.2965s
Epoch: 46 cost time: 18.671005249023438
Epoch: 46, Steps: 140 | Train Loss: 0.2272872 Vali Loss: 0.1955744 Test Loss: 0.2213334
Validation loss decreased (0.195603 --> 0.195574).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2343559
	speed: 0.3272s/iter; left time: 2441.2153s
Epoch: 47 cost time: 18.564778089523315
Epoch: 47, Steps: 140 | Train Loss: 0.2272895 Vali Loss: 0.1954161 Test Loss: 0.2213253
Validation loss decreased (0.195574 --> 0.195416).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2299540
	speed: 0.3366s/iter; left time: 2464.4201s
Epoch: 48 cost time: 18.425276279449463
Epoch: 48, Steps: 140 | Train Loss: 0.2273509 Vali Loss: 0.1954609 Test Loss: 0.2213176
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2048827
	speed: 0.3249s/iter; left time: 2333.3909s
Epoch: 49 cost time: 18.43888258934021
Epoch: 49, Steps: 140 | Train Loss: 0.2272877 Vali Loss: 0.1954255 Test Loss: 0.2213068
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2182516
	speed: 0.3346s/iter; left time: 2355.6797s
Epoch: 50 cost time: 18.855618000030518
Epoch: 50, Steps: 140 | Train Loss: 0.2272708 Vali Loss: 0.1952813 Test Loss: 0.2213016
Validation loss decreased (0.195416 --> 0.195281).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2244789
	speed: 0.3296s/iter; left time: 2274.4020s
Epoch: 51 cost time: 17.676871299743652
Epoch: 51, Steps: 140 | Train Loss: 0.2273082 Vali Loss: 0.1955464 Test Loss: 0.2212989
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2341246
	speed: 0.3215s/iter; left time: 2173.9733s
Epoch: 52 cost time: 18.109774112701416
Epoch: 52, Steps: 140 | Train Loss: 0.2272678 Vali Loss: 0.1956808 Test Loss: 0.2212949
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2350083
	speed: 0.3197s/iter; left time: 2116.9891s
Epoch: 53 cost time: 17.757981061935425
Epoch: 53, Steps: 140 | Train Loss: 0.2272754 Vali Loss: 0.1957100 Test Loss: 0.2212897
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2222817
	speed: 0.3226s/iter; left time: 2091.0897s
Epoch: 54 cost time: 18.0908522605896
Epoch: 54, Steps: 140 | Train Loss: 0.2272284 Vali Loss: 0.1960000 Test Loss: 0.2212873
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2298177
	speed: 0.3314s/iter; left time: 2101.5476s
Epoch: 55 cost time: 18.537233352661133
Epoch: 55, Steps: 140 | Train Loss: 0.2272214 Vali Loss: 0.1953294 Test Loss: 0.2212810
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2220387
	speed: 0.3254s/iter; left time: 2018.0561s
Epoch: 56 cost time: 18.160298109054565
Epoch: 56, Steps: 140 | Train Loss: 0.2272731 Vali Loss: 0.1954023 Test Loss: 0.2212792
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2276932
	speed: 0.3237s/iter; left time: 1961.9632s
Epoch: 57 cost time: 18.040958642959595
Epoch: 57, Steps: 140 | Train Loss: 0.2271633 Vali Loss: 0.1954857 Test Loss: 0.2212705
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2299003
	speed: 0.3245s/iter; left time: 1921.4849s
Epoch: 58 cost time: 18.081144094467163
Epoch: 58, Steps: 140 | Train Loss: 0.2272896 Vali Loss: 0.1955970 Test Loss: 0.2212721
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2345424
	speed: 0.3262s/iter; left time: 1886.0015s
Epoch: 59 cost time: 18.49122190475464
Epoch: 59, Steps: 140 | Train Loss: 0.2273298 Vali Loss: 0.1955831 Test Loss: 0.2212692
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.2286457
	speed: 0.3279s/iter; left time: 1849.5928s
Epoch: 60 cost time: 18.58899426460266
Epoch: 60, Steps: 140 | Train Loss: 0.2272202 Vali Loss: 0.1956422 Test Loss: 0.2212687
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.2286109
	speed: 0.3250s/iter; left time: 1787.9150s
Epoch: 61 cost time: 18.525118827819824
Epoch: 61, Steps: 140 | Train Loss: 0.2273205 Vali Loss: 0.1954724 Test Loss: 0.2212670
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.2217704
	speed: 0.3275s/iter; left time: 1755.8498s
Epoch: 62 cost time: 18.642565727233887
Epoch: 62, Steps: 140 | Train Loss: 0.2272690 Vali Loss: 0.1952289 Test Loss: 0.2212644
Validation loss decreased (0.195281 --> 0.195229).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.2274077
	speed: 0.3325s/iter; left time: 1736.0100s
Epoch: 63 cost time: 18.81568145751953
Epoch: 63, Steps: 140 | Train Loss: 0.2272718 Vali Loss: 0.1956886 Test Loss: 0.2212647
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.2242244
	speed: 0.3233s/iter; left time: 1642.8498s
Epoch: 64 cost time: 17.975096940994263
Epoch: 64, Steps: 140 | Train Loss: 0.2272515 Vali Loss: 0.1956199 Test Loss: 0.2212617
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.2236963
	speed: 0.3176s/iter; left time: 1569.0641s
Epoch: 65 cost time: 18.223366498947144
Epoch: 65, Steps: 140 | Train Loss: 0.2271849 Vali Loss: 0.1954611 Test Loss: 0.2212633
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.2520747
	speed: 0.3192s/iter; left time: 1532.5439s
Epoch: 66 cost time: 18.000765562057495
Epoch: 66, Steps: 140 | Train Loss: 0.2272365 Vali Loss: 0.1954829 Test Loss: 0.2212616
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.2451403
	speed: 0.3266s/iter; left time: 1522.3414s
Epoch: 67 cost time: 18.429608583450317
Epoch: 67, Steps: 140 | Train Loss: 0.2272364 Vali Loss: 0.1957314 Test Loss: 0.2212592
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.2386825
	speed: 0.3298s/iter; left time: 1490.8901s
Epoch: 68 cost time: 18.595000982284546
Epoch: 68, Steps: 140 | Train Loss: 0.2272407 Vali Loss: 0.1954111 Test Loss: 0.2212577
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.2273930
	speed: 0.3235s/iter; left time: 1417.1617s
Epoch: 69 cost time: 18.080695390701294
Epoch: 69, Steps: 140 | Train Loss: 0.2272571 Vali Loss: 0.1955659 Test Loss: 0.2212564
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.2280290
	speed: 0.3286s/iter; left time: 1393.3929s
Epoch: 70 cost time: 18.26201558113098
Epoch: 70, Steps: 140 | Train Loss: 0.2272509 Vali Loss: 0.1956540 Test Loss: 0.2212561
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.2142072
	speed: 0.3289s/iter; left time: 1348.6410s
Epoch: 71 cost time: 18.322930335998535
Epoch: 71, Steps: 140 | Train Loss: 0.2273037 Vali Loss: 0.1957174 Test Loss: 0.2212567
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.2208912
	speed: 0.3282s/iter; left time: 1300.1811s
Epoch: 72 cost time: 18.146965742111206
Epoch: 72, Steps: 140 | Train Loss: 0.2272400 Vali Loss: 0.1956056 Test Loss: 0.2212546
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.2268108
	speed: 0.3203s/iter; left time: 1223.7789s
Epoch: 73 cost time: 18.0617573261261
Epoch: 73, Steps: 140 | Train Loss: 0.2272552 Vali Loss: 0.1957499 Test Loss: 0.2212527
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.2232497
	speed: 0.3254s/iter; left time: 1197.9701s
Epoch: 74 cost time: 17.945504903793335
Epoch: 74, Steps: 140 | Train Loss: 0.2272447 Vali Loss: 0.1957179 Test Loss: 0.2212547
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.2257154
	speed: 0.3208s/iter; left time: 1136.0733s
Epoch: 75 cost time: 17.808618545532227
Epoch: 75, Steps: 140 | Train Loss: 0.2272812 Vali Loss: 0.1957832 Test Loss: 0.2212541
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.2351940
	speed: 0.3265s/iter; left time: 1110.5898s
Epoch: 76 cost time: 18.760835647583008
Epoch: 76, Steps: 140 | Train Loss: 0.2272001 Vali Loss: 0.1955486 Test Loss: 0.2212533
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.2327678
	speed: 0.3266s/iter; left time: 1065.0784s
Epoch: 77 cost time: 18.278939962387085
Epoch: 77, Steps: 140 | Train Loss: 0.2272098 Vali Loss: 0.1956325 Test Loss: 0.2212529
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.2345575
	speed: 0.3165s/iter; left time: 987.7389s
Epoch: 78 cost time: 17.727135181427002
Epoch: 78, Steps: 140 | Train Loss: 0.2272267 Vali Loss: 0.1957632 Test Loss: 0.2212537
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.2301789
	speed: 0.3246s/iter; left time: 967.6633s
Epoch: 79 cost time: 18.242907524108887
Epoch: 79, Steps: 140 | Train Loss: 0.2271399 Vali Loss: 0.1956840 Test Loss: 0.2212518
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.2264691
	speed: 0.3239s/iter; left time: 920.1740s
Epoch: 80 cost time: 18.65735363960266
Epoch: 80, Steps: 140 | Train Loss: 0.2272305 Vali Loss: 0.1955341 Test Loss: 0.2212510
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.2247298
	speed: 0.3343s/iter; left time: 903.0293s
Epoch: 81 cost time: 18.37854790687561
Epoch: 81, Steps: 140 | Train Loss: 0.2272051 Vali Loss: 0.1955858 Test Loss: 0.2212510
EarlyStopping counter: 19 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.2249836
	speed: 0.3258s/iter; left time: 834.3281s
Epoch: 82 cost time: 18.25157904624939
Epoch: 82, Steps: 140 | Train Loss: 0.2272338 Vali Loss: 0.1955968 Test Loss: 0.2212499
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_90_j336_H6_FITS_custom_ftM_sl90_ll48_pl336_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4925
mse:0.22536920011043549, mae:0.30686497688293457, rse:0.47248560190200806, corr:[0.4553555  0.4505336  0.45084155 0.44799593 0.44764048 0.44811434
 0.44788852 0.4483641  0.44768456 0.445891   0.4450229  0.44512492
 0.4444984  0.44455126 0.44426554 0.44339138 0.4443025  0.44427672
 0.444124   0.44432807 0.4441264  0.44387785 0.44349766 0.4423621
 0.4392053  0.43729293 0.43618724 0.43530986 0.4353502  0.43539366
 0.43705118 0.4378667  0.43728787 0.43696365 0.43629485 0.43543762
 0.43551376 0.43574    0.43522632 0.43498465 0.43559223 0.4354431
 0.43548143 0.43600157 0.43601072 0.43567854 0.43544933 0.43503973
 0.43328086 0.43251395 0.43140635 0.4313432  0.4335533  0.4355202
 0.43841624 0.4402899  0.44021517 0.44000256 0.43991894 0.43955728
 0.43913767 0.43890047 0.4389368  0.4394372  0.44007045 0.43985397
 0.440033   0.44066626 0.44081655 0.44068676 0.4410509  0.44109562
 0.4398552  0.440362   0.44106328 0.44120196 0.443313   0.4467065
 0.45098105 0.45446768 0.45537058 0.45441806 0.45340693 0.4531872
 0.45280328 0.4522553  0.4527022  0.45321745 0.45342794 0.45354968
 0.4540863  0.4544044  0.4542697  0.454496   0.45494488 0.45470724
 0.45362327 0.45327377 0.4529946  0.45295882 0.45341823 0.45382145
 0.45467106 0.4549227  0.45469916 0.45456558 0.45404738 0.45338675
 0.45334038 0.4533071  0.45324835 0.4535768  0.45414737 0.45415395
 0.45430312 0.454617   0.45416954 0.45382354 0.4542625  0.45427108
 0.45358208 0.45386767 0.45322078 0.4524917  0.4533812  0.45379156
 0.45422623 0.45461997 0.45407218 0.45327997 0.45307398 0.45311305
 0.4528177  0.45287883 0.4535279  0.45356587 0.4539088  0.45447567
 0.4547655  0.45481724 0.45485651 0.45494738 0.45456442 0.4539351
 0.45339438 0.4531694  0.45239824 0.45234382 0.45281222 0.45268592
 0.45364156 0.45445666 0.4539228  0.4531135  0.45245826 0.4518934
 0.45175964 0.45168364 0.45214525 0.45287693 0.4532073  0.45341888
 0.4540824  0.45411524 0.4534111  0.453411   0.45274958 0.44935283
 0.44507945 0.44207042 0.43901792 0.4378723  0.43858287 0.43780154
 0.4384603  0.4396421  0.4390675  0.43833163 0.43826824 0.4376769
 0.43704513 0.43705845 0.4374173  0.4372077  0.43705782 0.43711552
 0.4371431  0.43708247 0.4368035  0.43638107 0.4354276  0.43328834
 0.43033916 0.4284012  0.4262709  0.4248283  0.4251039  0.4261491
 0.4284524  0.42974406 0.42962176 0.42961133 0.4296556  0.42893684
 0.42864302 0.4289882  0.42903998 0.42864248 0.42886442 0.42910665
 0.428908   0.42883343 0.42909744 0.42925966 0.42871234 0.4277099
 0.4260715  0.42494723 0.42444536 0.4248659  0.42541435 0.42735824
 0.43135563 0.433735   0.434133   0.4342852  0.43432498 0.43376243
 0.43372813 0.43394294 0.43376502 0.43381104 0.43431377 0.43448004
 0.43450817 0.43447632 0.43427753 0.4346246  0.43479782 0.43393996
 0.43298256 0.4330356  0.4329186  0.4345216  0.43756565 0.44028255
 0.44435868 0.44815657 0.4491373  0.44873473 0.4486975  0.44836062
 0.44780248 0.44774613 0.44778237 0.44757593 0.4481262  0.44874233
 0.44903958 0.4491569  0.44907534 0.44909152 0.44901228 0.44875628
 0.44839728 0.44813406 0.44748935 0.44739905 0.44788978 0.44846356
 0.44948867 0.45005465 0.45000997 0.44967264 0.44925764 0.44869974
 0.44839805 0.44815066 0.44822612 0.448452   0.44883242 0.44910526
 0.44921288 0.4492472  0.4489708  0.44887492 0.4491078  0.44898313
 0.4485865  0.44862735 0.44813687 0.4479783  0.44837415 0.448717
 0.44946256 0.44980845 0.44957897 0.44927385 0.4490998  0.44865325
 0.44848028 0.44838256 0.44844383 0.44861674 0.44888416 0.44918758
 0.44925186 0.44906643 0.44885343 0.44895503 0.4489326  0.4484018
 0.44795185 0.44766116 0.44695228 0.44739854 0.4479308  0.44798067
 0.44895133 0.44939342 0.44904605 0.44897467 0.44879866 0.44816837
 0.4482613  0.4481607  0.44806874 0.44823962 0.44809997 0.44859192
 0.44834688 0.44769755 0.4483418  0.44714454 0.44681215 0.44549182]
