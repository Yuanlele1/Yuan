Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=34, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_90_j720_H6', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_90_j720_H6_FITS_custom_ftM_sl90_ll48_pl720_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17603
val 1913
test 4541
Model(
  (freq_upsampler): Linear(in_features=34, out_features=306, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  427479552.0
params:  10710.0
Trainable parameters:  10710
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 1.2804630
	speed: 0.1939s/iter; left time: 2636.8979s
Epoch: 1 cost time: 26.105233192443848
Epoch: 1, Steps: 137 | Train Loss: 1.7903905 Vali Loss: 0.9227248 Test Loss: 1.0173275
Validation loss decreased (inf --> 0.922725).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6969067
	speed: 0.4819s/iter; left time: 6487.6955s
Epoch: 2 cost time: 27.029459476470947
Epoch: 2, Steps: 137 | Train Loss: 0.7906624 Vali Loss: 0.5655356 Test Loss: 0.6323795
Validation loss decreased (0.922725 --> 0.565536).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5000097
	speed: 0.4858s/iter; left time: 6474.2803s
Epoch: 3 cost time: 27.839901447296143
Epoch: 3, Steps: 137 | Train Loss: 0.5357972 Vali Loss: 0.4270205 Test Loss: 0.4811259
Validation loss decreased (0.565536 --> 0.427020).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3995587
	speed: 0.5039s/iter; left time: 6646.5959s
Epoch: 4 cost time: 26.40965247154236
Epoch: 4, Steps: 137 | Train Loss: 0.4236647 Vali Loss: 0.3557403 Test Loss: 0.4024865
Validation loss decreased (0.427020 --> 0.355740).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3551066
	speed: 0.4812s/iter; left time: 6280.7979s
Epoch: 5 cost time: 26.583378314971924
Epoch: 5, Steps: 137 | Train Loss: 0.3633093 Vali Loss: 0.3158383 Test Loss: 0.3576102
Validation loss decreased (0.355740 --> 0.315838).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3198245
	speed: 0.4818s/iter; left time: 6223.0727s
Epoch: 6 cost time: 26.087314128875732
Epoch: 6, Steps: 137 | Train Loss: 0.3280756 Vali Loss: 0.2914428 Test Loss: 0.3306215
Validation loss decreased (0.315838 --> 0.291443).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2963545
	speed: 0.4844s/iter; left time: 6189.9814s
Epoch: 7 cost time: 26.34737467765808
Epoch: 7, Steps: 137 | Train Loss: 0.3063297 Vali Loss: 0.2767811 Test Loss: 0.3136292
Validation loss decreased (0.291443 --> 0.276781).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3030957
	speed: 0.4827s/iter; left time: 6102.7647s
Epoch: 8 cost time: 26.36151957511902
Epoch: 8, Steps: 137 | Train Loss: 0.2923427 Vali Loss: 0.2670522 Test Loss: 0.3024059
Validation loss decreased (0.276781 --> 0.267052).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2767700
	speed: 0.4828s/iter; left time: 6037.9869s
Epoch: 9 cost time: 26.49689483642578
Epoch: 9, Steps: 137 | Train Loss: 0.2829941 Vali Loss: 0.2602608 Test Loss: 0.2947159
Validation loss decreased (0.267052 --> 0.260261).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2833373
	speed: 0.4857s/iter; left time: 6006.6940s
Epoch: 10 cost time: 26.323780298233032
Epoch: 10, Steps: 137 | Train Loss: 0.2764079 Vali Loss: 0.2550246 Test Loss: 0.2892016
Validation loss decreased (0.260261 --> 0.255025).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2678007
	speed: 0.4819s/iter; left time: 5893.6976s
Epoch: 11 cost time: 26.928924083709717
Epoch: 11, Steps: 137 | Train Loss: 0.2715192 Vali Loss: 0.2509954 Test Loss: 0.2850757
Validation loss decreased (0.255025 --> 0.250995).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2685459
	speed: 0.4793s/iter; left time: 5796.2695s
Epoch: 12 cost time: 26.824390649795532
Epoch: 12, Steps: 137 | Train Loss: 0.2679976 Vali Loss: 0.2484825 Test Loss: 0.2819518
Validation loss decreased (0.250995 --> 0.248483).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2656971
	speed: 0.4889s/iter; left time: 5845.1884s
Epoch: 13 cost time: 26.935405254364014
Epoch: 13, Steps: 137 | Train Loss: 0.2651304 Vali Loss: 0.2460138 Test Loss: 0.2795129
Validation loss decreased (0.248483 --> 0.246014).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2690906
	speed: 0.4784s/iter; left time: 5654.2354s
Epoch: 14 cost time: 26.54802680015564
Epoch: 14, Steps: 137 | Train Loss: 0.2628961 Vali Loss: 0.2447114 Test Loss: 0.2775182
Validation loss decreased (0.246014 --> 0.244711).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2551839
	speed: 0.4790s/iter; left time: 5596.6971s
Epoch: 15 cost time: 27.011200189590454
Epoch: 15, Steps: 137 | Train Loss: 0.2611150 Vali Loss: 0.2433411 Test Loss: 0.2758998
Validation loss decreased (0.244711 --> 0.243341).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2526564
	speed: 0.4897s/iter; left time: 5654.5187s
Epoch: 16 cost time: 27.23381519317627
Epoch: 16, Steps: 137 | Train Loss: 0.2595218 Vali Loss: 0.2424280 Test Loss: 0.2745694
Validation loss decreased (0.243341 --> 0.242428).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2630750
	speed: 0.4745s/iter; left time: 5413.4430s
Epoch: 17 cost time: 26.655457258224487
Epoch: 17, Steps: 137 | Train Loss: 0.2583262 Vali Loss: 0.2412318 Test Loss: 0.2734367
Validation loss decreased (0.242428 --> 0.241232).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2463145
	speed: 0.4890s/iter; left time: 5511.6246s
Epoch: 18 cost time: 27.61217761039734
Epoch: 18, Steps: 137 | Train Loss: 0.2573419 Vali Loss: 0.2406686 Test Loss: 0.2724827
Validation loss decreased (0.241232 --> 0.240669).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2694564
	speed: 0.4840s/iter; left time: 5389.1153s
Epoch: 19 cost time: 27.502949476242065
Epoch: 19, Steps: 137 | Train Loss: 0.2564036 Vali Loss: 0.2394810 Test Loss: 0.2717106
Validation loss decreased (0.240669 --> 0.239481).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2545571
	speed: 0.4850s/iter; left time: 5334.2204s
Epoch: 20 cost time: 27.238407850265503
Epoch: 20, Steps: 137 | Train Loss: 0.2556131 Vali Loss: 0.2388652 Test Loss: 0.2709859
Validation loss decreased (0.239481 --> 0.238865).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2504409
	speed: 0.4847s/iter; left time: 5263.9521s
Epoch: 21 cost time: 26.828064680099487
Epoch: 21, Steps: 137 | Train Loss: 0.2550209 Vali Loss: 0.2384619 Test Loss: 0.2703513
Validation loss decreased (0.238865 --> 0.238462).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2505844
	speed: 0.4814s/iter; left time: 5162.5897s
Epoch: 22 cost time: 26.85071063041687
Epoch: 22, Steps: 137 | Train Loss: 0.2544257 Vali Loss: 0.2376841 Test Loss: 0.2697989
Validation loss decreased (0.238462 --> 0.237684).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2411339
	speed: 0.4843s/iter; left time: 5127.1219s
Epoch: 23 cost time: 26.963440895080566
Epoch: 23, Steps: 137 | Train Loss: 0.2539138 Vali Loss: 0.2375021 Test Loss: 0.2693390
Validation loss decreased (0.237684 --> 0.237502).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2528395
	speed: 0.4820s/iter; left time: 5037.3724s
Epoch: 24 cost time: 26.405463457107544
Epoch: 24, Steps: 137 | Train Loss: 0.2534247 Vali Loss: 0.2370320 Test Loss: 0.2689078
Validation loss decreased (0.237502 --> 0.237032).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2590628
	speed: 0.4875s/iter; left time: 5027.3778s
Epoch: 25 cost time: 26.773917198181152
Epoch: 25, Steps: 137 | Train Loss: 0.2530503 Vali Loss: 0.2369375 Test Loss: 0.2685393
Validation loss decreased (0.237032 --> 0.236937).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2456005
	speed: 0.4889s/iter; left time: 4974.8907s
Epoch: 26 cost time: 26.400018215179443
Epoch: 26, Steps: 137 | Train Loss: 0.2526918 Vali Loss: 0.2363854 Test Loss: 0.2681842
Validation loss decreased (0.236937 --> 0.236385).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2609459
	speed: 0.4810s/iter; left time: 4828.3856s
Epoch: 27 cost time: 26.092191696166992
Epoch: 27, Steps: 137 | Train Loss: 0.2523298 Vali Loss: 0.2364335 Test Loss: 0.2678589
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2618479
	speed: 0.4834s/iter; left time: 4786.5861s
Epoch: 28 cost time: 26.549044847488403
Epoch: 28, Steps: 137 | Train Loss: 0.2519705 Vali Loss: 0.2354293 Test Loss: 0.2675906
Validation loss decreased (0.236385 --> 0.235429).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2284965
	speed: 0.4845s/iter; left time: 4731.0582s
Epoch: 29 cost time: 26.487598180770874
Epoch: 29, Steps: 137 | Train Loss: 0.2517208 Vali Loss: 0.2347959 Test Loss: 0.2673241
Validation loss decreased (0.235429 --> 0.234796).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2507801
	speed: 0.4819s/iter; left time: 4639.6925s
Epoch: 30 cost time: 26.421342134475708
Epoch: 30, Steps: 137 | Train Loss: 0.2515039 Vali Loss: 0.2353312 Test Loss: 0.2671007
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2489806
	speed: 0.4777s/iter; left time: 4534.1834s
Epoch: 31 cost time: 26.323588132858276
Epoch: 31, Steps: 137 | Train Loss: 0.2512665 Vali Loss: 0.2347326 Test Loss: 0.2668759
Validation loss decreased (0.234796 --> 0.234733).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2501484
	speed: 0.4897s/iter; left time: 4580.6164s
Epoch: 32 cost time: 27.151859045028687
Epoch: 32, Steps: 137 | Train Loss: 0.2509988 Vali Loss: 0.2350182 Test Loss: 0.2666628
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2370473
	speed: 0.4878s/iter; left time: 4496.4061s
Epoch: 33 cost time: 26.64583420753479
Epoch: 33, Steps: 137 | Train Loss: 0.2508282 Vali Loss: 0.2351756 Test Loss: 0.2664806
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2424903
	speed: 0.4876s/iter; left time: 4427.2118s
Epoch: 34 cost time: 27.230544567108154
Epoch: 34, Steps: 137 | Train Loss: 0.2506686 Vali Loss: 0.2344866 Test Loss: 0.2662854
Validation loss decreased (0.234733 --> 0.234487).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2551899
	speed: 0.4981s/iter; left time: 4454.6957s
Epoch: 35 cost time: 27.560109853744507
Epoch: 35, Steps: 137 | Train Loss: 0.2504622 Vali Loss: 0.2346099 Test Loss: 0.2661304
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2562574
	speed: 0.4924s/iter; left time: 4336.0142s
Epoch: 36 cost time: 27.683086395263672
Epoch: 36, Steps: 137 | Train Loss: 0.2503060 Vali Loss: 0.2342706 Test Loss: 0.2659760
Validation loss decreased (0.234487 --> 0.234271).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2491864
	speed: 0.4952s/iter; left time: 4292.9581s
Epoch: 37 cost time: 27.448901891708374
Epoch: 37, Steps: 137 | Train Loss: 0.2501663 Vali Loss: 0.2337388 Test Loss: 0.2658244
Validation loss decreased (0.234271 --> 0.233739).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2543202
	speed: 0.4924s/iter; left time: 4200.8738s
Epoch: 38 cost time: 27.710971117019653
Epoch: 38, Steps: 137 | Train Loss: 0.2500517 Vali Loss: 0.2342609 Test Loss: 0.2656927
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2439989
	speed: 0.4882s/iter; left time: 4098.4738s
Epoch: 39 cost time: 26.974438190460205
Epoch: 39, Steps: 137 | Train Loss: 0.2499396 Vali Loss: 0.2340478 Test Loss: 0.2655593
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2605258
	speed: 0.4805s/iter; left time: 3968.0181s
Epoch: 40 cost time: 27.548490285873413
Epoch: 40, Steps: 137 | Train Loss: 0.2497317 Vali Loss: 0.2332720 Test Loss: 0.2654528
Validation loss decreased (0.233739 --> 0.233272).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2510082
	speed: 0.4818s/iter; left time: 3912.5149s
Epoch: 41 cost time: 26.75295925140381
Epoch: 41, Steps: 137 | Train Loss: 0.2496775 Vali Loss: 0.2333994 Test Loss: 0.2653352
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2495051
	speed: 0.4800s/iter; left time: 3832.4638s
Epoch: 42 cost time: 27.282021284103394
Epoch: 42, Steps: 137 | Train Loss: 0.2495024 Vali Loss: 0.2336705 Test Loss: 0.2652248
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2472346
	speed: 0.4868s/iter; left time: 3819.5767s
Epoch: 43 cost time: 27.090876579284668
Epoch: 43, Steps: 137 | Train Loss: 0.2494752 Vali Loss: 0.2334197 Test Loss: 0.2651291
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2412797
	speed: 0.4872s/iter; left time: 3756.3426s
Epoch: 44 cost time: 26.91305708885193
Epoch: 44, Steps: 137 | Train Loss: 0.2493857 Vali Loss: 0.2337179 Test Loss: 0.2650316
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2546325
	speed: 0.4802s/iter; left time: 3636.5804s
Epoch: 45 cost time: 26.806256532669067
Epoch: 45, Steps: 137 | Train Loss: 0.2492959 Vali Loss: 0.2335135 Test Loss: 0.2649367
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2542161
	speed: 0.4900s/iter; left time: 3643.4170s
Epoch: 46 cost time: 26.938626766204834
Epoch: 46, Steps: 137 | Train Loss: 0.2491019 Vali Loss: 0.2329572 Test Loss: 0.2648520
Validation loss decreased (0.233272 --> 0.232957).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2488774
	speed: 0.4816s/iter; left time: 3515.3146s
Epoch: 47 cost time: 26.411020517349243
Epoch: 47, Steps: 137 | Train Loss: 0.2491126 Vali Loss: 0.2326297 Test Loss: 0.2647761
Validation loss decreased (0.232957 --> 0.232630).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2429885
	speed: 0.4871s/iter; left time: 3488.6848s
Epoch: 48 cost time: 26.718841552734375
Epoch: 48, Steps: 137 | Train Loss: 0.2490093 Vali Loss: 0.2333270 Test Loss: 0.2646897
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2478851
	speed: 0.4843s/iter; left time: 3402.3291s
Epoch: 49 cost time: 26.732798099517822
Epoch: 49, Steps: 137 | Train Loss: 0.2489521 Vali Loss: 0.2325486 Test Loss: 0.2646151
Validation loss decreased (0.232630 --> 0.232549).  Saving model ...
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2446689
	speed: 0.4893s/iter; left time: 3370.1564s
Epoch: 50 cost time: 26.624337673187256
Epoch: 50, Steps: 137 | Train Loss: 0.2488500 Vali Loss: 0.2329355 Test Loss: 0.2645438
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2406438
	speed: 0.4851s/iter; left time: 3275.2187s
Epoch: 51 cost time: 26.69235134124756
Epoch: 51, Steps: 137 | Train Loss: 0.2488108 Vali Loss: 0.2330251 Test Loss: 0.2644875
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2532250
	speed: 0.4832s/iter; left time: 3195.7370s
Epoch: 52 cost time: 26.667347192764282
Epoch: 52, Steps: 137 | Train Loss: 0.2487375 Vali Loss: 0.2326160 Test Loss: 0.2644158
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2467898
	speed: 0.4928s/iter; left time: 3192.1327s
Epoch: 53 cost time: 27.453877210617065
Epoch: 53, Steps: 137 | Train Loss: 0.2485945 Vali Loss: 0.2323217 Test Loss: 0.2643675
Validation loss decreased (0.232549 --> 0.232322).  Saving model ...
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2435050
	speed: 0.4865s/iter; left time: 3084.6816s
Epoch: 54 cost time: 26.88459873199463
Epoch: 54, Steps: 137 | Train Loss: 0.2485766 Vali Loss: 0.2326234 Test Loss: 0.2643212
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2474872
	speed: 0.4914s/iter; left time: 3048.2566s
Epoch: 55 cost time: 26.921302318572998
Epoch: 55, Steps: 137 | Train Loss: 0.2485142 Vali Loss: 0.2325110 Test Loss: 0.2642626
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2582202
	speed: 0.4880s/iter; left time: 2960.0598s
Epoch: 56 cost time: 27.619819402694702
Epoch: 56, Steps: 137 | Train Loss: 0.2484689 Vali Loss: 0.2325304 Test Loss: 0.2642179
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2534014
	speed: 0.4784s/iter; left time: 2836.6839s
Epoch: 57 cost time: 27.02930521965027
Epoch: 57, Steps: 137 | Train Loss: 0.2484705 Vali Loss: 0.2325968 Test Loss: 0.2641712
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2399499
	speed: 0.4826s/iter; left time: 2795.0354s
Epoch: 58 cost time: 26.98599672317505
Epoch: 58, Steps: 137 | Train Loss: 0.2484427 Vali Loss: 0.2324272 Test Loss: 0.2641247
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2524970
	speed: 0.4788s/iter; left time: 2707.6911s
Epoch: 59 cost time: 26.921305418014526
Epoch: 59, Steps: 137 | Train Loss: 0.2483559 Vali Loss: 0.2322582 Test Loss: 0.2640876
Validation loss decreased (0.232322 --> 0.232258).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.2590938
	speed: 0.4797s/iter; left time: 2646.7521s
Epoch: 60 cost time: 27.14886450767517
Epoch: 60, Steps: 137 | Train Loss: 0.2483193 Vali Loss: 0.2323758 Test Loss: 0.2640424
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.2485675
	speed: 0.4862s/iter; left time: 2616.4190s
Epoch: 61 cost time: 27.274311542510986
Epoch: 61, Steps: 137 | Train Loss: 0.2482648 Vali Loss: 0.2326991 Test Loss: 0.2640065
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.2375357
	speed: 0.4929s/iter; left time: 2584.9787s
Epoch: 62 cost time: 27.60962438583374
Epoch: 62, Steps: 137 | Train Loss: 0.2482464 Vali Loss: 0.2321606 Test Loss: 0.2639717
Validation loss decreased (0.232258 --> 0.232161).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.2597408
	speed: 0.5013s/iter; left time: 2559.9360s
Epoch: 63 cost time: 28.39451289176941
Epoch: 63, Steps: 137 | Train Loss: 0.2482808 Vali Loss: 0.2324445 Test Loss: 0.2639395
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.2457570
	speed: 0.5290s/iter; left time: 2629.0635s
Epoch: 64 cost time: 28.125295162200928
Epoch: 64, Steps: 137 | Train Loss: 0.2481159 Vali Loss: 0.2320573 Test Loss: 0.2639137
Validation loss decreased (0.232161 --> 0.232057).  Saving model ...
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.2537023
	speed: 0.4874s/iter; left time: 2355.7834s
Epoch: 65 cost time: 27.319316387176514
Epoch: 65, Steps: 137 | Train Loss: 0.2481223 Vali Loss: 0.2325744 Test Loss: 0.2638841
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.2546225
	speed: 0.4904s/iter; left time: 2303.1077s
Epoch: 66 cost time: 27.124985694885254
Epoch: 66, Steps: 137 | Train Loss: 0.2481563 Vali Loss: 0.2325896 Test Loss: 0.2638583
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.2511106
	speed: 0.4846s/iter; left time: 2209.4640s
Epoch: 67 cost time: 26.934516429901123
Epoch: 67, Steps: 137 | Train Loss: 0.2480662 Vali Loss: 0.2322830 Test Loss: 0.2638344
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.2468894
	speed: 0.4931s/iter; left time: 2180.3773s
Epoch: 68 cost time: 26.60292959213257
Epoch: 68, Steps: 137 | Train Loss: 0.2480724 Vali Loss: 0.2326765 Test Loss: 0.2638051
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.2558233
	speed: 0.5112s/iter; left time: 2190.4005s
Epoch: 69 cost time: 27.78489637374878
Epoch: 69, Steps: 137 | Train Loss: 0.2481149 Vali Loss: 0.2323775 Test Loss: 0.2637855
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.2490989
	speed: 0.5052s/iter; left time: 2095.7373s
Epoch: 70 cost time: 26.867393255233765
Epoch: 70, Steps: 137 | Train Loss: 0.2480542 Vali Loss: 0.2319637 Test Loss: 0.2637695
Validation loss decreased (0.232057 --> 0.231964).  Saving model ...
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.2503914
	speed: 0.4917s/iter; left time: 1972.1846s
Epoch: 71 cost time: 26.913973808288574
Epoch: 71, Steps: 137 | Train Loss: 0.2480308 Vali Loss: 0.2322014 Test Loss: 0.2637508
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.2421587
	speed: 0.5006s/iter; left time: 1939.1580s
Epoch: 72 cost time: 27.735275268554688
Epoch: 72, Steps: 137 | Train Loss: 0.2479759 Vali Loss: 0.2320500 Test Loss: 0.2637312
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.2384502
	speed: 0.5027s/iter; left time: 1878.6261s
Epoch: 73 cost time: 28.28853464126587
Epoch: 73, Steps: 137 | Train Loss: 0.2480048 Vali Loss: 0.2322872 Test Loss: 0.2637130
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.2537921
	speed: 0.5084s/iter; left time: 1830.2671s
Epoch: 74 cost time: 27.152852535247803
Epoch: 74, Steps: 137 | Train Loss: 0.2479671 Vali Loss: 0.2323376 Test Loss: 0.2636980
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.2517994
	speed: 0.4895s/iter; left time: 1695.0927s
Epoch: 75 cost time: 27.313687086105347
Epoch: 75, Steps: 137 | Train Loss: 0.2480315 Vali Loss: 0.2322468 Test Loss: 0.2636825
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.2407748
	speed: 0.4892s/iter; left time: 1627.0845s
Epoch: 76 cost time: 27.24103879928589
Epoch: 76, Steps: 137 | Train Loss: 0.2479556 Vali Loss: 0.2318366 Test Loss: 0.2636663
Validation loss decreased (0.231964 --> 0.231837).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.2502792
	speed: 0.4901s/iter; left time: 1563.0486s
Epoch: 77 cost time: 27.57978320121765
Epoch: 77, Steps: 137 | Train Loss: 0.2478813 Vali Loss: 0.2324456 Test Loss: 0.2636515
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.2584153
	speed: 0.4902s/iter; left time: 1496.0814s
Epoch: 78 cost time: 27.602521419525146
Epoch: 78, Steps: 137 | Train Loss: 0.2478386 Vali Loss: 0.2320902 Test Loss: 0.2636399
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.2509403
	speed: 0.4867s/iter; left time: 1418.7650s
Epoch: 79 cost time: 27.244089365005493
Epoch: 79, Steps: 137 | Train Loss: 0.2477955 Vali Loss: 0.2319274 Test Loss: 0.2636286
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.2504004
	speed: 0.4871s/iter; left time: 1353.1427s
Epoch: 80 cost time: 27.333871603012085
Epoch: 80, Steps: 137 | Train Loss: 0.2478587 Vali Loss: 0.2324740 Test Loss: 0.2636155
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.2417168
	speed: 0.4894s/iter; left time: 1292.5862s
Epoch: 81 cost time: 27.43096375465393
Epoch: 81, Steps: 137 | Train Loss: 0.2479416 Vali Loss: 0.2322720 Test Loss: 0.2636065
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.2399107
	speed: 0.4912s/iter; left time: 1229.8410s
Epoch: 82 cost time: 27.486320972442627
Epoch: 82, Steps: 137 | Train Loss: 0.2477929 Vali Loss: 0.2321083 Test Loss: 0.2635974
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.2441282
	speed: 0.4881s/iter; left time: 1155.3047s
Epoch: 83 cost time: 26.82633924484253
Epoch: 83, Steps: 137 | Train Loss: 0.2478509 Vali Loss: 0.2318243 Test Loss: 0.2635874
Validation loss decreased (0.231837 --> 0.231824).  Saving model ...
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.2539999
	speed: 0.4915s/iter; left time: 1096.0808s
Epoch: 84 cost time: 27.940716981887817
Epoch: 84, Steps: 137 | Train Loss: 0.2477531 Vali Loss: 0.2321198 Test Loss: 0.2635800
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.2617033
	speed: 0.4960s/iter; left time: 1038.0290s
Epoch: 85 cost time: 26.861608743667603
Epoch: 85, Steps: 137 | Train Loss: 0.2477437 Vali Loss: 0.2317218 Test Loss: 0.2635716
Validation loss decreased (0.231824 --> 0.231722).  Saving model ...
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.2596393
	speed: 0.4846s/iter; left time: 947.8829s
Epoch: 86 cost time: 27.043167114257812
Epoch: 86, Steps: 137 | Train Loss: 0.2477146 Vali Loss: 0.2319005 Test Loss: 0.2635653
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.2379131
	speed: 0.4991s/iter; left time: 907.9184s
Epoch: 87 cost time: 27.12307596206665
Epoch: 87, Steps: 137 | Train Loss: 0.2478443 Vali Loss: 0.2317880 Test Loss: 0.2635585
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.2472952
	speed: 0.4834s/iter; left time: 813.1234s
Epoch: 88 cost time: 26.987993955612183
Epoch: 88, Steps: 137 | Train Loss: 0.2477418 Vali Loss: 0.2322883 Test Loss: 0.2635502
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.2551957
	speed: 0.4962s/iter; left time: 766.6308s
Epoch: 89 cost time: 26.599209785461426
Epoch: 89, Steps: 137 | Train Loss: 0.2477761 Vali Loss: 0.2321755 Test Loss: 0.2635463
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.2489632
	speed: 0.5040s/iter; left time: 709.6272s
Epoch: 90 cost time: 28.12762427330017
Epoch: 90, Steps: 137 | Train Loss: 0.2477676 Vali Loss: 0.2316609 Test Loss: 0.2635384
Validation loss decreased (0.231722 --> 0.231661).  Saving model ...
Updating learning rate to 5.204402478767869e-06
	iters: 100, epoch: 91 | loss: 0.2494995
	speed: 0.4993s/iter; left time: 634.5745s
Epoch: 91 cost time: 27.79633617401123
Epoch: 91, Steps: 137 | Train Loss: 0.2476825 Vali Loss: 0.2316963 Test Loss: 0.2635350
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.944182354829475e-06
	iters: 100, epoch: 92 | loss: 0.2518699
	speed: 0.4937s/iter; left time: 559.8333s
Epoch: 92 cost time: 26.60459017753601
Epoch: 92, Steps: 137 | Train Loss: 0.2476794 Vali Loss: 0.2317766 Test Loss: 0.2635285
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.696973237088e-06
	iters: 100, epoch: 93 | loss: 0.2458522
	speed: 0.4800s/iter; left time: 478.5601s
Epoch: 93 cost time: 26.54613447189331
Epoch: 93, Steps: 137 | Train Loss: 0.2477377 Vali Loss: 0.2320913 Test Loss: 0.2635223
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.462124575233601e-06
	iters: 100, epoch: 94 | loss: 0.2373838
	speed: 0.4891s/iter; left time: 420.6141s
Epoch: 94 cost time: 27.215954065322876
Epoch: 94, Steps: 137 | Train Loss: 0.2478165 Vali Loss: 0.2315457 Test Loss: 0.2635183
Validation loss decreased (0.231661 --> 0.231546).  Saving model ...
Updating learning rate to 4.239018346471921e-06
	iters: 100, epoch: 95 | loss: 0.2394025
	speed: 0.4843s/iter; left time: 350.1716s
Epoch: 95 cost time: 26.582074880599976
Epoch: 95, Steps: 137 | Train Loss: 0.2477703 Vali Loss: 0.2321953 Test Loss: 0.2635132
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.027067429148324e-06
	iters: 100, epoch: 96 | loss: 0.2628045
	speed: 0.4903s/iter; left time: 287.2979s
Epoch: 96 cost time: 27.857274293899536
Epoch: 96, Steps: 137 | Train Loss: 0.2476855 Vali Loss: 0.2318200 Test Loss: 0.2635092
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.825714057690908e-06
	iters: 100, epoch: 97 | loss: 0.2488882
	speed: 0.5173s/iter; left time: 232.2690s
Epoch: 97 cost time: 27.758068561553955
Epoch: 97, Steps: 137 | Train Loss: 0.2477265 Vali Loss: 0.2321145 Test Loss: 0.2635052
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.6344283548063623e-06
	iters: 100, epoch: 98 | loss: 0.2485274
	speed: 0.5274s/iter; left time: 164.5591s
Epoch: 98 cost time: 30.081223487854004
Epoch: 98, Steps: 137 | Train Loss: 0.2477260 Vali Loss: 0.2317720 Test Loss: 0.2635010
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.452706937066044e-06
	iters: 100, epoch: 99 | loss: 0.2440859
	speed: 0.4918s/iter; left time: 86.0650s
Epoch: 99 cost time: 27.862082958221436
Epoch: 99, Steps: 137 | Train Loss: 0.2477421 Vali Loss: 0.2315333 Test Loss: 0.2634974
Validation loss decreased (0.231546 --> 0.231533).  Saving model ...
Updating learning rate to 3.2800715902127414e-06
	iters: 100, epoch: 100 | loss: 0.2461672
	speed: 0.4942s/iter; left time: 18.7804s
Epoch: 100 cost time: 27.407336950302124
Epoch: 100, Steps: 137 | Train Loss: 0.2476875 Vali Loss: 0.2322873 Test Loss: 0.2634947
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1160680107021042e-06
train 17603
val 1913
test 4541
Model(
  (freq_upsampler): Linear(in_features=34, out_features=306, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  427479552.0
params:  10710.0
Trainable parameters:  10710
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2718097
	speed: 0.2100s/iter; left time: 2856.5219s
Epoch: 1 cost time: 28.014132976531982
Epoch: 1, Steps: 137 | Train Loss: 0.2766732 Vali Loss: 0.2315151 Test Loss: 0.2628470
Validation loss decreased (inf --> 0.231515).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2680045
	speed: 0.5235s/iter; left time: 7047.9466s
Epoch: 2 cost time: 30.817569255828857
Epoch: 2, Steps: 137 | Train Loss: 0.2763984 Vali Loss: 0.2312546 Test Loss: 0.2627822
Validation loss decreased (0.231515 --> 0.231255).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2656315
	speed: 0.4975s/iter; left time: 6629.7684s
Epoch: 3 cost time: 27.79039716720581
Epoch: 3, Steps: 137 | Train Loss: 0.2763488 Vali Loss: 0.2308092 Test Loss: 0.2626318
Validation loss decreased (0.231255 --> 0.230809).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2718253
	speed: 0.5132s/iter; left time: 6769.1493s
Epoch: 4 cost time: 27.146973609924316
Epoch: 4, Steps: 137 | Train Loss: 0.2762602 Vali Loss: 0.2312260 Test Loss: 0.2626847
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2816478
	speed: 0.5187s/iter; left time: 6770.2730s
Epoch: 5 cost time: 28.37565279006958
Epoch: 5, Steps: 137 | Train Loss: 0.2762601 Vali Loss: 0.2308907 Test Loss: 0.2626201
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2868988
	speed: 0.4918s/iter; left time: 6352.4320s
Epoch: 6 cost time: 27.204823970794678
Epoch: 6, Steps: 137 | Train Loss: 0.2761587 Vali Loss: 0.2308778 Test Loss: 0.2626501
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2723375
	speed: 0.4929s/iter; left time: 6299.1784s
Epoch: 7 cost time: 27.952996492385864
Epoch: 7, Steps: 137 | Train Loss: 0.2761902 Vali Loss: 0.2311194 Test Loss: 0.2626530
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2806817
	speed: 0.5371s/iter; left time: 6789.6160s
Epoch: 8 cost time: 28.508123874664307
Epoch: 8, Steps: 137 | Train Loss: 0.2762140 Vali Loss: 0.2313761 Test Loss: 0.2626358
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2919235
	speed: 0.5059s/iter; left time: 6326.3233s
Epoch: 9 cost time: 28.58854627609253
Epoch: 9, Steps: 137 | Train Loss: 0.2762011 Vali Loss: 0.2308850 Test Loss: 0.2626248
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2621490
	speed: 0.4995s/iter; left time: 6178.0152s
Epoch: 10 cost time: 26.409389972686768
Epoch: 10, Steps: 137 | Train Loss: 0.2761741 Vali Loss: 0.2308595 Test Loss: 0.2626623
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2769330
	speed: 0.5216s/iter; left time: 6379.1530s
Epoch: 11 cost time: 28.468987226486206
Epoch: 11, Steps: 137 | Train Loss: 0.2761952 Vali Loss: 0.2307043 Test Loss: 0.2626489
Validation loss decreased (0.230809 --> 0.230704).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2768770
	speed: 0.5259s/iter; left time: 6360.7386s
Epoch: 12 cost time: 29.594138860702515
Epoch: 12, Steps: 137 | Train Loss: 0.2761732 Vali Loss: 0.2312578 Test Loss: 0.2626374
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2713692
	speed: 0.5150s/iter; left time: 6157.5686s
Epoch: 13 cost time: 28.01706051826477
Epoch: 13, Steps: 137 | Train Loss: 0.2761836 Vali Loss: 0.2311169 Test Loss: 0.2626288
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2844216
	speed: 0.5165s/iter; left time: 6104.6806s
Epoch: 14 cost time: 26.62558650970459
Epoch: 14, Steps: 137 | Train Loss: 0.2761408 Vali Loss: 0.2309721 Test Loss: 0.2625700
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2627775
	speed: 0.5472s/iter; left time: 6393.1654s
Epoch: 15 cost time: 31.277247667312622
Epoch: 15, Steps: 137 | Train Loss: 0.2760789 Vali Loss: 0.2307124 Test Loss: 0.2626616
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2765100
	speed: 0.5019s/iter; left time: 5794.9651s
Epoch: 16 cost time: 27.12212562561035
Epoch: 16, Steps: 137 | Train Loss: 0.2761127 Vali Loss: 0.2306863 Test Loss: 0.2625864
Validation loss decreased (0.230704 --> 0.230686).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2773297
	speed: 0.5094s/iter; left time: 5811.3678s
Epoch: 17 cost time: 26.922614812850952
Epoch: 17, Steps: 137 | Train Loss: 0.2760375 Vali Loss: 0.2311730 Test Loss: 0.2625976
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2660829
	speed: 0.5085s/iter; left time: 5731.8382s
Epoch: 18 cost time: 30.11089038848877
Epoch: 18, Steps: 137 | Train Loss: 0.2760891 Vali Loss: 0.2310989 Test Loss: 0.2626283
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2805600
	speed: 0.4935s/iter; left time: 5495.5252s
Epoch: 19 cost time: 27.49924612045288
Epoch: 19, Steps: 137 | Train Loss: 0.2759617 Vali Loss: 0.2307942 Test Loss: 0.2626274
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2725051
	speed: 0.5169s/iter; left time: 5684.6467s
Epoch: 20 cost time: 27.566975355148315
Epoch: 20, Steps: 137 | Train Loss: 0.2760538 Vali Loss: 0.2311230 Test Loss: 0.2625953
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2731655
	speed: 0.5183s/iter; left time: 5629.4374s
Epoch: 21 cost time: 28.141467094421387
Epoch: 21, Steps: 137 | Train Loss: 0.2760753 Vali Loss: 0.2303550 Test Loss: 0.2626512
Validation loss decreased (0.230686 --> 0.230355).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2714588
	speed: 0.4911s/iter; left time: 5266.6527s
Epoch: 22 cost time: 27.453149795532227
Epoch: 22, Steps: 137 | Train Loss: 0.2760782 Vali Loss: 0.2305834 Test Loss: 0.2626079
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2740228
	speed: 0.4817s/iter; left time: 5099.6597s
Epoch: 23 cost time: 26.88890027999878
Epoch: 23, Steps: 137 | Train Loss: 0.2761295 Vali Loss: 0.2310863 Test Loss: 0.2626112
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2811873
	speed: 0.4918s/iter; left time: 5139.3028s
Epoch: 24 cost time: 27.527013778686523
Epoch: 24, Steps: 137 | Train Loss: 0.2760148 Vali Loss: 0.2309925 Test Loss: 0.2626010
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2727466
	speed: 0.5264s/iter; left time: 5429.1558s
Epoch: 25 cost time: 29.810524225234985
Epoch: 25, Steps: 137 | Train Loss: 0.2761512 Vali Loss: 0.2307723 Test Loss: 0.2626299
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2767192
	speed: 0.5186s/iter; left time: 5276.8865s
Epoch: 26 cost time: 28.678661346435547
Epoch: 26, Steps: 137 | Train Loss: 0.2761456 Vali Loss: 0.2304651 Test Loss: 0.2626502
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2770278
	speed: 0.4847s/iter; left time: 4865.9231s
Epoch: 27 cost time: 27.08476686477661
Epoch: 27, Steps: 137 | Train Loss: 0.2760631 Vali Loss: 0.2310762 Test Loss: 0.2625964
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2843078
	speed: 0.4578s/iter; left time: 4532.7770s
Epoch: 28 cost time: 24.012398958206177
Epoch: 28, Steps: 137 | Train Loss: 0.2759975 Vali Loss: 0.2305750 Test Loss: 0.2626099
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2916154
	speed: 0.4323s/iter; left time: 4221.6176s
Epoch: 29 cost time: 23.762373447418213
Epoch: 29, Steps: 137 | Train Loss: 0.2760463 Vali Loss: 0.2310443 Test Loss: 0.2626072
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2671524
	speed: 0.4509s/iter; left time: 4341.6392s
Epoch: 30 cost time: 24.149896144866943
Epoch: 30, Steps: 137 | Train Loss: 0.2761508 Vali Loss: 0.2306237 Test Loss: 0.2626274
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2768798
	speed: 0.4374s/iter; left time: 4151.8273s
Epoch: 31 cost time: 26.049068450927734
Epoch: 31, Steps: 137 | Train Loss: 0.2760483 Vali Loss: 0.2304836 Test Loss: 0.2625817
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2727615
	speed: 0.4541s/iter; left time: 4247.7680s
Epoch: 32 cost time: 24.242594480514526
Epoch: 32, Steps: 137 | Train Loss: 0.2761043 Vali Loss: 0.2310785 Test Loss: 0.2626137
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2858279
	speed: 0.4511s/iter; left time: 4157.6003s
Epoch: 33 cost time: 23.921770811080933
Epoch: 33, Steps: 137 | Train Loss: 0.2760942 Vali Loss: 0.2303976 Test Loss: 0.2626044
EarlyStopping counter: 12 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2787132
	speed: 0.4526s/iter; left time: 4109.8586s
Epoch: 34 cost time: 26.00160050392151
Epoch: 34, Steps: 137 | Train Loss: 0.2761114 Vali Loss: 0.2307601 Test Loss: 0.2626037
EarlyStopping counter: 13 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2680723
	speed: 0.4158s/iter; left time: 3718.0566s
Epoch: 35 cost time: 23.26021432876587
Epoch: 35, Steps: 137 | Train Loss: 0.2760751 Vali Loss: 0.2303441 Test Loss: 0.2626114
Validation loss decreased (0.230355 --> 0.230344).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2696183
	speed: 0.4245s/iter; left time: 3737.9584s
Epoch: 36 cost time: 23.764633178710938
Epoch: 36, Steps: 137 | Train Loss: 0.2760454 Vali Loss: 0.2306737 Test Loss: 0.2625799
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2714158
	speed: 0.4203s/iter; left time: 3643.2716s
Epoch: 37 cost time: 24.193548679351807
Epoch: 37, Steps: 137 | Train Loss: 0.2759998 Vali Loss: 0.2305184 Test Loss: 0.2626082
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2836441
	speed: 0.4844s/iter; left time: 4132.5209s
Epoch: 38 cost time: 24.72289204597473
Epoch: 38, Steps: 137 | Train Loss: 0.2760608 Vali Loss: 0.2308842 Test Loss: 0.2626048
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2794428
	speed: 0.4436s/iter; left time: 3724.3872s
Epoch: 39 cost time: 24.463364839553833
Epoch: 39, Steps: 137 | Train Loss: 0.2760189 Vali Loss: 0.2305620 Test Loss: 0.2626155
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2852349
	speed: 0.4454s/iter; left time: 3678.2772s
Epoch: 40 cost time: 24.617228746414185
Epoch: 40, Steps: 137 | Train Loss: 0.2761093 Vali Loss: 0.2304675 Test Loss: 0.2625972
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2662122
	speed: 0.4987s/iter; left time: 4050.0790s
Epoch: 41 cost time: 27.305238723754883
Epoch: 41, Steps: 137 | Train Loss: 0.2760317 Vali Loss: 0.2304911 Test Loss: 0.2625872
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2920872
	speed: 0.4300s/iter; left time: 3433.0556s
Epoch: 42 cost time: 24.730746746063232
Epoch: 42, Steps: 137 | Train Loss: 0.2760212 Vali Loss: 0.2310420 Test Loss: 0.2625965
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2924677
	speed: 0.4910s/iter; left time: 3852.5546s
Epoch: 43 cost time: 24.608133554458618
Epoch: 43, Steps: 137 | Train Loss: 0.2759356 Vali Loss: 0.2306902 Test Loss: 0.2626043
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2881364
	speed: 0.4077s/iter; left time: 3143.3716s
Epoch: 44 cost time: 22.86868691444397
Epoch: 44, Steps: 137 | Train Loss: 0.2761169 Vali Loss: 0.2304460 Test Loss: 0.2625827
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2832732
	speed: 0.4364s/iter; left time: 3304.7586s
Epoch: 45 cost time: 24.15758180618286
Epoch: 45, Steps: 137 | Train Loss: 0.2760009 Vali Loss: 0.2309362 Test Loss: 0.2625909
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2760663
	speed: 0.4376s/iter; left time: 3253.6382s
Epoch: 46 cost time: 23.171059608459473
Epoch: 46, Steps: 137 | Train Loss: 0.2760712 Vali Loss: 0.2309107 Test Loss: 0.2626020
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2736433
	speed: 0.4098s/iter; left time: 2991.1638s
Epoch: 47 cost time: 23.509927988052368
Epoch: 47, Steps: 137 | Train Loss: 0.2760736 Vali Loss: 0.2304800 Test Loss: 0.2626026
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2744377
	speed: 0.4948s/iter; left time: 3543.5547s
Epoch: 48 cost time: 25.336416006088257
Epoch: 48, Steps: 137 | Train Loss: 0.2759669 Vali Loss: 0.2306784 Test Loss: 0.2625984
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2926006
	speed: 0.4612s/iter; left time: 3239.6868s
Epoch: 49 cost time: 27.086034297943115
Epoch: 49, Steps: 137 | Train Loss: 0.2760343 Vali Loss: 0.2309304 Test Loss: 0.2625896
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2712133
	speed: 0.4754s/iter; left time: 3274.8302s
Epoch: 50 cost time: 23.502740144729614
Epoch: 50, Steps: 137 | Train Loss: 0.2760353 Vali Loss: 0.2309587 Test Loss: 0.2626086
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2717038
	speed: 0.4397s/iter; left time: 2968.3053s
Epoch: 51 cost time: 25.215561151504517
Epoch: 51, Steps: 137 | Train Loss: 0.2760667 Vali Loss: 0.2308853 Test Loss: 0.2626077
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2805200
	speed: 0.4461s/iter; left time: 2950.7209s
Epoch: 52 cost time: 23.304091930389404
Epoch: 52, Steps: 137 | Train Loss: 0.2759665 Vali Loss: 0.2306038 Test Loss: 0.2626043
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2882085
	speed: 0.4158s/iter; left time: 2692.8482s
Epoch: 53 cost time: 23.31952738761902
Epoch: 53, Steps: 137 | Train Loss: 0.2760091 Vali Loss: 0.2303767 Test Loss: 0.2625953
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2690310
	speed: 0.4163s/iter; left time: 2639.3021s
Epoch: 54 cost time: 23.402786254882812
Epoch: 54, Steps: 137 | Train Loss: 0.2760083 Vali Loss: 0.2305290 Test Loss: 0.2625925
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2745419
	speed: 0.4494s/iter; left time: 2787.3670s
Epoch: 55 cost time: 23.36624813079834
Epoch: 55, Steps: 137 | Train Loss: 0.2760434 Vali Loss: 0.2306553 Test Loss: 0.2625989
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_90_j720_H6_FITS_custom_ftM_sl90_ll48_pl720_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
mse:0.2625870406627655, mae:0.33378294110298157, rse:0.5111684799194336, corr:[0.43779662 0.43592417 0.43818033 0.43663788 0.4354776  0.43478346
 0.43472898 0.4344197  0.4340398  0.43370807 0.4333731  0.43317625
 0.43313965 0.43279552 0.43280166 0.4325052  0.43245304 0.43256637
 0.43252516 0.43248618 0.43213013 0.43196413 0.43141153 0.42975917
 0.42773673 0.4263256  0.4251311  0.42423007 0.42378315 0.42410594
 0.42504182 0.4255723  0.42555568 0.42541593 0.42521206 0.42504153
 0.4251174  0.42479786 0.42483962 0.42454723 0.42438334 0.42450714
 0.42448914 0.4245262  0.42446294 0.42463455 0.4244997  0.42388138
 0.42299154 0.4225179  0.4223361  0.42243618 0.42316818 0.4247369
 0.42686382 0.42854556 0.42897177 0.42903677 0.42898074 0.42879957
 0.428784   0.4284386  0.42861202 0.4286273  0.42872217 0.42895582
 0.42916998 0.42937377 0.42953643 0.43004107 0.43031135 0.43043587
 0.43061337 0.43103948 0.43161517 0.43263483 0.43435082 0.43698126
 0.44009933 0.44273132 0.44328234 0.44309127 0.44281882 0.44244704
 0.44226244 0.4418179  0.4419906  0.44196856 0.44215408 0.44251257
 0.44262627 0.44275066 0.4428033  0.44291744 0.4430506  0.4429967
 0.44276312 0.44278172 0.4426105  0.44250613 0.44254148 0.44271225
 0.44311762 0.4433294  0.443039   0.44275314 0.44242463 0.44212267
 0.44207206 0.44169432 0.44189432 0.4418995  0.44200516 0.44228008
 0.44231227 0.44237348 0.44240206 0.44248053 0.44261867 0.4426769
 0.44247413 0.44250965 0.44236836 0.44228798 0.44230446 0.4423154
 0.44253567 0.44260824 0.44235224 0.44211704 0.44178897 0.44151118
 0.4415282  0.44125685 0.44152862 0.44156092 0.44177124 0.44213036
 0.44225192 0.4424927  0.4426411  0.4427485  0.44280237 0.44265816
 0.44227305 0.4421376  0.44197565 0.4418696  0.44193244 0.44203776
 0.44229233 0.44240522 0.44205183 0.44173887 0.441344   0.44099167
 0.4410427  0.4408551  0.4411701  0.4412589  0.44156346 0.44199717
 0.44220656 0.44234404 0.44204772 0.4417903  0.44098118 0.43844467
 0.43553904 0.43315464 0.43134552 0.42986113 0.4288925  0.42845562
 0.42838603 0.4282838  0.4279021  0.42742932 0.42714384 0.42689326
 0.4268291  0.4264816  0.4265548  0.42623508 0.4261734  0.42635417
 0.4262412  0.42615348 0.42575508 0.42546904 0.42485133 0.42311203
 0.42087778 0.41938603 0.41823786 0.41729927 0.41702828 0.41754663
 0.4185552  0.41925728 0.4192325  0.4190068  0.41880873 0.4186009
 0.41871774 0.4184335  0.41848156 0.4181812  0.41811365 0.41828072
 0.41821262 0.4182346  0.4181428  0.41824564 0.4181029  0.417461
 0.41647667 0.41598788 0.4158195  0.41594887 0.416929   0.4186494
 0.42076045 0.4225971  0.42304367 0.42302978 0.4229838  0.42273602
 0.42270783 0.42243248 0.42262083 0.42261901 0.42274088 0.42299286
 0.42320216 0.42344537 0.42364407 0.42410332 0.42438647 0.42452937
 0.42459494 0.42506045 0.42569482 0.42667598 0.4285275  0.43115085
 0.43427393 0.43702734 0.43759182 0.43737084 0.4371841  0.43680844
 0.43661064 0.4362371  0.43641743 0.43636242 0.43661734 0.436992
 0.43706447 0.43726805 0.43735373 0.43745643 0.4376608  0.4376395
 0.43736464 0.43732473 0.43715194 0.43711787 0.43725047 0.43743005
 0.4378664  0.43814877 0.43781847 0.43748108 0.43716478 0.43680197
 0.4367032  0.43633524 0.43652484 0.43647334 0.43662506 0.43693843
 0.43692794 0.4370056  0.4370627  0.43716273 0.4373303  0.43734878
 0.43712193 0.43716487 0.4370132  0.43692786 0.43703657 0.43706116
 0.43732098 0.43741354 0.4370522  0.4368336  0.43654335 0.43622208
 0.43624482 0.43596655 0.43620712 0.43625972 0.43648848 0.43684882
 0.43697646 0.43722636 0.437381   0.43751177 0.43756044 0.43737453
 0.4369803  0.43679348 0.43657514 0.43651998 0.436697   0.43676463
 0.43705207 0.4372095  0.4368106  0.4365389  0.43619394 0.435797
 0.4358435  0.43561903 0.43584296 0.43592826 0.43625006 0.43662387
 0.43675363 0.4368445  0.43647352 0.4361498  0.43521696 0.4325067
 0.4295152  0.42714262 0.4252583  0.42384285 0.42296153 0.4225282
 0.4225456  0.4224521  0.42200577 0.4214915  0.4210964  0.4207485
 0.4206496  0.420275   0.4202681  0.4199565  0.41994396 0.42004687
 0.41990948 0.41985556 0.41947082 0.41927806 0.41860053 0.4166481
 0.41430962 0.4126823  0.4114035  0.41059238 0.41044822 0.41092864
 0.41195244 0.41266444 0.4125787  0.4123331  0.41208288 0.41176662
 0.41184413 0.41155535 0.41158026 0.41133434 0.411273   0.41140667
 0.41133213 0.411418   0.4113565  0.41152477 0.4113841  0.410626
 0.4095699  0.40908167 0.40901613 0.40937373 0.41050327 0.41233802
 0.4146701  0.4165346  0.4169522  0.41702318 0.41692984 0.41665003
 0.41666195 0.4163415  0.41650036 0.41654304 0.41668868 0.41697952
 0.41719002 0.41745284 0.41767693 0.41818908 0.4184984  0.4185897
 0.41866207 0.4191475  0.41987875 0.42117885 0.42324    0.42603454
 0.42944187 0.4322095  0.43281084 0.4327494  0.43255642 0.4321407
 0.43201405 0.4316411  0.43178684 0.43179587 0.43204242 0.43238646
 0.4325062  0.43272626 0.43282762 0.43298247 0.43322524 0.43318743
 0.43286958 0.43281692 0.4327275  0.4327714  0.43294242 0.4331727
 0.43368068 0.4339138  0.43356836 0.43329117 0.43285766 0.43243888
 0.4323889  0.43203294 0.43217167 0.43215525 0.43229377 0.43259874
 0.43263945 0.43272486 0.4327998  0.43293756 0.43312508 0.4331724
 0.43295863 0.43299326 0.43293273 0.43293878 0.43305594 0.43310145
 0.43337917 0.4334066  0.43306017 0.43288302 0.43249974 0.43215477
 0.43219674 0.43194082 0.43221775 0.43231982 0.43249497 0.43283534
 0.43300742 0.43323687 0.4334195  0.43360317 0.43370464 0.43356812
 0.43319756 0.43303972 0.43291172 0.43287906 0.4330423  0.43316677
 0.43347856 0.43356386 0.4331684  0.43292347 0.43249968 0.43213776
 0.43221232 0.43199798 0.4322424  0.43238148 0.43268368 0.43306285
 0.43324077 0.43328696 0.43297422 0.4327054  0.43177736 0.42913178
 0.4261792  0.42371246 0.42189074 0.4205487  0.41968834 0.41933855
 0.4193084  0.419118   0.41869375 0.41819376 0.41775534 0.41741687
 0.4173429  0.4169658  0.41691807 0.41662776 0.41658118 0.41671306
 0.4166116  0.4164605  0.4160959  0.4158898  0.41517052 0.41323552
 0.41082385 0.4091228  0.40801445 0.40722603 0.40700403 0.40753955
 0.4085119  0.40906078 0.4089162  0.4085878  0.40828705 0.40808386
 0.4081476  0.40785566 0.40792617 0.407675   0.40752792 0.40771136
 0.4076715  0.4076465  0.4076583  0.407857   0.40768012 0.40694296
 0.40585968 0.4052834  0.40524435 0.40554827 0.4066187  0.4084816
 0.41071966 0.4124256  0.41285208 0.41278094 0.41259187 0.41234955
 0.41225395 0.4119356  0.41210505 0.41205955 0.4120914  0.412286
 0.41241786 0.41261277 0.41283613 0.4133342  0.4136563  0.41379324
 0.4138892  0.41431916 0.4151181  0.41634476 0.4182966  0.42111018
 0.42433622 0.4269302  0.42755458 0.42733073 0.42697293 0.42667088
 0.4264843  0.42611107 0.4263623  0.42635453 0.4265033  0.4268805
 0.42697436 0.42713    0.42729273 0.42743155 0.4276655  0.4276279
 0.42727777 0.42722708 0.4271556  0.42714685 0.42730808 0.42758238
 0.42799944 0.42810017 0.42776722 0.4273688  0.42690542 0.42661348
 0.42647    0.42608717 0.42635897 0.4263499  0.426346   0.42666593
 0.4267137  0.42677027 0.42688063 0.42696434 0.42717928 0.4272771
 0.42703596 0.42709413 0.4270697  0.42706215 0.4272121  0.42731285
 0.4275298  0.42751196 0.42722067 0.4269031  0.4264869  0.42622676
 0.42618936 0.42595112 0.42624667 0.42626175 0.42638242 0.4267822
 0.42685303 0.42702743 0.42723384 0.42733404 0.42747107 0.42733595
 0.42686468 0.42678195 0.42670304 0.42665732 0.4268877  0.4270833
 0.4272984  0.427354   0.42705226 0.42666087 0.42626524 0.425981
 0.42592853 0.42573932 0.42604434 0.42609876 0.4262655  0.42665824
 0.42665863 0.42664462 0.42642292 0.42602438 0.4252042  0.4226408
 0.41940916 0.41708028 0.41531086 0.41393638 0.4132478  0.4128698
 0.41283062 0.4127771  0.41236255 0.4116487  0.41129184 0.410947
 0.41066682 0.41028762 0.41029254 0.40975532 0.40957156 0.40992737
 0.40942895 0.40937626 0.40923297 0.40868935 0.40838316 0.40666485
 0.40407386 0.40286598 0.40166065 0.40087223 0.400956   0.40152374
 0.40230355 0.40319178 0.4032274  0.40226287 0.4024408  0.401916
 0.40128672 0.40090328 0.40064487 0.39934596 0.3988087  0.39504004
 0.39689758 0.39362144 0.39338064 0.3948208  0.39378357 0.38423306]
