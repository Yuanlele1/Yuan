Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=42, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_90_j96_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=10, pred_len=96, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_90_j96_H8_FITS_custom_ftM_sl90_ll48_pl96_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 12095
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=42, out_features=86, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  398533632.0
params:  3698.0
Trainable parameters:  3698
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 15.117178440093994
Epoch: 1, Steps: 94 | Train Loss: 1.0814131 Vali Loss: 1.2279786 Test Loss: 1.4113902
Validation loss decreased (inf --> 1.227979).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 14.55269455909729
Epoch: 2, Steps: 94 | Train Loss: 0.7356238 Vali Loss: 0.9911198 Test Loss: 1.1404662
Validation loss decreased (1.227979 --> 0.991120).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 14.76721715927124
Epoch: 3, Steps: 94 | Train Loss: 0.5723949 Vali Loss: 0.8701674 Test Loss: 1.0022209
Validation loss decreased (0.991120 --> 0.870167).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 14.629922151565552
Epoch: 4, Steps: 94 | Train Loss: 0.4782619 Vali Loss: 0.7983260 Test Loss: 0.9227611
Validation loss decreased (0.870167 --> 0.798326).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 14.775773763656616
Epoch: 5, Steps: 94 | Train Loss: 0.4185886 Vali Loss: 0.7513828 Test Loss: 0.8697715
Validation loss decreased (0.798326 --> 0.751383).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 14.457038879394531
Epoch: 6, Steps: 94 | Train Loss: 0.3779715 Vali Loss: 0.7197643 Test Loss: 0.8354740
Validation loss decreased (0.751383 --> 0.719764).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 14.380293607711792
Epoch: 7, Steps: 94 | Train Loss: 0.3492706 Vali Loss: 0.6955585 Test Loss: 0.8106650
Validation loss decreased (0.719764 --> 0.695559).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 14.477123022079468
Epoch: 8, Steps: 94 | Train Loss: 0.3281831 Vali Loss: 0.6774867 Test Loss: 0.7913727
Validation loss decreased (0.695559 --> 0.677487).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 14.359782695770264
Epoch: 9, Steps: 94 | Train Loss: 0.3123334 Vali Loss: 0.6664354 Test Loss: 0.7767906
Validation loss decreased (0.677487 --> 0.666435).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 14.025174140930176
Epoch: 10, Steps: 94 | Train Loss: 0.3001167 Vali Loss: 0.6545022 Test Loss: 0.7651376
Validation loss decreased (0.666435 --> 0.654502).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 14.559005498886108
Epoch: 11, Steps: 94 | Train Loss: 0.2906132 Vali Loss: 0.6477838 Test Loss: 0.7556931
Validation loss decreased (0.654502 --> 0.647784).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 15.080406427383423
Epoch: 12, Steps: 94 | Train Loss: 0.2829104 Vali Loss: 0.6396198 Test Loss: 0.7480915
Validation loss decreased (0.647784 --> 0.639620).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 13.94924807548523
Epoch: 13, Steps: 94 | Train Loss: 0.2769408 Vali Loss: 0.6323161 Test Loss: 0.7415707
Validation loss decreased (0.639620 --> 0.632316).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 14.889561891555786
Epoch: 14, Steps: 94 | Train Loss: 0.2719675 Vali Loss: 0.6289274 Test Loss: 0.7362623
Validation loss decreased (0.632316 --> 0.628927).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 13.786856412887573
Epoch: 15, Steps: 94 | Train Loss: 0.2678640 Vali Loss: 0.6241019 Test Loss: 0.7316043
Validation loss decreased (0.628927 --> 0.624102).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 14.982619762420654
Epoch: 16, Steps: 94 | Train Loss: 0.2645001 Vali Loss: 0.6209540 Test Loss: 0.7275824
Validation loss decreased (0.624102 --> 0.620954).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 14.088862180709839
Epoch: 17, Steps: 94 | Train Loss: 0.2615830 Vali Loss: 0.6180955 Test Loss: 0.7241647
Validation loss decreased (0.620954 --> 0.618095).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 15.049328565597534
Epoch: 18, Steps: 94 | Train Loss: 0.2590618 Vali Loss: 0.6146284 Test Loss: 0.7211803
Validation loss decreased (0.618095 --> 0.614628).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 13.306405782699585
Epoch: 19, Steps: 94 | Train Loss: 0.2569247 Vali Loss: 0.6121589 Test Loss: 0.7185181
Validation loss decreased (0.614628 --> 0.612159).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 15.047680616378784
Epoch: 20, Steps: 94 | Train Loss: 0.2551449 Vali Loss: 0.6108999 Test Loss: 0.7161682
Validation loss decreased (0.612159 --> 0.610900).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 14.167064189910889
Epoch: 21, Steps: 94 | Train Loss: 0.2535368 Vali Loss: 0.6083437 Test Loss: 0.7141598
Validation loss decreased (0.610900 --> 0.608344).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 15.021798372268677
Epoch: 22, Steps: 94 | Train Loss: 0.2521952 Vali Loss: 0.6067802 Test Loss: 0.7122236
Validation loss decreased (0.608344 --> 0.606780).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 14.583922386169434
Epoch: 23, Steps: 94 | Train Loss: 0.2509136 Vali Loss: 0.6068550 Test Loss: 0.7106086
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 14.365952730178833
Epoch: 24, Steps: 94 | Train Loss: 0.2497989 Vali Loss: 0.6037125 Test Loss: 0.7091116
Validation loss decreased (0.606780 --> 0.603712).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 15.089696168899536
Epoch: 25, Steps: 94 | Train Loss: 0.2487307 Vali Loss: 0.6028277 Test Loss: 0.7077566
Validation loss decreased (0.603712 --> 0.602828).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 14.671785593032837
Epoch: 26, Steps: 94 | Train Loss: 0.2479145 Vali Loss: 0.6012127 Test Loss: 0.7064252
Validation loss decreased (0.602828 --> 0.601213).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 15.136866331100464
Epoch: 27, Steps: 94 | Train Loss: 0.2469950 Vali Loss: 0.6008816 Test Loss: 0.7052417
Validation loss decreased (0.601213 --> 0.600882).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 14.298776388168335
Epoch: 28, Steps: 94 | Train Loss: 0.2463332 Vali Loss: 0.6012823 Test Loss: 0.7043429
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 15.053191661834717
Epoch: 29, Steps: 94 | Train Loss: 0.2455991 Vali Loss: 0.5994192 Test Loss: 0.7032601
Validation loss decreased (0.600882 --> 0.599419).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 13.914996147155762
Epoch: 30, Steps: 94 | Train Loss: 0.2449329 Vali Loss: 0.5985385 Test Loss: 0.7024552
Validation loss decreased (0.599419 --> 0.598538).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 14.695310592651367
Epoch: 31, Steps: 94 | Train Loss: 0.2443052 Vali Loss: 0.5993339 Test Loss: 0.7015911
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 13.895560026168823
Epoch: 32, Steps: 94 | Train Loss: 0.2438101 Vali Loss: 0.5972291 Test Loss: 0.7008188
Validation loss decreased (0.598538 --> 0.597229).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 14.361998796463013
Epoch: 33, Steps: 94 | Train Loss: 0.2433415 Vali Loss: 0.5984357 Test Loss: 0.7001098
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 13.74434494972229
Epoch: 34, Steps: 94 | Train Loss: 0.2428880 Vali Loss: 0.5959797 Test Loss: 0.6994228
Validation loss decreased (0.597229 --> 0.595980).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 14.855290412902832
Epoch: 35, Steps: 94 | Train Loss: 0.2424316 Vali Loss: 0.5957912 Test Loss: 0.6988181
Validation loss decreased (0.595980 --> 0.595791).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 14.152883291244507
Epoch: 36, Steps: 94 | Train Loss: 0.2420581 Vali Loss: 0.5962763 Test Loss: 0.6983058
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 14.970069885253906
Epoch: 37, Steps: 94 | Train Loss: 0.2416076 Vali Loss: 0.5946863 Test Loss: 0.6977406
Validation loss decreased (0.595791 --> 0.594686).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 14.655882835388184
Epoch: 38, Steps: 94 | Train Loss: 0.2413151 Vali Loss: 0.5943910 Test Loss: 0.6972489
Validation loss decreased (0.594686 --> 0.594391).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 14.372838020324707
Epoch: 39, Steps: 94 | Train Loss: 0.2409859 Vali Loss: 0.5941848 Test Loss: 0.6967487
Validation loss decreased (0.594391 --> 0.594185).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 14.666299819946289
Epoch: 40, Steps: 94 | Train Loss: 0.2406551 Vali Loss: 0.5947023 Test Loss: 0.6963193
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 13.610947608947754
Epoch: 41, Steps: 94 | Train Loss: 0.2403564 Vali Loss: 0.5937879 Test Loss: 0.6959408
Validation loss decreased (0.594185 --> 0.593788).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 15.003854274749756
Epoch: 42, Steps: 94 | Train Loss: 0.2401028 Vali Loss: 0.5921431 Test Loss: 0.6955228
Validation loss decreased (0.593788 --> 0.592143).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 13.768409967422485
Epoch: 43, Steps: 94 | Train Loss: 0.2398717 Vali Loss: 0.5910572 Test Loss: 0.6951679
Validation loss decreased (0.592143 --> 0.591057).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 14.876329898834229
Epoch: 44, Steps: 94 | Train Loss: 0.2395548 Vali Loss: 0.5922381 Test Loss: 0.6947974
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 14.083333492279053
Epoch: 45, Steps: 94 | Train Loss: 0.2392217 Vali Loss: 0.5925995 Test Loss: 0.6944942
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 14.802853345870972
Epoch: 46, Steps: 94 | Train Loss: 0.2391204 Vali Loss: 0.5908519 Test Loss: 0.6941963
Validation loss decreased (0.591057 --> 0.590852).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 13.724794387817383
Epoch: 47, Steps: 94 | Train Loss: 0.2388401 Vali Loss: 0.5917165 Test Loss: 0.6939042
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 14.418767213821411
Epoch: 48, Steps: 94 | Train Loss: 0.2386613 Vali Loss: 0.5917524 Test Loss: 0.6936158
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 14.031539916992188
Epoch: 49, Steps: 94 | Train Loss: 0.2384910 Vali Loss: 0.5927132 Test Loss: 0.6933600
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 14.554566383361816
Epoch: 50, Steps: 94 | Train Loss: 0.2382824 Vali Loss: 0.5913255 Test Loss: 0.6931012
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 13.576709270477295
Epoch: 51, Steps: 94 | Train Loss: 0.2381537 Vali Loss: 0.5890008 Test Loss: 0.6928681
Validation loss decreased (0.590852 --> 0.589001).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 14.089707136154175
Epoch: 52, Steps: 94 | Train Loss: 0.2380142 Vali Loss: 0.5884241 Test Loss: 0.6926646
Validation loss decreased (0.589001 --> 0.588424).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 14.673837184906006
Epoch: 53, Steps: 94 | Train Loss: 0.2377491 Vali Loss: 0.5903434 Test Loss: 0.6924669
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 13.906965732574463
Epoch: 54, Steps: 94 | Train Loss: 0.2377005 Vali Loss: 0.5906685 Test Loss: 0.6922503
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 14.748744010925293
Epoch: 55, Steps: 94 | Train Loss: 0.2374960 Vali Loss: 0.5895507 Test Loss: 0.6920604
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 14.121573448181152
Epoch: 56, Steps: 94 | Train Loss: 0.2373760 Vali Loss: 0.5889986 Test Loss: 0.6918797
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 12.235363721847534
Epoch: 57, Steps: 94 | Train Loss: 0.2372852 Vali Loss: 0.5893758 Test Loss: 0.6917148
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 12.105961084365845
Epoch: 58, Steps: 94 | Train Loss: 0.2371388 Vali Loss: 0.5885499 Test Loss: 0.6915643
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 12.124658584594727
Epoch: 59, Steps: 94 | Train Loss: 0.2370362 Vali Loss: 0.5898700 Test Loss: 0.6913858
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 14.115915536880493
Epoch: 60, Steps: 94 | Train Loss: 0.2369663 Vali Loss: 0.5887640 Test Loss: 0.6912616
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 14.456339597702026
Epoch: 61, Steps: 94 | Train Loss: 0.2367958 Vali Loss: 0.5866937 Test Loss: 0.6911151
Validation loss decreased (0.588424 --> 0.586694).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 14.395053148269653
Epoch: 62, Steps: 94 | Train Loss: 0.2367488 Vali Loss: 0.5890750 Test Loss: 0.6909891
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 14.0496985912323
Epoch: 63, Steps: 94 | Train Loss: 0.2366780 Vali Loss: 0.5880181 Test Loss: 0.6908658
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 13.492858171463013
Epoch: 64, Steps: 94 | Train Loss: 0.2365945 Vali Loss: 0.5867867 Test Loss: 0.6907485
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 13.553353309631348
Epoch: 65, Steps: 94 | Train Loss: 0.2364011 Vali Loss: 0.5869924 Test Loss: 0.6906376
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 13.856099843978882
Epoch: 66, Steps: 94 | Train Loss: 0.2364425 Vali Loss: 0.5883324 Test Loss: 0.6905309
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 13.467897891998291
Epoch: 67, Steps: 94 | Train Loss: 0.2362773 Vali Loss: 0.5885595 Test Loss: 0.6904395
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 13.386180877685547
Epoch: 68, Steps: 94 | Train Loss: 0.2362159 Vali Loss: 0.5858606 Test Loss: 0.6903438
Validation loss decreased (0.586694 --> 0.585861).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 13.509249210357666
Epoch: 69, Steps: 94 | Train Loss: 0.2361961 Vali Loss: 0.5881601 Test Loss: 0.6902394
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 13.245111227035522
Epoch: 70, Steps: 94 | Train Loss: 0.2361435 Vali Loss: 0.5891718 Test Loss: 0.6901613
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 13.547722339630127
Epoch: 71, Steps: 94 | Train Loss: 0.2360470 Vali Loss: 0.5878375 Test Loss: 0.6900800
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 13.861295223236084
Epoch: 72, Steps: 94 | Train Loss: 0.2360026 Vali Loss: 0.5863376 Test Loss: 0.6900112
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 13.830648422241211
Epoch: 73, Steps: 94 | Train Loss: 0.2359082 Vali Loss: 0.5882581 Test Loss: 0.6899421
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 13.462029695510864
Epoch: 74, Steps: 94 | Train Loss: 0.2358744 Vali Loss: 0.5895012 Test Loss: 0.6898555
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 13.707744836807251
Epoch: 75, Steps: 94 | Train Loss: 0.2358100 Vali Loss: 0.5865403 Test Loss: 0.6897920
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 13.744250297546387
Epoch: 76, Steps: 94 | Train Loss: 0.2358210 Vali Loss: 0.5859591 Test Loss: 0.6897189
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 13.480271577835083
Epoch: 77, Steps: 94 | Train Loss: 0.2357831 Vali Loss: 0.5868155 Test Loss: 0.6896602
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 13.514241218566895
Epoch: 78, Steps: 94 | Train Loss: 0.2356864 Vali Loss: 0.5881727 Test Loss: 0.6896182
EarlyStopping counter: 10 out of 10
Early stopping
train 12095
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=42, out_features=86, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  398533632.0
params:  3698.0
Trainable parameters:  3698
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 13.914667844772339
Epoch: 1, Steps: 94 | Train Loss: 0.4393605 Vali Loss: 0.5767403 Test Loss: 0.6799355
Validation loss decreased (inf --> 0.576740).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 13.76460862159729
Epoch: 2, Steps: 94 | Train Loss: 0.4354069 Vali Loss: 0.5772539 Test Loss: 0.6783214
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000475
Epoch: 3 cost time: 13.726776599884033
Epoch: 3, Steps: 94 | Train Loss: 0.4342631 Vali Loss: 0.5745817 Test Loss: 0.6780045
Validation loss decreased (0.576740 --> 0.574582).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 13.561762571334839
Epoch: 4, Steps: 94 | Train Loss: 0.4340119 Vali Loss: 0.5738940 Test Loss: 0.6778215
Validation loss decreased (0.574582 --> 0.573894).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 13.570921421051025
Epoch: 5, Steps: 94 | Train Loss: 0.4337414 Vali Loss: 0.5746735 Test Loss: 0.6778376
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 13.484742641448975
Epoch: 6, Steps: 94 | Train Loss: 0.4337091 Vali Loss: 0.5765687 Test Loss: 0.6776928
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 13.480974674224854
Epoch: 7, Steps: 94 | Train Loss: 0.4338337 Vali Loss: 0.5730186 Test Loss: 0.6774326
Validation loss decreased (0.573894 --> 0.573019).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 13.69373369216919
Epoch: 8, Steps: 94 | Train Loss: 0.4337059 Vali Loss: 0.5750504 Test Loss: 0.6770912
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 13.219734191894531
Epoch: 9, Steps: 94 | Train Loss: 0.4335083 Vali Loss: 0.5739152 Test Loss: 0.6774082
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 13.839861392974854
Epoch: 10, Steps: 94 | Train Loss: 0.4331359 Vali Loss: 0.5755447 Test Loss: 0.6769500
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 13.486031532287598
Epoch: 11, Steps: 94 | Train Loss: 0.4334223 Vali Loss: 0.5755333 Test Loss: 0.6770366
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 13.746091604232788
Epoch: 12, Steps: 94 | Train Loss: 0.4335439 Vali Loss: 0.5737010 Test Loss: 0.6771522
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 13.398260831832886
Epoch: 13, Steps: 94 | Train Loss: 0.4333632 Vali Loss: 0.5749332 Test Loss: 0.6771510
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 13.470867156982422
Epoch: 14, Steps: 94 | Train Loss: 0.4332720 Vali Loss: 0.5732183 Test Loss: 0.6770296
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 13.51114273071289
Epoch: 15, Steps: 94 | Train Loss: 0.4333371 Vali Loss: 0.5738162 Test Loss: 0.6771206
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 13.251508951187134
Epoch: 16, Steps: 94 | Train Loss: 0.4331830 Vali Loss: 0.5726033 Test Loss: 0.6770822
Validation loss decreased (0.573019 --> 0.572603).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 13.400166034698486
Epoch: 17, Steps: 94 | Train Loss: 0.4330801 Vali Loss: 0.5732146 Test Loss: 0.6768531
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 13.37586522102356
Epoch: 18, Steps: 94 | Train Loss: 0.4331050 Vali Loss: 0.5730650 Test Loss: 0.6770599
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 13.964656114578247
Epoch: 19, Steps: 94 | Train Loss: 0.4332678 Vali Loss: 0.5737928 Test Loss: 0.6768149
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 13.709899663925171
Epoch: 20, Steps: 94 | Train Loss: 0.4333079 Vali Loss: 0.5728804 Test Loss: 0.6770507
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 13.926066875457764
Epoch: 21, Steps: 94 | Train Loss: 0.4333157 Vali Loss: 0.5751027 Test Loss: 0.6768750
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 13.701443195343018
Epoch: 22, Steps: 94 | Train Loss: 0.4332190 Vali Loss: 0.5725375 Test Loss: 0.6769344
Validation loss decreased (0.572603 --> 0.572538).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 14.030148983001709
Epoch: 23, Steps: 94 | Train Loss: 0.4330784 Vali Loss: 0.5741471 Test Loss: 0.6769031
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 13.773053169250488
Epoch: 24, Steps: 94 | Train Loss: 0.4331761 Vali Loss: 0.5726132 Test Loss: 0.6768995
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 13.508216381072998
Epoch: 25, Steps: 94 | Train Loss: 0.4331726 Vali Loss: 0.5745035 Test Loss: 0.6769604
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 14.054157257080078
Epoch: 26, Steps: 94 | Train Loss: 0.4329552 Vali Loss: 0.5720487 Test Loss: 0.6768838
Validation loss decreased (0.572538 --> 0.572049).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 13.943434715270996
Epoch: 27, Steps: 94 | Train Loss: 0.4330751 Vali Loss: 0.5744334 Test Loss: 0.6769075
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 13.285606622695923
Epoch: 28, Steps: 94 | Train Loss: 0.4332418 Vali Loss: 0.5727937 Test Loss: 0.6767669
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 13.864769458770752
Epoch: 29, Steps: 94 | Train Loss: 0.4331520 Vali Loss: 0.5713992 Test Loss: 0.6767951
Validation loss decreased (0.572049 --> 0.571399).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 13.607454061508179
Epoch: 30, Steps: 94 | Train Loss: 0.4331564 Vali Loss: 0.5722453 Test Loss: 0.6768619
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 13.573482513427734
Epoch: 31, Steps: 94 | Train Loss: 0.4330799 Vali Loss: 0.5756494 Test Loss: 0.6768039
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 13.316980838775635
Epoch: 32, Steps: 94 | Train Loss: 0.4332340 Vali Loss: 0.5733544 Test Loss: 0.6767819
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 13.509849786758423
Epoch: 33, Steps: 94 | Train Loss: 0.4330826 Vali Loss: 0.5739642 Test Loss: 0.6767734
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 13.715684652328491
Epoch: 34, Steps: 94 | Train Loss: 0.4329843 Vali Loss: 0.5727823 Test Loss: 0.6768012
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 13.671085834503174
Epoch: 35, Steps: 94 | Train Loss: 0.4330971 Vali Loss: 0.5743387 Test Loss: 0.6766871
EarlyStopping counter: 6 out of 10
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 13.612754106521606
Epoch: 36, Steps: 94 | Train Loss: 0.4331617 Vali Loss: 0.5719389 Test Loss: 0.6767209
EarlyStopping counter: 7 out of 10
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 13.46715760231018
Epoch: 37, Steps: 94 | Train Loss: 0.4329562 Vali Loss: 0.5742717 Test Loss: 0.6767087
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 13.597798824310303
Epoch: 38, Steps: 94 | Train Loss: 0.4330146 Vali Loss: 0.5725380 Test Loss: 0.6767883
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 13.747171640396118
Epoch: 39, Steps: 94 | Train Loss: 0.4331718 Vali Loss: 0.5737997 Test Loss: 0.6768077
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : Traffic_90_j96_H8_FITS_custom_ftM_sl90_ll48_pl96_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3413
mse:0.6814639568328857, mae:0.40316975116729736, rse:0.6835572719573975, corr:[0.2677898  0.28653994 0.28695133 0.28534412 0.28581014 0.28709766
 0.2894478  0.29023755 0.28984484 0.28892714 0.28823218 0.28780392
 0.28689906 0.28651753 0.2860066  0.28648135 0.28737003 0.28833455
 0.290021   0.29100582 0.29269132 0.29347548 0.29413965 0.2943903
 0.29870188 0.3027814  0.3021167  0.30068916 0.30086252 0.30235004
 0.30362394 0.30503243 0.30495188 0.30396408 0.30360454 0.30285358
 0.30220342 0.30145258 0.30105364 0.30158633 0.30234498 0.30282748
 0.30389753 0.30479404 0.30516624 0.3051787  0.30526695 0.30387372
 0.30391175 0.30204353 0.30024606 0.29996583 0.29838118 0.29437554
 0.29163226 0.29236975 0.2924182  0.2915967  0.29035875 0.2890331
 0.28790805 0.28708595 0.28664854 0.2869591  0.28741583 0.28790253
 0.28885546 0.28982326 0.28971505 0.29050368 0.29031056 0.28866926
 0.28674963 0.28490105 0.28427988 0.28496128 0.2866488  0.28621927
 0.28615743 0.28805315 0.28815445 0.28770733 0.28650695 0.2859546
 0.28457326 0.28410977 0.28381458 0.28376707 0.28412443 0.28404534
 0.28499275 0.28515393 0.28595102 0.28550434 0.28606385 0.2842717 ]
