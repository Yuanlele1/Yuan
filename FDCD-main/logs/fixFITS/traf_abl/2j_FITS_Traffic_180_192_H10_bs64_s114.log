Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_180_j192_H10', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=10, pred_len=192, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_180_j192_H10_FITS_custom_ftM_sl180_ll48_pl192_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11909
val 1565
test 3317
Model(
  (freq_upsampler): Linear(in_features=90, out_features=186, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1847024640.0
params:  16926.0
Trainable parameters:  16926
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 100.59669661521912
Epoch: 1, Steps: 93 | Train Loss: 1.1000008 Vali Loss: 1.0935880 Test Loss: 1.3125234
Validation loss decreased (inf --> 1.093588).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 92.41221761703491
Epoch: 2, Steps: 93 | Train Loss: 0.6826442 Vali Loss: 0.8259537 Test Loss: 1.0029080
Validation loss decreased (1.093588 --> 0.825954).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 87.99462723731995
Epoch: 3, Steps: 93 | Train Loss: 0.5098437 Vali Loss: 0.6990698 Test Loss: 0.8581192
Validation loss decreased (0.825954 --> 0.699070).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 90.22117519378662
Epoch: 4, Steps: 93 | Train Loss: 0.4191077 Vali Loss: 0.6296061 Test Loss: 0.7782078
Validation loss decreased (0.699070 --> 0.629606).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 87.22370934486389
Epoch: 5, Steps: 93 | Train Loss: 0.3645079 Vali Loss: 0.5869936 Test Loss: 0.7288533
Validation loss decreased (0.629606 --> 0.586994).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 83.51893067359924
Epoch: 6, Steps: 93 | Train Loss: 0.3278378 Vali Loss: 0.5563766 Test Loss: 0.6921858
Validation loss decreased (0.586994 --> 0.556377).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 87.48751020431519
Epoch: 7, Steps: 93 | Train Loss: 0.3011100 Vali Loss: 0.5330770 Test Loss: 0.6638378
Validation loss decreased (0.556377 --> 0.533077).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 92.4543731212616
Epoch: 8, Steps: 93 | Train Loss: 0.2805224 Vali Loss: 0.5132836 Test Loss: 0.6402702
Validation loss decreased (0.533077 --> 0.513284).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 93.08715486526489
Epoch: 9, Steps: 93 | Train Loss: 0.2640306 Vali Loss: 0.4980038 Test Loss: 0.6209379
Validation loss decreased (0.513284 --> 0.498004).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 87.61665868759155
Epoch: 10, Steps: 93 | Train Loss: 0.2504423 Vali Loss: 0.4850515 Test Loss: 0.6045460
Validation loss decreased (0.498004 --> 0.485051).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 95.01060628890991
Epoch: 11, Steps: 93 | Train Loss: 0.2391430 Vali Loss: 0.4728999 Test Loss: 0.5903804
Validation loss decreased (0.485051 --> 0.472900).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 94.05969762802124
Epoch: 12, Steps: 93 | Train Loss: 0.2296031 Vali Loss: 0.4633081 Test Loss: 0.5779732
Validation loss decreased (0.472900 --> 0.463308).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 88.18843746185303
Epoch: 13, Steps: 93 | Train Loss: 0.2214287 Vali Loss: 0.4553877 Test Loss: 0.5673133
Validation loss decreased (0.463308 --> 0.455388).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 86.68712019920349
Epoch: 14, Steps: 93 | Train Loss: 0.2144079 Vali Loss: 0.4476675 Test Loss: 0.5578653
Validation loss decreased (0.455388 --> 0.447667).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 90.3866925239563
Epoch: 15, Steps: 93 | Train Loss: 0.2082791 Vali Loss: 0.4411488 Test Loss: 0.5496992
Validation loss decreased (0.447667 --> 0.441149).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 89.39093232154846
Epoch: 16, Steps: 93 | Train Loss: 0.2029222 Vali Loss: 0.4355972 Test Loss: 0.5427732
Validation loss decreased (0.441149 --> 0.435597).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 98.01691794395447
Epoch: 17, Steps: 93 | Train Loss: 0.1982321 Vali Loss: 0.4306983 Test Loss: 0.5363065
Validation loss decreased (0.435597 --> 0.430698).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 93.29644083976746
Epoch: 18, Steps: 93 | Train Loss: 0.1940480 Vali Loss: 0.4262564 Test Loss: 0.5307322
Validation loss decreased (0.430698 --> 0.426256).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 92.56706094741821
Epoch: 19, Steps: 93 | Train Loss: 0.1903532 Vali Loss: 0.4216430 Test Loss: 0.5253049
Validation loss decreased (0.426256 --> 0.421643).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 94.00342965126038
Epoch: 20, Steps: 93 | Train Loss: 0.1870330 Vali Loss: 0.4180523 Test Loss: 0.5209491
Validation loss decreased (0.421643 --> 0.418052).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 98.8865134716034
Epoch: 21, Steps: 93 | Train Loss: 0.1840760 Vali Loss: 0.4156229 Test Loss: 0.5169290
Validation loss decreased (0.418052 --> 0.415623).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 94.56622076034546
Epoch: 22, Steps: 93 | Train Loss: 0.1813916 Vali Loss: 0.4124334 Test Loss: 0.5131823
Validation loss decreased (0.415623 --> 0.412433).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 94.10255336761475
Epoch: 23, Steps: 93 | Train Loss: 0.1789746 Vali Loss: 0.4100376 Test Loss: 0.5098793
Validation loss decreased (0.412433 --> 0.410038).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 94.55949592590332
Epoch: 24, Steps: 93 | Train Loss: 0.1767768 Vali Loss: 0.4073081 Test Loss: 0.5067308
Validation loss decreased (0.410038 --> 0.407308).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 97.62962222099304
Epoch: 25, Steps: 93 | Train Loss: 0.1747941 Vali Loss: 0.4054874 Test Loss: 0.5040700
Validation loss decreased (0.407308 --> 0.405487).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 91.35879015922546
Epoch: 26, Steps: 93 | Train Loss: 0.1729739 Vali Loss: 0.4030455 Test Loss: 0.5014613
Validation loss decreased (0.405487 --> 0.403046).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 87.08950901031494
Epoch: 27, Steps: 93 | Train Loss: 0.1712992 Vali Loss: 0.4020557 Test Loss: 0.4992304
Validation loss decreased (0.403046 --> 0.402056).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 90.38848090171814
Epoch: 28, Steps: 93 | Train Loss: 0.1698146 Vali Loss: 0.3996166 Test Loss: 0.4971281
Validation loss decreased (0.402056 --> 0.399617).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 88.2095594406128
Epoch: 29, Steps: 93 | Train Loss: 0.1684082 Vali Loss: 0.3985704 Test Loss: 0.4953068
Validation loss decreased (0.399617 --> 0.398570).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 81.43099093437195
Epoch: 30, Steps: 93 | Train Loss: 0.1671244 Vali Loss: 0.3970100 Test Loss: 0.4934150
Validation loss decreased (0.398570 --> 0.397010).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 85.27649426460266
Epoch: 31, Steps: 93 | Train Loss: 0.1659558 Vali Loss: 0.3960166 Test Loss: 0.4918022
Validation loss decreased (0.397010 --> 0.396017).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 78.91793322563171
Epoch: 32, Steps: 93 | Train Loss: 0.1648689 Vali Loss: 0.3945689 Test Loss: 0.4903864
Validation loss decreased (0.396017 --> 0.394569).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 79.69578123092651
Epoch: 33, Steps: 93 | Train Loss: 0.1638793 Vali Loss: 0.3938694 Test Loss: 0.4889377
Validation loss decreased (0.394569 --> 0.393869).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 82.37992644309998
Epoch: 34, Steps: 93 | Train Loss: 0.1629566 Vali Loss: 0.3932053 Test Loss: 0.4876370
Validation loss decreased (0.393869 --> 0.393205).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 84.74142575263977
Epoch: 35, Steps: 93 | Train Loss: 0.1620954 Vali Loss: 0.3914765 Test Loss: 0.4864524
Validation loss decreased (0.393205 --> 0.391476).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 80.67724680900574
Epoch: 36, Steps: 93 | Train Loss: 0.1613023 Vali Loss: 0.3910749 Test Loss: 0.4853882
Validation loss decreased (0.391476 --> 0.391075).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 75.85087609291077
Epoch: 37, Steps: 93 | Train Loss: 0.1605605 Vali Loss: 0.3901311 Test Loss: 0.4843130
Validation loss decreased (0.391075 --> 0.390131).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 76.96642565727234
Epoch: 38, Steps: 93 | Train Loss: 0.1598759 Vali Loss: 0.3893422 Test Loss: 0.4833804
Validation loss decreased (0.390131 --> 0.389342).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 79.60282111167908
Epoch: 39, Steps: 93 | Train Loss: 0.1592362 Vali Loss: 0.3886372 Test Loss: 0.4825084
Validation loss decreased (0.389342 --> 0.388637).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 81.07081174850464
Epoch: 40, Steps: 93 | Train Loss: 0.1586527 Vali Loss: 0.3883133 Test Loss: 0.4817356
Validation loss decreased (0.388637 --> 0.388313).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 76.84549188613892
Epoch: 41, Steps: 93 | Train Loss: 0.1581009 Vali Loss: 0.3874923 Test Loss: 0.4809408
Validation loss decreased (0.388313 --> 0.387492).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 78.6315188407898
Epoch: 42, Steps: 93 | Train Loss: 0.1575716 Vali Loss: 0.3873168 Test Loss: 0.4802497
Validation loss decreased (0.387492 --> 0.387317).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 79.90119743347168
Epoch: 43, Steps: 93 | Train Loss: 0.1570949 Vali Loss: 0.3865425 Test Loss: 0.4796021
Validation loss decreased (0.387317 --> 0.386543).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 76.69028425216675
Epoch: 44, Steps: 93 | Train Loss: 0.1566395 Vali Loss: 0.3858066 Test Loss: 0.4789834
Validation loss decreased (0.386543 --> 0.385807).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 77.42613482475281
Epoch: 45, Steps: 93 | Train Loss: 0.1562076 Vali Loss: 0.3854934 Test Loss: 0.4783960
Validation loss decreased (0.385807 --> 0.385493).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 63.41042876243591
Epoch: 46, Steps: 93 | Train Loss: 0.1558278 Vali Loss: 0.3847087 Test Loss: 0.4778672
Validation loss decreased (0.385493 --> 0.384709).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 77.78011345863342
Epoch: 47, Steps: 93 | Train Loss: 0.1554599 Vali Loss: 0.3844068 Test Loss: 0.4773721
Validation loss decreased (0.384709 --> 0.384407).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 77.0930061340332
Epoch: 48, Steps: 93 | Train Loss: 0.1551020 Vali Loss: 0.3839423 Test Loss: 0.4769264
Validation loss decreased (0.384407 --> 0.383942).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 73.66723442077637
Epoch: 49, Steps: 93 | Train Loss: 0.1547952 Vali Loss: 0.3839867 Test Loss: 0.4764774
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 70.78726649284363
Epoch: 50, Steps: 93 | Train Loss: 0.1544827 Vali Loss: 0.3838349 Test Loss: 0.4760624
Validation loss decreased (0.383942 --> 0.383835).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 64.15918231010437
Epoch: 51, Steps: 93 | Train Loss: 0.1542059 Vali Loss: 0.3830159 Test Loss: 0.4756726
Validation loss decreased (0.383835 --> 0.383016).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 67.88591432571411
Epoch: 52, Steps: 93 | Train Loss: 0.1539275 Vali Loss: 0.3830560 Test Loss: 0.4753354
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 67.84864854812622
Epoch: 53, Steps: 93 | Train Loss: 0.1536661 Vali Loss: 0.3829201 Test Loss: 0.4750021
Validation loss decreased (0.383016 --> 0.382920).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 64.69916439056396
Epoch: 54, Steps: 93 | Train Loss: 0.1534345 Vali Loss: 0.3825275 Test Loss: 0.4746790
Validation loss decreased (0.382920 --> 0.382528).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 64.90340065956116
Epoch: 55, Steps: 93 | Train Loss: 0.1532226 Vali Loss: 0.3821799 Test Loss: 0.4743945
Validation loss decreased (0.382528 --> 0.382180).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 69.54423785209656
Epoch: 56, Steps: 93 | Train Loss: 0.1530109 Vali Loss: 0.3822206 Test Loss: 0.4741130
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 63.93012619018555
Epoch: 57, Steps: 93 | Train Loss: 0.1527980 Vali Loss: 0.3822352 Test Loss: 0.4738361
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 68.77842450141907
Epoch: 58, Steps: 93 | Train Loss: 0.1526204 Vali Loss: 0.3813902 Test Loss: 0.4735934
Validation loss decreased (0.382180 --> 0.381390).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 71.252760887146
Epoch: 59, Steps: 93 | Train Loss: 0.1524392 Vali Loss: 0.3814391 Test Loss: 0.4733839
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 98.23822498321533
Epoch: 60, Steps: 93 | Train Loss: 0.1522709 Vali Loss: 0.3813722 Test Loss: 0.4731461
Validation loss decreased (0.381390 --> 0.381372).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 103.6553156375885
Epoch: 61, Steps: 93 | Train Loss: 0.1521211 Vali Loss: 0.3813539 Test Loss: 0.4729427
Validation loss decreased (0.381372 --> 0.381354).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 104.12125968933105
Epoch: 62, Steps: 93 | Train Loss: 0.1519611 Vali Loss: 0.3807801 Test Loss: 0.4727480
Validation loss decreased (0.381354 --> 0.380780).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 102.53983879089355
Epoch: 63, Steps: 93 | Train Loss: 0.1518278 Vali Loss: 0.3812505 Test Loss: 0.4725750
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 98.50045704841614
Epoch: 64, Steps: 93 | Train Loss: 0.1517003 Vali Loss: 0.3803922 Test Loss: 0.4724013
Validation loss decreased (0.380780 --> 0.380392).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 119.81150555610657
Epoch: 65, Steps: 93 | Train Loss: 0.1515593 Vali Loss: 0.3807505 Test Loss: 0.4722328
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 90.27972483634949
Epoch: 66, Steps: 93 | Train Loss: 0.1514380 Vali Loss: 0.3806201 Test Loss: 0.4720781
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 102.56127619743347
Epoch: 67, Steps: 93 | Train Loss: 0.1513403 Vali Loss: 0.3806188 Test Loss: 0.4719384
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 103.87480616569519
Epoch: 68, Steps: 93 | Train Loss: 0.1512220 Vali Loss: 0.3805802 Test Loss: 0.4718027
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 103.54305100440979
Epoch: 69, Steps: 93 | Train Loss: 0.1511285 Vali Loss: 0.3804741 Test Loss: 0.4716747
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 96.43102478981018
Epoch: 70, Steps: 93 | Train Loss: 0.1510239 Vali Loss: 0.3799491 Test Loss: 0.4715499
Validation loss decreased (0.380392 --> 0.379949).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 100.26917386054993
Epoch: 71, Steps: 93 | Train Loss: 0.1509270 Vali Loss: 0.3796965 Test Loss: 0.4714321
Validation loss decreased (0.379949 --> 0.379697).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 100.0979859828949
Epoch: 72, Steps: 93 | Train Loss: 0.1508550 Vali Loss: 0.3799674 Test Loss: 0.4713260
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 101.5182831287384
Epoch: 73, Steps: 93 | Train Loss: 0.1507672 Vali Loss: 0.3799755 Test Loss: 0.4712236
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 104.26409029960632
Epoch: 74, Steps: 93 | Train Loss: 0.1506839 Vali Loss: 0.3798109 Test Loss: 0.4711272
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 108.4660210609436
Epoch: 75, Steps: 93 | Train Loss: 0.1506193 Vali Loss: 0.3797467 Test Loss: 0.4710285
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 101.79710674285889
Epoch: 76, Steps: 93 | Train Loss: 0.1505522 Vali Loss: 0.3797483 Test Loss: 0.4709443
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 95.99202632904053
Epoch: 77, Steps: 93 | Train Loss: 0.1504828 Vali Loss: 0.3798933 Test Loss: 0.4708673
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 104.0015299320221
Epoch: 78, Steps: 93 | Train Loss: 0.1504177 Vali Loss: 0.3795463 Test Loss: 0.4707865
Validation loss decreased (0.379697 --> 0.379546).  Saving model ...
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 89.33855962753296
Epoch: 79, Steps: 93 | Train Loss: 0.1503521 Vali Loss: 0.3795336 Test Loss: 0.4707146
Validation loss decreased (0.379546 --> 0.379534).  Saving model ...
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 102.46693849563599
Epoch: 80, Steps: 93 | Train Loss: 0.1503010 Vali Loss: 0.3788910 Test Loss: 0.4706421
Validation loss decreased (0.379534 --> 0.378891).  Saving model ...
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 93.61341691017151
Epoch: 81, Steps: 93 | Train Loss: 0.1502544 Vali Loss: 0.3790341 Test Loss: 0.4705749
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 89.16081047058105
Epoch: 82, Steps: 93 | Train Loss: 0.1502096 Vali Loss: 0.3790803 Test Loss: 0.4705108
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 92.42778301239014
Epoch: 83, Steps: 93 | Train Loss: 0.1501506 Vali Loss: 0.3793003 Test Loss: 0.4704536
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 89.77685809135437
Epoch: 84, Steps: 93 | Train Loss: 0.1501096 Vali Loss: 0.3790849 Test Loss: 0.4704003
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 87.45889949798584
Epoch: 85, Steps: 93 | Train Loss: 0.1500595 Vali Loss: 0.3798715 Test Loss: 0.4703459
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 88.51870155334473
Epoch: 86, Steps: 93 | Train Loss: 0.1500248 Vali Loss: 0.3792953 Test Loss: 0.4702951
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 86.85993909835815
Epoch: 87, Steps: 93 | Train Loss: 0.1499887 Vali Loss: 0.3787507 Test Loss: 0.4702457
Validation loss decreased (0.378891 --> 0.378751).  Saving model ...
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 90.10336232185364
Epoch: 88, Steps: 93 | Train Loss: 0.1499387 Vali Loss: 0.3789397 Test Loss: 0.4702009
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 85.5740556716919
Epoch: 89, Steps: 93 | Train Loss: 0.1499065 Vali Loss: 0.3789368 Test Loss: 0.4701628
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 84.81577515602112
Epoch: 90, Steps: 93 | Train Loss: 0.1498751 Vali Loss: 0.3785979 Test Loss: 0.4701206
Validation loss decreased (0.378751 --> 0.378598).  Saving model ...
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 77.01609635353088
Epoch: 91, Steps: 93 | Train Loss: 0.1498444 Vali Loss: 0.3789571 Test Loss: 0.4700809
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 96.14187169075012
Epoch: 92, Steps: 93 | Train Loss: 0.1498173 Vali Loss: 0.3787680 Test Loss: 0.4700415
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 105.59373259544373
Epoch: 93, Steps: 93 | Train Loss: 0.1497848 Vali Loss: 0.3788111 Test Loss: 0.4700089
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 103.39472007751465
Epoch: 94, Steps: 93 | Train Loss: 0.1497615 Vali Loss: 0.3783796 Test Loss: 0.4699783
Validation loss decreased (0.378598 --> 0.378380).  Saving model ...
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 99.8513810634613
Epoch: 95, Steps: 93 | Train Loss: 0.1497212 Vali Loss: 0.3786777 Test Loss: 0.4699443
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 96.63717603683472
Epoch: 96, Steps: 93 | Train Loss: 0.1497073 Vali Loss: 0.3792333 Test Loss: 0.4699164
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 89.02107691764832
Epoch: 97, Steps: 93 | Train Loss: 0.1496834 Vali Loss: 0.3788961 Test Loss: 0.4698866
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 83.12237477302551
Epoch: 98, Steps: 93 | Train Loss: 0.1496576 Vali Loss: 0.3786212 Test Loss: 0.4698603
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 84.12533926963806
Epoch: 99, Steps: 93 | Train Loss: 0.1496342 Vali Loss: 0.3788601 Test Loss: 0.4698355
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 87.69251894950867
Epoch: 100, Steps: 93 | Train Loss: 0.1496201 Vali Loss: 0.3788754 Test Loss: 0.4698108
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.1160680107021042e-06
train 11909
val 1565
test 3317
Model(
  (freq_upsampler): Linear(in_features=90, out_features=186, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1847024640.0
params:  16926.0
Trainable parameters:  16926
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 98.5191855430603
Epoch: 1, Steps: 93 | Train Loss: 0.2804239 Vali Loss: 0.3737816 Test Loss: 0.4640636
Validation loss decreased (inf --> 0.373782).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 119.11013317108154
Epoch: 2, Steps: 93 | Train Loss: 0.2783606 Vali Loss: 0.3729084 Test Loss: 0.4635773
Validation loss decreased (0.373782 --> 0.372908).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 124.07207655906677
Epoch: 3, Steps: 93 | Train Loss: 0.2780207 Vali Loss: 0.3728410 Test Loss: 0.4634997
Validation loss decreased (0.372908 --> 0.372841).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 116.92017006874084
Epoch: 4, Steps: 93 | Train Loss: 0.2779389 Vali Loss: 0.3727443 Test Loss: 0.4633707
Validation loss decreased (0.372841 --> 0.372744).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 113.41694402694702
Epoch: 5, Steps: 93 | Train Loss: 0.2778921 Vali Loss: 0.3729771 Test Loss: 0.4633605
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 114.39307618141174
Epoch: 6, Steps: 93 | Train Loss: 0.2778379 Vali Loss: 0.3724410 Test Loss: 0.4632529
Validation loss decreased (0.372744 --> 0.372441).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 111.84557056427002
Epoch: 7, Steps: 93 | Train Loss: 0.2778079 Vali Loss: 0.3723181 Test Loss: 0.4631410
Validation loss decreased (0.372441 --> 0.372318).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 111.35202741622925
Epoch: 8, Steps: 93 | Train Loss: 0.2777683 Vali Loss: 0.3725815 Test Loss: 0.4629236
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 113.56175374984741
Epoch: 9, Steps: 93 | Train Loss: 0.2777332 Vali Loss: 0.3727076 Test Loss: 0.4630974
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 112.83739495277405
Epoch: 10, Steps: 93 | Train Loss: 0.2777209 Vali Loss: 0.3724792 Test Loss: 0.4629475
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 114.0002031326294
Epoch: 11, Steps: 93 | Train Loss: 0.2777017 Vali Loss: 0.3726278 Test Loss: 0.4629922
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 112.32396030426025
Epoch: 12, Steps: 93 | Train Loss: 0.2777006 Vali Loss: 0.3726473 Test Loss: 0.4630781
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 111.75504541397095
Epoch: 13, Steps: 93 | Train Loss: 0.2776721 Vali Loss: 0.3720753 Test Loss: 0.4629699
Validation loss decreased (0.372318 --> 0.372075).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 112.94934606552124
Epoch: 14, Steps: 93 | Train Loss: 0.2776515 Vali Loss: 0.3723858 Test Loss: 0.4629616
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 111.54969620704651
Epoch: 15, Steps: 93 | Train Loss: 0.2776238 Vali Loss: 0.3719859 Test Loss: 0.4629582
Validation loss decreased (0.372075 --> 0.371986).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 119.76508617401123
Epoch: 16, Steps: 93 | Train Loss: 0.2776392 Vali Loss: 0.3722935 Test Loss: 0.4628393
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 116.49319553375244
Epoch: 17, Steps: 93 | Train Loss: 0.2776117 Vali Loss: 0.3721163 Test Loss: 0.4627933
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 112.89064025878906
Epoch: 18, Steps: 93 | Train Loss: 0.2776038 Vali Loss: 0.3723809 Test Loss: 0.4628779
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 108.55474662780762
Epoch: 19, Steps: 93 | Train Loss: 0.2775904 Vali Loss: 0.3725926 Test Loss: 0.4628671
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 110.00929355621338
Epoch: 20, Steps: 93 | Train Loss: 0.2775907 Vali Loss: 0.3718041 Test Loss: 0.4627547
Validation loss decreased (0.371986 --> 0.371804).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 104.87916278839111
Epoch: 21, Steps: 93 | Train Loss: 0.2775780 Vali Loss: 0.3725824 Test Loss: 0.4628543
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 110.91458082199097
Epoch: 22, Steps: 93 | Train Loss: 0.2775559 Vali Loss: 0.3718969 Test Loss: 0.4627972
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 116.67433857917786
Epoch: 23, Steps: 93 | Train Loss: 0.2775693 Vali Loss: 0.3724074 Test Loss: 0.4627209
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 107.6899151802063
Epoch: 24, Steps: 93 | Train Loss: 0.2775404 Vali Loss: 0.3727982 Test Loss: 0.4627755
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 108.71064019203186
Epoch: 25, Steps: 93 | Train Loss: 0.2775107 Vali Loss: 0.3724890 Test Loss: 0.4627219
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 109.84461236000061
Epoch: 26, Steps: 93 | Train Loss: 0.2775231 Vali Loss: 0.3723652 Test Loss: 0.4628325
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 110.789377450943
Epoch: 27, Steps: 93 | Train Loss: 0.2775273 Vali Loss: 0.3727219 Test Loss: 0.4627097
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 110.06448769569397
Epoch: 28, Steps: 93 | Train Loss: 0.2775149 Vali Loss: 0.3723067 Test Loss: 0.4628609
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 97.77086734771729
Epoch: 29, Steps: 93 | Train Loss: 0.2774892 Vali Loss: 0.3725733 Test Loss: 0.4628057
EarlyStopping counter: 9 out of 10
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 102.15626811981201
Epoch: 30, Steps: 93 | Train Loss: 0.2775051 Vali Loss: 0.3724474 Test Loss: 0.4627298
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : Traffic_180_j192_H10_FITS_custom_ftM_sl180_ll48_pl192_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3317
mse:0.4619069993495941, mae:0.3011360168457031, rse:0.5609269738197327, corr:[0.27011958 0.2875901  0.28772047 0.2871772  0.28691468 0.2871304
 0.28694105 0.28698206 0.28631234 0.28675362 0.286697   0.28650147
 0.28636783 0.28673688 0.28642872 0.28614512 0.28566334 0.28580818
 0.2854973  0.28524905 0.28536603 0.2860333  0.28722227 0.28745627
 0.2871864  0.28647137 0.2859657  0.28589705 0.28637213 0.2863655
 0.28620088 0.2864795  0.28630957 0.28618413 0.2865157  0.2862494
 0.28585348 0.28581098 0.28560856 0.28531048 0.28492776 0.28509995
 0.28543293 0.28523657 0.28535277 0.2856032  0.28566822 0.28595278
 0.28563708 0.28491947 0.28461057 0.2846354  0.28480688 0.28511178
 0.28523043 0.28520876 0.28550428 0.28582162 0.2853829  0.2845556
 0.28394938 0.28437576 0.28442872 0.28488538 0.2848768  0.28461358
 0.2841546  0.28363654 0.28438136 0.28463954 0.28447592 0.28471896
 0.2845556  0.28391463 0.28320858 0.2833711  0.2834799  0.28328398
 0.28328645 0.2834603  0.2836205  0.2839278  0.28349835 0.28345564
 0.28336725 0.28337586 0.2834979  0.28357667 0.28361472 0.28326038
 0.28315997 0.28358254 0.28368816 0.28320178 0.28293666 0.28284773
 0.283032   0.2838931  0.28369248 0.28345388 0.2834669  0.2833294
 0.2829003  0.28247792 0.28253597 0.2831713  0.28277737 0.28267118
 0.28285626 0.2824837  0.28290364 0.2828982  0.28248814 0.28241286
 0.28279105 0.28322062 0.28281537 0.28208658 0.28198    0.28221285
 0.2824944  0.2827758  0.282738   0.28271285 0.28259963 0.28235126
 0.28270864 0.28277624 0.2825626  0.28259957 0.28227386 0.28250772
 0.28304803 0.28329888 0.28350922 0.2833642  0.28329659 0.28312203
 0.28317294 0.28345475 0.28359276 0.2838961  0.2843944  0.28481242
 0.28456756 0.28434616 0.28376332 0.2833783  0.28303528 0.2831747
 0.2835576  0.28342068 0.2836185  0.28390628 0.28484502 0.2851205
 0.28640893 0.28671283 0.2863264  0.28608295 0.28493795 0.28487602
 0.28491455 0.28525048 0.2857199  0.28653073 0.28737235 0.28810304
 0.28755742 0.28713858 0.28630507 0.28612933 0.2860869  0.28574255
 0.28558722 0.28548262 0.2856543  0.28553686 0.28544572 0.2853866
 0.28522664 0.28515908 0.28497618 0.28513572 0.28559473 0.28556722
 0.28541318 0.28496155 0.2852058  0.28499818 0.28600624 0.2843002 ]
