Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_180_j96_H10', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=10, pred_len=96, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_180_j96_H10_FITS_custom_ftM_sl180_ll48_pl96_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 12005
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=90, out_features=138, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1370373120.0
params:  12558.0
Trainable parameters:  12558
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 95.2136902809143
Epoch: 1, Steps: 93 | Train Loss: 0.8017546 Vali Loss: 0.6596289 Test Loss: 0.7835648
Validation loss decreased (inf --> 0.659629).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 89.01808071136475
Epoch: 2, Steps: 93 | Train Loss: 0.4355476 Vali Loss: 0.5038643 Test Loss: 0.5987110
Validation loss decreased (0.659629 --> 0.503864).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 97.66196012496948
Epoch: 3, Steps: 93 | Train Loss: 0.3537282 Vali Loss: 0.4418123 Test Loss: 0.5273091
Validation loss decreased (0.503864 --> 0.441812).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 98.68871688842773
Epoch: 4, Steps: 93 | Train Loss: 0.3173297 Vali Loss: 0.4138353 Test Loss: 0.4926975
Validation loss decreased (0.441812 --> 0.413835).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 92.42008090019226
Epoch: 5, Steps: 93 | Train Loss: 0.2988956 Vali Loss: 0.3975004 Test Loss: 0.4752818
Validation loss decreased (0.413835 --> 0.397500).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 94.73364591598511
Epoch: 6, Steps: 93 | Train Loss: 0.2890295 Vali Loss: 0.3890501 Test Loss: 0.4659344
Validation loss decreased (0.397500 --> 0.389050).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 101.16143417358398
Epoch: 7, Steps: 93 | Train Loss: 0.2831816 Vali Loss: 0.3816456 Test Loss: 0.4606512
Validation loss decreased (0.389050 --> 0.381646).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 97.95722579956055
Epoch: 8, Steps: 93 | Train Loss: 0.2799007 Vali Loss: 0.3792845 Test Loss: 0.4576297
Validation loss decreased (0.381646 --> 0.379285).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 89.52233839035034
Epoch: 9, Steps: 93 | Train Loss: 0.2780078 Vali Loss: 0.3784421 Test Loss: 0.4556105
Validation loss decreased (0.379285 --> 0.378442).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 89.68435478210449
Epoch: 10, Steps: 93 | Train Loss: 0.2766114 Vali Loss: 0.3764229 Test Loss: 0.4543935
Validation loss decreased (0.378442 --> 0.376423).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 87.92735695838928
Epoch: 11, Steps: 93 | Train Loss: 0.2756152 Vali Loss: 0.3744176 Test Loss: 0.4535390
Validation loss decreased (0.376423 --> 0.374418).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 79.39090394973755
Epoch: 12, Steps: 93 | Train Loss: 0.2750290 Vali Loss: 0.3753351 Test Loss: 0.4530207
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 77.49060916900635
Epoch: 13, Steps: 93 | Train Loss: 0.2745325 Vali Loss: 0.3742689 Test Loss: 0.4526524
Validation loss decreased (0.374418 --> 0.374269).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 78.19066333770752
Epoch: 14, Steps: 93 | Train Loss: 0.2743713 Vali Loss: 0.3739506 Test Loss: 0.4523228
Validation loss decreased (0.374269 --> 0.373951).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 81.08314919471741
Epoch: 15, Steps: 93 | Train Loss: 0.2737698 Vali Loss: 0.3740462 Test Loss: 0.4521638
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 84.37370467185974
Epoch: 16, Steps: 93 | Train Loss: 0.2738276 Vali Loss: 0.3735984 Test Loss: 0.4520011
Validation loss decreased (0.373951 --> 0.373598).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 80.70385026931763
Epoch: 17, Steps: 93 | Train Loss: 0.2735932 Vali Loss: 0.3723567 Test Loss: 0.4518350
Validation loss decreased (0.373598 --> 0.372357).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 79.0633933544159
Epoch: 18, Steps: 93 | Train Loss: 0.2734767 Vali Loss: 0.3732795 Test Loss: 0.4518031
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 79.22370386123657
Epoch: 19, Steps: 93 | Train Loss: 0.2735218 Vali Loss: 0.3722807 Test Loss: 0.4517515
Validation loss decreased (0.372357 --> 0.372281).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 74.9074239730835
Epoch: 20, Steps: 93 | Train Loss: 0.2735697 Vali Loss: 0.3731256 Test Loss: 0.4516217
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 80.32861542701721
Epoch: 21, Steps: 93 | Train Loss: 0.2733425 Vali Loss: 0.3712373 Test Loss: 0.4515701
Validation loss decreased (0.372281 --> 0.371237).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 72.53960657119751
Epoch: 22, Steps: 93 | Train Loss: 0.2733506 Vali Loss: 0.3734570 Test Loss: 0.4515335
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 69.37981629371643
Epoch: 23, Steps: 93 | Train Loss: 0.2733287 Vali Loss: 0.3726898 Test Loss: 0.4514989
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 70.13795208930969
Epoch: 24, Steps: 93 | Train Loss: 0.2731097 Vali Loss: 0.3721655 Test Loss: 0.4514970
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 75.50146293640137
Epoch: 25, Steps: 93 | Train Loss: 0.2731995 Vali Loss: 0.3726256 Test Loss: 0.4513958
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 68.3559923171997
Epoch: 26, Steps: 93 | Train Loss: 0.2732672 Vali Loss: 0.3726159 Test Loss: 0.4513748
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 69.9799222946167
Epoch: 27, Steps: 93 | Train Loss: 0.2731088 Vali Loss: 0.3724587 Test Loss: 0.4513549
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 71.46777439117432
Epoch: 28, Steps: 93 | Train Loss: 0.2731410 Vali Loss: 0.3731439 Test Loss: 0.4513706
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 69.17327666282654
Epoch: 29, Steps: 93 | Train Loss: 0.2730534 Vali Loss: 0.3729497 Test Loss: 0.4513408
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 70.13795733451843
Epoch: 30, Steps: 93 | Train Loss: 0.2731169 Vali Loss: 0.3731745 Test Loss: 0.4513538
EarlyStopping counter: 9 out of 10
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 76.66787719726562
Epoch: 31, Steps: 93 | Train Loss: 0.2729773 Vali Loss: 0.3719494 Test Loss: 0.4512863
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : Traffic_180_j96_H10_FITS_custom_ftM_sl180_ll48_pl96_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3413
mse:0.45134004950523376, mae:0.2988932430744171, rse:0.5562953352928162, corr:[0.27428856 0.29107544 0.28896368 0.29020485 0.2889866  0.29033417
 0.28991938 0.29091066 0.29045972 0.290293   0.29030105 0.28966665
 0.28924057 0.28869152 0.288768   0.2882699  0.28820288 0.28807613
 0.28849605 0.28911018 0.28922683 0.28966016 0.29004088 0.28997284
 0.28988186 0.28896254 0.28920147 0.28905118 0.28914976 0.2892547
 0.28909934 0.2896603  0.28912652 0.28851548 0.28803182 0.2876553
 0.28736064 0.287234   0.287312   0.2874349  0.2878824  0.28842154
 0.28869733 0.288676   0.28851023 0.2887393  0.2882859  0.28853408
 0.2883039  0.28806013 0.28828526 0.28815398 0.28850913 0.28851622
 0.2888037  0.28892106 0.28867707 0.2882382  0.28786048 0.28772596
 0.28733543 0.28752884 0.28804025 0.28778937 0.28813666 0.2881978
 0.28851685 0.2884691  0.28821617 0.2882692  0.28749275 0.28776625
 0.2871475  0.28724998 0.28732857 0.28748634 0.2876397  0.2873415
 0.28736326 0.28729466 0.28713402 0.28777817 0.28787324 0.28773242
 0.28763148 0.28815654 0.28843483 0.2883952  0.28827608 0.28752854
 0.28790253 0.2865275  0.28684896 0.28476986 0.28714266 0.28642917]
