Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=138, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_360_j192_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_360_j192_H8_FITS_custom_ftM_sl360_ll48_pl192_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17861
val 2441
test 5069
Model(
  (freq_upsampler): Linear(in_features=138, out_features=211, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1196400384.0
params:  29329.0
Trainable parameters:  29329
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5463459
	speed: 0.4929s/iter; left time: 6802.5212s
Epoch: 1 cost time: 68.8958990573883
Epoch: 1, Steps: 139 | Train Loss: 0.6907523 Vali Loss: 0.3600123 Test Loss: 0.4178767
Validation loss decreased (inf --> 0.360012).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2765188
	speed: 1.0441s/iter; left time: 14265.0740s
Epoch: 2 cost time: 64.78115248680115
Epoch: 2, Steps: 139 | Train Loss: 0.3185514 Vali Loss: 0.2008620 Test Loss: 0.2379488
Validation loss decreased (0.360012 --> 0.200862).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1936875
	speed: 1.0616s/iter; left time: 14355.8962s
Epoch: 3 cost time: 60.82781267166138
Epoch: 3, Steps: 139 | Train Loss: 0.2053648 Vali Loss: 0.1515863 Test Loss: 0.1812196
Validation loss decreased (0.200862 --> 0.151586).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1645559
	speed: 1.0662s/iter; left time: 14270.2621s
Epoch: 4 cost time: 67.391104221344
Epoch: 4, Steps: 139 | Train Loss: 0.1717033 Vali Loss: 0.1386556 Test Loss: 0.1657339
Validation loss decreased (0.151586 --> 0.138656).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1591312
	speed: 1.0310s/iter; left time: 13655.9463s
Epoch: 5 cost time: 62.79486346244812
Epoch: 5, Steps: 139 | Train Loss: 0.1628711 Vali Loss: 0.1355324 Test Loss: 0.1617292
Validation loss decreased (0.138656 --> 0.135532).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1680818
	speed: 1.0613s/iter; left time: 13909.5950s
Epoch: 6 cost time: 62.63267803192139
Epoch: 6, Steps: 139 | Train Loss: 0.1604012 Vali Loss: 0.1347124 Test Loss: 0.1605184
Validation loss decreased (0.135532 --> 0.134712).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1560982
	speed: 1.0241s/iter; left time: 13279.4894s
Epoch: 7 cost time: 60.52354860305786
Epoch: 7, Steps: 139 | Train Loss: 0.1595958 Vali Loss: 0.1343729 Test Loss: 0.1600003
Validation loss decreased (0.134712 --> 0.134373).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1473723
	speed: 1.1014s/iter; left time: 14128.3951s
Epoch: 8 cost time: 64.959956407547
Epoch: 8, Steps: 139 | Train Loss: 0.1591716 Vali Loss: 0.1341348 Test Loss: 0.1597294
Validation loss decreased (0.134373 --> 0.134135).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1508036
	speed: 0.9830s/iter; left time: 12472.8926s
Epoch: 9 cost time: 59.26965260505676
Epoch: 9, Steps: 139 | Train Loss: 0.1588797 Vali Loss: 0.1339250 Test Loss: 0.1595231
Validation loss decreased (0.134135 --> 0.133925).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1581936
	speed: 1.0662s/iter; left time: 13380.2814s
Epoch: 10 cost time: 64.54973936080933
Epoch: 10, Steps: 139 | Train Loss: 0.1587129 Vali Loss: 0.1337648 Test Loss: 0.1593947
Validation loss decreased (0.133925 --> 0.133765).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1571143
	speed: 1.0044s/iter; left time: 12465.2769s
Epoch: 11 cost time: 61.63590407371521
Epoch: 11, Steps: 139 | Train Loss: 0.1585838 Vali Loss: 0.1337272 Test Loss: 0.1593191
Validation loss decreased (0.133765 --> 0.133727).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1605186
	speed: 1.0819s/iter; left time: 13276.5128s
Epoch: 12 cost time: 67.02522039413452
Epoch: 12, Steps: 139 | Train Loss: 0.1584815 Vali Loss: 0.1336593 Test Loss: 0.1592085
Validation loss decreased (0.133727 --> 0.133659).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1678728
	speed: 1.0411s/iter; left time: 12631.5873s
Epoch: 13 cost time: 63.68176984786987
Epoch: 13, Steps: 139 | Train Loss: 0.1583495 Vali Loss: 0.1335481 Test Loss: 0.1591312
Validation loss decreased (0.133659 --> 0.133548).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1617431
	speed: 1.0708s/iter; left time: 12843.7371s
Epoch: 14 cost time: 60.82123875617981
Epoch: 14, Steps: 139 | Train Loss: 0.1582470 Vali Loss: 0.1334540 Test Loss: 0.1590671
Validation loss decreased (0.133548 --> 0.133454).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1557918
	speed: 1.0000s/iter; left time: 11854.8415s
Epoch: 15 cost time: 60.34317898750305
Epoch: 15, Steps: 139 | Train Loss: 0.1582096 Vali Loss: 0.1333924 Test Loss: 0.1590274
Validation loss decreased (0.133454 --> 0.133392).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1705396
	speed: 1.0188s/iter; left time: 11936.2047s
Epoch: 16 cost time: 64.00270128250122
Epoch: 16, Steps: 139 | Train Loss: 0.1581476 Vali Loss: 0.1334101 Test Loss: 0.1589834
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1591749
	speed: 0.9892s/iter; left time: 11451.8633s
Epoch: 17 cost time: 59.83955407142639
Epoch: 17, Steps: 139 | Train Loss: 0.1581055 Vali Loss: 0.1333167 Test Loss: 0.1589419
Validation loss decreased (0.133392 --> 0.133317).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1625857
	speed: 0.9748s/iter; left time: 11149.3753s
Epoch: 18 cost time: 59.13342523574829
Epoch: 18, Steps: 139 | Train Loss: 0.1580416 Vali Loss: 0.1333521 Test Loss: 0.1589032
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1606217
	speed: 1.0157s/iter; left time: 11476.7737s
Epoch: 19 cost time: 66.21764206886292
Epoch: 19, Steps: 139 | Train Loss: 0.1579733 Vali Loss: 0.1332401 Test Loss: 0.1588813
Validation loss decreased (0.133317 --> 0.133240).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1413806
	speed: 0.9896s/iter; left time: 11044.3424s
Epoch: 20 cost time: 60.29599642753601
Epoch: 20, Steps: 139 | Train Loss: 0.1580353 Vali Loss: 0.1332227 Test Loss: 0.1588504
Validation loss decreased (0.133240 --> 0.133223).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1510027
	speed: 1.0002s/iter; left time: 11022.8704s
Epoch: 21 cost time: 61.91039276123047
Epoch: 21, Steps: 139 | Train Loss: 0.1579423 Vali Loss: 0.1332387 Test Loss: 0.1588436
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1528922
	speed: 1.0126s/iter; left time: 11019.4524s
Epoch: 22 cost time: 63.07267379760742
Epoch: 22, Steps: 139 | Train Loss: 0.1579114 Vali Loss: 0.1331015 Test Loss: 0.1588221
Validation loss decreased (0.133223 --> 0.133101).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1537229
	speed: 1.0666s/iter; left time: 11458.8966s
Epoch: 23 cost time: 62.065842628479004
Epoch: 23, Steps: 139 | Train Loss: 0.1578748 Vali Loss: 0.1332406 Test Loss: 0.1587907
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1603482
	speed: 1.0374s/iter; left time: 11000.8537s
Epoch: 24 cost time: 61.936848878860474
Epoch: 24, Steps: 139 | Train Loss: 0.1578327 Vali Loss: 0.1332499 Test Loss: 0.1587880
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1624584
	speed: 1.0565s/iter; left time: 11056.6612s
Epoch: 25 cost time: 68.23540186882019
Epoch: 25, Steps: 139 | Train Loss: 0.1578833 Vali Loss: 0.1332174 Test Loss: 0.1587645
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1756959
	speed: 1.1394s/iter; left time: 11765.3691s
Epoch: 26 cost time: 67.52034616470337
Epoch: 26, Steps: 139 | Train Loss: 0.1579038 Vali Loss: 0.1331836 Test Loss: 0.1587609
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1662561
	speed: 1.0319s/iter; left time: 10511.9625s
Epoch: 27 cost time: 66.40346217155457
Epoch: 27, Steps: 139 | Train Loss: 0.1577743 Vali Loss: 0.1332199 Test Loss: 0.1587615
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1476892
	speed: 1.1149s/iter; left time: 11203.0026s
Epoch: 28 cost time: 68.16589307785034
Epoch: 28, Steps: 139 | Train Loss: 0.1578267 Vali Loss: 0.1331689 Test Loss: 0.1587382
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1689363
	speed: 1.0824s/iter; left time: 10725.4996s
Epoch: 29 cost time: 63.76933813095093
Epoch: 29, Steps: 139 | Train Loss: 0.1578312 Vali Loss: 0.1331394 Test Loss: 0.1587243
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1673400
	speed: 1.0078s/iter; left time: 9846.6550s
Epoch: 30 cost time: 63.41646456718445
Epoch: 30, Steps: 139 | Train Loss: 0.1577931 Vali Loss: 0.1331600 Test Loss: 0.1587227
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1472880
	speed: 1.0854s/iter; left time: 10453.7572s
Epoch: 31 cost time: 69.33588361740112
Epoch: 31, Steps: 139 | Train Loss: 0.1578050 Vali Loss: 0.1331600 Test Loss: 0.1587127
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1708206
	speed: 1.0537s/iter; left time: 10002.0902s
Epoch: 32 cost time: 63.70675611495972
Epoch: 32, Steps: 139 | Train Loss: 0.1577888 Vali Loss: 0.1331034 Test Loss: 0.1587049
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1565242
	speed: 1.0661s/iter; left time: 9971.4527s
Epoch: 33 cost time: 65.47368860244751
Epoch: 33, Steps: 139 | Train Loss: 0.1577232 Vali Loss: 0.1331250 Test Loss: 0.1587021
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1489214
	speed: 1.0249s/iter; left time: 9443.0543s
Epoch: 34 cost time: 63.90749430656433
Epoch: 34, Steps: 139 | Train Loss: 0.1577861 Vali Loss: 0.1331840 Test Loss: 0.1586999
EarlyStopping counter: 12 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1654457
	speed: 1.0896s/iter; left time: 9888.1472s
Epoch: 35 cost time: 68.30946159362793
Epoch: 35, Steps: 139 | Train Loss: 0.1577628 Vali Loss: 0.1330919 Test Loss: 0.1586931
Validation loss decreased (0.133101 --> 0.133092).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1519217
	speed: 1.0608s/iter; left time: 9479.3428s
Epoch: 36 cost time: 64.8907675743103
Epoch: 36, Steps: 139 | Train Loss: 0.1577475 Vali Loss: 0.1330891 Test Loss: 0.1586805
Validation loss decreased (0.133092 --> 0.133089).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1603367
	speed: 1.0472s/iter; left time: 9212.5016s
Epoch: 37 cost time: 64.05517387390137
Epoch: 37, Steps: 139 | Train Loss: 0.1577655 Vali Loss: 0.1331183 Test Loss: 0.1586788
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1556503
	speed: 1.0405s/iter; left time: 9008.6571s
Epoch: 38 cost time: 62.82055950164795
Epoch: 38, Steps: 139 | Train Loss: 0.1577635 Vali Loss: 0.1330751 Test Loss: 0.1586774
Validation loss decreased (0.133089 --> 0.133075).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1520547
	speed: 1.0530s/iter; left time: 8970.2857s
Epoch: 39 cost time: 65.15590381622314
Epoch: 39, Steps: 139 | Train Loss: 0.1577980 Vali Loss: 0.1330767 Test Loss: 0.1586850
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1580527
	speed: 1.0564s/iter; left time: 8852.6646s
Epoch: 40 cost time: 62.97158193588257
Epoch: 40, Steps: 139 | Train Loss: 0.1577399 Vali Loss: 0.1331572 Test Loss: 0.1586856
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1629508
	speed: 1.0319s/iter; left time: 8503.5385s
Epoch: 41 cost time: 62.89857625961304
Epoch: 41, Steps: 139 | Train Loss: 0.1577041 Vali Loss: 0.1330791 Test Loss: 0.1586704
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1636231
	speed: 1.0017s/iter; left time: 8115.8485s
Epoch: 42 cost time: 63.43209743499756
Epoch: 42, Steps: 139 | Train Loss: 0.1577756 Vali Loss: 0.1331294 Test Loss: 0.1586730
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1500955
	speed: 1.1670s/iter; left time: 9293.0693s
Epoch: 43 cost time: 80.77454328536987
Epoch: 43, Steps: 139 | Train Loss: 0.1577338 Vali Loss: 0.1331327 Test Loss: 0.1586634
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1521940
	speed: 1.3712s/iter; left time: 10728.2052s
Epoch: 44 cost time: 78.11178684234619
Epoch: 44, Steps: 139 | Train Loss: 0.1577795 Vali Loss: 0.1330501 Test Loss: 0.1586628
Validation loss decreased (0.133075 --> 0.133050).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1492645
	speed: 1.1416s/iter; left time: 8773.2173s
Epoch: 45 cost time: 70.15072083473206
Epoch: 45, Steps: 139 | Train Loss: 0.1577067 Vali Loss: 0.1331702 Test Loss: 0.1586627
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1637217
	speed: 1.0348s/iter; left time: 7808.5080s
Epoch: 46 cost time: 63.36101746559143
Epoch: 46, Steps: 139 | Train Loss: 0.1577358 Vali Loss: 0.1331608 Test Loss: 0.1586621
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1563429
	speed: 1.0146s/iter; left time: 7515.0196s
Epoch: 47 cost time: 61.16660237312317
Epoch: 47, Steps: 139 | Train Loss: 0.1577254 Vali Loss: 0.1330975 Test Loss: 0.1586566
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1610401
	speed: 1.0437s/iter; left time: 7585.7658s
Epoch: 48 cost time: 63.38547968864441
Epoch: 48, Steps: 139 | Train Loss: 0.1577068 Vali Loss: 0.1331195 Test Loss: 0.1586558
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1597234
	speed: 1.0085s/iter; left time: 7189.3106s
Epoch: 49 cost time: 62.56741452217102
Epoch: 49, Steps: 139 | Train Loss: 0.1576932 Vali Loss: 0.1331077 Test Loss: 0.1586632
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1586431
	speed: 1.0087s/iter; left time: 7050.6954s
Epoch: 50 cost time: 64.1954517364502
Epoch: 50, Steps: 139 | Train Loss: 0.1576895 Vali Loss: 0.1330843 Test Loss: 0.1586592
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1639098
	speed: 1.0964s/iter; left time: 7511.2404s
Epoch: 51 cost time: 60.716445446014404
Epoch: 51, Steps: 139 | Train Loss: 0.1576957 Vali Loss: 0.1330792 Test Loss: 0.1586542
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1609235
	speed: 1.0116s/iter; left time: 6789.8603s
Epoch: 52 cost time: 62.546945095062256
Epoch: 52, Steps: 139 | Train Loss: 0.1576931 Vali Loss: 0.1330484 Test Loss: 0.1586525
Validation loss decreased (0.133050 --> 0.133048).  Saving model ...
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1606673
	speed: 0.9921s/iter; left time: 6520.9643s
Epoch: 53 cost time: 61.4393413066864
Epoch: 53, Steps: 139 | Train Loss: 0.1576942 Vali Loss: 0.1329949 Test Loss: 0.1586516
Validation loss decreased (0.133048 --> 0.132995).  Saving model ...
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1534928
	speed: 0.9818s/iter; left time: 6317.1722s
Epoch: 54 cost time: 61.704607248306274
Epoch: 54, Steps: 139 | Train Loss: 0.1576854 Vali Loss: 0.1330917 Test Loss: 0.1586501
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1509803
	speed: 1.0073s/iter; left time: 6340.9030s
Epoch: 55 cost time: 61.9006073474884
Epoch: 55, Steps: 139 | Train Loss: 0.1577265 Vali Loss: 0.1330319 Test Loss: 0.1586500
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1583141
	speed: 1.0019s/iter; left time: 6167.9467s
Epoch: 56 cost time: 61.30772924423218
Epoch: 56, Steps: 139 | Train Loss: 0.1576888 Vali Loss: 0.1330678 Test Loss: 0.1586466
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.1567585
	speed: 1.0280s/iter; left time: 6185.7408s
Epoch: 57 cost time: 65.76080083847046
Epoch: 57, Steps: 139 | Train Loss: 0.1576191 Vali Loss: 0.1331003 Test Loss: 0.1586500
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1538949
	speed: 1.0369s/iter; left time: 6094.7604s
Epoch: 58 cost time: 63.25535488128662
Epoch: 58, Steps: 139 | Train Loss: 0.1576917 Vali Loss: 0.1330325 Test Loss: 0.1586479
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1634940
	speed: 1.0250s/iter; left time: 5882.5470s
Epoch: 59 cost time: 63.446529388427734
Epoch: 59, Steps: 139 | Train Loss: 0.1577099 Vali Loss: 0.1331268 Test Loss: 0.1586421
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1572483
	speed: 1.0910s/iter; left time: 6109.4158s
Epoch: 60 cost time: 64.07786059379578
Epoch: 60, Steps: 139 | Train Loss: 0.1576745 Vali Loss: 0.1330733 Test Loss: 0.1586452
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1553263
	speed: 1.0059s/iter; left time: 5493.2530s
Epoch: 61 cost time: 61.5064914226532
Epoch: 61, Steps: 139 | Train Loss: 0.1577619 Vali Loss: 0.1331032 Test Loss: 0.1586482
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1519807
	speed: 1.0012s/iter; left time: 5328.4436s
Epoch: 62 cost time: 59.843605041503906
Epoch: 62, Steps: 139 | Train Loss: 0.1576613 Vali Loss: 0.1330613 Test Loss: 0.1586435
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1695178
	speed: 0.9815s/iter; left time: 5086.9059s
Epoch: 63 cost time: 60.12864017486572
Epoch: 63, Steps: 139 | Train Loss: 0.1576258 Vali Loss: 0.1330029 Test Loss: 0.1586450
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1563168
	speed: 0.9898s/iter; left time: 4992.5564s
Epoch: 64 cost time: 60.883066177368164
Epoch: 64, Steps: 139 | Train Loss: 0.1576959 Vali Loss: 0.1330522 Test Loss: 0.1586428
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.1634692
	speed: 1.0026s/iter; left time: 4917.7127s
Epoch: 65 cost time: 62.15311598777771
Epoch: 65, Steps: 139 | Train Loss: 0.1576704 Vali Loss: 0.1330633 Test Loss: 0.1586422
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.1522170
	speed: 0.9878s/iter; left time: 4707.6803s
Epoch: 66 cost time: 62.05024170875549
Epoch: 66, Steps: 139 | Train Loss: 0.1577000 Vali Loss: 0.1330497 Test Loss: 0.1586409
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.1640939
	speed: 0.9874s/iter; left time: 4568.9194s
Epoch: 67 cost time: 59.887197494506836
Epoch: 67, Steps: 139 | Train Loss: 0.1576468 Vali Loss: 0.1330602 Test Loss: 0.1586407
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.1599175
	speed: 1.1428s/iter; left time: 5129.0266s
Epoch: 68 cost time: 70.4654929637909
Epoch: 68, Steps: 139 | Train Loss: 0.1576591 Vali Loss: 0.1331070 Test Loss: 0.1586416
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.1493217
	speed: 1.0496s/iter; left time: 4564.8360s
Epoch: 69 cost time: 62.16193389892578
Epoch: 69, Steps: 139 | Train Loss: 0.1576817 Vali Loss: 0.1330602 Test Loss: 0.1586413
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.1643173
	speed: 0.9899s/iter; left time: 4167.3556s
Epoch: 70 cost time: 60.142422914505005
Epoch: 70, Steps: 139 | Train Loss: 0.1576154 Vali Loss: 0.1330386 Test Loss: 0.1586420
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.1470772
	speed: 1.0382s/iter; left time: 4226.4354s
Epoch: 71 cost time: 66.47752451896667
Epoch: 71, Steps: 139 | Train Loss: 0.1577009 Vali Loss: 0.1330763 Test Loss: 0.1586407
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.1579933
	speed: 1.0484s/iter; left time: 4122.4827s
Epoch: 72 cost time: 58.494667291641235
Epoch: 72, Steps: 139 | Train Loss: 0.1576808 Vali Loss: 0.1330572 Test Loss: 0.1586424
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.1635839
	speed: 1.0295s/iter; left time: 3904.8844s
Epoch: 73 cost time: 60.97821354866028
Epoch: 73, Steps: 139 | Train Loss: 0.1577049 Vali Loss: 0.1330236 Test Loss: 0.1586392
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_360_j192_H8_FITS_custom_ftM_sl360_ll48_pl192_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5069
mse:0.15582913160324097, mae:0.251108318567276, rse:0.3924882709980011, corr:[0.46352622 0.46479914 0.4664807  0.4665562  0.4676558  0.4673827
 0.4676167  0.4675724  0.4670995  0.46710303 0.46683094 0.46671325
 0.46666938 0.46650818 0.46659014 0.46652496 0.46642268 0.466481
 0.4663285  0.46608034 0.4660689  0.46608338 0.46604142 0.4663716
 0.46663737 0.4666641  0.46683398 0.46676344 0.46653706 0.46653777
 0.46630022 0.46609107 0.46603304 0.46580008 0.46565825 0.4655578
 0.46541336 0.46539438 0.4652669  0.4651089  0.46506244 0.46489227
 0.46468878 0.46460253 0.46452543 0.46443602 0.4644626  0.46465153
 0.46473166 0.46487543 0.46492848 0.464768   0.4647783  0.46470004
 0.4645393  0.46450546 0.4643854  0.46432766 0.46432394 0.4642521
 0.46429792 0.4642808  0.46420413 0.4642347  0.4642044  0.46415102
 0.46412426 0.46400785 0.4638934  0.4638503  0.4638388  0.46389765
 0.46398303 0.46406612 0.4640175  0.46399572 0.46396708 0.4638713
 0.46387252 0.4638149  0.46371275 0.4637051  0.46363494 0.46362296
 0.46361026 0.46352    0.46357504 0.46357265 0.46348986 0.46356165
 0.46352553 0.46332052 0.46321222 0.46319094 0.46316314 0.46326885
 0.46340975 0.46340147 0.4634149  0.46348566 0.46339256 0.46336517
 0.4634123  0.46332726 0.4632598  0.46319616 0.4631168  0.4631186
 0.46306726 0.46306017 0.46306562 0.46299922 0.46302047 0.4630283
 0.4629971  0.46304443 0.4630615  0.4630886  0.46317953 0.46334937
 0.4634806  0.46353328 0.46362635 0.4636506  0.46362644 0.4636607
 0.46362114 0.46358737 0.46355262 0.46345034 0.46341693 0.4633243
 0.4632589  0.4633599  0.4633025  0.46325767 0.46333435 0.46328613
 0.4632982  0.46329096 0.46319452 0.46326286 0.46334994 0.46360546
 0.46398893 0.46420974 0.46430147 0.4643196  0.46437457 0.4643729
 0.46430165 0.4642673  0.46416056 0.46408918 0.464025   0.46391788
 0.46397617 0.46393383 0.4639029  0.4640542  0.46403942 0.46405992
 0.46412235 0.4638608  0.46362263 0.4635453  0.46342695 0.46345064
 0.46338332 0.46327904 0.4632011  0.46305984 0.46289355 0.46269628
 0.46247372 0.46231964 0.46216437 0.46198493 0.46192232 0.46198872
 0.46191138 0.46194464 0.46213967 0.46194106 0.46189097 0.46193808
 0.46146044 0.46143058 0.46116957 0.4611931  0.46152785 0.4616099 ]
