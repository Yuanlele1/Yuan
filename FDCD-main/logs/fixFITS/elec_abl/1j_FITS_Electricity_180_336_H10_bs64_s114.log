Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_180_j336_H10', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_180_j336_H10_FITS_custom_ftM_sl180_ll48_pl336_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17897
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=90, out_features=258, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  954063360.0
params:  23478.0
Trainable parameters:  23478
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5568230
	speed: 0.7568s/iter; left time: 10444.4367s
Epoch: 1 cost time: 103.33541679382324
Epoch: 1, Steps: 139 | Train Loss: 0.7725591 Vali Loss: 0.3686374 Test Loss: 0.4104033
Validation loss decreased (inf --> 0.368637).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3152900
	speed: 1.7026s/iter; left time: 23261.1322s
Epoch: 2 cost time: 106.86907434463501
Epoch: 2, Steps: 139 | Train Loss: 0.3361796 Vali Loss: 0.2437223 Test Loss: 0.2715265
Validation loss decreased (0.368637 --> 0.243722).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2525637
	speed: 1.6533s/iter; left time: 22357.5174s
Epoch: 3 cost time: 98.1297059059143
Epoch: 3, Steps: 139 | Train Loss: 0.2596615 Vali Loss: 0.2075938 Test Loss: 0.2343182
Validation loss decreased (0.243722 --> 0.207594).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2234517
	speed: 1.7008s/iter; left time: 22763.9099s
Epoch: 4 cost time: 104.0942645072937
Epoch: 4, Steps: 139 | Train Loss: 0.2314405 Vali Loss: 0.1892293 Test Loss: 0.2158264
Validation loss decreased (0.207594 --> 0.189229).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2127031
	speed: 1.6368s/iter; left time: 21678.7786s
Epoch: 5 cost time: 100.22496247291565
Epoch: 5, Steps: 139 | Train Loss: 0.2162298 Vali Loss: 0.1789639 Test Loss: 0.2053969
Validation loss decreased (0.189229 --> 0.178964).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2122260
	speed: 1.6892s/iter; left time: 22138.9542s
Epoch: 6 cost time: 98.77419257164001
Epoch: 6, Steps: 139 | Train Loss: 0.2075639 Vali Loss: 0.1730482 Test Loss: 0.1992536
Validation loss decreased (0.178964 --> 0.173048).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1980560
	speed: 1.6581s/iter; left time: 21500.4026s
Epoch: 7 cost time: 96.70605230331421
Epoch: 7, Steps: 139 | Train Loss: 0.2024047 Vali Loss: 0.1691952 Test Loss: 0.1955491
Validation loss decreased (0.173048 --> 0.169195).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1950074
	speed: 1.6195s/iter; left time: 20774.8697s
Epoch: 8 cost time: 100.82075786590576
Epoch: 8, Steps: 139 | Train Loss: 0.1994194 Vali Loss: 0.1671931 Test Loss: 0.1932068
Validation loss decreased (0.169195 --> 0.167193).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2121638
	speed: 1.8464s/iter; left time: 23428.7150s
Epoch: 9 cost time: 107.60073375701904
Epoch: 9, Steps: 139 | Train Loss: 0.1974186 Vali Loss: 0.1657027 Test Loss: 0.1916573
Validation loss decreased (0.167193 --> 0.165703).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2041799
	speed: 1.7136s/iter; left time: 21505.5704s
Epoch: 10 cost time: 101.98819208145142
Epoch: 10, Steps: 139 | Train Loss: 0.1961310 Vali Loss: 0.1648017 Test Loss: 0.1905986
Validation loss decreased (0.165703 --> 0.164802).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1980883
	speed: 1.8345s/iter; left time: 22768.4656s
Epoch: 11 cost time: 105.06306791305542
Epoch: 11, Steps: 139 | Train Loss: 0.1951432 Vali Loss: 0.1642685 Test Loss: 0.1897867
Validation loss decreased (0.164802 --> 0.164269).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1960654
	speed: 1.7256s/iter; left time: 21176.6164s
Epoch: 12 cost time: 94.146484375
Epoch: 12, Steps: 139 | Train Loss: 0.1944915 Vali Loss: 0.1636797 Test Loss: 0.1891679
Validation loss decreased (0.164269 --> 0.163680).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1948648
	speed: 1.8791s/iter; left time: 22798.5817s
Epoch: 13 cost time: 122.30165791511536
Epoch: 13, Steps: 139 | Train Loss: 0.1939276 Vali Loss: 0.1631843 Test Loss: 0.1886959
Validation loss decreased (0.163680 --> 0.163184).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1846246
	speed: 2.3171s/iter; left time: 27791.1075s
Epoch: 14 cost time: 124.32873439788818
Epoch: 14, Steps: 139 | Train Loss: 0.1934199 Vali Loss: 0.1627938 Test Loss: 0.1883202
Validation loss decreased (0.163184 --> 0.162794).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1981760
	speed: 2.2586s/iter; left time: 26776.1748s
Epoch: 15 cost time: 139.2759702205658
Epoch: 15, Steps: 139 | Train Loss: 0.1930602 Vali Loss: 0.1625660 Test Loss: 0.1879872
Validation loss decreased (0.162794 --> 0.162566).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1897313
	speed: 2.1952s/iter; left time: 25719.3833s
Epoch: 16 cost time: 122.5652060508728
Epoch: 16, Steps: 139 | Train Loss: 0.1927860 Vali Loss: 0.1624462 Test Loss: 0.1877211
Validation loss decreased (0.162566 --> 0.162446).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1958449
	speed: 2.2476s/iter; left time: 26020.9675s
Epoch: 17 cost time: 126.50237321853638
Epoch: 17, Steps: 139 | Train Loss: 0.1925884 Vali Loss: 0.1622014 Test Loss: 0.1874948
Validation loss decreased (0.162446 --> 0.162201).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1877424
	speed: 2.3355s/iter; left time: 26713.5914s
Epoch: 18 cost time: 131.24049854278564
Epoch: 18, Steps: 139 | Train Loss: 0.1923563 Vali Loss: 0.1617563 Test Loss: 0.1872983
Validation loss decreased (0.162201 --> 0.161756).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1954619
	speed: 2.2310s/iter; left time: 25208.0227s
Epoch: 19 cost time: 123.96920228004456
Epoch: 19, Steps: 139 | Train Loss: 0.1921485 Vali Loss: 0.1616667 Test Loss: 0.1871370
Validation loss decreased (0.161756 --> 0.161667).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2054103
	speed: 2.1616s/iter; left time: 24123.9572s
Epoch: 20 cost time: 129.6593120098114
Epoch: 20, Steps: 139 | Train Loss: 0.1920492 Vali Loss: 0.1613840 Test Loss: 0.1869966
Validation loss decreased (0.161667 --> 0.161384).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1938063
	speed: 2.2547s/iter; left time: 24848.8917s
Epoch: 21 cost time: 130.34156155586243
Epoch: 21, Steps: 139 | Train Loss: 0.1918999 Vali Loss: 0.1613586 Test Loss: 0.1868697
Validation loss decreased (0.161384 --> 0.161359).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1884398
	speed: 2.2901s/iter; left time: 24920.5502s
Epoch: 22 cost time: 130.8216404914856
Epoch: 22, Steps: 139 | Train Loss: 0.1917999 Vali Loss: 0.1612068 Test Loss: 0.1867654
Validation loss decreased (0.161359 --> 0.161207).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1882353
	speed: 2.1876s/iter; left time: 23501.8983s
Epoch: 23 cost time: 127.62820482254028
Epoch: 23, Steps: 139 | Train Loss: 0.1916581 Vali Loss: 0.1612897 Test Loss: 0.1866869
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1894036
	speed: 2.2465s/iter; left time: 23821.9471s
Epoch: 24 cost time: 129.06687450408936
Epoch: 24, Steps: 139 | Train Loss: 0.1915603 Vali Loss: 0.1608886 Test Loss: 0.1865998
Validation loss decreased (0.161207 --> 0.160889).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2043599
	speed: 2.1950s/iter; left time: 22970.6280s
Epoch: 25 cost time: 120.73207426071167
Epoch: 25, Steps: 139 | Train Loss: 0.1914509 Vali Loss: 0.1609391 Test Loss: 0.1865110
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1835033
	speed: 2.0300s/iter; left time: 20961.8541s
Epoch: 26 cost time: 114.80768203735352
Epoch: 26, Steps: 139 | Train Loss: 0.1913612 Vali Loss: 0.1607531 Test Loss: 0.1864621
Validation loss decreased (0.160889 --> 0.160753).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1814012
	speed: 2.0597s/iter; left time: 20981.9466s
Epoch: 27 cost time: 123.67497444152832
Epoch: 27, Steps: 139 | Train Loss: 0.1913667 Vali Loss: 0.1610400 Test Loss: 0.1863983
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2068032
	speed: 2.0404s/iter; left time: 20501.9154s
Epoch: 28 cost time: 116.86877822875977
Epoch: 28, Steps: 139 | Train Loss: 0.1912446 Vali Loss: 0.1607106 Test Loss: 0.1863400
Validation loss decreased (0.160753 --> 0.160711).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1881227
	speed: 2.0571s/iter; left time: 20383.5914s
Epoch: 29 cost time: 119.53227090835571
Epoch: 29, Steps: 139 | Train Loss: 0.1912205 Vali Loss: 0.1606161 Test Loss: 0.1863147
Validation loss decreased (0.160711 --> 0.160616).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1944212
	speed: 2.1211s/iter; left time: 20723.0400s
Epoch: 30 cost time: 122.98828649520874
Epoch: 30, Steps: 139 | Train Loss: 0.1911548 Vali Loss: 0.1607726 Test Loss: 0.1862569
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2069276
	speed: 2.1074s/iter; left time: 20296.8248s
Epoch: 31 cost time: 123.73409080505371
Epoch: 31, Steps: 139 | Train Loss: 0.1911644 Vali Loss: 0.1605358 Test Loss: 0.1862312
Validation loss decreased (0.160616 --> 0.160536).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1979379
	speed: 1.9961s/iter; left time: 18947.1729s
Epoch: 32 cost time: 113.79494309425354
Epoch: 32, Steps: 139 | Train Loss: 0.1911220 Vali Loss: 0.1606283 Test Loss: 0.1861976
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1991284
	speed: 2.0969s/iter; left time: 19612.4823s
Epoch: 33 cost time: 114.58518934249878
Epoch: 33, Steps: 139 | Train Loss: 0.1910873 Vali Loss: 0.1608817 Test Loss: 0.1861782
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1961767
	speed: 1.8492s/iter; left time: 17038.2332s
Epoch: 34 cost time: 102.84429216384888
Epoch: 34, Steps: 139 | Train Loss: 0.1910821 Vali Loss: 0.1606192 Test Loss: 0.1861617
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1867443
	speed: 1.8888s/iter; left time: 17141.0693s
Epoch: 35 cost time: 110.74979019165039
Epoch: 35, Steps: 139 | Train Loss: 0.1910650 Vali Loss: 0.1606046 Test Loss: 0.1861358
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1995156
	speed: 1.4019s/iter; left time: 12527.6375s
Epoch: 36 cost time: 73.07679581642151
Epoch: 36, Steps: 139 | Train Loss: 0.1910315 Vali Loss: 0.1605186 Test Loss: 0.1861168
Validation loss decreased (0.160536 --> 0.160519).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1972638
	speed: 1.2771s/iter; left time: 11234.9992s
Epoch: 37 cost time: 76.70657920837402
Epoch: 37, Steps: 139 | Train Loss: 0.1910090 Vali Loss: 0.1607694 Test Loss: 0.1860987
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1781513
	speed: 1.2610s/iter; left time: 10918.1295s
Epoch: 38 cost time: 73.41827940940857
Epoch: 38, Steps: 139 | Train Loss: 0.1910127 Vali Loss: 0.1604195 Test Loss: 0.1860830
Validation loss decreased (0.160519 --> 0.160419).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1904149
	speed: 1.2183s/iter; left time: 10378.2985s
Epoch: 39 cost time: 70.56132888793945
Epoch: 39, Steps: 139 | Train Loss: 0.1909788 Vali Loss: 0.1605712 Test Loss: 0.1860718
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1911341
	speed: 1.1181s/iter; left time: 9369.9255s
Epoch: 40 cost time: 62.19707274436951
Epoch: 40, Steps: 139 | Train Loss: 0.1909149 Vali Loss: 0.1603666 Test Loss: 0.1860644
Validation loss decreased (0.160419 --> 0.160367).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1840396
	speed: 0.9951s/iter; left time: 8200.5448s
Epoch: 41 cost time: 56.004542112350464
Epoch: 41, Steps: 139 | Train Loss: 0.1909962 Vali Loss: 0.1603466 Test Loss: 0.1860549
Validation loss decreased (0.160367 --> 0.160347).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1890217
	speed: 1.2802s/iter; left time: 10371.7773s
Epoch: 42 cost time: 73.14762616157532
Epoch: 42, Steps: 139 | Train Loss: 0.1909144 Vali Loss: 0.1605381 Test Loss: 0.1860344
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1984658
	speed: 1.0391s/iter; left time: 8274.3204s
Epoch: 43 cost time: 57.402958154678345
Epoch: 43, Steps: 139 | Train Loss: 0.1909782 Vali Loss: 0.1604781 Test Loss: 0.1860327
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1872810
	speed: 1.0556s/iter; left time: 8259.0802s
Epoch: 44 cost time: 63.71823811531067
Epoch: 44, Steps: 139 | Train Loss: 0.1908412 Vali Loss: 0.1603226 Test Loss: 0.1860342
Validation loss decreased (0.160347 --> 0.160323).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1799868
	speed: 1.0385s/iter; left time: 7980.9280s
Epoch: 45 cost time: 59.274413108825684
Epoch: 45, Steps: 139 | Train Loss: 0.1908569 Vali Loss: 0.1604694 Test Loss: 0.1860200
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1893407
	speed: 0.9707s/iter; left time: 7325.0353s
Epoch: 46 cost time: 60.75321125984192
Epoch: 46, Steps: 139 | Train Loss: 0.1909304 Vali Loss: 0.1604329 Test Loss: 0.1860094
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2014129
	speed: 1.3375s/iter; left time: 9907.0107s
Epoch: 47 cost time: 86.8221800327301
Epoch: 47, Steps: 139 | Train Loss: 0.1908346 Vali Loss: 0.1604643 Test Loss: 0.1860048
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1973356
	speed: 1.4728s/iter; left time: 10704.5432s
Epoch: 48 cost time: 86.94213461875916
Epoch: 48, Steps: 139 | Train Loss: 0.1908337 Vali Loss: 0.1602757 Test Loss: 0.1859972
Validation loss decreased (0.160323 --> 0.160276).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1789600
	speed: 1.5026s/iter; left time: 10711.7276s
Epoch: 49 cost time: 83.22496724128723
Epoch: 49, Steps: 139 | Train Loss: 0.1909210 Vali Loss: 0.1602392 Test Loss: 0.1859979
Validation loss decreased (0.160276 --> 0.160239).  Saving model ...
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1833679
	speed: 1.4440s/iter; left time: 10093.2640s
Epoch: 50 cost time: 89.00753855705261
Epoch: 50, Steps: 139 | Train Loss: 0.1909300 Vali Loss: 0.1605104 Test Loss: 0.1859947
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1972731
	speed: 1.6037s/iter; left time: 10987.0918s
Epoch: 51 cost time: 97.12073707580566
Epoch: 51, Steps: 139 | Train Loss: 0.1908624 Vali Loss: 0.1603720 Test Loss: 0.1859947
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1994898
	speed: 1.5738s/iter; left time: 10563.0956s
Epoch: 52 cost time: 94.64221286773682
Epoch: 52, Steps: 139 | Train Loss: 0.1908638 Vali Loss: 0.1603042 Test Loss: 0.1859814
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1869592
	speed: 1.5367s/iter; left time: 10100.9133s
Epoch: 53 cost time: 84.28667140007019
Epoch: 53, Steps: 139 | Train Loss: 0.1909520 Vali Loss: 0.1603747 Test Loss: 0.1859784
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1985888
	speed: 1.5039s/iter; left time: 9676.3990s
Epoch: 54 cost time: 83.65644264221191
Epoch: 54, Steps: 139 | Train Loss: 0.1908160 Vali Loss: 0.1602680 Test Loss: 0.1859782
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1954928
	speed: 1.5193s/iter; left time: 9563.8425s
Epoch: 55 cost time: 87.13864779472351
Epoch: 55, Steps: 139 | Train Loss: 0.1908128 Vali Loss: 0.1603671 Test Loss: 0.1859823
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1859703
	speed: 1.4927s/iter; left time: 9189.1481s
Epoch: 56 cost time: 85.38796257972717
Epoch: 56, Steps: 139 | Train Loss: 0.1908787 Vali Loss: 0.1601568 Test Loss: 0.1859710
Validation loss decreased (0.160239 --> 0.160157).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.1887916
	speed: 1.5030s/iter; left time: 9043.5569s
Epoch: 57 cost time: 86.15759563446045
Epoch: 57, Steps: 139 | Train Loss: 0.1908871 Vali Loss: 0.1603618 Test Loss: 0.1859696
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1960706
	speed: 1.5406s/iter; left time: 9055.9191s
Epoch: 58 cost time: 85.78951406478882
Epoch: 58, Steps: 139 | Train Loss: 0.1909360 Vali Loss: 0.1603307 Test Loss: 0.1859739
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2029114
	speed: 1.5018s/iter; left time: 8618.7848s
Epoch: 59 cost time: 87.58427000045776
Epoch: 59, Steps: 139 | Train Loss: 0.1907819 Vali Loss: 0.1602257 Test Loss: 0.1859656
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1820503
	speed: 1.5585s/iter; left time: 8727.3996s
Epoch: 60 cost time: 91.30235815048218
Epoch: 60, Steps: 139 | Train Loss: 0.1907796 Vali Loss: 0.1604632 Test Loss: 0.1859664
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1943844
	speed: 1.5558s/iter; left time: 8496.4607s
Epoch: 61 cost time: 90.94334173202515
Epoch: 61, Steps: 139 | Train Loss: 0.1907325 Vali Loss: 0.1603336 Test Loss: 0.1859639
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1814071
	speed: 1.4726s/iter; left time: 7837.3462s
Epoch: 62 cost time: 85.25605750083923
Epoch: 62, Steps: 139 | Train Loss: 0.1908448 Vali Loss: 0.1607091 Test Loss: 0.1859608
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1901670
	speed: 1.6544s/iter; left time: 8574.9759s
Epoch: 63 cost time: 99.62935185432434
Epoch: 63, Steps: 139 | Train Loss: 0.1908293 Vali Loss: 0.1603587 Test Loss: 0.1859621
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1856992
	speed: 1.5652s/iter; left time: 7894.9773s
Epoch: 64 cost time: 96.3609209060669
Epoch: 64, Steps: 139 | Train Loss: 0.1908337 Vali Loss: 0.1602131 Test Loss: 0.1859595
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.1949120
	speed: 1.7823s/iter; left time: 8742.3842s
Epoch: 65 cost time: 98.40674376487732
Epoch: 65, Steps: 139 | Train Loss: 0.1908944 Vali Loss: 0.1604529 Test Loss: 0.1859567
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.1989653
	speed: 1.8108s/iter; left time: 8630.1389s
Epoch: 66 cost time: 104.68631958961487
Epoch: 66, Steps: 139 | Train Loss: 0.1908547 Vali Loss: 0.1602947 Test Loss: 0.1859557
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.1877676
	speed: 1.6631s/iter; left time: 7695.3880s
Epoch: 67 cost time: 93.19442987442017
Epoch: 67, Steps: 139 | Train Loss: 0.1908757 Vali Loss: 0.1603861 Test Loss: 0.1859557
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.1951748
	speed: 1.6231s/iter; left time: 7284.4535s
Epoch: 68 cost time: 93.19421601295471
Epoch: 68, Steps: 139 | Train Loss: 0.1906990 Vali Loss: 0.1604767 Test Loss: 0.1859552
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.1799628
	speed: 1.5677s/iter; left time: 6817.8103s
Epoch: 69 cost time: 92.42140984535217
Epoch: 69, Steps: 139 | Train Loss: 0.1907682 Vali Loss: 0.1602204 Test Loss: 0.1859559
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.1814817
	speed: 1.5994s/iter; left time: 6733.6108s
Epoch: 70 cost time: 92.22907662391663
Epoch: 70, Steps: 139 | Train Loss: 0.1908220 Vali Loss: 0.1602204 Test Loss: 0.1859507
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.1877518
	speed: 1.6263s/iter; left time: 6620.7756s
Epoch: 71 cost time: 96.96440887451172
Epoch: 71, Steps: 139 | Train Loss: 0.1908015 Vali Loss: 0.1602666 Test Loss: 0.1859542
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.1901615
	speed: 1.5438s/iter; left time: 6070.2031s
Epoch: 72 cost time: 87.7558319568634
Epoch: 72, Steps: 139 | Train Loss: 0.1908907 Vali Loss: 0.1604513 Test Loss: 0.1859531
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.1908538
	speed: 1.4842s/iter; left time: 5629.5294s
Epoch: 73 cost time: 84.94806432723999
Epoch: 73, Steps: 139 | Train Loss: 0.1907999 Vali Loss: 0.1603651 Test Loss: 0.1859503
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.1864276
	speed: 1.4669s/iter; left time: 5360.2135s
Epoch: 74 cost time: 87.32116770744324
Epoch: 74, Steps: 139 | Train Loss: 0.1908135 Vali Loss: 0.1606872 Test Loss: 0.1859479
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.1813858
	speed: 1.4959s/iter; left time: 5258.1214s
Epoch: 75 cost time: 82.88357138633728
Epoch: 75, Steps: 139 | Train Loss: 0.1908893 Vali Loss: 0.1602228 Test Loss: 0.1859483
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.1854197
	speed: 1.4556s/iter; left time: 4914.0080s
Epoch: 76 cost time: 84.49935102462769
Epoch: 76, Steps: 139 | Train Loss: 0.1907841 Vali Loss: 0.1602930 Test Loss: 0.1859486
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_180_j336_H10_FITS_custom_ftM_sl180_ll48_pl336_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4925
mse:0.184022918343544, mae:0.27504611015319824, rse:0.42695021629333496, corr:[0.45860305 0.4615995  0.4611253  0.4618967  0.46165657 0.4620074
 0.4617623  0.46175486 0.46136665 0.4611841  0.46094432 0.46069187
 0.46055496 0.46042693 0.4604     0.46026507 0.4602467  0.4601171
 0.46020648 0.4599925  0.46007204 0.46008042 0.4605403  0.4607397
 0.46040076 0.46018097 0.46009138 0.45987514 0.45979822 0.45969462
 0.45947424 0.45933995 0.45920134 0.45910567 0.45896316 0.45881993
 0.45878172 0.4587678  0.45874563 0.45864803 0.45859218 0.45849815
 0.4584878  0.4583355  0.45823294 0.45815265 0.45830354 0.4584598
 0.45829943 0.4582171  0.45825848 0.45813277 0.45803457 0.45793322
 0.45790163 0.45782283 0.45785537 0.4578098  0.45778316 0.45768118
 0.4577408  0.45768493 0.45767134 0.45772722 0.45757774 0.45753324
 0.45746356 0.45723447 0.4570666  0.45700186 0.4571754  0.45728174
 0.45707366 0.45697948 0.45695654 0.45685974 0.45681694 0.45670512
 0.45677763 0.4567175  0.45671526 0.45665422 0.45664614 0.45664862
 0.45661086 0.45659572 0.45657358 0.45655406 0.45650387 0.45646587
 0.45644835 0.45638275 0.45640782 0.45635632 0.4565456  0.45670483
 0.4565197  0.45643142 0.45648375 0.456438   0.45644614 0.45634222
 0.45639408 0.4564155  0.45641822 0.45640182 0.45633918 0.45635286
 0.45639122 0.45636222 0.4563375  0.45628703 0.45629522 0.45620555
 0.45615065 0.45594475 0.4558197  0.45578113 0.4558414  0.45597214
 0.45589972 0.4559158  0.45607352 0.4561032  0.4561374  0.45614454
 0.45622402 0.45623815 0.45632818 0.45633632 0.4563456  0.4563512
 0.4564945  0.4564209  0.4564008  0.4563946  0.45635733 0.45634317
 0.4563155  0.45615932 0.4561061  0.4560964  0.45629618 0.4564956
 0.45640147 0.45644787 0.45656875 0.4566382  0.45670554 0.45671362
 0.45685923 0.45682952 0.45696533 0.45710075 0.4570938  0.45723078
 0.45751825 0.45770243 0.4576089  0.45753536 0.45764336 0.45773637
 0.45785072 0.45785278 0.4579982  0.45826972 0.45879054 0.45875698
 0.4578901  0.45732266 0.45699966 0.45662516 0.45633894 0.45610464
 0.4559098  0.45578808 0.45560136 0.45537508 0.45509905 0.45495355
 0.45490992 0.45466644 0.45462072 0.4545231  0.4544178  0.4543312
 0.45425925 0.45419943 0.4541778  0.4542309  0.45437574 0.45436615
 0.4539248  0.45373455 0.4536434  0.45342645 0.45332542 0.45319042
 0.45303962 0.4529551  0.45283318 0.45268816 0.45251834 0.45246127
 0.45250097 0.45248634 0.45244566 0.45252404 0.4525426  0.45257017
 0.4526361  0.45255703 0.45247722 0.45249122 0.45254987 0.45264477
 0.45249793 0.45240614 0.45242754 0.45228252 0.45215842 0.45210215
 0.45207667 0.4519847  0.45196745 0.45191607 0.45185187 0.45182684
 0.45185176 0.4518184  0.45181453 0.4518327  0.45186022 0.45186514
 0.4517794  0.45169914 0.45160374 0.4515492  0.45164084 0.4517369
 0.4515161  0.45143425 0.45145717 0.4513605  0.45134345 0.45133632
 0.45132354 0.45128208 0.451261   0.45119885 0.45111725 0.45112208
 0.45125785 0.45123217 0.45121562 0.45123664 0.45123455 0.45126075
 0.4512411  0.45132753 0.45127815 0.4513125  0.4514521  0.45150846
 0.4513633  0.45132324 0.45129955 0.45125997 0.45119366 0.4511763
 0.45126498 0.4511763  0.45117313 0.4511261  0.4511009  0.45114416
 0.45115992 0.4511707  0.45117486 0.45121288 0.4512662  0.45129734
 0.45123932 0.45113876 0.45103183 0.45095184 0.45097706 0.45111376
 0.45103678 0.45105323 0.45118904 0.4511407  0.45111513 0.4511342
 0.4511667  0.45111227 0.45113593 0.4512417  0.45135704 0.45135447
 0.45159164 0.4516327  0.4516574  0.451749   0.45169702 0.45177138
 0.45165655 0.45160538 0.45139253 0.45132563 0.4514194  0.45162296
 0.4514776  0.4515045  0.45151478 0.45158374 0.45148993 0.4515271
 0.4514934  0.4515839  0.45164865 0.45191056 0.45218712 0.4526129
 0.4532145  0.45352364 0.45353374 0.453509   0.45343047 0.45333514
 0.45322707 0.45312992 0.45321977 0.4536009  0.4538254  0.4532926 ]
