Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=22, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_90_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_90_720_FITS_ETTm1_ftM_sl90_ll48_pl720_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33751
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=22, out_features=198, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3902976.0
params:  4554.0
Trainable parameters:  4554
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.9432384
	speed: 0.0420s/iter; left time: 1099.6326s
	iters: 200, epoch: 1 | loss: 0.6784105
	speed: 0.0332s/iter; left time: 865.7698s
Epoch: 1 cost time: 9.511431455612183
Epoch: 1, Steps: 263 | Train Loss: 0.9534948 Vali Loss: 1.4057982 Test Loss: 0.8671478
Validation loss decreased (inf --> 1.405798).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5370073
	speed: 0.1247s/iter; left time: 3234.3152s
	iters: 200, epoch: 2 | loss: 0.4838205
	speed: 0.0267s/iter; left time: 688.8346s
Epoch: 2 cost time: 7.385668992996216
Epoch: 2, Steps: 263 | Train Loss: 0.5417122 Vali Loss: 1.1305538 Test Loss: 0.6014518
Validation loss decreased (1.405798 --> 1.130554).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4615216
	speed: 0.1276s/iter; left time: 3275.4656s
	iters: 200, epoch: 3 | loss: 0.4540083
	speed: 0.0272s/iter; left time: 694.5926s
Epoch: 3 cost time: 7.418679475784302
Epoch: 3, Steps: 263 | Train Loss: 0.4714014 Vali Loss: 1.0694370 Test Loss: 0.5452613
Validation loss decreased (1.130554 --> 1.069437).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4666032
	speed: 0.1314s/iter; left time: 3339.6422s
	iters: 200, epoch: 4 | loss: 0.4841689
	speed: 0.0321s/iter; left time: 812.3915s
Epoch: 4 cost time: 10.081292867660522
Epoch: 4, Steps: 263 | Train Loss: 0.4549229 Vali Loss: 1.0450692 Test Loss: 0.5234562
Validation loss decreased (1.069437 --> 1.045069).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4939571
	speed: 0.1762s/iter; left time: 4431.1940s
	iters: 200, epoch: 5 | loss: 0.4453313
	speed: 0.0329s/iter; left time: 822.9601s
Epoch: 5 cost time: 9.62392282485962
Epoch: 5, Steps: 263 | Train Loss: 0.4481536 Vali Loss: 1.0316817 Test Loss: 0.5120357
Validation loss decreased (1.045069 --> 1.031682).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4586613
	speed: 0.1666s/iter; left time: 4146.7823s
	iters: 200, epoch: 6 | loss: 0.4382471
	speed: 0.0222s/iter; left time: 549.9703s
Epoch: 6 cost time: 7.126283168792725
Epoch: 6, Steps: 263 | Train Loss: 0.4449706 Vali Loss: 1.0250901 Test Loss: 0.5053872
Validation loss decreased (1.031682 --> 1.025090).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4660484
	speed: 0.1140s/iter; left time: 2807.7674s
	iters: 200, epoch: 7 | loss: 0.4284503
	speed: 0.0231s/iter; left time: 566.4860s
Epoch: 7 cost time: 6.956801414489746
Epoch: 7, Steps: 263 | Train Loss: 0.4432503 Vali Loss: 1.0206029 Test Loss: 0.5016753
Validation loss decreased (1.025090 --> 1.020603).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4323482
	speed: 0.1136s/iter; left time: 2768.4348s
	iters: 200, epoch: 8 | loss: 0.4209255
	speed: 0.0235s/iter; left time: 570.3414s
Epoch: 8 cost time: 7.3003880977630615
Epoch: 8, Steps: 263 | Train Loss: 0.4423117 Vali Loss: 1.0180954 Test Loss: 0.4988677
Validation loss decreased (1.020603 --> 1.018095).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4358553
	speed: 0.1645s/iter; left time: 3963.5451s
	iters: 200, epoch: 9 | loss: 0.4691283
	speed: 0.0233s/iter; left time: 559.5232s
Epoch: 9 cost time: 9.550037145614624
Epoch: 9, Steps: 263 | Train Loss: 0.4417839 Vali Loss: 1.0171626 Test Loss: 0.4971592
Validation loss decreased (1.018095 --> 1.017163).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4316369
	speed: 0.1360s/iter; left time: 3241.6949s
	iters: 200, epoch: 10 | loss: 0.4447088
	speed: 0.0288s/iter; left time: 682.8585s
Epoch: 10 cost time: 8.71837306022644
Epoch: 10, Steps: 263 | Train Loss: 0.4415137 Vali Loss: 1.0159326 Test Loss: 0.4964795
Validation loss decreased (1.017163 --> 1.015933).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4549520
	speed: 0.1624s/iter; left time: 3827.1857s
	iters: 200, epoch: 11 | loss: 0.4553591
	speed: 0.0342s/iter; left time: 803.6830s
Epoch: 11 cost time: 9.03791356086731
Epoch: 11, Steps: 263 | Train Loss: 0.4413073 Vali Loss: 1.0151708 Test Loss: 0.4959499
Validation loss decreased (1.015933 --> 1.015171).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4393090
	speed: 0.1130s/iter; left time: 2633.0913s
	iters: 200, epoch: 12 | loss: 0.4741493
	speed: 0.0205s/iter; left time: 475.2991s
Epoch: 12 cost time: 6.209434747695923
Epoch: 12, Steps: 263 | Train Loss: 0.4412494 Vali Loss: 1.0144913 Test Loss: 0.4955536
Validation loss decreased (1.015171 --> 1.014491).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4148943
	speed: 0.1019s/iter; left time: 2349.3517s
	iters: 200, epoch: 13 | loss: 0.4214177
	speed: 0.0297s/iter; left time: 681.7057s
Epoch: 13 cost time: 7.40893816947937
Epoch: 13, Steps: 263 | Train Loss: 0.4412117 Vali Loss: 1.0151098 Test Loss: 0.4953540
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4408475
	speed: 0.1409s/iter; left time: 3209.4299s
	iters: 200, epoch: 14 | loss: 0.4735310
	speed: 0.0394s/iter; left time: 892.6488s
Epoch: 14 cost time: 11.714892387390137
Epoch: 14, Steps: 263 | Train Loss: 0.4411086 Vali Loss: 1.0148419 Test Loss: 0.4952054
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4003413
	speed: 0.1659s/iter; left time: 3734.7880s
	iters: 200, epoch: 15 | loss: 0.4571803
	speed: 0.0227s/iter; left time: 509.7855s
Epoch: 15 cost time: 9.23720383644104
Epoch: 15, Steps: 263 | Train Loss: 0.4410103 Vali Loss: 1.0148981 Test Loss: 0.4949417
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4334714
	speed: 0.1783s/iter; left time: 3968.6091s
	iters: 200, epoch: 16 | loss: 0.4136726
	speed: 0.0364s/iter; left time: 807.3835s
Epoch: 16 cost time: 10.659657001495361
Epoch: 16, Steps: 263 | Train Loss: 0.4410766 Vali Loss: 1.0153854 Test Loss: 0.4952362
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4439465
	speed: 0.1142s/iter; left time: 2512.6972s
	iters: 200, epoch: 17 | loss: 0.4458090
	speed: 0.0229s/iter; left time: 501.7576s
Epoch: 17 cost time: 7.147762775421143
Epoch: 17, Steps: 263 | Train Loss: 0.4411807 Vali Loss: 1.0151777 Test Loss: 0.4950833
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4551881
	speed: 0.1219s/iter; left time: 2649.9326s
	iters: 200, epoch: 18 | loss: 0.4679824
	speed: 0.0244s/iter; left time: 527.8096s
Epoch: 18 cost time: 6.745751857757568
Epoch: 18, Steps: 263 | Train Loss: 0.4410588 Vali Loss: 1.0151942 Test Loss: 0.4951944
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4601446
	speed: 0.1215s/iter; left time: 2607.8506s
	iters: 200, epoch: 19 | loss: 0.4309308
	speed: 0.0248s/iter; left time: 528.9704s
Epoch: 19 cost time: 9.108605861663818
Epoch: 19, Steps: 263 | Train Loss: 0.4410994 Vali Loss: 1.0148008 Test Loss: 0.4949849
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4642335
	speed: 0.1250s/iter; left time: 2649.8292s
	iters: 200, epoch: 20 | loss: 0.4257830
	speed: 0.0404s/iter; left time: 851.5989s
Epoch: 20 cost time: 10.99840760231018
Epoch: 20, Steps: 263 | Train Loss: 0.4411332 Vali Loss: 1.0146414 Test Loss: 0.4950359
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4199509
	speed: 0.1821s/iter; left time: 3814.0424s
	iters: 200, epoch: 21 | loss: 0.4466726
	speed: 0.0245s/iter; left time: 510.6068s
Epoch: 21 cost time: 9.150264501571655
Epoch: 21, Steps: 263 | Train Loss: 0.4411764 Vali Loss: 1.0142949 Test Loss: 0.4951201
Validation loss decreased (1.014491 --> 1.014295).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4638314
	speed: 0.1247s/iter; left time: 2577.8277s
	iters: 200, epoch: 22 | loss: 0.4255216
	speed: 0.0295s/iter; left time: 607.3570s
Epoch: 22 cost time: 7.0178773403167725
Epoch: 22, Steps: 263 | Train Loss: 0.4409171 Vali Loss: 1.0148134 Test Loss: 0.4952390
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4360363
	speed: 0.0847s/iter; left time: 1730.0521s
	iters: 200, epoch: 23 | loss: 0.3984661
	speed: 0.0213s/iter; left time: 431.7032s
Epoch: 23 cost time: 5.564553260803223
Epoch: 23, Steps: 263 | Train Loss: 0.4411322 Vali Loss: 1.0153129 Test Loss: 0.4952496
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4462147
	speed: 0.0965s/iter; left time: 1945.6147s
	iters: 200, epoch: 24 | loss: 0.4418745
	speed: 0.0319s/iter; left time: 638.9978s
Epoch: 24 cost time: 7.059819221496582
Epoch: 24, Steps: 263 | Train Loss: 0.4412028 Vali Loss: 1.0143836 Test Loss: 0.4950475
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4342192
	speed: 0.1053s/iter; left time: 2094.9318s
	iters: 200, epoch: 25 | loss: 0.4587569
	speed: 0.0241s/iter; left time: 477.6623s
Epoch: 25 cost time: 6.853479862213135
Epoch: 25, Steps: 263 | Train Loss: 0.4410435 Vali Loss: 1.0145022 Test Loss: 0.4952537
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4008823
	speed: 0.0909s/iter; left time: 1784.3705s
	iters: 200, epoch: 26 | loss: 0.4260394
	speed: 0.0192s/iter; left time: 375.2603s
Epoch: 26 cost time: 6.508132219314575
Epoch: 26, Steps: 263 | Train Loss: 0.4409646 Vali Loss: 1.0147550 Test Loss: 0.4952073
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4506316
	speed: 0.0937s/iter; left time: 1814.9204s
	iters: 200, epoch: 27 | loss: 0.4678589
	speed: 0.0172s/iter; left time: 331.1849s
Epoch: 27 cost time: 5.218307256698608
Epoch: 27, Steps: 263 | Train Loss: 0.4410824 Vali Loss: 1.0152898 Test Loss: 0.4953642
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4490622
	speed: 0.0919s/iter; left time: 1755.9137s
	iters: 200, epoch: 28 | loss: 0.4305396
	speed: 0.0185s/iter; left time: 351.6028s
Epoch: 28 cost time: 5.280324459075928
Epoch: 28, Steps: 263 | Train Loss: 0.4409816 Vali Loss: 1.0144548 Test Loss: 0.4953241
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4181875
	speed: 0.0814s/iter; left time: 1533.3482s
	iters: 200, epoch: 29 | loss: 0.4170191
	speed: 0.0174s/iter; left time: 325.2166s
Epoch: 29 cost time: 5.055229187011719
Epoch: 29, Steps: 263 | Train Loss: 0.4408931 Vali Loss: 1.0140911 Test Loss: 0.4952944
Validation loss decreased (1.014295 --> 1.014091).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4703442
	speed: 0.0853s/iter; left time: 1585.2722s
	iters: 200, epoch: 30 | loss: 0.4582639
	speed: 0.0169s/iter; left time: 312.2348s
Epoch: 30 cost time: 5.082145929336548
Epoch: 30, Steps: 263 | Train Loss: 0.4410410 Vali Loss: 1.0152887 Test Loss: 0.4953073
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4964261
	speed: 0.0836s/iter; left time: 1530.1862s
	iters: 200, epoch: 31 | loss: 0.4736675
	speed: 0.0166s/iter; left time: 302.9659s
Epoch: 31 cost time: 5.469750165939331
Epoch: 31, Steps: 263 | Train Loss: 0.4410482 Vali Loss: 1.0147656 Test Loss: 0.4952894
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4480521
	speed: 0.0997s/iter; left time: 1799.3526s
	iters: 200, epoch: 32 | loss: 0.4886550
	speed: 0.0171s/iter; left time: 307.6142s
Epoch: 32 cost time: 5.712291479110718
Epoch: 32, Steps: 263 | Train Loss: 0.4411172 Vali Loss: 1.0155042 Test Loss: 0.4954874
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4593048
	speed: 0.1125s/iter; left time: 2000.0783s
	iters: 200, epoch: 33 | loss: 0.4099434
	speed: 0.0176s/iter; left time: 311.6447s
Epoch: 33 cost time: 6.097745180130005
Epoch: 33, Steps: 263 | Train Loss: 0.4411379 Vali Loss: 1.0152174 Test Loss: 0.4954368
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4302125
	speed: 0.0943s/iter; left time: 1652.3595s
	iters: 200, epoch: 34 | loss: 0.4496832
	speed: 0.0169s/iter; left time: 293.6855s
Epoch: 34 cost time: 5.323235988616943
Epoch: 34, Steps: 263 | Train Loss: 0.4409462 Vali Loss: 1.0148107 Test Loss: 0.4953581
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4700017
	speed: 0.0897s/iter; left time: 1547.5879s
	iters: 200, epoch: 35 | loss: 0.4578888
	speed: 0.0235s/iter; left time: 403.8483s
Epoch: 35 cost time: 7.072136163711548
Epoch: 35, Steps: 263 | Train Loss: 0.4410951 Vali Loss: 1.0156263 Test Loss: 0.4953180
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4409115
	speed: 0.0994s/iter; left time: 1690.1854s
	iters: 200, epoch: 36 | loss: 0.4477601
	speed: 0.0154s/iter; left time: 259.5811s
Epoch: 36 cost time: 4.8475446701049805
Epoch: 36, Steps: 263 | Train Loss: 0.4409022 Vali Loss: 1.0151708 Test Loss: 0.4953584
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4475258
	speed: 0.0908s/iter; left time: 1518.9775s
	iters: 200, epoch: 37 | loss: 0.4492142
	speed: 0.0168s/iter; left time: 279.8329s
Epoch: 37 cost time: 5.177059888839722
Epoch: 37, Steps: 263 | Train Loss: 0.4409714 Vali Loss: 1.0149232 Test Loss: 0.4954619
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4549240
	speed: 0.0816s/iter; left time: 1344.6608s
	iters: 200, epoch: 38 | loss: 0.4903125
	speed: 0.0313s/iter; left time: 511.7331s
Epoch: 38 cost time: 7.11167573928833
Epoch: 38, Steps: 263 | Train Loss: 0.4409663 Vali Loss: 1.0156156 Test Loss: 0.4954294
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4504430
	speed: 0.1223s/iter; left time: 1982.0658s
	iters: 200, epoch: 39 | loss: 0.4011615
	speed: 0.0193s/iter; left time: 311.1049s
Epoch: 39 cost time: 7.649257659912109
Epoch: 39, Steps: 263 | Train Loss: 0.4410253 Vali Loss: 1.0153421 Test Loss: 0.4954471
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.4262087
	speed: 0.0895s/iter; left time: 1427.2964s
	iters: 200, epoch: 40 | loss: 0.4413379
	speed: 0.0190s/iter; left time: 301.3554s
Epoch: 40 cost time: 6.068976640701294
Epoch: 40, Steps: 263 | Train Loss: 0.4409678 Vali Loss: 1.0159075 Test Loss: 0.4954750
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.4258818
	speed: 0.1223s/iter; left time: 1918.1790s
	iters: 200, epoch: 41 | loss: 0.4383483
	speed: 0.0449s/iter; left time: 699.9838s
Epoch: 41 cost time: 9.755136489868164
Epoch: 41, Steps: 263 | Train Loss: 0.4409868 Vali Loss: 1.0157555 Test Loss: 0.4954772
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.4568401
	speed: 0.0880s/iter; left time: 1357.2414s
	iters: 200, epoch: 42 | loss: 0.4293934
	speed: 0.0188s/iter; left time: 287.7771s
Epoch: 42 cost time: 5.135736703872681
Epoch: 42, Steps: 263 | Train Loss: 0.4408291 Vali Loss: 1.0155621 Test Loss: 0.4955142
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.4344280
	speed: 0.0809s/iter; left time: 1226.7488s
	iters: 200, epoch: 43 | loss: 0.4663793
	speed: 0.0166s/iter; left time: 250.0892s
Epoch: 43 cost time: 5.110047101974487
Epoch: 43, Steps: 263 | Train Loss: 0.4410604 Vali Loss: 1.0151186 Test Loss: 0.4955130
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.4533854
	speed: 0.0876s/iter; left time: 1305.2213s
	iters: 200, epoch: 44 | loss: 0.4423882
	speed: 0.0189s/iter; left time: 280.2050s
Epoch: 44 cost time: 5.345118045806885
Epoch: 44, Steps: 263 | Train Loss: 0.4410705 Vali Loss: 1.0153303 Test Loss: 0.4955304
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.4480835
	speed: 0.1075s/iter; left time: 1572.9172s
	iters: 200, epoch: 45 | loss: 0.4350384
	speed: 0.0268s/iter; left time: 389.8510s
Epoch: 45 cost time: 7.053297519683838
Epoch: 45, Steps: 263 | Train Loss: 0.4409355 Vali Loss: 1.0158714 Test Loss: 0.4955037
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.4168721
	speed: 0.0910s/iter; left time: 1306.9236s
	iters: 200, epoch: 46 | loss: 0.4682148
	speed: 0.0223s/iter; left time: 318.5557s
Epoch: 46 cost time: 7.383193731307983
Epoch: 46, Steps: 263 | Train Loss: 0.4410572 Vali Loss: 1.0156800 Test Loss: 0.4954989
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.4460702
	speed: 0.0957s/iter; left time: 1350.2218s
	iters: 200, epoch: 47 | loss: 0.4466061
	speed: 0.0271s/iter; left time: 379.1131s
Epoch: 47 cost time: 6.60243558883667
Epoch: 47, Steps: 263 | Train Loss: 0.4408251 Vali Loss: 1.0151331 Test Loss: 0.4955096
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.4267818
	speed: 0.1323s/iter; left time: 1830.5705s
	iters: 200, epoch: 48 | loss: 0.4668316
	speed: 0.0209s/iter; left time: 287.6785s
Epoch: 48 cost time: 6.1296186447143555
Epoch: 48, Steps: 263 | Train Loss: 0.4409721 Vali Loss: 1.0156559 Test Loss: 0.4955017
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.4663988
	speed: 0.0831s/iter; left time: 1128.6710s
	iters: 200, epoch: 49 | loss: 0.4054176
	speed: 0.0169s/iter; left time: 228.3472s
Epoch: 49 cost time: 5.241067886352539
Epoch: 49, Steps: 263 | Train Loss: 0.4409524 Vali Loss: 1.0144076 Test Loss: 0.4954761
EarlyStopping counter: 20 out of 20
Early stopping
train 33751
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=22, out_features=198, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3902976.0
params:  4554.0
Trainable parameters:  4554
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5055229
	speed: 0.0250s/iter; left time: 653.9322s
	iters: 200, epoch: 1 | loss: 0.4644850
	speed: 0.0166s/iter; left time: 433.3619s
Epoch: 1 cost time: 5.175027132034302
Epoch: 1, Steps: 263 | Train Loss: 0.4935546 Vali Loss: 1.0135704 Test Loss: 0.4939278
Validation loss decreased (inf --> 1.013570).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5033247
	speed: 0.0789s/iter; left time: 2046.0065s
	iters: 200, epoch: 2 | loss: 0.4487317
	speed: 0.0163s/iter; left time: 420.1366s
Epoch: 2 cost time: 4.90357518196106
Epoch: 2, Steps: 263 | Train Loss: 0.4933908 Vali Loss: 1.0124511 Test Loss: 0.4937508
Validation loss decreased (1.013570 --> 1.012451).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4843796
	speed: 0.0825s/iter; left time: 2117.9650s
	iters: 200, epoch: 3 | loss: 0.4697024
	speed: 0.0171s/iter; left time: 437.3186s
Epoch: 3 cost time: 5.34967827796936
Epoch: 3, Steps: 263 | Train Loss: 0.4933847 Vali Loss: 1.0129179 Test Loss: 0.4938892
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4773664
	speed: 0.0845s/iter; left time: 2147.5814s
	iters: 200, epoch: 4 | loss: 0.4936760
	speed: 0.0198s/iter; left time: 500.1523s
Epoch: 4 cost time: 5.300111532211304
Epoch: 4, Steps: 263 | Train Loss: 0.4932671 Vali Loss: 1.0128708 Test Loss: 0.4935928
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4271488
	speed: 0.0979s/iter; left time: 2461.0822s
	iters: 200, epoch: 5 | loss: 0.4959356
	speed: 0.0165s/iter; left time: 412.0781s
Epoch: 5 cost time: 6.552149534225464
Epoch: 5, Steps: 263 | Train Loss: 0.4933876 Vali Loss: 1.0129544 Test Loss: 0.4936167
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4832972
	speed: 0.1109s/iter; left time: 2759.3460s
	iters: 200, epoch: 6 | loss: 0.4452482
	speed: 0.0215s/iter; left time: 531.7579s
Epoch: 6 cost time: 5.602972030639648
Epoch: 6, Steps: 263 | Train Loss: 0.4933980 Vali Loss: 1.0133796 Test Loss: 0.4942042
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.5178425
	speed: 0.0887s/iter; left time: 2184.4779s
	iters: 200, epoch: 7 | loss: 0.5702372
	speed: 0.0164s/iter; left time: 402.2453s
Epoch: 7 cost time: 5.21858811378479
Epoch: 7, Steps: 263 | Train Loss: 0.4933103 Vali Loss: 1.0133448 Test Loss: 0.4944819
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4815435
	speed: 0.1145s/iter; left time: 2788.0425s
	iters: 200, epoch: 8 | loss: 0.4677916
	speed: 0.0294s/iter; left time: 712.7337s
Epoch: 8 cost time: 8.413143873214722
Epoch: 8, Steps: 263 | Train Loss: 0.4932243 Vali Loss: 1.0127968 Test Loss: 0.4943377
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4448614
	speed: 0.0874s/iter; left time: 2105.7337s
	iters: 200, epoch: 9 | loss: 0.4497283
	speed: 0.0169s/iter; left time: 405.3298s
Epoch: 9 cost time: 5.13819694519043
Epoch: 9, Steps: 263 | Train Loss: 0.4932824 Vali Loss: 1.0131549 Test Loss: 0.4942517
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.5358462
	speed: 0.0910s/iter; left time: 2168.8167s
	iters: 200, epoch: 10 | loss: 0.4779045
	speed: 0.0170s/iter; left time: 402.3655s
Epoch: 10 cost time: 5.670050621032715
Epoch: 10, Steps: 263 | Train Loss: 0.4933617 Vali Loss: 1.0136545 Test Loss: 0.4944814
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.5418254
	speed: 0.0939s/iter; left time: 2212.3244s
	iters: 200, epoch: 11 | loss: 0.5074186
	speed: 0.0300s/iter; left time: 704.2871s
Epoch: 11 cost time: 7.519292593002319
Epoch: 11, Steps: 263 | Train Loss: 0.4932661 Vali Loss: 1.0136071 Test Loss: 0.4941425
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4596354
	speed: 0.0916s/iter; left time: 2134.8237s
	iters: 200, epoch: 12 | loss: 0.4962105
	speed: 0.0191s/iter; left time: 443.4451s
Epoch: 12 cost time: 5.419645071029663
Epoch: 12, Steps: 263 | Train Loss: 0.4932983 Vali Loss: 1.0129488 Test Loss: 0.4942291
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4747672
	speed: 0.1330s/iter; left time: 3064.6686s
	iters: 200, epoch: 13 | loss: 0.4781950
	speed: 0.0189s/iter; left time: 433.5511s
Epoch: 13 cost time: 7.234738349914551
Epoch: 13, Steps: 263 | Train Loss: 0.4932016 Vali Loss: 1.0132201 Test Loss: 0.4945111
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4867309
	speed: 0.1203s/iter; left time: 2739.6136s
	iters: 200, epoch: 14 | loss: 0.4713936
	speed: 0.0183s/iter; left time: 415.3499s
Epoch: 14 cost time: 5.605001926422119
Epoch: 14, Steps: 263 | Train Loss: 0.4931613 Vali Loss: 1.0134262 Test Loss: 0.4943073
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4915438
	speed: 0.0873s/iter; left time: 1965.1161s
	iters: 200, epoch: 15 | loss: 0.5028996
	speed: 0.0186s/iter; left time: 416.1208s
Epoch: 15 cost time: 5.695894718170166
Epoch: 15, Steps: 263 | Train Loss: 0.4932363 Vali Loss: 1.0131524 Test Loss: 0.4943582
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4843268
	speed: 0.0862s/iter; left time: 1917.9064s
	iters: 200, epoch: 16 | loss: 0.5074133
	speed: 0.0155s/iter; left time: 343.6987s
Epoch: 16 cost time: 4.767117500305176
Epoch: 16, Steps: 263 | Train Loss: 0.4932427 Vali Loss: 1.0133270 Test Loss: 0.4946127
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4735497
	speed: 0.0939s/iter; left time: 2064.6463s
	iters: 200, epoch: 17 | loss: 0.5257536
	speed: 0.0182s/iter; left time: 397.5653s
Epoch: 17 cost time: 6.244464874267578
Epoch: 17, Steps: 263 | Train Loss: 0.4931963 Vali Loss: 1.0123968 Test Loss: 0.4944330
Validation loss decreased (1.012451 --> 1.012397).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4740230
	speed: 0.1116s/iter; left time: 2424.5771s
	iters: 200, epoch: 18 | loss: 0.4946720
	speed: 0.0188s/iter; left time: 406.1279s
Epoch: 18 cost time: 6.332891464233398
Epoch: 18, Steps: 263 | Train Loss: 0.4932813 Vali Loss: 1.0126380 Test Loss: 0.4944521
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4766100
	speed: 0.0949s/iter; left time: 2036.7841s
	iters: 200, epoch: 19 | loss: 0.5148659
	speed: 0.0207s/iter; left time: 442.7604s
Epoch: 19 cost time: 5.749085903167725
Epoch: 19, Steps: 263 | Train Loss: 0.4931003 Vali Loss: 1.0135760 Test Loss: 0.4943931
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4954889
	speed: 0.0932s/iter; left time: 1976.4832s
	iters: 200, epoch: 20 | loss: 0.5282921
	speed: 0.0165s/iter; left time: 347.3807s
Epoch: 20 cost time: 4.937981605529785
Epoch: 20, Steps: 263 | Train Loss: 0.4932186 Vali Loss: 1.0138384 Test Loss: 0.4943849
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.5431557
	speed: 0.0827s/iter; left time: 1731.2594s
	iters: 200, epoch: 21 | loss: 0.4634399
	speed: 0.0253s/iter; left time: 526.9639s
Epoch: 21 cost time: 5.804610967636108
Epoch: 21, Steps: 263 | Train Loss: 0.4930873 Vali Loss: 1.0125006 Test Loss: 0.4944778
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.5203068
	speed: 0.0870s/iter; left time: 1799.3530s
	iters: 200, epoch: 22 | loss: 0.5193399
	speed: 0.0178s/iter; left time: 365.8262s
Epoch: 22 cost time: 5.28182578086853
Epoch: 22, Steps: 263 | Train Loss: 0.4932841 Vali Loss: 1.0130848 Test Loss: 0.4944752
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.5085611
	speed: 0.0956s/iter; left time: 1951.5488s
	iters: 200, epoch: 23 | loss: 0.4985620
	speed: 0.0172s/iter; left time: 349.6911s
Epoch: 23 cost time: 6.643185377120972
Epoch: 23, Steps: 263 | Train Loss: 0.4931446 Vali Loss: 1.0125237 Test Loss: 0.4945155
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4768685
	speed: 0.0944s/iter; left time: 1901.6339s
	iters: 200, epoch: 24 | loss: 0.4856274
	speed: 0.0167s/iter; left time: 333.8959s
Epoch: 24 cost time: 5.407784700393677
Epoch: 24, Steps: 263 | Train Loss: 0.4932492 Vali Loss: 1.0131558 Test Loss: 0.4944565
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.5050281
	speed: 0.0838s/iter; left time: 1666.0882s
	iters: 200, epoch: 25 | loss: 0.4599575
	speed: 0.0166s/iter; left time: 327.5779s
Epoch: 25 cost time: 5.074389219284058
Epoch: 25, Steps: 263 | Train Loss: 0.4930924 Vali Loss: 1.0134122 Test Loss: 0.4946344
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4573860
	speed: 0.0897s/iter; left time: 1759.9300s
	iters: 200, epoch: 26 | loss: 0.5119782
	speed: 0.0309s/iter; left time: 604.1286s
Epoch: 26 cost time: 7.055142879486084
Epoch: 26, Steps: 263 | Train Loss: 0.4930893 Vali Loss: 1.0125670 Test Loss: 0.4944096
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4635880
	speed: 0.0834s/iter; left time: 1615.3183s
	iters: 200, epoch: 27 | loss: 0.4800122
	speed: 0.0165s/iter; left time: 317.3096s
Epoch: 27 cost time: 6.279249429702759
Epoch: 27, Steps: 263 | Train Loss: 0.4932522 Vali Loss: 1.0136530 Test Loss: 0.4944904
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.5387889
	speed: 0.1185s/iter; left time: 2262.4476s
	iters: 200, epoch: 28 | loss: 0.4525937
	speed: 0.0235s/iter; left time: 445.7440s
Epoch: 28 cost time: 6.614181756973267
Epoch: 28, Steps: 263 | Train Loss: 0.4930620 Vali Loss: 1.0126359 Test Loss: 0.4944475
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4941904
	speed: 0.0893s/iter; left time: 1681.9827s
	iters: 200, epoch: 29 | loss: 0.4772353
	speed: 0.0171s/iter; left time: 321.1962s
Epoch: 29 cost time: 5.068368673324585
Epoch: 29, Steps: 263 | Train Loss: 0.4931271 Vali Loss: 1.0132912 Test Loss: 0.4946018
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4810631
	speed: 0.0953s/iter; left time: 1770.9241s
	iters: 200, epoch: 30 | loss: 0.5233411
	speed: 0.0236s/iter; left time: 435.8001s
Epoch: 30 cost time: 7.291877746582031
Epoch: 30, Steps: 263 | Train Loss: 0.4931304 Vali Loss: 1.0135946 Test Loss: 0.4945455
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4812449
	speed: 0.0947s/iter; left time: 1733.7472s
	iters: 200, epoch: 31 | loss: 0.5171757
	speed: 0.0254s/iter; left time: 461.8973s
Epoch: 31 cost time: 6.568906545639038
Epoch: 31, Steps: 263 | Train Loss: 0.4932144 Vali Loss: 1.0132110 Test Loss: 0.4944289
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4697619
	speed: 0.0990s/iter; left time: 1786.6023s
	iters: 200, epoch: 32 | loss: 0.5038494
	speed: 0.0178s/iter; left time: 318.7510s
Epoch: 32 cost time: 5.50446891784668
Epoch: 32, Steps: 263 | Train Loss: 0.4931197 Vali Loss: 1.0128084 Test Loss: 0.4947110
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4650993
	speed: 0.1478s/iter; left time: 2628.9734s
	iters: 200, epoch: 33 | loss: 0.4960078
	speed: 0.0309s/iter; left time: 546.4627s
Epoch: 33 cost time: 8.43202543258667
Epoch: 33, Steps: 263 | Train Loss: 0.4929888 Vali Loss: 1.0122545 Test Loss: 0.4945364
Validation loss decreased (1.012397 --> 1.012254).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4986215
	speed: 0.1023s/iter; left time: 1792.7572s
	iters: 200, epoch: 34 | loss: 0.5088213
	speed: 0.0163s/iter; left time: 283.6234s
Epoch: 34 cost time: 5.708763360977173
Epoch: 34, Steps: 263 | Train Loss: 0.4931279 Vali Loss: 1.0132118 Test Loss: 0.4945818
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4553014
	speed: 0.0849s/iter; left time: 1464.4342s
	iters: 200, epoch: 35 | loss: 0.4439234
	speed: 0.0174s/iter; left time: 298.6305s
Epoch: 35 cost time: 5.09173846244812
Epoch: 35, Steps: 263 | Train Loss: 0.4931006 Vali Loss: 1.0135218 Test Loss: 0.4945447
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4959725
	speed: 0.1052s/iter; left time: 1788.4901s
	iters: 200, epoch: 36 | loss: 0.5042556
	speed: 0.0168s/iter; left time: 284.3281s
Epoch: 36 cost time: 5.461522817611694
Epoch: 36, Steps: 263 | Train Loss: 0.4930951 Vali Loss: 1.0125936 Test Loss: 0.4945311
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.5261024
	speed: 0.0873s/iter; left time: 1460.2871s
	iters: 200, epoch: 37 | loss: 0.4989073
	speed: 0.0172s/iter; left time: 286.2489s
Epoch: 37 cost time: 5.141268491744995
Epoch: 37, Steps: 263 | Train Loss: 0.4930463 Vali Loss: 1.0129988 Test Loss: 0.4945822
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4454113
	speed: 0.0973s/iter; left time: 1601.7646s
	iters: 200, epoch: 38 | loss: 0.5121074
	speed: 0.0172s/iter; left time: 282.0860s
Epoch: 38 cost time: 5.651155233383179
Epoch: 38, Steps: 263 | Train Loss: 0.4930998 Vali Loss: 1.0129946 Test Loss: 0.4945409
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4605448
	speed: 0.0882s/iter; left time: 1429.9713s
	iters: 200, epoch: 39 | loss: 0.4789464
	speed: 0.0192s/iter; left time: 308.7510s
Epoch: 39 cost time: 5.252024412155151
Epoch: 39, Steps: 263 | Train Loss: 0.4929762 Vali Loss: 1.0130670 Test Loss: 0.4945960
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.4979429
	speed: 0.0855s/iter; left time: 1362.8515s
	iters: 200, epoch: 40 | loss: 0.5020561
	speed: 0.0230s/iter; left time: 364.4688s
Epoch: 40 cost time: 5.645478248596191
Epoch: 40, Steps: 263 | Train Loss: 0.4929604 Vali Loss: 1.0132222 Test Loss: 0.4946661
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.5475658
	speed: 0.0939s/iter; left time: 1472.8948s
	iters: 200, epoch: 41 | loss: 0.5454548
	speed: 0.0202s/iter; left time: 314.3462s
Epoch: 41 cost time: 5.756716012954712
Epoch: 41, Steps: 263 | Train Loss: 0.4930999 Vali Loss: 1.0139943 Test Loss: 0.4945962
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.4756959
	speed: 0.0873s/iter; left time: 1346.2164s
	iters: 200, epoch: 42 | loss: 0.4382045
	speed: 0.0188s/iter; left time: 288.2700s
Epoch: 42 cost time: 5.471515893936157
Epoch: 42, Steps: 263 | Train Loss: 0.4930396 Vali Loss: 1.0126741 Test Loss: 0.4945991
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.4894432
	speed: 0.1032s/iter; left time: 1563.5969s
	iters: 200, epoch: 43 | loss: 0.4856195
	speed: 0.0197s/iter; left time: 295.9591s
Epoch: 43 cost time: 6.934331893920898
Epoch: 43, Steps: 263 | Train Loss: 0.4928709 Vali Loss: 1.0141777 Test Loss: 0.4946015
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.5347535
	speed: 0.0968s/iter; left time: 1441.2616s
	iters: 200, epoch: 44 | loss: 0.4543884
	speed: 0.0168s/iter; left time: 248.1229s
Epoch: 44 cost time: 4.96453595161438
Epoch: 44, Steps: 263 | Train Loss: 0.4931679 Vali Loss: 1.0131921 Test Loss: 0.4946356
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.4463119
	speed: 0.0796s/iter; left time: 1165.1857s
	iters: 200, epoch: 45 | loss: 0.4806172
	speed: 0.0177s/iter; left time: 257.1651s
Epoch: 45 cost time: 5.249399900436401
Epoch: 45, Steps: 263 | Train Loss: 0.4930806 Vali Loss: 1.0128443 Test Loss: 0.4946263
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.4855436
	speed: 0.0794s/iter; left time: 1140.5126s
	iters: 200, epoch: 46 | loss: 0.4775160
	speed: 0.0165s/iter; left time: 234.7229s
Epoch: 46 cost time: 4.885494709014893
Epoch: 46, Steps: 263 | Train Loss: 0.4931381 Vali Loss: 1.0131388 Test Loss: 0.4946351
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.5109817
	speed: 0.0908s/iter; left time: 1281.2432s
	iters: 200, epoch: 47 | loss: 0.4749851
	speed: 0.0173s/iter; left time: 241.8429s
Epoch: 47 cost time: 4.961994647979736
Epoch: 47, Steps: 263 | Train Loss: 0.4930772 Vali Loss: 1.0134531 Test Loss: 0.4945984
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.5061460
	speed: 0.0967s/iter; left time: 1337.8201s
	iters: 200, epoch: 48 | loss: 0.4722318
	speed: 0.0229s/iter; left time: 315.0389s
Epoch: 48 cost time: 6.566814184188843
Epoch: 48, Steps: 263 | Train Loss: 0.4931141 Vali Loss: 1.0133352 Test Loss: 0.4945971
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.4375302
	speed: 0.1104s/iter; left time: 1498.4129s
	iters: 200, epoch: 49 | loss: 0.5181898
	speed: 0.0305s/iter; left time: 411.4454s
Epoch: 49 cost time: 9.33086347579956
Epoch: 49, Steps: 263 | Train Loss: 0.4931256 Vali Loss: 1.0141317 Test Loss: 0.4946279
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.5064730
	speed: 0.0989s/iter; left time: 1317.2616s
	iters: 200, epoch: 50 | loss: 0.4802215
	speed: 0.0180s/iter; left time: 238.0940s
Epoch: 50 cost time: 5.053279161453247
Epoch: 50, Steps: 263 | Train Loss: 0.4930226 Vali Loss: 1.0140085 Test Loss: 0.4946306
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.4747488
	speed: 0.0898s/iter; left time: 1172.2832s
	iters: 200, epoch: 51 | loss: 0.4738182
	speed: 0.0194s/iter; left time: 250.8754s
Epoch: 51 cost time: 5.715366363525391
Epoch: 51, Steps: 263 | Train Loss: 0.4930875 Vali Loss: 1.0132997 Test Loss: 0.4946321
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.4820603
	speed: 0.0960s/iter; left time: 1228.1031s
	iters: 200, epoch: 52 | loss: 0.5260710
	speed: 0.0230s/iter; left time: 291.4702s
Epoch: 52 cost time: 5.914673328399658
Epoch: 52, Steps: 263 | Train Loss: 0.4930972 Vali Loss: 1.0139984 Test Loss: 0.4946293
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.5018724
	speed: 0.0862s/iter; left time: 1079.5230s
	iters: 200, epoch: 53 | loss: 0.5365924
	speed: 0.0259s/iter; left time: 321.4550s
Epoch: 53 cost time: 8.111949443817139
Epoch: 53, Steps: 263 | Train Loss: 0.4931928 Vali Loss: 1.0137323 Test Loss: 0.4946474
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_90_720_FITS_ETTm1_ftM_sl90_ll48_pl720_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.49258893728256226, mae:0.4531060457229614, rse:0.667748749256134, corr:[0.5312778  0.53017473 0.5260004  0.52473694 0.52147424 0.51729524
 0.51550275 0.5146517  0.51271063 0.5108237  0.510017   0.5092764
 0.5078357  0.5059682  0.50349396 0.49988848 0.4959579  0.49279907
 0.49018955 0.4872446  0.48395315 0.48099995 0.4783854  0.47514835
 0.47108945 0.4670073  0.46404943 0.4618945  0.4598245  0.45769426
 0.45656708 0.45688754 0.45718437 0.45724016 0.4575399  0.4582015
 0.45818165 0.4577707  0.45760524 0.45770046 0.45769298 0.4571179
 0.45668846 0.4567496  0.456604   0.45601013 0.45556313 0.45571673
 0.45628822 0.45677146 0.45704874 0.45723015 0.4576938  0.45813146
 0.4585745  0.4589828  0.45954153 0.4599715  0.45982674 0.4596039
 0.4595908  0.4593349  0.45905322 0.45877773 0.45884725 0.45881778
 0.45832175 0.45784077 0.45816153 0.45906094 0.45963198 0.4599574
 0.46057546 0.46136013 0.46214876 0.46262908 0.46340168 0.4646029
 0.4657398  0.46652594 0.46703765 0.4673743  0.46790096 0.4683029
 0.4686283  0.46901703 0.4696867  0.47056824 0.4714699  0.47243717
 0.47350454 0.47439077 0.47481498 0.47489306 0.47500232 0.47496763
 0.4743786  0.47338533 0.47238106 0.47163242 0.47119454 0.47097385
 0.4707132  0.47018126 0.4696568  0.46922037 0.46862674 0.46779236
 0.4668797  0.46604818 0.46518525 0.46415886 0.46307835 0.46214938
 0.46132785 0.4606205  0.45974064 0.45855212 0.45721495 0.45598793
 0.45495    0.4535756  0.45192528 0.45086268 0.45036778 0.44976634
 0.44888267 0.44815958 0.44794744 0.44798797 0.4479456  0.44789192
 0.44786948 0.44803143 0.447977   0.4476343  0.44732046 0.4472251
 0.4471061  0.44685376 0.44661617 0.44656622 0.44656825 0.44660953
 0.44668844 0.4469375  0.4472992  0.44748637 0.44779915 0.4480601
 0.44821358 0.44856623 0.44893944 0.44920367 0.4492542  0.44935676
 0.44942436 0.44940355 0.4492356  0.44908446 0.44917706 0.4493558
 0.44952026 0.44968897 0.44997314 0.4503708  0.4509738  0.45178407
 0.45260906 0.4532554  0.4538128  0.45466375 0.45558512 0.4564257
 0.4570709  0.45762756 0.45807788 0.45839167 0.45852825 0.45878276
 0.45920908 0.4597893  0.46032774 0.4608499  0.46147642 0.46232373
 0.46329352 0.4639393  0.46401125 0.463836   0.463984   0.46449444
 0.46505466 0.46565914 0.46638298 0.4672086  0.4680078  0.46867666
 0.4690034  0.46880287 0.4683694  0.4678431  0.4670702  0.4660464
 0.46482113 0.463418   0.46168336 0.45991516 0.45837137 0.457154
 0.45590442 0.45445856 0.4530072  0.4515421  0.44997972 0.44833952
 0.4462669  0.44404823 0.44220847 0.44111627 0.44019875 0.43914425
 0.4383558  0.43845966 0.4389203  0.43916765 0.43931895 0.43895927
 0.4383045  0.4379703  0.43796176 0.43784553 0.43763018 0.43727425
 0.43698534 0.4368003  0.4364738  0.43629938 0.43643412 0.4363548
 0.4363167  0.43632415 0.43662065 0.43719962 0.43746296 0.43767193
 0.4380299  0.43859336 0.4390626  0.43953133 0.43979403 0.44009817
 0.4401281  0.43999407 0.4396664  0.43983585 0.44003835 0.43990818
 0.43986607 0.4403066  0.4407147  0.44098857 0.4412928  0.44183105
 0.44295967 0.4439729  0.44461277 0.4453144  0.44649255 0.44768283
 0.44867146 0.44922602 0.4496812  0.4501878  0.45077273 0.45129493
 0.4517641  0.45236194 0.45299414 0.4537542  0.45455313 0.45535612
 0.4561854  0.45690802 0.45737857 0.45741156 0.4568803  0.4557348
 0.45386896 0.45150423 0.44922796 0.4475764  0.44667584 0.4462975
 0.446026   0.44567144 0.44547737 0.4453375  0.44493106 0.4441147
 0.4430146  0.44177946 0.44041756 0.4389339  0.43769133 0.4368049
 0.4362627  0.435548   0.43463764 0.43368903 0.43282768 0.43191373
 0.4307968  0.429652   0.42879453 0.42830718 0.42768827 0.42709216
 0.42666724 0.42644045 0.4262927  0.42605284 0.42574972 0.42562243
 0.42550224 0.42539272 0.42508566 0.42466182 0.42425346 0.42386237
 0.42371523 0.42357463 0.42348838 0.423339   0.42322487 0.42309773
 0.42314124 0.42315763 0.42344424 0.4235784  0.42371008 0.42387286
 0.4242339  0.42485455 0.4252656  0.42536616 0.42531013 0.42529476
 0.42530763 0.42520204 0.42519477 0.42530727 0.42540032 0.42538878
 0.4252765  0.42520654 0.4253802  0.42577663 0.42632473 0.42697245
 0.42754924 0.4278957  0.4282017  0.42881775 0.4301368  0.4316467
 0.432803   0.433713   0.43446746 0.4350418  0.43572673 0.43645716
 0.4373278  0.43825823 0.43954608 0.4411602  0.4427537  0.444154
 0.44533733 0.44619396 0.4466672  0.44689485 0.4468632  0.4466824
 0.44650847 0.44648647 0.4466087  0.44685492 0.4474387  0.44848898
 0.44943845 0.44976535 0.44968897 0.44939983 0.44897836 0.44834563
 0.44743675 0.44636387 0.4451153  0.44388786 0.4427004  0.44159502
 0.44063354 0.43995598 0.43952745 0.43886158 0.43763644 0.43620655
 0.43514675 0.43406433 0.43303034 0.43248925 0.4321214  0.4316506
 0.4312261  0.4308142  0.4306949  0.43065584 0.43050593 0.43034923
 0.4300497  0.4297732  0.42953622 0.4294193  0.42932573 0.42914706
 0.42882422 0.4286018  0.42821836 0.4280121  0.4279301  0.42802855
 0.42816797 0.4281302  0.42816687 0.42845213 0.4287499  0.42903963
 0.42938343 0.42992732 0.4304248  0.43067557 0.4307193  0.43084624
 0.43112177 0.43150565 0.43152496 0.43132502 0.43114558 0.4312127
 0.43127987 0.43136287 0.43136108 0.43149343 0.43169153 0.43216255
 0.43283084 0.43331927 0.43365794 0.43423346 0.43511325 0.43610808
 0.43707737 0.43800357 0.43861145 0.43904918 0.43958077 0.4402877
 0.4410191  0.44165865 0.44253942 0.4436213  0.444679   0.4456384
 0.44650912 0.44719172 0.44747326 0.44729218 0.44661376 0.4455585
 0.4442946  0.44312227 0.44213587 0.44125205 0.4404816  0.44011942
 0.4400695  0.44009715 0.4401073  0.43976298 0.43895537 0.4378562
 0.4366532  0.43533397 0.43382454 0.43220794 0.4307107  0.42935956
 0.42798868 0.42673808 0.42570212 0.42473057 0.42385525 0.42280978
 0.42169857 0.420437   0.41917264 0.41809726 0.41721827 0.416703
 0.41645953 0.4164532  0.41630656 0.41596347 0.4156381  0.4156599
 0.41573432 0.41575897 0.41571376 0.41535452 0.41499233 0.41476282
 0.41461557 0.4146608  0.414505   0.41414446 0.41366202 0.4134571
 0.41351366 0.41373935 0.41388652 0.41382754 0.41370317 0.41373447
 0.4141151  0.4145099  0.41485772 0.4150526  0.41505396 0.41489592
 0.41504374 0.41535217 0.4154452  0.41516793 0.41468722 0.41450468
 0.41460884 0.41470453 0.4147016  0.4147489  0.41499576 0.4155963
 0.4162226  0.4164868  0.41673735 0.41743258 0.41860902 0.4198122
 0.42084497 0.4218482  0.4226818  0.42320827 0.4236724  0.42431462
 0.42511168 0.42607787 0.4270194  0.4280769  0.42922342 0.4302899
 0.43118593 0.43177068 0.4319723  0.4316393  0.43068334 0.4292193
 0.42747977 0.4257459  0.42420095 0.42307514 0.42280036 0.42316195
 0.42345345 0.42348716 0.4236645  0.4238922  0.42362446 0.42263538
 0.42118865 0.4196068  0.4179462  0.41636726 0.41502574 0.41394958
 0.41311604 0.41229397 0.411255   0.40991995 0.408526   0.40733644
 0.40637308 0.4053428  0.4042683  0.40333804 0.40251982 0.4019825
 0.40171453 0.40170848 0.4015702  0.40133557 0.40113407 0.40126902
 0.401393   0.4014396  0.4014812  0.40140432 0.40132388 0.40102008
 0.40083438 0.40095678 0.4009768  0.4007834  0.40060833 0.40068755
 0.40078512 0.40085328 0.40113148 0.4013148  0.40140128 0.40153983
 0.4017061  0.40192783 0.40226904 0.40225467 0.40207934 0.40200236
 0.40209782 0.4019552  0.40136108 0.40060154 0.40043312 0.4007191
 0.40078577 0.40053844 0.40049326 0.4009543  0.40139636 0.4017803
 0.40231445 0.40290076 0.40329874 0.40373668 0.40437686 0.40543342
 0.40645966 0.4072944  0.4079316  0.4085748  0.4092931  0.40997303
 0.41054446 0.41118443 0.41226804 0.4135789  0.4147204  0.41564146
 0.41647014 0.4171512  0.41737598 0.41692284 0.41588777 0.41435242
 0.412377   0.41057047 0.40978077 0.40984347 0.40992492 0.4098656
 0.41026863 0.41122654 0.41197088 0.41186747 0.41118556 0.41046104
 0.4095988  0.40820706 0.4064697  0.4049066  0.40357053 0.4019941
 0.40038788 0.3992341  0.39845374 0.3972796  0.39541537 0.39380118
 0.3929623  0.39213747 0.39056078 0.38905123 0.38856018 0.3884855
 0.38775036 0.38658893 0.3863199  0.3864786  0.38567242 0.3847016
 0.38499698 0.38601834 0.38590094 0.38489124 0.38508826 0.38634738
 0.3864584  0.38599443 0.38757446 0.3899344  0.3899835  0.39116427]
