Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=14, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_90_96', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_90_96_FITS_ETTm1_ftM_sl90_ll48_pl96_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34375
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=14, out_features=28, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  351232.0
params:  420.0
Trainable parameters:  420
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5054992
	speed: 0.0896s/iter; left time: 2392.9331s
	iters: 200, epoch: 1 | loss: 0.3860427
	speed: 0.0849s/iter; left time: 2258.5143s
Epoch: 1 cost time: 22.297955989837646
Epoch: 1, Steps: 268 | Train Loss: 0.4752570 Vali Loss: 0.5102597 Test Loss: 0.4444026
Validation loss decreased (inf --> 0.510260).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3668007
	speed: 0.3301s/iter; left time: 8726.1764s
	iters: 200, epoch: 2 | loss: 0.3528176
	speed: 0.0819s/iter; left time: 2155.9535s
Epoch: 2 cost time: 22.625572204589844
Epoch: 2, Steps: 268 | Train Loss: 0.3687302 Vali Loss: 0.4421748 Test Loss: 0.3812459
Validation loss decreased (0.510260 --> 0.442175).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3317096
	speed: 0.3557s/iter; left time: 9306.3645s
	iters: 200, epoch: 3 | loss: 0.3714800
	speed: 0.0769s/iter; left time: 2003.8885s
Epoch: 3 cost time: 21.46194553375244
Epoch: 3, Steps: 268 | Train Loss: 0.3551367 Vali Loss: 0.4281855 Test Loss: 0.3687299
Validation loss decreased (0.442175 --> 0.428185).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3843060
	speed: 0.2914s/iter; left time: 7546.8848s
	iters: 200, epoch: 4 | loss: 0.3600504
	speed: 0.0745s/iter; left time: 1921.3376s
Epoch: 4 cost time: 20.843514919281006
Epoch: 4, Steps: 268 | Train Loss: 0.3520932 Vali Loss: 0.4260354 Test Loss: 0.3664111
Validation loss decreased (0.428185 --> 0.426035).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3472006
	speed: 0.3245s/iter; left time: 8315.5492s
	iters: 200, epoch: 5 | loss: 0.3893469
	speed: 0.0854s/iter; left time: 2181.2226s
Epoch: 5 cost time: 22.360411882400513
Epoch: 5, Steps: 268 | Train Loss: 0.3508885 Vali Loss: 0.4241104 Test Loss: 0.3647550
Validation loss decreased (0.426035 --> 0.424110).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3635763
	speed: 0.3641s/iter; left time: 9234.7065s
	iters: 200, epoch: 6 | loss: 0.3226048
	speed: 0.0733s/iter; left time: 1851.8453s
Epoch: 6 cost time: 22.550147771835327
Epoch: 6, Steps: 268 | Train Loss: 0.3503089 Vali Loss: 0.4225357 Test Loss: 0.3640576
Validation loss decreased (0.424110 --> 0.422536).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3739842
	speed: 0.3228s/iter; left time: 8100.9348s
	iters: 200, epoch: 7 | loss: 0.3455547
	speed: 0.0927s/iter; left time: 2316.7002s
Epoch: 7 cost time: 23.93264603614807
Epoch: 7, Steps: 268 | Train Loss: 0.3500151 Vali Loss: 0.4233337 Test Loss: 0.3650219
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3259559
	speed: 0.3743s/iter; left time: 9292.0823s
	iters: 200, epoch: 8 | loss: 0.3439715
	speed: 0.0909s/iter; left time: 2246.8400s
Epoch: 8 cost time: 24.364547729492188
Epoch: 8, Steps: 268 | Train Loss: 0.3496828 Vali Loss: 0.4226039 Test Loss: 0.3641783
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3326387
	speed: 0.3336s/iter; left time: 8193.2346s
	iters: 200, epoch: 9 | loss: 0.3524389
	speed: 0.0836s/iter; left time: 2043.8827s
Epoch: 9 cost time: 23.540046215057373
Epoch: 9, Steps: 268 | Train Loss: 0.3495212 Vali Loss: 0.4233562 Test Loss: 0.3643775
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3415830
	speed: 0.3348s/iter; left time: 8132.6623s
	iters: 200, epoch: 10 | loss: 0.3502886
	speed: 0.0716s/iter; left time: 1730.9048s
Epoch: 10 cost time: 22.965700149536133
Epoch: 10, Steps: 268 | Train Loss: 0.3493342 Vali Loss: 0.4219095 Test Loss: 0.3636325
Validation loss decreased (0.422536 --> 0.421910).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3568821
	speed: 0.3579s/iter; left time: 8597.3533s
	iters: 200, epoch: 11 | loss: 0.3598574
	speed: 0.0798s/iter; left time: 1908.6497s
Epoch: 11 cost time: 23.187439680099487
Epoch: 11, Steps: 268 | Train Loss: 0.3492881 Vali Loss: 0.4222696 Test Loss: 0.3638695
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3578958
	speed: 0.3474s/iter; left time: 8251.8585s
	iters: 200, epoch: 12 | loss: 0.3300603
	speed: 0.0857s/iter; left time: 2026.4947s
Epoch: 12 cost time: 21.84716010093689
Epoch: 12, Steps: 268 | Train Loss: 0.3492615 Vali Loss: 0.4223393 Test Loss: 0.3639033
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3654135
	speed: 0.2791s/iter; left time: 6553.8387s
	iters: 200, epoch: 13 | loss: 0.3459773
	speed: 0.0639s/iter; left time: 1494.7391s
Epoch: 13 cost time: 19.092706441879272
Epoch: 13, Steps: 268 | Train Loss: 0.3491459 Vali Loss: 0.4209252 Test Loss: 0.3631232
Validation loss decreased (0.421910 --> 0.420925).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3489896
	speed: 0.3396s/iter; left time: 7885.5305s
	iters: 200, epoch: 14 | loss: 0.3524829
	speed: 0.0880s/iter; left time: 2033.2470s
Epoch: 14 cost time: 22.235408067703247
Epoch: 14, Steps: 268 | Train Loss: 0.3491183 Vali Loss: 0.4225610 Test Loss: 0.3640958
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3580545
	speed: 0.3295s/iter; left time: 7560.6563s
	iters: 200, epoch: 15 | loss: 0.3588155
	speed: 0.0664s/iter; left time: 1517.8643s
Epoch: 15 cost time: 18.473738193511963
Epoch: 15, Steps: 268 | Train Loss: 0.3490116 Vali Loss: 0.4224973 Test Loss: 0.3640558
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3516418
	speed: 0.3331s/iter; left time: 7554.8990s
	iters: 200, epoch: 16 | loss: 0.3795038
	speed: 0.0740s/iter; left time: 1671.4104s
Epoch: 16 cost time: 21.21843981742859
Epoch: 16, Steps: 268 | Train Loss: 0.3488773 Vali Loss: 0.4213153 Test Loss: 0.3631054
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3656162
	speed: 0.3467s/iter; left time: 7770.1851s
	iters: 200, epoch: 17 | loss: 0.3212075
	speed: 0.0766s/iter; left time: 1708.9196s
Epoch: 17 cost time: 21.972448110580444
Epoch: 17, Steps: 268 | Train Loss: 0.3487855 Vali Loss: 0.4222748 Test Loss: 0.3638355
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3746011
	speed: 0.3621s/iter; left time: 8017.7808s
	iters: 200, epoch: 18 | loss: 0.3492040
	speed: 0.0752s/iter; left time: 1656.9622s
Epoch: 18 cost time: 21.89559316635132
Epoch: 18, Steps: 268 | Train Loss: 0.3488576 Vali Loss: 0.4223370 Test Loss: 0.3638382
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3334098
	speed: 0.3362s/iter; left time: 7355.9042s
	iters: 200, epoch: 19 | loss: 0.3448929
	speed: 0.0711s/iter; left time: 1549.1928s
Epoch: 19 cost time: 20.332211017608643
Epoch: 19, Steps: 268 | Train Loss: 0.3487642 Vali Loss: 0.4220785 Test Loss: 0.3637533
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3552203
	speed: 0.3352s/iter; left time: 7244.0828s
	iters: 200, epoch: 20 | loss: 0.3341799
	speed: 0.0743s/iter; left time: 1599.0574s
Epoch: 20 cost time: 19.658936977386475
Epoch: 20, Steps: 268 | Train Loss: 0.3487157 Vali Loss: 0.4221764 Test Loss: 0.3634638
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3200458
	speed: 0.3620s/iter; left time: 7724.9800s
	iters: 200, epoch: 21 | loss: 0.3348793
	speed: 0.0747s/iter; left time: 1587.5073s
Epoch: 21 cost time: 20.271926403045654
Epoch: 21, Steps: 268 | Train Loss: 0.3486044 Vali Loss: 0.4220417 Test Loss: 0.3634268
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3310547
	speed: 0.3259s/iter; left time: 6867.5825s
	iters: 200, epoch: 22 | loss: 0.3664623
	speed: 0.0733s/iter; left time: 1536.3063s
Epoch: 22 cost time: 20.974235773086548
Epoch: 22, Steps: 268 | Train Loss: 0.3485724 Vali Loss: 0.4218402 Test Loss: 0.3635053
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4075863
	speed: 0.3622s/iter; left time: 7535.2938s
	iters: 200, epoch: 23 | loss: 0.3585489
	speed: 0.0874s/iter; left time: 1808.9334s
Epoch: 23 cost time: 23.007731676101685
Epoch: 23, Steps: 268 | Train Loss: 0.3486156 Vali Loss: 0.4217177 Test Loss: 0.3633121
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3639941
	speed: 0.3700s/iter; left time: 7598.0787s
	iters: 200, epoch: 24 | loss: 0.3654337
	speed: 0.0674s/iter; left time: 1376.8376s
Epoch: 24 cost time: 21.388612031936646
Epoch: 24, Steps: 268 | Train Loss: 0.3486286 Vali Loss: 0.4216032 Test Loss: 0.3634991
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3200873
	speed: 0.3564s/iter; left time: 7224.2520s
	iters: 200, epoch: 25 | loss: 0.3648160
	speed: 0.0719s/iter; left time: 1450.3891s
Epoch: 25 cost time: 21.858654499053955
Epoch: 25, Steps: 268 | Train Loss: 0.3487292 Vali Loss: 0.4219994 Test Loss: 0.3637635
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3322805
	speed: 0.3280s/iter; left time: 6561.1292s
	iters: 200, epoch: 26 | loss: 0.3320674
	speed: 0.0866s/iter; left time: 1723.2204s
Epoch: 26 cost time: 21.916667222976685
Epoch: 26, Steps: 268 | Train Loss: 0.3485765 Vali Loss: 0.4220431 Test Loss: 0.3639920
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3175423
	speed: 0.3459s/iter; left time: 6825.0135s
	iters: 200, epoch: 27 | loss: 0.2997701
	speed: 0.0802s/iter; left time: 1574.9506s
Epoch: 27 cost time: 22.759397268295288
Epoch: 27, Steps: 268 | Train Loss: 0.3485238 Vali Loss: 0.4222798 Test Loss: 0.3639848
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3823553
	speed: 0.3508s/iter; left time: 6828.0350s
	iters: 200, epoch: 28 | loss: 0.3387896
	speed: 0.0760s/iter; left time: 1472.6789s
Epoch: 28 cost time: 19.748558282852173
Epoch: 28, Steps: 268 | Train Loss: 0.3485484 Vali Loss: 0.4218380 Test Loss: 0.3639140
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3237305
	speed: 0.2887s/iter; left time: 5541.4102s
	iters: 200, epoch: 29 | loss: 0.3800725
	speed: 0.0762s/iter; left time: 1455.1136s
Epoch: 29 cost time: 19.94934368133545
Epoch: 29, Steps: 268 | Train Loss: 0.3484721 Vali Loss: 0.4212047 Test Loss: 0.3630826
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3325014
	speed: 0.3494s/iter; left time: 6613.3279s
	iters: 200, epoch: 30 | loss: 0.3373848
	speed: 0.0807s/iter; left time: 1520.0191s
Epoch: 30 cost time: 21.875494718551636
Epoch: 30, Steps: 268 | Train Loss: 0.3484185 Vali Loss: 0.4215389 Test Loss: 0.3633524
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3432958
	speed: 0.3383s/iter; left time: 6313.5590s
	iters: 200, epoch: 31 | loss: 0.3473265
	speed: 0.0660s/iter; left time: 1224.2384s
Epoch: 31 cost time: 18.772703170776367
Epoch: 31, Steps: 268 | Train Loss: 0.3484566 Vali Loss: 0.4212185 Test Loss: 0.3633167
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3026893
	speed: 0.3025s/iter; left time: 5564.2724s
	iters: 200, epoch: 32 | loss: 0.3734278
	speed: 0.0726s/iter; left time: 1327.4363s
Epoch: 32 cost time: 21.210039854049683
Epoch: 32, Steps: 268 | Train Loss: 0.3484873 Vali Loss: 0.4215390 Test Loss: 0.3637520
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3681852
	speed: 0.3436s/iter; left time: 6228.0230s
	iters: 200, epoch: 33 | loss: 0.3455024
	speed: 0.0719s/iter; left time: 1296.2857s
Epoch: 33 cost time: 19.677675008773804
Epoch: 33, Steps: 268 | Train Loss: 0.3483666 Vali Loss: 0.4214454 Test Loss: 0.3634208
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_90_96_FITS_ETTm1_ftM_sl90_ll48_pl96_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.3656715452671051, mae:0.38218027353286743, rse:0.5754100680351257, corr:[0.55066335 0.5543571  0.5511103  0.54533046 0.5417356  0.54146147
 0.54189885 0.5409592  0.53877205 0.53654355 0.53513485 0.53459626
 0.53409374 0.53275645 0.5303344  0.52710545 0.52376825 0.52090454
 0.51842374 0.51580644 0.5127892  0.50930536 0.5055628  0.5019809
 0.4988966  0.49616694 0.4936471  0.4912423  0.48904195 0.48711935
 0.48597595 0.4861049  0.4868279  0.48745143 0.48764643 0.48749843
 0.48709264 0.48690924 0.48713207 0.48759258 0.48804942 0.48803103
 0.48755586 0.48697698 0.48653987 0.48648825 0.48687166 0.48738712
 0.4876572  0.48757544 0.4873775  0.4873244  0.48776346 0.4886082
 0.48959002 0.4901862  0.49024656 0.48989037 0.48935658 0.48911646
 0.4892758  0.48936975 0.48917967 0.4885837  0.48801628 0.4877423
 0.48776034 0.4880173  0.4884406  0.48883873 0.4889354  0.4888694
 0.48902565 0.48958212 0.49053824 0.49146044 0.49218497 0.49262702
 0.4928335  0.49310434 0.49369112 0.49449497 0.4954544  0.4961674
 0.49640384 0.4962261  0.4960889  0.49651968 0.497843   0.49965847
 0.50092196 0.50109404 0.500941   0.5019265  0.50527763 0.50703186]
