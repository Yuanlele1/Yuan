Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=30, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_180_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_180_336_FITS_ETTm1_ftM_sl180_ll48_pl336_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34045
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=30, out_features=86, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2311680.0
params:  2666.0
Trainable parameters:  2666
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5402458
	speed: 0.0203s/iter; left time: 535.8988s
	iters: 200, epoch: 1 | loss: 0.4587281
	speed: 0.0171s/iter; left time: 450.8929s
Epoch: 1 cost time: 4.6407177448272705
Epoch: 1, Steps: 265 | Train Loss: 0.5563552 Vali Loss: 0.7864435 Test Loss: 0.4753155
Validation loss decreased (inf --> 0.786444).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4194105
	speed: 0.0706s/iter; left time: 1845.4133s
	iters: 200, epoch: 2 | loss: 0.3843720
	speed: 0.0136s/iter; left time: 354.6241s
Epoch: 2 cost time: 4.115810394287109
Epoch: 2, Steps: 265 | Train Loss: 0.4026641 Vali Loss: 0.7004482 Test Loss: 0.4050282
Validation loss decreased (0.786444 --> 0.700448).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3721802
	speed: 0.0683s/iter; left time: 1766.8334s
	iters: 200, epoch: 3 | loss: 0.4175510
	speed: 0.0145s/iter; left time: 372.8704s
Epoch: 3 cost time: 4.233351469039917
Epoch: 3, Steps: 265 | Train Loss: 0.3823064 Vali Loss: 0.6803318 Test Loss: 0.3905287
Validation loss decreased (0.700448 --> 0.680332).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3293907
	speed: 0.0915s/iter; left time: 2342.1906s
	iters: 200, epoch: 4 | loss: 0.3889157
	speed: 0.0130s/iter; left time: 332.5486s
Epoch: 4 cost time: 6.170641660690308
Epoch: 4, Steps: 265 | Train Loss: 0.3770031 Vali Loss: 0.6734420 Test Loss: 0.3858777
Validation loss decreased (0.680332 --> 0.673442).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3650927
	speed: 0.0677s/iter; left time: 1714.8295s
	iters: 200, epoch: 5 | loss: 0.3481897
	speed: 0.0136s/iter; left time: 344.0275s
Epoch: 5 cost time: 3.984661817550659
Epoch: 5, Steps: 265 | Train Loss: 0.3751059 Vali Loss: 0.6703783 Test Loss: 0.3848982
Validation loss decreased (0.673442 --> 0.670378).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3627749
	speed: 0.0707s/iter; left time: 1772.2379s
	iters: 200, epoch: 6 | loss: 0.3748377
	speed: 0.0147s/iter; left time: 367.1202s
Epoch: 6 cost time: 4.2398903369903564
Epoch: 6, Steps: 265 | Train Loss: 0.3748221 Vali Loss: 0.6689955 Test Loss: 0.3845095
Validation loss decreased (0.670378 --> 0.668995).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3334482
	speed: 0.0726s/iter; left time: 1801.2368s
	iters: 200, epoch: 7 | loss: 0.3443325
	speed: 0.0190s/iter; left time: 468.5179s
Epoch: 7 cost time: 5.074608325958252
Epoch: 7, Steps: 265 | Train Loss: 0.3744224 Vali Loss: 0.6685804 Test Loss: 0.3840772
Validation loss decreased (0.668995 --> 0.668580).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3494715
	speed: 0.0722s/iter; left time: 1773.0934s
	iters: 200, epoch: 8 | loss: 0.3619907
	speed: 0.0131s/iter; left time: 320.4068s
Epoch: 8 cost time: 4.0580456256866455
Epoch: 8, Steps: 265 | Train Loss: 0.3742469 Vali Loss: 0.6669675 Test Loss: 0.3842375
Validation loss decreased (0.668580 --> 0.666967).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3752589
	speed: 0.0813s/iter; left time: 1975.1705s
	iters: 200, epoch: 9 | loss: 0.3386438
	speed: 0.0140s/iter; left time: 339.6281s
Epoch: 9 cost time: 4.254192590713501
Epoch: 9, Steps: 265 | Train Loss: 0.3742440 Vali Loss: 0.6672742 Test Loss: 0.3841448
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3656708
	speed: 0.0681s/iter; left time: 1636.2366s
	iters: 200, epoch: 10 | loss: 0.3796241
	speed: 0.0138s/iter; left time: 331.2027s
Epoch: 10 cost time: 4.174023628234863
Epoch: 10, Steps: 265 | Train Loss: 0.3740486 Vali Loss: 0.6671098 Test Loss: 0.3838817
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3555374
	speed: 0.0716s/iter; left time: 1700.8826s
	iters: 200, epoch: 11 | loss: 0.4010388
	speed: 0.0146s/iter; left time: 344.3957s
Epoch: 11 cost time: 4.330201864242554
Epoch: 11, Steps: 265 | Train Loss: 0.3740423 Vali Loss: 0.6662338 Test Loss: 0.3839417
Validation loss decreased (0.666967 --> 0.666234).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3804012
	speed: 0.0679s/iter; left time: 1595.0352s
	iters: 200, epoch: 12 | loss: 0.3740209
	speed: 0.0133s/iter; left time: 310.3536s
Epoch: 12 cost time: 3.986768960952759
Epoch: 12, Steps: 265 | Train Loss: 0.3739087 Vali Loss: 0.6666426 Test Loss: 0.3838148
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3856845
	speed: 0.0833s/iter; left time: 1933.7853s
	iters: 200, epoch: 13 | loss: 0.3680853
	speed: 0.0131s/iter; left time: 302.8468s
Epoch: 13 cost time: 5.46634316444397
Epoch: 13, Steps: 265 | Train Loss: 0.3738402 Vali Loss: 0.6669806 Test Loss: 0.3838209
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3310818
	speed: 0.0673s/iter; left time: 1544.9182s
	iters: 200, epoch: 14 | loss: 0.3678513
	speed: 0.0129s/iter; left time: 294.1533s
Epoch: 14 cost time: 3.912038564682007
Epoch: 14, Steps: 265 | Train Loss: 0.3737222 Vali Loss: 0.6669167 Test Loss: 0.3838980
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3635091
	speed: 0.0682s/iter; left time: 1546.4676s
	iters: 200, epoch: 15 | loss: 0.3727273
	speed: 0.0131s/iter; left time: 296.2290s
Epoch: 15 cost time: 4.033050775527954
Epoch: 15, Steps: 265 | Train Loss: 0.3738739 Vali Loss: 0.6668741 Test Loss: 0.3838560
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3982106
	speed: 0.0666s/iter; left time: 1492.5284s
	iters: 200, epoch: 16 | loss: 0.3861599
	speed: 0.0133s/iter; left time: 297.6136s
Epoch: 16 cost time: 3.9749033451080322
Epoch: 16, Steps: 265 | Train Loss: 0.3738514 Vali Loss: 0.6661115 Test Loss: 0.3839816
Validation loss decreased (0.666234 --> 0.666111).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3827944
	speed: 0.0685s/iter; left time: 1517.7792s
	iters: 200, epoch: 17 | loss: 0.3511457
	speed: 0.0133s/iter; left time: 293.8884s
Epoch: 17 cost time: 4.066370964050293
Epoch: 17, Steps: 265 | Train Loss: 0.3737742 Vali Loss: 0.6655553 Test Loss: 0.3840622
Validation loss decreased (0.666111 --> 0.665555).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4232526
	speed: 0.0677s/iter; left time: 1481.9687s
	iters: 200, epoch: 18 | loss: 0.4183363
	speed: 0.0130s/iter; left time: 282.7498s
Epoch: 18 cost time: 4.006387233734131
Epoch: 18, Steps: 265 | Train Loss: 0.3736783 Vali Loss: 0.6657023 Test Loss: 0.3838965
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3893357
	speed: 0.0674s/iter; left time: 1456.8822s
	iters: 200, epoch: 19 | loss: 0.3735633
	speed: 0.0131s/iter; left time: 281.2464s
Epoch: 19 cost time: 4.015367269515991
Epoch: 19, Steps: 265 | Train Loss: 0.3738775 Vali Loss: 0.6658272 Test Loss: 0.3837134
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3582565
	speed: 0.1047s/iter; left time: 2237.5756s
	iters: 200, epoch: 20 | loss: 0.3708843
	speed: 0.0154s/iter; left time: 327.9652s
Epoch: 20 cost time: 4.5954270362854
Epoch: 20, Steps: 265 | Train Loss: 0.3736042 Vali Loss: 0.6659347 Test Loss: 0.3837591
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3869507
	speed: 0.0708s/iter; left time: 1494.5157s
	iters: 200, epoch: 21 | loss: 0.3842269
	speed: 0.0151s/iter; left time: 316.3030s
Epoch: 21 cost time: 4.3066065311431885
Epoch: 21, Steps: 265 | Train Loss: 0.3736585 Vali Loss: 0.6657337 Test Loss: 0.3837137
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3492443
	speed: 0.0706s/iter; left time: 1470.1711s
	iters: 200, epoch: 22 | loss: 0.3900661
	speed: 0.0409s/iter; left time: 848.1711s
Epoch: 22 cost time: 7.405695676803589
Epoch: 22, Steps: 265 | Train Loss: 0.3737327 Vali Loss: 0.6662658 Test Loss: 0.3838796
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3948157
	speed: 0.0734s/iter; left time: 1508.9428s
	iters: 200, epoch: 23 | loss: 0.4026818
	speed: 0.0140s/iter; left time: 287.2452s
Epoch: 23 cost time: 4.210218667984009
Epoch: 23, Steps: 265 | Train Loss: 0.3737011 Vali Loss: 0.6661848 Test Loss: 0.3839857
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3455860
	speed: 0.0693s/iter; left time: 1406.6445s
	iters: 200, epoch: 24 | loss: 0.3472985
	speed: 0.0131s/iter; left time: 264.3527s
Epoch: 24 cost time: 4.004456043243408
Epoch: 24, Steps: 265 | Train Loss: 0.3736652 Vali Loss: 0.6655370 Test Loss: 0.3838384
Validation loss decreased (0.665555 --> 0.665537).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3436400
	speed: 0.0675s/iter; left time: 1352.4157s
	iters: 200, epoch: 25 | loss: 0.3811032
	speed: 0.0134s/iter; left time: 266.3359s
Epoch: 25 cost time: 4.063007116317749
Epoch: 25, Steps: 265 | Train Loss: 0.3736943 Vali Loss: 0.6657988 Test Loss: 0.3838870
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3695796
	speed: 0.0721s/iter; left time: 1426.6173s
	iters: 200, epoch: 26 | loss: 0.3127042
	speed: 0.0154s/iter; left time: 302.9284s
Epoch: 26 cost time: 4.670007228851318
Epoch: 26, Steps: 265 | Train Loss: 0.3735682 Vali Loss: 0.6647748 Test Loss: 0.3838138
Validation loss decreased (0.665537 --> 0.664775).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3742310
	speed: 0.0686s/iter; left time: 1337.6899s
	iters: 200, epoch: 27 | loss: 0.3863098
	speed: 0.0132s/iter; left time: 256.7788s
Epoch: 27 cost time: 3.9147229194641113
Epoch: 27, Steps: 265 | Train Loss: 0.3738242 Vali Loss: 0.6658803 Test Loss: 0.3839031
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3828339
	speed: 0.0692s/iter; left time: 1332.4947s
	iters: 200, epoch: 28 | loss: 0.4084454
	speed: 0.0151s/iter; left time: 288.9353s
Epoch: 28 cost time: 4.390433073043823
Epoch: 28, Steps: 265 | Train Loss: 0.3735289 Vali Loss: 0.6663821 Test Loss: 0.3839136
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3549217
	speed: 0.0697s/iter; left time: 1323.7505s
	iters: 200, epoch: 29 | loss: 0.4255326
	speed: 0.0133s/iter; left time: 251.9969s
Epoch: 29 cost time: 3.983363628387451
Epoch: 29, Steps: 265 | Train Loss: 0.3736847 Vali Loss: 0.6655619 Test Loss: 0.3838041
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3519274
	speed: 0.0697s/iter; left time: 1303.9736s
	iters: 200, epoch: 30 | loss: 0.4205763
	speed: 0.0142s/iter; left time: 265.0547s
Epoch: 30 cost time: 4.506296634674072
Epoch: 30, Steps: 265 | Train Loss: 0.3736811 Vali Loss: 0.6654576 Test Loss: 0.3837436
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3652462
	speed: 0.0674s/iter; left time: 1244.1911s
	iters: 200, epoch: 31 | loss: 0.3862377
	speed: 0.0132s/iter; left time: 242.7090s
Epoch: 31 cost time: 4.18113899230957
Epoch: 31, Steps: 265 | Train Loss: 0.3737030 Vali Loss: 0.6655767 Test Loss: 0.3837321
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3506982
	speed: 0.0686s/iter; left time: 1246.8507s
	iters: 200, epoch: 32 | loss: 0.3493613
	speed: 0.0134s/iter; left time: 242.0414s
Epoch: 32 cost time: 4.057193756103516
Epoch: 32, Steps: 265 | Train Loss: 0.3735768 Vali Loss: 0.6649324 Test Loss: 0.3837704
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3504422
	speed: 0.0709s/iter; left time: 1271.1617s
	iters: 200, epoch: 33 | loss: 0.3950171
	speed: 0.0147s/iter; left time: 262.2198s
Epoch: 33 cost time: 4.327043533325195
Epoch: 33, Steps: 265 | Train Loss: 0.3735159 Vali Loss: 0.6646488 Test Loss: 0.3837956
Validation loss decreased (0.664775 --> 0.664649).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3631940
	speed: 0.0678s/iter; left time: 1196.8273s
	iters: 200, epoch: 34 | loss: 0.4130478
	speed: 0.0132s/iter; left time: 231.7504s
Epoch: 34 cost time: 3.9737818241119385
Epoch: 34, Steps: 265 | Train Loss: 0.3736220 Vali Loss: 0.6656926 Test Loss: 0.3837622
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3372671
	speed: 0.0684s/iter; left time: 1189.7973s
	iters: 200, epoch: 35 | loss: 0.3918354
	speed: 0.0134s/iter; left time: 231.9509s
Epoch: 35 cost time: 4.1673619747161865
Epoch: 35, Steps: 265 | Train Loss: 0.3736786 Vali Loss: 0.6654991 Test Loss: 0.3837388
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3903464
	speed: 0.0698s/iter; left time: 1194.6864s
	iters: 200, epoch: 36 | loss: 0.3751989
	speed: 0.0135s/iter; left time: 229.8226s
Epoch: 36 cost time: 4.118890762329102
Epoch: 36, Steps: 265 | Train Loss: 0.3736082 Vali Loss: 0.6662315 Test Loss: 0.3837891
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3974757
	speed: 0.0696s/iter; left time: 1172.8515s
	iters: 200, epoch: 37 | loss: 0.3638746
	speed: 0.0137s/iter; left time: 230.1126s
Epoch: 37 cost time: 4.186650037765503
Epoch: 37, Steps: 265 | Train Loss: 0.3737101 Vali Loss: 0.6653559 Test Loss: 0.3838184
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3664010
	speed: 0.0709s/iter; left time: 1177.1519s
	iters: 200, epoch: 38 | loss: 0.3786527
	speed: 0.0155s/iter; left time: 256.1606s
Epoch: 38 cost time: 4.6198554039001465
Epoch: 38, Steps: 265 | Train Loss: 0.3735762 Vali Loss: 0.6652675 Test Loss: 0.3838038
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3536486
	speed: 0.0712s/iter; left time: 1163.0264s
	iters: 200, epoch: 39 | loss: 0.4310211
	speed: 0.0131s/iter; left time: 212.3596s
Epoch: 39 cost time: 4.0581910610198975
Epoch: 39, Steps: 265 | Train Loss: 0.3735450 Vali Loss: 0.6655182 Test Loss: 0.3837690
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.3454009
	speed: 0.0685s/iter; left time: 1099.9489s
	iters: 200, epoch: 40 | loss: 0.3696573
	speed: 0.0135s/iter; left time: 215.4111s
Epoch: 40 cost time: 4.106668472290039
Epoch: 40, Steps: 265 | Train Loss: 0.3735337 Vali Loss: 0.6658790 Test Loss: 0.3837563
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3618665
	speed: 0.0667s/iter; left time: 1053.5980s
	iters: 200, epoch: 41 | loss: 0.3509220
	speed: 0.0133s/iter; left time: 209.4304s
Epoch: 41 cost time: 4.050728797912598
Epoch: 41, Steps: 265 | Train Loss: 0.3735503 Vali Loss: 0.6654353 Test Loss: 0.3837670
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3643588
	speed: 0.0682s/iter; left time: 1059.9089s
	iters: 200, epoch: 42 | loss: 0.4024558
	speed: 0.0130s/iter; left time: 201.0915s
Epoch: 42 cost time: 4.031905889511108
Epoch: 42, Steps: 265 | Train Loss: 0.3736702 Vali Loss: 0.6662959 Test Loss: 0.3837767
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3241151
	speed: 0.0776s/iter; left time: 1184.5571s
	iters: 200, epoch: 43 | loss: 0.3470678
	speed: 0.0153s/iter; left time: 232.6401s
Epoch: 43 cost time: 4.463343143463135
Epoch: 43, Steps: 265 | Train Loss: 0.3737497 Vali Loss: 0.6661265 Test Loss: 0.3838055
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.3692595
	speed: 0.0753s/iter; left time: 1129.2217s
	iters: 200, epoch: 44 | loss: 0.3838003
	speed: 0.0150s/iter; left time: 223.8967s
Epoch: 44 cost time: 4.673651933670044
Epoch: 44, Steps: 265 | Train Loss: 0.3734479 Vali Loss: 0.6657915 Test Loss: 0.3837834
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.3462821
	speed: 0.0698s/iter; left time: 1029.6154s
	iters: 200, epoch: 45 | loss: 0.3543091
	speed: 0.0135s/iter; left time: 197.6634s
Epoch: 45 cost time: 3.9941864013671875
Epoch: 45, Steps: 265 | Train Loss: 0.3735901 Vali Loss: 0.6653435 Test Loss: 0.3837911
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.3464465
	speed: 0.0690s/iter; left time: 999.4011s
	iters: 200, epoch: 46 | loss: 0.3655159
	speed: 0.0136s/iter; left time: 196.0762s
Epoch: 46 cost time: 4.0718958377838135
Epoch: 46, Steps: 265 | Train Loss: 0.3734782 Vali Loss: 0.6660179 Test Loss: 0.3837954
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.3637838
	speed: 0.0700s/iter; left time: 995.0121s
	iters: 200, epoch: 47 | loss: 0.3756939
	speed: 0.0143s/iter; left time: 201.6323s
Epoch: 47 cost time: 4.304463624954224
Epoch: 47, Steps: 265 | Train Loss: 0.3735307 Vali Loss: 0.6656433 Test Loss: 0.3838051
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.3627352
	speed: 0.0743s/iter; left time: 1036.7595s
	iters: 200, epoch: 48 | loss: 0.3405876
	speed: 0.0132s/iter; left time: 183.2454s
Epoch: 48 cost time: 4.530569791793823
Epoch: 48, Steps: 265 | Train Loss: 0.3736320 Vali Loss: 0.6651597 Test Loss: 0.3837857
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.3586523
	speed: 0.0668s/iter; left time: 914.1605s
	iters: 200, epoch: 49 | loss: 0.3306707
	speed: 0.0134s/iter; left time: 181.7034s
Epoch: 49 cost time: 4.021758317947388
Epoch: 49, Steps: 265 | Train Loss: 0.3735136 Vali Loss: 0.6652964 Test Loss: 0.3837679
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.3800215
	speed: 0.0666s/iter; left time: 893.9328s
	iters: 200, epoch: 50 | loss: 0.3895895
	speed: 0.0270s/iter; left time: 360.1591s
Epoch: 50 cost time: 5.406968593597412
Epoch: 50, Steps: 265 | Train Loss: 0.3734324 Vali Loss: 0.6658044 Test Loss: 0.3837584
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.3450443
	speed: 0.0692s/iter; left time: 909.7307s
	iters: 200, epoch: 51 | loss: 0.3807891
	speed: 0.0134s/iter; left time: 175.3275s
Epoch: 51 cost time: 4.07553243637085
Epoch: 51, Steps: 265 | Train Loss: 0.3734763 Vali Loss: 0.6661250 Test Loss: 0.3837763
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.4096078
	speed: 0.0711s/iter; left time: 916.1586s
	iters: 200, epoch: 52 | loss: 0.3944673
	speed: 0.0149s/iter; left time: 190.7521s
Epoch: 52 cost time: 4.538401126861572
Epoch: 52, Steps: 265 | Train Loss: 0.3736123 Vali Loss: 0.6651624 Test Loss: 0.3837786
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.3514593
	speed: 0.0836s/iter; left time: 1055.1899s
	iters: 200, epoch: 53 | loss: 0.3761650
	speed: 0.0157s/iter; left time: 197.1197s
Epoch: 53 cost time: 5.383716821670532
Epoch: 53, Steps: 265 | Train Loss: 0.3735087 Vali Loss: 0.6653777 Test Loss: 0.3837682
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_180_336_FITS_ETTm1_ftM_sl180_ll48_pl336_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.3837943375110626, mae:0.3901596963405609, rse:0.5895187258720398, corr:[0.5464571  0.5487638  0.5467627  0.54461133 0.5435587  0.54299176
 0.5422341  0.54164094 0.5414405  0.541936   0.5427221  0.54287994
 0.54242796 0.54124874 0.53968555 0.53799707 0.5361547  0.53428507
 0.5325191  0.53085333 0.5291637  0.5272112  0.524923   0.5224492
 0.5199653  0.517707   0.5158999  0.51440567 0.5132165  0.5124197
 0.51233125 0.5128677  0.51357013 0.5140558  0.51409554 0.5138655
 0.5134713  0.513066   0.5128777  0.5127231  0.5125904  0.5123343
 0.512044   0.5119453  0.5120271  0.5122034  0.5123844  0.5124502
 0.51240265 0.51227915 0.51225775 0.5123907  0.5126069  0.5127144
 0.51265985 0.5124828  0.5124071  0.5123499  0.5123002  0.5121216
 0.51186955 0.5116286  0.51145947 0.51140285 0.51140755 0.511521
 0.5116256  0.5116694  0.5118523  0.5122231  0.51270795 0.5130862
 0.5132101  0.5130829  0.5129727  0.5129557  0.5131351  0.5133545
 0.5134091  0.513198   0.51287115 0.51261204 0.51257104 0.5125933
 0.51251644 0.51228344 0.5119187  0.5114701  0.5110979  0.511063
 0.51125807 0.51141536 0.51128316 0.51085514 0.5102165  0.50944096
 0.5086035  0.5077195  0.50674474 0.50576013 0.5051757  0.5053086
 0.5060529  0.5069934  0.5078197  0.50849813 0.50924337 0.5102333
 0.51135427 0.5122329  0.5126163  0.512652   0.51244897 0.5122321
 0.51208425 0.5120423  0.5118484  0.5113297  0.5106067  0.50989336
 0.50946444 0.50921685 0.5089672  0.5086446  0.5081161  0.5074319
 0.5068475  0.50653124 0.506431   0.5063914  0.50626725 0.5060173
 0.50573945 0.50561124 0.50551736 0.5052446  0.5049185  0.5045803
 0.5043411  0.5043472  0.5044525  0.5044883  0.5043814  0.5042148
 0.5041174  0.50421023 0.5043418  0.50447935 0.50467473 0.50466305
 0.50454205 0.5044717  0.50446856 0.50452304 0.5044629  0.50439495
 0.50438017 0.50449276 0.50461817 0.50473905 0.50477636 0.5047727
 0.5048466  0.5050729  0.5053865  0.505781   0.5060753  0.5062088
 0.5062911  0.5063755  0.5064633  0.5066542  0.5067818  0.50673145
 0.50655544 0.5063083  0.50611377 0.50603354 0.50595254 0.5058677
 0.5057411  0.50561494 0.5055427  0.5056222  0.5058723  0.5061893
 0.5064214  0.50647676 0.5064384  0.50648344 0.50671804 0.50705296
 0.50722325 0.5071158  0.50670755 0.5060031  0.5052715  0.5047654
 0.50445145 0.5041323  0.50376254 0.503621   0.5036356  0.50372225
 0.50375956 0.5034777  0.5030388  0.50263816 0.5022659  0.50189584
 0.5014782  0.5010263  0.5004486  0.49964046 0.49864298 0.49763355
 0.49676657 0.49602488 0.49536568 0.49474636 0.49414745 0.4937224
 0.49360874 0.4938144  0.4940622  0.49415812 0.49405754 0.4937603
 0.4933913  0.49320453 0.49309993 0.49290568 0.4926023  0.49230242
 0.49216613 0.49229485 0.49247137 0.49267757 0.49280414 0.49275398
 0.492735   0.49273303 0.492855   0.49298564 0.4930486  0.49301535
 0.49294558 0.4928619  0.49289396 0.49303886 0.49314994 0.49310702
 0.49294212 0.49286196 0.49285746 0.49298185 0.4930955  0.4931092
 0.49311846 0.49319354 0.49337798 0.49368444 0.4940146  0.494325
 0.49460414 0.49475145 0.4948623  0.49501133 0.4951935  0.49525076
 0.4952194  0.4951179  0.4951317  0.49530935 0.4956561  0.4960134
 0.4962503  0.49637848 0.4963968  0.49640766 0.49653238 0.49673155
 0.4968946  0.4968084  0.49645415 0.49593127 0.49538502 0.49488696
 0.49426004 0.49346733 0.4925734  0.4916394  0.49094337 0.4906148
 0.49069023 0.49081615 0.4909162  0.49104682 0.49132687 0.49181357
 0.4922942  0.49244425 0.49232477 0.49209288 0.4918944  0.49178916
 0.49180186 0.49176848 0.49152377 0.4911042  0.4906652  0.49036774
 0.49021277 0.48999485 0.4896536  0.48928234 0.48880318 0.48848292
 0.48835605 0.48816073 0.4877866  0.48739967 0.48703715 0.4868653
 0.48684216 0.48676765 0.48635867 0.48568442 0.48506075 0.48480937
 0.48492745 0.485088   0.4850098  0.48511645 0.48594183 0.48678866]
