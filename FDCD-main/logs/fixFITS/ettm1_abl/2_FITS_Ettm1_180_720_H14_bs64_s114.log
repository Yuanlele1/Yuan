Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=38, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_180_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_180_720_FITS_ETTm1_ftM_sl180_ll48_pl720_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33661
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=38, out_features=190, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6469120.0
params:  7410.0
Trainable parameters:  7410
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.7261864
	speed: 0.0195s/iter; left time: 509.0507s
	iters: 200, epoch: 1 | loss: 0.5437726
	speed: 0.0134s/iter; left time: 347.2108s
Epoch: 1 cost time: 4.163213014602661
Epoch: 1, Steps: 262 | Train Loss: 0.6762055 Vali Loss: 1.2029951 Test Loss: 0.6275785
Validation loss decreased (inf --> 1.202995).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4635018
	speed: 0.0628s/iter; left time: 1621.5649s
	iters: 200, epoch: 2 | loss: 0.4312530
	speed: 0.0139s/iter; left time: 358.6308s
Epoch: 2 cost time: 4.170161008834839
Epoch: 2, Steps: 262 | Train Loss: 0.4237312 Vali Loss: 1.0744604 Test Loss: 0.5136920
Validation loss decreased (1.202995 --> 1.074460).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4192719
	speed: 0.0651s/iter; left time: 1666.1874s
	iters: 200, epoch: 3 | loss: 0.3890141
	speed: 0.0164s/iter; left time: 417.9347s
Epoch: 3 cost time: 4.447298049926758
Epoch: 3, Steps: 262 | Train Loss: 0.3864544 Vali Loss: 1.0329723 Test Loss: 0.4806280
Validation loss decreased (1.074460 --> 1.032972).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3503958
	speed: 0.0698s/iter; left time: 1766.4233s
	iters: 200, epoch: 4 | loss: 0.3778087
	speed: 0.0153s/iter; left time: 384.6836s
Epoch: 4 cost time: 4.462408542633057
Epoch: 4, Steps: 262 | Train Loss: 0.3733887 Vali Loss: 1.0116193 Test Loss: 0.4642774
Validation loss decreased (1.032972 --> 1.011619).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3686623
	speed: 0.0731s/iter; left time: 1830.5522s
	iters: 200, epoch: 5 | loss: 0.3857740
	speed: 0.0163s/iter; left time: 406.2404s
Epoch: 5 cost time: 4.849792718887329
Epoch: 5, Steps: 262 | Train Loss: 0.3665492 Vali Loss: 0.9996085 Test Loss: 0.4557265
Validation loss decreased (1.011619 --> 0.999609).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3839578
	speed: 0.0682s/iter; left time: 1691.5884s
	iters: 200, epoch: 6 | loss: 0.3683932
	speed: 0.0139s/iter; left time: 343.2324s
Epoch: 6 cost time: 4.289660930633545
Epoch: 6, Steps: 262 | Train Loss: 0.3627325 Vali Loss: 0.9926068 Test Loss: 0.4508749
Validation loss decreased (0.999609 --> 0.992607).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3679352
	speed: 0.0628s/iter; left time: 1541.6467s
	iters: 200, epoch: 7 | loss: 0.3618941
	speed: 0.0148s/iter; left time: 360.4248s
Epoch: 7 cost time: 4.211055278778076
Epoch: 7, Steps: 262 | Train Loss: 0.3605155 Vali Loss: 0.9885292 Test Loss: 0.4482622
Validation loss decreased (0.992607 --> 0.988529).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3724430
	speed: 0.0774s/iter; left time: 1879.0603s
	iters: 200, epoch: 8 | loss: 0.3643223
	speed: 0.0135s/iter; left time: 325.4274s
Epoch: 8 cost time: 4.049931287765503
Epoch: 8, Steps: 262 | Train Loss: 0.3592799 Vali Loss: 0.9858627 Test Loss: 0.4470813
Validation loss decreased (0.988529 --> 0.985863).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3575618
	speed: 0.0700s/iter; left time: 1681.0161s
	iters: 200, epoch: 9 | loss: 0.4102561
	speed: 0.0125s/iter; left time: 299.8487s
Epoch: 9 cost time: 5.234123468399048
Epoch: 9, Steps: 262 | Train Loss: 0.3586286 Vali Loss: 0.9842321 Test Loss: 0.4465513
Validation loss decreased (0.985863 --> 0.984232).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3806790
	speed: 0.0752s/iter; left time: 1786.5606s
	iters: 200, epoch: 10 | loss: 0.3495080
	speed: 0.0187s/iter; left time: 442.0355s
Epoch: 10 cost time: 6.272534370422363
Epoch: 10, Steps: 262 | Train Loss: 0.3582619 Vali Loss: 0.9824442 Test Loss: 0.4463786
Validation loss decreased (0.984232 --> 0.982444).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3947837
	speed: 0.0903s/iter; left time: 2120.9944s
	iters: 200, epoch: 11 | loss: 0.3406802
	speed: 0.0176s/iter; left time: 412.1315s
Epoch: 11 cost time: 5.875260353088379
Epoch: 11, Steps: 262 | Train Loss: 0.3580699 Vali Loss: 0.9821014 Test Loss: 0.4462528
Validation loss decreased (0.982444 --> 0.982101).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4015801
	speed: 0.0948s/iter; left time: 2201.0018s
	iters: 200, epoch: 12 | loss: 0.3393811
	speed: 0.0162s/iter; left time: 375.6727s
Epoch: 12 cost time: 5.4284467697143555
Epoch: 12, Steps: 262 | Train Loss: 0.3579836 Vali Loss: 0.9828306 Test Loss: 0.4459892
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3623081
	speed: 0.0880s/iter; left time: 2021.2522s
	iters: 200, epoch: 13 | loss: 0.3672856
	speed: 0.0168s/iter; left time: 382.9679s
Epoch: 13 cost time: 5.183719635009766
Epoch: 13, Steps: 262 | Train Loss: 0.3578675 Vali Loss: 0.9829977 Test Loss: 0.4464992
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3638573
	speed: 0.0821s/iter; left time: 1862.7271s
	iters: 200, epoch: 14 | loss: 0.3514993
	speed: 0.0218s/iter; left time: 491.4555s
Epoch: 14 cost time: 5.860594749450684
Epoch: 14, Steps: 262 | Train Loss: 0.3578921 Vali Loss: 0.9828951 Test Loss: 0.4462804
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3395837
	speed: 0.0863s/iter; left time: 1936.7236s
	iters: 200, epoch: 15 | loss: 0.3626941
	speed: 0.0405s/iter; left time: 904.7908s
Epoch: 15 cost time: 8.81023359298706
Epoch: 15, Steps: 262 | Train Loss: 0.3578014 Vali Loss: 0.9827487 Test Loss: 0.4460643
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3435632
	speed: 0.0953s/iter; left time: 2112.1553s
	iters: 200, epoch: 16 | loss: 0.3743399
	speed: 0.0171s/iter; left time: 376.8493s
Epoch: 16 cost time: 5.2402355670928955
Epoch: 16, Steps: 262 | Train Loss: 0.3578481 Vali Loss: 0.9823413 Test Loss: 0.4464504
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3086030
	speed: 0.0818s/iter; left time: 1793.2492s
	iters: 200, epoch: 17 | loss: 0.3655967
	speed: 0.0177s/iter; left time: 386.6237s
Epoch: 17 cost time: 5.068368911743164
Epoch: 17, Steps: 262 | Train Loss: 0.3576422 Vali Loss: 0.9826902 Test Loss: 0.4463105
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3394975
	speed: 0.0785s/iter; left time: 1700.3123s
	iters: 200, epoch: 18 | loss: 0.3799425
	speed: 0.0176s/iter; left time: 378.7147s
Epoch: 18 cost time: 5.1283652782440186
Epoch: 18, Steps: 262 | Train Loss: 0.3578133 Vali Loss: 0.9829389 Test Loss: 0.4461938
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3314441
	speed: 0.0805s/iter; left time: 1721.6714s
	iters: 200, epoch: 19 | loss: 0.3500866
	speed: 0.0171s/iter; left time: 363.6947s
Epoch: 19 cost time: 5.028702735900879
Epoch: 19, Steps: 262 | Train Loss: 0.3580669 Vali Loss: 0.9827307 Test Loss: 0.4464665
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3500955
	speed: 0.0862s/iter; left time: 1821.5844s
	iters: 200, epoch: 20 | loss: 0.3749014
	speed: 0.0160s/iter; left time: 336.9948s
Epoch: 20 cost time: 4.8741443157196045
Epoch: 20, Steps: 262 | Train Loss: 0.3577910 Vali Loss: 0.9824760 Test Loss: 0.4463561
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3369357
	speed: 0.0772s/iter; left time: 1609.5887s
	iters: 200, epoch: 21 | loss: 0.3648884
	speed: 0.0166s/iter; left time: 343.9009s
Epoch: 21 cost time: 4.838974714279175
Epoch: 21, Steps: 262 | Train Loss: 0.3577487 Vali Loss: 0.9826840 Test Loss: 0.4464040
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3724174
	speed: 0.0778s/iter; left time: 1603.4468s
	iters: 200, epoch: 22 | loss: 0.3705066
	speed: 0.0164s/iter; left time: 337.1772s
Epoch: 22 cost time: 4.986647129058838
Epoch: 22, Steps: 262 | Train Loss: 0.3578490 Vali Loss: 0.9823552 Test Loss: 0.4464521
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3716257
	speed: 0.0894s/iter; left time: 1818.4703s
	iters: 200, epoch: 23 | loss: 0.3425899
	speed: 0.0170s/iter; left time: 343.8341s
Epoch: 23 cost time: 5.916102647781372
Epoch: 23, Steps: 262 | Train Loss: 0.3577152 Vali Loss: 0.9823033 Test Loss: 0.4465096
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3573962
	speed: 0.0783s/iter; left time: 1572.7399s
	iters: 200, epoch: 24 | loss: 0.3536682
	speed: 0.0196s/iter; left time: 391.2836s
Epoch: 24 cost time: 5.270650148391724
Epoch: 24, Steps: 262 | Train Loss: 0.3577841 Vali Loss: 0.9821431 Test Loss: 0.4464630
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3616458
	speed: 0.0758s/iter; left time: 1502.1183s
	iters: 200, epoch: 25 | loss: 0.3685995
	speed: 0.0144s/iter; left time: 282.9390s
Epoch: 25 cost time: 4.16540002822876
Epoch: 25, Steps: 262 | Train Loss: 0.3578595 Vali Loss: 0.9819521 Test Loss: 0.4463785
Validation loss decreased (0.982101 --> 0.981952).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3657046
	speed: 0.0653s/iter; left time: 1276.4418s
	iters: 200, epoch: 26 | loss: 0.3607377
	speed: 0.0139s/iter; left time: 269.8347s
Epoch: 26 cost time: 4.210062265396118
Epoch: 26, Steps: 262 | Train Loss: 0.3577551 Vali Loss: 0.9821325 Test Loss: 0.4464183
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3923019
	speed: 0.0639s/iter; left time: 1233.1400s
	iters: 200, epoch: 27 | loss: 0.3568307
	speed: 0.0141s/iter; left time: 271.3258s
Epoch: 27 cost time: 4.190678834915161
Epoch: 27, Steps: 262 | Train Loss: 0.3577505 Vali Loss: 0.9828290 Test Loss: 0.4465074
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3324114
	speed: 0.0672s/iter; left time: 1278.3553s
	iters: 200, epoch: 28 | loss: 0.3882436
	speed: 0.0156s/iter; left time: 294.8068s
Epoch: 28 cost time: 4.668722152709961
Epoch: 28, Steps: 262 | Train Loss: 0.3577827 Vali Loss: 0.9820905 Test Loss: 0.4465073
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3397131
	speed: 0.0672s/iter; left time: 1260.5083s
	iters: 200, epoch: 29 | loss: 0.3644719
	speed: 0.0149s/iter; left time: 278.8946s
Epoch: 29 cost time: 4.500225067138672
Epoch: 29, Steps: 262 | Train Loss: 0.3578412 Vali Loss: 0.9822656 Test Loss: 0.4464769
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3311594
	speed: 0.0733s/iter; left time: 1355.6425s
	iters: 200, epoch: 30 | loss: 0.3445669
	speed: 0.0155s/iter; left time: 285.6933s
Epoch: 30 cost time: 4.608635425567627
Epoch: 30, Steps: 262 | Train Loss: 0.3578092 Vali Loss: 0.9820228 Test Loss: 0.4464814
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3730179
	speed: 0.0719s/iter; left time: 1312.3403s
	iters: 200, epoch: 31 | loss: 0.3618765
	speed: 0.0148s/iter; left time: 269.0735s
Epoch: 31 cost time: 4.400381326675415
Epoch: 31, Steps: 262 | Train Loss: 0.3578506 Vali Loss: 0.9819522 Test Loss: 0.4464782
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3527373
	speed: 0.0701s/iter; left time: 1259.7923s
	iters: 200, epoch: 32 | loss: 0.3521153
	speed: 0.0153s/iter; left time: 273.8138s
Epoch: 32 cost time: 4.592261075973511
Epoch: 32, Steps: 262 | Train Loss: 0.3577407 Vali Loss: 0.9831878 Test Loss: 0.4464921
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3672224
	speed: 0.0695s/iter; left time: 1231.2823s
	iters: 200, epoch: 33 | loss: 0.3746771
	speed: 0.0140s/iter; left time: 246.2000s
Epoch: 33 cost time: 4.299222946166992
Epoch: 33, Steps: 262 | Train Loss: 0.3577902 Vali Loss: 0.9828342 Test Loss: 0.4464944
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3831252
	speed: 0.0677s/iter; left time: 1182.4324s
	iters: 200, epoch: 34 | loss: 0.3607809
	speed: 0.0143s/iter; left time: 247.9245s
Epoch: 34 cost time: 4.362065076828003
Epoch: 34, Steps: 262 | Train Loss: 0.3577307 Vali Loss: 0.9813727 Test Loss: 0.4464881
Validation loss decreased (0.981952 --> 0.981373).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3720112
	speed: 0.0678s/iter; left time: 1166.0466s
	iters: 200, epoch: 35 | loss: 0.3242100
	speed: 0.0168s/iter; left time: 287.9253s
Epoch: 35 cost time: 4.653957843780518
Epoch: 35, Steps: 262 | Train Loss: 0.3577880 Vali Loss: 0.9818109 Test Loss: 0.4464929
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3413810
	speed: 0.0655s/iter; left time: 1108.9302s
	iters: 200, epoch: 36 | loss: 0.3542104
	speed: 0.0146s/iter; left time: 244.9235s
Epoch: 36 cost time: 4.357037782669067
Epoch: 36, Steps: 262 | Train Loss: 0.3578770 Vali Loss: 0.9820007 Test Loss: 0.4464661
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3373958
	speed: 0.0651s/iter; left time: 1084.5531s
	iters: 200, epoch: 37 | loss: 0.3260130
	speed: 0.0143s/iter; left time: 236.9627s
Epoch: 37 cost time: 4.1848225593566895
Epoch: 37, Steps: 262 | Train Loss: 0.3578081 Vali Loss: 0.9824898 Test Loss: 0.4465328
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3764302
	speed: 0.0645s/iter; left time: 1058.3450s
	iters: 200, epoch: 38 | loss: 0.3314319
	speed: 0.0138s/iter; left time: 224.8641s
Epoch: 38 cost time: 4.198412656784058
Epoch: 38, Steps: 262 | Train Loss: 0.3577882 Vali Loss: 0.9822562 Test Loss: 0.4465165
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3423066
	speed: 0.0691s/iter; left time: 1116.2035s
	iters: 200, epoch: 39 | loss: 0.3424817
	speed: 0.0142s/iter; left time: 227.7874s
Epoch: 39 cost time: 4.431748390197754
Epoch: 39, Steps: 262 | Train Loss: 0.3576982 Vali Loss: 0.9818833 Test Loss: 0.4464814
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.3525175
	speed: 0.0691s/iter; left time: 1097.6682s
	iters: 200, epoch: 40 | loss: 0.3420833
	speed: 0.0146s/iter; left time: 230.4605s
Epoch: 40 cost time: 4.489737510681152
Epoch: 40, Steps: 262 | Train Loss: 0.3578349 Vali Loss: 0.9828509 Test Loss: 0.4464979
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3687912
	speed: 0.0707s/iter; left time: 1104.9140s
	iters: 200, epoch: 41 | loss: 0.3874696
	speed: 0.0146s/iter; left time: 226.3684s
Epoch: 41 cost time: 4.445081472396851
Epoch: 41, Steps: 262 | Train Loss: 0.3577624 Vali Loss: 0.9821352 Test Loss: 0.4465239
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3427063
	speed: 0.0672s/iter; left time: 1031.7586s
	iters: 200, epoch: 42 | loss: 0.3506139
	speed: 0.0125s/iter; left time: 191.2218s
Epoch: 42 cost time: 3.9656176567077637
Epoch: 42, Steps: 262 | Train Loss: 0.3577415 Vali Loss: 0.9814531 Test Loss: 0.4465275
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3368392
	speed: 0.0595s/iter; left time: 897.6830s
	iters: 200, epoch: 43 | loss: 0.3636254
	speed: 0.0131s/iter; left time: 196.8322s
Epoch: 43 cost time: 3.950237274169922
Epoch: 43, Steps: 262 | Train Loss: 0.3577911 Vali Loss: 0.9818939 Test Loss: 0.4465037
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.3911532
	speed: 0.0748s/iter; left time: 1109.7366s
	iters: 200, epoch: 44 | loss: 0.3686370
	speed: 0.0143s/iter; left time: 210.6773s
Epoch: 44 cost time: 4.622195720672607
Epoch: 44, Steps: 262 | Train Loss: 0.3577711 Vali Loss: 0.9824016 Test Loss: 0.4464802
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.3603266
	speed: 0.0657s/iter; left time: 957.1260s
	iters: 200, epoch: 45 | loss: 0.3663049
	speed: 0.0140s/iter; left time: 203.1774s
Epoch: 45 cost time: 4.365872621536255
Epoch: 45, Steps: 262 | Train Loss: 0.3578845 Vali Loss: 0.9819546 Test Loss: 0.4465283
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.3435633
	speed: 0.0672s/iter; left time: 961.3010s
	iters: 200, epoch: 46 | loss: 0.3935479
	speed: 0.0141s/iter; left time: 200.3020s
Epoch: 46 cost time: 4.462325096130371
Epoch: 46, Steps: 262 | Train Loss: 0.3578100 Vali Loss: 0.9825980 Test Loss: 0.4465193
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.3636711
	speed: 0.0696s/iter; left time: 977.4023s
	iters: 200, epoch: 47 | loss: 0.3854477
	speed: 0.0141s/iter; left time: 196.4103s
Epoch: 47 cost time: 4.548207521438599
Epoch: 47, Steps: 262 | Train Loss: 0.3576448 Vali Loss: 0.9819093 Test Loss: 0.4465562
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.3396976
	speed: 0.0646s/iter; left time: 890.5265s
	iters: 200, epoch: 48 | loss: 0.3653443
	speed: 0.0142s/iter; left time: 194.5620s
Epoch: 48 cost time: 4.219243049621582
Epoch: 48, Steps: 262 | Train Loss: 0.3578656 Vali Loss: 0.9819570 Test Loss: 0.4465382
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.3323786
	speed: 0.0690s/iter; left time: 933.0366s
	iters: 200, epoch: 49 | loss: 0.3567092
	speed: 0.0127s/iter; left time: 170.6950s
Epoch: 49 cost time: 3.914205551147461
Epoch: 49, Steps: 262 | Train Loss: 0.3578346 Vali Loss: 0.9820031 Test Loss: 0.4465508
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.3447563
	speed: 0.0646s/iter; left time: 856.5728s
	iters: 200, epoch: 50 | loss: 0.3255938
	speed: 0.0140s/iter; left time: 184.7082s
Epoch: 50 cost time: 4.2202112674713135
Epoch: 50, Steps: 262 | Train Loss: 0.3578386 Vali Loss: 0.9818676 Test Loss: 0.4465509
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.3338003
	speed: 0.0662s/iter; left time: 861.0087s
	iters: 200, epoch: 51 | loss: 0.3573140
	speed: 0.0151s/iter; left time: 194.3770s
Epoch: 51 cost time: 4.373820066452026
Epoch: 51, Steps: 262 | Train Loss: 0.3577100 Vali Loss: 0.9830832 Test Loss: 0.4465367
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.3499626
	speed: 0.0690s/iter; left time: 878.7457s
	iters: 200, epoch: 52 | loss: 0.3483239
	speed: 0.0145s/iter; left time: 183.2315s
Epoch: 52 cost time: 4.425034284591675
Epoch: 52, Steps: 262 | Train Loss: 0.3577591 Vali Loss: 0.9817716 Test Loss: 0.4465268
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.3768351
	speed: 0.0671s/iter; left time: 836.7174s
	iters: 200, epoch: 53 | loss: 0.3467651
	speed: 0.0146s/iter; left time: 180.7665s
Epoch: 53 cost time: 4.375033140182495
Epoch: 53, Steps: 262 | Train Loss: 0.3577193 Vali Loss: 0.9821119 Test Loss: 0.4465276
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.3578221
	speed: 0.0793s/iter; left time: 968.8379s
	iters: 200, epoch: 54 | loss: 0.3459654
	speed: 0.0150s/iter; left time: 182.2102s
Epoch: 54 cost time: 4.546091556549072
Epoch: 54, Steps: 262 | Train Loss: 0.3576307 Vali Loss: 0.9818547 Test Loss: 0.4465297
EarlyStopping counter: 20 out of 20
Early stopping
train 33661
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=38, out_features=190, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6469120.0
params:  7410.0
Trainable parameters:  7410
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4530429
	speed: 0.0193s/iter; left time: 503.4690s
	iters: 200, epoch: 1 | loss: 0.4371077
	speed: 0.0141s/iter; left time: 366.8636s
Epoch: 1 cost time: 4.19639778137207
Epoch: 1, Steps: 262 | Train Loss: 0.4429818 Vali Loss: 0.9805018 Test Loss: 0.4453509
Validation loss decreased (inf --> 0.980502).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4494196
	speed: 0.0687s/iter; left time: 1776.1326s
	iters: 200, epoch: 2 | loss: 0.4401680
	speed: 0.0140s/iter; left time: 361.0781s
Epoch: 2 cost time: 4.275591850280762
Epoch: 2, Steps: 262 | Train Loss: 0.4425594 Vali Loss: 0.9801137 Test Loss: 0.4452051
Validation loss decreased (0.980502 --> 0.980114).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3934945
	speed: 0.0650s/iter; left time: 1662.1895s
	iters: 200, epoch: 3 | loss: 0.4346771
	speed: 0.0145s/iter; left time: 369.1706s
Epoch: 3 cost time: 4.293568134307861
Epoch: 3, Steps: 262 | Train Loss: 0.4426095 Vali Loss: 0.9803548 Test Loss: 0.4449724
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4370915
	speed: 0.0669s/iter; left time: 1692.3833s
	iters: 200, epoch: 4 | loss: 0.4432174
	speed: 0.0141s/iter; left time: 356.2757s
Epoch: 4 cost time: 4.504959583282471
Epoch: 4, Steps: 262 | Train Loss: 0.4426481 Vali Loss: 0.9807234 Test Loss: 0.4449956
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4453299
	speed: 0.0696s/iter; left time: 1744.5741s
	iters: 200, epoch: 5 | loss: 0.4497460
	speed: 0.0147s/iter; left time: 366.7278s
Epoch: 5 cost time: 4.4277260303497314
Epoch: 5, Steps: 262 | Train Loss: 0.4423941 Vali Loss: 0.9792483 Test Loss: 0.4453743
Validation loss decreased (0.980114 --> 0.979248).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4609315
	speed: 0.0785s/iter; left time: 1946.4555s
	iters: 200, epoch: 6 | loss: 0.4312840
	speed: 0.0177s/iter; left time: 436.6156s
Epoch: 6 cost time: 5.2349278926849365
Epoch: 6, Steps: 262 | Train Loss: 0.4423482 Vali Loss: 0.9796602 Test Loss: 0.4451118
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4619171
	speed: 0.0751s/iter; left time: 1841.5875s
	iters: 200, epoch: 7 | loss: 0.4001938
	speed: 0.0157s/iter; left time: 384.0153s
Epoch: 7 cost time: 5.416522979736328
Epoch: 7, Steps: 262 | Train Loss: 0.4422999 Vali Loss: 0.9799524 Test Loss: 0.4450711
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4308468
	speed: 0.1017s/iter; left time: 2467.2887s
	iters: 200, epoch: 8 | loss: 0.4497076
	speed: 0.0180s/iter; left time: 434.3253s
Epoch: 8 cost time: 5.282294988632202
Epoch: 8, Steps: 262 | Train Loss: 0.4424189 Vali Loss: 0.9806836 Test Loss: 0.4453256
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4291805
	speed: 0.0722s/iter; left time: 1734.0090s
	iters: 200, epoch: 9 | loss: 0.4390607
	speed: 0.0156s/iter; left time: 373.2352s
Epoch: 9 cost time: 4.621230840682983
Epoch: 9, Steps: 262 | Train Loss: 0.4424643 Vali Loss: 0.9802204 Test Loss: 0.4450709
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4359492
	speed: 0.0845s/iter; left time: 2006.8544s
	iters: 200, epoch: 10 | loss: 0.4703707
	speed: 0.0169s/iter; left time: 398.4592s
Epoch: 10 cost time: 5.654620885848999
Epoch: 10, Steps: 262 | Train Loss: 0.4424157 Vali Loss: 0.9804360 Test Loss: 0.4453569
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4350043
	speed: 0.0989s/iter; left time: 2321.2001s
	iters: 200, epoch: 11 | loss: 0.4639284
	speed: 0.0177s/iter; left time: 413.9132s
Epoch: 11 cost time: 5.3549182415008545
Epoch: 11, Steps: 262 | Train Loss: 0.4423761 Vali Loss: 0.9797583 Test Loss: 0.4449607
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4389254
	speed: 0.0811s/iter; left time: 1881.9017s
	iters: 200, epoch: 12 | loss: 0.4369170
	speed: 0.0169s/iter; left time: 391.5591s
Epoch: 12 cost time: 4.658110857009888
Epoch: 12, Steps: 262 | Train Loss: 0.4423743 Vali Loss: 0.9807505 Test Loss: 0.4452153
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4541215
	speed: 0.0778s/iter; left time: 1786.2012s
	iters: 200, epoch: 13 | loss: 0.4252271
	speed: 0.0172s/iter; left time: 393.6571s
Epoch: 13 cost time: 5.57719612121582
Epoch: 13, Steps: 262 | Train Loss: 0.4422042 Vali Loss: 0.9804372 Test Loss: 0.4450625
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4640819
	speed: 0.1245s/iter; left time: 2825.0505s
	iters: 200, epoch: 14 | loss: 0.4456767
	speed: 0.0463s/iter; left time: 1045.4447s
Epoch: 14 cost time: 11.197022676467896
Epoch: 14, Steps: 262 | Train Loss: 0.4421760 Vali Loss: 0.9796460 Test Loss: 0.4452572
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4655424
	speed: 0.1394s/iter; left time: 3126.7086s
	iters: 200, epoch: 15 | loss: 0.4133178
	speed: 0.0379s/iter; left time: 845.9247s
Epoch: 15 cost time: 9.250574588775635
Epoch: 15, Steps: 262 | Train Loss: 0.4421890 Vali Loss: 0.9798492 Test Loss: 0.4453607
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4149916
	speed: 0.2070s/iter; left time: 4589.6618s
	iters: 200, epoch: 16 | loss: 0.4423356
	speed: 0.0285s/iter; left time: 628.3888s
Epoch: 16 cost time: 10.485054016113281
Epoch: 16, Steps: 262 | Train Loss: 0.4423370 Vali Loss: 0.9802352 Test Loss: 0.4452227
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4331255
	speed: 0.1352s/iter; left time: 2961.4797s
	iters: 200, epoch: 17 | loss: 0.4147981
	speed: 0.0258s/iter; left time: 562.9004s
Epoch: 17 cost time: 7.39996862411499
Epoch: 17, Steps: 262 | Train Loss: 0.4422983 Vali Loss: 0.9800130 Test Loss: 0.4452171
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4722729
	speed: 0.1244s/iter; left time: 2691.8780s
	iters: 200, epoch: 18 | loss: 0.4981247
	speed: 0.0225s/iter; left time: 484.4520s
Epoch: 18 cost time: 6.811418771743774
Epoch: 18, Steps: 262 | Train Loss: 0.4423126 Vali Loss: 0.9800382 Test Loss: 0.4453095
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4818654
	speed: 0.1327s/iter; left time: 2837.4109s
	iters: 200, epoch: 19 | loss: 0.4584296
	speed: 0.0362s/iter; left time: 770.9884s
Epoch: 19 cost time: 9.926903247833252
Epoch: 19, Steps: 262 | Train Loss: 0.4421494 Vali Loss: 0.9800247 Test Loss: 0.4453351
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4210934
	speed: 0.1357s/iter; left time: 2865.8439s
	iters: 200, epoch: 20 | loss: 0.4258935
	speed: 0.0328s/iter; left time: 689.3813s
Epoch: 20 cost time: 8.664956092834473
Epoch: 20, Steps: 262 | Train Loss: 0.4422404 Vali Loss: 0.9791481 Test Loss: 0.4452288
Validation loss decreased (0.979248 --> 0.979148).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4010631
	speed: 0.1669s/iter; left time: 3482.1856s
	iters: 200, epoch: 21 | loss: 0.4361021
	speed: 0.0319s/iter; left time: 661.3292s
Epoch: 21 cost time: 8.832732200622559
Epoch: 21, Steps: 262 | Train Loss: 0.4423544 Vali Loss: 0.9792157 Test Loss: 0.4451776
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4720255
	speed: 0.1282s/iter; left time: 2641.7646s
	iters: 200, epoch: 22 | loss: 0.4415467
	speed: 0.0317s/iter; left time: 650.7127s
Epoch: 22 cost time: 8.119745016098022
Epoch: 22, Steps: 262 | Train Loss: 0.4420786 Vali Loss: 0.9794658 Test Loss: 0.4451192
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4269433
	speed: 0.1078s/iter; left time: 2192.0571s
	iters: 200, epoch: 23 | loss: 0.4267275
	speed: 0.0271s/iter; left time: 549.1522s
Epoch: 23 cost time: 7.32744288444519
Epoch: 23, Steps: 262 | Train Loss: 0.4421587 Vali Loss: 0.9804174 Test Loss: 0.4452994
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4212049
	speed: 0.1419s/iter; left time: 2847.7467s
	iters: 200, epoch: 24 | loss: 0.4487598
	speed: 0.0380s/iter; left time: 758.4631s
Epoch: 24 cost time: 9.422336101531982
Epoch: 24, Steps: 262 | Train Loss: 0.4421321 Vali Loss: 0.9800432 Test Loss: 0.4453372
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4936369
	speed: 0.1442s/iter; left time: 2857.0543s
	iters: 200, epoch: 25 | loss: 0.4520573
	speed: 0.0279s/iter; left time: 549.2263s
Epoch: 25 cost time: 8.830471992492676
Epoch: 25, Steps: 262 | Train Loss: 0.4423518 Vali Loss: 0.9793604 Test Loss: 0.4452669
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4548505
	speed: 0.1472s/iter; left time: 2878.7192s
	iters: 200, epoch: 26 | loss: 0.4043195
	speed: 0.0269s/iter; left time: 522.5330s
Epoch: 26 cost time: 7.817403078079224
Epoch: 26, Steps: 262 | Train Loss: 0.4422563 Vali Loss: 0.9799047 Test Loss: 0.4452665
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4401848
	speed: 0.1170s/iter; left time: 2256.6439s
	iters: 200, epoch: 27 | loss: 0.4491741
	speed: 0.0254s/iter; left time: 487.7703s
Epoch: 27 cost time: 6.8545823097229
Epoch: 27, Steps: 262 | Train Loss: 0.4421941 Vali Loss: 0.9803914 Test Loss: 0.4452677
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4255228
	speed: 0.1108s/iter; left time: 2108.2868s
	iters: 200, epoch: 28 | loss: 0.4611627
	speed: 0.0252s/iter; left time: 476.2993s
Epoch: 28 cost time: 7.284420490264893
Epoch: 28, Steps: 262 | Train Loss: 0.4422220 Vali Loss: 0.9806339 Test Loss: 0.4452989
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4113767
	speed: 0.1357s/iter; left time: 2547.2939s
	iters: 200, epoch: 29 | loss: 0.4722565
	speed: 0.0376s/iter; left time: 701.8654s
Epoch: 29 cost time: 10.243333578109741
Epoch: 29, Steps: 262 | Train Loss: 0.4421870 Vali Loss: 0.9794421 Test Loss: 0.4451835
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3974191
	speed: 0.1454s/iter; left time: 2689.8450s
	iters: 200, epoch: 30 | loss: 0.4217013
	speed: 0.0355s/iter; left time: 652.7638s
Epoch: 30 cost time: 9.212989091873169
Epoch: 30, Steps: 262 | Train Loss: 0.4421798 Vali Loss: 0.9796169 Test Loss: 0.4452404
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4159093
	speed: 0.1814s/iter; left time: 3308.2719s
	iters: 200, epoch: 31 | loss: 0.4448895
	speed: 0.0569s/iter; left time: 1032.2349s
Epoch: 31 cost time: 15.710572004318237
Epoch: 31, Steps: 262 | Train Loss: 0.4420879 Vali Loss: 0.9800794 Test Loss: 0.4452329
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4208747
	speed: 0.1305s/iter; left time: 2346.6402s
	iters: 200, epoch: 32 | loss: 0.4315291
	speed: 0.0277s/iter; left time: 495.9319s
Epoch: 32 cost time: 7.643574237823486
Epoch: 32, Steps: 262 | Train Loss: 0.4422364 Vali Loss: 0.9796427 Test Loss: 0.4452782
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4002023
	speed: 0.1211s/iter; left time: 2144.8305s
	iters: 200, epoch: 33 | loss: 0.4092069
	speed: 0.0224s/iter; left time: 394.6862s
Epoch: 33 cost time: 6.610341310501099
Epoch: 33, Steps: 262 | Train Loss: 0.4423878 Vali Loss: 0.9805144 Test Loss: 0.4453231
EarlyStopping counter: 13 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4417697
	speed: 0.1245s/iter; left time: 2173.2858s
	iters: 200, epoch: 34 | loss: 0.4240844
	speed: 0.0350s/iter; left time: 607.3376s
Epoch: 34 cost time: 9.066078901290894
Epoch: 34, Steps: 262 | Train Loss: 0.4421133 Vali Loss: 0.9803031 Test Loss: 0.4451911
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4819544
	speed: 0.1432s/iter; left time: 2462.8855s
	iters: 200, epoch: 35 | loss: 0.4422778
	speed: 0.0370s/iter; left time: 631.7872s
Epoch: 35 cost time: 8.903140544891357
Epoch: 35, Steps: 262 | Train Loss: 0.4422694 Vali Loss: 0.9794812 Test Loss: 0.4452313
EarlyStopping counter: 15 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4027652
	speed: 0.1346s/iter; left time: 2279.2231s
	iters: 200, epoch: 36 | loss: 0.4308156
	speed: 0.0513s/iter; left time: 863.6980s
Epoch: 36 cost time: 10.080516815185547
Epoch: 36, Steps: 262 | Train Loss: 0.4420963 Vali Loss: 0.9799032 Test Loss: 0.4452583
EarlyStopping counter: 16 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4346828
	speed: 0.1247s/iter; left time: 2079.3331s
	iters: 200, epoch: 37 | loss: 0.3733298
	speed: 0.0214s/iter; left time: 353.8813s
Epoch: 37 cost time: 7.0879151821136475
Epoch: 37, Steps: 262 | Train Loss: 0.4420450 Vali Loss: 0.9802438 Test Loss: 0.4452053
EarlyStopping counter: 17 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4759122
	speed: 0.1164s/iter; left time: 1909.5666s
	iters: 200, epoch: 38 | loss: 0.4265670
	speed: 0.0236s/iter; left time: 384.9538s
Epoch: 38 cost time: 6.995377063751221
Epoch: 38, Steps: 262 | Train Loss: 0.4422135 Vali Loss: 0.9795531 Test Loss: 0.4453075
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4418750
	speed: 0.1431s/iter; left time: 2309.5709s
	iters: 200, epoch: 39 | loss: 0.4362419
	speed: 0.0234s/iter; left time: 375.5739s
Epoch: 39 cost time: 8.127341032028198
Epoch: 39, Steps: 262 | Train Loss: 0.4420367 Vali Loss: 0.9793183 Test Loss: 0.4452885
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.4593705
	speed: 0.1499s/iter; left time: 2380.4861s
	iters: 200, epoch: 40 | loss: 0.4446336
	speed: 0.0585s/iter; left time: 922.8611s
Epoch: 40 cost time: 13.054196834564209
Epoch: 40, Steps: 262 | Train Loss: 0.4422022 Vali Loss: 0.9793043 Test Loss: 0.4453124
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_180_720_FITS_ETTm1_ftM_sl180_ll48_pl720_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.44338443875312805, mae:0.4247116446495056, rse:0.6335209608078003, corr:[0.5298804  0.5327775  0.5295213  0.52909005 0.5296726  0.528453
 0.5265637  0.5264294  0.5271346  0.5272775  0.52697945 0.5268755
 0.52688044 0.52579343 0.5238785  0.5217695  0.5197676  0.5179742
 0.51626617 0.51451105 0.5125508  0.510407   0.5082262  0.50592
 0.50331706 0.50074863 0.49879187 0.49746513 0.4964483  0.4955736
 0.49527416 0.49561983 0.49619436 0.49663928 0.49673748 0.49677953
 0.49667203 0.4963363  0.49606693 0.49585944 0.49580115 0.4956258
 0.49531108 0.4950999  0.49505016 0.49513155 0.4953397  0.49558356
 0.49582842 0.49594474 0.49597746 0.4959552  0.49595296 0.49594682
 0.49601683 0.49610248 0.4962457  0.49614403 0.49589607 0.49560893
 0.49553838 0.495612   0.49558368 0.49538043 0.495077   0.49499172
 0.4950646  0.49512568 0.49534953 0.49571162 0.49610472 0.49630308
 0.49634892 0.4964036  0.4966923  0.49688938 0.49689624 0.49671575
 0.49654424 0.49653056 0.4967139  0.49688354 0.49687004 0.496514
 0.49611992 0.49606392 0.4962991  0.4963071  0.49586582 0.49552923
 0.49561697 0.49596667 0.49602935 0.49558467 0.49492577 0.4943093
 0.49370065 0.49283662 0.49165902 0.49057573 0.49005008 0.49011874
 0.49046093 0.49098837 0.49196464 0.49337244 0.49473357 0.49565274
 0.49614558 0.49638775 0.4965145  0.49666816 0.4966622  0.49648765
 0.49615696 0.49588564 0.49552524 0.4950031  0.49448138 0.49401927
 0.49366814 0.49312457 0.49246782 0.49208713 0.4918362  0.4913566
 0.4905797  0.4898014  0.4893912  0.4894434  0.48969015 0.4898093
 0.4897333  0.48964596 0.48942843 0.48893043 0.48852485 0.48827675
 0.48809364 0.48791552 0.48763943 0.48746485 0.48765844 0.4881534
 0.48848876 0.4884333  0.4880192  0.4877994  0.48815498 0.48846862
 0.48853412 0.48842922 0.48827392 0.48823455 0.48814857 0.4881344
 0.48813015 0.4881657  0.48808908 0.48807353 0.4881303  0.48828134
 0.48849705 0.48866612 0.48868862 0.48882934 0.48914978 0.48964235
 0.49029016 0.49077007 0.4907963  0.4906539  0.49047098 0.49035338
 0.49036795 0.49034992 0.49031216 0.4903181  0.4902719  0.4902518
 0.49023715 0.49020433 0.49006566 0.48986042 0.4897365  0.48983732
 0.49009895 0.49028128 0.49026367 0.4902016  0.49028197 0.4904357
 0.4904024  0.49011478 0.4896546  0.48902705 0.48839232 0.48790127
 0.487516   0.48714164 0.4867655  0.48667988 0.4866759  0.48665717
 0.48653206 0.48608577 0.48549682 0.4849004  0.48426592 0.48367125
 0.4831473  0.48271024 0.48212138 0.48117793 0.47996652 0.47880247
 0.47781742 0.47687298 0.47605476 0.47550556 0.4751116  0.47475517
 0.47446495 0.47443599 0.47463083 0.47487143 0.47497493 0.47476396
 0.47438997 0.47423938 0.47413453 0.47382328 0.47340032 0.47311723
 0.47303733 0.47305906 0.47280937 0.47262698 0.47274822 0.473039
 0.4734356  0.47352913 0.47349292 0.4734037  0.47339594 0.4734557
 0.47348258 0.4733428  0.4732566  0.47336242 0.47356802 0.47368407
 0.47363925 0.47362724 0.47355506 0.47355196 0.4734842  0.4733716
 0.4734428  0.47364566 0.47382677 0.47400033 0.47420877 0.4745877
 0.47514373 0.47545874 0.47547764 0.4754401  0.47562033 0.4758933
 0.47613883 0.47612178 0.4761142  0.4762902  0.47670636 0.47706917
 0.47722253 0.47736597 0.47755983 0.47776836 0.47795966 0.47807607
 0.4781821  0.47813258 0.4780105  0.47788677 0.47775576 0.47749564
 0.47684368 0.47594836 0.47510427 0.47437304 0.47383964 0.4734329
 0.47329074 0.4733203  0.4737127  0.47438955 0.47502565 0.4754307
 0.47555786 0.47550437 0.47554332 0.47567195 0.47573477 0.47562414
 0.4754413  0.47519833 0.47480354 0.4742767  0.47379118 0.47350624
 0.47336668 0.47311863 0.47279105 0.4725523  0.4721863  0.47196445
 0.47189263 0.47174004 0.47151837 0.47141758 0.47124213 0.47101676
 0.4707073  0.47033414 0.4699071  0.46955532 0.4692801  0.4690652
 0.46883413 0.46860525 0.46830904 0.46810138 0.46816778 0.4683402
 0.46848562 0.46852604 0.46849585 0.46852276 0.46874183 0.46886894
 0.4688094  0.46865803 0.46862242 0.46868408 0.46872595 0.46875006
 0.46869192 0.46866158 0.46871766 0.4686993  0.46866518 0.46869808
 0.46880335 0.46899927 0.46906567 0.46910372 0.4691999  0.46942267
 0.4696404  0.46980396 0.46973056 0.46956655 0.4695158  0.46960455
 0.46968722 0.46977973 0.469936   0.47015154 0.47046912 0.4707308
 0.47099185 0.4712963  0.47163248 0.47177756 0.47173393 0.4718032
 0.4721466  0.4725541  0.47280127 0.472783   0.4726422  0.47251734
 0.4723188  0.47184223 0.47123364 0.47056803 0.47002771 0.4698592
 0.46996185 0.4702194  0.47049412 0.47105467 0.47179836 0.4725568
 0.47307047 0.47322574 0.47311255 0.4730117  0.47295558 0.47292504
 0.4728173  0.4725406  0.47215822 0.47176918 0.47134367 0.47084892
 0.47025013 0.46953613 0.46897942 0.46875522 0.46871856 0.46858054
 0.46839377 0.4681478  0.46807757 0.46811807 0.46802822 0.4679176
 0.4676485  0.46741325 0.46713248 0.46675318 0.46632877 0.4660977
 0.46599475 0.4660424  0.46597567 0.4657992  0.4656103  0.46575415
 0.46604064 0.46631572 0.4664038  0.46636927 0.4661924  0.4661883
 0.4662026  0.4661292  0.46598184 0.4658576  0.46588045 0.46610537
 0.466354   0.46645486 0.4663159  0.46623203 0.46627367 0.46634477
 0.4664321  0.4664733  0.46646684 0.46659613 0.46681193 0.46723133
 0.4675176  0.46739542 0.46700042 0.46673727 0.46669704 0.46688783
 0.4671118  0.46718928 0.4670871  0.4670468  0.4671276  0.46721038
 0.46728694 0.46745968 0.46781245 0.46804318 0.46807006 0.46797797
 0.46784618 0.46774542 0.46760833 0.46731406 0.46681094 0.4660586
 0.46491665 0.46347675 0.46207795 0.4609773  0.4601659  0.45956016
 0.45906788 0.4585515  0.45833033 0.458276   0.4582021  0.45807198
 0.45807678 0.4581164  0.45809355 0.45795092 0.4576076  0.4570829
 0.45653376 0.456132   0.4558092  0.45543537 0.45503634 0.45455423
 0.45409212 0.45362297 0.45321798 0.45300442 0.45281482 0.45263514
 0.45246306 0.45243183 0.452505   0.45264354 0.45256212 0.45225272
 0.45192295 0.4518948  0.45199278 0.4517924  0.45128176 0.4507799
 0.450508   0.4505887  0.4506779  0.45051104 0.4502259  0.45003992
 0.45002592 0.45018053 0.450277   0.45021808 0.45008004 0.44994757
 0.44991186 0.44995996 0.45020038 0.4503535  0.45036048 0.4503194
 0.4503955  0.4504315  0.45050192 0.45048544 0.45037314 0.450267
 0.45023838 0.4503368  0.45055634 0.4507846  0.45094657 0.4511422
 0.45131555 0.4513569  0.45131552 0.4513587  0.45139626 0.45144385
 0.45159793 0.4518618  0.45207295 0.45221782 0.4522385  0.4522125
 0.45214885 0.452367   0.45268795 0.4529144  0.45290792 0.45280772
 0.45278323 0.4528159  0.4528264  0.45257616 0.4518912  0.45068213
 0.4490366  0.44733804 0.44588664 0.44464192 0.44364834 0.44296882
 0.44263786 0.44265255 0.44303682 0.44360602 0.44420096 0.4445966
 0.44472727 0.44460905 0.4444234  0.44431177 0.44426078 0.44422793
 0.44409332 0.44383737 0.44343466 0.44287    0.44233203 0.44187778
 0.44161537 0.44130793 0.44087464 0.44054168 0.44024616 0.44002497
 0.43998322 0.44019085 0.44040406 0.4404174  0.44024754 0.4401465
 0.44013122 0.44013983 0.44021448 0.44011024 0.4398038  0.43932512
 0.43899685 0.438901   0.43893945 0.43897778 0.43901393 0.43911803
 0.43928793 0.43957153 0.43982854 0.43983218 0.43966308 0.4394919
 0.4393798  0.43932337 0.43920988 0.43899298 0.43886355 0.4387446
 0.43864265 0.43866703 0.4386075  0.43839782 0.43825534 0.43813682
 0.4381637  0.43834808 0.43859607 0.4388732  0.43911716 0.43938968
 0.43969226 0.43991846 0.4401511  0.44041103 0.44049856 0.4403878
 0.44019964 0.4401713  0.44040316 0.44080725 0.441202   0.4413827
 0.44135508 0.4414011  0.44167513 0.44194365 0.4420758  0.4420798
 0.44212195 0.44227442 0.4422695  0.44181007 0.4408976  0.43981814
 0.43878588 0.4378461  0.43692076 0.43608916 0.43562782 0.43546137
 0.435362   0.43537584 0.43564937 0.43627113 0.43700436 0.4376651
 0.4380593  0.43808258 0.43798003 0.43786976 0.43768287 0.4373056
 0.43682495 0.43636596 0.43597582 0.43544132 0.4346289  0.43392304
 0.43350804 0.43319815 0.43280283 0.43215126 0.43146813 0.43108672
 0.431083   0.43103886 0.43076482 0.4305344  0.43049    0.43065515
 0.4305253  0.42988956 0.42941108 0.42944968 0.42963278 0.42937714
 0.42917076 0.4297431  0.43059108 0.43074724 0.43105987 0.43284342]
