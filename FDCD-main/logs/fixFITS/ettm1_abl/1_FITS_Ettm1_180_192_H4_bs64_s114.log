Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=18, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_180_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_180_192_FITS_ETTm1_ftM_sl180_ll48_pl192_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34189
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=18, out_features=37, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  596736.0
params:  703.0
Trainable parameters:  703
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4847432
	speed: 0.1465s/iter; left time: 3896.7812s
	iters: 200, epoch: 1 | loss: 0.4722162
	speed: 0.1299s/iter; left time: 3442.4345s
Epoch: 1 cost time: 36.9621844291687
Epoch: 1, Steps: 267 | Train Loss: 0.5278455 Vali Loss: 0.6866501 Test Loss: 0.4744105
Validation loss decreased (inf --> 0.686650).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3629313
	speed: 0.6141s/iter; left time: 16171.2844s
	iters: 200, epoch: 2 | loss: 0.3640288
	speed: 0.1309s/iter; left time: 3433.2840s
Epoch: 2 cost time: 36.400046586990356
Epoch: 2, Steps: 267 | Train Loss: 0.3721639 Vali Loss: 0.5776657 Test Loss: 0.3825354
Validation loss decreased (0.686650 --> 0.577666).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3338004
	speed: 0.6346s/iter; left time: 16541.4265s
	iters: 200, epoch: 3 | loss: 0.3277337
	speed: 0.1401s/iter; left time: 3638.6661s
Epoch: 3 cost time: 38.863096714019775
Epoch: 3, Steps: 267 | Train Loss: 0.3456187 Vali Loss: 0.5486947 Test Loss: 0.3613117
Validation loss decreased (0.577666 --> 0.548695).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3751297
	speed: 0.6330s/iter; left time: 16331.6518s
	iters: 200, epoch: 4 | loss: 0.3187636
	speed: 0.1406s/iter; left time: 3614.5719s
Epoch: 4 cost time: 37.003700733184814
Epoch: 4, Steps: 267 | Train Loss: 0.3378171 Vali Loss: 0.5361779 Test Loss: 0.3542850
Validation loss decreased (0.548695 --> 0.536178).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3189712
	speed: 0.6293s/iter; left time: 16066.9878s
	iters: 200, epoch: 5 | loss: 0.3368331
	speed: 0.1303s/iter; left time: 3313.5295s
Epoch: 5 cost time: 35.37901329994202
Epoch: 5, Steps: 267 | Train Loss: 0.3348708 Vali Loss: 0.5317678 Test Loss: 0.3515948
Validation loss decreased (0.536178 --> 0.531768).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3146476
	speed: 0.5863s/iter; left time: 14812.8518s
	iters: 200, epoch: 6 | loss: 0.3227612
	speed: 0.1268s/iter; left time: 3189.8478s
Epoch: 6 cost time: 34.37820482254028
Epoch: 6, Steps: 267 | Train Loss: 0.3335499 Vali Loss: 0.5288717 Test Loss: 0.3504230
Validation loss decreased (0.531768 --> 0.528872).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3118143
	speed: 0.6216s/iter; left time: 15540.1985s
	iters: 200, epoch: 7 | loss: 0.3341598
	speed: 0.1365s/iter; left time: 3398.1093s
Epoch: 7 cost time: 36.687686920166016
Epoch: 7, Steps: 267 | Train Loss: 0.3328930 Vali Loss: 0.5278283 Test Loss: 0.3499822
Validation loss decreased (0.528872 --> 0.527828).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3181526
	speed: 0.6180s/iter; left time: 15283.8531s
	iters: 200, epoch: 8 | loss: 0.3299252
	speed: 0.1200s/iter; left time: 2954.8738s
Epoch: 8 cost time: 34.99526309967041
Epoch: 8, Steps: 267 | Train Loss: 0.3325643 Vali Loss: 0.5272529 Test Loss: 0.3497373
Validation loss decreased (0.527828 --> 0.527253).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3095588
	speed: 0.6011s/iter; left time: 14706.8693s
	iters: 200, epoch: 9 | loss: 0.3817628
	speed: 0.1473s/iter; left time: 3589.5034s
Epoch: 9 cost time: 38.77390933036804
Epoch: 9, Steps: 267 | Train Loss: 0.3323689 Vali Loss: 0.5267255 Test Loss: 0.3495362
Validation loss decreased (0.527253 --> 0.526726).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3597728
	speed: 0.6369s/iter; left time: 15412.5516s
	iters: 200, epoch: 10 | loss: 0.3096673
	speed: 0.1371s/iter; left time: 3304.0100s
Epoch: 10 cost time: 36.40231156349182
Epoch: 10, Steps: 267 | Train Loss: 0.3322037 Vali Loss: 0.5262356 Test Loss: 0.3492877
Validation loss decreased (0.526726 --> 0.526236).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3129080
	speed: 0.5855s/iter; left time: 14012.7326s
	iters: 200, epoch: 11 | loss: 0.3664711
	speed: 0.1216s/iter; left time: 2898.1164s
Epoch: 11 cost time: 32.69459629058838
Epoch: 11, Steps: 267 | Train Loss: 0.3320803 Vali Loss: 0.5259241 Test Loss: 0.3490401
Validation loss decreased (0.526236 --> 0.525924).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3147234
	speed: 0.5417s/iter; left time: 12818.8688s
	iters: 200, epoch: 12 | loss: 0.3289641
	speed: 0.1253s/iter; left time: 2953.1981s
Epoch: 12 cost time: 34.49577832221985
Epoch: 12, Steps: 267 | Train Loss: 0.3319969 Vali Loss: 0.5256247 Test Loss: 0.3491386
Validation loss decreased (0.525924 --> 0.525625).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3530479
	speed: 0.5609s/iter; left time: 13122.8082s
	iters: 200, epoch: 13 | loss: 0.3606276
	speed: 0.1393s/iter; left time: 3244.9306s
Epoch: 13 cost time: 34.86842441558838
Epoch: 13, Steps: 267 | Train Loss: 0.3319073 Vali Loss: 0.5253062 Test Loss: 0.3491552
Validation loss decreased (0.525625 --> 0.525306).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3401898
	speed: 0.5406s/iter; left time: 12503.8675s
	iters: 200, epoch: 14 | loss: 0.3135292
	speed: 0.1244s/iter; left time: 2865.2451s
Epoch: 14 cost time: 34.72574520111084
Epoch: 14, Steps: 267 | Train Loss: 0.3318409 Vali Loss: 0.5249664 Test Loss: 0.3491082
Validation loss decreased (0.525306 --> 0.524966).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3304131
	speed: 0.5670s/iter; left time: 12964.0557s
	iters: 200, epoch: 15 | loss: 0.3178312
	speed: 0.1238s/iter; left time: 2817.0031s
Epoch: 15 cost time: 33.04836678504944
Epoch: 15, Steps: 267 | Train Loss: 0.3318875 Vali Loss: 0.5251643 Test Loss: 0.3490447
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3457825
	speed: 0.5964s/iter; left time: 13477.1113s
	iters: 200, epoch: 16 | loss: 0.3126697
	speed: 0.1365s/iter; left time: 3070.5558s
Epoch: 16 cost time: 36.300628423690796
Epoch: 16, Steps: 267 | Train Loss: 0.3318197 Vali Loss: 0.5245858 Test Loss: 0.3489499
Validation loss decreased (0.524966 --> 0.524586).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3434657
	speed: 0.6162s/iter; left time: 13758.4530s
	iters: 200, epoch: 17 | loss: 0.3624872
	speed: 0.1292s/iter; left time: 2871.7078s
Epoch: 17 cost time: 35.050827741622925
Epoch: 17, Steps: 267 | Train Loss: 0.3317719 Vali Loss: 0.5252746 Test Loss: 0.3487925
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3201917
	speed: 0.5267s/iter; left time: 11618.9695s
	iters: 200, epoch: 18 | loss: 0.3229026
	speed: 0.1276s/iter; left time: 2802.3551s
Epoch: 18 cost time: 35.4359929561615
Epoch: 18, Steps: 267 | Train Loss: 0.3317417 Vali Loss: 0.5250944 Test Loss: 0.3487409
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3513330
	speed: 0.5833s/iter; left time: 12714.1084s
	iters: 200, epoch: 19 | loss: 0.3343109
	speed: 0.1189s/iter; left time: 2579.8925s
Epoch: 19 cost time: 32.937488317489624
Epoch: 19, Steps: 267 | Train Loss: 0.3316964 Vali Loss: 0.5248508 Test Loss: 0.3489513
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3289519
	speed: 0.5733s/iter; left time: 12342.2920s
	iters: 200, epoch: 20 | loss: 0.3669187
	speed: 0.1361s/iter; left time: 2916.2454s
Epoch: 20 cost time: 34.69297242164612
Epoch: 20, Steps: 267 | Train Loss: 0.3316570 Vali Loss: 0.5253581 Test Loss: 0.3487942
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3799455
	speed: 0.5876s/iter; left time: 12493.4124s
	iters: 200, epoch: 21 | loss: 0.3158320
	speed: 0.1371s/iter; left time: 2900.1812s
Epoch: 21 cost time: 36.61508846282959
Epoch: 21, Steps: 267 | Train Loss: 0.3316231 Vali Loss: 0.5243390 Test Loss: 0.3488500
Validation loss decreased (0.524586 --> 0.524339).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3478759
	speed: 0.5640s/iter; left time: 11840.8815s
	iters: 200, epoch: 22 | loss: 0.3056981
	speed: 0.1308s/iter; left time: 2733.7363s
Epoch: 22 cost time: 35.96528959274292
Epoch: 22, Steps: 267 | Train Loss: 0.3316639 Vali Loss: 0.5250092 Test Loss: 0.3490939
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3457841
	speed: 0.5899s/iter; left time: 12226.2586s
	iters: 200, epoch: 23 | loss: 0.3216589
	speed: 0.1265s/iter; left time: 2609.9999s
Epoch: 23 cost time: 34.72968339920044
Epoch: 23, Steps: 267 | Train Loss: 0.3316362 Vali Loss: 0.5234816 Test Loss: 0.3489675
Validation loss decreased (0.524339 --> 0.523482).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3525509
	speed: 0.5700s/iter; left time: 11661.6040s
	iters: 200, epoch: 24 | loss: 0.3445745
	speed: 0.1189s/iter; left time: 2420.4540s
Epoch: 24 cost time: 32.916993141174316
Epoch: 24, Steps: 267 | Train Loss: 0.3316064 Vali Loss: 0.5241634 Test Loss: 0.3488291
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3594117
	speed: 0.5939s/iter; left time: 11992.5283s
	iters: 200, epoch: 25 | loss: 0.2894081
	speed: 0.1264s/iter; left time: 2538.8613s
Epoch: 25 cost time: 35.827680349349976
Epoch: 25, Steps: 267 | Train Loss: 0.3316050 Vali Loss: 0.5246328 Test Loss: 0.3488648
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3378034
	speed: 0.5642s/iter; left time: 11243.2041s
	iters: 200, epoch: 26 | loss: 0.3013811
	speed: 0.1208s/iter; left time: 2394.3409s
Epoch: 26 cost time: 33.28551912307739
Epoch: 26, Steps: 267 | Train Loss: 0.3315647 Vali Loss: 0.5245599 Test Loss: 0.3489447
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3355892
	speed: 0.5759s/iter; left time: 11320.7435s
	iters: 200, epoch: 27 | loss: 0.3775738
	speed: 0.1301s/iter; left time: 2545.4585s
Epoch: 27 cost time: 34.66559052467346
Epoch: 27, Steps: 267 | Train Loss: 0.3315900 Vali Loss: 0.5242248 Test Loss: 0.3488247
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3293616
	speed: 0.5763s/iter; left time: 11175.5211s
	iters: 200, epoch: 28 | loss: 0.3189944
	speed: 0.1143s/iter; left time: 2204.2206s
Epoch: 28 cost time: 31.619672298431396
Epoch: 28, Steps: 267 | Train Loss: 0.3315363 Vali Loss: 0.5247573 Test Loss: 0.3489433
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3193876
	speed: 0.5578s/iter; left time: 10667.1866s
	iters: 200, epoch: 29 | loss: 0.3417475
	speed: 0.1317s/iter; left time: 2505.6083s
Epoch: 29 cost time: 34.921875953674316
Epoch: 29, Steps: 267 | Train Loss: 0.3315070 Vali Loss: 0.5241306 Test Loss: 0.3487809
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3243105
	speed: 0.5985s/iter; left time: 11285.6462s
	iters: 200, epoch: 30 | loss: 0.3399880
	speed: 0.1283s/iter; left time: 2407.5698s
Epoch: 30 cost time: 34.549410343170166
Epoch: 30, Steps: 267 | Train Loss: 0.3315419 Vali Loss: 0.5246854 Test Loss: 0.3489263
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3336073
	speed: 0.5353s/iter; left time: 9951.5982s
	iters: 200, epoch: 31 | loss: 0.3161221
	speed: 0.1218s/iter; left time: 2252.6504s
Epoch: 31 cost time: 34.64034581184387
Epoch: 31, Steps: 267 | Train Loss: 0.3315182 Vali Loss: 0.5246218 Test Loss: 0.3488520
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3611684
	speed: 0.5781s/iter; left time: 10592.3449s
	iters: 200, epoch: 32 | loss: 0.3304734
	speed: 0.1217s/iter; left time: 2218.6626s
Epoch: 32 cost time: 34.93579316139221
Epoch: 32, Steps: 267 | Train Loss: 0.3315013 Vali Loss: 0.5242280 Test Loss: 0.3488024
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3298753
	speed: 0.5328s/iter; left time: 9620.8985s
	iters: 200, epoch: 33 | loss: 0.3150139
	speed: 0.1257s/iter; left time: 2256.7604s
Epoch: 33 cost time: 33.89524507522583
Epoch: 33, Steps: 267 | Train Loss: 0.3315320 Vali Loss: 0.5245731 Test Loss: 0.3487753
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2910972
	speed: 0.5594s/iter; left time: 9951.6893s
	iters: 200, epoch: 34 | loss: 0.3011698
	speed: 0.1119s/iter; left time: 1978.8183s
Epoch: 34 cost time: 32.42008852958679
Epoch: 34, Steps: 267 | Train Loss: 0.3314791 Vali Loss: 0.5245090 Test Loss: 0.3488242
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3300290
	speed: 0.5547s/iter; left time: 9720.7400s
	iters: 200, epoch: 35 | loss: 0.3237107
	speed: 0.1172s/iter; left time: 2042.3944s
Epoch: 35 cost time: 32.261332988739014
Epoch: 35, Steps: 267 | Train Loss: 0.3313991 Vali Loss: 0.5246774 Test Loss: 0.3488191
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3099663
	speed: 0.5263s/iter; left time: 9081.0818s
	iters: 200, epoch: 36 | loss: 0.3298625
	speed: 0.1339s/iter; left time: 2296.3636s
Epoch: 36 cost time: 34.26122283935547
Epoch: 36, Steps: 267 | Train Loss: 0.3314782 Vali Loss: 0.5243517 Test Loss: 0.3488527
EarlyStopping counter: 13 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3621026
	speed: 0.5135s/iter; left time: 8723.4675s
	iters: 200, epoch: 37 | loss: 0.3431961
	speed: 0.1166s/iter; left time: 1970.0950s
Epoch: 37 cost time: 30.472678184509277
Epoch: 37, Steps: 267 | Train Loss: 0.3314542 Vali Loss: 0.5239055 Test Loss: 0.3488085
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3057710
	speed: 0.5348s/iter; left time: 8942.8233s
	iters: 200, epoch: 38 | loss: 0.3474346
	speed: 0.1221s/iter; left time: 2030.0838s
Epoch: 38 cost time: 32.5794141292572
Epoch: 38, Steps: 267 | Train Loss: 0.3314487 Vali Loss: 0.5241010 Test Loss: 0.3488009
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3254945
	speed: 0.5211s/iter; left time: 8574.2022s
	iters: 200, epoch: 39 | loss: 0.3290277
	speed: 0.1247s/iter; left time: 2038.8379s
Epoch: 39 cost time: 31.94350266456604
Epoch: 39, Steps: 267 | Train Loss: 0.3314286 Vali Loss: 0.5243056 Test Loss: 0.3488076
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.3433863
	speed: 0.5059s/iter; left time: 8189.0590s
	iters: 200, epoch: 40 | loss: 0.3086984
	speed: 0.1163s/iter; left time: 1870.8132s
Epoch: 40 cost time: 32.966004371643066
Epoch: 40, Steps: 267 | Train Loss: 0.3314592 Vali Loss: 0.5248619 Test Loss: 0.3488446
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3258716
	speed: 0.5452s/iter; left time: 8679.9268s
	iters: 200, epoch: 41 | loss: 0.3380463
	speed: 0.1082s/iter; left time: 1711.9245s
Epoch: 41 cost time: 30.450720071792603
Epoch: 41, Steps: 267 | Train Loss: 0.3314310 Vali Loss: 0.5242637 Test Loss: 0.3488087
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3483429
	speed: 0.4619s/iter; left time: 7230.9151s
	iters: 200, epoch: 42 | loss: 0.3370148
	speed: 0.1030s/iter; left time: 1602.3085s
Epoch: 42 cost time: 29.68063712120056
Epoch: 42, Steps: 267 | Train Loss: 0.3314201 Vali Loss: 0.5242465 Test Loss: 0.3488359
EarlyStopping counter: 19 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3350146
	speed: 0.4504s/iter; left time: 6929.6110s
	iters: 200, epoch: 43 | loss: 0.3185152
	speed: 0.1124s/iter; left time: 1718.5827s
Epoch: 43 cost time: 30.07527804374695
Epoch: 43, Steps: 267 | Train Loss: 0.3314344 Vali Loss: 0.5235264 Test Loss: 0.3488360
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_180_192_FITS_ETTm1_ftM_sl180_ll48_pl192_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.34916502237319946, mae:0.3701515793800354, rse:0.5624926686286926, corr:[0.5488467  0.55248296 0.55275124 0.5507065  0.5479496  0.54605854
 0.5456319  0.5466003  0.5480066  0.54914486 0.54967934 0.54925084
 0.54815674 0.54646635 0.5445428  0.5427697  0.5411558  0.5396188
 0.53806037 0.5363846  0.53452325 0.5323365  0.5298199  0.5271585
 0.5246048  0.5224493  0.5209458  0.520057   0.51968807 0.5196556
 0.51987165 0.5201056  0.52011836 0.51989657 0.51948494 0.51902944
 0.51856416 0.5181386  0.51786166 0.5176598  0.51754296 0.51741064
 0.51724726 0.5171281  0.51707405 0.51711214 0.5172694  0.51751083
 0.5177758  0.51797634 0.51811165 0.51820505 0.51826376 0.518263
 0.51819587 0.51804084 0.51789325 0.5177194  0.5175829  0.5174694
 0.5174245  0.5174298  0.5174208  0.51735896 0.5172624  0.51724225
 0.51731503 0.5174738  0.51778436 0.5182038  0.51867044 0.51907384
 0.51932395 0.51937395 0.51930755 0.51912534 0.51893073 0.51877064
 0.5186686  0.5186105  0.5185953  0.5185785  0.5185522  0.51844674
 0.51825976 0.518046   0.5178314  0.5175481  0.51718086 0.5168186
 0.5164977  0.5162149  0.5159545  0.5157266  0.515477   0.51506096
 0.5144314  0.5136429  0.5127591  0.51186645 0.51119703 0.5109394
 0.5111506  0.51181865 0.5128675  0.51414925 0.5154213  0.5164706
 0.51716226 0.5174359  0.5173767  0.5172788  0.5172178  0.51725495
 0.5173533  0.51748264 0.5174969  0.5172867  0.5168522  0.5162262
 0.5155359  0.5148056  0.5141182  0.5136088  0.5133095  0.5131835
 0.5131995  0.5132806  0.51331866 0.5132345  0.512972   0.5125269
 0.5119736  0.5115118  0.51121074 0.51104885 0.51106113 0.5111416
 0.5111817  0.5111678  0.5110598  0.5108945  0.5107479  0.510713
 0.5108108  0.5110401  0.5112784  0.5114961  0.5117111  0.5117505
 0.5116187  0.51139104 0.5111257  0.51093453 0.51081413 0.51084286
 0.5110138  0.5113027  0.5115851  0.51180875 0.51191163 0.5118973
 0.51181376 0.5117318  0.5116912  0.51178795 0.5120037  0.5123272
 0.5127251  0.5130892  0.513331   0.51349336 0.51352423 0.51341224
 0.51320183 0.5129082  0.51261574 0.5123897  0.51222223 0.5121893
 0.5122964  0.5125138  0.5127002  0.5126913  0.51234704 0.51164407
 0.5107678  0.51011425 0.5102842  0.5118995  0.5146867  0.5162857 ]
