Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=14, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_90_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_90_336_FITS_ETTm1_ftM_sl90_ll48_pl336_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=14, out_features=66, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  827904.0
params:  990.0
Trainable parameters:  990
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.7955029
	speed: 0.0159s/iter; left time: 420.5271s
	iters: 200, epoch: 1 | loss: 0.5502713
	speed: 0.0111s/iter; left time: 292.3590s
Epoch: 1 cost time: 3.374253988265991
Epoch: 1, Steps: 266 | Train Loss: 0.7138729 Vali Loss: 1.0578725 Test Loss: 0.7937315
Validation loss decreased (inf --> 1.057873).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4617234
	speed: 0.0494s/iter; left time: 1295.2296s
	iters: 200, epoch: 2 | loss: 0.4846291
	speed: 0.0109s/iter; left time: 283.5949s
Epoch: 2 cost time: 3.3500571250915527
Epoch: 2, Steps: 266 | Train Loss: 0.4458992 Vali Loss: 0.8322705 Test Loss: 0.5658827
Validation loss decreased (1.057873 --> 0.832271).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3921578
	speed: 0.0524s/iter; left time: 1359.7346s
	iters: 200, epoch: 3 | loss: 0.3489558
	speed: 0.0117s/iter; left time: 301.4496s
Epoch: 3 cost time: 3.450310707092285
Epoch: 3, Steps: 266 | Train Loss: 0.3752430 Vali Loss: 0.7624294 Test Loss: 0.4964203
Validation loss decreased (0.832271 --> 0.762429).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3426427
	speed: 0.0500s/iter; left time: 1284.8528s
	iters: 200, epoch: 4 | loss: 0.3737046
	speed: 0.0111s/iter; left time: 283.9581s
Epoch: 4 cost time: 3.3882763385772705
Epoch: 4, Steps: 266 | Train Loss: 0.3546877 Vali Loss: 0.7337879 Test Loss: 0.4681029
Validation loss decreased (0.762429 --> 0.733788).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3426735
	speed: 0.0498s/iter; left time: 1266.1294s
	iters: 200, epoch: 5 | loss: 0.3282915
	speed: 0.0122s/iter; left time: 308.5482s
Epoch: 5 cost time: 3.4184372425079346
Epoch: 5, Steps: 266 | Train Loss: 0.3471056 Vali Loss: 0.7188552 Test Loss: 0.4540120
Validation loss decreased (0.733788 --> 0.718855).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3379898
	speed: 0.0514s/iter; left time: 1294.9866s
	iters: 200, epoch: 6 | loss: 0.3301900
	speed: 0.0116s/iter; left time: 289.8553s
Epoch: 6 cost time: 3.490635395050049
Epoch: 6, Steps: 266 | Train Loss: 0.3440038 Vali Loss: 0.7110195 Test Loss: 0.4462631
Validation loss decreased (0.718855 --> 0.711020).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3332904
	speed: 0.0499s/iter; left time: 1243.5036s
	iters: 200, epoch: 7 | loss: 0.3421713
	speed: 0.0115s/iter; left time: 285.4620s
Epoch: 7 cost time: 3.374225616455078
Epoch: 7, Steps: 266 | Train Loss: 0.3425097 Vali Loss: 0.7072986 Test Loss: 0.4419305
Validation loss decreased (0.711020 --> 0.707299).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3156944
	speed: 0.0518s/iter; left time: 1275.4328s
	iters: 200, epoch: 8 | loss: 0.3977670
	speed: 0.0108s/iter; left time: 264.1255s
Epoch: 8 cost time: 3.4075710773468018
Epoch: 8, Steps: 266 | Train Loss: 0.3418552 Vali Loss: 0.7051616 Test Loss: 0.4393979
Validation loss decreased (0.707299 --> 0.705162).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3297425
	speed: 0.0507s/iter; left time: 1236.4014s
	iters: 200, epoch: 9 | loss: 0.3627027
	speed: 0.0111s/iter; left time: 270.0416s
Epoch: 9 cost time: 3.4355366230010986
Epoch: 9, Steps: 266 | Train Loss: 0.3415572 Vali Loss: 0.7033671 Test Loss: 0.4377382
Validation loss decreased (0.705162 --> 0.703367).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3365573
	speed: 0.0490s/iter; left time: 1181.9482s
	iters: 200, epoch: 10 | loss: 0.3390933
	speed: 0.0109s/iter; left time: 260.5844s
Epoch: 10 cost time: 3.298489570617676
Epoch: 10, Steps: 266 | Train Loss: 0.3414035 Vali Loss: 0.7024623 Test Loss: 0.4367939
Validation loss decreased (0.703367 --> 0.702462).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3773158
	speed: 0.0488s/iter; left time: 1163.3306s
	iters: 200, epoch: 11 | loss: 0.3689424
	speed: 0.0117s/iter; left time: 276.5999s
Epoch: 11 cost time: 3.369304656982422
Epoch: 11, Steps: 266 | Train Loss: 0.3413641 Vali Loss: 0.7023205 Test Loss: 0.4364332
Validation loss decreased (0.702462 --> 0.702321).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3530607
	speed: 0.0508s/iter; left time: 1197.8710s
	iters: 200, epoch: 12 | loss: 0.3360553
	speed: 0.0101s/iter; left time: 236.5955s
Epoch: 12 cost time: 3.2621984481811523
Epoch: 12, Steps: 266 | Train Loss: 0.3413674 Vali Loss: 0.7018063 Test Loss: 0.4362774
Validation loss decreased (0.702321 --> 0.701806).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3535300
	speed: 0.0506s/iter; left time: 1180.5471s
	iters: 200, epoch: 13 | loss: 0.3848750
	speed: 0.0095s/iter; left time: 221.1116s
Epoch: 13 cost time: 3.2996842861175537
Epoch: 13, Steps: 266 | Train Loss: 0.3412489 Vali Loss: 0.7012659 Test Loss: 0.4360755
Validation loss decreased (0.701806 --> 0.701266).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3500332
	speed: 0.0488s/iter; left time: 1124.9175s
	iters: 200, epoch: 14 | loss: 0.3781675
	speed: 0.0113s/iter; left time: 260.1385s
Epoch: 14 cost time: 3.3698508739471436
Epoch: 14, Steps: 266 | Train Loss: 0.3412612 Vali Loss: 0.7019030 Test Loss: 0.4361786
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3305202
	speed: 0.0501s/iter; left time: 1141.5402s
	iters: 200, epoch: 15 | loss: 0.2976072
	speed: 0.0096s/iter; left time: 217.5507s
Epoch: 15 cost time: 3.218982458114624
Epoch: 15, Steps: 266 | Train Loss: 0.3412840 Vali Loss: 0.7013665 Test Loss: 0.4359095
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3493295
	speed: 0.0480s/iter; left time: 1079.7155s
	iters: 200, epoch: 16 | loss: 0.3266653
	speed: 0.0109s/iter; left time: 244.9069s
Epoch: 16 cost time: 3.306966781616211
Epoch: 16, Steps: 266 | Train Loss: 0.3413046 Vali Loss: 0.7020739 Test Loss: 0.4360702
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3088519
	speed: 0.0490s/iter; left time: 1090.2688s
	iters: 200, epoch: 17 | loss: 0.3275598
	speed: 0.0111s/iter; left time: 245.3312s
Epoch: 17 cost time: 3.228057622909546
Epoch: 17, Steps: 266 | Train Loss: 0.3412966 Vali Loss: 0.7017144 Test Loss: 0.4360269
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3550171
	speed: 0.0486s/iter; left time: 1067.4844s
	iters: 200, epoch: 18 | loss: 0.3215609
	speed: 0.0108s/iter; left time: 235.7001s
Epoch: 18 cost time: 3.2211804389953613
Epoch: 18, Steps: 266 | Train Loss: 0.3413278 Vali Loss: 0.7006184 Test Loss: 0.4359576
Validation loss decreased (0.701266 --> 0.700618).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3722091
	speed: 0.0504s/iter; left time: 1093.6103s
	iters: 200, epoch: 19 | loss: 0.3374230
	speed: 0.0109s/iter; left time: 234.8405s
Epoch: 19 cost time: 3.389317274093628
Epoch: 19, Steps: 266 | Train Loss: 0.3412291 Vali Loss: 0.7019470 Test Loss: 0.4363395
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3526584
	speed: 0.0482s/iter; left time: 1033.9895s
	iters: 200, epoch: 20 | loss: 0.3318916
	speed: 0.0098s/iter; left time: 209.6050s
Epoch: 20 cost time: 3.1746726036071777
Epoch: 20, Steps: 266 | Train Loss: 0.3411825 Vali Loss: 0.7015994 Test Loss: 0.4360652
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3882051
	speed: 0.0492s/iter; left time: 1042.9210s
	iters: 200, epoch: 21 | loss: 0.3317105
	speed: 0.0108s/iter; left time: 228.6973s
Epoch: 21 cost time: 3.348145008087158
Epoch: 21, Steps: 266 | Train Loss: 0.3412978 Vali Loss: 0.7017439 Test Loss: 0.4362399
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3246219
	speed: 0.0500s/iter; left time: 1045.4058s
	iters: 200, epoch: 22 | loss: 0.3106817
	speed: 0.0104s/iter; left time: 216.8628s
Epoch: 22 cost time: 3.337373971939087
Epoch: 22, Steps: 266 | Train Loss: 0.3412427 Vali Loss: 0.7016801 Test Loss: 0.4361372
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3425713
	speed: 0.0489s/iter; left time: 1009.5372s
	iters: 200, epoch: 23 | loss: 0.3632007
	speed: 0.0109s/iter; left time: 223.5097s
Epoch: 23 cost time: 3.286193370819092
Epoch: 23, Steps: 266 | Train Loss: 0.3412753 Vali Loss: 0.7020786 Test Loss: 0.4363718
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3558992
	speed: 0.0523s/iter; left time: 1065.0976s
	iters: 200, epoch: 24 | loss: 0.3213108
	speed: 0.0114s/iter; left time: 230.9190s
Epoch: 24 cost time: 3.592061996459961
Epoch: 24, Steps: 266 | Train Loss: 0.3412056 Vali Loss: 0.7013666 Test Loss: 0.4360407
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3641877
	speed: 0.0508s/iter; left time: 1022.9480s
	iters: 200, epoch: 25 | loss: 0.3972180
	speed: 0.0111s/iter; left time: 222.9823s
Epoch: 25 cost time: 3.4520585536956787
Epoch: 25, Steps: 266 | Train Loss: 0.3411409 Vali Loss: 0.7015631 Test Loss: 0.4362016
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3452786
	speed: 0.0512s/iter; left time: 1016.8988s
	iters: 200, epoch: 26 | loss: 0.3317863
	speed: 0.0111s/iter; left time: 218.7240s
Epoch: 26 cost time: 3.451138496398926
Epoch: 26, Steps: 266 | Train Loss: 0.3412610 Vali Loss: 0.7010985 Test Loss: 0.4361088
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3708450
	speed: 0.0511s/iter; left time: 1000.1204s
	iters: 200, epoch: 27 | loss: 0.3315198
	speed: 0.0107s/iter; left time: 208.5906s
Epoch: 27 cost time: 3.397303581237793
Epoch: 27, Steps: 266 | Train Loss: 0.3412121 Vali Loss: 0.7008582 Test Loss: 0.4362468
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3526589
	speed: 0.0504s/iter; left time: 974.0366s
	iters: 200, epoch: 28 | loss: 0.3622929
	speed: 0.0112s/iter; left time: 216.0149s
Epoch: 28 cost time: 3.403921365737915
Epoch: 28, Steps: 266 | Train Loss: 0.3412655 Vali Loss: 0.7019814 Test Loss: 0.4361731
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3466041
	speed: 0.0509s/iter; left time: 970.0239s
	iters: 200, epoch: 29 | loss: 0.3553192
	speed: 0.0109s/iter; left time: 206.0431s
Epoch: 29 cost time: 3.32474684715271
Epoch: 29, Steps: 266 | Train Loss: 0.3412876 Vali Loss: 0.7012207 Test Loss: 0.4361501
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3327412
	speed: 0.0491s/iter; left time: 922.5184s
	iters: 200, epoch: 30 | loss: 0.3369652
	speed: 0.0116s/iter; left time: 216.5439s
Epoch: 30 cost time: 3.412511110305786
Epoch: 30, Steps: 266 | Train Loss: 0.3412942 Vali Loss: 0.7014110 Test Loss: 0.4362203
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3066384
	speed: 0.0507s/iter; left time: 938.7977s
	iters: 200, epoch: 31 | loss: 0.3675508
	speed: 0.0118s/iter; left time: 217.6701s
Epoch: 31 cost time: 3.453043222427368
Epoch: 31, Steps: 266 | Train Loss: 0.3412467 Vali Loss: 0.7021594 Test Loss: 0.4362598
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3276294
	speed: 0.0503s/iter; left time: 918.6166s
	iters: 200, epoch: 32 | loss: 0.3785867
	speed: 0.0109s/iter; left time: 197.0927s
Epoch: 32 cost time: 3.3378148078918457
Epoch: 32, Steps: 266 | Train Loss: 0.3412612 Vali Loss: 0.7019076 Test Loss: 0.4362870
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3724841
	speed: 0.0509s/iter; left time: 915.9276s
	iters: 200, epoch: 33 | loss: 0.3545567
	speed: 0.0115s/iter; left time: 204.9689s
Epoch: 33 cost time: 3.428654432296753
Epoch: 33, Steps: 266 | Train Loss: 0.3411683 Vali Loss: 0.7020078 Test Loss: 0.4362921
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3638092
	speed: 0.0502s/iter; left time: 889.4450s
	iters: 200, epoch: 34 | loss: 0.3678204
	speed: 0.0119s/iter; left time: 210.4712s
Epoch: 34 cost time: 3.4646081924438477
Epoch: 34, Steps: 266 | Train Loss: 0.3412505 Vali Loss: 0.7020096 Test Loss: 0.4363169
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3744818
	speed: 0.0513s/iter; left time: 895.7600s
	iters: 200, epoch: 35 | loss: 0.3452093
	speed: 0.0116s/iter; left time: 201.0027s
Epoch: 35 cost time: 3.4304451942443848
Epoch: 35, Steps: 266 | Train Loss: 0.3411545 Vali Loss: 0.7017220 Test Loss: 0.4362338
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3394733
	speed: 0.0490s/iter; left time: 842.3673s
	iters: 200, epoch: 36 | loss: 0.3464288
	speed: 0.0108s/iter; left time: 184.1681s
Epoch: 36 cost time: 3.3087196350097656
Epoch: 36, Steps: 266 | Train Loss: 0.3411544 Vali Loss: 0.7012641 Test Loss: 0.4363284
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3558769
	speed: 0.0512s/iter; left time: 866.0321s
	iters: 200, epoch: 37 | loss: 0.3572149
	speed: 0.0108s/iter; left time: 182.3921s
Epoch: 37 cost time: 3.3736484050750732
Epoch: 37, Steps: 266 | Train Loss: 0.3412205 Vali Loss: 0.7019030 Test Loss: 0.4363192
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3500054
	speed: 0.0502s/iter; left time: 835.6869s
	iters: 200, epoch: 38 | loss: 0.3369638
	speed: 0.0106s/iter; left time: 175.2624s
Epoch: 38 cost time: 3.347627639770508
Epoch: 38, Steps: 266 | Train Loss: 0.3412811 Vali Loss: 0.7018524 Test Loss: 0.4363790
EarlyStopping counter: 20 out of 20
Early stopping
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=14, out_features=66, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  827904.0
params:  990.0
Trainable parameters:  990
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4341263
	speed: 0.0152s/iter; left time: 403.4771s
	iters: 200, epoch: 1 | loss: 0.4302754
	speed: 0.0107s/iter; left time: 283.7932s
Epoch: 1 cost time: 3.360288619995117
Epoch: 1, Steps: 266 | Train Loss: 0.4253049 Vali Loss: 0.6973863 Test Loss: 0.4328201
Validation loss decreased (inf --> 0.697386).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4232572
	speed: 0.0509s/iter; left time: 1335.5095s
	iters: 200, epoch: 2 | loss: 0.4342025
	speed: 0.0109s/iter; left time: 285.9853s
Epoch: 2 cost time: 3.332261800765991
Epoch: 2, Steps: 266 | Train Loss: 0.4247736 Vali Loss: 0.6971778 Test Loss: 0.4324970
Validation loss decreased (0.697386 --> 0.697178).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3865485
	speed: 0.0526s/iter; left time: 1365.8202s
	iters: 200, epoch: 3 | loss: 0.4218502
	speed: 0.0107s/iter; left time: 276.3085s
Epoch: 3 cost time: 3.471860885620117
Epoch: 3, Steps: 266 | Train Loss: 0.4244817 Vali Loss: 0.6974027 Test Loss: 0.4324650
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4113946
	speed: 0.0522s/iter; left time: 1342.4028s
	iters: 200, epoch: 4 | loss: 0.4992435
	speed: 0.0108s/iter; left time: 276.4822s
Epoch: 4 cost time: 3.393230438232422
Epoch: 4, Steps: 266 | Train Loss: 0.4246314 Vali Loss: 0.6969099 Test Loss: 0.4322785
Validation loss decreased (0.697178 --> 0.696910).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4437310
	speed: 0.0519s/iter; left time: 1320.6881s
	iters: 200, epoch: 5 | loss: 0.4585673
	speed: 0.0107s/iter; left time: 271.0377s
Epoch: 5 cost time: 3.502323627471924
Epoch: 5, Steps: 266 | Train Loss: 0.4245750 Vali Loss: 0.6961121 Test Loss: 0.4326754
Validation loss decreased (0.696910 --> 0.696112).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3843143
	speed: 0.0507s/iter; left time: 1275.5973s
	iters: 200, epoch: 6 | loss: 0.4606659
	speed: 0.0116s/iter; left time: 291.1924s
Epoch: 6 cost time: 3.3814499378204346
Epoch: 6, Steps: 266 | Train Loss: 0.4244877 Vali Loss: 0.6966566 Test Loss: 0.4324698
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4262222
	speed: 0.0501s/iter; left time: 1247.4422s
	iters: 200, epoch: 7 | loss: 0.4952812
	speed: 0.0114s/iter; left time: 282.3338s
Epoch: 7 cost time: 3.3514463901519775
Epoch: 7, Steps: 266 | Train Loss: 0.4244873 Vali Loss: 0.6961145 Test Loss: 0.4322165
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4546783
	speed: 0.0506s/iter; left time: 1247.4573s
	iters: 200, epoch: 8 | loss: 0.4074495
	speed: 0.0113s/iter; left time: 277.3894s
Epoch: 8 cost time: 3.4800124168395996
Epoch: 8, Steps: 266 | Train Loss: 0.4245137 Vali Loss: 0.6974197 Test Loss: 0.4333674
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4294719
	speed: 0.0516s/iter; left time: 1257.5437s
	iters: 200, epoch: 9 | loss: 0.4696314
	speed: 0.0106s/iter; left time: 257.3026s
Epoch: 9 cost time: 3.3171236515045166
Epoch: 9, Steps: 266 | Train Loss: 0.4243554 Vali Loss: 0.6955755 Test Loss: 0.4318337
Validation loss decreased (0.696112 --> 0.695576).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4456989
	speed: 0.0521s/iter; left time: 1255.9225s
	iters: 200, epoch: 10 | loss: 0.4255719
	speed: 0.0115s/iter; left time: 274.9261s
Epoch: 10 cost time: 3.4776062965393066
Epoch: 10, Steps: 266 | Train Loss: 0.4245619 Vali Loss: 0.6968347 Test Loss: 0.4324319
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3798872
	speed: 0.0502s/iter; left time: 1197.1748s
	iters: 200, epoch: 11 | loss: 0.4185696
	speed: 0.0114s/iter; left time: 270.4756s
Epoch: 11 cost time: 3.4589176177978516
Epoch: 11, Steps: 266 | Train Loss: 0.4245467 Vali Loss: 0.6972333 Test Loss: 0.4325917
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4571386
	speed: 0.0506s/iter; left time: 1193.3686s
	iters: 200, epoch: 12 | loss: 0.3884765
	speed: 0.0114s/iter; left time: 267.4580s
Epoch: 12 cost time: 3.3778622150421143
Epoch: 12, Steps: 266 | Train Loss: 0.4244217 Vali Loss: 0.6957523 Test Loss: 0.4323907
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4709639
	speed: 0.0496s/iter; left time: 1156.9943s
	iters: 200, epoch: 13 | loss: 0.4106831
	speed: 0.0104s/iter; left time: 242.0918s
Epoch: 13 cost time: 3.2975778579711914
Epoch: 13, Steps: 266 | Train Loss: 0.4244287 Vali Loss: 0.6965074 Test Loss: 0.4323253
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4643791
	speed: 0.0515s/iter; left time: 1186.5605s
	iters: 200, epoch: 14 | loss: 0.4409615
	speed: 0.0114s/iter; left time: 261.2616s
Epoch: 14 cost time: 3.389305830001831
Epoch: 14, Steps: 266 | Train Loss: 0.4243145 Vali Loss: 0.6962978 Test Loss: 0.4323334
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3797658
	speed: 0.0512s/iter; left time: 1166.1027s
	iters: 200, epoch: 15 | loss: 0.3801807
	speed: 0.0104s/iter; left time: 235.8583s
Epoch: 15 cost time: 3.374164342880249
Epoch: 15, Steps: 266 | Train Loss: 0.4243931 Vali Loss: 0.6966850 Test Loss: 0.4326812
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4050015
	speed: 0.0508s/iter; left time: 1143.1177s
	iters: 200, epoch: 16 | loss: 0.3908416
	speed: 0.0097s/iter; left time: 218.3608s
Epoch: 16 cost time: 3.2664382457733154
Epoch: 16, Steps: 266 | Train Loss: 0.4244442 Vali Loss: 0.6961064 Test Loss: 0.4325034
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4101087
	speed: 0.0506s/iter; left time: 1125.9664s
	iters: 200, epoch: 17 | loss: 0.4226227
	speed: 0.0114s/iter; left time: 252.9892s
Epoch: 17 cost time: 3.472996234893799
Epoch: 17, Steps: 266 | Train Loss: 0.4244544 Vali Loss: 0.6956891 Test Loss: 0.4325396
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4631572
	speed: 0.0503s/iter; left time: 1105.4749s
	iters: 200, epoch: 18 | loss: 0.4649420
	speed: 0.0113s/iter; left time: 248.2243s
Epoch: 18 cost time: 3.444215774536133
Epoch: 18, Steps: 266 | Train Loss: 0.4243665 Vali Loss: 0.6957886 Test Loss: 0.4325181
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4478597
	speed: 0.0504s/iter; left time: 1095.1653s
	iters: 200, epoch: 19 | loss: 0.4447845
	speed: 0.0111s/iter; left time: 239.8343s
Epoch: 19 cost time: 3.3385682106018066
Epoch: 19, Steps: 266 | Train Loss: 0.4242805 Vali Loss: 0.6966127 Test Loss: 0.4327230
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4101782
	speed: 0.0500s/iter; left time: 1072.8442s
	iters: 200, epoch: 20 | loss: 0.4207804
	speed: 0.0111s/iter; left time: 235.9440s
Epoch: 20 cost time: 3.3111352920532227
Epoch: 20, Steps: 266 | Train Loss: 0.4243828 Vali Loss: 0.6962658 Test Loss: 0.4325721
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3936595
	speed: 0.0514s/iter; left time: 1088.3748s
	iters: 200, epoch: 21 | loss: 0.4753894
	speed: 0.0104s/iter; left time: 219.9302s
Epoch: 21 cost time: 3.4853923320770264
Epoch: 21, Steps: 266 | Train Loss: 0.4241904 Vali Loss: 0.6959518 Test Loss: 0.4328269
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4036862
	speed: 0.0490s/iter; left time: 1024.8507s
	iters: 200, epoch: 22 | loss: 0.4218592
	speed: 0.0109s/iter; left time: 227.8920s
Epoch: 22 cost time: 3.3591949939727783
Epoch: 22, Steps: 266 | Train Loss: 0.4243596 Vali Loss: 0.6960402 Test Loss: 0.4329512
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4014831
	speed: 0.0487s/iter; left time: 1005.2671s
	iters: 200, epoch: 23 | loss: 0.4262618
	speed: 0.0109s/iter; left time: 222.9608s
Epoch: 23 cost time: 3.3743457794189453
Epoch: 23, Steps: 266 | Train Loss: 0.4243029 Vali Loss: 0.6964521 Test Loss: 0.4327461
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4409955
	speed: 0.0508s/iter; left time: 1034.4836s
	iters: 200, epoch: 24 | loss: 0.4322243
	speed: 0.0111s/iter; left time: 224.8844s
Epoch: 24 cost time: 3.4464797973632812
Epoch: 24, Steps: 266 | Train Loss: 0.4243201 Vali Loss: 0.6966875 Test Loss: 0.4328201
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4547708
	speed: 0.0514s/iter; left time: 1034.8375s
	iters: 200, epoch: 25 | loss: 0.4176871
	speed: 0.0107s/iter; left time: 214.0716s
Epoch: 25 cost time: 3.408193588256836
Epoch: 25, Steps: 266 | Train Loss: 0.4242470 Vali Loss: 0.6962630 Test Loss: 0.4325015
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4740573
	speed: 0.0490s/iter; left time: 971.7557s
	iters: 200, epoch: 26 | loss: 0.4085531
	speed: 0.0111s/iter; left time: 219.7847s
Epoch: 26 cost time: 3.3503127098083496
Epoch: 26, Steps: 266 | Train Loss: 0.4243270 Vali Loss: 0.6961248 Test Loss: 0.4324984
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4252856
	speed: 0.0509s/iter; left time: 996.4016s
	iters: 200, epoch: 27 | loss: 0.4220962
	speed: 0.0108s/iter; left time: 211.0159s
Epoch: 27 cost time: 3.527466058731079
Epoch: 27, Steps: 266 | Train Loss: 0.4243949 Vali Loss: 0.6954401 Test Loss: 0.4324039
Validation loss decreased (0.695576 --> 0.695440).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4727418
	speed: 0.0521s/iter; left time: 1006.2381s
	iters: 200, epoch: 28 | loss: 0.4139513
	speed: 0.0105s/iter; left time: 202.5327s
Epoch: 28 cost time: 3.351611375808716
Epoch: 28, Steps: 266 | Train Loss: 0.4242264 Vali Loss: 0.6963345 Test Loss: 0.4325617
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4187239
	speed: 0.0517s/iter; left time: 984.8926s
	iters: 200, epoch: 29 | loss: 0.4570869
	speed: 0.0120s/iter; left time: 227.1531s
Epoch: 29 cost time: 3.5220983028411865
Epoch: 29, Steps: 266 | Train Loss: 0.4243351 Vali Loss: 0.6968756 Test Loss: 0.4324706
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4819685
	speed: 0.0496s/iter; left time: 931.0815s
	iters: 200, epoch: 30 | loss: 0.4496205
	speed: 0.0099s/iter; left time: 185.8903s
Epoch: 30 cost time: 3.2327475547790527
Epoch: 30, Steps: 266 | Train Loss: 0.4242841 Vali Loss: 0.6964033 Test Loss: 0.4325337
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4504314
	speed: 0.0488s/iter; left time: 904.0559s
	iters: 200, epoch: 31 | loss: 0.3984684
	speed: 0.0119s/iter; left time: 219.8226s
Epoch: 31 cost time: 3.437901020050049
Epoch: 31, Steps: 266 | Train Loss: 0.4243393 Vali Loss: 0.6968132 Test Loss: 0.4324896
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4260831
	speed: 0.0504s/iter; left time: 920.1774s
	iters: 200, epoch: 32 | loss: 0.3749507
	speed: 0.0111s/iter; left time: 202.1083s
Epoch: 32 cost time: 3.46258282661438
Epoch: 32, Steps: 266 | Train Loss: 0.4242414 Vali Loss: 0.6966685 Test Loss: 0.4326013
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3992743
	speed: 0.0495s/iter; left time: 890.9730s
	iters: 200, epoch: 33 | loss: 0.3969869
	speed: 0.0111s/iter; left time: 197.7094s
Epoch: 33 cost time: 3.3637893199920654
Epoch: 33, Steps: 266 | Train Loss: 0.4242358 Vali Loss: 0.6961419 Test Loss: 0.4326500
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4006089
	speed: 0.0500s/iter; left time: 886.3136s
	iters: 200, epoch: 34 | loss: 0.3992219
	speed: 0.0109s/iter; left time: 191.6799s
Epoch: 34 cost time: 3.404751777648926
Epoch: 34, Steps: 266 | Train Loss: 0.4241480 Vali Loss: 0.6962830 Test Loss: 0.4325793
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4384613
	speed: 0.0514s/iter; left time: 897.3531s
	iters: 200, epoch: 35 | loss: 0.4265713
	speed: 0.0112s/iter; left time: 194.6770s
Epoch: 35 cost time: 3.4222357273101807
Epoch: 35, Steps: 266 | Train Loss: 0.4242670 Vali Loss: 0.6964979 Test Loss: 0.4325221
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4100157
	speed: 0.0502s/iter; left time: 863.4206s
	iters: 200, epoch: 36 | loss: 0.4420146
	speed: 0.0099s/iter; left time: 169.7436s
Epoch: 36 cost time: 3.3116891384124756
Epoch: 36, Steps: 266 | Train Loss: 0.4242607 Vali Loss: 0.6963403 Test Loss: 0.4326523
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4219618
	speed: 0.0501s/iter; left time: 848.5375s
	iters: 200, epoch: 37 | loss: 0.4430255
	speed: 0.0110s/iter; left time: 185.1340s
Epoch: 37 cost time: 3.421769857406616
Epoch: 37, Steps: 266 | Train Loss: 0.4242927 Vali Loss: 0.6969088 Test Loss: 0.4326438
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4963292
	speed: 0.0497s/iter; left time: 827.5415s
	iters: 200, epoch: 38 | loss: 0.4640468
	speed: 0.0112s/iter; left time: 186.0658s
Epoch: 38 cost time: 3.4079041481018066
Epoch: 38, Steps: 266 | Train Loss: 0.4242600 Vali Loss: 0.6964994 Test Loss: 0.4326692
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4368618
	speed: 0.0512s/iter; left time: 839.6405s
	iters: 200, epoch: 39 | loss: 0.3817618
	speed: 0.0112s/iter; left time: 183.0610s
Epoch: 39 cost time: 3.4427170753479004
Epoch: 39, Steps: 266 | Train Loss: 0.4242873 Vali Loss: 0.6968771 Test Loss: 0.4326663
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.4038839
	speed: 0.0497s/iter; left time: 801.3916s
	iters: 200, epoch: 40 | loss: 0.3879569
	speed: 0.0116s/iter; left time: 185.2137s
Epoch: 40 cost time: 3.4496562480926514
Epoch: 40, Steps: 266 | Train Loss: 0.4243247 Vali Loss: 0.6965553 Test Loss: 0.4326076
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.4634547
	speed: 0.0493s/iter; left time: 782.1596s
	iters: 200, epoch: 41 | loss: 0.4271704
	speed: 0.0113s/iter; left time: 177.7029s
Epoch: 41 cost time: 3.406237840652466
Epoch: 41, Steps: 266 | Train Loss: 0.4243014 Vali Loss: 0.6960278 Test Loss: 0.4325757
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3770354
	speed: 0.0497s/iter; left time: 775.2840s
	iters: 200, epoch: 42 | loss: 0.3831454
	speed: 0.0108s/iter; left time: 167.1425s
Epoch: 42 cost time: 3.286062002182007
Epoch: 42, Steps: 266 | Train Loss: 0.4243393 Vali Loss: 0.6970932 Test Loss: 0.4326396
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.4482038
	speed: 0.0490s/iter; left time: 750.9894s
	iters: 200, epoch: 43 | loss: 0.4751616
	speed: 0.0106s/iter; left time: 161.9754s
Epoch: 43 cost time: 3.2916762828826904
Epoch: 43, Steps: 266 | Train Loss: 0.4243591 Vali Loss: 0.6974341 Test Loss: 0.4326427
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.4604682
	speed: 0.0494s/iter; left time: 743.8402s
	iters: 200, epoch: 44 | loss: 0.4271647
	speed: 0.0116s/iter; left time: 173.5316s
Epoch: 44 cost time: 3.438913345336914
Epoch: 44, Steps: 266 | Train Loss: 0.4242583 Vali Loss: 0.6970597 Test Loss: 0.4326883
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.4332804
	speed: 0.0491s/iter; left time: 726.3912s
	iters: 200, epoch: 45 | loss: 0.4364539
	speed: 0.0107s/iter; left time: 157.3790s
Epoch: 45 cost time: 3.3177566528320312
Epoch: 45, Steps: 266 | Train Loss: 0.4242239 Vali Loss: 0.6959235 Test Loss: 0.4326080
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.4352273
	speed: 0.0492s/iter; left time: 714.3099s
	iters: 200, epoch: 46 | loss: 0.4286029
	speed: 0.0117s/iter; left time: 168.5609s
Epoch: 46 cost time: 3.3815839290618896
Epoch: 46, Steps: 266 | Train Loss: 0.4243160 Vali Loss: 0.6962366 Test Loss: 0.4326279
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.4802862
	speed: 0.0501s/iter; left time: 714.0447s
	iters: 200, epoch: 47 | loss: 0.4378534
	speed: 0.0111s/iter; left time: 157.6291s
Epoch: 47 cost time: 3.4272878170013428
Epoch: 47, Steps: 266 | Train Loss: 0.4241182 Vali Loss: 0.6971222 Test Loss: 0.4325843
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_90_336_FITS_ETTm1_ftM_sl90_ll48_pl336_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.43250563740730286, mae:0.4197567403316498, rse:0.6258124709129333, corr:[0.54404384 0.5457742  0.54256576 0.53842264 0.5359318  0.53502417
 0.53388304 0.5317749  0.52928734 0.52738684 0.5262323  0.525273
 0.52402437 0.52227557 0.5198861  0.5168728  0.51362646 0.51053035
 0.5076589  0.50485927 0.50201905 0.49898288 0.49568662 0.49212828
 0.48846656 0.4847816  0.48139957 0.47862217 0.47662252 0.47508526
 0.4740414  0.47394553 0.47433096 0.4747933  0.47518274 0.47555357
 0.4756164  0.47555476 0.47549266 0.47546118 0.4755902  0.47562656
 0.47555122 0.47535318 0.4749001  0.47438842 0.47412944 0.47421455
 0.47455332 0.47500068 0.47543272 0.47568423 0.47593647 0.4762512
 0.47679624 0.4774127  0.47800073 0.47838894 0.47836244 0.47816795
 0.47801262 0.4777655  0.4775646  0.47727817 0.47711268 0.47697574
 0.476692   0.47641185 0.4764872  0.4769985  0.4776074  0.47819343
 0.47876194 0.479224   0.47976494 0.48034266 0.48116523 0.48217863
 0.48311827 0.48386997 0.48443198 0.48473784 0.4849891  0.48513025
 0.48529628 0.4855851  0.48608065 0.4867459  0.48753306 0.48839006
 0.48920867 0.4899085  0.49049613 0.49095508 0.49116728 0.49091265
 0.49014273 0.48917764 0.48820978 0.48734346 0.4868346  0.48658147
 0.48635733 0.48581332 0.4851437  0.4844922  0.48380697 0.48308095
 0.48232904 0.48157054 0.48079973 0.4800034  0.47915915 0.47827968
 0.477307   0.47634223 0.47534686 0.47431478 0.47324312 0.47213355
 0.4710386  0.46984753 0.46859935 0.46757352 0.46677825 0.46609858
 0.46553808 0.46514064 0.46495718 0.4649702  0.46509948 0.46524996
 0.46523902 0.46513233 0.46489647 0.46459934 0.4643558  0.46424338
 0.46421054 0.4641758  0.46407202 0.46396658 0.46390322 0.46396354
 0.4641025  0.46431404 0.4645492  0.46468312 0.4648904  0.4651011
 0.4653014  0.46565458 0.46602893 0.46627074 0.46623626 0.46608692
 0.46592474 0.46585327 0.46584463 0.4658578  0.46593755 0.4660015
 0.4660633  0.4661902  0.46648782 0.46696165 0.46759632 0.46831614
 0.4690114  0.4696036  0.47012347 0.47075927 0.4714404  0.4721113
 0.4726594  0.4731266  0.47357166 0.47398546 0.47424212 0.47441077
 0.47454166 0.4747778  0.47518635 0.47585878 0.47674486 0.4775891
 0.4781668  0.47842804 0.47854784 0.47879636 0.4793218  0.4800763
 0.48087016 0.48182583 0.48292536 0.4841532  0.4854244  0.48661476
 0.4873531  0.48729855 0.48671713 0.48608005 0.48543036 0.48467067
 0.48371193 0.48254615 0.48120642 0.4798651  0.47852632 0.47727928
 0.47605905 0.4747991  0.4734751  0.4720026  0.4703349  0.46871316
 0.46707925 0.46551567 0.46407568 0.46291602 0.46197444 0.46126276
 0.4608151  0.46073171 0.46068797 0.46049872 0.46036506 0.4601742
 0.4599645  0.45990643 0.4599277  0.4598261  0.45962077 0.45931154
 0.4590181  0.4587992  0.45855293 0.4584212  0.4584934  0.45852163
 0.4586347  0.45875484 0.45892265 0.45920023 0.45938915 0.45957544
 0.45979625 0.4601302  0.46053112 0.46102607 0.46132076 0.46142232
 0.46123967 0.46103495 0.46083286 0.4609163  0.46106434 0.4611276
 0.46121603 0.46142703 0.46162593 0.46194518 0.46246263 0.46313223
 0.4639902  0.46472195 0.46529365 0.46588162 0.46661505 0.467343
 0.4680878  0.46876416 0.46943453 0.4700454  0.47060108 0.4711109
 0.47162622 0.472179   0.47269234 0.47325304 0.47388172 0.47456244
 0.47523546 0.47579262 0.47612545 0.47610283 0.475572   0.4743643
 0.47244963 0.47027743 0.46841773 0.46705645 0.46611813 0.46549648
 0.4650834  0.4646303  0.4643404  0.4641904  0.46392503 0.46335375
 0.46243724 0.46129125 0.46015543 0.45916057 0.4583569  0.45757928
 0.45682016 0.4559256  0.45496807 0.45408234 0.45332772 0.45258725
 0.4516617  0.45050925 0.44933522 0.4484507  0.44782633 0.44750404
 0.44727263 0.446883   0.44627982 0.445642   0.44520164 0.44512945
 0.44514224 0.44496527 0.44435322 0.44354793 0.44307688 0.44329962
 0.4441649  0.44483858 0.44479883 0.44454902 0.44579685 0.44934902]
