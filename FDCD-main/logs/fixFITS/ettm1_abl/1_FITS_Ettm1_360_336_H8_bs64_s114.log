Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=42, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_360_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_360_336_FITS_ETTm1_ftM_sl360_ll48_pl336_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33865
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=42, out_features=81, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3048192.0
params:  3483.0
Trainable parameters:  3483
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4359851
	speed: 0.0208s/iter; left time: 546.0547s
	iters: 200, epoch: 1 | loss: 0.4304469
	speed: 0.0146s/iter; left time: 381.2816s
Epoch: 1 cost time: 4.41999363899231
Epoch: 1, Steps: 264 | Train Loss: 0.4845294 Vali Loss: 0.7473897 Test Loss: 0.4191114
Validation loss decreased (inf --> 0.747390).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3595046
	speed: 0.0694s/iter; left time: 1807.4708s
	iters: 200, epoch: 2 | loss: 0.3441548
	speed: 0.0135s/iter; left time: 350.9456s
Epoch: 2 cost time: 4.084593772888184
Epoch: 2, Steps: 264 | Train Loss: 0.3723649 Vali Loss: 0.6870249 Test Loss: 0.3811407
Validation loss decreased (0.747390 --> 0.687025).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3739150
	speed: 0.0682s/iter; left time: 1758.8006s
	iters: 200, epoch: 3 | loss: 0.3956476
	speed: 0.0131s/iter; left time: 336.1927s
Epoch: 3 cost time: 4.015582323074341
Epoch: 3, Steps: 264 | Train Loss: 0.3577312 Vali Loss: 0.6713566 Test Loss: 0.3743372
Validation loss decreased (0.687025 --> 0.671357).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3725711
	speed: 0.0694s/iter; left time: 1770.8199s
	iters: 200, epoch: 4 | loss: 0.3550921
	speed: 0.0134s/iter; left time: 340.7164s
Epoch: 4 cost time: 4.091113567352295
Epoch: 4, Steps: 264 | Train Loss: 0.3526590 Vali Loss: 0.6643181 Test Loss: 0.3724160
Validation loss decreased (0.671357 --> 0.664318).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3776757
	speed: 0.0691s/iter; left time: 1743.6917s
	iters: 200, epoch: 5 | loss: 0.3363509
	speed: 0.0158s/iter; left time: 397.1699s
Epoch: 5 cost time: 4.519335031509399
Epoch: 5, Steps: 264 | Train Loss: 0.3504120 Vali Loss: 0.6607784 Test Loss: 0.3715834
Validation loss decreased (0.664318 --> 0.660778).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3388258
	speed: 0.0718s/iter; left time: 1794.8489s
	iters: 200, epoch: 6 | loss: 0.3470837
	speed: 0.0132s/iter; left time: 328.4215s
Epoch: 6 cost time: 4.118003845214844
Epoch: 6, Steps: 264 | Train Loss: 0.3494811 Vali Loss: 0.6604051 Test Loss: 0.3716927
Validation loss decreased (0.660778 --> 0.660405).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3593361
	speed: 0.0692s/iter; left time: 1710.8145s
	iters: 200, epoch: 7 | loss: 0.3209565
	speed: 0.0138s/iter; left time: 338.6329s
Epoch: 7 cost time: 4.211028814315796
Epoch: 7, Steps: 264 | Train Loss: 0.3488361 Vali Loss: 0.6586467 Test Loss: 0.3716430
Validation loss decreased (0.660405 --> 0.658647).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3363869
	speed: 0.0704s/iter; left time: 1722.4133s
	iters: 200, epoch: 8 | loss: 0.3642238
	speed: 0.0127s/iter; left time: 310.0597s
Epoch: 8 cost time: 4.094940423965454
Epoch: 8, Steps: 264 | Train Loss: 0.3486374 Vali Loss: 0.6584958 Test Loss: 0.3718382
Validation loss decreased (0.658647 --> 0.658496).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3629771
	speed: 0.0695s/iter; left time: 1682.0853s
	iters: 200, epoch: 9 | loss: 0.3431879
	speed: 0.0145s/iter; left time: 348.5599s
Epoch: 9 cost time: 4.333089351654053
Epoch: 9, Steps: 264 | Train Loss: 0.3483345 Vali Loss: 0.6566974 Test Loss: 0.3720818
Validation loss decreased (0.658496 --> 0.656697).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3547054
	speed: 0.0706s/iter; left time: 1690.0412s
	iters: 200, epoch: 10 | loss: 0.3475519
	speed: 0.0134s/iter; left time: 319.7510s
Epoch: 10 cost time: 4.143354654312134
Epoch: 10, Steps: 264 | Train Loss: 0.3482243 Vali Loss: 0.6565655 Test Loss: 0.3719631
Validation loss decreased (0.656697 --> 0.656565).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3236143
	speed: 0.0673s/iter; left time: 1593.3278s
	iters: 200, epoch: 11 | loss: 0.3659217
	speed: 0.0136s/iter; left time: 319.4457s
Epoch: 11 cost time: 4.063637018203735
Epoch: 11, Steps: 264 | Train Loss: 0.3480659 Vali Loss: 0.6558778 Test Loss: 0.3717912
Validation loss decreased (0.656565 --> 0.655878).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3471661
	speed: 0.0759s/iter; left time: 1776.7467s
	iters: 200, epoch: 12 | loss: 0.3488864
	speed: 0.0134s/iter; left time: 312.2157s
Epoch: 12 cost time: 4.08962869644165
Epoch: 12, Steps: 264 | Train Loss: 0.3479693 Vali Loss: 0.6550873 Test Loss: 0.3722490
Validation loss decreased (0.655878 --> 0.655087).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3512409
	speed: 0.0670s/iter; left time: 1551.0312s
	iters: 200, epoch: 13 | loss: 0.3516442
	speed: 0.0142s/iter; left time: 326.9795s
Epoch: 13 cost time: 4.158252716064453
Epoch: 13, Steps: 264 | Train Loss: 0.3479773 Vali Loss: 0.6554120 Test Loss: 0.3721075
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3485607
	speed: 0.0701s/iter; left time: 1604.2497s
	iters: 200, epoch: 14 | loss: 0.3387609
	speed: 0.0130s/iter; left time: 295.2407s
Epoch: 14 cost time: 4.113465070724487
Epoch: 14, Steps: 264 | Train Loss: 0.3479128 Vali Loss: 0.6552783 Test Loss: 0.3720725
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3513019
	speed: 0.0686s/iter; left time: 1550.0434s
	iters: 200, epoch: 15 | loss: 0.3939846
	speed: 0.0135s/iter; left time: 304.2564s
Epoch: 15 cost time: 4.088844537734985
Epoch: 15, Steps: 264 | Train Loss: 0.3479142 Vali Loss: 0.6550125 Test Loss: 0.3721638
Validation loss decreased (0.655087 --> 0.655012).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3485451
	speed: 0.0688s/iter; left time: 1536.6222s
	iters: 200, epoch: 16 | loss: 0.3369152
	speed: 0.0133s/iter; left time: 295.4058s
Epoch: 16 cost time: 4.144989252090454
Epoch: 16, Steps: 264 | Train Loss: 0.3479351 Vali Loss: 0.6546940 Test Loss: 0.3721312
Validation loss decreased (0.655012 --> 0.654694).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3445896
	speed: 0.0678s/iter; left time: 1497.8919s
	iters: 200, epoch: 17 | loss: 0.3469745
	speed: 0.0133s/iter; left time: 292.8791s
Epoch: 17 cost time: 3.9908642768859863
Epoch: 17, Steps: 264 | Train Loss: 0.3478766 Vali Loss: 0.6540495 Test Loss: 0.3721004
Validation loss decreased (0.654694 --> 0.654049).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3522952
	speed: 0.0671s/iter; left time: 1462.9547s
	iters: 200, epoch: 18 | loss: 0.3551674
	speed: 0.0132s/iter; left time: 287.6637s
Epoch: 18 cost time: 4.0198752880096436
Epoch: 18, Steps: 264 | Train Loss: 0.3478680 Vali Loss: 0.6546451 Test Loss: 0.3723410
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3751663
	speed: 0.0672s/iter; left time: 1448.6818s
	iters: 200, epoch: 19 | loss: 0.3356774
	speed: 0.0128s/iter; left time: 274.6264s
Epoch: 19 cost time: 3.989093542098999
Epoch: 19, Steps: 264 | Train Loss: 0.3478453 Vali Loss: 0.6540130 Test Loss: 0.3721771
Validation loss decreased (0.654049 --> 0.654013).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3131572
	speed: 0.0694s/iter; left time: 1476.7081s
	iters: 200, epoch: 20 | loss: 0.3608102
	speed: 0.0143s/iter; left time: 302.7132s
Epoch: 20 cost time: 4.334298849105835
Epoch: 20, Steps: 264 | Train Loss: 0.3476959 Vali Loss: 0.6539143 Test Loss: 0.3721074
Validation loss decreased (0.654013 --> 0.653914).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3442094
	speed: 0.0731s/iter; left time: 1537.5212s
	iters: 200, epoch: 21 | loss: 0.3308634
	speed: 0.0158s/iter; left time: 331.5238s
Epoch: 21 cost time: 4.785789489746094
Epoch: 21, Steps: 264 | Train Loss: 0.3478088 Vali Loss: 0.6537808 Test Loss: 0.3721234
Validation loss decreased (0.653914 --> 0.653781).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2988371
	speed: 0.0720s/iter; left time: 1495.0031s
	iters: 200, epoch: 22 | loss: 0.3269240
	speed: 0.0133s/iter; left time: 273.9214s
Epoch: 22 cost time: 4.037374973297119
Epoch: 22, Steps: 264 | Train Loss: 0.3477464 Vali Loss: 0.6545869 Test Loss: 0.3721832
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3444429
	speed: 0.0680s/iter; left time: 1392.6615s
	iters: 200, epoch: 23 | loss: 0.3290852
	speed: 0.0131s/iter; left time: 266.1605s
Epoch: 23 cost time: 4.0443115234375
Epoch: 23, Steps: 264 | Train Loss: 0.3477277 Vali Loss: 0.6547558 Test Loss: 0.3722103
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3379757
	speed: 0.0677s/iter; left time: 1370.4016s
	iters: 200, epoch: 24 | loss: 0.3484096
	speed: 0.0132s/iter; left time: 266.0540s
Epoch: 24 cost time: 4.0135133266448975
Epoch: 24, Steps: 264 | Train Loss: 0.3477060 Vali Loss: 0.6528665 Test Loss: 0.3722193
Validation loss decreased (0.653781 --> 0.652866).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3561389
	speed: 0.0676s/iter; left time: 1350.4285s
	iters: 200, epoch: 25 | loss: 0.2969481
	speed: 0.0129s/iter; left time: 255.8581s
Epoch: 25 cost time: 3.9807465076446533
Epoch: 25, Steps: 264 | Train Loss: 0.3476635 Vali Loss: 0.6541724 Test Loss: 0.3723640
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3198619
	speed: 0.0684s/iter; left time: 1347.4846s
	iters: 200, epoch: 26 | loss: 0.3465655
	speed: 0.0132s/iter; left time: 258.8808s
Epoch: 26 cost time: 4.027437686920166
Epoch: 26, Steps: 264 | Train Loss: 0.3478116 Vali Loss: 0.6542085 Test Loss: 0.3722076
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3279334
	speed: 0.0697s/iter; left time: 1354.3472s
	iters: 200, epoch: 27 | loss: 0.3636002
	speed: 0.0139s/iter; left time: 269.2430s
Epoch: 27 cost time: 4.404856204986572
Epoch: 27, Steps: 264 | Train Loss: 0.3476422 Vali Loss: 0.6546884 Test Loss: 0.3722624
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3745513
	speed: 0.0700s/iter; left time: 1342.4433s
	iters: 200, epoch: 28 | loss: 0.3112288
	speed: 0.0130s/iter; left time: 247.8621s
Epoch: 28 cost time: 3.9840786457061768
Epoch: 28, Steps: 264 | Train Loss: 0.3476567 Vali Loss: 0.6543919 Test Loss: 0.3722165
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3862235
	speed: 0.0688s/iter; left time: 1301.1436s
	iters: 200, epoch: 29 | loss: 0.3607123
	speed: 0.0135s/iter; left time: 253.5555s
Epoch: 29 cost time: 4.123131275177002
Epoch: 29, Steps: 264 | Train Loss: 0.3477052 Vali Loss: 0.6541695 Test Loss: 0.3723723
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3371976
	speed: 0.0693s/iter; left time: 1292.5792s
	iters: 200, epoch: 30 | loss: 0.3180280
	speed: 0.0140s/iter; left time: 259.1292s
Epoch: 30 cost time: 4.188772678375244
Epoch: 30, Steps: 264 | Train Loss: 0.3476785 Vali Loss: 0.6540020 Test Loss: 0.3723189
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4269001
	speed: 0.0686s/iter; left time: 1261.5337s
	iters: 200, epoch: 31 | loss: 0.3329208
	speed: 0.0131s/iter; left time: 239.5748s
Epoch: 31 cost time: 4.047287464141846
Epoch: 31, Steps: 264 | Train Loss: 0.3476723 Vali Loss: 0.6541104 Test Loss: 0.3721924
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3869610
	speed: 0.0678s/iter; left time: 1227.8122s
	iters: 200, epoch: 32 | loss: 0.4182763
	speed: 0.0129s/iter; left time: 231.9663s
Epoch: 32 cost time: 3.910600423812866
Epoch: 32, Steps: 264 | Train Loss: 0.3477712 Vali Loss: 0.6543078 Test Loss: 0.3723259
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3204221
	speed: 0.0662s/iter; left time: 1182.0069s
	iters: 200, epoch: 33 | loss: 0.3282088
	speed: 0.0132s/iter; left time: 233.8170s
Epoch: 33 cost time: 3.9818084239959717
Epoch: 33, Steps: 264 | Train Loss: 0.3476310 Vali Loss: 0.6537834 Test Loss: 0.3721666
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3137160
	speed: 0.0730s/iter; left time: 1283.9190s
	iters: 200, epoch: 34 | loss: 0.3778223
	speed: 0.0160s/iter; left time: 279.6644s
Epoch: 34 cost time: 4.795263290405273
Epoch: 34, Steps: 264 | Train Loss: 0.3476739 Vali Loss: 0.6539366 Test Loss: 0.3723095
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3457162
	speed: 0.0728s/iter; left time: 1261.1702s
	iters: 200, epoch: 35 | loss: 0.3635705
	speed: 0.0131s/iter; left time: 226.3064s
Epoch: 35 cost time: 4.033297300338745
Epoch: 35, Steps: 264 | Train Loss: 0.3476958 Vali Loss: 0.6536117 Test Loss: 0.3722547
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3295694
	speed: 0.0733s/iter; left time: 1250.0950s
	iters: 200, epoch: 36 | loss: 0.3541692
	speed: 0.0136s/iter; left time: 230.4179s
Epoch: 36 cost time: 4.064357042312622
Epoch: 36, Steps: 264 | Train Loss: 0.3475618 Vali Loss: 0.6539112 Test Loss: 0.3723208
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3362136
	speed: 0.0665s/iter; left time: 1117.3574s
	iters: 200, epoch: 37 | loss: 0.3188730
	speed: 0.0130s/iter; left time: 216.5538s
Epoch: 37 cost time: 4.028519868850708
Epoch: 37, Steps: 264 | Train Loss: 0.3476285 Vali Loss: 0.6543127 Test Loss: 0.3721947
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3647692
	speed: 0.0826s/iter; left time: 1365.6507s
	iters: 200, epoch: 38 | loss: 0.3266601
	speed: 0.0135s/iter; left time: 222.5169s
Epoch: 38 cost time: 4.1759984493255615
Epoch: 38, Steps: 264 | Train Loss: 0.3475987 Vali Loss: 0.6536831 Test Loss: 0.3724014
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3874811
	speed: 0.0676s/iter; left time: 1099.4327s
	iters: 200, epoch: 39 | loss: 0.3043780
	speed: 0.0131s/iter; left time: 211.1527s
Epoch: 39 cost time: 4.065126657485962
Epoch: 39, Steps: 264 | Train Loss: 0.3475547 Vali Loss: 0.6541134 Test Loss: 0.3723442
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.3462614
	speed: 0.0664s/iter; left time: 1062.1233s
	iters: 200, epoch: 40 | loss: 0.2783184
	speed: 0.0133s/iter; left time: 211.5641s
Epoch: 40 cost time: 4.050693988800049
Epoch: 40, Steps: 264 | Train Loss: 0.3475391 Vali Loss: 0.6545284 Test Loss: 0.3722363
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3197672
	speed: 0.0687s/iter; left time: 1081.9501s
	iters: 200, epoch: 41 | loss: 0.3740913
	speed: 0.0132s/iter; left time: 206.3162s
Epoch: 41 cost time: 4.093129873275757
Epoch: 41, Steps: 264 | Train Loss: 0.3475422 Vali Loss: 0.6542388 Test Loss: 0.3722728
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3434993
	speed: 0.0698s/iter; left time: 1080.5197s
	iters: 200, epoch: 42 | loss: 0.3364346
	speed: 0.0131s/iter; left time: 201.2941s
Epoch: 42 cost time: 4.210395336151123
Epoch: 42, Steps: 264 | Train Loss: 0.3475952 Vali Loss: 0.6543339 Test Loss: 0.3722247
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3684353
	speed: 0.0678s/iter; left time: 1031.8079s
	iters: 200, epoch: 43 | loss: 0.3464308
	speed: 0.0128s/iter; left time: 193.5355s
Epoch: 43 cost time: 3.9246573448181152
Epoch: 43, Steps: 264 | Train Loss: 0.3475732 Vali Loss: 0.6547525 Test Loss: 0.3722729
EarlyStopping counter: 19 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.3246634
	speed: 0.0670s/iter; left time: 1001.8826s
	iters: 200, epoch: 44 | loss: 0.3082331
	speed: 0.0142s/iter; left time: 210.2755s
Epoch: 44 cost time: 4.065071105957031
Epoch: 44, Steps: 264 | Train Loss: 0.3475572 Vali Loss: 0.6543797 Test Loss: 0.3723166
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_360_336_FITS_ETTm1_ftM_sl360_ll48_pl336_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.371957391500473, mae:0.38498586416244507, rse:0.5803565979003906, corr:[0.5412796  0.54667044 0.5491456  0.5491235  0.5483496  0.54794157
 0.5481239  0.54864347 0.5491092  0.5494491  0.54993004 0.55044854
 0.5510019  0.5513717  0.5511642  0.5501258  0.548551   0.54693216
 0.5454743  0.5443404  0.54343754 0.5427435  0.5419443  0.5409941
 0.53984696 0.53850406 0.5372559  0.53640836 0.53603506 0.5359617
 0.53621644 0.5367189  0.5371877  0.5374298  0.5373554  0.53719485
 0.5370529  0.53692025 0.5367678  0.5365091  0.53614724 0.53567487
 0.5351435  0.5347197  0.5344614  0.53438973 0.5344868  0.5345317
 0.5343706  0.534058   0.5336291  0.533204   0.53297555 0.53296876
 0.53314275 0.53339887 0.5335437  0.5335098  0.5333298  0.5329751
 0.532642   0.532388   0.5322877  0.53227395 0.53239447 0.53261757
 0.5328129  0.53288794 0.5329839  0.5330943  0.53324467 0.5334271
 0.5336772  0.5339698  0.534187   0.53424263 0.5341306  0.53391427
 0.53365433 0.53341573 0.53324306 0.5331114  0.5329177  0.5325805
 0.53217584 0.531719   0.5313508  0.53107446 0.5309038  0.5309032
 0.53102535 0.53111476 0.53104615 0.5308069  0.5303712  0.52977014
 0.5291195  0.5285308  0.52800816 0.5275     0.5271145  0.52691644
 0.5269128  0.52700245 0.52726364 0.5276529  0.52797157 0.5282628
 0.5283865  0.52846307 0.52847385 0.52847326 0.5284435  0.52851063
 0.5286484  0.52884877 0.52901393 0.52910656 0.52909636 0.5291507
 0.5292509  0.5292725  0.52921575 0.5291993  0.5291744  0.529065
 0.52889675 0.5287374  0.5286181  0.5285695  0.5285561  0.5284889
 0.52834386 0.5280356  0.5276375  0.52720326 0.526849   0.5266049
 0.5265451  0.5266008  0.5266409  0.5266275  0.52649575 0.5262821
 0.5260346  0.5258439  0.5257349  0.52573824 0.52586484 0.5259484
 0.52595514 0.52594715 0.52586246 0.5257199  0.52557534 0.5255349
 0.52559507 0.5257282  0.5258624  0.5259793  0.5260921  0.5261649
 0.52623445 0.5263145  0.52651024 0.52683735 0.5272402  0.52773356
 0.5281968  0.5285403  0.52873135 0.5287849  0.5286875  0.5285355
 0.5284126  0.5283992  0.52845174 0.5284895  0.5283783  0.52812773
 0.5277565  0.52743    0.52715963 0.5270458  0.5270724  0.52717096
 0.5272567  0.5272846  0.5272445  0.52715474 0.5269682  0.5266906
 0.52630585 0.5259268  0.52551997 0.5250043  0.5244596  0.5240765
 0.5238263  0.5236221  0.5234722  0.52332187 0.52308816 0.5227929
 0.5224924  0.5221248  0.5217946  0.52145046 0.5211184  0.5208112
 0.5204434  0.52007145 0.5196503  0.5192428  0.51882374 0.5185028
 0.51826954 0.5180645  0.5178183  0.5176644  0.51755303 0.5174605
 0.51743674 0.5174208  0.5173822  0.51732165 0.51728845 0.5172289
 0.51716363 0.5171033  0.5169826  0.51677173 0.51652354 0.5162387
 0.5160298  0.5159109  0.5157793  0.5157349  0.51572883 0.5157255
 0.51570505 0.51564425 0.51558644 0.51551515 0.51540554 0.5153053
 0.5151996  0.5150842  0.51498413 0.51494586 0.5149048  0.51490426
 0.51487386 0.51490813 0.51496136 0.51501536 0.5150039  0.5150236
 0.5150229  0.5150507  0.5151494  0.51532495 0.51549417 0.5157644
 0.51608086 0.5163817  0.5165954  0.51678693 0.5169224  0.5169446
 0.5169777  0.517042   0.51710606 0.5171581  0.51710445 0.5170064
 0.516824   0.51665807 0.51643556 0.51627195 0.5161185  0.5160046
 0.5159609  0.5159004  0.51578087 0.515519   0.5150898  0.5144833
 0.5136968  0.5129495  0.5123742  0.51179487 0.5112983  0.5108902
 0.5105554  0.5101522  0.50978017 0.50939626 0.50906163 0.5087252
 0.5084101  0.50813174 0.5079111  0.50776416 0.5076261  0.50747186
 0.50735444 0.5072247  0.50713074 0.5071193  0.50718373 0.50724065
 0.5072683  0.5071384  0.5067304  0.5063252  0.5059678  0.5057592
 0.5057005  0.5056955  0.50559014 0.5052895  0.5047764  0.5041641
 0.5036385  0.5033329  0.5032316  0.50330484 0.5033155  0.5031776
 0.5029043  0.50273037 0.50285107 0.5033217  0.50387937 0.5037743 ]
