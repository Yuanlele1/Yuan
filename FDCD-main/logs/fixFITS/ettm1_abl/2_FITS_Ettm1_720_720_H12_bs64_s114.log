Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_720_720_FITS_ETTm1_ftM_sl720_ll48_pl720_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=106, out_features=212, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  20134912.0
params:  22684.0
Trainable parameters:  22684
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4775875
	speed: 0.0491s/iter; left time: 1262.6899s
	iters: 200, epoch: 1 | loss: 0.3946110
	speed: 0.0439s/iter; left time: 1124.7152s
Epoch: 1 cost time: 11.577484846115112
Epoch: 1, Steps: 258 | Train Loss: 0.4944156 Vali Loss: 1.1861022 Test Loss: 0.5847777
Validation loss decreased (inf --> 1.186102).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3151536
	speed: 0.1727s/iter; left time: 4393.0506s
	iters: 200, epoch: 2 | loss: 0.3074704
	speed: 0.0428s/iter; left time: 1084.8160s
Epoch: 2 cost time: 11.685292720794678
Epoch: 2, Steps: 258 | Train Loss: 0.3199942 Vali Loss: 1.0645040 Test Loss: 0.5029512
Validation loss decreased (1.186102 --> 1.064504).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2632964
	speed: 0.1773s/iter; left time: 4465.9103s
	iters: 200, epoch: 3 | loss: 0.2762060
	speed: 0.0458s/iter; left time: 1147.9224s
Epoch: 3 cost time: 11.539909839630127
Epoch: 3, Steps: 258 | Train Loss: 0.2696378 Vali Loss: 1.0140002 Test Loss: 0.4687172
Validation loss decreased (1.064504 --> 1.014000).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2420076
	speed: 0.1812s/iter; left time: 4515.6008s
	iters: 200, epoch: 4 | loss: 0.2318859
	speed: 0.0397s/iter; left time: 984.5872s
Epoch: 4 cost time: 11.912112951278687
Epoch: 4, Steps: 258 | Train Loss: 0.2459524 Vali Loss: 0.9869373 Test Loss: 0.4508940
Validation loss decreased (1.014000 --> 0.986937).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2143624
	speed: 0.1643s/iter; left time: 4053.2485s
	iters: 200, epoch: 5 | loss: 0.2164769
	speed: 0.0400s/iter; left time: 983.6333s
Epoch: 5 cost time: 11.797991037368774
Epoch: 5, Steps: 258 | Train Loss: 0.2328594 Vali Loss: 0.9713478 Test Loss: 0.4386677
Validation loss decreased (0.986937 --> 0.971348).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2396297
	speed: 0.2188s/iter; left time: 5340.5531s
	iters: 200, epoch: 6 | loss: 0.2075291
	speed: 0.0451s/iter; left time: 1095.4656s
Epoch: 6 cost time: 13.735821723937988
Epoch: 6, Steps: 258 | Train Loss: 0.2248978 Vali Loss: 0.9588810 Test Loss: 0.4306060
Validation loss decreased (0.971348 --> 0.958881).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2031832
	speed: 0.1922s/iter; left time: 4643.0535s
	iters: 200, epoch: 7 | loss: 0.2275121
	speed: 0.0412s/iter; left time: 991.1380s
Epoch: 7 cost time: 11.803203821182251
Epoch: 7, Steps: 258 | Train Loss: 0.2197396 Vali Loss: 0.9519437 Test Loss: 0.4252274
Validation loss decreased (0.958881 --> 0.951944).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2313638
	speed: 0.1644s/iter; left time: 3927.9994s
	iters: 200, epoch: 8 | loss: 0.2239211
	speed: 0.0406s/iter; left time: 965.8426s
Epoch: 8 cost time: 11.320704936981201
Epoch: 8, Steps: 258 | Train Loss: 0.2162959 Vali Loss: 0.9471353 Test Loss: 0.4212267
Validation loss decreased (0.951944 --> 0.947135).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2191861
	speed: 0.1765s/iter; left time: 4172.0559s
	iters: 200, epoch: 9 | loss: 0.1995327
	speed: 0.0494s/iter; left time: 1162.2061s
Epoch: 9 cost time: 12.209713220596313
Epoch: 9, Steps: 258 | Train Loss: 0.2139348 Vali Loss: 0.9430757 Test Loss: 0.4189470
Validation loss decreased (0.947135 --> 0.943076).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2061763
	speed: 0.1687s/iter; left time: 3944.9920s
	iters: 200, epoch: 10 | loss: 0.2049591
	speed: 0.0404s/iter; left time: 940.3672s
Epoch: 10 cost time: 11.075617551803589
Epoch: 10, Steps: 258 | Train Loss: 0.2123628 Vali Loss: 0.9425358 Test Loss: 0.4173717
Validation loss decreased (0.943076 --> 0.942536).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2070379
	speed: 0.2062s/iter; left time: 4766.7273s
	iters: 200, epoch: 11 | loss: 0.2059679
	speed: 0.0357s/iter; left time: 821.4163s
Epoch: 11 cost time: 11.76657509803772
Epoch: 11, Steps: 258 | Train Loss: 0.2112703 Vali Loss: 0.9407607 Test Loss: 0.4164060
Validation loss decreased (0.942536 --> 0.940761).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1973599
	speed: 0.1867s/iter; left time: 4267.7331s
	iters: 200, epoch: 12 | loss: 0.2106906
	speed: 0.0349s/iter; left time: 795.0611s
Epoch: 12 cost time: 11.202961921691895
Epoch: 12, Steps: 258 | Train Loss: 0.2104412 Vali Loss: 0.9400087 Test Loss: 0.4162779
Validation loss decreased (0.940761 --> 0.940009).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2025477
	speed: 0.1700s/iter; left time: 3842.5003s
	iters: 200, epoch: 13 | loss: 0.1965127
	speed: 0.0475s/iter; left time: 1068.8981s
Epoch: 13 cost time: 11.75001859664917
Epoch: 13, Steps: 258 | Train Loss: 0.2098400 Vali Loss: 0.9394040 Test Loss: 0.4159896
Validation loss decreased (0.940009 --> 0.939404).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2219154
	speed: 0.1787s/iter; left time: 3992.4319s
	iters: 200, epoch: 14 | loss: 0.2030340
	speed: 0.0423s/iter; left time: 940.7724s
Epoch: 14 cost time: 11.44827914237976
Epoch: 14, Steps: 258 | Train Loss: 0.2094781 Vali Loss: 0.9389804 Test Loss: 0.4160752
Validation loss decreased (0.939404 --> 0.938980).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1999514
	speed: 0.1754s/iter; left time: 3874.6627s
	iters: 200, epoch: 15 | loss: 0.2136512
	speed: 0.0457s/iter; left time: 1005.9111s
Epoch: 15 cost time: 11.06463623046875
Epoch: 15, Steps: 258 | Train Loss: 0.2091917 Vali Loss: 0.9390821 Test Loss: 0.4162151
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2050111
	speed: 0.1716s/iter; left time: 3746.4816s
	iters: 200, epoch: 16 | loss: 0.2149524
	speed: 0.0392s/iter; left time: 850.8417s
Epoch: 16 cost time: 11.061912059783936
Epoch: 16, Steps: 258 | Train Loss: 0.2090480 Vali Loss: 0.9389106 Test Loss: 0.4164636
Validation loss decreased (0.938980 --> 0.938911).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2200879
	speed: 0.1608s/iter; left time: 3469.8865s
	iters: 200, epoch: 17 | loss: 0.2124819
	speed: 0.0393s/iter; left time: 843.5047s
Epoch: 17 cost time: 11.040525674819946
Epoch: 17, Steps: 258 | Train Loss: 0.2089255 Vali Loss: 0.9380663 Test Loss: 0.4166559
Validation loss decreased (0.938911 --> 0.938066).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2066381
	speed: 0.1723s/iter; left time: 3673.0290s
	iters: 200, epoch: 18 | loss: 0.2015360
	speed: 0.0403s/iter; left time: 854.5401s
Epoch: 18 cost time: 10.5293550491333
Epoch: 18, Steps: 258 | Train Loss: 0.2087719 Vali Loss: 0.9389331 Test Loss: 0.4169708
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1998508
	speed: 0.1844s/iter; left time: 3883.6282s
	iters: 200, epoch: 19 | loss: 0.2142940
	speed: 0.0393s/iter; left time: 824.0247s
Epoch: 19 cost time: 11.307858228683472
Epoch: 19, Steps: 258 | Train Loss: 0.2087500 Vali Loss: 0.9380443 Test Loss: 0.4169431
Validation loss decreased (0.938066 --> 0.938044).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2080835
	speed: 0.1600s/iter; left time: 3328.1364s
	iters: 200, epoch: 20 | loss: 0.2133667
	speed: 0.0325s/iter; left time: 671.7916s
Epoch: 20 cost time: 10.442228555679321
Epoch: 20, Steps: 258 | Train Loss: 0.2087171 Vali Loss: 0.9386560 Test Loss: 0.4171991
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2290298
	speed: 0.1690s/iter; left time: 3471.7311s
	iters: 200, epoch: 21 | loss: 0.2241163
	speed: 0.0389s/iter; left time: 794.8741s
Epoch: 21 cost time: 12.14250898361206
Epoch: 21, Steps: 258 | Train Loss: 0.2086295 Vali Loss: 0.9386398 Test Loss: 0.4175586
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2052090
	speed: 0.1802s/iter; left time: 3655.2810s
	iters: 200, epoch: 22 | loss: 0.1910381
	speed: 0.0445s/iter; left time: 897.4767s
Epoch: 22 cost time: 13.801641941070557
Epoch: 22, Steps: 258 | Train Loss: 0.2086167 Vali Loss: 0.9384946 Test Loss: 0.4176585
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2025583
	speed: 0.2558s/iter; left time: 5121.4436s
	iters: 200, epoch: 23 | loss: 0.2277076
	speed: 0.0504s/iter; left time: 1003.9802s
Epoch: 23 cost time: 14.507702112197876
Epoch: 23, Steps: 258 | Train Loss: 0.2086194 Vali Loss: 0.9383642 Test Loss: 0.4177003
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2119246
	speed: 0.2455s/iter; left time: 4853.2220s
	iters: 200, epoch: 24 | loss: 0.1903277
	speed: 0.0604s/iter; left time: 1188.5421s
Epoch: 24 cost time: 15.528111934661865
Epoch: 24, Steps: 258 | Train Loss: 0.2086751 Vali Loss: 0.9390419 Test Loss: 0.4175953
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1916373
	speed: 0.1642s/iter; left time: 3202.5841s
	iters: 200, epoch: 25 | loss: 0.2221149
	speed: 0.0352s/iter; left time: 682.9607s
Epoch: 25 cost time: 10.381009340286255
Epoch: 25, Steps: 258 | Train Loss: 0.2086211 Vali Loss: 0.9392606 Test Loss: 0.4179057
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2214310
	speed: 0.1648s/iter; left time: 3173.0237s
	iters: 200, epoch: 26 | loss: 0.2119820
	speed: 0.0391s/iter; left time: 749.6756s
Epoch: 26 cost time: 11.132675409317017
Epoch: 26, Steps: 258 | Train Loss: 0.2086387 Vali Loss: 0.9391932 Test Loss: 0.4178335
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1966517
	speed: 0.1757s/iter; left time: 3337.3709s
	iters: 200, epoch: 27 | loss: 0.2226806
	speed: 0.0446s/iter; left time: 841.9522s
Epoch: 27 cost time: 13.557110786437988
Epoch: 27, Steps: 258 | Train Loss: 0.2086276 Vali Loss: 0.9390374 Test Loss: 0.4180249
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2251202
	speed: 0.2143s/iter; left time: 4014.5773s
	iters: 200, epoch: 28 | loss: 0.2074355
	speed: 0.0529s/iter; left time: 986.0754s
Epoch: 28 cost time: 14.001873254776001
Epoch: 28, Steps: 258 | Train Loss: 0.2086014 Vali Loss: 0.9383590 Test Loss: 0.4179817
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2110917
	speed: 0.2119s/iter; left time: 3915.6879s
	iters: 200, epoch: 29 | loss: 0.2148248
	speed: 0.0368s/iter; left time: 677.0738s
Epoch: 29 cost time: 10.226384162902832
Epoch: 29, Steps: 258 | Train Loss: 0.2086036 Vali Loss: 0.9382293 Test Loss: 0.4177959
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2077884
	speed: 0.1769s/iter; left time: 3222.3585s
	iters: 200, epoch: 30 | loss: 0.1993871
	speed: 0.0346s/iter; left time: 627.3858s
Epoch: 30 cost time: 10.565241813659668
Epoch: 30, Steps: 258 | Train Loss: 0.2085820 Vali Loss: 0.9385487 Test Loss: 0.4179986
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2114742
	speed: 0.1669s/iter; left time: 2998.5479s
	iters: 200, epoch: 31 | loss: 0.2171268
	speed: 0.0365s/iter; left time: 652.2281s
Epoch: 31 cost time: 9.964746236801147
Epoch: 31, Steps: 258 | Train Loss: 0.2085852 Vali Loss: 0.9387141 Test Loss: 0.4179668
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2094060
	speed: 0.1747s/iter; left time: 3092.7835s
	iters: 200, epoch: 32 | loss: 0.1925744
	speed: 0.0407s/iter; left time: 716.3629s
Epoch: 32 cost time: 10.908071279525757
Epoch: 32, Steps: 258 | Train Loss: 0.2085308 Vali Loss: 0.9392663 Test Loss: 0.4181890
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2062332
	speed: 0.1649s/iter; left time: 2876.1517s
	iters: 200, epoch: 33 | loss: 0.2040392
	speed: 0.0463s/iter; left time: 803.8936s
Epoch: 33 cost time: 11.39522647857666
Epoch: 33, Steps: 258 | Train Loss: 0.2085534 Vali Loss: 0.9385915 Test Loss: 0.4178402
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2159354
	speed: 0.1720s/iter; left time: 2956.0161s
	iters: 200, epoch: 34 | loss: 0.1936349
	speed: 0.0439s/iter; left time: 749.9707s
Epoch: 34 cost time: 11.717162609100342
Epoch: 34, Steps: 258 | Train Loss: 0.2085496 Vali Loss: 0.9383632 Test Loss: 0.4180374
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2142375
	speed: 0.1709s/iter; left time: 2893.7594s
	iters: 200, epoch: 35 | loss: 0.2100536
	speed: 0.0421s/iter; left time: 709.1627s
Epoch: 35 cost time: 11.607923030853271
Epoch: 35, Steps: 258 | Train Loss: 0.2085439 Vali Loss: 0.9387200 Test Loss: 0.4179314
EarlyStopping counter: 16 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1967605
	speed: 0.1758s/iter; left time: 2930.0624s
	iters: 200, epoch: 36 | loss: 0.2133786
	speed: 0.0422s/iter; left time: 698.6593s
Epoch: 36 cost time: 13.550617218017578
Epoch: 36, Steps: 258 | Train Loss: 0.2086005 Vali Loss: 0.9390790 Test Loss: 0.4180852
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2114887
	speed: 0.2133s/iter; left time: 3500.5782s
	iters: 200, epoch: 37 | loss: 0.2047383
	speed: 0.0444s/iter; left time: 724.3179s
Epoch: 37 cost time: 11.925862312316895
Epoch: 37, Steps: 258 | Train Loss: 0.2086308 Vali Loss: 0.9393174 Test Loss: 0.4180970
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2209761
	speed: 0.1689s/iter; left time: 2729.1222s
	iters: 200, epoch: 38 | loss: 0.2166913
	speed: 0.0348s/iter; left time: 558.0130s
Epoch: 38 cost time: 10.082220077514648
Epoch: 38, Steps: 258 | Train Loss: 0.2085789 Vali Loss: 0.9385648 Test Loss: 0.4181002
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2094221
	speed: 0.1660s/iter; left time: 2639.5224s
	iters: 200, epoch: 39 | loss: 0.2046184
	speed: 0.0452s/iter; left time: 714.2510s
Epoch: 39 cost time: 12.611918687820435
Epoch: 39, Steps: 258 | Train Loss: 0.2085780 Vali Loss: 0.9378388 Test Loss: 0.4180598
Validation loss decreased (0.938044 --> 0.937839).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1963767
	speed: 0.2127s/iter; left time: 3326.3296s
	iters: 200, epoch: 40 | loss: 0.2182669
	speed: 0.0400s/iter; left time: 621.8870s
Epoch: 40 cost time: 11.291171789169312
Epoch: 40, Steps: 258 | Train Loss: 0.2085655 Vali Loss: 0.9390126 Test Loss: 0.4180484
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1923880
	speed: 0.1787s/iter; left time: 2749.1650s
	iters: 200, epoch: 41 | loss: 0.1848899
	speed: 0.0425s/iter; left time: 649.5922s
Epoch: 41 cost time: 11.891806840896606
Epoch: 41, Steps: 258 | Train Loss: 0.2085180 Vali Loss: 0.9379631 Test Loss: 0.4181899
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2279032
	speed: 0.1660s/iter; left time: 2510.9683s
	iters: 200, epoch: 42 | loss: 0.2120789
	speed: 0.0486s/iter; left time: 729.4774s
Epoch: 42 cost time: 12.46216106414795
Epoch: 42, Steps: 258 | Train Loss: 0.2085682 Vali Loss: 0.9388090 Test Loss: 0.4180616
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1916112
	speed: 0.1682s/iter; left time: 2500.6188s
	iters: 200, epoch: 43 | loss: 0.2205022
	speed: 0.0429s/iter; left time: 632.9478s
Epoch: 43 cost time: 10.781255722045898
Epoch: 43, Steps: 258 | Train Loss: 0.2085099 Vali Loss: 0.9390321 Test Loss: 0.4180537
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2087760
	speed: 0.1638s/iter; left time: 2393.0877s
	iters: 200, epoch: 44 | loss: 0.2166969
	speed: 0.0476s/iter; left time: 690.9009s
Epoch: 44 cost time: 11.521888732910156
Epoch: 44, Steps: 258 | Train Loss: 0.2085413 Vali Loss: 0.9387304 Test Loss: 0.4179758
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2101595
	speed: 0.1731s/iter; left time: 2483.4369s
	iters: 200, epoch: 45 | loss: 0.2088033
	speed: 0.0424s/iter; left time: 604.7049s
Epoch: 45 cost time: 11.604495763778687
Epoch: 45, Steps: 258 | Train Loss: 0.2084965 Vali Loss: 0.9380344 Test Loss: 0.4180967
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2105937
	speed: 0.1671s/iter; left time: 2354.6126s
	iters: 200, epoch: 46 | loss: 0.2235347
	speed: 0.0442s/iter; left time: 618.5519s
Epoch: 46 cost time: 11.049278497695923
Epoch: 46, Steps: 258 | Train Loss: 0.2085071 Vali Loss: 0.9387916 Test Loss: 0.4180020
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2074920
	speed: 0.2006s/iter; left time: 2775.4760s
	iters: 200, epoch: 47 | loss: 0.2171470
	speed: 0.0497s/iter; left time: 682.7121s
Epoch: 47 cost time: 13.18696928024292
Epoch: 47, Steps: 258 | Train Loss: 0.2084846 Vali Loss: 0.9385213 Test Loss: 0.4179733
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2108804
	speed: 0.1992s/iter; left time: 2704.2733s
	iters: 200, epoch: 48 | loss: 0.2142908
	speed: 0.0511s/iter; left time: 689.2235s
Epoch: 48 cost time: 13.191526412963867
Epoch: 48, Steps: 258 | Train Loss: 0.2084583 Vali Loss: 0.9391845 Test Loss: 0.4181020
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2115052
	speed: 0.1587s/iter; left time: 2113.7602s
	iters: 200, epoch: 49 | loss: 0.2068801
	speed: 0.0392s/iter; left time: 518.6795s
Epoch: 49 cost time: 10.32401418685913
Epoch: 49, Steps: 258 | Train Loss: 0.2085448 Vali Loss: 0.9392440 Test Loss: 0.4180065
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1941114
	speed: 0.1657s/iter; left time: 2163.9109s
	iters: 200, epoch: 50 | loss: 0.2302298
	speed: 0.0387s/iter; left time: 501.0628s
Epoch: 50 cost time: 10.191290140151978
Epoch: 50, Steps: 258 | Train Loss: 0.2084957 Vali Loss: 0.9382192 Test Loss: 0.4180059
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2252628
	speed: 0.2059s/iter; left time: 2636.2668s
	iters: 200, epoch: 51 | loss: 0.2033997
	speed: 0.0416s/iter; left time: 528.7021s
Epoch: 51 cost time: 12.953144073486328
Epoch: 51, Steps: 258 | Train Loss: 0.2085393 Vali Loss: 0.9393896 Test Loss: 0.4181471
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2126094
	speed: 0.1802s/iter; left time: 2260.6361s
	iters: 200, epoch: 52 | loss: 0.1976575
	speed: 0.0405s/iter; left time: 503.3942s
Epoch: 52 cost time: 11.225442171096802
Epoch: 52, Steps: 258 | Train Loss: 0.2085468 Vali Loss: 0.9387830 Test Loss: 0.4180089
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2189072
	speed: 0.1715s/iter; left time: 2106.4265s
	iters: 200, epoch: 53 | loss: 0.2181653
	speed: 0.0418s/iter; left time: 509.9114s
Epoch: 53 cost time: 13.091323614120483
Epoch: 53, Steps: 258 | Train Loss: 0.2084359 Vali Loss: 0.9388574 Test Loss: 0.4180882
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2138049
	speed: 0.1894s/iter; left time: 2277.6842s
	iters: 200, epoch: 54 | loss: 0.1883951
	speed: 0.0487s/iter; left time: 580.4205s
Epoch: 54 cost time: 13.439145803451538
Epoch: 54, Steps: 258 | Train Loss: 0.2084930 Vali Loss: 0.9388170 Test Loss: 0.4180314
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2098049
	speed: 0.1897s/iter; left time: 2233.0721s
	iters: 200, epoch: 55 | loss: 0.2283701
	speed: 0.0501s/iter; left time: 585.0348s
Epoch: 55 cost time: 12.818931579589844
Epoch: 55, Steps: 258 | Train Loss: 0.2085023 Vali Loss: 0.9386049 Test Loss: 0.4180190
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2152390
	speed: 0.1642s/iter; left time: 1890.5087s
	iters: 200, epoch: 56 | loss: 0.2170008
	speed: 0.0507s/iter; left time: 578.7064s
Epoch: 56 cost time: 12.81262755393982
Epoch: 56, Steps: 258 | Train Loss: 0.2085156 Vali Loss: 0.9388152 Test Loss: 0.4180538
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2135311
	speed: 0.1715s/iter; left time: 1929.8214s
	iters: 200, epoch: 57 | loss: 0.2095685
	speed: 0.0444s/iter; left time: 495.1512s
Epoch: 57 cost time: 11.762912511825562
Epoch: 57, Steps: 258 | Train Loss: 0.2084811 Vali Loss: 0.9394767 Test Loss: 0.4180376
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2008706
	speed: 0.1798s/iter; left time: 1976.8745s
	iters: 200, epoch: 58 | loss: 0.1930794
	speed: 0.0485s/iter; left time: 528.1571s
Epoch: 58 cost time: 12.411730289459229
Epoch: 58, Steps: 258 | Train Loss: 0.2085188 Vali Loss: 0.9394160 Test Loss: 0.4180605
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1989924
	speed: 0.1567s/iter; left time: 1682.3187s
	iters: 200, epoch: 59 | loss: 0.2189606
	speed: 0.0406s/iter; left time: 431.8106s
Epoch: 59 cost time: 10.06686544418335
Epoch: 59, Steps: 258 | Train Loss: 0.2084697 Vali Loss: 0.9392455 Test Loss: 0.4180303
EarlyStopping counter: 20 out of 20
Early stopping
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=106, out_features=212, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  20134912.0
params:  22684.0
Trainable parameters:  22684
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3644707
	speed: 0.0484s/iter; left time: 1244.0133s
	iters: 200, epoch: 1 | loss: 0.4075073
	speed: 0.0386s/iter; left time: 988.4750s
Epoch: 1 cost time: 10.960482358932495
Epoch: 1, Steps: 258 | Train Loss: 0.3982896 Vali Loss: 0.9335427 Test Loss: 0.4172715
Validation loss decreased (inf --> 0.933543).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3759238
	speed: 0.1792s/iter; left time: 4558.3686s
	iters: 200, epoch: 2 | loss: 0.3938437
	speed: 0.0422s/iter; left time: 1068.5389s
Epoch: 2 cost time: 12.174373626708984
Epoch: 2, Steps: 258 | Train Loss: 0.3975194 Vali Loss: 0.9314176 Test Loss: 0.4171460
Validation loss decreased (0.933543 --> 0.931418).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3995488
	speed: 0.1599s/iter; left time: 4027.8257s
	iters: 200, epoch: 3 | loss: 0.3905811
	speed: 0.0485s/iter; left time: 1215.4657s
Epoch: 3 cost time: 12.333514928817749
Epoch: 3, Steps: 258 | Train Loss: 0.3973045 Vali Loss: 0.9322770 Test Loss: 0.4166577
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4169821
	speed: 0.1646s/iter; left time: 4103.6303s
	iters: 200, epoch: 4 | loss: 0.4065525
	speed: 0.0434s/iter; left time: 1078.6461s
Epoch: 4 cost time: 11.730256080627441
Epoch: 4, Steps: 258 | Train Loss: 0.3971699 Vali Loss: 0.9316677 Test Loss: 0.4160511
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4071124
	speed: 0.1497s/iter; left time: 3691.8580s
	iters: 200, epoch: 5 | loss: 0.4214951
	speed: 0.0361s/iter; left time: 886.3564s
Epoch: 5 cost time: 10.815602779388428
Epoch: 5, Steps: 258 | Train Loss: 0.3968294 Vali Loss: 0.9305765 Test Loss: 0.4162522
Validation loss decreased (0.931418 --> 0.930577).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4002748
	speed: 0.1645s/iter; left time: 4014.7983s
	iters: 200, epoch: 6 | loss: 0.3950780
	speed: 0.0388s/iter; left time: 944.4669s
Epoch: 6 cost time: 10.875301599502563
Epoch: 6, Steps: 258 | Train Loss: 0.3969982 Vali Loss: 0.9314134 Test Loss: 0.4171720
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3775494
	speed: 0.1743s/iter; left time: 4210.3078s
	iters: 200, epoch: 7 | loss: 0.3928320
	speed: 0.0336s/iter; left time: 808.4517s
Epoch: 7 cost time: 11.139373302459717
Epoch: 7, Steps: 258 | Train Loss: 0.3968133 Vali Loss: 0.9307833 Test Loss: 0.4167439
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3693801
	speed: 0.1728s/iter; left time: 4128.8093s
	iters: 200, epoch: 8 | loss: 0.3813066
	speed: 0.0410s/iter; left time: 975.9793s
Epoch: 8 cost time: 11.171679496765137
Epoch: 8, Steps: 258 | Train Loss: 0.3968780 Vali Loss: 0.9311586 Test Loss: 0.4167652
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4001201
	speed: 0.1737s/iter; left time: 4105.5695s
	iters: 200, epoch: 9 | loss: 0.4072860
	speed: 0.0485s/iter; left time: 1142.4476s
Epoch: 9 cost time: 12.412074089050293
Epoch: 9, Steps: 258 | Train Loss: 0.3968998 Vali Loss: 0.9303681 Test Loss: 0.4166342
Validation loss decreased (0.930577 --> 0.930368).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4190616
	speed: 0.1856s/iter; left time: 4338.5639s
	iters: 200, epoch: 10 | loss: 0.3991129
	speed: 0.0380s/iter; left time: 883.9947s
Epoch: 10 cost time: 11.011455059051514
Epoch: 10, Steps: 258 | Train Loss: 0.3966725 Vali Loss: 0.9314860 Test Loss: 0.4168528
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3828564
	speed: 0.1629s/iter; left time: 3766.6242s
	iters: 200, epoch: 11 | loss: 0.3823829
	speed: 0.0418s/iter; left time: 961.9098s
Epoch: 11 cost time: 11.8760666847229
Epoch: 11, Steps: 258 | Train Loss: 0.3967959 Vali Loss: 0.9310930 Test Loss: 0.4169972
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3750812
	speed: 0.1721s/iter; left time: 3935.2659s
	iters: 200, epoch: 12 | loss: 0.4289542
	speed: 0.0478s/iter; left time: 1087.2628s
Epoch: 12 cost time: 13.278186559677124
Epoch: 12, Steps: 258 | Train Loss: 0.3966481 Vali Loss: 0.9308116 Test Loss: 0.4171048
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3801844
	speed: 0.1567s/iter; left time: 3542.3409s
	iters: 200, epoch: 13 | loss: 0.3593144
	speed: 0.0456s/iter; left time: 1025.9399s
Epoch: 13 cost time: 11.367387056350708
Epoch: 13, Steps: 258 | Train Loss: 0.3967255 Vali Loss: 0.9310488 Test Loss: 0.4163756
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4020934
	speed: 0.1564s/iter; left time: 3495.1169s
	iters: 200, epoch: 14 | loss: 0.3685340
	speed: 0.0455s/iter; left time: 1012.4757s
Epoch: 14 cost time: 11.428285121917725
Epoch: 14, Steps: 258 | Train Loss: 0.3965655 Vali Loss: 0.9309701 Test Loss: 0.4165682
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4015956
	speed: 0.1562s/iter; left time: 3449.9908s
	iters: 200, epoch: 15 | loss: 0.3918744
	speed: 0.0449s/iter; left time: 987.3413s
Epoch: 15 cost time: 11.796022891998291
Epoch: 15, Steps: 258 | Train Loss: 0.3965883 Vali Loss: 0.9301721 Test Loss: 0.4163183
Validation loss decreased (0.930368 --> 0.930172).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4058277
	speed: 0.1577s/iter; left time: 3443.1543s
	iters: 200, epoch: 16 | loss: 0.3835757
	speed: 0.0377s/iter; left time: 819.9028s
Epoch: 16 cost time: 9.70374608039856
Epoch: 16, Steps: 258 | Train Loss: 0.3965422 Vali Loss: 0.9298614 Test Loss: 0.4166463
Validation loss decreased (0.930172 --> 0.929861).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4125486
	speed: 0.1786s/iter; left time: 3852.4631s
	iters: 200, epoch: 17 | loss: 0.3894447
	speed: 0.0490s/iter; left time: 1051.6381s
Epoch: 17 cost time: 13.117606163024902
Epoch: 17, Steps: 258 | Train Loss: 0.3965224 Vali Loss: 0.9301668 Test Loss: 0.4165148
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4259147
	speed: 0.1816s/iter; left time: 3869.9946s
	iters: 200, epoch: 18 | loss: 0.3934261
	speed: 0.0467s/iter; left time: 990.2158s
Epoch: 18 cost time: 11.537946701049805
Epoch: 18, Steps: 258 | Train Loss: 0.3964535 Vali Loss: 0.9290698 Test Loss: 0.4169232
Validation loss decreased (0.929861 --> 0.929070).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3938441
	speed: 0.1747s/iter; left time: 3678.0621s
	iters: 200, epoch: 19 | loss: 0.4191151
	speed: 0.0375s/iter; left time: 784.9285s
Epoch: 19 cost time: 11.765405654907227
Epoch: 19, Steps: 258 | Train Loss: 0.3965085 Vali Loss: 0.9308408 Test Loss: 0.4164679
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3910469
	speed: 0.1762s/iter; left time: 3664.9765s
	iters: 200, epoch: 20 | loss: 0.3600657
	speed: 0.0396s/iter; left time: 819.1451s
Epoch: 20 cost time: 10.824095487594604
Epoch: 20, Steps: 258 | Train Loss: 0.3965163 Vali Loss: 0.9312056 Test Loss: 0.4168565
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3533981
	speed: 0.1789s/iter; left time: 3674.1611s
	iters: 200, epoch: 21 | loss: 0.3930096
	speed: 0.0451s/iter; left time: 922.4634s
Epoch: 21 cost time: 12.000115156173706
Epoch: 21, Steps: 258 | Train Loss: 0.3964566 Vali Loss: 0.9302533 Test Loss: 0.4167455
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3756731
	speed: 0.1644s/iter; left time: 3334.8011s
	iters: 200, epoch: 22 | loss: 0.3867359
	speed: 0.0326s/iter; left time: 658.4071s
Epoch: 22 cost time: 10.333139657974243
Epoch: 22, Steps: 258 | Train Loss: 0.3964514 Vali Loss: 0.9300626 Test Loss: 0.4169189
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3544082
	speed: 0.1723s/iter; left time: 3449.8505s
	iters: 200, epoch: 23 | loss: 0.3895452
	speed: 0.0478s/iter; left time: 951.4707s
Epoch: 23 cost time: 11.981372833251953
Epoch: 23, Steps: 258 | Train Loss: 0.3963617 Vali Loss: 0.9305557 Test Loss: 0.4170986
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4013456
	speed: 0.1554s/iter; left time: 3072.6553s
	iters: 200, epoch: 24 | loss: 0.3889610
	speed: 0.0359s/iter; left time: 705.6004s
Epoch: 24 cost time: 9.710724592208862
Epoch: 24, Steps: 258 | Train Loss: 0.3963863 Vali Loss: 0.9302325 Test Loss: 0.4164251
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4045650
	speed: 0.2000s/iter; left time: 3902.4796s
	iters: 200, epoch: 25 | loss: 0.4157918
	speed: 0.0395s/iter; left time: 766.9336s
Epoch: 25 cost time: 10.944225549697876
Epoch: 25, Steps: 258 | Train Loss: 0.3964532 Vali Loss: 0.9304595 Test Loss: 0.4168495
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3975900
	speed: 0.1652s/iter; left time: 3180.9937s
	iters: 200, epoch: 26 | loss: 0.4026168
	speed: 0.0411s/iter; left time: 786.5060s
Epoch: 26 cost time: 11.09607744216919
Epoch: 26, Steps: 258 | Train Loss: 0.3963441 Vali Loss: 0.9300787 Test Loss: 0.4165683
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3755958
	speed: 0.1623s/iter; left time: 3082.7732s
	iters: 200, epoch: 27 | loss: 0.4116835
	speed: 0.0411s/iter; left time: 776.9884s
Epoch: 27 cost time: 11.640252828598022
Epoch: 27, Steps: 258 | Train Loss: 0.3963523 Vali Loss: 0.9307302 Test Loss: 0.4168855
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3871121
	speed: 0.1632s/iter; left time: 3058.2221s
	iters: 200, epoch: 28 | loss: 0.4099299
	speed: 0.0407s/iter; left time: 759.0162s
Epoch: 28 cost time: 11.28567123413086
Epoch: 28, Steps: 258 | Train Loss: 0.3964631 Vali Loss: 0.9307430 Test Loss: 0.4165297
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4076638
	speed: 0.1736s/iter; left time: 3208.3021s
	iters: 200, epoch: 29 | loss: 0.3903231
	speed: 0.0473s/iter; left time: 868.5451s
Epoch: 29 cost time: 11.905190467834473
Epoch: 29, Steps: 258 | Train Loss: 0.3963463 Vali Loss: 0.9296654 Test Loss: 0.4168596
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4091049
	speed: 0.1803s/iter; left time: 3285.3274s
	iters: 200, epoch: 30 | loss: 0.4067845
	speed: 0.0372s/iter; left time: 674.8705s
Epoch: 30 cost time: 11.143709421157837
Epoch: 30, Steps: 258 | Train Loss: 0.3963194 Vali Loss: 0.9314646 Test Loss: 0.4169540
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3722384
	speed: 0.1725s/iter; left time: 3099.1319s
	iters: 200, epoch: 31 | loss: 0.3578510
	speed: 0.0492s/iter; left time: 879.1396s
Epoch: 31 cost time: 12.858499765396118
Epoch: 31, Steps: 258 | Train Loss: 0.3962787 Vali Loss: 0.9297575 Test Loss: 0.4167926
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3812491
	speed: 0.2000s/iter; left time: 3540.9814s
	iters: 200, epoch: 32 | loss: 0.3966133
	speed: 0.0377s/iter; left time: 664.0841s
Epoch: 32 cost time: 10.65352177619934
Epoch: 32, Steps: 258 | Train Loss: 0.3964089 Vali Loss: 0.9300594 Test Loss: 0.4166473
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3752613
	speed: 0.1776s/iter; left time: 3098.9008s
	iters: 200, epoch: 33 | loss: 0.4087220
	speed: 0.0427s/iter; left time: 739.8729s
Epoch: 33 cost time: 12.29856276512146
Epoch: 33, Steps: 258 | Train Loss: 0.3963406 Vali Loss: 0.9297903 Test Loss: 0.4169336
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3865652
	speed: 0.1871s/iter; left time: 3214.8626s
	iters: 200, epoch: 34 | loss: 0.3948221
	speed: 0.0434s/iter; left time: 741.0149s
Epoch: 34 cost time: 11.820679664611816
Epoch: 34, Steps: 258 | Train Loss: 0.3963380 Vali Loss: 0.9303377 Test Loss: 0.4166235
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4162880
	speed: 0.1758s/iter; left time: 2975.5930s
	iters: 200, epoch: 35 | loss: 0.4043989
	speed: 0.0403s/iter; left time: 677.7819s
Epoch: 35 cost time: 12.664672136306763
Epoch: 35, Steps: 258 | Train Loss: 0.3962399 Vali Loss: 0.9304000 Test Loss: 0.4164958
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4232948
	speed: 0.1665s/iter; left time: 2776.2630s
	iters: 200, epoch: 36 | loss: 0.4164823
	speed: 0.0432s/iter; left time: 716.5374s
Epoch: 36 cost time: 10.824211835861206
Epoch: 36, Steps: 258 | Train Loss: 0.3963897 Vali Loss: 0.9296086 Test Loss: 0.4170960
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3576305
	speed: 0.1677s/iter; left time: 2752.8954s
	iters: 200, epoch: 37 | loss: 0.3888493
	speed: 0.0387s/iter; left time: 631.2338s
Epoch: 37 cost time: 11.903933763504028
Epoch: 37, Steps: 258 | Train Loss: 0.3963002 Vali Loss: 0.9295056 Test Loss: 0.4168099
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4110918
	speed: 0.1697s/iter; left time: 2742.0465s
	iters: 200, epoch: 38 | loss: 0.3841456
	speed: 0.0406s/iter; left time: 651.5419s
Epoch: 38 cost time: 11.266851663589478
Epoch: 38, Steps: 258 | Train Loss: 0.3963715 Vali Loss: 0.9295468 Test Loss: 0.4167098
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_720_720_FITS_ETTm1_ftM_sl720_ll48_pl720_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.41588127613067627, mae:0.4118660092353821, rse:0.6135576963424683, corr:[0.52416694 0.5324025  0.53587013 0.5365439  0.5370491  0.5385266
 0.54036325 0.54159266 0.54203504 0.5421793  0.5426482  0.54333806
 0.5438161  0.54359764 0.54262197 0.54128164 0.54006815 0.53913045
 0.53819656 0.5370302  0.5355494  0.533766   0.53187    0.53029245
 0.528986   0.52798885 0.5271877  0.52649087 0.5261214  0.5262032
 0.5267133  0.5275207  0.52819425 0.5286215  0.52872443 0.5288989
 0.52907854 0.5292318  0.52922016 0.5288741  0.52841437 0.5279758
 0.5277297  0.5277341  0.5277712  0.52771336 0.52769524 0.5278126
 0.52803665 0.5282327  0.5283611  0.52827585 0.5280316  0.5276253
 0.52729046 0.52715045 0.52715737 0.527084   0.5268688  0.52644116
 0.5260183  0.52582526 0.52591    0.5260334  0.52611    0.5260905
 0.5259666  0.52585316 0.5259094  0.52608144 0.5262783  0.5263218
 0.5261515  0.52584255 0.52559793 0.5254388  0.5252887  0.5250854
 0.5247904  0.5244617  0.5241942  0.5240631  0.52409554 0.52415556
 0.5242084  0.52414334 0.5240055  0.52385914 0.52384883 0.5241184
 0.52459025 0.525069   0.5253829  0.5254267  0.5252599  0.5249691
 0.5247376  0.5247095  0.52469945 0.524685   0.52458316 0.52439386
 0.5242023  0.52401954 0.52393514 0.5240143  0.52408314 0.5240909
 0.52393043 0.523651   0.5232857  0.5228609  0.5224445  0.5221176
 0.52186215 0.5216785  0.52153504 0.5213692  0.5211642  0.52100796
 0.5209041  0.52083576 0.5207331  0.5206675  0.52061075 0.52043056
 0.52011055 0.5197904  0.5195588  0.51950675 0.5195129  0.51943356
 0.5192195  0.518852   0.5183509  0.5179349  0.5178365  0.51794064
 0.51816595 0.5184122  0.5185153  0.51855737 0.5186878  0.51898766
 0.51937044 0.519583   0.5195548  0.5193137  0.51907104 0.51894003
 0.5189678  0.51916325 0.5193499  0.5193632  0.5191439  0.51886886
 0.51865876 0.51858884 0.51871854 0.51890415 0.51916164 0.5194225
 0.51962924 0.5197322  0.5197663  0.51978606 0.51986945 0.5200691
 0.52033204 0.52054214 0.5207007  0.5207717  0.52066547 0.5204546
 0.5202706  0.52021337 0.5203046  0.520479   0.52058846 0.5205867
 0.5204428  0.5202233  0.5199707  0.5198501  0.51993144 0.5201908
 0.5205429  0.5209692  0.5214058  0.5217498  0.52191794 0.52188885
 0.52168137 0.5214118  0.5210304  0.52050626 0.5198607  0.5191597
 0.5184138  0.5176882  0.51700646 0.5164461  0.5159636  0.5155157
 0.5150329  0.51445264 0.513761   0.5130569  0.5124248  0.51191014
 0.5114651  0.5110861  0.51070136 0.51023287 0.50955987 0.5087975
 0.50807756 0.50741655 0.5068941  0.50649863 0.50623107 0.5061311
 0.5062362  0.5063656  0.5065062  0.50666034 0.5067755  0.5068763
 0.5069963  0.5071349  0.50725013 0.5072405  0.5071121  0.5069338
 0.5067547  0.50667363 0.5066154  0.50674874 0.50699335 0.5073276
 0.50760376 0.50764567 0.5075082  0.5073226  0.50722665 0.5071727
 0.5071168  0.5070348  0.5068792  0.5067034  0.50648963 0.506365
 0.5062738  0.5062979  0.5063441  0.5063502  0.506308   0.5062554
 0.506231   0.50627416 0.5063667  0.50649863 0.5066762  0.50698084
 0.5072979  0.50755787 0.5077074  0.5077651  0.50773084 0.5075985
 0.5074816  0.5074113  0.5074317  0.5075391  0.50767785 0.5078153
 0.5078653  0.5078867  0.50781506 0.50775486 0.50770324 0.5076806
 0.5077778  0.50792986 0.50803405 0.50802463 0.50781804 0.5074014
 0.50690645 0.5065494  0.506368   0.50621027 0.50595737 0.5055172
 0.5049125  0.5041789  0.503523   0.5030059  0.5026117  0.5022741
 0.5018601  0.501352   0.5008268  0.50035423 0.5000102  0.4997919
 0.49976707 0.49976936 0.49969214 0.49948493 0.4992492  0.49902374
 0.49886844 0.49884722 0.49886665 0.4988732  0.49882635 0.49876583
 0.4986862  0.49856165 0.49841228 0.49826273 0.49811396 0.49795985
 0.49781466 0.4977539  0.4977265  0.4977182  0.49764124 0.4974582
 0.49727744 0.4971303  0.49703753 0.49706304 0.49717188 0.49739173
 0.49755946 0.49745768 0.49722126 0.4969592  0.49681762 0.49681658
 0.4968624  0.49694487 0.49695355 0.49685085 0.49665123 0.4964403
 0.49620757 0.49605656 0.49601495 0.49603108 0.49611086 0.49620533
 0.49625424 0.4962873  0.49630454 0.49630225 0.49632078 0.4963223
 0.49621332 0.49605846 0.4958787  0.49573672 0.49570042 0.4957577
 0.4957419  0.49566966 0.4955404  0.49534807 0.49524492 0.49531588
 0.4955608  0.49590227 0.49618647 0.4963682  0.49642172 0.49648538
 0.4966803  0.49705186 0.49757788 0.49805996 0.49833217 0.49833262
 0.49805784 0.49761114 0.49715328 0.49672154 0.49628457 0.49593654
 0.49560276 0.49524534 0.4948736  0.49458748 0.49435547 0.49417216
 0.49395213 0.49362573 0.4931597  0.49258563 0.4919582  0.49148533
 0.4911776  0.4910593  0.49095905 0.49082226 0.49061126 0.49042177
 0.49029276 0.4902786  0.4903352  0.4904107  0.4904407  0.49033526
 0.49029014 0.49026796 0.4904053  0.49059352 0.4908076  0.49102572
 0.49110594 0.49111122 0.49102938 0.49094912 0.49086642 0.4908555
 0.4908282  0.4907622  0.49059385 0.4904772  0.4904196  0.4905565
 0.49072543 0.4907209  0.49055994 0.4903288  0.49007744 0.48985663
 0.489693   0.48960268 0.4895873  0.4896054  0.48964587 0.4897159
 0.48979014 0.48992258 0.49009544 0.49027157 0.49040198 0.4904098
 0.4903736  0.49032518 0.49031016 0.49031612 0.49034882 0.49046203
 0.49051115 0.49047202 0.49033365 0.49018764 0.4900125  0.4899231
 0.489911   0.49000698 0.49008492 0.49013588 0.49015346 0.49012867
 0.49011725 0.49006954 0.49001727 0.48995718 0.4899175  0.4899204
 0.48995128 0.4900731  0.49026233 0.4903675  0.4902784  0.4899713
 0.4894927  0.48894295 0.48841032 0.48788399 0.48734564 0.48683387
 0.4863989  0.48593035 0.4854394  0.48495415 0.48438427 0.4837214
 0.4829967  0.48230487 0.4816577  0.4810166  0.48039237 0.47984943
 0.47936916 0.4790087  0.47875032 0.4784211  0.4781488  0.47788852
 0.4777029  0.47758487 0.477506   0.4775516  0.4777106  0.4780074
 0.47839224 0.47871917 0.4789373  0.4791793  0.47944435 0.47973388
 0.479983   0.48022306 0.48044097 0.48051837 0.48047474 0.48042274
 0.48042914 0.4805317  0.48071223 0.4808953  0.4811522  0.4815027
 0.48182246 0.48197794 0.48190737 0.4817409  0.4815665  0.48139262
 0.48122862 0.4810522  0.48087627 0.48071417 0.48056856 0.480452
 0.4803864  0.48036152 0.48036733 0.48035216 0.4802895  0.48024866
 0.48025206 0.48036075 0.4806031  0.4808899  0.4811398  0.48135057
 0.48137507 0.48123264 0.48103297 0.48091742 0.48090544 0.4810019
 0.48109183 0.48108754 0.48095557 0.48076138 0.48060566 0.480543
 0.48055685 0.48070106 0.48078617 0.4807864  0.4807132  0.48065817
 0.48070502 0.48086923 0.48113307 0.48133227 0.48131797 0.48100916
 0.48049036 0.47992286 0.47936493 0.4787774  0.47814444 0.4775789
 0.47709057 0.47671694 0.47640747 0.47608557 0.47568583 0.47510448
 0.4743984  0.47362497 0.47290456 0.47231394 0.47192362 0.47166526
 0.47146013 0.4712183  0.47094855 0.4706555  0.4703393  0.46999767
 0.4696819  0.46937308 0.46915686 0.46908987 0.46919838 0.46937487
 0.4696236  0.46981403 0.46992603 0.47       0.47007757 0.47023737
 0.47046694 0.47065723 0.47083154 0.47094536 0.47102603 0.47108433
 0.47118437 0.47136706 0.47153357 0.4717171  0.4720481  0.47248024
 0.47282138 0.47303385 0.47307563 0.47297853 0.47290522 0.4729233
 0.4729508  0.47300074 0.47302607 0.47294298 0.47281817 0.47264308
 0.4724226  0.47223344 0.47211885 0.47196445 0.47181574 0.4716321
 0.47145298 0.47131935 0.47128227 0.47134975 0.47144815 0.47155264
 0.47157562 0.47145286 0.4713096  0.47123614 0.47123706 0.4712567
 0.47122958 0.47111812 0.47095326 0.4708021  0.47071925 0.47072238
 0.47079775 0.47096607 0.47115415 0.4712792  0.4714229  0.47160193
 0.47183478 0.47208172 0.47225466 0.47226623 0.4720312  0.47158274
 0.47106326 0.47067913 0.47045878 0.47026283 0.46994653 0.46944812
 0.46881014 0.468106   0.46754047 0.46716478 0.46686035 0.46669763
 0.46646258 0.46619442 0.46584737 0.46554285 0.4652781  0.46501657
 0.46476385 0.46447948 0.46421874 0.46392062 0.4636915  0.4636046
 0.46361288 0.4637461  0.4639103  0.4640719  0.4643088  0.46453753
 0.46482572 0.4651193  0.4654189  0.4657868  0.46607825 0.46630076
 0.46643564 0.46657848 0.466832   0.46721533 0.46774864 0.4681728
 0.4683457  0.46825042 0.4680289  0.46818087 0.46842203 0.46650064]
