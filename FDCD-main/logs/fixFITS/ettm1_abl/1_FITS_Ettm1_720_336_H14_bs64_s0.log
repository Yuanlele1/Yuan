Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=122, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=0, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_720_336_FITS_ETTm1_ftM_sl720_ll48_pl336_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=122, out_features=178, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  19457536.0
params:  21894.0
Trainable parameters:  21894
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4013353
	speed: 0.0177s/iter; left time: 460.0465s
	iters: 200, epoch: 1 | loss: 0.3362793
	speed: 0.0135s/iter; left time: 349.8731s
Epoch: 1 cost time: 3.9217851161956787
Epoch: 1, Steps: 261 | Train Loss: 0.4246296 Vali Loss: 0.7223939 Test Loss: 0.3758179
Validation loss decreased (inf --> 0.722394).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3604309
	speed: 0.0582s/iter; left time: 1497.4482s
	iters: 200, epoch: 2 | loss: 0.3465954
	speed: 0.0139s/iter; left time: 355.2959s
Epoch: 2 cost time: 4.041599750518799
Epoch: 2, Steps: 261 | Train Loss: 0.3479279 Vali Loss: 0.6848717 Test Loss: 0.3653513
Validation loss decreased (0.722394 --> 0.684872).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3138794
	speed: 0.0592s/iter; left time: 1509.3089s
	iters: 200, epoch: 3 | loss: 0.3480545
	speed: 0.0136s/iter; left time: 346.1086s
Epoch: 3 cost time: 4.011427640914917
Epoch: 3, Steps: 261 | Train Loss: 0.3409983 Vali Loss: 0.6708612 Test Loss: 0.3656928
Validation loss decreased (0.684872 --> 0.670861).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3538365
	speed: 0.0597s/iter; left time: 1504.3597s
	iters: 200, epoch: 4 | loss: 0.3097647
	speed: 0.0137s/iter; left time: 344.8045s
Epoch: 4 cost time: 4.075652837753296
Epoch: 4, Steps: 261 | Train Loss: 0.3389087 Vali Loss: 0.6665226 Test Loss: 0.3662483
Validation loss decreased (0.670861 --> 0.666523).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3300838
	speed: 0.0586s/iter; left time: 1462.6364s
	iters: 200, epoch: 5 | loss: 0.3953803
	speed: 0.0138s/iter; left time: 341.9927s
Epoch: 5 cost time: 3.949862003326416
Epoch: 5, Steps: 261 | Train Loss: 0.3379552 Vali Loss: 0.6658386 Test Loss: 0.3666268
Validation loss decreased (0.666523 --> 0.665839).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3467437
	speed: 0.0588s/iter; left time: 1452.3370s
	iters: 200, epoch: 6 | loss: 0.3493687
	speed: 0.0137s/iter; left time: 335.7435s
Epoch: 6 cost time: 4.04519248008728
Epoch: 6, Steps: 261 | Train Loss: 0.3374411 Vali Loss: 0.6598927 Test Loss: 0.3667597
Validation loss decreased (0.665839 --> 0.659893).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3242524
	speed: 0.0585s/iter; left time: 1429.3075s
	iters: 200, epoch: 7 | loss: 0.3350848
	speed: 0.0136s/iter; left time: 331.7602s
Epoch: 7 cost time: 3.9843175411224365
Epoch: 7, Steps: 261 | Train Loss: 0.3371396 Vali Loss: 0.6584544 Test Loss: 0.3666726
Validation loss decreased (0.659893 --> 0.658454).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3480624
	speed: 0.0596s/iter; left time: 1439.6719s
	iters: 200, epoch: 8 | loss: 0.3208037
	speed: 0.0135s/iter; left time: 325.7721s
Epoch: 8 cost time: 4.050847291946411
Epoch: 8, Steps: 261 | Train Loss: 0.3368305 Vali Loss: 0.6578596 Test Loss: 0.3665834
Validation loss decreased (0.658454 --> 0.657860).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3702124
	speed: 0.0604s/iter; left time: 1444.2946s
	iters: 200, epoch: 9 | loss: 0.3377120
	speed: 0.0138s/iter; left time: 328.1435s
Epoch: 9 cost time: 4.0778985023498535
Epoch: 9, Steps: 261 | Train Loss: 0.3367117 Vali Loss: 0.6575627 Test Loss: 0.3665276
Validation loss decreased (0.657860 --> 0.657563).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3281510
	speed: 0.0595s/iter; left time: 1407.6171s
	iters: 200, epoch: 10 | loss: 0.3290253
	speed: 0.0136s/iter; left time: 320.2453s
Epoch: 10 cost time: 4.049013614654541
Epoch: 10, Steps: 261 | Train Loss: 0.3366576 Vali Loss: 0.6577905 Test Loss: 0.3666302
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3448363
	speed: 0.0583s/iter; left time: 1363.7373s
	iters: 200, epoch: 11 | loss: 0.3595953
	speed: 0.0136s/iter; left time: 316.2347s
Epoch: 11 cost time: 3.9806737899780273
Epoch: 11, Steps: 261 | Train Loss: 0.3365541 Vali Loss: 0.6557718 Test Loss: 0.3666403
Validation loss decreased (0.657563 --> 0.655772).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3316298
	speed: 0.0586s/iter; left time: 1355.6212s
	iters: 200, epoch: 12 | loss: 0.3233059
	speed: 0.0138s/iter; left time: 316.7203s
Epoch: 12 cost time: 4.0080626010894775
Epoch: 12, Steps: 261 | Train Loss: 0.3363348 Vali Loss: 0.6562169 Test Loss: 0.3667966
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3118159
	speed: 0.0592s/iter; left time: 1353.5187s
	iters: 200, epoch: 13 | loss: 0.3752345
	speed: 0.0136s/iter; left time: 308.7873s
Epoch: 13 cost time: 3.996535539627075
Epoch: 13, Steps: 261 | Train Loss: 0.3363632 Vali Loss: 0.6564893 Test Loss: 0.3666671
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3779449
	speed: 0.0587s/iter; left time: 1327.2056s
	iters: 200, epoch: 14 | loss: 0.3545752
	speed: 0.0136s/iter; left time: 306.5074s
Epoch: 14 cost time: 3.9890618324279785
Epoch: 14, Steps: 261 | Train Loss: 0.3364580 Vali Loss: 0.6556228 Test Loss: 0.3665964
Validation loss decreased (0.655772 --> 0.655623).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3112940
	speed: 0.0587s/iter; left time: 1312.5682s
	iters: 200, epoch: 15 | loss: 0.3484284
	speed: 0.0138s/iter; left time: 306.2209s
Epoch: 15 cost time: 4.0203917026519775
Epoch: 15, Steps: 261 | Train Loss: 0.3362416 Vali Loss: 0.6549559 Test Loss: 0.3666166
Validation loss decreased (0.655623 --> 0.654956).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3476107
	speed: 0.0592s/iter; left time: 1308.0661s
	iters: 200, epoch: 16 | loss: 0.3439437
	speed: 0.0134s/iter; left time: 295.0024s
Epoch: 16 cost time: 3.9595561027526855
Epoch: 16, Steps: 261 | Train Loss: 0.3361904 Vali Loss: 0.6552075 Test Loss: 0.3668000
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3616184
	speed: 0.0599s/iter; left time: 1307.5899s
	iters: 200, epoch: 17 | loss: 0.3019038
	speed: 0.0137s/iter; left time: 298.2931s
Epoch: 17 cost time: 4.058393955230713
Epoch: 17, Steps: 261 | Train Loss: 0.3361994 Vali Loss: 0.6553035 Test Loss: 0.3668032
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3165066
	speed: 0.0600s/iter; left time: 1294.8567s
	iters: 200, epoch: 18 | loss: 0.3468942
	speed: 0.0139s/iter; left time: 299.1686s
Epoch: 18 cost time: 4.0381920337677
Epoch: 18, Steps: 261 | Train Loss: 0.3362497 Vali Loss: 0.6537700 Test Loss: 0.3667832
Validation loss decreased (0.654956 --> 0.653770).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3207800
	speed: 0.0587s/iter; left time: 1250.1364s
	iters: 200, epoch: 19 | loss: 0.3410507
	speed: 0.0135s/iter; left time: 286.2712s
Epoch: 19 cost time: 3.933058023452759
Epoch: 19, Steps: 261 | Train Loss: 0.3361269 Vali Loss: 0.6548458 Test Loss: 0.3664422
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3586380
	speed: 0.0589s/iter; left time: 1239.8019s
	iters: 200, epoch: 20 | loss: 0.3104747
	speed: 0.0140s/iter; left time: 293.6160s
Epoch: 20 cost time: 4.052630186080933
Epoch: 20, Steps: 261 | Train Loss: 0.3360425 Vali Loss: 0.6546357 Test Loss: 0.3664147
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3310138
	speed: 0.0590s/iter; left time: 1226.0024s
	iters: 200, epoch: 21 | loss: 0.3634313
	speed: 0.0136s/iter; left time: 281.7219s
Epoch: 21 cost time: 3.9055464267730713
Epoch: 21, Steps: 261 | Train Loss: 0.3359501 Vali Loss: 0.6549500 Test Loss: 0.3668607
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3062193
	speed: 0.0570s/iter; left time: 1169.3834s
	iters: 200, epoch: 22 | loss: 0.3659981
	speed: 0.0136s/iter; left time: 278.5664s
Epoch: 22 cost time: 3.9382400512695312
Epoch: 22, Steps: 261 | Train Loss: 0.3358810 Vali Loss: 0.6545637 Test Loss: 0.3665555
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3389521
	speed: 0.0578s/iter; left time: 1171.8559s
	iters: 200, epoch: 23 | loss: 0.3448385
	speed: 0.0136s/iter; left time: 273.6845s
Epoch: 23 cost time: 3.9923038482666016
Epoch: 23, Steps: 261 | Train Loss: 0.3360274 Vali Loss: 0.6542253 Test Loss: 0.3669016
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3186142
	speed: 0.0583s/iter; left time: 1166.4345s
	iters: 200, epoch: 24 | loss: 0.3571439
	speed: 0.0134s/iter; left time: 267.3772s
Epoch: 24 cost time: 3.8841025829315186
Epoch: 24, Steps: 261 | Train Loss: 0.3360433 Vali Loss: 0.6541973 Test Loss: 0.3667138
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3417694
	speed: 0.0590s/iter; left time: 1165.0757s
	iters: 200, epoch: 25 | loss: 0.3145883
	speed: 0.0133s/iter; left time: 261.5768s
Epoch: 25 cost time: 3.98587703704834
Epoch: 25, Steps: 261 | Train Loss: 0.3358097 Vali Loss: 0.6530981 Test Loss: 0.3667806
Validation loss decreased (0.653770 --> 0.653098).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3347527
	speed: 0.0579s/iter; left time: 1128.0565s
	iters: 200, epoch: 26 | loss: 0.3157206
	speed: 0.0136s/iter; left time: 262.8729s
Epoch: 26 cost time: 3.9133007526397705
Epoch: 26, Steps: 261 | Train Loss: 0.3359241 Vali Loss: 0.6549542 Test Loss: 0.3669368
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3271469
	speed: 0.0589s/iter; left time: 1131.8957s
	iters: 200, epoch: 27 | loss: 0.3378166
	speed: 0.0136s/iter; left time: 260.6542s
Epoch: 27 cost time: 4.048965930938721
Epoch: 27, Steps: 261 | Train Loss: 0.3359530 Vali Loss: 0.6542488 Test Loss: 0.3667404
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3834432
	speed: 0.0592s/iter; left time: 1122.7327s
	iters: 200, epoch: 28 | loss: 0.3052676
	speed: 0.0134s/iter; left time: 252.5705s
Epoch: 28 cost time: 3.96671462059021
Epoch: 28, Steps: 261 | Train Loss: 0.3358075 Vali Loss: 0.6543653 Test Loss: 0.3667303
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3296510
	speed: 0.0582s/iter; left time: 1088.1527s
	iters: 200, epoch: 29 | loss: 0.3526329
	speed: 0.0135s/iter; left time: 250.2725s
Epoch: 29 cost time: 3.9443352222442627
Epoch: 29, Steps: 261 | Train Loss: 0.3357803 Vali Loss: 0.6540062 Test Loss: 0.3667974
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3378435
	speed: 0.0597s/iter; left time: 1100.4322s
	iters: 200, epoch: 30 | loss: 0.3365945
	speed: 0.0139s/iter; left time: 254.8170s
Epoch: 30 cost time: 4.079402208328247
Epoch: 30, Steps: 261 | Train Loss: 0.3358497 Vali Loss: 0.6539193 Test Loss: 0.3664435
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3624081
	speed: 0.0598s/iter; left time: 1085.9647s
	iters: 200, epoch: 31 | loss: 0.3306522
	speed: 0.0134s/iter; left time: 242.4047s
Epoch: 31 cost time: 3.9903619289398193
Epoch: 31, Steps: 261 | Train Loss: 0.3357719 Vali Loss: 0.6544670 Test Loss: 0.3666678
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2961009
	speed: 0.0584s/iter; left time: 1045.5168s
	iters: 200, epoch: 32 | loss: 0.3800209
	speed: 0.0134s/iter; left time: 239.3095s
Epoch: 32 cost time: 3.9230494499206543
Epoch: 32, Steps: 261 | Train Loss: 0.3357115 Vali Loss: 0.6541731 Test Loss: 0.3667689
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3203247
	speed: 0.0580s/iter; left time: 1023.9684s
	iters: 200, epoch: 33 | loss: 0.3414394
	speed: 0.0134s/iter; left time: 234.7008s
Epoch: 33 cost time: 3.9946579933166504
Epoch: 33, Steps: 261 | Train Loss: 0.3357411 Vali Loss: 0.6538763 Test Loss: 0.3667331
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3487004
	speed: 0.0589s/iter; left time: 1023.5604s
	iters: 200, epoch: 34 | loss: 0.3339841
	speed: 0.0137s/iter; left time: 237.2535s
Epoch: 34 cost time: 4.040713548660278
Epoch: 34, Steps: 261 | Train Loss: 0.3357392 Vali Loss: 0.6546587 Test Loss: 0.3664667
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3009914
	speed: 0.0585s/iter; left time: 1002.5126s
	iters: 200, epoch: 35 | loss: 0.3704485
	speed: 0.0137s/iter; left time: 233.2085s
Epoch: 35 cost time: 4.006369113922119
Epoch: 35, Steps: 261 | Train Loss: 0.3357046 Vali Loss: 0.6539576 Test Loss: 0.3666625
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3167540
	speed: 0.0586s/iter; left time: 988.8396s
	iters: 200, epoch: 36 | loss: 0.3155072
	speed: 0.0137s/iter; left time: 229.1275s
Epoch: 36 cost time: 3.9432032108306885
Epoch: 36, Steps: 261 | Train Loss: 0.3357500 Vali Loss: 0.6552368 Test Loss: 0.3666362
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3187600
	speed: 0.0588s/iter; left time: 976.8508s
	iters: 200, epoch: 37 | loss: 0.3839889
	speed: 0.0134s/iter; left time: 221.1873s
Epoch: 37 cost time: 3.9469752311706543
Epoch: 37, Steps: 261 | Train Loss: 0.3356968 Vali Loss: 0.6540294 Test Loss: 0.3666732
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3333018
	speed: 0.0599s/iter; left time: 978.9953s
	iters: 200, epoch: 38 | loss: 0.3194245
	speed: 0.0137s/iter; left time: 222.0050s
Epoch: 38 cost time: 4.027355432510376
Epoch: 38, Steps: 261 | Train Loss: 0.3356079 Vali Loss: 0.6536440 Test Loss: 0.3668500
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4081941
	speed: 0.0594s/iter; left time: 955.1234s
	iters: 200, epoch: 39 | loss: 0.3122882
	speed: 0.0136s/iter; left time: 217.8599s
Epoch: 39 cost time: 3.986436605453491
Epoch: 39, Steps: 261 | Train Loss: 0.3358235 Vali Loss: 0.6537855 Test Loss: 0.3667067
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.3500060
	speed: 0.0585s/iter; left time: 925.8229s
	iters: 200, epoch: 40 | loss: 0.3020475
	speed: 0.0140s/iter; left time: 220.0192s
Epoch: 40 cost time: 4.1200478076934814
Epoch: 40, Steps: 261 | Train Loss: 0.3358039 Vali Loss: 0.6542875 Test Loss: 0.3666557
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3743159
	speed: 0.0590s/iter; left time: 918.6907s
	iters: 200, epoch: 41 | loss: 0.3150493
	speed: 0.0135s/iter; left time: 209.3989s
Epoch: 41 cost time: 4.036397218704224
Epoch: 41, Steps: 261 | Train Loss: 0.3357822 Vali Loss: 0.6545016 Test Loss: 0.3665442
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3177915
	speed: 0.0593s/iter; left time: 907.4680s
	iters: 200, epoch: 42 | loss: 0.3210012
	speed: 0.0136s/iter; left time: 206.7793s
Epoch: 42 cost time: 3.968667984008789
Epoch: 42, Steps: 261 | Train Loss: 0.3356478 Vali Loss: 0.6537475 Test Loss: 0.3666296
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3415042
	speed: 0.0587s/iter; left time: 882.5180s
	iters: 200, epoch: 43 | loss: 0.3210266
	speed: 0.0139s/iter; left time: 207.5334s
Epoch: 43 cost time: 3.99105167388916
Epoch: 43, Steps: 261 | Train Loss: 0.3357563 Vali Loss: 0.6540346 Test Loss: 0.3667506
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2992049
	speed: 0.0590s/iter; left time: 872.4204s
	iters: 200, epoch: 44 | loss: 0.3661107
	speed: 0.0136s/iter; left time: 200.1237s
Epoch: 44 cost time: 4.060173988342285
Epoch: 44, Steps: 261 | Train Loss: 0.3354759 Vali Loss: 0.6540913 Test Loss: 0.3667029
EarlyStopping counter: 19 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.3329169
	speed: 0.0593s/iter; left time: 860.2176s
	iters: 200, epoch: 45 | loss: 0.3608575
	speed: 0.0138s/iter; left time: 199.1338s
Epoch: 45 cost time: 4.025050401687622
Epoch: 45, Steps: 261 | Train Loss: 0.3356597 Vali Loss: 0.6532872 Test Loss: 0.3667017
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_720_336_FITS_ETTm1_ftM_sl720_ll48_pl336_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.3662881851196289, mae:0.38478294014930725, rse:0.5759168267250061, corr:[0.53703946 0.5454362  0.54862607 0.5496467  0.55116695 0.5535569
 0.55560815 0.5566128  0.5570206  0.55740064 0.5579996  0.5585523
 0.5588693  0.5588606  0.55852354 0.55781686 0.5567987  0.5557099
 0.55471    0.5538338  0.5528745  0.5515136  0.54976004 0.54809713
 0.5466755  0.5457453  0.54516137 0.544586   0.5441321  0.5439686
 0.5442705  0.54507554 0.54596657 0.54663503 0.54677343 0.54679996
 0.5467611  0.54669684 0.5464799  0.54598576 0.54554325 0.5453728
 0.54556787 0.5459559  0.5460311  0.5456537  0.5451853  0.54496825
 0.5450141  0.5450071  0.54476327 0.54422617 0.5436881  0.54337895
 0.54344404 0.54365957 0.54368204 0.54332316 0.54285103 0.54247713
 0.542371   0.54245305 0.5425402  0.54246813 0.54248625 0.542771
 0.5432095  0.54354626 0.543631   0.5434643  0.54326695 0.54318655
 0.5432039  0.5431871  0.5430682  0.5427775  0.5423526  0.54196507
 0.54171205 0.5416029  0.5415765  0.54153425 0.54146516 0.5413637
 0.54132515 0.5413145  0.54127806 0.54109937 0.54081553 0.5406448
 0.54070485 0.54100347 0.5414428  0.54186237 0.542075   0.5419745
 0.5416385  0.54127103 0.5408788  0.5405614  0.5403305  0.54013234
 0.53991306 0.5395671  0.53921944 0.5390087  0.53886616 0.53880674
 0.5386834  0.5384737  0.53819937 0.5378972  0.5376464  0.53751093
 0.53743106 0.5373188  0.5371013  0.536737   0.5363126  0.5359905
 0.5357978  0.5356827  0.53554624 0.53545773 0.53542656 0.5353452
 0.53515875 0.53491455 0.53466946 0.534576   0.53463227 0.5347758
 0.534953   0.5350339  0.53492373 0.5347476  0.5346885  0.53463554
 0.53457665 0.5344803  0.5342783  0.5341399  0.534249   0.5346371
 0.53516    0.5355396  0.5357016  0.53563875 0.53547525 0.5352605
 0.5350989  0.53515095 0.5353901  0.53566873 0.5357679  0.53561956
 0.53521544 0.5347062  0.53442025 0.53441006 0.5346743  0.5349772
 0.53514177 0.53512734 0.5351178  0.5352965  0.5356594  0.5360277
 0.5361573  0.5359777  0.53572726 0.5356258  0.53567463 0.5357868
 0.53582805 0.5357446  0.5355887  0.5355021  0.5355422  0.5357198
 0.5359118  0.5360341  0.5360377  0.5360615  0.5361918  0.5364131
 0.5366531  0.53689855 0.5371386  0.5373452  0.5375305  0.5376855
 0.5377369  0.53767353 0.537355   0.5367573  0.536011   0.53530616
 0.53470856 0.53421724 0.5337341  0.5331829  0.5325201  0.5317982
 0.5311069  0.53047323 0.5298659  0.52929294 0.52872485 0.52816266
 0.5276263  0.5271947  0.5268113  0.52637726 0.5257464  0.52503294
 0.5243876  0.52383804 0.5234442  0.52313983 0.5229443  0.5229372
 0.5231707  0.5234473  0.52368677 0.523821   0.52380335 0.52373606
 0.5237466  0.52389044 0.52412695 0.52430385 0.52439594 0.52446663
 0.5245617  0.5247512  0.5248709  0.5250451  0.52520543 0.5253928
 0.5255389  0.5254986  0.52532697 0.52512217 0.52497464 0.52482945
 0.5246587  0.52450126 0.5243339  0.52422905 0.524118   0.5240586
 0.52393925 0.52385783 0.52375644 0.52363014 0.52354074 0.52354217
 0.5236361  0.5237867  0.5238863  0.52389985 0.52387327 0.5239536
 0.52408475 0.52420586 0.52428186 0.52431446 0.52426463 0.5240874
 0.52390283 0.5237845  0.52380085 0.523959   0.524151   0.5243179
 0.5243994  0.52451146 0.5246155  0.5247669  0.5248487  0.5248192
 0.52477896 0.52481747 0.5249242  0.5250605  0.5250519  0.5247175
 0.5241105  0.52348137 0.5229613  0.522452   0.5219197  0.52132505
 0.5207344  0.520173   0.5197766  0.51942563 0.5189811  0.51835823
 0.51757085 0.51682246 0.51631975 0.51604575 0.51584595 0.51554585
 0.5152761  0.51499414 0.51469636 0.51433957 0.51398194 0.5136524
 0.5134995  0.5136616  0.51393926 0.5141131  0.5140247  0.51376534
 0.5135067  0.5133428  0.5133207  0.5133503  0.5132875  0.51306874
 0.5127748  0.51264066 0.51266915 0.51280266 0.51283467 0.5126627
 0.5124817  0.5124393  0.5126476  0.5131148  0.51324815 0.5112556 ]
