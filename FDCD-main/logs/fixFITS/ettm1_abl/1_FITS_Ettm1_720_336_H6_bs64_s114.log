Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=58, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_720_336_FITS_ETTm1_ftM_sl720_ll48_pl336_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=58, out_features=85, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4417280.0
params:  5015.0
Trainable parameters:  5015
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3912515
	speed: 0.0324s/iter; left time: 842.0692s
	iters: 200, epoch: 1 | loss: 0.3696247
	speed: 0.0259s/iter; left time: 671.8465s
Epoch: 1 cost time: 7.346060037612915
Epoch: 1, Steps: 261 | Train Loss: 0.4316363 Vali Loss: 0.7366642 Test Loss: 0.3823877
Validation loss decreased (inf --> 0.736664).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3733246
	speed: 0.1292s/iter; left time: 3326.1517s
	iters: 200, epoch: 2 | loss: 0.3634768
	speed: 0.0376s/iter; left time: 963.1981s
Epoch: 2 cost time: 10.041974306106567
Epoch: 2, Steps: 261 | Train Loss: 0.3514690 Vali Loss: 0.6930820 Test Loss: 0.3711374
Validation loss decreased (0.736664 --> 0.693082).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3427374
	speed: 0.1500s/iter; left time: 3822.6886s
	iters: 200, epoch: 3 | loss: 0.3488662
	speed: 0.0264s/iter; left time: 669.2274s
Epoch: 3 cost time: 8.26130199432373
Epoch: 3, Steps: 261 | Train Loss: 0.3443280 Vali Loss: 0.6782269 Test Loss: 0.3702386
Validation loss decreased (0.693082 --> 0.678227).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3232037
	speed: 0.1398s/iter; left time: 3525.9453s
	iters: 200, epoch: 4 | loss: 0.3453159
	speed: 0.0329s/iter; left time: 826.6564s
Epoch: 4 cost time: 8.59123945236206
Epoch: 4, Steps: 261 | Train Loss: 0.3420254 Vali Loss: 0.6706771 Test Loss: 0.3707502
Validation loss decreased (0.678227 --> 0.670677).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3373400
	speed: 0.1360s/iter; left time: 3393.9930s
	iters: 200, epoch: 5 | loss: 0.3508411
	speed: 0.0309s/iter; left time: 767.8088s
Epoch: 5 cost time: 9.231136560440063
Epoch: 5, Steps: 261 | Train Loss: 0.3408551 Vali Loss: 0.6681857 Test Loss: 0.3699735
Validation loss decreased (0.670677 --> 0.668186).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3369078
	speed: 0.1582s/iter; left time: 3907.0043s
	iters: 200, epoch: 6 | loss: 0.3540356
	speed: 0.0256s/iter; left time: 628.6137s
Epoch: 6 cost time: 7.042812347412109
Epoch: 6, Steps: 261 | Train Loss: 0.3403176 Vali Loss: 0.6646482 Test Loss: 0.3701984
Validation loss decreased (0.668186 --> 0.664648).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3567264
	speed: 0.1250s/iter; left time: 3055.0824s
	iters: 200, epoch: 7 | loss: 0.3154530
	speed: 0.0344s/iter; left time: 836.6099s
Epoch: 7 cost time: 9.451496362686157
Epoch: 7, Steps: 261 | Train Loss: 0.3398093 Vali Loss: 0.6644172 Test Loss: 0.3704225
Validation loss decreased (0.664648 --> 0.664417).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3260809
	speed: 0.1371s/iter; left time: 3314.0769s
	iters: 200, epoch: 8 | loss: 0.3325517
	speed: 0.0315s/iter; left time: 758.4031s
Epoch: 8 cost time: 8.729324340820312
Epoch: 8, Steps: 261 | Train Loss: 0.3394803 Vali Loss: 0.6624095 Test Loss: 0.3703580
Validation loss decreased (0.664417 --> 0.662409).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3570558
	speed: 0.1368s/iter; left time: 3272.1456s
	iters: 200, epoch: 9 | loss: 0.3538311
	speed: 0.0366s/iter; left time: 872.5307s
Epoch: 9 cost time: 10.678436040878296
Epoch: 9, Steps: 261 | Train Loss: 0.3395572 Vali Loss: 0.6610374 Test Loss: 0.3700847
Validation loss decreased (0.662409 --> 0.661037).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3681710
	speed: 0.1317s/iter; left time: 3114.4466s
	iters: 200, epoch: 10 | loss: 0.3639522
	speed: 0.0315s/iter; left time: 741.1271s
Epoch: 10 cost time: 9.827407598495483
Epoch: 10, Steps: 261 | Train Loss: 0.3391870 Vali Loss: 0.6612790 Test Loss: 0.3700539
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3468153
	speed: 0.1461s/iter; left time: 3418.4605s
	iters: 200, epoch: 11 | loss: 0.3420653
	speed: 0.0398s/iter; left time: 927.9418s
Epoch: 11 cost time: 10.599751472473145
Epoch: 11, Steps: 261 | Train Loss: 0.3391098 Vali Loss: 0.6610280 Test Loss: 0.3703097
Validation loss decreased (0.661037 --> 0.661028).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3576731
	speed: 0.1330s/iter; left time: 3077.2559s
	iters: 200, epoch: 12 | loss: 0.3491504
	speed: 0.0238s/iter; left time: 549.1951s
Epoch: 12 cost time: 7.635151386260986
Epoch: 12, Steps: 261 | Train Loss: 0.3390206 Vali Loss: 0.6601526 Test Loss: 0.3703493
Validation loss decreased (0.661028 --> 0.660153).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3350368
	speed: 0.1374s/iter; left time: 3143.0749s
	iters: 200, epoch: 13 | loss: 0.3021221
	speed: 0.0324s/iter; left time: 736.8218s
Epoch: 13 cost time: 9.145300149917603
Epoch: 13, Steps: 261 | Train Loss: 0.3389388 Vali Loss: 0.6588982 Test Loss: 0.3699426
Validation loss decreased (0.660153 --> 0.658898).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3787870
	speed: 0.1287s/iter; left time: 2909.9797s
	iters: 200, epoch: 14 | loss: 0.3476483
	speed: 0.0298s/iter; left time: 671.8043s
Epoch: 14 cost time: 8.160560607910156
Epoch: 14, Steps: 261 | Train Loss: 0.3388156 Vali Loss: 0.6584600 Test Loss: 0.3702097
Validation loss decreased (0.658898 --> 0.658460).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3417470
	speed: 0.1261s/iter; left time: 2817.7731s
	iters: 200, epoch: 15 | loss: 0.3189282
	speed: 0.0291s/iter; left time: 647.1228s
Epoch: 15 cost time: 8.18659496307373
Epoch: 15, Steps: 261 | Train Loss: 0.3389556 Vali Loss: 0.6595042 Test Loss: 0.3702861
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3310111
	speed: 0.1315s/iter; left time: 2903.9746s
	iters: 200, epoch: 16 | loss: 0.3619837
	speed: 0.0329s/iter; left time: 723.2130s
Epoch: 16 cost time: 10.043392419815063
Epoch: 16, Steps: 261 | Train Loss: 0.3387315 Vali Loss: 0.6583996 Test Loss: 0.3703657
Validation loss decreased (0.658460 --> 0.658400).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3443592
	speed: 0.1568s/iter; left time: 3421.0890s
	iters: 200, epoch: 17 | loss: 0.3428219
	speed: 0.0408s/iter; left time: 885.5988s
Epoch: 17 cost time: 11.161024332046509
Epoch: 17, Steps: 261 | Train Loss: 0.3387978 Vali Loss: 0.6583320 Test Loss: 0.3704464
Validation loss decreased (0.658400 --> 0.658332).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3125103
	speed: 0.1331s/iter; left time: 2869.4972s
	iters: 200, epoch: 18 | loss: 0.3423877
	speed: 0.0254s/iter; left time: 544.7431s
Epoch: 18 cost time: 7.72831916809082
Epoch: 18, Steps: 261 | Train Loss: 0.3387749 Vali Loss: 0.6574104 Test Loss: 0.3704281
Validation loss decreased (0.658332 --> 0.657410).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3501778
	speed: 0.1489s/iter; left time: 3172.9365s
	iters: 200, epoch: 19 | loss: 0.3564111
	speed: 0.0363s/iter; left time: 768.6606s
Epoch: 19 cost time: 9.378260135650635
Epoch: 19, Steps: 261 | Train Loss: 0.3384255 Vali Loss: 0.6579950 Test Loss: 0.3701436
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3546003
	speed: 0.1334s/iter; left time: 2806.2050s
	iters: 200, epoch: 20 | loss: 0.3302733
	speed: 0.0328s/iter; left time: 686.0672s
Epoch: 20 cost time: 9.469298362731934
Epoch: 20, Steps: 261 | Train Loss: 0.3386955 Vali Loss: 0.6577605 Test Loss: 0.3702908
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3334189
	speed: 0.1339s/iter; left time: 2783.5170s
	iters: 200, epoch: 21 | loss: 0.3211109
	speed: 0.0324s/iter; left time: 670.5697s
Epoch: 21 cost time: 9.487364530563354
Epoch: 21, Steps: 261 | Train Loss: 0.3387106 Vali Loss: 0.6582246 Test Loss: 0.3705304
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3324264
	speed: 0.1363s/iter; left time: 2796.9385s
	iters: 200, epoch: 22 | loss: 0.3295535
	speed: 0.0320s/iter; left time: 652.5324s
Epoch: 22 cost time: 9.55147123336792
Epoch: 22, Steps: 261 | Train Loss: 0.3385962 Vali Loss: 0.6583182 Test Loss: 0.3702449
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3250979
	speed: 0.1345s/iter; left time: 2725.7255s
	iters: 200, epoch: 23 | loss: 0.3225850
	speed: 0.0299s/iter; left time: 602.4779s
Epoch: 23 cost time: 8.873523712158203
Epoch: 23, Steps: 261 | Train Loss: 0.3385906 Vali Loss: 0.6584373 Test Loss: 0.3704359
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3218661
	speed: 0.1350s/iter; left time: 2699.3639s
	iters: 200, epoch: 24 | loss: 0.3496331
	speed: 0.0268s/iter; left time: 534.0437s
Epoch: 24 cost time: 8.370448589324951
Epoch: 24, Steps: 261 | Train Loss: 0.3385975 Vali Loss: 0.6581392 Test Loss: 0.3703223
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3175947
	speed: 0.1425s/iter; left time: 2813.3912s
	iters: 200, epoch: 25 | loss: 0.3482278
	speed: 0.0420s/iter; left time: 824.6146s
Epoch: 25 cost time: 11.24472689628601
Epoch: 25, Steps: 261 | Train Loss: 0.3385024 Vali Loss: 0.6581271 Test Loss: 0.3703332
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3315062
	speed: 0.1257s/iter; left time: 2447.7908s
	iters: 200, epoch: 26 | loss: 0.3416251
	speed: 0.0260s/iter; left time: 504.2624s
Epoch: 26 cost time: 7.329688310623169
Epoch: 26, Steps: 261 | Train Loss: 0.3385310 Vali Loss: 0.6585704 Test Loss: 0.3703219
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3062990
	speed: 0.1463s/iter; left time: 2811.7526s
	iters: 200, epoch: 27 | loss: 0.3249898
	speed: 0.0353s/iter; left time: 673.9670s
Epoch: 27 cost time: 10.154115915298462
Epoch: 27, Steps: 261 | Train Loss: 0.3385578 Vali Loss: 0.6576196 Test Loss: 0.3701845
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3380928
	speed: 0.1432s/iter; left time: 2713.5651s
	iters: 200, epoch: 28 | loss: 0.3131679
	speed: 0.0323s/iter; left time: 609.6432s
Epoch: 28 cost time: 9.419433355331421
Epoch: 28, Steps: 261 | Train Loss: 0.3385339 Vali Loss: 0.6579576 Test Loss: 0.3701355
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3194986
	speed: 0.1412s/iter; left time: 2638.8944s
	iters: 200, epoch: 29 | loss: 0.3202142
	speed: 0.0379s/iter; left time: 704.9642s
Epoch: 29 cost time: 10.376836776733398
Epoch: 29, Steps: 261 | Train Loss: 0.3384446 Vali Loss: 0.6579027 Test Loss: 0.3702798
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3358011
	speed: 0.1545s/iter; left time: 2848.3844s
	iters: 200, epoch: 30 | loss: 0.3292178
	speed: 0.0392s/iter; left time: 718.7520s
Epoch: 30 cost time: 11.47493863105774
Epoch: 30, Steps: 261 | Train Loss: 0.3384979 Vali Loss: 0.6579484 Test Loss: 0.3705136
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3408292
	speed: 0.1325s/iter; left time: 2406.9734s
	iters: 200, epoch: 31 | loss: 0.3607833
	speed: 0.0377s/iter; left time: 681.7367s
Epoch: 31 cost time: 9.826130867004395
Epoch: 31, Steps: 261 | Train Loss: 0.3384818 Vali Loss: 0.6580226 Test Loss: 0.3703119
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3669896
	speed: 0.1345s/iter; left time: 2409.2619s
	iters: 200, epoch: 32 | loss: 0.3304856
	speed: 0.0235s/iter; left time: 418.5654s
Epoch: 32 cost time: 7.232246398925781
Epoch: 32, Steps: 261 | Train Loss: 0.3384057 Vali Loss: 0.6575324 Test Loss: 0.3701861
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3363832
	speed: 0.1198s/iter; left time: 2114.7772s
	iters: 200, epoch: 33 | loss: 0.3622502
	speed: 0.0303s/iter; left time: 532.3228s
Epoch: 33 cost time: 7.900864124298096
Epoch: 33, Steps: 261 | Train Loss: 0.3383814 Vali Loss: 0.6585189 Test Loss: 0.3702785
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3391821
	speed: 0.1304s/iter; left time: 2266.9333s
	iters: 200, epoch: 34 | loss: 0.3626752
	speed: 0.0276s/iter; left time: 477.5610s
Epoch: 34 cost time: 8.38025712966919
Epoch: 34, Steps: 261 | Train Loss: 0.3383641 Vali Loss: 0.6576319 Test Loss: 0.3703444
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3236826
	speed: 0.1406s/iter; left time: 2408.6798s
	iters: 200, epoch: 35 | loss: 0.3201007
	speed: 0.0340s/iter; left time: 578.4650s
Epoch: 35 cost time: 10.255718231201172
Epoch: 35, Steps: 261 | Train Loss: 0.3384267 Vali Loss: 0.6581921 Test Loss: 0.3703332
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3131658
	speed: 0.1472s/iter; left time: 2483.1431s
	iters: 200, epoch: 36 | loss: 0.3448918
	speed: 0.0311s/iter; left time: 522.1684s
Epoch: 36 cost time: 8.628166675567627
Epoch: 36, Steps: 261 | Train Loss: 0.3384282 Vali Loss: 0.6575938 Test Loss: 0.3702917
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3661619
	speed: 0.1361s/iter; left time: 2259.9014s
	iters: 200, epoch: 37 | loss: 0.3131791
	speed: 0.0313s/iter; left time: 516.2349s
Epoch: 37 cost time: 9.07339072227478
Epoch: 37, Steps: 261 | Train Loss: 0.3383656 Vali Loss: 0.6577259 Test Loss: 0.3705284
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3483386
	speed: 0.1315s/iter; left time: 2148.5621s
	iters: 200, epoch: 38 | loss: 0.3317608
	speed: 0.0306s/iter; left time: 497.2784s
Epoch: 38 cost time: 8.497126340866089
Epoch: 38, Steps: 261 | Train Loss: 0.3384216 Vali Loss: 0.6574482 Test Loss: 0.3704100
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_720_336_FITS_ETTm1_ftM_sl720_ll48_pl336_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.3699377179145813, mae:0.3878049850463867, rse:0.5787788033485413, corr:[0.5369555  0.5432932  0.5487246  0.5524883  0.5544955  0.55532956
 0.55555505 0.5556439  0.5558938  0.5563645  0.5570209  0.5576074
 0.55798405 0.5579894  0.55756986 0.5567748  0.55570436 0.55444586
 0.55301595 0.55146074 0.5498736  0.5482763  0.5467243  0.545375
 0.5442021  0.54333216 0.5428249  0.5425964  0.5426913  0.54305303
 0.5435663  0.5441719  0.5446915  0.5451011  0.54528534 0.54534
 0.5451885  0.544932   0.5446464  0.54430324 0.5440057  0.5437655
 0.54361576 0.5436289  0.5437243  0.5438114  0.54389703 0.5439135
 0.54377884 0.54342324 0.542959   0.542479   0.54210675 0.5418203
 0.5416569  0.5415811  0.5415436  0.54147863 0.541385   0.54121697
 0.54100615 0.5408129  0.5406614  0.5405371  0.54052925 0.5406684
 0.5408959  0.5411603  0.5414161  0.54159397 0.5416804  0.5416574
 0.54150337 0.5412511  0.54097074 0.54070437 0.54045457 0.5402582
 0.5401119  0.54001284 0.53993046 0.539824   0.53967416 0.5394525
 0.53920597 0.5389565  0.5387665  0.53864187 0.53860503 0.5386921
 0.5388704  0.539067   0.5392139  0.53927886 0.53923374 0.5390622
 0.53881925 0.5386291  0.5384344  0.53827447 0.53815377 0.5380639
 0.5380025  0.53792    0.5378336  0.53777814 0.5376907  0.53759646
 0.53745824 0.5372885  0.5371021  0.5368853  0.5366314  0.53637713
 0.5361408  0.535932   0.5357649  0.5356237  0.5354998  0.5354096
 0.53531885 0.53519285 0.53498006 0.53473336 0.53449225 0.5342632
 0.53407    0.53395844 0.5339069  0.53392243 0.53393126 0.5338912
 0.5338279  0.53374547 0.53362036 0.5334838  0.533403   0.5333332
 0.5333237  0.5334205  0.5335684  0.5337743  0.53401995 0.5342768
 0.53449094 0.5345655  0.5345192  0.53436905 0.5341919  0.53401697
 0.53385395 0.5337514  0.5337352  0.5337839  0.5338682  0.53401166
 0.534168   0.53429145 0.53439724 0.5344283  0.53445137 0.5344786
 0.5345313  0.53460294 0.53469276 0.5347922  0.53489727 0.5350309
 0.5351276  0.53514534 0.53512824 0.53509176 0.5350122  0.5348871
 0.53473514 0.53456795 0.5344015  0.53425485 0.5341242  0.53404695
 0.5340327  0.5341033  0.53422457 0.53442025 0.53468007 0.5349703
 0.5352652  0.535541   0.535781   0.5359365  0.53594977 0.5358359
 0.5355775  0.53528935 0.5349291  0.5344633  0.53388894 0.5332422
 0.5325246  0.53176767 0.53099847 0.53026646 0.529588   0.5289689
 0.528414   0.5278969  0.52738076 0.52686495 0.5263174  0.5257119
 0.52503014 0.5243056  0.52357674 0.52289563 0.522263   0.5217511
 0.5214195  0.52124554 0.5212037  0.5212106  0.52121556 0.52122456
 0.52126735 0.5212913  0.52132726 0.52139217 0.5214663  0.52156013
 0.5216803  0.52182883 0.52197367 0.52206105 0.52209264 0.52208894
 0.52209103 0.5221875  0.52230746 0.5225357  0.5228085  0.5231243
 0.52342707 0.52358055 0.52358216 0.5234785  0.5233417  0.5231624
 0.5229625  0.5227713  0.5225905  0.52245903 0.52235264 0.5223053
 0.52226615 0.5222888  0.52232355 0.5223409  0.52235043 0.5223598
 0.5223764  0.5224192  0.52246875 0.5224966  0.5224867  0.5225069
 0.52249515 0.5224637  0.52242917 0.5224198  0.52244294 0.5224549
 0.52247155 0.52247596 0.5224743  0.52246857 0.5224465  0.52242595
 0.52238774 0.52240616 0.52243334 0.52253246 0.52266526 0.52279997
 0.5229227  0.52297914 0.52290684 0.52271825 0.5224027  0.5219425
 0.5213695  0.52080846 0.5203048  0.51979977 0.51928073 0.51875126
 0.51823115 0.51769257 0.5172011  0.51674294 0.5163172  0.5159413
 0.515603   0.5152799  0.51500046 0.5147311  0.5144306  0.51404935
 0.513674   0.51327604 0.5128848  0.5125419  0.5123238  0.51222676
 0.5122335  0.51233035 0.5124141  0.5124262  0.51234037 0.5122133
 0.51207584 0.5119272  0.5117955  0.5117153  0.5116681  0.51161134
 0.51149464 0.5113174  0.5110308  0.5106672  0.5102608  0.50991845
 0.5098219  0.509994   0.51033604 0.5106676  0.51060414 0.50947756]
