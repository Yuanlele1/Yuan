Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=24, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_90_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_90_336_FITS_ETTm1_ftM_sl90_ll48_pl336_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=24, out_features=113, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2429952.0
params:  2825.0
Trainable parameters:  2825
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6404757
	speed: 0.0357s/iter; left time: 946.0636s
	iters: 200, epoch: 1 | loss: 0.5519611
	speed: 0.0357s/iter; left time: 942.0799s
Epoch: 1 cost time: 8.362810373306274
Epoch: 1, Steps: 266 | Train Loss: 0.6648821 Vali Loss: 0.8821175 Test Loss: 0.6146943
Validation loss decreased (inf --> 0.882118).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4266842
	speed: 0.1087s/iter; left time: 2851.5989s
	iters: 200, epoch: 2 | loss: 0.4377027
	speed: 0.0208s/iter; left time: 542.9680s
Epoch: 2 cost time: 7.287371873855591
Epoch: 2, Steps: 266 | Train Loss: 0.4673606 Vali Loss: 0.7586612 Test Loss: 0.4902514
Validation loss decreased (0.882118 --> 0.758661).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4796126
	speed: 0.1449s/iter; left time: 3762.0887s
	iters: 200, epoch: 3 | loss: 0.4447230
	speed: 0.0263s/iter; left time: 680.4050s
Epoch: 3 cost time: 7.946165084838867
Epoch: 3, Steps: 266 | Train Loss: 0.4365827 Vali Loss: 0.7204195 Test Loss: 0.4535649
Validation loss decreased (0.758661 --> 0.720419).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4599883
	speed: 0.1015s/iter; left time: 2610.0929s
	iters: 200, epoch: 4 | loss: 0.4491061
	speed: 0.0265s/iter; left time: 677.8961s
Epoch: 4 cost time: 6.110394477844238
Epoch: 4, Steps: 266 | Train Loss: 0.4280802 Vali Loss: 0.7051775 Test Loss: 0.4397143
Validation loss decreased (0.720419 --> 0.705177).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4664779
	speed: 0.1116s/iter; left time: 2839.6416s
	iters: 200, epoch: 5 | loss: 0.4495416
	speed: 0.0279s/iter; left time: 705.8191s
Epoch: 5 cost time: 7.9536988735198975
Epoch: 5, Steps: 266 | Train Loss: 0.4255337 Vali Loss: 0.6993485 Test Loss: 0.4343915
Validation loss decreased (0.705177 --> 0.699349).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4382080
	speed: 0.1124s/iter; left time: 2828.9205s
	iters: 200, epoch: 6 | loss: 0.4488906
	speed: 0.0288s/iter; left time: 722.5639s
Epoch: 6 cost time: 7.418471813201904
Epoch: 6, Steps: 266 | Train Loss: 0.4244035 Vali Loss: 0.6969654 Test Loss: 0.4323047
Validation loss decreased (0.699349 --> 0.696965).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4736613
	speed: 0.1513s/iter; left time: 3769.0278s
	iters: 200, epoch: 7 | loss: 0.4189566
	speed: 0.0390s/iter; left time: 966.6833s
Epoch: 7 cost time: 10.127120733261108
Epoch: 7, Steps: 266 | Train Loss: 0.4238432 Vali Loss: 0.6956891 Test Loss: 0.4313140
Validation loss decreased (0.696965 --> 0.695689).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4543871
	speed: 0.1440s/iter; left time: 3547.6068s
	iters: 200, epoch: 8 | loss: 0.4167643
	speed: 0.0307s/iter; left time: 754.2652s
Epoch: 8 cost time: 8.389681816101074
Epoch: 8, Steps: 266 | Train Loss: 0.4236412 Vali Loss: 0.6944914 Test Loss: 0.4309368
Validation loss decreased (0.695689 --> 0.694491).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4031422
	speed: 0.1178s/iter; left time: 2871.0683s
	iters: 200, epoch: 9 | loss: 0.4325112
	speed: 0.0278s/iter; left time: 674.6502s
Epoch: 9 cost time: 7.913900375366211
Epoch: 9, Steps: 266 | Train Loss: 0.4236995 Vali Loss: 0.6946658 Test Loss: 0.4307570
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4326314
	speed: 0.1110s/iter; left time: 2676.6817s
	iters: 200, epoch: 10 | loss: 0.4060322
	speed: 0.0199s/iter; left time: 478.7816s
Epoch: 10 cost time: 6.23516845703125
Epoch: 10, Steps: 266 | Train Loss: 0.4235305 Vali Loss: 0.6947547 Test Loss: 0.4305780
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4038207
	speed: 0.1235s/iter; left time: 2943.3047s
	iters: 200, epoch: 11 | loss: 0.4344891
	speed: 0.0269s/iter; left time: 639.7895s
Epoch: 11 cost time: 8.329676389694214
Epoch: 11, Steps: 266 | Train Loss: 0.4235381 Vali Loss: 0.6945481 Test Loss: 0.4307881
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4019816
	speed: 0.0963s/iter; left time: 2271.2384s
	iters: 200, epoch: 12 | loss: 0.3808799
	speed: 0.0192s/iter; left time: 450.5509s
Epoch: 12 cost time: 6.013505220413208
Epoch: 12, Steps: 266 | Train Loss: 0.4231855 Vali Loss: 0.6944464 Test Loss: 0.4304106
Validation loss decreased (0.694491 --> 0.694446).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4260032
	speed: 0.0959s/iter; left time: 2234.6358s
	iters: 200, epoch: 13 | loss: 0.4401526
	speed: 0.0230s/iter; left time: 534.7703s
Epoch: 13 cost time: 6.410405397415161
Epoch: 13, Steps: 266 | Train Loss: 0.4233541 Vali Loss: 0.6940870 Test Loss: 0.4305833
Validation loss decreased (0.694446 --> 0.694087).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3924897
	speed: 0.1022s/iter; left time: 2354.1510s
	iters: 200, epoch: 14 | loss: 0.4194300
	speed: 0.0183s/iter; left time: 419.8191s
Epoch: 14 cost time: 5.79315972328186
Epoch: 14, Steps: 266 | Train Loss: 0.4232947 Vali Loss: 0.6936621 Test Loss: 0.4306592
Validation loss decreased (0.694087 --> 0.693662).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4081928
	speed: 0.1403s/iter; left time: 3195.2992s
	iters: 200, epoch: 15 | loss: 0.4020064
	speed: 0.0490s/iter; left time: 1111.8464s
Epoch: 15 cost time: 14.423807621002197
Epoch: 15, Steps: 266 | Train Loss: 0.4234186 Vali Loss: 0.6944246 Test Loss: 0.4303870
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4684468
	speed: 0.1962s/iter; left time: 4415.7074s
	iters: 200, epoch: 16 | loss: 0.3590428
	speed: 0.0282s/iter; left time: 631.0956s
Epoch: 16 cost time: 7.408722162246704
Epoch: 16, Steps: 266 | Train Loss: 0.4233577 Vali Loss: 0.6939155 Test Loss: 0.4305999
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4252959
	speed: 0.1165s/iter; left time: 2592.5846s
	iters: 200, epoch: 17 | loss: 0.4256082
	speed: 0.0207s/iter; left time: 459.4144s
Epoch: 17 cost time: 6.877036809921265
Epoch: 17, Steps: 266 | Train Loss: 0.4233576 Vali Loss: 0.6946346 Test Loss: 0.4306563
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3947969
	speed: 0.1030s/iter; left time: 2264.6252s
	iters: 200, epoch: 18 | loss: 0.4349344
	speed: 0.0187s/iter; left time: 408.7306s
Epoch: 18 cost time: 6.300037384033203
Epoch: 18, Steps: 266 | Train Loss: 0.4232357 Vali Loss: 0.6940262 Test Loss: 0.4307235
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4367552
	speed: 0.1023s/iter; left time: 2220.7946s
	iters: 200, epoch: 19 | loss: 0.4219617
	speed: 0.0197s/iter; left time: 426.2350s
Epoch: 19 cost time: 5.7689549922943115
Epoch: 19, Steps: 266 | Train Loss: 0.4232883 Vali Loss: 0.6946347 Test Loss: 0.4309808
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4354150
	speed: 0.1054s/iter; left time: 2260.1165s
	iters: 200, epoch: 20 | loss: 0.4049287
	speed: 0.0209s/iter; left time: 445.7891s
Epoch: 20 cost time: 6.216145992279053
Epoch: 20, Steps: 266 | Train Loss: 0.4231990 Vali Loss: 0.6948384 Test Loss: 0.4307387
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3952333
	speed: 0.1346s/iter; left time: 2851.5062s
	iters: 200, epoch: 21 | loss: 0.4355502
	speed: 0.0315s/iter; left time: 663.3531s
Epoch: 21 cost time: 8.768177270889282
Epoch: 21, Steps: 266 | Train Loss: 0.4232252 Vali Loss: 0.6945177 Test Loss: 0.4307688
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3820162
	speed: 0.1262s/iter; left time: 2640.0947s
	iters: 200, epoch: 22 | loss: 0.4700644
	speed: 0.0209s/iter; left time: 434.0636s
Epoch: 22 cost time: 6.3966193199157715
Epoch: 22, Steps: 266 | Train Loss: 0.4231525 Vali Loss: 0.6948766 Test Loss: 0.4306896
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4225419
	speed: 0.1381s/iter; left time: 2852.1095s
	iters: 200, epoch: 23 | loss: 0.4268984
	speed: 0.0237s/iter; left time: 486.1736s
Epoch: 23 cost time: 8.296146392822266
Epoch: 23, Steps: 266 | Train Loss: 0.4232785 Vali Loss: 0.6944126 Test Loss: 0.4307312
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4106922
	speed: 0.1454s/iter; left time: 2964.4873s
	iters: 200, epoch: 24 | loss: 0.4590853
	speed: 0.0211s/iter; left time: 427.5212s
Epoch: 24 cost time: 8.535432577133179
Epoch: 24, Steps: 266 | Train Loss: 0.4231825 Vali Loss: 0.6943417 Test Loss: 0.4309281
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4252903
	speed: 0.1037s/iter; left time: 2085.2614s
	iters: 200, epoch: 25 | loss: 0.4503657
	speed: 0.0218s/iter; left time: 437.3618s
Epoch: 25 cost time: 6.337568283081055
Epoch: 25, Steps: 266 | Train Loss: 0.4232485 Vali Loss: 0.6948147 Test Loss: 0.4308184
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4419659
	speed: 0.1378s/iter; left time: 2734.6109s
	iters: 200, epoch: 26 | loss: 0.4418833
	speed: 0.0454s/iter; left time: 897.4276s
Epoch: 26 cost time: 11.769864320755005
Epoch: 26, Steps: 266 | Train Loss: 0.4231052 Vali Loss: 0.6949942 Test Loss: 0.4307608
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4077930
	speed: 0.1483s/iter; left time: 2904.7087s
	iters: 200, epoch: 27 | loss: 0.4258137
	speed: 0.0305s/iter; left time: 593.6962s
Epoch: 27 cost time: 9.708263874053955
Epoch: 27, Steps: 266 | Train Loss: 0.4232308 Vali Loss: 0.6939657 Test Loss: 0.4308338
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4226117
	speed: 0.1837s/iter; left time: 3549.3090s
	iters: 200, epoch: 28 | loss: 0.3997162
	speed: 0.0344s/iter; left time: 661.5866s
Epoch: 28 cost time: 10.525041818618774
Epoch: 28, Steps: 266 | Train Loss: 0.4231956 Vali Loss: 0.6943287 Test Loss: 0.4306561
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4304361
	speed: 0.1337s/iter; left time: 2547.9031s
	iters: 200, epoch: 29 | loss: 0.4285750
	speed: 0.0332s/iter; left time: 629.2203s
Epoch: 29 cost time: 7.851006269454956
Epoch: 29, Steps: 266 | Train Loss: 0.4231546 Vali Loss: 0.6936182 Test Loss: 0.4306526
Validation loss decreased (0.693662 --> 0.693618).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4309143
	speed: 0.1123s/iter; left time: 2109.1903s
	iters: 200, epoch: 30 | loss: 0.3751985
	speed: 0.0232s/iter; left time: 432.6819s
Epoch: 30 cost time: 6.677769660949707
Epoch: 30, Steps: 266 | Train Loss: 0.4232216 Vali Loss: 0.6944132 Test Loss: 0.4304578
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3996904
	speed: 0.1471s/iter; left time: 2724.3371s
	iters: 200, epoch: 31 | loss: 0.4012306
	speed: 0.0373s/iter; left time: 687.8078s
Epoch: 31 cost time: 10.65389347076416
Epoch: 31, Steps: 266 | Train Loss: 0.4231768 Vali Loss: 0.6942019 Test Loss: 0.4306033
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3997454
	speed: 0.2101s/iter; left time: 3835.3735s
	iters: 200, epoch: 32 | loss: 0.4093662
	speed: 0.0337s/iter; left time: 611.6317s
Epoch: 32 cost time: 8.989874124526978
Epoch: 32, Steps: 266 | Train Loss: 0.4231842 Vali Loss: 0.6947328 Test Loss: 0.4308040
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4178222
	speed: 0.1280s/iter; left time: 2301.7487s
	iters: 200, epoch: 33 | loss: 0.3861941
	speed: 0.0405s/iter; left time: 724.7012s
Epoch: 33 cost time: 9.373685359954834
Epoch: 33, Steps: 266 | Train Loss: 0.4230554 Vali Loss: 0.6945704 Test Loss: 0.4308599
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3852831
	speed: 0.1294s/iter; left time: 2294.0836s
	iters: 200, epoch: 34 | loss: 0.4707576
	speed: 0.0199s/iter; left time: 350.9976s
Epoch: 34 cost time: 6.083839416503906
Epoch: 34, Steps: 266 | Train Loss: 0.4230641 Vali Loss: 0.6941305 Test Loss: 0.4307644
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3868304
	speed: 0.0951s/iter; left time: 1659.4926s
	iters: 200, epoch: 35 | loss: 0.4376605
	speed: 0.0222s/iter; left time: 385.6298s
Epoch: 35 cost time: 6.428397178649902
Epoch: 35, Steps: 266 | Train Loss: 0.4230166 Vali Loss: 0.6943136 Test Loss: 0.4307863
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4182912
	speed: 0.1104s/iter; left time: 1897.8166s
	iters: 200, epoch: 36 | loss: 0.4360749
	speed: 0.0302s/iter; left time: 515.5838s
Epoch: 36 cost time: 7.825767755508423
Epoch: 36, Steps: 266 | Train Loss: 0.4230849 Vali Loss: 0.6940743 Test Loss: 0.4307481
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4104103
	speed: 0.1171s/iter; left time: 1981.2104s
	iters: 200, epoch: 37 | loss: 0.4129288
	speed: 0.0320s/iter; left time: 538.8786s
Epoch: 37 cost time: 8.462763786315918
Epoch: 37, Steps: 266 | Train Loss: 0.4230306 Vali Loss: 0.6947628 Test Loss: 0.4308392
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4090244
	speed: 0.1334s/iter; left time: 2221.6066s
	iters: 200, epoch: 38 | loss: 0.4000019
	speed: 0.0238s/iter; left time: 394.9246s
Epoch: 38 cost time: 8.380060195922852
Epoch: 38, Steps: 266 | Train Loss: 0.4232479 Vali Loss: 0.6944578 Test Loss: 0.4308089
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4470327
	speed: 0.1464s/iter; left time: 2399.1754s
	iters: 200, epoch: 39 | loss: 0.4273441
	speed: 0.0549s/iter; left time: 894.8187s
Epoch: 39 cost time: 11.926714181900024
Epoch: 39, Steps: 266 | Train Loss: 0.4231640 Vali Loss: 0.6948783 Test Loss: 0.4307871
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.4269545
	speed: 0.1200s/iter; left time: 1935.6177s
	iters: 200, epoch: 40 | loss: 0.4414163
	speed: 0.0191s/iter; left time: 306.7442s
Epoch: 40 cost time: 5.6873133182525635
Epoch: 40, Steps: 266 | Train Loss: 0.4230664 Vali Loss: 0.6941559 Test Loss: 0.4308232
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.4169434
	speed: 0.0972s/iter; left time: 1542.1409s
	iters: 200, epoch: 41 | loss: 0.4066942
	speed: 0.0198s/iter; left time: 311.4248s
Epoch: 41 cost time: 5.967644929885864
Epoch: 41, Steps: 266 | Train Loss: 0.4231274 Vali Loss: 0.6949298 Test Loss: 0.4308144
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3931272
	speed: 0.1151s/iter; left time: 1794.7455s
	iters: 200, epoch: 42 | loss: 0.3636343
	speed: 0.0227s/iter; left time: 352.0707s
Epoch: 42 cost time: 7.047357797622681
Epoch: 42, Steps: 266 | Train Loss: 0.4230428 Vali Loss: 0.6944917 Test Loss: 0.4308104
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.4019322
	speed: 0.1296s/iter; left time: 1986.0249s
	iters: 200, epoch: 43 | loss: 0.4646234
	speed: 0.0229s/iter; left time: 349.1220s
Epoch: 43 cost time: 7.742504596710205
Epoch: 43, Steps: 266 | Train Loss: 0.4229445 Vali Loss: 0.6948286 Test Loss: 0.4308009
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.4174041
	speed: 0.1664s/iter; left time: 2507.1687s
	iters: 200, epoch: 44 | loss: 0.3774343
	speed: 0.0265s/iter; left time: 396.3998s
Epoch: 44 cost time: 8.895358085632324
Epoch: 44, Steps: 266 | Train Loss: 0.4231487 Vali Loss: 0.6942743 Test Loss: 0.4308222
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.4256282
	speed: 0.1442s/iter; left time: 2134.3129s
	iters: 200, epoch: 45 | loss: 0.3970792
	speed: 0.0300s/iter; left time: 440.6815s
Epoch: 45 cost time: 8.208327054977417
Epoch: 45, Steps: 266 | Train Loss: 0.4230987 Vali Loss: 0.6941491 Test Loss: 0.4308344
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.4520340
	speed: 0.1287s/iter; left time: 1870.7485s
	iters: 200, epoch: 46 | loss: 0.4563364
	speed: 0.0253s/iter; left time: 364.8317s
Epoch: 46 cost time: 8.091688632965088
Epoch: 46, Steps: 266 | Train Loss: 0.4231099 Vali Loss: 0.6942726 Test Loss: 0.4308505
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.3805747
	speed: 0.1239s/iter; left time: 1767.2658s
	iters: 200, epoch: 47 | loss: 0.4306666
	speed: 0.0173s/iter; left time: 245.0232s
Epoch: 47 cost time: 6.208678960800171
Epoch: 47, Steps: 266 | Train Loss: 0.4230516 Vali Loss: 0.6946609 Test Loss: 0.4308360
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.4031619
	speed: 0.1035s/iter; left time: 1448.9760s
	iters: 200, epoch: 48 | loss: 0.3907859
	speed: 0.0301s/iter; left time: 418.7688s
Epoch: 48 cost time: 7.449302673339844
Epoch: 48, Steps: 266 | Train Loss: 0.4229949 Vali Loss: 0.6939957 Test Loss: 0.4308346
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.4274457
	speed: 0.1184s/iter; left time: 1626.1071s
	iters: 200, epoch: 49 | loss: 0.4100586
	speed: 0.0275s/iter; left time: 374.6136s
Epoch: 49 cost time: 6.9495625495910645
Epoch: 49, Steps: 266 | Train Loss: 0.4229090 Vali Loss: 0.6942773 Test Loss: 0.4308115
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_90_336_FITS_ETTm1_ftM_sl90_ll48_pl336_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.4307488203048706, mae:0.4185907542705536, rse:0.6245401501655579, corr:[0.54656214 0.5455176  0.54180145 0.540472   0.5368219  0.5333691
 0.5316324  0.52959317 0.52756524 0.52645147 0.5256151  0.5248725
 0.5242523  0.52286917 0.5200071  0.51677245 0.5139986  0.5110498
 0.5077502  0.50498813 0.50270414 0.49982935 0.4962943  0.4930529
 0.49019802 0.4865558  0.482768   0.4803291  0.47908047 0.4774304
 0.4758952  0.47610325 0.47671732 0.47664642 0.4764615  0.47718075
 0.47764498 0.4772828  0.47676268 0.47675785 0.47687212 0.47617865
 0.47559482 0.4758204  0.47588244 0.47529918 0.47487435 0.47499347
 0.47507587 0.47491497 0.4751819  0.47580698 0.47626227 0.47622222
 0.47652435 0.4771902  0.47775146 0.47791815 0.47783405 0.4778004
 0.47751808 0.47695315 0.47689474 0.47677007 0.47631374 0.47589785
 0.47591865 0.47610694 0.47623053 0.47662115 0.47724113 0.47791058
 0.4783966  0.47879463 0.47964427 0.48045784 0.48113066 0.48188972
 0.48278922 0.4836112  0.4842107  0.48458666 0.48507318 0.4854002
 0.4856679  0.4860741  0.48673066 0.48751268 0.4883018  0.48916605
 0.49015158 0.49108532 0.4917196  0.49196148 0.4919219  0.49166843
 0.4909862  0.4899508  0.48880395 0.48783922 0.48738092 0.48736143
 0.48722515 0.48678428 0.48641986 0.48599002 0.48518404 0.48424852
 0.48360124 0.48301485 0.4820393  0.48083732 0.47988257 0.47908485
 0.47805223 0.4770813  0.47635132 0.47555628 0.47428533 0.47273123
 0.4715218  0.4704868  0.4692377  0.46803182 0.46713492 0.46650642
 0.4658261  0.46509936 0.46482593 0.4649923  0.46497893 0.46466422
 0.46443886 0.46459925 0.46453205 0.46419647 0.4640915  0.46419838
 0.4639529  0.4634927  0.46345973 0.46381938 0.46383953 0.4636093
 0.46367747 0.464062   0.4641834  0.46395513 0.4642243  0.4646982
 0.46480387 0.46491507 0.46530968 0.4657293  0.46569434 0.46557128
 0.46564424 0.4657092  0.4655156  0.46544716 0.4658172  0.46598697
 0.46573442 0.46574    0.4664645  0.46729022 0.46772757 0.46812662
 0.46890464 0.46976906 0.47033346 0.47098786 0.47183377 0.4726184
 0.4730796  0.47355133 0.47420794 0.47476727 0.47500575 0.47527063
 0.47568607 0.47619691 0.47675985 0.4775003  0.4783379  0.47910205
 0.47993273 0.4808294  0.48137    0.4812984  0.48104468 0.48122415
 0.48200214 0.48296514 0.483841   0.48487204 0.48604846 0.48682806
 0.48699474 0.4869895  0.48704678 0.4866458  0.48588502 0.4852017
 0.48441684 0.483059   0.48127276 0.4799033  0.4788522  0.47750887
 0.47592387 0.47480664 0.4740155  0.47264037 0.47071722 0.4691248
 0.46753776 0.46552905 0.4636686  0.462942   0.4625762  0.4615155
 0.46016502 0.45987424 0.46025592 0.46029744 0.46020794 0.4601405
 0.46012706 0.4600352  0.45979908 0.459509   0.4593314  0.45910835
 0.45907325 0.45917755 0.45887765 0.45844808 0.45851183 0.4586703
 0.4586588  0.45838377 0.45854267 0.4592398  0.45950297 0.45945758
 0.45971823 0.4603628  0.46071428 0.46095684 0.461314   0.4618359
 0.46180615 0.46153423 0.46144298 0.46185726 0.46195364 0.46172783
 0.46190524 0.46248627 0.46271068 0.46287936 0.46336088 0.46387297
 0.46441522 0.46498045 0.46573326 0.4665186  0.46723032 0.4679214
 0.46891317 0.46976015 0.47026038 0.47062716 0.47118065 0.47170925
 0.4720583  0.47249305 0.47306946 0.4736841  0.4742221  0.47484955
 0.4756     0.47617427 0.47636065 0.4762633  0.47575465 0.4744189
 0.47205302 0.4695444  0.4677167  0.4664806  0.46568143 0.46546495
 0.4652593  0.46475688 0.46452892 0.46458796 0.46425995 0.46330988
 0.46230915 0.46138296 0.46010524 0.45855203 0.4574063  0.4567373
 0.45614544 0.45529133 0.45465904 0.4543445  0.45372412 0.4524795
 0.45123297 0.45051998 0.44985923 0.4489507  0.44823435 0.44813347
 0.44775638 0.44688255 0.4465288  0.44680643 0.4466117  0.44596007
 0.44580913 0.44626543 0.44613853 0.44557562 0.44547907 0.4453424
 0.44485602 0.44479862 0.4452     0.4445206  0.4441718  0.44666666]
