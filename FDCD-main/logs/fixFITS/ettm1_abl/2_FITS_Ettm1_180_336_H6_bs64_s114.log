Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=22, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_180_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_180_336_FITS_ETTm1_ftM_sl180_ll48_pl336_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34045
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=22, out_features=63, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1241856.0
params:  1449.0
Trainable parameters:  1449
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5794021
	speed: 0.0370s/iter; left time: 975.5814s
	iters: 200, epoch: 1 | loss: 0.4123767
	speed: 0.0212s/iter; left time: 558.3965s
Epoch: 1 cost time: 9.963677406311035
Epoch: 1, Steps: 265 | Train Loss: 0.5442994 Vali Loss: 0.9146453 Test Loss: 0.6004984
Validation loss decreased (inf --> 0.914645).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3067779
	speed: 0.1099s/iter; left time: 2871.1033s
	iters: 200, epoch: 2 | loss: 0.3428198
	speed: 0.0139s/iter; left time: 361.3414s
Epoch: 2 cost time: 4.317594289779663
Epoch: 2, Steps: 265 | Train Loss: 0.3427722 Vali Loss: 0.7845058 Test Loss: 0.4828577
Validation loss decreased (0.914645 --> 0.784506).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2794878
	speed: 0.0711s/iter; left time: 1839.9561s
	iters: 200, epoch: 3 | loss: 0.3085218
	speed: 0.0142s/iter; left time: 365.6794s
Epoch: 3 cost time: 4.264746189117432
Epoch: 3, Steps: 265 | Train Loss: 0.2937404 Vali Loss: 0.7348989 Test Loss: 0.4400841
Validation loss decreased (0.784506 --> 0.734899).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2890373
	speed: 0.0852s/iter; left time: 2180.6437s
	iters: 200, epoch: 4 | loss: 0.2576920
	speed: 0.0168s/iter; left time: 428.0269s
Epoch: 4 cost time: 6.272449493408203
Epoch: 4, Steps: 265 | Train Loss: 0.2750964 Vali Loss: 0.7088805 Test Loss: 0.4177440
Validation loss decreased (0.734899 --> 0.708881).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2365493
	speed: 0.1082s/iter; left time: 2743.0584s
	iters: 200, epoch: 5 | loss: 0.2268492
	speed: 0.0146s/iter; left time: 367.5706s
Epoch: 5 cost time: 4.282994508743286
Epoch: 5, Steps: 265 | Train Loss: 0.2656073 Vali Loss: 0.6945636 Test Loss: 0.4047900
Validation loss decreased (0.708881 --> 0.694564).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2460307
	speed: 0.0726s/iter; left time: 1820.1991s
	iters: 200, epoch: 6 | loss: 0.2451084
	speed: 0.0149s/iter; left time: 371.1990s
Epoch: 6 cost time: 4.381792068481445
Epoch: 6, Steps: 265 | Train Loss: 0.2602580 Vali Loss: 0.6860711 Test Loss: 0.3977548
Validation loss decreased (0.694564 --> 0.686071).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2645166
	speed: 0.0711s/iter; left time: 1764.0949s
	iters: 200, epoch: 7 | loss: 0.2478941
	speed: 0.0143s/iter; left time: 353.2019s
Epoch: 7 cost time: 4.289452791213989
Epoch: 7, Steps: 265 | Train Loss: 0.2572319 Vali Loss: 0.6805388 Test Loss: 0.3937666
Validation loss decreased (0.686071 --> 0.680539).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2725716
	speed: 0.0709s/iter; left time: 1740.3643s
	iters: 200, epoch: 8 | loss: 0.2711357
	speed: 0.0145s/iter; left time: 354.6151s
Epoch: 8 cost time: 4.4435133934021
Epoch: 8, Steps: 265 | Train Loss: 0.2554132 Vali Loss: 0.6772643 Test Loss: 0.3909865
Validation loss decreased (0.680539 --> 0.677264).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2849455
	speed: 0.0714s/iter; left time: 1732.5481s
	iters: 200, epoch: 9 | loss: 0.2550584
	speed: 0.0163s/iter; left time: 393.5045s
Epoch: 9 cost time: 4.503254652023315
Epoch: 9, Steps: 265 | Train Loss: 0.2544778 Vali Loss: 0.6756499 Test Loss: 0.3897584
Validation loss decreased (0.677264 --> 0.675650).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2305062
	speed: 0.0678s/iter; left time: 1628.8722s
	iters: 200, epoch: 10 | loss: 0.2576333
	speed: 0.0140s/iter; left time: 335.3619s
Epoch: 10 cost time: 4.262665748596191
Epoch: 10, Steps: 265 | Train Loss: 0.2539731 Vali Loss: 0.6744245 Test Loss: 0.3890456
Validation loss decreased (0.675650 --> 0.674424).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2547470
	speed: 0.0709s/iter; left time: 1683.7055s
	iters: 200, epoch: 11 | loss: 0.2777470
	speed: 0.0142s/iter; left time: 336.8567s
Epoch: 11 cost time: 4.208200693130493
Epoch: 11, Steps: 265 | Train Loss: 0.2536132 Vali Loss: 0.6736583 Test Loss: 0.3889742
Validation loss decreased (0.674424 --> 0.673658).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2533755
	speed: 0.0709s/iter; left time: 1665.9040s
	iters: 200, epoch: 12 | loss: 0.2495865
	speed: 0.0139s/iter; left time: 324.3203s
Epoch: 12 cost time: 4.421706199645996
Epoch: 12, Steps: 265 | Train Loss: 0.2536738 Vali Loss: 0.6738600 Test Loss: 0.3885516
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2418212
	speed: 0.0809s/iter; left time: 1878.9453s
	iters: 200, epoch: 13 | loss: 0.2903861
	speed: 0.0145s/iter; left time: 335.9435s
Epoch: 13 cost time: 4.1246421337127686
Epoch: 13, Steps: 265 | Train Loss: 0.2535590 Vali Loss: 0.6740834 Test Loss: 0.3882784
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2531428
	speed: 0.0713s/iter; left time: 1637.2740s
	iters: 200, epoch: 14 | loss: 0.2681802
	speed: 0.0142s/iter; left time: 324.0725s
Epoch: 14 cost time: 4.387484788894653
Epoch: 14, Steps: 265 | Train Loss: 0.2534490 Vali Loss: 0.6740140 Test Loss: 0.3880944
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2517968
	speed: 0.0690s/iter; left time: 1564.9382s
	iters: 200, epoch: 15 | loss: 0.2769516
	speed: 0.0135s/iter; left time: 306.0633s
Epoch: 15 cost time: 4.412832736968994
Epoch: 15, Steps: 265 | Train Loss: 0.2535550 Vali Loss: 0.6731811 Test Loss: 0.3882178
Validation loss decreased (0.673658 --> 0.673181).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2423165
	speed: 0.0727s/iter; left time: 1629.2816s
	iters: 200, epoch: 16 | loss: 0.2290730
	speed: 0.0137s/iter; left time: 305.0570s
Epoch: 16 cost time: 4.2897889614105225
Epoch: 16, Steps: 265 | Train Loss: 0.2534758 Vali Loss: 0.6732054 Test Loss: 0.3880588
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2409789
	speed: 0.0718s/iter; left time: 1590.7051s
	iters: 200, epoch: 17 | loss: 0.2490800
	speed: 0.0143s/iter; left time: 316.0933s
Epoch: 17 cost time: 4.498223304748535
Epoch: 17, Steps: 265 | Train Loss: 0.2534220 Vali Loss: 0.6732979 Test Loss: 0.3880594
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2357860
	speed: 0.0711s/iter; left time: 1557.0389s
	iters: 200, epoch: 18 | loss: 0.2570721
	speed: 0.0141s/iter; left time: 307.5766s
Epoch: 18 cost time: 4.2557737827301025
Epoch: 18, Steps: 265 | Train Loss: 0.2535184 Vali Loss: 0.6729155 Test Loss: 0.3882232
Validation loss decreased (0.673181 --> 0.672916).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2575814
	speed: 0.0715s/iter; left time: 1547.5138s
	iters: 200, epoch: 19 | loss: 0.2875303
	speed: 0.0153s/iter; left time: 329.4608s
Epoch: 19 cost time: 4.4509382247924805
Epoch: 19, Steps: 265 | Train Loss: 0.2535509 Vali Loss: 0.6724924 Test Loss: 0.3883651
Validation loss decreased (0.672916 --> 0.672492).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2771309
	speed: 0.0696s/iter; left time: 1486.1643s
	iters: 200, epoch: 20 | loss: 0.2841318
	speed: 0.0141s/iter; left time: 300.6283s
Epoch: 20 cost time: 4.167378187179565
Epoch: 20, Steps: 265 | Train Loss: 0.2534724 Vali Loss: 0.6738240 Test Loss: 0.3881616
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2466936
	speed: 0.0701s/iter; left time: 1479.3190s
	iters: 200, epoch: 21 | loss: 0.2559348
	speed: 0.0158s/iter; left time: 331.4131s
Epoch: 21 cost time: 4.587829828262329
Epoch: 21, Steps: 265 | Train Loss: 0.2535138 Vali Loss: 0.6733524 Test Loss: 0.3881719
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2555377
	speed: 0.0733s/iter; left time: 1527.1525s
	iters: 200, epoch: 22 | loss: 0.2397146
	speed: 0.0142s/iter; left time: 295.3109s
Epoch: 22 cost time: 4.2820446491241455
Epoch: 22, Steps: 265 | Train Loss: 0.2534907 Vali Loss: 0.6729510 Test Loss: 0.3881589
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2647736
	speed: 0.0726s/iter; left time: 1493.1055s
	iters: 200, epoch: 23 | loss: 0.2588958
	speed: 0.0151s/iter; left time: 309.5597s
Epoch: 23 cost time: 4.644700050354004
Epoch: 23, Steps: 265 | Train Loss: 0.2535538 Vali Loss: 0.6735451 Test Loss: 0.3881644
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2655663
	speed: 0.0712s/iter; left time: 1445.2071s
	iters: 200, epoch: 24 | loss: 0.2735634
	speed: 0.0142s/iter; left time: 286.1084s
Epoch: 24 cost time: 4.341642379760742
Epoch: 24, Steps: 265 | Train Loss: 0.2534849 Vali Loss: 0.6725988 Test Loss: 0.3881224
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2607646
	speed: 0.0677s/iter; left time: 1357.2826s
	iters: 200, epoch: 25 | loss: 0.2373561
	speed: 0.0146s/iter; left time: 291.3244s
Epoch: 25 cost time: 4.41760778427124
Epoch: 25, Steps: 265 | Train Loss: 0.2534940 Vali Loss: 0.6728252 Test Loss: 0.3882192
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2537806
	speed: 0.0733s/iter; left time: 1449.7652s
	iters: 200, epoch: 26 | loss: 0.2456237
	speed: 0.0151s/iter; left time: 296.4802s
Epoch: 26 cost time: 4.406634569168091
Epoch: 26, Steps: 265 | Train Loss: 0.2534124 Vali Loss: 0.6730859 Test Loss: 0.3882224
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2583595
	speed: 0.0709s/iter; left time: 1383.5046s
	iters: 200, epoch: 27 | loss: 0.2473701
	speed: 0.0144s/iter; left time: 279.1903s
Epoch: 27 cost time: 4.344876050949097
Epoch: 27, Steps: 265 | Train Loss: 0.2534949 Vali Loss: 0.6735526 Test Loss: 0.3882765
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2710611
	speed: 0.0703s/iter; left time: 1352.1705s
	iters: 200, epoch: 28 | loss: 0.2589005
	speed: 0.0142s/iter; left time: 272.5793s
Epoch: 28 cost time: 4.23508620262146
Epoch: 28, Steps: 265 | Train Loss: 0.2535484 Vali Loss: 0.6731345 Test Loss: 0.3882653
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2760007
	speed: 0.0711s/iter; left time: 1349.8633s
	iters: 200, epoch: 29 | loss: 0.2282520
	speed: 0.0150s/iter; left time: 283.2959s
Epoch: 29 cost time: 4.457052707672119
Epoch: 29, Steps: 265 | Train Loss: 0.2535095 Vali Loss: 0.6722208 Test Loss: 0.3882060
Validation loss decreased (0.672492 --> 0.672221).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2497725
	speed: 0.0684s/iter; left time: 1280.4634s
	iters: 200, epoch: 30 | loss: 0.2359651
	speed: 0.0151s/iter; left time: 281.4209s
Epoch: 30 cost time: 4.307119846343994
Epoch: 30, Steps: 265 | Train Loss: 0.2535161 Vali Loss: 0.6731853 Test Loss: 0.3881907
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2650684
	speed: 0.0720s/iter; left time: 1328.1581s
	iters: 200, epoch: 31 | loss: 0.2288953
	speed: 0.0142s/iter; left time: 261.0818s
Epoch: 31 cost time: 5.779039621353149
Epoch: 31, Steps: 265 | Train Loss: 0.2534733 Vali Loss: 0.6727345 Test Loss: 0.3881846
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2474876
	speed: 0.1174s/iter; left time: 2135.1686s
	iters: 200, epoch: 32 | loss: 0.2309183
	speed: 0.0139s/iter; left time: 251.1351s
Epoch: 32 cost time: 4.252853870391846
Epoch: 32, Steps: 265 | Train Loss: 0.2534351 Vali Loss: 0.6730399 Test Loss: 0.3881755
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2377406
	speed: 0.1242s/iter; left time: 2225.4407s
	iters: 200, epoch: 33 | loss: 0.2687335
	speed: 0.0162s/iter; left time: 288.0786s
Epoch: 33 cost time: 8.195422410964966
Epoch: 33, Steps: 265 | Train Loss: 0.2535565 Vali Loss: 0.6730885 Test Loss: 0.3882066
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2484536
	speed: 0.0763s/iter; left time: 1347.1996s
	iters: 200, epoch: 34 | loss: 0.2883890
	speed: 0.0141s/iter; left time: 247.0849s
Epoch: 34 cost time: 4.388226509094238
Epoch: 34, Steps: 265 | Train Loss: 0.2534386 Vali Loss: 0.6733559 Test Loss: 0.3882916
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2596018
	speed: 0.0722s/iter; left time: 1254.9856s
	iters: 200, epoch: 35 | loss: 0.2803266
	speed: 0.0143s/iter; left time: 247.6233s
Epoch: 35 cost time: 4.374178171157837
Epoch: 35, Steps: 265 | Train Loss: 0.2534506 Vali Loss: 0.6728114 Test Loss: 0.3881761
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2598669
	speed: 0.0717s/iter; left time: 1228.6639s
	iters: 200, epoch: 36 | loss: 0.2371164
	speed: 0.0142s/iter; left time: 241.3151s
Epoch: 36 cost time: 4.2514684200286865
Epoch: 36, Steps: 265 | Train Loss: 0.2534204 Vali Loss: 0.6731080 Test Loss: 0.3881585
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3277004
	speed: 0.0711s/iter; left time: 1199.3761s
	iters: 200, epoch: 37 | loss: 0.2244938
	speed: 0.0155s/iter; left time: 259.4812s
Epoch: 37 cost time: 4.513655424118042
Epoch: 37, Steps: 265 | Train Loss: 0.2535206 Vali Loss: 0.6726233 Test Loss: 0.3882031
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2686819
	speed: 0.0706s/iter; left time: 1170.9345s
	iters: 200, epoch: 38 | loss: 0.2372400
	speed: 0.0143s/iter; left time: 235.7476s
Epoch: 38 cost time: 6.081318140029907
Epoch: 38, Steps: 265 | Train Loss: 0.2534272 Vali Loss: 0.6731902 Test Loss: 0.3882132
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2646167
	speed: 0.1250s/iter; left time: 2041.4876s
	iters: 200, epoch: 39 | loss: 0.2288908
	speed: 0.0141s/iter; left time: 228.9038s
Epoch: 39 cost time: 4.304537773132324
Epoch: 39, Steps: 265 | Train Loss: 0.2534834 Vali Loss: 0.6730580 Test Loss: 0.3881844
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2272397
	speed: 0.0701s/iter; left time: 1125.9899s
	iters: 200, epoch: 40 | loss: 0.2298137
	speed: 0.0339s/iter; left time: 540.9803s
Epoch: 40 cost time: 9.312530040740967
Epoch: 40, Steps: 265 | Train Loss: 0.2534577 Vali Loss: 0.6729852 Test Loss: 0.3882090
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2344158
	speed: 0.1200s/iter; left time: 1896.6692s
	iters: 200, epoch: 41 | loss: 0.2400496
	speed: 0.0145s/iter; left time: 228.3008s
Epoch: 41 cost time: 4.464458227157593
Epoch: 41, Steps: 265 | Train Loss: 0.2534318 Vali Loss: 0.6724744 Test Loss: 0.3882290
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2414119
	speed: 0.0714s/iter; left time: 1109.1782s
	iters: 200, epoch: 42 | loss: 0.2501263
	speed: 0.0144s/iter; left time: 222.5648s
Epoch: 42 cost time: 4.2665581703186035
Epoch: 42, Steps: 265 | Train Loss: 0.2534322 Vali Loss: 0.6735339 Test Loss: 0.3882353
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2763954
	speed: 0.0723s/iter; left time: 1103.7992s
	iters: 200, epoch: 43 | loss: 0.2275428
	speed: 0.0145s/iter; left time: 219.6128s
Epoch: 43 cost time: 4.604217052459717
Epoch: 43, Steps: 265 | Train Loss: 0.2535904 Vali Loss: 0.6734412 Test Loss: 0.3882522
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2408748
	speed: 0.0687s/iter; left time: 1031.2539s
	iters: 200, epoch: 44 | loss: 0.2744716
	speed: 0.0155s/iter; left time: 230.7691s
Epoch: 44 cost time: 4.484034538269043
Epoch: 44, Steps: 265 | Train Loss: 0.2534640 Vali Loss: 0.6738128 Test Loss: 0.3882251
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2620983
	speed: 0.0659s/iter; left time: 971.9715s
	iters: 200, epoch: 45 | loss: 0.2506280
	speed: 0.0137s/iter; left time: 200.6513s
Epoch: 45 cost time: 4.20618748664856
Epoch: 45, Steps: 265 | Train Loss: 0.2534283 Vali Loss: 0.6733575 Test Loss: 0.3882291
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2781906
	speed: 0.0705s/iter; left time: 1021.1793s
	iters: 200, epoch: 46 | loss: 0.2363162
	speed: 0.0143s/iter; left time: 205.6660s
Epoch: 46 cost time: 4.211227655410767
Epoch: 46, Steps: 265 | Train Loss: 0.2533660 Vali Loss: 0.6730918 Test Loss: 0.3882708
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2568366
	speed: 0.0875s/iter; left time: 1242.9704s
	iters: 200, epoch: 47 | loss: 0.2711414
	speed: 0.0192s/iter; left time: 270.7505s
Epoch: 47 cost time: 8.518650770187378
Epoch: 47, Steps: 265 | Train Loss: 0.2534283 Vali Loss: 0.6734328 Test Loss: 0.3881913
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2724707
	speed: 0.1133s/iter; left time: 1579.7502s
	iters: 200, epoch: 48 | loss: 0.2719229
	speed: 0.0147s/iter; left time: 203.9395s
Epoch: 48 cost time: 4.465849876403809
Epoch: 48, Steps: 265 | Train Loss: 0.2534433 Vali Loss: 0.6728022 Test Loss: 0.3882610
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2263671
	speed: 0.0707s/iter; left time: 967.5906s
	iters: 200, epoch: 49 | loss: 0.2314043
	speed: 0.0137s/iter; left time: 185.4874s
Epoch: 49 cost time: 4.246855735778809
Epoch: 49, Steps: 265 | Train Loss: 0.2534875 Vali Loss: 0.6728230 Test Loss: 0.3882097
EarlyStopping counter: 20 out of 20
Early stopping
train 34045
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=22, out_features=63, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1241856.0
params:  1449.0
Trainable parameters:  1449
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3750020
	speed: 0.0208s/iter; left time: 550.2442s
	iters: 200, epoch: 1 | loss: 0.3626054
	speed: 0.0145s/iter; left time: 382.0507s
Epoch: 1 cost time: 4.5147576332092285
Epoch: 1, Steps: 265 | Train Loss: 0.3756143 Vali Loss: 0.6690224 Test Loss: 0.3855023
Validation loss decreased (inf --> 0.669022).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3830098
	speed: 0.0723s/iter; left time: 1888.8015s
	iters: 200, epoch: 2 | loss: 0.4012094
	speed: 0.0145s/iter; left time: 377.7956s
Epoch: 2 cost time: 4.402640104293823
Epoch: 2, Steps: 265 | Train Loss: 0.3748730 Vali Loss: 0.6680915 Test Loss: 0.3849072
Validation loss decreased (0.669022 --> 0.668092).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3707476
	speed: 0.0876s/iter; left time: 2265.3474s
	iters: 200, epoch: 3 | loss: 0.3720792
	speed: 0.0169s/iter; left time: 435.0237s
Epoch: 3 cost time: 6.385514259338379
Epoch: 3, Steps: 265 | Train Loss: 0.3746256 Vali Loss: 0.6680355 Test Loss: 0.3846336
Validation loss decreased (0.668092 --> 0.668036).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3656839
	speed: 0.1162s/iter; left time: 2974.6307s
	iters: 200, epoch: 4 | loss: 0.3436532
	speed: 0.0156s/iter; left time: 398.7516s
Epoch: 4 cost time: 4.723963975906372
Epoch: 4, Steps: 265 | Train Loss: 0.3746100 Vali Loss: 0.6680809 Test Loss: 0.3847814
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3730626
	speed: 0.0747s/iter; left time: 1892.5367s
	iters: 200, epoch: 5 | loss: 0.3694776
	speed: 0.0154s/iter; left time: 389.4943s
Epoch: 5 cost time: 4.683717966079712
Epoch: 5, Steps: 265 | Train Loss: 0.3745397 Vali Loss: 0.6670163 Test Loss: 0.3843350
Validation loss decreased (0.668036 --> 0.667016).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3580989
	speed: 0.0730s/iter; left time: 1831.5898s
	iters: 200, epoch: 6 | loss: 0.3850759
	speed: 0.0161s/iter; left time: 401.7521s
Epoch: 6 cost time: 4.695568799972534
Epoch: 6, Steps: 265 | Train Loss: 0.3745340 Vali Loss: 0.6675916 Test Loss: 0.3847554
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3780380
	speed: 0.0726s/iter; left time: 1802.3884s
	iters: 200, epoch: 7 | loss: 0.3760995
	speed: 0.0142s/iter; left time: 351.5550s
Epoch: 7 cost time: 4.340346813201904
Epoch: 7, Steps: 265 | Train Loss: 0.3745164 Vali Loss: 0.6669854 Test Loss: 0.3847152
Validation loss decreased (0.667016 --> 0.666985).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3664983
	speed: 0.0692s/iter; left time: 1699.0339s
	iters: 200, epoch: 8 | loss: 0.3786879
	speed: 0.0139s/iter; left time: 339.2969s
Epoch: 8 cost time: 4.066467761993408
Epoch: 8, Steps: 265 | Train Loss: 0.3744704 Vali Loss: 0.6671981 Test Loss: 0.3843913
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3559308
	speed: 0.0751s/iter; left time: 1824.4743s
	iters: 200, epoch: 9 | loss: 0.3866777
	speed: 0.0156s/iter; left time: 377.6558s
Epoch: 9 cost time: 4.87739109992981
Epoch: 9, Steps: 265 | Train Loss: 0.3743306 Vali Loss: 0.6668683 Test Loss: 0.3842260
Validation loss decreased (0.666985 --> 0.666868).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4088976
	speed: 0.0734s/iter; left time: 1763.6871s
	iters: 200, epoch: 10 | loss: 0.4048119
	speed: 0.0142s/iter; left time: 339.2184s
Epoch: 10 cost time: 4.341174125671387
Epoch: 10, Steps: 265 | Train Loss: 0.3744133 Vali Loss: 0.6658105 Test Loss: 0.3842187
Validation loss decreased (0.666868 --> 0.665810).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3861059
	speed: 0.0728s/iter; left time: 1730.2415s
	iters: 200, epoch: 11 | loss: 0.3419531
	speed: 0.0147s/iter; left time: 347.7378s
Epoch: 11 cost time: 4.520079135894775
Epoch: 11, Steps: 265 | Train Loss: 0.3744967 Vali Loss: 0.6664622 Test Loss: 0.3844049
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3859288
	speed: 0.0713s/iter; left time: 1674.7378s
	iters: 200, epoch: 12 | loss: 0.3527744
	speed: 0.0155s/iter; left time: 362.6283s
Epoch: 12 cost time: 4.664660692214966
Epoch: 12, Steps: 265 | Train Loss: 0.3742188 Vali Loss: 0.6669940 Test Loss: 0.3843923
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3793298
	speed: 0.0733s/iter; left time: 1702.3909s
	iters: 200, epoch: 13 | loss: 0.4105321
	speed: 0.0155s/iter; left time: 359.0814s
Epoch: 13 cost time: 4.591320514678955
Epoch: 13, Steps: 265 | Train Loss: 0.3743305 Vali Loss: 0.6671102 Test Loss: 0.3844827
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3273937
	speed: 0.0730s/iter; left time: 1674.7566s
	iters: 200, epoch: 14 | loss: 0.3470194
	speed: 0.0145s/iter; left time: 330.9969s
Epoch: 14 cost time: 4.392293214797974
Epoch: 14, Steps: 265 | Train Loss: 0.3744139 Vali Loss: 0.6669370 Test Loss: 0.3843721
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3672427
	speed: 0.0687s/iter; left time: 1558.9154s
	iters: 200, epoch: 15 | loss: 0.3513067
	speed: 0.0143s/iter; left time: 323.9636s
Epoch: 15 cost time: 4.218872308731079
Epoch: 15, Steps: 265 | Train Loss: 0.3742880 Vali Loss: 0.6672822 Test Loss: 0.3845451
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3588084
	speed: 0.0714s/iter; left time: 1601.2520s
	iters: 200, epoch: 16 | loss: 0.3849937
	speed: 0.0142s/iter; left time: 317.8411s
Epoch: 16 cost time: 4.296878099441528
Epoch: 16, Steps: 265 | Train Loss: 0.3741565 Vali Loss: 0.6678265 Test Loss: 0.3843462
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4104175
	speed: 0.0718s/iter; left time: 1591.5914s
	iters: 200, epoch: 17 | loss: 0.3724198
	speed: 0.0145s/iter; left time: 320.7320s
Epoch: 17 cost time: 4.384519100189209
Epoch: 17, Steps: 265 | Train Loss: 0.3743430 Vali Loss: 0.6673447 Test Loss: 0.3844740
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3559071
	speed: 0.0722s/iter; left time: 1580.2932s
	iters: 200, epoch: 18 | loss: 0.3846578
	speed: 0.0146s/iter; left time: 317.1615s
Epoch: 18 cost time: 4.3633949756622314
Epoch: 18, Steps: 265 | Train Loss: 0.3742296 Vali Loss: 0.6666108 Test Loss: 0.3844570
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3865817
	speed: 0.0709s/iter; left time: 1534.3640s
	iters: 200, epoch: 19 | loss: 0.3387187
	speed: 0.0139s/iter; left time: 300.3542s
Epoch: 19 cost time: 4.292163610458374
Epoch: 19, Steps: 265 | Train Loss: 0.3743119 Vali Loss: 0.6674048 Test Loss: 0.3844169
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3663126
	speed: 0.0710s/iter; left time: 1517.0920s
	iters: 200, epoch: 20 | loss: 0.3827503
	speed: 0.0142s/iter; left time: 302.6294s
Epoch: 20 cost time: 5.027729511260986
Epoch: 20, Steps: 265 | Train Loss: 0.3741282 Vali Loss: 0.6659446 Test Loss: 0.3843936
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3822117
	speed: 0.0811s/iter; left time: 1712.0787s
	iters: 200, epoch: 21 | loss: 0.3931409
	speed: 0.0148s/iter; left time: 311.0762s
Epoch: 21 cost time: 4.677128076553345
Epoch: 21, Steps: 265 | Train Loss: 0.3744039 Vali Loss: 0.6675338 Test Loss: 0.3844584
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3304857
	speed: 0.0713s/iter; left time: 1484.9400s
	iters: 200, epoch: 22 | loss: 0.3595107
	speed: 0.0146s/iter; left time: 302.8720s
Epoch: 22 cost time: 4.289418697357178
Epoch: 22, Steps: 265 | Train Loss: 0.3742599 Vali Loss: 0.6666161 Test Loss: 0.3843117
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3878519
	speed: 0.0712s/iter; left time: 1464.8595s
	iters: 200, epoch: 23 | loss: 0.3725823
	speed: 0.0139s/iter; left time: 283.5477s
Epoch: 23 cost time: 4.12708044052124
Epoch: 23, Steps: 265 | Train Loss: 0.3741794 Vali Loss: 0.6667855 Test Loss: 0.3844503
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3514152
	speed: 0.0696s/iter; left time: 1412.4443s
	iters: 200, epoch: 24 | loss: 0.3758203
	speed: 0.0154s/iter; left time: 312.0320s
Epoch: 24 cost time: 4.551509857177734
Epoch: 24, Steps: 265 | Train Loss: 0.3741393 Vali Loss: 0.6669214 Test Loss: 0.3845048
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3483977
	speed: 0.0715s/iter; left time: 1433.5985s
	iters: 200, epoch: 25 | loss: 0.3553942
	speed: 0.0153s/iter; left time: 304.3312s
Epoch: 25 cost time: 4.41471529006958
Epoch: 25, Steps: 265 | Train Loss: 0.3741449 Vali Loss: 0.6671198 Test Loss: 0.3844851
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3873945
	speed: 0.0693s/iter; left time: 1369.7292s
	iters: 200, epoch: 26 | loss: 0.3864905
	speed: 0.0144s/iter; left time: 283.9019s
Epoch: 26 cost time: 4.3973143100738525
Epoch: 26, Steps: 265 | Train Loss: 0.3744324 Vali Loss: 0.6668767 Test Loss: 0.3843474
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3803003
	speed: 0.0722s/iter; left time: 1409.0497s
	iters: 200, epoch: 27 | loss: 0.3652754
	speed: 0.0137s/iter; left time: 265.9688s
Epoch: 27 cost time: 4.272641181945801
Epoch: 27, Steps: 265 | Train Loss: 0.3742372 Vali Loss: 0.6675254 Test Loss: 0.3844474
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3697570
	speed: 0.0747s/iter; left time: 1438.2278s
	iters: 200, epoch: 28 | loss: 0.3999289
	speed: 0.0158s/iter; left time: 303.4275s
Epoch: 28 cost time: 4.758248805999756
Epoch: 28, Steps: 265 | Train Loss: 0.3741339 Vali Loss: 0.6666791 Test Loss: 0.3843851
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4074439
	speed: 0.0737s/iter; left time: 1398.5844s
	iters: 200, epoch: 29 | loss: 0.3777458
	speed: 0.0138s/iter; left time: 260.9946s
Epoch: 29 cost time: 4.3435304164886475
Epoch: 29, Steps: 265 | Train Loss: 0.3741082 Vali Loss: 0.6668873 Test Loss: 0.3843264
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3318479
	speed: 0.0721s/iter; left time: 1349.2807s
	iters: 200, epoch: 30 | loss: 0.3895614
	speed: 0.0145s/iter; left time: 270.7266s
Epoch: 30 cost time: 4.441839694976807
Epoch: 30, Steps: 265 | Train Loss: 0.3741136 Vali Loss: 0.6671597 Test Loss: 0.3844292
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_180_336_FITS_ETTm1_ftM_sl180_ll48_pl336_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.38421571254730225, mae:0.3902103304862976, rse:0.5898422598838806, corr:[0.5431701  0.5478708  0.54852873 0.54650456 0.5439382  0.5424074
 0.5421195  0.5427416  0.54341596 0.5438861  0.5442058  0.5440378
 0.5434188  0.54198366 0.5398287  0.5374597  0.53524894 0.53336495
 0.53170586 0.5300573  0.5282784  0.5262461  0.5240005  0.521697
 0.519415   0.5172664  0.5154544  0.5140371  0.51313406 0.51277375
 0.51300883 0.5135486  0.51396513 0.51409245 0.51390034 0.5135783
 0.5132263  0.51291066 0.51273715 0.5125589  0.5123742  0.51208454
 0.51174825 0.51152563 0.5114734  0.5116149  0.5119273  0.5122931
 0.51259494 0.51271266 0.5127062  0.5126895  0.5127462  0.5128475
 0.5129482  0.51296705 0.51296693 0.5128642  0.5127042  0.5124843
 0.5123026  0.51220834 0.51215523 0.5121082  0.5120411  0.5120481
 0.5121027  0.51216906 0.51233697 0.512595   0.51291925 0.51323
 0.5134535  0.51353055 0.51352483 0.513393   0.5132211  0.5130518
 0.5129193  0.51283497 0.5128409  0.51289684 0.5129471  0.5128383
 0.51254743 0.5121799  0.51183337 0.51149994 0.5111978  0.5110536
 0.5110442  0.5110776  0.51101834 0.5108069  0.5103661  0.5096023
 0.5085904  0.5075158  0.50650764 0.5056406  0.5050901  0.50495887
 0.5052046  0.50574166 0.506529   0.50752985 0.50867665 0.5098715
 0.510954   0.5117321  0.5121172  0.5122986  0.5122675  0.5121175
 0.511871   0.5116409  0.51136446 0.51100445 0.51063234 0.51026803
 0.5099735  0.50961447 0.50911856 0.5085586  0.50793827 0.5072982
 0.5067673  0.5064276  0.5062528  0.5061776  0.5060942  0.5059003
 0.50558776 0.5052979  0.50505066 0.50479156 0.504631   0.5044983
 0.504346   0.5042449  0.5041812  0.50418085 0.5042593  0.50441456
 0.5045849  0.5047326  0.5047377  0.5046817  0.5047351  0.504753
 0.50477    0.5048238  0.5048632  0.50488794 0.50478363 0.50464463
 0.50451434 0.5044719  0.5044768  0.5045745  0.5047342  0.50495195
 0.5052241  0.5055327  0.50581944 0.5061552  0.5064799  0.5067615
 0.5070055  0.5071389  0.50711405 0.5070539  0.50693816 0.5067798
 0.50665224 0.5065569  0.5065243  0.50654805 0.50652367 0.5064647
 0.50636494 0.5062644  0.5061798  0.5061541  0.50619656 0.5062835
 0.5063956  0.5065176  0.5066614  0.50685066 0.50703526 0.50715977
 0.5071217  0.50698483 0.50671047 0.5061318  0.5053927  0.504751
 0.5043043  0.5040204  0.5038566  0.503958   0.50405973 0.5039947
 0.50376135 0.5032176  0.5025598  0.5019876  0.50149125 0.5010733
 0.50068486 0.50033015 0.49993247 0.49939525 0.49870822 0.49794653
 0.4971682  0.49637824 0.4956452  0.49505022 0.49460733 0.4943488
 0.49427176 0.4943676  0.49448717 0.49456882 0.4945866  0.49445564
 0.49414957 0.4938156  0.49345583 0.49308452 0.492766   0.49255154
 0.49246112 0.4925024  0.4925309  0.4926102  0.49272242 0.4927904
 0.49289262 0.49292907 0.492965   0.49298254 0.49300134 0.4930343
 0.49310267 0.4931372  0.4931848  0.49324787 0.4932772  0.49323168
 0.49313453 0.49307474 0.49298906 0.49290797 0.49281642 0.49274716
 0.4928113  0.49301508 0.49329004 0.49357367 0.49378875 0.4939697
 0.49417296 0.49434176 0.49452472 0.4947522  0.4950141  0.49519724
 0.49531284 0.4953299  0.49534252 0.4953876  0.49551663 0.49569812
 0.49590364 0.49614403 0.4963172  0.4963753  0.4963378  0.49623755
 0.49614677 0.49604315 0.49592048 0.4957066  0.49530834 0.49470302
 0.49384573 0.49294397 0.4922024  0.49160105 0.49120036 0.49098969
 0.49103758 0.49118695 0.49143863 0.49174133 0.49201652 0.49226987
 0.49245092 0.4924482  0.49241617 0.49243662 0.4924794  0.4924453
 0.49233204 0.49209985 0.49175432 0.4913827  0.49106142 0.49081358
 0.49057803 0.49021795 0.4897606  0.48933083 0.48886204 0.48851344
 0.4883404  0.4882158  0.4880614  0.48786443 0.4874658  0.48691368
 0.48632053 0.48586345 0.48561206 0.4855605  0.48552263 0.48529598
 0.48481512 0.48431247 0.48419368 0.4849081  0.4864929  0.487932  ]
