Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=58, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_360_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_360_192_FITS_ETTm1_ftM_sl360_ll48_pl192_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34009
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=58, out_features=88, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4573184.0
params:  5192.0
Trainable parameters:  5192
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3759787
	speed: 0.0268s/iter; left time: 707.7275s
	iters: 200, epoch: 1 | loss: 0.2878105
	speed: 0.0212s/iter; left time: 558.2891s
Epoch: 1 cost time: 6.7668986320495605
Epoch: 1, Steps: 265 | Train Loss: 0.4031165 Vali Loss: 0.5712161 Test Loss: 0.3559349
Validation loss decreased (inf --> 0.571216).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3393202
	speed: 0.1072s/iter; left time: 2802.0574s
	iters: 200, epoch: 2 | loss: 0.3001978
	speed: 0.0253s/iter; left time: 657.9140s
Epoch: 2 cost time: 6.39153790473938
Epoch: 2, Steps: 265 | Train Loss: 0.3215606 Vali Loss: 0.5351046 Test Loss: 0.3409659
Validation loss decreased (0.571216 --> 0.535105).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3355519
	speed: 0.1030s/iter; left time: 2663.8248s
	iters: 200, epoch: 3 | loss: 0.3222431
	speed: 0.0239s/iter; left time: 616.4290s
Epoch: 3 cost time: 6.368458032608032
Epoch: 3, Steps: 265 | Train Loss: 0.3132265 Vali Loss: 0.5242221 Test Loss: 0.3374608
Validation loss decreased (0.535105 --> 0.524222).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3025213
	speed: 0.1055s/iter; left time: 2701.6523s
	iters: 200, epoch: 4 | loss: 0.3259585
	speed: 0.0226s/iter; left time: 576.2735s
Epoch: 4 cost time: 6.642115831375122
Epoch: 4, Steps: 265 | Train Loss: 0.3101787 Vali Loss: 0.5183615 Test Loss: 0.3368469
Validation loss decreased (0.524222 --> 0.518362).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3022508
	speed: 0.1072s/iter; left time: 2715.3968s
	iters: 200, epoch: 5 | loss: 0.3013207
	speed: 0.0303s/iter; left time: 765.9839s
Epoch: 5 cost time: 7.0649895668029785
Epoch: 5, Steps: 265 | Train Loss: 0.3089464 Vali Loss: 0.5171146 Test Loss: 0.3358124
Validation loss decreased (0.518362 --> 0.517115).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2924884
	speed: 0.1030s/iter; left time: 2582.5238s
	iters: 200, epoch: 6 | loss: 0.3459299
	speed: 0.0165s/iter; left time: 412.8716s
Epoch: 6 cost time: 5.169799089431763
Epoch: 6, Steps: 265 | Train Loss: 0.3082401 Vali Loss: 0.5138453 Test Loss: 0.3359582
Validation loss decreased (0.517115 --> 0.513845).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3100188
	speed: 0.0970s/iter; left time: 2407.1247s
	iters: 200, epoch: 7 | loss: 0.2887185
	speed: 0.0190s/iter; left time: 469.1511s
Epoch: 7 cost time: 5.756159067153931
Epoch: 7, Steps: 265 | Train Loss: 0.3077294 Vali Loss: 0.5127553 Test Loss: 0.3364792
Validation loss decreased (0.513845 --> 0.512755).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3002447
	speed: 0.1013s/iter; left time: 2487.1940s
	iters: 200, epoch: 8 | loss: 0.3020686
	speed: 0.0208s/iter; left time: 508.6217s
Epoch: 8 cost time: 6.555283784866333
Epoch: 8, Steps: 265 | Train Loss: 0.3075399 Vali Loss: 0.5121505 Test Loss: 0.3364299
Validation loss decreased (0.512755 --> 0.512151).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2848968
	speed: 0.0933s/iter; left time: 2265.7286s
	iters: 200, epoch: 9 | loss: 0.3256922
	speed: 0.0192s/iter; left time: 463.5018s
Epoch: 9 cost time: 5.9574339389801025
Epoch: 9, Steps: 265 | Train Loss: 0.3073814 Vali Loss: 0.5116358 Test Loss: 0.3364728
Validation loss decreased (0.512151 --> 0.511636).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3284761
	speed: 0.1068s/iter; left time: 2565.5890s
	iters: 200, epoch: 10 | loss: 0.2893856
	speed: 0.0189s/iter; left time: 451.4939s
Epoch: 10 cost time: 5.874040365219116
Epoch: 10, Steps: 265 | Train Loss: 0.3072040 Vali Loss: 0.5112789 Test Loss: 0.3365631
Validation loss decreased (0.511636 --> 0.511279).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3231438
	speed: 0.0943s/iter; left time: 2238.9028s
	iters: 200, epoch: 11 | loss: 0.2922648
	speed: 0.0230s/iter; left time: 544.7052s
Epoch: 11 cost time: 6.159918785095215
Epoch: 11, Steps: 265 | Train Loss: 0.3072163 Vali Loss: 0.5104790 Test Loss: 0.3365791
Validation loss decreased (0.511279 --> 0.510479).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3213695
	speed: 0.1126s/iter; left time: 2645.0222s
	iters: 200, epoch: 12 | loss: 0.3127990
	speed: 0.0229s/iter; left time: 535.4274s
Epoch: 12 cost time: 7.115782976150513
Epoch: 12, Steps: 265 | Train Loss: 0.3070072 Vali Loss: 0.5109444 Test Loss: 0.3362824
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3224128
	speed: 0.1092s/iter; left time: 2536.8624s
	iters: 200, epoch: 13 | loss: 0.3055147
	speed: 0.0193s/iter; left time: 447.1847s
Epoch: 13 cost time: 6.104349374771118
Epoch: 13, Steps: 265 | Train Loss: 0.3069242 Vali Loss: 0.5103580 Test Loss: 0.3363891
Validation loss decreased (0.510479 --> 0.510358).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2865478
	speed: 0.1103s/iter; left time: 2532.1540s
	iters: 200, epoch: 14 | loss: 0.2982075
	speed: 0.0194s/iter; left time: 442.3548s
Epoch: 14 cost time: 5.81425404548645
Epoch: 14, Steps: 265 | Train Loss: 0.3069096 Vali Loss: 0.5105383 Test Loss: 0.3367329
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2982300
	speed: 0.0992s/iter; left time: 2249.8748s
	iters: 200, epoch: 15 | loss: 0.3206954
	speed: 0.0220s/iter; left time: 496.9786s
Epoch: 15 cost time: 6.2015886306762695
Epoch: 15, Steps: 265 | Train Loss: 0.3068508 Vali Loss: 0.5085877 Test Loss: 0.3363771
Validation loss decreased (0.510358 --> 0.508588).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3264228
	speed: 0.1016s/iter; left time: 2278.1409s
	iters: 200, epoch: 16 | loss: 0.2850498
	speed: 0.0190s/iter; left time: 423.6506s
Epoch: 16 cost time: 5.60488486289978
Epoch: 16, Steps: 265 | Train Loss: 0.3067455 Vali Loss: 0.5101092 Test Loss: 0.3360644
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3246958
	speed: 0.0981s/iter; left time: 2174.6868s
	iters: 200, epoch: 17 | loss: 0.2896910
	speed: 0.0244s/iter; left time: 539.0632s
Epoch: 17 cost time: 6.619238376617432
Epoch: 17, Steps: 265 | Train Loss: 0.3066211 Vali Loss: 0.5092838 Test Loss: 0.3363723
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3302270
	speed: 0.1057s/iter; left time: 2314.5226s
	iters: 200, epoch: 18 | loss: 0.2799884
	speed: 0.0229s/iter; left time: 499.9491s
Epoch: 18 cost time: 6.228671312332153
Epoch: 18, Steps: 265 | Train Loss: 0.3066743 Vali Loss: 0.5101812 Test Loss: 0.3363432
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2901834
	speed: 0.1082s/iter; left time: 2340.2099s
	iters: 200, epoch: 19 | loss: 0.3371520
	speed: 0.0230s/iter; left time: 496.1581s
Epoch: 19 cost time: 6.5304179191589355
Epoch: 19, Steps: 265 | Train Loss: 0.3065251 Vali Loss: 0.5094084 Test Loss: 0.3363940
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2981242
	speed: 0.1154s/iter; left time: 2464.9074s
	iters: 200, epoch: 20 | loss: 0.2890975
	speed: 0.0195s/iter; left time: 413.7834s
Epoch: 20 cost time: 5.860084772109985
Epoch: 20, Steps: 265 | Train Loss: 0.3066653 Vali Loss: 0.5092009 Test Loss: 0.3367420
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2979227
	speed: 0.0941s/iter; left time: 1985.1819s
	iters: 200, epoch: 21 | loss: 0.3124466
	speed: 0.0209s/iter; left time: 437.9117s
Epoch: 21 cost time: 5.908177852630615
Epoch: 21, Steps: 265 | Train Loss: 0.3065303 Vali Loss: 0.5084664 Test Loss: 0.3364567
Validation loss decreased (0.508588 --> 0.508466).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2849954
	speed: 0.0992s/iter; left time: 2066.5728s
	iters: 200, epoch: 22 | loss: 0.3249911
	speed: 0.0205s/iter; left time: 424.1858s
Epoch: 22 cost time: 6.576620817184448
Epoch: 22, Steps: 265 | Train Loss: 0.3066228 Vali Loss: 0.5099461 Test Loss: 0.3364441
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2990883
	speed: 0.1178s/iter; left time: 2422.3488s
	iters: 200, epoch: 23 | loss: 0.3165694
	speed: 0.0211s/iter; left time: 432.1099s
Epoch: 23 cost time: 5.831689834594727
Epoch: 23, Steps: 265 | Train Loss: 0.3065413 Vali Loss: 0.5090549 Test Loss: 0.3363444
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2820938
	speed: 0.1064s/iter; left time: 2159.9188s
	iters: 200, epoch: 24 | loss: 0.2903745
	speed: 0.0194s/iter; left time: 391.8080s
Epoch: 24 cost time: 6.161451578140259
Epoch: 24, Steps: 265 | Train Loss: 0.3065661 Vali Loss: 0.5087602 Test Loss: 0.3364237
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3611691
	speed: 0.1061s/iter; left time: 2125.8320s
	iters: 200, epoch: 25 | loss: 0.3076753
	speed: 0.0218s/iter; left time: 435.2749s
Epoch: 25 cost time: 6.916844606399536
Epoch: 25, Steps: 265 | Train Loss: 0.3065707 Vali Loss: 0.5085970 Test Loss: 0.3364107
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3129202
	speed: 0.0950s/iter; left time: 1879.0590s
	iters: 200, epoch: 26 | loss: 0.2790892
	speed: 0.0204s/iter; left time: 402.2005s
Epoch: 26 cost time: 6.069559812545776
Epoch: 26, Steps: 265 | Train Loss: 0.3065000 Vali Loss: 0.5089231 Test Loss: 0.3365057
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3058269
	speed: 0.1036s/iter; left time: 2021.7020s
	iters: 200, epoch: 27 | loss: 0.3114504
	speed: 0.0196s/iter; left time: 381.4025s
Epoch: 27 cost time: 5.574799299240112
Epoch: 27, Steps: 265 | Train Loss: 0.3065067 Vali Loss: 0.5087100 Test Loss: 0.3363434
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2929565
	speed: 0.0967s/iter; left time: 1861.6246s
	iters: 200, epoch: 28 | loss: 0.2989130
	speed: 0.0245s/iter; left time: 469.8337s
Epoch: 28 cost time: 6.657533645629883
Epoch: 28, Steps: 265 | Train Loss: 0.3065182 Vali Loss: 0.5086908 Test Loss: 0.3364435
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3202859
	speed: 0.1155s/iter; left time: 2193.2179s
	iters: 200, epoch: 29 | loss: 0.3249800
	speed: 0.0204s/iter; left time: 385.6818s
Epoch: 29 cost time: 6.765632152557373
Epoch: 29, Steps: 265 | Train Loss: 0.3063608 Vali Loss: 0.5085157 Test Loss: 0.3365541
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3040409
	speed: 0.1164s/iter; left time: 2178.3413s
	iters: 200, epoch: 30 | loss: 0.3081850
	speed: 0.0244s/iter; left time: 453.4656s
Epoch: 30 cost time: 6.982851505279541
Epoch: 30, Steps: 265 | Train Loss: 0.3065155 Vali Loss: 0.5085241 Test Loss: 0.3364069
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3235474
	speed: 0.1083s/iter; left time: 1997.9655s
	iters: 200, epoch: 31 | loss: 0.2906253
	speed: 0.0204s/iter; left time: 374.9611s
Epoch: 31 cost time: 6.196407079696655
Epoch: 31, Steps: 265 | Train Loss: 0.3064349 Vali Loss: 0.5088413 Test Loss: 0.3365229
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2932873
	speed: 0.0982s/iter; left time: 1785.0961s
	iters: 200, epoch: 32 | loss: 0.2813166
	speed: 0.0195s/iter; left time: 353.0303s
Epoch: 32 cost time: 5.8860132694244385
Epoch: 32, Steps: 265 | Train Loss: 0.3064897 Vali Loss: 0.5090228 Test Loss: 0.3364466
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2987239
	speed: 0.1054s/iter; left time: 1889.6843s
	iters: 200, epoch: 33 | loss: 0.2793029
	speed: 0.0265s/iter; left time: 471.9893s
Epoch: 33 cost time: 7.119535684585571
Epoch: 33, Steps: 265 | Train Loss: 0.3064073 Vali Loss: 0.5090046 Test Loss: 0.3364835
EarlyStopping counter: 12 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3307606
	speed: 0.0994s/iter; left time: 1754.1598s
	iters: 200, epoch: 34 | loss: 0.3179044
	speed: 0.0214s/iter; left time: 375.7875s
Epoch: 34 cost time: 6.7387213706970215
Epoch: 34, Steps: 265 | Train Loss: 0.3064583 Vali Loss: 0.5085793 Test Loss: 0.3364200
EarlyStopping counter: 13 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2996736
	speed: 0.1251s/iter; left time: 2175.4868s
	iters: 200, epoch: 35 | loss: 0.3062494
	speed: 0.0227s/iter; left time: 392.5473s
Epoch: 35 cost time: 7.529356956481934
Epoch: 35, Steps: 265 | Train Loss: 0.3063240 Vali Loss: 0.5088027 Test Loss: 0.3365317
EarlyStopping counter: 14 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2936036
	speed: 0.1019s/iter; left time: 1745.2532s
	iters: 200, epoch: 36 | loss: 0.2938763
	speed: 0.0184s/iter; left time: 313.6944s
Epoch: 36 cost time: 5.631604194641113
Epoch: 36, Steps: 265 | Train Loss: 0.3064224 Vali Loss: 0.5086428 Test Loss: 0.3364676
EarlyStopping counter: 15 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2972549
	speed: 0.0887s/iter; left time: 1494.9843s
	iters: 200, epoch: 37 | loss: 0.3213075
	speed: 0.0189s/iter; left time: 317.2511s
Epoch: 37 cost time: 5.869943618774414
Epoch: 37, Steps: 265 | Train Loss: 0.3064493 Vali Loss: 0.5091450 Test Loss: 0.3365198
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3151042
	speed: 0.1001s/iter; left time: 1661.1103s
	iters: 200, epoch: 38 | loss: 0.2961313
	speed: 0.0200s/iter; left time: 330.4558s
Epoch: 38 cost time: 6.014559507369995
Epoch: 38, Steps: 265 | Train Loss: 0.3063695 Vali Loss: 0.5091444 Test Loss: 0.3364981
EarlyStopping counter: 17 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2747020
	speed: 0.1023s/iter; left time: 1670.8025s
	iters: 200, epoch: 39 | loss: 0.3150239
	speed: 0.0240s/iter; left time: 389.4255s
Epoch: 39 cost time: 6.3942975997924805
Epoch: 39, Steps: 265 | Train Loss: 0.3063473 Vali Loss: 0.5087817 Test Loss: 0.3364372
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.3146080
	speed: 0.0953s/iter; left time: 1531.0441s
	iters: 200, epoch: 40 | loss: 0.2989023
	speed: 0.0166s/iter; left time: 264.7722s
Epoch: 40 cost time: 5.38685941696167
Epoch: 40, Steps: 265 | Train Loss: 0.3064073 Vali Loss: 0.5086429 Test Loss: 0.3364697
EarlyStopping counter: 19 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3250235
	speed: 0.1081s/iter; left time: 1708.1151s
	iters: 200, epoch: 41 | loss: 0.3371521
	speed: 0.0217s/iter; left time: 340.0583s
Epoch: 41 cost time: 6.723673105239868
Epoch: 41, Steps: 265 | Train Loss: 0.3064035 Vali Loss: 0.5086977 Test Loss: 0.3364085
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_360_192_FITS_ETTm1_ftM_sl360_ll48_pl192_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.3374137282371521, mae:0.365118145942688, rse:0.5529462695121765, corr:[0.5444501  0.55293536 0.55451465 0.5535951  0.5534384  0.55421746
 0.5549044  0.5548615  0.5544424  0.55447394 0.55532837 0.55625033
 0.55670255 0.55653495 0.55589384 0.5549109  0.55373055 0.5524762
 0.55108434 0.5497423  0.5485303  0.5475619  0.54657215 0.5455782
 0.54455924 0.5434487  0.54247665 0.5417695  0.5412476  0.5407813
 0.54066795 0.5410674  0.5417151  0.5422531  0.5423761  0.5422325
 0.54192597 0.54158413 0.54138744 0.5413489  0.54134667 0.5411712
 0.5407606  0.5403424  0.5400499  0.5399509  0.5400201  0.53998166
 0.53969157 0.5393545  0.5390966  0.53899175 0.5390516  0.53909487
 0.5390209  0.53886217 0.5386585  0.538505   0.53847843 0.53838795
 0.53830767 0.5381788  0.5381195  0.5381288  0.5383619  0.53876597
 0.5391174  0.5392419  0.5393164  0.53935677 0.53944874 0.53957415
 0.5397453  0.5398813  0.5398901  0.539784   0.53971523 0.5397532
 0.5397998  0.53970766 0.5394238  0.53902227 0.5386118  0.5382713
 0.538096   0.53793025 0.5377421  0.5374292  0.53703815 0.53677714
 0.5367005  0.53668916 0.53662544 0.5364997  0.5362284  0.53577584
 0.535214   0.53463537 0.5340914  0.5335742  0.53325367 0.53318685
 0.5333061  0.5334104  0.5336148  0.53394246 0.53424996 0.5345905
 0.5347528  0.5348169  0.53474325 0.5346125  0.5344394  0.5343674
 0.53434104 0.5343427  0.534306   0.53425807 0.53423625 0.53442067
 0.5346881  0.53480446 0.53475136 0.53467095 0.5345648  0.5343774
 0.5341531  0.5339554  0.53380495 0.53374016 0.53374976 0.5337483
 0.53369373 0.53344464 0.5330793  0.532662   0.53235173 0.53216
 0.5321422  0.5321716  0.53209776 0.53200305 0.5319566  0.5320455
 0.5321932  0.5322894  0.5321947  0.5319708  0.53181    0.53172535
 0.53180337 0.53207153 0.53228325 0.53228986 0.532129   0.53198117
 0.5319183  0.53192437 0.53189176 0.531825   0.53179747 0.5318265
 0.53196585 0.53215575 0.5323929  0.53258574 0.5326618  0.53277254
 0.5329587  0.5332214  0.5334839  0.5336572  0.53359413 0.533402
 0.53320915 0.53313184 0.53305405 0.53286785 0.53248256 0.5321304
 0.5319286  0.5319618  0.5318961  0.53162724 0.53125584 0.5311455
 0.5314783  0.5320957  0.5324543  0.5323882  0.53236884 0.5333937 ]
