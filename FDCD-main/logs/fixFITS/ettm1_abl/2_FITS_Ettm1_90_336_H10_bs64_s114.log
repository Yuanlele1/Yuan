Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=20, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_90_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_90_336_FITS_ETTm1_ftM_sl90_ll48_pl336_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=20, out_features=94, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1684480.0
params:  1974.0
Trainable parameters:  1974
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.7210211
	speed: 0.0190s/iter; left time: 503.5939s
	iters: 200, epoch: 1 | loss: 0.5681366
	speed: 0.0124s/iter; left time: 328.6857s
Epoch: 1 cost time: 3.991211175918579
Epoch: 1, Steps: 266 | Train Loss: 0.6645485 Vali Loss: 1.0048608 Test Loss: 0.7392935
Validation loss decreased (inf --> 1.004861).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4335824
	speed: 0.0673s/iter; left time: 1764.7027s
	iters: 200, epoch: 2 | loss: 0.4092578
	speed: 0.0132s/iter; left time: 345.0509s
Epoch: 2 cost time: 4.099834680557251
Epoch: 2, Steps: 266 | Train Loss: 0.4218994 Vali Loss: 0.8251759 Test Loss: 0.5625833
Validation loss decreased (1.004861 --> 0.825176).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3388712
	speed: 0.0673s/iter; left time: 1747.7751s
	iters: 200, epoch: 3 | loss: 0.3698895
	speed: 0.0134s/iter; left time: 345.5594s
Epoch: 3 cost time: 4.024613618850708
Epoch: 3, Steps: 266 | Train Loss: 0.3714246 Vali Loss: 0.7691959 Test Loss: 0.5063988
Validation loss decreased (0.825176 --> 0.769196).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3302349
	speed: 0.0652s/iter; left time: 1675.2480s
	iters: 200, epoch: 4 | loss: 0.3463475
	speed: 0.0131s/iter; left time: 335.0648s
Epoch: 4 cost time: 4.030484914779663
Epoch: 4, Steps: 266 | Train Loss: 0.3553071 Vali Loss: 0.7403857 Test Loss: 0.4785642
Validation loss decreased (0.769196 --> 0.740386).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3422459
	speed: 0.0680s/iter; left time: 1730.9581s
	iters: 200, epoch: 5 | loss: 0.3338282
	speed: 0.0144s/iter; left time: 364.8717s
Epoch: 5 cost time: 4.3100926876068115
Epoch: 5, Steps: 266 | Train Loss: 0.3478989 Vali Loss: 0.7234879 Test Loss: 0.4618937
Validation loss decreased (0.740386 --> 0.723488).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3359783
	speed: 0.0853s/iter; left time: 2146.1931s
	iters: 200, epoch: 6 | loss: 0.3493086
	speed: 0.0137s/iter; left time: 342.7120s
Epoch: 6 cost time: 4.207269668579102
Epoch: 6, Steps: 266 | Train Loss: 0.3440741 Vali Loss: 0.7140490 Test Loss: 0.4519729
Validation loss decreased (0.723488 --> 0.714049).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3538768
	speed: 0.0683s/iter; left time: 1700.8427s
	iters: 200, epoch: 7 | loss: 0.3343820
	speed: 0.0132s/iter; left time: 328.6248s
Epoch: 7 cost time: 4.126921892166138
Epoch: 7, Steps: 266 | Train Loss: 0.3418665 Vali Loss: 0.7086911 Test Loss: 0.4456098
Validation loss decreased (0.714049 --> 0.708691).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3345151
	speed: 0.0688s/iter; left time: 1695.4181s
	iters: 200, epoch: 8 | loss: 0.3168787
	speed: 0.0131s/iter; left time: 321.5227s
Epoch: 8 cost time: 4.083630561828613
Epoch: 8, Steps: 266 | Train Loss: 0.3409784 Vali Loss: 0.7041308 Test Loss: 0.4414871
Validation loss decreased (0.708691 --> 0.704131).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3267310
	speed: 0.0658s/iter; left time: 1602.7275s
	iters: 200, epoch: 9 | loss: 0.3705495
	speed: 0.0130s/iter; left time: 316.5961s
Epoch: 9 cost time: 3.883836030960083
Epoch: 9, Steps: 266 | Train Loss: 0.3402082 Vali Loss: 0.7035273 Test Loss: 0.4395380
Validation loss decreased (0.704131 --> 0.703527).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3584314
	speed: 0.0688s/iter; left time: 1659.4192s
	iters: 200, epoch: 10 | loss: 0.3552780
	speed: 0.0135s/iter; left time: 324.1203s
Epoch: 10 cost time: 4.269394636154175
Epoch: 10, Steps: 266 | Train Loss: 0.3398451 Vali Loss: 0.7018599 Test Loss: 0.4376437
Validation loss decreased (0.703527 --> 0.701860).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3458921
	speed: 0.0670s/iter; left time: 1596.8068s
	iters: 200, epoch: 11 | loss: 0.3218720
	speed: 0.0146s/iter; left time: 347.1652s
Epoch: 11 cost time: 4.340864419937134
Epoch: 11, Steps: 266 | Train Loss: 0.3396493 Vali Loss: 0.7012970 Test Loss: 0.4366469
Validation loss decreased (0.701860 --> 0.701297).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3172251
	speed: 0.0692s/iter; left time: 1632.0662s
	iters: 200, epoch: 12 | loss: 0.3193203
	speed: 0.0134s/iter; left time: 315.0202s
Epoch: 12 cost time: 4.21217155456543
Epoch: 12, Steps: 266 | Train Loss: 0.3395972 Vali Loss: 0.6999367 Test Loss: 0.4360369
Validation loss decreased (0.701297 --> 0.699937).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3308948
	speed: 0.0650s/iter; left time: 1515.7662s
	iters: 200, epoch: 13 | loss: 0.3550140
	speed: 0.0143s/iter; left time: 332.4266s
Epoch: 13 cost time: 4.180680990219116
Epoch: 13, Steps: 266 | Train Loss: 0.3395220 Vali Loss: 0.7007602 Test Loss: 0.4354844
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3319481
	speed: 0.0684s/iter; left time: 1575.9507s
	iters: 200, epoch: 14 | loss: 0.3441982
	speed: 0.0137s/iter; left time: 314.8326s
Epoch: 14 cost time: 4.176474332809448
Epoch: 14, Steps: 266 | Train Loss: 0.3393700 Vali Loss: 0.6996044 Test Loss: 0.4353224
Validation loss decreased (0.699937 --> 0.699604).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3054926
	speed: 0.0724s/iter; left time: 1648.4948s
	iters: 200, epoch: 15 | loss: 0.3378967
	speed: 0.0141s/iter; left time: 320.2915s
Epoch: 15 cost time: 4.2270848751068115
Epoch: 15, Steps: 266 | Train Loss: 0.3394217 Vali Loss: 0.6990054 Test Loss: 0.4348049
Validation loss decreased (0.699604 --> 0.699005).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3347612
	speed: 0.0704s/iter; left time: 1585.2884s
	iters: 200, epoch: 16 | loss: 0.4206529
	speed: 0.0131s/iter; left time: 292.5583s
Epoch: 16 cost time: 4.2529919147491455
Epoch: 16, Steps: 266 | Train Loss: 0.3395121 Vali Loss: 0.6997790 Test Loss: 0.4348858
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3316602
	speed: 0.0680s/iter; left time: 1513.7694s
	iters: 200, epoch: 17 | loss: 0.3259390
	speed: 0.0133s/iter; left time: 294.2125s
Epoch: 17 cost time: 4.046766519546509
Epoch: 17, Steps: 266 | Train Loss: 0.3394472 Vali Loss: 0.6996932 Test Loss: 0.4348859
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3638869
	speed: 0.0670s/iter; left time: 1473.4785s
	iters: 200, epoch: 18 | loss: 0.3289443
	speed: 0.0128s/iter; left time: 280.7128s
Epoch: 18 cost time: 4.058484792709351
Epoch: 18, Steps: 266 | Train Loss: 0.3395175 Vali Loss: 0.7002516 Test Loss: 0.4349052
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3441038
	speed: 0.0682s/iter; left time: 1479.9139s
	iters: 200, epoch: 19 | loss: 0.3552875
	speed: 0.0134s/iter; left time: 290.3249s
Epoch: 19 cost time: 4.12485933303833
Epoch: 19, Steps: 266 | Train Loss: 0.3395379 Vali Loss: 0.6999925 Test Loss: 0.4349481
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3410978
	speed: 0.0652s/iter; left time: 1399.3203s
	iters: 200, epoch: 20 | loss: 0.3557751
	speed: 0.0127s/iter; left time: 270.9967s
Epoch: 20 cost time: 4.004972696304321
Epoch: 20, Steps: 266 | Train Loss: 0.3394684 Vali Loss: 0.7001567 Test Loss: 0.4348549
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3838566
	speed: 0.0664s/iter; left time: 1406.1244s
	iters: 200, epoch: 21 | loss: 0.3203409
	speed: 0.0131s/iter; left time: 276.6105s
Epoch: 21 cost time: 4.0669121742248535
Epoch: 21, Steps: 266 | Train Loss: 0.3394860 Vali Loss: 0.6991330 Test Loss: 0.4347935
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3313019
	speed: 0.0680s/iter; left time: 1422.8936s
	iters: 200, epoch: 22 | loss: 0.3835376
	speed: 0.0134s/iter; left time: 277.9234s
Epoch: 22 cost time: 4.197876930236816
Epoch: 22, Steps: 266 | Train Loss: 0.3394842 Vali Loss: 0.7002316 Test Loss: 0.4344975
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3400379
	speed: 0.0672s/iter; left time: 1388.5910s
	iters: 200, epoch: 23 | loss: 0.3556428
	speed: 0.0135s/iter; left time: 277.5594s
Epoch: 23 cost time: 4.074170827865601
Epoch: 23, Steps: 266 | Train Loss: 0.3394685 Vali Loss: 0.7003213 Test Loss: 0.4348651
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3229259
	speed: 0.0671s/iter; left time: 1366.7607s
	iters: 200, epoch: 24 | loss: 0.3503095
	speed: 0.0135s/iter; left time: 274.8259s
Epoch: 24 cost time: 4.057400226593018
Epoch: 24, Steps: 266 | Train Loss: 0.3393984 Vali Loss: 0.6997157 Test Loss: 0.4347779
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3258710
	speed: 0.0647s/iter; left time: 1301.8354s
	iters: 200, epoch: 25 | loss: 0.3644195
	speed: 0.0132s/iter; left time: 264.7199s
Epoch: 25 cost time: 4.074768781661987
Epoch: 25, Steps: 266 | Train Loss: 0.3393046 Vali Loss: 0.6999032 Test Loss: 0.4348236
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3511533
	speed: 0.0668s/iter; left time: 1325.4241s
	iters: 200, epoch: 26 | loss: 0.3217740
	speed: 0.0135s/iter; left time: 267.6160s
Epoch: 26 cost time: 4.031772613525391
Epoch: 26, Steps: 266 | Train Loss: 0.3394370 Vali Loss: 0.7001222 Test Loss: 0.4348776
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3149890
	speed: 0.0660s/iter; left time: 1292.5182s
	iters: 200, epoch: 27 | loss: 0.3388062
	speed: 0.0143s/iter; left time: 279.5074s
Epoch: 27 cost time: 4.269114971160889
Epoch: 27, Steps: 266 | Train Loss: 0.3393440 Vali Loss: 0.6995820 Test Loss: 0.4348812
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3339206
	speed: 0.0675s/iter; left time: 1304.2541s
	iters: 200, epoch: 28 | loss: 0.3356412
	speed: 0.0133s/iter; left time: 256.2141s
Epoch: 28 cost time: 4.10570502281189
Epoch: 28, Steps: 266 | Train Loss: 0.3394396 Vali Loss: 0.6998911 Test Loss: 0.4349736
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3529752
	speed: 0.0684s/iter; left time: 1303.1828s
	iters: 200, epoch: 29 | loss: 0.3073239
	speed: 0.0129s/iter; left time: 243.7462s
Epoch: 29 cost time: 4.067199230194092
Epoch: 29, Steps: 266 | Train Loss: 0.3395748 Vali Loss: 0.6998056 Test Loss: 0.4348012
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3444178
	speed: 0.0655s/iter; left time: 1230.8770s
	iters: 200, epoch: 30 | loss: 0.3347007
	speed: 0.0134s/iter; left time: 250.6548s
Epoch: 30 cost time: 4.112489461898804
Epoch: 30, Steps: 266 | Train Loss: 0.3394914 Vali Loss: 0.7002283 Test Loss: 0.4349579
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3582840
	speed: 0.0671s/iter; left time: 1242.5694s
	iters: 200, epoch: 31 | loss: 0.3254419
	speed: 0.0133s/iter; left time: 245.5409s
Epoch: 31 cost time: 4.160998344421387
Epoch: 31, Steps: 266 | Train Loss: 0.3394738 Vali Loss: 0.6990009 Test Loss: 0.4348029
Validation loss decreased (0.699005 --> 0.699001).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3621761
	speed: 0.0688s/iter; left time: 1256.8378s
	iters: 200, epoch: 32 | loss: 0.3493454
	speed: 0.0191s/iter; left time: 347.2770s
Epoch: 32 cost time: 6.736194372177124
Epoch: 32, Steps: 266 | Train Loss: 0.3394586 Vali Loss: 0.6994890 Test Loss: 0.4348502
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3653032
	speed: 0.0860s/iter; left time: 1547.6540s
	iters: 200, epoch: 33 | loss: 0.3661729
	speed: 0.0131s/iter; left time: 234.7567s
Epoch: 33 cost time: 3.9468488693237305
Epoch: 33, Steps: 266 | Train Loss: 0.3394358 Vali Loss: 0.7000534 Test Loss: 0.4349484
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3621348
	speed: 0.0647s/iter; left time: 1147.4583s
	iters: 200, epoch: 34 | loss: 0.3588599
	speed: 0.0129s/iter; left time: 227.0464s
Epoch: 34 cost time: 4.001481056213379
Epoch: 34, Steps: 266 | Train Loss: 0.3393853 Vali Loss: 0.7001068 Test Loss: 0.4350439
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3545918
	speed: 0.0670s/iter; left time: 1170.0523s
	iters: 200, epoch: 35 | loss: 0.3283207
	speed: 0.0137s/iter; left time: 237.1608s
Epoch: 35 cost time: 4.126173257827759
Epoch: 35, Steps: 266 | Train Loss: 0.3394789 Vali Loss: 0.6997111 Test Loss: 0.4350358
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3292974
	speed: 0.0679s/iter; left time: 1167.1627s
	iters: 200, epoch: 36 | loss: 0.3453281
	speed: 0.0127s/iter; left time: 217.3250s
Epoch: 36 cost time: 4.073204040527344
Epoch: 36, Steps: 266 | Train Loss: 0.3395052 Vali Loss: 0.6998178 Test Loss: 0.4348401
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3225798
	speed: 0.0678s/iter; left time: 1147.7167s
	iters: 200, epoch: 37 | loss: 0.3525593
	speed: 0.0129s/iter; left time: 217.6802s
Epoch: 37 cost time: 4.071382999420166
Epoch: 37, Steps: 266 | Train Loss: 0.3394418 Vali Loss: 0.7001458 Test Loss: 0.4349808
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3288958
	speed: 0.0672s/iter; left time: 1120.0352s
	iters: 200, epoch: 38 | loss: 0.3041722
	speed: 0.0135s/iter; left time: 222.8310s
Epoch: 38 cost time: 4.104657888412476
Epoch: 38, Steps: 266 | Train Loss: 0.3395101 Vali Loss: 0.7001327 Test Loss: 0.4349319
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3358096
	speed: 0.0674s/iter; left time: 1104.5678s
	iters: 200, epoch: 39 | loss: 0.3097014
	speed: 0.0132s/iter; left time: 215.6393s
Epoch: 39 cost time: 4.052783489227295
Epoch: 39, Steps: 266 | Train Loss: 0.3394052 Vali Loss: 0.6994047 Test Loss: 0.4349917
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.3596874
	speed: 0.0661s/iter; left time: 1066.3322s
	iters: 200, epoch: 40 | loss: 0.3088838
	speed: 0.0130s/iter; left time: 208.1733s
Epoch: 40 cost time: 3.976870059967041
Epoch: 40, Steps: 266 | Train Loss: 0.3393302 Vali Loss: 0.7007426 Test Loss: 0.4349863
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3432089
	speed: 0.0671s/iter; left time: 1064.7601s
	iters: 200, epoch: 41 | loss: 0.3335620
	speed: 0.0137s/iter; left time: 216.2457s
Epoch: 41 cost time: 4.174753189086914
Epoch: 41, Steps: 266 | Train Loss: 0.3394209 Vali Loss: 0.6994124 Test Loss: 0.4349422
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3531846
	speed: 0.0661s/iter; left time: 1030.5391s
	iters: 200, epoch: 42 | loss: 0.3283367
	speed: 0.0133s/iter; left time: 205.4930s
Epoch: 42 cost time: 4.0149359703063965
Epoch: 42, Steps: 266 | Train Loss: 0.3394921 Vali Loss: 0.7000605 Test Loss: 0.4351057
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3267909
	speed: 0.0689s/iter; left time: 1055.4187s
	iters: 200, epoch: 43 | loss: 0.3173780
	speed: 0.0135s/iter; left time: 206.1711s
Epoch: 43 cost time: 4.207810878753662
Epoch: 43, Steps: 266 | Train Loss: 0.3393165 Vali Loss: 0.6998856 Test Loss: 0.4349532
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.3697693
	speed: 0.0680s/iter; left time: 1024.7057s
	iters: 200, epoch: 44 | loss: 0.3389869
	speed: 0.0139s/iter; left time: 207.8139s
Epoch: 44 cost time: 4.232140302658081
Epoch: 44, Steps: 266 | Train Loss: 0.3393842 Vali Loss: 0.7000127 Test Loss: 0.4350620
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.3566090
	speed: 0.0683s/iter; left time: 1010.3881s
	iters: 200, epoch: 45 | loss: 0.3456905
	speed: 0.0135s/iter; left time: 197.6922s
Epoch: 45 cost time: 4.189995050430298
Epoch: 45, Steps: 266 | Train Loss: 0.3395383 Vali Loss: 0.7000845 Test Loss: 0.4350979
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.3156295
	speed: 0.0662s/iter; left time: 962.2369s
	iters: 200, epoch: 46 | loss: 0.3163254
	speed: 0.0131s/iter; left time: 189.1584s
Epoch: 46 cost time: 4.040888786315918
Epoch: 46, Steps: 266 | Train Loss: 0.3394180 Vali Loss: 0.6997316 Test Loss: 0.4350397
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2908322
	speed: 0.0660s/iter; left time: 940.8090s
	iters: 200, epoch: 47 | loss: 0.3710390
	speed: 0.0131s/iter; left time: 186.0878s
Epoch: 47 cost time: 4.067749500274658
Epoch: 47, Steps: 266 | Train Loss: 0.3394893 Vali Loss: 0.6995343 Test Loss: 0.4349584
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.3226493
	speed: 0.0647s/iter; left time: 905.7788s
	iters: 200, epoch: 48 | loss: 0.3741843
	speed: 0.0133s/iter; left time: 185.4912s
Epoch: 48 cost time: 4.006570816040039
Epoch: 48, Steps: 266 | Train Loss: 0.3393159 Vali Loss: 0.6995206 Test Loss: 0.4349912
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.3754873
	speed: 0.0659s/iter; left time: 905.1356s
	iters: 200, epoch: 49 | loss: 0.3584187
	speed: 0.0132s/iter; left time: 180.1271s
Epoch: 49 cost time: 4.0545878410339355
Epoch: 49, Steps: 266 | Train Loss: 0.3394434 Vali Loss: 0.6999841 Test Loss: 0.4350819
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.3351120
	speed: 0.0664s/iter; left time: 894.7545s
	iters: 200, epoch: 50 | loss: 0.3906925
	speed: 0.0132s/iter; left time: 176.2890s
Epoch: 50 cost time: 4.047988176345825
Epoch: 50, Steps: 266 | Train Loss: 0.3395631 Vali Loss: 0.6997842 Test Loss: 0.4350519
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.3408993
	speed: 0.0695s/iter; left time: 917.7788s
	iters: 200, epoch: 51 | loss: 0.3314162
	speed: 0.0141s/iter; left time: 185.0712s
Epoch: 51 cost time: 4.453221559524536
Epoch: 51, Steps: 266 | Train Loss: 0.3395174 Vali Loss: 0.6996827 Test Loss: 0.4350306
EarlyStopping counter: 20 out of 20
Early stopping
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=20, out_features=94, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1684480.0
params:  1974.0
Trainable parameters:  1974
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4381962
	speed: 0.0194s/iter; left time: 514.3001s
	iters: 200, epoch: 1 | loss: 0.3721775
	speed: 0.0134s/iter; left time: 353.9165s
Epoch: 1 cost time: 4.1366260051727295
Epoch: 1, Steps: 266 | Train Loss: 0.4245257 Vali Loss: 0.6956241 Test Loss: 0.4310983
Validation loss decreased (inf --> 0.695624).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4284134
	speed: 0.0686s/iter; left time: 1798.9723s
	iters: 200, epoch: 2 | loss: 0.4380427
	speed: 0.0134s/iter; left time: 350.0290s
Epoch: 2 cost time: 4.148592948913574
Epoch: 2, Steps: 266 | Train Loss: 0.4239071 Vali Loss: 0.6963512 Test Loss: 0.4322448
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4384647
	speed: 0.0677s/iter; left time: 1757.9726s
	iters: 200, epoch: 3 | loss: 0.4052539
	speed: 0.0133s/iter; left time: 343.8678s
Epoch: 3 cost time: 4.0132224559783936
Epoch: 3, Steps: 266 | Train Loss: 0.4236221 Vali Loss: 0.6951599 Test Loss: 0.4314879
Validation loss decreased (0.695624 --> 0.695160).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3989065
	speed: 0.0656s/iter; left time: 1684.9372s
	iters: 200, epoch: 4 | loss: 0.4310343
	speed: 0.0129s/iter; left time: 331.2078s
Epoch: 4 cost time: 4.00156831741333
Epoch: 4, Steps: 266 | Train Loss: 0.4237961 Vali Loss: 0.6950723 Test Loss: 0.4314899
Validation loss decreased (0.695160 --> 0.695072).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3919359
	speed: 0.0645s/iter; left time: 1641.4397s
	iters: 200, epoch: 5 | loss: 0.3968103
	speed: 0.0135s/iter; left time: 342.0242s
Epoch: 5 cost time: 3.9670145511627197
Epoch: 5, Steps: 266 | Train Loss: 0.4236356 Vali Loss: 0.6949024 Test Loss: 0.4315118
Validation loss decreased (0.695072 --> 0.694902).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4880490
	speed: 0.0655s/iter; left time: 1649.1862s
	iters: 200, epoch: 6 | loss: 0.4131010
	speed: 0.0133s/iter; left time: 333.2406s
Epoch: 6 cost time: 4.004284858703613
Epoch: 6, Steps: 266 | Train Loss: 0.4236510 Vali Loss: 0.6949707 Test Loss: 0.4314762
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4490695
	speed: 0.0700s/iter; left time: 1743.8516s
	iters: 200, epoch: 7 | loss: 0.4229369
	speed: 0.0145s/iter; left time: 359.6991s
Epoch: 7 cost time: 4.212530851364136
Epoch: 7, Steps: 266 | Train Loss: 0.4235448 Vali Loss: 0.6946971 Test Loss: 0.4313537
Validation loss decreased (0.694902 --> 0.694697).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4117452
	speed: 0.0658s/iter; left time: 1622.1596s
	iters: 200, epoch: 8 | loss: 0.4304459
	speed: 0.0131s/iter; left time: 320.6652s
Epoch: 8 cost time: 4.042708873748779
Epoch: 8, Steps: 266 | Train Loss: 0.4235807 Vali Loss: 0.6958010 Test Loss: 0.4316163
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4155636
	speed: 0.0668s/iter; left time: 1629.1037s
	iters: 200, epoch: 9 | loss: 0.4230515
	speed: 0.0133s/iter; left time: 322.8392s
Epoch: 9 cost time: 4.062739849090576
Epoch: 9, Steps: 266 | Train Loss: 0.4236441 Vali Loss: 0.6954163 Test Loss: 0.4320371
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4153507
	speed: 0.0672s/iter; left time: 1620.7209s
	iters: 200, epoch: 10 | loss: 0.4694173
	speed: 0.0134s/iter; left time: 322.6686s
Epoch: 10 cost time: 4.079205751419067
Epoch: 10, Steps: 266 | Train Loss: 0.4233685 Vali Loss: 0.6947898 Test Loss: 0.4316072
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4370991
	speed: 0.0679s/iter; left time: 1618.2386s
	iters: 200, epoch: 11 | loss: 0.4007499
	speed: 0.0129s/iter; left time: 305.5276s
Epoch: 11 cost time: 4.033050060272217
Epoch: 11, Steps: 266 | Train Loss: 0.4236405 Vali Loss: 0.6952094 Test Loss: 0.4317512
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4122944
	speed: 0.0640s/iter; left time: 1509.8527s
	iters: 200, epoch: 12 | loss: 0.4088415
	speed: 0.0131s/iter; left time: 306.9564s
Epoch: 12 cost time: 3.8819406032562256
Epoch: 12, Steps: 266 | Train Loss: 0.4235837 Vali Loss: 0.6948431 Test Loss: 0.4311586
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4035570
	speed: 0.0677s/iter; left time: 1577.7782s
	iters: 200, epoch: 13 | loss: 0.4108830
	speed: 0.0144s/iter; left time: 333.9584s
Epoch: 13 cost time: 4.421641111373901
Epoch: 13, Steps: 266 | Train Loss: 0.4234511 Vali Loss: 0.6944895 Test Loss: 0.4315967
Validation loss decreased (0.694697 --> 0.694490).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4261489
	speed: 0.0680s/iter; left time: 1568.0375s
	iters: 200, epoch: 14 | loss: 0.3933644
	speed: 0.0129s/iter; left time: 295.0859s
Epoch: 14 cost time: 3.975353240966797
Epoch: 14, Steps: 266 | Train Loss: 0.4233650 Vali Loss: 0.6948353 Test Loss: 0.4314893
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4343109
	speed: 0.0655s/iter; left time: 1491.0024s
	iters: 200, epoch: 15 | loss: 0.4254785
	speed: 0.0130s/iter; left time: 294.6638s
Epoch: 15 cost time: 4.0249855518341064
Epoch: 15, Steps: 266 | Train Loss: 0.4232865 Vali Loss: 0.6949995 Test Loss: 0.4314372
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4093633
	speed: 0.0672s/iter; left time: 1513.1293s
	iters: 200, epoch: 16 | loss: 0.4409347
	speed: 0.0138s/iter; left time: 308.3489s
Epoch: 16 cost time: 4.193610668182373
Epoch: 16, Steps: 266 | Train Loss: 0.4234551 Vali Loss: 0.6950712 Test Loss: 0.4314818
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4370629
	speed: 0.0683s/iter; left time: 1519.7417s
	iters: 200, epoch: 17 | loss: 0.4378226
	speed: 0.0135s/iter; left time: 299.2071s
Epoch: 17 cost time: 4.076528549194336
Epoch: 17, Steps: 266 | Train Loss: 0.4233405 Vali Loss: 0.6944118 Test Loss: 0.4314763
Validation loss decreased (0.694490 --> 0.694412).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3903443
	speed: 0.0652s/iter; left time: 1432.1800s
	iters: 200, epoch: 18 | loss: 0.4263722
	speed: 0.0130s/iter; left time: 284.7156s
Epoch: 18 cost time: 4.013136863708496
Epoch: 18, Steps: 266 | Train Loss: 0.4234388 Vali Loss: 0.6942002 Test Loss: 0.4314730
Validation loss decreased (0.694412 --> 0.694200).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4264543
	speed: 0.0644s/iter; left time: 1398.2583s
	iters: 200, epoch: 19 | loss: 0.4417038
	speed: 0.0132s/iter; left time: 286.1028s
Epoch: 19 cost time: 3.9068281650543213
Epoch: 19, Steps: 266 | Train Loss: 0.4234308 Vali Loss: 0.6954189 Test Loss: 0.4316177
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3712886
	speed: 0.0829s/iter; left time: 1778.8162s
	iters: 200, epoch: 20 | loss: 0.4180669
	speed: 0.0279s/iter; left time: 595.7293s
Epoch: 20 cost time: 7.318837642669678
Epoch: 20, Steps: 266 | Train Loss: 0.4233816 Vali Loss: 0.6951075 Test Loss: 0.4316650
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4186639
	speed: 0.0673s/iter; left time: 1425.3991s
	iters: 200, epoch: 21 | loss: 0.4350926
	speed: 0.0137s/iter; left time: 288.0554s
Epoch: 21 cost time: 4.1504435539245605
Epoch: 21, Steps: 266 | Train Loss: 0.4235281 Vali Loss: 0.6950238 Test Loss: 0.4314065
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4890922
	speed: 0.0678s/iter; left time: 1418.6465s
	iters: 200, epoch: 22 | loss: 0.4538323
	speed: 0.0141s/iter; left time: 293.4553s
Epoch: 22 cost time: 4.375335693359375
Epoch: 22, Steps: 266 | Train Loss: 0.4235399 Vali Loss: 0.6949726 Test Loss: 0.4314338
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3925052
	speed: 0.0681s/iter; left time: 1407.0381s
	iters: 200, epoch: 23 | loss: 0.4725147
	speed: 0.0133s/iter; left time: 272.5838s
Epoch: 23 cost time: 4.046232223510742
Epoch: 23, Steps: 266 | Train Loss: 0.4234290 Vali Loss: 0.6942564 Test Loss: 0.4312699
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3953392
	speed: 0.0664s/iter; left time: 1354.2762s
	iters: 200, epoch: 24 | loss: 0.4058808
	speed: 0.0134s/iter; left time: 271.3023s
Epoch: 24 cost time: 4.072777509689331
Epoch: 24, Steps: 266 | Train Loss: 0.4234780 Vali Loss: 0.6946765 Test Loss: 0.4314938
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4460391
	speed: 0.0662s/iter; left time: 1331.1598s
	iters: 200, epoch: 25 | loss: 0.4501729
	speed: 0.0136s/iter; left time: 271.2374s
Epoch: 25 cost time: 4.1255481243133545
Epoch: 25, Steps: 266 | Train Loss: 0.4233356 Vali Loss: 0.6944156 Test Loss: 0.4314256
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4251565
	speed: 0.0663s/iter; left time: 1316.0677s
	iters: 200, epoch: 26 | loss: 0.5082161
	speed: 0.0138s/iter; left time: 273.3468s
Epoch: 26 cost time: 4.126068592071533
Epoch: 26, Steps: 266 | Train Loss: 0.4235270 Vali Loss: 0.6948126 Test Loss: 0.4314172
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4271972
	speed: 0.0684s/iter; left time: 1340.3058s
	iters: 200, epoch: 27 | loss: 0.4413131
	speed: 0.0140s/iter; left time: 272.7490s
Epoch: 27 cost time: 4.247727870941162
Epoch: 27, Steps: 266 | Train Loss: 0.4233207 Vali Loss: 0.6945067 Test Loss: 0.4315096
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4098121
	speed: 0.0702s/iter; left time: 1355.5324s
	iters: 200, epoch: 28 | loss: 0.4544758
	speed: 0.0143s/iter; left time: 275.7277s
Epoch: 28 cost time: 4.254642486572266
Epoch: 28, Steps: 266 | Train Loss: 0.4234540 Vali Loss: 0.6951909 Test Loss: 0.4315900
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4303444
	speed: 0.0675s/iter; left time: 1285.5095s
	iters: 200, epoch: 29 | loss: 0.3777691
	speed: 0.0131s/iter; left time: 248.8636s
Epoch: 29 cost time: 4.006881237030029
Epoch: 29, Steps: 266 | Train Loss: 0.4234139 Vali Loss: 0.6946134 Test Loss: 0.4316287
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4329128
	speed: 0.0672s/iter; left time: 1262.8387s
	iters: 200, epoch: 30 | loss: 0.4142544
	speed: 0.0137s/iter; left time: 256.8243s
Epoch: 30 cost time: 4.044384956359863
Epoch: 30, Steps: 266 | Train Loss: 0.4235266 Vali Loss: 0.6947112 Test Loss: 0.4315737
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4567576
	speed: 0.0678s/iter; left time: 1254.9783s
	iters: 200, epoch: 31 | loss: 0.4807595
	speed: 0.0144s/iter; left time: 266.0331s
Epoch: 31 cost time: 4.344552755355835
Epoch: 31, Steps: 266 | Train Loss: 0.4233683 Vali Loss: 0.6945899 Test Loss: 0.4314945
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4254576
	speed: 0.0697s/iter; left time: 1272.7955s
	iters: 200, epoch: 32 | loss: 0.4357567
	speed: 0.0136s/iter; left time: 247.6692s
Epoch: 32 cost time: 4.163780450820923
Epoch: 32, Steps: 266 | Train Loss: 0.4233553 Vali Loss: 0.6953912 Test Loss: 0.4318399
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4474170
	speed: 0.0687s/iter; left time: 1236.5200s
	iters: 200, epoch: 33 | loss: 0.4153261
	speed: 0.0135s/iter; left time: 241.9413s
Epoch: 33 cost time: 4.164746284484863
Epoch: 33, Steps: 266 | Train Loss: 0.4234463 Vali Loss: 0.6958850 Test Loss: 0.4314925
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4513484
	speed: 0.0658s/iter; left time: 1165.8359s
	iters: 200, epoch: 34 | loss: 0.3960993
	speed: 0.0128s/iter; left time: 225.6351s
Epoch: 34 cost time: 4.046487331390381
Epoch: 34, Steps: 266 | Train Loss: 0.4233821 Vali Loss: 0.6951436 Test Loss: 0.4314416
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3894753
	speed: 0.0679s/iter; left time: 1185.4623s
	iters: 200, epoch: 35 | loss: 0.4835002
	speed: 0.0136s/iter; left time: 236.5459s
Epoch: 35 cost time: 4.220321416854858
Epoch: 35, Steps: 266 | Train Loss: 0.4233834 Vali Loss: 0.6942236 Test Loss: 0.4316031
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4040770
	speed: 0.0685s/iter; left time: 1177.0898s
	iters: 200, epoch: 36 | loss: 0.3892629
	speed: 0.0133s/iter; left time: 226.8804s
Epoch: 36 cost time: 4.072784900665283
Epoch: 36, Steps: 266 | Train Loss: 0.4234483 Vali Loss: 0.6949137 Test Loss: 0.4315693
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4501649
	speed: 0.0675s/iter; left time: 1141.6643s
	iters: 200, epoch: 37 | loss: 0.3847211
	speed: 0.0138s/iter; left time: 232.0284s
Epoch: 37 cost time: 4.2516961097717285
Epoch: 37, Steps: 266 | Train Loss: 0.4234695 Vali Loss: 0.6946744 Test Loss: 0.4314865
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4150874
	speed: 0.0707s/iter; left time: 1177.8338s
	iters: 200, epoch: 38 | loss: 0.4440995
	speed: 0.0155s/iter; left time: 256.7106s
Epoch: 38 cost time: 4.658822298049927
Epoch: 38, Steps: 266 | Train Loss: 0.4234068 Vali Loss: 0.6955197 Test Loss: 0.4315547
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_90_336_FITS_ETTm1_ftM_sl90_ll48_pl336_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.4315689206123352, mae:0.4191436469554901, rse:0.6251344084739685, corr:[0.5452605  0.5459484  0.5410377  0.5390273  0.53803676 0.5355057
 0.53245264 0.53061146 0.52934396 0.52774507 0.5260995  0.5253233
 0.5248805  0.52350163 0.5206597  0.5170569  0.5136757  0.5107671
 0.508065   0.50517213 0.5021807  0.49925196 0.49622744 0.4927705
 0.48901176 0.48537463 0.48233074 0.4799067  0.47788948 0.47597167
 0.4746288  0.47456083 0.4750376  0.47553334 0.47580227 0.47603586
 0.4760305  0.4761728  0.47638175 0.47633976 0.4760903  0.4755564
 0.47521606 0.47522607 0.47513872 0.4748656  0.4747258  0.47483394
 0.47502863 0.47517687 0.47537503 0.47563902 0.47620383 0.4767959
 0.47736079 0.47770968 0.4780466  0.4783161  0.47815776 0.477858
 0.47772494 0.4775858  0.47755614 0.47729954 0.47707802 0.47693568
 0.4767181  0.4765014  0.47659996 0.47706673 0.47749573 0.4779494
 0.4785776  0.47920677 0.4799102  0.48053545 0.48141295 0.48245606
 0.48324496 0.48378196 0.48433495 0.48486942 0.4854675  0.48581704
 0.48602995 0.48632485 0.48687255 0.48760155 0.48838496 0.48919392
 0.4900138  0.49075678 0.49127096 0.49141288 0.49120918 0.49084586
 0.49036843 0.48966098 0.48866004 0.48771793 0.48725882 0.4869921
 0.48653007 0.48587513 0.4854034  0.48493046 0.48415324 0.48323986
 0.48255676 0.48211834 0.4814745  0.48034674 0.47903693 0.47808015
 0.47746852 0.4769132  0.47599864 0.47481695 0.47364923 0.47251043
 0.47129694 0.46985826 0.4685104  0.46776083 0.46729666 0.46660528
 0.46568847 0.46497515 0.4648014  0.46498308 0.46508634 0.46498927
 0.46485418 0.46506172 0.46530056 0.4652338  0.46489525 0.46462524
 0.4645524  0.46451193 0.4643052  0.46412513 0.4641461  0.46436453
 0.46447244 0.46449336 0.46468207 0.46501058 0.46546945 0.46559638
 0.46543956 0.46565574 0.46625116 0.46669757 0.46647426 0.4659338
 0.46561283 0.4657732  0.46605977 0.46607825 0.46593535 0.46585688
 0.46603715 0.4663717  0.46673372 0.4670998  0.46764168 0.4683813
 0.46913448 0.46971852 0.4701778  0.47087643 0.47175393 0.47260708
 0.47313517 0.47345766 0.4738199  0.47425604 0.47454125 0.4748188
 0.47529063 0.47601184 0.4766159  0.47696576 0.47734424 0.4781914
 0.4794608  0.48041284 0.4804259  0.47968012 0.47910023 0.47947136
 0.48077247 0.48246592 0.48391277 0.48488244 0.48553622 0.486169
 0.4867254  0.48693615 0.48679572 0.48631763 0.48552734 0.48463267
 0.48378786 0.48284185 0.48150486 0.47994223 0.47841635 0.47719043
 0.4760421  0.47474426 0.47332904 0.47188812 0.4704491  0.46900126
 0.46712977 0.4651407  0.46358562 0.4627288  0.46199492 0.46102703
 0.46010566 0.45984736 0.46003008 0.46018833 0.46035334 0.46028268
 0.46016997 0.4602611  0.46026638 0.45986927 0.45938846 0.4590452
 0.45894808 0.4589036  0.458626   0.4583965  0.4584446  0.4584031
 0.45844385 0.45852572 0.45879352 0.45920166 0.45930788 0.45937642
 0.45969748 0.4603701  0.46100402 0.4614394  0.4614858  0.46156374
 0.46163124 0.46166125 0.46133614 0.46116367 0.46115443 0.46125254
 0.4614994  0.4618029  0.46189228 0.46206018 0.4624844  0.4630704
 0.46383518 0.46446747 0.46504706 0.46582475 0.4668736  0.4678402
 0.46871677 0.46941862 0.47003227 0.47050712 0.47094786 0.47148976
 0.47218055 0.47289622 0.47337535 0.47378063 0.47436333 0.47521654
 0.4761147  0.4767463  0.47702697 0.47700366 0.47657084 0.47543445
 0.47344866 0.47118133 0.4693698  0.46808037 0.46702936 0.46621343
 0.46575683 0.46561053 0.4656385  0.4654476  0.4648704  0.464064
 0.4631809  0.46216282 0.46091652 0.4595538  0.45844394 0.4576192
 0.45693445 0.45604905 0.45513418 0.4544397  0.45388824 0.45307076
 0.45188883 0.45078182 0.45007548 0.44955355 0.44866732 0.44781053
 0.44736448 0.44706902 0.44645575 0.44564378 0.44521606 0.44533464
 0.44511414 0.44425598 0.44355217 0.44393572 0.44470984 0.4444332
 0.44354773 0.4436689  0.44492736 0.44535327 0.44551775 0.44901603]
