Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=26, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_180_192', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_180_192_FITS_ETTm1_ftM_sl180_ll48_pl192_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34189
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=26, out_features=53, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1234688.0
params:  1431.0
Trainable parameters:  1431
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5239650
	speed: 0.0176s/iter; left time: 468.4535s
	iters: 200, epoch: 1 | loss: 0.3650264
	speed: 0.0105s/iter; left time: 278.3348s
Epoch: 1 cost time: 3.529015064239502
Epoch: 1, Steps: 267 | Train Loss: 0.4672846 Vali Loss: 0.6280472 Test Loss: 0.4254878
Validation loss decreased (inf --> 0.628047).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3434865
	speed: 0.0628s/iter; left time: 1653.5059s
	iters: 200, epoch: 2 | loss: 0.3523041
	speed: 0.0104s/iter; left time: 273.7516s
Epoch: 2 cost time: 3.5010440349578857
Epoch: 2, Steps: 267 | Train Loss: 0.3558210 Vali Loss: 0.5581180 Test Loss: 0.3699989
Validation loss decreased (0.628047 --> 0.558118).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3015763
	speed: 0.0597s/iter; left time: 1557.4545s
	iters: 200, epoch: 3 | loss: 0.3280677
	speed: 0.0109s/iter; left time: 283.0998s
Epoch: 3 cost time: 3.4366090297698975
Epoch: 3, Steps: 267 | Train Loss: 0.3388560 Vali Loss: 0.5369686 Test Loss: 0.3553144
Validation loss decreased (0.558118 --> 0.536969).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3006962
	speed: 0.0616s/iter; left time: 1589.0297s
	iters: 200, epoch: 4 | loss: 0.3142969
	speed: 0.0112s/iter; left time: 287.4427s
Epoch: 4 cost time: 3.6216466426849365
Epoch: 4, Steps: 267 | Train Loss: 0.3337787 Vali Loss: 0.5302175 Test Loss: 0.3506110
Validation loss decreased (0.536969 --> 0.530218).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3070898
	speed: 0.0612s/iter; left time: 1561.7411s
	iters: 200, epoch: 5 | loss: 0.3241356
	speed: 0.0112s/iter; left time: 284.9220s
Epoch: 5 cost time: 3.5871171951293945
Epoch: 5, Steps: 267 | Train Loss: 0.3320951 Vali Loss: 0.5270681 Test Loss: 0.3492571
Validation loss decreased (0.530218 --> 0.527068).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3636812
	speed: 0.0613s/iter; left time: 1547.8822s
	iters: 200, epoch: 6 | loss: 0.3505445
	speed: 0.0103s/iter; left time: 258.0635s
Epoch: 6 cost time: 3.3990297317504883
Epoch: 6, Steps: 267 | Train Loss: 0.3313646 Vali Loss: 0.5253897 Test Loss: 0.3491472
Validation loss decreased (0.527068 --> 0.525390).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3090162
	speed: 0.0607s/iter; left time: 1516.5870s
	iters: 200, epoch: 7 | loss: 0.3544177
	speed: 0.0101s/iter; left time: 250.9998s
Epoch: 7 cost time: 3.3899614810943604
Epoch: 7, Steps: 267 | Train Loss: 0.3311034 Vali Loss: 0.5247390 Test Loss: 0.3480893
Validation loss decreased (0.525390 --> 0.524739).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3430326
	speed: 0.0604s/iter; left time: 1494.6446s
	iters: 200, epoch: 8 | loss: 0.3349203
	speed: 0.0106s/iter; left time: 260.9047s
Epoch: 8 cost time: 3.4910082817077637
Epoch: 8, Steps: 267 | Train Loss: 0.3309201 Vali Loss: 0.5241804 Test Loss: 0.3485447
Validation loss decreased (0.524739 --> 0.524180).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3282438
	speed: 0.0606s/iter; left time: 1483.7173s
	iters: 200, epoch: 9 | loss: 0.3531788
	speed: 0.0103s/iter; left time: 250.0073s
Epoch: 9 cost time: 3.3197269439697266
Epoch: 9, Steps: 267 | Train Loss: 0.3307949 Vali Loss: 0.5235857 Test Loss: 0.3481447
Validation loss decreased (0.524180 --> 0.523586).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3156206
	speed: 0.0604s/iter; left time: 1461.9637s
	iters: 200, epoch: 10 | loss: 0.3273028
	speed: 0.0109s/iter; left time: 261.7616s
Epoch: 10 cost time: 3.4141979217529297
Epoch: 10, Steps: 267 | Train Loss: 0.3306585 Vali Loss: 0.5238823 Test Loss: 0.3477042
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3253441
	speed: 0.0625s/iter; left time: 1494.8014s
	iters: 200, epoch: 11 | loss: 0.3153682
	speed: 0.0114s/iter; left time: 271.4282s
Epoch: 11 cost time: 3.6261706352233887
Epoch: 11, Steps: 267 | Train Loss: 0.3306368 Vali Loss: 0.5227581 Test Loss: 0.3481621
Validation loss decreased (0.523586 --> 0.522758).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3060237
	speed: 0.0613s/iter; left time: 1449.8793s
	iters: 200, epoch: 12 | loss: 0.3683482
	speed: 0.0106s/iter; left time: 249.5079s
Epoch: 12 cost time: 3.4177744388580322
Epoch: 12, Steps: 267 | Train Loss: 0.3305888 Vali Loss: 0.5234785 Test Loss: 0.3478536
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3049023
	speed: 0.0641s/iter; left time: 1499.6314s
	iters: 200, epoch: 13 | loss: 0.3117726
	speed: 0.0106s/iter; left time: 247.5581s
Epoch: 13 cost time: 3.555623769760132
Epoch: 13, Steps: 267 | Train Loss: 0.3305124 Vali Loss: 0.5218765 Test Loss: 0.3478079
Validation loss decreased (0.522758 --> 0.521877).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3166207
	speed: 0.0817s/iter; left time: 1890.8219s
	iters: 200, epoch: 14 | loss: 0.2920710
	speed: 0.0106s/iter; left time: 244.6231s
Epoch: 14 cost time: 5.510767459869385
Epoch: 14, Steps: 267 | Train Loss: 0.3304709 Vali Loss: 0.5223789 Test Loss: 0.3480626
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3308148
	speed: 0.0600s/iter; left time: 1371.5576s
	iters: 200, epoch: 15 | loss: 0.3386216
	speed: 0.0104s/iter; left time: 235.7176s
Epoch: 15 cost time: 3.4415693283081055
Epoch: 15, Steps: 267 | Train Loss: 0.3304473 Vali Loss: 0.5225645 Test Loss: 0.3478045
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3343554
	speed: 0.0600s/iter; left time: 1355.4239s
	iters: 200, epoch: 16 | loss: 0.3311176
	speed: 0.0104s/iter; left time: 233.2662s
Epoch: 16 cost time: 3.3602259159088135
Epoch: 16, Steps: 267 | Train Loss: 0.3304020 Vali Loss: 0.5225735 Test Loss: 0.3479304
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3063128
	speed: 0.0602s/iter; left time: 1344.4735s
	iters: 200, epoch: 17 | loss: 0.3179931
	speed: 0.0108s/iter; left time: 239.7356s
Epoch: 17 cost time: 3.4198126792907715
Epoch: 17, Steps: 267 | Train Loss: 0.3304040 Vali Loss: 0.5224413 Test Loss: 0.3477695
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3324969
	speed: 0.0590s/iter; left time: 1302.4166s
	iters: 200, epoch: 18 | loss: 0.3795532
	speed: 0.0102s/iter; left time: 224.1451s
Epoch: 18 cost time: 3.298696517944336
Epoch: 18, Steps: 267 | Train Loss: 0.3303273 Vali Loss: 0.5215115 Test Loss: 0.3476745
Validation loss decreased (0.521877 --> 0.521511).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3085139
	speed: 0.0620s/iter; left time: 1351.9314s
	iters: 200, epoch: 19 | loss: 0.3331006
	speed: 0.0107s/iter; left time: 232.4897s
Epoch: 19 cost time: 3.5580999851226807
Epoch: 19, Steps: 267 | Train Loss: 0.3302956 Vali Loss: 0.5225374 Test Loss: 0.3478664
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3227788
	speed: 0.0624s/iter; left time: 1344.0155s
	iters: 200, epoch: 20 | loss: 0.3184863
	speed: 0.0102s/iter; left time: 219.5903s
Epoch: 20 cost time: 3.494469404220581
Epoch: 20, Steps: 267 | Train Loss: 0.3303291 Vali Loss: 0.5221428 Test Loss: 0.3478246
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3160281
	speed: 0.0624s/iter; left time: 1325.8174s
	iters: 200, epoch: 21 | loss: 0.3307259
	speed: 0.0109s/iter; left time: 230.1848s
Epoch: 21 cost time: 3.590353488922119
Epoch: 21, Steps: 267 | Train Loss: 0.3302839 Vali Loss: 0.5232891 Test Loss: 0.3478763
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3143310
	speed: 0.0621s/iter; left time: 1303.7685s
	iters: 200, epoch: 22 | loss: 0.3380173
	speed: 0.0114s/iter; left time: 237.2683s
Epoch: 22 cost time: 3.6151459217071533
Epoch: 22, Steps: 267 | Train Loss: 0.3302477 Vali Loss: 0.5224217 Test Loss: 0.3479343
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3000582
	speed: 0.0636s/iter; left time: 1318.1905s
	iters: 200, epoch: 23 | loss: 0.3443707
	speed: 0.0104s/iter; left time: 213.8501s
Epoch: 23 cost time: 3.4060161113739014
Epoch: 23, Steps: 267 | Train Loss: 0.3302480 Vali Loss: 0.5227661 Test Loss: 0.3477540
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3425997
	speed: 0.0603s/iter; left time: 1234.2748s
	iters: 200, epoch: 24 | loss: 0.3205917
	speed: 0.0103s/iter; left time: 210.1183s
Epoch: 24 cost time: 3.3787331581115723
Epoch: 24, Steps: 267 | Train Loss: 0.3302406 Vali Loss: 0.5221604 Test Loss: 0.3478081
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2857002
	speed: 0.0609s/iter; left time: 1229.9307s
	iters: 200, epoch: 25 | loss: 0.3315438
	speed: 0.0108s/iter; left time: 217.4527s
Epoch: 25 cost time: 3.4390182495117188
Epoch: 25, Steps: 267 | Train Loss: 0.3301915 Vali Loss: 0.5221079 Test Loss: 0.3477162
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3144919
	speed: 0.0609s/iter; left time: 1212.9773s
	iters: 200, epoch: 26 | loss: 0.3289436
	speed: 0.0103s/iter; left time: 203.9042s
Epoch: 26 cost time: 3.4707772731781006
Epoch: 26, Steps: 267 | Train Loss: 0.3301780 Vali Loss: 0.5226550 Test Loss: 0.3477981
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3122238
	speed: 0.0598s/iter; left time: 1174.8373s
	iters: 200, epoch: 27 | loss: 0.3080949
	speed: 0.0106s/iter; left time: 206.9994s
Epoch: 27 cost time: 3.3127028942108154
Epoch: 27, Steps: 267 | Train Loss: 0.3302269 Vali Loss: 0.5222021 Test Loss: 0.3477414
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3245433
	speed: 0.0607s/iter; left time: 1177.0868s
	iters: 200, epoch: 28 | loss: 0.3384807
	speed: 0.0112s/iter; left time: 217.0348s
Epoch: 28 cost time: 3.476668119430542
Epoch: 28, Steps: 267 | Train Loss: 0.3301195 Vali Loss: 0.5228395 Test Loss: 0.3477323
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3095049
	speed: 0.0725s/iter; left time: 1386.7118s
	iters: 200, epoch: 29 | loss: 0.3402117
	speed: 0.0109s/iter; left time: 207.1080s
Epoch: 29 cost time: 3.723015308380127
Epoch: 29, Steps: 267 | Train Loss: 0.3301658 Vali Loss: 0.5224780 Test Loss: 0.3476421
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3049314
	speed: 0.0650s/iter; left time: 1224.9816s
	iters: 200, epoch: 30 | loss: 0.3283780
	speed: 0.0106s/iter; left time: 198.1246s
Epoch: 30 cost time: 3.428704023361206
Epoch: 30, Steps: 267 | Train Loss: 0.3301508 Vali Loss: 0.5223480 Test Loss: 0.3477157
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3442977
	speed: 0.0634s/iter; left time: 1177.9360s
	iters: 200, epoch: 31 | loss: 0.3195091
	speed: 0.0102s/iter; left time: 189.1720s
Epoch: 31 cost time: 3.544469118118286
Epoch: 31, Steps: 267 | Train Loss: 0.3301770 Vali Loss: 0.5224209 Test Loss: 0.3477666
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3186281
	speed: 0.0693s/iter; left time: 1269.6381s
	iters: 200, epoch: 32 | loss: 0.3200598
	speed: 0.0105s/iter; left time: 190.4500s
Epoch: 32 cost time: 3.5001072883605957
Epoch: 32, Steps: 267 | Train Loss: 0.3301924 Vali Loss: 0.5219657 Test Loss: 0.3476085
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3139758
	speed: 0.0611s/iter; left time: 1102.9605s
	iters: 200, epoch: 33 | loss: 0.3121216
	speed: 0.0103s/iter; left time: 185.0802s
Epoch: 33 cost time: 3.505427122116089
Epoch: 33, Steps: 267 | Train Loss: 0.3301691 Vali Loss: 0.5223427 Test Loss: 0.3477134
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3658938
	speed: 0.0608s/iter; left time: 1081.4473s
	iters: 200, epoch: 34 | loss: 0.3214350
	speed: 0.0101s/iter; left time: 179.4560s
Epoch: 34 cost time: 3.3852174282073975
Epoch: 34, Steps: 267 | Train Loss: 0.3301501 Vali Loss: 0.5220463 Test Loss: 0.3476933
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3570593
	speed: 0.0584s/iter; left time: 1022.7714s
	iters: 200, epoch: 35 | loss: 0.3536409
	speed: 0.0106s/iter; left time: 183.9144s
Epoch: 35 cost time: 3.4082202911376953
Epoch: 35, Steps: 267 | Train Loss: 0.3301163 Vali Loss: 0.5219173 Test Loss: 0.3476740
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3473556
	speed: 0.0590s/iter; left time: 1017.3491s
	iters: 200, epoch: 36 | loss: 0.3312677
	speed: 0.0107s/iter; left time: 183.9165s
Epoch: 36 cost time: 3.3091564178466797
Epoch: 36, Steps: 267 | Train Loss: 0.3300729 Vali Loss: 0.5221376 Test Loss: 0.3476857
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3573146
	speed: 0.0599s/iter; left time: 1016.8883s
	iters: 200, epoch: 37 | loss: 0.3351389
	speed: 0.0109s/iter; left time: 184.4129s
Epoch: 37 cost time: 3.5221030712127686
Epoch: 37, Steps: 267 | Train Loss: 0.3300935 Vali Loss: 0.5220318 Test Loss: 0.3477562
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3340079
	speed: 0.0617s/iter; left time: 1031.4600s
	iters: 200, epoch: 38 | loss: 0.3257125
	speed: 0.0106s/iter; left time: 176.8223s
Epoch: 38 cost time: 3.4165472984313965
Epoch: 38, Steps: 267 | Train Loss: 0.3301045 Vali Loss: 0.5220501 Test Loss: 0.3477911
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_180_192_FITS_ETTm1_ftM_sl180_ll48_pl192_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.34786003828048706, mae:0.368930846452713, rse:0.5614405274391174, corr:[0.5500195  0.5530972  0.55149484 0.54875785 0.54741174 0.5476162
 0.5480484  0.5480621  0.54752344 0.5472653  0.54787683 0.54864156
 0.5487668  0.54752415 0.5454384  0.54340327 0.5417062  0.5402615
 0.5387978  0.53708285 0.53511614 0.53297335 0.5307855  0.5286771
 0.5265959  0.52454525 0.52268106 0.52104044 0.5197774  0.51902044
 0.5189773  0.51943606 0.5199474  0.5202326  0.52014774 0.5198328
 0.51936984 0.51887    0.51852745 0.51821923 0.51794523 0.51758575
 0.517208   0.51699775 0.51699376 0.51717263 0.51745427 0.5176877
 0.5177588  0.51763713 0.5175019  0.5175299  0.51778346 0.5181311
 0.51841134 0.5184679  0.5183683  0.51808035 0.51777244 0.5175018
 0.5173831  0.5173957  0.5174173  0.51734966 0.51720494 0.51717865
 0.5173161  0.51757646 0.51798785 0.51842535 0.5187898  0.51899004
 0.5190331  0.51898396 0.5190274  0.5191169  0.51924866 0.5193171
 0.5192581  0.5190814  0.51891583 0.51881856 0.51880866 0.5187533
 0.51859975 0.5183947  0.518176   0.51785976 0.51742524 0.51701546
 0.5166816  0.5164562  0.51631624 0.51620054 0.5159379  0.5153394
 0.514452   0.5135124  0.5127569  0.51229703 0.512234   0.512503
 0.5128883  0.51324743 0.51365626 0.5142958  0.51526284 0.51643425
 0.5175058  0.51816344 0.5183511  0.5183422  0.5182525  0.5181967
 0.5181683  0.51816404 0.51801825 0.51763093 0.51708215 0.5164637
 0.51592344 0.5154078  0.51490325 0.51446015 0.514025   0.51358277
 0.51325303 0.51313287 0.51321405 0.51341134 0.5135608  0.51351476
 0.51325023 0.5129426  0.5126485  0.5123552  0.512167   0.51200604
 0.5118307  0.5117371  0.5117346  0.511834   0.5119964  0.51215625
 0.5122045  0.51214254 0.51195127 0.5118362  0.5120085  0.51225525
 0.5124737  0.51257795 0.5124867  0.5122645  0.511945   0.5117453
 0.5117415  0.51189405 0.511984   0.51193696 0.51173896 0.5115375
 0.5115119  0.51174337 0.51212525 0.5125635  0.5128417  0.5128928
 0.51283914 0.5127976  0.5128577  0.5131196  0.5133329  0.51324064
 0.51279336 0.51211816 0.51158327 0.51148766 0.51175815 0.5121657
 0.51231843 0.512027   0.51141715 0.51093495 0.5109941  0.51158386
 0.512261   0.51253724 0.5124258  0.5127962  0.51485795 0.518132  ]
