Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=74, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_720_720_FITS_ETTm1_ftM_sl720_ll48_pl720_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=74, out_features=148, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  9812992.0
params:  11100.0
Trainable parameters:  11100
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5010173
	speed: 0.0348s/iter; left time: 893.1858s
	iters: 200, epoch: 1 | loss: 0.4066080
	speed: 0.0276s/iter; left time: 706.2608s
Epoch: 1 cost time: 8.10860824584961
Epoch: 1, Steps: 258 | Train Loss: 0.5000284 Vali Loss: 1.1972593 Test Loss: 0.5945662
Validation loss decreased (inf --> 1.197259).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3307959
	speed: 0.1383s/iter; left time: 3517.9718s
	iters: 200, epoch: 2 | loss: 0.3032863
	speed: 0.0330s/iter; left time: 836.2182s
Epoch: 2 cost time: 9.55212116241455
Epoch: 2, Steps: 258 | Train Loss: 0.3234422 Vali Loss: 1.0659019 Test Loss: 0.5048543
Validation loss decreased (1.197259 --> 1.065902).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2652995
	speed: 0.1527s/iter; left time: 3845.9808s
	iters: 200, epoch: 3 | loss: 0.2584271
	speed: 0.0358s/iter; left time: 898.9914s
Epoch: 3 cost time: 9.6720552444458
Epoch: 3, Steps: 258 | Train Loss: 0.2716426 Vali Loss: 1.0141313 Test Loss: 0.4697957
Validation loss decreased (1.065902 --> 1.014131).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2539927
	speed: 0.1490s/iter; left time: 3713.3901s
	iters: 200, epoch: 4 | loss: 0.2196151
	speed: 0.0372s/iter; left time: 923.6399s
Epoch: 4 cost time: 10.412999868392944
Epoch: 4, Steps: 258 | Train Loss: 0.2480493 Vali Loss: 0.9881434 Test Loss: 0.4515314
Validation loss decreased (1.014131 --> 0.988143).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2500425
	speed: 0.1447s/iter; left time: 3569.3115s
	iters: 200, epoch: 5 | loss: 0.2201651
	speed: 0.0336s/iter; left time: 825.0459s
Epoch: 5 cost time: 9.439153909683228
Epoch: 5, Steps: 258 | Train Loss: 0.2353795 Vali Loss: 0.9695007 Test Loss: 0.4398259
Validation loss decreased (0.988143 --> 0.969501).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2174145
	speed: 0.1588s/iter; left time: 3876.8398s
	iters: 200, epoch: 6 | loss: 0.2311713
	speed: 0.0325s/iter; left time: 790.9473s
Epoch: 6 cost time: 9.459330558776855
Epoch: 6, Steps: 258 | Train Loss: 0.2276228 Vali Loss: 0.9605027 Test Loss: 0.4314863
Validation loss decreased (0.969501 --> 0.960503).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2280852
	speed: 0.1528s/iter; left time: 3690.3665s
	iters: 200, epoch: 7 | loss: 0.2169555
	speed: 0.0378s/iter; left time: 909.5039s
Epoch: 7 cost time: 10.215188026428223
Epoch: 7, Steps: 258 | Train Loss: 0.2225100 Vali Loss: 0.9519953 Test Loss: 0.4264993
Validation loss decreased (0.960503 --> 0.951995).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2299331
	speed: 0.1475s/iter; left time: 3525.2374s
	iters: 200, epoch: 8 | loss: 0.2110244
	speed: 0.0342s/iter; left time: 814.1624s
Epoch: 8 cost time: 9.969082593917847
Epoch: 8, Steps: 258 | Train Loss: 0.2191232 Vali Loss: 0.9472034 Test Loss: 0.4225256
Validation loss decreased (0.951995 --> 0.947203).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2167791
	speed: 0.1507s/iter; left time: 3561.5152s
	iters: 200, epoch: 9 | loss: 0.2405268
	speed: 0.0308s/iter; left time: 723.9318s
Epoch: 9 cost time: 8.942431449890137
Epoch: 9, Steps: 258 | Train Loss: 0.2168306 Vali Loss: 0.9453102 Test Loss: 0.4197815
Validation loss decreased (0.947203 --> 0.945310).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1904951
	speed: 0.1527s/iter; left time: 3569.9628s
	iters: 200, epoch: 10 | loss: 0.2349274
	speed: 0.0365s/iter; left time: 850.0945s
Epoch: 10 cost time: 9.695152521133423
Epoch: 10, Steps: 258 | Train Loss: 0.2151526 Vali Loss: 0.9431666 Test Loss: 0.4180697
Validation loss decreased (0.945310 --> 0.943167).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2084035
	speed: 0.1550s/iter; left time: 3583.4089s
	iters: 200, epoch: 11 | loss: 0.2035293
	speed: 0.0337s/iter; left time: 775.2852s
Epoch: 11 cost time: 10.535057544708252
Epoch: 11, Steps: 258 | Train Loss: 0.2139337 Vali Loss: 0.9420663 Test Loss: 0.4170933
Validation loss decreased (0.943167 --> 0.942066).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2184874
	speed: 0.1655s/iter; left time: 3784.4796s
	iters: 200, epoch: 12 | loss: 0.2156184
	speed: 0.0341s/iter; left time: 775.1724s
Epoch: 12 cost time: 9.885611772537231
Epoch: 12, Steps: 258 | Train Loss: 0.2131455 Vali Loss: 0.9406499 Test Loss: 0.4166472
Validation loss decreased (0.942066 --> 0.940650).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2169824
	speed: 0.1453s/iter; left time: 3284.9475s
	iters: 200, epoch: 13 | loss: 0.2307098
	speed: 0.0367s/iter; left time: 826.6955s
Epoch: 13 cost time: 10.420909643173218
Epoch: 13, Steps: 258 | Train Loss: 0.2125788 Vali Loss: 0.9406432 Test Loss: 0.4167569
Validation loss decreased (0.940650 --> 0.940643).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2154130
	speed: 0.1572s/iter; left time: 3513.4692s
	iters: 200, epoch: 14 | loss: 0.2052199
	speed: 0.0391s/iter; left time: 870.0656s
Epoch: 14 cost time: 10.895477771759033
Epoch: 14, Steps: 258 | Train Loss: 0.2121415 Vali Loss: 0.9395803 Test Loss: 0.4164980
Validation loss decreased (0.940643 --> 0.939580).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2094658
	speed: 0.1554s/iter; left time: 3433.4331s
	iters: 200, epoch: 15 | loss: 0.2013419
	speed: 0.0415s/iter; left time: 911.9912s
Epoch: 15 cost time: 11.038139343261719
Epoch: 15, Steps: 258 | Train Loss: 0.2118650 Vali Loss: 0.9398302 Test Loss: 0.4167195
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2273258
	speed: 0.1608s/iter; left time: 3511.0337s
	iters: 200, epoch: 16 | loss: 0.2156697
	speed: 0.0405s/iter; left time: 880.4127s
Epoch: 16 cost time: 11.530194759368896
Epoch: 16, Steps: 258 | Train Loss: 0.2116406 Vali Loss: 0.9397172 Test Loss: 0.4169326
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2158363
	speed: 0.1560s/iter; left time: 3364.4038s
	iters: 200, epoch: 17 | loss: 0.2178413
	speed: 0.0360s/iter; left time: 773.4390s
Epoch: 17 cost time: 10.783891201019287
Epoch: 17, Steps: 258 | Train Loss: 0.2115271 Vali Loss: 0.9389577 Test Loss: 0.4171219
Validation loss decreased (0.939580 --> 0.938958).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2021318
	speed: 0.1529s/iter; left time: 3258.8020s
	iters: 200, epoch: 18 | loss: 0.2001671
	speed: 0.0307s/iter; left time: 651.2215s
Epoch: 18 cost time: 9.240561485290527
Epoch: 18, Steps: 258 | Train Loss: 0.2114256 Vali Loss: 0.9398771 Test Loss: 0.4173356
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2179300
	speed: 0.1628s/iter; left time: 3428.4011s
	iters: 200, epoch: 19 | loss: 0.2019952
	speed: 0.0414s/iter; left time: 866.6378s
Epoch: 19 cost time: 11.190690279006958
Epoch: 19, Steps: 258 | Train Loss: 0.2113781 Vali Loss: 0.9399772 Test Loss: 0.4173723
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2020617
	speed: 0.1442s/iter; left time: 2998.9038s
	iters: 200, epoch: 20 | loss: 0.2209165
	speed: 0.0338s/iter; left time: 699.0965s
Epoch: 20 cost time: 9.572218656539917
Epoch: 20, Steps: 258 | Train Loss: 0.2112716 Vali Loss: 0.9404610 Test Loss: 0.4174985
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2263705
	speed: 0.1608s/iter; left time: 3302.6013s
	iters: 200, epoch: 21 | loss: 0.2108828
	speed: 0.0385s/iter; left time: 787.8374s
Epoch: 21 cost time: 10.927764654159546
Epoch: 21, Steps: 258 | Train Loss: 0.2112906 Vali Loss: 0.9399179 Test Loss: 0.4179731
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2017825
	speed: 0.1405s/iter; left time: 2849.3461s
	iters: 200, epoch: 22 | loss: 0.2151540
	speed: 0.0325s/iter; left time: 655.7366s
Epoch: 22 cost time: 9.479091167449951
Epoch: 22, Steps: 258 | Train Loss: 0.2113516 Vali Loss: 0.9404166 Test Loss: 0.4178675
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2131665
	speed: 0.1450s/iter; left time: 2904.3193s
	iters: 200, epoch: 23 | loss: 0.2036296
	speed: 0.0314s/iter; left time: 626.1442s
Epoch: 23 cost time: 9.199162483215332
Epoch: 23, Steps: 258 | Train Loss: 0.2112936 Vali Loss: 0.9400963 Test Loss: 0.4181407
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2035124
	speed: 0.1491s/iter; left time: 2946.3325s
	iters: 200, epoch: 24 | loss: 0.2165638
	speed: 0.0296s/iter; left time: 582.5533s
Epoch: 24 cost time: 8.744832038879395
Epoch: 24, Steps: 258 | Train Loss: 0.2112696 Vali Loss: 0.9398425 Test Loss: 0.4184543
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1947035
	speed: 0.1531s/iter; left time: 2987.2329s
	iters: 200, epoch: 25 | loss: 0.2124742
	speed: 0.0359s/iter; left time: 696.4501s
Epoch: 25 cost time: 10.24743366241455
Epoch: 25, Steps: 258 | Train Loss: 0.2112404 Vali Loss: 0.9391906 Test Loss: 0.4184515
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2031326
	speed: 0.1355s/iter; left time: 2608.9976s
	iters: 200, epoch: 26 | loss: 0.2203928
	speed: 0.0312s/iter; left time: 598.1618s
Epoch: 26 cost time: 8.875166177749634
Epoch: 26, Steps: 258 | Train Loss: 0.2112892 Vali Loss: 0.9405486 Test Loss: 0.4184268
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2010929
	speed: 0.1445s/iter; left time: 2744.4478s
	iters: 200, epoch: 27 | loss: 0.1900059
	speed: 0.0372s/iter; left time: 702.0412s
Epoch: 27 cost time: 9.765660762786865
Epoch: 27, Steps: 258 | Train Loss: 0.2112212 Vali Loss: 0.9406949 Test Loss: 0.4184715
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2178306
	speed: 0.1447s/iter; left time: 2711.2322s
	iters: 200, epoch: 28 | loss: 0.2232025
	speed: 0.0325s/iter; left time: 605.2104s
Epoch: 28 cost time: 9.261723756790161
Epoch: 28, Steps: 258 | Train Loss: 0.2112816 Vali Loss: 0.9399189 Test Loss: 0.4185392
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2013091
	speed: 0.1317s/iter; left time: 2434.0907s
	iters: 200, epoch: 29 | loss: 0.2104130
	speed: 0.0355s/iter; left time: 652.4153s
Epoch: 29 cost time: 9.688221454620361
Epoch: 29, Steps: 258 | Train Loss: 0.2112615 Vali Loss: 0.9404410 Test Loss: 0.4186018
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2279538
	speed: 0.1423s/iter; left time: 2592.5775s
	iters: 200, epoch: 30 | loss: 0.2296792
	speed: 0.0397s/iter; left time: 719.2259s
Epoch: 30 cost time: 10.578697204589844
Epoch: 30, Steps: 258 | Train Loss: 0.2112532 Vali Loss: 0.9396794 Test Loss: 0.4184465
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2274566
	speed: 0.1489s/iter; left time: 2673.6455s
	iters: 200, epoch: 31 | loss: 0.2397879
	speed: 0.0329s/iter; left time: 588.1690s
Epoch: 31 cost time: 9.64789080619812
Epoch: 31, Steps: 258 | Train Loss: 0.2111753 Vali Loss: 0.9401356 Test Loss: 0.4181416
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1976337
	speed: 0.1469s/iter; left time: 2601.3359s
	iters: 200, epoch: 32 | loss: 0.2235536
	speed: 0.0315s/iter; left time: 553.8803s
Epoch: 32 cost time: 8.839510440826416
Epoch: 32, Steps: 258 | Train Loss: 0.2112645 Vali Loss: 0.9402162 Test Loss: 0.4185254
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2266876
	speed: 0.1593s/iter; left time: 2779.3264s
	iters: 200, epoch: 33 | loss: 0.2032705
	speed: 0.0320s/iter; left time: 554.7748s
Epoch: 33 cost time: 9.307102918624878
Epoch: 33, Steps: 258 | Train Loss: 0.2111582 Vali Loss: 0.9393335 Test Loss: 0.4183334
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2238433
	speed: 0.1526s/iter; left time: 2623.2319s
	iters: 200, epoch: 34 | loss: 0.2115002
	speed: 0.0334s/iter; left time: 571.5049s
Epoch: 34 cost time: 10.26593542098999
Epoch: 34, Steps: 258 | Train Loss: 0.2112576 Vali Loss: 0.9398845 Test Loss: 0.4185086
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2106898
	speed: 0.1542s/iter; left time: 2610.3967s
	iters: 200, epoch: 35 | loss: 0.2121909
	speed: 0.0323s/iter; left time: 542.8489s
Epoch: 35 cost time: 9.227669954299927
Epoch: 35, Steps: 258 | Train Loss: 0.2112350 Vali Loss: 0.9393822 Test Loss: 0.4185929
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2100910
	speed: 0.1529s/iter; left time: 2549.3512s
	iters: 200, epoch: 36 | loss: 0.2204784
	speed: 0.0313s/iter; left time: 518.7063s
Epoch: 36 cost time: 8.875935554504395
Epoch: 36, Steps: 258 | Train Loss: 0.2112605 Vali Loss: 0.9397687 Test Loss: 0.4185715
EarlyStopping counter: 19 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2004302
	speed: 0.1467s/iter; left time: 2408.0168s
	iters: 200, epoch: 37 | loss: 0.2156852
	speed: 0.0311s/iter; left time: 507.2806s
Epoch: 37 cost time: 9.29773736000061
Epoch: 37, Steps: 258 | Train Loss: 0.2111584 Vali Loss: 0.9404666 Test Loss: 0.4185337
EarlyStopping counter: 20 out of 20
Early stopping
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=74, out_features=148, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  9812992.0
params:  11100.0
Trainable parameters:  11100
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4007016
	speed: 0.0457s/iter; left time: 1174.2285s
	iters: 200, epoch: 1 | loss: 0.3968253
	speed: 0.0342s/iter; left time: 876.2040s
Epoch: 1 cost time: 10.033564805984497
Epoch: 1, Steps: 258 | Train Loss: 0.3989578 Vali Loss: 0.9355726 Test Loss: 0.4171869
Validation loss decreased (inf --> 0.935573).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3898824
	speed: 0.1458s/iter; left time: 3708.7455s
	iters: 200, epoch: 2 | loss: 0.3942195
	speed: 0.0321s/iter; left time: 814.7417s
Epoch: 2 cost time: 9.38714599609375
Epoch: 2, Steps: 258 | Train Loss: 0.3982314 Vali Loss: 0.9341932 Test Loss: 0.4166277
Validation loss decreased (0.935573 --> 0.934193).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4035067
	speed: 0.1529s/iter; left time: 3851.9293s
	iters: 200, epoch: 3 | loss: 0.3782141
	speed: 0.0444s/iter; left time: 1115.0110s
Epoch: 3 cost time: 12.195966482162476
Epoch: 3, Steps: 258 | Train Loss: 0.3979362 Vali Loss: 0.9329465 Test Loss: 0.4171227
Validation loss decreased (0.934193 --> 0.932947).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4441115
	speed: 0.1521s/iter; left time: 3792.2220s
	iters: 200, epoch: 4 | loss: 0.3826001
	speed: 0.0326s/iter; left time: 809.5503s
Epoch: 4 cost time: 10.083759307861328
Epoch: 4, Steps: 258 | Train Loss: 0.3978365 Vali Loss: 0.9326876 Test Loss: 0.4169776
Validation loss decreased (0.932947 --> 0.932688).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4132917
	speed: 0.1526s/iter; left time: 3763.6122s
	iters: 200, epoch: 5 | loss: 0.3594616
	speed: 0.0439s/iter; left time: 1079.2485s
Epoch: 5 cost time: 11.029282569885254
Epoch: 5, Steps: 258 | Train Loss: 0.3977617 Vali Loss: 0.9318411 Test Loss: 0.4176002
Validation loss decreased (0.932688 --> 0.931841).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3800313
	speed: 0.1487s/iter; left time: 3629.2590s
	iters: 200, epoch: 6 | loss: 0.3803335
	speed: 0.0377s/iter; left time: 916.0180s
Epoch: 6 cost time: 10.850583553314209
Epoch: 6, Steps: 258 | Train Loss: 0.3975904 Vali Loss: 0.9340168 Test Loss: 0.4173861
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4074275
	speed: 0.1476s/iter; left time: 3565.6768s
	iters: 200, epoch: 7 | loss: 0.3693922
	speed: 0.0354s/iter; left time: 850.8349s
Epoch: 7 cost time: 9.61422610282898
Epoch: 7, Steps: 258 | Train Loss: 0.3975387 Vali Loss: 0.9323276 Test Loss: 0.4164000
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4098082
	speed: 0.1533s/iter; left time: 3664.0682s
	iters: 200, epoch: 8 | loss: 0.3657699
	speed: 0.0380s/iter; left time: 904.3556s
Epoch: 8 cost time: 10.719133377075195
Epoch: 8, Steps: 258 | Train Loss: 0.3975768 Vali Loss: 0.9321104 Test Loss: 0.4172074
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4451066
	speed: 0.1719s/iter; left time: 4062.9029s
	iters: 200, epoch: 9 | loss: 0.3778332
	speed: 0.0399s/iter; left time: 937.9518s
Epoch: 9 cost time: 11.598334550857544
Epoch: 9, Steps: 258 | Train Loss: 0.3974438 Vali Loss: 0.9321973 Test Loss: 0.4173571
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3836920
	speed: 0.1485s/iter; left time: 3471.1632s
	iters: 200, epoch: 10 | loss: 0.3876919
	speed: 0.0402s/iter; left time: 935.8124s
Epoch: 10 cost time: 10.258652210235596
Epoch: 10, Steps: 258 | Train Loss: 0.3973711 Vali Loss: 0.9319274 Test Loss: 0.4168206
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3754658
	speed: 0.1447s/iter; left time: 3346.0735s
	iters: 200, epoch: 11 | loss: 0.4096794
	speed: 0.0333s/iter; left time: 765.7196s
Epoch: 11 cost time: 9.721030235290527
Epoch: 11, Steps: 258 | Train Loss: 0.3974482 Vali Loss: 0.9331845 Test Loss: 0.4171350
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3685586
	speed: 0.1484s/iter; left time: 3393.6576s
	iters: 200, epoch: 12 | loss: 0.3897341
	speed: 0.0325s/iter; left time: 740.7912s
Epoch: 12 cost time: 9.712782859802246
Epoch: 12, Steps: 258 | Train Loss: 0.3974240 Vali Loss: 0.9318412 Test Loss: 0.4170591
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3827895
	speed: 0.1440s/iter; left time: 3254.2750s
	iters: 200, epoch: 13 | loss: 0.4370928
	speed: 0.0360s/iter; left time: 809.9013s
Epoch: 13 cost time: 10.881584167480469
Epoch: 13, Steps: 258 | Train Loss: 0.3972901 Vali Loss: 0.9323557 Test Loss: 0.4169788
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4069902
	speed: 0.1466s/iter; left time: 3275.7464s
	iters: 200, epoch: 14 | loss: 0.4014217
	speed: 0.0364s/iter; left time: 810.9028s
Epoch: 14 cost time: 10.257386445999146
Epoch: 14, Steps: 258 | Train Loss: 0.3972557 Vali Loss: 0.9325668 Test Loss: 0.4173138
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3937926
	speed: 0.1430s/iter; left time: 3159.1164s
	iters: 200, epoch: 15 | loss: 0.4046957
	speed: 0.0304s/iter; left time: 669.2744s
Epoch: 15 cost time: 8.80919885635376
Epoch: 15, Steps: 258 | Train Loss: 0.3972450 Vali Loss: 0.9320117 Test Loss: 0.4166382
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4058860
	speed: 0.1429s/iter; left time: 3120.6384s
	iters: 200, epoch: 16 | loss: 0.4004698
	speed: 0.0371s/iter; left time: 805.8493s
Epoch: 16 cost time: 10.233514308929443
Epoch: 16, Steps: 258 | Train Loss: 0.3971600 Vali Loss: 0.9311270 Test Loss: 0.4169332
Validation loss decreased (0.931841 --> 0.931127).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3886188
	speed: 0.1413s/iter; left time: 3047.8826s
	iters: 200, epoch: 17 | loss: 0.4057926
	speed: 0.0309s/iter; left time: 662.5307s
Epoch: 17 cost time: 8.68813705444336
Epoch: 17, Steps: 258 | Train Loss: 0.3972531 Vali Loss: 0.9316920 Test Loss: 0.4172775
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4166816
	speed: 0.1457s/iter; left time: 3106.4668s
	iters: 200, epoch: 18 | loss: 0.3850232
	speed: 0.0383s/iter; left time: 812.3708s
Epoch: 18 cost time: 10.950164794921875
Epoch: 18, Steps: 258 | Train Loss: 0.3972273 Vali Loss: 0.9316441 Test Loss: 0.4171478
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3880100
	speed: 0.1550s/iter; left time: 3263.3151s
	iters: 200, epoch: 19 | loss: 0.3828203
	speed: 0.0390s/iter; left time: 816.9586s
Epoch: 19 cost time: 10.984544515609741
Epoch: 19, Steps: 258 | Train Loss: 0.3972341 Vali Loss: 0.9309314 Test Loss: 0.4169245
Validation loss decreased (0.931127 --> 0.930931).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4101864
	speed: 0.1508s/iter; left time: 3136.4792s
	iters: 200, epoch: 20 | loss: 0.3982926
	speed: 0.0326s/iter; left time: 674.6738s
Epoch: 20 cost time: 8.911752462387085
Epoch: 20, Steps: 258 | Train Loss: 0.3971258 Vali Loss: 0.9316949 Test Loss: 0.4170955
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3709414
	speed: 0.1445s/iter; left time: 2967.5109s
	iters: 200, epoch: 21 | loss: 0.4026863
	speed: 0.0331s/iter; left time: 675.7016s
Epoch: 21 cost time: 9.398620128631592
Epoch: 21, Steps: 258 | Train Loss: 0.3971979 Vali Loss: 0.9310684 Test Loss: 0.4170496
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3531068
	speed: 0.1426s/iter; left time: 2892.9280s
	iters: 200, epoch: 22 | loss: 0.3963097
	speed: 0.0358s/iter; left time: 722.4688s
Epoch: 22 cost time: 9.925631523132324
Epoch: 22, Steps: 258 | Train Loss: 0.3971757 Vali Loss: 0.9317954 Test Loss: 0.4172598
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3650333
	speed: 0.1526s/iter; left time: 3055.7835s
	iters: 200, epoch: 23 | loss: 0.3921908
	speed: 0.0336s/iter; left time: 669.1604s
Epoch: 23 cost time: 9.895097494125366
Epoch: 23, Steps: 258 | Train Loss: 0.3970416 Vali Loss: 0.9317812 Test Loss: 0.4169673
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4478560
	speed: 0.1421s/iter; left time: 2807.9051s
	iters: 200, epoch: 24 | loss: 0.4402403
	speed: 0.0359s/iter; left time: 706.3694s
Epoch: 24 cost time: 10.111284494400024
Epoch: 24, Steps: 258 | Train Loss: 0.3970814 Vali Loss: 0.9314463 Test Loss: 0.4171081
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3614214
	speed: 0.1507s/iter; left time: 2940.0481s
	iters: 200, epoch: 25 | loss: 0.3934573
	speed: 0.0371s/iter; left time: 720.0162s
Epoch: 25 cost time: 9.927801132202148
Epoch: 25, Steps: 258 | Train Loss: 0.3970629 Vali Loss: 0.9310615 Test Loss: 0.4170987
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3894223
	speed: 0.1361s/iter; left time: 2620.5970s
	iters: 200, epoch: 26 | loss: 0.3997032
	speed: 0.0296s/iter; left time: 567.7402s
Epoch: 26 cost time: 8.619084358215332
Epoch: 26, Steps: 258 | Train Loss: 0.3971503 Vali Loss: 0.9311990 Test Loss: 0.4172730
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3708747
	speed: 0.1487s/iter; left time: 2823.7354s
	iters: 200, epoch: 27 | loss: 0.3851594
	speed: 0.0383s/iter; left time: 723.1754s
Epoch: 27 cost time: 10.79849910736084
Epoch: 27, Steps: 258 | Train Loss: 0.3971373 Vali Loss: 0.9320592 Test Loss: 0.4170745
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3700553
	speed: 0.1475s/iter; left time: 2762.6554s
	iters: 200, epoch: 28 | loss: 0.3878533
	speed: 0.0383s/iter; left time: 714.0831s
Epoch: 28 cost time: 9.638345956802368
Epoch: 28, Steps: 258 | Train Loss: 0.3970552 Vali Loss: 0.9312037 Test Loss: 0.4167509
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3763139
	speed: 0.1446s/iter; left time: 2671.9873s
	iters: 200, epoch: 29 | loss: 0.4340684
	speed: 0.0305s/iter; left time: 560.5013s
Epoch: 29 cost time: 8.71621584892273
Epoch: 29, Steps: 258 | Train Loss: 0.3970799 Vali Loss: 0.9318246 Test Loss: 0.4171394
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4079549
	speed: 0.1554s/iter; left time: 2832.1423s
	iters: 200, epoch: 30 | loss: 0.3988392
	speed: 0.0401s/iter; left time: 725.6674s
Epoch: 30 cost time: 10.26720118522644
Epoch: 30, Steps: 258 | Train Loss: 0.3971008 Vali Loss: 0.9319881 Test Loss: 0.4168479
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3987267
	speed: 0.1452s/iter; left time: 2607.0432s
	iters: 200, epoch: 31 | loss: 0.3717796
	speed: 0.0341s/iter; left time: 609.0636s
Epoch: 31 cost time: 10.154839515686035
Epoch: 31, Steps: 258 | Train Loss: 0.3969743 Vali Loss: 0.9309451 Test Loss: 0.4170296
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3750869
	speed: 0.1555s/iter; left time: 2752.3642s
	iters: 200, epoch: 32 | loss: 0.4084013
	speed: 0.0360s/iter; left time: 634.2391s
Epoch: 32 cost time: 9.598765134811401
Epoch: 32, Steps: 258 | Train Loss: 0.3969655 Vali Loss: 0.9311985 Test Loss: 0.4174566
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3971975
	speed: 0.1431s/iter; left time: 2495.9138s
	iters: 200, epoch: 33 | loss: 0.3835469
	speed: 0.0281s/iter; left time: 486.6653s
Epoch: 33 cost time: 8.038096189498901
Epoch: 33, Steps: 258 | Train Loss: 0.3969748 Vali Loss: 0.9299809 Test Loss: 0.4170594
Validation loss decreased (0.930931 --> 0.929981).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4001216
	speed: 0.1528s/iter; left time: 2626.7407s
	iters: 200, epoch: 34 | loss: 0.3906761
	speed: 0.0412s/iter; left time: 703.7377s
Epoch: 34 cost time: 11.28736925125122
Epoch: 34, Steps: 258 | Train Loss: 0.3970544 Vali Loss: 0.9309030 Test Loss: 0.4171121
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3893763
	speed: 0.1443s/iter; left time: 2442.1397s
	iters: 200, epoch: 35 | loss: 0.4030208
	speed: 0.0363s/iter; left time: 611.1687s
Epoch: 35 cost time: 9.371776342391968
Epoch: 35, Steps: 258 | Train Loss: 0.3970975 Vali Loss: 0.9314622 Test Loss: 0.4171527
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3993309
	speed: 0.1390s/iter; left time: 2317.4900s
	iters: 200, epoch: 36 | loss: 0.4171748
	speed: 0.0393s/iter; left time: 650.4437s
Epoch: 36 cost time: 10.588770151138306
Epoch: 36, Steps: 258 | Train Loss: 0.3969041 Vali Loss: 0.9311631 Test Loss: 0.4170333
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3901549
	speed: 0.1641s/iter; left time: 2694.1584s
	iters: 200, epoch: 37 | loss: 0.3494384
	speed: 0.0373s/iter; left time: 608.3961s
Epoch: 37 cost time: 11.142717361450195
Epoch: 37, Steps: 258 | Train Loss: 0.3970496 Vali Loss: 0.9317727 Test Loss: 0.4169932
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4049922
	speed: 0.1510s/iter; left time: 2438.8854s
	iters: 200, epoch: 38 | loss: 0.3995752
	speed: 0.0319s/iter; left time: 512.2970s
Epoch: 38 cost time: 9.183387279510498
Epoch: 38, Steps: 258 | Train Loss: 0.3969554 Vali Loss: 0.9312965 Test Loss: 0.4170190
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3716643
	speed: 0.1517s/iter; left time: 2411.9627s
	iters: 200, epoch: 39 | loss: 0.3930660
	speed: 0.0352s/iter; left time: 556.2616s
Epoch: 39 cost time: 10.026318073272705
Epoch: 39, Steps: 258 | Train Loss: 0.3969481 Vali Loss: 0.9315036 Test Loss: 0.4170397
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.4122069
	speed: 0.1447s/iter; left time: 2263.1120s
	iters: 200, epoch: 40 | loss: 0.4266236
	speed: 0.0326s/iter; left time: 506.8822s
Epoch: 40 cost time: 9.2015221118927
Epoch: 40, Steps: 258 | Train Loss: 0.3970074 Vali Loss: 0.9308626 Test Loss: 0.4170706
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.4458095
	speed: 0.1444s/iter; left time: 2220.8202s
	iters: 200, epoch: 41 | loss: 0.4043080
	speed: 0.0313s/iter; left time: 477.7401s
Epoch: 41 cost time: 9.153912544250488
Epoch: 41, Steps: 258 | Train Loss: 0.3971208 Vali Loss: 0.9305704 Test Loss: 0.4169339
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3983696
	speed: 0.1488s/iter; left time: 2249.9748s
	iters: 200, epoch: 42 | loss: 0.3921575
	speed: 0.0311s/iter; left time: 467.8075s
Epoch: 42 cost time: 9.01049256324768
Epoch: 42, Steps: 258 | Train Loss: 0.3970161 Vali Loss: 0.9310899 Test Loss: 0.4169617
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.4290956
	speed: 0.1434s/iter; left time: 2130.9241s
	iters: 200, epoch: 43 | loss: 0.4226507
	speed: 0.0348s/iter; left time: 513.9665s
Epoch: 43 cost time: 9.778452157974243
Epoch: 43, Steps: 258 | Train Loss: 0.3969969 Vali Loss: 0.9310558 Test Loss: 0.4170862
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.3985086
	speed: 0.1408s/iter; left time: 2057.0330s
	iters: 200, epoch: 44 | loss: 0.3873144
	speed: 0.0307s/iter; left time: 445.5646s
Epoch: 44 cost time: 8.508612394332886
Epoch: 44, Steps: 258 | Train Loss: 0.3969206 Vali Loss: 0.9310002 Test Loss: 0.4170671
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.3824310
	speed: 0.1383s/iter; left time: 1984.4738s
	iters: 200, epoch: 45 | loss: 0.4360881
	speed: 0.0289s/iter; left time: 411.7163s
Epoch: 45 cost time: 8.565324544906616
Epoch: 45, Steps: 258 | Train Loss: 0.3969337 Vali Loss: 0.9309184 Test Loss: 0.4171719
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.4201902
	speed: 0.1444s/iter; left time: 2035.1544s
	iters: 200, epoch: 46 | loss: 0.3795354
	speed: 0.0333s/iter; left time: 465.7593s
Epoch: 46 cost time: 9.413316249847412
Epoch: 46, Steps: 258 | Train Loss: 0.3969820 Vali Loss: 0.9313124 Test Loss: 0.4170207
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.4214070
	speed: 0.1414s/iter; left time: 1955.4355s
	iters: 200, epoch: 47 | loss: 0.3897384
	speed: 0.0365s/iter; left time: 501.2190s
Epoch: 47 cost time: 10.123279809951782
Epoch: 47, Steps: 258 | Train Loss: 0.3969336 Vali Loss: 0.9312073 Test Loss: 0.4171375
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.4129627
	speed: 0.1464s/iter; left time: 1987.1058s
	iters: 200, epoch: 48 | loss: 0.4291882
	speed: 0.0397s/iter; left time: 535.0926s
Epoch: 48 cost time: 10.887028694152832
Epoch: 48, Steps: 258 | Train Loss: 0.3969817 Vali Loss: 0.9304738 Test Loss: 0.4171341
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.3891763
	speed: 0.1699s/iter; left time: 2262.2138s
	iters: 200, epoch: 49 | loss: 0.4015677
	speed: 0.0360s/iter; left time: 476.0591s
Epoch: 49 cost time: 11.241191148757935
Epoch: 49, Steps: 258 | Train Loss: 0.3967456 Vali Loss: 0.9306253 Test Loss: 0.4169939
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.3948122
	speed: 0.1502s/iter; left time: 1961.4856s
	iters: 200, epoch: 50 | loss: 0.3962252
	speed: 0.0391s/iter; left time: 506.7017s
Epoch: 50 cost time: 10.347561836242676
Epoch: 50, Steps: 258 | Train Loss: 0.3970494 Vali Loss: 0.9319961 Test Loss: 0.4170410
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.3937115
	speed: 0.1423s/iter; left time: 1821.8446s
	iters: 200, epoch: 51 | loss: 0.4218476
	speed: 0.0290s/iter; left time: 368.7836s
Epoch: 51 cost time: 8.494134902954102
Epoch: 51, Steps: 258 | Train Loss: 0.3968987 Vali Loss: 0.9318115 Test Loss: 0.4171406
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.3933307
	speed: 0.1493s/iter; left time: 1872.0948s
	iters: 200, epoch: 52 | loss: 0.4270255
	speed: 0.0382s/iter; left time: 475.5358s
Epoch: 52 cost time: 10.236409664154053
Epoch: 52, Steps: 258 | Train Loss: 0.3969986 Vali Loss: 0.9315605 Test Loss: 0.4171526
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.4028758
	speed: 0.1452s/iter; left time: 1783.9654s
	iters: 200, epoch: 53 | loss: 0.3844567
	speed: 0.0320s/iter; left time: 389.4147s
Epoch: 53 cost time: 9.037060499191284
Epoch: 53, Steps: 258 | Train Loss: 0.3969148 Vali Loss: 0.9315555 Test Loss: 0.4171287
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_720_720_FITS_ETTm1_ftM_sl720_ll48_pl720_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.41606414318084717, mae:0.4121640622615814, rse:0.613692581653595, corr:[0.5248623  0.5315403  0.5361523  0.5382336  0.5385668  0.53854734
 0.53892976 0.5399243  0.54140556 0.5428926  0.5439577  0.5442419
 0.54383385 0.54296833 0.5418959  0.5408201  0.539867   0.5390001
 0.53805673 0.536944   0.5356621  0.5341666  0.5324691  0.5308051
 0.5291872  0.5278747  0.52697164 0.5264529  0.52636546 0.5266456
 0.5271431  0.52779466 0.52839375 0.52890605 0.52915806 0.52927804
 0.5291727  0.52897024 0.5287494  0.5284862  0.5283124  0.52821225
 0.5282113  0.52834916 0.52848744 0.5285115  0.528462   0.5283375
 0.528112   0.5277936  0.52755123 0.527424   0.5274588  0.5274599
 0.5273712  0.5271531  0.5268432  0.52647775 0.5261959  0.52599657
 0.5259384  0.5260253  0.5261768  0.52623045 0.52620447 0.5261398
 0.5260505  0.5259917  0.5260462  0.5261868  0.52640235 0.5265762
 0.52657855 0.52634716 0.52595764 0.52545923 0.5249201  0.52445316
 0.52414    0.5240166  0.52404064 0.5241286  0.52421236 0.52418846
 0.52411747 0.5239953  0.5239114  0.52390015 0.52401406 0.52431756
 0.52474916 0.52517855 0.52549654 0.5256183  0.52554893 0.5252852
 0.5249425  0.5246719  0.5243964  0.52420783 0.52408284 0.5239969
 0.5239392  0.52383804 0.52371764 0.52364415 0.5235443  0.5234546
 0.5233273  0.5231863  0.52301866 0.52278453 0.52247876 0.5221301
 0.5217499  0.52137166 0.52101254 0.52067816 0.5203872  0.5202066
 0.5201071  0.52002686 0.5198641  0.51966923 0.51946664 0.51924014
 0.519009   0.5188469  0.51874274 0.5187023  0.5186271  0.5184806
 0.51832026 0.5181833  0.51803887 0.51795155 0.5180036  0.5181046
 0.51827276 0.51852417 0.51874745 0.51892877 0.5190617  0.5191567
 0.5192145  0.51917887 0.51910955 0.5190337  0.51900584 0.5189805
 0.5189112  0.5188573  0.5188088  0.5187699  0.5187359  0.51879865
 0.5189162  0.51903164 0.5191354  0.5191303  0.519079   0.5190008
 0.51894444 0.51893723 0.51901925 0.5192054  0.5194906  0.51984733
 0.5201563  0.52030957 0.52036136 0.5203684  0.5203189  0.5202636
 0.5202425  0.5202567  0.52029413 0.52032137 0.5202814  0.520196
 0.5200777  0.519986   0.51991934 0.51998216 0.5202025  0.5205567
 0.5209783  0.52142024 0.52181816 0.5220934  0.5221696  0.5220641
 0.5217985  0.521495   0.52109826 0.52056855 0.51992196 0.5192282
 0.5184983  0.5177758  0.5170499  0.5163669  0.51571363 0.51509076
 0.5144953  0.51391655 0.5133385  0.5127979  0.51229364 0.51180726
 0.511281   0.5107214  0.51011956 0.50947773 0.50875497 0.50805414
 0.50748    0.5070452  0.50679505 0.506676   0.5066531  0.5067283
 0.50693107 0.50712603 0.5072812  0.5074001  0.50744027 0.50743634
 0.50743735 0.50747913 0.50756437 0.5076257  0.5076701  0.5077151
 0.5077752  0.507893   0.5079697  0.5080914  0.50818956 0.5083039
 0.50839484 0.50837034 0.50826395 0.50813824 0.5080562  0.5079703
 0.5078583  0.50771874 0.50754696 0.5073867  0.507221   0.5071341
 0.5070643  0.50707984 0.5071179  0.50713384 0.50712377 0.5071026
 0.50710005 0.50715643 0.50726384 0.507398   0.50752926 0.5077129
 0.5078446  0.5079083  0.5078945  0.5078515  0.50779504 0.5077102
 0.5076416  0.50758606 0.50755495 0.50754154 0.50752753 0.50751466
 0.5074702  0.50749177 0.50752646 0.50765234 0.50782746 0.5079994
 0.50817895 0.5082761  0.50824094 0.5080944  0.50782126 0.50742406
 0.5069582  0.5065423  0.50618434 0.50580716 0.5053742  0.50487775
 0.5043433  0.50375336 0.50319576 0.50266826 0.5021569  0.5016868
 0.50122684 0.50079423 0.5004339  0.50013787 0.49988085 0.499613
 0.49940655 0.49920082 0.4989864  0.49877346 0.49862713 0.49852747
 0.49846813 0.4984737  0.49847445 0.4984601  0.49841815 0.49838918
 0.49835977 0.49828818 0.49817467 0.49803653 0.49788782 0.49773443
 0.4975887  0.49748933 0.4974073  0.49735254 0.49728605 0.49719968
 0.49717385 0.497198   0.49723223 0.4972824  0.4973212  0.49742046
 0.4975152  0.4974548  0.4973255  0.4971591  0.49701223 0.49689388
 0.49675328 0.49662453 0.49649054 0.49636874 0.49627036 0.49624735
 0.4962323  0.49625757 0.4963043  0.4963172  0.49631438 0.49628618
 0.49620935 0.49613073 0.4960631  0.49602592 0.49606234 0.49616596
 0.4962311  0.49627998 0.49627012 0.49621013 0.49612787 0.4960432
 0.49591774 0.4958291  0.4958041  0.49579704 0.49583426 0.49590182
 0.49598563 0.4960987  0.4962273  0.49640623 0.49661803 0.49688753
 0.49722013 0.49758166 0.4979479  0.49821246 0.49830994 0.49825218
 0.49804014 0.4977063  0.49732673 0.4969003  0.49639744 0.4959567
 0.49557975 0.49527147 0.49500737 0.49479112 0.4945284  0.494206
 0.49381673 0.4933868  0.49296147 0.49257445 0.4921929  0.49188158
 0.4916047  0.49139345 0.49115336 0.49091026 0.4906623  0.49046162
 0.4903131  0.49023688 0.49022695 0.49028718 0.49040017 0.4904867
 0.49063173 0.49071747 0.4907963  0.4907895  0.49075213 0.49075958
 0.49077076 0.49083287 0.490889   0.4909295  0.4909018  0.4908735
 0.4908286  0.4908039  0.49075994 0.49078497 0.4908246  0.49096403
 0.4910969  0.49109226 0.49096864 0.4907961  0.49060032 0.49041593
 0.49025306 0.49012935 0.49005187 0.49001026 0.49000236 0.49003562
 0.49006495 0.49011198 0.49014598 0.49016702 0.49017704 0.49015963
 0.49017152 0.4902062  0.49025482 0.49028862 0.49029344 0.49033317
 0.49031928 0.49029666 0.4902758  0.4903152  0.49034584 0.49039263
 0.4904137  0.49043006 0.49038535 0.49030635 0.49020907 0.49010378
 0.49003634 0.48998603 0.48998758 0.49004278 0.49015072 0.49028423
 0.49037483 0.4904258  0.49042314 0.49029535 0.49001825 0.48961833
 0.48913532 0.48863608 0.48815954 0.48766837 0.48711094 0.4865168
 0.4859489  0.4853396  0.4847257  0.4841482  0.48356357 0.48296237
 0.48236164 0.48182067 0.48134524 0.48088896 0.48044118 0.48003063
 0.47965077 0.4793424  0.47910187 0.47880268 0.47855154 0.47831944
 0.47815788 0.47805393 0.47796977 0.47795063 0.4779779  0.47808847
 0.47828388 0.47847965 0.47864082 0.47884336 0.47905022 0.47924486
 0.47938046 0.479511   0.47966516 0.4797697  0.47982574 0.47989592
 0.48001316 0.4801903  0.48039865 0.48055848 0.48071024 0.48089036
 0.4810425  0.48110166 0.48101842 0.48089632 0.4808081  0.4807471
 0.48071066 0.48067233 0.48062456 0.48057255 0.48051238 0.48045158
 0.48040697 0.4803774  0.4803738  0.48037747 0.4803614  0.48035166
 0.48032224 0.48028117 0.48023537 0.48015663 0.4800545  0.4800189
 0.4799817  0.4799573  0.4799631  0.48002112 0.4800959  0.48019138
 0.48027518 0.48035273 0.4804082  0.48045316 0.48048908 0.48049766
 0.48045602 0.48046783 0.48046693 0.48050207 0.4805819  0.48070416
 0.48084033 0.48092642 0.48096138 0.48088756 0.48066744 0.48027238
 0.47975776 0.4792321  0.4787241  0.47820595 0.4776446  0.47712627
 0.47663483 0.4761956  0.4757801  0.4753641  0.47493532 0.474434
 0.47390231 0.47335047 0.47280583 0.47228014 0.47182798 0.4714457
 0.47111818 0.47080562 0.47051165 0.4702258  0.469941   0.46966037
 0.46944404 0.469291   0.46923685 0.4692857  0.46943054 0.4695894
 0.46978092 0.4699308  0.47001883 0.47005698 0.47006586 0.47011575
 0.47023204 0.4703615  0.4705315  0.47069186 0.4708222  0.47090748
 0.4709974  0.47113898 0.4712747  0.47141573 0.4716402  0.47191474
 0.47211784 0.4722403  0.47225878 0.472163   0.47208717 0.47207695
 0.47207743 0.4721342  0.4722338  0.47231144 0.47236595 0.4723417
 0.47218952 0.4719638  0.47173774 0.47148487 0.47129485 0.4711512
 0.47105497 0.47098705 0.47094798 0.4709329  0.4709176  0.4709311
 0.47093135 0.4708671  0.4708045  0.47078136 0.47079742 0.47083604
 0.47088155 0.4709191  0.47094306 0.47095546 0.4709506  0.4709216
 0.4708825  0.47092396 0.47104946 0.47120738 0.4714127  0.47161853
 0.47177726 0.47185525 0.47183758 0.4717572  0.47158417 0.47131228
 0.47096148 0.4706205  0.47028372 0.4698934  0.46940935 0.46884304
 0.4682508  0.46765837 0.46718016 0.46682617 0.4664934  0.466267
 0.46599117 0.46569422 0.46531057 0.46491152 0.46451327 0.46414
 0.46385106 0.46364924 0.46356148 0.46348628 0.46343476 0.4634206
 0.46339288 0.4634055  0.4634374  0.46348956 0.46362504 0.4637793
 0.46399993 0.46424255 0.4645129  0.46487182 0.46523315 0.46562865
 0.46603182 0.46643898 0.46680003 0.46704063 0.46719393 0.46725428
 0.46738604 0.4676781  0.4680026  0.4682848  0.4680709  0.46639946]
