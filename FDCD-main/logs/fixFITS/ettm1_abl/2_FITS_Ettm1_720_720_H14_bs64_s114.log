Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=122, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_720', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_720_720_FITS_ETTm1_ftM_sl720_ll48_pl720_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=122, out_features=244, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  26672128.0
params:  30012.0
Trainable parameters:  30012
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4562596
	speed: 0.0464s/iter; left time: 1191.8599s
	iters: 200, epoch: 1 | loss: 0.3890638
	speed: 0.0357s/iter; left time: 913.8852s
Epoch: 1 cost time: 10.317230939865112
Epoch: 1, Steps: 258 | Train Loss: 0.4813778 Vali Loss: 1.1713362 Test Loss: 0.5656516
Validation loss decreased (inf --> 1.171336).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3041724
	speed: 0.1649s/iter; left time: 4194.9221s
	iters: 200, epoch: 2 | loss: 0.2926376
	speed: 0.0339s/iter; left time: 860.0466s
Epoch: 2 cost time: 10.482401609420776
Epoch: 2, Steps: 258 | Train Loss: 0.3120744 Vali Loss: 1.0545866 Test Loss: 0.4896765
Validation loss decreased (1.171336 --> 1.054587).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2608463
	speed: 0.1629s/iter; left time: 4103.3540s
	iters: 200, epoch: 3 | loss: 0.2498273
	speed: 0.0421s/iter; left time: 1054.9618s
Epoch: 3 cost time: 11.915698289871216
Epoch: 3, Steps: 258 | Train Loss: 0.2634577 Vali Loss: 1.0059866 Test Loss: 0.4587839
Validation loss decreased (1.054587 --> 1.005987).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2453034
	speed: 0.1836s/iter; left time: 4575.3942s
	iters: 200, epoch: 4 | loss: 0.2652143
	speed: 0.0385s/iter; left time: 955.9542s
Epoch: 4 cost time: 10.937049150466919
Epoch: 4, Steps: 258 | Train Loss: 0.2409136 Vali Loss: 0.9802986 Test Loss: 0.4420092
Validation loss decreased (1.005987 --> 0.980299).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2482164
	speed: 0.1776s/iter; left time: 4381.2833s
	iters: 200, epoch: 5 | loss: 0.2337150
	speed: 0.0381s/iter; left time: 935.0502s
Epoch: 5 cost time: 11.243958711624146
Epoch: 5, Steps: 258 | Train Loss: 0.2286616 Vali Loss: 0.9643948 Test Loss: 0.4316329
Validation loss decreased (0.980299 --> 0.964395).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2229728
	speed: 0.1659s/iter; left time: 4049.3008s
	iters: 200, epoch: 6 | loss: 0.2315278
	speed: 0.0412s/iter; left time: 1000.9708s
Epoch: 6 cost time: 11.433417558670044
Epoch: 6, Steps: 258 | Train Loss: 0.2213788 Vali Loss: 0.9555538 Test Loss: 0.4247303
Validation loss decreased (0.964395 --> 0.955554).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2222626
	speed: 0.1785s/iter; left time: 4312.4549s
	iters: 200, epoch: 7 | loss: 0.2221963
	speed: 0.0454s/iter; left time: 1090.8792s
Epoch: 7 cost time: 11.738969802856445
Epoch: 7, Steps: 258 | Train Loss: 0.2167579 Vali Loss: 0.9481912 Test Loss: 0.4207241
Validation loss decreased (0.955554 --> 0.948191).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2340588
	speed: 0.1618s/iter; left time: 3866.1501s
	iters: 200, epoch: 8 | loss: 0.2299697
	speed: 0.0405s/iter; left time: 963.9942s
Epoch: 8 cost time: 11.88291049003601
Epoch: 8, Steps: 258 | Train Loss: 0.2138786 Vali Loss: 0.9444327 Test Loss: 0.4180207
Validation loss decreased (0.948191 --> 0.944433).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2110227
	speed: 0.1689s/iter; left time: 3992.5635s
	iters: 200, epoch: 9 | loss: 0.2141840
	speed: 0.0377s/iter; left time: 888.3276s
Epoch: 9 cost time: 10.473517179489136
Epoch: 9, Steps: 258 | Train Loss: 0.2119171 Vali Loss: 0.9413222 Test Loss: 0.4165522
Validation loss decreased (0.944433 --> 0.941322).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2223875
	speed: 0.1690s/iter; left time: 3950.6904s
	iters: 200, epoch: 10 | loss: 0.1985987
	speed: 0.0326s/iter; left time: 758.0915s
Epoch: 10 cost time: 10.721925973892212
Epoch: 10, Steps: 258 | Train Loss: 0.2105434 Vali Loss: 0.9411969 Test Loss: 0.4159902
Validation loss decreased (0.941322 --> 0.941197).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1996138
	speed: 0.1602s/iter; left time: 3703.5254s
	iters: 200, epoch: 11 | loss: 0.2077828
	speed: 0.0338s/iter; left time: 777.2614s
Epoch: 11 cost time: 10.172305822372437
Epoch: 11, Steps: 258 | Train Loss: 0.2096523 Vali Loss: 0.9391923 Test Loss: 0.4155627
Validation loss decreased (0.941197 --> 0.939192).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2112553
	speed: 0.1607s/iter; left time: 3674.0863s
	iters: 200, epoch: 12 | loss: 0.2165666
	speed: 0.0379s/iter; left time: 863.2947s
Epoch: 12 cost time: 10.412351846694946
Epoch: 12, Steps: 258 | Train Loss: 0.2091205 Vali Loss: 0.9386914 Test Loss: 0.4155642
Validation loss decreased (0.939192 --> 0.938691).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1930981
	speed: 0.1727s/iter; left time: 3904.9039s
	iters: 200, epoch: 13 | loss: 0.2165103
	speed: 0.0412s/iter; left time: 927.5722s
Epoch: 13 cost time: 11.28342890739441
Epoch: 13, Steps: 258 | Train Loss: 0.2087043 Vali Loss: 0.9383304 Test Loss: 0.4154786
Validation loss decreased (0.938691 --> 0.938330).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2066566
	speed: 0.1659s/iter; left time: 3707.4968s
	iters: 200, epoch: 14 | loss: 0.1984549
	speed: 0.0403s/iter; left time: 896.6806s
Epoch: 14 cost time: 10.286165952682495
Epoch: 14, Steps: 258 | Train Loss: 0.2083827 Vali Loss: 0.9387514 Test Loss: 0.4156850
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1999466
	speed: 0.1721s/iter; left time: 3800.7125s
	iters: 200, epoch: 15 | loss: 0.2157337
	speed: 0.0351s/iter; left time: 771.2990s
Epoch: 15 cost time: 11.38553762435913
Epoch: 15, Steps: 258 | Train Loss: 0.2082275 Vali Loss: 0.9387966 Test Loss: 0.4162592
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1972649
	speed: 0.1615s/iter; left time: 3525.6240s
	iters: 200, epoch: 16 | loss: 0.1966497
	speed: 0.0368s/iter; left time: 800.3653s
Epoch: 16 cost time: 10.398093700408936
Epoch: 16, Steps: 258 | Train Loss: 0.2080453 Vali Loss: 0.9379547 Test Loss: 0.4159872
Validation loss decreased (0.938330 --> 0.937955).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2064511
	speed: 0.1659s/iter; left time: 3578.4664s
	iters: 200, epoch: 17 | loss: 0.1918213
	speed: 0.0365s/iter; left time: 784.1324s
Epoch: 17 cost time: 10.018270015716553
Epoch: 17, Steps: 258 | Train Loss: 0.2079552 Vali Loss: 0.9393027 Test Loss: 0.4164840
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2169303
	speed: 0.1603s/iter; left time: 3416.5083s
	iters: 200, epoch: 18 | loss: 0.2076568
	speed: 0.0311s/iter; left time: 660.3558s
Epoch: 18 cost time: 10.139766693115234
Epoch: 18, Steps: 258 | Train Loss: 0.2078831 Vali Loss: 0.9374941 Test Loss: 0.4166954
Validation loss decreased (0.937955 --> 0.937494).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2204648
	speed: 0.1747s/iter; left time: 3678.1901s
	iters: 200, epoch: 19 | loss: 0.2050431
	speed: 0.0370s/iter; left time: 774.6645s
Epoch: 19 cost time: 10.269167423248291
Epoch: 19, Steps: 258 | Train Loss: 0.2078542 Vali Loss: 0.9381359 Test Loss: 0.4170767
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2084783
	speed: 0.1706s/iter; left time: 3547.8864s
	iters: 200, epoch: 20 | loss: 0.2042582
	speed: 0.0418s/iter; left time: 865.0972s
Epoch: 20 cost time: 11.076372385025024
Epoch: 20, Steps: 258 | Train Loss: 0.2077595 Vali Loss: 0.9393439 Test Loss: 0.4169916
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2014866
	speed: 0.1674s/iter; left time: 3438.4355s
	iters: 200, epoch: 21 | loss: 0.2016940
	speed: 0.0393s/iter; left time: 803.8336s
Epoch: 21 cost time: 10.933109760284424
Epoch: 21, Steps: 258 | Train Loss: 0.2078052 Vali Loss: 0.9386477 Test Loss: 0.4174704
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2045418
	speed: 0.1763s/iter; left time: 3576.1082s
	iters: 200, epoch: 22 | loss: 0.2295424
	speed: 0.0385s/iter; left time: 777.7984s
Epoch: 22 cost time: 10.891419172286987
Epoch: 22, Steps: 258 | Train Loss: 0.2077298 Vali Loss: 0.9381511 Test Loss: 0.4176418
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2144243
	speed: 0.1551s/iter; left time: 3105.2225s
	iters: 200, epoch: 23 | loss: 0.2021586
	speed: 0.0333s/iter; left time: 663.3393s
Epoch: 23 cost time: 9.93796157836914
Epoch: 23, Steps: 258 | Train Loss: 0.2077480 Vali Loss: 0.9386028 Test Loss: 0.4177004
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2121648
	speed: 0.1534s/iter; left time: 3033.0418s
	iters: 200, epoch: 24 | loss: 0.2125348
	speed: 0.0381s/iter; left time: 749.9560s
Epoch: 24 cost time: 10.036580324172974
Epoch: 24, Steps: 258 | Train Loss: 0.2077494 Vali Loss: 0.9392787 Test Loss: 0.4178776
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2066736
	speed: 0.1559s/iter; left time: 3041.5949s
	iters: 200, epoch: 25 | loss: 0.2130094
	speed: 0.0334s/iter; left time: 648.6232s
Epoch: 25 cost time: 9.948901891708374
Epoch: 25, Steps: 258 | Train Loss: 0.2077603 Vali Loss: 0.9382586 Test Loss: 0.4179812
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2053517
	speed: 0.1817s/iter; left time: 3498.0015s
	iters: 200, epoch: 26 | loss: 0.2212561
	speed: 0.0402s/iter; left time: 770.8070s
Epoch: 26 cost time: 11.719919204711914
Epoch: 26, Steps: 258 | Train Loss: 0.2076574 Vali Loss: 0.9392874 Test Loss: 0.4176856
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1966200
	speed: 0.1724s/iter; left time: 3274.4242s
	iters: 200, epoch: 27 | loss: 0.2121413
	speed: 0.0381s/iter; left time: 719.9968s
Epoch: 27 cost time: 10.479910850524902
Epoch: 27, Steps: 258 | Train Loss: 0.2077302 Vali Loss: 0.9386846 Test Loss: 0.4177378
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2097557
	speed: 0.1825s/iter; left time: 3419.1973s
	iters: 200, epoch: 28 | loss: 0.2071210
	speed: 0.0334s/iter; left time: 621.6703s
Epoch: 28 cost time: 10.078564643859863
Epoch: 28, Steps: 258 | Train Loss: 0.2076610 Vali Loss: 0.9390613 Test Loss: 0.4177406
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2205349
	speed: 0.1711s/iter; left time: 3161.2731s
	iters: 200, epoch: 29 | loss: 0.2074382
	speed: 0.0350s/iter; left time: 642.4403s
Epoch: 29 cost time: 10.762682676315308
Epoch: 29, Steps: 258 | Train Loss: 0.2076842 Vali Loss: 0.9393630 Test Loss: 0.4180361
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2101889
	speed: 0.1745s/iter; left time: 3179.6480s
	iters: 200, epoch: 30 | loss: 0.2034031
	speed: 0.0342s/iter; left time: 620.4106s
Epoch: 30 cost time: 10.165314197540283
Epoch: 30, Steps: 258 | Train Loss: 0.2077430 Vali Loss: 0.9390582 Test Loss: 0.4179290
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2108488
	speed: 0.1688s/iter; left time: 3032.2694s
	iters: 200, epoch: 31 | loss: 0.2078857
	speed: 0.0366s/iter; left time: 653.1498s
Epoch: 31 cost time: 10.184846639633179
Epoch: 31, Steps: 258 | Train Loss: 0.2077349 Vali Loss: 0.9388088 Test Loss: 0.4180844
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2053072
	speed: 0.1645s/iter; left time: 2912.6154s
	iters: 200, epoch: 32 | loss: 0.2080033
	speed: 0.0380s/iter; left time: 669.6472s
Epoch: 32 cost time: 11.160657405853271
Epoch: 32, Steps: 258 | Train Loss: 0.2076840 Vali Loss: 0.9375176 Test Loss: 0.4179803
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1948574
	speed: 0.1806s/iter; left time: 3150.6850s
	iters: 200, epoch: 33 | loss: 0.2078300
	speed: 0.0342s/iter; left time: 592.4068s
Epoch: 33 cost time: 11.134643077850342
Epoch: 33, Steps: 258 | Train Loss: 0.2076730 Vali Loss: 0.9390092 Test Loss: 0.4179548
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2189217
	speed: 0.1595s/iter; left time: 2741.2368s
	iters: 200, epoch: 34 | loss: 0.1971377
	speed: 0.0407s/iter; left time: 694.8520s
Epoch: 34 cost time: 10.411092281341553
Epoch: 34, Steps: 258 | Train Loss: 0.2077406 Vali Loss: 0.9390680 Test Loss: 0.4179902
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2138314
	speed: 0.1538s/iter; left time: 2603.9177s
	iters: 200, epoch: 35 | loss: 0.2117582
	speed: 0.0400s/iter; left time: 673.1925s
Epoch: 35 cost time: 10.776824235916138
Epoch: 35, Steps: 258 | Train Loss: 0.2076909 Vali Loss: 0.9383401 Test Loss: 0.4179774
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2061309
	speed: 0.1635s/iter; left time: 2725.8899s
	iters: 200, epoch: 36 | loss: 0.2129411
	speed: 0.0392s/iter; left time: 649.3008s
Epoch: 36 cost time: 10.731434106826782
Epoch: 36, Steps: 258 | Train Loss: 0.2076246 Vali Loss: 0.9394862 Test Loss: 0.4180278
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2025875
	speed: 0.1611s/iter; left time: 2644.2471s
	iters: 200, epoch: 37 | loss: 0.1926929
	speed: 0.0389s/iter; left time: 635.0974s
Epoch: 37 cost time: 10.563266038894653
Epoch: 37, Steps: 258 | Train Loss: 0.2077269 Vali Loss: 0.9386146 Test Loss: 0.4180105
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1892239
	speed: 0.1550s/iter; left time: 2504.1636s
	iters: 200, epoch: 38 | loss: 0.2074716
	speed: 0.0354s/iter; left time: 569.0136s
Epoch: 38 cost time: 10.602132320404053
Epoch: 38, Steps: 258 | Train Loss: 0.2076999 Vali Loss: 0.9386663 Test Loss: 0.4179746
EarlyStopping counter: 20 out of 20
Early stopping
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=122, out_features=244, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  26672128.0
params:  30012.0
Trainable parameters:  30012
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3971976
	speed: 0.0526s/iter; left time: 1350.8995s
	iters: 200, epoch: 1 | loss: 0.4033707
	speed: 0.0410s/iter; left time: 1048.6773s
Epoch: 1 cost time: 11.945916652679443
Epoch: 1, Steps: 258 | Train Loss: 0.3982428 Vali Loss: 0.9349955 Test Loss: 0.4175678
Validation loss decreased (inf --> 0.934995).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4166617
	speed: 0.1729s/iter; left time: 4399.8859s
	iters: 200, epoch: 2 | loss: 0.3719964
	speed: 0.0340s/iter; left time: 861.5871s
Epoch: 2 cost time: 10.850048065185547
Epoch: 2, Steps: 258 | Train Loss: 0.3973756 Vali Loss: 0.9337696 Test Loss: 0.4170151
Validation loss decreased (0.934995 --> 0.933770).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3688846
	speed: 0.1739s/iter; left time: 4379.6392s
	iters: 200, epoch: 3 | loss: 0.4266181
	speed: 0.0359s/iter; left time: 901.3481s
Epoch: 3 cost time: 10.851784706115723
Epoch: 3, Steps: 258 | Train Loss: 0.3972317 Vali Loss: 0.9310958 Test Loss: 0.4162590
Validation loss decreased (0.933770 --> 0.931096).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4439914
	speed: 0.1540s/iter; left time: 3837.9098s
	iters: 200, epoch: 4 | loss: 0.4101716
	speed: 0.0377s/iter; left time: 935.0467s
Epoch: 4 cost time: 9.388222694396973
Epoch: 4, Steps: 258 | Train Loss: 0.3970469 Vali Loss: 0.9317363 Test Loss: 0.4167446
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3529384
	speed: 0.1642s/iter; left time: 4049.6982s
	iters: 200, epoch: 5 | loss: 0.3876847
	speed: 0.0375s/iter; left time: 920.6022s
Epoch: 5 cost time: 10.677442789077759
Epoch: 5, Steps: 258 | Train Loss: 0.3969160 Vali Loss: 0.9313450 Test Loss: 0.4163614
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3977143
	speed: 0.1798s/iter; left time: 4388.6041s
	iters: 200, epoch: 6 | loss: 0.4346318
	speed: 0.0367s/iter; left time: 891.7129s
Epoch: 6 cost time: 10.838371992111206
Epoch: 6, Steps: 258 | Train Loss: 0.3967563 Vali Loss: 0.9309786 Test Loss: 0.4167557
Validation loss decreased (0.931096 --> 0.930979).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3822118
	speed: 0.1546s/iter; left time: 3734.5802s
	iters: 200, epoch: 7 | loss: 0.4445141
	speed: 0.0387s/iter; left time: 931.6554s
Epoch: 7 cost time: 10.09478235244751
Epoch: 7, Steps: 258 | Train Loss: 0.3967852 Vali Loss: 0.9302188 Test Loss: 0.4161713
Validation loss decreased (0.930979 --> 0.930219).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3996984
	speed: 0.1586s/iter; left time: 3790.2770s
	iters: 200, epoch: 8 | loss: 0.3902627
	speed: 0.0404s/iter; left time: 961.1595s
Epoch: 8 cost time: 11.677266597747803
Epoch: 8, Steps: 258 | Train Loss: 0.3966954 Vali Loss: 0.9306009 Test Loss: 0.4164129
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4069455
	speed: 0.1773s/iter; left time: 4190.7306s
	iters: 200, epoch: 9 | loss: 0.4016473
	speed: 0.0446s/iter; left time: 1049.9959s
Epoch: 9 cost time: 11.591041564941406
Epoch: 9, Steps: 258 | Train Loss: 0.3966291 Vali Loss: 0.9308450 Test Loss: 0.4161653
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3867211
	speed: 0.1699s/iter; left time: 3971.5246s
	iters: 200, epoch: 10 | loss: 0.4004435
	speed: 0.0403s/iter; left time: 938.0589s
Epoch: 10 cost time: 10.848106861114502
Epoch: 10, Steps: 258 | Train Loss: 0.3966266 Vali Loss: 0.9308832 Test Loss: 0.4167513
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3584049
	speed: 0.1710s/iter; left time: 3953.1433s
	iters: 200, epoch: 11 | loss: 0.4250432
	speed: 0.0416s/iter; left time: 958.0439s
Epoch: 11 cost time: 10.763582944869995
Epoch: 11, Steps: 258 | Train Loss: 0.3966953 Vali Loss: 0.9292234 Test Loss: 0.4166289
Validation loss decreased (0.930219 --> 0.929223).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4152724
	speed: 0.1729s/iter; left time: 3953.0452s
	iters: 200, epoch: 12 | loss: 0.3931084
	speed: 0.0341s/iter; left time: 776.5924s
Epoch: 12 cost time: 10.565964937210083
Epoch: 12, Steps: 258 | Train Loss: 0.3966284 Vali Loss: 0.9297926 Test Loss: 0.4170004
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3672995
	speed: 0.1628s/iter; left time: 3680.9452s
	iters: 200, epoch: 13 | loss: 0.3681318
	speed: 0.0397s/iter; left time: 894.2748s
Epoch: 13 cost time: 10.747662544250488
Epoch: 13, Steps: 258 | Train Loss: 0.3965677 Vali Loss: 0.9304351 Test Loss: 0.4159963
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3823775
	speed: 0.1656s/iter; left time: 3700.5678s
	iters: 200, epoch: 14 | loss: 0.4370945
	speed: 0.0327s/iter; left time: 726.6045s
Epoch: 14 cost time: 9.799689292907715
Epoch: 14, Steps: 258 | Train Loss: 0.3965397 Vali Loss: 0.9310944 Test Loss: 0.4167124
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3991769
	speed: 0.1716s/iter; left time: 3790.1580s
	iters: 200, epoch: 15 | loss: 0.4095649
	speed: 0.0396s/iter; left time: 869.6854s
Epoch: 15 cost time: 10.828791379928589
Epoch: 15, Steps: 258 | Train Loss: 0.3965532 Vali Loss: 0.9304730 Test Loss: 0.4166350
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4052593
	speed: 0.1655s/iter; left time: 3613.1100s
	iters: 200, epoch: 16 | loss: 0.4214482
	speed: 0.0403s/iter; left time: 876.1096s
Epoch: 16 cost time: 10.744213581085205
Epoch: 16, Steps: 258 | Train Loss: 0.3964253 Vali Loss: 0.9309922 Test Loss: 0.4166988
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3935407
	speed: 0.1662s/iter; left time: 3585.4358s
	iters: 200, epoch: 17 | loss: 0.3996941
	speed: 0.0351s/iter; left time: 754.1302s
Epoch: 17 cost time: 10.397272825241089
Epoch: 17, Steps: 258 | Train Loss: 0.3963962 Vali Loss: 0.9303393 Test Loss: 0.4165371
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3850854
	speed: 0.1700s/iter; left time: 3624.3642s
	iters: 200, epoch: 18 | loss: 0.3884436
	speed: 0.0351s/iter; left time: 745.5548s
Epoch: 18 cost time: 11.079875707626343
Epoch: 18, Steps: 258 | Train Loss: 0.3963952 Vali Loss: 0.9296927 Test Loss: 0.4163188
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3780657
	speed: 0.1715s/iter; left time: 3612.3195s
	iters: 200, epoch: 19 | loss: 0.4040749
	speed: 0.0360s/iter; left time: 755.3107s
Epoch: 19 cost time: 10.900014162063599
Epoch: 19, Steps: 258 | Train Loss: 0.3963549 Vali Loss: 0.9301234 Test Loss: 0.4165626
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4077569
	speed: 0.1670s/iter; left time: 3474.4069s
	iters: 200, epoch: 20 | loss: 0.3754499
	speed: 0.0388s/iter; left time: 803.8479s
Epoch: 20 cost time: 11.09166145324707
Epoch: 20, Steps: 258 | Train Loss: 0.3963801 Vali Loss: 0.9298623 Test Loss: 0.4166277
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3765137
	speed: 0.1567s/iter; left time: 3219.5371s
	iters: 200, epoch: 21 | loss: 0.3848452
	speed: 0.0378s/iter; left time: 773.4244s
Epoch: 21 cost time: 10.674760341644287
Epoch: 21, Steps: 258 | Train Loss: 0.3963921 Vali Loss: 0.9305501 Test Loss: 0.4164338
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4037428
	speed: 0.1622s/iter; left time: 3289.7362s
	iters: 200, epoch: 22 | loss: 0.4022709
	speed: 0.0380s/iter; left time: 767.4978s
Epoch: 22 cost time: 10.664189100265503
Epoch: 22, Steps: 258 | Train Loss: 0.3962578 Vali Loss: 0.9303348 Test Loss: 0.4164701
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3844159
	speed: 0.1786s/iter; left time: 3577.2982s
	iters: 200, epoch: 23 | loss: 0.3949560
	speed: 0.0453s/iter; left time: 903.4997s
Epoch: 23 cost time: 11.092775583267212
Epoch: 23, Steps: 258 | Train Loss: 0.3961756 Vali Loss: 0.9301822 Test Loss: 0.4165178
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3993731
	speed: 0.1573s/iter; left time: 3110.1889s
	iters: 200, epoch: 24 | loss: 0.4182714
	speed: 0.0314s/iter; left time: 617.5487s
Epoch: 24 cost time: 9.652406454086304
Epoch: 24, Steps: 258 | Train Loss: 0.3961651 Vali Loss: 0.9296145 Test Loss: 0.4162786
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3884947
	speed: 0.1845s/iter; left time: 3599.0929s
	iters: 200, epoch: 25 | loss: 0.4183505
	speed: 0.0410s/iter; left time: 794.9408s
Epoch: 25 cost time: 11.98033356666565
Epoch: 25, Steps: 258 | Train Loss: 0.3962190 Vali Loss: 0.9304788 Test Loss: 0.4167027
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3834153
	speed: 0.1876s/iter; left time: 3612.2064s
	iters: 200, epoch: 26 | loss: 0.4087902
	speed: 0.0381s/iter; left time: 728.7623s
Epoch: 26 cost time: 10.686028957366943
Epoch: 26, Steps: 258 | Train Loss: 0.3961929 Vali Loss: 0.9300023 Test Loss: 0.4163872
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4132635
	speed: 0.1692s/iter; left time: 3214.4069s
	iters: 200, epoch: 27 | loss: 0.4184306
	speed: 0.0399s/iter; left time: 753.2763s
Epoch: 27 cost time: 11.54749345779419
Epoch: 27, Steps: 258 | Train Loss: 0.3962485 Vali Loss: 0.9304450 Test Loss: 0.4165400
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4012552
	speed: 0.1938s/iter; left time: 3630.7235s
	iters: 200, epoch: 28 | loss: 0.4161385
	speed: 0.0394s/iter; left time: 734.4816s
Epoch: 28 cost time: 11.845689535140991
Epoch: 28, Steps: 258 | Train Loss: 0.3962361 Vali Loss: 0.9306206 Test Loss: 0.4165515
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3701566
	speed: 0.1884s/iter; left time: 3481.7379s
	iters: 200, epoch: 29 | loss: 0.3709718
	speed: 0.0400s/iter; left time: 734.8197s
Epoch: 29 cost time: 10.520638227462769
Epoch: 29, Steps: 258 | Train Loss: 0.3962387 Vali Loss: 0.9292112 Test Loss: 0.4164200
Validation loss decreased (0.929223 --> 0.929211).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3686396
	speed: 0.1721s/iter; left time: 3136.2696s
	iters: 200, epoch: 30 | loss: 0.3801378
	speed: 0.0463s/iter; left time: 838.7048s
Epoch: 30 cost time: 12.408724069595337
Epoch: 30, Steps: 258 | Train Loss: 0.3961749 Vali Loss: 0.9303885 Test Loss: 0.4165516
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3793055
	speed: 0.2005s/iter; left time: 3601.0320s
	iters: 200, epoch: 31 | loss: 0.4003082
	speed: 0.0409s/iter; left time: 730.2360s
Epoch: 31 cost time: 11.952637672424316
Epoch: 31, Steps: 258 | Train Loss: 0.3962808 Vali Loss: 0.9302586 Test Loss: 0.4163752
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3984084
	speed: 0.1783s/iter; left time: 3156.5932s
	iters: 200, epoch: 32 | loss: 0.4144315
	speed: 0.0365s/iter; left time: 642.9465s
Epoch: 32 cost time: 11.533425331115723
Epoch: 32, Steps: 258 | Train Loss: 0.3962324 Vali Loss: 0.9301918 Test Loss: 0.4164886
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3766256
	speed: 0.2234s/iter; left time: 3897.5355s
	iters: 200, epoch: 33 | loss: 0.4122751
	speed: 0.0331s/iter; left time: 574.7971s
Epoch: 33 cost time: 12.018288850784302
Epoch: 33, Steps: 258 | Train Loss: 0.3961747 Vali Loss: 0.9300988 Test Loss: 0.4163858
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3733871
	speed: 0.2137s/iter; left time: 3673.4219s
	iters: 200, epoch: 34 | loss: 0.3710656
	speed: 0.0363s/iter; left time: 619.6949s
Epoch: 34 cost time: 11.619251728057861
Epoch: 34, Steps: 258 | Train Loss: 0.3962055 Vali Loss: 0.9299318 Test Loss: 0.4165881
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4196973
	speed: 0.1739s/iter; left time: 2943.7543s
	iters: 200, epoch: 35 | loss: 0.3768361
	speed: 0.0425s/iter; left time: 716.0673s
Epoch: 35 cost time: 11.946424961090088
Epoch: 35, Steps: 258 | Train Loss: 0.3960751 Vali Loss: 0.9310254 Test Loss: 0.4162243
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4021072
	speed: 0.1773s/iter; left time: 2955.6372s
	iters: 200, epoch: 36 | loss: 0.3726108
	speed: 0.0434s/iter; left time: 719.3555s
Epoch: 36 cost time: 12.048478126525879
Epoch: 36, Steps: 258 | Train Loss: 0.3960865 Vali Loss: 0.9292257 Test Loss: 0.4163122
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4072045
	speed: 0.1992s/iter; left time: 3269.6974s
	iters: 200, epoch: 37 | loss: 0.3856168
	speed: 0.0441s/iter; left time: 720.0154s
Epoch: 37 cost time: 11.97502088546753
Epoch: 37, Steps: 258 | Train Loss: 0.3961208 Vali Loss: 0.9291154 Test Loss: 0.4166364
Validation loss decreased (0.929211 --> 0.929115).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3946179
	speed: 0.1848s/iter; left time: 2985.2952s
	iters: 200, epoch: 38 | loss: 0.3792022
	speed: 0.0406s/iter; left time: 651.1114s
Epoch: 38 cost time: 11.290557146072388
Epoch: 38, Steps: 258 | Train Loss: 0.3960780 Vali Loss: 0.9300770 Test Loss: 0.4165523
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4233444
	speed: 0.1920s/iter; left time: 3052.8819s
	iters: 200, epoch: 39 | loss: 0.3631110
	speed: 0.0505s/iter; left time: 798.1900s
Epoch: 39 cost time: 13.67160439491272
Epoch: 39, Steps: 258 | Train Loss: 0.3961004 Vali Loss: 0.9295805 Test Loss: 0.4164436
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.4192823
	speed: 0.2277s/iter; left time: 3560.6504s
	iters: 200, epoch: 40 | loss: 0.3789906
	speed: 0.0625s/iter; left time: 970.7843s
Epoch: 40 cost time: 18.25797700881958
Epoch: 40, Steps: 258 | Train Loss: 0.3961045 Vali Loss: 0.9300138 Test Loss: 0.4162967
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.4111659
	speed: 0.2981s/iter; left time: 4585.6316s
	iters: 200, epoch: 41 | loss: 0.3700834
	speed: 0.0439s/iter; left time: 670.6465s
Epoch: 41 cost time: 14.498533487319946
Epoch: 41, Steps: 258 | Train Loss: 0.3960859 Vali Loss: 0.9306008 Test Loss: 0.4164504
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3811008
	speed: 0.2761s/iter; left time: 4174.9667s
	iters: 200, epoch: 42 | loss: 0.3935317
	speed: 0.0505s/iter; left time: 759.2667s
Epoch: 42 cost time: 15.059813261032104
Epoch: 42, Steps: 258 | Train Loss: 0.3959618 Vali Loss: 0.9300988 Test Loss: 0.4165419
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3646068
	speed: 0.2428s/iter; left time: 3609.6151s
	iters: 200, epoch: 43 | loss: 0.3980553
	speed: 0.0582s/iter; left time: 859.4504s
Epoch: 43 cost time: 17.192959547042847
Epoch: 43, Steps: 258 | Train Loss: 0.3961002 Vali Loss: 0.9302914 Test Loss: 0.4164589
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.3961772
	speed: 0.2548s/iter; left time: 3721.7478s
	iters: 200, epoch: 44 | loss: 0.4236154
	speed: 0.0682s/iter; left time: 990.0138s
Epoch: 44 cost time: 18.31836247444153
Epoch: 44, Steps: 258 | Train Loss: 0.3960286 Vali Loss: 0.9296638 Test Loss: 0.4165437
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.3917984
	speed: 0.2867s/iter; left time: 4114.0577s
	iters: 200, epoch: 45 | loss: 0.4062908
	speed: 0.0627s/iter; left time: 893.5190s
Epoch: 45 cost time: 16.627103090286255
Epoch: 45, Steps: 258 | Train Loss: 0.3960875 Vali Loss: 0.9298726 Test Loss: 0.4164763
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.3631681
	speed: 0.2875s/iter; left time: 4051.5025s
	iters: 200, epoch: 46 | loss: 0.3751767
	speed: 0.0648s/iter; left time: 906.5840s
Epoch: 46 cost time: 17.463285446166992
Epoch: 46, Steps: 258 | Train Loss: 0.3960698 Vali Loss: 0.9293483 Test Loss: 0.4164359
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.3763639
	speed: 0.2827s/iter; left time: 3910.2164s
	iters: 200, epoch: 47 | loss: 0.3833149
	speed: 0.0664s/iter; left time: 911.3856s
Epoch: 47 cost time: 17.230687618255615
Epoch: 47, Steps: 258 | Train Loss: 0.3960478 Vali Loss: 0.9293286 Test Loss: 0.4163820
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.3658006
	speed: 0.2677s/iter; left time: 3633.4361s
	iters: 200, epoch: 48 | loss: 0.4035428
	speed: 0.0637s/iter; left time: 858.0332s
Epoch: 48 cost time: 16.9013090133667
Epoch: 48, Steps: 258 | Train Loss: 0.3960260 Vali Loss: 0.9302264 Test Loss: 0.4164053
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.3831108
	speed: 0.2906s/iter; left time: 3870.5523s
	iters: 200, epoch: 49 | loss: 0.4085968
	speed: 0.0664s/iter; left time: 877.1506s
Epoch: 49 cost time: 18.2793288230896
Epoch: 49, Steps: 258 | Train Loss: 0.3961339 Vali Loss: 0.9302503 Test Loss: 0.4164085
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.3676288
	speed: 0.2551s/iter; left time: 3331.6277s
	iters: 200, epoch: 50 | loss: 0.3672234
	speed: 0.0571s/iter; left time: 739.7260s
Epoch: 50 cost time: 16.303077936172485
Epoch: 50, Steps: 258 | Train Loss: 0.3960578 Vali Loss: 0.9304962 Test Loss: 0.4164318
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.3829667
	speed: 0.2786s/iter; left time: 3566.4683s
	iters: 200, epoch: 51 | loss: 0.4005957
	speed: 0.0563s/iter; left time: 714.5817s
Epoch: 51 cost time: 15.185459852218628
Epoch: 51, Steps: 258 | Train Loss: 0.3961530 Vali Loss: 0.9292797 Test Loss: 0.4164606
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.3885088
	speed: 0.2451s/iter; left time: 3074.8356s
	iters: 200, epoch: 52 | loss: 0.4033019
	speed: 0.0619s/iter; left time: 769.9653s
Epoch: 52 cost time: 16.61053967475891
Epoch: 52, Steps: 258 | Train Loss: 0.3960441 Vali Loss: 0.9300963 Test Loss: 0.4164564
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.4196545
	speed: 0.2416s/iter; left time: 2968.5259s
	iters: 200, epoch: 53 | loss: 0.4082500
	speed: 0.0582s/iter; left time: 709.1698s
Epoch: 53 cost time: 16.03856110572815
Epoch: 53, Steps: 258 | Train Loss: 0.3960036 Vali Loss: 0.9294673 Test Loss: 0.4165212
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.4029863
	speed: 0.2497s/iter; left time: 3002.6609s
	iters: 200, epoch: 54 | loss: 0.3577895
	speed: 0.0559s/iter; left time: 666.4342s
Epoch: 54 cost time: 15.61614179611206
Epoch: 54, Steps: 258 | Train Loss: 0.3960152 Vali Loss: 0.9301236 Test Loss: 0.4165414
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.3913838
	speed: 0.2751s/iter; left time: 3237.8034s
	iters: 200, epoch: 55 | loss: 0.4021695
	speed: 0.0555s/iter; left time: 648.0817s
Epoch: 55 cost time: 16.222630500793457
Epoch: 55, Steps: 258 | Train Loss: 0.3960912 Vali Loss: 0.9304161 Test Loss: 0.4164622
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.4347801
	speed: 0.2735s/iter; left time: 3148.8245s
	iters: 200, epoch: 56 | loss: 0.4219743
	speed: 0.0608s/iter; left time: 693.6247s
Epoch: 56 cost time: 17.165233612060547
Epoch: 56, Steps: 258 | Train Loss: 0.3960611 Vali Loss: 0.9298016 Test Loss: 0.4164416
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.3948063
	speed: 0.3043s/iter; left time: 3424.2091s
	iters: 200, epoch: 57 | loss: 0.4032129
	speed: 0.0685s/iter; left time: 763.6450s
Epoch: 57 cost time: 18.177053689956665
Epoch: 57, Steps: 258 | Train Loss: 0.3959803 Vali Loss: 0.9303787 Test Loss: 0.4163961
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_720_720_FITS_ETTm1_ftM_sl720_ll48_pl720_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.41559872031211853, mae:0.4116794764995575, rse:0.6133492588996887, corr:[0.5256641  0.5320243  0.5337087  0.5345569  0.5364322  0.5388665
 0.5403035  0.54050386 0.5405632  0.5412159  0.5423194  0.5430247
 0.5430236  0.54262483 0.5421972  0.54170567 0.540867   0.5395665
 0.5379595  0.5364374  0.5351925  0.5340481  0.5327429  0.53137875
 0.5298734  0.52855265 0.52749604 0.5265838  0.5259963  0.5258768
 0.5263669  0.5274496  0.5285782  0.5293307  0.5293513  0.5291935
 0.52904683 0.52906513 0.52906084 0.52876455 0.52837765 0.528088
 0.5280964  0.52835345 0.5284158  0.528103   0.5277189  0.52757394
 0.5276922  0.52781636 0.5278232  0.52760273 0.52735054 0.52712834
 0.5270798  0.5271115  0.5270922  0.52693367 0.5268136  0.52669466
 0.5266083  0.52649003 0.52630466 0.526004   0.52586865 0.5260055
 0.526242   0.5263704  0.52638024 0.5263263  0.52640176 0.52656525
 0.5266547  0.5265117  0.52620625 0.5258092  0.5254379  0.52518094
 0.5249945  0.52480716 0.5246008  0.5244147  0.5243334  0.5242956
 0.5243103  0.5242365  0.5240659  0.5238225  0.5236623  0.52379507
 0.5241864  0.52467656 0.52510554 0.52535117 0.52539253 0.5252031
 0.5248937  0.5246301  0.5243189  0.5240795  0.5239169  0.52381355
 0.523744   0.523598   0.52345574 0.5234398  0.52342767 0.5234212
 0.5232935  0.52309203 0.5228529  0.5225731  0.52227956 0.5220083
 0.52174133 0.52151483 0.5213507  0.5212113  0.5210773  0.5209725
 0.52081    0.5205448  0.5201759  0.5199154  0.5198297  0.51975167
 0.5195423  0.5192635  0.51902455 0.5190285  0.51921844 0.5194118
 0.5194808  0.5193252  0.51894677 0.51859856 0.5185469  0.51863563
 0.5187729  0.5188882  0.5188784  0.51887673 0.5189966  0.5192105
 0.51939625 0.51939034 0.51928127 0.51916486 0.51915777 0.519164
 0.51910305 0.5190652  0.5190518  0.51905113 0.5190185  0.5190212
 0.5190157  0.51897246 0.5189778  0.51895446 0.5190004  0.519093
 0.5192139  0.5193289  0.5194585  0.5196152  0.51981026 0.52003956
 0.5202417  0.52036554 0.52050585 0.5206556  0.5206714  0.52055305
 0.52039295 0.5202949  0.5202822  0.5203095  0.52027565 0.52020603
 0.52013266 0.52013206 0.52017474 0.52029604 0.52047235 0.52068216
 0.52091634 0.5212799  0.52174276 0.5221212  0.5222355  0.5220469
 0.52166235 0.521305   0.52096486 0.52056104 0.5200312  0.5193811
 0.5186344  0.5179088  0.5172465  0.51667786 0.51610726 0.515491
 0.51484203 0.5142084  0.51362246 0.5131318  0.5126712  0.51215047
 0.51150644 0.5108447  0.510213   0.5096258  0.5089974  0.5084271
 0.5079855  0.5075926  0.50725114 0.50690335 0.50660866 0.50650805
 0.50670314 0.5069807  0.5072653  0.5074948  0.5075955  0.50762606
 0.50767046 0.5077576  0.50785977 0.507859   0.50778204 0.5077166
 0.50771046 0.50782436 0.5079131  0.5081077  0.50832325 0.50859016
 0.50879914 0.50879407 0.50863796 0.50843596 0.50829107 0.50815713
 0.5080165  0.5078934  0.5077682  0.50767636 0.5075463  0.50747687
 0.5073966  0.5074175  0.50745785 0.5074721  0.50746375 0.5074526
 0.5074523  0.5074794  0.5074982  0.50749695 0.50749826 0.5076256
 0.5077825  0.5079349  0.508058   0.5081533  0.50815487 0.5079912
 0.50777286 0.5075912  0.507583   0.50777906 0.5080598  0.5082818
 0.5083078  0.50823706 0.508083   0.5080089  0.5080149  0.5080703
 0.5082207  0.5083978  0.5085311  0.50858    0.5084381  0.5080396
 0.50747025 0.5069196  0.50643575 0.50593877 0.50541633 0.5048712
 0.5043645  0.50387794 0.50349534 0.50313187 0.50269824 0.50217456
 0.5015454  0.5009377  0.50048816 0.5001907  0.49997106 0.49971274
 0.49950522 0.49927878 0.4990548  0.4988443  0.4987182  0.49860656
 0.49848387 0.4984048  0.4983079  0.49822608 0.4981964  0.4982657
 0.4983532  0.49833164 0.49819934 0.49803448 0.4979462  0.4979658
 0.49804342 0.4981209  0.4980454  0.49782896 0.49753243 0.49728155
 0.49724945 0.49735314 0.49743584 0.4974691  0.49745607 0.49755532
 0.49768564 0.49761435 0.4974364  0.49721286 0.49707073 0.4970275
 0.49701595 0.49705577 0.49705413 0.49699885 0.49692568 0.4969036
 0.4968571  0.4968242  0.49679688 0.49672934 0.49668315 0.49666002
 0.49661857 0.49658886 0.49656817 0.4965559  0.49660587 0.49667957
 0.4966626  0.49659252 0.4964597  0.49630076 0.49619654 0.49618325
 0.49614725 0.49613762 0.4961205  0.49601585 0.49591863 0.49589732
 0.49598247 0.49616733 0.49635607 0.49653015 0.49663886 0.49677026
 0.49698612 0.49729815 0.49768353 0.49799228 0.49813208 0.49810293
 0.49792528 0.49765745 0.4973781  0.49706203 0.4966527  0.4962743
 0.49589622 0.49552563 0.49514738 0.4948112  0.49443716 0.49404547
 0.49364066 0.49327105 0.4929482  0.4926236  0.4921947  0.4917627
 0.4913222  0.49099323 0.49071017 0.4905047  0.49034175 0.49025735
 0.49020392 0.4901888  0.49019778 0.49025443 0.49037457 0.4904534
 0.49061286 0.49067095 0.4907217  0.49070242 0.49070585 0.49079835
 0.49084228 0.49087024 0.4908163  0.49075127 0.49067602 0.4906856
 0.490696   0.49070528 0.49065402 0.4907156  0.49084622 0.4911277
 0.491333   0.4912804  0.49105075 0.49080145 0.49061006 0.49050236
 0.49043784 0.49037936 0.4903211  0.49025604 0.49021992 0.49023622
 0.49025822 0.4902938  0.4903098  0.49029508 0.49027142 0.4902132
 0.49020725 0.49022996 0.4902783  0.4903129  0.4903509  0.4904765
 0.49056292 0.4906046  0.49058062 0.49055755 0.49047342 0.49043682
 0.4904373  0.4905283  0.4905856  0.49059936 0.49055442 0.49043587
 0.49033606 0.4902399  0.49022886 0.4902886  0.4903991  0.49051264
 0.49056298 0.49060905 0.4906702  0.49064243 0.49045435 0.49009314
 0.48958147 0.48898688 0.48837402 0.48774752 0.487132   0.486581
 0.48612735 0.48561987 0.48506662 0.4845312  0.48395893 0.48335353
 0.48273718 0.4821879  0.48168987 0.48119456 0.48071277 0.48029262
 0.47989172 0.4795629  0.4792872  0.47890818 0.47860235 0.47834045
 0.4781591  0.47802266 0.4778956  0.47789592 0.4780337  0.47832048
 0.47865054 0.47881672 0.47877848 0.47873786 0.47877115 0.47892904
 0.47912478 0.47934172 0.47950613 0.4795038  0.47941026 0.4794064
 0.47957098 0.47986975 0.48016864 0.48033178 0.48048443 0.48073277
 0.48101166 0.48117816 0.48112112 0.4809488  0.48078278 0.48067585
 0.48067224 0.48072115 0.48077723 0.48078462 0.4807362  0.48067918
 0.48068553 0.48075747 0.48084104 0.48082668 0.4806678  0.48047915
 0.48032624 0.48028022 0.48033434 0.4803646  0.4803242  0.4803094
 0.4802759  0.48028073 0.48037463 0.48055682 0.48070896 0.48078945
 0.48076084 0.48068795 0.48063815 0.4806643  0.4807513  0.48082
 0.48080137 0.4808297  0.48083094 0.48086128 0.48090824 0.48097235
 0.48105106 0.48115098 0.48132646 0.4814795  0.48147258 0.48120266
 0.48070186 0.48009786 0.4794533  0.478789   0.4781499  0.47765994
 0.47727272 0.47693804 0.47657287 0.47614008 0.47566685 0.47512278
 0.47458833 0.4740459  0.47350165 0.47294092 0.4724403  0.47201702
 0.47167572 0.471372   0.47110096 0.47081935 0.47050983 0.47020742
 0.4700214  0.46991107 0.46986926 0.46985996 0.46990633 0.46997488
 0.4701722  0.4704047  0.47061107 0.4707605  0.47084692 0.47096747
 0.47114107 0.4712829  0.47143313 0.47153312 0.471589   0.47158968
 0.47159612 0.47166118 0.47170946 0.4718055  0.47209075 0.47247812
 0.4727121  0.47274387 0.4726034  0.472411   0.47237617 0.47251403
 0.47262248 0.4726776  0.47267008 0.47257635 0.47250897 0.4724127
 0.47220546 0.47194943 0.47173986 0.47153467 0.4714346  0.47136936
 0.47129065 0.47117347 0.4710718  0.47105345 0.47109568 0.47119242
 0.47124597 0.47117877 0.47112113 0.47114542 0.47121996 0.47126728
 0.4712438  0.4711759  0.47112483 0.47112146 0.4711334  0.47110358
 0.47103044 0.4710299  0.47111666 0.47122714 0.47139308 0.47156247
 0.47172812 0.47189862 0.4720653  0.47216406 0.47206682 0.47174552
 0.4712919  0.47087267 0.470515   0.47013518 0.46967876 0.4691504
 0.46861693 0.46809378 0.46768585 0.4673423  0.4669141  0.4665494
 0.46614155 0.46584034 0.46561393 0.46550998 0.4654131  0.46519756
 0.46486205 0.46444243 0.46409056 0.46378395 0.46363714 0.46365413
 0.4636853  0.4637356  0.4637545  0.4637862  0.46398357 0.46424234
 0.46456602 0.46484172 0.46507072 0.46538797 0.46570086 0.46604756
 0.46632665 0.46645755 0.46644783 0.46646026 0.4668204  0.4674343
 0.46803015 0.46816584 0.4676989  0.46756774 0.46825725 0.4675855 ]
