Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=18, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_180_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_180_336_FITS_ETTm1_ftM_sl180_ll48_pl336_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34045
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=18, out_features=51, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  822528.0
params:  969.0
Trainable parameters:  969
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5845644
	speed: 0.1359s/iter; left time: 3587.6187s
	iters: 200, epoch: 1 | loss: 0.5015574
	speed: 0.1277s/iter; left time: 3357.9756s
Epoch: 1 cost time: 34.58550453186035
Epoch: 1, Steps: 265 | Train Loss: 0.5546391 Vali Loss: 0.7784547 Test Loss: 0.4783309
Validation loss decreased (inf --> 0.778455).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4427988
	speed: 0.4727s/iter; left time: 12353.2910s
	iters: 200, epoch: 2 | loss: 0.3779060
	speed: 0.1160s/iter; left time: 3019.5662s
Epoch: 2 cost time: 30.265147924423218
Epoch: 2, Steps: 265 | Train Loss: 0.4015511 Vali Loss: 0.6962886 Test Loss: 0.4022194
Validation loss decreased (0.778455 --> 0.696289).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3859909
	speed: 0.4714s/iter; left time: 12195.9641s
	iters: 200, epoch: 3 | loss: 0.3886893
	speed: 0.0904s/iter; left time: 2328.6426s
Epoch: 3 cost time: 24.77379059791565
Epoch: 3, Steps: 265 | Train Loss: 0.3813769 Vali Loss: 0.6793648 Test Loss: 0.3892124
Validation loss decreased (0.696289 --> 0.679365).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3736004
	speed: 0.3744s/iter; left time: 9586.2651s
	iters: 200, epoch: 4 | loss: 0.4276786
	speed: 0.0806s/iter; left time: 2055.7088s
Epoch: 4 cost time: 22.239277362823486
Epoch: 4, Steps: 265 | Train Loss: 0.3771918 Vali Loss: 0.6730887 Test Loss: 0.3861518
Validation loss decreased (0.679365 --> 0.673089).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3525611
	speed: 0.6811s/iter; left time: 17259.8903s
	iters: 200, epoch: 5 | loss: 0.3593025
	speed: 0.1949s/iter; left time: 4919.4113s
Epoch: 5 cost time: 52.79569220542908
Epoch: 5, Steps: 265 | Train Loss: 0.3761355 Vali Loss: 0.6706519 Test Loss: 0.3853627
Validation loss decreased (0.673089 --> 0.670652).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3793471
	speed: 0.8489s/iter; left time: 21288.0126s
	iters: 200, epoch: 6 | loss: 0.3754080
	speed: 0.1843s/iter; left time: 4604.0838s
Epoch: 6 cost time: 50.176676988601685
Epoch: 6, Steps: 265 | Train Loss: 0.3757108 Vali Loss: 0.6700525 Test Loss: 0.3848308
Validation loss decreased (0.670652 --> 0.670052).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3421806
	speed: 0.8399s/iter; left time: 20839.6995s
	iters: 200, epoch: 7 | loss: 0.3696132
	speed: 0.1886s/iter; left time: 4660.8270s
Epoch: 7 cost time: 50.408363342285156
Epoch: 7, Steps: 265 | Train Loss: 0.3754371 Vali Loss: 0.6691007 Test Loss: 0.3850245
Validation loss decreased (0.670052 --> 0.669101).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3820878
	speed: 0.8600s/iter; left time: 21108.4315s
	iters: 200, epoch: 8 | loss: 0.3398089
	speed: 0.2032s/iter; left time: 4967.3950s
Epoch: 8 cost time: 52.66687798500061
Epoch: 8, Steps: 265 | Train Loss: 0.3751669 Vali Loss: 0.6693514 Test Loss: 0.3846981
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3697771
	speed: 0.8572s/iter; left time: 20813.8894s
	iters: 200, epoch: 9 | loss: 0.3943959
	speed: 0.1808s/iter; left time: 4373.0822s
Epoch: 9 cost time: 50.36066269874573
Epoch: 9, Steps: 265 | Train Loss: 0.3752144 Vali Loss: 0.6684197 Test Loss: 0.3847363
Validation loss decreased (0.669101 --> 0.668420).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3903655
	speed: 0.8667s/iter; left time: 20814.4570s
	iters: 200, epoch: 10 | loss: 0.3910570
	speed: 0.2014s/iter; left time: 4817.7980s
Epoch: 10 cost time: 53.315523624420166
Epoch: 10, Steps: 265 | Train Loss: 0.3751737 Vali Loss: 0.6681322 Test Loss: 0.3848452
Validation loss decreased (0.668420 --> 0.668132).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3645827
	speed: 0.8664s/iter; left time: 20577.9078s
	iters: 200, epoch: 11 | loss: 0.3597998
	speed: 0.1943s/iter; left time: 4594.6892s
Epoch: 11 cost time: 50.23103404045105
Epoch: 11, Steps: 265 | Train Loss: 0.3750983 Vali Loss: 0.6682501 Test Loss: 0.3847953
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3977778
	speed: 0.8588s/iter; left time: 20169.0707s
	iters: 200, epoch: 12 | loss: 0.3757992
	speed: 0.1911s/iter; left time: 4468.9639s
Epoch: 12 cost time: 52.84080266952515
Epoch: 12, Steps: 265 | Train Loss: 0.3749049 Vali Loss: 0.6685494 Test Loss: 0.3845371
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3529052
	speed: 0.8265s/iter; left time: 19191.9786s
	iters: 200, epoch: 13 | loss: 0.3803073
	speed: 0.1897s/iter; left time: 4385.0248s
Epoch: 13 cost time: 51.47798013687134
Epoch: 13, Steps: 265 | Train Loss: 0.3749490 Vali Loss: 0.6685354 Test Loss: 0.3846208
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3912920
	speed: 0.8455s/iter; left time: 19409.2720s
	iters: 200, epoch: 14 | loss: 0.3654894
	speed: 0.1847s/iter; left time: 4220.6356s
Epoch: 14 cost time: 51.55378532409668
Epoch: 14, Steps: 265 | Train Loss: 0.3750483 Vali Loss: 0.6679932 Test Loss: 0.3846424
Validation loss decreased (0.668132 --> 0.667993).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3822174
	speed: 0.8517s/iter; left time: 19325.1882s
	iters: 200, epoch: 15 | loss: 0.3715119
	speed: 0.1986s/iter; left time: 4486.7303s
Epoch: 15 cost time: 50.7878212928772
Epoch: 15, Steps: 265 | Train Loss: 0.3750697 Vali Loss: 0.6680874 Test Loss: 0.3849559
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3403376
	speed: 0.8776s/iter; left time: 19681.9456s
	iters: 200, epoch: 16 | loss: 0.3831310
	speed: 0.1851s/iter; left time: 4131.6813s
Epoch: 16 cost time: 48.89694309234619
Epoch: 16, Steps: 265 | Train Loss: 0.3750676 Vali Loss: 0.6680393 Test Loss: 0.3848980
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3707359
	speed: 0.8371s/iter; left time: 18551.8106s
	iters: 200, epoch: 17 | loss: 0.3641723
	speed: 0.2136s/iter; left time: 4711.2923s
Epoch: 17 cost time: 54.89662027359009
Epoch: 17, Steps: 265 | Train Loss: 0.3750467 Vali Loss: 0.6679155 Test Loss: 0.3846956
Validation loss decreased (0.667993 --> 0.667915).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3410820
	speed: 0.8593s/iter; left time: 18814.3114s
	iters: 200, epoch: 18 | loss: 0.4135908
	speed: 0.1886s/iter; left time: 4110.2096s
Epoch: 18 cost time: 51.60191226005554
Epoch: 18, Steps: 265 | Train Loss: 0.3749271 Vali Loss: 0.6677876 Test Loss: 0.3846734
Validation loss decreased (0.667915 --> 0.667788).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3762985
	speed: 0.8888s/iter; left time: 19225.7677s
	iters: 200, epoch: 19 | loss: 0.3968547
	speed: 0.1860s/iter; left time: 4004.5789s
Epoch: 19 cost time: 52.00352430343628
Epoch: 19, Steps: 265 | Train Loss: 0.3748046 Vali Loss: 0.6687250 Test Loss: 0.3846906
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3770751
	speed: 0.8811s/iter; left time: 18826.2135s
	iters: 200, epoch: 20 | loss: 0.3618223
	speed: 0.1892s/iter; left time: 4024.1414s
Epoch: 20 cost time: 51.15164828300476
Epoch: 20, Steps: 265 | Train Loss: 0.3747987 Vali Loss: 0.6674479 Test Loss: 0.3846394
Validation loss decreased (0.667788 --> 0.667448).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3518215
	speed: 0.8541s/iter; left time: 18022.3548s
	iters: 200, epoch: 21 | loss: 0.4064811
	speed: 0.1940s/iter; left time: 4074.7675s
Epoch: 21 cost time: 52.17724895477295
Epoch: 21, Steps: 265 | Train Loss: 0.3748704 Vali Loss: 0.6673415 Test Loss: 0.3846625
Validation loss decreased (0.667448 --> 0.667342).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3972438
	speed: 0.8517s/iter; left time: 17746.9210s
	iters: 200, epoch: 22 | loss: 0.3707101
	speed: 0.1956s/iter; left time: 4055.2478s
Epoch: 22 cost time: 52.18459510803223
Epoch: 22, Steps: 265 | Train Loss: 0.3747981 Vali Loss: 0.6679299 Test Loss: 0.3847599
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3785686
	speed: 0.8613s/iter; left time: 17718.2271s
	iters: 200, epoch: 23 | loss: 0.3489724
	speed: 0.1848s/iter; left time: 3782.1186s
Epoch: 23 cost time: 49.23189306259155
Epoch: 23, Steps: 265 | Train Loss: 0.3748620 Vali Loss: 0.6679921 Test Loss: 0.3848005
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3900120
	speed: 0.8343s/iter; left time: 16940.4065s
	iters: 200, epoch: 24 | loss: 0.3531030
	speed: 0.1927s/iter; left time: 3894.0988s
Epoch: 24 cost time: 51.63547372817993
Epoch: 24, Steps: 265 | Train Loss: 0.3747409 Vali Loss: 0.6670807 Test Loss: 0.3848277
Validation loss decreased (0.667342 --> 0.667081).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3883345
	speed: 0.8578s/iter; left time: 17190.8446s
	iters: 200, epoch: 25 | loss: 0.3518107
	speed: 0.1890s/iter; left time: 3768.9047s
Epoch: 25 cost time: 51.212775468826294
Epoch: 25, Steps: 265 | Train Loss: 0.3747829 Vali Loss: 0.6678907 Test Loss: 0.3846812
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3673877
	speed: 0.8323s/iter; left time: 16459.8304s
	iters: 200, epoch: 26 | loss: 0.4341998
	speed: 0.1821s/iter; left time: 3582.1203s
Epoch: 26 cost time: 49.37068223953247
Epoch: 26, Steps: 265 | Train Loss: 0.3748463 Vali Loss: 0.6676261 Test Loss: 0.3846726
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3723525
	speed: 0.8632s/iter; left time: 16842.5971s
	iters: 200, epoch: 27 | loss: 0.3629702
	speed: 0.1939s/iter; left time: 3763.9113s
Epoch: 27 cost time: 52.6749529838562
Epoch: 27, Steps: 265 | Train Loss: 0.3747423 Vali Loss: 0.6678857 Test Loss: 0.3847206
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3677985
	speed: 0.8627s/iter; left time: 16603.8493s
	iters: 200, epoch: 28 | loss: 0.3590215
	speed: 0.1974s/iter; left time: 3780.3361s
Epoch: 28 cost time: 52.27157163619995
Epoch: 28, Steps: 265 | Train Loss: 0.3747124 Vali Loss: 0.6678576 Test Loss: 0.3846208
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3731056
	speed: 0.8446s/iter; left time: 16031.5615s
	iters: 200, epoch: 29 | loss: 0.4182585
	speed: 0.1894s/iter; left time: 3575.8517s
Epoch: 29 cost time: 51.86366868019104
Epoch: 29, Steps: 265 | Train Loss: 0.3748435 Vali Loss: 0.6681492 Test Loss: 0.3847562
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3562272
	speed: 0.8663s/iter; left time: 16213.3535s
	iters: 200, epoch: 30 | loss: 0.3763508
	speed: 0.2000s/iter; left time: 3723.2243s
Epoch: 30 cost time: 51.45509362220764
Epoch: 30, Steps: 265 | Train Loss: 0.3747748 Vali Loss: 0.6680984 Test Loss: 0.3847061
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3618706
	speed: 0.8569s/iter; left time: 15810.9063s
	iters: 200, epoch: 31 | loss: 0.3735405
	speed: 0.1943s/iter; left time: 3566.2551s
Epoch: 31 cost time: 52.13046097755432
Epoch: 31, Steps: 265 | Train Loss: 0.3747612 Vali Loss: 0.6681057 Test Loss: 0.3847083
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4164334
	speed: 0.8573s/iter; left time: 15590.0792s
	iters: 200, epoch: 32 | loss: 0.3921051
	speed: 0.2006s/iter; left time: 3627.4062s
Epoch: 32 cost time: 52.60450220108032
Epoch: 32, Steps: 265 | Train Loss: 0.3747080 Vali Loss: 0.6676184 Test Loss: 0.3847342
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4012873
	speed: 0.8464s/iter; left time: 15167.4424s
	iters: 200, epoch: 33 | loss: 0.3881907
	speed: 0.1850s/iter; left time: 3296.8666s
Epoch: 33 cost time: 49.992735862731934
Epoch: 33, Steps: 265 | Train Loss: 0.3748280 Vali Loss: 0.6679699 Test Loss: 0.3847165
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3909346
	speed: 0.8272s/iter; left time: 14605.3150s
	iters: 200, epoch: 34 | loss: 0.3667988
	speed: 0.1888s/iter; left time: 3314.5901s
Epoch: 34 cost time: 51.494282960891724
Epoch: 34, Steps: 265 | Train Loss: 0.3749162 Vali Loss: 0.6677351 Test Loss: 0.3847340
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3695591
	speed: 0.8601s/iter; left time: 14957.4507s
	iters: 200, epoch: 35 | loss: 0.3869016
	speed: 0.1851s/iter; left time: 3200.4644s
Epoch: 35 cost time: 50.602728605270386
Epoch: 35, Steps: 265 | Train Loss: 0.3748173 Vali Loss: 0.6683720 Test Loss: 0.3847734
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4051553
	speed: 0.8582s/iter; left time: 14697.6981s
	iters: 200, epoch: 36 | loss: 0.3847079
	speed: 0.1891s/iter; left time: 3219.6141s
Epoch: 36 cost time: 50.52506136894226
Epoch: 36, Steps: 265 | Train Loss: 0.3748862 Vali Loss: 0.6678857 Test Loss: 0.3846805
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3850680
	speed: 0.8666s/iter; left time: 14611.5175s
	iters: 200, epoch: 37 | loss: 0.3818478
	speed: 0.1911s/iter; left time: 3202.2787s
Epoch: 37 cost time: 51.20505928993225
Epoch: 37, Steps: 265 | Train Loss: 0.3747171 Vali Loss: 0.6675333 Test Loss: 0.3847836
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3752546
	speed: 0.8662s/iter; left time: 14375.3105s
	iters: 200, epoch: 38 | loss: 0.3722531
	speed: 0.2015s/iter; left time: 3323.8631s
Epoch: 38 cost time: 52.717328786849976
Epoch: 38, Steps: 265 | Train Loss: 0.3746674 Vali Loss: 0.6675434 Test Loss: 0.3847061
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3475606
	speed: 0.8446s/iter; left time: 13793.3821s
	iters: 200, epoch: 39 | loss: 0.3908049
	speed: 0.2050s/iter; left time: 3326.5927s
Epoch: 39 cost time: 54.20976495742798
Epoch: 39, Steps: 265 | Train Loss: 0.3746193 Vali Loss: 0.6676887 Test Loss: 0.3846950
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.3590321
	speed: 0.8538s/iter; left time: 13716.8384s
	iters: 200, epoch: 40 | loss: 0.3573914
	speed: 0.1774s/iter; left time: 2832.1323s
Epoch: 40 cost time: 50.47093725204468
Epoch: 40, Steps: 265 | Train Loss: 0.3747527 Vali Loss: 0.6678327 Test Loss: 0.3846919
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.4251823
	speed: 0.8731s/iter; left time: 13796.6413s
	iters: 200, epoch: 41 | loss: 0.3168813
	speed: 0.1928s/iter; left time: 3026.5774s
Epoch: 41 cost time: 52.692749977111816
Epoch: 41, Steps: 265 | Train Loss: 0.3745029 Vali Loss: 0.6674867 Test Loss: 0.3847256
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3679052
	speed: 0.8460s/iter; left time: 13143.2526s
	iters: 200, epoch: 42 | loss: 0.3486923
	speed: 0.1875s/iter; left time: 2894.9656s
Epoch: 42 cost time: 50.888580560684204
Epoch: 42, Steps: 265 | Train Loss: 0.3749754 Vali Loss: 0.6676702 Test Loss: 0.3847395
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3945659
	speed: 0.8447s/iter; left time: 12898.7668s
	iters: 200, epoch: 43 | loss: 0.3838372
	speed: 0.1855s/iter; left time: 2814.0444s
Epoch: 43 cost time: 50.64871883392334
Epoch: 43, Steps: 265 | Train Loss: 0.3746346 Vali Loss: 0.6673680 Test Loss: 0.3847381
EarlyStopping counter: 19 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.3961572
	speed: 0.8265s/iter; left time: 12402.4048s
	iters: 200, epoch: 44 | loss: 0.3847255
	speed: 0.1813s/iter; left time: 2702.0420s
Epoch: 44 cost time: 49.355573654174805
Epoch: 44, Steps: 265 | Train Loss: 0.3747610 Vali Loss: 0.6684477 Test Loss: 0.3847491
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_180_336_FITS_ETTm1_ftM_sl180_ll48_pl336_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.38482463359832764, mae:0.39086034893989563, rse:0.5903095006942749, corr:[0.5449472  0.54733235 0.5474515  0.5459325  0.5437844  0.5421061
 0.5413229  0.5415467  0.5422088  0.5429394  0.54349583 0.54334015
 0.54253185 0.5409629  0.53894216 0.5369262  0.5350403  0.5332983
 0.5316268  0.5299237  0.5281127  0.52607054 0.52381563 0.521477
 0.51919156 0.5171445  0.5155642  0.51446235 0.5138145  0.513517
 0.5135603  0.51376224 0.5138884  0.5138879  0.51372313 0.51346916
 0.51310766 0.5126715  0.51227933 0.511889   0.51156193 0.51125973
 0.51101685 0.5109267  0.51098734 0.51118374 0.5114925  0.511824
 0.51210475 0.51222837 0.51221806 0.5121381  0.5120548  0.5119841
 0.5119375  0.51189137 0.51190734 0.5119058  0.5118882  0.51181126
 0.51171106 0.51160914 0.51147264 0.5113157  0.51117414 0.5111776
 0.51133084 0.51159674 0.51200813 0.51249796 0.5129891  0.51338035
 0.5136009  0.51362526 0.51355404 0.51340604 0.5132778  0.5131988
 0.5131594  0.5131216  0.51307434 0.5129794  0.51282746 0.51255125
 0.5121724  0.5117911  0.5114777  0.5111973  0.5109394  0.5107708
 0.510665   0.5105459  0.5103111  0.50994194 0.50940984 0.5086666
 0.5077801  0.5068969  0.5060944  0.50540304 0.50496525 0.50487083
 0.5051002  0.50561404 0.5064075  0.50744957 0.5086465  0.5098585
 0.5109002  0.5115843  0.5118646  0.51196563 0.5119274  0.5118312
 0.51167244 0.5114974  0.51122785 0.5108247  0.51033163 0.5097861
 0.50928205 0.5087662  0.50822604 0.5077378  0.5072961  0.50689423
 0.5065887  0.50640416 0.50631523 0.50627625 0.5062092  0.5060291
 0.50571793 0.50539464 0.50509375 0.50479794 0.50461656 0.50451016
 0.50442785 0.50439036 0.50434655 0.5042871  0.50422096 0.50418687
 0.5042011  0.50428474 0.504367   0.5044639  0.5046478  0.5047459
 0.5047477  0.504692   0.50457746 0.50447065 0.50432813 0.50423867
 0.50421894 0.504299   0.5044172  0.5045738  0.50474143 0.50491875
 0.5051183  0.50535023 0.50558764 0.5058846  0.50619435 0.50649357
 0.5067652  0.5069428  0.50699335 0.5070062  0.5069535  0.5068268
 0.5066618  0.5064486  0.50622994 0.5060427  0.5058562  0.50572485
 0.505658   0.50566286 0.5056999  0.5057525  0.5058027  0.5058376
 0.5058825  0.5059607  0.5060851  0.5062557  0.5063879  0.506421
 0.50629264 0.5061197  0.5059202  0.50554436 0.50507665 0.5046939
 0.5044361  0.5042377  0.5040506  0.5040457  0.504035   0.5039017
 0.50363904 0.50307554 0.5023742  0.5017475  0.501222   0.5008043
 0.50042325 0.5000457  0.49958262 0.49895442 0.4981732  0.49733925
 0.4965556  0.49584666 0.49526104 0.4948287  0.49452844 0.49434906
 0.4942672  0.49427554 0.49426845 0.49421653 0.4941135  0.49390703
 0.49357703 0.49324268 0.49290833 0.4925903  0.49234065 0.4921896
 0.49215937 0.49225226 0.49236384 0.49251556 0.49267143 0.49275085
 0.49281314 0.4927859  0.49273047 0.49266115 0.49260566 0.49257785
 0.4925946  0.49259043 0.4925971  0.49262437 0.49264896 0.49264854
 0.4926379  0.49268088 0.4927127  0.49273455 0.49272192 0.49269503
 0.49274737 0.4929065  0.4931603  0.49348307 0.49381754 0.4941604
 0.49450466 0.4947627  0.4949561  0.49511442 0.49526617 0.49536437
 0.4954427  0.49547604 0.49551418 0.49556234 0.49564677 0.49574956
 0.49586803 0.4960447  0.4962121  0.4963273  0.4963705  0.49632254
 0.4962086  0.4960003  0.49572504 0.495371   0.49489462 0.49429688
 0.49350685 0.49268255 0.4919744  0.4913283  0.4907919  0.4903811
 0.49019903 0.49016777 0.49032906 0.49064568 0.49102077 0.49140552
 0.4916903  0.49170488 0.49159077 0.49148157 0.49143657 0.49142742
 0.4914629  0.49145854 0.49133578 0.49109885 0.49078664 0.49046576
 0.49017787 0.48989037 0.48964775 0.48950794 0.4893201  0.48911875
 0.4889048  0.48861307 0.48826712 0.48795933 0.48763165 0.48731288
 0.48699945 0.48671916 0.48644435 0.48618916 0.48594168 0.48574057
 0.48563322 0.48565054 0.48572764 0.48582053 0.4858671  0.48565307]
