Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=18, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_90_336', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_90_336_FITS_ETTm1_ftM_sl90_ll48_pl336_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34135
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=18, out_features=85, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1370880.0
params:  1615.0
Trainable parameters:  1615
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.7019300
	speed: 0.0245s/iter; left time: 648.6382s
	iters: 200, epoch: 1 | loss: 0.6099106
	speed: 0.0132s/iter; left time: 349.5140s
Epoch: 1 cost time: 4.606338739395142
Epoch: 1, Steps: 266 | Train Loss: 0.7168703 Vali Loss: 0.9327003 Test Loss: 0.6494537
Validation loss decreased (inf --> 0.932700).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4745698
	speed: 0.0713s/iter; left time: 1870.4230s
	iters: 200, epoch: 2 | loss: 0.4607366
	speed: 0.0133s/iter; left time: 348.7824s
Epoch: 2 cost time: 4.131658554077148
Epoch: 2, Steps: 266 | Train Loss: 0.4788014 Vali Loss: 0.7641112 Test Loss: 0.4888558
Validation loss decreased (0.932700 --> 0.764111).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4150537
	speed: 0.0670s/iter; left time: 1740.1564s
	iters: 200, epoch: 3 | loss: 0.4253623
	speed: 0.0136s/iter; left time: 350.7828s
Epoch: 3 cost time: 4.068313121795654
Epoch: 3, Steps: 266 | Train Loss: 0.4372831 Vali Loss: 0.7198011 Test Loss: 0.4501864
Validation loss decreased (0.764111 --> 0.719801).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4037224
	speed: 0.0689s/iter; left time: 1769.7041s
	iters: 200, epoch: 4 | loss: 0.4351997
	speed: 0.0189s/iter; left time: 483.6819s
Epoch: 4 cost time: 4.983823537826538
Epoch: 4, Steps: 266 | Train Loss: 0.4280301 Vali Loss: 0.7056848 Test Loss: 0.4383109
Validation loss decreased (0.719801 --> 0.705685).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3876500
	speed: 0.0700s/iter; left time: 1781.0453s
	iters: 200, epoch: 5 | loss: 0.3933512
	speed: 0.0136s/iter; left time: 344.7694s
Epoch: 5 cost time: 4.322605133056641
Epoch: 5, Steps: 266 | Train Loss: 0.4256094 Vali Loss: 0.6998799 Test Loss: 0.4338126
Validation loss decreased (0.705685 --> 0.699880).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4459346
	speed: 0.0666s/iter; left time: 1675.4332s
	iters: 200, epoch: 6 | loss: 0.4346614
	speed: 0.0130s/iter; left time: 326.9137s
Epoch: 6 cost time: 4.040823698043823
Epoch: 6, Steps: 266 | Train Loss: 0.4248840 Vali Loss: 0.6969942 Test Loss: 0.4324061
Validation loss decreased (0.699880 --> 0.696994).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4101313
	speed: 0.0671s/iter; left time: 1670.6426s
	iters: 200, epoch: 7 | loss: 0.4043507
	speed: 0.0132s/iter; left time: 327.3874s
Epoch: 7 cost time: 4.123153924942017
Epoch: 7, Steps: 266 | Train Loss: 0.4244841 Vali Loss: 0.6962190 Test Loss: 0.4318793
Validation loss decreased (0.696994 --> 0.696219).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4378903
	speed: 0.0674s/iter; left time: 1661.1447s
	iters: 200, epoch: 8 | loss: 0.4183765
	speed: 0.0134s/iter; left time: 328.4487s
Epoch: 8 cost time: 4.193527698516846
Epoch: 8, Steps: 266 | Train Loss: 0.4242441 Vali Loss: 0.6956947 Test Loss: 0.4314567
Validation loss decreased (0.696219 --> 0.695695).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3984028
	speed: 0.0692s/iter; left time: 1686.4499s
	iters: 200, epoch: 9 | loss: 0.3996479
	speed: 0.0135s/iter; left time: 327.7594s
Epoch: 9 cost time: 4.313671112060547
Epoch: 9, Steps: 266 | Train Loss: 0.4240220 Vali Loss: 0.6956501 Test Loss: 0.4312941
Validation loss decreased (0.695695 --> 0.695650).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4299120
	speed: 0.0670s/iter; left time: 1614.5479s
	iters: 200, epoch: 10 | loss: 0.4300243
	speed: 0.0136s/iter; left time: 327.5092s
Epoch: 10 cost time: 4.0578293800354
Epoch: 10, Steps: 266 | Train Loss: 0.4238540 Vali Loss: 0.6954034 Test Loss: 0.4311866
Validation loss decreased (0.695650 --> 0.695403).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4136773
	speed: 0.0673s/iter; left time: 1605.2676s
	iters: 200, epoch: 11 | loss: 0.4428683
	speed: 0.0139s/iter; left time: 329.5539s
Epoch: 11 cost time: 4.304594993591309
Epoch: 11, Steps: 266 | Train Loss: 0.4240674 Vali Loss: 0.6957020 Test Loss: 0.4313061
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4166448
	speed: 0.0693s/iter; left time: 1634.4521s
	iters: 200, epoch: 12 | loss: 0.4081662
	speed: 0.0135s/iter; left time: 315.8958s
Epoch: 12 cost time: 4.091812372207642
Epoch: 12, Steps: 266 | Train Loss: 0.4237963 Vali Loss: 0.6957793 Test Loss: 0.4315933
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4521410
	speed: 0.0662s/iter; left time: 1542.4491s
	iters: 200, epoch: 13 | loss: 0.3969319
	speed: 0.0130s/iter; left time: 301.7326s
Epoch: 13 cost time: 4.020758152008057
Epoch: 13, Steps: 266 | Train Loss: 0.4238695 Vali Loss: 0.6947361 Test Loss: 0.4312283
Validation loss decreased (0.695403 --> 0.694736).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4660878
	speed: 0.0651s/iter; left time: 1500.6551s
	iters: 200, epoch: 14 | loss: 0.4342483
	speed: 0.0129s/iter; left time: 296.6271s
Epoch: 14 cost time: 4.033890724182129
Epoch: 14, Steps: 266 | Train Loss: 0.4237039 Vali Loss: 0.6953298 Test Loss: 0.4311153
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4167107
	speed: 0.0676s/iter; left time: 1540.4630s
	iters: 200, epoch: 15 | loss: 0.4366716
	speed: 0.0140s/iter; left time: 318.4435s
Epoch: 15 cost time: 4.278056859970093
Epoch: 15, Steps: 266 | Train Loss: 0.4239034 Vali Loss: 0.6954512 Test Loss: 0.4314123
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4099426
	speed: 0.0673s/iter; left time: 1514.0626s
	iters: 200, epoch: 16 | loss: 0.4408502
	speed: 0.0137s/iter; left time: 306.9084s
Epoch: 16 cost time: 4.156707048416138
Epoch: 16, Steps: 266 | Train Loss: 0.4239362 Vali Loss: 0.6954429 Test Loss: 0.4312025
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4446528
	speed: 0.0651s/iter; left time: 1449.0022s
	iters: 200, epoch: 17 | loss: 0.3783206
	speed: 0.0129s/iter; left time: 284.6197s
Epoch: 17 cost time: 3.9795644283294678
Epoch: 17, Steps: 266 | Train Loss: 0.4236936 Vali Loss: 0.6948942 Test Loss: 0.4311078
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4168244
	speed: 0.0649s/iter; left time: 1426.4856s
	iters: 200, epoch: 18 | loss: 0.4353979
	speed: 0.0133s/iter; left time: 290.7265s
Epoch: 18 cost time: 3.935494899749756
Epoch: 18, Steps: 266 | Train Loss: 0.4238338 Vali Loss: 0.6953365 Test Loss: 0.4312217
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4238658
	speed: 0.0670s/iter; left time: 1454.4029s
	iters: 200, epoch: 19 | loss: 0.4007984
	speed: 0.0131s/iter; left time: 283.6220s
Epoch: 19 cost time: 4.070463418960571
Epoch: 19, Steps: 266 | Train Loss: 0.4236721 Vali Loss: 0.6945252 Test Loss: 0.4309748
Validation loss decreased (0.694736 --> 0.694525).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4300292
	speed: 0.0669s/iter; left time: 1435.8154s
	iters: 200, epoch: 20 | loss: 0.4304223
	speed: 0.0133s/iter; left time: 283.7519s
Epoch: 20 cost time: 3.983588218688965
Epoch: 20, Steps: 266 | Train Loss: 0.4237898 Vali Loss: 0.6956067 Test Loss: 0.4314652
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4549125
	speed: 0.0644s/iter; left time: 1363.6765s
	iters: 200, epoch: 21 | loss: 0.3591042
	speed: 0.0131s/iter; left time: 275.5699s
Epoch: 21 cost time: 4.013415813446045
Epoch: 21, Steps: 266 | Train Loss: 0.4236750 Vali Loss: 0.6947135 Test Loss: 0.4310430
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4536141
	speed: 0.0675s/iter; left time: 1410.9274s
	iters: 200, epoch: 22 | loss: 0.4798504
	speed: 0.0132s/iter; left time: 275.7583s
Epoch: 22 cost time: 4.091515302658081
Epoch: 22, Steps: 266 | Train Loss: 0.4238618 Vali Loss: 0.6954893 Test Loss: 0.4314748
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4507476
	speed: 0.0660s/iter; left time: 1363.2146s
	iters: 200, epoch: 23 | loss: 0.4717678
	speed: 0.0131s/iter; left time: 269.2899s
Epoch: 23 cost time: 4.102367401123047
Epoch: 23, Steps: 266 | Train Loss: 0.4237457 Vali Loss: 0.6947923 Test Loss: 0.4315654
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4415371
	speed: 0.0664s/iter; left time: 1353.7336s
	iters: 200, epoch: 24 | loss: 0.4037104
	speed: 0.0130s/iter; left time: 262.8126s
Epoch: 24 cost time: 4.039143323898315
Epoch: 24, Steps: 266 | Train Loss: 0.4236620 Vali Loss: 0.6953855 Test Loss: 0.4314840
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4478453
	speed: 0.0670s/iter; left time: 1347.8946s
	iters: 200, epoch: 25 | loss: 0.4209501
	speed: 0.0128s/iter; left time: 256.0695s
Epoch: 25 cost time: 3.9754745960235596
Epoch: 25, Steps: 266 | Train Loss: 0.4237612 Vali Loss: 0.6954586 Test Loss: 0.4313527
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3845588
	speed: 0.0657s/iter; left time: 1305.0544s
	iters: 200, epoch: 26 | loss: 0.3777159
	speed: 0.0135s/iter; left time: 266.1302s
Epoch: 26 cost time: 4.116715431213379
Epoch: 26, Steps: 266 | Train Loss: 0.4234971 Vali Loss: 0.6952115 Test Loss: 0.4313216
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4451550
	speed: 0.0673s/iter; left time: 1317.2247s
	iters: 200, epoch: 27 | loss: 0.4026867
	speed: 0.0152s/iter; left time: 295.7833s
Epoch: 27 cost time: 4.326114892959595
Epoch: 27, Steps: 266 | Train Loss: 0.4237410 Vali Loss: 0.6956038 Test Loss: 0.4314014
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4177012
	speed: 0.0732s/iter; left time: 1414.7260s
	iters: 200, epoch: 28 | loss: 0.4711830
	speed: 0.0153s/iter; left time: 294.4951s
Epoch: 28 cost time: 4.692947864532471
Epoch: 28, Steps: 266 | Train Loss: 0.4236068 Vali Loss: 0.6945835 Test Loss: 0.4315141
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4563707
	speed: 0.0673s/iter; left time: 1282.3186s
	iters: 200, epoch: 29 | loss: 0.4496121
	speed: 0.0135s/iter; left time: 254.9714s
Epoch: 29 cost time: 4.065309286117554
Epoch: 29, Steps: 266 | Train Loss: 0.4237375 Vali Loss: 0.6955934 Test Loss: 0.4313665
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4228159
	speed: 0.0675s/iter; left time: 1268.8898s
	iters: 200, epoch: 30 | loss: 0.4265073
	speed: 0.0138s/iter; left time: 258.7008s
Epoch: 30 cost time: 4.435604095458984
Epoch: 30, Steps: 266 | Train Loss: 0.4237078 Vali Loss: 0.6953716 Test Loss: 0.4313329
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4029315
	speed: 0.0718s/iter; left time: 1329.2579s
	iters: 200, epoch: 31 | loss: 0.4089920
	speed: 0.0140s/iter; left time: 258.1721s
Epoch: 31 cost time: 4.391778469085693
Epoch: 31, Steps: 266 | Train Loss: 0.4236455 Vali Loss: 0.6945767 Test Loss: 0.4315057
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4160313
	speed: 0.0692s/iter; left time: 1263.8417s
	iters: 200, epoch: 32 | loss: 0.4078048
	speed: 0.0135s/iter; left time: 245.6633s
Epoch: 32 cost time: 4.243451356887817
Epoch: 32, Steps: 266 | Train Loss: 0.4235820 Vali Loss: 0.6952296 Test Loss: 0.4313251
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4426047
	speed: 0.0738s/iter; left time: 1328.1775s
	iters: 200, epoch: 33 | loss: 0.3904759
	speed: 0.0144s/iter; left time: 256.8876s
Epoch: 33 cost time: 4.4078528881073
Epoch: 33, Steps: 266 | Train Loss: 0.4236475 Vali Loss: 0.6952493 Test Loss: 0.4313579
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4783768
	speed: 0.0705s/iter; left time: 1249.1918s
	iters: 200, epoch: 34 | loss: 0.4273374
	speed: 0.0143s/iter; left time: 252.6866s
Epoch: 34 cost time: 4.368325710296631
Epoch: 34, Steps: 266 | Train Loss: 0.4234655 Vali Loss: 0.6955603 Test Loss: 0.4314766
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4093780
	speed: 0.0671s/iter; left time: 1170.8732s
	iters: 200, epoch: 35 | loss: 0.4248066
	speed: 0.0129s/iter; left time: 223.1563s
Epoch: 35 cost time: 3.9689300060272217
Epoch: 35, Steps: 266 | Train Loss: 0.4236632 Vali Loss: 0.6954006 Test Loss: 0.4315123
EarlyStopping counter: 16 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4520204
	speed: 0.0679s/iter; left time: 1167.8353s
	iters: 200, epoch: 36 | loss: 0.4445907
	speed: 0.0129s/iter; left time: 220.4912s
Epoch: 36 cost time: 4.018479347229004
Epoch: 36, Steps: 266 | Train Loss: 0.4237516 Vali Loss: 0.6954029 Test Loss: 0.4314899
EarlyStopping counter: 17 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4226093
	speed: 0.0659s/iter; left time: 1114.7044s
	iters: 200, epoch: 37 | loss: 0.4492314
	speed: 0.0140s/iter; left time: 234.7888s
Epoch: 37 cost time: 4.185073375701904
Epoch: 37, Steps: 266 | Train Loss: 0.4236166 Vali Loss: 0.6953281 Test Loss: 0.4313864
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4875083
	speed: 0.0652s/iter; left time: 1085.9116s
	iters: 200, epoch: 38 | loss: 0.4094267
	speed: 0.0139s/iter; left time: 229.6501s
Epoch: 38 cost time: 4.0563249588012695
Epoch: 38, Steps: 266 | Train Loss: 0.4235250 Vali Loss: 0.6954156 Test Loss: 0.4315377
EarlyStopping counter: 19 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4281940
	speed: 0.0655s/iter; left time: 1074.4935s
	iters: 200, epoch: 39 | loss: 0.4488985
	speed: 0.0140s/iter; left time: 228.2224s
Epoch: 39 cost time: 4.063593626022339
Epoch: 39, Steps: 266 | Train Loss: 0.4237041 Vali Loss: 0.6950349 Test Loss: 0.4314457
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm1_90_336_FITS_ETTm1_ftM_sl90_ll48_pl336_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.43107226490974426, mae:0.41859790682792664, rse:0.6247745752334595, corr:[0.5459487  0.5464444  0.54098237 0.53753275 0.53657377 0.53552186
 0.5328128  0.52973133 0.52788764 0.5272272  0.5267672  0.52581453
 0.5244712  0.5227733  0.520286   0.51703197 0.51365423 0.51065373
 0.50790495 0.50497884 0.50183237 0.49875617 0.4959168  0.49299473
 0.48971638 0.48605904 0.48267597 0.48012388 0.47837156 0.4767582
 0.47539222 0.47509634 0.47554934 0.4761639  0.47654182 0.47677585
 0.47668204 0.4766556  0.47676566 0.47679073 0.4766993  0.47628927
 0.47590673 0.4758007  0.4756891  0.47541964 0.47508702 0.4748282
 0.4748049  0.47507852 0.47552416 0.47580895 0.47610673 0.4764617
 0.4770679  0.4776293  0.47798696 0.47807166 0.47785774 0.47775438
 0.47779062 0.47745258 0.47684297 0.47612244 0.4758732  0.47597545
 0.4759046  0.47559854 0.4755384  0.4760259  0.4767301  0.47747344
 0.4781801  0.47874144 0.47939575 0.48006538 0.4809248  0.4818947
 0.4826966  0.48332724 0.48390833 0.48438442 0.4848928  0.48519674
 0.48532832 0.48546377 0.48588675 0.48668283 0.48770952 0.48869234
 0.48943663 0.48998863 0.49055085 0.49115592 0.4915465  0.4913702
 0.49054995 0.48945922 0.4884143  0.48759001 0.487153   0.4868851
 0.48651645 0.48592937 0.48543242 0.4850211  0.48445988 0.48369437
 0.48285738 0.48209387 0.4813808  0.48059508 0.4796914  0.4787746
 0.47788    0.47710449 0.47624457 0.4752042  0.47403598 0.4728086
 0.47157997 0.47019285 0.4687371  0.467607   0.46680915 0.46618256
 0.46568805 0.46530142 0.46499163 0.46474364 0.46460998 0.46468762
 0.46481678 0.46495348 0.46485072 0.46450293 0.46412405 0.46395746
 0.46396542 0.46396473 0.46378905 0.4635548  0.46339014 0.46340698
 0.46350485 0.46367273 0.46392578 0.46417612 0.4645939  0.46496692
 0.46520603 0.4655148  0.46582237 0.46600664 0.46592072 0.46576414
 0.4656353  0.4656197  0.46565464 0.46568584 0.46577454 0.46583796
 0.4659307  0.46613884 0.46652797 0.46704447 0.46767673 0.46839046
 0.4691039  0.46973237 0.4702778  0.47093067 0.47162256 0.4723334
 0.4729404  0.47345516 0.47389862 0.47426885 0.47448283 0.4746729
 0.47493288 0.47539622 0.47601658 0.47676817 0.47759098 0.47838238
 0.4790918  0.47966972 0.48006418 0.4802994  0.48057067 0.48108196
 0.4818441  0.48278147 0.48369852 0.48462972 0.48571402 0.48685023
 0.48744082 0.48716795 0.4865971  0.486169   0.48578307 0.48518372
 0.48421702 0.4829502  0.48152304 0.48013118 0.47870913 0.4773177
 0.47595984 0.4747271  0.473657   0.47252753 0.47103462 0.4692942
 0.46729282 0.46543366 0.46404734 0.4631948  0.46238858 0.4614324
 0.46054193 0.4601905  0.46020162 0.4602277  0.46029845 0.46014684
 0.45987284 0.45976767 0.45977104 0.45962763 0.4593995  0.45911974
 0.45892146 0.45878375 0.45851892 0.45835814 0.45847693 0.45854002
 0.4586132  0.45858425 0.4586423  0.45897684 0.45932773 0.459733
 0.460155   0.46062288 0.46104702 0.4614862  0.4616631  0.46172625
 0.46168986 0.4618288  0.46193245 0.46209124 0.4620039  0.46177053
 0.46185985 0.46242487 0.46297178 0.46332988 0.46354723 0.46383274
 0.46446085 0.4651202  0.46565813 0.46624488 0.467088   0.46803302
 0.46902105 0.46982142 0.47043517 0.47086477 0.47125408 0.47168303
 0.4721839  0.4727428  0.47321996 0.4736991  0.47427246 0.4749988
 0.47578907 0.47642788 0.47670305 0.47651702 0.47589403 0.47478735
 0.47290182 0.47035643 0.4679589  0.4663983  0.46570444 0.4654383
 0.46512577 0.46470562 0.4645352  0.46442783 0.4640052  0.46319464
 0.46217877 0.46113977 0.46006045 0.45885515 0.45767486 0.45665544
 0.4559498  0.45527366 0.45450792 0.45369244 0.45293117 0.4521557
 0.45122182 0.45019072 0.4492918  0.44867194 0.44801888 0.44735467
 0.44674712 0.446346   0.44620544 0.44615254 0.44588757 0.44540468
 0.44486144 0.44472107 0.44490814 0.44498932 0.44464287 0.4441051
 0.44413227 0.44454417 0.444582   0.44392875 0.44405535 0.44642004]
