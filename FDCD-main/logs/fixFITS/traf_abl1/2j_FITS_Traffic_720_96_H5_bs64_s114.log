Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=165, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_720_j96_H5', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=10, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_720_j96_H5_FITS_custom_ftM_sl720_ll48_pl96_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11465
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=165, out_features=187, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3404417280.0
params:  31042.0
Trainable parameters:  31042
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 125.22303938865662
Epoch: 1, Steps: 89 | Train Loss: 0.9827894 Vali Loss: 1.0768026 Test Loss: 1.2365526
Validation loss decreased (inf --> 1.076803).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 118.64521026611328
Epoch: 2, Steps: 89 | Train Loss: 0.7510298 Vali Loss: 0.9543495 Test Loss: 1.0973817
Validation loss decreased (1.076803 --> 0.954349).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 121.16854524612427
Epoch: 3, Steps: 89 | Train Loss: 0.6513732 Vali Loss: 0.8920422 Test Loss: 1.0264353
Validation loss decreased (0.954349 --> 0.892042).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 123.93014430999756
Epoch: 4, Steps: 89 | Train Loss: 0.5826819 Vali Loss: 0.8377683 Test Loss: 0.9669018
Validation loss decreased (0.892042 --> 0.837768).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 114.7076358795166
Epoch: 5, Steps: 89 | Train Loss: 0.5271102 Vali Loss: 0.7962687 Test Loss: 0.9208556
Validation loss decreased (0.837768 --> 0.796269).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 120.59236097335815
Epoch: 6, Steps: 89 | Train Loss: 0.4801376 Vali Loss: 0.7590171 Test Loss: 0.8755954
Validation loss decreased (0.796269 --> 0.759017).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 114.24262619018555
Epoch: 7, Steps: 89 | Train Loss: 0.4400156 Vali Loss: 0.7244573 Test Loss: 0.8357049
Validation loss decreased (0.759017 --> 0.724457).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 113.53135704994202
Epoch: 8, Steps: 89 | Train Loss: 0.4051832 Vali Loss: 0.6892456 Test Loss: 0.7986988
Validation loss decreased (0.724457 --> 0.689246).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 118.39434671401978
Epoch: 9, Steps: 89 | Train Loss: 0.3748666 Vali Loss: 0.6647367 Test Loss: 0.7678393
Validation loss decreased (0.689246 --> 0.664737).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 110.78025436401367
Epoch: 10, Steps: 89 | Train Loss: 0.3482478 Vali Loss: 0.6392254 Test Loss: 0.7400265
Validation loss decreased (0.664737 --> 0.639225).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 117.4070692062378
Epoch: 11, Steps: 89 | Train Loss: 0.3247820 Vali Loss: 0.6173111 Test Loss: 0.7144973
Validation loss decreased (0.639225 --> 0.617311).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 112.80552411079407
Epoch: 12, Steps: 89 | Train Loss: 0.3040014 Vali Loss: 0.5997251 Test Loss: 0.6920299
Validation loss decreased (0.617311 --> 0.599725).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 110.01078224182129
Epoch: 13, Steps: 89 | Train Loss: 0.2854584 Vali Loss: 0.5789078 Test Loss: 0.6683940
Validation loss decreased (0.599725 --> 0.578908).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 110.27559113502502
Epoch: 14, Steps: 89 | Train Loss: 0.2689612 Vali Loss: 0.5605038 Test Loss: 0.6483347
Validation loss decreased (0.578908 --> 0.560504).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 108.58757829666138
Epoch: 15, Steps: 89 | Train Loss: 0.2542010 Vali Loss: 0.5449885 Test Loss: 0.6320476
Validation loss decreased (0.560504 --> 0.544989).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 107.76426768302917
Epoch: 16, Steps: 89 | Train Loss: 0.2408906 Vali Loss: 0.5319182 Test Loss: 0.6163056
Validation loss decreased (0.544989 --> 0.531918).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 109.09660840034485
Epoch: 17, Steps: 89 | Train Loss: 0.2289290 Vali Loss: 0.5212973 Test Loss: 0.6037821
Validation loss decreased (0.531918 --> 0.521297).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 107.06364464759827
Epoch: 18, Steps: 89 | Train Loss: 0.2181437 Vali Loss: 0.5100445 Test Loss: 0.5894870
Validation loss decreased (0.521297 --> 0.510045).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 115.09121227264404
Epoch: 19, Steps: 89 | Train Loss: 0.2083178 Vali Loss: 0.4986734 Test Loss: 0.5780418
Validation loss decreased (0.510045 --> 0.498673).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 107.84107971191406
Epoch: 20, Steps: 89 | Train Loss: 0.1994567 Vali Loss: 0.4893778 Test Loss: 0.5677687
Validation loss decreased (0.498673 --> 0.489378).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 103.50703597068787
Epoch: 21, Steps: 89 | Train Loss: 0.1913755 Vali Loss: 0.4812517 Test Loss: 0.5566235
Validation loss decreased (0.489378 --> 0.481252).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 109.99854707717896
Epoch: 22, Steps: 89 | Train Loss: 0.1840011 Vali Loss: 0.4725565 Test Loss: 0.5476198
Validation loss decreased (0.481252 --> 0.472557).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 106.95968389511108
Epoch: 23, Steps: 89 | Train Loss: 0.1772757 Vali Loss: 0.4661337 Test Loss: 0.5402203
Validation loss decreased (0.472557 --> 0.466134).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 106.37325835227966
Epoch: 24, Steps: 89 | Train Loss: 0.1711320 Vali Loss: 0.4596376 Test Loss: 0.5326537
Validation loss decreased (0.466134 --> 0.459638).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 107.44642639160156
Epoch: 25, Steps: 89 | Train Loss: 0.1654608 Vali Loss: 0.4532740 Test Loss: 0.5247300
Validation loss decreased (0.459638 --> 0.453274).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 101.71863961219788
Epoch: 26, Steps: 89 | Train Loss: 0.1602821 Vali Loss: 0.4458522 Test Loss: 0.5178300
Validation loss decreased (0.453274 --> 0.445852).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 106.29298996925354
Epoch: 27, Steps: 89 | Train Loss: 0.1554831 Vali Loss: 0.4408772 Test Loss: 0.5123813
Validation loss decreased (0.445852 --> 0.440877).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 108.16704988479614
Epoch: 28, Steps: 89 | Train Loss: 0.1511095 Vali Loss: 0.4367758 Test Loss: 0.5066655
Validation loss decreased (0.440877 --> 0.436776).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 104.47242617607117
Epoch: 29, Steps: 89 | Train Loss: 0.1470447 Vali Loss: 0.4327984 Test Loss: 0.5025415
Validation loss decreased (0.436776 --> 0.432798).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 100.86942911148071
Epoch: 30, Steps: 89 | Train Loss: 0.1432985 Vali Loss: 0.4284465 Test Loss: 0.4975420
Validation loss decreased (0.432798 --> 0.428447).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 96.31473159790039
Epoch: 31, Steps: 89 | Train Loss: 0.1398288 Vali Loss: 0.4244386 Test Loss: 0.4924997
Validation loss decreased (0.428447 --> 0.424439).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 103.00734186172485
Epoch: 32, Steps: 89 | Train Loss: 0.1365969 Vali Loss: 0.4204558 Test Loss: 0.4885859
Validation loss decreased (0.424439 --> 0.420456).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 101.61761474609375
Epoch: 33, Steps: 89 | Train Loss: 0.1336322 Vali Loss: 0.4167119 Test Loss: 0.4853045
Validation loss decreased (0.420456 --> 0.416712).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 103.54072284698486
Epoch: 34, Steps: 89 | Train Loss: 0.1308556 Vali Loss: 0.4130205 Test Loss: 0.4801715
Validation loss decreased (0.416712 --> 0.413020).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 105.63464140892029
Epoch: 35, Steps: 89 | Train Loss: 0.1282818 Vali Loss: 0.4094318 Test Loss: 0.4774738
Validation loss decreased (0.413020 --> 0.409432).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 103.3276264667511
Epoch: 36, Steps: 89 | Train Loss: 0.1258609 Vali Loss: 0.4066591 Test Loss: 0.4736246
Validation loss decreased (0.409432 --> 0.406659).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 110.20510792732239
Epoch: 37, Steps: 89 | Train Loss: 0.1236273 Vali Loss: 0.4060214 Test Loss: 0.4723314
Validation loss decreased (0.406659 --> 0.406021).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 113.55568027496338
Epoch: 38, Steps: 89 | Train Loss: 0.1215403 Vali Loss: 0.4021007 Test Loss: 0.4690772
Validation loss decreased (0.406021 --> 0.402101).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 110.48657441139221
Epoch: 39, Steps: 89 | Train Loss: 0.1195579 Vali Loss: 0.3984571 Test Loss: 0.4658648
Validation loss decreased (0.402101 --> 0.398457).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 111.0863778591156
Epoch: 40, Steps: 89 | Train Loss: 0.1177581 Vali Loss: 0.4003472 Test Loss: 0.4646560
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 109.53303456306458
Epoch: 41, Steps: 89 | Train Loss: 0.1160321 Vali Loss: 0.3972703 Test Loss: 0.4623668
Validation loss decreased (0.398457 --> 0.397270).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 111.10261559486389
Epoch: 42, Steps: 89 | Train Loss: 0.1144509 Vali Loss: 0.3939721 Test Loss: 0.4603032
Validation loss decreased (0.397270 --> 0.393972).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 113.92665839195251
Epoch: 43, Steps: 89 | Train Loss: 0.1129422 Vali Loss: 0.3944097 Test Loss: 0.4583338
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 110.39801239967346
Epoch: 44, Steps: 89 | Train Loss: 0.1115236 Vali Loss: 0.3916353 Test Loss: 0.4564790
Validation loss decreased (0.393972 --> 0.391635).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 116.56719470024109
Epoch: 45, Steps: 89 | Train Loss: 0.1102066 Vali Loss: 0.3887527 Test Loss: 0.4547263
Validation loss decreased (0.391635 --> 0.388753).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 111.07626867294312
Epoch: 46, Steps: 89 | Train Loss: 0.1089576 Vali Loss: 0.3877883 Test Loss: 0.4532993
Validation loss decreased (0.388753 --> 0.387788).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 107.34310817718506
Epoch: 47, Steps: 89 | Train Loss: 0.1077859 Vali Loss: 0.3872814 Test Loss: 0.4516802
Validation loss decreased (0.387788 --> 0.387281).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 114.97952461242676
Epoch: 48, Steps: 89 | Train Loss: 0.1066790 Vali Loss: 0.3858769 Test Loss: 0.4501836
Validation loss decreased (0.387281 --> 0.385877).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 108.78397345542908
Epoch: 49, Steps: 89 | Train Loss: 0.1056524 Vali Loss: 0.3841198 Test Loss: 0.4486203
Validation loss decreased (0.385877 --> 0.384120).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 112.5499222278595
Epoch: 50, Steps: 89 | Train Loss: 0.1046627 Vali Loss: 0.3838011 Test Loss: 0.4473043
Validation loss decreased (0.384120 --> 0.383801).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 115.79793691635132
Epoch: 51, Steps: 89 | Train Loss: 0.1037478 Vali Loss: 0.3831363 Test Loss: 0.4462135
Validation loss decreased (0.383801 --> 0.383136).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 108.44407749176025
Epoch: 52, Steps: 89 | Train Loss: 0.1028752 Vali Loss: 0.3798201 Test Loss: 0.4450439
Validation loss decreased (0.383136 --> 0.379820).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 109.85505986213684
Epoch: 53, Steps: 89 | Train Loss: 0.1020586 Vali Loss: 0.3812537 Test Loss: 0.4439744
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 111.30483222007751
Epoch: 54, Steps: 89 | Train Loss: 0.1012744 Vali Loss: 0.3794448 Test Loss: 0.4430923
Validation loss decreased (0.379820 --> 0.379445).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 108.7951328754425
Epoch: 55, Steps: 89 | Train Loss: 0.1005665 Vali Loss: 0.3776628 Test Loss: 0.4423054
Validation loss decreased (0.379445 --> 0.377663).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 112.3516616821289
Epoch: 56, Steps: 89 | Train Loss: 0.0998598 Vali Loss: 0.3784895 Test Loss: 0.4415233
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 104.9615797996521
Epoch: 57, Steps: 89 | Train Loss: 0.0992190 Vali Loss: 0.3766046 Test Loss: 0.4405030
Validation loss decreased (0.377663 --> 0.376605).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 103.6701307296753
Epoch: 58, Steps: 89 | Train Loss: 0.0985896 Vali Loss: 0.3751539 Test Loss: 0.4396175
Validation loss decreased (0.376605 --> 0.375154).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 106.10063242912292
Epoch: 59, Steps: 89 | Train Loss: 0.0979885 Vali Loss: 0.3754939 Test Loss: 0.4387909
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 99.59768486022949
Epoch: 60, Steps: 89 | Train Loss: 0.0974450 Vali Loss: 0.3745109 Test Loss: 0.4380478
Validation loss decreased (0.375154 --> 0.374511).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 107.40972328186035
Epoch: 61, Steps: 89 | Train Loss: 0.0969286 Vali Loss: 0.3736480 Test Loss: 0.4373339
Validation loss decreased (0.374511 --> 0.373648).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 107.35364532470703
Epoch: 62, Steps: 89 | Train Loss: 0.0964186 Vali Loss: 0.3736632 Test Loss: 0.4370194
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 100.5670337677002
Epoch: 63, Steps: 89 | Train Loss: 0.0959493 Vali Loss: 0.3721642 Test Loss: 0.4362718
Validation loss decreased (0.373648 --> 0.372164).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 103.94291925430298
Epoch: 64, Steps: 89 | Train Loss: 0.0955137 Vali Loss: 0.3730305 Test Loss: 0.4359137
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 103.79852771759033
Epoch: 65, Steps: 89 | Train Loss: 0.0950667 Vali Loss: 0.3728137 Test Loss: 0.4351570
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 109.06421732902527
Epoch: 66, Steps: 89 | Train Loss: 0.0946904 Vali Loss: 0.3711193 Test Loss: 0.4347471
Validation loss decreased (0.372164 --> 0.371119).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 105.14945268630981
Epoch: 67, Steps: 89 | Train Loss: 0.0943015 Vali Loss: 0.3708962 Test Loss: 0.4340984
Validation loss decreased (0.371119 --> 0.370896).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 103.339768409729
Epoch: 68, Steps: 89 | Train Loss: 0.0939359 Vali Loss: 0.3712403 Test Loss: 0.4337805
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 101.72431135177612
Epoch: 69, Steps: 89 | Train Loss: 0.0935920 Vali Loss: 0.3699243 Test Loss: 0.4332730
Validation loss decreased (0.370896 --> 0.369924).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 108.84117722511292
Epoch: 70, Steps: 89 | Train Loss: 0.0932644 Vali Loss: 0.3704145 Test Loss: 0.4329109
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 103.90957760810852
Epoch: 71, Steps: 89 | Train Loss: 0.0929502 Vali Loss: 0.3687323 Test Loss: 0.4325165
Validation loss decreased (0.369924 --> 0.368732).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 106.46623730659485
Epoch: 72, Steps: 89 | Train Loss: 0.0926727 Vali Loss: 0.3690319 Test Loss: 0.4319613
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 106.26340103149414
Epoch: 73, Steps: 89 | Train Loss: 0.0924120 Vali Loss: 0.3689037 Test Loss: 0.4316650
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 101.78202795982361
Epoch: 74, Steps: 89 | Train Loss: 0.0921269 Vali Loss: 0.3684708 Test Loss: 0.4313314
Validation loss decreased (0.368732 --> 0.368471).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 105.47718620300293
Epoch: 75, Steps: 89 | Train Loss: 0.0918713 Vali Loss: 0.3676066 Test Loss: 0.4309334
Validation loss decreased (0.368471 --> 0.367607).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 105.11639213562012
Epoch: 76, Steps: 89 | Train Loss: 0.0916497 Vali Loss: 0.3676207 Test Loss: 0.4306380
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 106.49215030670166
Epoch: 77, Steps: 89 | Train Loss: 0.0914183 Vali Loss: 0.3677353 Test Loss: 0.4304341
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 104.96145749092102
Epoch: 78, Steps: 89 | Train Loss: 0.0911914 Vali Loss: 0.3668323 Test Loss: 0.4300757
Validation loss decreased (0.367607 --> 0.366832).  Saving model ...
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 97.77654957771301
Epoch: 79, Steps: 89 | Train Loss: 0.0909851 Vali Loss: 0.3678296 Test Loss: 0.4298901
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 100.55627250671387
Epoch: 80, Steps: 89 | Train Loss: 0.0907925 Vali Loss: 0.3666856 Test Loss: 0.4296415
Validation loss decreased (0.366832 --> 0.366686).  Saving model ...
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 102.97877526283264
Epoch: 81, Steps: 89 | Train Loss: 0.0906280 Vali Loss: 0.3663355 Test Loss: 0.4293741
Validation loss decreased (0.366686 --> 0.366336).  Saving model ...
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 99.77604460716248
Epoch: 82, Steps: 89 | Train Loss: 0.0904389 Vali Loss: 0.3668266 Test Loss: 0.4291563
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 100.65256714820862
Epoch: 83, Steps: 89 | Train Loss: 0.0902797 Vali Loss: 0.3659013 Test Loss: 0.4289040
Validation loss decreased (0.366336 --> 0.365901).  Saving model ...
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 98.70568656921387
Epoch: 84, Steps: 89 | Train Loss: 0.0901215 Vali Loss: 0.3652391 Test Loss: 0.4287813
Validation loss decreased (0.365901 --> 0.365239).  Saving model ...
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 100.93467903137207
Epoch: 85, Steps: 89 | Train Loss: 0.0899728 Vali Loss: 0.3659117 Test Loss: 0.4285516
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 101.5882670879364
Epoch: 86, Steps: 89 | Train Loss: 0.0898185 Vali Loss: 0.3654326 Test Loss: 0.4284046
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 99.19225144386292
Epoch: 87, Steps: 89 | Train Loss: 0.0896906 Vali Loss: 0.3654974 Test Loss: 0.4281844
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 98.95259046554565
Epoch: 88, Steps: 89 | Train Loss: 0.0895674 Vali Loss: 0.3648993 Test Loss: 0.4280319
Validation loss decreased (0.365239 --> 0.364899).  Saving model ...
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 97.60748386383057
Epoch: 89, Steps: 89 | Train Loss: 0.0894363 Vali Loss: 0.3658278 Test Loss: 0.4278698
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 100.27584481239319
Epoch: 90, Steps: 89 | Train Loss: 0.0893190 Vali Loss: 0.3655943 Test Loss: 0.4277124
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 101.83144927024841
Epoch: 91, Steps: 89 | Train Loss: 0.0892148 Vali Loss: 0.3645219 Test Loss: 0.4275753
Validation loss decreased (0.364899 --> 0.364522).  Saving model ...
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 96.85795593261719
Epoch: 92, Steps: 89 | Train Loss: 0.0890857 Vali Loss: 0.3643332 Test Loss: 0.4274683
Validation loss decreased (0.364522 --> 0.364333).  Saving model ...
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 100.30705904960632
Epoch: 93, Steps: 89 | Train Loss: 0.0889879 Vali Loss: 0.3651228 Test Loss: 0.4273182
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 98.48504424095154
Epoch: 94, Steps: 89 | Train Loss: 0.0889017 Vali Loss: 0.3644687 Test Loss: 0.4272183
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 99.20145106315613
Epoch: 95, Steps: 89 | Train Loss: 0.0888397 Vali Loss: 0.3644094 Test Loss: 0.4270751
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 100.64428567886353
Epoch: 96, Steps: 89 | Train Loss: 0.0887504 Vali Loss: 0.3630289 Test Loss: 0.4269856
Validation loss decreased (0.364333 --> 0.363029).  Saving model ...
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 99.98458695411682
Epoch: 97, Steps: 89 | Train Loss: 0.0886640 Vali Loss: 0.3642026 Test Loss: 0.4268833
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 95.79472374916077
Epoch: 98, Steps: 89 | Train Loss: 0.0885759 Vali Loss: 0.3647173 Test Loss: 0.4267923
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 98.12188243865967
Epoch: 99, Steps: 89 | Train Loss: 0.0884999 Vali Loss: 0.3641909 Test Loss: 0.4267012
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 98.91090250015259
Epoch: 100, Steps: 89 | Train Loss: 0.0884392 Vali Loss: 0.3636856 Test Loss: 0.4265809
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.1160680107021042e-06
train 11465
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=165, out_features=187, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3404417280.0
params:  31042.0
Trainable parameters:  31042
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 106.66368651390076
Epoch: 1, Steps: 89 | Train Loss: 0.2424055 Vali Loss: 0.3344580 Test Loss: 0.4019271
Validation loss decreased (inf --> 0.334458).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 105.6575288772583
Epoch: 2, Steps: 89 | Train Loss: 0.2390064 Vali Loss: 0.3343850 Test Loss: 0.4015988
Validation loss decreased (0.334458 --> 0.334385).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 106.1679060459137
Epoch: 3, Steps: 89 | Train Loss: 0.2387845 Vali Loss: 0.3342681 Test Loss: 0.4007444
Validation loss decreased (0.334385 --> 0.334268).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 104.14313530921936
Epoch: 4, Steps: 89 | Train Loss: 0.2383824 Vali Loss: 0.3346128 Test Loss: 0.4013598
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 108.33156752586365
Epoch: 5, Steps: 89 | Train Loss: 0.2383687 Vali Loss: 0.3344435 Test Loss: 0.4005933
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 104.81549763679504
Epoch: 6, Steps: 89 | Train Loss: 0.2382903 Vali Loss: 0.3345152 Test Loss: 0.4005832
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 105.68793296813965
Epoch: 7, Steps: 89 | Train Loss: 0.2382714 Vali Loss: 0.3319783 Test Loss: 0.4007952
Validation loss decreased (0.334268 --> 0.331978).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 105.43614101409912
Epoch: 8, Steps: 89 | Train Loss: 0.2381695 Vali Loss: 0.3337189 Test Loss: 0.4008215
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 101.6157124042511
Epoch: 9, Steps: 89 | Train Loss: 0.2380492 Vali Loss: 0.3332971 Test Loss: 0.4002614
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 107.76126384735107
Epoch: 10, Steps: 89 | Train Loss: 0.2380961 Vali Loss: 0.3339391 Test Loss: 0.4001764
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 105.80102229118347
Epoch: 11, Steps: 89 | Train Loss: 0.2379576 Vali Loss: 0.3340826 Test Loss: 0.4000699
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 104.31040096282959
Epoch: 12, Steps: 89 | Train Loss: 0.2379048 Vali Loss: 0.3344301 Test Loss: 0.4000535
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 106.02429270744324
Epoch: 13, Steps: 89 | Train Loss: 0.2378966 Vali Loss: 0.3333504 Test Loss: 0.4003870
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 105.9830539226532
Epoch: 14, Steps: 89 | Train Loss: 0.2379772 Vali Loss: 0.3327200 Test Loss: 0.3999101
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 106.82870864868164
Epoch: 15, Steps: 89 | Train Loss: 0.2378970 Vali Loss: 0.3330298 Test Loss: 0.4008632
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 104.13770365715027
Epoch: 16, Steps: 89 | Train Loss: 0.2379178 Vali Loss: 0.3319240 Test Loss: 0.3998845
Validation loss decreased (0.331978 --> 0.331924).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 104.22651839256287
Epoch: 17, Steps: 89 | Train Loss: 0.2378520 Vali Loss: 0.3328204 Test Loss: 0.3997460
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 105.99282956123352
Epoch: 18, Steps: 89 | Train Loss: 0.2377285 Vali Loss: 0.3336235 Test Loss: 0.4002168
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 107.08651518821716
Epoch: 19, Steps: 89 | Train Loss: 0.2378622 Vali Loss: 0.3330967 Test Loss: 0.3999064
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 109.4137134552002
Epoch: 20, Steps: 89 | Train Loss: 0.2377816 Vali Loss: 0.3333336 Test Loss: 0.3995533
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 109.4741039276123
Epoch: 21, Steps: 89 | Train Loss: 0.2377751 Vali Loss: 0.3322057 Test Loss: 0.3998376
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 103.91753697395325
Epoch: 22, Steps: 89 | Train Loss: 0.2376463 Vali Loss: 0.3323443 Test Loss: 0.3998209
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 116.81695818901062
Epoch: 23, Steps: 89 | Train Loss: 0.2376778 Vali Loss: 0.3336476 Test Loss: 0.3998133
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 111.37238812446594
Epoch: 24, Steps: 89 | Train Loss: 0.2377421 Vali Loss: 0.3320243 Test Loss: 0.3997499
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 106.22410607337952
Epoch: 25, Steps: 89 | Train Loss: 0.2377332 Vali Loss: 0.3325908 Test Loss: 0.4000329
EarlyStopping counter: 9 out of 10
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 106.59187197685242
Epoch: 26, Steps: 89 | Train Loss: 0.2375252 Vali Loss: 0.3329520 Test Loss: 0.3995832
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : Traffic_720_j96_H5_FITS_custom_ftM_sl720_ll48_pl96_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3413
mse:0.39721041917800903, mae:0.28434309363365173, rse:0.5218717455863953, corr:[0.28989884 0.2976843  0.29776174 0.29746    0.2971516  0.2968828
 0.29690567 0.2971299  0.29722828 0.29703936 0.2967002  0.29640242
 0.29622748 0.29616654 0.29627103 0.29647657 0.29659358 0.29649016
 0.29617152 0.29580757 0.2955258  0.29531145 0.2952376  0.29585084
 0.29702115 0.29720265 0.29696456 0.2966967  0.29631144 0.2959356
 0.29582044 0.295998   0.29627314 0.2964413  0.2964704  0.29644948
 0.2964254  0.2962491  0.29593092 0.29569468 0.2957274  0.29591116
 0.29598877 0.29590902 0.295795   0.29572636 0.29568958 0.29580516
 0.29598603 0.2959176  0.29584286 0.29579318 0.29570046 0.29563534
 0.29575607 0.29611027 0.2965408  0.29675537 0.29656595 0.296118
 0.29584637 0.2959218  0.29616728 0.29624447 0.2960554  0.29579356
 0.29563788 0.29559845 0.29559037 0.29558054 0.29556793 0.29561436
 0.2955479  0.2953951  0.29523975 0.29509196 0.29505387 0.29518145
 0.29544538 0.29578325 0.29606542 0.2961052  0.29580513 0.29527897
 0.29482096 0.29461253 0.29465884 0.2947737  0.29473582 0.29452717
 0.2943867  0.29454222 0.29483107 0.29482248 0.2945382  0.29485354]
