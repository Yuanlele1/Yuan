Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=258, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_720_j96_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=10, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_720_j96_H8_FITS_custom_ftM_sl720_ll48_pl96_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11465
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=258, out_features=292, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  8312272896.0
params:  75628.0
Trainable parameters:  75628
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 175.92693853378296
Epoch: 1, Steps: 89 | Train Loss: 0.6078478 Vali Loss: 0.4278344 Test Loss: 0.4986485
Validation loss decreased (inf --> 0.427834).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 224.86604380607605
Epoch: 2, Steps: 89 | Train Loss: 0.2656335 Vali Loss: 0.3381407 Test Loss: 0.4016422
Validation loss decreased (0.427834 --> 0.338141).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 226.2288773059845
Epoch: 3, Steps: 89 | Train Loss: 0.2364266 Vali Loss: 0.3293340 Test Loss: 0.3953774
Validation loss decreased (0.338141 --> 0.329334).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 214.4227488040924
Epoch: 4, Steps: 89 | Train Loss: 0.2338566 Vali Loss: 0.3274520 Test Loss: 0.3938832
Validation loss decreased (0.329334 --> 0.327452).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 224.88333010673523
Epoch: 5, Steps: 89 | Train Loss: 0.2332124 Vali Loss: 0.3273353 Test Loss: 0.3930867
Validation loss decreased (0.327452 --> 0.327335).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 223.224867105484
Epoch: 6, Steps: 89 | Train Loss: 0.2329226 Vali Loss: 0.3277216 Test Loss: 0.3923448
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 223.06536078453064
Epoch: 7, Steps: 89 | Train Loss: 0.2325290 Vali Loss: 0.3279913 Test Loss: 0.3919287
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 220.32858419418335
Epoch: 8, Steps: 89 | Train Loss: 0.2324390 Vali Loss: 0.3272159 Test Loss: 0.3919509
Validation loss decreased (0.327335 --> 0.327216).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 227.6698625087738
Epoch: 9, Steps: 89 | Train Loss: 0.2324834 Vali Loss: 0.3258899 Test Loss: 0.3917686
Validation loss decreased (0.327216 --> 0.325890).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 233.32780742645264
Epoch: 10, Steps: 89 | Train Loss: 0.2321771 Vali Loss: 0.3267263 Test Loss: 0.3917210
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 211.56271314620972
Epoch: 11, Steps: 89 | Train Loss: 0.2320695 Vali Loss: 0.3253997 Test Loss: 0.3916028
Validation loss decreased (0.325890 --> 0.325400).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 237.9185197353363
Epoch: 12, Steps: 89 | Train Loss: 0.2320595 Vali Loss: 0.3265672 Test Loss: 0.3910219
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 223.84191823005676
Epoch: 13, Steps: 89 | Train Loss: 0.2320817 Vali Loss: 0.3256455 Test Loss: 0.3908647
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 218.1935169696808
Epoch: 14, Steps: 89 | Train Loss: 0.2318102 Vali Loss: 0.3259905 Test Loss: 0.3911842
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 206.60057830810547
Epoch: 15, Steps: 89 | Train Loss: 0.2318604 Vali Loss: 0.3255576 Test Loss: 0.3909091
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 201.14751720428467
Epoch: 16, Steps: 89 | Train Loss: 0.2318497 Vali Loss: 0.3257287 Test Loss: 0.3910659
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 213.0249845981598
Epoch: 17, Steps: 89 | Train Loss: 0.2318288 Vali Loss: 0.3257359 Test Loss: 0.3910477
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 202.56152391433716
Epoch: 18, Steps: 89 | Train Loss: 0.2317592 Vali Loss: 0.3259639 Test Loss: 0.3906950
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 209.57162308692932
Epoch: 19, Steps: 89 | Train Loss: 0.2318133 Vali Loss: 0.3268880 Test Loss: 0.3910237
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 195.06786108016968
Epoch: 20, Steps: 89 | Train Loss: 0.2317138 Vali Loss: 0.3265405 Test Loss: 0.3907787
EarlyStopping counter: 9 out of 10
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 215.59323716163635
Epoch: 21, Steps: 89 | Train Loss: 0.2316878 Vali Loss: 0.3249803 Test Loss: 0.3908031
Validation loss decreased (0.325400 --> 0.324980).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 220.73047137260437
Epoch: 22, Steps: 89 | Train Loss: 0.2316062 Vali Loss: 0.3270317 Test Loss: 0.3909567
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 194.8895628452301
Epoch: 23, Steps: 89 | Train Loss: 0.2314715 Vali Loss: 0.3242778 Test Loss: 0.3907424
Validation loss decreased (0.324980 --> 0.324278).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 185.13099694252014
Epoch: 24, Steps: 89 | Train Loss: 0.2316444 Vali Loss: 0.3259988 Test Loss: 0.3906591
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 187.39550018310547
Epoch: 25, Steps: 89 | Train Loss: 0.2315292 Vali Loss: 0.3256216 Test Loss: 0.3905388
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 172.21235752105713
Epoch: 26, Steps: 89 | Train Loss: 0.2313971 Vali Loss: 0.3257483 Test Loss: 0.3903465
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 173.45519709587097
Epoch: 27, Steps: 89 | Train Loss: 0.2314488 Vali Loss: 0.3252146 Test Loss: 0.3904670
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 159.55121040344238
Epoch: 28, Steps: 89 | Train Loss: 0.2315258 Vali Loss: 0.3246370 Test Loss: 0.3903308
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 184.9271523952484
Epoch: 29, Steps: 89 | Train Loss: 0.2313606 Vali Loss: 0.3260503 Test Loss: 0.3904354
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 170.5172176361084
Epoch: 30, Steps: 89 | Train Loss: 0.2315152 Vali Loss: 0.3251873 Test Loss: 0.3903303
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 176.77632808685303
Epoch: 31, Steps: 89 | Train Loss: 0.2314760 Vali Loss: 0.3248911 Test Loss: 0.3902898
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 159.60643792152405
Epoch: 32, Steps: 89 | Train Loss: 0.2313293 Vali Loss: 0.3251601 Test Loss: 0.3903736
EarlyStopping counter: 9 out of 10
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 166.06683588027954
Epoch: 33, Steps: 89 | Train Loss: 0.2314617 Vali Loss: 0.3255579 Test Loss: 0.3906167
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : Traffic_720_j96_H8_FITS_custom_ftM_sl720_ll48_pl96_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3413
mse:0.3877905011177063, mae:0.27133336663246155, rse:0.5156464576721191, corr:[0.28088427 0.2908465  0.29288033 0.29160252 0.2929689  0.2937956
 0.2930257  0.29365584 0.29363194 0.29290703 0.29340273 0.29335898
 0.29273456 0.2929967  0.29300642 0.29257303 0.2927522  0.29281697
 0.29258803 0.29295698 0.29296443 0.29221007 0.29202843 0.29248804
 0.29357302 0.2939623  0.29407644 0.29375392 0.29388067 0.29414603
 0.29367778 0.29344425 0.29346848 0.29286376 0.2926365  0.29312664
 0.29308087 0.2928309  0.29300717 0.29291916 0.29272985 0.2928784
 0.29295558 0.29308102 0.29330957 0.29312792 0.2927923  0.29280293
 0.2929912  0.29298306 0.29315636 0.29285696 0.29250965 0.29265067
 0.2923351  0.291726   0.29199472 0.29234937 0.29216734 0.29247063
 0.29266277 0.29196444 0.29190648 0.2924784  0.29244646 0.29263464
 0.2931073  0.29273456 0.29248467 0.29290903 0.29278457 0.2926302
 0.2927564  0.29238278 0.2922328  0.2924879  0.29191777 0.29135916
 0.2916161  0.29122418 0.29058173 0.2909293  0.29109517 0.29112628
 0.29195562 0.29198226 0.29152888 0.29244423 0.29263815 0.29168332
 0.29199907 0.2912909  0.2899241  0.2911432  0.28965858 0.29276466]
