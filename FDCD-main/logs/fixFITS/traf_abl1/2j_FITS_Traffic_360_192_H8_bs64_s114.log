Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=138, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_360_j192_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=10, pred_len=192, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_360_j192_H8_FITS_custom_ftM_sl360_ll48_pl192_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11729
val 1565
test 3317
Model(
  (freq_upsampler): Linear(in_features=138, out_features=211, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3212763648.0
params:  29329.0
Trainable parameters:  29329
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 143.06645441055298
Epoch: 1, Steps: 91 | Train Loss: 1.1325283 Vali Loss: 1.1861151 Test Loss: 1.3883712
Validation loss decreased (inf --> 1.186115).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 128.0393443107605
Epoch: 2, Steps: 91 | Train Loss: 0.8285221 Vali Loss: 1.0210267 Test Loss: 1.1947681
Validation loss decreased (1.186115 --> 1.021027).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 130.60650753974915
Epoch: 3, Steps: 91 | Train Loss: 0.7128649 Vali Loss: 0.9422712 Test Loss: 1.1039727
Validation loss decreased (1.021027 --> 0.942271).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 88.65010404586792
Epoch: 4, Steps: 91 | Train Loss: 0.6412071 Vali Loss: 0.8872945 Test Loss: 1.0403819
Validation loss decreased (0.942271 --> 0.887294).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 94.15118336677551
Epoch: 5, Steps: 91 | Train Loss: 0.5845315 Vali Loss: 0.8381528 Test Loss: 0.9841189
Validation loss decreased (0.887294 --> 0.838153).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 106.17575335502625
Epoch: 6, Steps: 91 | Train Loss: 0.5367217 Vali Loss: 0.7954745 Test Loss: 0.9350072
Validation loss decreased (0.838153 --> 0.795474).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 138.3144989013672
Epoch: 7, Steps: 91 | Train Loss: 0.4957089 Vali Loss: 0.7590837 Test Loss: 0.8926278
Validation loss decreased (0.795474 --> 0.759084).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 97.12916159629822
Epoch: 8, Steps: 91 | Train Loss: 0.4599341 Vali Loss: 0.7232106 Test Loss: 0.8518057
Validation loss decreased (0.759084 --> 0.723211).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 87.09484004974365
Epoch: 9, Steps: 91 | Train Loss: 0.4287268 Vali Loss: 0.6930731 Test Loss: 0.8163357
Validation loss decreased (0.723211 --> 0.693073).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 87.80718994140625
Epoch: 10, Steps: 91 | Train Loss: 0.4011473 Vali Loss: 0.6669714 Test Loss: 0.7867431
Validation loss decreased (0.693073 --> 0.666971).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 87.02541708946228
Epoch: 11, Steps: 91 | Train Loss: 0.3768052 Vali Loss: 0.6416456 Test Loss: 0.7578126
Validation loss decreased (0.666971 --> 0.641646).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 81.42663288116455
Epoch: 12, Steps: 91 | Train Loss: 0.3550908 Vali Loss: 0.6208271 Test Loss: 0.7338247
Validation loss decreased (0.641646 --> 0.620827).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 82.30162763595581
Epoch: 13, Steps: 91 | Train Loss: 0.3357674 Vali Loss: 0.5986189 Test Loss: 0.7078561
Validation loss decreased (0.620827 --> 0.598619).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 79.42526531219482
Epoch: 14, Steps: 91 | Train Loss: 0.3183915 Vali Loss: 0.5824569 Test Loss: 0.6893607
Validation loss decreased (0.598619 --> 0.582457).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 82.39509224891663
Epoch: 15, Steps: 91 | Train Loss: 0.3028541 Vali Loss: 0.5655236 Test Loss: 0.6704716
Validation loss decreased (0.582457 --> 0.565524).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 141.6685996055603
Epoch: 16, Steps: 91 | Train Loss: 0.2887764 Vali Loss: 0.5500924 Test Loss: 0.6526255
Validation loss decreased (0.565524 --> 0.550092).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 138.21106457710266
Epoch: 17, Steps: 91 | Train Loss: 0.2760856 Vali Loss: 0.5376118 Test Loss: 0.6379274
Validation loss decreased (0.550092 --> 0.537612).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 127.85731196403503
Epoch: 18, Steps: 91 | Train Loss: 0.2645145 Vali Loss: 0.5255550 Test Loss: 0.6242256
Validation loss decreased (0.537612 --> 0.525555).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 136.40389204025269
Epoch: 19, Steps: 91 | Train Loss: 0.2541082 Vali Loss: 0.5137975 Test Loss: 0.6112357
Validation loss decreased (0.525555 --> 0.513797).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 108.91386365890503
Epoch: 20, Steps: 91 | Train Loss: 0.2445706 Vali Loss: 0.5048138 Test Loss: 0.6009525
Validation loss decreased (0.513797 --> 0.504814).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 155.1496798992157
Epoch: 21, Steps: 91 | Train Loss: 0.2358639 Vali Loss: 0.4939823 Test Loss: 0.5889966
Validation loss decreased (0.504814 --> 0.493982).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 162.37140274047852
Epoch: 22, Steps: 91 | Train Loss: 0.2279454 Vali Loss: 0.4861512 Test Loss: 0.5799315
Validation loss decreased (0.493982 --> 0.486151).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 154.14495015144348
Epoch: 23, Steps: 91 | Train Loss: 0.2206907 Vali Loss: 0.4791411 Test Loss: 0.5708836
Validation loss decreased (0.486151 --> 0.479141).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 162.70473647117615
Epoch: 24, Steps: 91 | Train Loss: 0.2139590 Vali Loss: 0.4709264 Test Loss: 0.5624033
Validation loss decreased (0.479141 --> 0.470926).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 189.08729028701782
Epoch: 25, Steps: 91 | Train Loss: 0.2078595 Vali Loss: 0.4645462 Test Loss: 0.5552759
Validation loss decreased (0.470926 --> 0.464546).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 175.59088802337646
Epoch: 26, Steps: 91 | Train Loss: 0.2022022 Vali Loss: 0.4586651 Test Loss: 0.5483702
Validation loss decreased (0.464546 --> 0.458665).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 157.72920083999634
Epoch: 27, Steps: 91 | Train Loss: 0.1969752 Vali Loss: 0.4523970 Test Loss: 0.5410777
Validation loss decreased (0.458665 --> 0.452397).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 201.014395236969
Epoch: 28, Steps: 91 | Train Loss: 0.1921779 Vali Loss: 0.4478519 Test Loss: 0.5358187
Validation loss decreased (0.452397 --> 0.447852).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 215.4127140045166
Epoch: 29, Steps: 91 | Train Loss: 0.1877136 Vali Loss: 0.4433461 Test Loss: 0.5306870
Validation loss decreased (0.447852 --> 0.443346).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 198.10890746116638
Epoch: 30, Steps: 91 | Train Loss: 0.1835857 Vali Loss: 0.4378060 Test Loss: 0.5249327
Validation loss decreased (0.443346 --> 0.437806).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 206.50021314620972
Epoch: 31, Steps: 91 | Train Loss: 0.1797501 Vali Loss: 0.4337889 Test Loss: 0.5204602
Validation loss decreased (0.437806 --> 0.433789).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 195.35510969161987
Epoch: 32, Steps: 91 | Train Loss: 0.1761943 Vali Loss: 0.4301047 Test Loss: 0.5161299
Validation loss decreased (0.433789 --> 0.430105).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 128.22042107582092
Epoch: 33, Steps: 91 | Train Loss: 0.1729052 Vali Loss: 0.4262975 Test Loss: 0.5121065
Validation loss decreased (0.430105 --> 0.426298).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 131.07100200653076
Epoch: 34, Steps: 91 | Train Loss: 0.1698079 Vali Loss: 0.4231853 Test Loss: 0.5084240
Validation loss decreased (0.426298 --> 0.423185).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 122.24064421653748
Epoch: 35, Steps: 91 | Train Loss: 0.1669111 Vali Loss: 0.4197915 Test Loss: 0.5050655
Validation loss decreased (0.423185 --> 0.419791).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 125.68713045120239
Epoch: 36, Steps: 91 | Train Loss: 0.1642665 Vali Loss: 0.4174917 Test Loss: 0.5016278
Validation loss decreased (0.419791 --> 0.417492).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 158.35787177085876
Epoch: 37, Steps: 91 | Train Loss: 0.1617657 Vali Loss: 0.4141825 Test Loss: 0.4984455
Validation loss decreased (0.417492 --> 0.414183).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 148.28971600532532
Epoch: 38, Steps: 91 | Train Loss: 0.1594728 Vali Loss: 0.4115773 Test Loss: 0.4956086
Validation loss decreased (0.414183 --> 0.411577).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 133.003888130188
Epoch: 39, Steps: 91 | Train Loss: 0.1572638 Vali Loss: 0.4096391 Test Loss: 0.4931491
Validation loss decreased (0.411577 --> 0.409639).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 124.4561460018158
Epoch: 40, Steps: 91 | Train Loss: 0.1552346 Vali Loss: 0.4069281 Test Loss: 0.4906244
Validation loss decreased (0.409639 --> 0.406928).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 125.74177742004395
Epoch: 41, Steps: 91 | Train Loss: 0.1533031 Vali Loss: 0.4050185 Test Loss: 0.4883633
Validation loss decreased (0.406928 --> 0.405018).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 128.0116856098175
Epoch: 42, Steps: 91 | Train Loss: 0.1514947 Vali Loss: 0.4033780 Test Loss: 0.4862867
Validation loss decreased (0.405018 --> 0.403378).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 146.7808895111084
Epoch: 43, Steps: 91 | Train Loss: 0.1498344 Vali Loss: 0.4012341 Test Loss: 0.4840198
Validation loss decreased (0.403378 --> 0.401234).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 151.00662899017334
Epoch: 44, Steps: 91 | Train Loss: 0.1482391 Vali Loss: 0.3992435 Test Loss: 0.4822859
Validation loss decreased (0.401234 --> 0.399244).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 144.86649131774902
Epoch: 45, Steps: 91 | Train Loss: 0.1467333 Vali Loss: 0.3979223 Test Loss: 0.4803407
Validation loss decreased (0.399244 --> 0.397922).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 164.48115181922913
Epoch: 46, Steps: 91 | Train Loss: 0.1453470 Vali Loss: 0.3960063 Test Loss: 0.4786673
Validation loss decreased (0.397922 --> 0.396006).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 161.81963443756104
Epoch: 47, Steps: 91 | Train Loss: 0.1440332 Vali Loss: 0.3947612 Test Loss: 0.4771190
Validation loss decreased (0.396006 --> 0.394761).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 120.71434307098389
Epoch: 48, Steps: 91 | Train Loss: 0.1427951 Vali Loss: 0.3934467 Test Loss: 0.4755428
Validation loss decreased (0.394761 --> 0.393447).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 133.81925439834595
Epoch: 49, Steps: 91 | Train Loss: 0.1416406 Vali Loss: 0.3921509 Test Loss: 0.4741023
Validation loss decreased (0.393447 --> 0.392151).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 152.85299396514893
Epoch: 50, Steps: 91 | Train Loss: 0.1405043 Vali Loss: 0.3914380 Test Loss: 0.4729691
Validation loss decreased (0.392151 --> 0.391438).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 148.57531237602234
Epoch: 51, Steps: 91 | Train Loss: 0.1394452 Vali Loss: 0.3905456 Test Loss: 0.4715947
Validation loss decreased (0.391438 --> 0.390546).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 145.13037824630737
Epoch: 52, Steps: 91 | Train Loss: 0.1385112 Vali Loss: 0.3889387 Test Loss: 0.4705627
Validation loss decreased (0.390546 --> 0.388939).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 95.42909789085388
Epoch: 53, Steps: 91 | Train Loss: 0.1375609 Vali Loss: 0.3876896 Test Loss: 0.4693617
Validation loss decreased (0.388939 --> 0.387690).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 113.01265835762024
Epoch: 54, Steps: 91 | Train Loss: 0.1366721 Vali Loss: 0.3868171 Test Loss: 0.4683892
Validation loss decreased (0.387690 --> 0.386817).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 97.71092796325684
Epoch: 55, Steps: 91 | Train Loss: 0.1358523 Vali Loss: 0.3854670 Test Loss: 0.4673609
Validation loss decreased (0.386817 --> 0.385467).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 108.55990076065063
Epoch: 56, Steps: 91 | Train Loss: 0.1350828 Vali Loss: 0.3846699 Test Loss: 0.4664888
Validation loss decreased (0.385467 --> 0.384670).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 132.43396019935608
Epoch: 57, Steps: 91 | Train Loss: 0.1343379 Vali Loss: 0.3841375 Test Loss: 0.4656121
Validation loss decreased (0.384670 --> 0.384138).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 128.68939328193665
Epoch: 58, Steps: 91 | Train Loss: 0.1336404 Vali Loss: 0.3835418 Test Loss: 0.4647777
Validation loss decreased (0.384138 --> 0.383542).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 124.63973927497864
Epoch: 59, Steps: 91 | Train Loss: 0.1329645 Vali Loss: 0.3830974 Test Loss: 0.4640161
Validation loss decreased (0.383542 --> 0.383097).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 106.36361241340637
Epoch: 60, Steps: 91 | Train Loss: 0.1323577 Vali Loss: 0.3825126 Test Loss: 0.4632549
Validation loss decreased (0.383097 --> 0.382513).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 89.91545534133911
Epoch: 61, Steps: 91 | Train Loss: 0.1317763 Vali Loss: 0.3816029 Test Loss: 0.4625421
Validation loss decreased (0.382513 --> 0.381603).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 106.20844960212708
Epoch: 62, Steps: 91 | Train Loss: 0.1312181 Vali Loss: 0.3810840 Test Loss: 0.4619472
Validation loss decreased (0.381603 --> 0.381084).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 100.27148580551147
Epoch: 63, Steps: 91 | Train Loss: 0.1306706 Vali Loss: 0.3804184 Test Loss: 0.4612544
Validation loss decreased (0.381084 --> 0.380418).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 141.03711819648743
Epoch: 64, Steps: 91 | Train Loss: 0.1301798 Vali Loss: 0.3798892 Test Loss: 0.4606549
Validation loss decreased (0.380418 --> 0.379889).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 165.9267418384552
Epoch: 65, Steps: 91 | Train Loss: 0.1296899 Vali Loss: 0.3793319 Test Loss: 0.4600923
Validation loss decreased (0.379889 --> 0.379332).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 134.51758742332458
Epoch: 66, Steps: 91 | Train Loss: 0.1292433 Vali Loss: 0.3786859 Test Loss: 0.4595867
Validation loss decreased (0.379332 --> 0.378686).  Saving model ...
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 123.07510924339294
Epoch: 67, Steps: 91 | Train Loss: 0.1287780 Vali Loss: 0.3781815 Test Loss: 0.4590639
Validation loss decreased (0.378686 --> 0.378181).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 161.36678552627563
Epoch: 68, Steps: 91 | Train Loss: 0.1284069 Vali Loss: 0.3777345 Test Loss: 0.4585734
Validation loss decreased (0.378181 --> 0.377735).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 167.32808303833008
Epoch: 69, Steps: 91 | Train Loss: 0.1279879 Vali Loss: 0.3770136 Test Loss: 0.4581047
Validation loss decreased (0.377735 --> 0.377014).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 164.38834238052368
Epoch: 70, Steps: 91 | Train Loss: 0.1276787 Vali Loss: 0.3771892 Test Loss: 0.4577358
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 159.05243968963623
Epoch: 71, Steps: 91 | Train Loss: 0.1272732 Vali Loss: 0.3766658 Test Loss: 0.4572873
Validation loss decreased (0.377014 --> 0.376666).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 147.78871726989746
Epoch: 72, Steps: 91 | Train Loss: 0.1269321 Vali Loss: 0.3763374 Test Loss: 0.4569283
Validation loss decreased (0.376666 --> 0.376337).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 145.50216722488403
Epoch: 73, Steps: 91 | Train Loss: 0.1266137 Vali Loss: 0.3760941 Test Loss: 0.4565821
Validation loss decreased (0.376337 --> 0.376094).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 72.15049576759338
Epoch: 74, Steps: 91 | Train Loss: 0.1263361 Vali Loss: 0.3755727 Test Loss: 0.4562074
Validation loss decreased (0.376094 --> 0.375573).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 73.77643537521362
Epoch: 75, Steps: 91 | Train Loss: 0.1260428 Vali Loss: 0.3752595 Test Loss: 0.4558554
Validation loss decreased (0.375573 --> 0.375260).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 134.53947162628174
Epoch: 76, Steps: 91 | Train Loss: 0.1257674 Vali Loss: 0.3747469 Test Loss: 0.4555496
Validation loss decreased (0.375260 --> 0.374747).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 168.72742128372192
Epoch: 77, Steps: 91 | Train Loss: 0.1255408 Vali Loss: 0.3742280 Test Loss: 0.4552660
Validation loss decreased (0.374747 --> 0.374228).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 173.15192222595215
Epoch: 78, Steps: 91 | Train Loss: 0.1253300 Vali Loss: 0.3742899 Test Loss: 0.4549767
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 163.69701027870178
Epoch: 79, Steps: 91 | Train Loss: 0.1250615 Vali Loss: 0.3741469 Test Loss: 0.4546962
Validation loss decreased (0.374228 --> 0.374147).  Saving model ...
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 161.80174899101257
Epoch: 80, Steps: 91 | Train Loss: 0.1248426 Vali Loss: 0.3734931 Test Loss: 0.4544573
Validation loss decreased (0.374147 --> 0.373493).  Saving model ...
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 161.04112482070923
Epoch: 81, Steps: 91 | Train Loss: 0.1246476 Vali Loss: 0.3738765 Test Loss: 0.4542201
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 162.08703446388245
Epoch: 82, Steps: 91 | Train Loss: 0.1244674 Vali Loss: 0.3734151 Test Loss: 0.4539905
Validation loss decreased (0.373493 --> 0.373415).  Saving model ...
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 161.45698285102844
Epoch: 83, Steps: 91 | Train Loss: 0.1242531 Vali Loss: 0.3733647 Test Loss: 0.4537719
Validation loss decreased (0.373415 --> 0.373365).  Saving model ...
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 163.33894658088684
Epoch: 84, Steps: 91 | Train Loss: 0.1240734 Vali Loss: 0.3727461 Test Loss: 0.4535637
Validation loss decreased (0.373365 --> 0.372746).  Saving model ...
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 163.10338282585144
Epoch: 85, Steps: 91 | Train Loss: 0.1239011 Vali Loss: 0.3728993 Test Loss: 0.4533548
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 164.02303218841553
Epoch: 86, Steps: 91 | Train Loss: 0.1237184 Vali Loss: 0.3726824 Test Loss: 0.4531686
Validation loss decreased (0.372746 --> 0.372682).  Saving model ...
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 170.56698393821716
Epoch: 87, Steps: 91 | Train Loss: 0.1235824 Vali Loss: 0.3722359 Test Loss: 0.4530045
Validation loss decreased (0.372682 --> 0.372236).  Saving model ...
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 142.73721075057983
Epoch: 88, Steps: 91 | Train Loss: 0.1234391 Vali Loss: 0.3727403 Test Loss: 0.4528353
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 138.15798902511597
Epoch: 89, Steps: 91 | Train Loss: 0.1232901 Vali Loss: 0.3719521 Test Loss: 0.4526657
Validation loss decreased (0.372236 --> 0.371952).  Saving model ...
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 134.4363088607788
Epoch: 90, Steps: 91 | Train Loss: 0.1231928 Vali Loss: 0.3719606 Test Loss: 0.4525220
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 140.6381278038025
Epoch: 91, Steps: 91 | Train Loss: 0.1230440 Vali Loss: 0.3726314 Test Loss: 0.4523805
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 112.66648650169373
Epoch: 92, Steps: 91 | Train Loss: 0.1229386 Vali Loss: 0.3718494 Test Loss: 0.4522294
Validation loss decreased (0.371952 --> 0.371849).  Saving model ...
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 123.71689248085022
Epoch: 93, Steps: 91 | Train Loss: 0.1228003 Vali Loss: 0.3716756 Test Loss: 0.4521071
Validation loss decreased (0.371849 --> 0.371676).  Saving model ...
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 122.37763929367065
Epoch: 94, Steps: 91 | Train Loss: 0.1227495 Vali Loss: 0.3713508 Test Loss: 0.4519853
Validation loss decreased (0.371676 --> 0.371351).  Saving model ...
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 118.95937323570251
Epoch: 95, Steps: 91 | Train Loss: 0.1226036 Vali Loss: 0.3715276 Test Loss: 0.4518658
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 133.800635099411
Epoch: 96, Steps: 91 | Train Loss: 0.1225169 Vali Loss: 0.3713566 Test Loss: 0.4517635
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 131.16021990776062
Epoch: 97, Steps: 91 | Train Loss: 0.1224187 Vali Loss: 0.3711578 Test Loss: 0.4516485
Validation loss decreased (0.371351 --> 0.371158).  Saving model ...
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 132.94696497917175
Epoch: 98, Steps: 91 | Train Loss: 0.1223359 Vali Loss: 0.3713908 Test Loss: 0.4515545
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 126.66345858573914
Epoch: 99, Steps: 91 | Train Loss: 0.1222620 Vali Loss: 0.3710469 Test Loss: 0.4514596
Validation loss decreased (0.371158 --> 0.371047).  Saving model ...
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 127.38480997085571
Epoch: 100, Steps: 91 | Train Loss: 0.1221670 Vali Loss: 0.3710930 Test Loss: 0.4513726
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.1160680107021042e-06
train 11729
val 1565
test 3317
Model(
  (freq_upsampler): Linear(in_features=138, out_features=211, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3212763648.0
params:  29329.0
Trainable parameters:  29329
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 120.4339005947113
Epoch: 1, Steps: 91 | Train Loss: 0.2609897 Vali Loss: 0.3417454 Test Loss: 0.4240790
Validation loss decreased (inf --> 0.341745).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 111.79229378700256
Epoch: 2, Steps: 91 | Train Loss: 0.2536465 Vali Loss: 0.3411524 Test Loss: 0.4243825
Validation loss decreased (0.341745 --> 0.341152).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 104.93495893478394
Epoch: 3, Steps: 91 | Train Loss: 0.2534164 Vali Loss: 0.3405414 Test Loss: 0.4241495
Validation loss decreased (0.341152 --> 0.340541).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 103.49642586708069
Epoch: 4, Steps: 91 | Train Loss: 0.2532783 Vali Loss: 0.3401363 Test Loss: 0.4241696
Validation loss decreased (0.340541 --> 0.340136).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 100.22740364074707
Epoch: 5, Steps: 91 | Train Loss: 0.2532207 Vali Loss: 0.3408217 Test Loss: 0.4239412
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 97.32694172859192
Epoch: 6, Steps: 91 | Train Loss: 0.2530958 Vali Loss: 0.3403687 Test Loss: 0.4238238
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 96.23666501045227
Epoch: 7, Steps: 91 | Train Loss: 0.2531483 Vali Loss: 0.3403691 Test Loss: 0.4238785
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 100.67129111289978
Epoch: 8, Steps: 91 | Train Loss: 0.2531389 Vali Loss: 0.3406113 Test Loss: 0.4238724
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 105.5807683467865
Epoch: 9, Steps: 91 | Train Loss: 0.2529933 Vali Loss: 0.3403637 Test Loss: 0.4236026
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 97.76200580596924
Epoch: 10, Steps: 91 | Train Loss: 0.2529629 Vali Loss: 0.3403520 Test Loss: 0.4237801
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 102.2315001487732
Epoch: 11, Steps: 91 | Train Loss: 0.2529079 Vali Loss: 0.3404841 Test Loss: 0.4238518
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 98.32490587234497
Epoch: 12, Steps: 91 | Train Loss: 0.2529673 Vali Loss: 0.3402877 Test Loss: 0.4235967
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 97.53043556213379
Epoch: 13, Steps: 91 | Train Loss: 0.2529515 Vali Loss: 0.3403106 Test Loss: 0.4237206
EarlyStopping counter: 9 out of 10
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 99.16971397399902
Epoch: 14, Steps: 91 | Train Loss: 0.2529352 Vali Loss: 0.3399794 Test Loss: 0.4235161
Validation loss decreased (0.340136 --> 0.339979).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 95.50088214874268
Epoch: 15, Steps: 91 | Train Loss: 0.2529096 Vali Loss: 0.3401029 Test Loss: 0.4236282
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 102.42904114723206
Epoch: 16, Steps: 91 | Train Loss: 0.2529038 Vali Loss: 0.3397582 Test Loss: 0.4235896
Validation loss decreased (0.339979 --> 0.339758).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 101.95955300331116
Epoch: 17, Steps: 91 | Train Loss: 0.2529257 Vali Loss: 0.3401147 Test Loss: 0.4232898
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 95.32982993125916
Epoch: 18, Steps: 91 | Train Loss: 0.2528144 Vali Loss: 0.3400971 Test Loss: 0.4234110
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 109.1384506225586
Epoch: 19, Steps: 91 | Train Loss: 0.2527454 Vali Loss: 0.3402995 Test Loss: 0.4235756
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 103.84308671951294
Epoch: 20, Steps: 91 | Train Loss: 0.2528188 Vali Loss: 0.3397657 Test Loss: 0.4234182
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 101.40650725364685
Epoch: 21, Steps: 91 | Train Loss: 0.2528379 Vali Loss: 0.3403261 Test Loss: 0.4234357
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 116.39946627616882
Epoch: 22, Steps: 91 | Train Loss: 0.2528645 Vali Loss: 0.3400336 Test Loss: 0.4234866
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 112.10217332839966
Epoch: 23, Steps: 91 | Train Loss: 0.2528116 Vali Loss: 0.3405614 Test Loss: 0.4234121
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 109.87720537185669
Epoch: 24, Steps: 91 | Train Loss: 0.2527552 Vali Loss: 0.3396181 Test Loss: 0.4233640
Validation loss decreased (0.339758 --> 0.339618).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 112.77340579032898
Epoch: 25, Steps: 91 | Train Loss: 0.2528041 Vali Loss: 0.3403329 Test Loss: 0.4234385
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 99.15785121917725
Epoch: 26, Steps: 91 | Train Loss: 0.2527692 Vali Loss: 0.3399388 Test Loss: 0.4234250
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 105.15993618965149
Epoch: 27, Steps: 91 | Train Loss: 0.2527721 Vali Loss: 0.3399345 Test Loss: 0.4234150
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 103.55223417282104
Epoch: 28, Steps: 91 | Train Loss: 0.2527379 Vali Loss: 0.3402915 Test Loss: 0.4234121
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 101.06888937950134
Epoch: 29, Steps: 91 | Train Loss: 0.2527651 Vali Loss: 0.3402781 Test Loss: 0.4234321
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 91.40495991706848
Epoch: 30, Steps: 91 | Train Loss: 0.2528094 Vali Loss: 0.3400171 Test Loss: 0.4233708
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 84.35647106170654
Epoch: 31, Steps: 91 | Train Loss: 0.2526960 Vali Loss: 0.3396640 Test Loss: 0.4233682
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 89.89748811721802
Epoch: 32, Steps: 91 | Train Loss: 0.2527274 Vali Loss: 0.3399188 Test Loss: 0.4233373
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 84.37848663330078
Epoch: 33, Steps: 91 | Train Loss: 0.2527179 Vali Loss: 0.3400276 Test Loss: 0.4232771
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 85.7113823890686
Epoch: 34, Steps: 91 | Train Loss: 0.2527380 Vali Loss: 0.3400588 Test Loss: 0.4232813
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : Traffic_360_j192_H8_FITS_custom_ftM_sl360_ll48_pl192_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3317
mse:0.42233628034591675, mae:0.2844044864177704, rse:0.5363622903823853, corr:[0.27507868 0.2891629  0.28953257 0.2892798  0.28934523 0.2890914
 0.28917077 0.28935632 0.28912613 0.2888191  0.28864002 0.2886935
 0.28897    0.28883123 0.28849742 0.28840432 0.28845546 0.28864905
 0.28859627 0.2883644  0.2883861  0.2882539  0.28792176 0.28831196
 0.2894995  0.28973004 0.28966713 0.2894057  0.28924927 0.28912196
 0.28865498 0.28863537 0.28905475 0.28884616 0.2884144  0.28838012
 0.28834242 0.28830191 0.28851834 0.28865755 0.28876516 0.28896445
 0.28890738 0.2886792  0.28846496 0.2880967  0.2876905  0.28749153
 0.28769967 0.28807646 0.28854322 0.28851765 0.288533   0.28865725
 0.28838858 0.28818575 0.28833848 0.28834704 0.2881663  0.28804713
 0.28797004 0.2878896  0.28787094 0.28781998 0.28772688 0.28761828
 0.2874285  0.28744185 0.28758895 0.2874146  0.28706113 0.28694132
 0.28691384 0.2871419  0.28756675 0.28759697 0.28736135 0.28727934
 0.2872279  0.28701386 0.2869461  0.28706527 0.28691772 0.28658763
 0.2865073  0.286461   0.28638607 0.28658226 0.286844   0.28677222
 0.2865464  0.28655288 0.28663114 0.2865217  0.28646484 0.28663036
 0.28651032 0.28628847 0.28628638 0.28648186 0.28643826 0.28618497
 0.28611588 0.28600252 0.2857419  0.28575978 0.28581452 0.2856011
 0.28574443 0.286139   0.28603888 0.2858491  0.28603417 0.28622627
 0.28627416 0.28616905 0.2858874  0.2858425  0.28597924 0.2857904
 0.28551492 0.28573743 0.28595614 0.28597948 0.28596365 0.28591624
 0.2860898  0.28629854 0.28622684 0.2861676  0.28624085 0.28616792
 0.28605807 0.28604314 0.2860498  0.28620324 0.28636795 0.28623116
 0.2862234  0.28632522 0.28618562 0.28619277 0.2863596  0.28648403
 0.28675398 0.28721803 0.28746778 0.28749987 0.28753015 0.28753585
 0.28732586 0.28710896 0.28717652 0.28727287 0.28726095 0.28729534
 0.28727558 0.28719756 0.28728184 0.28752783 0.28785485 0.28813842
 0.28815854 0.2881179  0.288173   0.28800428 0.28778264 0.28838465
 0.28940573 0.28895313 0.28868565 0.2885475  0.288294   0.28829747
 0.28809926 0.28787786 0.28815562 0.2881564  0.2880783  0.288154
 0.28787398 0.2878772  0.28824604 0.28837058 0.2886181  0.2885518
 0.28806564 0.28801087 0.28774658 0.28739828 0.2870765  0.2877302 ]
