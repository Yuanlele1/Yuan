Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=138, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_360_j96_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=10, pred_len=96, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_360_j96_H8_FITS_custom_ftM_sl360_ll48_pl96_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11825
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=138, out_features=174, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2649388032.0
params:  24186.0
Trainable parameters:  24186
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 82.38308000564575
Epoch: 1, Steps: 92 | Train Loss: 1.0465680 Vali Loss: 1.0751612 Test Loss: 1.2455857
Validation loss decreased (inf --> 1.075161).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 87.63113760948181
Epoch: 2, Steps: 92 | Train Loss: 0.7766701 Vali Loss: 0.9553068 Test Loss: 1.1025541
Validation loss decreased (1.075161 --> 0.955307).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 102.08734202384949
Epoch: 3, Steps: 92 | Train Loss: 0.6666235 Vali Loss: 0.8917747 Test Loss: 1.0291811
Validation loss decreased (0.955307 --> 0.891775).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 117.0045394897461
Epoch: 4, Steps: 92 | Train Loss: 0.5949224 Vali Loss: 0.8403544 Test Loss: 0.9694889
Validation loss decreased (0.891775 --> 0.840354).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 111.54950404167175
Epoch: 5, Steps: 92 | Train Loss: 0.5373253 Vali Loss: 0.7966719 Test Loss: 0.9208656
Validation loss decreased (0.840354 --> 0.796672).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 118.09625697135925
Epoch: 6, Steps: 92 | Train Loss: 0.4884890 Vali Loss: 0.7585201 Test Loss: 0.8762528
Validation loss decreased (0.796672 --> 0.758520).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 120.3672080039978
Epoch: 7, Steps: 92 | Train Loss: 0.4464086 Vali Loss: 0.7191669 Test Loss: 0.8336617
Validation loss decreased (0.758520 --> 0.719167).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 119.8779501914978
Epoch: 8, Steps: 92 | Train Loss: 0.4098643 Vali Loss: 0.6913405 Test Loss: 0.7993277
Validation loss decreased (0.719167 --> 0.691341).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 112.89755177497864
Epoch: 9, Steps: 92 | Train Loss: 0.3779872 Vali Loss: 0.6628351 Test Loss: 0.7682827
Validation loss decreased (0.691341 --> 0.662835).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 78.91141676902771
Epoch: 10, Steps: 92 | Train Loss: 0.3499736 Vali Loss: 0.6364598 Test Loss: 0.7393540
Validation loss decreased (0.662835 --> 0.636460).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 84.20134687423706
Epoch: 11, Steps: 92 | Train Loss: 0.3252072 Vali Loss: 0.6132417 Test Loss: 0.7133353
Validation loss decreased (0.636460 --> 0.613242).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 132.13711071014404
Epoch: 12, Steps: 92 | Train Loss: 0.3033006 Vali Loss: 0.5942076 Test Loss: 0.6912179
Validation loss decreased (0.613242 --> 0.594208).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 134.73587822914124
Epoch: 13, Steps: 92 | Train Loss: 0.2838883 Vali Loss: 0.5760188 Test Loss: 0.6696000
Validation loss decreased (0.594208 --> 0.576019).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 127.81346678733826
Epoch: 14, Steps: 92 | Train Loss: 0.2665812 Vali Loss: 0.5592326 Test Loss: 0.6512768
Validation loss decreased (0.576019 --> 0.559233).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 97.7405858039856
Epoch: 15, Steps: 92 | Train Loss: 0.2510534 Vali Loss: 0.5435514 Test Loss: 0.6343361
Validation loss decreased (0.559233 --> 0.543551).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 134.17840051651
Epoch: 16, Steps: 92 | Train Loss: 0.2371571 Vali Loss: 0.5311185 Test Loss: 0.6191893
Validation loss decreased (0.543551 --> 0.531118).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 78.59238266944885
Epoch: 17, Steps: 92 | Train Loss: 0.2246379 Vali Loss: 0.5171819 Test Loss: 0.6053347
Validation loss decreased (0.531118 --> 0.517182).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 99.21330142021179
Epoch: 18, Steps: 92 | Train Loss: 0.2133587 Vali Loss: 0.5063795 Test Loss: 0.5916318
Validation loss decreased (0.517182 --> 0.506380).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 99.71145963668823
Epoch: 19, Steps: 92 | Train Loss: 0.2031757 Vali Loss: 0.4957768 Test Loss: 0.5796600
Validation loss decreased (0.506380 --> 0.495777).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 92.90948581695557
Epoch: 20, Steps: 92 | Train Loss: 0.1939250 Vali Loss: 0.4840693 Test Loss: 0.5684922
Validation loss decreased (0.495777 --> 0.484069).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 114.74864625930786
Epoch: 21, Steps: 92 | Train Loss: 0.1855496 Vali Loss: 0.4756795 Test Loss: 0.5590944
Validation loss decreased (0.484069 --> 0.475680).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 137.66764402389526
Epoch: 22, Steps: 92 | Train Loss: 0.1779405 Vali Loss: 0.4687004 Test Loss: 0.5500175
Validation loss decreased (0.475680 --> 0.468700).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 144.45643520355225
Epoch: 23, Steps: 92 | Train Loss: 0.1709623 Vali Loss: 0.4612513 Test Loss: 0.5414658
Validation loss decreased (0.468700 --> 0.461251).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 128.42378544807434
Epoch: 24, Steps: 92 | Train Loss: 0.1646406 Vali Loss: 0.4539890 Test Loss: 0.5343665
Validation loss decreased (0.461251 --> 0.453989).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 135.46673226356506
Epoch: 25, Steps: 92 | Train Loss: 0.1588569 Vali Loss: 0.4487287 Test Loss: 0.5277707
Validation loss decreased (0.453989 --> 0.448729).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 161.7433774471283
Epoch: 26, Steps: 92 | Train Loss: 0.1534878 Vali Loss: 0.4418207 Test Loss: 0.5211537
Validation loss decreased (0.448729 --> 0.441821).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 180.22453904151917
Epoch: 27, Steps: 92 | Train Loss: 0.1486362 Vali Loss: 0.4374661 Test Loss: 0.5152848
Validation loss decreased (0.441821 --> 0.437466).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 150.75966501235962
Epoch: 28, Steps: 92 | Train Loss: 0.1441310 Vali Loss: 0.4338457 Test Loss: 0.5102201
Validation loss decreased (0.437466 --> 0.433846).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 139.84987807273865
Epoch: 29, Steps: 92 | Train Loss: 0.1400042 Vali Loss: 0.4282511 Test Loss: 0.5053203
Validation loss decreased (0.433846 --> 0.428251).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 160.55286312103271
Epoch: 30, Steps: 92 | Train Loss: 0.1361845 Vali Loss: 0.4253152 Test Loss: 0.5009626
Validation loss decreased (0.428251 --> 0.425315).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 165.28418517112732
Epoch: 31, Steps: 92 | Train Loss: 0.1326650 Vali Loss: 0.4190640 Test Loss: 0.4957381
Validation loss decreased (0.425315 --> 0.419064).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 166.42991423606873
Epoch: 32, Steps: 92 | Train Loss: 0.1293939 Vali Loss: 0.4168156 Test Loss: 0.4923400
Validation loss decreased (0.419064 --> 0.416816).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 193.9921691417694
Epoch: 33, Steps: 92 | Train Loss: 0.1263576 Vali Loss: 0.4121865 Test Loss: 0.4887796
Validation loss decreased (0.416816 --> 0.412187).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 177.2180495262146
Epoch: 34, Steps: 92 | Train Loss: 0.1235901 Vali Loss: 0.4101981 Test Loss: 0.4856103
Validation loss decreased (0.412187 --> 0.410198).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 188.70541977882385
Epoch: 35, Steps: 92 | Train Loss: 0.1209909 Vali Loss: 0.4063270 Test Loss: 0.4820376
Validation loss decreased (0.410198 --> 0.406327).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 112.74103665351868
Epoch: 36, Steps: 92 | Train Loss: 0.1185741 Vali Loss: 0.4038998 Test Loss: 0.4792543
Validation loss decreased (0.406327 --> 0.403900).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 134.10248446464539
Epoch: 37, Steps: 92 | Train Loss: 0.1163168 Vali Loss: 0.4017863 Test Loss: 0.4765906
Validation loss decreased (0.403900 --> 0.401786).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 130.10538291931152
Epoch: 38, Steps: 92 | Train Loss: 0.1142294 Vali Loss: 0.3991976 Test Loss: 0.4739949
Validation loss decreased (0.401786 --> 0.399198).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 143.85808658599854
Epoch: 39, Steps: 92 | Train Loss: 0.1122757 Vali Loss: 0.3978417 Test Loss: 0.4715924
Validation loss decreased (0.399198 --> 0.397842).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 151.706716299057
Epoch: 40, Steps: 92 | Train Loss: 0.1104367 Vali Loss: 0.3954724 Test Loss: 0.4694320
Validation loss decreased (0.397842 --> 0.395472).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 133.98399353027344
Epoch: 41, Steps: 92 | Train Loss: 0.1087201 Vali Loss: 0.3937286 Test Loss: 0.4670479
Validation loss decreased (0.395472 --> 0.393729).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 131.33107018470764
Epoch: 42, Steps: 92 | Train Loss: 0.1071164 Vali Loss: 0.3908487 Test Loss: 0.4651951
Validation loss decreased (0.393729 --> 0.390849).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 137.51897168159485
Epoch: 43, Steps: 92 | Train Loss: 0.1056264 Vali Loss: 0.3888609 Test Loss: 0.4634098
Validation loss decreased (0.390849 --> 0.388861).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 146.7226595878601
Epoch: 44, Steps: 92 | Train Loss: 0.1042610 Vali Loss: 0.3882795 Test Loss: 0.4617572
Validation loss decreased (0.388861 --> 0.388280).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 130.82606530189514
Epoch: 45, Steps: 92 | Train Loss: 0.1029522 Vali Loss: 0.3877211 Test Loss: 0.4604080
Validation loss decreased (0.388280 --> 0.387721).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 142.95372915267944
Epoch: 46, Steps: 92 | Train Loss: 0.1017121 Vali Loss: 0.3850097 Test Loss: 0.4586293
Validation loss decreased (0.387721 --> 0.385010).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 136.51921272277832
Epoch: 47, Steps: 92 | Train Loss: 0.1005346 Vali Loss: 0.3832490 Test Loss: 0.4575107
Validation loss decreased (0.385010 --> 0.383249).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 135.6446933746338
Epoch: 48, Steps: 92 | Train Loss: 0.0994940 Vali Loss: 0.3828281 Test Loss: 0.4564123
Validation loss decreased (0.383249 --> 0.382828).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 157.76375317573547
Epoch: 49, Steps: 92 | Train Loss: 0.0984407 Vali Loss: 0.3824471 Test Loss: 0.4549293
Validation loss decreased (0.382828 --> 0.382447).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 131.8911488056183
Epoch: 50, Steps: 92 | Train Loss: 0.0974963 Vali Loss: 0.3800861 Test Loss: 0.4536995
Validation loss decreased (0.382447 --> 0.380086).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 130.13774394989014
Epoch: 51, Steps: 92 | Train Loss: 0.0965962 Vali Loss: 0.3789366 Test Loss: 0.4524820
Validation loss decreased (0.380086 --> 0.378937).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 118.23130202293396
Epoch: 52, Steps: 92 | Train Loss: 0.0957431 Vali Loss: 0.3793330 Test Loss: 0.4518401
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 137.70184755325317
Epoch: 53, Steps: 92 | Train Loss: 0.0949425 Vali Loss: 0.3773602 Test Loss: 0.4505942
Validation loss decreased (0.378937 --> 0.377360).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 110.91651344299316
Epoch: 54, Steps: 92 | Train Loss: 0.0941864 Vali Loss: 0.3768610 Test Loss: 0.4498142
Validation loss decreased (0.377360 --> 0.376861).  Saving model ...
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 101.41685891151428
Epoch: 55, Steps: 92 | Train Loss: 0.0934770 Vali Loss: 0.3757398 Test Loss: 0.4491228
Validation loss decreased (0.376861 --> 0.375740).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 105.43204760551453
Epoch: 56, Steps: 92 | Train Loss: 0.0927949 Vali Loss: 0.3752512 Test Loss: 0.4480779
Validation loss decreased (0.375740 --> 0.375251).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 82.41961622238159
Epoch: 57, Steps: 92 | Train Loss: 0.0921470 Vali Loss: 0.3759978 Test Loss: 0.4474002
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 91.97945809364319
Epoch: 58, Steps: 92 | Train Loss: 0.0915523 Vali Loss: 0.3736271 Test Loss: 0.4467669
Validation loss decreased (0.375251 --> 0.373627).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 128.8962206840515
Epoch: 59, Steps: 92 | Train Loss: 0.0909933 Vali Loss: 0.3735569 Test Loss: 0.4461549
Validation loss decreased (0.373627 --> 0.373557).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 94.69467329978943
Epoch: 60, Steps: 92 | Train Loss: 0.0904526 Vali Loss: 0.3729477 Test Loss: 0.4454036
Validation loss decreased (0.373557 --> 0.372948).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 115.58992648124695
Epoch: 61, Steps: 92 | Train Loss: 0.0899326 Vali Loss: 0.3722874 Test Loss: 0.4448658
Validation loss decreased (0.372948 --> 0.372287).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 112.11208009719849
Epoch: 62, Steps: 92 | Train Loss: 0.0894509 Vali Loss: 0.3707713 Test Loss: 0.4442681
Validation loss decreased (0.372287 --> 0.370771).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 95.08777570724487
Epoch: 63, Steps: 92 | Train Loss: 0.0890088 Vali Loss: 0.3716571 Test Loss: 0.4437406
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 99.0026490688324
Epoch: 64, Steps: 92 | Train Loss: 0.0885489 Vali Loss: 0.3706226 Test Loss: 0.4432110
Validation loss decreased (0.370771 --> 0.370623).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 110.4862790107727
Epoch: 65, Steps: 92 | Train Loss: 0.0881724 Vali Loss: 0.3697073 Test Loss: 0.4427639
Validation loss decreased (0.370623 --> 0.369707).  Saving model ...
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 128.78822684288025
Epoch: 66, Steps: 92 | Train Loss: 0.0877716 Vali Loss: 0.3701535 Test Loss: 0.4422981
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 131.8972885608673
Epoch: 67, Steps: 92 | Train Loss: 0.0874152 Vali Loss: 0.3684375 Test Loss: 0.4418518
Validation loss decreased (0.369707 --> 0.368437).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 131.6459035873413
Epoch: 68, Steps: 92 | Train Loss: 0.0870647 Vali Loss: 0.3693113 Test Loss: 0.4414686
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 104.82377767562866
Epoch: 69, Steps: 92 | Train Loss: 0.0867238 Vali Loss: 0.3683596 Test Loss: 0.4410497
Validation loss decreased (0.368437 --> 0.368360).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 108.65913820266724
Epoch: 70, Steps: 92 | Train Loss: 0.0864246 Vali Loss: 0.3682737 Test Loss: 0.4407492
Validation loss decreased (0.368360 --> 0.368274).  Saving model ...
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 71.44769597053528
Epoch: 71, Steps: 92 | Train Loss: 0.0861202 Vali Loss: 0.3677692 Test Loss: 0.4403843
Validation loss decreased (0.368274 --> 0.367769).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 121.72005820274353
Epoch: 72, Steps: 92 | Train Loss: 0.0858437 Vali Loss: 0.3668742 Test Loss: 0.4400532
Validation loss decreased (0.367769 --> 0.366874).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 134.27245163917542
Epoch: 73, Steps: 92 | Train Loss: 0.0855621 Vali Loss: 0.3684151 Test Loss: 0.4397132
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 104.18360424041748
Epoch: 74, Steps: 92 | Train Loss: 0.0853284 Vali Loss: 0.3672148 Test Loss: 0.4394175
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 106.10567617416382
Epoch: 75, Steps: 92 | Train Loss: 0.0850839 Vali Loss: 0.3665107 Test Loss: 0.4391269
Validation loss decreased (0.366874 --> 0.366511).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 69.15553617477417
Epoch: 76, Steps: 92 | Train Loss: 0.0848439 Vali Loss: 0.3672968 Test Loss: 0.4389135
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 96.204430103302
Epoch: 77, Steps: 92 | Train Loss: 0.0846544 Vali Loss: 0.3675481 Test Loss: 0.4386442
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 148.16713976860046
Epoch: 78, Steps: 92 | Train Loss: 0.0844334 Vali Loss: 0.3671318 Test Loss: 0.4384081
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 146.3401427268982
Epoch: 79, Steps: 92 | Train Loss: 0.0842383 Vali Loss: 0.3650634 Test Loss: 0.4381838
Validation loss decreased (0.366511 --> 0.365063).  Saving model ...
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 137.28239130973816
Epoch: 80, Steps: 92 | Train Loss: 0.0840622 Vali Loss: 0.3659894 Test Loss: 0.4379809
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 139.1210000514984
Epoch: 81, Steps: 92 | Train Loss: 0.0838789 Vali Loss: 0.3659285 Test Loss: 0.4377769
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 97.75829100608826
Epoch: 82, Steps: 92 | Train Loss: 0.0837165 Vali Loss: 0.3650662 Test Loss: 0.4376043
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 143.1785454750061
Epoch: 83, Steps: 92 | Train Loss: 0.0835580 Vali Loss: 0.3645159 Test Loss: 0.4373911
Validation loss decreased (0.365063 --> 0.364516).  Saving model ...
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 156.51825165748596
Epoch: 84, Steps: 92 | Train Loss: 0.0834040 Vali Loss: 0.3644018 Test Loss: 0.4372178
Validation loss decreased (0.364516 --> 0.364402).  Saving model ...
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 132.03955745697021
Epoch: 85, Steps: 92 | Train Loss: 0.0832700 Vali Loss: 0.3651265 Test Loss: 0.4370625
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 155.16625833511353
Epoch: 86, Steps: 92 | Train Loss: 0.0831259 Vali Loss: 0.3659393 Test Loss: 0.4369092
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 153.51844310760498
Epoch: 87, Steps: 92 | Train Loss: 0.0829999 Vali Loss: 0.3644609 Test Loss: 0.4367621
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 143.29483723640442
Epoch: 88, Steps: 92 | Train Loss: 0.0828800 Vali Loss: 0.3644723 Test Loss: 0.4366337
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 150.93172764778137
Epoch: 89, Steps: 92 | Train Loss: 0.0827574 Vali Loss: 0.3628745 Test Loss: 0.4364897
Validation loss decreased (0.364402 --> 0.362875).  Saving model ...
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 139.5828845500946
Epoch: 90, Steps: 92 | Train Loss: 0.0826602 Vali Loss: 0.3640882 Test Loss: 0.4363724
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 144.91125226020813
Epoch: 91, Steps: 92 | Train Loss: 0.0825460 Vali Loss: 0.3640065 Test Loss: 0.4362653
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 134.9511878490448
Epoch: 92, Steps: 92 | Train Loss: 0.0824218 Vali Loss: 0.3635415 Test Loss: 0.4361407
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 148.6673035621643
Epoch: 93, Steps: 92 | Train Loss: 0.0823391 Vali Loss: 0.3641478 Test Loss: 0.4360434
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 144.02315592765808
Epoch: 94, Steps: 92 | Train Loss: 0.0822439 Vali Loss: 0.3633828 Test Loss: 0.4359269
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 139.64659309387207
Epoch: 95, Steps: 92 | Train Loss: 0.0821664 Vali Loss: 0.3634382 Test Loss: 0.4358424
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 151.60718512535095
Epoch: 96, Steps: 92 | Train Loss: 0.0820998 Vali Loss: 0.3631507 Test Loss: 0.4357419
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 142.29718017578125
Epoch: 97, Steps: 92 | Train Loss: 0.0820204 Vali Loss: 0.3630682 Test Loss: 0.4356481
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 134.38108658790588
Epoch: 98, Steps: 92 | Train Loss: 0.0819317 Vali Loss: 0.3636465 Test Loss: 0.4355722
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 126.49491453170776
Epoch: 99, Steps: 92 | Train Loss: 0.0818712 Vali Loss: 0.3637131 Test Loss: 0.4354911
EarlyStopping counter: 10 out of 10
Early stopping
train 11825
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=138, out_features=174, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2649388032.0
params:  24186.0
Trainable parameters:  24186
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 123.81489372253418
Epoch: 1, Steps: 92 | Train Loss: 0.2530733 Vali Loss: 0.3393399 Test Loss: 0.4147198
Validation loss decreased (inf --> 0.339340).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 122.78709602355957
Epoch: 2, Steps: 92 | Train Loss: 0.2484786 Vali Loss: 0.3389855 Test Loss: 0.4138437
Validation loss decreased (0.339340 --> 0.338986).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 126.0908567905426
Epoch: 3, Steps: 92 | Train Loss: 0.2481353 Vali Loss: 0.3370189 Test Loss: 0.4135612
Validation loss decreased (0.338986 --> 0.337019).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 115.3411316871643
Epoch: 4, Steps: 92 | Train Loss: 0.2479492 Vali Loss: 0.3372630 Test Loss: 0.4129843
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 105.68354630470276
Epoch: 5, Steps: 92 | Train Loss: 0.2477594 Vali Loss: 0.3379480 Test Loss: 0.4133152
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 105.63358044624329
Epoch: 6, Steps: 92 | Train Loss: 0.2477278 Vali Loss: 0.3382430 Test Loss: 0.4129139
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 104.8994870185852
Epoch: 7, Steps: 92 | Train Loss: 0.2475451 Vali Loss: 0.3371092 Test Loss: 0.4129128
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 109.20395255088806
Epoch: 8, Steps: 92 | Train Loss: 0.2474545 Vali Loss: 0.3371434 Test Loss: 0.4127751
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 106.36880326271057
Epoch: 9, Steps: 92 | Train Loss: 0.2474321 Vali Loss: 0.3368482 Test Loss: 0.4127218
Validation loss decreased (0.337019 --> 0.336848).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 113.44136309623718
Epoch: 10, Steps: 92 | Train Loss: 0.2474528 Vali Loss: 0.3373993 Test Loss: 0.4128094
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 114.27152013778687
Epoch: 11, Steps: 92 | Train Loss: 0.2473423 Vali Loss: 0.3371505 Test Loss: 0.4127361
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 116.75172328948975
Epoch: 12, Steps: 92 | Train Loss: 0.2473485 Vali Loss: 0.3375931 Test Loss: 0.4123508
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 114.53275322914124
Epoch: 13, Steps: 92 | Train Loss: 0.2472947 Vali Loss: 0.3383187 Test Loss: 0.4124801
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 110.63952159881592
Epoch: 14, Steps: 92 | Train Loss: 0.2473262 Vali Loss: 0.3367072 Test Loss: 0.4123852
Validation loss decreased (0.336848 --> 0.336707).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 110.86216568946838
Epoch: 15, Steps: 92 | Train Loss: 0.2472182 Vali Loss: 0.3377663 Test Loss: 0.4122583
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 106.04820203781128
Epoch: 16, Steps: 92 | Train Loss: 0.2472430 Vali Loss: 0.3385115 Test Loss: 0.4120640
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 95.69217610359192
Epoch: 17, Steps: 92 | Train Loss: 0.2472447 Vali Loss: 0.3375368 Test Loss: 0.4122705
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 90.38756704330444
Epoch: 18, Steps: 92 | Train Loss: 0.2472972 Vali Loss: 0.3371025 Test Loss: 0.4123484
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 96.28804731369019
Epoch: 19, Steps: 92 | Train Loss: 0.2471492 Vali Loss: 0.3362977 Test Loss: 0.4121031
Validation loss decreased (0.336707 --> 0.336298).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 88.5408284664154
Epoch: 20, Steps: 92 | Train Loss: 0.2471550 Vali Loss: 0.3371181 Test Loss: 0.4120970
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 84.38984370231628
Epoch: 21, Steps: 92 | Train Loss: 0.2470933 Vali Loss: 0.3379297 Test Loss: 0.4122685
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 86.65215563774109
Epoch: 22, Steps: 92 | Train Loss: 0.2471688 Vali Loss: 0.3372062 Test Loss: 0.4121199
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 88.09654474258423
Epoch: 23, Steps: 92 | Train Loss: 0.2470948 Vali Loss: 0.3374635 Test Loss: 0.4120932
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 86.67790198326111
Epoch: 24, Steps: 92 | Train Loss: 0.2471160 Vali Loss: 0.3369115 Test Loss: 0.4122074
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 94.13022041320801
Epoch: 25, Steps: 92 | Train Loss: 0.2471312 Vali Loss: 0.3374380 Test Loss: 0.4120860
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 92.41210556030273
Epoch: 26, Steps: 92 | Train Loss: 0.2469822 Vali Loss: 0.3378905 Test Loss: 0.4121775
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 96.7605459690094
Epoch: 27, Steps: 92 | Train Loss: 0.2470536 Vali Loss: 0.3361195 Test Loss: 0.4120438
Validation loss decreased (0.336298 --> 0.336120).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 89.12904095649719
Epoch: 28, Steps: 92 | Train Loss: 0.2470947 Vali Loss: 0.3378147 Test Loss: 0.4121721
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 84.96526837348938
Epoch: 29, Steps: 92 | Train Loss: 0.2470976 Vali Loss: 0.3363710 Test Loss: 0.4121756
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 90.00201725959778
Epoch: 30, Steps: 92 | Train Loss: 0.2470484 Vali Loss: 0.3373488 Test Loss: 0.4118778
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 83.24324107170105
Epoch: 31, Steps: 92 | Train Loss: 0.2469645 Vali Loss: 0.3378876 Test Loss: 0.4121259
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 90.74478244781494
Epoch: 32, Steps: 92 | Train Loss: 0.2469393 Vali Loss: 0.3378746 Test Loss: 0.4121263
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 90.15909051895142
Epoch: 33, Steps: 92 | Train Loss: 0.2470332 Vali Loss: 0.3365920 Test Loss: 0.4120878
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 97.42639422416687
Epoch: 34, Steps: 92 | Train Loss: 0.2470135 Vali Loss: 0.3377912 Test Loss: 0.4121351
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 90.49217915534973
Epoch: 35, Steps: 92 | Train Loss: 0.2468382 Vali Loss: 0.3362086 Test Loss: 0.4120457
EarlyStopping counter: 8 out of 10
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 93.06858801841736
Epoch: 36, Steps: 92 | Train Loss: 0.2469880 Vali Loss: 0.3358085 Test Loss: 0.4120905
Validation loss decreased (0.336120 --> 0.335809).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 85.50236821174622
Epoch: 37, Steps: 92 | Train Loss: 0.2469889 Vali Loss: 0.3356524 Test Loss: 0.4120201
Validation loss decreased (0.335809 --> 0.335652).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 95.22344040870667
Epoch: 38, Steps: 92 | Train Loss: 0.2469490 Vali Loss: 0.3361560 Test Loss: 0.4120577
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 95.74052119255066
Epoch: 39, Steps: 92 | Train Loss: 0.2469328 Vali Loss: 0.3362977 Test Loss: 0.4120663
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 102.2327766418457
Epoch: 40, Steps: 92 | Train Loss: 0.2468964 Vali Loss: 0.3372850 Test Loss: 0.4121220
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 100.16933846473694
Epoch: 41, Steps: 92 | Train Loss: 0.2469623 Vali Loss: 0.3372416 Test Loss: 0.4120335
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 98.00817370414734
Epoch: 42, Steps: 92 | Train Loss: 0.2468791 Vali Loss: 0.3378935 Test Loss: 0.4120042
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 99.90029454231262
Epoch: 43, Steps: 92 | Train Loss: 0.2470046 Vali Loss: 0.3372875 Test Loss: 0.4121313
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 92.9919204711914
Epoch: 44, Steps: 92 | Train Loss: 0.2469569 Vali Loss: 0.3372219 Test Loss: 0.4121053
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 94.71204853057861
Epoch: 45, Steps: 92 | Train Loss: 0.2469968 Vali Loss: 0.3372031 Test Loss: 0.4119807
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 88.46573495864868
Epoch: 46, Steps: 92 | Train Loss: 0.2469728 Vali Loss: 0.3374856 Test Loss: 0.4120342
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 99.12804245948792
Epoch: 47, Steps: 92 | Train Loss: 0.2469641 Vali Loss: 0.3358976 Test Loss: 0.4119971
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : Traffic_360_j96_H8_FITS_custom_ftM_sl360_ll48_pl96_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3413
mse:0.4104578197002411, mae:0.2803087532520294, rse:0.5305028557777405, corr:[0.2774086  0.2919222  0.29248446 0.29226404 0.29209077 0.29190204
 0.29181835 0.2917797  0.29178092 0.29175612 0.29168952 0.2915624
 0.29140154 0.2912874  0.29129994 0.29127315 0.2913091  0.29157618
 0.2916242  0.2913663  0.29124948 0.2910921  0.29071    0.2909385
 0.29212138 0.29234314 0.29221642 0.29209256 0.29193974 0.29174137
 0.29155886 0.291473   0.2913953  0.2914858  0.29166907 0.29152775
 0.2913789  0.29143053 0.29152173 0.29173478 0.29191682 0.2917745
 0.29150364 0.29143614 0.291539   0.29155254 0.29132295 0.2911437
 0.29148632 0.29161498 0.29150966 0.29141647 0.29149008 0.2914584
 0.29135635 0.29120514 0.29115278 0.29133454 0.29132372 0.29116634
 0.2912227  0.2911456  0.29108697 0.29123187 0.29132268 0.2914243
 0.29138672 0.29118955 0.2911777  0.29117343 0.29090366 0.29082257
 0.29089794 0.29079816 0.29083872 0.29096505 0.29067022 0.2904603
 0.29059324 0.29048535 0.29031542 0.2903106  0.29040125 0.29053682
 0.29031324 0.29012495 0.29030222 0.29028973 0.2903015  0.29013458
 0.28985757 0.2900046  0.28975525 0.28968254 0.28967005 0.29007393]
