Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=74, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_180_j192_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=10, pred_len=192, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_180_j192_H8_FITS_custom_ftM_sl180_ll48_pl192_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11909
val 1565
test 3317
Model(
  (freq_upsampler): Linear(in_features=74, out_features=152, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1241059328.0
params:  11400.0
Trainable parameters:  11400
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 113.93276238441467
Epoch: 1, Steps: 93 | Train Loss: 1.0741747 Vali Loss: 1.0600064 Test Loss: 1.2705176
Validation loss decreased (inf --> 1.060006).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 107.80160927772522
Epoch: 2, Steps: 93 | Train Loss: 0.6615282 Vali Loss: 0.7963496 Test Loss: 0.9673418
Validation loss decreased (1.060006 --> 0.796350).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 111.50360631942749
Epoch: 3, Steps: 93 | Train Loss: 0.4941029 Vali Loss: 0.6766930 Test Loss: 0.8294588
Validation loss decreased (0.796350 --> 0.676693).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 97.4332754611969
Epoch: 4, Steps: 93 | Train Loss: 0.4073720 Vali Loss: 0.6109910 Test Loss: 0.7539800
Validation loss decreased (0.676693 --> 0.610991).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 99.62752938270569
Epoch: 5, Steps: 93 | Train Loss: 0.3556117 Vali Loss: 0.5717984 Test Loss: 0.7081277
Validation loss decreased (0.610991 --> 0.571798).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 102.13139200210571
Epoch: 6, Steps: 93 | Train Loss: 0.3210890 Vali Loss: 0.5428085 Test Loss: 0.6740131
Validation loss decreased (0.571798 --> 0.542809).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 94.81727457046509
Epoch: 7, Steps: 93 | Train Loss: 0.2960011 Vali Loss: 0.5208163 Test Loss: 0.6479380
Validation loss decreased (0.542809 --> 0.520816).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 102.05580997467041
Epoch: 8, Steps: 93 | Train Loss: 0.2766473 Vali Loss: 0.5036613 Test Loss: 0.6261238
Validation loss decreased (0.520816 --> 0.503661).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 106.88168406486511
Epoch: 9, Steps: 93 | Train Loss: 0.2611300 Vali Loss: 0.4888587 Test Loss: 0.6083866
Validation loss decreased (0.503661 --> 0.488859).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 94.08012342453003
Epoch: 10, Steps: 93 | Train Loss: 0.2483610 Vali Loss: 0.4762203 Test Loss: 0.5928620
Validation loss decreased (0.488859 --> 0.476220).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 95.43289256095886
Epoch: 11, Steps: 93 | Train Loss: 0.2376481 Vali Loss: 0.4659117 Test Loss: 0.5795767
Validation loss decreased (0.476220 --> 0.465912).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 85.97694230079651
Epoch: 12, Steps: 93 | Train Loss: 0.2285818 Vali Loss: 0.4565113 Test Loss: 0.5683591
Validation loss decreased (0.465912 --> 0.456511).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 99.17989778518677
Epoch: 13, Steps: 93 | Train Loss: 0.2207944 Vali Loss: 0.4488997 Test Loss: 0.5585674
Validation loss decreased (0.456511 --> 0.448900).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 94.70062565803528
Epoch: 14, Steps: 93 | Train Loss: 0.2140841 Vali Loss: 0.4418550 Test Loss: 0.5497521
Validation loss decreased (0.448900 --> 0.441855).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 104.90350437164307
Epoch: 15, Steps: 93 | Train Loss: 0.2082569 Vali Loss: 0.4353700 Test Loss: 0.5423778
Validation loss decreased (0.441855 --> 0.435370).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 94.05077719688416
Epoch: 16, Steps: 93 | Train Loss: 0.2031325 Vali Loss: 0.4299862 Test Loss: 0.5355224
Validation loss decreased (0.435370 --> 0.429986).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 101.72096967697144
Epoch: 17, Steps: 93 | Train Loss: 0.1986608 Vali Loss: 0.4249032 Test Loss: 0.5294511
Validation loss decreased (0.429986 --> 0.424903).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 96.67641234397888
Epoch: 18, Steps: 93 | Train Loss: 0.1947111 Vali Loss: 0.4211964 Test Loss: 0.5243593
Validation loss decreased (0.424903 --> 0.421196).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 89.93387770652771
Epoch: 19, Steps: 93 | Train Loss: 0.1911858 Vali Loss: 0.4177313 Test Loss: 0.5195911
Validation loss decreased (0.421196 --> 0.417731).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 96.62940406799316
Epoch: 20, Steps: 93 | Train Loss: 0.1880616 Vali Loss: 0.4141912 Test Loss: 0.5152826
Validation loss decreased (0.417731 --> 0.414191).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 92.66800260543823
Epoch: 21, Steps: 93 | Train Loss: 0.1852579 Vali Loss: 0.4113384 Test Loss: 0.5117181
Validation loss decreased (0.414191 --> 0.411338).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 106.04935097694397
Epoch: 22, Steps: 93 | Train Loss: 0.1827556 Vali Loss: 0.4084478 Test Loss: 0.5082961
Validation loss decreased (0.411338 --> 0.408448).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 97.0780074596405
Epoch: 23, Steps: 93 | Train Loss: 0.1804970 Vali Loss: 0.4063871 Test Loss: 0.5053198
Validation loss decreased (0.408448 --> 0.406387).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 100.87904262542725
Epoch: 24, Steps: 93 | Train Loss: 0.1784512 Vali Loss: 0.4046976 Test Loss: 0.5025968
Validation loss decreased (0.406387 --> 0.404698).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 97.69828152656555
Epoch: 25, Steps: 93 | Train Loss: 0.1766044 Vali Loss: 0.4021653 Test Loss: 0.5000795
Validation loss decreased (0.404698 --> 0.402165).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 100.69425368309021
Epoch: 26, Steps: 93 | Train Loss: 0.1749379 Vali Loss: 0.4004733 Test Loss: 0.4977153
Validation loss decreased (0.402165 --> 0.400473).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 100.15432524681091
Epoch: 27, Steps: 93 | Train Loss: 0.1734149 Vali Loss: 0.3985568 Test Loss: 0.4958082
Validation loss decreased (0.400473 --> 0.398557).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 98.01318883895874
Epoch: 28, Steps: 93 | Train Loss: 0.1720226 Vali Loss: 0.3973229 Test Loss: 0.4938048
Validation loss decreased (0.398557 --> 0.397323).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 98.22645664215088
Epoch: 29, Steps: 93 | Train Loss: 0.1707607 Vali Loss: 0.3960864 Test Loss: 0.4921743
Validation loss decreased (0.397323 --> 0.396086).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 110.0111997127533
Epoch: 30, Steps: 93 | Train Loss: 0.1696073 Vali Loss: 0.3947316 Test Loss: 0.4906087
Validation loss decreased (0.396086 --> 0.394732).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 99.8513445854187
Epoch: 31, Steps: 93 | Train Loss: 0.1685459 Vali Loss: 0.3937496 Test Loss: 0.4892241
Validation loss decreased (0.394732 --> 0.393750).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 93.38619303703308
Epoch: 32, Steps: 93 | Train Loss: 0.1675535 Vali Loss: 0.3925731 Test Loss: 0.4878903
Validation loss decreased (0.393750 --> 0.392573).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 85.70908379554749
Epoch: 33, Steps: 93 | Train Loss: 0.1666644 Vali Loss: 0.3920712 Test Loss: 0.4866803
Validation loss decreased (0.392573 --> 0.392071).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 76.63604831695557
Epoch: 34, Steps: 93 | Train Loss: 0.1658360 Vali Loss: 0.3906990 Test Loss: 0.4855388
Validation loss decreased (0.392071 --> 0.390699).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 93.24926280975342
Epoch: 35, Steps: 93 | Train Loss: 0.1650649 Vali Loss: 0.3899372 Test Loss: 0.4845464
Validation loss decreased (0.390699 --> 0.389937).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 85.63983917236328
Epoch: 36, Steps: 93 | Train Loss: 0.1643539 Vali Loss: 0.3891585 Test Loss: 0.4836092
Validation loss decreased (0.389937 --> 0.389158).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 94.15591979026794
Epoch: 37, Steps: 93 | Train Loss: 0.1637256 Vali Loss: 0.3885919 Test Loss: 0.4827140
Validation loss decreased (0.389158 --> 0.388592).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 90.31921029090881
Epoch: 38, Steps: 93 | Train Loss: 0.1631022 Vali Loss: 0.3877519 Test Loss: 0.4819487
Validation loss decreased (0.388592 --> 0.387752).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 99.5388994216919
Epoch: 39, Steps: 93 | Train Loss: 0.1625452 Vali Loss: 0.3874847 Test Loss: 0.4811988
Validation loss decreased (0.387752 --> 0.387485).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 103.68752145767212
Epoch: 40, Steps: 93 | Train Loss: 0.1620298 Vali Loss: 0.3869719 Test Loss: 0.4804814
Validation loss decreased (0.387485 --> 0.386972).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 98.93965697288513
Epoch: 41, Steps: 93 | Train Loss: 0.1615288 Vali Loss: 0.3862143 Test Loss: 0.4798187
Validation loss decreased (0.386972 --> 0.386214).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 102.98340368270874
Epoch: 42, Steps: 93 | Train Loss: 0.1611030 Vali Loss: 0.3858930 Test Loss: 0.4792586
Validation loss decreased (0.386214 --> 0.385893).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 101.89793252944946
Epoch: 43, Steps: 93 | Train Loss: 0.1606652 Vali Loss: 0.3856409 Test Loss: 0.4786862
Validation loss decreased (0.385893 --> 0.385641).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 105.17771506309509
Epoch: 44, Steps: 93 | Train Loss: 0.1602657 Vali Loss: 0.3854332 Test Loss: 0.4781964
Validation loss decreased (0.385641 --> 0.385433).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 103.4023072719574
Epoch: 45, Steps: 93 | Train Loss: 0.1599066 Vali Loss: 0.3847795 Test Loss: 0.4777078
Validation loss decreased (0.385433 --> 0.384779).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 106.9798514842987
Epoch: 46, Steps: 93 | Train Loss: 0.1595690 Vali Loss: 0.3837783 Test Loss: 0.4772490
Validation loss decreased (0.384779 --> 0.383778).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 98.02710509300232
Epoch: 47, Steps: 93 | Train Loss: 0.1592352 Vali Loss: 0.3838737 Test Loss: 0.4768750
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 103.06708931922913
Epoch: 48, Steps: 93 | Train Loss: 0.1589357 Vali Loss: 0.3834647 Test Loss: 0.4764575
Validation loss decreased (0.383778 --> 0.383465).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 105.320565700531
Epoch: 49, Steps: 93 | Train Loss: 0.1586582 Vali Loss: 0.3844008 Test Loss: 0.4760823
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 85.59397649765015
Epoch: 50, Steps: 93 | Train Loss: 0.1583813 Vali Loss: 0.3830662 Test Loss: 0.4757589
Validation loss decreased (0.383465 --> 0.383066).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 97.52591443061829
Epoch: 51, Steps: 93 | Train Loss: 0.1581402 Vali Loss: 0.3827657 Test Loss: 0.4754461
Validation loss decreased (0.383066 --> 0.382766).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 92.77512621879578
Epoch: 52, Steps: 93 | Train Loss: 0.1579042 Vali Loss: 0.3825957 Test Loss: 0.4751555
Validation loss decreased (0.382766 --> 0.382596).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 99.14404296875
Epoch: 53, Steps: 93 | Train Loss: 0.1576840 Vali Loss: 0.3825183 Test Loss: 0.4748661
Validation loss decreased (0.382596 --> 0.382518).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 98.33026027679443
Epoch: 54, Steps: 93 | Train Loss: 0.1574761 Vali Loss: 0.3827260 Test Loss: 0.4745955
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 92.72030830383301
Epoch: 55, Steps: 93 | Train Loss: 0.1572978 Vali Loss: 0.3820568 Test Loss: 0.4743829
Validation loss decreased (0.382518 --> 0.382057).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 92.57114863395691
Epoch: 56, Steps: 93 | Train Loss: 0.1571077 Vali Loss: 0.3819736 Test Loss: 0.4741412
Validation loss decreased (0.382057 --> 0.381974).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 89.8720109462738
Epoch: 57, Steps: 93 | Train Loss: 0.1569317 Vali Loss: 0.3815399 Test Loss: 0.4739003
Validation loss decreased (0.381974 --> 0.381540).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 83.55858635902405
Epoch: 58, Steps: 93 | Train Loss: 0.1567693 Vali Loss: 0.3818963 Test Loss: 0.4737165
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 82.78121900558472
Epoch: 59, Steps: 93 | Train Loss: 0.1566049 Vali Loss: 0.3811906 Test Loss: 0.4735040
Validation loss decreased (0.381540 --> 0.381191).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 80.58429288864136
Epoch: 60, Steps: 93 | Train Loss: 0.1564704 Vali Loss: 0.3813098 Test Loss: 0.4733464
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 85.35298037528992
Epoch: 61, Steps: 93 | Train Loss: 0.1563275 Vali Loss: 0.3813313 Test Loss: 0.4731788
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 81.95663547515869
Epoch: 62, Steps: 93 | Train Loss: 0.1562080 Vali Loss: 0.3814175 Test Loss: 0.4730107
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 75.48312401771545
Epoch: 63, Steps: 93 | Train Loss: 0.1560773 Vali Loss: 0.3805324 Test Loss: 0.4728520
Validation loss decreased (0.381191 --> 0.380532).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 79.43720889091492
Epoch: 64, Steps: 93 | Train Loss: 0.1559715 Vali Loss: 0.3807570 Test Loss: 0.4727296
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 75.84642052650452
Epoch: 65, Steps: 93 | Train Loss: 0.1558623 Vali Loss: 0.3809384 Test Loss: 0.4725836
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 76.50270390510559
Epoch: 66, Steps: 93 | Train Loss: 0.1557673 Vali Loss: 0.3806559 Test Loss: 0.4724510
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 75.56886172294617
Epoch: 67, Steps: 93 | Train Loss: 0.1556520 Vali Loss: 0.3810978 Test Loss: 0.4723336
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 70.6992540359497
Epoch: 68, Steps: 93 | Train Loss: 0.1555641 Vali Loss: 0.3804078 Test Loss: 0.4722411
Validation loss decreased (0.380532 --> 0.380408).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 76.24848818778992
Epoch: 69, Steps: 93 | Train Loss: 0.1554700 Vali Loss: 0.3801203 Test Loss: 0.4721173
Validation loss decreased (0.380408 --> 0.380120).  Saving model ...
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 73.51377701759338
Epoch: 70, Steps: 93 | Train Loss: 0.1553899 Vali Loss: 0.3802339 Test Loss: 0.4720160
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 77.34821891784668
Epoch: 71, Steps: 93 | Train Loss: 0.1553186 Vali Loss: 0.3803034 Test Loss: 0.4719168
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 69.54408931732178
Epoch: 72, Steps: 93 | Train Loss: 0.1552383 Vali Loss: 0.3799261 Test Loss: 0.4718295
Validation loss decreased (0.380120 --> 0.379926).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 103.87381601333618
Epoch: 73, Steps: 93 | Train Loss: 0.1551644 Vali Loss: 0.3799169 Test Loss: 0.4717619
Validation loss decreased (0.379926 --> 0.379917).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 118.785329580307
Epoch: 74, Steps: 93 | Train Loss: 0.1551110 Vali Loss: 0.3799222 Test Loss: 0.4716688
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 116.43014931678772
Epoch: 75, Steps: 93 | Train Loss: 0.1550339 Vali Loss: 0.3799020 Test Loss: 0.4715908
Validation loss decreased (0.379917 --> 0.379902).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 117.1652283668518
Epoch: 76, Steps: 93 | Train Loss: 0.1549757 Vali Loss: 0.3793866 Test Loss: 0.4715180
Validation loss decreased (0.379902 --> 0.379387).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 67.81955933570862
Epoch: 77, Steps: 93 | Train Loss: 0.1549201 Vali Loss: 0.3792785 Test Loss: 0.4714496
Validation loss decreased (0.379387 --> 0.379279).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 73.70510292053223
Epoch: 78, Steps: 93 | Train Loss: 0.1548579 Vali Loss: 0.3800503 Test Loss: 0.4713849
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 71.04366397857666
Epoch: 79, Steps: 93 | Train Loss: 0.1548212 Vali Loss: 0.3795689 Test Loss: 0.4713258
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 91.69537353515625
Epoch: 80, Steps: 93 | Train Loss: 0.1547720 Vali Loss: 0.3794124 Test Loss: 0.4712692
EarlyStopping counter: 3 out of 10
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 110.39588236808777
Epoch: 81, Steps: 93 | Train Loss: 0.1547139 Vali Loss: 0.3795460 Test Loss: 0.4712137
EarlyStopping counter: 4 out of 10
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 112.32606601715088
Epoch: 82, Steps: 93 | Train Loss: 0.1546805 Vali Loss: 0.3793809 Test Loss: 0.4711499
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 111.27593612670898
Epoch: 83, Steps: 93 | Train Loss: 0.1546221 Vali Loss: 0.3794059 Test Loss: 0.4711126
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 109.4103934764862
Epoch: 84, Steps: 93 | Train Loss: 0.1545955 Vali Loss: 0.3791384 Test Loss: 0.4710583
Validation loss decreased (0.379279 --> 0.379138).  Saving model ...
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 87.52453398704529
Epoch: 85, Steps: 93 | Train Loss: 0.1545504 Vali Loss: 0.3795840 Test Loss: 0.4710173
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 76.55573439598083
Epoch: 86, Steps: 93 | Train Loss: 0.1545070 Vali Loss: 0.3797569 Test Loss: 0.4709812
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 113.04011821746826
Epoch: 87, Steps: 93 | Train Loss: 0.1544930 Vali Loss: 0.3795641 Test Loss: 0.4709363
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 104.85019111633301
Epoch: 88, Steps: 93 | Train Loss: 0.1544467 Vali Loss: 0.3794976 Test Loss: 0.4709021
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 108.1431291103363
Epoch: 89, Steps: 93 | Train Loss: 0.1544199 Vali Loss: 0.3793237 Test Loss: 0.4708627
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 105.2115592956543
Epoch: 90, Steps: 93 | Train Loss: 0.1543991 Vali Loss: 0.3792734 Test Loss: 0.4708318
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 105.84342741966248
Epoch: 91, Steps: 93 | Train Loss: 0.1543592 Vali Loss: 0.3793159 Test Loss: 0.4707974
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 113.18895196914673
Epoch: 92, Steps: 93 | Train Loss: 0.1543462 Vali Loss: 0.3789430 Test Loss: 0.4707698
Validation loss decreased (0.379138 --> 0.378943).  Saving model ...
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 108.8169493675232
Epoch: 93, Steps: 93 | Train Loss: 0.1543131 Vali Loss: 0.3789879 Test Loss: 0.4707406
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 110.0010633468628
Epoch: 94, Steps: 93 | Train Loss: 0.1542857 Vali Loss: 0.3790221 Test Loss: 0.4707158
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 112.86733555793762
Epoch: 95, Steps: 93 | Train Loss: 0.1542835 Vali Loss: 0.3792233 Test Loss: 0.4706834
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 106.19439578056335
Epoch: 96, Steps: 93 | Train Loss: 0.1542454 Vali Loss: 0.3792204 Test Loss: 0.4706576
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 98.17881321907043
Epoch: 97, Steps: 93 | Train Loss: 0.1542253 Vali Loss: 0.3797460 Test Loss: 0.4706356
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 98.6804928779602
Epoch: 98, Steps: 93 | Train Loss: 0.1542029 Vali Loss: 0.3787715 Test Loss: 0.4706145
Validation loss decreased (0.378943 --> 0.378772).  Saving model ...
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 93.66616487503052
Epoch: 99, Steps: 93 | Train Loss: 0.1541847 Vali Loss: 0.3790118 Test Loss: 0.4705934
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 91.96860885620117
Epoch: 100, Steps: 93 | Train Loss: 0.1541693 Vali Loss: 0.3791345 Test Loss: 0.4705734
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.1160680107021042e-06
train 11909
val 1565
test 3317
Model(
  (freq_upsampler): Linear(in_features=74, out_features=152, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1241059328.0
params:  11400.0
Trainable parameters:  11400
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 90.21692681312561
Epoch: 1, Steps: 93 | Train Loss: 0.2808240 Vali Loss: 0.3742725 Test Loss: 0.4652847
Validation loss decreased (inf --> 0.374272).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 93.0012059211731
Epoch: 2, Steps: 93 | Train Loss: 0.2790380 Vali Loss: 0.3734206 Test Loss: 0.4643850
Validation loss decreased (0.374272 --> 0.373421).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 88.80512642860413
Epoch: 3, Steps: 93 | Train Loss: 0.2786946 Vali Loss: 0.3737913 Test Loss: 0.4640622
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00045125
Epoch: 4 cost time: 83.69400978088379
Epoch: 4, Steps: 93 | Train Loss: 0.2785258 Vali Loss: 0.3732398 Test Loss: 0.4640441
Validation loss decreased (0.373421 --> 0.373240).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 81.95473074913025
Epoch: 5, Steps: 93 | Train Loss: 0.2784785 Vali Loss: 0.3734605 Test Loss: 0.4640528
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 61.062578439712524
Epoch: 6, Steps: 93 | Train Loss: 0.2783726 Vali Loss: 0.3729731 Test Loss: 0.4638937
Validation loss decreased (0.373240 --> 0.372973).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 63.00426173210144
Epoch: 7, Steps: 93 | Train Loss: 0.2783478 Vali Loss: 0.3735034 Test Loss: 0.4640548
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 62.88159942626953
Epoch: 8, Steps: 93 | Train Loss: 0.2783147 Vali Loss: 0.3730680 Test Loss: 0.4636549
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 67.17263746261597
Epoch: 9, Steps: 93 | Train Loss: 0.2783182 Vali Loss: 0.3730199 Test Loss: 0.4638359
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 62.69028830528259
Epoch: 10, Steps: 93 | Train Loss: 0.2782874 Vali Loss: 0.3732718 Test Loss: 0.4637617
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 59.65608763694763
Epoch: 11, Steps: 93 | Train Loss: 0.2782619 Vali Loss: 0.3736618 Test Loss: 0.4636674
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 58.49200415611267
Epoch: 12, Steps: 93 | Train Loss: 0.2782353 Vali Loss: 0.3728453 Test Loss: 0.4638026
Validation loss decreased (0.372973 --> 0.372845).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 57.76210045814514
Epoch: 13, Steps: 93 | Train Loss: 0.2782194 Vali Loss: 0.3726033 Test Loss: 0.4637788
Validation loss decreased (0.372845 --> 0.372603).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 62.912797927856445
Epoch: 14, Steps: 93 | Train Loss: 0.2782139 Vali Loss: 0.3726388 Test Loss: 0.4635970
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 52.27070999145508
Epoch: 15, Steps: 93 | Train Loss: 0.2781735 Vali Loss: 0.3733832 Test Loss: 0.4636296
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 55.07446002960205
Epoch: 16, Steps: 93 | Train Loss: 0.2781713 Vali Loss: 0.3729203 Test Loss: 0.4637006
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 56.05555963516235
Epoch: 17, Steps: 93 | Train Loss: 0.2781778 Vali Loss: 0.3731880 Test Loss: 0.4636053
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 62.10052227973938
Epoch: 18, Steps: 93 | Train Loss: 0.2781469 Vali Loss: 0.3729597 Test Loss: 0.4636198
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 72.21869373321533
Epoch: 19, Steps: 93 | Train Loss: 0.2781624 Vali Loss: 0.3733395 Test Loss: 0.4635978
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 70.257009267807
Epoch: 20, Steps: 93 | Train Loss: 0.2781322 Vali Loss: 0.3730398 Test Loss: 0.4636189
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 75.14301800727844
Epoch: 21, Steps: 93 | Train Loss: 0.2781233 Vali Loss: 0.3729805 Test Loss: 0.4636998
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 72.5427474975586
Epoch: 22, Steps: 93 | Train Loss: 0.2781169 Vali Loss: 0.3730398 Test Loss: 0.4636075
EarlyStopping counter: 9 out of 10
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 69.77981066703796
Epoch: 23, Steps: 93 | Train Loss: 0.2781274 Vali Loss: 0.3730521 Test Loss: 0.4636499
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : Traffic_180_j192_H8_FITS_custom_ftM_sl180_ll48_pl192_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3317
mse:0.46292901039123535, mae:0.302413672208786, rse:0.5615471601486206, corr:[0.27321362 0.2880929  0.28817528 0.28711033 0.2875664  0.2866275
 0.28724605 0.2868576  0.28716698 0.28745916 0.28754961 0.28675857
 0.28625676 0.28653637 0.28676888 0.2863956  0.28662297 0.2864855
 0.28614488 0.2863923  0.28657708 0.28667268 0.28734583 0.28744948
 0.2871192  0.2866087  0.28593075 0.28572097 0.28561535 0.28598213
 0.2863029  0.28626215 0.28663442 0.2869695  0.28676128 0.28615284
 0.28571978 0.2853423  0.28543887 0.28569576 0.28598624 0.28617388
 0.28612593 0.2859123  0.2854741  0.28552195 0.2856825  0.28545848
 0.28504494 0.284801   0.28488314 0.28526285 0.28541586 0.28552082
 0.28603333 0.28569913 0.28554678 0.28579104 0.28570634 0.2853657
 0.2853921  0.28511065 0.28507346 0.28555217 0.2852622  0.28483346
 0.28425482 0.28424108 0.28486523 0.28498852 0.28463757 0.28462598
 0.28424984 0.28372076 0.28366292 0.2835619  0.283801   0.28413457
 0.2842436  0.28427818 0.2849767  0.28539315 0.2850102  0.28418028
 0.28363138 0.28359023 0.28343964 0.28376377 0.2840997  0.28384286
 0.28348756 0.2836709  0.2836905  0.28361285 0.28369603 0.28379086
 0.28379133 0.28364068 0.2838158  0.28388068 0.28400072 0.28377578
 0.2833881  0.2832465  0.2834023  0.2834273  0.2829343  0.2828732
 0.28291726 0.28277594 0.2826952  0.2828643  0.28272125 0.28267372
 0.2825752  0.2820476  0.2815171  0.28180698 0.28259453 0.28269988
 0.28313532 0.28349596 0.28353116 0.28370523 0.28378576 0.28352034
 0.28325278 0.28301334 0.2830906  0.28317624 0.28270623 0.28298452
 0.28342438 0.28349555 0.28356346 0.28387392 0.28369698 0.2837751
 0.28389964 0.28356683 0.28367287 0.28379267 0.28455535 0.28474635
 0.28463218 0.28475353 0.28445128 0.2843438  0.28473303 0.2850094
 0.28518546 0.2849465  0.2842468  0.284001   0.2843707  0.2852608
 0.28646442 0.28725126 0.28682572 0.2864288  0.2859596  0.28593868
 0.2862102  0.2864855  0.28717434 0.2871078  0.28805637 0.2881993
 0.28731352 0.2871417  0.28656855 0.28555    0.28585413 0.28624916
 0.28613648 0.2858525  0.28568685 0.28590876 0.28601462 0.28571308
 0.28532907 0.28587294 0.28600147 0.28592077 0.28639758 0.28661546
 0.28601086 0.28593966 0.28573215 0.28555685 0.2858877  0.2860527 ]
