Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=134, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_720_j192_H4', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_720_j192_H4_FITS_custom_ftM_sl720_ll48_pl192_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17501
val 2441
test 5069
Model(
  (freq_upsampler): Linear(in_features=134, out_features=169, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  930478848.0
params:  22815.0
Trainable parameters:  22815
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4216927
	speed: 0.5392s/iter; left time: 7279.1578s
Epoch: 1 cost time: 75.47226452827454
Epoch: 1, Steps: 136 | Train Loss: 0.6356275 Vali Loss: 0.2753357 Test Loss: 0.3310483
Validation loss decreased (inf --> 0.275336).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2130258
	speed: 1.2918s/iter; left time: 17264.7145s
Epoch: 2 cost time: 80.67864346504211
Epoch: 2, Steps: 136 | Train Loss: 0.2423301 Vali Loss: 0.1594849 Test Loss: 0.1936952
Validation loss decreased (0.275336 --> 0.159485).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1820309
	speed: 1.2668s/iter; left time: 16759.1002s
Epoch: 3 cost time: 75.15769386291504
Epoch: 3, Steps: 136 | Train Loss: 0.1786331 Vali Loss: 0.1440302 Test Loss: 0.1736784
Validation loss decreased (0.159485 --> 0.144030).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1643921
	speed: 1.3147s/iter; left time: 17213.1680s
Epoch: 4 cost time: 83.27458620071411
Epoch: 4, Steps: 136 | Train Loss: 0.1696670 Vali Loss: 0.1418275 Test Loss: 0.1704894
Validation loss decreased (0.144030 --> 0.141828).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1724108
	speed: 1.2326s/iter; left time: 15970.4908s
Epoch: 5 cost time: 77.9896891117096
Epoch: 5, Steps: 136 | Train Loss: 0.1677603 Vali Loss: 0.1410069 Test Loss: 0.1694350
Validation loss decreased (0.141828 --> 0.141007).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1686849
	speed: 1.3035s/iter; left time: 16711.9510s
Epoch: 6 cost time: 84.94913864135742
Epoch: 6, Steps: 136 | Train Loss: 0.1667684 Vali Loss: 0.1407479 Test Loss: 0.1688978
Validation loss decreased (0.141007 --> 0.140748).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1710337
	speed: 1.1917s/iter; left time: 15117.0355s
Epoch: 7 cost time: 72.90775418281555
Epoch: 7, Steps: 136 | Train Loss: 0.1663531 Vali Loss: 0.1404391 Test Loss: 0.1685829
Validation loss decreased (0.140748 --> 0.140439).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1802460
	speed: 1.2353s/iter; left time: 15502.3737s
Epoch: 8 cost time: 78.09020805358887
Epoch: 8, Steps: 136 | Train Loss: 0.1660465 Vali Loss: 0.1402924 Test Loss: 0.1683868
Validation loss decreased (0.140439 --> 0.140292).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1629817
	speed: 1.3267s/iter; left time: 16467.9177s
Epoch: 9 cost time: 91.99485063552856
Epoch: 9, Steps: 136 | Train Loss: 0.1658530 Vali Loss: 0.1402317 Test Loss: 0.1682706
Validation loss decreased (0.140292 --> 0.140232).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1708022
	speed: 2.1680s/iter; left time: 26615.9413s
Epoch: 10 cost time: 141.4222435951233
Epoch: 10, Steps: 136 | Train Loss: 0.1656097 Vali Loss: 0.1401569 Test Loss: 0.1681053
Validation loss decreased (0.140232 --> 0.140157).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1689594
	speed: 2.3896s/iter; left time: 29012.1764s
Epoch: 11 cost time: 148.26839423179626
Epoch: 11, Steps: 136 | Train Loss: 0.1655647 Vali Loss: 0.1400920 Test Loss: 0.1680803
Validation loss decreased (0.140157 --> 0.140092).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1610042
	speed: 2.4065s/iter; left time: 28889.5039s
Epoch: 12 cost time: 144.15501832962036
Epoch: 12, Steps: 136 | Train Loss: 0.1654731 Vali Loss: 0.1400175 Test Loss: 0.1680329
Validation loss decreased (0.140092 --> 0.140017).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1691778
	speed: 2.3660s/iter; left time: 28081.7941s
Epoch: 13 cost time: 142.32783722877502
Epoch: 13, Steps: 136 | Train Loss: 0.1652729 Vali Loss: 0.1400257 Test Loss: 0.1679712
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1704330
	speed: 2.3539s/iter; left time: 27618.6941s
Epoch: 14 cost time: 156.3693811893463
Epoch: 14, Steps: 136 | Train Loss: 0.1652842 Vali Loss: 0.1399789 Test Loss: 0.1679042
Validation loss decreased (0.140017 --> 0.139979).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1651996
	speed: 2.3821s/iter; left time: 27624.7013s
Epoch: 15 cost time: 148.20584511756897
Epoch: 15, Steps: 136 | Train Loss: 0.1652005 Vali Loss: 0.1398991 Test Loss: 0.1679159
Validation loss decreased (0.139979 --> 0.139899).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1748298
	speed: 2.5004s/iter; left time: 28656.7767s
Epoch: 16 cost time: 156.98064589500427
Epoch: 16, Steps: 136 | Train Loss: 0.1651790 Vali Loss: 0.1399060 Test Loss: 0.1678850
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1578226
	speed: 2.4395s/iter; left time: 27627.1649s
Epoch: 17 cost time: 156.80061054229736
Epoch: 17, Steps: 136 | Train Loss: 0.1651684 Vali Loss: 0.1398444 Test Loss: 0.1678823
Validation loss decreased (0.139899 --> 0.139844).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1584938
	speed: 2.4569s/iter; left time: 27490.0388s
Epoch: 18 cost time: 152.36005306243896
Epoch: 18, Steps: 136 | Train Loss: 0.1651413 Vali Loss: 0.1398982 Test Loss: 0.1678011
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1588154
	speed: 2.3800s/iter; left time: 26306.0882s
Epoch: 19 cost time: 152.45095944404602
Epoch: 19, Steps: 136 | Train Loss: 0.1651411 Vali Loss: 0.1397973 Test Loss: 0.1677977
Validation loss decreased (0.139844 --> 0.139797).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1648957
	speed: 2.4286s/iter; left time: 26512.5086s
Epoch: 20 cost time: 153.7435290813446
Epoch: 20, Steps: 136 | Train Loss: 0.1651060 Vali Loss: 0.1398645 Test Loss: 0.1677562
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1711185
	speed: 2.4311s/iter; left time: 26209.2208s
Epoch: 21 cost time: 154.5967960357666
Epoch: 21, Steps: 136 | Train Loss: 0.1650133 Vali Loss: 0.1398403 Test Loss: 0.1677638
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1723084
	speed: 2.4307s/iter; left time: 25874.4646s
Epoch: 22 cost time: 153.9318356513977
Epoch: 22, Steps: 136 | Train Loss: 0.1649953 Vali Loss: 0.1398447 Test Loss: 0.1677380
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1688878
	speed: 2.3620s/iter; left time: 24822.6977s
Epoch: 23 cost time: 147.57943844795227
Epoch: 23, Steps: 136 | Train Loss: 0.1649622 Vali Loss: 0.1397865 Test Loss: 0.1677596
Validation loss decreased (0.139797 --> 0.139787).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1652054
	speed: 2.4164s/iter; left time: 25064.9603s
Epoch: 24 cost time: 154.37718963623047
Epoch: 24, Steps: 136 | Train Loss: 0.1649525 Vali Loss: 0.1397768 Test Loss: 0.1677402
Validation loss decreased (0.139787 --> 0.139777).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1672914
	speed: 2.4025s/iter; left time: 24594.1787s
Epoch: 25 cost time: 152.84365487098694
Epoch: 25, Steps: 136 | Train Loss: 0.1650218 Vali Loss: 0.1398236 Test Loss: 0.1677407
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1601371
	speed: 2.3652s/iter; left time: 23890.4838s
Epoch: 26 cost time: 147.95712113380432
Epoch: 26, Steps: 136 | Train Loss: 0.1648791 Vali Loss: 0.1397249 Test Loss: 0.1677084
Validation loss decreased (0.139777 --> 0.139725).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1765077
	speed: 2.4358s/iter; left time: 24273.0841s
Epoch: 27 cost time: 152.32592940330505
Epoch: 27, Steps: 136 | Train Loss: 0.1648806 Vali Loss: 0.1397413 Test Loss: 0.1677102
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1666356
	speed: 2.3072s/iter; left time: 22677.6458s
Epoch: 28 cost time: 145.11188912391663
Epoch: 28, Steps: 136 | Train Loss: 0.1649158 Vali Loss: 0.1397482 Test Loss: 0.1677301
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1766994
	speed: 2.3566s/iter; left time: 22842.3823s
Epoch: 29 cost time: 140.6424045562744
Epoch: 29, Steps: 136 | Train Loss: 0.1649454 Vali Loss: 0.1397447 Test Loss: 0.1676897
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1511252
	speed: 2.1246s/iter; left time: 20304.8383s
Epoch: 30 cost time: 133.07931637763977
Epoch: 30, Steps: 136 | Train Loss: 0.1649015 Vali Loss: 0.1397380 Test Loss: 0.1676934
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1641326
	speed: 2.2155s/iter; left time: 20872.6475s
Epoch: 31 cost time: 142.20448994636536
Epoch: 31, Steps: 136 | Train Loss: 0.1649247 Vali Loss: 0.1397708 Test Loss: 0.1676778
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1547779
	speed: 2.2528s/iter; left time: 20916.8828s
Epoch: 32 cost time: 142.16191625595093
Epoch: 32, Steps: 136 | Train Loss: 0.1649081 Vali Loss: 0.1397405 Test Loss: 0.1676583
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1651202
	speed: 2.1934s/iter; left time: 20067.8388s
Epoch: 33 cost time: 135.5525667667389
Epoch: 33, Steps: 136 | Train Loss: 0.1649520 Vali Loss: 0.1397503 Test Loss: 0.1676628
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1533661
	speed: 2.2039s/iter; left time: 19863.8565s
Epoch: 34 cost time: 134.61130499839783
Epoch: 34, Steps: 136 | Train Loss: 0.1649213 Vali Loss: 0.1397401 Test Loss: 0.1676631
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1666584
	speed: 2.2087s/iter; left time: 19606.6048s
Epoch: 35 cost time: 144.80955529212952
Epoch: 35, Steps: 136 | Train Loss: 0.1648486 Vali Loss: 0.1397314 Test Loss: 0.1676666
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1617972
	speed: 2.2313s/iter; left time: 19503.4479s
Epoch: 36 cost time: 142.63933324813843
Epoch: 36, Steps: 136 | Train Loss: 0.1648561 Vali Loss: 0.1397060 Test Loss: 0.1676491
Validation loss decreased (0.139725 --> 0.139706).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1658544
	speed: 2.3811s/iter; left time: 20489.6683s
Epoch: 37 cost time: 145.60813450813293
Epoch: 37, Steps: 136 | Train Loss: 0.1648322 Vali Loss: 0.1397296 Test Loss: 0.1676582
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1714248
	speed: 2.2816s/iter; left time: 19322.5403s
Epoch: 38 cost time: 144.28982138633728
Epoch: 38, Steps: 136 | Train Loss: 0.1648062 Vali Loss: 0.1397421 Test Loss: 0.1676510
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1583318
	speed: 2.3922s/iter; left time: 19934.4289s
Epoch: 39 cost time: 143.98443961143494
Epoch: 39, Steps: 136 | Train Loss: 0.1648680 Vali Loss: 0.1397010 Test Loss: 0.1676141
Validation loss decreased (0.139706 --> 0.139701).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1539685
	speed: 2.2725s/iter; left time: 18627.6846s
Epoch: 40 cost time: 142.95240831375122
Epoch: 40, Steps: 136 | Train Loss: 0.1648657 Vali Loss: 0.1397914 Test Loss: 0.1676427
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1748423
	speed: 2.1238s/iter; left time: 17119.9532s
Epoch: 41 cost time: 132.43912267684937
Epoch: 41, Steps: 136 | Train Loss: 0.1648630 Vali Loss: 0.1396362 Test Loss: 0.1676384
Validation loss decreased (0.139701 --> 0.139636).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1724023
	speed: 2.1021s/iter; left time: 16658.8029s
Epoch: 42 cost time: 127.63762211799622
Epoch: 42, Steps: 136 | Train Loss: 0.1648287 Vali Loss: 0.1397819 Test Loss: 0.1676272
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1646253
	speed: 1.8663s/iter; left time: 14536.4176s
Epoch: 43 cost time: 111.94440221786499
Epoch: 43, Steps: 136 | Train Loss: 0.1648423 Vali Loss: 0.1397038 Test Loss: 0.1676318
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1574429
	speed: 1.9792s/iter; left time: 15146.8285s
Epoch: 44 cost time: 130.65555214881897
Epoch: 44, Steps: 136 | Train Loss: 0.1648824 Vali Loss: 0.1396731 Test Loss: 0.1676392
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1702401
	speed: 2.0262s/iter; left time: 15230.6176s
Epoch: 45 cost time: 118.48944044113159
Epoch: 45, Steps: 136 | Train Loss: 0.1648081 Vali Loss: 0.1396121 Test Loss: 0.1676358
Validation loss decreased (0.139636 --> 0.139612).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1562654
	speed: 1.8504s/iter; left time: 13658.0778s
Epoch: 46 cost time: 119.98349022865295
Epoch: 46, Steps: 136 | Train Loss: 0.1648530 Vali Loss: 0.1397065 Test Loss: 0.1676332
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1841232
	speed: 1.8886s/iter; left time: 13683.1876s
Epoch: 47 cost time: 112.1600456237793
Epoch: 47, Steps: 136 | Train Loss: 0.1647743 Vali Loss: 0.1396967 Test Loss: 0.1676298
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1537607
	speed: 1.8272s/iter; left time: 12989.2190s
Epoch: 48 cost time: 115.00819873809814
Epoch: 48, Steps: 136 | Train Loss: 0.1648429 Vali Loss: 0.1397446 Test Loss: 0.1676177
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1603204
	speed: 1.8401s/iter; left time: 12831.3068s
Epoch: 49 cost time: 119.0360221862793
Epoch: 49, Steps: 136 | Train Loss: 0.1648695 Vali Loss: 0.1397051 Test Loss: 0.1676231
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1714450
	speed: 1.9985s/iter; left time: 13663.8486s
Epoch: 50 cost time: 117.91854071617126
Epoch: 50, Steps: 136 | Train Loss: 0.1648135 Vali Loss: 0.1397093 Test Loss: 0.1676188
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1625737
	speed: 1.9151s/iter; left time: 12833.3961s
Epoch: 51 cost time: 115.92180728912354
Epoch: 51, Steps: 136 | Train Loss: 0.1647937 Vali Loss: 0.1397047 Test Loss: 0.1676127
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1676265
	speed: 1.8086s/iter; left time: 11873.1988s
Epoch: 52 cost time: 110.61088371276855
Epoch: 52, Steps: 136 | Train Loss: 0.1648710 Vali Loss: 0.1395990 Test Loss: 0.1676183
Validation loss decreased (0.139612 --> 0.139599).  Saving model ...
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1685002
	speed: 1.7796s/iter; left time: 11441.2193s
Epoch: 53 cost time: 108.8740029335022
Epoch: 53, Steps: 136 | Train Loss: 0.1648292 Vali Loss: 0.1396338 Test Loss: 0.1676300
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1592146
	speed: 1.7736s/iter; left time: 11161.5051s
Epoch: 54 cost time: 109.85595035552979
Epoch: 54, Steps: 136 | Train Loss: 0.1648489 Vali Loss: 0.1396365 Test Loss: 0.1676222
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1597237
	speed: 1.8088s/iter; left time: 11137.0116s
Epoch: 55 cost time: 111.22853493690491
Epoch: 55, Steps: 136 | Train Loss: 0.1647921 Vali Loss: 0.1396341 Test Loss: 0.1676202
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1607985
	speed: 1.7047s/iter; left time: 10264.2426s
Epoch: 56 cost time: 104.10816287994385
Epoch: 56, Steps: 136 | Train Loss: 0.1648729 Vali Loss: 0.1396413 Test Loss: 0.1676224
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.1821405
	speed: 1.7733s/iter; left time: 10435.8077s
Epoch: 57 cost time: 108.1119601726532
Epoch: 57, Steps: 136 | Train Loss: 0.1648064 Vali Loss: 0.1396841 Test Loss: 0.1676110
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1615152
	speed: 1.4530s/iter; left time: 8353.0953s
Epoch: 58 cost time: 83.72424650192261
Epoch: 58, Steps: 136 | Train Loss: 0.1648217 Vali Loss: 0.1396810 Test Loss: 0.1676131
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1674025
	speed: 1.6535s/iter; left time: 9281.1182s
Epoch: 59 cost time: 108.02555441856384
Epoch: 59, Steps: 136 | Train Loss: 0.1648198 Vali Loss: 0.1396884 Test Loss: 0.1676097
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1637262
	speed: 1.6648s/iter; left time: 9117.9899s
Epoch: 60 cost time: 105.06587052345276
Epoch: 60, Steps: 136 | Train Loss: 0.1647649 Vali Loss: 0.1397192 Test Loss: 0.1676110
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1667658
	speed: 1.5891s/iter; left time: 8487.4331s
Epoch: 61 cost time: 97.51179051399231
Epoch: 61, Steps: 136 | Train Loss: 0.1647130 Vali Loss: 0.1396644 Test Loss: 0.1676126
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1705692
	speed: 1.5932s/iter; left time: 8292.6184s
Epoch: 62 cost time: 102.96362209320068
Epoch: 62, Steps: 136 | Train Loss: 0.1648342 Vali Loss: 0.1396978 Test Loss: 0.1676070
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1650832
	speed: 1.6058s/iter; left time: 8139.9593s
Epoch: 63 cost time: 99.67832040786743
Epoch: 63, Steps: 136 | Train Loss: 0.1647332 Vali Loss: 0.1396270 Test Loss: 0.1676087
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1546670
	speed: 1.5450s/iter; left time: 7621.3287s
Epoch: 64 cost time: 104.57208919525146
Epoch: 64, Steps: 136 | Train Loss: 0.1648305 Vali Loss: 0.1396583 Test Loss: 0.1676079
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.1567407
	speed: 1.6202s/iter; left time: 7772.2769s
Epoch: 65 cost time: 102.75745153427124
Epoch: 65, Steps: 136 | Train Loss: 0.1647888 Vali Loss: 0.1397015 Test Loss: 0.1676083
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.1649416
	speed: 1.5332s/iter; left time: 7146.3443s
Epoch: 66 cost time: 100.0042052268982
Epoch: 66, Steps: 136 | Train Loss: 0.1647712 Vali Loss: 0.1397145 Test Loss: 0.1676102
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.1593281
	speed: 1.5504s/iter; left time: 7015.4862s
Epoch: 67 cost time: 97.57984519004822
Epoch: 67, Steps: 136 | Train Loss: 0.1647953 Vali Loss: 0.1396876 Test Loss: 0.1676098
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.1731614
	speed: 1.6095s/iter; left time: 7064.0578s
Epoch: 68 cost time: 102.08302330970764
Epoch: 68, Steps: 136 | Train Loss: 0.1647151 Vali Loss: 0.1396866 Test Loss: 0.1676041
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.1685381
	speed: 1.5526s/iter; left time: 6603.2469s
Epoch: 69 cost time: 98.46825122833252
Epoch: 69, Steps: 136 | Train Loss: 0.1648729 Vali Loss: 0.1397198 Test Loss: 0.1676111
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.1615061
	speed: 1.5973s/iter; left time: 6576.0510s
Epoch: 70 cost time: 96.31362867355347
Epoch: 70, Steps: 136 | Train Loss: 0.1647175 Vali Loss: 0.1397177 Test Loss: 0.1676068
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.1666401
	speed: 1.4875s/iter; left time: 5921.7497s
Epoch: 71 cost time: 90.75016283988953
Epoch: 71, Steps: 136 | Train Loss: 0.1648328 Vali Loss: 0.1396497 Test Loss: 0.1676047
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.1658027
	speed: 1.4544s/iter; left time: 5591.9823s
Epoch: 72 cost time: 90.90562081336975
Epoch: 72, Steps: 136 | Train Loss: 0.1647553 Vali Loss: 0.1396316 Test Loss: 0.1676091
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_720_j192_H4_FITS_custom_ftM_sl720_ll48_pl192_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5069
mse:0.16476762294769287, mae:0.2686648666858673, rse:0.40358805656433105, corr:[0.4631444  0.4653758  0.46597698 0.4667266  0.467293   0.4673366
 0.46710742 0.46692866 0.4668198  0.46669614 0.46653178 0.46644908
 0.46649635 0.46659103 0.46663848 0.4666345  0.4666074  0.46660948
 0.46658176 0.46642637 0.46630606 0.46633223 0.46653947 0.46683314
 0.46699747 0.4671182  0.46707106 0.46693188 0.4668282  0.46673602
 0.46661708 0.4665086  0.46640697 0.466337   0.46627003 0.46618775
 0.4660999  0.46600878 0.465945   0.46588904 0.46578115 0.46561304
 0.46543375 0.46525177 0.46511126 0.4650774  0.46516833 0.4653076
 0.46545455 0.46563843 0.4657058  0.46561554 0.4654943  0.46542254
 0.4653851  0.46533987 0.46526718 0.46520007 0.46517426 0.4651909
 0.46522373 0.4652079  0.46515882 0.46511954 0.46511164 0.4651356
 0.46511036 0.46495852 0.46476692 0.46466926 0.46468657 0.46474785
 0.4647881  0.46486193 0.4649044  0.46491233 0.46490848 0.4648834
 0.46483988 0.46478274 0.46473774 0.4647142  0.46468136 0.4646303
 0.46459007 0.46457225 0.464579   0.4645746  0.46453032 0.46446764
 0.46436414 0.4641931  0.46403915 0.46400738 0.46405438 0.4641328
 0.46423763 0.46435675 0.46438566 0.46435192 0.46431738 0.4643029
 0.4642862  0.46424192 0.46416178 0.4640886  0.46403775 0.46402586
 0.464012   0.46395454 0.463872   0.46380392 0.46377966 0.46380642
 0.463871   0.46388346 0.46383864 0.46384478 0.4639866  0.46420562
 0.46441203 0.46451336 0.46453205 0.46454906 0.4645776  0.4645872
 0.46455315 0.46448684 0.46442103 0.4643584  0.4642667  0.46416342
 0.46409842 0.4640914  0.4641383  0.46417195 0.46412963 0.4640417
 0.46396986 0.46386972 0.4637826  0.46375906 0.46378267 0.46385124
 0.46395567 0.46411094 0.46418476 0.4641554  0.4640877  0.46403885
 0.46399927 0.46392745 0.46381572 0.46368685 0.46358082 0.46352422
 0.46349487 0.46345007 0.46343383 0.46347636 0.46356764 0.463677
 0.46369383 0.4635024  0.4632168  0.46310237 0.46320087 0.46336398
 0.46338347 0.4634317  0.4633663  0.46320188 0.4630464  0.46289474
 0.46269614 0.46247104 0.4622515  0.46210456 0.46201965 0.4620123
 0.46209064 0.4621968  0.46225664 0.46221927 0.46210665 0.46210465
 0.46220443 0.46211436 0.461713   0.46127322 0.46163934 0.4625377 ]
