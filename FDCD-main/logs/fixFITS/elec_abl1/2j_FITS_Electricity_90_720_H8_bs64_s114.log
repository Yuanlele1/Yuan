Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=42, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_90_j720_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_90_j720_H8_FITS_custom_ftM_sl90_ll48_pl720_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17603
val 1913
test 4541
Model(
  (freq_upsampler): Linear(in_features=42, out_features=378, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  652313088.0
params:  16254.0
Trainable parameters:  16254
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 1.0988041
	speed: 0.7061s/iter; left time: 9603.3883s
Epoch: 1 cost time: 97.51047801971436
Epoch: 1, Steps: 137 | Train Loss: 1.5800477 Vali Loss: 0.7779698 Test Loss: 0.8591877
Validation loss decreased (inf --> 0.777970).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5918243
	speed: 1.6947s/iter; left time: 22817.0856s
Epoch: 2 cost time: 95.08702969551086
Epoch: 2, Steps: 137 | Train Loss: 0.6707483 Vali Loss: 0.4829353 Test Loss: 0.5439079
Validation loss decreased (0.777970 --> 0.482935).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4237214
	speed: 1.7230s/iter; left time: 22961.8188s
Epoch: 3 cost time: 95.17342448234558
Epoch: 3, Steps: 137 | Train Loss: 0.4689757 Vali Loss: 0.3766538 Test Loss: 0.4279098
Validation loss decreased (0.482935 --> 0.376654).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3621487
	speed: 1.6162s/iter; left time: 21317.7892s
Epoch: 4 cost time: 93.34348654747009
Epoch: 4, Steps: 137 | Train Loss: 0.3829650 Vali Loss: 0.3244366 Test Loss: 0.3693693
Validation loss decreased (0.376654 --> 0.324437).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3317102
	speed: 1.6726s/iter; left time: 21832.0100s
Epoch: 5 cost time: 94.17535018920898
Epoch: 5, Steps: 137 | Train Loss: 0.3369353 Vali Loss: 0.2949773 Test Loss: 0.3357804
Validation loss decreased (0.324437 --> 0.294977).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2961281
	speed: 1.7061s/iter; left time: 22036.5851s
Epoch: 6 cost time: 96.46246147155762
Epoch: 6, Steps: 137 | Train Loss: 0.3098743 Vali Loss: 0.2771635 Test Loss: 0.3152946
Validation loss decreased (0.294977 --> 0.277163).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2887042
	speed: 1.7961s/iter; left time: 22952.4913s
Epoch: 7 cost time: 102.39381408691406
Epoch: 7, Steps: 137 | Train Loss: 0.2929088 Vali Loss: 0.2654480 Test Loss: 0.3020217
Validation loss decreased (0.277163 --> 0.265448).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2686124
	speed: 1.7780s/iter; left time: 22477.3110s
Epoch: 8 cost time: 98.52865433692932
Epoch: 8, Steps: 137 | Train Loss: 0.2817571 Vali Loss: 0.2576768 Test Loss: 0.2929988
Validation loss decreased (0.265448 --> 0.257677).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2799725
	speed: 1.6961s/iter; left time: 21209.7450s
Epoch: 9 cost time: 96.13060450553894
Epoch: 9, Steps: 137 | Train Loss: 0.2742062 Vali Loss: 0.2521439 Test Loss: 0.2866912
Validation loss decreased (0.257677 --> 0.252144).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2817520
	speed: 1.7127s/iter; left time: 21182.6943s
Epoch: 10 cost time: 95.2567777633667
Epoch: 10, Steps: 137 | Train Loss: 0.2687569 Vali Loss: 0.2482504 Test Loss: 0.2820723
Validation loss decreased (0.252144 --> 0.248250).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2669952
	speed: 1.6041s/iter; left time: 19619.4490s
Epoch: 11 cost time: 92.43117761611938
Epoch: 11, Steps: 137 | Train Loss: 0.2647307 Vali Loss: 0.2451375 Test Loss: 0.2786534
Validation loss decreased (0.248250 --> 0.245138).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2492193
	speed: 1.6392s/iter; left time: 19825.0169s
Epoch: 12 cost time: 91.58039855957031
Epoch: 12, Steps: 137 | Train Loss: 0.2616735 Vali Loss: 0.2427042 Test Loss: 0.2760076
Validation loss decreased (0.245138 --> 0.242704).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2476567
	speed: 1.7074s/iter; left time: 20415.6034s
Epoch: 13 cost time: 97.67708945274353
Epoch: 13, Steps: 137 | Train Loss: 0.2592178 Vali Loss: 0.2408893 Test Loss: 0.2739489
Validation loss decreased (0.242704 --> 0.240889).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2523248
	speed: 1.6802s/iter; left time: 19860.1259s
Epoch: 14 cost time: 94.3206844329834
Epoch: 14, Steps: 137 | Train Loss: 0.2574268 Vali Loss: 0.2396338 Test Loss: 0.2722768
Validation loss decreased (0.240889 --> 0.239634).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2533951
	speed: 1.8665s/iter; left time: 21805.7542s
Epoch: 15 cost time: 117.7120463848114
Epoch: 15, Steps: 137 | Train Loss: 0.2558765 Vali Loss: 0.2386849 Test Loss: 0.2709299
Validation loss decreased (0.239634 --> 0.238685).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2706136
	speed: 2.0889s/iter; left time: 24118.3384s
Epoch: 16 cost time: 117.92884063720703
Epoch: 16, Steps: 137 | Train Loss: 0.2546460 Vali Loss: 0.2374605 Test Loss: 0.2698303
Validation loss decreased (0.238685 --> 0.237461).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2550184
	speed: 2.1366s/iter; left time: 24376.4780s
Epoch: 17 cost time: 117.7891161441803
Epoch: 17, Steps: 137 | Train Loss: 0.2535995 Vali Loss: 0.2369200 Test Loss: 0.2689152
Validation loss decreased (0.237461 --> 0.236920).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2599316
	speed: 1.9968s/iter; left time: 22507.7174s
Epoch: 18 cost time: 105.52642464637756
Epoch: 18, Steps: 137 | Train Loss: 0.2526879 Vali Loss: 0.2359898 Test Loss: 0.2680886
Validation loss decreased (0.236920 --> 0.235990).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2530760
	speed: 1.9408s/iter; left time: 21610.5678s
Epoch: 19 cost time: 108.18803834915161
Epoch: 19, Steps: 137 | Train Loss: 0.2519562 Vali Loss: 0.2349801 Test Loss: 0.2674279
Validation loss decreased (0.235990 --> 0.234980).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2452667
	speed: 1.9621s/iter; left time: 21579.1375s
Epoch: 20 cost time: 111.27592134475708
Epoch: 20, Steps: 137 | Train Loss: 0.2513568 Vali Loss: 0.2354030 Test Loss: 0.2668832
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2442810
	speed: 1.9862s/iter; left time: 21572.0979s
Epoch: 21 cost time: 110.95729446411133
Epoch: 21, Steps: 137 | Train Loss: 0.2508218 Vali Loss: 0.2343776 Test Loss: 0.2663839
Validation loss decreased (0.234980 --> 0.234378).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2464295
	speed: 1.9748s/iter; left time: 21177.7975s
Epoch: 22 cost time: 111.25865364074707
Epoch: 22, Steps: 137 | Train Loss: 0.2502164 Vali Loss: 0.2337301 Test Loss: 0.2659511
Validation loss decreased (0.234378 --> 0.233730).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2434171
	speed: 2.0430s/iter; left time: 21629.0000s
Epoch: 23 cost time: 115.74194931983948
Epoch: 23, Steps: 137 | Train Loss: 0.2498548 Vali Loss: 0.2338611 Test Loss: 0.2655725
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2515634
	speed: 2.0212s/iter; left time: 21121.6722s
Epoch: 24 cost time: 116.34107732772827
Epoch: 24, Steps: 137 | Train Loss: 0.2494894 Vali Loss: 0.2336619 Test Loss: 0.2652574
Validation loss decreased (0.233730 --> 0.233662).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2440876
	speed: 2.0693s/iter; left time: 21340.2559s
Epoch: 25 cost time: 114.03033137321472
Epoch: 25, Steps: 137 | Train Loss: 0.2491811 Vali Loss: 0.2333467 Test Loss: 0.2649396
Validation loss decreased (0.233662 --> 0.233347).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2588938
	speed: 1.9695s/iter; left time: 20041.9498s
Epoch: 26 cost time: 116.46308660507202
Epoch: 26, Steps: 137 | Train Loss: 0.2488377 Vali Loss: 0.2335746 Test Loss: 0.2646820
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2482800
	speed: 1.9169s/iter; left time: 19243.3447s
Epoch: 27 cost time: 107.36378145217896
Epoch: 27, Steps: 137 | Train Loss: 0.2486283 Vali Loss: 0.2332128 Test Loss: 0.2644500
Validation loss decreased (0.233347 --> 0.233213).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2406779
	speed: 2.0610s/iter; left time: 20408.4139s
Epoch: 28 cost time: 111.34009170532227
Epoch: 28, Steps: 137 | Train Loss: 0.2483315 Vali Loss: 0.2318008 Test Loss: 0.2642502
Validation loss decreased (0.233213 --> 0.231801).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2587143
	speed: 1.9464s/iter; left time: 19006.8024s
Epoch: 29 cost time: 111.26952838897705
Epoch: 29, Steps: 137 | Train Loss: 0.2481607 Vali Loss: 0.2324796 Test Loss: 0.2640492
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2523926
	speed: 2.0675s/iter; left time: 19906.3540s
Epoch: 30 cost time: 112.51232361793518
Epoch: 30, Steps: 137 | Train Loss: 0.2479652 Vali Loss: 0.2324215 Test Loss: 0.2638768
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2379090
	speed: 1.9752s/iter; left time: 18746.5344s
Epoch: 31 cost time: 110.44642281532288
Epoch: 31, Steps: 137 | Train Loss: 0.2478132 Vali Loss: 0.2320454 Test Loss: 0.2637226
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2454144
	speed: 2.1079s/iter; left time: 19717.6707s
Epoch: 32 cost time: 118.64599537849426
Epoch: 32, Steps: 137 | Train Loss: 0.2476682 Vali Loss: 0.2321923 Test Loss: 0.2635801
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2448986
	speed: 2.0869s/iter; left time: 19234.8608s
Epoch: 33 cost time: 117.4236855506897
Epoch: 33, Steps: 137 | Train Loss: 0.2475146 Vali Loss: 0.2319452 Test Loss: 0.2634370
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2499474
	speed: 1.9908s/iter; left time: 18076.5533s
Epoch: 34 cost time: 111.56210064888
Epoch: 34, Steps: 137 | Train Loss: 0.2473543 Vali Loss: 0.2323075 Test Loss: 0.2633269
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2514688
	speed: 1.9922s/iter; left time: 17816.2349s
Epoch: 35 cost time: 113.94825315475464
Epoch: 35, Steps: 137 | Train Loss: 0.2472525 Vali Loss: 0.2320195 Test Loss: 0.2632299
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2460585
	speed: 1.9686s/iter; left time: 17335.8489s
Epoch: 36 cost time: 114.6192581653595
Epoch: 36, Steps: 137 | Train Loss: 0.2471172 Vali Loss: 0.2316425 Test Loss: 0.2631134
Validation loss decreased (0.231801 --> 0.231642).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2429809
	speed: 1.9908s/iter; left time: 17258.2489s
Epoch: 37 cost time: 110.78630471229553
Epoch: 37, Steps: 137 | Train Loss: 0.2470653 Vali Loss: 0.2315520 Test Loss: 0.2630284
Validation loss decreased (0.231642 --> 0.231552).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2473545
	speed: 1.9629s/iter; left time: 16747.2852s
Epoch: 38 cost time: 110.71128463745117
Epoch: 38, Steps: 137 | Train Loss: 0.2468764 Vali Loss: 0.2319299 Test Loss: 0.2629473
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2465915
	speed: 1.9923s/iter; left time: 16725.5161s
Epoch: 39 cost time: 113.14931344985962
Epoch: 39, Steps: 137 | Train Loss: 0.2468550 Vali Loss: 0.2314410 Test Loss: 0.2628404
Validation loss decreased (0.231552 --> 0.231441).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2539243
	speed: 1.9449s/iter; left time: 16060.6065s
Epoch: 40 cost time: 107.41571736335754
Epoch: 40, Steps: 137 | Train Loss: 0.2467279 Vali Loss: 0.2315546 Test Loss: 0.2627691
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2441656
	speed: 2.0370s/iter; left time: 16542.6853s
Epoch: 41 cost time: 114.05089807510376
Epoch: 41, Steps: 137 | Train Loss: 0.2466451 Vali Loss: 0.2311169 Test Loss: 0.2626987
Validation loss decreased (0.231441 --> 0.231117).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2448041
	speed: 1.9019s/iter; left time: 15185.0997s
Epoch: 42 cost time: 106.61273145675659
Epoch: 42, Steps: 137 | Train Loss: 0.2465640 Vali Loss: 0.2308937 Test Loss: 0.2626368
Validation loss decreased (0.231117 --> 0.230894).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2497098
	speed: 1.9109s/iter; left time: 14994.5308s
Epoch: 43 cost time: 104.53608417510986
Epoch: 43, Steps: 137 | Train Loss: 0.2465620 Vali Loss: 0.2313036 Test Loss: 0.2625772
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2368044
	speed: 1.7648s/iter; left time: 13606.5145s
Epoch: 44 cost time: 99.78154706954956
Epoch: 44, Steps: 137 | Train Loss: 0.2464074 Vali Loss: 0.2310505 Test Loss: 0.2625206
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2553841
	speed: 1.7266s/iter; left time: 13075.2066s
Epoch: 45 cost time: 95.37526631355286
Epoch: 45, Steps: 137 | Train Loss: 0.2464029 Vali Loss: 0.2310469 Test Loss: 0.2624470
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2337499
	speed: 1.6353s/iter; left time: 12159.8878s
Epoch: 46 cost time: 93.36145401000977
Epoch: 46, Steps: 137 | Train Loss: 0.2463293 Vali Loss: 0.2310088 Test Loss: 0.2623996
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2497950
	speed: 1.4810s/iter; left time: 10809.9731s
Epoch: 47 cost time: 83.1483633518219
Epoch: 47, Steps: 137 | Train Loss: 0.2462518 Vali Loss: 0.2307361 Test Loss: 0.2623526
Validation loss decreased (0.230894 --> 0.230736).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2467033
	speed: 1.4390s/iter; left time: 10305.8222s
Epoch: 48 cost time: 82.85321569442749
Epoch: 48, Steps: 137 | Train Loss: 0.2462473 Vali Loss: 0.2308228 Test Loss: 0.2623074
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2440082
	speed: 1.4516s/iter; left time: 10197.7849s
Epoch: 49 cost time: 80.08067536354065
Epoch: 49, Steps: 137 | Train Loss: 0.2461900 Vali Loss: 0.2305426 Test Loss: 0.2622662
Validation loss decreased (0.230736 --> 0.230543).  Saving model ...
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2485440
	speed: 1.4108s/iter; left time: 9717.5621s
Epoch: 50 cost time: 81.19634795188904
Epoch: 50, Steps: 137 | Train Loss: 0.2460568 Vali Loss: 0.2306699 Test Loss: 0.2622212
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2481392
	speed: 1.3736s/iter; left time: 9273.1963s
Epoch: 51 cost time: 80.23782086372375
Epoch: 51, Steps: 137 | Train Loss: 0.2461325 Vali Loss: 0.2311206 Test Loss: 0.2621740
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2401665
	speed: 1.4496s/iter; left time: 9587.8899s
Epoch: 52 cost time: 83.1510226726532
Epoch: 52, Steps: 137 | Train Loss: 0.2460291 Vali Loss: 0.2307805 Test Loss: 0.2621418
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2438069
	speed: 1.4261s/iter; left time: 9236.6468s
Epoch: 53 cost time: 83.50383615493774
Epoch: 53, Steps: 137 | Train Loss: 0.2459792 Vali Loss: 0.2311219 Test Loss: 0.2621190
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2588759
	speed: 1.4148s/iter; left time: 8969.5782s
Epoch: 54 cost time: 79.85664176940918
Epoch: 54, Steps: 137 | Train Loss: 0.2459511 Vali Loss: 0.2312179 Test Loss: 0.2620843
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2450537
	speed: 1.4185s/iter; left time: 8799.1394s
Epoch: 55 cost time: 81.78900909423828
Epoch: 55, Steps: 137 | Train Loss: 0.2460203 Vali Loss: 0.2303431 Test Loss: 0.2620470
Validation loss decreased (0.230543 --> 0.230343).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2477482
	speed: 1.3858s/iter; left time: 8406.0989s
Epoch: 56 cost time: 78.29881644248962
Epoch: 56, Steps: 137 | Train Loss: 0.2458755 Vali Loss: 0.2306427 Test Loss: 0.2620160
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2582455
	speed: 1.4682s/iter; left time: 8705.1846s
Epoch: 57 cost time: 82.31078720092773
Epoch: 57, Steps: 137 | Train Loss: 0.2458930 Vali Loss: 0.2309894 Test Loss: 0.2619936
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2398186
	speed: 1.4599s/iter; left time: 8455.5654s
Epoch: 58 cost time: 83.68195080757141
Epoch: 58, Steps: 137 | Train Loss: 0.2458777 Vali Loss: 0.2306537 Test Loss: 0.2619730
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2435527
	speed: 1.3980s/iter; left time: 7905.4636s
Epoch: 59 cost time: 77.23376870155334
Epoch: 59, Steps: 137 | Train Loss: 0.2458190 Vali Loss: 0.2305954 Test Loss: 0.2619340
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.2377635
	speed: 1.4462s/iter; left time: 7979.9252s
Epoch: 60 cost time: 84.32984566688538
Epoch: 60, Steps: 137 | Train Loss: 0.2458195 Vali Loss: 0.2304156 Test Loss: 0.2619196
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.2519167
	speed: 1.3047s/iter; left time: 7020.4738s
Epoch: 61 cost time: 68.15330648422241
Epoch: 61, Steps: 137 | Train Loss: 0.2457480 Vali Loss: 0.2306171 Test Loss: 0.2619015
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.2504877
	speed: 1.1903s/iter; left time: 6242.0057s
Epoch: 62 cost time: 69.27237844467163
Epoch: 62, Steps: 137 | Train Loss: 0.2457442 Vali Loss: 0.2301978 Test Loss: 0.2618757
Validation loss decreased (0.230343 --> 0.230198).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.2431836
	speed: 1.3205s/iter; left time: 6743.6828s
Epoch: 63 cost time: 78.26189637184143
Epoch: 63, Steps: 137 | Train Loss: 0.2457423 Vali Loss: 0.2305123 Test Loss: 0.2618533
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.2319481
	speed: 1.3014s/iter; left time: 6467.7534s
Epoch: 64 cost time: 71.08216285705566
Epoch: 64, Steps: 137 | Train Loss: 0.2457159 Vali Loss: 0.2299799 Test Loss: 0.2618324
Validation loss decreased (0.230198 --> 0.229980).  Saving model ...
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.2467688
	speed: 1.3182s/iter; left time: 6370.7032s
Epoch: 65 cost time: 74.69641947746277
Epoch: 65, Steps: 137 | Train Loss: 0.2457221 Vali Loss: 0.2303769 Test Loss: 0.2618222
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.2525730
	speed: 1.3220s/iter; left time: 6208.1129s
Epoch: 66 cost time: 75.7326831817627
Epoch: 66, Steps: 137 | Train Loss: 0.2456873 Vali Loss: 0.2307360 Test Loss: 0.2618024
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.2386033
	speed: 1.2810s/iter; left time: 5840.1285s
Epoch: 67 cost time: 72.82792592048645
Epoch: 67, Steps: 137 | Train Loss: 0.2456510 Vali Loss: 0.2301043 Test Loss: 0.2617886
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.2554297
	speed: 1.3269s/iter; left time: 5867.4034s
Epoch: 68 cost time: 77.92172908782959
Epoch: 68, Steps: 137 | Train Loss: 0.2456321 Vali Loss: 0.2306065 Test Loss: 0.2617728
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.2496564
	speed: 1.3156s/iter; left time: 5637.1718s
Epoch: 69 cost time: 70.15776515007019
Epoch: 69, Steps: 137 | Train Loss: 0.2455256 Vali Loss: 0.2303334 Test Loss: 0.2617570
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.2535129
	speed: 1.2897s/iter; left time: 5349.7787s
Epoch: 70 cost time: 72.19596195220947
Epoch: 70, Steps: 137 | Train Loss: 0.2456077 Vali Loss: 0.2307417 Test Loss: 0.2617425
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.2443355
	speed: 1.1448s/iter; left time: 4591.9308s
Epoch: 71 cost time: 65.90744614601135
Epoch: 71, Steps: 137 | Train Loss: 0.2456008 Vali Loss: 0.2302609 Test Loss: 0.2617315
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.2416686
	speed: 1.1509s/iter; left time: 4458.4620s
Epoch: 72 cost time: 63.947747468948364
Epoch: 72, Steps: 137 | Train Loss: 0.2455833 Vali Loss: 0.2305159 Test Loss: 0.2617254
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.2434340
	speed: 1.1640s/iter; left time: 4350.0221s
Epoch: 73 cost time: 66.81845736503601
Epoch: 73, Steps: 137 | Train Loss: 0.2455481 Vali Loss: 0.2304418 Test Loss: 0.2617081
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.2472124
	speed: 1.1258s/iter; left time: 4052.7537s
Epoch: 74 cost time: 62.48724555969238
Epoch: 74, Steps: 137 | Train Loss: 0.2456078 Vali Loss: 0.2299262 Test Loss: 0.2617034
Validation loss decreased (0.229980 --> 0.229926).  Saving model ...
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.2552734
	speed: 1.1676s/iter; left time: 4043.2852s
Epoch: 75 cost time: 65.81334662437439
Epoch: 75, Steps: 137 | Train Loss: 0.2455339 Vali Loss: 0.2300628 Test Loss: 0.2616878
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.2404885
	speed: 1.1761s/iter; left time: 3911.7624s
Epoch: 76 cost time: 69.13530278205872
Epoch: 76, Steps: 137 | Train Loss: 0.2454610 Vali Loss: 0.2303402 Test Loss: 0.2616822
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.2504515
	speed: 1.2489s/iter; left time: 3982.6755s
Epoch: 77 cost time: 69.3451635837555
Epoch: 77, Steps: 137 | Train Loss: 0.2454744 Vali Loss: 0.2300824 Test Loss: 0.2616751
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.2500744
	speed: 1.1636s/iter; left time: 3551.3004s
Epoch: 78 cost time: 63.05175471305847
Epoch: 78, Steps: 137 | Train Loss: 0.2454928 Vali Loss: 0.2305408 Test Loss: 0.2616662
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.2405242
	speed: 1.0394s/iter; left time: 3029.9438s
Epoch: 79 cost time: 57.910980463027954
Epoch: 79, Steps: 137 | Train Loss: 0.2454680 Vali Loss: 0.2299854 Test Loss: 0.2616602
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.2381138
	speed: 1.0601s/iter; left time: 2944.9209s
Epoch: 80 cost time: 57.56443691253662
Epoch: 80, Steps: 137 | Train Loss: 0.2454165 Vali Loss: 0.2304849 Test Loss: 0.2616516
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.2302475
	speed: 1.0810s/iter; left time: 2854.8784s
Epoch: 81 cost time: 61.85584616661072
Epoch: 81, Steps: 137 | Train Loss: 0.2455315 Vali Loss: 0.2302241 Test Loss: 0.2616461
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.2446179
	speed: 1.0158s/iter; left time: 2543.5837s
Epoch: 82 cost time: 57.05909252166748
Epoch: 82, Steps: 137 | Train Loss: 0.2453795 Vali Loss: 0.2303151 Test Loss: 0.2616382
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.2471451
	speed: 1.0707s/iter; left time: 2534.2613s
Epoch: 83 cost time: 60.04913663864136
Epoch: 83, Steps: 137 | Train Loss: 0.2454190 Vali Loss: 0.2301382 Test Loss: 0.2616319
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.2497557
	speed: 1.0520s/iter; left time: 2345.8758s
Epoch: 84 cost time: 63.806490421295166
Epoch: 84, Steps: 137 | Train Loss: 0.2454681 Vali Loss: 0.2301109 Test Loss: 0.2616273
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.2559555
	speed: 1.0749s/iter; left time: 2249.8686s
Epoch: 85 cost time: 58.77427935600281
Epoch: 85, Steps: 137 | Train Loss: 0.2454551 Vali Loss: 0.2302261 Test Loss: 0.2616213
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.2280657
	speed: 0.9545s/iter; left time: 1866.9124s
Epoch: 86 cost time: 52.31386184692383
Epoch: 86, Steps: 137 | Train Loss: 0.2454950 Vali Loss: 0.2307518 Test Loss: 0.2616180
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.2554990
	speed: 0.9620s/iter; left time: 1749.7919s
Epoch: 87 cost time: 54.8979058265686
Epoch: 87, Steps: 137 | Train Loss: 0.2454457 Vali Loss: 0.2305000 Test Loss: 0.2616148
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.2529206
	speed: 0.9582s/iter; left time: 1611.6388s
Epoch: 88 cost time: 55.92640709877014
Epoch: 88, Steps: 137 | Train Loss: 0.2454586 Vali Loss: 0.2302326 Test Loss: 0.2616101
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.2489443
	speed: 1.0113s/iter; left time: 1562.4910s
Epoch: 89 cost time: 65.23655915260315
Epoch: 89, Steps: 137 | Train Loss: 0.2454290 Vali Loss: 0.2304388 Test Loss: 0.2616060
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.2420934
	speed: 1.4522s/iter; left time: 2044.7044s
Epoch: 90 cost time: 82.95182180404663
Epoch: 90, Steps: 137 | Train Loss: 0.2454221 Vali Loss: 0.2303365 Test Loss: 0.2616018
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.204402478767869e-06
	iters: 100, epoch: 91 | loss: 0.2323044
	speed: 1.5221s/iter; left time: 1934.5732s
Epoch: 91 cost time: 87.86633825302124
Epoch: 91, Steps: 137 | Train Loss: 0.2453829 Vali Loss: 0.2304050 Test Loss: 0.2615976
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.944182354829475e-06
	iters: 100, epoch: 92 | loss: 0.2414066
	speed: 1.5344s/iter; left time: 1740.0526s
Epoch: 92 cost time: 85.3638391494751
Epoch: 92, Steps: 137 | Train Loss: 0.2454554 Vali Loss: 0.2303046 Test Loss: 0.2615958
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.696973237088e-06
	iters: 100, epoch: 93 | loss: 0.2502507
	speed: 1.4674s/iter; left time: 1463.0142s
Epoch: 93 cost time: 84.38281011581421
Epoch: 93, Steps: 137 | Train Loss: 0.2453771 Vali Loss: 0.2303123 Test Loss: 0.2615924
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.462124575233601e-06
	iters: 100, epoch: 94 | loss: 0.2407293
	speed: 1.3464s/iter; left time: 1157.8775s
Epoch: 94 cost time: 76.49619889259338
Epoch: 94, Steps: 137 | Train Loss: 0.2453769 Vali Loss: 0.2303255 Test Loss: 0.2615900
EarlyStopping counter: 20 out of 20
Early stopping
train 17603
val 1913
test 4541
Model(
  (freq_upsampler): Linear(in_features=42, out_features=378, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  652313088.0
params:  16254.0
Trainable parameters:  16254
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2840222
	speed: 0.5801s/iter; left time: 7889.5158s
Epoch: 1 cost time: 80.07684445381165
Epoch: 1, Steps: 137 | Train Loss: 0.2750822 Vali Loss: 0.2301456 Test Loss: 0.2611161
Validation loss decreased (inf --> 0.230146).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2785871
	speed: 1.3486s/iter; left time: 18157.9376s
Epoch: 2 cost time: 76.12735652923584
Epoch: 2, Steps: 137 | Train Loss: 0.2748288 Vali Loss: 0.2295600 Test Loss: 0.2610381
Validation loss decreased (0.230146 --> 0.229560).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2848283
	speed: 1.4291s/iter; left time: 19045.8065s
Epoch: 3 cost time: 81.72180223464966
Epoch: 3, Steps: 137 | Train Loss: 0.2747942 Vali Loss: 0.2300421 Test Loss: 0.2609841
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2692686
	speed: 1.3433s/iter; left time: 17718.5252s
Epoch: 4 cost time: 74.75708937644958
Epoch: 4, Steps: 137 | Train Loss: 0.2747811 Vali Loss: 0.2295554 Test Loss: 0.2610291
Validation loss decreased (0.229560 --> 0.229555).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2649609
	speed: 1.2658s/iter; left time: 16522.0960s
Epoch: 5 cost time: 74.79716634750366
Epoch: 5, Steps: 137 | Train Loss: 0.2747156 Vali Loss: 0.2294814 Test Loss: 0.2610637
Validation loss decreased (0.229555 --> 0.229481).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2743327
	speed: 1.3480s/iter; left time: 17410.8581s
Epoch: 6 cost time: 75.5119903087616
Epoch: 6, Steps: 137 | Train Loss: 0.2746608 Vali Loss: 0.2296796 Test Loss: 0.2609843
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2751944
	speed: 1.3889s/iter; left time: 17748.9804s
Epoch: 7 cost time: 76.77794361114502
Epoch: 7, Steps: 137 | Train Loss: 0.2746276 Vali Loss: 0.2293508 Test Loss: 0.2610284
Validation loss decreased (0.229481 --> 0.229351).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2709830
	speed: 1.3572s/iter; left time: 17157.6442s
Epoch: 8 cost time: 80.04802536964417
Epoch: 8, Steps: 137 | Train Loss: 0.2746083 Vali Loss: 0.2292828 Test Loss: 0.2609677
Validation loss decreased (0.229351 --> 0.229283).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2632910
	speed: 1.3279s/iter; left time: 16605.4280s
Epoch: 9 cost time: 74.64296412467957
Epoch: 9, Steps: 137 | Train Loss: 0.2746181 Vali Loss: 0.2296882 Test Loss: 0.2609999
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2663625
	speed: 1.3808s/iter; left time: 17078.2685s
Epoch: 10 cost time: 78.93948030471802
Epoch: 10, Steps: 137 | Train Loss: 0.2746176 Vali Loss: 0.2294930 Test Loss: 0.2609999
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2735371
	speed: 1.3150s/iter; left time: 16083.9964s
Epoch: 11 cost time: 72.0558671951294
Epoch: 11, Steps: 137 | Train Loss: 0.2745738 Vali Loss: 0.2295440 Test Loss: 0.2609188
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2708345
	speed: 1.3253s/iter; left time: 16028.7689s
Epoch: 12 cost time: 78.99875545501709
Epoch: 12, Steps: 137 | Train Loss: 0.2746398 Vali Loss: 0.2292648 Test Loss: 0.2609010
Validation loss decreased (0.229283 --> 0.229265).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2816710
	speed: 1.4002s/iter; left time: 16741.6306s
Epoch: 13 cost time: 77.97133445739746
Epoch: 13, Steps: 137 | Train Loss: 0.2744830 Vali Loss: 0.2293024 Test Loss: 0.2609292
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2726434
	speed: 1.3973s/iter; left time: 16516.5410s
Epoch: 14 cost time: 80.13070011138916
Epoch: 14, Steps: 137 | Train Loss: 0.2745275 Vali Loss: 0.2294790 Test Loss: 0.2609824
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2786334
	speed: 1.3992s/iter; left time: 16346.9811s
Epoch: 15 cost time: 78.69165182113647
Epoch: 15, Steps: 137 | Train Loss: 0.2745553 Vali Loss: 0.2291309 Test Loss: 0.2610019
Validation loss decreased (0.229265 --> 0.229131).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2781941
	speed: 1.3846s/iter; left time: 15986.3593s
Epoch: 16 cost time: 79.08086466789246
Epoch: 16, Steps: 137 | Train Loss: 0.2745532 Vali Loss: 0.2291889 Test Loss: 0.2609694
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2660159
	speed: 1.3627s/iter; left time: 15546.9847s
Epoch: 17 cost time: 73.2902295589447
Epoch: 17, Steps: 137 | Train Loss: 0.2745954 Vali Loss: 0.2292266 Test Loss: 0.2609129
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2639540
	speed: 1.3676s/iter; left time: 15415.4480s
Epoch: 18 cost time: 76.11240410804749
Epoch: 18, Steps: 137 | Train Loss: 0.2745765 Vali Loss: 0.2290293 Test Loss: 0.2609705
Validation loss decreased (0.229131 --> 0.229029).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2882497
	speed: 1.3629s/iter; left time: 15175.8137s
Epoch: 19 cost time: 78.53965210914612
Epoch: 19, Steps: 137 | Train Loss: 0.2745955 Vali Loss: 0.2296474 Test Loss: 0.2609456
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2725648
	speed: 1.3047s/iter; left time: 14349.2287s
Epoch: 20 cost time: 70.54262804985046
Epoch: 20, Steps: 137 | Train Loss: 0.2746304 Vali Loss: 0.2295371 Test Loss: 0.2609849
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2663265
	speed: 1.3235s/iter; left time: 14374.7687s
Epoch: 21 cost time: 77.82447099685669
Epoch: 21, Steps: 137 | Train Loss: 0.2746538 Vali Loss: 0.2297417 Test Loss: 0.2609154
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2821465
	speed: 1.3645s/iter; left time: 14632.6292s
Epoch: 22 cost time: 79.58244490623474
Epoch: 22, Steps: 137 | Train Loss: 0.2745840 Vali Loss: 0.2285784 Test Loss: 0.2609764
Validation loss decreased (0.229029 --> 0.228578).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2832495
	speed: 1.3531s/iter; left time: 14325.3168s
Epoch: 23 cost time: 75.59790015220642
Epoch: 23, Steps: 137 | Train Loss: 0.2744064 Vali Loss: 0.2291144 Test Loss: 0.2609503
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2766828
	speed: 1.3955s/iter; left time: 14582.7897s
Epoch: 24 cost time: 80.74901103973389
Epoch: 24, Steps: 137 | Train Loss: 0.2745184 Vali Loss: 0.2292729 Test Loss: 0.2609353
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2823887
	speed: 1.3015s/iter; left time: 13421.9164s
Epoch: 25 cost time: 69.97916531562805
Epoch: 25, Steps: 137 | Train Loss: 0.2745533 Vali Loss: 0.2295324 Test Loss: 0.2609586
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2801413
	speed: 1.2238s/iter; left time: 12452.9400s
Epoch: 26 cost time: 70.71529936790466
Epoch: 26, Steps: 137 | Train Loss: 0.2744092 Vali Loss: 0.2294062 Test Loss: 0.2609103
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2794972
	speed: 1.1807s/iter; left time: 11852.7708s
Epoch: 27 cost time: 65.84277534484863
Epoch: 27, Steps: 137 | Train Loss: 0.2744818 Vali Loss: 0.2291052 Test Loss: 0.2609408
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2710656
	speed: 1.1864s/iter; left time: 11747.7306s
Epoch: 28 cost time: 67.9048364162445
Epoch: 28, Steps: 137 | Train Loss: 0.2745018 Vali Loss: 0.2290740 Test Loss: 0.2609411
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2767027
	speed: 1.2705s/iter; left time: 12406.8541s
Epoch: 29 cost time: 74.56265187263489
Epoch: 29, Steps: 137 | Train Loss: 0.2744787 Vali Loss: 0.2290871 Test Loss: 0.2609183
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2734507
	speed: 1.2873s/iter; left time: 12394.1995s
Epoch: 30 cost time: 71.15208959579468
Epoch: 30, Steps: 137 | Train Loss: 0.2745200 Vali Loss: 0.2291974 Test Loss: 0.2609353
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2658022
	speed: 1.3338s/iter; left time: 12659.0840s
Epoch: 31 cost time: 78.01483798027039
Epoch: 31, Steps: 137 | Train Loss: 0.2744797 Vali Loss: 0.2291807 Test Loss: 0.2609089
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2726978
	speed: 1.2154s/iter; left time: 11368.4031s
Epoch: 32 cost time: 68.38830018043518
Epoch: 32, Steps: 137 | Train Loss: 0.2745173 Vali Loss: 0.2294595 Test Loss: 0.2609696
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2748478
	speed: 1.2582s/iter; left time: 11596.4252s
Epoch: 33 cost time: 73.7267472743988
Epoch: 33, Steps: 137 | Train Loss: 0.2745027 Vali Loss: 0.2294692 Test Loss: 0.2609535
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2785425
	speed: 1.3002s/iter; left time: 11805.9796s
Epoch: 34 cost time: 75.09524869918823
Epoch: 34, Steps: 137 | Train Loss: 0.2744758 Vali Loss: 0.2294025 Test Loss: 0.2609277
EarlyStopping counter: 12 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2705344
	speed: 1.3696s/iter; left time: 12248.6403s
Epoch: 35 cost time: 75.23321604728699
Epoch: 35, Steps: 137 | Train Loss: 0.2745346 Vali Loss: 0.2295226 Test Loss: 0.2609096
EarlyStopping counter: 13 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2658837
	speed: 1.2698s/iter; left time: 11182.1202s
Epoch: 36 cost time: 69.3713641166687
Epoch: 36, Steps: 137 | Train Loss: 0.2745121 Vali Loss: 0.2291942 Test Loss: 0.2609392
EarlyStopping counter: 14 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2771167
	speed: 1.2288s/iter; left time: 10652.7654s
Epoch: 37 cost time: 69.19734334945679
Epoch: 37, Steps: 137 | Train Loss: 0.2745092 Vali Loss: 0.2293464 Test Loss: 0.2609428
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2698671
	speed: 1.2263s/iter; left time: 10462.3661s
Epoch: 38 cost time: 67.47430849075317
Epoch: 38, Steps: 137 | Train Loss: 0.2744553 Vali Loss: 0.2290006 Test Loss: 0.2609116
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2713032
	speed: 1.2047s/iter; left time: 10113.1201s
Epoch: 39 cost time: 64.4620521068573
Epoch: 39, Steps: 137 | Train Loss: 0.2745224 Vali Loss: 0.2290093 Test Loss: 0.2609335
EarlyStopping counter: 17 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2748350
	speed: 1.1963s/iter; left time: 9878.8133s
Epoch: 40 cost time: 67.12819361686707
Epoch: 40, Steps: 137 | Train Loss: 0.2744231 Vali Loss: 0.2288769 Test Loss: 0.2609210
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2666580
	speed: 1.2108s/iter; left time: 9833.2250s
Epoch: 41 cost time: 66.39352369308472
Epoch: 41, Steps: 137 | Train Loss: 0.2744849 Vali Loss: 0.2292866 Test Loss: 0.2609100
EarlyStopping counter: 19 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2607165
	speed: 1.1545s/iter; left time: 9217.8782s
Epoch: 42 cost time: 61.81953763961792
Epoch: 42, Steps: 137 | Train Loss: 0.2745245 Vali Loss: 0.2293428 Test Loss: 0.2609346
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_90_j720_H8_FITS_custom_ftM_sl90_ll48_pl720_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
mse:0.2596490979194641, mae:0.32963278889656067, rse:0.5083008408546448, corr:[0.44202417 0.4419733  0.4413345  0.43971586 0.43862492 0.43784744
 0.43771023 0.43703324 0.43596014 0.4351686  0.43443018 0.43403727
 0.433781   0.43332106 0.4331665  0.43273467 0.43272963 0.43298426
 0.4331862  0.43306917 0.4329581  0.43285662 0.43275127 0.43159157
 0.42961374 0.42820784 0.42718104 0.4261121  0.4256202  0.42598987
 0.426644   0.4268888  0.42650238 0.42611223 0.42570364 0.4255952
 0.4255514  0.4252769  0.42511505 0.42496422 0.42483824 0.4248915
 0.4248498  0.42479813 0.42501917 0.42513147 0.42507422 0.42468116
 0.42394987 0.42358786 0.42360923 0.42379692 0.42450923 0.42601413
 0.42801973 0.4293426  0.42938572 0.4294689  0.42939693 0.4292427
 0.42904213 0.42893845 0.42890447 0.42897558 0.42920104 0.4293612
 0.42961222 0.42980698 0.43023026 0.43055254 0.4310791  0.43139103
 0.43166876 0.43224096 0.43284124 0.43390986 0.43569335 0.438116
 0.44132495 0.44349045 0.4435271  0.4432597  0.442911   0.44263422
 0.44238424 0.4422258  0.44237173 0.44244915 0.44261393 0.44282627
 0.4429814  0.44306195 0.44328514 0.44340533 0.44348648 0.44359377
 0.4432899  0.44328323 0.4432986  0.4431898  0.443203   0.4432303
 0.44361243 0.44367674 0.44328573 0.4429605  0.44258976 0.44235927
 0.4421963  0.44202456 0.44216284 0.44231734 0.44250262 0.44258013
 0.44261676 0.44268787 0.44266844 0.44288078 0.4430615  0.4430796
 0.4428519  0.44293562 0.44296202 0.44288096 0.4428636  0.44283527
 0.44307268 0.44300863 0.44260654 0.44236243 0.442149   0.4418946
 0.4418638  0.44176337 0.4418656  0.44188777 0.4421171  0.44240496
 0.44252783 0.4426874  0.4428221  0.44299468 0.4431098  0.44302145
 0.4426398  0.44260207 0.44260132 0.44255015 0.44251388 0.44257593
 0.44292444 0.44279534 0.44241396 0.44207036 0.44168845 0.44139457
 0.4413959  0.4413342  0.44145617 0.44157335 0.44184828 0.44218966
 0.44252503 0.44257382 0.44256422 0.4421976  0.44173256 0.4396288
 0.4365519  0.43429723 0.43259442 0.4311375  0.43012682 0.42959446
 0.4294652  0.42934725 0.4285503  0.42811385 0.4277201  0.42745498
 0.42746875 0.42726237 0.4271336  0.4268858  0.42687994 0.42688084
 0.42689636 0.4266127  0.42650348 0.42624995 0.42578182 0.42428657
 0.42209756 0.42052093 0.41948852 0.41861215 0.41826198 0.41859224
 0.41960377 0.4201353  0.4196849  0.4195962  0.41929516 0.41905668
 0.41919687 0.41912046 0.41911352 0.4188963  0.41875017 0.41892383
 0.41895637 0.4187921  0.41885975 0.4188148  0.41886902 0.41832983
 0.41732466 0.41692817 0.41690886 0.41729617 0.41834217 0.41972667
 0.4218901  0.423478   0.423468   0.42363012 0.4234882  0.42341846
 0.42337054 0.42319041 0.4232472  0.42326373 0.4234776  0.42361033
 0.42375326 0.42402762 0.42435652 0.4246735  0.42533827 0.4255192
 0.42568383 0.42623264 0.42704064 0.4280531  0.4297868  0.43226558
 0.43542376 0.43771383 0.4377957  0.43776777 0.43750837 0.43725368
 0.4371019  0.43692017 0.4369573  0.43700534 0.4372209  0.43745083
 0.43760413 0.43771955 0.4378034  0.43809062 0.43830428 0.43832472
 0.43796417 0.4379221  0.43798083 0.43792388 0.4378623  0.43805477
 0.43842974 0.43850026 0.4381838  0.4378091  0.43750593 0.43727404
 0.43718046 0.4369668  0.43696296 0.437033   0.437189   0.43732464
 0.43744177 0.43741474 0.4373766  0.43754226 0.43775925 0.4378701
 0.43762022 0.43764076 0.437601   0.43750778 0.4375257  0.4375781
 0.4378723  0.4377416  0.43739292 0.4371435  0.43690675 0.4367003
 0.43672916 0.43675226 0.43674105 0.43674842 0.4369998  0.43726683
 0.4375508  0.437604   0.43769726 0.43785462 0.43789595 0.43779352
 0.43733424 0.4371499  0.43717808 0.43706122 0.43706882 0.43716866
 0.43752813 0.4374924  0.43718946 0.43686873 0.43650165 0.43624994
 0.4362878  0.43614435 0.43619263 0.43631327 0.43657908 0.43694186
 0.4371434  0.43718112 0.4370751  0.4366455  0.4360142  0.43358904
 0.4304774  0.42821583 0.42649063 0.42513075 0.42396513 0.4233794
 0.42342642 0.42318106 0.42226806 0.42171013 0.42128882 0.4211306
 0.42102793 0.42078462 0.42069948 0.42055827 0.42049974 0.4205809
 0.42059958 0.42039597 0.42031464 0.42006302 0.4196496  0.41788718
 0.4155853  0.4140297  0.41294113 0.41207644 0.41163543 0.41205835
 0.4129995  0.41337672 0.41298974 0.41277334 0.4124838  0.41234773
 0.41238445 0.41231903 0.412276   0.41212717 0.41213772 0.41221523
 0.4121484  0.4120689  0.41205654 0.41223383 0.41231132 0.41169268
 0.41070068 0.4103399  0.4105518  0.410836   0.41190046 0.4137222
 0.41591248 0.4174438  0.41751623 0.41757202 0.41738608 0.41739315
 0.4173862  0.41707584 0.41703147 0.41697094 0.41711283 0.4175313
 0.41774797 0.4179921  0.41830233 0.4186684  0.4193682  0.41958728
 0.4198146  0.42046753 0.421413   0.42265326 0.42476195 0.42725733
 0.43049616 0.43304724 0.43321335 0.4331622  0.43309012 0.4328306
 0.432645   0.43236956 0.43252063 0.4325328  0.43270642 0.43302622
 0.433122   0.43321627 0.43322092 0.43346918 0.4337442  0.4337409
 0.4334709  0.43348128 0.43346733 0.43343517 0.4334524  0.43359947
 0.43400264 0.43407264 0.43376595 0.43341154 0.43306664 0.43294597
 0.43292317 0.43259043 0.4325852  0.43261564 0.43269342 0.43291423
 0.43309626 0.43305078 0.4330492  0.43328148 0.4334446  0.43348646
 0.43329608 0.43334025 0.43338805 0.43328193 0.43338424 0.43353033
 0.4337878  0.4336683  0.4334028  0.43311745 0.4328095  0.43257272
 0.43260127 0.43246084 0.43255278 0.4326867  0.43287662 0.4331709
 0.43344966 0.4336637  0.43381146 0.4339541  0.4341539  0.43405536
 0.43361366 0.43345368 0.43339688 0.4334785  0.43354434 0.4336277
 0.43395153 0.4337829  0.43358597 0.43334094 0.43306527 0.43280184
 0.4325748  0.43254215 0.4326366  0.43272072 0.43310568 0.43336168
 0.4335881  0.43366587 0.43350688 0.43311915 0.4325422  0.43011108
 0.4268456  0.42458922 0.42285722 0.42142957 0.42058975 0.41997448
 0.41985244 0.41973415 0.41877323 0.4182804  0.41785255 0.41766757
 0.4177827  0.4173937  0.41735733 0.41717133 0.41697752 0.41722727
 0.41721523 0.41704068 0.41692623 0.4167092  0.41642845 0.41463992
 0.41212898 0.41062346 0.409413   0.4085627  0.40834048 0.4043575
 0.40925667 0.4096943  0.40918246 0.4089855  0.40866402 0.40841696
 0.4085247  0.40840495 0.40834156 0.40405762 0.40400234 0.40409696
 0.40410253 0.40398833 0.40410635 0.40428245 0.40437973 0.40367317
 0.40260524 0.4021968  0.40227455 0.40243095 0.4035734  0.40540266
 0.4073639  0.4087657  0.40893802 0.40905046 0.40885875 0.40861514
 0.40854105 0.40840128 0.40837574 0.40832427 0.40851343 0.4086499
 0.40873352 0.40911257 0.40944535 0.40970665 0.41046995 0.41071612
 0.4107766  0.4113611  0.4122465  0.41345802 0.41525412 0.4177402
 0.42107072 0.42341974 0.42370972 0.42361388 0.4233378  0.42302662
 0.4227029  0.42254055 0.42261425 0.42264715 0.42287078 0.4230855
 0.4233708  0.42344978 0.42347807 0.4236686  0.42384887 0.42388406
 0.4235567  0.4235965  0.42351034 0.4233866  0.42353454 0.42367098
 0.42397106 0.42402232 0.42363966 0.4233185  0.42299303 0.42278826
 0.42267635 0.42242882 0.422493   0.42257392 0.42270613 0.42296293
 0.42305025 0.4230326  0.42309695 0.42332408 0.42346972 0.42350975
 0.4232698  0.4233294  0.42325336 0.4231855  0.42325518 0.42325076
 0.42351934 0.42340013 0.42306042 0.42277363 0.42245948 0.42234066
 0.42239088 0.42231417 0.42236614 0.42245585 0.4226512  0.42291182
 0.42316136 0.42328486 0.42345744 0.42369547 0.42378813 0.4236318
 0.42311603 0.42310578 0.4231312  0.42309386 0.42315078 0.4231769
 0.42353746 0.42331865 0.42294356 0.4226868  0.42242953 0.42210567
 0.4220328  0.42197093 0.4219895  0.42208847 0.42230457 0.42259467
 0.42287403 0.42288563 0.42285    0.4224042  0.42182133 0.4193718
 0.41601256 0.41378203 0.41212535 0.41087115 0.4097799  0.40935966
 0.40934756 0.4092195  0.40830088 0.40760863 0.40725428 0.40687037
 0.406703   0.40637144 0.40632582 0.40613303 0.40593317 0.4059248
 0.4058618  0.40576205 0.40574884 0.40553668 0.40528792 0.4035244
 0.4012206  0.39963388 0.39869356 0.3976909  0.39750278 0.3980247
 0.3987182  0.39922872 0.39852515 0.39823633 0.39751005 0.3971957
 0.3969987  0.39657444 0.39670658 0.3961815  0.39625135 0.39603007
 0.3963415  0.39624572 0.39694297 0.39756584 0.39765564 0.3980056 ]
