Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=74, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_180_j720_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_180_j720_H8_FITS_custom_ftM_sl180_ll48_pl720_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17513
val 1913
test 4541
Model(
  (freq_upsampler): Linear(in_features=74, out_features=370, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1124989440.0
params:  27750.0
Trainable parameters:  27750
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.8518932
	speed: 0.6586s/iter; left time: 8891.1645s
Epoch: 1 cost time: 88.29435896873474
Epoch: 1, Steps: 136 | Train Loss: 1.1862259 Vali Loss: 0.6853349 Test Loss: 0.7607173
Validation loss decreased (inf --> 0.685335).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5086221
	speed: 1.5274s/iter; left time: 20413.4441s
Epoch: 2 cost time: 86.87446236610413
Epoch: 2, Steps: 136 | Train Loss: 0.5813620 Vali Loss: 0.4514310 Test Loss: 0.5030223
Validation loss decreased (0.685335 --> 0.451431).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3979902
	speed: 1.5401s/iter; left time: 20374.5333s
Epoch: 3 cost time: 87.90588569641113
Epoch: 3, Steps: 136 | Train Loss: 0.4181525 Vali Loss: 0.3594175 Test Loss: 0.4000144
Validation loss decreased (0.451431 --> 0.359417).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3214019
	speed: 1.5779s/iter; left time: 20659.5516s
Epoch: 4 cost time: 86.38178539276123
Epoch: 4, Steps: 136 | Train Loss: 0.3483002 Vali Loss: 0.3155079 Test Loss: 0.3513802
Validation loss decreased (0.359417 --> 0.315508).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3003577
	speed: 1.5588s/iter; left time: 20197.0961s
Epoch: 5 cost time: 92.34626913070679
Epoch: 5, Steps: 136 | Train Loss: 0.3115814 Vali Loss: 0.2902710 Test Loss: 0.3241740
Validation loss decreased (0.315508 --> 0.290271).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2737279
	speed: 1.5374s/iter; left time: 19710.9017s
Epoch: 6 cost time: 87.59905457496643
Epoch: 6, Steps: 136 | Train Loss: 0.2888799 Vali Loss: 0.2725865 Test Loss: 0.3065795
Validation loss decreased (0.290271 --> 0.272587).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2738214
	speed: 1.5907s/iter; left time: 20178.0895s
Epoch: 7 cost time: 93.72120594978333
Epoch: 7, Steps: 136 | Train Loss: 0.2729705 Vali Loss: 0.2597815 Test Loss: 0.2938515
Validation loss decreased (0.272587 --> 0.259782).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2649776
	speed: 1.6458s/iter; left time: 20653.2578s
Epoch: 8 cost time: 96.05218601226807
Epoch: 8, Steps: 136 | Train Loss: 0.2610592 Vali Loss: 0.2499562 Test Loss: 0.2841389
Validation loss decreased (0.259782 --> 0.249956).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2483077
	speed: 1.5881s/iter; left time: 19713.0622s
Epoch: 9 cost time: 90.2578067779541
Epoch: 9, Steps: 136 | Train Loss: 0.2515888 Vali Loss: 0.2422079 Test Loss: 0.2763449
Validation loss decreased (0.249956 --> 0.242208).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2493151
	speed: 1.5828s/iter; left time: 19431.4727s
Epoch: 10 cost time: 88.49659132957458
Epoch: 10, Steps: 136 | Train Loss: 0.2438462 Vali Loss: 0.2352907 Test Loss: 0.2700200
Validation loss decreased (0.242208 --> 0.235291).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2363868
	speed: 1.6182s/iter; left time: 19647.1402s
Epoch: 11 cost time: 89.88947606086731
Epoch: 11, Steps: 136 | Train Loss: 0.2374920 Vali Loss: 0.2298028 Test Loss: 0.2647261
Validation loss decreased (0.235291 --> 0.229803).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2353333
	speed: 1.5850s/iter; left time: 19028.3346s
Epoch: 12 cost time: 95.0021402835846
Epoch: 12, Steps: 136 | Train Loss: 0.2321284 Vali Loss: 0.2257297 Test Loss: 0.2602293
Validation loss decreased (0.229803 --> 0.225730).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2163395
	speed: 1.6606s/iter; left time: 19709.4638s
Epoch: 13 cost time: 90.383709192276
Epoch: 13, Steps: 136 | Train Loss: 0.2275014 Vali Loss: 0.2213597 Test Loss: 0.2565405
Validation loss decreased (0.225730 --> 0.221360).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2210426
	speed: 1.5526s/iter; left time: 18217.2403s
Epoch: 14 cost time: 89.80656456947327
Epoch: 14, Steps: 136 | Train Loss: 0.2236668 Vali Loss: 0.2181866 Test Loss: 0.2532569
Validation loss decreased (0.221360 --> 0.218187).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2093608
	speed: 1.5538s/iter; left time: 18019.8992s
Epoch: 15 cost time: 91.16112494468689
Epoch: 15, Steps: 136 | Train Loss: 0.2203086 Vali Loss: 0.2154179 Test Loss: 0.2504647
Validation loss decreased (0.218187 --> 0.215418).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2243441
	speed: 1.5684s/iter; left time: 17975.4532s
Epoch: 16 cost time: 89.52194476127625
Epoch: 16, Steps: 136 | Train Loss: 0.2173881 Vali Loss: 0.2126290 Test Loss: 0.2480560
Validation loss decreased (0.215418 --> 0.212629).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2280721
	speed: 1.5673s/iter; left time: 17749.8991s
Epoch: 17 cost time: 93.0261607170105
Epoch: 17, Steps: 136 | Train Loss: 0.2148491 Vali Loss: 0.2104918 Test Loss: 0.2458764
Validation loss decreased (0.212629 --> 0.210492).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2100728
	speed: 1.6364s/iter; left time: 18309.5956s
Epoch: 18 cost time: 86.13473558425903
Epoch: 18, Steps: 136 | Train Loss: 0.2126311 Vali Loss: 0.2089585 Test Loss: 0.2440569
Validation loss decreased (0.210492 --> 0.208958).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1967047
	speed: 1.4961s/iter; left time: 16536.0309s
Epoch: 19 cost time: 86.65855264663696
Epoch: 19, Steps: 136 | Train Loss: 0.2106983 Vali Loss: 0.2069638 Test Loss: 0.2424393
Validation loss decreased (0.208958 --> 0.206964).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2135569
	speed: 1.8435s/iter; left time: 20125.1559s
Epoch: 20 cost time: 110.61253142356873
Epoch: 20, Steps: 136 | Train Loss: 0.2089908 Vali Loss: 0.2057126 Test Loss: 0.2409256
Validation loss decreased (0.206964 --> 0.205713).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2073049
	speed: 1.8971s/iter; left time: 20452.4217s
Epoch: 21 cost time: 106.85869574546814
Epoch: 21, Steps: 136 | Train Loss: 0.2073983 Vali Loss: 0.2044757 Test Loss: 0.2396742
Validation loss decreased (0.205713 --> 0.204476).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1969656
	speed: 2.0284s/iter; left time: 21592.8016s
Epoch: 22 cost time: 112.29960656166077
Epoch: 22, Steps: 136 | Train Loss: 0.2061411 Vali Loss: 0.2030418 Test Loss: 0.2385013
Validation loss decreased (0.204476 --> 0.203042).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2094429
	speed: 1.9199s/iter; left time: 20176.1481s
Epoch: 23 cost time: 109.83487844467163
Epoch: 23, Steps: 136 | Train Loss: 0.2048423 Vali Loss: 0.2025000 Test Loss: 0.2374836
Validation loss decreased (0.203042 --> 0.202500).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2010459
	speed: 1.8523s/iter; left time: 19213.6278s
Epoch: 24 cost time: 109.67851567268372
Epoch: 24, Steps: 136 | Train Loss: 0.2037276 Vali Loss: 0.2015289 Test Loss: 0.2365910
Validation loss decreased (0.202500 --> 0.201529).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1914442
	speed: 1.9132s/iter; left time: 19585.6361s
Epoch: 25 cost time: 106.0438961982727
Epoch: 25, Steps: 136 | Train Loss: 0.2028605 Vali Loss: 0.2005975 Test Loss: 0.2357443
Validation loss decreased (0.201529 --> 0.200598).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2018380
	speed: 1.8308s/iter; left time: 18493.3760s
Epoch: 26 cost time: 102.82833480834961
Epoch: 26, Steps: 136 | Train Loss: 0.2019131 Vali Loss: 0.1998313 Test Loss: 0.2349926
Validation loss decreased (0.200598 --> 0.199831).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1971111
	speed: 1.8440s/iter; left time: 18375.8517s
Epoch: 27 cost time: 105.02109861373901
Epoch: 27, Steps: 136 | Train Loss: 0.2012780 Vali Loss: 0.1993517 Test Loss: 0.2343004
Validation loss decreased (0.199831 --> 0.199352).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2013357
	speed: 1.8310s/iter; left time: 17996.4294s
Epoch: 28 cost time: 103.72740197181702
Epoch: 28, Steps: 136 | Train Loss: 0.2005438 Vali Loss: 0.1992051 Test Loss: 0.2336577
Validation loss decreased (0.199352 --> 0.199205).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1919399
	speed: 1.7535s/iter; left time: 16996.9959s
Epoch: 29 cost time: 98.66294622421265
Epoch: 29, Steps: 136 | Train Loss: 0.1999778 Vali Loss: 0.1983825 Test Loss: 0.2330887
Validation loss decreased (0.199205 --> 0.198383).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1965520
	speed: 1.7527s/iter; left time: 16750.4012s
Epoch: 30 cost time: 104.15466642379761
Epoch: 30, Steps: 136 | Train Loss: 0.1993522 Vali Loss: 0.1980619 Test Loss: 0.2326167
Validation loss decreased (0.198383 --> 0.198062).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1993722
	speed: 1.7825s/iter; left time: 16792.6109s
Epoch: 31 cost time: 101.96201252937317
Epoch: 31, Steps: 136 | Train Loss: 0.1989235 Vali Loss: 0.1975421 Test Loss: 0.2321784
Validation loss decreased (0.198062 --> 0.197542).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1923263
	speed: 1.8611s/iter; left time: 17280.2256s
Epoch: 32 cost time: 103.00198268890381
Epoch: 32, Steps: 136 | Train Loss: 0.1984077 Vali Loss: 0.1974732 Test Loss: 0.2317513
Validation loss decreased (0.197542 --> 0.197473).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2126133
	speed: 1.7804s/iter; left time: 16289.3297s
Epoch: 33 cost time: 101.52692437171936
Epoch: 33, Steps: 136 | Train Loss: 0.1979785 Vali Loss: 0.1968319 Test Loss: 0.2313515
Validation loss decreased (0.197473 --> 0.196832).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2016307
	speed: 1.8239s/iter; left time: 16438.7823s
Epoch: 34 cost time: 104.51530694961548
Epoch: 34, Steps: 136 | Train Loss: 0.1976071 Vali Loss: 0.1965369 Test Loss: 0.2310055
Validation loss decreased (0.196832 --> 0.196537).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2008727
	speed: 1.9615s/iter; left time: 17412.0346s
Epoch: 35 cost time: 111.51099395751953
Epoch: 35, Steps: 136 | Train Loss: 0.1973416 Vali Loss: 0.1965482 Test Loss: 0.2307009
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1910881
	speed: 2.0606s/iter; left time: 18011.9237s
Epoch: 36 cost time: 122.6961145401001
Epoch: 36, Steps: 136 | Train Loss: 0.1969884 Vali Loss: 0.1962268 Test Loss: 0.2304082
Validation loss decreased (0.196537 --> 0.196227).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1985641
	speed: 2.1004s/iter; left time: 18073.5151s
Epoch: 37 cost time: 118.14423823356628
Epoch: 37, Steps: 136 | Train Loss: 0.1967254 Vali Loss: 0.1958136 Test Loss: 0.2301452
Validation loss decreased (0.196227 --> 0.195814).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2000924
	speed: 1.9311s/iter; left time: 16354.1236s
Epoch: 38 cost time: 111.04097056388855
Epoch: 38, Steps: 136 | Train Loss: 0.1964674 Vali Loss: 0.1955057 Test Loss: 0.2299016
Validation loss decreased (0.195814 --> 0.195506).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2009906
	speed: 1.9934s/iter; left time: 16610.7243s
Epoch: 39 cost time: 108.11265754699707
Epoch: 39, Steps: 136 | Train Loss: 0.1962079 Vali Loss: 0.1955056 Test Loss: 0.2296886
Validation loss decreased (0.195506 --> 0.195506).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1900392
	speed: 1.9600s/iter; left time: 16066.3841s
Epoch: 40 cost time: 109.40117692947388
Epoch: 40, Steps: 136 | Train Loss: 0.1959963 Vali Loss: 0.1954524 Test Loss: 0.2294827
Validation loss decreased (0.195506 --> 0.195452).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2002643
	speed: 1.9829s/iter; left time: 15984.1159s
Epoch: 41 cost time: 113.20103240013123
Epoch: 41, Steps: 136 | Train Loss: 0.1958672 Vali Loss: 0.1952204 Test Loss: 0.2292803
Validation loss decreased (0.195452 --> 0.195220).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1962250
	speed: 1.9126s/iter; left time: 15157.1835s
Epoch: 42 cost time: 110.32097434997559
Epoch: 42, Steps: 136 | Train Loss: 0.1955860 Vali Loss: 0.1951233 Test Loss: 0.2291194
Validation loss decreased (0.195220 --> 0.195123).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1950897
	speed: 1.8435s/iter; left time: 14359.1219s
Epoch: 43 cost time: 107.71685266494751
Epoch: 43, Steps: 136 | Train Loss: 0.1954970 Vali Loss: 0.1950192 Test Loss: 0.2289569
Validation loss decreased (0.195123 --> 0.195019).  Saving model ...
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1994232
	speed: 1.8981s/iter; left time: 14526.4388s
Epoch: 44 cost time: 106.52329397201538
Epoch: 44, Steps: 136 | Train Loss: 0.1952632 Vali Loss: 0.1946272 Test Loss: 0.2288024
Validation loss decreased (0.195019 --> 0.194627).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1909028
	speed: 1.9662s/iter; left time: 14780.2344s
Epoch: 45 cost time: 110.19229698181152
Epoch: 45, Steps: 136 | Train Loss: 0.1952349 Vali Loss: 0.1949763 Test Loss: 0.2286775
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2032521
	speed: 2.0391s/iter; left time: 15050.3706s
Epoch: 46 cost time: 112.13455724716187
Epoch: 46, Steps: 136 | Train Loss: 0.1950123 Vali Loss: 0.1946173 Test Loss: 0.2285505
Validation loss decreased (0.194627 --> 0.194617).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1964547
	speed: 1.9318s/iter; left time: 13995.8279s
Epoch: 47 cost time: 114.79241871833801
Epoch: 47, Steps: 136 | Train Loss: 0.1949827 Vali Loss: 0.1944976 Test Loss: 0.2284266
Validation loss decreased (0.194617 --> 0.194498).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2078825
	speed: 1.9996s/iter; left time: 14215.0175s
Epoch: 48 cost time: 112.05121684074402
Epoch: 48, Steps: 136 | Train Loss: 0.1948968 Vali Loss: 0.1946398 Test Loss: 0.2283163
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1947605
	speed: 1.9176s/iter; left time: 13371.3584s
Epoch: 49 cost time: 112.73331665992737
Epoch: 49, Steps: 136 | Train Loss: 0.1947773 Vali Loss: 0.1943932 Test Loss: 0.2282156
Validation loss decreased (0.194498 --> 0.194393).  Saving model ...
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2008020
	speed: 2.0627s/iter; left time: 14102.6125s
Epoch: 50 cost time: 116.34791588783264
Epoch: 50, Steps: 136 | Train Loss: 0.1946507 Vali Loss: 0.1944604 Test Loss: 0.2281337
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1952225
	speed: 1.9031s/iter; left time: 12752.6272s
Epoch: 51 cost time: 111.10940408706665
Epoch: 51, Steps: 136 | Train Loss: 0.1944600 Vali Loss: 0.1943015 Test Loss: 0.2280337
Validation loss decreased (0.194393 --> 0.194301).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1933580
	speed: 1.9885s/iter; left time: 13054.5906s
Epoch: 52 cost time: 111.2332010269165
Epoch: 52, Steps: 136 | Train Loss: 0.1945634 Vali Loss: 0.1947134 Test Loss: 0.2279616
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1904101
	speed: 1.9381s/iter; left time: 12460.2903s
Epoch: 53 cost time: 102.56254863739014
Epoch: 53, Steps: 136 | Train Loss: 0.1944244 Vali Loss: 0.1945329 Test Loss: 0.2278742
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1900109
	speed: 1.7026s/iter; left time: 10714.3060s
Epoch: 54 cost time: 93.54260563850403
Epoch: 54, Steps: 136 | Train Loss: 0.1944421 Vali Loss: 0.1942755 Test Loss: 0.2278154
Validation loss decreased (0.194301 --> 0.194276).  Saving model ...
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1897750
	speed: 1.5976s/iter; left time: 9836.2622s
Epoch: 55 cost time: 94.22531390190125
Epoch: 55, Steps: 136 | Train Loss: 0.1942491 Vali Loss: 0.1942283 Test Loss: 0.2277530
Validation loss decreased (0.194276 --> 0.194228).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1872589
	speed: 1.6301s/iter; left time: 9814.5914s
Epoch: 56 cost time: 95.7737512588501
Epoch: 56, Steps: 136 | Train Loss: 0.1942602 Vali Loss: 0.1943041 Test Loss: 0.2277024
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.1945093
	speed: 1.5569s/iter; left time: 9162.0866s
Epoch: 57 cost time: 89.28670692443848
Epoch: 57, Steps: 136 | Train Loss: 0.1941854 Vali Loss: 0.1940361 Test Loss: 0.2276492
Validation loss decreased (0.194228 --> 0.194036).  Saving model ...
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1830372
	speed: 1.7836s/iter; left time: 10253.6776s
Epoch: 58 cost time: 109.21716547012329
Epoch: 58, Steps: 136 | Train Loss: 0.1941632 Vali Loss: 0.1945640 Test Loss: 0.2275942
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1886217
	speed: 1.9622s/iter; left time: 11013.9642s
Epoch: 59 cost time: 110.18981409072876
Epoch: 59, Steps: 136 | Train Loss: 0.1941496 Vali Loss: 0.1943187 Test Loss: 0.2275514
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1996882
	speed: 1.8985s/iter; left time: 10398.0679s
Epoch: 60 cost time: 103.92674279212952
Epoch: 60, Steps: 136 | Train Loss: 0.1940893 Vali Loss: 0.1944027 Test Loss: 0.2275070
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1966993
	speed: 1.8086s/iter; left time: 9659.9931s
Epoch: 61 cost time: 98.89333081245422
Epoch: 61, Steps: 136 | Train Loss: 0.1940082 Vali Loss: 0.1942552 Test Loss: 0.2274584
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1929424
	speed: 1.7142s/iter; left time: 8922.6453s
Epoch: 62 cost time: 92.12053608894348
Epoch: 62, Steps: 136 | Train Loss: 0.1940456 Vali Loss: 0.1942885 Test Loss: 0.2274214
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1870898
	speed: 1.7449s/iter; left time: 8844.8879s
Epoch: 63 cost time: 100.07661461830139
Epoch: 63, Steps: 136 | Train Loss: 0.1939833 Vali Loss: 0.1942583 Test Loss: 0.2273872
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1981722
	speed: 1.7539s/iter; left time: 8652.0098s
Epoch: 64 cost time: 99.01474046707153
Epoch: 64, Steps: 136 | Train Loss: 0.1939529 Vali Loss: 0.1941100 Test Loss: 0.2273549
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.2076813
	speed: 1.7620s/iter; left time: 8452.2228s
Epoch: 65 cost time: 102.09142351150513
Epoch: 65, Steps: 136 | Train Loss: 0.1939715 Vali Loss: 0.1941224 Test Loss: 0.2273235
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.1881633
	speed: 1.7291s/iter; left time: 8059.4162s
Epoch: 66 cost time: 95.9846408367157
Epoch: 66, Steps: 136 | Train Loss: 0.1939690 Vali Loss: 0.1941120 Test Loss: 0.2273020
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.2063059
	speed: 1.7601s/iter; left time: 7964.6532s
Epoch: 67 cost time: 115.92342758178711
Epoch: 67, Steps: 136 | Train Loss: 0.1938650 Vali Loss: 0.1939440 Test Loss: 0.2272720
Validation loss decreased (0.194036 --> 0.193944).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.1862911
	speed: 2.0511s/iter; left time: 9002.0619s
Epoch: 68 cost time: 110.26319360733032
Epoch: 68, Steps: 136 | Train Loss: 0.1939259 Vali Loss: 0.1939450 Test Loss: 0.2272496
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.1948529
	speed: 1.9828s/iter; left time: 8433.0321s
Epoch: 69 cost time: 111.6257438659668
Epoch: 69, Steps: 136 | Train Loss: 0.1938793 Vali Loss: 0.1942066 Test Loss: 0.2272243
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.2094898
	speed: 1.9664s/iter; left time: 8095.4781s
Epoch: 70 cost time: 110.06854438781738
Epoch: 70, Steps: 136 | Train Loss: 0.1938903 Vali Loss: 0.1943892 Test Loss: 0.2272016
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.1969064
	speed: 1.8771s/iter; left time: 7472.8151s
Epoch: 71 cost time: 106.47421288490295
Epoch: 71, Steps: 136 | Train Loss: 0.1938250 Vali Loss: 0.1939160 Test Loss: 0.2271881
Validation loss decreased (0.193944 --> 0.193916).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.1988326
	speed: 2.0222s/iter; left time: 7775.2276s
Epoch: 72 cost time: 114.30099487304688
Epoch: 72, Steps: 136 | Train Loss: 0.1937666 Vali Loss: 0.1941475 Test Loss: 0.2271658
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.1947670
	speed: 1.9592s/iter; left time: 7266.6406s
Epoch: 73 cost time: 113.33575391769409
Epoch: 73, Steps: 136 | Train Loss: 0.1938344 Vali Loss: 0.1936697 Test Loss: 0.2271498
Validation loss decreased (0.193916 --> 0.193670).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.1956941
	speed: 1.9132s/iter; left time: 6836.0411s
Epoch: 74 cost time: 106.31869602203369
Epoch: 74, Steps: 136 | Train Loss: 0.1938253 Vali Loss: 0.1946663 Test Loss: 0.2271370
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.1911032
	speed: 1.8978s/iter; left time: 6522.7399s
Epoch: 75 cost time: 106.53666710853577
Epoch: 75, Steps: 136 | Train Loss: 0.1937235 Vali Loss: 0.1939169 Test Loss: 0.2271163
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.1958757
	speed: 1.6476s/iter; left time: 5438.6109s
Epoch: 76 cost time: 71.26530981063843
Epoch: 76, Steps: 136 | Train Loss: 0.1937375 Vali Loss: 0.1941446 Test Loss: 0.2271051
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.1975360
	speed: 1.2416s/iter; left time: 3929.5895s
Epoch: 77 cost time: 71.695321559906
Epoch: 77, Steps: 136 | Train Loss: 0.1937943 Vali Loss: 0.1940033 Test Loss: 0.2270882
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.1834113
	speed: 1.2530s/iter; left time: 3795.2249s
Epoch: 78 cost time: 70.70848369598389
Epoch: 78, Steps: 136 | Train Loss: 0.1937025 Vali Loss: 0.1937637 Test Loss: 0.2270757
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.1980743
	speed: 1.2649s/iter; left time: 3659.2851s
Epoch: 79 cost time: 71.48393058776855
Epoch: 79, Steps: 136 | Train Loss: 0.1938248 Vali Loss: 0.1939898 Test Loss: 0.2270646
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.1955570
	speed: 1.2031s/iter; left time: 3316.8220s
Epoch: 80 cost time: 68.51746010780334
Epoch: 80, Steps: 136 | Train Loss: 0.1937799 Vali Loss: 0.1942693 Test Loss: 0.2270537
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.2025279
	speed: 1.1965s/iter; left time: 3136.1498s
Epoch: 81 cost time: 67.58415842056274
Epoch: 81, Steps: 136 | Train Loss: 0.1937875 Vali Loss: 0.1940849 Test Loss: 0.2270430
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.1910211
	speed: 1.1423s/iter; left time: 2838.5247s
Epoch: 82 cost time: 57.13507676124573
Epoch: 82, Steps: 136 | Train Loss: 0.1936840 Vali Loss: 0.1940393 Test Loss: 0.2270359
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.1863468
	speed: 1.0645s/iter; left time: 2500.5890s
Epoch: 83 cost time: 64.75803017616272
Epoch: 83, Steps: 136 | Train Loss: 0.1937584 Vali Loss: 0.1942109 Test Loss: 0.2270268
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.1886498
	speed: 1.1512s/iter; left time: 2547.5081s
Epoch: 84 cost time: 69.31028604507446
Epoch: 84, Steps: 136 | Train Loss: 0.1936790 Vali Loss: 0.1939315 Test Loss: 0.2270165
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.1939173
	speed: 1.2933s/iter; left time: 2686.1933s
Epoch: 85 cost time: 74.31596899032593
Epoch: 85, Steps: 136 | Train Loss: 0.1937069 Vali Loss: 0.1943008 Test Loss: 0.2270103
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.1951685
	speed: 1.1904s/iter; left time: 2310.5084s
Epoch: 86 cost time: 70.6171772480011
Epoch: 86, Steps: 136 | Train Loss: 0.1937078 Vali Loss: 0.1940692 Test Loss: 0.2270016
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.1975630
	speed: 1.2932s/iter; left time: 2334.2184s
Epoch: 87 cost time: 73.83541178703308
Epoch: 87, Steps: 136 | Train Loss: 0.1937117 Vali Loss: 0.1940381 Test Loss: 0.2269940
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.1965774
	speed: 1.2276s/iter; left time: 2048.9076s
Epoch: 88 cost time: 67.05815649032593
Epoch: 88, Steps: 136 | Train Loss: 0.1936861 Vali Loss: 0.1941065 Test Loss: 0.2269904
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.1878835
	speed: 1.1473s/iter; left time: 1758.8755s
Epoch: 89 cost time: 58.92099189758301
Epoch: 89, Steps: 136 | Train Loss: 0.1937004 Vali Loss: 0.1939035 Test Loss: 0.2269841
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.1945342
	speed: 1.0475s/iter; left time: 1463.3705s
Epoch: 90 cost time: 58.166181802749634
Epoch: 90, Steps: 136 | Train Loss: 0.1937191 Vali Loss: 0.1939878 Test Loss: 0.2269756
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.204402478767869e-06
	iters: 100, epoch: 91 | loss: 0.1862191
	speed: 0.9261s/iter; left time: 1167.7724s
Epoch: 91 cost time: 58.25275683403015
Epoch: 91, Steps: 136 | Train Loss: 0.1936587 Vali Loss: 0.1942991 Test Loss: 0.2269730
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.944182354829475e-06
	iters: 100, epoch: 92 | loss: 0.1838025
	speed: 1.4308s/iter; left time: 1609.6321s
Epoch: 92 cost time: 83.55297923088074
Epoch: 92, Steps: 136 | Train Loss: 0.1936587 Vali Loss: 0.1941181 Test Loss: 0.2269670
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.696973237088e-06
	iters: 100, epoch: 93 | loss: 0.2032830
	speed: 1.4598s/iter; left time: 1443.7095s
Epoch: 93 cost time: 80.26274061203003
Epoch: 93, Steps: 136 | Train Loss: 0.1936557 Vali Loss: 0.1942533 Test Loss: 0.2269610
EarlyStopping counter: 20 out of 20
Early stopping
train 17513
val 1913
test 4541
Model(
  (freq_upsampler): Linear(in_features=74, out_features=370, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1124989440.0
params:  27750.0
Trainable parameters:  27750
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2428803
	speed: 0.6224s/iter; left time: 8403.1340s
Epoch: 1 cost time: 84.09070467948914
Epoch: 1, Steps: 136 | Train Loss: 0.2394758 Vali Loss: 0.1937765 Test Loss: 0.2262411
Validation loss decreased (inf --> 0.193776).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2418468
	speed: 1.4323s/iter; left time: 19143.1827s
Epoch: 2 cost time: 78.1091890335083
Epoch: 2, Steps: 136 | Train Loss: 0.2391226 Vali Loss: 0.1933320 Test Loss: 0.2261233
Validation loss decreased (0.193776 --> 0.193332).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2301636
	speed: 1.2597s/iter; left time: 16664.8527s
Epoch: 3 cost time: 69.35718703269958
Epoch: 3, Steps: 136 | Train Loss: 0.2391372 Vali Loss: 0.1935152 Test Loss: 0.2260917
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2371815
	speed: 1.1595s/iter; left time: 15181.4335s
Epoch: 4 cost time: 63.511983156204224
Epoch: 4, Steps: 136 | Train Loss: 0.2389911 Vali Loss: 0.1932250 Test Loss: 0.2261291
Validation loss decreased (0.193332 --> 0.193225).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2324515
	speed: 1.1280s/iter; left time: 14614.9667s
Epoch: 5 cost time: 65.12969708442688
Epoch: 5, Steps: 136 | Train Loss: 0.2390509 Vali Loss: 0.1934792 Test Loss: 0.2260265
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2366108
	speed: 1.1515s/iter; left time: 14763.2129s
Epoch: 6 cost time: 65.97468900680542
Epoch: 6, Steps: 136 | Train Loss: 0.2389627 Vali Loss: 0.1930645 Test Loss: 0.2260762
Validation loss decreased (0.193225 --> 0.193064).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2379322
	speed: 1.1714s/iter; left time: 14859.5455s
Epoch: 7 cost time: 65.33641171455383
Epoch: 7, Steps: 136 | Train Loss: 0.2388986 Vali Loss: 0.1932703 Test Loss: 0.2260584
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2244352
	speed: 1.1486s/iter; left time: 14414.3281s
Epoch: 8 cost time: 64.87273001670837
Epoch: 8, Steps: 136 | Train Loss: 0.2389465 Vali Loss: 0.1933265 Test Loss: 0.2260465
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2338943
	speed: 1.1219s/iter; left time: 13926.6736s
Epoch: 9 cost time: 63.83320617675781
Epoch: 9, Steps: 136 | Train Loss: 0.2389401 Vali Loss: 0.1927419 Test Loss: 0.2260390
Validation loss decreased (0.193064 --> 0.192742).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2387690
	speed: 1.1792s/iter; left time: 14477.3724s
Epoch: 10 cost time: 66.57260966300964
Epoch: 10, Steps: 136 | Train Loss: 0.2389384 Vali Loss: 0.1933899 Test Loss: 0.2260034
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2438641
	speed: 1.1306s/iter; left time: 13726.5134s
Epoch: 11 cost time: 62.15549683570862
Epoch: 11, Steps: 136 | Train Loss: 0.2387643 Vali Loss: 0.1930412 Test Loss: 0.2259967
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2449784
	speed: 1.0707s/iter; left time: 12853.2352s
Epoch: 12 cost time: 60.12801384925842
Epoch: 12, Steps: 136 | Train Loss: 0.2389298 Vali Loss: 0.1930613 Test Loss: 0.2260055
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2370521
	speed: 1.0792s/iter; left time: 12809.2069s
Epoch: 13 cost time: 60.54307246208191
Epoch: 13, Steps: 136 | Train Loss: 0.2388773 Vali Loss: 0.1932617 Test Loss: 0.2260179
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2450561
	speed: 1.0481s/iter; left time: 12296.8245s
Epoch: 14 cost time: 57.8793420791626
Epoch: 14, Steps: 136 | Train Loss: 0.2388697 Vali Loss: 0.1930734 Test Loss: 0.2259943
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2402429
	speed: 1.1194s/iter; left time: 12982.0826s
Epoch: 15 cost time: 63.97681736946106
Epoch: 15, Steps: 136 | Train Loss: 0.2388514 Vali Loss: 0.1931472 Test Loss: 0.2259921
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2223006
	speed: 1.1037s/iter; left time: 12649.8131s
Epoch: 16 cost time: 59.78100395202637
Epoch: 16, Steps: 136 | Train Loss: 0.2388633 Vali Loss: 0.1931627 Test Loss: 0.2259354
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2443061
	speed: 1.1048s/iter; left time: 12512.3801s
Epoch: 17 cost time: 62.90714240074158
Epoch: 17, Steps: 136 | Train Loss: 0.2387740 Vali Loss: 0.1932454 Test Loss: 0.2259653
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2411331
	speed: 1.1121s/iter; left time: 12443.2785s
Epoch: 18 cost time: 63.106945514678955
Epoch: 18, Steps: 136 | Train Loss: 0.2388541 Vali Loss: 0.1932661 Test Loss: 0.2259629
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2370509
	speed: 1.1030s/iter; left time: 12191.8029s
Epoch: 19 cost time: 62.68195819854736
Epoch: 19, Steps: 136 | Train Loss: 0.2388550 Vali Loss: 0.1932602 Test Loss: 0.2260047
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2289084
	speed: 1.1072s/iter; left time: 12087.2999s
Epoch: 20 cost time: 64.71854758262634
Epoch: 20, Steps: 136 | Train Loss: 0.2387678 Vali Loss: 0.1929554 Test Loss: 0.2259539
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2490732
	speed: 1.1009s/iter; left time: 11868.9733s
Epoch: 21 cost time: 61.67014765739441
Epoch: 21, Steps: 136 | Train Loss: 0.2386857 Vali Loss: 0.1930552 Test Loss: 0.2259869
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2269859
	speed: 1.0976s/iter; left time: 11683.7662s
Epoch: 22 cost time: 60.63283944129944
Epoch: 22, Steps: 136 | Train Loss: 0.2388336 Vali Loss: 0.1928844 Test Loss: 0.2259738
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2429668
	speed: 1.0127s/iter; left time: 10642.7927s
Epoch: 23 cost time: 54.139190435409546
Epoch: 23, Steps: 136 | Train Loss: 0.2387749 Vali Loss: 0.1928767 Test Loss: 0.2260067
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2379790
	speed: 1.0399s/iter; left time: 10786.4096s
Epoch: 24 cost time: 64.03463697433472
Epoch: 24, Steps: 136 | Train Loss: 0.2388413 Vali Loss: 0.1931151 Test Loss: 0.2259718
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2316409
	speed: 1.0409s/iter; left time: 10655.4877s
Epoch: 25 cost time: 55.47122120857239
Epoch: 25, Steps: 136 | Train Loss: 0.2388367 Vali Loss: 0.1930729 Test Loss: 0.2259820
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2397039
	speed: 1.0228s/iter; left time: 10331.7740s
Epoch: 26 cost time: 56.6903018951416
Epoch: 26, Steps: 136 | Train Loss: 0.2387857 Vali Loss: 0.1927033 Test Loss: 0.2259666
Validation loss decreased (0.192742 --> 0.192703).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2430199
	speed: 0.9854s/iter; left time: 9819.9686s
Epoch: 27 cost time: 57.25285267829895
Epoch: 27, Steps: 136 | Train Loss: 0.2387646 Vali Loss: 0.1928829 Test Loss: 0.2259911
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2324542
	speed: 1.0414s/iter; left time: 10236.0433s
Epoch: 28 cost time: 56.31031537055969
Epoch: 28, Steps: 136 | Train Loss: 0.2388578 Vali Loss: 0.1930123 Test Loss: 0.2259682
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2317210
	speed: 1.0110s/iter; left time: 9799.3795s
Epoch: 29 cost time: 57.001630783081055
Epoch: 29, Steps: 136 | Train Loss: 0.2388004 Vali Loss: 0.1929663 Test Loss: 0.2259638
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2441381
	speed: 1.0308s/iter; left time: 9851.4176s
Epoch: 30 cost time: 55.08933091163635
Epoch: 30, Steps: 136 | Train Loss: 0.2386921 Vali Loss: 0.1931186 Test Loss: 0.2259542
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2377312
	speed: 1.0312s/iter; left time: 9714.9359s
Epoch: 31 cost time: 58.53555107116699
Epoch: 31, Steps: 136 | Train Loss: 0.2386566 Vali Loss: 0.1930204 Test Loss: 0.2259829
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2293902
	speed: 0.9760s/iter; left time: 9061.8915s
Epoch: 32 cost time: 53.508835792541504
Epoch: 32, Steps: 136 | Train Loss: 0.2388365 Vali Loss: 0.1929406 Test Loss: 0.2259341
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2335011
	speed: 1.2085s/iter; left time: 11056.4668s
Epoch: 33 cost time: 69.93358039855957
Epoch: 33, Steps: 136 | Train Loss: 0.2387765 Vali Loss: 0.1930027 Test Loss: 0.2259447
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2443808
	speed: 1.2111s/iter; left time: 10915.3202s
Epoch: 34 cost time: 70.97467494010925
Epoch: 34, Steps: 136 | Train Loss: 0.2387490 Vali Loss: 0.1927625 Test Loss: 0.2259413
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2409190
	speed: 1.2665s/iter; left time: 11242.8792s
Epoch: 35 cost time: 71.93691682815552
Epoch: 35, Steps: 136 | Train Loss: 0.2387389 Vali Loss: 0.1930770 Test Loss: 0.2259735
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2418365
	speed: 1.2778s/iter; left time: 11169.6382s
Epoch: 36 cost time: 70.75476241111755
Epoch: 36, Steps: 136 | Train Loss: 0.2387329 Vali Loss: 0.1929886 Test Loss: 0.2259464
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2454862
	speed: 1.2716s/iter; left time: 10941.7023s
Epoch: 37 cost time: 70.6428632736206
Epoch: 37, Steps: 136 | Train Loss: 0.2388223 Vali Loss: 0.1930842 Test Loss: 0.2259750
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2381144
	speed: 1.1367s/iter; left time: 9626.9299s
Epoch: 38 cost time: 60.462533473968506
Epoch: 38, Steps: 136 | Train Loss: 0.2386790 Vali Loss: 0.1926717 Test Loss: 0.2259598
Validation loss decreased (0.192703 --> 0.192672).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2484783
	speed: 1.1506s/iter; left time: 9587.6466s
Epoch: 39 cost time: 68.26058006286621
Epoch: 39, Steps: 136 | Train Loss: 0.2388476 Vali Loss: 0.1931283 Test Loss: 0.2259594
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2443137
	speed: 1.1223s/iter; left time: 9199.7266s
Epoch: 40 cost time: 63.82945108413696
Epoch: 40, Steps: 136 | Train Loss: 0.2387272 Vali Loss: 0.1927976 Test Loss: 0.2259696
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2425197
	speed: 1.1667s/iter; left time: 9405.0158s
Epoch: 41 cost time: 63.216031551361084
Epoch: 41, Steps: 136 | Train Loss: 0.2388035 Vali Loss: 0.1925384 Test Loss: 0.2259277
Validation loss decreased (0.192672 --> 0.192538).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2474208
	speed: 1.1252s/iter; left time: 8917.3358s
Epoch: 42 cost time: 65.82381463050842
Epoch: 42, Steps: 136 | Train Loss: 0.2387206 Vali Loss: 0.1931609 Test Loss: 0.2259430
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2284703
	speed: 1.1364s/iter; left time: 8851.2024s
Epoch: 43 cost time: 61.76877999305725
Epoch: 43, Steps: 136 | Train Loss: 0.2387969 Vali Loss: 0.1929030 Test Loss: 0.2259534
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2371452
	speed: 1.1475s/iter; left time: 8782.0000s
Epoch: 44 cost time: 64.96417331695557
Epoch: 44, Steps: 136 | Train Loss: 0.2385433 Vali Loss: 0.1927356 Test Loss: 0.2259446
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2322980
	speed: 1.2047s/iter; left time: 9055.9747s
Epoch: 45 cost time: 66.96173024177551
Epoch: 45, Steps: 136 | Train Loss: 0.2387746 Vali Loss: 0.1929112 Test Loss: 0.2259405
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2547151
	speed: 1.0347s/iter; left time: 7637.4650s
Epoch: 46 cost time: 54.767650842666626
Epoch: 46, Steps: 136 | Train Loss: 0.2386636 Vali Loss: 0.1929116 Test Loss: 0.2259465
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2448220
	speed: 1.0217s/iter; left time: 7402.1325s
Epoch: 47 cost time: 55.57607650756836
Epoch: 47, Steps: 136 | Train Loss: 0.2386591 Vali Loss: 0.1928765 Test Loss: 0.2259475
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2285569
	speed: 1.4287s/iter; left time: 10156.6333s
Epoch: 48 cost time: 87.44113636016846
Epoch: 48, Steps: 136 | Train Loss: 0.2387771 Vali Loss: 0.1932354 Test Loss: 0.2259438
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2330101
	speed: 1.6194s/iter; left time: 11292.3219s
Epoch: 49 cost time: 88.78415966033936
Epoch: 49, Steps: 136 | Train Loss: 0.2387965 Vali Loss: 0.1928388 Test Loss: 0.2259504
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2467682
	speed: 1.6044s/iter; left time: 10969.5274s
Epoch: 50 cost time: 88.5617139339447
Epoch: 50, Steps: 136 | Train Loss: 0.2386430 Vali Loss: 0.1928346 Test Loss: 0.2259534
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2320650
	speed: 1.4517s/iter; left time: 9727.7297s
Epoch: 51 cost time: 81.7896978855133
Epoch: 51, Steps: 136 | Train Loss: 0.2387264 Vali Loss: 0.1930325 Test Loss: 0.2259471
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2285912
	speed: 1.4109s/iter; left time: 9262.4716s
Epoch: 52 cost time: 78.76716637611389
Epoch: 52, Steps: 136 | Train Loss: 0.2386138 Vali Loss: 0.1928494 Test Loss: 0.2259401
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2384538
	speed: 1.3352s/iter; left time: 8583.9430s
Epoch: 53 cost time: 77.28204321861267
Epoch: 53, Steps: 136 | Train Loss: 0.2387264 Vali Loss: 0.1929268 Test Loss: 0.2259340
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2408178
	speed: 1.3396s/iter; left time: 8430.0270s
Epoch: 54 cost time: 72.04682421684265
Epoch: 54, Steps: 136 | Train Loss: 0.2387066 Vali Loss: 0.1930647 Test Loss: 0.2259418
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2348408
	speed: 1.2922s/iter; left time: 7956.1618s
Epoch: 55 cost time: 72.02299189567566
Epoch: 55, Steps: 136 | Train Loss: 0.2385836 Vali Loss: 0.1928318 Test Loss: 0.2259408
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2351351
	speed: 1.2154s/iter; left time: 7318.0376s
Epoch: 56 cost time: 68.11163711547852
Epoch: 56, Steps: 136 | Train Loss: 0.2387461 Vali Loss: 0.1928975 Test Loss: 0.2259480
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2420806
	speed: 1.2415s/iter; left time: 7306.4470s
Epoch: 57 cost time: 68.98903799057007
Epoch: 57, Steps: 136 | Train Loss: 0.2387114 Vali Loss: 0.1926709 Test Loss: 0.2259409
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2432724
	speed: 1.1415s/iter; left time: 6562.4263s
Epoch: 58 cost time: 64.9754593372345
Epoch: 58, Steps: 136 | Train Loss: 0.2387790 Vali Loss: 0.1925950 Test Loss: 0.2259470
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2233281
	speed: 1.1593s/iter; left time: 6507.1006s
Epoch: 59 cost time: 67.62900996208191
Epoch: 59, Steps: 136 | Train Loss: 0.2385805 Vali Loss: 0.1928815 Test Loss: 0.2259457
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.2442843
	speed: 1.2371s/iter; left time: 6775.5795s
Epoch: 60 cost time: 71.26719641685486
Epoch: 60, Steps: 136 | Train Loss: 0.2386571 Vali Loss: 0.1930697 Test Loss: 0.2259358
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.2409548
	speed: 1.1024s/iter; left time: 5887.9564s
Epoch: 61 cost time: 60.500335454940796
Epoch: 61, Steps: 136 | Train Loss: 0.2387044 Vali Loss: 0.1931050 Test Loss: 0.2259385
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_180_j720_H8_FITS_custom_ftM_sl180_ll48_pl720_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
mse:0.22433407604694366, mae:0.30849170684814453, rse:0.47247084975242615, corr:[0.44514236 0.44866478 0.44910902 0.44932547 0.44918898 0.44927815
 0.44917727 0.44906363 0.4487923  0.44854918 0.4482038  0.44805753
 0.44779995 0.4476045  0.4475967  0.44744292 0.44745    0.44740286
 0.4473682  0.44737583 0.4474602  0.44750097 0.4479985  0.44800726
 0.44766888 0.44744015 0.4472642  0.4472282  0.44705886 0.44700065
 0.4468955  0.44669795 0.446552   0.4463785  0.44627127 0.4461812
 0.44600603 0.44586393 0.44590652 0.4458386  0.44579792 0.44577807
 0.44574195 0.44567293 0.4456745  0.44566578 0.44593638 0.44596937
 0.44578654 0.44577536 0.44572878 0.44566295 0.44549984 0.4454659
 0.4454209  0.44539127 0.44532043 0.44525877 0.4452317  0.4451187
 0.44509032 0.44498566 0.4449952  0.44495764 0.4449459  0.44489822
 0.44485277 0.44469118 0.44463584 0.44465044 0.44485041 0.4448898
 0.4447597  0.44476223 0.44460273 0.4446102  0.44455123 0.44450426
 0.44442743 0.44436863 0.44425818 0.4441853  0.44423845 0.44414642
 0.44420218 0.4440552  0.4440249  0.44403327 0.44404468 0.44398075
 0.4439595  0.44384623 0.443733   0.44380653 0.44395846 0.44395927
 0.44385523 0.44390586 0.4437484  0.44372317 0.44369522 0.44371918
 0.44375503 0.44372874 0.4436566  0.4435905  0.44365564 0.4436102
 0.4436465  0.44357798 0.44360858 0.44348636 0.4434158  0.44344866
 0.44339174 0.44322076 0.44308275 0.4430899  0.44326365 0.44338855
 0.44324234 0.4433484  0.44336694 0.44339615 0.44342184 0.44349483
 0.4435382  0.44348538 0.44348416 0.44347492 0.4435503  0.44354022
 0.44364363 0.4436225  0.44363883 0.44358897 0.44346225 0.4434894
 0.4435247  0.44355476 0.4436083  0.44369057 0.4439739  0.44416195
 0.44404623 0.44412833 0.4441356  0.4442081  0.44429824 0.44429725
 0.4442911  0.44439524 0.44448596 0.44452852 0.4446045  0.444591
 0.44484317 0.44494674 0.44491768 0.44491884 0.44483668 0.44500232
 0.4451808  0.44526252 0.44542357 0.4456624  0.44616598 0.4458386
 0.44503117 0.4445654  0.4442387  0.44388738 0.44364047 0.4434609
 0.4433049  0.4430931  0.44284934 0.44264632 0.4426183  0.44251245
 0.4424353  0.44231573 0.44232062 0.4423488  0.44234988 0.44237885
 0.44234812 0.4422155  0.4422038  0.4422598  0.44242585 0.44227752
 0.44191137 0.4417206  0.44154125 0.44141817 0.44125775 0.44115886
 0.4410639  0.44090456 0.44076613 0.44064593 0.44062987 0.44057018
 0.44065917 0.4405985  0.44062608 0.44061366 0.44059432 0.44064063
 0.4406119  0.4404278  0.44034448 0.44036567 0.44045877 0.44045183
 0.44027668 0.44021443 0.44016695 0.44009835 0.44000217 0.43998486
 0.43988243 0.43981192 0.43984088 0.43976164 0.43974432 0.4396933
 0.43968773 0.4396109  0.43968093 0.4396845  0.43964115 0.43962756
 0.43959665 0.43942127 0.4393195  0.43927205 0.43933466 0.4393271
 0.4392737  0.43930238 0.43916053 0.43918326 0.43911105 0.4390093
 0.4390076  0.4389845  0.4389703  0.4389508  0.4389897  0.43892783
 0.4389322  0.4388363  0.4388871  0.43892157 0.4388688  0.43884254
 0.43880892 0.43868938 0.43863678 0.43864182 0.4387038  0.43870142
 0.43856868 0.43855593 0.43853134 0.43860674 0.43856367 0.43854457
 0.4385345  0.4384876  0.438497   0.43846762 0.4385197  0.43853843
 0.43855417 0.4384333  0.43848243 0.43848738 0.4384735  0.43849742
 0.4383786  0.43824208 0.43820488 0.43816322 0.4382327  0.43831092
 0.4381801  0.43825382 0.43827766 0.43831336 0.4383476  0.43834442
 0.43839604 0.43843657 0.43837234 0.43843684 0.43856624 0.43858218
 0.4387281  0.4387696  0.4387814  0.43871477 0.43860415 0.43860537
 0.43859363 0.4385339  0.4386015  0.43862832 0.43878177 0.43897104
 0.43891138 0.43900082 0.43902946 0.43910983 0.43922043 0.43927395
 0.43931255 0.439434   0.4395186  0.43965822 0.43989906 0.44002837
 0.44030726 0.44048202 0.44044366 0.44037956 0.44033355 0.44047472
 0.4405862  0.4404935  0.4404779  0.44062358 0.4409744  0.4405888
 0.43989712 0.43949318 0.4391709  0.4389091  0.43864363 0.43843246
 0.43827486 0.4381256  0.43793738 0.4376724  0.43754554 0.4374831
 0.4374761  0.4373242  0.4372724  0.43728077 0.43728864 0.43729794
 0.43731856 0.4372432  0.4372172  0.43732086 0.43753818 0.43743584
 0.43703958 0.4368383  0.43669704 0.4366063  0.43640825 0.43626872
 0.43620253 0.4360866  0.435968   0.4358069  0.4357364  0.43564203
 0.43568113 0.43559414 0.43562263 0.43561384 0.43556765 0.4355511
 0.4355277  0.4354706  0.43544483 0.43549114 0.43562567 0.4356699
 0.43552527 0.4354629  0.43538597 0.43536854 0.4352827  0.43523422
 0.43521312 0.4351882  0.43509692 0.43498164 0.43503764 0.43497822
 0.43502986 0.4349877  0.43492788 0.4348501  0.43482432 0.4348608
 0.43488657 0.43475804 0.43462837 0.43471897 0.43484592 0.43485603
 0.43486172 0.4348442  0.43471888 0.43482372 0.4347751  0.43471956
 0.43480685 0.434725   0.43463597 0.43466598 0.43466794 0.43464896
 0.43474177 0.43460494 0.4345703  0.4345938  0.43455687 0.43456912
 0.43450227 0.43430984 0.4342731  0.4342483  0.4343629  0.43448162
 0.43438414 0.43443313 0.43438727 0.43435648 0.43431765 0.43432322
 0.43438265 0.43433338 0.4342351  0.4343114  0.434366   0.434281
 0.4343784  0.4342947  0.43429273 0.43433917 0.43430096 0.43430403
 0.43430084 0.43410468 0.43401176 0.43406332 0.4341492  0.43424094
 0.43419868 0.4343392  0.43440047 0.43440893 0.4343852  0.43445146
 0.43449634 0.43455395 0.43457615 0.43456173 0.43467513 0.43470225
 0.43480527 0.4347701  0.4346832  0.43463328 0.43466845 0.4346569
 0.4346247  0.43464386 0.43467203 0.43481123 0.4350943  0.43524483
 0.43522918 0.43534374 0.4353765  0.43549123 0.43556854 0.43562964
 0.43566036 0.43569374 0.43585193 0.43599394 0.4361772  0.4362927
 0.43646976 0.43657225 0.43645766 0.43642634 0.4363872  0.43648672
 0.43659818 0.43653506 0.43655276 0.4366609  0.43697274 0.4365442
 0.43583012 0.4353252  0.434907   0.43473116 0.43450695 0.43424365
 0.43404907 0.43388045 0.43367937 0.4334618  0.43341458 0.4333074
 0.4332939  0.43318573 0.4331307  0.43313155 0.43321022 0.4332134
 0.43318653 0.4331374  0.43309143 0.4331531  0.43333197 0.43308452
 0.43259487 0.4323965  0.43208945 0.43188715 0.43180478 0.43161434
 0.431458   0.43137354 0.43121898 0.43102068 0.43103534 0.4310506
 0.43111527 0.43100283 0.4310201  0.43099886 0.4309382  0.43100274
 0.43103153 0.4309651  0.4309552  0.43096644 0.43105048 0.43105498
 0.43081632 0.43060997 0.43046963 0.43041113 0.43031603 0.43018073
 0.43005896 0.42999342 0.4299837  0.4298548  0.4298341  0.4298499
 0.42979857 0.42964038 0.4296161  0.4295486  0.42949453 0.4294027
 0.42929122 0.4292397  0.42925066 0.4292747  0.42934665 0.42926177
 0.4290817  0.4291392  0.42908853 0.42909315 0.4291117  0.42899057
 0.4289036  0.42892122 0.42890725 0.42886218 0.42894834 0.42892015
 0.42893523 0.42892918 0.42892295 0.4288179  0.4287628  0.4287753
 0.4287414  0.42861846 0.42855692 0.42855316 0.42866632 0.4286431
 0.42843384 0.42844692 0.42843553 0.4283918  0.42834172 0.4283441
 0.42834535 0.4282926  0.4282687  0.42829916 0.42836773 0.4283972
 0.42847583 0.42840782 0.42840603 0.4284322  0.42842314 0.424229
 0.42419508 0.4282194  0.42392126 0.42387095 0.42392525 0.42397738
 0.42396593 0.42409113 0.42416465 0.42430297 0.42435974 0.42428866
 0.42431858 0.42441761 0.4243584  0.42444724 0.42463377 0.42463169
 0.4248546  0.42490324 0.42473003 0.42467928 0.4246718  0.42462105
 0.42464066 0.4246583  0.42466545 0.4247278  0.42499632 0.42514578
 0.42512983 0.4252222  0.42523766 0.42537215 0.42548758 0.42554346
 0.4255989  0.4257158  0.42578587 0.4259926  0.4262836  0.42646414
 0.42675185 0.42689085 0.4267892  0.4267723  0.42669567 0.42670834
 0.42685348 0.42678404 0.4268048  0.42693704 0.4272309  0.42680788
 0.4260531  0.4255384  0.42515174 0.4250013  0.42479426 0.42460713
 0.42440876 0.42418936 0.42398658 0.42376104 0.42371735 0.42362776
 0.4236617  0.42357832 0.4235061  0.423488   0.42349386 0.4234949
 0.4234797  0.42330322 0.4232611  0.42328072 0.42338347 0.42325854
 0.4227663  0.422538   0.42231658 0.42223316 0.4221197  0.4219643
 0.42185608 0.4216635  0.42154244 0.4214602  0.4214555  0.4213685
 0.42143744 0.42143515 0.4214307  0.42139366 0.42134503 0.4213171
 0.42124683 0.421013   0.42098674 0.42084482 0.42126942 0.42110553]
