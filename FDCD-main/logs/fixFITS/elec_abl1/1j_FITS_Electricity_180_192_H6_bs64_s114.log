Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=58, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_180_j192_H6', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=180, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_180_j192_H6_FITS_custom_ftM_sl180_ll48_pl192_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18041
val 2441
test 5069
Model(
  (freq_upsampler): Linear(in_features=58, out_features=119, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  283589376.0
params:  7021.0
Trainable parameters:  7021
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4947817
	speed: 0.5325s/iter; left time: 7402.3208s
Epoch: 1 cost time: 75.2746832370758
Epoch: 1, Steps: 140 | Train Loss: 0.7082907 Vali Loss: 0.3410000 Test Loss: 0.3729250
Validation loss decreased (inf --> 0.341000).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2791392
	speed: 1.1409s/iter; left time: 15699.2414s
Epoch: 2 cost time: 65.66802048683167
Epoch: 2, Steps: 140 | Train Loss: 0.3129935 Vali Loss: 0.2327090 Test Loss: 0.2572379
Validation loss decreased (0.341000 --> 0.232709).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2246982
	speed: 1.1264s/iter; left time: 15342.6798s
Epoch: 3 cost time: 69.05355048179626
Epoch: 3, Steps: 140 | Train Loss: 0.2438452 Vali Loss: 0.1969705 Test Loss: 0.2226995
Validation loss decreased (0.232709 --> 0.196971).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2284399
	speed: 1.1096s/iter; left time: 14958.0360s
Epoch: 4 cost time: 65.14519596099854
Epoch: 4, Steps: 140 | Train Loss: 0.2148338 Vali Loss: 0.1778549 Test Loss: 0.2046166
Validation loss decreased (0.196971 --> 0.177855).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1938394
	speed: 1.1038s/iter; left time: 14726.2217s
Epoch: 5 cost time: 67.97886109352112
Epoch: 5, Steps: 140 | Train Loss: 0.1987015 Vali Loss: 0.1667425 Test Loss: 0.1941204
Validation loss decreased (0.177855 --> 0.166743).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1875780
	speed: 1.0411s/iter; left time: 13743.5838s
Epoch: 6 cost time: 63.59293723106384
Epoch: 6, Steps: 140 | Train Loss: 0.1892087 Vali Loss: 0.1602504 Test Loss: 0.1878848
Validation loss decreased (0.166743 --> 0.160250).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1866724
	speed: 1.0749s/iter; left time: 14039.5772s
Epoch: 7 cost time: 64.6077139377594
Epoch: 7, Steps: 140 | Train Loss: 0.1835062 Vali Loss: 0.1564324 Test Loss: 0.1840616
Validation loss decreased (0.160250 --> 0.156432).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1782133
	speed: 1.0258s/iter; left time: 13254.0543s
Epoch: 8 cost time: 62.785422563552856
Epoch: 8, Steps: 140 | Train Loss: 0.1801500 Vali Loss: 0.1540097 Test Loss: 0.1815951
Validation loss decreased (0.156432 --> 0.154010).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1732184
	speed: 1.0485s/iter; left time: 13400.3204s
Epoch: 9 cost time: 63.49060130119324
Epoch: 9, Steps: 140 | Train Loss: 0.1778151 Vali Loss: 0.1523980 Test Loss: 0.1799817
Validation loss decreased (0.154010 --> 0.152398).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1817836
	speed: 1.0043s/iter; left time: 12695.6184s
Epoch: 10 cost time: 61.47620511054993
Epoch: 10, Steps: 140 | Train Loss: 0.1764159 Vali Loss: 0.1513530 Test Loss: 0.1788336
Validation loss decreased (0.152398 --> 0.151353).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1812559
	speed: 1.0345s/iter; left time: 12932.5081s
Epoch: 11 cost time: 62.80784010887146
Epoch: 11, Steps: 140 | Train Loss: 0.1753454 Vali Loss: 0.1505915 Test Loss: 0.1779913
Validation loss decreased (0.151353 --> 0.150592).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1646431
	speed: 1.0719s/iter; left time: 13250.3038s
Epoch: 12 cost time: 65.22850203514099
Epoch: 12, Steps: 140 | Train Loss: 0.1746082 Vali Loss: 0.1499216 Test Loss: 0.1773955
Validation loss decreased (0.150592 --> 0.149922).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1726450
	speed: 1.0414s/iter; left time: 12727.4225s
Epoch: 13 cost time: 63.61040544509888
Epoch: 13, Steps: 140 | Train Loss: 0.1740446 Vali Loss: 0.1494928 Test Loss: 0.1768730
Validation loss decreased (0.149922 --> 0.149493).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1734943
	speed: 1.0516s/iter; left time: 12704.1473s
Epoch: 14 cost time: 66.44388937950134
Epoch: 14, Steps: 140 | Train Loss: 0.1735936 Vali Loss: 0.1490435 Test Loss: 0.1764744
Validation loss decreased (0.149493 --> 0.149044).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1776267
	speed: 1.0447s/iter; left time: 12475.3185s
Epoch: 15 cost time: 60.161619901657104
Epoch: 15, Steps: 140 | Train Loss: 0.1730991 Vali Loss: 0.1487671 Test Loss: 0.1761446
Validation loss decreased (0.149044 --> 0.148767).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1793554
	speed: 1.1349s/iter; left time: 13393.4598s
Epoch: 16 cost time: 69.31151628494263
Epoch: 16, Steps: 140 | Train Loss: 0.1727636 Vali Loss: 0.1484089 Test Loss: 0.1758981
Validation loss decreased (0.148767 --> 0.148409).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1674836
	speed: 1.1298s/iter; left time: 13174.5846s
Epoch: 17 cost time: 68.035484790802
Epoch: 17, Steps: 140 | Train Loss: 0.1725647 Vali Loss: 0.1481992 Test Loss: 0.1756697
Validation loss decreased (0.148409 --> 0.148199).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1659785
	speed: 1.1520s/iter; left time: 13272.3009s
Epoch: 18 cost time: 68.4537501335144
Epoch: 18, Steps: 140 | Train Loss: 0.1723373 Vali Loss: 0.1479650 Test Loss: 0.1754952
Validation loss decreased (0.148199 --> 0.147965).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1734354
	speed: 1.0571s/iter; left time: 12030.8886s
Epoch: 19 cost time: 63.684624433517456
Epoch: 19, Steps: 140 | Train Loss: 0.1721347 Vali Loss: 0.1479213 Test Loss: 0.1753330
Validation loss decreased (0.147965 --> 0.147921).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1718477
	speed: 1.1165s/iter; left time: 12550.5240s
Epoch: 20 cost time: 65.75024509429932
Epoch: 20, Steps: 140 | Train Loss: 0.1719759 Vali Loss: 0.1476698 Test Loss: 0.1752061
Validation loss decreased (0.147921 --> 0.147670).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1761810
	speed: 1.0540s/iter; left time: 11699.9889s
Epoch: 21 cost time: 65.0907974243164
Epoch: 21, Steps: 140 | Train Loss: 0.1718773 Vali Loss: 0.1476241 Test Loss: 0.1750876
Validation loss decreased (0.147670 --> 0.147624).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1657655
	speed: 1.0573s/iter; left time: 11588.6403s
Epoch: 22 cost time: 63.78038811683655
Epoch: 22, Steps: 140 | Train Loss: 0.1718036 Vali Loss: 0.1474199 Test Loss: 0.1750189
Validation loss decreased (0.147624 --> 0.147420).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1712742
	speed: 1.0084s/iter; left time: 10911.9211s
Epoch: 23 cost time: 63.895580530166626
Epoch: 23, Steps: 140 | Train Loss: 0.1716561 Vali Loss: 0.1474240 Test Loss: 0.1749218
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1750330
	speed: 0.9612s/iter; left time: 10266.6482s
Epoch: 24 cost time: 54.70677900314331
Epoch: 24, Steps: 140 | Train Loss: 0.1715863 Vali Loss: 0.1473784 Test Loss: 0.1748445
Validation loss decreased (0.147420 --> 0.147378).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1660220
	speed: 1.0575s/iter; left time: 11146.7638s
Epoch: 25 cost time: 68.77078533172607
Epoch: 25, Steps: 140 | Train Loss: 0.1715942 Vali Loss: 0.1472441 Test Loss: 0.1748022
Validation loss decreased (0.147378 --> 0.147244).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1772471
	speed: 1.0851s/iter; left time: 11286.4830s
Epoch: 26 cost time: 64.70497608184814
Epoch: 26, Steps: 140 | Train Loss: 0.1714353 Vali Loss: 0.1472246 Test Loss: 0.1747454
Validation loss decreased (0.147244 --> 0.147225).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1835333
	speed: 1.0912s/iter; left time: 11197.1793s
Epoch: 27 cost time: 66.38591742515564
Epoch: 27, Steps: 140 | Train Loss: 0.1713204 Vali Loss: 0.1472054 Test Loss: 0.1747041
Validation loss decreased (0.147225 --> 0.147205).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1752473
	speed: 1.0788s/iter; left time: 10918.4180s
Epoch: 28 cost time: 63.144683837890625
Epoch: 28, Steps: 140 | Train Loss: 0.1713751 Vali Loss: 0.1471568 Test Loss: 0.1746723
Validation loss decreased (0.147205 --> 0.147157).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1646363
	speed: 1.0893s/iter; left time: 10872.2301s
Epoch: 29 cost time: 66.05845308303833
Epoch: 29, Steps: 140 | Train Loss: 0.1712720 Vali Loss: 0.1470891 Test Loss: 0.1746295
Validation loss decreased (0.147157 --> 0.147089).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1827469
	speed: 1.0403s/iter; left time: 10238.0553s
Epoch: 30 cost time: 64.33964276313782
Epoch: 30, Steps: 140 | Train Loss: 0.1713848 Vali Loss: 0.1470216 Test Loss: 0.1746029
Validation loss decreased (0.147089 --> 0.147022).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1720182
	speed: 1.0720s/iter; left time: 10399.9077s
Epoch: 31 cost time: 63.27078914642334
Epoch: 31, Steps: 140 | Train Loss: 0.1712348 Vali Loss: 0.1470019 Test Loss: 0.1745741
Validation loss decreased (0.147022 --> 0.147002).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1876035
	speed: 1.0505s/iter; left time: 10044.2916s
Epoch: 32 cost time: 63.108033418655396
Epoch: 32, Steps: 140 | Train Loss: 0.1712060 Vali Loss: 0.1469739 Test Loss: 0.1745494
Validation loss decreased (0.147002 --> 0.146974).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1840515
	speed: 1.0584s/iter; left time: 9970.8966s
Epoch: 33 cost time: 61.08567786216736
Epoch: 33, Steps: 140 | Train Loss: 0.1712640 Vali Loss: 0.1470018 Test Loss: 0.1745305
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1688546
	speed: 1.0044s/iter; left time: 9321.5517s
Epoch: 34 cost time: 65.01491618156433
Epoch: 34, Steps: 140 | Train Loss: 0.1711083 Vali Loss: 0.1469377 Test Loss: 0.1745142
Validation loss decreased (0.146974 --> 0.146938).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1671813
	speed: 1.0404s/iter; left time: 9510.6644s
Epoch: 35 cost time: 61.22513699531555
Epoch: 35, Steps: 140 | Train Loss: 0.1712333 Vali Loss: 0.1468815 Test Loss: 0.1744985
Validation loss decreased (0.146938 --> 0.146882).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1757404
	speed: 1.0318s/iter; left time: 9286.8531s
Epoch: 36 cost time: 63.16693663597107
Epoch: 36, Steps: 140 | Train Loss: 0.1711937 Vali Loss: 0.1468474 Test Loss: 0.1744815
Validation loss decreased (0.146882 --> 0.146847).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1627300
	speed: 1.0057s/iter; left time: 8911.8844s
Epoch: 37 cost time: 58.603281021118164
Epoch: 37, Steps: 140 | Train Loss: 0.1711106 Vali Loss: 0.1469740 Test Loss: 0.1744687
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1910506
	speed: 0.9832s/iter; left time: 8574.0650s
Epoch: 38 cost time: 59.199846506118774
Epoch: 38, Steps: 140 | Train Loss: 0.1711623 Vali Loss: 0.1468460 Test Loss: 0.1744507
Validation loss decreased (0.146847 --> 0.146846).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1800256
	speed: 0.9717s/iter; left time: 8337.8047s
Epoch: 39 cost time: 60.788182735443115
Epoch: 39, Steps: 140 | Train Loss: 0.1711160 Vali Loss: 0.1468513 Test Loss: 0.1744446
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1696988
	speed: 1.0555s/iter; left time: 8909.3770s
Epoch: 40 cost time: 61.640655755996704
Epoch: 40, Steps: 140 | Train Loss: 0.1711582 Vali Loss: 0.1468332 Test Loss: 0.1744251
Validation loss decreased (0.146846 --> 0.146833).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1775285
	speed: 0.9101s/iter; left time: 7554.6544s
Epoch: 41 cost time: 46.790385007858276
Epoch: 41, Steps: 140 | Train Loss: 0.1710732 Vali Loss: 0.1468154 Test Loss: 0.1744177
Validation loss decreased (0.146833 --> 0.146815).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1771644
	speed: 0.8289s/iter; left time: 6764.3307s
Epoch: 42 cost time: 48.08684468269348
Epoch: 42, Steps: 140 | Train Loss: 0.1710528 Vali Loss: 0.1468508 Test Loss: 0.1744132
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1726095
	speed: 0.7651s/iter; left time: 6136.5157s
Epoch: 43 cost time: 48.84408521652222
Epoch: 43, Steps: 140 | Train Loss: 0.1710871 Vali Loss: 0.1468781 Test Loss: 0.1744141
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1697582
	speed: 0.8292s/iter; left time: 6535.2197s
Epoch: 44 cost time: 47.21729898452759
Epoch: 44, Steps: 140 | Train Loss: 0.1711253 Vali Loss: 0.1467824 Test Loss: 0.1743968
Validation loss decreased (0.146815 --> 0.146782).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1792238
	speed: 0.8431s/iter; left time: 6526.2834s
Epoch: 45 cost time: 51.40827131271362
Epoch: 45, Steps: 140 | Train Loss: 0.1710229 Vali Loss: 0.1468128 Test Loss: 0.1743922
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1711243
	speed: 0.8657s/iter; left time: 6580.0929s
Epoch: 46 cost time: 49.855690479278564
Epoch: 46, Steps: 140 | Train Loss: 0.1710576 Vali Loss: 0.1467510 Test Loss: 0.1743858
Validation loss decreased (0.146782 --> 0.146751).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1727014
	speed: 0.8193s/iter; left time: 6112.7977s
Epoch: 47 cost time: 52.745909214019775
Epoch: 47, Steps: 140 | Train Loss: 0.1709631 Vali Loss: 0.1467734 Test Loss: 0.1743782
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1622088
	speed: 0.8066s/iter; left time: 5905.0994s
Epoch: 48 cost time: 47.30085754394531
Epoch: 48, Steps: 140 | Train Loss: 0.1710124 Vali Loss: 0.1468692 Test Loss: 0.1743695
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1673476
	speed: 0.7996s/iter; left time: 5742.2433s
Epoch: 49 cost time: 48.74904251098633
Epoch: 49, Steps: 140 | Train Loss: 0.1710052 Vali Loss: 0.1468061 Test Loss: 0.1743672
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1640139
	speed: 0.8249s/iter; left time: 5807.9240s
Epoch: 50 cost time: 47.64043664932251
Epoch: 50, Steps: 140 | Train Loss: 0.1710634 Vali Loss: 0.1467229 Test Loss: 0.1743648
Validation loss decreased (0.146751 --> 0.146723).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1684500
	speed: 0.7806s/iter; left time: 5387.1500s
Epoch: 51 cost time: 44.13690757751465
Epoch: 51, Steps: 140 | Train Loss: 0.1710024 Vali Loss: 0.1467836 Test Loss: 0.1743636
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1672852
	speed: 0.7601s/iter; left time: 5138.9602s
Epoch: 52 cost time: 49.023802042007446
Epoch: 52, Steps: 140 | Train Loss: 0.1710050 Vali Loss: 0.1468169 Test Loss: 0.1743520
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1706798
	speed: 0.8576s/iter; left time: 5678.0289s
Epoch: 53 cost time: 48.825209617614746
Epoch: 53, Steps: 140 | Train Loss: 0.1710689 Vali Loss: 0.1468073 Test Loss: 0.1743530
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1760053
	speed: 0.8397s/iter; left time: 5442.3800s
Epoch: 54 cost time: 49.815791606903076
Epoch: 54, Steps: 140 | Train Loss: 0.1710391 Vali Loss: 0.1467189 Test Loss: 0.1743499
Validation loss decreased (0.146723 --> 0.146719).  Saving model ...
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1659985
	speed: 0.8174s/iter; left time: 5183.1122s
Epoch: 55 cost time: 48.40975904464722
Epoch: 55, Steps: 140 | Train Loss: 0.1710172 Vali Loss: 0.1466873 Test Loss: 0.1743474
Validation loss decreased (0.146719 --> 0.146687).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1626378
	speed: 0.7555s/iter; left time: 4685.0614s
Epoch: 56 cost time: 44.86371827125549
Epoch: 56, Steps: 140 | Train Loss: 0.1709951 Vali Loss: 0.1467416 Test Loss: 0.1743441
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.1679750
	speed: 0.6795s/iter; left time: 4118.2602s
Epoch: 57 cost time: 38.775482177734375
Epoch: 57, Steps: 140 | Train Loss: 0.1709651 Vali Loss: 0.1467499 Test Loss: 0.1743442
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1748792
	speed: 0.6550s/iter; left time: 3878.2623s
Epoch: 58 cost time: 40.907849073410034
Epoch: 58, Steps: 140 | Train Loss: 0.1709769 Vali Loss: 0.1467847 Test Loss: 0.1743360
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1607088
	speed: 0.7030s/iter; left time: 4064.0319s
Epoch: 59 cost time: 42.31972932815552
Epoch: 59, Steps: 140 | Train Loss: 0.1709769 Vali Loss: 0.1467464 Test Loss: 0.1743311
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1761788
	speed: 0.6328s/iter; left time: 3569.7606s
Epoch: 60 cost time: 38.801714181900024
Epoch: 60, Steps: 140 | Train Loss: 0.1709304 Vali Loss: 0.1466233 Test Loss: 0.1743324
Validation loss decreased (0.146687 --> 0.146623).  Saving model ...
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1632900
	speed: 0.7369s/iter; left time: 4053.4658s
Epoch: 61 cost time: 43.068612813949585
Epoch: 61, Steps: 140 | Train Loss: 0.1709363 Vali Loss: 0.1467238 Test Loss: 0.1743295
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1626707
	speed: 0.6647s/iter; left time: 3563.2067s
Epoch: 62 cost time: 40.75813269615173
Epoch: 62, Steps: 140 | Train Loss: 0.1709667 Vali Loss: 0.1467132 Test Loss: 0.1743261
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1780915
	speed: 0.7219s/iter; left time: 3769.2499s
Epoch: 63 cost time: 41.128737926483154
Epoch: 63, Steps: 140 | Train Loss: 0.1710412 Vali Loss: 0.1467184 Test Loss: 0.1743225
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1690383
	speed: 0.6194s/iter; left time: 3147.1311s
Epoch: 64 cost time: 38.03097438812256
Epoch: 64, Steps: 140 | Train Loss: 0.1709577 Vali Loss: 0.1467079 Test Loss: 0.1743219
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.1696936
	speed: 0.6744s/iter; left time: 3332.1653s
Epoch: 65 cost time: 40.2615008354187
Epoch: 65, Steps: 140 | Train Loss: 0.1709822 Vali Loss: 0.1467340 Test Loss: 0.1743215
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.1799585
	speed: 0.6675s/iter; left time: 3204.8785s
Epoch: 66 cost time: 38.50955605506897
Epoch: 66, Steps: 140 | Train Loss: 0.1710003 Vali Loss: 0.1467102 Test Loss: 0.1743189
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.1836907
	speed: 0.6517s/iter; left time: 3037.5672s
Epoch: 67 cost time: 39.65804147720337
Epoch: 67, Steps: 140 | Train Loss: 0.1709271 Vali Loss: 0.1466536 Test Loss: 0.1743184
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.1734628
	speed: 0.6489s/iter; left time: 2933.5124s
Epoch: 68 cost time: 39.42885065078735
Epoch: 68, Steps: 140 | Train Loss: 0.1710048 Vali Loss: 0.1467464 Test Loss: 0.1743213
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.1754773
	speed: 0.6759s/iter; left time: 2961.0637s
Epoch: 69 cost time: 42.855661153793335
Epoch: 69, Steps: 140 | Train Loss: 0.1710152 Vali Loss: 0.1467106 Test Loss: 0.1743165
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.1711500
	speed: 0.7812s/iter; left time: 3313.1126s
Epoch: 70 cost time: 46.316062450408936
Epoch: 70, Steps: 140 | Train Loss: 0.1710030 Vali Loss: 0.1467561 Test Loss: 0.1743173
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.1727520
	speed: 0.7513s/iter; left time: 3081.1205s
Epoch: 71 cost time: 44.69135880470276
Epoch: 71, Steps: 140 | Train Loss: 0.1709964 Vali Loss: 0.1467647 Test Loss: 0.1743158
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.1601990
	speed: 0.6778s/iter; left time: 2684.9085s
Epoch: 72 cost time: 38.44625902175903
Epoch: 72, Steps: 140 | Train Loss: 0.1710205 Vali Loss: 0.1467348 Test Loss: 0.1743126
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.1722883
	speed: 0.7229s/iter; left time: 2762.2941s
Epoch: 73 cost time: 46.403111696243286
Epoch: 73, Steps: 140 | Train Loss: 0.1709398 Vali Loss: 0.1467448 Test Loss: 0.1743118
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.1639007
	speed: 0.7637s/iter; left time: 2811.3275s
Epoch: 74 cost time: 42.72810244560242
Epoch: 74, Steps: 140 | Train Loss: 0.1710104 Vali Loss: 0.1467275 Test Loss: 0.1743109
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.1668972
	speed: 0.7481s/iter; left time: 2649.1052s
Epoch: 75 cost time: 49.380720138549805
Epoch: 75, Steps: 140 | Train Loss: 0.1708969 Vali Loss: 0.1466986 Test Loss: 0.1743094
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.1776397
	speed: 0.7689s/iter; left time: 2615.0290s
Epoch: 76 cost time: 42.03421425819397
Epoch: 76, Steps: 140 | Train Loss: 0.1710010 Vali Loss: 0.1467321 Test Loss: 0.1743090
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.1711340
	speed: 0.7107s/iter; left time: 2317.7407s
Epoch: 77 cost time: 41.32866811752319
Epoch: 77, Steps: 140 | Train Loss: 0.1709338 Vali Loss: 0.1467044 Test Loss: 0.1743063
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.1816615
	speed: 0.6056s/iter; left time: 1889.9779s
Epoch: 78 cost time: 34.483370542526245
Epoch: 78, Steps: 140 | Train Loss: 0.1709384 Vali Loss: 0.1467148 Test Loss: 0.1743066
EarlyStopping counter: 18 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.1659904
	speed: 0.6045s/iter; left time: 1802.0898s
Epoch: 79 cost time: 36.584859132766724
Epoch: 79, Steps: 140 | Train Loss: 0.1709651 Vali Loss: 0.1467375 Test Loss: 0.1743053
EarlyStopping counter: 19 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.1677848
	speed: 0.5985s/iter; left time: 1700.2216s
Epoch: 80 cost time: 35.62564277648926
Epoch: 80, Steps: 140 | Train Loss: 0.1709724 Vali Loss: 0.1466935 Test Loss: 0.1743068
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_180_j192_H6_FITS_custom_ftM_sl180_ll48_pl192_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5069
mse:0.1716824322938919, mae:0.26632407307624817, rse:0.41196972131729126, corr:[0.4644209  0.4644165  0.46547297 0.46551383 0.4656289  0.46587223
 0.46589175 0.46539378 0.4652407  0.46527863 0.46469232 0.46443382
 0.46462527 0.4641645  0.46414158 0.46420264 0.4640074  0.4639819
 0.4640204  0.4639663  0.4639411  0.46414506 0.4647009  0.46466145
 0.4641879  0.46415165 0.46391004 0.4636623  0.46359324 0.46346357
 0.4633427  0.46316686 0.46299082 0.46296337 0.46271357 0.46242923
 0.46248648 0.4621995  0.46203643 0.46196154 0.4617765  0.46165425
 0.46160087 0.46154404 0.46147034 0.46148354 0.46175787 0.46181974
 0.46151108 0.46146998 0.4614049  0.46125266 0.46115583 0.46111915
 0.4611388  0.4610894  0.46099076 0.46104416 0.46102905 0.4608108
 0.46088704 0.46085984 0.46081045 0.46077442 0.460752   0.46073973
 0.46071333 0.4606181  0.46050802 0.460487   0.46063766 0.4606751
 0.46043497 0.4603348  0.46028042 0.4602785  0.46020705 0.46011367
 0.460147   0.46016768 0.46010852 0.46010625 0.46012622 0.46004805
 0.46006313 0.45999843 0.46001375 0.45998427 0.45997694 0.460002
 0.45994544 0.45980155 0.45966324 0.4596189  0.45972583 0.45972976
 0.45958945 0.45960212 0.45950937 0.4595305  0.45959777 0.45953703
 0.45953184 0.45955393 0.45952743 0.45953223 0.45949543 0.45946822
 0.45954055 0.459432   0.45947763 0.4594934  0.45940685 0.4594176
 0.4594344  0.45936775 0.4593096  0.45930198 0.4594226  0.4594788
 0.45936203 0.45951968 0.45954466 0.4595467  0.4596795  0.45974413
 0.45975283 0.4597494  0.45978296 0.45988968 0.45985025 0.4597501
 0.45993465 0.45996606 0.4599125  0.45992613 0.45988768 0.45984447
 0.45986032 0.45973873 0.4595826  0.4596258  0.45988402 0.46000278
 0.45986462 0.4599758  0.46011016 0.46017936 0.46025094 0.46031606
 0.46037376 0.4603965  0.46040842 0.46048728 0.4606099  0.46073893
 0.46099174 0.4612309  0.46120757 0.4611769  0.46128452 0.46132678
 0.4614458  0.4615179  0.46138233 0.4615211  0.46200687 0.4616536
 0.4609127  0.46039084 0.46007738 0.45989668 0.45958036 0.45923346
 0.4591136  0.45895675 0.45867392 0.45854622 0.45855537 0.45862103
 0.45872268 0.45864016 0.45874298 0.4587086  0.45846733 0.45826212
 0.45812845 0.45793092 0.45764455 0.4577448  0.45830965 0.45747498]
