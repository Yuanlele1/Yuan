Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_720_j336_H6', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_720_j336_H6_FITS_custom_ftM_sl720_ll48_pl336_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17357
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=196, out_features=287, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2311282176.0
params:  56539.0
Trainable parameters:  56539
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5263775
	speed: 0.8563s/iter; left time: 11475.6341s
Epoch: 1 cost time: 116.07073855400085
Epoch: 1, Steps: 135 | Train Loss: 0.7158294 Vali Loss: 0.3666847 Test Loss: 0.4394911
Validation loss decreased (inf --> 0.366685).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2978812
	speed: 1.8583s/iter; left time: 24652.7075s
Epoch: 2 cost time: 114.29038548469543
Epoch: 2, Steps: 135 | Train Loss: 0.3366854 Vali Loss: 0.2109792 Test Loss: 0.2560176
Validation loss decreased (0.366685 --> 0.210979).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2142593
	speed: 1.8850s/iter; left time: 24752.2331s
Epoch: 3 cost time: 112.07069993019104
Epoch: 3, Steps: 135 | Train Loss: 0.2254173 Vali Loss: 0.1639708 Test Loss: 0.1977203
Validation loss decreased (0.210979 --> 0.163971).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1865688
	speed: 1.8825s/iter; left time: 24464.7736s
Epoch: 4 cost time: 115.82709527015686
Epoch: 4, Steps: 135 | Train Loss: 0.1923313 Vali Loss: 0.1515774 Test Loss: 0.1812374
Validation loss decreased (0.163971 --> 0.151577).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1770294
	speed: 1.9016s/iter; left time: 24457.0452s
Epoch: 5 cost time: 113.09790110588074
Epoch: 5, Steps: 135 | Train Loss: 0.1834917 Vali Loss: 0.1489559 Test Loss: 0.1768084
Validation loss decreased (0.151577 --> 0.148956).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1794699
	speed: 1.8473s/iter; left time: 23508.3450s
Epoch: 6 cost time: 116.992356300354
Epoch: 6, Steps: 135 | Train Loss: 0.1809719 Vali Loss: 0.1481315 Test Loss: 0.1754320
Validation loss decreased (0.148956 --> 0.148132).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1907420
	speed: 1.8447s/iter; left time: 23226.1164s
Epoch: 7 cost time: 110.38274645805359
Epoch: 7, Steps: 135 | Train Loss: 0.1801194 Vali Loss: 0.1483063 Test Loss: 0.1748647
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1768782
	speed: 1.8466s/iter; left time: 23000.9609s
Epoch: 8 cost time: 111.66693234443665
Epoch: 8, Steps: 135 | Train Loss: 0.1796034 Vali Loss: 0.1478622 Test Loss: 0.1745418
Validation loss decreased (0.148132 --> 0.147862).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1874933
	speed: 1.8789s/iter; left time: 23150.4335s
Epoch: 9 cost time: 111.54010605812073
Epoch: 9, Steps: 135 | Train Loss: 0.1793891 Vali Loss: 0.1478266 Test Loss: 0.1743811
Validation loss decreased (0.147862 --> 0.147827).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1699293
	speed: 1.8405s/iter; left time: 22428.4923s
Epoch: 10 cost time: 113.31547999382019
Epoch: 10, Steps: 135 | Train Loss: 0.1791912 Vali Loss: 0.1478524 Test Loss: 0.1742212
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1702765
	speed: 1.8551s/iter; left time: 22355.8955s
Epoch: 11 cost time: 115.54886841773987
Epoch: 11, Steps: 135 | Train Loss: 0.1790616 Vali Loss: 0.1475413 Test Loss: 0.1741335
Validation loss decreased (0.147827 --> 0.147541).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1726989
	speed: 1.8939s/iter; left time: 22567.4570s
Epoch: 12 cost time: 113.54601407051086
Epoch: 12, Steps: 135 | Train Loss: 0.1789142 Vali Loss: 0.1478026 Test Loss: 0.1740656
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1821974
	speed: 1.8365s/iter; left time: 21635.5272s
Epoch: 13 cost time: 109.35539293289185
Epoch: 13, Steps: 135 | Train Loss: 0.1786826 Vali Loss: 0.1475385 Test Loss: 0.1740206
Validation loss decreased (0.147541 --> 0.147539).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1856833
	speed: 1.8490s/iter; left time: 21533.3292s
Epoch: 14 cost time: 110.56657838821411
Epoch: 14, Steps: 135 | Train Loss: 0.1787484 Vali Loss: 0.1478246 Test Loss: 0.1739605
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1696310
	speed: 1.8161s/iter; left time: 20905.3214s
Epoch: 15 cost time: 111.566823720932
Epoch: 15, Steps: 135 | Train Loss: 0.1786256 Vali Loss: 0.1473259 Test Loss: 0.1739427
Validation loss decreased (0.147539 --> 0.147326).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1714758
	speed: 1.8478s/iter; left time: 21020.4845s
Epoch: 16 cost time: 111.72139096260071
Epoch: 16, Steps: 135 | Train Loss: 0.1785324 Vali Loss: 0.1472874 Test Loss: 0.1739388
Validation loss decreased (0.147326 --> 0.147287).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1817904
	speed: 1.8356s/iter; left time: 20633.5362s
Epoch: 17 cost time: 112.73780035972595
Epoch: 17, Steps: 135 | Train Loss: 0.1785371 Vali Loss: 0.1471370 Test Loss: 0.1738751
Validation loss decreased (0.147287 --> 0.147137).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1752434
	speed: 1.7846s/iter; left time: 19820.2283s
Epoch: 18 cost time: 109.52871870994568
Epoch: 18, Steps: 135 | Train Loss: 0.1784425 Vali Loss: 0.1473232 Test Loss: 0.1738565
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1838714
	speed: 1.7881s/iter; left time: 19617.5932s
Epoch: 19 cost time: 105.899822473526
Epoch: 19, Steps: 135 | Train Loss: 0.1784347 Vali Loss: 0.1476162 Test Loss: 0.1738440
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1703733
	speed: 1.7739s/iter; left time: 19221.5950s
Epoch: 20 cost time: 110.20095252990723
Epoch: 20, Steps: 135 | Train Loss: 0.1783964 Vali Loss: 0.1475570 Test Loss: 0.1738141
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1676838
	speed: 1.7806s/iter; left time: 19054.4478s
Epoch: 21 cost time: 108.35791230201721
Epoch: 21, Steps: 135 | Train Loss: 0.1783283 Vali Loss: 0.1472636 Test Loss: 0.1738207
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1669545
	speed: 1.7939s/iter; left time: 18954.4853s
Epoch: 22 cost time: 112.02253437042236
Epoch: 22, Steps: 135 | Train Loss: 0.1783317 Vali Loss: 0.1474506 Test Loss: 0.1738339
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1848320
	speed: 1.8125s/iter; left time: 18906.6661s
Epoch: 23 cost time: 113.74038434028625
Epoch: 23, Steps: 135 | Train Loss: 0.1783104 Vali Loss: 0.1474193 Test Loss: 0.1737733
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1816235
	speed: 1.8324s/iter; left time: 18866.0535s
Epoch: 24 cost time: 107.5725154876709
Epoch: 24, Steps: 135 | Train Loss: 0.1783013 Vali Loss: 0.1472155 Test Loss: 0.1737859
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1673942
	speed: 1.8315s/iter; left time: 18609.3706s
Epoch: 25 cost time: 112.59933400154114
Epoch: 25, Steps: 135 | Train Loss: 0.1782192 Vali Loss: 0.1471498 Test Loss: 0.1737660
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1828578
	speed: 1.8485s/iter; left time: 18532.9869s
Epoch: 26 cost time: 112.13561654090881
Epoch: 26, Steps: 135 | Train Loss: 0.1782867 Vali Loss: 0.1473533 Test Loss: 0.1737529
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1704629
	speed: 1.8431s/iter; left time: 18230.0090s
Epoch: 27 cost time: 114.13867163658142
Epoch: 27, Steps: 135 | Train Loss: 0.1782889 Vali Loss: 0.1469335 Test Loss: 0.1737486
Validation loss decreased (0.147137 --> 0.146933).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1817105
	speed: 1.8346s/iter; left time: 17898.8452s
Epoch: 28 cost time: 112.16589713096619
Epoch: 28, Steps: 135 | Train Loss: 0.1782083 Vali Loss: 0.1473520 Test Loss: 0.1737436
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1773042
	speed: 1.8054s/iter; left time: 17369.3931s
Epoch: 29 cost time: 109.76172161102295
Epoch: 29, Steps: 135 | Train Loss: 0.1781794 Vali Loss: 0.1471891 Test Loss: 0.1737477
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1646392
	speed: 1.8646s/iter; left time: 17687.9290s
Epoch: 30 cost time: 111.91623067855835
Epoch: 30, Steps: 135 | Train Loss: 0.1781711 Vali Loss: 0.1469355 Test Loss: 0.1737522
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1797627
	speed: 1.8574s/iter; left time: 17368.7539s
Epoch: 31 cost time: 115.00473022460938
Epoch: 31, Steps: 135 | Train Loss: 0.1782409 Vali Loss: 0.1471054 Test Loss: 0.1737341
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1791013
	speed: 1.8695s/iter; left time: 17229.2326s
Epoch: 32 cost time: 116.63205814361572
Epoch: 32, Steps: 135 | Train Loss: 0.1781398 Vali Loss: 0.1473413 Test Loss: 0.1737112
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1730315
	speed: 1.8556s/iter; left time: 16850.9330s
Epoch: 33 cost time: 114.35673022270203
Epoch: 33, Steps: 135 | Train Loss: 0.1781266 Vali Loss: 0.1472164 Test Loss: 0.1736925
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1778655
	speed: 1.8127s/iter; left time: 16216.2904s
Epoch: 34 cost time: 109.34461212158203
Epoch: 34, Steps: 135 | Train Loss: 0.1781222 Vali Loss: 0.1470861 Test Loss: 0.1737080
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1832260
	speed: 1.8272s/iter; left time: 16099.2340s
Epoch: 35 cost time: 112.46612787246704
Epoch: 35, Steps: 135 | Train Loss: 0.1781770 Vali Loss: 0.1471179 Test Loss: 0.1736941
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1748805
	speed: 1.8510s/iter; left time: 16059.2282s
Epoch: 36 cost time: 115.3737723827362
Epoch: 36, Steps: 135 | Train Loss: 0.1781504 Vali Loss: 0.1471216 Test Loss: 0.1736858
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1724719
	speed: 1.8218s/iter; left time: 15560.3827s
Epoch: 37 cost time: 113.46089506149292
Epoch: 37, Steps: 135 | Train Loss: 0.1781660 Vali Loss: 0.1469711 Test Loss: 0.1736987
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1740409
	speed: 1.8768s/iter; left time: 15776.3716s
Epoch: 38 cost time: 115.43438792228699
Epoch: 38, Steps: 135 | Train Loss: 0.1781023 Vali Loss: 0.1471625 Test Loss: 0.1736952
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1692915
	speed: 1.8532s/iter; left time: 15327.6450s
Epoch: 39 cost time: 110.85364246368408
Epoch: 39, Steps: 135 | Train Loss: 0.1781061 Vali Loss: 0.1471010 Test Loss: 0.1736815
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1829651
	speed: 1.8625s/iter; left time: 15153.1643s
Epoch: 40 cost time: 113.05913281440735
Epoch: 40, Steps: 135 | Train Loss: 0.1779955 Vali Loss: 0.1471924 Test Loss: 0.1736756
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1777131
	speed: 1.8244s/iter; left time: 14596.7054s
Epoch: 41 cost time: 110.85783529281616
Epoch: 41, Steps: 135 | Train Loss: 0.1780728 Vali Loss: 0.1472036 Test Loss: 0.1736679
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1675753
	speed: 1.6771s/iter; left time: 13191.8545s
Epoch: 42 cost time: 96.78650283813477
Epoch: 42, Steps: 135 | Train Loss: 0.1780918 Vali Loss: 0.1471154 Test Loss: 0.1736752
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1821444
	speed: 1.3948s/iter; left time: 10783.3562s
Epoch: 43 cost time: 84.62283277511597
Epoch: 43, Steps: 135 | Train Loss: 0.1780731 Vali Loss: 0.1471475 Test Loss: 0.1736788
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1734388
	speed: 1.3523s/iter; left time: 10272.0404s
Epoch: 44 cost time: 82.40508723258972
Epoch: 44, Steps: 135 | Train Loss: 0.1780444 Vali Loss: 0.1470719 Test Loss: 0.1736663
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1869937
	speed: 1.3930s/iter; left time: 10393.3163s
Epoch: 45 cost time: 83.11366987228394
Epoch: 45, Steps: 135 | Train Loss: 0.1780634 Vali Loss: 0.1471300 Test Loss: 0.1736815
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1832703
	speed: 1.4011s/iter; left time: 10264.7214s
Epoch: 46 cost time: 86.183926820755
Epoch: 46, Steps: 135 | Train Loss: 0.1780574 Vali Loss: 0.1469067 Test Loss: 0.1736533
Validation loss decreased (0.146933 --> 0.146907).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1654976
	speed: 1.4306s/iter; left time: 10287.7221s
Epoch: 47 cost time: 89.57143568992615
Epoch: 47, Steps: 135 | Train Loss: 0.1780794 Vali Loss: 0.1470430 Test Loss: 0.1736742
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1801190
	speed: 1.3876s/iter; left time: 9791.0125s
Epoch: 48 cost time: 83.37188863754272
Epoch: 48, Steps: 135 | Train Loss: 0.1780956 Vali Loss: 0.1471026 Test Loss: 0.1736727
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1957171
	speed: 1.3685s/iter; left time: 9471.6788s
Epoch: 49 cost time: 81.86416935920715
Epoch: 49, Steps: 135 | Train Loss: 0.1780663 Vali Loss: 0.1471460 Test Loss: 0.1736695
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1736581
	speed: 1.4234s/iter; left time: 9659.1431s
Epoch: 50 cost time: 87.06457018852234
Epoch: 50, Steps: 135 | Train Loss: 0.1780275 Vali Loss: 0.1470105 Test Loss: 0.1736700
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1720253
	speed: 1.3247s/iter; left time: 8810.6268s
Epoch: 51 cost time: 71.43295645713806
Epoch: 51, Steps: 135 | Train Loss: 0.1780793 Vali Loss: 0.1471218 Test Loss: 0.1736692
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1846777
	speed: 1.0062s/iter; left time: 6556.4444s
Epoch: 52 cost time: 61.65580868721008
Epoch: 52, Steps: 135 | Train Loss: 0.1780497 Vali Loss: 0.1470586 Test Loss: 0.1736639
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1883152
	speed: 1.0080s/iter; left time: 6432.0962s
Epoch: 53 cost time: 61.180286169052124
Epoch: 53, Steps: 135 | Train Loss: 0.1780852 Vali Loss: 0.1469736 Test Loss: 0.1736634
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1769071
	speed: 0.9694s/iter; left time: 6054.6457s
Epoch: 54 cost time: 59.40206480026245
Epoch: 54, Steps: 135 | Train Loss: 0.1780367 Vali Loss: 0.1469365 Test Loss: 0.1736610
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1773753
	speed: 1.0075s/iter; left time: 6157.0345s
Epoch: 55 cost time: 59.01524901390076
Epoch: 55, Steps: 135 | Train Loss: 0.1780140 Vali Loss: 0.1470606 Test Loss: 0.1736574
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1729023
	speed: 1.0055s/iter; left time: 6008.6196s
Epoch: 56 cost time: 60.74358940124512
Epoch: 56, Steps: 135 | Train Loss: 0.1779447 Vali Loss: 0.1470728 Test Loss: 0.1736598
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.1745895
	speed: 0.9856s/iter; left time: 5756.8796s
Epoch: 57 cost time: 61.784308671951294
Epoch: 57, Steps: 135 | Train Loss: 0.1780001 Vali Loss: 0.1473544 Test Loss: 0.1736536
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1797269
	speed: 0.9953s/iter; left time: 5679.4042s
Epoch: 58 cost time: 61.0831093788147
Epoch: 58, Steps: 135 | Train Loss: 0.1779810 Vali Loss: 0.1469420 Test Loss: 0.1736523
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1750951
	speed: 0.9750s/iter; left time: 5431.7475s
Epoch: 59 cost time: 60.31185507774353
Epoch: 59, Steps: 135 | Train Loss: 0.1780322 Vali Loss: 0.1470871 Test Loss: 0.1736424
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1857378
	speed: 0.9810s/iter; left time: 5332.4591s
Epoch: 60 cost time: 57.63296818733215
Epoch: 60, Steps: 135 | Train Loss: 0.1780026 Vali Loss: 0.1470318 Test Loss: 0.1736495
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1799909
	speed: 0.9618s/iter; left time: 5098.5170s
Epoch: 61 cost time: 58.768479108810425
Epoch: 61, Steps: 135 | Train Loss: 0.1780477 Vali Loss: 0.1470305 Test Loss: 0.1736485
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1814620
	speed: 1.0113s/iter; left time: 5224.4901s
Epoch: 62 cost time: 62.003716468811035
Epoch: 62, Steps: 135 | Train Loss: 0.1780552 Vali Loss: 0.1470461 Test Loss: 0.1736428
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1855377
	speed: 1.0014s/iter; left time: 5038.2787s
Epoch: 63 cost time: 62.28893184661865
Epoch: 63, Steps: 135 | Train Loss: 0.1779190 Vali Loss: 0.1470810 Test Loss: 0.1736452
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1731063
	speed: 1.0082s/iter; left time: 4936.1852s
Epoch: 64 cost time: 63.43115448951721
Epoch: 64, Steps: 135 | Train Loss: 0.1780140 Vali Loss: 0.1470316 Test Loss: 0.1736536
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.1869668
	speed: 1.0686s/iter; left time: 5087.5408s
Epoch: 65 cost time: 64.3945083618164
Epoch: 65, Steps: 135 | Train Loss: 0.1780526 Vali Loss: 0.1468889 Test Loss: 0.1736518
Validation loss decreased (0.146907 --> 0.146889).  Saving model ...
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.1746126
	speed: 1.0281s/iter; left time: 4756.1058s
Epoch: 66 cost time: 61.221131324768066
Epoch: 66, Steps: 135 | Train Loss: 0.1780338 Vali Loss: 0.1473201 Test Loss: 0.1736454
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.1674227
	speed: 1.0497s/iter; left time: 4714.3241s
Epoch: 67 cost time: 63.929073333740234
Epoch: 67, Steps: 135 | Train Loss: 0.1780572 Vali Loss: 0.1472064 Test Loss: 0.1736458
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.1754858
	speed: 1.0698s/iter; left time: 4660.2510s
Epoch: 68 cost time: 66.91350626945496
Epoch: 68, Steps: 135 | Train Loss: 0.1779706 Vali Loss: 0.1472098 Test Loss: 0.1736545
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.1746873
	speed: 1.0634s/iter; left time: 4488.5855s
Epoch: 69 cost time: 65.23035144805908
Epoch: 69, Steps: 135 | Train Loss: 0.1779118 Vali Loss: 0.1472168 Test Loss: 0.1736473
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.1810188
	speed: 1.0426s/iter; left time: 4260.2468s
Epoch: 70 cost time: 65.73223495483398
Epoch: 70, Steps: 135 | Train Loss: 0.1779595 Vali Loss: 0.1469204 Test Loss: 0.1736509
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.1742765
	speed: 1.0579s/iter; left time: 4179.6423s
Epoch: 71 cost time: 62.83949875831604
Epoch: 71, Steps: 135 | Train Loss: 0.1779636 Vali Loss: 0.1469482 Test Loss: 0.1736502
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.1708881
	speed: 1.0439s/iter; left time: 3983.6642s
Epoch: 72 cost time: 63.29426908493042
Epoch: 72, Steps: 135 | Train Loss: 0.1780260 Vali Loss: 0.1470797 Test Loss: 0.1736463
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.1819747
	speed: 1.0328s/iter; left time: 3801.5759s
Epoch: 73 cost time: 63.29547071456909
Epoch: 73, Steps: 135 | Train Loss: 0.1779298 Vali Loss: 0.1469712 Test Loss: 0.1736424
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.1786379
	speed: 1.0417s/iter; left time: 3693.8121s
Epoch: 74 cost time: 67.15276575088501
Epoch: 74, Steps: 135 | Train Loss: 0.1779973 Vali Loss: 0.1471719 Test Loss: 0.1736446
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.1785136
	speed: 1.0715s/iter; left time: 3654.9201s
Epoch: 75 cost time: 63.91178011894226
Epoch: 75, Steps: 135 | Train Loss: 0.1780118 Vali Loss: 0.1471943 Test Loss: 0.1736469
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.1912518
	speed: 1.0245s/iter; left time: 3356.2125s
Epoch: 76 cost time: 62.787460803985596
Epoch: 76, Steps: 135 | Train Loss: 0.1780336 Vali Loss: 0.1471489 Test Loss: 0.1736431
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.1661940
	speed: 1.0368s/iter; left time: 3256.5947s
Epoch: 77 cost time: 61.81113052368164
Epoch: 77, Steps: 135 | Train Loss: 0.1780152 Vali Loss: 0.1470515 Test Loss: 0.1736427
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.1637940
	speed: 1.0349s/iter; left time: 3110.8532s
Epoch: 78 cost time: 61.358606815338135
Epoch: 78, Steps: 135 | Train Loss: 0.1780215 Vali Loss: 0.1470441 Test Loss: 0.1736420
EarlyStopping counter: 13 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.1769071
	speed: 1.0031s/iter; left time: 2880.0168s
Epoch: 79 cost time: 62.185792207717896
Epoch: 79, Steps: 135 | Train Loss: 0.1779922 Vali Loss: 0.1471974 Test Loss: 0.1736420
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.1759226
	speed: 0.9510s/iter; left time: 2601.8888s
Epoch: 80 cost time: 58.93527388572693
Epoch: 80, Steps: 135 | Train Loss: 0.1779912 Vali Loss: 0.1470218 Test Loss: 0.1736439
EarlyStopping counter: 15 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.1807433
	speed: 0.9714s/iter; left time: 2526.6915s
Epoch: 81 cost time: 57.90054702758789
Epoch: 81, Steps: 135 | Train Loss: 0.1779610 Vali Loss: 0.1466482 Test Loss: 0.1736433
Validation loss decreased (0.146889 --> 0.146648).  Saving model ...
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.1706639
	speed: 1.0255s/iter; left time: 2528.9265s
Epoch: 82 cost time: 62.32203555107117
Epoch: 82, Steps: 135 | Train Loss: 0.1779747 Vali Loss: 0.1469886 Test Loss: 0.1736431
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.1763192
	speed: 1.0402s/iter; left time: 2424.7856s
Epoch: 83 cost time: 62.21217584609985
Epoch: 83, Steps: 135 | Train Loss: 0.1780275 Vali Loss: 0.1470799 Test Loss: 0.1736407
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.1752695
	speed: 0.9981s/iter; left time: 2191.7629s
Epoch: 84 cost time: 61.68453574180603
Epoch: 84, Steps: 135 | Train Loss: 0.1779818 Vali Loss: 0.1472311 Test Loss: 0.1736413
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.1757857
	speed: 1.0089s/iter; left time: 2079.3732s
Epoch: 85 cost time: 63.887683629989624
Epoch: 85, Steps: 135 | Train Loss: 0.1779876 Vali Loss: 0.1472193 Test Loss: 0.1736425
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.1760255
	speed: 1.0134s/iter; left time: 1951.8307s
Epoch: 86 cost time: 62.23542809486389
Epoch: 86, Steps: 135 | Train Loss: 0.1779691 Vali Loss: 0.1472177 Test Loss: 0.1736417
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.1747565
	speed: 1.0354s/iter; left time: 1854.3214s
Epoch: 87 cost time: 62.65802550315857
Epoch: 87, Steps: 135 | Train Loss: 0.1780158 Vali Loss: 0.1470254 Test Loss: 0.1736438
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.1783271
	speed: 1.0326s/iter; left time: 1709.9428s
Epoch: 88 cost time: 59.82886838912964
Epoch: 88, Steps: 135 | Train Loss: 0.1780129 Vali Loss: 0.1470032 Test Loss: 0.1736425
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.1917445
	speed: 1.0338s/iter; left time: 1572.4645s
Epoch: 89 cost time: 63.6150119304657
Epoch: 89, Steps: 135 | Train Loss: 0.1779639 Vali Loss: 0.1471049 Test Loss: 0.1736433
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.1805089
	speed: 1.0273s/iter; left time: 1423.8230s
Epoch: 90 cost time: 64.47826743125916
Epoch: 90, Steps: 135 | Train Loss: 0.1780136 Vali Loss: 0.1470496 Test Loss: 0.1736407
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.204402478767869e-06
	iters: 100, epoch: 91 | loss: 0.1815934
	speed: 1.0436s/iter; left time: 1305.5935s
Epoch: 91 cost time: 63.68636894226074
Epoch: 91, Steps: 135 | Train Loss: 0.1780064 Vali Loss: 0.1471711 Test Loss: 0.1736413
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.944182354829475e-06
	iters: 100, epoch: 92 | loss: 0.1750698
	speed: 1.0150s/iter; left time: 1132.7859s
Epoch: 92 cost time: 62.7407169342041
Epoch: 92, Steps: 135 | Train Loss: 0.1779679 Vali Loss: 0.1471148 Test Loss: 0.1736401
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.696973237088e-06
	iters: 100, epoch: 93 | loss: 0.1841683
	speed: 0.9957s/iter; left time: 976.7640s
Epoch: 93 cost time: 59.19875121116638
Epoch: 93, Steps: 135 | Train Loss: 0.1779387 Vali Loss: 0.1470840 Test Loss: 0.1736400
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.462124575233601e-06
	iters: 100, epoch: 94 | loss: 0.1914221
	speed: 0.9835s/iter; left time: 832.0412s
Epoch: 94 cost time: 61.3883535861969
Epoch: 94, Steps: 135 | Train Loss: 0.1780698 Vali Loss: 0.1469408 Test Loss: 0.1736393
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.239018346471921e-06
	iters: 100, epoch: 95 | loss: 0.1710378
	speed: 1.0170s/iter; left time: 723.1177s
Epoch: 95 cost time: 60.57086539268494
Epoch: 95, Steps: 135 | Train Loss: 0.1780341 Vali Loss: 0.1469787 Test Loss: 0.1736403
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.027067429148324e-06
	iters: 100, epoch: 96 | loss: 0.1655243
	speed: 0.9835s/iter; left time: 566.4741s
Epoch: 96 cost time: 61.20514941215515
Epoch: 96, Steps: 135 | Train Loss: 0.1780078 Vali Loss: 0.1471844 Test Loss: 0.1736403
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.825714057690908e-06
	iters: 100, epoch: 97 | loss: 0.1742510
	speed: 0.9709s/iter; left time: 428.1882s
Epoch: 97 cost time: 59.14267420768738
Epoch: 97, Steps: 135 | Train Loss: 0.1780202 Vali Loss: 0.1470840 Test Loss: 0.1736398
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.6344283548063623e-06
	iters: 100, epoch: 98 | loss: 0.1760459
	speed: 0.9861s/iter; left time: 301.7319s
Epoch: 98 cost time: 58.95827126502991
Epoch: 98, Steps: 135 | Train Loss: 0.1779777 Vali Loss: 0.1468048 Test Loss: 0.1736406
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.452706937066044e-06
	iters: 100, epoch: 99 | loss: 0.1818646
	speed: 0.9961s/iter; left time: 170.3380s
Epoch: 99 cost time: 60.0845365524292
Epoch: 99, Steps: 135 | Train Loss: 0.1779551 Vali Loss: 0.1469016 Test Loss: 0.1736403
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.2800715902127414e-06
	iters: 100, epoch: 100 | loss: 0.1774783
	speed: 1.0414s/iter; left time: 37.4889s
Epoch: 100 cost time: 64.37070655822754
Epoch: 100, Steps: 135 | Train Loss: 0.1779038 Vali Loss: 0.1472484 Test Loss: 0.1736400
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.1160680107021042e-06
>>>>>>>testing : Electricity_720_j336_H6_FITS_custom_ftM_sl720_ll48_pl336_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4925
mse:0.17144903540611267, mae:0.27054426074028015, rse:0.41210588812828064, corr:[0.4595638  0.4599856  0.46197367 0.46238536 0.4624251  0.46306905
 0.46325812 0.46292496 0.46274984 0.46267164 0.46242577 0.46225113
 0.4622407  0.462251   0.46226135 0.46227252 0.4622518  0.462318
 0.4624051  0.46225333 0.46207952 0.46218878 0.46245402 0.4626634
 0.46278444 0.46309963 0.46326795 0.46314636 0.46292132 0.46281278
 0.46272478 0.46254215 0.4623379  0.4622458  0.46220288 0.4621642
 0.4621597  0.46219394 0.46225166 0.46227252 0.46224743 0.46223876
 0.4622418  0.4621471  0.4619894  0.4618896  0.46194732 0.46213993
 0.46227863 0.46236467 0.46238074 0.4623611  0.46226406 0.46209228
 0.46196038 0.4619239  0.46187449 0.46178567 0.4617496  0.46178314
 0.4618129  0.46180066 0.46181315 0.4618614  0.46189043 0.461889
 0.46177173 0.46155986 0.46145946 0.46142703 0.46138015 0.4613761
 0.4614583  0.46158245 0.46153894 0.4614033  0.46132687 0.46129444
 0.4612091  0.46110085 0.46107513 0.46108893 0.46105143 0.46100754
 0.4610301  0.46107864 0.46109274 0.46105474 0.4610224  0.461045
 0.46108255 0.46103144 0.46094722 0.46094492 0.46101996 0.46109587
 0.46113226 0.4611884  0.46121493 0.46118546 0.46108374 0.46101153
 0.46100903 0.4610014  0.46092975 0.46087307 0.46086502 0.46088606
 0.460871   0.4608374  0.4608608  0.46089584 0.4608751  0.46083292
 0.4608121  0.4607329  0.46064663 0.46058744 0.4605919  0.46074495
 0.46094403 0.46101406 0.46097666 0.46096602 0.46097946 0.46098125
 0.4609484  0.46091428 0.4609074  0.46089327 0.46083418 0.46079108
 0.46080866 0.46083304 0.46081832 0.46078762 0.46080217 0.4608602
 0.4608243  0.46059486 0.4603945  0.46031207 0.46024314 0.46022376
 0.46027404 0.46037102 0.4604104  0.46041217 0.46038783 0.46037567
 0.46037334 0.46036947 0.4603439  0.4603198  0.46032122 0.46032047
 0.46027893 0.4602501  0.4602982  0.46032292 0.46028492 0.4602794
 0.46028814 0.46014464 0.45999587 0.45988795 0.45980784 0.45982352
 0.4598348  0.45988497 0.4598479  0.4597746  0.45969406 0.45959637
 0.45951927 0.45948127 0.459417   0.45930502 0.45915303 0.4590548
 0.45900115 0.45889795 0.45875964 0.4586519  0.4585677  0.4584506
 0.45826218 0.45805058 0.45794013 0.4579129  0.45789042 0.45791435
 0.45803806 0.45824814 0.45829064 0.45822868 0.45819217 0.4581726
 0.45809883 0.45800728 0.45794514 0.45788413 0.45778853 0.4577185
 0.45769507 0.45766956 0.4576569  0.45759937 0.45751476 0.45749336
 0.45749953 0.45737568 0.45719153 0.4571205  0.45719984 0.45733964
 0.45746398 0.45763958 0.45774466 0.45776203 0.457735   0.45769697
 0.45766783 0.45764786 0.4576042  0.4575081  0.4574208  0.45738113
 0.45734575 0.45725408 0.45718402 0.45718008 0.45720145 0.45717123
 0.45705885 0.45690954 0.45682988 0.45680144 0.4567998  0.45689926
 0.45708114 0.45727554 0.4573202  0.4573031  0.45730558 0.45729178
 0.45723614 0.4571621  0.45710468 0.4570187  0.45689678 0.45680413
 0.45676512 0.4567475  0.45669684 0.456604   0.45653933 0.45657462
 0.4566341  0.45659795 0.45656264 0.45666015 0.45681632 0.45692566
 0.4570209  0.4571821  0.4572737  0.45724967 0.45718056 0.4571461
 0.45710325 0.45699129 0.45682815 0.45669657 0.45661396 0.4565516
 0.45647117 0.4563754  0.45638317 0.45643935 0.45641997 0.45637235
 0.45640433 0.45640388 0.4563536  0.4563384  0.45649245 0.45678782
 0.45701084 0.4570587  0.4570525  0.45708942 0.45706305 0.45694086
 0.45681587 0.4567168  0.4566075  0.456438   0.45622665 0.45610872
 0.45612544 0.4561238  0.45605335 0.45604786 0.45618623 0.45630687
 0.45621014 0.45597914 0.45591503 0.45595682 0.4559101  0.4559332
 0.45607895 0.45617425 0.4560494  0.45592391 0.4558847  0.45575967
 0.45552063 0.45535704 0.4553021  0.45523322 0.45514652 0.45513767
 0.45528182 0.45553836 0.45568153 0.45557445 0.45555553 0.4558637
 0.45574796 0.45493662 0.45492136 0.45535177 0.45445946 0.4559368 ]
