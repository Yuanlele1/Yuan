Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=42, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_90_j336_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_90_j336_H8_FITS_custom_ftM_sl90_ll48_pl336_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17987
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=42, out_features=198, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  341687808.0
params:  8514.0
Trainable parameters:  8514
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.9578362
	speed: 0.3757s/iter; left time: 5222.5318s
Epoch: 1 cost time: 52.4164252281189
Epoch: 1, Steps: 140 | Train Loss: 1.2183416 Vali Loss: 0.6265368 Test Loss: 0.7189111
Validation loss decreased (inf --> 0.626537).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5080042
	speed: 0.9208s/iter; left time: 12671.1022s
Epoch: 2 cost time: 51.5075786113739
Epoch: 2, Steps: 140 | Train Loss: 0.5680804 Vali Loss: 0.3813569 Test Loss: 0.4370066
Validation loss decreased (0.626537 --> 0.381357).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3411391
	speed: 0.9554s/iter; left time: 13013.8531s
Epoch: 3 cost time: 51.605969190597534
Epoch: 3, Steps: 140 | Train Loss: 0.3848227 Vali Loss: 0.2887715 Test Loss: 0.3292574
Validation loss decreased (0.381357 --> 0.288771).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2996991
	speed: 0.8928s/iter; left time: 12036.1239s
Epoch: 4 cost time: 51.94889187812805
Epoch: 4, Steps: 140 | Train Loss: 0.3117867 Vali Loss: 0.2503373 Test Loss: 0.2837226
Validation loss decreased (0.288771 --> 0.250337).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2721354
	speed: 0.9315s/iter; left time: 12427.1508s
Epoch: 5 cost time: 52.71139621734619
Epoch: 5, Steps: 140 | Train Loss: 0.2798193 Vali Loss: 0.2321368 Test Loss: 0.2623500
Validation loss decreased (0.250337 --> 0.232137).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2583791
	speed: 0.9220s/iter; left time: 12171.3473s
Epoch: 6 cost time: 51.10367512702942
Epoch: 6, Steps: 140 | Train Loss: 0.2638279 Vali Loss: 0.2218712 Test Loss: 0.2508345
Validation loss decreased (0.232137 --> 0.221871).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2440798
	speed: 0.9329s/iter; left time: 12184.9786s
Epoch: 7 cost time: 53.22866463661194
Epoch: 7, Steps: 140 | Train Loss: 0.2545915 Vali Loss: 0.2161069 Test Loss: 0.2437425
Validation loss decreased (0.221871 --> 0.216107).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2415663
	speed: 0.8968s/iter; left time: 11588.0923s
Epoch: 8 cost time: 51.106287240982056
Epoch: 8, Steps: 140 | Train Loss: 0.2485870 Vali Loss: 0.2115478 Test Loss: 0.2389432
Validation loss decreased (0.216107 --> 0.211548).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2632538
	speed: 1.0218s/iter; left time: 13059.2881s
Epoch: 9 cost time: 59.286654233932495
Epoch: 9, Steps: 140 | Train Loss: 0.2443269 Vali Loss: 0.2086359 Test Loss: 0.2354646
Validation loss decreased (0.211548 --> 0.208636).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2458571
	speed: 1.0914s/iter; left time: 13797.0044s
Epoch: 10 cost time: 63.70533990859985
Epoch: 10, Steps: 140 | Train Loss: 0.2412571 Vali Loss: 0.2065739 Test Loss: 0.2328831
Validation loss decreased (0.208636 --> 0.206574).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2477353
	speed: 1.1646s/iter; left time: 14558.2400s
Epoch: 11 cost time: 68.08057475090027
Epoch: 11, Steps: 140 | Train Loss: 0.2388136 Vali Loss: 0.2043624 Test Loss: 0.2308506
Validation loss decreased (0.206574 --> 0.204362).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2358264
	speed: 1.1534s/iter; left time: 14257.1325s
Epoch: 12 cost time: 62.97201585769653
Epoch: 12, Steps: 140 | Train Loss: 0.2369020 Vali Loss: 0.2030026 Test Loss: 0.2292751
Validation loss decreased (0.204362 --> 0.203003).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2259629
	speed: 1.1036s/iter; left time: 13487.0349s
Epoch: 13 cost time: 58.32842755317688
Epoch: 13, Steps: 140 | Train Loss: 0.2353832 Vali Loss: 0.2018248 Test Loss: 0.2280262
Validation loss decreased (0.203003 --> 0.201825).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2221431
	speed: 1.0769s/iter; left time: 13009.9887s
Epoch: 14 cost time: 61.452388286590576
Epoch: 14, Steps: 140 | Train Loss: 0.2341857 Vali Loss: 0.2014004 Test Loss: 0.2270158
Validation loss decreased (0.201825 --> 0.201400).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2295111
	speed: 1.1024s/iter; left time: 13164.0396s
Epoch: 15 cost time: 61.817580699920654
Epoch: 15, Steps: 140 | Train Loss: 0.2332392 Vali Loss: 0.1999688 Test Loss: 0.2261484
Validation loss decreased (0.201400 --> 0.199969).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2238683
	speed: 1.1215s/iter; left time: 13234.3112s
Epoch: 16 cost time: 63.253499031066895
Epoch: 16, Steps: 140 | Train Loss: 0.2324799 Vali Loss: 0.1993957 Test Loss: 0.2254485
Validation loss decreased (0.199969 --> 0.199396).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2319017
	speed: 1.1262s/iter; left time: 13133.0077s
Epoch: 17 cost time: 60.636810302734375
Epoch: 17, Steps: 140 | Train Loss: 0.2315860 Vali Loss: 0.1987375 Test Loss: 0.2248486
Validation loss decreased (0.199396 --> 0.198738).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2212416
	speed: 1.1110s/iter; left time: 12799.3574s
Epoch: 18 cost time: 60.10273337364197
Epoch: 18, Steps: 140 | Train Loss: 0.2311024 Vali Loss: 0.1983378 Test Loss: 0.2243317
Validation loss decreased (0.198738 --> 0.198338).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2239290
	speed: 1.1079s/iter; left time: 12609.5463s
Epoch: 19 cost time: 61.4861626625061
Epoch: 19, Steps: 140 | Train Loss: 0.2305801 Vali Loss: 0.1979401 Test Loss: 0.2238829
Validation loss decreased (0.198338 --> 0.197940).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2344593
	speed: 1.1191s/iter; left time: 12580.0341s
Epoch: 20 cost time: 60.98823070526123
Epoch: 20, Steps: 140 | Train Loss: 0.2301761 Vali Loss: 0.1976184 Test Loss: 0.2234928
Validation loss decreased (0.197940 --> 0.197618).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2326201
	speed: 1.0764s/iter; left time: 11949.3785s
Epoch: 21 cost time: 60.93297219276428
Epoch: 21, Steps: 140 | Train Loss: 0.2297468 Vali Loss: 0.1973599 Test Loss: 0.2231442
Validation loss decreased (0.197618 --> 0.197360).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2255175
	speed: 1.0725s/iter; left time: 11755.6390s
Epoch: 22 cost time: 58.63310265541077
Epoch: 22, Steps: 140 | Train Loss: 0.2293422 Vali Loss: 0.1968594 Test Loss: 0.2228284
Validation loss decreased (0.197360 --> 0.196859).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2387958
	speed: 1.0661s/iter; left time: 11535.9988s
Epoch: 23 cost time: 58.72118377685547
Epoch: 23, Steps: 140 | Train Loss: 0.2291075 Vali Loss: 0.1968672 Test Loss: 0.2225483
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2291536
	speed: 1.0727s/iter; left time: 11457.2172s
Epoch: 24 cost time: 61.67558312416077
Epoch: 24, Steps: 140 | Train Loss: 0.2287702 Vali Loss: 0.1967777 Test Loss: 0.2222980
Validation loss decreased (0.196859 --> 0.196778).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2138569
	speed: 1.0210s/iter; left time: 10762.0670s
Epoch: 25 cost time: 56.64990425109863
Epoch: 25, Steps: 140 | Train Loss: 0.2284967 Vali Loss: 0.1962696 Test Loss: 0.2220691
Validation loss decreased (0.196778 --> 0.196270).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2282472
	speed: 1.0567s/iter; left time: 10990.5861s
Epoch: 26 cost time: 57.14517593383789
Epoch: 26, Steps: 140 | Train Loss: 0.2282572 Vali Loss: 0.1961936 Test Loss: 0.2218406
Validation loss decreased (0.196270 --> 0.196194).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2291185
	speed: 0.9909s/iter; left time: 10167.4225s
Epoch: 27 cost time: 54.86916923522949
Epoch: 27, Steps: 140 | Train Loss: 0.2279796 Vali Loss: 0.1961682 Test Loss: 0.2216486
Validation loss decreased (0.196194 --> 0.196168).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2319409
	speed: 0.9918s/iter; left time: 10037.5144s
Epoch: 28 cost time: 55.855870723724365
Epoch: 28, Steps: 140 | Train Loss: 0.2278423 Vali Loss: 0.1960272 Test Loss: 0.2214722
Validation loss decreased (0.196168 --> 0.196027).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2406537
	speed: 0.9998s/iter; left time: 9979.2667s
Epoch: 29 cost time: 58.424065589904785
Epoch: 29, Steps: 140 | Train Loss: 0.2275961 Vali Loss: 0.1956180 Test Loss: 0.2213078
Validation loss decreased (0.196027 --> 0.195618).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2219948
	speed: 1.2589s/iter; left time: 12388.8136s
Epoch: 30 cost time: 74.96328496932983
Epoch: 30, Steps: 140 | Train Loss: 0.2274983 Vali Loss: 0.1953114 Test Loss: 0.2211598
Validation loss decreased (0.195618 --> 0.195311).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2408296
	speed: 1.3285s/iter; left time: 12888.1702s
Epoch: 31 cost time: 74.70489311218262
Epoch: 31, Steps: 140 | Train Loss: 0.2273237 Vali Loss: 0.1952976 Test Loss: 0.2210162
Validation loss decreased (0.195311 --> 0.195298).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2222084
	speed: 1.3519s/iter; left time: 12925.6163s
Epoch: 32 cost time: 79.22453713417053
Epoch: 32, Steps: 140 | Train Loss: 0.2271645 Vali Loss: 0.1954579 Test Loss: 0.2208863
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2241152
	speed: 1.3695s/iter; left time: 12902.2431s
Epoch: 33 cost time: 75.90190100669861
Epoch: 33, Steps: 140 | Train Loss: 0.2270139 Vali Loss: 0.1953808 Test Loss: 0.2207641
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2164596
	speed: 1.3501s/iter; left time: 12530.5612s
Epoch: 34 cost time: 74.68288564682007
Epoch: 34, Steps: 140 | Train Loss: 0.2268984 Vali Loss: 0.1951095 Test Loss: 0.2206523
Validation loss decreased (0.195298 --> 0.195110).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2302068
	speed: 1.2624s/iter; left time: 11539.9884s
Epoch: 35 cost time: 70.8343346118927
Epoch: 35, Steps: 140 | Train Loss: 0.2267601 Vali Loss: 0.1948772 Test Loss: 0.2205456
Validation loss decreased (0.195110 --> 0.194877).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2209813
	speed: 1.2878s/iter; left time: 11591.6681s
Epoch: 36 cost time: 70.69990706443787
Epoch: 36, Steps: 140 | Train Loss: 0.2267021 Vali Loss: 0.1950688 Test Loss: 0.2204532
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2336800
	speed: 1.2827s/iter; left time: 11365.9204s
Epoch: 37 cost time: 72.0952353477478
Epoch: 37, Steps: 140 | Train Loss: 0.2265775 Vali Loss: 0.1945022 Test Loss: 0.2203659
Validation loss decreased (0.194877 --> 0.194502).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2162935
	speed: 1.3425s/iter; left time: 11707.5130s
Epoch: 38 cost time: 74.82109022140503
Epoch: 38, Steps: 140 | Train Loss: 0.2264204 Vali Loss: 0.1945891 Test Loss: 0.2202808
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2389825
	speed: 1.2862s/iter; left time: 11036.7125s
Epoch: 39 cost time: 72.52635169029236
Epoch: 39, Steps: 140 | Train Loss: 0.2264539 Vali Loss: 0.1948742 Test Loss: 0.2202141
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2324433
	speed: 1.3018s/iter; left time: 10988.8346s
Epoch: 40 cost time: 71.84697794914246
Epoch: 40, Steps: 140 | Train Loss: 0.2263331 Vali Loss: 0.1947070 Test Loss: 0.2201458
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2325149
	speed: 1.2520s/iter; left time: 10392.8069s
Epoch: 41 cost time: 73.68040013313293
Epoch: 41, Steps: 140 | Train Loss: 0.2262726 Vali Loss: 0.1947494 Test Loss: 0.2200811
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2238955
	speed: 1.3037s/iter; left time: 10639.7041s
Epoch: 42 cost time: 72.343985080719
Epoch: 42, Steps: 140 | Train Loss: 0.2262102 Vali Loss: 0.1943557 Test Loss: 0.2200266
Validation loss decreased (0.194502 --> 0.194356).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2162303
	speed: 1.3172s/iter; left time: 10565.0960s
Epoch: 43 cost time: 72.22593665122986
Epoch: 43, Steps: 140 | Train Loss: 0.2261398 Vali Loss: 0.1944164 Test Loss: 0.2199689
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2184970
	speed: 1.2756s/iter; left time: 10052.9377s
Epoch: 44 cost time: 73.77393102645874
Epoch: 44, Steps: 140 | Train Loss: 0.2261283 Vali Loss: 0.1946683 Test Loss: 0.2199138
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2180830
	speed: 1.3240s/iter; left time: 10249.3877s
Epoch: 45 cost time: 72.59102749824524
Epoch: 45, Steps: 140 | Train Loss: 0.2259988 Vali Loss: 0.1946657 Test Loss: 0.2198693
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2308937
	speed: 1.3739s/iter; left time: 10442.6795s
Epoch: 46 cost time: 71.76379585266113
Epoch: 46, Steps: 140 | Train Loss: 0.2260092 Vali Loss: 0.1948997 Test Loss: 0.2198312
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2212527
	speed: 1.2913s/iter; left time: 9634.1447s
Epoch: 47 cost time: 73.68444061279297
Epoch: 47, Steps: 140 | Train Loss: 0.2259717 Vali Loss: 0.1939942 Test Loss: 0.2197886
Validation loss decreased (0.194356 --> 0.193994).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2287214
	speed: 1.3531s/iter; left time: 9906.3687s
Epoch: 48 cost time: 74.78983640670776
Epoch: 48, Steps: 140 | Train Loss: 0.2259845 Vali Loss: 0.1941115 Test Loss: 0.2197526
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2169830
	speed: 1.2631s/iter; left time: 9070.3227s
Epoch: 49 cost time: 73.40505480766296
Epoch: 49, Steps: 140 | Train Loss: 0.2257947 Vali Loss: 0.1943492 Test Loss: 0.2197243
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2173373
	speed: 1.2756s/iter; left time: 8981.6411s
Epoch: 50 cost time: 67.69226264953613
Epoch: 50, Steps: 140 | Train Loss: 0.2258570 Vali Loss: 0.1939416 Test Loss: 0.2196942
Validation loss decreased (0.193994 --> 0.193942).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2381390
	speed: 1.3010s/iter; left time: 8978.4123s
Epoch: 51 cost time: 75.74155473709106
Epoch: 51, Steps: 140 | Train Loss: 0.2258102 Vali Loss: 0.1941522 Test Loss: 0.2196624
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2181690
	speed: 1.2717s/iter; left time: 8597.6539s
Epoch: 52 cost time: 69.7307813167572
Epoch: 52, Steps: 140 | Train Loss: 0.2257760 Vali Loss: 0.1938295 Test Loss: 0.2196369
Validation loss decreased (0.193942 --> 0.193830).  Saving model ...
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2233885
	speed: 1.2935s/iter; left time: 8564.5300s
Epoch: 53 cost time: 72.81715416908264
Epoch: 53, Steps: 140 | Train Loss: 0.2257479 Vali Loss: 0.1938009 Test Loss: 0.2196153
Validation loss decreased (0.193830 --> 0.193801).  Saving model ...
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2310310
	speed: 1.2750s/iter; left time: 8262.9688s
Epoch: 54 cost time: 70.85448503494263
Epoch: 54, Steps: 140 | Train Loss: 0.2257429 Vali Loss: 0.1940510 Test Loss: 0.2195922
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2322461
	speed: 1.2969s/iter; left time: 8223.6795s
Epoch: 55 cost time: 72.7958025932312
Epoch: 55, Steps: 140 | Train Loss: 0.2256631 Vali Loss: 0.1940460 Test Loss: 0.2195724
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2166988
	speed: 1.2966s/iter; left time: 8040.4960s
Epoch: 56 cost time: 74.69537162780762
Epoch: 56, Steps: 140 | Train Loss: 0.2256317 Vali Loss: 0.1938036 Test Loss: 0.2195553
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2194456
	speed: 1.2860s/iter; left time: 7794.1784s
Epoch: 57 cost time: 72.40150594711304
Epoch: 57, Steps: 140 | Train Loss: 0.2256668 Vali Loss: 0.1938670 Test Loss: 0.2195387
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2302856
	speed: 1.2545s/iter; left time: 7428.1360s
Epoch: 58 cost time: 69.2403736114502
Epoch: 58, Steps: 140 | Train Loss: 0.2256456 Vali Loss: 0.1938880 Test Loss: 0.2195255
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2273316
	speed: 1.2016s/iter; left time: 6946.4723s
Epoch: 59 cost time: 62.658186197280884
Epoch: 59, Steps: 140 | Train Loss: 0.2256986 Vali Loss: 0.1943724 Test Loss: 0.2195101
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.2245249
	speed: 1.0578s/iter; left time: 5966.8348s
Epoch: 60 cost time: 58.51588153839111
Epoch: 60, Steps: 140 | Train Loss: 0.2256197 Vali Loss: 0.1940452 Test Loss: 0.2194957
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.2203267
	speed: 1.0774s/iter; left time: 5926.5642s
Epoch: 61 cost time: 60.90027713775635
Epoch: 61, Steps: 140 | Train Loss: 0.2256698 Vali Loss: 0.1942615 Test Loss: 0.2194815
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.2351722
	speed: 1.0293s/iter; left time: 5518.0488s
Epoch: 62 cost time: 56.082173585891724
Epoch: 62, Steps: 140 | Train Loss: 0.2256372 Vali Loss: 0.1938407 Test Loss: 0.2194737
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.2142031
	speed: 1.0078s/iter; left time: 5261.8021s
Epoch: 63 cost time: 57.07372283935547
Epoch: 63, Steps: 140 | Train Loss: 0.2255763 Vali Loss: 0.1940600 Test Loss: 0.2194638
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.2308531
	speed: 0.9681s/iter; left time: 4918.9328s
Epoch: 64 cost time: 53.44685935974121
Epoch: 64, Steps: 140 | Train Loss: 0.2255765 Vali Loss: 0.1939972 Test Loss: 0.2194542
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.2150942
	speed: 1.0100s/iter; left time: 4990.6172s
Epoch: 65 cost time: 55.68096971511841
Epoch: 65, Steps: 140 | Train Loss: 0.2255954 Vali Loss: 0.1942600 Test Loss: 0.2194444
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.2234947
	speed: 1.0104s/iter; left time: 4851.1279s
Epoch: 66 cost time: 56.387155532836914
Epoch: 66, Steps: 140 | Train Loss: 0.2256334 Vali Loss: 0.1940296 Test Loss: 0.2194410
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.2214629
	speed: 0.9952s/iter; left time: 4638.8309s
Epoch: 67 cost time: 56.34733176231384
Epoch: 67, Steps: 140 | Train Loss: 0.2255552 Vali Loss: 0.1939753 Test Loss: 0.2194325
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.2217358
	speed: 0.9723s/iter; left time: 4395.8704s
Epoch: 68 cost time: 54.96777009963989
Epoch: 68, Steps: 140 | Train Loss: 0.2255241 Vali Loss: 0.1937426 Test Loss: 0.2194247
Validation loss decreased (0.193801 --> 0.193743).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.2304169
	speed: 0.9987s/iter; left time: 4375.1463s
Epoch: 69 cost time: 53.04672026634216
Epoch: 69, Steps: 140 | Train Loss: 0.2255876 Vali Loss: 0.1938954 Test Loss: 0.2194186
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.2148048
	speed: 0.9486s/iter; left time: 4022.8218s
Epoch: 70 cost time: 54.272433280944824
Epoch: 70, Steps: 140 | Train Loss: 0.2255208 Vali Loss: 0.1940203 Test Loss: 0.2194153
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.2256825
	speed: 0.9489s/iter; left time: 3891.3674s
Epoch: 71 cost time: 53.897236824035645
Epoch: 71, Steps: 140 | Train Loss: 0.2255232 Vali Loss: 0.1937895 Test Loss: 0.2194120
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.2265537
	speed: 0.9963s/iter; left time: 3946.4881s
Epoch: 72 cost time: 55.10143184661865
Epoch: 72, Steps: 140 | Train Loss: 0.2256092 Vali Loss: 0.1937310 Test Loss: 0.2194058
Validation loss decreased (0.193743 --> 0.193731).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.2292684
	speed: 0.9087s/iter; left time: 3472.1577s
Epoch: 73 cost time: 47.50625801086426
Epoch: 73, Steps: 140 | Train Loss: 0.2255233 Vali Loss: 0.1937928 Test Loss: 0.2194016
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.2189150
	speed: 0.8852s/iter; left time: 3258.6048s
Epoch: 74 cost time: 49.27756404876709
Epoch: 74, Steps: 140 | Train Loss: 0.2255034 Vali Loss: 0.1938100 Test Loss: 0.2193984
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.2293691
	speed: 0.8764s/iter; left time: 3103.4966s
Epoch: 75 cost time: 46.150705099105835
Epoch: 75, Steps: 140 | Train Loss: 0.2255183 Vali Loss: 0.1937946 Test Loss: 0.2193932
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.2274379
	speed: 0.8145s/iter; left time: 2770.0026s
Epoch: 76 cost time: 46.969820499420166
Epoch: 76, Steps: 140 | Train Loss: 0.2255087 Vali Loss: 0.1937174 Test Loss: 0.2193910
Validation loss decreased (0.193731 --> 0.193717).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.2232267
	speed: 0.8652s/iter; left time: 2821.4991s
Epoch: 77 cost time: 48.79285264015198
Epoch: 77, Steps: 140 | Train Loss: 0.2255202 Vali Loss: 0.1938858 Test Loss: 0.2193889
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.2252229
	speed: 0.8340s/iter; left time: 2602.7701s
Epoch: 78 cost time: 45.947882413864136
Epoch: 78, Steps: 140 | Train Loss: 0.2255022 Vali Loss: 0.1937772 Test Loss: 0.2193851
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.2321334
	speed: 0.8565s/iter; left time: 2553.3658s
Epoch: 79 cost time: 47.973400592803955
Epoch: 79, Steps: 140 | Train Loss: 0.2254385 Vali Loss: 0.1939044 Test Loss: 0.2193838
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.2151233
	speed: 0.8934s/iter; left time: 2538.0507s
Epoch: 80 cost time: 48.81338548660278
Epoch: 80, Steps: 140 | Train Loss: 0.2254340 Vali Loss: 0.1939064 Test Loss: 0.2193810
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.2092022
	speed: 0.8384s/iter; left time: 2264.5512s
Epoch: 81 cost time: 46.73508977890015
Epoch: 81, Steps: 140 | Train Loss: 0.2255313 Vali Loss: 0.1935272 Test Loss: 0.2193793
Validation loss decreased (0.193717 --> 0.193527).  Saving model ...
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.2149644
	speed: 0.9024s/iter; left time: 2311.1530s
Epoch: 82 cost time: 58.171059370040894
Epoch: 82, Steps: 140 | Train Loss: 0.2254805 Vali Loss: 0.1938519 Test Loss: 0.2193774
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.2079453
	speed: 1.0316s/iter; left time: 2497.3902s
Epoch: 83 cost time: 59.39782214164734
Epoch: 83, Steps: 140 | Train Loss: 0.2255228 Vali Loss: 0.1939450 Test Loss: 0.2193758
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.2119319
	speed: 1.0169s/iter; left time: 2319.4477s
Epoch: 84 cost time: 57.23256802558899
Epoch: 84, Steps: 140 | Train Loss: 0.2254655 Vali Loss: 0.1941528 Test Loss: 0.2193734
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.2227146
	speed: 1.0306s/iter; left time: 2206.5458s
Epoch: 85 cost time: 57.45234727859497
Epoch: 85, Steps: 140 | Train Loss: 0.2255611 Vali Loss: 0.1939138 Test Loss: 0.2193718
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.2285468
	speed: 0.9920s/iter; left time: 1985.0738s
Epoch: 86 cost time: 55.72326397895813
Epoch: 86, Steps: 140 | Train Loss: 0.2254666 Vali Loss: 0.1937138 Test Loss: 0.2193716
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.2250429
	speed: 1.0296s/iter; left time: 1916.0308s
Epoch: 87 cost time: 57.94425702095032
Epoch: 87, Steps: 140 | Train Loss: 0.2254117 Vali Loss: 0.1937489 Test Loss: 0.2193694
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.2149646
	speed: 0.9834s/iter; left time: 1692.4034s
Epoch: 88 cost time: 56.25704264640808
Epoch: 88, Steps: 140 | Train Loss: 0.2255573 Vali Loss: 0.1936541 Test Loss: 0.2193688
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.2386389
	speed: 1.0177s/iter; left time: 1608.9175s
Epoch: 89 cost time: 58.249775886535645
Epoch: 89, Steps: 140 | Train Loss: 0.2255402 Vali Loss: 0.1934022 Test Loss: 0.2193677
Validation loss decreased (0.193527 --> 0.193402).  Saving model ...
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.2221889
	speed: 1.0634s/iter; left time: 1532.3209s
Epoch: 90 cost time: 59.88170027732849
Epoch: 90, Steps: 140 | Train Loss: 0.2254102 Vali Loss: 0.1938138 Test Loss: 0.2193661
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.204402478767869e-06
	iters: 100, epoch: 91 | loss: 0.2150751
	speed: 1.0123s/iter; left time: 1316.9401s
Epoch: 91 cost time: 57.228484869003296
Epoch: 91, Steps: 140 | Train Loss: 0.2254768 Vali Loss: 0.1941490 Test Loss: 0.2193648
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.944182354829475e-06
	iters: 100, epoch: 92 | loss: 0.2281351
	speed: 1.0086s/iter; left time: 1170.9602s
Epoch: 92 cost time: 57.11349081993103
Epoch: 92, Steps: 140 | Train Loss: 0.2255139 Vali Loss: 0.1935695 Test Loss: 0.2193642
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.696973237088e-06
	iters: 100, epoch: 93 | loss: 0.2255145
	speed: 1.0207s/iter; left time: 1042.0921s
Epoch: 93 cost time: 58.28858423233032
Epoch: 93, Steps: 140 | Train Loss: 0.2254817 Vali Loss: 0.1937920 Test Loss: 0.2193636
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.462124575233601e-06
	iters: 100, epoch: 94 | loss: 0.2280560
	speed: 1.0136s/iter; left time: 893.0193s
Epoch: 94 cost time: 57.02363038063049
Epoch: 94, Steps: 140 | Train Loss: 0.2255123 Vali Loss: 0.1937966 Test Loss: 0.2193632
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.239018346471921e-06
	iters: 100, epoch: 95 | loss: 0.2302859
	speed: 1.0148s/iter; left time: 751.9846s
Epoch: 95 cost time: 55.547292709350586
Epoch: 95, Steps: 140 | Train Loss: 0.2254078 Vali Loss: 0.1936770 Test Loss: 0.2193625
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.027067429148324e-06
	iters: 100, epoch: 96 | loss: 0.2109158
	speed: 1.0123s/iter; left time: 608.3785s
Epoch: 96 cost time: 56.66549324989319
Epoch: 96, Steps: 140 | Train Loss: 0.2254584 Vali Loss: 0.1941391 Test Loss: 0.2193610
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.825714057690908e-06
	iters: 100, epoch: 97 | loss: 0.2285905
	speed: 1.0528s/iter; left time: 485.3505s
Epoch: 97 cost time: 60.41002941131592
Epoch: 97, Steps: 140 | Train Loss: 0.2255027 Vali Loss: 0.1935970 Test Loss: 0.2193605
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.6344283548063623e-06
	iters: 100, epoch: 98 | loss: 0.2312231
	speed: 1.0500s/iter; left time: 337.0612s
Epoch: 98 cost time: 57.15571570396423
Epoch: 98, Steps: 140 | Train Loss: 0.2254992 Vali Loss: 0.1939736 Test Loss: 0.2193601
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.452706937066044e-06
	iters: 100, epoch: 99 | loss: 0.2194571
	speed: 1.0234s/iter; left time: 185.2327s
Epoch: 99 cost time: 58.80404710769653
Epoch: 99, Steps: 140 | Train Loss: 0.2254657 Vali Loss: 0.1938010 Test Loss: 0.2193594
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.2800715902127414e-06
	iters: 100, epoch: 100 | loss: 0.2218702
	speed: 1.0739s/iter; left time: 44.0304s
Epoch: 100 cost time: 62.1856849193573
Epoch: 100, Steps: 140 | Train Loss: 0.2255061 Vali Loss: 0.1935577 Test Loss: 0.2193592
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.1160680107021042e-06
>>>>>>>testing : Electricity_90_j336_H8_FITS_custom_ftM_sl90_ll48_pl336_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4925
mse:0.21790839731693268, mae:0.29696500301361084, rse:0.46459898352622986, corr:[0.45381752 0.454832   0.45371628 0.45244026 0.4513102  0.45055354
 0.4503007  0.44958612 0.44850996 0.44777438 0.44709525 0.44670472
 0.44646195 0.44593894 0.4459061  0.44522408 0.44522738 0.44532946
 0.4455839  0.44532362 0.4452673  0.4451011  0.44491842 0.44373453
 0.44178584 0.44019413 0.43892092 0.43801057 0.43760914 0.4379724
 0.43880913 0.43891987 0.4386558  0.43821177 0.4379341  0.43787882
 0.43779612 0.4376571  0.43743393 0.437038   0.43704605 0.43705356
 0.43717295 0.43729365 0.43748719 0.43756828 0.43765715 0.43727112
 0.43619218 0.43557143 0.43544388 0.43550918 0.43627852 0.43802473
 0.4402474  0.44164658 0.44164917 0.44156286 0.4413853  0.44127205
 0.4410286  0.44094905 0.44112116 0.44104224 0.4410386  0.44136184
 0.44160342 0.4415858  0.44198397 0.4424508  0.44315767 0.44335657
 0.44340926 0.44382298 0.44463608 0.44568285 0.44745195 0.4500847
 0.4535982  0.45606247 0.45600244 0.4557111  0.4554366  0.45502898
 0.45465395 0.454542   0.4545268  0.4546546  0.4549129  0.4550361
 0.45528498 0.45535517 0.45539793 0.455661   0.45582083 0.45590782
 0.4556498  0.45560127 0.45554438 0.4555831  0.45559067 0.45569462
 0.45629174 0.45625913 0.45595706 0.45560786 0.45527056 0.45516607
 0.4548953  0.45474237 0.45480844 0.45484188 0.45503125 0.45517504
 0.45524195 0.45530635 0.45536056 0.4554113  0.45546612 0.45557827
 0.45531282 0.45549724 0.45542976 0.45527703 0.4553387  0.45520136
 0.45539913 0.45546308 0.4551688  0.45493454 0.45479426 0.45461574
 0.45450845 0.45443684 0.45443666 0.45449045 0.4548235  0.45492798
 0.45511177 0.45530853 0.45534927 0.4553761  0.4553479  0.45529953
 0.45492065 0.45467764 0.4545874  0.45450842 0.45451805 0.4545933
 0.45491838 0.45477104 0.45445922 0.45408148 0.45379695 0.45356628
 0.4536146  0.45363167 0.45372242 0.45392433 0.4542551  0.45459503
 0.45488256 0.4548782  0.4548913  0.454499   0.4539942  0.45171836
 0.44862026 0.44638035 0.44463402 0.44313335 0.4421598  0.44162095
 0.44144118 0.4412872  0.44043222 0.44001308 0.43967855 0.43950307
 0.4393221  0.43912464 0.4389747  0.4385773  0.4385073  0.43858314
 0.4385154  0.43825334 0.43806735 0.43774745 0.43739048 0.43566722
 0.43354335 0.43192413 0.43058988 0.42974105 0.42931932 0.42967737
 0.4306663  0.4312179  0.43088138 0.43080196 0.43073565 0.43075863
 0.43088207 0.43091616 0.43090835 0.43057063 0.43048403 0.43053928
 0.43056968 0.43072295 0.43093455 0.43071896 0.43077075 0.43011788
 0.4290853  0.42853382 0.42831165 0.42846394 0.42921597 0.43097073
 0.4332385  0.43489367 0.43513423 0.43508863 0.43513182 0.4350629
 0.43491846 0.43505806 0.43508998 0.43522516 0.43529242 0.43551958
 0.4359523  0.43576267 0.4362977  0.4367427  0.4371859  0.43735716
 0.43742216 0.4378701  0.43847126 0.439494   0.44155762 0.44413552
 0.4475366  0.45008618 0.45024046 0.45004618 0.44974288 0.4496553
 0.4492862  0.44927981 0.44938993 0.44945845 0.44969258 0.44980192
 0.4500582  0.45022678 0.45039967 0.450506   0.45064816 0.4507331
 0.45040628 0.45042285 0.45026565 0.45018962 0.45022064 0.4503686
 0.45091808 0.4511596  0.45093432 0.45050007 0.450236   0.44997302
 0.44973505 0.449694   0.44958627 0.44948855 0.44960943 0.4497046
 0.4499558  0.4499     0.45000595 0.4500581  0.4500648  0.45019966
 0.44996634 0.45002583 0.4500242  0.44985947 0.4497278  0.44963965
 0.4501266  0.4501181  0.44985366 0.44972032 0.44960693 0.44940314
 0.4493898  0.4494353  0.44949317 0.44950777 0.4496538  0.44972277
 0.44989792 0.44988784 0.44978198 0.4497034  0.44968837 0.44964084
 0.4492782  0.4490294  0.44902477 0.44884673 0.44891277 0.44904608
 0.44934824 0.44956112 0.44948298 0.44934288 0.44928524 0.4490986
 0.44920218 0.4492355  0.44930175 0.44930732 0.44934878 0.4494057
 0.449377   0.44923195 0.4492612  0.44920543 0.44894838 0.44880548]
