Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=34, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_90_j336_H6', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_90_j336_H6_FITS_custom_ftM_sl90_ll48_pl336_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17987
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=34, out_features=160, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  223518720.0
params:  5600.0
Trainable parameters:  5600
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.7105962
	speed: 0.5672s/iter; left time: 7885.0749s
Epoch: 1 cost time: 79.89046311378479
Epoch: 1, Steps: 140 | Train Loss: 0.9812323 Vali Loss: 0.4815333 Test Loss: 0.5347448
Validation loss decreased (inf --> 0.481533).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3910149
	speed: 1.3740s/iter; left time: 18907.4033s
Epoch: 2 cost time: 78.33901858329773
Epoch: 2, Steps: 140 | Train Loss: 0.4334943 Vali Loss: 0.3065099 Test Loss: 0.3426011
Validation loss decreased (0.481533 --> 0.306510).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2881757
	speed: 1.4206s/iter; left time: 19349.5920s
Epoch: 3 cost time: 80.84645175933838
Epoch: 3, Steps: 140 | Train Loss: 0.3171615 Vali Loss: 0.2519612 Test Loss: 0.2826146
Validation loss decreased (0.306510 --> 0.251961).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2778371
	speed: 1.3885s/iter; left time: 18718.3192s
Epoch: 4 cost time: 80.87343382835388
Epoch: 4, Steps: 140 | Train Loss: 0.2769004 Vali Loss: 0.2297546 Test Loss: 0.2585523
Validation loss decreased (0.251961 --> 0.229755).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2635131
	speed: 1.3845s/iter; left time: 18470.8373s
Epoch: 5 cost time: 78.0855278968811
Epoch: 5, Steps: 140 | Train Loss: 0.2592560 Vali Loss: 0.2188885 Test Loss: 0.2465389
Validation loss decreased (0.229755 --> 0.218889).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2452299
	speed: 1.3416s/iter; left time: 17711.0846s
Epoch: 6 cost time: 74.869877576828
Epoch: 6, Steps: 140 | Train Loss: 0.2497802 Vali Loss: 0.2125522 Test Loss: 0.2394554
Validation loss decreased (0.218889 --> 0.212552).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2428163
	speed: 1.3990s/iter; left time: 18272.7616s
Epoch: 7 cost time: 76.67150783538818
Epoch: 7, Steps: 140 | Train Loss: 0.2438197 Vali Loss: 0.2082854 Test Loss: 0.2348954
Validation loss decreased (0.212552 --> 0.208285).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2529567
	speed: 1.3244s/iter; left time: 17113.1274s
Epoch: 8 cost time: 78.62662720680237
Epoch: 8, Steps: 140 | Train Loss: 0.2399262 Vali Loss: 0.2054914 Test Loss: 0.2317915
Validation loss decreased (0.208285 --> 0.205491).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2249987
	speed: 1.3425s/iter; left time: 17158.3983s
Epoch: 9 cost time: 79.87919306755066
Epoch: 9, Steps: 140 | Train Loss: 0.2372018 Vali Loss: 0.2035271 Test Loss: 0.2295905
Validation loss decreased (0.205491 --> 0.203527).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2290428
	speed: 1.4000s/iter; left time: 17697.1199s
Epoch: 10 cost time: 76.26981329917908
Epoch: 10, Steps: 140 | Train Loss: 0.2351968 Vali Loss: 0.2015211 Test Loss: 0.2280039
Validation loss decreased (0.203527 --> 0.201521).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2405036
	speed: 1.3316s/iter; left time: 16646.6270s
Epoch: 11 cost time: 78.67222285270691
Epoch: 11, Steps: 140 | Train Loss: 0.2337288 Vali Loss: 0.2006127 Test Loss: 0.2268022
Validation loss decreased (0.201521 --> 0.200613).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2407027
	speed: 1.3358s/iter; left time: 16512.3302s
Epoch: 12 cost time: 78.50755906105042
Epoch: 12, Steps: 140 | Train Loss: 0.2326808 Vali Loss: 0.1997830 Test Loss: 0.2259122
Validation loss decreased (0.200613 --> 0.199783).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2341676
	speed: 1.3557s/iter; left time: 16567.6190s
Epoch: 13 cost time: 77.06439399719238
Epoch: 13, Steps: 140 | Train Loss: 0.2317185 Vali Loss: 0.1988202 Test Loss: 0.2252013
Validation loss decreased (0.199783 --> 0.198820).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2307043
	speed: 1.3820s/iter; left time: 16695.7122s
Epoch: 14 cost time: 81.8620913028717
Epoch: 14, Steps: 140 | Train Loss: 0.2311805 Vali Loss: 0.1988807 Test Loss: 0.2246484
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2317495
	speed: 1.4256s/iter; left time: 17022.6891s
Epoch: 15 cost time: 83.1442015171051
Epoch: 15, Steps: 140 | Train Loss: 0.2305802 Vali Loss: 0.1980392 Test Loss: 0.2241838
Validation loss decreased (0.198820 --> 0.198039).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2306914
	speed: 1.4017s/iter; left time: 16540.9725s
Epoch: 16 cost time: 78.48043441772461
Epoch: 16, Steps: 140 | Train Loss: 0.2302145 Vali Loss: 0.1980226 Test Loss: 0.2237950
Validation loss decreased (0.198039 --> 0.198023).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2255193
	speed: 1.3312s/iter; left time: 15523.1868s
Epoch: 17 cost time: 75.2753791809082
Epoch: 17, Steps: 140 | Train Loss: 0.2298172 Vali Loss: 0.1974671 Test Loss: 0.2234778
Validation loss decreased (0.198023 --> 0.197467).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2171190
	speed: 1.3543s/iter; left time: 15602.9615s
Epoch: 18 cost time: 80.68761467933655
Epoch: 18, Steps: 140 | Train Loss: 0.2295601 Vali Loss: 0.1973104 Test Loss: 0.2232109
Validation loss decreased (0.197467 --> 0.197310).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2344981
	speed: 1.3857s/iter; left time: 15770.1402s
Epoch: 19 cost time: 80.03159093856812
Epoch: 19, Steps: 140 | Train Loss: 0.2293051 Vali Loss: 0.1973293 Test Loss: 0.2229827
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2230686
	speed: 1.4016s/iter; left time: 15755.7102s
Epoch: 20 cost time: 81.26422429084778
Epoch: 20, Steps: 140 | Train Loss: 0.2290450 Vali Loss: 0.1970354 Test Loss: 0.2227813
Validation loss decreased (0.197310 --> 0.197035).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2213626
	speed: 1.2700s/iter; left time: 14097.9697s
Epoch: 21 cost time: 72.5818030834198
Epoch: 21, Steps: 140 | Train Loss: 0.2287645 Vali Loss: 0.1968518 Test Loss: 0.2226110
Validation loss decreased (0.197035 --> 0.196852).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2208700
	speed: 1.3077s/iter; left time: 14333.8547s
Epoch: 22 cost time: 75.10961246490479
Epoch: 22, Steps: 140 | Train Loss: 0.2287016 Vali Loss: 0.1967819 Test Loss: 0.2224559
Validation loss decreased (0.196852 --> 0.196782).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2186261
	speed: 1.2211s/iter; left time: 13214.0542s
Epoch: 23 cost time: 67.0290539264679
Epoch: 23, Steps: 140 | Train Loss: 0.2285218 Vali Loss: 0.1966284 Test Loss: 0.2223241
Validation loss decreased (0.196782 --> 0.196628).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2270047
	speed: 1.1914s/iter; left time: 12725.5736s
Epoch: 24 cost time: 68.49668335914612
Epoch: 24, Steps: 140 | Train Loss: 0.2283871 Vali Loss: 0.1961350 Test Loss: 0.2221978
Validation loss decreased (0.196628 --> 0.196135).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2227615
	speed: 1.2761s/iter; left time: 13450.8906s
Epoch: 25 cost time: 77.5430679321289
Epoch: 25, Steps: 140 | Train Loss: 0.2282141 Vali Loss: 0.1962493 Test Loss: 0.2221008
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2276512
	speed: 1.2808s/iter; left time: 13321.6111s
Epoch: 26 cost time: 75.1909339427948
Epoch: 26, Steps: 140 | Train Loss: 0.2281196 Vali Loss: 0.1962658 Test Loss: 0.2220089
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2318091
	speed: 1.3041s/iter; left time: 13381.2330s
Epoch: 27 cost time: 74.7740786075592
Epoch: 27, Steps: 140 | Train Loss: 0.2280206 Vali Loss: 0.1962705 Test Loss: 0.2219257
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2135902
	speed: 1.3367s/iter; left time: 13528.5806s
Epoch: 28 cost time: 79.52260565757751
Epoch: 28, Steps: 140 | Train Loss: 0.2279269 Vali Loss: 0.1963363 Test Loss: 0.2218588
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2244831
	speed: 1.5242s/iter; left time: 15212.9482s
Epoch: 29 cost time: 88.60927224159241
Epoch: 29, Steps: 140 | Train Loss: 0.2279267 Vali Loss: 0.1962896 Test Loss: 0.2217848
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2292851
	speed: 1.5132s/iter; left time: 14891.2624s
Epoch: 30 cost time: 83.34441685676575
Epoch: 30, Steps: 140 | Train Loss: 0.2277669 Vali Loss: 0.1959708 Test Loss: 0.2217272
Validation loss decreased (0.196135 --> 0.195971).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2299690
	speed: 1.4850s/iter; left time: 14405.8352s
Epoch: 31 cost time: 85.13081288337708
Epoch: 31, Steps: 140 | Train Loss: 0.2277298 Vali Loss: 0.1960240 Test Loss: 0.2216816
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2386857
	speed: 1.4808s/iter; left time: 14158.3870s
Epoch: 32 cost time: 87.22156500816345
Epoch: 32, Steps: 140 | Train Loss: 0.2277607 Vali Loss: 0.1958877 Test Loss: 0.2216354
Validation loss decreased (0.195971 --> 0.195888).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2341193
	speed: 1.5417s/iter; left time: 14524.3788s
Epoch: 33 cost time: 87.24014258384705
Epoch: 33, Steps: 140 | Train Loss: 0.2276310 Vali Loss: 0.1956861 Test Loss: 0.2215875
Validation loss decreased (0.195888 --> 0.195686).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2220857
	speed: 1.4126s/iter; left time: 13109.8875s
Epoch: 34 cost time: 76.63589692115784
Epoch: 34, Steps: 140 | Train Loss: 0.2276236 Vali Loss: 0.1961851 Test Loss: 0.2215476
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2183890
	speed: 1.3403s/iter; left time: 12251.3315s
Epoch: 35 cost time: 79.9915361404419
Epoch: 35, Steps: 140 | Train Loss: 0.2275173 Vali Loss: 0.1956909 Test Loss: 0.2215206
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2197449
	speed: 1.3752s/iter; left time: 12378.0489s
Epoch: 36 cost time: 77.13054943084717
Epoch: 36, Steps: 140 | Train Loss: 0.2274915 Vali Loss: 0.1962478 Test Loss: 0.2214896
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2168036
	speed: 1.2888s/iter; left time: 11419.8487s
Epoch: 37 cost time: 72.46304750442505
Epoch: 37, Steps: 140 | Train Loss: 0.2274760 Vali Loss: 0.1959146 Test Loss: 0.2214613
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2229481
	speed: 1.2616s/iter; left time: 11002.7949s
Epoch: 38 cost time: 75.46079158782959
Epoch: 38, Steps: 140 | Train Loss: 0.2274537 Vali Loss: 0.1957556 Test Loss: 0.2214429
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2220610
	speed: 1.2573s/iter; left time: 10788.4886s
Epoch: 39 cost time: 73.97222566604614
Epoch: 39, Steps: 140 | Train Loss: 0.2274328 Vali Loss: 0.1959328 Test Loss: 0.2214257
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2203455
	speed: 1.2948s/iter; left time: 10929.6213s
Epoch: 40 cost time: 70.56685042381287
Epoch: 40, Steps: 140 | Train Loss: 0.2273583 Vali Loss: 0.1956655 Test Loss: 0.2214016
Validation loss decreased (0.195686 --> 0.195665).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2237400
	speed: 1.2940s/iter; left time: 10741.3813s
Epoch: 41 cost time: 71.33138799667358
Epoch: 41, Steps: 140 | Train Loss: 0.2274507 Vali Loss: 0.1956026 Test Loss: 0.2213837
Validation loss decreased (0.195665 --> 0.195603).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2258348
	speed: 1.2587s/iter; left time: 10272.6177s
Epoch: 42 cost time: 73.7447874546051
Epoch: 42, Steps: 140 | Train Loss: 0.2273409 Vali Loss: 0.1959623 Test Loss: 0.2213729
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2179314
	speed: 1.2399s/iter; left time: 9945.6334s
Epoch: 43 cost time: 71.4792263507843
Epoch: 43, Steps: 140 | Train Loss: 0.2274138 Vali Loss: 0.1957601 Test Loss: 0.2213582
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2240897
	speed: 1.2896s/iter; left time: 10163.0397s
Epoch: 44 cost time: 74.78390741348267
Epoch: 44, Steps: 140 | Train Loss: 0.2273864 Vali Loss: 0.1959093 Test Loss: 0.2213457
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2332732
	speed: 1.3443s/iter; left time: 10406.2003s
Epoch: 45 cost time: 75.72201085090637
Epoch: 45, Steps: 140 | Train Loss: 0.2272574 Vali Loss: 0.1958316 Test Loss: 0.2213355
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2300666
	speed: 1.2267s/iter; left time: 9324.2474s
Epoch: 46 cost time: 67.11121559143066
Epoch: 46, Steps: 140 | Train Loss: 0.2272872 Vali Loss: 0.1955744 Test Loss: 0.2213333
Validation loss decreased (0.195603 --> 0.195574).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2343559
	speed: 1.1474s/iter; left time: 8560.6934s
Epoch: 47 cost time: 65.33053374290466
Epoch: 47, Steps: 140 | Train Loss: 0.2272895 Vali Loss: 0.1954161 Test Loss: 0.2213253
Validation loss decreased (0.195574 --> 0.195416).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2299540
	speed: 1.2055s/iter; left time: 8825.3225s
Epoch: 48 cost time: 66.73631811141968
Epoch: 48, Steps: 140 | Train Loss: 0.2273509 Vali Loss: 0.1954609 Test Loss: 0.2213176
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2048827
	speed: 1.1956s/iter; left time: 8585.4675s
Epoch: 49 cost time: 70.510906457901
Epoch: 49, Steps: 140 | Train Loss: 0.2272877 Vali Loss: 0.1954254 Test Loss: 0.2213068
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2182516
	speed: 1.1359s/iter; left time: 7998.1280s
Epoch: 50 cost time: 65.35474681854248
Epoch: 50, Steps: 140 | Train Loss: 0.2272708 Vali Loss: 0.1952813 Test Loss: 0.2213016
Validation loss decreased (0.195416 --> 0.195281).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2244789
	speed: 1.2141s/iter; left time: 8378.6511s
Epoch: 51 cost time: 66.37697577476501
Epoch: 51, Steps: 140 | Train Loss: 0.2273082 Vali Loss: 0.1955464 Test Loss: 0.2212989
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2341246
	speed: 1.1203s/iter; left time: 7574.2990s
Epoch: 52 cost time: 64.25165033340454
Epoch: 52, Steps: 140 | Train Loss: 0.2272678 Vali Loss: 0.1956808 Test Loss: 0.2212949
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2350083
	speed: 1.0036s/iter; left time: 6644.9441s
Epoch: 53 cost time: 57.45350432395935
Epoch: 53, Steps: 140 | Train Loss: 0.2272754 Vali Loss: 0.1957100 Test Loss: 0.2212897
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2222817
	speed: 1.0542s/iter; left time: 6832.1807s
Epoch: 54 cost time: 59.30914354324341
Epoch: 54, Steps: 140 | Train Loss: 0.2272284 Vali Loss: 0.1960000 Test Loss: 0.2212873
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2298177
	speed: 1.0530s/iter; left time: 6677.1758s
Epoch: 55 cost time: 59.92176365852356
Epoch: 55, Steps: 140 | Train Loss: 0.2272214 Vali Loss: 0.1953294 Test Loss: 0.2212810
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2220387
	speed: 1.0463s/iter; left time: 6488.2310s
Epoch: 56 cost time: 60.05698108673096
Epoch: 56, Steps: 140 | Train Loss: 0.2272731 Vali Loss: 0.1954023 Test Loss: 0.2212792
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2276932
	speed: 1.0029s/iter; left time: 6078.4914s
Epoch: 57 cost time: 57.543701171875
Epoch: 57, Steps: 140 | Train Loss: 0.2271633 Vali Loss: 0.1954857 Test Loss: 0.2212705
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2299003
	speed: 1.0402s/iter; left time: 6159.1163s
Epoch: 58 cost time: 54.303601026535034
Epoch: 58, Steps: 140 | Train Loss: 0.2272896 Vali Loss: 0.1955970 Test Loss: 0.2212721
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2345424
	speed: 0.7829s/iter; left time: 4526.1673s
Epoch: 59 cost time: 43.30000448226929
Epoch: 59, Steps: 140 | Train Loss: 0.2273298 Vali Loss: 0.1955831 Test Loss: 0.2212692
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.2286457
	speed: 0.7565s/iter; left time: 4267.5748s
Epoch: 60 cost time: 42.517207860946655
Epoch: 60, Steps: 140 | Train Loss: 0.2272202 Vali Loss: 0.1956422 Test Loss: 0.2212687
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.2286109
	speed: 0.7797s/iter; left time: 4289.1397s
Epoch: 61 cost time: 42.840662240982056
Epoch: 61, Steps: 140 | Train Loss: 0.2273205 Vali Loss: 0.1954724 Test Loss: 0.2212671
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.2217704
	speed: 0.7421s/iter; left time: 3978.1422s
Epoch: 62 cost time: 44.479920625686646
Epoch: 62, Steps: 140 | Train Loss: 0.2272690 Vali Loss: 0.1952289 Test Loss: 0.2212645
Validation loss decreased (0.195281 --> 0.195229).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.2274077
	speed: 0.7578s/iter; left time: 3956.6830s
Epoch: 63 cost time: 43.29226303100586
Epoch: 63, Steps: 140 | Train Loss: 0.2272718 Vali Loss: 0.1956886 Test Loss: 0.2212647
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.2242244
	speed: 0.7652s/iter; left time: 3888.0697s
Epoch: 64 cost time: 42.68170142173767
Epoch: 64, Steps: 140 | Train Loss: 0.2272515 Vali Loss: 0.1956199 Test Loss: 0.2212617
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.2236963
	speed: 0.7574s/iter; left time: 3742.2366s
Epoch: 65 cost time: 43.76878809928894
Epoch: 65, Steps: 140 | Train Loss: 0.2271849 Vali Loss: 0.1954611 Test Loss: 0.2212633
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.2520747
	speed: 0.7617s/iter; left time: 3656.8399s
Epoch: 66 cost time: 44.796408891677856
Epoch: 66, Steps: 140 | Train Loss: 0.2272365 Vali Loss: 0.1954829 Test Loss: 0.2212616
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.2451403
	speed: 0.7876s/iter; left time: 3670.8083s
Epoch: 67 cost time: 43.09941840171814
Epoch: 67, Steps: 140 | Train Loss: 0.2272364 Vali Loss: 0.1957314 Test Loss: 0.2212592
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.2386825
	speed: 0.7906s/iter; left time: 3574.1466s
Epoch: 68 cost time: 44.748677015304565
Epoch: 68, Steps: 140 | Train Loss: 0.2272407 Vali Loss: 0.1954111 Test Loss: 0.2212577
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.2273930
	speed: 0.7565s/iter; left time: 3314.4354s
Epoch: 69 cost time: 44.529651403427124
Epoch: 69, Steps: 140 | Train Loss: 0.2272571 Vali Loss: 0.1955659 Test Loss: 0.2212564
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.2280290
	speed: 0.7543s/iter; left time: 3198.9586s
Epoch: 70 cost time: 43.77160620689392
Epoch: 70, Steps: 140 | Train Loss: 0.2272509 Vali Loss: 0.1956540 Test Loss: 0.2212561
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.2142072
	speed: 0.7727s/iter; left time: 3168.6709s
Epoch: 71 cost time: 40.90941905975342
Epoch: 71, Steps: 140 | Train Loss: 0.2273037 Vali Loss: 0.1957174 Test Loss: 0.2212567
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.2208912
	speed: 0.7478s/iter; left time: 2962.1226s
Epoch: 72 cost time: 43.95694327354431
Epoch: 72, Steps: 140 | Train Loss: 0.2272400 Vali Loss: 0.1956056 Test Loss: 0.2212546
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.2268108
	speed: 0.7664s/iter; left time: 2928.4744s
Epoch: 73 cost time: 43.44304013252258
Epoch: 73, Steps: 140 | Train Loss: 0.2272552 Vali Loss: 0.1957499 Test Loss: 0.2212527
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.2232497
	speed: 0.7418s/iter; left time: 2730.3950s
Epoch: 74 cost time: 40.73502063751221
Epoch: 74, Steps: 140 | Train Loss: 0.2272447 Vali Loss: 0.1957179 Test Loss: 0.2212547
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.2257154
	speed: 0.7589s/iter; left time: 2687.1713s
Epoch: 75 cost time: 42.90400147438049
Epoch: 75, Steps: 140 | Train Loss: 0.2272812 Vali Loss: 0.1957832 Test Loss: 0.2212541
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.2351940
	speed: 0.7244s/iter; left time: 2463.7562s
Epoch: 76 cost time: 43.037400007247925
Epoch: 76, Steps: 140 | Train Loss: 0.2272001 Vali Loss: 0.1955486 Test Loss: 0.2212533
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.2327678
	speed: 0.7360s/iter; left time: 2400.1210s
Epoch: 77 cost time: 41.724289417266846
Epoch: 77, Steps: 140 | Train Loss: 0.2272098 Vali Loss: 0.1956325 Test Loss: 0.2212529
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.2345575
	speed: 0.7347s/iter; left time: 2293.1333s
Epoch: 78 cost time: 40.62303876876831
Epoch: 78, Steps: 140 | Train Loss: 0.2272267 Vali Loss: 0.1957632 Test Loss: 0.2212537
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.2301789
	speed: 0.7320s/iter; left time: 2181.9718s
Epoch: 79 cost time: 43.48821949958801
Epoch: 79, Steps: 140 | Train Loss: 0.2271399 Vali Loss: 0.1956840 Test Loss: 0.2212518
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.2264691
	speed: 0.7531s/iter; left time: 2139.5033s
Epoch: 80 cost time: 42.805150747299194
Epoch: 80, Steps: 140 | Train Loss: 0.2272305 Vali Loss: 0.1955341 Test Loss: 0.2212510
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.2247298
	speed: 0.7547s/iter; left time: 2038.5404s
Epoch: 81 cost time: 41.740642786026
Epoch: 81, Steps: 140 | Train Loss: 0.2272051 Vali Loss: 0.1955858 Test Loss: 0.2212510
EarlyStopping counter: 19 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.2249836
	speed: 0.7632s/iter; left time: 1954.5996s
Epoch: 82 cost time: 42.75402569770813
Epoch: 82, Steps: 140 | Train Loss: 0.2272338 Vali Loss: 0.1955968 Test Loss: 0.2212499
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_90_j336_H6_FITS_custom_ftM_sl90_ll48_pl336_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4925
mse:0.21981339156627655, mae:0.30022940039634705, rse:0.4666253626346588, corr:[0.4553363  0.45336547 0.4528859  0.45127758 0.4508704  0.45039633
 0.44993946 0.44938228 0.448405   0.4473339  0.4465381  0.4461117
 0.44573864 0.44506496 0.44503775 0.44441333 0.44450545 0.4447298
 0.44477156 0.44484827 0.44467217 0.44482872 0.4447332  0.44361004
 0.44151187 0.44017935 0.43894398 0.43796596 0.43764988 0.43756962
 0.4384517  0.43869087 0.43809965 0.43779436 0.43727908 0.436953
 0.43703407 0.43664593 0.4366473  0.4362827  0.4362921  0.4364763
 0.43655777 0.43665725 0.43674022 0.4370836  0.43707007 0.43673372
 0.43573433 0.43537214 0.43527877 0.4354359  0.43640086 0.43773162
 0.4398927  0.44136065 0.44136006 0.44133866 0.4411179  0.44083098
 0.4407786  0.4404694  0.44065574 0.44065496 0.44080675 0.44110847
 0.4413898  0.44157082 0.44189593 0.44246253 0.44279087 0.44315046
 0.44328102 0.4438147  0.4444574  0.44555637 0.4474658  0.44991717
 0.45314914 0.4555932  0.45581245 0.45551252 0.4550761  0.45460624
 0.45440626 0.45408937 0.45429698 0.45426282 0.45448303 0.454814
 0.45500854 0.45523474 0.45537567 0.4555241  0.4556932  0.45576274
 0.45551413 0.4555061  0.4553487  0.45531318 0.4554205  0.45543393
 0.45585582 0.4559344  0.45551163 0.45524794 0.45482284 0.45449093
 0.45446616 0.45421633 0.45441833 0.45443392 0.45458403 0.45487833
 0.45501336 0.45507315 0.45509142 0.45519355 0.45531467 0.45543414
 0.4552321  0.4552759  0.45516405 0.45513958 0.45521495 0.4550856
 0.4553126  0.45522803 0.45481643 0.4546709  0.45434174 0.45405254
 0.4541357  0.45399195 0.45420924 0.45429507 0.45448822 0.45480973
 0.4549884  0.45507398 0.455079   0.45518455 0.45519766 0.4550648
 0.45467597 0.45454216 0.45436722 0.45431444 0.45445323 0.45441127
 0.45465705 0.45468563 0.45422813 0.4539664  0.45361888 0.45325893
 0.45336303 0.45329738 0.45356452 0.45374116 0.45403656 0.45446077
 0.45471358 0.4547686  0.4544983  0.45428494 0.45344242 0.45095733
 0.4480832  0.4457838  0.4439739  0.44254574 0.44155204 0.44087663
 0.44077274 0.44051036 0.43998697 0.43952182 0.43918437 0.43891025
 0.43890348 0.4386513  0.43861607 0.4383012  0.43813753 0.43814835
 0.43797317 0.43786776 0.43755457 0.4373659  0.43674946 0.43499702
 0.43277228 0.43128586 0.4300834  0.42929623 0.42900646 0.42925835
 0.4302645  0.4308096  0.4307076  0.43050894 0.43037045 0.4302219
 0.43037543 0.43025514 0.4303061  0.43008274 0.42997077 0.43008122
 0.42998618 0.4299686  0.4299332  0.43006003 0.4298995  0.42927068
 0.42831892 0.42791873 0.4278303  0.42812654 0.42897668 0.43056872
 0.4328484  0.43456513 0.43497905 0.43504795 0.43507904 0.43484592
 0.43487507 0.43471858 0.43482125 0.43481472 0.43487993 0.43511575
 0.43525955 0.4354259  0.43559757 0.43607646 0.436371   0.43650103
 0.4367186  0.43726963 0.43795502 0.43913913 0.440933   0.44354972
 0.44681853 0.44952694 0.45011553 0.4498645  0.44972324 0.44936228
 0.44923317 0.44898504 0.4491302  0.4491003  0.44920647 0.4494971
 0.44955355 0.44971815 0.4498227  0.44997323 0.45010132 0.45005164
 0.44985116 0.4497918  0.44966006 0.44973338 0.44974676 0.449938
 0.4504165  0.45062146 0.45039117 0.45011887 0.44990528 0.44953853
 0.4495274  0.44929218 0.44939983 0.4493511  0.4493658  0.44964263
 0.44964027 0.44964954 0.44960228 0.4496572  0.4497693  0.44976738
 0.44961548 0.44964758 0.44956714 0.44966158 0.44967043 0.44972605
 0.4500282  0.45004168 0.44976157 0.44961786 0.44945505 0.44909838
 0.4492616  0.44907698 0.44919994 0.44922736 0.4492505  0.44950378
 0.4494843  0.44947827 0.4493895  0.44947696 0.4494934  0.4492319
 0.4489556  0.44880942 0.44866863 0.4487824  0.4487537  0.4489292
 0.44929135 0.44935894 0.44909412 0.44906384 0.4489088  0.44852954
 0.44885343 0.4485898  0.44871175 0.44870898 0.44869155 0.4489114
 0.44893774 0.44879335 0.44879484 0.44867146 0.44818386 0.44781962]
