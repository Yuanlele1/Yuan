Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=34, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_90_j336_H6', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_90_j336_H6_FITS_custom_ftM_sl90_ll48_pl336_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17987
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=34, out_features=160, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  223518720.0
params:  5600.0
Trainable parameters:  5600
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.8852629
	speed: 0.5934s/iter; left time: 8248.3694s
Epoch: 1 cost time: 82.909827709198
Epoch: 1, Steps: 140 | Train Loss: 1.1439717 Vali Loss: 0.6500398 Test Loss: 0.7251486
Validation loss decreased (inf --> 0.650040).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5128692
	speed: 1.4612s/iter; left time: 20108.1835s
Epoch: 2 cost time: 83.59604597091675
Epoch: 2, Steps: 140 | Train Loss: 0.5629801 Vali Loss: 0.4372366 Test Loss: 0.4923298
Validation loss decreased (0.650040 --> 0.437237).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3630758
	speed: 1.4476s/iter; left time: 19717.9707s
Epoch: 3 cost time: 82.02334523200989
Epoch: 3, Steps: 140 | Train Loss: 0.4024707 Vali Loss: 0.3471873 Test Loss: 0.3922812
Validation loss decreased (0.437237 --> 0.347187).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3162742
	speed: 1.4442s/iter; left time: 19469.1082s
Epoch: 4 cost time: 84.21196842193604
Epoch: 4, Steps: 140 | Train Loss: 0.3246873 Vali Loss: 0.2973588 Test Loss: 0.3365571
Validation loss decreased (0.347187 --> 0.297359).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2798572
	speed: 1.4268s/iter; left time: 19035.1066s
Epoch: 5 cost time: 82.75265073776245
Epoch: 5, Steps: 140 | Train Loss: 0.2799870 Vali Loss: 0.2678609 Test Loss: 0.3029366
Validation loss decreased (0.297359 --> 0.267861).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2459300
	speed: 1.4054s/iter; left time: 18552.4952s
Epoch: 6 cost time: 79.62713384628296
Epoch: 6, Steps: 140 | Train Loss: 0.2526123 Vali Loss: 0.2492360 Test Loss: 0.2816593
Validation loss decreased (0.267861 --> 0.249236).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2325108
	speed: 1.4249s/iter; left time: 18611.2124s
Epoch: 7 cost time: 83.02596378326416
Epoch: 7, Steps: 140 | Train Loss: 0.2349750 Vali Loss: 0.2371261 Test Loss: 0.2676472
Validation loss decreased (0.249236 --> 0.237126).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2333750
	speed: 1.4296s/iter; left time: 18472.2182s
Epoch: 8 cost time: 82.15746116638184
Epoch: 8, Steps: 140 | Train Loss: 0.2233326 Vali Loss: 0.2288989 Test Loss: 0.2582025
Validation loss decreased (0.237126 --> 0.228899).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2040876
	speed: 1.3629s/iter; left time: 17419.4540s
Epoch: 9 cost time: 80.12577509880066
Epoch: 9, Steps: 140 | Train Loss: 0.2153143 Vali Loss: 0.2230219 Test Loss: 0.2514615
Validation loss decreased (0.228899 --> 0.223022).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2040731
	speed: 1.4058s/iter; left time: 17770.2686s
Epoch: 10 cost time: 79.45088934898376
Epoch: 10, Steps: 140 | Train Loss: 0.2095481 Vali Loss: 0.2183097 Test Loss: 0.2466403
Validation loss decreased (0.223022 --> 0.218310).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2103301
	speed: 1.3651s/iter; left time: 17064.6256s
Epoch: 11 cost time: 78.11367893218994
Epoch: 11, Steps: 140 | Train Loss: 0.2052984 Vali Loss: 0.2151946 Test Loss: 0.2428862
Validation loss decreased (0.218310 --> 0.215195).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2081187
	speed: 1.3460s/iter; left time: 16637.5813s
Epoch: 12 cost time: 76.75933504104614
Epoch: 12, Steps: 140 | Train Loss: 0.2020980 Vali Loss: 0.2126962 Test Loss: 0.2401203
Validation loss decreased (0.215195 --> 0.212696).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2018133
	speed: 1.3743s/iter; left time: 16795.2572s
Epoch: 13 cost time: 79.59116530418396
Epoch: 13, Steps: 140 | Train Loss: 0.1994609 Vali Loss: 0.2103793 Test Loss: 0.2378364
Validation loss decreased (0.212696 --> 0.210379).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1967188
	speed: 1.3698s/iter; left time: 16549.0834s
Epoch: 14 cost time: 78.85465788841248
Epoch: 14, Steps: 140 | Train Loss: 0.1975155 Vali Loss: 0.2092621 Test Loss: 0.2360167
Validation loss decreased (0.210379 --> 0.209262).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1970140
	speed: 1.3548s/iter; left time: 16177.8828s
Epoch: 15 cost time: 78.46943712234497
Epoch: 15, Steps: 140 | Train Loss: 0.1957993 Vali Loss: 0.2074764 Test Loss: 0.2345113
Validation loss decreased (0.209262 --> 0.207476).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1945649
	speed: 1.3167s/iter; left time: 15537.8807s
Epoch: 16 cost time: 74.19201159477234
Epoch: 16, Steps: 140 | Train Loss: 0.1944555 Vali Loss: 0.2066657 Test Loss: 0.2332207
Validation loss decreased (0.207476 --> 0.206666).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1895449
	speed: 1.2699s/iter; left time: 14808.5014s
Epoch: 17 cost time: 69.41856575012207
Epoch: 17, Steps: 140 | Train Loss: 0.1932601 Vali Loss: 0.2054069 Test Loss: 0.2321307
Validation loss decreased (0.206666 --> 0.205407).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1822736
	speed: 1.3067s/iter; left time: 15054.5525s
Epoch: 18 cost time: 77.37407493591309
Epoch: 18, Steps: 140 | Train Loss: 0.1922968 Vali Loss: 0.2046172 Test Loss: 0.2312159
Validation loss decreased (0.205407 --> 0.204617).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1953437
	speed: 1.3480s/iter; left time: 15341.3345s
Epoch: 19 cost time: 75.54379653930664
Epoch: 19, Steps: 140 | Train Loss: 0.1914435 Vali Loss: 0.2041239 Test Loss: 0.2304265
Validation loss decreased (0.204617 --> 0.204124).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1855884
	speed: 1.3455s/iter; left time: 15125.2593s
Epoch: 20 cost time: 76.15847420692444
Epoch: 20, Steps: 140 | Train Loss: 0.1906694 Vali Loss: 0.2033516 Test Loss: 0.2297298
Validation loss decreased (0.204124 --> 0.203352).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1833706
	speed: 1.3209s/iter; left time: 14663.2812s
Epoch: 21 cost time: 75.90041255950928
Epoch: 21, Steps: 140 | Train Loss: 0.1899523 Vali Loss: 0.2028018 Test Loss: 0.2291387
Validation loss decreased (0.203352 --> 0.202802).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1835218
	speed: 1.3120s/iter; left time: 14380.5405s
Epoch: 22 cost time: 78.68646502494812
Epoch: 22, Steps: 140 | Train Loss: 0.1894643 Vali Loss: 0.2023522 Test Loss: 0.2285815
Validation loss decreased (0.202802 --> 0.202352).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1814221
	speed: 1.2503s/iter; left time: 13530.0212s
Epoch: 23 cost time: 69.2074077129364
Epoch: 23, Steps: 140 | Train Loss: 0.1889397 Vali Loss: 0.2019092 Test Loss: 0.2281182
Validation loss decreased (0.202352 --> 0.201909).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1871091
	speed: 1.2208s/iter; left time: 13039.2858s
Epoch: 24 cost time: 65.06706357002258
Epoch: 24, Steps: 140 | Train Loss: 0.1884852 Vali Loss: 0.2011228 Test Loss: 0.2276858
Validation loss decreased (0.201909 --> 0.201123).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1839194
	speed: 1.0859s/iter; left time: 11446.8608s
Epoch: 25 cost time: 64.28125667572021
Epoch: 25, Steps: 140 | Train Loss: 0.1880383 Vali Loss: 0.2009876 Test Loss: 0.2273017
Validation loss decreased (0.201123 --> 0.200988).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1876829
	speed: 1.0745s/iter; left time: 11175.6731s
Epoch: 26 cost time: 63.07226777076721
Epoch: 26, Steps: 140 | Train Loss: 0.1876872 Vali Loss: 0.2007703 Test Loss: 0.2269668
Validation loss decreased (0.200988 --> 0.200770).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1900854
	speed: 1.0785s/iter; left time: 11066.9222s
Epoch: 27 cost time: 65.21335315704346
Epoch: 27, Steps: 140 | Train Loss: 0.1873492 Vali Loss: 0.2005786 Test Loss: 0.2266825
Validation loss decreased (0.200770 --> 0.200579).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1754712
	speed: 1.1294s/iter; left time: 11430.4971s
Epoch: 28 cost time: 65.67447996139526
Epoch: 28, Steps: 140 | Train Loss: 0.1870458 Vali Loss: 0.2004604 Test Loss: 0.2264044
Validation loss decreased (0.200579 --> 0.200460).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1841553
	speed: 1.1378s/iter; left time: 11356.4711s
Epoch: 29 cost time: 64.51676654815674
Epoch: 29, Steps: 140 | Train Loss: 0.1868362 Vali Loss: 0.2002078 Test Loss: 0.2261229
Validation loss decreased (0.200460 --> 0.200208).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1875532
	speed: 1.1496s/iter; left time: 11313.0125s
Epoch: 30 cost time: 62.26645350456238
Epoch: 30, Steps: 140 | Train Loss: 0.1865109 Vali Loss: 0.1997770 Test Loss: 0.2258929
Validation loss decreased (0.200208 --> 0.199777).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1882426
	speed: 1.1670s/iter; left time: 11321.4586s
Epoch: 31 cost time: 66.93844866752625
Epoch: 31, Steps: 140 | Train Loss: 0.1863026 Vali Loss: 0.1996651 Test Loss: 0.2256918
Validation loss decreased (0.199777 --> 0.199665).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1946251
	speed: 1.1481s/iter; left time: 10976.9144s
Epoch: 32 cost time: 65.42283248901367
Epoch: 32, Steps: 140 | Train Loss: 0.1861577 Vali Loss: 0.1993796 Test Loss: 0.2255014
Validation loss decreased (0.199665 --> 0.199380).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1910953
	speed: 1.0838s/iter; left time: 10210.0156s
Epoch: 33 cost time: 64.60446405410767
Epoch: 33, Steps: 140 | Train Loss: 0.1858987 Vali Loss: 0.1990778 Test Loss: 0.2253123
Validation loss decreased (0.199380 --> 0.199078).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1814640
	speed: 1.0963s/iter; left time: 10175.1766s
Epoch: 34 cost time: 64.52305436134338
Epoch: 34, Steps: 140 | Train Loss: 0.1857459 Vali Loss: 0.1994242 Test Loss: 0.2251418
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1782574
	speed: 1.0779s/iter; left time: 9853.1963s
Epoch: 35 cost time: 63.36261701583862
Epoch: 35, Steps: 140 | Train Loss: 0.1855234 Vali Loss: 0.1988396 Test Loss: 0.2249889
Validation loss decreased (0.199078 --> 0.198840).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1793319
	speed: 1.1251s/iter; left time: 10126.7656s
Epoch: 36 cost time: 65.22306036949158
Epoch: 36, Steps: 140 | Train Loss: 0.1853765 Vali Loss: 0.1992778 Test Loss: 0.2248460
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1770459
	speed: 1.0808s/iter; left time: 9576.9595s
Epoch: 37 cost time: 61.12379169464111
Epoch: 37, Steps: 140 | Train Loss: 0.1852452 Vali Loss: 0.1988459 Test Loss: 0.2247128
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1817413
	speed: 1.0710s/iter; left time: 9340.2401s
Epoch: 38 cost time: 59.48462510108948
Epoch: 38, Steps: 140 | Train Loss: 0.1851098 Vali Loss: 0.1985957 Test Loss: 0.2245820
Validation loss decreased (0.198840 --> 0.198596).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1805015
	speed: 1.1302s/iter; left time: 9698.5084s
Epoch: 39 cost time: 65.19993758201599
Epoch: 39, Steps: 140 | Train Loss: 0.1849884 Vali Loss: 0.1986603 Test Loss: 0.2244719
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1792043
	speed: 1.0623s/iter; left time: 8966.6776s
Epoch: 40 cost time: 61.967392683029175
Epoch: 40, Steps: 140 | Train Loss: 0.1848251 Vali Loss: 0.1983379 Test Loss: 0.2243504
Validation loss decreased (0.198596 --> 0.198338).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1818415
	speed: 1.0749s/iter; left time: 8922.4546s
Epoch: 41 cost time: 59.865686893463135
Epoch: 41, Steps: 140 | Train Loss: 0.1847999 Vali Loss: 0.1981885 Test Loss: 0.2242445
Validation loss decreased (0.198338 --> 0.198188).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1831556
	speed: 1.0432s/iter; left time: 8513.2505s
Epoch: 42 cost time: 59.72202229499817
Epoch: 42, Steps: 140 | Train Loss: 0.1846222 Vali Loss: 0.1984565 Test Loss: 0.2241592
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1771046
	speed: 1.0763s/iter; left time: 8633.2504s
Epoch: 43 cost time: 61.57717418670654
Epoch: 43, Steps: 140 | Train Loss: 0.1845920 Vali Loss: 0.1981899 Test Loss: 0.2240690
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1819960
	speed: 1.0950s/iter; left time: 8629.5087s
Epoch: 44 cost time: 64.56739640235901
Epoch: 44, Steps: 140 | Train Loss: 0.1844862 Vali Loss: 0.1982740 Test Loss: 0.2239740
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1890410
	speed: 1.0720s/iter; left time: 8298.2464s
Epoch: 45 cost time: 61.590458393096924
Epoch: 45, Steps: 140 | Train Loss: 0.1843091 Vali Loss: 0.1981088 Test Loss: 0.2238913
Validation loss decreased (0.198188 --> 0.198109).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1867518
	speed: 1.0607s/iter; left time: 8062.6766s
Epoch: 46 cost time: 60.24835181236267
Epoch: 46, Steps: 140 | Train Loss: 0.1842565 Vali Loss: 0.1978187 Test Loss: 0.2238252
Validation loss decreased (0.198109 --> 0.197819).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1898120
	speed: 1.0401s/iter; left time: 7759.9333s
Epoch: 47 cost time: 57.9739453792572
Epoch: 47, Steps: 140 | Train Loss: 0.1841867 Vali Loss: 0.1976029 Test Loss: 0.2237494
Validation loss decreased (0.197819 --> 0.197603).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1859328
	speed: 1.0088s/iter; left time: 7385.1787s
Epoch: 48 cost time: 58.06140327453613
Epoch: 48, Steps: 140 | Train Loss: 0.1841689 Vali Loss: 0.1975878 Test Loss: 0.2236871
Validation loss decreased (0.197603 --> 0.197588).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1664321
	speed: 1.0076s/iter; left time: 7235.7116s
Epoch: 49 cost time: 56.769338607788086
Epoch: 49, Steps: 140 | Train Loss: 0.1840539 Vali Loss: 0.1974922 Test Loss: 0.2236177
Validation loss decreased (0.197588 --> 0.197492).  Saving model ...
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1770277
	speed: 0.9199s/iter; left time: 6476.9948s
Epoch: 50 cost time: 51.46890664100647
Epoch: 50, Steps: 140 | Train Loss: 0.1839788 Vali Loss: 0.1973097 Test Loss: 0.2235634
Validation loss decreased (0.197492 --> 0.197310).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1814848
	speed: 0.9556s/iter; left time: 6594.4591s
Epoch: 51 cost time: 52.874655961990356
Epoch: 51, Steps: 140 | Train Loss: 0.1839485 Vali Loss: 0.1975142 Test Loss: 0.2235114
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1895315
	speed: 0.8978s/iter; left time: 6069.8330s
Epoch: 52 cost time: 52.56156134605408
Epoch: 52, Steps: 140 | Train Loss: 0.1838648 Vali Loss: 0.1976011 Test Loss: 0.2234543
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1898147
	speed: 0.9291s/iter; left time: 6151.2520s
Epoch: 53 cost time: 50.196229457855225
Epoch: 53, Steps: 140 | Train Loss: 0.1838182 Vali Loss: 0.1975978 Test Loss: 0.2234063
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1800189
	speed: 0.9192s/iter; left time: 5957.2498s
Epoch: 54 cost time: 55.47698664665222
Epoch: 54, Steps: 140 | Train Loss: 0.1837328 Vali Loss: 0.1978362 Test Loss: 0.2233568
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1856560
	speed: 0.8530s/iter; left time: 5408.9473s
Epoch: 55 cost time: 46.56950497627258
Epoch: 55, Steps: 140 | Train Loss: 0.1836805 Vali Loss: 0.1971442 Test Loss: 0.2233070
Validation loss decreased (0.197310 --> 0.197144).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1794549
	speed: 0.8067s/iter; left time: 5002.6470s
Epoch: 56 cost time: 43.661858797073364
Epoch: 56, Steps: 140 | Train Loss: 0.1836749 Vali Loss: 0.1971720 Test Loss: 0.2232685
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.1840585
	speed: 0.7950s/iter; left time: 4818.2628s
Epoch: 57 cost time: 45.90504765510559
Epoch: 57, Steps: 140 | Train Loss: 0.1835489 Vali Loss: 0.1972141 Test Loss: 0.2232209
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1855510
	speed: 0.7714s/iter; left time: 4567.4539s
Epoch: 58 cost time: 43.881025075912476
Epoch: 58, Steps: 140 | Train Loss: 0.1836076 Vali Loss: 0.1972909 Test Loss: 0.2231850
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1892887
	speed: 0.7920s/iter; left time: 4578.5851s
Epoch: 59 cost time: 45.78254699707031
Epoch: 59, Steps: 140 | Train Loss: 0.1836021 Vali Loss: 0.1972395 Test Loss: 0.2231547
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1842833
	speed: 0.8105s/iter; left time: 4572.1659s
Epoch: 60 cost time: 47.390400648117065
Epoch: 60, Steps: 140 | Train Loss: 0.1834812 Vali Loss: 0.1972773 Test Loss: 0.2231206
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1842695
	speed: 0.7792s/iter; left time: 4286.4233s
Epoch: 61 cost time: 42.719491958618164
Epoch: 61, Steps: 140 | Train Loss: 0.1835259 Vali Loss: 0.1970844 Test Loss: 0.2230907
Validation loss decreased (0.197144 --> 0.197084).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1791621
	speed: 0.7164s/iter; left time: 3840.5237s
Epoch: 62 cost time: 40.696343660354614
Epoch: 62, Steps: 140 | Train Loss: 0.1834547 Vali Loss: 0.1968274 Test Loss: 0.2230595
Validation loss decreased (0.197084 --> 0.196827).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1835441
	speed: 0.7302s/iter; left time: 3812.2549s
Epoch: 63 cost time: 41.99673008918762
Epoch: 63, Steps: 140 | Train Loss: 0.1834265 Vali Loss: 0.1972433 Test Loss: 0.2230314
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1810381
	speed: 0.8704s/iter; left time: 4422.6651s
Epoch: 64 cost time: 59.955339193344116
Epoch: 64, Steps: 140 | Train Loss: 0.1833837 Vali Loss: 0.1971512 Test Loss: 0.2230050
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.1804632
	speed: 1.0606s/iter; left time: 5240.5786s
Epoch: 65 cost time: 61.17794227600098
Epoch: 65, Steps: 140 | Train Loss: 0.1833027 Vali Loss: 0.1969727 Test Loss: 0.2229808
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.2030765
	speed: 1.0353s/iter; left time: 4970.2505s
Epoch: 66 cost time: 58.84351849555969
Epoch: 66, Steps: 140 | Train Loss: 0.1833181 Vali Loss: 0.1969748 Test Loss: 0.2229573
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.1974930
	speed: 1.0189s/iter; left time: 4748.9833s
Epoch: 67 cost time: 59.9177520275116
Epoch: 67, Steps: 140 | Train Loss: 0.1832951 Vali Loss: 0.1972047 Test Loss: 0.2229364
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.1924142
	speed: 1.0116s/iter; left time: 4573.3075s
Epoch: 68 cost time: 59.748937368392944
Epoch: 68, Steps: 140 | Train Loss: 0.1832745 Vali Loss: 0.1968566 Test Loss: 0.2229122
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.1834317
	speed: 1.0457s/iter; left time: 4581.1114s
Epoch: 69 cost time: 61.633976221084595
Epoch: 69, Steps: 140 | Train Loss: 0.1832671 Vali Loss: 0.1970153 Test Loss: 0.2228952
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.1838821
	speed: 1.0663s/iter; left time: 4522.1645s
Epoch: 70 cost time: 63.83074951171875
Epoch: 70, Steps: 140 | Train Loss: 0.1832425 Vali Loss: 0.1970716 Test Loss: 0.2228786
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.1726869
	speed: 1.0505s/iter; left time: 4308.0986s
Epoch: 71 cost time: 57.797921895980835
Epoch: 71, Steps: 140 | Train Loss: 0.1832671 Vali Loss: 0.1971297 Test Loss: 0.2228603
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.1778761
	speed: 1.1820s/iter; left time: 4682.0874s
Epoch: 72 cost time: 68.71945548057556
Epoch: 72, Steps: 140 | Train Loss: 0.1831985 Vali Loss: 0.1970137 Test Loss: 0.2228442
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.1829784
	speed: 1.1843s/iter; left time: 4525.2713s
Epoch: 73 cost time: 68.12799167633057
Epoch: 73, Steps: 140 | Train Loss: 0.1831954 Vali Loss: 0.1971333 Test Loss: 0.2228302
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.1801603
	speed: 1.1170s/iter; left time: 4111.7838s
Epoch: 74 cost time: 65.0560941696167
Epoch: 74, Steps: 140 | Train Loss: 0.1831709 Vali Loss: 0.1970821 Test Loss: 0.2228156
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.1819302
	speed: 1.1710s/iter; left time: 4146.5496s
Epoch: 75 cost time: 65.51122069358826
Epoch: 75, Steps: 140 | Train Loss: 0.1831855 Vali Loss: 0.1971426 Test Loss: 0.2228010
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.1894329
	speed: 1.0987s/iter; left time: 3736.7000s
Epoch: 76 cost time: 64.77840304374695
Epoch: 76, Steps: 140 | Train Loss: 0.1831063 Vali Loss: 0.1968792 Test Loss: 0.2227904
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.1875219
	speed: 1.1443s/iter; left time: 3731.4592s
Epoch: 77 cost time: 64.64863395690918
Epoch: 77, Steps: 140 | Train Loss: 0.1831019 Vali Loss: 0.1969574 Test Loss: 0.2227760
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.1886537
	speed: 1.1600s/iter; left time: 3620.4490s
Epoch: 78 cost time: 65.60354971885681
Epoch: 78, Steps: 140 | Train Loss: 0.1831029 Vali Loss: 0.1970804 Test Loss: 0.2227668
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.1853800
	speed: 1.0574s/iter; left time: 3152.0069s
Epoch: 79 cost time: 58.34989666938782
Epoch: 79, Steps: 140 | Train Loss: 0.1830214 Vali Loss: 0.1969958 Test Loss: 0.2227562
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.1825854
	speed: 0.9855s/iter; left time: 2799.7981s
Epoch: 80 cost time: 59.08222579956055
Epoch: 80, Steps: 140 | Train Loss: 0.1830851 Vali Loss: 0.1968359 Test Loss: 0.2227439
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.1810260
	speed: 1.0435s/iter; left time: 2818.4588s
Epoch: 81 cost time: 58.169400691986084
Epoch: 81, Steps: 140 | Train Loss: 0.1830530 Vali Loss: 0.1968742 Test Loss: 0.2227358
EarlyStopping counter: 19 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.1812658
	speed: 1.0130s/iter; left time: 2594.1744s
Epoch: 82 cost time: 56.930155754089355
Epoch: 82, Steps: 140 | Train Loss: 0.1830688 Vali Loss: 0.1968834 Test Loss: 0.2227262
EarlyStopping counter: 20 out of 20
Early stopping
train 17987
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=34, out_features=160, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  223518720.0
params:  5600.0
Trainable parameters:  5600
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2287229
	speed: 0.4096s/iter; left time: 5693.1965s
Epoch: 1 cost time: 58.90420436859131
Epoch: 1, Steps: 140 | Train Loss: 0.2281353 Vali Loss: 0.1957563 Test Loss: 0.2216445
Validation loss decreased (inf --> 0.195756).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2253966
	speed: 1.1896s/iter; left time: 16370.3231s
Epoch: 2 cost time: 69.30137872695923
Epoch: 2, Steps: 140 | Train Loss: 0.2275473 Vali Loss: 0.1956700 Test Loss: 0.2214372
Validation loss decreased (0.195756 --> 0.195670).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2241471
	speed: 1.1735s/iter; left time: 15983.9583s
Epoch: 3 cost time: 65.88188028335571
Epoch: 3, Steps: 140 | Train Loss: 0.2273913 Vali Loss: 0.1956871 Test Loss: 0.2213751
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2306612
	speed: 1.1456s/iter; left time: 15444.4462s
Epoch: 4 cost time: 67.45714235305786
Epoch: 4, Steps: 140 | Train Loss: 0.2273619 Vali Loss: 0.1958795 Test Loss: 0.2213527
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2257494
	speed: 1.1290s/iter; left time: 15061.9883s
Epoch: 5 cost time: 65.53928112983704
Epoch: 5, Steps: 140 | Train Loss: 0.2273325 Vali Loss: 0.1954887 Test Loss: 0.2213390
Validation loss decreased (0.195670 --> 0.195489).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2349789
	speed: 1.1237s/iter; left time: 14834.4165s
Epoch: 6 cost time: 66.46250247955322
Epoch: 6, Steps: 140 | Train Loss: 0.2273064 Vali Loss: 0.1958130 Test Loss: 0.2212923
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2243868
	speed: 1.2012s/iter; left time: 15688.4603s
Epoch: 7 cost time: 67.79101347923279
Epoch: 7, Steps: 140 | Train Loss: 0.2272884 Vali Loss: 0.1953086 Test Loss: 0.2212950
Validation loss decreased (0.195489 --> 0.195309).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2247069
	speed: 1.1453s/iter; left time: 14798.5548s
Epoch: 8 cost time: 68.60194039344788
Epoch: 8, Steps: 140 | Train Loss: 0.2272815 Vali Loss: 0.1955956 Test Loss: 0.2212839
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2216585
	speed: 0.9705s/iter; left time: 12403.9998s
Epoch: 9 cost time: 47.02490782737732
Epoch: 9, Steps: 140 | Train Loss: 0.2272571 Vali Loss: 0.1949508 Test Loss: 0.2212995
Validation loss decreased (0.195309 --> 0.194951).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2425541
	speed: 0.8581s/iter; left time: 10847.4934s
Epoch: 10 cost time: 49.5503785610199
Epoch: 10, Steps: 140 | Train Loss: 0.2272344 Vali Loss: 0.1952669 Test Loss: 0.2212706
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2268266
	speed: 0.9373s/iter; left time: 11717.7067s
Epoch: 11 cost time: 54.66775441169739
Epoch: 11, Steps: 140 | Train Loss: 0.2272614 Vali Loss: 0.1955718 Test Loss: 0.2212557
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2239151
	speed: 0.9339s/iter; left time: 11543.9893s
Epoch: 12 cost time: 55.0995876789093
Epoch: 12, Steps: 140 | Train Loss: 0.2273118 Vali Loss: 0.1955702 Test Loss: 0.2212468
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2209470
	speed: 0.9304s/iter; left time: 11369.8178s
Epoch: 13 cost time: 53.06702518463135
Epoch: 13, Steps: 140 | Train Loss: 0.2271840 Vali Loss: 0.1955920 Test Loss: 0.2212333
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2385663
	speed: 0.9627s/iter; left time: 11630.7923s
Epoch: 14 cost time: 53.24550437927246
Epoch: 14, Steps: 140 | Train Loss: 0.2272405 Vali Loss: 0.1952914 Test Loss: 0.2212724
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2183195
	speed: 0.9296s/iter; left time: 11100.4111s
Epoch: 15 cost time: 54.7938551902771
Epoch: 15, Steps: 140 | Train Loss: 0.2272126 Vali Loss: 0.1955650 Test Loss: 0.2212480
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2289453
	speed: 0.9046s/iter; left time: 10675.1232s
Epoch: 16 cost time: 52.50763463973999
Epoch: 16, Steps: 140 | Train Loss: 0.2272893 Vali Loss: 0.1954238 Test Loss: 0.2212444
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2298529
	speed: 0.9321s/iter; left time: 10869.4856s
Epoch: 17 cost time: 52.06087589263916
Epoch: 17, Steps: 140 | Train Loss: 0.2272343 Vali Loss: 0.1953250 Test Loss: 0.2212431
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2322280
	speed: 0.9536s/iter; left time: 10986.4941s
Epoch: 18 cost time: 55.227869272232056
Epoch: 18, Steps: 140 | Train Loss: 0.2271415 Vali Loss: 0.1955806 Test Loss: 0.2212284
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2333401
	speed: 0.8986s/iter; left time: 10226.7699s
Epoch: 19 cost time: 52.9698281288147
Epoch: 19, Steps: 140 | Train Loss: 0.2271884 Vali Loss: 0.1953925 Test Loss: 0.2212431
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2346028
	speed: 0.9613s/iter; left time: 10806.3826s
Epoch: 20 cost time: 52.2466037273407
Epoch: 20, Steps: 140 | Train Loss: 0.2271817 Vali Loss: 0.1956844 Test Loss: 0.2212386
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2227454
	speed: 0.9533s/iter; left time: 10582.3936s
Epoch: 21 cost time: 54.80547499656677
Epoch: 21, Steps: 140 | Train Loss: 0.2271827 Vali Loss: 0.1955581 Test Loss: 0.2212337
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2431661
	speed: 0.9522s/iter; left time: 10437.2179s
Epoch: 22 cost time: 57.94411110877991
Epoch: 22, Steps: 140 | Train Loss: 0.2272191 Vali Loss: 0.1956516 Test Loss: 0.2212440
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2286836
	speed: 0.9269s/iter; left time: 10030.0744s
Epoch: 23 cost time: 51.055614948272705
Epoch: 23, Steps: 140 | Train Loss: 0.2271608 Vali Loss: 0.1954155 Test Loss: 0.2212193
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2256622
	speed: 0.9401s/iter; left time: 10041.3407s
Epoch: 24 cost time: 52.130014181137085
Epoch: 24, Steps: 140 | Train Loss: 0.2271378 Vali Loss: 0.1954872 Test Loss: 0.2212193
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2283944
	speed: 0.9498s/iter; left time: 10012.2855s
Epoch: 25 cost time: 57.685336112976074
Epoch: 25, Steps: 140 | Train Loss: 0.2272349 Vali Loss: 0.1957527 Test Loss: 0.2212481
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2227757
	speed: 0.9489s/iter; left time: 9869.0838s
Epoch: 26 cost time: 55.21215033531189
Epoch: 26, Steps: 140 | Train Loss: 0.2271687 Vali Loss: 0.1956237 Test Loss: 0.2212299
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2302363
	speed: 0.9573s/iter; left time: 9823.2047s
Epoch: 27 cost time: 52.685078620910645
Epoch: 27, Steps: 140 | Train Loss: 0.2272215 Vali Loss: 0.1955225 Test Loss: 0.2212183
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2243185
	speed: 0.9858s/iter; left time: 9977.2901s
Epoch: 28 cost time: 55.58720374107361
Epoch: 28, Steps: 140 | Train Loss: 0.2271346 Vali Loss: 0.1953646 Test Loss: 0.2212203
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2197276
	speed: 0.9425s/iter; left time: 9407.4979s
Epoch: 29 cost time: 57.14709520339966
Epoch: 29, Steps: 140 | Train Loss: 0.2270888 Vali Loss: 0.1953393 Test Loss: 0.2212323
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_90_j336_H6_FITS_custom_ftM_sl90_ll48_pl336_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4925
mse:0.2198459804058075, mae:0.3003830909729004, rse:0.4666599929332733, corr:[0.45373514 0.4548644  0.45332792 0.452234   0.45102322 0.45017025
 0.4498131  0.44907025 0.44810534 0.44711792 0.44644615 0.44607505
 0.44587448 0.4452029  0.44537613 0.4447599  0.44474322 0.4450433
 0.44490162 0.44501704 0.44485787 0.4448368  0.44461688 0.44341245
 0.44129047 0.4398804  0.43875694 0.43762764 0.43724117 0.43752787
 0.43825892 0.43855625 0.43832362 0.43801498 0.4374439  0.43713468
 0.4370745  0.43662965 0.43678114 0.43628952 0.4361836  0.436324
 0.43614295 0.43620986 0.43636152 0.43660492 0.43653807 0.43627772
 0.43531233 0.43495017 0.43509278 0.43534952 0.43633765 0.43774405
 0.43974575 0.44127306 0.44145042 0.44139782 0.44104898 0.44086906
 0.44095397 0.4405611  0.44077438 0.4407386  0.44072247 0.44088736
 0.4410704  0.44126907 0.44158405 0.44212198 0.44249883 0.4428898
 0.44299522 0.4436625  0.44444668 0.44552577 0.44748545 0.45001683
 0.4531758  0.45563552 0.4559643  0.45568728 0.4551496  0.45468876
 0.4545115  0.4542006  0.45438576 0.45423007 0.4544818  0.454866
 0.45504767 0.45529318 0.45540226 0.455479   0.45563933 0.4557115
 0.4554253  0.45544478 0.45533076 0.4553213  0.45547718 0.45545852
 0.45577276 0.4558623  0.4554485  0.45512596 0.45470107 0.45444193
 0.45436954 0.45402944 0.45422015 0.45419955 0.45435485 0.45462507
 0.45477748 0.45501643 0.45501894 0.45490292 0.45504782 0.45535335
 0.4552073  0.45521986 0.45508525 0.455002   0.4551042  0.45502856
 0.4552403  0.4552144  0.45492923 0.45473734 0.45428208 0.45404178
 0.45415768 0.45396668 0.45416138 0.4541639  0.45434386 0.4546638
 0.45480037 0.45498812 0.4550441  0.45504534 0.45507202 0.45504484
 0.4546659  0.454526   0.45430687 0.45417544 0.45431995 0.45436248
 0.45464596 0.45458528 0.45407426 0.45375663 0.45341128 0.45326877
 0.4534103  0.45323431 0.45345065 0.45358244 0.45396063 0.45443594
 0.45465487 0.45471    0.45448852 0.45433426 0.45354572 0.4511592
 0.44827318 0.4459157  0.4441888  0.44282576 0.44186845 0.44123656
 0.44098398 0.44066516 0.44024658 0.4395824  0.4391175  0.43898925
 0.43891692 0.43856615 0.43866408 0.43844444 0.43825075 0.43824658
 0.43808782 0.43792704 0.43760005 0.43745592 0.43685862 0.435213
 0.4330748  0.43153954 0.43028602 0.42948022 0.42918456 0.42944643
 0.43046477 0.43094766 0.43083042 0.43060616 0.43029135 0.42998534
 0.43012854 0.43010223 0.43024385 0.4299405  0.4298445  0.43000725
 0.42978847 0.429736   0.4297729  0.42987198 0.42967418 0.42919266
 0.4282784  0.42778194 0.42778164 0.428281   0.42929137 0.4308864
 0.43297175 0.43459356 0.43507946 0.43498507 0.43483764 0.4348163
 0.43498543 0.43475017 0.4349097  0.43498966 0.43492997 0.4350737
 0.43534788 0.43565258 0.43580088 0.43625608 0.43664634 0.43686682
 0.43708658 0.43765643 0.4383137  0.43954456 0.44135788 0.44376296
 0.44689587 0.44952053 0.45008102 0.44975698 0.44946772 0.4491142
 0.44902468 0.44880202 0.44909817 0.4491199  0.4492028  0.4495332
 0.44966233 0.4499353  0.45010403 0.4502594  0.45040736 0.4503487
 0.4500879  0.45003635 0.4497892  0.4497457  0.449834   0.44999495
 0.45032722 0.45042074 0.45019943 0.4498666  0.44946972 0.44917107
 0.44924635 0.44897616 0.4491138  0.44904962 0.44901663 0.44941998
 0.449592   0.44967502 0.4497062  0.44974875 0.44986227 0.4499557
 0.44977805 0.4497189  0.44951624 0.44952765 0.44953728 0.44946223
 0.4497779  0.44980487 0.44946235 0.4493708  0.44916865 0.4488919
 0.44901705 0.44873038 0.44887748 0.4489663  0.44904807 0.44928926
 0.4492804  0.4494256  0.44954348 0.44959384 0.44948244 0.4493169
 0.44907698 0.44888774 0.4487301  0.44876873 0.44865766 0.44863024
 0.44904116 0.44929063 0.4489538  0.4488511  0.44881183 0.44862592
 0.44897464 0.44880804 0.44883785 0.44885492 0.44867647 0.44865736
 0.4487945  0.448621   0.44855937 0.44860938 0.4484     0.4479614 ]
