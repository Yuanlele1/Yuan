Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_720_j192_H6', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_720_j192_H6_FITS_custom_ftM_sl720_ll48_pl192_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17501
val 2441
test 5069
Model(
  (freq_upsampler): Linear(in_features=196, out_features=248, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1997205504.0
params:  48856.0
Trainable parameters:  48856
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3696043
	speed: 0.7646s/iter; left time: 10322.7375s
Epoch: 1 cost time: 103.76080513000488
Epoch: 1, Steps: 136 | Train Loss: 0.5618936 Vali Loss: 0.2347317 Test Loss: 0.2827873
Validation loss decreased (inf --> 0.234732).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1798916
	speed: 1.5037s/iter; left time: 20096.7364s
Epoch: 2 cost time: 88.22315192222595
Epoch: 2, Steps: 136 | Train Loss: 0.2116258 Vali Loss: 0.1433491 Test Loss: 0.1748990
Validation loss decreased (0.234732 --> 0.143349).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1672660
	speed: 1.4680s/iter; left time: 19420.6363s
Epoch: 3 cost time: 90.15821480751038
Epoch: 3, Steps: 136 | Train Loss: 0.1658599 Vali Loss: 0.1347786 Test Loss: 0.1631083
Validation loss decreased (0.143349 --> 0.134779).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1559504
	speed: 1.4223s/iter; left time: 18621.8010s
Epoch: 4 cost time: 89.90439772605896
Epoch: 4, Steps: 136 | Train Loss: 0.1604474 Vali Loss: 0.1335306 Test Loss: 0.1611505
Validation loss decreased (0.134779 --> 0.133531).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1485889
	speed: 1.4645s/iter; left time: 18975.0730s
Epoch: 5 cost time: 88.95400953292847
Epoch: 5, Steps: 136 | Train Loss: 0.1589446 Vali Loss: 0.1328257 Test Loss: 0.1603205
Validation loss decreased (0.133531 --> 0.132826).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1661952
	speed: 1.4669s/iter; left time: 18806.5059s
Epoch: 6 cost time: 90.16920614242554
Epoch: 6, Steps: 136 | Train Loss: 0.1582169 Vali Loss: 0.1325602 Test Loss: 0.1599382
Validation loss decreased (0.132826 --> 0.132560).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1585125
	speed: 1.3737s/iter; left time: 17425.7944s
Epoch: 7 cost time: 87.30019450187683
Epoch: 7, Steps: 136 | Train Loss: 0.1577678 Vali Loss: 0.1323839 Test Loss: 0.1596462
Validation loss decreased (0.132560 --> 0.132384).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1546459
	speed: 1.4467s/iter; left time: 18154.2778s
Epoch: 8 cost time: 87.87885570526123
Epoch: 8, Steps: 136 | Train Loss: 0.1574499 Vali Loss: 0.1322257 Test Loss: 0.1594396
Validation loss decreased (0.132384 --> 0.132226).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1538206
	speed: 1.4416s/iter; left time: 17894.6946s
Epoch: 9 cost time: 91.50252914428711
Epoch: 9, Steps: 136 | Train Loss: 0.1572179 Vali Loss: 0.1321559 Test Loss: 0.1593451
Validation loss decreased (0.132226 --> 0.132156).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1665395
	speed: 1.4387s/iter; left time: 17662.8608s
Epoch: 10 cost time: 88.81616187095642
Epoch: 10, Steps: 136 | Train Loss: 0.1570158 Vali Loss: 0.1319903 Test Loss: 0.1592118
Validation loss decreased (0.132156 --> 0.131990).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1469825
	speed: 1.4185s/iter; left time: 17221.9639s
Epoch: 11 cost time: 87.45964908599854
Epoch: 11, Steps: 136 | Train Loss: 0.1569161 Vali Loss: 0.1319711 Test Loss: 0.1591656
Validation loss decreased (0.131990 --> 0.131971).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1594975
	speed: 1.4193s/iter; left time: 17038.1835s
Epoch: 12 cost time: 87.9771318435669
Epoch: 12, Steps: 136 | Train Loss: 0.1568726 Vali Loss: 0.1318137 Test Loss: 0.1590855
Validation loss decreased (0.131971 --> 0.131814).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1582991
	speed: 1.4650s/iter; left time: 17388.1233s
Epoch: 13 cost time: 89.75432848930359
Epoch: 13, Steps: 136 | Train Loss: 0.1567058 Vali Loss: 0.1318354 Test Loss: 0.1590455
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1513562
	speed: 1.4595s/iter; left time: 17124.7445s
Epoch: 14 cost time: 90.41018676757812
Epoch: 14, Steps: 136 | Train Loss: 0.1565693 Vali Loss: 0.1318675 Test Loss: 0.1589493
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1555079
	speed: 1.3980s/iter; left time: 16212.2753s
Epoch: 15 cost time: 86.77372765541077
Epoch: 15, Steps: 136 | Train Loss: 0.1565265 Vali Loss: 0.1317610 Test Loss: 0.1589331
Validation loss decreased (0.131814 --> 0.131761).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1563099
	speed: 1.4293s/iter; left time: 16381.0487s
Epoch: 16 cost time: 86.07711029052734
Epoch: 16, Steps: 136 | Train Loss: 0.1564885 Vali Loss: 0.1318086 Test Loss: 0.1589206
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1523296
	speed: 1.4036s/iter; left time: 15895.7676s
Epoch: 17 cost time: 86.71758031845093
Epoch: 17, Steps: 136 | Train Loss: 0.1564110 Vali Loss: 0.1316722 Test Loss: 0.1588817
Validation loss decreased (0.131761 --> 0.131672).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1566468
	speed: 1.3999s/iter; left time: 15663.0703s
Epoch: 18 cost time: 84.33911943435669
Epoch: 18, Steps: 136 | Train Loss: 0.1564286 Vali Loss: 0.1317552 Test Loss: 0.1588486
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1627005
	speed: 1.3904s/iter; left time: 15368.5655s
Epoch: 19 cost time: 88.01818919181824
Epoch: 19, Steps: 136 | Train Loss: 0.1564279 Vali Loss: 0.1317576 Test Loss: 0.1588722
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1677098
	speed: 1.3768s/iter; left time: 15030.9339s
Epoch: 20 cost time: 87.02785468101501
Epoch: 20, Steps: 136 | Train Loss: 0.1563878 Vali Loss: 0.1316683 Test Loss: 0.1588589
Validation loss decreased (0.131672 --> 0.131668).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1744333
	speed: 1.4130s/iter; left time: 15233.2741s
Epoch: 21 cost time: 84.86525344848633
Epoch: 21, Steps: 136 | Train Loss: 0.1563610 Vali Loss: 0.1317000 Test Loss: 0.1588333
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1421232
	speed: 1.4260s/iter; left time: 15179.9723s
Epoch: 22 cost time: 87.86302447319031
Epoch: 22, Steps: 136 | Train Loss: 0.1563427 Vali Loss: 0.1316681 Test Loss: 0.1587832
Validation loss decreased (0.131668 --> 0.131668).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1524598
	speed: 1.3692s/iter; left time: 14388.4859s
Epoch: 23 cost time: 84.57898283004761
Epoch: 23, Steps: 136 | Train Loss: 0.1563034 Vali Loss: 0.1317617 Test Loss: 0.1587945
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1642064
	speed: 1.3860s/iter; left time: 14377.1375s
Epoch: 24 cost time: 84.65561366081238
Epoch: 24, Steps: 136 | Train Loss: 0.1562729 Vali Loss: 0.1316449 Test Loss: 0.1587653
Validation loss decreased (0.131668 --> 0.131645).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1599225
	speed: 1.3574s/iter; left time: 13896.1317s
Epoch: 25 cost time: 85.61508798599243
Epoch: 25, Steps: 136 | Train Loss: 0.1562126 Vali Loss: 0.1315529 Test Loss: 0.1587443
Validation loss decreased (0.131645 --> 0.131553).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1526342
	speed: 1.3378s/iter; left time: 13513.1114s
Epoch: 26 cost time: 81.27858686447144
Epoch: 26, Steps: 136 | Train Loss: 0.1563283 Vali Loss: 0.1315493 Test Loss: 0.1587429
Validation loss decreased (0.131553 --> 0.131549).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1667625
	speed: 1.3804s/iter; left time: 13755.4403s
Epoch: 27 cost time: 84.33919501304626
Epoch: 27, Steps: 136 | Train Loss: 0.1563325 Vali Loss: 0.1316605 Test Loss: 0.1587621
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1528256
	speed: 1.3641s/iter; left time: 13407.8633s
Epoch: 28 cost time: 88.99062490463257
Epoch: 28, Steps: 136 | Train Loss: 0.1562277 Vali Loss: 0.1316400 Test Loss: 0.1587485
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1507398
	speed: 1.4390s/iter; left time: 13948.6372s
Epoch: 29 cost time: 86.24864029884338
Epoch: 29, Steps: 136 | Train Loss: 0.1561961 Vali Loss: 0.1316538 Test Loss: 0.1587325
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1530544
	speed: 1.3811s/iter; left time: 13198.8928s
Epoch: 30 cost time: 85.40106081962585
Epoch: 30, Steps: 136 | Train Loss: 0.1561832 Vali Loss: 0.1316168 Test Loss: 0.1587197
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1641788
	speed: 1.3866s/iter; left time: 13062.8873s
Epoch: 31 cost time: 87.44449758529663
Epoch: 31, Steps: 136 | Train Loss: 0.1562122 Vali Loss: 0.1315519 Test Loss: 0.1587195
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1507954
	speed: 1.4165s/iter; left time: 13151.8906s
Epoch: 32 cost time: 85.4921007156372
Epoch: 32, Steps: 136 | Train Loss: 0.1562114 Vali Loss: 0.1316191 Test Loss: 0.1587209
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1539132
	speed: 1.4011s/iter; left time: 12819.0066s
Epoch: 33 cost time: 84.37962365150452
Epoch: 33, Steps: 136 | Train Loss: 0.1561530 Vali Loss: 0.1316002 Test Loss: 0.1586957
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1524857
	speed: 1.4036s/iter; left time: 12650.2802s
Epoch: 34 cost time: 86.86512327194214
Epoch: 34, Steps: 136 | Train Loss: 0.1562573 Vali Loss: 0.1316296 Test Loss: 0.1587140
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1567593
	speed: 1.3863s/iter; left time: 12306.2055s
Epoch: 35 cost time: 88.06576871871948
Epoch: 35, Steps: 136 | Train Loss: 0.1561767 Vali Loss: 0.1315476 Test Loss: 0.1587180
Validation loss decreased (0.131549 --> 0.131548).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1519794
	speed: 1.3955s/iter; left time: 12198.4042s
Epoch: 36 cost time: 84.37505102157593
Epoch: 36, Steps: 136 | Train Loss: 0.1562192 Vali Loss: 0.1316043 Test Loss: 0.1586945
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1718347
	speed: 1.4261s/iter; left time: 12271.8917s
Epoch: 37 cost time: 87.16533970832825
Epoch: 37, Steps: 136 | Train Loss: 0.1561714 Vali Loss: 0.1315012 Test Loss: 0.1586960
Validation loss decreased (0.131548 --> 0.131501).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1587791
	speed: 1.4231s/iter; left time: 12052.3723s
Epoch: 38 cost time: 89.09522008895874
Epoch: 38, Steps: 136 | Train Loss: 0.1561615 Vali Loss: 0.1315542 Test Loss: 0.1586857
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1502422
	speed: 1.3815s/iter; left time: 11511.7026s
Epoch: 39 cost time: 86.08111476898193
Epoch: 39, Steps: 136 | Train Loss: 0.1561585 Vali Loss: 0.1316689 Test Loss: 0.1586588
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1592334
	speed: 1.4113s/iter; left time: 11568.6490s
Epoch: 40 cost time: 91.23608088493347
Epoch: 40, Steps: 136 | Train Loss: 0.1561340 Vali Loss: 0.1315848 Test Loss: 0.1586830
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1642997
	speed: 1.3977s/iter; left time: 11267.2567s
Epoch: 41 cost time: 87.7790412902832
Epoch: 41, Steps: 136 | Train Loss: 0.1561692 Vali Loss: 0.1314760 Test Loss: 0.1586704
Validation loss decreased (0.131501 --> 0.131476).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1608515
	speed: 1.4333s/iter; left time: 11358.8742s
Epoch: 42 cost time: 88.37311935424805
Epoch: 42, Steps: 136 | Train Loss: 0.1561856 Vali Loss: 0.1316064 Test Loss: 0.1586843
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1645643
	speed: 1.3988s/iter; left time: 10894.8811s
Epoch: 43 cost time: 87.94988656044006
Epoch: 43, Steps: 136 | Train Loss: 0.1561768 Vali Loss: 0.1315309 Test Loss: 0.1586890
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1558414
	speed: 1.4246s/iter; left time: 10902.4960s
Epoch: 44 cost time: 88.32809543609619
Epoch: 44, Steps: 136 | Train Loss: 0.1561204 Vali Loss: 0.1316166 Test Loss: 0.1586745
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1577589
	speed: 1.4152s/iter; left time: 10638.3850s
Epoch: 45 cost time: 86.47762155532837
Epoch: 45, Steps: 136 | Train Loss: 0.1561525 Vali Loss: 0.1314570 Test Loss: 0.1586603
Validation loss decreased (0.131476 --> 0.131457).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1539695
	speed: 1.3841s/iter; left time: 10215.8283s
Epoch: 46 cost time: 87.67565512657166
Epoch: 46, Steps: 136 | Train Loss: 0.1560255 Vali Loss: 0.1315559 Test Loss: 0.1586604
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1525716
	speed: 1.4352s/iter; left time: 10398.2259s
Epoch: 47 cost time: 85.77865266799927
Epoch: 47, Steps: 136 | Train Loss: 0.1560889 Vali Loss: 0.1315875 Test Loss: 0.1586601
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1571317
	speed: 1.4245s/iter; left time: 10126.8343s
Epoch: 48 cost time: 90.52421975135803
Epoch: 48, Steps: 136 | Train Loss: 0.1562048 Vali Loss: 0.1314980 Test Loss: 0.1586607
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1604427
	speed: 1.4306s/iter; left time: 9975.5079s
Epoch: 49 cost time: 89.19896936416626
Epoch: 49, Steps: 136 | Train Loss: 0.1560408 Vali Loss: 0.1315217 Test Loss: 0.1586591
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1523331
	speed: 1.4612s/iter; left time: 9990.1873s
Epoch: 50 cost time: 90.45736837387085
Epoch: 50, Steps: 136 | Train Loss: 0.1561151 Vali Loss: 0.1315199 Test Loss: 0.1586488
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1605030
	speed: 1.4507s/iter; left time: 9721.0310s
Epoch: 51 cost time: 87.04718470573425
Epoch: 51, Steps: 136 | Train Loss: 0.1561094 Vali Loss: 0.1315560 Test Loss: 0.1586433
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1517907
	speed: 1.4056s/iter; left time: 9227.7179s
Epoch: 52 cost time: 84.61977648735046
Epoch: 52, Steps: 136 | Train Loss: 0.1560761 Vali Loss: 0.1315107 Test Loss: 0.1586475
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1616551
	speed: 1.4238s/iter; left time: 9153.3762s
Epoch: 53 cost time: 90.66228866577148
Epoch: 53, Steps: 136 | Train Loss: 0.1560941 Vali Loss: 0.1314700 Test Loss: 0.1586464
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1653746
	speed: 1.3247s/iter; left time: 8336.3043s
Epoch: 54 cost time: 77.53242993354797
Epoch: 54, Steps: 136 | Train Loss: 0.1561622 Vali Loss: 0.1315755 Test Loss: 0.1586449
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1521092
	speed: 1.1304s/iter; left time: 6959.7575s
Epoch: 55 cost time: 63.469213247299194
Epoch: 55, Steps: 136 | Train Loss: 0.1561044 Vali Loss: 0.1315084 Test Loss: 0.1586497
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1558504
	speed: 1.0638s/iter; left time: 6405.1944s
Epoch: 56 cost time: 66.51409554481506
Epoch: 56, Steps: 136 | Train Loss: 0.1561190 Vali Loss: 0.1316187 Test Loss: 0.1586417
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.1611344
	speed: 1.0501s/iter; left time: 6179.6378s
Epoch: 57 cost time: 64.50128054618835
Epoch: 57, Steps: 136 | Train Loss: 0.1560744 Vali Loss: 0.1315038 Test Loss: 0.1586410
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1536651
	speed: 1.0717s/iter; left time: 6161.0309s
Epoch: 58 cost time: 66.68246650695801
Epoch: 58, Steps: 136 | Train Loss: 0.1560380 Vali Loss: 0.1315694 Test Loss: 0.1586456
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1479523
	speed: 1.0541s/iter; left time: 5916.8857s
Epoch: 59 cost time: 64.69177913665771
Epoch: 59, Steps: 136 | Train Loss: 0.1560683 Vali Loss: 0.1315257 Test Loss: 0.1586420
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1591441
	speed: 1.0762s/iter; left time: 5894.1986s
Epoch: 60 cost time: 66.36898469924927
Epoch: 60, Steps: 136 | Train Loss: 0.1560763 Vali Loss: 0.1316077 Test Loss: 0.1586366
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1498470
	speed: 1.0941s/iter; left time: 5843.4142s
Epoch: 61 cost time: 68.76298093795776
Epoch: 61, Steps: 136 | Train Loss: 0.1560776 Vali Loss: 0.1314928 Test Loss: 0.1586423
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1596231
	speed: 1.0550s/iter; left time: 5491.4968s
Epoch: 62 cost time: 66.16469216346741
Epoch: 62, Steps: 136 | Train Loss: 0.1560889 Vali Loss: 0.1316479 Test Loss: 0.1586466
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1577909
	speed: 1.0823s/iter; left time: 5486.2587s
Epoch: 63 cost time: 63.52147626876831
Epoch: 63, Steps: 136 | Train Loss: 0.1560419 Vali Loss: 0.1315535 Test Loss: 0.1586456
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1423113
	speed: 1.0665s/iter; left time: 5261.0434s
Epoch: 64 cost time: 68.60954737663269
Epoch: 64, Steps: 136 | Train Loss: 0.1560796 Vali Loss: 0.1315849 Test Loss: 0.1586435
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.1594280
	speed: 1.0863s/iter; left time: 5210.9559s
Epoch: 65 cost time: 65.10640978813171
Epoch: 65, Steps: 136 | Train Loss: 0.1560680 Vali Loss: 0.1315268 Test Loss: 0.1586365
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_720_j192_H6_FITS_custom_ftM_sl720_ll48_pl192_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5069
mse:0.15579353272914886, mae:0.2551437318325043, rse:0.39244344830513, corr:[0.4633702  0.46480328 0.46672285 0.46739185 0.4673382  0.46775246
 0.467897   0.4675401  0.46733195 0.46728447 0.4670939  0.46700335
 0.46707147 0.4670368  0.46697447 0.46705976 0.46712494 0.46709695
 0.46702665 0.46686935 0.4667637  0.4667795  0.4669462  0.4671818
 0.46731704 0.4675872  0.4677612  0.4676706  0.4674616  0.4673899
 0.46737388 0.46724865 0.4670785  0.4669905  0.4668491  0.46665922
 0.46659315 0.4666119  0.4665435  0.46636993 0.4662155  0.4661009
 0.465973   0.4658237  0.4656943  0.46559408 0.4656145  0.4658122
 0.46602207 0.466162   0.46620512 0.46621454 0.4661472  0.46602106
 0.4659573  0.46595    0.4658639  0.46575695 0.46576223 0.46579668
 0.46575493 0.4657074  0.46575335 0.46574923 0.46561468 0.46551454
 0.46546775 0.4653329  0.46518898 0.46513796 0.4651657  0.46525267
 0.46538243 0.46553928 0.46552876 0.46543425 0.465412   0.46541178
 0.46534047 0.4652785  0.46530473 0.46529907 0.46519488 0.46514565
 0.465192   0.46516925 0.4650642  0.46501815 0.4650368  0.46500605
 0.46485373 0.46466112 0.4645725  0.46456885 0.4645994  0.464692
 0.46479926 0.4649167  0.46498752 0.46498713 0.46490374 0.46484286
 0.46483847 0.46479633 0.46469668 0.46465826 0.46465075 0.46459392
 0.4645161  0.46451285 0.46452293 0.46441776 0.4642875  0.464293
 0.4643721  0.46436986 0.46437967 0.46448565 0.46464452 0.46485934
 0.46509874 0.46522453 0.46523613 0.4652588  0.46527618 0.46523556
 0.46516004 0.46511227 0.46504286 0.46488693 0.46472767 0.46466923
 0.46461517 0.46450186 0.4644772  0.46455416 0.46455672 0.46449
 0.4644965  0.46448082 0.4643716  0.46420863 0.464146   0.46425045
 0.4643746  0.4644998  0.46456724 0.4645917  0.46458435 0.46455458
 0.46447155 0.4643731  0.46434578 0.464318   0.46417603 0.46403775
 0.46406558 0.4641249  0.46406978 0.46401808 0.46415296 0.46434096
 0.46430033 0.46409565 0.4640006  0.46392763 0.46375877 0.4637636
 0.4638536  0.46396708 0.46388182 0.46374834 0.46362808 0.46343455
 0.46320537 0.46304664 0.46290419 0.46280116 0.462718   0.46266592
 0.4627281  0.46294597 0.4630388  0.4628398  0.46275645 0.46302938
 0.46287227 0.46214172 0.4621675  0.46253875 0.46205842 0.46323425]
