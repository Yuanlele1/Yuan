Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=42, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_90_j336_H8', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=90, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_90_j336_H8_FITS_custom_ftM_sl90_ll48_pl336_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17987
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=42, out_features=198, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  341687808.0
params:  8514.0
Trainable parameters:  8514
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 1.1338921
	speed: 0.5143s/iter; left time: 7149.3784s
Epoch: 1 cost time: 70.19369220733643
Epoch: 1, Steps: 140 | Train Loss: 1.3613080 Vali Loss: 0.8176687 Test Loss: 0.9400478
Validation loss decreased (inf --> 0.817669).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6813757
	speed: 1.2017s/iter; left time: 16536.9187s
Epoch: 2 cost time: 64.75846576690674
Epoch: 2, Steps: 140 | Train Loss: 0.7399644 Vali Loss: 0.5657755 Test Loss: 0.6557570
Validation loss decreased (0.817669 --> 0.565775).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4885687
	speed: 1.2039s/iter; left time: 16398.7682s
Epoch: 3 cost time: 67.28358507156372
Epoch: 3, Steps: 140 | Train Loss: 0.5384369 Vali Loss: 0.4435591 Test Loss: 0.5152447
Validation loss decreased (0.565775 --> 0.443559).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4075166
	speed: 1.1960s/iter; left time: 16123.1382s
Epoch: 4 cost time: 66.5354392528534
Epoch: 4, Steps: 140 | Train Loss: 0.4288731 Vali Loss: 0.3717701 Test Loss: 0.4303528
Validation loss decreased (0.443559 --> 0.371770).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3397385
	speed: 1.1378s/iter; left time: 15180.0199s
Epoch: 5 cost time: 65.38805484771729
Epoch: 5, Steps: 140 | Train Loss: 0.3602401 Vali Loss: 0.3253969 Test Loss: 0.3756931
Validation loss decreased (0.371770 --> 0.325397).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3048283
	speed: 1.1488s/iter; left time: 15164.7535s
Epoch: 6 cost time: 60.74892330169678
Epoch: 6, Steps: 140 | Train Loss: 0.3148229 Vali Loss: 0.2942079 Test Loss: 0.3384198
Validation loss decreased (0.325397 --> 0.294208).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2706441
	speed: 1.1371s/iter; left time: 14851.3080s
Epoch: 7 cost time: 66.62652659416199
Epoch: 7, Steps: 140 | Train Loss: 0.2839539 Vali Loss: 0.2736363 Test Loss: 0.3129057
Validation loss decreased (0.294208 --> 0.273636).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2521121
	speed: 1.1947s/iter; left time: 15436.5926s
Epoch: 8 cost time: 69.7139163017273
Epoch: 8, Steps: 140 | Train Loss: 0.2625226 Vali Loss: 0.2583373 Test Loss: 0.2947813
Validation loss decreased (0.273636 --> 0.258337).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2604994
	speed: 1.2195s/iter; left time: 15586.1550s
Epoch: 9 cost time: 67.18644571304321
Epoch: 9, Steps: 140 | Train Loss: 0.2472795 Vali Loss: 0.2475923 Test Loss: 0.2816895
Validation loss decreased (0.258337 --> 0.247592).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2377154
	speed: 1.2600s/iter; left time: 15928.1082s
Epoch: 10 cost time: 67.66235637664795
Epoch: 10, Steps: 140 | Train Loss: 0.2362622 Vali Loss: 0.2398650 Test Loss: 0.2719729
Validation loss decreased (0.247592 --> 0.239865).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2341465
	speed: 1.1989s/iter; left time: 14986.8738s
Epoch: 11 cost time: 68.71988677978516
Epoch: 11, Steps: 140 | Train Loss: 0.2279590 Vali Loss: 0.2335236 Test Loss: 0.2647970
Validation loss decreased (0.239865 --> 0.233524).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2220506
	speed: 1.2219s/iter; left time: 15104.4066s
Epoch: 12 cost time: 68.63962149620056
Epoch: 12, Steps: 140 | Train Loss: 0.2216036 Vali Loss: 0.2287700 Test Loss: 0.2590695
Validation loss decreased (0.233524 --> 0.228770).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2113534
	speed: 1.2197s/iter; left time: 14906.3163s
Epoch: 13 cost time: 66.23660516738892
Epoch: 13, Steps: 140 | Train Loss: 0.2166230 Vali Loss: 0.2249747 Test Loss: 0.2545300
Validation loss decreased (0.228770 --> 0.224975).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2029639
	speed: 1.1749s/iter; left time: 14193.6843s
Epoch: 14 cost time: 66.72514510154724
Epoch: 14, Steps: 140 | Train Loss: 0.2126507 Vali Loss: 0.2223407 Test Loss: 0.2509078
Validation loss decreased (0.224975 --> 0.222341).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2030814
	speed: 1.1262s/iter; left time: 13447.6416s
Epoch: 15 cost time: 63.01160001754761
Epoch: 15, Steps: 140 | Train Loss: 0.2093962 Vali Loss: 0.2190697 Test Loss: 0.2478246
Validation loss decreased (0.222341 --> 0.219070).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1979605
	speed: 1.1802s/iter; left time: 13927.9276s
Epoch: 16 cost time: 64.46497392654419
Epoch: 16, Steps: 140 | Train Loss: 0.2066859 Vali Loss: 0.2170439 Test Loss: 0.2453138
Validation loss decreased (0.219070 --> 0.217044).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2058235
	speed: 1.1321s/iter; left time: 13201.7198s
Epoch: 17 cost time: 65.40931272506714
Epoch: 17, Steps: 140 | Train Loss: 0.2041570 Vali Loss: 0.2150755 Test Loss: 0.2431251
Validation loss decreased (0.217044 --> 0.215075).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1937533
	speed: 1.2096s/iter; left time: 13935.6787s
Epoch: 18 cost time: 67.85542821884155
Epoch: 18, Steps: 140 | Train Loss: 0.2022002 Vali Loss: 0.2134506 Test Loss: 0.2411707
Validation loss decreased (0.215075 --> 0.213451).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1951209
	speed: 1.1725s/iter; left time: 13344.4859s
Epoch: 19 cost time: 64.35994386672974
Epoch: 19, Steps: 140 | Train Loss: 0.2004043 Vali Loss: 0.2119248 Test Loss: 0.2395269
Validation loss decreased (0.213451 --> 0.211925).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2017977
	speed: 1.1413s/iter; left time: 12828.9270s
Epoch: 20 cost time: 64.14954042434692
Epoch: 20, Steps: 140 | Train Loss: 0.1988582 Vali Loss: 0.2106767 Test Loss: 0.2380548
Validation loss decreased (0.211925 --> 0.210677).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1989360
	speed: 1.2726s/iter; left time: 14126.9365s
Epoch: 21 cost time: 82.23414301872253
Epoch: 21, Steps: 140 | Train Loss: 0.1974267 Vali Loss: 0.2096529 Test Loss: 0.2367496
Validation loss decreased (0.210677 --> 0.209653).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1937166
	speed: 1.4928s/iter; left time: 16362.9174s
Epoch: 22 cost time: 85.1184229850769
Epoch: 22, Steps: 140 | Train Loss: 0.1961336 Vali Loss: 0.2084018 Test Loss: 0.2355690
Validation loss decreased (0.209653 --> 0.208402).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2029523
	speed: 1.4757s/iter; left time: 15968.1292s
Epoch: 23 cost time: 82.15943503379822
Epoch: 23, Steps: 140 | Train Loss: 0.1950773 Vali Loss: 0.2076585 Test Loss: 0.2345555
Validation loss decreased (0.208402 --> 0.207659).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1937312
	speed: 1.4753s/iter; left time: 15757.4666s
Epoch: 24 cost time: 84.569748878479
Epoch: 24, Steps: 140 | Train Loss: 0.1940245 Vali Loss: 0.2069799 Test Loss: 0.2336017
Validation loss decreased (0.207659 --> 0.206980).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1807416
	speed: 1.4805s/iter; left time: 15606.4704s
Epoch: 25 cost time: 79.75690913200378
Epoch: 25, Steps: 140 | Train Loss: 0.1931104 Vali Loss: 0.2059146 Test Loss: 0.2327668
Validation loss decreased (0.206980 --> 0.205915).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1927337
	speed: 1.2778s/iter; left time: 13290.2178s
Epoch: 26 cost time: 69.53436279296875
Epoch: 26, Steps: 140 | Train Loss: 0.1922795 Vali Loss: 0.2053518 Test Loss: 0.2319722
Validation loss decreased (0.205915 --> 0.205352).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1931852
	speed: 1.3695s/iter; left time: 14052.8665s
Epoch: 27 cost time: 77.16877341270447
Epoch: 27, Steps: 140 | Train Loss: 0.1914888 Vali Loss: 0.2048344 Test Loss: 0.2312955
Validation loss decreased (0.205352 --> 0.204834).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1937592
	speed: 1.3801s/iter; left time: 13967.7991s
Epoch: 28 cost time: 75.33560991287231
Epoch: 28, Steps: 140 | Train Loss: 0.1908629 Vali Loss: 0.2043146 Test Loss: 0.2306630
Validation loss decreased (0.204834 --> 0.204315).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1999214
	speed: 1.3438s/iter; left time: 13412.6609s
Epoch: 29 cost time: 72.57564568519592
Epoch: 29, Steps: 140 | Train Loss: 0.1901936 Vali Loss: 0.2035537 Test Loss: 0.2300760
Validation loss decreased (0.204315 --> 0.203554).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1850200
	speed: 1.3636s/iter; left time: 13419.2360s
Epoch: 30 cost time: 77.12540555000305
Epoch: 30, Steps: 140 | Train Loss: 0.1896922 Vali Loss: 0.2029216 Test Loss: 0.2295831
Validation loss decreased (0.203554 --> 0.202922).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1997693
	speed: 1.3699s/iter; left time: 13289.3526s
Epoch: 31 cost time: 78.1711893081665
Epoch: 31, Steps: 140 | Train Loss: 0.1891682 Vali Loss: 0.2026443 Test Loss: 0.2290932
Validation loss decreased (0.202922 --> 0.202644).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1845376
	speed: 1.3800s/iter; left time: 13194.5294s
Epoch: 32 cost time: 79.15924048423767
Epoch: 32, Steps: 140 | Train Loss: 0.1886839 Vali Loss: 0.2025027 Test Loss: 0.2286596
Validation loss decreased (0.202644 --> 0.202503).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1868240
	speed: 1.4481s/iter; left time: 13642.8744s
Epoch: 33 cost time: 78.73147344589233
Epoch: 33, Steps: 140 | Train Loss: 0.1882394 Vali Loss: 0.2021666 Test Loss: 0.2282302
Validation loss decreased (0.202503 --> 0.202167).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1790825
	speed: 1.4468s/iter; left time: 13427.3997s
Epoch: 34 cost time: 83.85506391525269
Epoch: 34, Steps: 140 | Train Loss: 0.1878561 Vali Loss: 0.2016823 Test Loss: 0.2278676
Validation loss decreased (0.202167 --> 0.201682).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1899458
	speed: 1.4771s/iter; left time: 13502.0247s
Epoch: 35 cost time: 80.35552835464478
Epoch: 35, Steps: 140 | Train Loss: 0.1874672 Vali Loss: 0.2012120 Test Loss: 0.2275226
Validation loss decreased (0.201682 --> 0.201212).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1827010
	speed: 1.3900s/iter; left time: 12511.3341s
Epoch: 36 cost time: 75.26220703125
Epoch: 36, Steps: 140 | Train Loss: 0.1871659 Vali Loss: 0.2012127 Test Loss: 0.2272176
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1934433
	speed: 1.4184s/iter; left time: 12568.8784s
Epoch: 37 cost time: 79.04790616035461
Epoch: 37, Steps: 140 | Train Loss: 0.1868293 Vali Loss: 0.2004823 Test Loss: 0.2269186
Validation loss decreased (0.201212 --> 0.200482).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1785911
	speed: 1.3987s/iter; left time: 12197.7742s
Epoch: 38 cost time: 76.12302875518799
Epoch: 38, Steps: 140 | Train Loss: 0.1864846 Vali Loss: 0.2003885 Test Loss: 0.2266398
Validation loss decreased (0.200482 --> 0.200388).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1957505
	speed: 1.4109s/iter; left time: 12107.0564s
Epoch: 39 cost time: 77.51006746292114
Epoch: 39, Steps: 140 | Train Loss: 0.1863097 Vali Loss: 0.2005168 Test Loss: 0.2263940
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1908778
	speed: 1.3864s/iter; left time: 11702.9521s
Epoch: 40 cost time: 77.47774386405945
Epoch: 40, Steps: 140 | Train Loss: 0.1860215 Vali Loss: 0.2002034 Test Loss: 0.2261570
Validation loss decreased (0.200388 --> 0.200203).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1910618
	speed: 1.3238s/iter; left time: 10988.7528s
Epoch: 41 cost time: 74.70677876472473
Epoch: 41, Steps: 140 | Train Loss: 0.1857932 Vali Loss: 0.2000937 Test Loss: 0.2259315
Validation loss decreased (0.200203 --> 0.200094).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1837519
	speed: 1.4111s/iter; left time: 11515.8835s
Epoch: 42 cost time: 78.05652379989624
Epoch: 42, Steps: 140 | Train Loss: 0.1855735 Vali Loss: 0.1995971 Test Loss: 0.2257338
Validation loss decreased (0.200094 --> 0.199597).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1776348
	speed: 1.4136s/iter; left time: 11338.4268s
Epoch: 43 cost time: 80.31787371635437
Epoch: 43, Steps: 140 | Train Loss: 0.1853599 Vali Loss: 0.1995180 Test Loss: 0.2255343
Validation loss decreased (0.199597 --> 0.199518).  Saving model ...
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1792883
	speed: 1.4075s/iter; left time: 11092.7310s
Epoch: 44 cost time: 80.08329153060913
Epoch: 44, Steps: 140 | Train Loss: 0.1852003 Vali Loss: 0.1996131 Test Loss: 0.2253466
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1787685
	speed: 1.4590s/iter; left time: 11294.4831s
Epoch: 45 cost time: 81.32040023803711
Epoch: 45, Steps: 140 | Train Loss: 0.1849513 Vali Loss: 0.1995105 Test Loss: 0.2251648
Validation loss decreased (0.199518 --> 0.199510).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1889700
	speed: 1.4755s/iter; left time: 11215.1763s
Epoch: 46 cost time: 83.50048804283142
Epoch: 46, Steps: 140 | Train Loss: 0.1848214 Vali Loss: 0.1996432 Test Loss: 0.2250120
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1809627
	speed: 1.4399s/iter; left time: 10743.3108s
Epoch: 47 cost time: 81.09349822998047
Epoch: 47, Steps: 140 | Train Loss: 0.1846610 Vali Loss: 0.1986266 Test Loss: 0.2248518
Validation loss decreased (0.199510 --> 0.198627).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1868446
	speed: 1.4360s/iter; left time: 10512.6790s
Epoch: 48 cost time: 81.61528372764587
Epoch: 48, Steps: 140 | Train Loss: 0.1845481 Vali Loss: 0.1986592 Test Loss: 0.2247087
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1773117
	speed: 1.3639s/iter; left time: 9793.9118s
Epoch: 49 cost time: 74.2214879989624
Epoch: 49, Steps: 140 | Train Loss: 0.1842822 Vali Loss: 0.1987991 Test Loss: 0.2245777
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1774406
	speed: 1.4056s/iter; left time: 9896.9075s
Epoch: 50 cost time: 78.64565443992615
Epoch: 50, Steps: 140 | Train Loss: 0.1842169 Vali Loss: 0.1982972 Test Loss: 0.2244434
Validation loss decreased (0.198627 --> 0.198297).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1935482
	speed: 1.3979s/iter; left time: 9646.5823s
Epoch: 51 cost time: 79.87786817550659
Epoch: 51, Steps: 140 | Train Loss: 0.1840710 Vali Loss: 0.1984086 Test Loss: 0.2243175
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1777828
	speed: 1.4141s/iter; left time: 9560.6911s
Epoch: 52 cost time: 80.13165593147278
Epoch: 52, Steps: 140 | Train Loss: 0.1839407 Vali Loss: 0.1980054 Test Loss: 0.2241966
Validation loss decreased (0.198297 --> 0.198005).  Saving model ...
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1819239
	speed: 1.4135s/iter; left time: 9358.9770s
Epoch: 53 cost time: 76.88769698143005
Epoch: 53, Steps: 140 | Train Loss: 0.1838184 Vali Loss: 0.1979032 Test Loss: 0.2240899
Validation loss decreased (0.198005 --> 0.197903).  Saving model ...
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1876865
	speed: 1.3831s/iter; left time: 8964.1552s
Epoch: 54 cost time: 75.56225538253784
Epoch: 54, Steps: 140 | Train Loss: 0.1837199 Vali Loss: 0.1980780 Test Loss: 0.2239829
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1885121
	speed: 1.3777s/iter; left time: 8736.2964s
Epoch: 55 cost time: 79.19101524353027
Epoch: 55, Steps: 140 | Train Loss: 0.1835652 Vali Loss: 0.1979770 Test Loss: 0.2238776
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1762249
	speed: 1.4247s/iter; left time: 8834.2796s
Epoch: 56 cost time: 80.02452349662781
Epoch: 56, Steps: 140 | Train Loss: 0.1834549 Vali Loss: 0.1976619 Test Loss: 0.2237851
Validation loss decreased (0.197903 --> 0.197662).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.1782124
	speed: 1.3700s/iter; left time: 8303.5711s
Epoch: 57 cost time: 74.6478533744812
Epoch: 57, Steps: 140 | Train Loss: 0.1833973 Vali Loss: 0.1976740 Test Loss: 0.2236962
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1878076
	speed: 1.4356s/iter; left time: 8500.2813s
Epoch: 58 cost time: 80.48915004730225
Epoch: 58, Steps: 140 | Train Loss: 0.1833016 Vali Loss: 0.1976211 Test Loss: 0.2236153
Validation loss decreased (0.197662 --> 0.197621).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1841013
	speed: 1.4240s/iter; left time: 8232.3816s
Epoch: 59 cost time: 75.83634352684021
Epoch: 59, Steps: 140 | Train Loss: 0.1832671 Vali Loss: 0.1980461 Test Loss: 0.2235285
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1819355
	speed: 1.3421s/iter; left time: 7570.9386s
Epoch: 60 cost time: 75.70249080657959
Epoch: 60, Steps: 140 | Train Loss: 0.1831299 Vali Loss: 0.1976585 Test Loss: 0.2234472
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1788938
	speed: 1.3407s/iter; left time: 7375.4235s
Epoch: 61 cost time: 73.29450941085815
Epoch: 61, Steps: 140 | Train Loss: 0.1830996 Vali Loss: 0.1978091 Test Loss: 0.2233697
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1905579
	speed: 1.2293s/iter; left time: 6590.4358s
Epoch: 62 cost time: 67.17071437835693
Epoch: 62, Steps: 140 | Train Loss: 0.1830070 Vali Loss: 0.1973292 Test Loss: 0.2233040
Validation loss decreased (0.197621 --> 0.197329).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1735763
	speed: 1.2472s/iter; left time: 6511.5040s
Epoch: 63 cost time: 67.5107626914978
Epoch: 63, Steps: 140 | Train Loss: 0.1828943 Vali Loss: 0.1974999 Test Loss: 0.2232349
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1871359
	speed: 1.1691s/iter; left time: 5940.2362s
Epoch: 64 cost time: 64.33766651153564
Epoch: 64, Steps: 140 | Train Loss: 0.1828324 Vali Loss: 0.1973830 Test Loss: 0.2231692
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.1745322
	speed: 1.1341s/iter; left time: 5603.7213s
Epoch: 65 cost time: 63.05605435371399
Epoch: 65, Steps: 140 | Train Loss: 0.1827907 Vali Loss: 0.1975965 Test Loss: 0.2231115
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.1805497
	speed: 1.0999s/iter; left time: 5280.7540s
Epoch: 66 cost time: 55.59097480773926
Epoch: 66, Steps: 140 | Train Loss: 0.1827640 Vali Loss: 0.1973194 Test Loss: 0.2230550
Validation loss decreased (0.197329 --> 0.197319).  Saving model ...
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.1793774
	speed: 1.0210s/iter; left time: 4758.9257s
Epoch: 67 cost time: 59.88893413543701
Epoch: 67, Steps: 140 | Train Loss: 0.1826482 Vali Loss: 0.1972294 Test Loss: 0.2229985
Validation loss decreased (0.197319 --> 0.197229).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.1793616
	speed: 1.0266s/iter; left time: 4641.1158s
Epoch: 68 cost time: 58.5439977645874
Epoch: 68, Steps: 140 | Train Loss: 0.1825699 Vali Loss: 0.1969296 Test Loss: 0.2229463
Validation loss decreased (0.197229 --> 0.196930).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.1862722
	speed: 1.0413s/iter; left time: 4562.0633s
Epoch: 69 cost time: 58.34742498397827
Epoch: 69, Steps: 140 | Train Loss: 0.1825725 Vali Loss: 0.1970608 Test Loss: 0.2228957
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.1740669
	speed: 1.0244s/iter; left time: 4344.2792s
Epoch: 70 cost time: 56.72213959693909
Epoch: 70, Steps: 140 | Train Loss: 0.1824745 Vali Loss: 0.1971604 Test Loss: 0.2228510
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.1825678
	speed: 1.0424s/iter; left time: 4275.0283s
Epoch: 71 cost time: 58.38634490966797
Epoch: 71, Steps: 140 | Train Loss: 0.1824330 Vali Loss: 0.1968839 Test Loss: 0.2228091
Validation loss decreased (0.196930 --> 0.196884).  Saving model ...
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.1835723
	speed: 0.9889s/iter; left time: 3916.9321s
Epoch: 72 cost time: 55.95599293708801
Epoch: 72, Steps: 140 | Train Loss: 0.1824583 Vali Loss: 0.1967769 Test Loss: 0.2227639
Validation loss decreased (0.196884 --> 0.196777).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.1852229
	speed: 1.0468s/iter; left time: 3999.8846s
Epoch: 73 cost time: 58.64559531211853
Epoch: 73, Steps: 140 | Train Loss: 0.1823502 Vali Loss: 0.1968045 Test Loss: 0.2227238
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.1770760
	speed: 1.0678s/iter; left time: 3930.6629s
Epoch: 74 cost time: 61.570505142211914
Epoch: 74, Steps: 140 | Train Loss: 0.1822982 Vali Loss: 0.1968064 Test Loss: 0.2226870
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.1853667
	speed: 1.0287s/iter; left time: 3642.7478s
Epoch: 75 cost time: 57.70544075965881
Epoch: 75, Steps: 140 | Train Loss: 0.1822732 Vali Loss: 0.1967700 Test Loss: 0.2226479
Validation loss decreased (0.196777 --> 0.196770).  Saving model ...
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.1838895
	speed: 1.0215s/iter; left time: 3474.1137s
Epoch: 76 cost time: 57.15405774116516
Epoch: 76, Steps: 140 | Train Loss: 0.1822289 Vali Loss: 0.1966441 Test Loss: 0.2226160
Validation loss decreased (0.196770 --> 0.196644).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.1807793
	speed: 1.0008s/iter; left time: 3263.6028s
Epoch: 77 cost time: 54.901262521743774
Epoch: 77, Steps: 140 | Train Loss: 0.1822072 Vali Loss: 0.1967817 Test Loss: 0.2225860
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.1818853
	speed: 1.0241s/iter; left time: 3196.2218s
Epoch: 78 cost time: 57.12213945388794
Epoch: 78, Steps: 140 | Train Loss: 0.1821619 Vali Loss: 0.1966517 Test Loss: 0.2225541
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.1872963
	speed: 0.9976s/iter; left time: 2973.8590s
Epoch: 79 cost time: 55.70796513557434
Epoch: 79, Steps: 140 | Train Loss: 0.1820824 Vali Loss: 0.1967496 Test Loss: 0.2225263
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.1736732
	speed: 1.0464s/iter; left time: 2972.7776s
Epoch: 80 cost time: 59.00879955291748
Epoch: 80, Steps: 140 | Train Loss: 0.1820520 Vali Loss: 0.1967296 Test Loss: 0.2224990
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.1691466
	speed: 1.0159s/iter; left time: 2743.9878s
Epoch: 81 cost time: 55.86387538909912
Epoch: 81, Steps: 140 | Train Loss: 0.1821020 Vali Loss: 0.1963543 Test Loss: 0.2224740
Validation loss decreased (0.196644 --> 0.196354).  Saving model ...
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.1737418
	speed: 1.0415s/iter; left time: 2667.1629s
Epoch: 82 cost time: 59.19893407821655
Epoch: 82, Steps: 140 | Train Loss: 0.1820356 Vali Loss: 0.1966297 Test Loss: 0.2224493
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.1680677
	speed: 0.9896s/iter; left time: 2395.7497s
Epoch: 83 cost time: 52.72837781906128
Epoch: 83, Steps: 140 | Train Loss: 0.1820471 Vali Loss: 0.1967039 Test Loss: 0.2224268
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.1715456
	speed: 1.0036s/iter; left time: 2289.3025s
Epoch: 84 cost time: 58.25395083427429
Epoch: 84, Steps: 140 | Train Loss: 0.1819795 Vali Loss: 0.1968933 Test Loss: 0.2224043
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.1797749
	speed: 1.0515s/iter; left time: 2251.3490s
Epoch: 85 cost time: 59.6955451965332
Epoch: 85, Steps: 140 | Train Loss: 0.1820308 Vali Loss: 0.1966351 Test Loss: 0.2223833
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.1845831
	speed: 0.9682s/iter; left time: 1937.3656s
Epoch: 86 cost time: 50.12478017807007
Epoch: 86, Steps: 140 | Train Loss: 0.1819364 Vali Loss: 0.1964088 Test Loss: 0.2223640
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.1819521
	speed: 0.8559s/iter; left time: 1592.8260s
Epoch: 87 cost time: 46.549055099487305
Epoch: 87, Steps: 140 | Train Loss: 0.1818762 Vali Loss: 0.1964208 Test Loss: 0.2223444
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.1739772
	speed: 0.8848s/iter; left time: 1522.7650s
Epoch: 88 cost time: 52.311758279800415
Epoch: 88, Steps: 140 | Train Loss: 0.1819715 Vali Loss: 0.1963390 Test Loss: 0.2223276
Validation loss decreased (0.196354 --> 0.196339).  Saving model ...
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.1920518
	speed: 0.9384s/iter; left time: 1483.5827s
Epoch: 89 cost time: 53.43323349952698
Epoch: 89, Steps: 140 | Train Loss: 0.1819389 Vali Loss: 0.1960594 Test Loss: 0.2223109
Validation loss decreased (0.196339 --> 0.196059).  Saving model ...
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.1794993
	speed: 0.9154s/iter; left time: 1319.1079s
Epoch: 90 cost time: 49.67294692993164
Epoch: 90, Steps: 140 | Train Loss: 0.1818233 Vali Loss: 0.1964715 Test Loss: 0.2222936
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.204402478767869e-06
	iters: 100, epoch: 91 | loss: 0.1737631
	speed: 0.9210s/iter; left time: 1198.2603s
Epoch: 91 cost time: 51.17449140548706
Epoch: 91, Steps: 140 | Train Loss: 0.1818584 Vali Loss: 0.1967846 Test Loss: 0.2222784
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.944182354829475e-06
	iters: 100, epoch: 92 | loss: 0.1841063
	speed: 0.9475s/iter; left time: 1100.0938s
Epoch: 92 cost time: 53.12759470939636
Epoch: 92, Steps: 140 | Train Loss: 0.1818747 Vali Loss: 0.1961762 Test Loss: 0.2222643
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.696973237088e-06
	iters: 100, epoch: 93 | loss: 0.1819620
	speed: 0.9118s/iter; left time: 930.9728s
Epoch: 93 cost time: 51.328253746032715
Epoch: 93, Steps: 140 | Train Loss: 0.1818328 Vali Loss: 0.1964060 Test Loss: 0.2222513
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.462124575233601e-06
	iters: 100, epoch: 94 | loss: 0.1836852
	speed: 0.9319s/iter; left time: 821.0283s
Epoch: 94 cost time: 49.56590700149536
Epoch: 94, Steps: 140 | Train Loss: 0.1818445 Vali Loss: 0.1963752 Test Loss: 0.2222392
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.239018346471921e-06
	iters: 100, epoch: 95 | loss: 0.1857203
	speed: 0.9145s/iter; left time: 677.6412s
Epoch: 95 cost time: 50.45629835128784
Epoch: 95, Steps: 140 | Train Loss: 0.1817477 Vali Loss: 0.1962738 Test Loss: 0.2222272
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.027067429148324e-06
	iters: 100, epoch: 96 | loss: 0.1701467
	speed: 0.9335s/iter; left time: 561.0380s
Epoch: 96 cost time: 52.46758008003235
Epoch: 96, Steps: 140 | Train Loss: 0.1817779 Vali Loss: 0.1967151 Test Loss: 0.2222142
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.825714057690908e-06
	iters: 100, epoch: 97 | loss: 0.1839629
	speed: 0.9582s/iter; left time: 441.7324s
Epoch: 97 cost time: 51.005868911743164
Epoch: 97, Steps: 140 | Train Loss: 0.1818010 Vali Loss: 0.1961742 Test Loss: 0.2222038
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.6344283548063623e-06
	iters: 100, epoch: 98 | loss: 0.1861959
	speed: 0.9289s/iter; left time: 298.1613s
Epoch: 98 cost time: 52.302987575531006
Epoch: 98, Steps: 140 | Train Loss: 0.1817871 Vali Loss: 0.1965343 Test Loss: 0.2221938
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.452706937066044e-06
	iters: 100, epoch: 99 | loss: 0.1771430
	speed: 0.9281s/iter; left time: 167.9939s
Epoch: 99 cost time: 50.435372829437256
Epoch: 99, Steps: 140 | Train Loss: 0.1817508 Vali Loss: 0.1963696 Test Loss: 0.2221841
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.2800715902127414e-06
	iters: 100, epoch: 100 | loss: 0.1789783
	speed: 0.7735s/iter; left time: 31.7129s
Epoch: 100 cost time: 43.468329191207886
Epoch: 100, Steps: 140 | Train Loss: 0.1817729 Vali Loss: 0.1961002 Test Loss: 0.2221742
EarlyStopping counter: 11 out of 20
Updating learning rate to 3.1160680107021042e-06
train 17987
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=42, out_features=198, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  341687808.0
params:  8514.0
Trainable parameters:  8514
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2238780
	speed: 0.3054s/iter; left time: 4245.9006s
Epoch: 1 cost time: 42.553470611572266
Epoch: 1, Steps: 140 | Train Loss: 0.2270529 Vali Loss: 0.1944062 Test Loss: 0.2199905
Validation loss decreased (inf --> 0.194406).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2269906
	speed: 0.7934s/iter; left time: 10918.0303s
Epoch: 2 cost time: 42.81597542762756
Epoch: 2, Steps: 140 | Train Loss: 0.2258624 Vali Loss: 0.1940606 Test Loss: 0.2195372
Validation loss decreased (0.194406 --> 0.194061).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2194263
	speed: 0.7886s/iter; left time: 10742.1978s
Epoch: 3 cost time: 44.23702049255371
Epoch: 3, Steps: 140 | Train Loss: 0.2256476 Vali Loss: 0.1936949 Test Loss: 0.2194761
Validation loss decreased (0.194061 --> 0.193695).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2172704
	speed: 0.7964s/iter; left time: 10736.5916s
Epoch: 4 cost time: 42.07321548461914
Epoch: 4, Steps: 140 | Train Loss: 0.2255590 Vali Loss: 0.1937056 Test Loss: 0.2194075
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2302563
	speed: 0.7788s/iter; left time: 10389.3174s
Epoch: 5 cost time: 43.18545055389404
Epoch: 5, Steps: 140 | Train Loss: 0.2254747 Vali Loss: 0.1939373 Test Loss: 0.2193991
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2274852
	speed: 0.7840s/iter; left time: 10349.9963s
Epoch: 6 cost time: 43.316333055496216
Epoch: 6, Steps: 140 | Train Loss: 0.2255370 Vali Loss: 0.1935409 Test Loss: 0.2193657
Validation loss decreased (0.193695 --> 0.193541).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2197176
	speed: 0.7849s/iter; left time: 10251.0860s
Epoch: 7 cost time: 42.86742544174194
Epoch: 7, Steps: 140 | Train Loss: 0.2254273 Vali Loss: 0.1937240 Test Loss: 0.2193812
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2134657
	speed: 0.8402s/iter; left time: 10855.7480s
Epoch: 8 cost time: 46.454304933547974
Epoch: 8, Steps: 140 | Train Loss: 0.2255139 Vali Loss: 0.1935814 Test Loss: 0.2193361
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2284893
	speed: 0.8411s/iter; left time: 10750.5891s
Epoch: 9 cost time: 46.96145248413086
Epoch: 9, Steps: 140 | Train Loss: 0.2254074 Vali Loss: 0.1937519 Test Loss: 0.2193711
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2428396
	speed: 0.8400s/iter; left time: 10618.2606s
Epoch: 10 cost time: 43.58043050765991
Epoch: 10, Steps: 140 | Train Loss: 0.2254912 Vali Loss: 0.1938013 Test Loss: 0.2193415
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2229209
	speed: 0.7265s/iter; left time: 9081.6371s
Epoch: 11 cost time: 36.38223123550415
Epoch: 11, Steps: 140 | Train Loss: 0.2254592 Vali Loss: 0.1941436 Test Loss: 0.2193434
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2230083
	speed: 0.7096s/iter; left time: 8770.9240s
Epoch: 12 cost time: 41.030484199523926
Epoch: 12, Steps: 140 | Train Loss: 0.2254505 Vali Loss: 0.1934659 Test Loss: 0.2193552
Validation loss decreased (0.193541 --> 0.193466).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2369760
	speed: 0.7404s/iter; left time: 9048.1870s
Epoch: 13 cost time: 40.54046082496643
Epoch: 13, Steps: 140 | Train Loss: 0.2254681 Vali Loss: 0.1939527 Test Loss: 0.2193227
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2137361
	speed: 0.7136s/iter; left time: 8620.8978s
Epoch: 14 cost time: 40.0317108631134
Epoch: 14, Steps: 140 | Train Loss: 0.2254809 Vali Loss: 0.1940327 Test Loss: 0.2193209
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2117934
	speed: 0.7550s/iter; left time: 9015.1341s
Epoch: 15 cost time: 40.65306043624878
Epoch: 15, Steps: 140 | Train Loss: 0.2254262 Vali Loss: 0.1939143 Test Loss: 0.2193442
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2235269
	speed: 0.6739s/iter; left time: 7952.8680s
Epoch: 16 cost time: 36.29370403289795
Epoch: 16, Steps: 140 | Train Loss: 0.2254119 Vali Loss: 0.1936951 Test Loss: 0.2193324
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2138135
	speed: 0.6998s/iter; left time: 8159.8914s
Epoch: 17 cost time: 37.939650774002075
Epoch: 17, Steps: 140 | Train Loss: 0.2254164 Vali Loss: 0.1939400 Test Loss: 0.2193232
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2279430
	speed: 0.7372s/iter; left time: 8493.2639s
Epoch: 18 cost time: 38.33398914337158
Epoch: 18, Steps: 140 | Train Loss: 0.2254290 Vali Loss: 0.1940809 Test Loss: 0.2193255
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2334986
	speed: 0.6751s/iter; left time: 7683.5141s
Epoch: 19 cost time: 39.43954634666443
Epoch: 19, Steps: 140 | Train Loss: 0.2254306 Vali Loss: 0.1936534 Test Loss: 0.2193261
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2272037
	speed: 0.7618s/iter; left time: 8563.7801s
Epoch: 20 cost time: 39.01783347129822
Epoch: 20, Steps: 140 | Train Loss: 0.2254486 Vali Loss: 0.1936749 Test Loss: 0.2193203
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2158979
	speed: 0.7082s/iter; left time: 7861.7513s
Epoch: 21 cost time: 37.66376829147339
Epoch: 21, Steps: 140 | Train Loss: 0.2253545 Vali Loss: 0.1936337 Test Loss: 0.2193364
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2236335
	speed: 0.6332s/iter; left time: 6940.6615s
Epoch: 22 cost time: 31.35854196548462
Epoch: 22, Steps: 140 | Train Loss: 0.2254220 Vali Loss: 0.1939301 Test Loss: 0.2193424
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2328080
	speed: 0.6265s/iter; left time: 6779.6018s
Epoch: 23 cost time: 32.90799856185913
Epoch: 23, Steps: 140 | Train Loss: 0.2253699 Vali Loss: 0.1936930 Test Loss: 0.2193279
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2231358
	speed: 0.6573s/iter; left time: 7020.2367s
Epoch: 24 cost time: 36.091546297073364
Epoch: 24, Steps: 140 | Train Loss: 0.2253408 Vali Loss: 0.1937781 Test Loss: 0.2193129
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2191318
	speed: 0.6293s/iter; left time: 6633.6430s
Epoch: 25 cost time: 36.334697008132935
Epoch: 25, Steps: 140 | Train Loss: 0.2254200 Vali Loss: 0.1936025 Test Loss: 0.2193227
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2156243
	speed: 0.6639s/iter; left time: 6904.8043s
Epoch: 26 cost time: 35.27481150627136
Epoch: 26, Steps: 140 | Train Loss: 0.2253450 Vali Loss: 0.1935326 Test Loss: 0.2193087
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2186354
	speed: 0.7850s/iter; left time: 8054.6647s
Epoch: 27 cost time: 55.67678737640381
Epoch: 27, Steps: 140 | Train Loss: 0.2253911 Vali Loss: 0.1937948 Test Loss: 0.2193166
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2206022
	speed: 1.0330s/iter; left time: 10455.0338s
Epoch: 28 cost time: 55.62499952316284
Epoch: 28, Steps: 140 | Train Loss: 0.2253876 Vali Loss: 0.1939851 Test Loss: 0.2192991
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2208045
	speed: 1.0835s/iter; left time: 10814.1137s
Epoch: 29 cost time: 61.030847787857056
Epoch: 29, Steps: 140 | Train Loss: 0.2253178 Vali Loss: 0.1935001 Test Loss: 0.2193038
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2219564
	speed: 1.0948s/iter; left time: 10774.1870s
Epoch: 30 cost time: 60.84600758552551
Epoch: 30, Steps: 140 | Train Loss: 0.2252871 Vali Loss: 0.1937581 Test Loss: 0.2192922
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2185408
	speed: 1.0837s/iter; left time: 10513.3858s
Epoch: 31 cost time: 58.21125841140747
Epoch: 31, Steps: 140 | Train Loss: 0.2254416 Vali Loss: 0.1938824 Test Loss: 0.2192913
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2299938
	speed: 1.0243s/iter; left time: 9792.9229s
Epoch: 32 cost time: 58.4721622467041
Epoch: 32, Steps: 140 | Train Loss: 0.2254032 Vali Loss: 0.1939135 Test Loss: 0.2193027
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_90_j336_H8_FITS_custom_ftM_sl90_ll48_pl336_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4925
mse:0.21789568662643433, mae:0.2970626652240753, rse:0.46458545327186584, corr:[0.45447528 0.45485705 0.4538982  0.4525105  0.45139375 0.45056397
 0.450266   0.4496327  0.44871497 0.44794562 0.44722125 0.44662738
 0.44628963 0.4457128  0.4456411  0.44500467 0.44513288 0.44517833
 0.44535342 0.44506854 0.44503027 0.44505477 0.44490018 0.4436477
 0.44160625 0.43999457 0.43904325 0.43811953 0.43754467 0.43775225
 0.43863708 0.43881527 0.4384282  0.43809882 0.43781406 0.43761313
 0.43740124 0.43725812 0.437182   0.4368641  0.4368376  0.4368483
 0.43680894 0.4368081  0.43690208 0.43705475 0.43719223 0.43689495
 0.43594405 0.43547633 0.43548968 0.4357404  0.43662536 0.43819344
 0.440319   0.44174904 0.44176283 0.44174215 0.44160283 0.4414169
 0.44112027 0.4409789  0.44101447 0.44103038 0.44125983 0.44134304
 0.4416713  0.44188154 0.44220668 0.4426134  0.4431203  0.4433565
 0.4435011  0.44397032 0.44468594 0.44583595 0.44766662 0.45010424
 0.45352137 0.45585674 0.4558929  0.45566928 0.45531416 0.45489696
 0.45460895 0.4544407  0.45455387 0.45453689 0.45467556 0.45489258
 0.45517412 0.45534277 0.4555036  0.45574763 0.4558444  0.45588607
 0.4556536  0.45562398 0.45559433 0.45558733 0.4555301  0.45563978
 0.45610008 0.45613992 0.4556918  0.45542085 0.45522013 0.45479885
 0.45463392 0.45463443 0.45471376 0.45467356 0.45477667 0.45495695
 0.45528632 0.45528066 0.45522678 0.45541295 0.45556453 0.45564488
 0.45546946 0.45548582 0.4554287  0.45547014 0.45539632 0.45526358
 0.4555117  0.4552935  0.45498937 0.45469987 0.4544595  0.4542735
 0.4542365  0.45414713 0.4543557  0.4544121  0.4546719  0.45486987
 0.45502517 0.45510855 0.4551265  0.45526817 0.4552966  0.4550953
 0.45472422 0.45470423 0.454664   0.45457998 0.45473638 0.45477438
 0.4550223  0.45487106 0.45447    0.45407638 0.45375308 0.45354536
 0.4535382  0.45349035 0.45380062 0.45392624 0.45422968 0.45458198
 0.45489702 0.45505336 0.4547768  0.4543463  0.45388958 0.45132992
 0.44841906 0.4462589  0.44439784 0.44305345 0.44198993 0.44142467
 0.4412166  0.44094416 0.4402702  0.43996677 0.43960547 0.43939373
 0.43914673 0.43892813 0.43890643 0.43858904 0.43855366 0.43860212
 0.4383378  0.4382445  0.43810073 0.4377176  0.43734652 0.43552768
 0.4333847  0.4318396  0.43075758 0.42990643 0.42948267 0.42984807
 0.43074435 0.43129274 0.43100962 0.4309028  0.43067613 0.43053013
 0.43048143 0.43058884 0.43059123 0.43033674 0.43049464 0.43054453
 0.43041813 0.4303913  0.43044975 0.4305343  0.4306454  0.42988303
 0.42896682 0.42861032 0.42849186 0.42880636 0.4297265  0.43124947
 0.43348113 0.4350795  0.4353009  0.43538302 0.4352654  0.4351298
 0.4348285  0.4349118  0.43520334 0.43518957 0.4354075  0.43562815
 0.43581784 0.43595684 0.4364236  0.4368569  0.43732578 0.43738455
 0.43754303 0.43803564 0.43872875 0.43995738 0.4418134  0.44417074
 0.44766462 0.4501456  0.45028147 0.45022732 0.44977424 0.44953552
 0.4493763  0.4492083  0.44932964 0.44933102 0.44960868 0.44969347
 0.44996992 0.45030338 0.4503293  0.4504893  0.4506441  0.4506008
 0.45036742 0.45034546 0.45015255 0.45012298 0.45020306 0.45025575
 0.4507235  0.45089605 0.450502   0.4501863  0.44998014 0.44975188
 0.44965962 0.4495127  0.44949797 0.44952366 0.4496305  0.44965404
 0.4499063  0.44985515 0.44993126 0.4501527  0.45019448 0.4502661
 0.45006806 0.45010325 0.45006767 0.4498985  0.44992015 0.45001867
 0.45019743 0.4500824  0.44986114 0.44952902 0.4493666  0.44928196
 0.44929305 0.44924155 0.44940084 0.44931987 0.44927052 0.44953504
 0.4495804  0.44961482 0.4494887  0.44943586 0.4496346  0.4493712
 0.44908592 0.44897592 0.44881183 0.44889247 0.4489565  0.44916484
 0.44953236 0.449632   0.4496377  0.4494673  0.44926056 0.44921538
 0.4491405  0.44907585 0.44921228 0.44908676 0.4491759  0.44916308
 0.44907326 0.4491354  0.44884166 0.44884005 0.4488699  0.4481718 ]
