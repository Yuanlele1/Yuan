Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=134, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_720_j336_H4', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_720_j336_H4_FITS_custom_ftM_sl720_ll48_pl336_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17357
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=134, out_features=196, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1079135232.0
params:  26460.0
Trainable parameters:  26460
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5015445
	speed: 0.6434s/iter; left time: 8621.7646s
Epoch: 1 cost time: 88.8205246925354
Epoch: 1, Steps: 135 | Train Loss: 0.6983406 Vali Loss: 0.3459916 Test Loss: 0.4086148
Validation loss decreased (inf --> 0.345992).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2563829
	speed: 1.6119s/iter; left time: 21383.7674s
Epoch: 2 cost time: 102.52347707748413
Epoch: 2, Steps: 135 | Train Loss: 0.3167548 Vali Loss: 0.2031972 Test Loss: 0.2436598
Validation loss decreased (0.345992 --> 0.203197).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2136668
	speed: 1.6839s/iter; left time: 22111.9472s
Epoch: 3 cost time: 103.14727425575256
Epoch: 3, Steps: 135 | Train Loss: 0.2210400 Vali Loss: 0.1660094 Test Loss: 0.1988302
Validation loss decreased (0.203197 --> 0.166009).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1864607
	speed: 1.6658s/iter; left time: 21649.0285s
Epoch: 4 cost time: 106.89990854263306
Epoch: 4, Steps: 135 | Train Loss: 0.1965267 Vali Loss: 0.1584233 Test Loss: 0.1877656
Validation loss decreased (0.166009 --> 0.158423).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2000291
	speed: 1.5599s/iter; left time: 20061.8184s
Epoch: 5 cost time: 91.28992581367493
Epoch: 5, Steps: 135 | Train Loss: 0.1906768 Vali Loss: 0.1563869 Test Loss: 0.1848684
Validation loss decreased (0.158423 --> 0.156387).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1861748
	speed: 1.5520s/iter; left time: 19750.8194s
Epoch: 6 cost time: 97.0838623046875
Epoch: 6, Steps: 135 | Train Loss: 0.1889767 Vali Loss: 0.1558501 Test Loss: 0.1838599
Validation loss decreased (0.156387 --> 0.155850).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1807589
	speed: 1.1666s/iter; left time: 14688.8899s
Epoch: 7 cost time: 62.536173820495605
Epoch: 7, Steps: 135 | Train Loss: 0.1882242 Vali Loss: 0.1556021 Test Loss: 0.1834079
Validation loss decreased (0.155850 --> 0.155602).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1906866
	speed: 1.5389s/iter; left time: 19168.2217s
Epoch: 8 cost time: 116.34624814987183
Epoch: 8, Steps: 135 | Train Loss: 0.1879016 Vali Loss: 0.1556163 Test Loss: 0.1831539
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1804885
	speed: 2.2085s/iter; left time: 27210.7050s
Epoch: 9 cost time: 185.6675307750702
Epoch: 9, Steps: 135 | Train Loss: 0.1876404 Vali Loss: 0.1553557 Test Loss: 0.1829851
Validation loss decreased (0.155602 --> 0.155356).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2029163
	speed: 3.0887s/iter; left time: 37638.6219s
Epoch: 10 cost time: 186.0804455280304
Epoch: 10, Steps: 135 | Train Loss: 0.1874102 Vali Loss: 0.1551287 Test Loss: 0.1828593
Validation loss decreased (0.155356 --> 0.155129).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1759960
	speed: 3.0251s/iter; left time: 36455.2326s
Epoch: 11 cost time: 194.42424178123474
Epoch: 11, Steps: 135 | Train Loss: 0.1873420 Vali Loss: 0.1555517 Test Loss: 0.1828252
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1864591
	speed: 3.1276s/iter; left time: 37268.5567s
Epoch: 12 cost time: 196.9328258037567
Epoch: 12, Steps: 135 | Train Loss: 0.1872333 Vali Loss: 0.1553973 Test Loss: 0.1827487
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1861383
	speed: 3.1089s/iter; left time: 36626.0090s
Epoch: 13 cost time: 195.66819047927856
Epoch: 13, Steps: 135 | Train Loss: 0.1870941 Vali Loss: 0.1555940 Test Loss: 0.1826892
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2006658
	speed: 3.0282s/iter; left time: 35266.8546s
Epoch: 14 cost time: 181.04872918128967
Epoch: 14, Steps: 135 | Train Loss: 0.1871128 Vali Loss: 0.1551934 Test Loss: 0.1826535
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1846942
	speed: 3.0640s/iter; left time: 35269.6667s
Epoch: 15 cost time: 186.37154531478882
Epoch: 15, Steps: 135 | Train Loss: 0.1869644 Vali Loss: 0.1552326 Test Loss: 0.1826154
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1846883
	speed: 2.9038s/iter; left time: 33033.3474s
Epoch: 16 cost time: 179.97921538352966
Epoch: 16, Steps: 135 | Train Loss: 0.1869016 Vali Loss: 0.1551721 Test Loss: 0.1825798
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1844069
	speed: 2.9937s/iter; left time: 33651.9622s
Epoch: 17 cost time: 179.40590643882751
Epoch: 17, Steps: 135 | Train Loss: 0.1868662 Vali Loss: 0.1550168 Test Loss: 0.1825751
Validation loss decreased (0.155129 --> 0.155017).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1952342
	speed: 2.8216s/iter; left time: 31336.1378s
Epoch: 18 cost time: 181.9300103187561
Epoch: 18, Steps: 135 | Train Loss: 0.1868798 Vali Loss: 0.1551863 Test Loss: 0.1825631
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1892841
	speed: 2.9353s/iter; left time: 32203.0579s
Epoch: 19 cost time: 169.44134163856506
Epoch: 19, Steps: 135 | Train Loss: 0.1868433 Vali Loss: 0.1550611 Test Loss: 0.1824911
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1836935
	speed: 2.8324s/iter; left time: 30691.3579s
Epoch: 20 cost time: 188.03016638755798
Epoch: 20, Steps: 135 | Train Loss: 0.1867595 Vali Loss: 0.1552163 Test Loss: 0.1825137
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1824248
	speed: 3.1393s/iter; left time: 33593.5028s
Epoch: 21 cost time: 201.60672450065613
Epoch: 21, Steps: 135 | Train Loss: 0.1867021 Vali Loss: 0.1549398 Test Loss: 0.1824993
Validation loss decreased (0.155017 --> 0.154940).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1777570
	speed: 3.0969s/iter; left time: 32722.2633s
Epoch: 22 cost time: 193.12314081192017
Epoch: 22, Steps: 135 | Train Loss: 0.1866957 Vali Loss: 0.1551080 Test Loss: 0.1824926
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1854955
	speed: 2.8195s/iter; left time: 29410.1804s
Epoch: 23 cost time: 172.89994740486145
Epoch: 23, Steps: 135 | Train Loss: 0.1866552 Vali Loss: 0.1549774 Test Loss: 0.1824633
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2033640
	speed: 2.9517s/iter; left time: 30390.7075s
Epoch: 24 cost time: 181.9139220714569
Epoch: 24, Steps: 135 | Train Loss: 0.1867010 Vali Loss: 0.1551062 Test Loss: 0.1824481
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1868911
	speed: 2.8601s/iter; left time: 29061.5606s
Epoch: 25 cost time: 173.4925389289856
Epoch: 25, Steps: 135 | Train Loss: 0.1866515 Vali Loss: 0.1550326 Test Loss: 0.1824539
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1900018
	speed: 2.9233s/iter; left time: 29309.2497s
Epoch: 26 cost time: 181.6402072906494
Epoch: 26, Steps: 135 | Train Loss: 0.1865941 Vali Loss: 0.1551477 Test Loss: 0.1824483
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1806646
	speed: 2.9507s/iter; left time: 29185.0060s
Epoch: 27 cost time: 177.09166312217712
Epoch: 27, Steps: 135 | Train Loss: 0.1865927 Vali Loss: 0.1552629 Test Loss: 0.1824332
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1884409
	speed: 2.8409s/iter; left time: 27715.7182s
Epoch: 28 cost time: 174.35622692108154
Epoch: 28, Steps: 135 | Train Loss: 0.1866032 Vali Loss: 0.1552183 Test Loss: 0.1824418
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1811776
	speed: 2.8474s/iter; left time: 27394.5760s
Epoch: 29 cost time: 179.438805103302
Epoch: 29, Steps: 135 | Train Loss: 0.1866008 Vali Loss: 0.1552294 Test Loss: 0.1824174
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1934192
	speed: 2.8587s/iter; left time: 27117.8314s
Epoch: 30 cost time: 178.15015029907227
Epoch: 30, Steps: 135 | Train Loss: 0.1865975 Vali Loss: 0.1549185 Test Loss: 0.1823985
Validation loss decreased (0.154940 --> 0.154919).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1818419
	speed: 2.7684s/iter; left time: 25887.6119s
Epoch: 31 cost time: 165.86555981636047
Epoch: 31, Steps: 135 | Train Loss: 0.1865394 Vali Loss: 0.1551894 Test Loss: 0.1823795
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1961755
	speed: 2.8740s/iter; left time: 26486.3825s
Epoch: 32 cost time: 185.97522592544556
Epoch: 32, Steps: 135 | Train Loss: 0.1865647 Vali Loss: 0.1549686 Test Loss: 0.1823992
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1813110
	speed: 2.9414s/iter; left time: 26710.8271s
Epoch: 33 cost time: 176.10709285736084
Epoch: 33, Steps: 135 | Train Loss: 0.1865802 Vali Loss: 0.1552072 Test Loss: 0.1823868
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1880092
	speed: 2.6566s/iter; left time: 23765.6571s
Epoch: 34 cost time: 158.7630112171173
Epoch: 34, Steps: 135 | Train Loss: 0.1865277 Vali Loss: 0.1550821 Test Loss: 0.1823917
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1896384
	speed: 2.4676s/iter; left time: 21741.8808s
Epoch: 35 cost time: 146.57488751411438
Epoch: 35, Steps: 135 | Train Loss: 0.1865985 Vali Loss: 0.1552012 Test Loss: 0.1823947
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1949090
	speed: 2.5446s/iter; left time: 22077.2340s
Epoch: 36 cost time: 158.63895630836487
Epoch: 36, Steps: 135 | Train Loss: 0.1864767 Vali Loss: 0.1548431 Test Loss: 0.1823778
Validation loss decreased (0.154919 --> 0.154843).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2004752
	speed: 2.4142s/iter; left time: 20619.3081s
Epoch: 37 cost time: 145.20620322227478
Epoch: 37, Steps: 135 | Train Loss: 0.1864627 Vali Loss: 0.1549182 Test Loss: 0.1823927
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1850765
	speed: 2.4675s/iter; left time: 20741.5233s
Epoch: 38 cost time: 151.56617093086243
Epoch: 38, Steps: 135 | Train Loss: 0.1865235 Vali Loss: 0.1549501 Test Loss: 0.1823731
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1865628
	speed: 2.3304s/iter; left time: 19275.0243s
Epoch: 39 cost time: 136.53333830833435
Epoch: 39, Steps: 135 | Train Loss: 0.1864892 Vali Loss: 0.1547122 Test Loss: 0.1823771
Validation loss decreased (0.154843 --> 0.154712).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1896905
	speed: 2.6088s/iter; left time: 21225.2922s
Epoch: 40 cost time: 164.38095211982727
Epoch: 40, Steps: 135 | Train Loss: 0.1865070 Vali Loss: 0.1548262 Test Loss: 0.1823707
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1986483
	speed: 2.6003s/iter; left time: 20805.2292s
Epoch: 41 cost time: 150.2748155593872
Epoch: 41, Steps: 135 | Train Loss: 0.1864535 Vali Loss: 0.1549874 Test Loss: 0.1823715
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1825011
	speed: 2.3908s/iter; left time: 18805.8239s
Epoch: 42 cost time: 146.78117895126343
Epoch: 42, Steps: 135 | Train Loss: 0.1864405 Vali Loss: 0.1551440 Test Loss: 0.1823645
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1810034
	speed: 2.4325s/iter; left time: 18805.9242s
Epoch: 43 cost time: 143.82627534866333
Epoch: 43, Steps: 135 | Train Loss: 0.1865414 Vali Loss: 0.1548500 Test Loss: 0.1823597
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1991306
	speed: 2.3608s/iter; left time: 17932.3093s
Epoch: 44 cost time: 136.0578808784485
Epoch: 44, Steps: 135 | Train Loss: 0.1864664 Vali Loss: 0.1550305 Test Loss: 0.1823568
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1824315
	speed: 2.2978s/iter; left time: 17143.6695s
Epoch: 45 cost time: 137.73141074180603
Epoch: 45, Steps: 135 | Train Loss: 0.1864546 Vali Loss: 0.1545877 Test Loss: 0.1823629
Validation loss decreased (0.154712 --> 0.154588).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2030724
	speed: 2.1475s/iter; left time: 15732.7359s
Epoch: 46 cost time: 118.39483261108398
Epoch: 46, Steps: 135 | Train Loss: 0.1865165 Vali Loss: 0.1551215 Test Loss: 0.1823658
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1738501
	speed: 1.9380s/iter; left time: 13936.2163s
Epoch: 47 cost time: 133.4305968284607
Epoch: 47, Steps: 135 | Train Loss: 0.1863980 Vali Loss: 0.1548958 Test Loss: 0.1823571
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1871369
	speed: 2.0772s/iter; left time: 14656.7479s
Epoch: 48 cost time: 118.472571849823
Epoch: 48, Steps: 135 | Train Loss: 0.1864878 Vali Loss: 0.1549086 Test Loss: 0.1823530
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1847426
	speed: 1.8507s/iter; left time: 12808.8937s
Epoch: 49 cost time: 121.85520720481873
Epoch: 49, Steps: 135 | Train Loss: 0.1864726 Vali Loss: 0.1547109 Test Loss: 0.1823588
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1782517
	speed: 2.0296s/iter; left time: 13772.8537s
Epoch: 50 cost time: 130.14238619804382
Epoch: 50, Steps: 135 | Train Loss: 0.1864524 Vali Loss: 0.1546905 Test Loss: 0.1823504
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1872687
	speed: 1.8441s/iter; left time: 12265.3160s
Epoch: 51 cost time: 105.2723081111908
Epoch: 51, Steps: 135 | Train Loss: 0.1864756 Vali Loss: 0.1549532 Test Loss: 0.1823530
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1843809
	speed: 1.9710s/iter; left time: 12842.8379s
Epoch: 52 cost time: 124.17814230918884
Epoch: 52, Steps: 135 | Train Loss: 0.1863977 Vali Loss: 0.1549577 Test Loss: 0.1823450
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1891199
	speed: 1.8414s/iter; left time: 11749.7789s
Epoch: 53 cost time: 114.73975157737732
Epoch: 53, Steps: 135 | Train Loss: 0.1864895 Vali Loss: 0.1548849 Test Loss: 0.1823419
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1895075
	speed: 1.9386s/iter; left time: 12108.3479s
Epoch: 54 cost time: 124.91034030914307
Epoch: 54, Steps: 135 | Train Loss: 0.1864590 Vali Loss: 0.1549410 Test Loss: 0.1823370
EarlyStopping counter: 9 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1867337
	speed: 2.0700s/iter; left time: 12649.5723s
Epoch: 55 cost time: 125.20814299583435
Epoch: 55, Steps: 135 | Train Loss: 0.1863866 Vali Loss: 0.1549290 Test Loss: 0.1823409
EarlyStopping counter: 10 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1844308
	speed: 2.0040s/iter; left time: 11976.1121s
Epoch: 56 cost time: 123.57458472251892
Epoch: 56, Steps: 135 | Train Loss: 0.1864393 Vali Loss: 0.1545894 Test Loss: 0.1823406
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.1971484
	speed: 1.9322s/iter; left time: 11286.0131s
Epoch: 57 cost time: 118.44451904296875
Epoch: 57, Steps: 135 | Train Loss: 0.1864352 Vali Loss: 0.1548503 Test Loss: 0.1823389
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1796401
	speed: 1.8940s/iter; left time: 10807.1343s
Epoch: 58 cost time: 108.76419854164124
Epoch: 58, Steps: 135 | Train Loss: 0.1864300 Vali Loss: 0.1549736 Test Loss: 0.1823374
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1844072
	speed: 1.6192s/iter; left time: 9020.2965s
Epoch: 59 cost time: 97.21550273895264
Epoch: 59, Steps: 135 | Train Loss: 0.1864293 Vali Loss: 0.1549130 Test Loss: 0.1823454
EarlyStopping counter: 14 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1833641
	speed: 1.5835s/iter; left time: 8607.7458s
Epoch: 60 cost time: 98.85308861732483
Epoch: 60, Steps: 135 | Train Loss: 0.1863755 Vali Loss: 0.1548253 Test Loss: 0.1823408
EarlyStopping counter: 15 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1921136
	speed: 1.5411s/iter; left time: 8169.1924s
Epoch: 61 cost time: 99.49096155166626
Epoch: 61, Steps: 135 | Train Loss: 0.1864140 Vali Loss: 0.1550807 Test Loss: 0.1823354
EarlyStopping counter: 16 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1857233
	speed: 1.5208s/iter; left time: 7856.3219s
Epoch: 62 cost time: 97.60889840126038
Epoch: 62, Steps: 135 | Train Loss: 0.1864238 Vali Loss: 0.1549568 Test Loss: 0.1823312
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1892678
	speed: 1.5517s/iter; left time: 7806.7340s
Epoch: 63 cost time: 95.56592440605164
Epoch: 63, Steps: 135 | Train Loss: 0.1864501 Vali Loss: 0.1549661 Test Loss: 0.1823356
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1854017
	speed: 1.4681s/iter; left time: 7187.6798s
Epoch: 64 cost time: 93.0566086769104
Epoch: 64, Steps: 135 | Train Loss: 0.1863799 Vali Loss: 0.1549474 Test Loss: 0.1823336
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.1826818
	speed: 1.5238s/iter; left time: 7254.6943s
Epoch: 65 cost time: 94.45805072784424
Epoch: 65, Steps: 135 | Train Loss: 0.1864181 Vali Loss: 0.1549301 Test Loss: 0.1823346
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_720_j336_H4_FITS_custom_ftM_sl720_ll48_pl336_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4925
mse:0.18017813563346863, mae:0.2833714783191681, rse:0.42246654629707336, corr:[0.4586754  0.46052527 0.46096966 0.46188962 0.4626406  0.46275604
 0.46252155 0.4623022  0.462126   0.46193033 0.4617457  0.46172366
 0.46186066 0.4619886  0.4620085  0.46198183 0.4619855  0.4620573
 0.46210402 0.46197468 0.46178195 0.4617794  0.46203822 0.46238935
 0.46259144 0.46273795 0.46268687 0.4625258  0.46240866 0.4623118
 0.46216655 0.4620202  0.4619167  0.46186832 0.46182925 0.46178877
 0.46177706 0.4618055  0.46188837 0.4619645  0.46196425 0.4619002
 0.46181324 0.46168935 0.46157107 0.46151435 0.46152157 0.4615956
 0.4617355  0.46194556 0.46201366 0.46187937 0.46169746 0.46159145
 0.46156463 0.46156493 0.46153736 0.4614901  0.46146578 0.46147966
 0.46150988 0.46150306 0.46147007 0.46145514 0.4614695  0.46149492
 0.46140662 0.4611642  0.46093917 0.46085674 0.46091616 0.46099812
 0.4610223  0.46103042 0.46098056 0.46091163 0.4608668  0.4608333
 0.4607949  0.46074218 0.46070707 0.4606927  0.46067354 0.4606463
 0.46063754 0.46064684 0.4606739  0.46068072 0.4606311  0.460552
 0.46051085 0.46049178 0.46046987 0.46046877 0.4604969  0.4605532
 0.46064952 0.460763   0.46077305 0.46069336 0.4606014  0.4605539
 0.46054342 0.4605401  0.46051937 0.460496   0.46047586 0.4604829
 0.46049362 0.4604671  0.4604189  0.4603708  0.46034938 0.46035945
 0.46036476 0.46024522 0.46006724 0.46001425 0.46011904 0.46030048
 0.46046516 0.46052667 0.4605113  0.46051776 0.46056765 0.46061713
 0.46061957 0.46057802 0.46053195 0.46049407 0.46044132 0.46037745
 0.46032947 0.4603091  0.46032715 0.46035534 0.4603528  0.46033424
 0.46029937 0.46016398 0.45997405 0.45983133 0.45975217 0.4597461
 0.45980093 0.45990372 0.45995417 0.4599546  0.45994493 0.45995814
 0.45997664 0.4599829  0.45996657 0.45993865 0.45990482 0.45987788
 0.45985362 0.45981583 0.45978913 0.45976615 0.45975128 0.4597615
 0.45975685 0.45961428 0.45945904 0.4593649  0.45934904 0.4594014
 0.45941263 0.4594578  0.45939502 0.45926222 0.459179   0.45915034
 0.4591305  0.45907772 0.45895877 0.45882282 0.45869023 0.4585835
 0.4585015  0.45841646 0.45834562 0.45827404 0.45814326 0.45796475
 0.457797   0.4576414  0.45752642 0.45749268 0.45754027 0.45760062
 0.45767733 0.45784664 0.45793676 0.45789352 0.45779434 0.45770082
 0.45762363 0.45754722 0.45746082 0.45736808 0.4572794  0.4572215
 0.4571822  0.4571051  0.457035   0.45700034 0.45701158 0.45704916
 0.4570385  0.45690417 0.4567354  0.45668712 0.45679352 0.4569749
 0.45716238 0.45736358 0.45745337 0.4574359  0.45740348 0.45738018
 0.45733973 0.4572606  0.45715576 0.45703351 0.4569176  0.45681858
 0.4567585  0.45672825 0.45673788 0.45674857 0.45673868 0.45670635
 0.45662147 0.45646963 0.45634952 0.45635462 0.45644686 0.45656562
 0.4567109  0.45691752 0.45702982 0.45700622 0.45691955 0.45683467
 0.4567746  0.45669645 0.45660055 0.4564903  0.45639476 0.4563354
 0.45628238 0.45620027 0.45610946 0.45606497 0.45608085 0.4561446
 0.4562139  0.4562162  0.45617062 0.45618773 0.45631254 0.45648447
 0.45662963 0.45673597 0.45675567 0.45672914 0.45671412 0.45670134
 0.45663807 0.45651588 0.45637125 0.4562352  0.45609984 0.4559798
 0.45591426 0.45589918 0.45594996 0.4559968  0.45598724 0.4559422
 0.45591766 0.45586863 0.45584083 0.455897   0.45602158 0.45617148
 0.4563629  0.4565301  0.45658657 0.45654836 0.45646602 0.4563722
 0.456292   0.45619845 0.456076   0.45592785 0.45577002 0.45564753
 0.45556659 0.45549515 0.4554733  0.45554066 0.45568332 0.45584324
 0.4558871  0.45569506 0.4554009  0.45528156 0.4553664  0.4554978
 0.45553902 0.45552406 0.45544794 0.45536238 0.45530346 0.45522228
 0.45505744 0.45484126 0.45467505 0.4546145  0.45464233 0.454723
 0.45486593 0.4550452  0.45518726 0.45519426 0.45506918 0.4550264
 0.45514604 0.4550761  0.45454    0.4537633  0.45414817 0.4554621 ]
