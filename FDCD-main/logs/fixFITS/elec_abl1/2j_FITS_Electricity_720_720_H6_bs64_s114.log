Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_720_j720_H6', moving_avg=25, n_heads=8, num_workers=4, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Electricity_720_j720_H6_FITS_custom_ftM_sl720_ll48_pl720_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 16973
val 1913
test 4541
Model(
  (freq_upsampler): Linear(in_features=196, out_features=392, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3156873216.0
params:  77224.0
Trainable parameters:  77224
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.8259348
	speed: 1.0485s/iter; left time: 13736.5505s
Epoch: 1 cost time: 138.14667677879333
Epoch: 1, Steps: 132 | Train Loss: 0.9878039 Vali Loss: 0.7081494 Test Loss: 0.8339151
Validation loss decreased (inf --> 0.708149).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6901113
	speed: 2.3001s/iter; left time: 29830.3929s
Epoch: 2 cost time: 140.64044046401978
Epoch: 2, Steps: 132 | Train Loss: 0.7131633 Vali Loss: 0.6156580 Test Loss: 0.7299484
Validation loss decreased (0.708149 --> 0.615658).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5946743
	speed: 2.3236s/iter; left time: 29827.4831s
Epoch: 3 cost time: 137.45744514465332
Epoch: 3, Steps: 132 | Train Loss: 0.6219164 Vali Loss: 0.5546776 Test Loss: 0.6609886
Validation loss decreased (0.615658 --> 0.554678).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.5236756
	speed: 2.3135s/iter; left time: 29392.7809s
Epoch: 4 cost time: 141.82040190696716
Epoch: 4, Steps: 132 | Train Loss: 0.5515451 Vali Loss: 0.5050785 Test Loss: 0.6041579
Validation loss decreased (0.554678 --> 0.505078).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4807121
	speed: 2.2367s/iter; left time: 28121.6874s
Epoch: 5 cost time: 137.2300317287445
Epoch: 5, Steps: 132 | Train Loss: 0.4934603 Vali Loss: 0.4608694 Test Loss: 0.5539577
Validation loss decreased (0.505078 --> 0.460869).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4357661
	speed: 2.2577s/iter; left time: 28087.9787s
Epoch: 6 cost time: 137.8303186893463
Epoch: 6, Steps: 132 | Train Loss: 0.4445073 Vali Loss: 0.4254083 Test Loss: 0.5129316
Validation loss decreased (0.460869 --> 0.425408).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3866423
	speed: 2.3162s/iter; left time: 28510.2702s
Epoch: 7 cost time: 138.15292954444885
Epoch: 7, Steps: 132 | Train Loss: 0.4030187 Vali Loss: 0.3932073 Test Loss: 0.4755065
Validation loss decreased (0.425408 --> 0.393207).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3576087
	speed: 2.3484s/iter; left time: 28596.8884s
Epoch: 8 cost time: 140.1296100616455
Epoch: 8, Steps: 132 | Train Loss: 0.3676375 Vali Loss: 0.3657295 Test Loss: 0.4442575
Validation loss decreased (0.393207 --> 0.365730).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3373825
	speed: 2.4081s/iter; left time: 29005.6078s
Epoch: 9 cost time: 144.0736162662506
Epoch: 9, Steps: 132 | Train Loss: 0.3372403 Vali Loss: 0.3423839 Test Loss: 0.4171302
Validation loss decreased (0.365730 --> 0.342384).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3047849
	speed: 2.3268s/iter; left time: 27718.6650s
Epoch: 10 cost time: 143.56857061386108
Epoch: 10, Steps: 132 | Train Loss: 0.3110997 Vali Loss: 0.3220282 Test Loss: 0.3927833
Validation loss decreased (0.342384 --> 0.322028).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2809854
	speed: 2.6461s/iter; left time: 31173.7437s
Epoch: 11 cost time: 156.65476489067078
Epoch: 11, Steps: 132 | Train Loss: 0.2884965 Vali Loss: 0.3039741 Test Loss: 0.3718235
Validation loss decreased (0.322028 --> 0.303974).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2603382
	speed: 2.4941s/iter; left time: 29053.3127s
Epoch: 12 cost time: 150.88783931732178
Epoch: 12, Steps: 132 | Train Loss: 0.2687797 Vali Loss: 0.2889496 Test Loss: 0.3536977
Validation loss decreased (0.303974 --> 0.288950).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2509548
	speed: 2.4330s/iter; left time: 28020.7174s
Epoch: 13 cost time: 149.33411407470703
Epoch: 13, Steps: 132 | Train Loss: 0.2516764 Vali Loss: 0.2761997 Test Loss: 0.3382394
Validation loss decreased (0.288950 --> 0.276200).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2378232
	speed: 2.4732s/iter; left time: 28157.4303s
Epoch: 14 cost time: 154.7786591053009
Epoch: 14, Steps: 132 | Train Loss: 0.2367089 Vali Loss: 0.2645676 Test Loss: 0.3246557
Validation loss decreased (0.276200 --> 0.264568).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2205600
	speed: 2.3485s/iter; left time: 26427.3514s
Epoch: 15 cost time: 142.71849846839905
Epoch: 15, Steps: 132 | Train Loss: 0.2237001 Vali Loss: 0.2547683 Test Loss: 0.3126707
Validation loss decreased (0.264568 --> 0.254768).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2078114
	speed: 2.2798s/iter; left time: 25353.9787s
Epoch: 16 cost time: 135.32402968406677
Epoch: 16, Steps: 132 | Train Loss: 0.2122991 Vali Loss: 0.2456470 Test Loss: 0.3018050
Validation loss decreased (0.254768 --> 0.245647).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2036704
	speed: 2.2776s/iter; left time: 25028.1887s
Epoch: 17 cost time: 137.98857831954956
Epoch: 17, Steps: 132 | Train Loss: 0.2022186 Vali Loss: 0.2381136 Test Loss: 0.2924009
Validation loss decreased (0.245647 --> 0.238114).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1950787
	speed: 2.3156s/iter; left time: 25140.7115s
Epoch: 18 cost time: 139.55429673194885
Epoch: 18, Steps: 132 | Train Loss: 0.1934131 Vali Loss: 0.2309197 Test Loss: 0.2834929
Validation loss decreased (0.238114 --> 0.230920).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1794797
	speed: 2.3467s/iter; left time: 25168.5127s
Epoch: 19 cost time: 140.84460759162903
Epoch: 19, Steps: 132 | Train Loss: 0.1855749 Vali Loss: 0.2249341 Test Loss: 0.2761059
Validation loss decreased (0.230920 --> 0.224934).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1709046
	speed: 2.2843s/iter; left time: 24197.7475s
Epoch: 20 cost time: 136.81764817237854
Epoch: 20, Steps: 132 | Train Loss: 0.1787157 Vali Loss: 0.2198402 Test Loss: 0.2697162
Validation loss decreased (0.224934 --> 0.219840).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1755804
	speed: 2.2757s/iter; left time: 23806.6006s
Epoch: 21 cost time: 137.07297492027283
Epoch: 21, Steps: 132 | Train Loss: 0.1725933 Vali Loss: 0.2151344 Test Loss: 0.2639276
Validation loss decreased (0.219840 --> 0.215134).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1630259
	speed: 2.2854s/iter; left time: 23606.0487s
Epoch: 22 cost time: 134.42870950698853
Epoch: 22, Steps: 132 | Train Loss: 0.1672224 Vali Loss: 0.2110481 Test Loss: 0.2586209
Validation loss decreased (0.215134 --> 0.211048).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1575114
	speed: 2.3227s/iter; left time: 23684.9541s
Epoch: 23 cost time: 143.9074580669403
Epoch: 23, Steps: 132 | Train Loss: 0.1624568 Vali Loss: 0.2081449 Test Loss: 0.2544224
Validation loss decreased (0.211048 --> 0.208145).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1583074
	speed: 2.3487s/iter; left time: 23639.1746s
Epoch: 24 cost time: 143.0182728767395
Epoch: 24, Steps: 132 | Train Loss: 0.1581961 Vali Loss: 0.2045676 Test Loss: 0.2500305
Validation loss decreased (0.208145 --> 0.204568).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1499329
	speed: 2.2742s/iter; left time: 22589.8066s
Epoch: 25 cost time: 131.80439805984497
Epoch: 25, Steps: 132 | Train Loss: 0.1544265 Vali Loss: 0.2016501 Test Loss: 0.2462967
Validation loss decreased (0.204568 --> 0.201650).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1505921
	speed: 2.1582s/iter; left time: 21152.6676s
Epoch: 26 cost time: 130.10307478904724
Epoch: 26, Steps: 132 | Train Loss: 0.1510771 Vali Loss: 0.1997233 Test Loss: 0.2433413
Validation loss decreased (0.201650 --> 0.199723).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1464386
	speed: 2.3297s/iter; left time: 22525.4138s
Epoch: 27 cost time: 140.6375014781952
Epoch: 27, Steps: 132 | Train Loss: 0.1480563 Vali Loss: 0.1973354 Test Loss: 0.2401497
Validation loss decreased (0.199723 --> 0.197335).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1511684
	speed: 2.2570s/iter; left time: 21524.7028s
Epoch: 28 cost time: 135.01946806907654
Epoch: 28, Steps: 132 | Train Loss: 0.1453948 Vali Loss: 0.1952988 Test Loss: 0.2376631
Validation loss decreased (0.197335 --> 0.195299).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1525755
	speed: 2.2944s/iter; left time: 21579.1419s
Epoch: 29 cost time: 139.8885908126831
Epoch: 29, Steps: 132 | Train Loss: 0.1429712 Vali Loss: 0.1936904 Test Loss: 0.2352547
Validation loss decreased (0.195299 --> 0.193690).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1438622
	speed: 2.3846s/iter; left time: 22112.4993s
Epoch: 30 cost time: 144.73773384094238
Epoch: 30, Steps: 132 | Train Loss: 0.1408694 Vali Loss: 0.1920968 Test Loss: 0.2330631
Validation loss decreased (0.193690 --> 0.192097).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1448461
	speed: 2.3489s/iter; left time: 21470.8436s
Epoch: 31 cost time: 141.86128520965576
Epoch: 31, Steps: 132 | Train Loss: 0.1389452 Vali Loss: 0.1910416 Test Loss: 0.2311342
Validation loss decreased (0.192097 --> 0.191042).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1359790
	speed: 2.3774s/iter; left time: 21418.4336s
Epoch: 32 cost time: 148.2156593799591
Epoch: 32, Steps: 132 | Train Loss: 0.1372077 Vali Loss: 0.1896621 Test Loss: 0.2295070
Validation loss decreased (0.191042 --> 0.189662).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1314861
	speed: 2.3701s/iter; left time: 21039.6619s
Epoch: 33 cost time: 140.27067470550537
Epoch: 33, Steps: 132 | Train Loss: 0.1357271 Vali Loss: 0.1888332 Test Loss: 0.2280598
Validation loss decreased (0.189662 --> 0.188833).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1314596
	speed: 2.3438s/iter; left time: 20496.3147s
Epoch: 34 cost time: 139.82527422904968
Epoch: 34, Steps: 132 | Train Loss: 0.1343452 Vali Loss: 0.1877756 Test Loss: 0.2265968
Validation loss decreased (0.188833 --> 0.187776).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1307553
	speed: 2.2995s/iter; left time: 19805.4898s
Epoch: 35 cost time: 138.49312663078308
Epoch: 35, Steps: 132 | Train Loss: 0.1330858 Vali Loss: 0.1865937 Test Loss: 0.2253423
Validation loss decreased (0.187776 --> 0.186594).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1352296
	speed: 2.3129s/iter; left time: 19616.0771s
Epoch: 36 cost time: 141.39700555801392
Epoch: 36, Steps: 132 | Train Loss: 0.1319909 Vali Loss: 0.1859448 Test Loss: 0.2242013
Validation loss decreased (0.186594 --> 0.185945).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1305324
	speed: 2.3223s/iter; left time: 19388.5519s
Epoch: 37 cost time: 141.17066192626953
Epoch: 37, Steps: 132 | Train Loss: 0.1309912 Vali Loss: 0.1854259 Test Loss: 0.2232578
Validation loss decreased (0.185945 --> 0.185426).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1299227
	speed: 2.3592s/iter; left time: 19385.2877s
Epoch: 38 cost time: 146.0962471961975
Epoch: 38, Steps: 132 | Train Loss: 0.1301336 Vali Loss: 0.1845713 Test Loss: 0.2223119
Validation loss decreased (0.185426 --> 0.184571).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1242842
	speed: 2.4272s/iter; left time: 19623.5771s
Epoch: 39 cost time: 144.44333839416504
Epoch: 39, Steps: 132 | Train Loss: 0.1293015 Vali Loss: 0.1844897 Test Loss: 0.2214438
Validation loss decreased (0.184571 --> 0.184490).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1307326
	speed: 2.3661s/iter; left time: 18817.6475s
Epoch: 40 cost time: 142.9234173297882
Epoch: 40, Steps: 132 | Train Loss: 0.1285497 Vali Loss: 0.1839560 Test Loss: 0.2207047
Validation loss decreased (0.184490 --> 0.183956).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1203706
	speed: 2.3992s/iter; left time: 18763.9574s
Epoch: 41 cost time: 148.76539731025696
Epoch: 41, Steps: 132 | Train Loss: 0.1279231 Vali Loss: 0.1834469 Test Loss: 0.2199919
Validation loss decreased (0.183956 --> 0.183447).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1292644
	speed: 2.4330s/iter; left time: 18706.9875s
Epoch: 42 cost time: 148.41089725494385
Epoch: 42, Steps: 132 | Train Loss: 0.1273424 Vali Loss: 0.1834448 Test Loss: 0.2194882
Validation loss decreased (0.183447 --> 0.183445).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1282528
	speed: 2.3672s/iter; left time: 17888.8615s
Epoch: 43 cost time: 142.17462873458862
Epoch: 43, Steps: 132 | Train Loss: 0.1268145 Vali Loss: 0.1827144 Test Loss: 0.2188484
Validation loss decreased (0.183445 --> 0.182714).  Saving model ...
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1235524
	speed: 2.4413s/iter; left time: 18126.7494s
Epoch: 44 cost time: 141.46229648590088
Epoch: 44, Steps: 132 | Train Loss: 0.1262994 Vali Loss: 0.1826613 Test Loss: 0.2183710
Validation loss decreased (0.182714 --> 0.182661).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1276820
	speed: 2.3814s/iter; left time: 17367.3235s
Epoch: 45 cost time: 143.75226187705994
Epoch: 45, Steps: 132 | Train Loss: 0.1259078 Vali Loss: 0.1825002 Test Loss: 0.2178489
Validation loss decreased (0.182661 --> 0.182500).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1230792
	speed: 2.3852s/iter; left time: 17080.1915s
Epoch: 46 cost time: 145.28569865226746
Epoch: 46, Steps: 132 | Train Loss: 0.1254842 Vali Loss: 0.1822102 Test Loss: 0.2174983
Validation loss decreased (0.182500 --> 0.182210).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1267730
	speed: 2.3979s/iter; left time: 16855.1309s
Epoch: 47 cost time: 144.54805541038513
Epoch: 47, Steps: 132 | Train Loss: 0.1251439 Vali Loss: 0.1818386 Test Loss: 0.2170721
Validation loss decreased (0.182210 --> 0.181839).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1289224
	speed: 2.3816s/iter; left time: 16426.0462s
Epoch: 48 cost time: 144.60890793800354
Epoch: 48, Steps: 132 | Train Loss: 0.1248156 Vali Loss: 0.1817324 Test Loss: 0.2167362
Validation loss decreased (0.181839 --> 0.181732).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1265854
	speed: 2.4609s/iter; left time: 16647.6544s
Epoch: 49 cost time: 146.28328132629395
Epoch: 49, Steps: 132 | Train Loss: 0.1244962 Vali Loss: 0.1817739 Test Loss: 0.2164275
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1204440
	speed: 2.3583s/iter; left time: 15642.7491s
Epoch: 50 cost time: 142.01818227767944
Epoch: 50, Steps: 132 | Train Loss: 0.1242539 Vali Loss: 0.1817089 Test Loss: 0.2161458
Validation loss decreased (0.181732 --> 0.181709).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.1270068
	speed: 2.4060s/iter; left time: 15641.2051s
Epoch: 51 cost time: 142.20057654380798
Epoch: 51, Steps: 132 | Train Loss: 0.1239982 Vali Loss: 0.1813994 Test Loss: 0.2159041
Validation loss decreased (0.181709 --> 0.181399).  Saving model ...
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.1298972
	speed: 2.2871s/iter; left time: 14566.3575s
Epoch: 52 cost time: 136.34524703025818
Epoch: 52, Steps: 132 | Train Loss: 0.1238151 Vali Loss: 0.1814022 Test Loss: 0.2156168
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.1217112
	speed: 2.1994s/iter; left time: 13717.5284s
Epoch: 53 cost time: 139.70055484771729
Epoch: 53, Steps: 132 | Train Loss: 0.1236363 Vali Loss: 0.1813475 Test Loss: 0.2153877
Validation loss decreased (0.181399 --> 0.181347).  Saving model ...
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.1233315
	speed: 2.3071s/iter; left time: 14084.6859s
Epoch: 54 cost time: 138.7359812259674
Epoch: 54, Steps: 132 | Train Loss: 0.1234204 Vali Loss: 0.1809530 Test Loss: 0.2152256
Validation loss decreased (0.181347 --> 0.180953).  Saving model ...
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.1237257
	speed: 2.2865s/iter; left time: 13657.2817s
Epoch: 55 cost time: 137.4490611553192
Epoch: 55, Steps: 132 | Train Loss: 0.1232833 Vali Loss: 0.1810017 Test Loss: 0.2150223
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.1192580
	speed: 2.2361s/iter; left time: 13061.2115s
Epoch: 56 cost time: 135.95130252838135
Epoch: 56, Steps: 132 | Train Loss: 0.1231433 Vali Loss: 0.1812026 Test Loss: 0.2148597
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.1312182
	speed: 2.3539s/iter; left time: 13438.2244s
Epoch: 57 cost time: 140.2886140346527
Epoch: 57, Steps: 132 | Train Loss: 0.1230256 Vali Loss: 0.1810260 Test Loss: 0.2146989
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.1200040
	speed: 2.3050s/iter; left time: 12855.1269s
Epoch: 58 cost time: 142.69721817970276
Epoch: 58, Steps: 132 | Train Loss: 0.1228554 Vali Loss: 0.1810212 Test Loss: 0.2145652
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.1225312
	speed: 2.3801s/iter; left time: 12959.3794s
Epoch: 59 cost time: 142.17254734039307
Epoch: 59, Steps: 132 | Train Loss: 0.1227598 Vali Loss: 0.1810732 Test Loss: 0.2144234
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.1212081
	speed: 2.3698s/iter; left time: 12590.7365s
Epoch: 60 cost time: 142.0991530418396
Epoch: 60, Steps: 132 | Train Loss: 0.1226657 Vali Loss: 0.1810124 Test Loss: 0.2143276
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.1194649
	speed: 2.3962s/iter; left time: 12414.8738s
Epoch: 61 cost time: 141.4156801700592
Epoch: 61, Steps: 132 | Train Loss: 0.1225677 Vali Loss: 0.1809236 Test Loss: 0.2142162
Validation loss decreased (0.180953 --> 0.180924).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.1207664
	speed: 2.3555s/iter; left time: 11892.7549s
Epoch: 62 cost time: 144.71775603294373
Epoch: 62, Steps: 132 | Train Loss: 0.1224994 Vali Loss: 0.1808667 Test Loss: 0.2141133
Validation loss decreased (0.180924 --> 0.180867).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.1203168
	speed: 2.3783s/iter; left time: 11693.8800s
Epoch: 63 cost time: 144.19657921791077
Epoch: 63, Steps: 132 | Train Loss: 0.1224191 Vali Loss: 0.1808268 Test Loss: 0.2140205
Validation loss decreased (0.180867 --> 0.180827).  Saving model ...
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.1262900
	speed: 2.3751s/iter; left time: 11364.9392s
Epoch: 64 cost time: 144.77336978912354
Epoch: 64, Steps: 132 | Train Loss: 0.1223519 Vali Loss: 0.1809931 Test Loss: 0.2139298
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.1204892
	speed: 2.4221s/iter; left time: 11270.0845s
Epoch: 65 cost time: 144.82476782798767
Epoch: 65, Steps: 132 | Train Loss: 0.1222817 Vali Loss: 0.1809107 Test Loss: 0.2138555
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.1231504
	speed: 2.3667s/iter; left time: 10699.7259s
Epoch: 66 cost time: 143.73648071289062
Epoch: 66, Steps: 132 | Train Loss: 0.1222204 Vali Loss: 0.1808720 Test Loss: 0.2137703
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.1289347
	speed: 2.3849s/iter; left time: 10467.2232s
Epoch: 67 cost time: 140.8700840473175
Epoch: 67, Steps: 132 | Train Loss: 0.1221531 Vali Loss: 0.1808348 Test Loss: 0.2137147
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.1255695
	speed: 2.3893s/iter; left time: 10171.1515s
Epoch: 68 cost time: 144.37398600578308
Epoch: 68, Steps: 132 | Train Loss: 0.1221221 Vali Loss: 0.1805896 Test Loss: 0.2136548
Validation loss decreased (0.180827 --> 0.180590).  Saving model ...
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.1165864
	speed: 2.4085s/iter; left time: 9935.0564s
Epoch: 69 cost time: 145.2778890132904
Epoch: 69, Steps: 132 | Train Loss: 0.1220830 Vali Loss: 0.1810040 Test Loss: 0.2136039
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.1268079
	speed: 2.3513s/iter; left time: 9388.6805s
Epoch: 70 cost time: 140.93257117271423
Epoch: 70, Steps: 132 | Train Loss: 0.1220489 Vali Loss: 0.1811805 Test Loss: 0.2135475
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.1235600
	speed: 2.3726s/iter; left time: 9160.4297s
Epoch: 71 cost time: 145.60405445098877
Epoch: 71, Steps: 132 | Train Loss: 0.1219961 Vali Loss: 0.1807067 Test Loss: 0.2134988
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.1210195
	speed: 2.4072s/iter; left time: 8976.5109s
Epoch: 72 cost time: 145.26706433296204
Epoch: 72, Steps: 132 | Train Loss: 0.1219535 Vali Loss: 0.1807013 Test Loss: 0.2134502
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.1241973
	speed: 2.3723s/iter; left time: 8533.0809s
Epoch: 73 cost time: 141.903156042099
Epoch: 73, Steps: 132 | Train Loss: 0.1219230 Vali Loss: 0.1811430 Test Loss: 0.2134136
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.1220888
	speed: 2.3795s/iter; left time: 8245.0888s
Epoch: 74 cost time: 139.95129132270813
Epoch: 74, Steps: 132 | Train Loss: 0.1219096 Vali Loss: 0.1809131 Test Loss: 0.2133708
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.1251092
	speed: 2.2871s/iter; left time: 7622.7398s
Epoch: 75 cost time: 136.42775297164917
Epoch: 75, Steps: 132 | Train Loss: 0.1218886 Vali Loss: 0.1808396 Test Loss: 0.2133396
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.1155568
	speed: 2.3427s/iter; left time: 7498.9851s
Epoch: 76 cost time: 139.48778533935547
Epoch: 76, Steps: 132 | Train Loss: 0.1218765 Vali Loss: 0.1809829 Test Loss: 0.2133018
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.1212645
	speed: 2.2943s/iter; left time: 7041.1149s
Epoch: 77 cost time: 136.503493309021
Epoch: 77, Steps: 132 | Train Loss: 0.1218404 Vali Loss: 0.1810878 Test Loss: 0.2132735
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.1164711
	speed: 2.3227s/iter; left time: 6821.6495s
Epoch: 78 cost time: 142.579683303833
Epoch: 78, Steps: 132 | Train Loss: 0.1217875 Vali Loss: 0.1807188 Test Loss: 0.2132459
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.1183096
	speed: 2.2975s/iter; left time: 6444.4839s
Epoch: 79 cost time: 141.36783814430237
Epoch: 79, Steps: 132 | Train Loss: 0.1218062 Vali Loss: 0.1809435 Test Loss: 0.2132207
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.1208461
	speed: 2.3296s/iter; left time: 6227.1150s
Epoch: 80 cost time: 139.16242861747742
Epoch: 80, Steps: 132 | Train Loss: 0.1217936 Vali Loss: 0.1809959 Test Loss: 0.2131961
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.1287317
	speed: 2.4414s/iter; left time: 6203.4740s
Epoch: 81 cost time: 148.61906027793884
Epoch: 81, Steps: 132 | Train Loss: 0.1217612 Vali Loss: 0.1809988 Test Loss: 0.2131748
EarlyStopping counter: 13 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.1181674
	speed: 2.3005s/iter; left time: 5541.8760s
Epoch: 82 cost time: 137.7920389175415
Epoch: 82, Steps: 132 | Train Loss: 0.1217450 Vali Loss: 0.1807965 Test Loss: 0.2131557
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.1267837
	speed: 2.0682s/iter; left time: 4709.3124s
Epoch: 83 cost time: 117.54214525222778
Epoch: 83, Steps: 132 | Train Loss: 0.1217607 Vali Loss: 0.1809293 Test Loss: 0.2131369
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.1246625
	speed: 1.9740s/iter; left time: 4234.3096s
Epoch: 84 cost time: 124.6539261341095
Epoch: 84, Steps: 132 | Train Loss: 0.1217220 Vali Loss: 0.1809972 Test Loss: 0.2131158
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.1229270
	speed: 1.8879s/iter; left time: 3800.4010s
Epoch: 85 cost time: 110.92782354354858
Epoch: 85, Steps: 132 | Train Loss: 0.1216855 Vali Loss: 0.1809944 Test Loss: 0.2131005
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.1186541
	speed: 1.7987s/iter; left time: 3383.3706s
Epoch: 86 cost time: 116.02846145629883
Epoch: 86, Steps: 132 | Train Loss: 0.1217115 Vali Loss: 0.1808826 Test Loss: 0.2130842
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.1243911
	speed: 2.1669s/iter; left time: 3789.9048s
Epoch: 87 cost time: 126.23363208770752
Epoch: 87, Steps: 132 | Train Loss: 0.1217288 Vali Loss: 0.1808984 Test Loss: 0.2130713
EarlyStopping counter: 19 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.1342046
	speed: 1.9995s/iter; left time: 3233.1319s
Epoch: 88 cost time: 110.54326248168945
Epoch: 88, Steps: 132 | Train Loss: 0.1216682 Vali Loss: 0.1808439 Test Loss: 0.2130561
EarlyStopping counter: 20 out of 20
Early stopping
train 16973
val 1913
test 4541
Model(
  (freq_upsampler): Linear(in_features=196, out_features=392, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3156873216.0
params:  77224.0
Trainable parameters:  77224
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2229509
	speed: 0.9102s/iter; left time: 11924.2400s
Epoch: 1 cost time: 118.42241287231445
Epoch: 1, Steps: 132 | Train Loss: 0.2237563 Vali Loss: 0.1803399 Test Loss: 0.2119560
Validation loss decreased (inf --> 0.180340).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2252254
	speed: 1.8037s/iter; left time: 23392.2191s
Epoch: 2 cost time: 106.75995254516602
Epoch: 2, Steps: 132 | Train Loss: 0.2232117 Vali Loss: 0.1804463 Test Loss: 0.2117226
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2292961
	speed: 1.6479s/iter; left time: 21154.6869s
Epoch: 3 cost time: 97.90998244285583
Epoch: 3, Steps: 132 | Train Loss: 0.2230975 Vali Loss: 0.1803487 Test Loss: 0.2116953
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2146914
	speed: 1.7310s/iter; left time: 21992.9646s
Epoch: 4 cost time: 105.12581372261047
Epoch: 4, Steps: 132 | Train Loss: 0.2228803 Vali Loss: 0.1801983 Test Loss: 0.2113932
Validation loss decreased (0.180340 --> 0.180198).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2263938
	speed: 1.7211s/iter; left time: 21639.0806s
Epoch: 5 cost time: 102.6849045753479
Epoch: 5, Steps: 132 | Train Loss: 0.2229141 Vali Loss: 0.1801380 Test Loss: 0.2115324
Validation loss decreased (0.180198 --> 0.180138).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2205055
	speed: 1.7661s/iter; left time: 21971.5481s
Epoch: 6 cost time: 110.67913246154785
Epoch: 6, Steps: 132 | Train Loss: 0.2228858 Vali Loss: 0.1800314 Test Loss: 0.2114065
Validation loss decreased (0.180138 --> 0.180031).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2240612
	speed: 1.8096s/iter; left time: 22274.2243s
Epoch: 7 cost time: 107.02459239959717
Epoch: 7, Steps: 132 | Train Loss: 0.2226803 Vali Loss: 0.1802763 Test Loss: 0.2115580
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2269236
	speed: 1.7326s/iter; left time: 21098.0394s
Epoch: 8 cost time: 104.43902707099915
Epoch: 8, Steps: 132 | Train Loss: 0.2227047 Vali Loss: 0.1801012 Test Loss: 0.2114394
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2401715
	speed: 1.7261s/iter; left time: 20790.6613s
Epoch: 9 cost time: 105.66319561004639
Epoch: 9, Steps: 132 | Train Loss: 0.2226943 Vali Loss: 0.1799886 Test Loss: 0.2114197
Validation loss decreased (0.180031 --> 0.179989).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2302027
	speed: 1.7479s/iter; left time: 20822.5490s
Epoch: 10 cost time: 108.44119215011597
Epoch: 10, Steps: 132 | Train Loss: 0.2226348 Vali Loss: 0.1801047 Test Loss: 0.2114011
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2284347
	speed: 1.7711s/iter; left time: 20865.3756s
Epoch: 11 cost time: 105.78680944442749
Epoch: 11, Steps: 132 | Train Loss: 0.2226779 Vali Loss: 0.1801548 Test Loss: 0.2113813
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2257626
	speed: 1.7714s/iter; left time: 20634.7166s
Epoch: 12 cost time: 106.52909970283508
Epoch: 12, Steps: 132 | Train Loss: 0.2227155 Vali Loss: 0.1796041 Test Loss: 0.2114968
Validation loss decreased (0.179989 --> 0.179604).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2282136
	speed: 1.7696s/iter; left time: 20381.0458s
Epoch: 13 cost time: 106.49504613876343
Epoch: 13, Steps: 132 | Train Loss: 0.2226293 Vali Loss: 0.1797028 Test Loss: 0.2113520
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2240773
	speed: 1.7495s/iter; left time: 19918.4524s
Epoch: 14 cost time: 104.38090181350708
Epoch: 14, Steps: 132 | Train Loss: 0.2226005 Vali Loss: 0.1798785 Test Loss: 0.2113702
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2179862
	speed: 1.7738s/iter; left time: 19960.5573s
Epoch: 15 cost time: 106.87541151046753
Epoch: 15, Steps: 132 | Train Loss: 0.2226475 Vali Loss: 0.1799164 Test Loss: 0.2112994
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2341707
	speed: 1.7157s/iter; left time: 19080.5207s
Epoch: 16 cost time: 105.92332935333252
Epoch: 16, Steps: 132 | Train Loss: 0.2225740 Vali Loss: 0.1803766 Test Loss: 0.2113117
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2182276
	speed: 1.7499s/iter; left time: 19229.9864s
Epoch: 17 cost time: 107.01047110557556
Epoch: 17, Steps: 132 | Train Loss: 0.2225303 Vali Loss: 0.1798436 Test Loss: 0.2113539
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2248749
	speed: 1.7551s/iter; left time: 19054.9207s
Epoch: 18 cost time: 105.99553155899048
Epoch: 18, Steps: 132 | Train Loss: 0.2225156 Vali Loss: 0.1798967 Test Loss: 0.2113267
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2197544
	speed: 1.7515s/iter; left time: 18785.2238s
Epoch: 19 cost time: 104.88932752609253
Epoch: 19, Steps: 132 | Train Loss: 0.2225642 Vali Loss: 0.1796574 Test Loss: 0.2113494
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2248700
	speed: 1.7355s/iter; left time: 18383.7656s
Epoch: 20 cost time: 104.11747241020203
Epoch: 20, Steps: 132 | Train Loss: 0.2224528 Vali Loss: 0.1797414 Test Loss: 0.2113897
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2150949
	speed: 1.7241s/iter; left time: 18035.6590s
Epoch: 21 cost time: 104.54160571098328
Epoch: 21, Steps: 132 | Train Loss: 0.2225807 Vali Loss: 0.1798199 Test Loss: 0.2113757
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2294087
	speed: 1.7348s/iter; left time: 17918.7433s
Epoch: 22 cost time: 103.78949165344238
Epoch: 22, Steps: 132 | Train Loss: 0.2224447 Vali Loss: 0.1797368 Test Loss: 0.2113305
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2283479
	speed: 1.7236s/iter; left time: 17575.6257s
Epoch: 23 cost time: 101.38905239105225
Epoch: 23, Steps: 132 | Train Loss: 0.2224519 Vali Loss: 0.1799849 Test Loss: 0.2113181
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2091813
	speed: 1.7559s/iter; left time: 17673.4008s
Epoch: 24 cost time: 108.11473608016968
Epoch: 24, Steps: 132 | Train Loss: 0.2224302 Vali Loss: 0.1796806 Test Loss: 0.2113201
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2228893
	speed: 1.8114s/iter; left time: 17992.6850s
Epoch: 25 cost time: 111.91369342803955
Epoch: 25, Steps: 132 | Train Loss: 0.2224301 Vali Loss: 0.1798201 Test Loss: 0.2113419
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2278618
	speed: 1.8071s/iter; left time: 17711.6355s
Epoch: 26 cost time: 110.53656578063965
Epoch: 26, Steps: 132 | Train Loss: 0.2224872 Vali Loss: 0.1800885 Test Loss: 0.2113609
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2246393
	speed: 1.8653s/iter; left time: 18035.3756s
Epoch: 27 cost time: 112.07796716690063
Epoch: 27, Steps: 132 | Train Loss: 0.2224101 Vali Loss: 0.1797521 Test Loss: 0.2113219
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2251222
	speed: 1.8245s/iter; left time: 17399.7980s
Epoch: 28 cost time: 111.81491565704346
Epoch: 28, Steps: 132 | Train Loss: 0.2224557 Vali Loss: 0.1796971 Test Loss: 0.2113100
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2223353
	speed: 1.6941s/iter; left time: 15933.2414s
Epoch: 29 cost time: 90.49141788482666
Epoch: 29, Steps: 132 | Train Loss: 0.2223713 Vali Loss: 0.1795986 Test Loss: 0.2113427
Validation loss decreased (0.179604 --> 0.179599).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2114903
	speed: 1.3598s/iter; left time: 12609.4585s
Epoch: 30 cost time: 80.82228755950928
Epoch: 30, Steps: 132 | Train Loss: 0.2223813 Vali Loss: 0.1797514 Test Loss: 0.2113004
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2175187
	speed: 1.3385s/iter; left time: 12235.1628s
Epoch: 31 cost time: 80.01991128921509
Epoch: 31, Steps: 132 | Train Loss: 0.2224716 Vali Loss: 0.1797509 Test Loss: 0.2113339
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2321750
	speed: 1.2896s/iter; left time: 11617.6522s
Epoch: 32 cost time: 78.80873608589172
Epoch: 32, Steps: 132 | Train Loss: 0.2224795 Vali Loss: 0.1797751 Test Loss: 0.2113348
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2210211
	speed: 1.1370s/iter; left time: 10092.8405s
Epoch: 33 cost time: 62.702592611312866
Epoch: 33, Steps: 132 | Train Loss: 0.2224324 Vali Loss: 0.1797981 Test Loss: 0.2113201
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2296011
	speed: 0.9648s/iter; left time: 8436.7798s
Epoch: 34 cost time: 59.071155309677124
Epoch: 34, Steps: 132 | Train Loss: 0.2224419 Vali Loss: 0.1796053 Test Loss: 0.2113101
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2218935
	speed: 1.0172s/iter; left time: 8761.2991s
Epoch: 35 cost time: 60.69658303260803
Epoch: 35, Steps: 132 | Train Loss: 0.2224784 Vali Loss: 0.1796614 Test Loss: 0.2112721
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2186376
	speed: 1.0759s/iter; left time: 9125.0811s
Epoch: 36 cost time: 67.486989736557
Epoch: 36, Steps: 132 | Train Loss: 0.2224872 Vali Loss: 0.1798726 Test Loss: 0.2112765
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2307750
	speed: 1.0844s/iter; left time: 9053.8333s
Epoch: 37 cost time: 63.140785217285156
Epoch: 37, Steps: 132 | Train Loss: 0.2224510 Vali Loss: 0.1795655 Test Loss: 0.2113042
Validation loss decreased (0.179599 --> 0.179566).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2201461
	speed: 1.0925s/iter; left time: 8976.8572s
Epoch: 38 cost time: 68.24282217025757
Epoch: 38, Steps: 132 | Train Loss: 0.2223498 Vali Loss: 0.1798328 Test Loss: 0.2113150
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2348730
	speed: 1.1137s/iter; left time: 9004.3898s
Epoch: 39 cost time: 66.09177422523499
Epoch: 39, Steps: 132 | Train Loss: 0.2224176 Vali Loss: 0.1797347 Test Loss: 0.2112938
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2269650
	speed: 1.0207s/iter; left time: 8117.6820s
Epoch: 40 cost time: 60.58932113647461
Epoch: 40, Steps: 132 | Train Loss: 0.2224475 Vali Loss: 0.1801293 Test Loss: 0.2113121
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2257994
	speed: 1.0609s/iter; left time: 8297.2914s
Epoch: 41 cost time: 64.89077234268188
Epoch: 41, Steps: 132 | Train Loss: 0.2224321 Vali Loss: 0.1795996 Test Loss: 0.2113017
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2296450
	speed: 1.0452s/iter; left time: 8036.1841s
Epoch: 42 cost time: 64.07599449157715
Epoch: 42, Steps: 132 | Train Loss: 0.2223263 Vali Loss: 0.1799015 Test Loss: 0.2113006
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2137691
	speed: 1.1064s/iter; left time: 8360.7812s
Epoch: 43 cost time: 66.97139143943787
Epoch: 43, Steps: 132 | Train Loss: 0.2223854 Vali Loss: 0.1797950 Test Loss: 0.2112800
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2099752
	speed: 1.1211s/iter; left time: 8324.2614s
Epoch: 44 cost time: 67.28833270072937
Epoch: 44, Steps: 132 | Train Loss: 0.2224668 Vali Loss: 0.1799971 Test Loss: 0.2112759
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2367412
	speed: 1.0050s/iter; left time: 7329.2771s
Epoch: 45 cost time: 58.35794949531555
Epoch: 45, Steps: 132 | Train Loss: 0.2223811 Vali Loss: 0.1795680 Test Loss: 0.2112925
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2257589
	speed: 0.9979s/iter; left time: 7146.0759s
Epoch: 46 cost time: 62.41429114341736
Epoch: 46, Steps: 132 | Train Loss: 0.2224721 Vali Loss: 0.1795742 Test Loss: 0.2112989
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2281749
	speed: 1.0674s/iter; left time: 7503.0357s
Epoch: 47 cost time: 66.44109416007996
Epoch: 47, Steps: 132 | Train Loss: 0.2222602 Vali Loss: 0.1796324 Test Loss: 0.2112716
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2172243
	speed: 1.0905s/iter; left time: 7521.5152s
Epoch: 48 cost time: 65.02512741088867
Epoch: 48, Steps: 132 | Train Loss: 0.2223905 Vali Loss: 0.1795407 Test Loss: 0.2113021
Validation loss decreased (0.179566 --> 0.179541).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2130445
	speed: 1.0841s/iter; left time: 7333.6812s
Epoch: 49 cost time: 65.58210921287537
Epoch: 49, Steps: 132 | Train Loss: 0.2224079 Vali Loss: 0.1798806 Test Loss: 0.2112885
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2322141
	speed: 1.0900s/iter; left time: 7229.9158s
Epoch: 50 cost time: 67.76598453521729
Epoch: 50, Steps: 132 | Train Loss: 0.2223310 Vali Loss: 0.1792796 Test Loss: 0.2112835
Validation loss decreased (0.179541 --> 0.179280).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
	iters: 100, epoch: 51 | loss: 0.2096052
	speed: 1.1470s/iter; left time: 7456.7085s
Epoch: 51 cost time: 69.0705349445343
Epoch: 51, Steps: 132 | Train Loss: 0.2224123 Vali Loss: 0.1794214 Test Loss: 0.2112816
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
	iters: 100, epoch: 52 | loss: 0.2177289
	speed: 1.1016s/iter; left time: 7016.1578s
Epoch: 52 cost time: 65.5932469367981
Epoch: 52, Steps: 132 | Train Loss: 0.2223391 Vali Loss: 0.1796343 Test Loss: 0.2112942
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
	iters: 100, epoch: 53 | loss: 0.2314929
	speed: 1.1086s/iter; left time: 6914.2091s
Epoch: 53 cost time: 67.29421401023865
Epoch: 53, Steps: 132 | Train Loss: 0.2223686 Vali Loss: 0.1796451 Test Loss: 0.2112803
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.47214200936168e-05
	iters: 100, epoch: 54 | loss: 0.2231271
	speed: 1.1207s/iter; left time: 6841.8343s
Epoch: 54 cost time: 68.38845014572144
Epoch: 54, Steps: 132 | Train Loss: 0.2223737 Vali Loss: 0.1797128 Test Loss: 0.2112822
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.298534908893597e-05
	iters: 100, epoch: 55 | loss: 0.2211984
	speed: 1.1366s/iter; left time: 6788.7339s
Epoch: 55 cost time: 69.02431106567383
Epoch: 55, Steps: 132 | Train Loss: 0.2224009 Vali Loss: 0.1797086 Test Loss: 0.2112856
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.1336081634489166e-05
	iters: 100, epoch: 56 | loss: 0.2251991
	speed: 1.1141s/iter; left time: 6507.6382s
Epoch: 56 cost time: 65.68559098243713
Epoch: 56, Steps: 132 | Train Loss: 0.2224336 Vali Loss: 0.1799574 Test Loss: 0.2112886
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.9769277552764706e-05
	iters: 100, epoch: 57 | loss: 0.2241845
	speed: 1.0885s/iter; left time: 6214.3899s
Epoch: 57 cost time: 66.62340450286865
Epoch: 57, Steps: 132 | Train Loss: 0.2224095 Vali Loss: 0.1795972 Test Loss: 0.2112883
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.8280813675126466e-05
	iters: 100, epoch: 58 | loss: 0.2125794
	speed: 1.0776s/iter; left time: 6009.5609s
Epoch: 58 cost time: 67.2215895652771
Epoch: 58, Steps: 132 | Train Loss: 0.2223145 Vali Loss: 0.1796912 Test Loss: 0.2112883
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.6866772991370145e-05
	iters: 100, epoch: 59 | loss: 0.2317058
	speed: 1.0372s/iter; left time: 5647.6234s
Epoch: 59 cost time: 61.012850284576416
Epoch: 59, Steps: 132 | Train Loss: 0.2224206 Vali Loss: 0.1796869 Test Loss: 0.2112830
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.5523434341801633e-05
	iters: 100, epoch: 60 | loss: 0.2184824
	speed: 0.9867s/iter; left time: 5242.4326s
Epoch: 60 cost time: 60.06988883018494
Epoch: 60, Steps: 132 | Train Loss: 0.2223625 Vali Loss: 0.1797774 Test Loss: 0.2112909
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.4247262624711552e-05
	iters: 100, epoch: 61 | loss: 0.2222891
	speed: 1.0495s/iter; left time: 5437.5975s
Epoch: 61 cost time: 64.71202564239502
Epoch: 61, Steps: 132 | Train Loss: 0.2223621 Vali Loss: 0.1798886 Test Loss: 0.2112834
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.3034899493475973e-05
	iters: 100, epoch: 62 | loss: 0.2315406
	speed: 1.0554s/iter; left time: 5328.5722s
Epoch: 62 cost time: 64.5541501045227
Epoch: 62, Steps: 132 | Train Loss: 0.2223350 Vali Loss: 0.1797885 Test Loss: 0.2112857
EarlyStopping counter: 12 out of 20
Updating learning rate to 2.1883154518802173e-05
	iters: 100, epoch: 63 | loss: 0.2156715
	speed: 1.0726s/iter; left time: 5273.9160s
Epoch: 63 cost time: 65.30919241905212
Epoch: 63, Steps: 132 | Train Loss: 0.2222798 Vali Loss: 0.1797935 Test Loss: 0.2112789
EarlyStopping counter: 13 out of 20
Updating learning rate to 2.0788996792862066e-05
	iters: 100, epoch: 64 | loss: 0.2118494
	speed: 1.1315s/iter; left time: 5414.2737s
Epoch: 64 cost time: 68.43319797515869
Epoch: 64, Steps: 132 | Train Loss: 0.2223629 Vali Loss: 0.1802374 Test Loss: 0.2112769
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.974954695321896e-05
	iters: 100, epoch: 65 | loss: 0.2288217
	speed: 1.0730s/iter; left time: 4992.6447s
Epoch: 65 cost time: 65.80755543708801
Epoch: 65, Steps: 132 | Train Loss: 0.2223492 Vali Loss: 0.1795447 Test Loss: 0.2112848
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.876206960555801e-05
	iters: 100, epoch: 66 | loss: 0.2257450
	speed: 1.1376s/iter; left time: 5142.8976s
Epoch: 66 cost time: 67.86206912994385
Epoch: 66, Steps: 132 | Train Loss: 0.2222955 Vali Loss: 0.1798623 Test Loss: 0.2112862
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.782396612528011e-05
	iters: 100, epoch: 67 | loss: 0.2317838
	speed: 0.9980s/iter; left time: 4380.2288s
Epoch: 67 cost time: 60.07038068771362
Epoch: 67, Steps: 132 | Train Loss: 0.2222039 Vali Loss: 0.1797719 Test Loss: 0.2112813
EarlyStopping counter: 17 out of 20
Updating learning rate to 1.6932767819016104e-05
	iters: 100, epoch: 68 | loss: 0.2224958
	speed: 1.0660s/iter; left time: 4538.0387s
Epoch: 68 cost time: 66.76318168640137
Epoch: 68, Steps: 132 | Train Loss: 0.2223311 Vali Loss: 0.1796902 Test Loss: 0.2112793
EarlyStopping counter: 18 out of 20
Updating learning rate to 1.6086129428065296e-05
	iters: 100, epoch: 69 | loss: 0.2245310
	speed: 1.1008s/iter; left time: 4540.7220s
Epoch: 69 cost time: 67.14279651641846
Epoch: 69, Steps: 132 | Train Loss: 0.2223604 Vali Loss: 0.1795285 Test Loss: 0.2112850
EarlyStopping counter: 19 out of 20
Updating learning rate to 1.5281822956662033e-05
	iters: 100, epoch: 70 | loss: 0.2052321
	speed: 1.1019s/iter; left time: 4399.9495s
Epoch: 70 cost time: 65.81396818161011
Epoch: 70, Steps: 132 | Train Loss: 0.2223641 Vali Loss: 0.1792698 Test Loss: 0.2112855
Validation loss decreased (0.179280 --> 0.179270).  Saving model ...
Updating learning rate to 1.451773180882893e-05
	iters: 100, epoch: 71 | loss: 0.2589648
	speed: 1.1178s/iter; left time: 4315.9872s
Epoch: 71 cost time: 67.88164710998535
Epoch: 71, Steps: 132 | Train Loss: 0.2223695 Vali Loss: 0.1794761 Test Loss: 0.2112811
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3791845218387483e-05
	iters: 100, epoch: 72 | loss: 0.2064882
	speed: 1.0754s/iter; left time: 4010.2515s
Epoch: 72 cost time: 63.564756631851196
Epoch: 72, Steps: 132 | Train Loss: 0.2223119 Vali Loss: 0.1798514 Test Loss: 0.2112800
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.3102252957468109e-05
	iters: 100, epoch: 73 | loss: 0.2188948
	speed: 1.0787s/iter; left time: 3880.1921s
Epoch: 73 cost time: 68.71477484703064
Epoch: 73, Steps: 132 | Train Loss: 0.2223168 Vali Loss: 0.1794848 Test Loss: 0.2112802
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.2447140309594702e-05
	iters: 100, epoch: 74 | loss: 0.2122916
	speed: 1.1484s/iter; left time: 3979.1733s
Epoch: 74 cost time: 64.51350545883179
Epoch: 74, Steps: 132 | Train Loss: 0.2224065 Vali Loss: 0.1795962 Test Loss: 0.2112836
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.1824783294114967e-05
	iters: 100, epoch: 75 | loss: 0.2324058
	speed: 1.0030s/iter; left time: 3343.0072s
Epoch: 75 cost time: 60.57667326927185
Epoch: 75, Steps: 132 | Train Loss: 0.2223331 Vali Loss: 0.1796022 Test Loss: 0.2112816
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.1233544129409218e-05
	iters: 100, epoch: 76 | loss: 0.2101729
	speed: 1.0173s/iter; left time: 3256.3761s
Epoch: 76 cost time: 62.98640298843384
Epoch: 76, Steps: 132 | Train Loss: 0.2223576 Vali Loss: 0.1797152 Test Loss: 0.2112832
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.0671866922938755e-05
	iters: 100, epoch: 77 | loss: 0.2162226
	speed: 1.0382s/iter; left time: 3186.2604s
Epoch: 77 cost time: 63.83963346481323
Epoch: 77, Steps: 132 | Train Loss: 0.2222776 Vali Loss: 0.1796369 Test Loss: 0.2112813
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.0138273576791817e-05
	iters: 100, epoch: 78 | loss: 0.2269953
	speed: 1.1221s/iter; left time: 3295.7328s
Epoch: 78 cost time: 67.72688364982605
Epoch: 78, Steps: 132 | Train Loss: 0.2223818 Vali Loss: 0.1793964 Test Loss: 0.2112827
EarlyStopping counter: 8 out of 20
Updating learning rate to 9.631359897952226e-06
	iters: 100, epoch: 79 | loss: 0.2312368
	speed: 1.1011s/iter; left time: 3088.6277s
Epoch: 79 cost time: 69.09278917312622
Epoch: 79, Steps: 132 | Train Loss: 0.2223925 Vali Loss: 0.1794454 Test Loss: 0.2112818
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.149791903054614e-06
	iters: 100, epoch: 80 | loss: 0.2312844
	speed: 1.1230s/iter; left time: 3001.7030s
Epoch: 80 cost time: 67.47060060501099
Epoch: 80, Steps: 132 | Train Loss: 0.2223799 Vali Loss: 0.1795175 Test Loss: 0.2112835
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.692302307901884e-06
	iters: 100, epoch: 81 | loss: 0.2180992
	speed: 1.1843s/iter; left time: 3009.1909s
Epoch: 81 cost time: 71.42792797088623
Epoch: 81, Steps: 132 | Train Loss: 0.2223976 Vali Loss: 0.1795170 Test Loss: 0.2112817
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.25768719250679e-06
	iters: 100, epoch: 82 | loss: 0.2373008
	speed: 1.0954s/iter; left time: 2638.8113s
Epoch: 82 cost time: 66.46406507492065
Epoch: 82, Steps: 132 | Train Loss: 0.2222911 Vali Loss: 0.1797385 Test Loss: 0.2112816
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.84480283288145e-06
	iters: 100, epoch: 83 | loss: 0.2247267
	speed: 1.1544s/iter; left time: 2628.6789s
Epoch: 83 cost time: 71.91872978210449
Epoch: 83, Steps: 132 | Train Loss: 0.2223351 Vali Loss: 0.1795512 Test Loss: 0.2112831
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.452562691237377e-06
	iters: 100, epoch: 84 | loss: 0.2131315
	speed: 1.1970s/iter; left time: 2567.5494s
Epoch: 84 cost time: 71.98765182495117
Epoch: 84, Steps: 132 | Train Loss: 0.2223813 Vali Loss: 0.1795683 Test Loss: 0.2112833
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.079934556675507e-06
	iters: 100, epoch: 85 | loss: 0.2386894
	speed: 1.0873s/iter; left time: 2188.7871s
Epoch: 85 cost time: 65.92055010795593
Epoch: 85, Steps: 132 | Train Loss: 0.2223653 Vali Loss: 0.1796100 Test Loss: 0.2112843
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.725937828841732e-06
	iters: 100, epoch: 86 | loss: 0.2321070
	speed: 1.1468s/iter; left time: 2157.2120s
Epoch: 86 cost time: 68.63398742675781
Epoch: 86, Steps: 132 | Train Loss: 0.2223674 Vali Loss: 0.1796234 Test Loss: 0.2112834
EarlyStopping counter: 16 out of 20
Updating learning rate to 6.389640937399644e-06
	iters: 100, epoch: 87 | loss: 0.2317195
	speed: 1.0680s/iter; left time: 1868.0081s
Epoch: 87 cost time: 63.358437299728394
Epoch: 87, Steps: 132 | Train Loss: 0.2223223 Vali Loss: 0.1798847 Test Loss: 0.2112835
EarlyStopping counter: 17 out of 20
Updating learning rate to 6.070158890529662e-06
	iters: 100, epoch: 88 | loss: 0.2194749
	speed: 1.1559s/iter; left time: 1869.1555s
Epoch: 88 cost time: 70.6308364868164
Epoch: 88, Steps: 132 | Train Loss: 0.2222812 Vali Loss: 0.1797038 Test Loss: 0.2112831
EarlyStopping counter: 18 out of 20
Updating learning rate to 5.766650946003179e-06
	iters: 100, epoch: 89 | loss: 0.2240475
	speed: 1.1235s/iter; left time: 1668.4464s
Epoch: 89 cost time: 69.61474275588989
Epoch: 89, Steps: 132 | Train Loss: 0.2223835 Vali Loss: 0.1795830 Test Loss: 0.2112820
EarlyStopping counter: 19 out of 20
Updating learning rate to 5.47831839870302e-06
	iters: 100, epoch: 90 | loss: 0.2355765
	speed: 1.1239s/iter; left time: 1520.6499s
Epoch: 90 cost time: 67.0364842414856
Epoch: 90, Steps: 132 | Train Loss: 0.2223765 Vali Loss: 0.1799409 Test Loss: 0.2112816
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_720_j720_H6_FITS_custom_ftM_sl720_ll48_pl720_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
mse:0.20959050953388214, mae:0.3014536499977112, rse:0.4566812813282013, corr:[0.44661835 0.44953552 0.450205   0.45049736 0.45073876 0.45079735
 0.45072323 0.450641   0.45054114 0.45040137 0.4502724  0.450238
 0.45018312 0.45011887 0.45011917 0.45012996 0.45005843 0.45002234
 0.4500154  0.44987732 0.44976208 0.44979832 0.44986972 0.44996265
 0.45016256 0.45052192 0.45062274 0.4505833  0.45054576 0.45047775
 0.45035252 0.45023295 0.4501069  0.44997317 0.44984698 0.44978568
 0.44974947 0.44970027 0.44966856 0.44965866 0.4496391  0.4496227
 0.4495988  0.44946656 0.4493417  0.44933993 0.44940895 0.44949207
 0.4496325  0.44987148 0.44995752 0.4499182  0.44985554 0.4497828
 0.44970056 0.44963434 0.44956744 0.44948146 0.44939208 0.44932112
 0.44927856 0.44926152 0.4492586  0.44924933 0.44923708 0.44924942
 0.44922712 0.44906923 0.44895676 0.44896016 0.44900188 0.4490312
 0.44910166 0.44924372 0.4492699  0.4492278  0.4491772  0.44910806
 0.4490171  0.44891882 0.4488462  0.4487913  0.44873428 0.44867805
 0.4486202  0.44858882 0.4485974  0.4486005  0.44857877 0.44857684
 0.44858554 0.44850037 0.44840705 0.44840664 0.44843295 0.44846705
 0.44856527 0.44869047 0.44868502 0.44864374 0.4486095  0.44856167
 0.4484866  0.44841242 0.44834033 0.44826826 0.448181   0.44811815
 0.4480747  0.44805124 0.44805166 0.44805625 0.44804955 0.4480622
 0.4480445  0.44792333 0.44784245 0.44783542 0.447872   0.44798672
 0.448196   0.44834056 0.44835833 0.44834945 0.44830737 0.4482546
 0.44821048 0.4481568  0.44808662 0.44800383 0.44791773 0.44785398
 0.4478294  0.4478351  0.44786248 0.44787824 0.44788542 0.44791186
 0.44795072 0.44794717 0.44795555 0.4479768  0.4479679  0.44797006
 0.44801956 0.44809985 0.4481053  0.44811198 0.4480976  0.44804513
 0.44798797 0.44796306 0.44793108 0.44784832 0.44776225 0.44772184
 0.44770515 0.44768873 0.44769585 0.44769982 0.44772238 0.44778702
 0.44785193 0.44780573 0.44774994 0.44773474 0.44763905 0.4475093
 0.44744128 0.44754714 0.4475497  0.44748348 0.44740868 0.4473136
 0.44720888 0.44710693 0.44699872 0.4469029  0.4468208  0.44677284
 0.4467361  0.44670185 0.4466949  0.446691   0.44666964 0.4466611
 0.44661272 0.4464078  0.44624048 0.44618598 0.4461474  0.4461278
 0.44619286 0.44636592 0.44640023 0.4463626  0.4463242  0.4462518
 0.44613734 0.44603872 0.44597358 0.44588742 0.44578707 0.44573393
 0.4457122  0.44567737 0.44567397 0.44567925 0.44566593 0.44565886
 0.44563544 0.44545773 0.44528806 0.44523907 0.44523546 0.44524768
 0.44533047 0.44551158 0.44557053 0.4455439  0.4455135  0.44547328
 0.44540676 0.44533634 0.44528687 0.4452078  0.44511107 0.445037
 0.44499958 0.44497335 0.44496852 0.4449628  0.44496703 0.44496867
 0.44494194 0.44478047 0.4446501  0.4446143  0.44461966 0.44463554
 0.4447095  0.4448702  0.44493458 0.44492942 0.44490242 0.4448459
 0.4447711  0.4446937  0.44463602 0.4445655  0.44448143 0.4444215
 0.44437602 0.44434798 0.44434795 0.44434717 0.44432873 0.44432756
 0.44432533 0.44424215 0.44417435 0.44417682 0.44419566 0.4442094
 0.4442953  0.44443655 0.44447702 0.44445908 0.44443202 0.44438872
 0.4443098  0.44421852 0.44413152 0.4440501  0.44397756 0.44392565
 0.44389793 0.44387004 0.44388106 0.44389474 0.44388708 0.44388473
 0.44385326 0.44373873 0.4436748  0.44368008 0.44373733 0.44387504
 0.44409633 0.44424295 0.44426823 0.4442792  0.4442533  0.44420227
 0.44416755 0.4441247  0.4440455  0.44393694 0.44383937 0.44378102
 0.44375628 0.44375837 0.44377682 0.44376627 0.44374186 0.44376674
 0.44383162 0.44383857 0.443827   0.44384977 0.44386208 0.44385856
 0.4438788  0.44394615 0.4439629  0.44396368 0.443951   0.44391266
 0.44385278 0.4437908  0.44373894 0.44366163 0.44357497 0.44351253
 0.44348738 0.44347933 0.44349593 0.44351336 0.44354078 0.4435887
 0.44360912 0.44352004 0.44342905 0.4433926  0.4432661  0.44308856
 0.44298267 0.44306627 0.44304538 0.44297403 0.4429     0.4428022
 0.44267783 0.44255468 0.44242567 0.44230428 0.44220054 0.44213066
 0.44208804 0.44205824 0.44206682 0.44206223 0.4420345  0.44203815
 0.4420436  0.44192827 0.44181827 0.44181433 0.4418087  0.44178098
 0.4417974  0.4419181  0.4419241  0.44187    0.44182947 0.44177526
 0.44166237 0.4415322  0.44142804 0.44133464 0.44124413 0.44117832
 0.44114053 0.44109386 0.44108078 0.44108835 0.4410943  0.44110176
 0.4410845  0.44094568 0.44083178 0.4408165  0.44082683 0.44083855
 0.44089454 0.44101745 0.44107136 0.44107527 0.44105795 0.4410135
 0.44092566 0.44084266 0.44076923 0.44068512 0.44058928 0.44051996
 0.44048476 0.4404724  0.440493   0.44049868 0.44048083 0.44048658
 0.44049376 0.4403856  0.4402739  0.44025347 0.44024754 0.4402409
 0.44029978 0.44044432 0.44051287 0.4405203  0.44050705 0.44047663
 0.44040257 0.44030026 0.44020045 0.44012836 0.44008076 0.44003436
 0.4400327  0.44004077 0.4400602  0.4400688  0.44006687 0.44009098
 0.44010565 0.43999988 0.4399087  0.43991402 0.43994713 0.4399725
 0.44005275 0.44017157 0.44021553 0.44021422 0.4401964  0.44016513
 0.44012383 0.44005176 0.43995652 0.4398503  0.43977123 0.43974864
 0.43975067 0.43973672 0.43973556 0.43974894 0.43976593 0.4397923
 0.43974707 0.43958762 0.43949798 0.43949884 0.43954432 0.4396609
 0.4398767  0.44002432 0.44005913 0.44009155 0.44009048 0.4400548
 0.44003534 0.43999484 0.43990588 0.43979236 0.43971688 0.4396872
 0.4396749  0.4396609  0.43969253 0.4397322  0.43974864 0.43977043
 0.43981844 0.43983072 0.43982548 0.4398436  0.43983886 0.43982917
 0.4398706  0.43996143 0.43999347 0.44000548 0.44000357 0.4399841
 0.43993935 0.43988383 0.43982384 0.43974483 0.43968    0.4396605
 0.4396736  0.439697   0.43973744 0.43976283 0.43978268 0.43982682
 0.43984562 0.43974262 0.43964636 0.43959185 0.43946874 0.43929812
 0.4391581  0.43917906 0.43914482 0.43910673 0.43906993 0.43899107
 0.43886736 0.43874195 0.43861756 0.43849912 0.43840483 0.4383616
 0.43834323 0.43831348 0.43830672 0.43830913 0.438298   0.4383179
 0.438304   0.43812078 0.43794537 0.43789744 0.4378634  0.43778247
 0.4377361  0.43783584 0.4378811  0.43785033 0.4377917  0.43772754
 0.43763494 0.43752456 0.43739894 0.43726653 0.43714538 0.4370898
 0.43708777 0.43707865 0.43707293 0.43705606 0.43702158 0.43701145
 0.436974   0.4368285  0.43675217 0.43673426 0.43671095 0.43668818
 0.43671542 0.43680373 0.43681937 0.43677375 0.43671238 0.43664014
 0.4365714  0.4365071  0.43642515 0.4363002  0.43615893 0.43605086
 0.43598995 0.4359235  0.43587315 0.43581572 0.43573952 0.43565452
 0.43556586 0.43542784 0.4353145  0.43530384 0.4353395  0.43533504
 0.43536472 0.43548006 0.43554422 0.43554246 0.43551362 0.4354549
 0.43539205 0.43532383 0.43521953 0.4350908  0.43497616 0.4349285
 0.43492588 0.43489796 0.43488878 0.43488562 0.43487087 0.43485317
 0.43483528 0.4347449  0.43468112 0.43468532 0.43469238 0.43468106
 0.43474633 0.43486753 0.4349015  0.43487412 0.4348351  0.43480304
 0.43474573 0.4346472  0.43452126 0.43441847 0.43434238 0.43430045
 0.434284   0.4342661  0.43425336 0.4342376  0.4342213  0.434236
 0.43422168 0.4341108  0.4340415  0.43405336 0.4340719  0.4341446
 0.43434942 0.4344858  0.43448925 0.43449447 0.4344927  0.43445268
 0.4344018  0.43432945 0.43421996 0.43408817 0.43400645 0.43399104
 0.43397033 0.43393192 0.43395117 0.43397844 0.4339694  0.43396544
 0.43400577 0.43401927 0.43400654 0.43402714 0.4340529  0.43404436
 0.4340485  0.43411452 0.4341365  0.43412986 0.43411258 0.43408027
 0.4340174  0.43394026 0.4338877  0.43382812 0.43374628 0.43367797
 0.4336576  0.43366873 0.43367848 0.43368453 0.4337229  0.43378565
 0.4337901  0.4336694  0.43360525 0.43360037 0.4335022  0.4333025
 0.4331087  0.43310648 0.43306598 0.43298265 0.43287754 0.43274486
 0.4326282  0.43252495 0.43238467 0.43222454 0.43212402 0.43207812
 0.4320248  0.43198317 0.43200806 0.43200934 0.43195963 0.43196815
 0.431983   0.4318182  0.4316429  0.43162337 0.43160915 0.43152654
 0.43150252 0.43161303 0.4315992  0.43150577 0.43147323 0.43142018
 0.43127462 0.43115738 0.4269025  0.43095416 0.4308145  0.43081224
 0.42663124 0.43075928 0.43077728 0.4266358  0.42658886 0.43080997
 0.4267155  0.4265283  0.4263839  0.4264777  0.42637905 0.43045402]
