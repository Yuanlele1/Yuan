Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, individual=False, is_training=1, itr=1, label_len=48, learning_rate=0.005, loss='mse', lradj='type1', model='DLinear', model_id='ETTh2_336_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seq_len=336, target='OT', test_flop=False, train_epochs=10, train_only=False, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_336_96_DLinear_ETTh2_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.5833327
	speed: 0.0680s/iter; left time: 167.3177s
	iters: 200, epoch: 1 | loss: 0.3037431
	speed: 0.0537s/iter; left time: 126.7209s
Epoch: 1 cost time: 15.44514775276184
Epoch: 1, Steps: 256 | Train Loss: 0.4700276 Vali Loss: 0.3233340 Test Loss: 0.5183531
Validation loss decreased (inf --> 0.323334).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2501007
	speed: 0.2157s/iter; left time: 475.6385s
	iters: 200, epoch: 2 | loss: 0.5484206
	speed: 0.0592s/iter; left time: 124.6615s
Epoch: 2 cost time: 16.068776845932007
Epoch: 2, Steps: 256 | Train Loss: 0.4460159 Vali Loss: 0.2550586 Test Loss: 0.3606876
Validation loss decreased (0.323334 --> 0.255059).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.4464799
	speed: 0.2189s/iter; left time: 426.6333s
	iters: 200, epoch: 3 | loss: 0.3807354
	speed: 0.0558s/iter; left time: 103.1525s
Epoch: 3 cost time: 15.675629615783691
Epoch: 3, Steps: 256 | Train Loss: 0.4121177 Vali Loss: 0.2386980 Test Loss: 0.3346679
Validation loss decreased (0.255059 --> 0.238698).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5286982
	speed: 0.2167s/iter; left time: 366.8653s
	iters: 200, epoch: 4 | loss: 0.3847786
	speed: 0.0659s/iter; left time: 105.0115s
Epoch: 4 cost time: 17.333957195281982
Epoch: 4, Steps: 256 | Train Loss: 0.3994960 Vali Loss: 0.2350743 Test Loss: 0.3329776
Validation loss decreased (0.238698 --> 0.235074).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.3101895
	speed: 0.2527s/iter; left time: 363.1484s
	iters: 200, epoch: 5 | loss: 0.7994350
	speed: 0.0711s/iter; left time: 95.0461s
Epoch: 5 cost time: 18.612309217453003
Epoch: 5, Steps: 256 | Train Loss: 0.3897759 Vali Loss: 0.2090016 Test Loss: 0.2807273
Validation loss decreased (0.235074 --> 0.209002).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4345850
	speed: 0.2585s/iter; left time: 305.2899s
	iters: 200, epoch: 6 | loss: 0.5048042
	speed: 0.0691s/iter; left time: 74.6807s
Epoch: 6 cost time: 18.676214933395386
Epoch: 6, Steps: 256 | Train Loss: 0.3854331 Vali Loss: 0.2330534 Test Loss: 0.3245729
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4866955
	speed: 0.2522s/iter; left time: 233.2635s
	iters: 200, epoch: 7 | loss: 0.4318261
	speed: 0.0552s/iter; left time: 45.5688s
Epoch: 7 cost time: 15.682114124298096
Epoch: 7, Steps: 256 | Train Loss: 0.3829140 Vali Loss: 0.2233569 Test Loss: 0.3031659
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.3670470
	speed: 0.1880s/iter; left time: 125.7865s
	iters: 200, epoch: 8 | loss: 0.3281014
	speed: 0.0496s/iter; left time: 28.2141s
Epoch: 8 cost time: 13.160130023956299
Epoch: 8, Steps: 256 | Train Loss: 0.3811252 Vali Loss: 0.2218432 Test Loss: 0.3007466
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_336_96_DLinear_ETTh2_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.28209826350212097, mae:0.34556010365486145
